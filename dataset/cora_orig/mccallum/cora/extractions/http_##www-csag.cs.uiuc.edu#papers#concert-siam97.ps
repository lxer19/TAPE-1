URL: http://www-csag.cs.uiuc.edu/papers/concert-siam97.ps
Refering-URL: http://www-csag.cs.uiuc.edu/papers/index.html
Root-URL: http://www.cs.uiuc.edu
Email: fganguly,achieng@cs.uiuc.edu and fgbryan,normang@ncsa.uiuc.edu  
Title: Exploring Structured Adaptive Mesh Refinement (SAMR) Methods with the Illinois Concert System  
Author: Bishwaroop Ganguly, Greg Bryan, Mike Norman, and Andrew Chien 
Date: January 1, 1997  
Affiliation: Department of Computer Science and National Center for Supercomputing Applications University of Illinois at Urbana-Champaign  
Abstract: Structured Adaptive Mesh Refinement (SAMR) simulation methods are attractive because they can increase computational efficiency dramatically. However, their irregular and less predictable computational and data structure makes them challenging to parallelize efficiently on large-scale parallel machines. We use the Illinois Concert C++ system (which supports dynamic, object-based parallelism) to build a flexible SAMR code for the Cosmology NSF Grand Challenge. The Concert System provides language support to ease the expression of the dynamic parallelism, as well as compiler and runtime support for efficient execution. We plan to perform analysis for the Cray T3D and SGI high-performance architectures. Evaluation of the code's achieved sequential performance, and the benefits of using the Illinois Concert system (and parallel object systems in general) for adaptive methods indicates that the code will benefit from parallelization, with sequential times being within a factor of 1.2 to 1.6.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gul Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The Concert system supports fine-grained, concurrent object-oriented programming on Actors <ref> [1] </ref> in an extension of C++ called ICC++ [8, 7]. Computation is expressed as method invocations on objects or collections of objects. Method invocations conceptually operate within dynamically created threads that are inherently concurrent. Thus, the user only thinks about the implementation of the algorithm, and not about managing concurrency.
Reference: [2] <author> John Bell, Marsha Berger, Jeff Saltzman, and Mike Welcome. </author> <title> Three dimensional adapative mesh refinement for hyperbolic conservation law. </title> <journal> SIAM Journal of Scientific Computing, </journal> <volume> 15(1) </volume> <pages> 127-138, </pages> <year> 1994. </year>
Reference-contexts: Our particular code solves the equations of compressible fluid dynamics and is primarily designed for applications in astrophysical hydrodynamics, however SAMR methods have, in general, a much wider area of applicability (e.g. <ref> [2] </ref>). However, SAMR poses a number of significant challenges for parallelization. These include dynamic parallelism, dynamic memory allocation and complex data structures. These characteristics tend to interact poorly with the most widely used parallel programming tools High Performance Fortran (HPF) and Fortran + Message Passing.
Reference: [3] <author> Marsha J. Berger and Phillip Colella. </author> <title> Local adaptive mesh refinement for shock hydrodynamics. </title> <journal> Journal of Computational Physics, </journal> <volume> 82 </volume> <pages> 64-84, </pages> <year> 1989. </year>
Reference-contexts: In general, the most efficient discretization is not known in advance and may change with the evolution of the simulation. Structured Adaptive Mesh Refinement (SAMR) methods explore the dynamical structure of the simulation and adapt their meshing to preserve numerical stability while conserving both computation and memory <ref> [4, 3] </ref>. SAMR methods are based on the observation that many problems have large regions of space which are nearly uniform (or slowly varying) and therefore require only coarse meshes to model correctly.
Reference: [4] <author> Marsha J. Berger and Joseph Oliger. </author> <title> Adaptive mesh refinement for hyperbolic partial differential equations. </title> <journal> Journal of Computational Physics, </journal> <volume> 53 </volume> <pages> 484-512, </pages> <year> 1984. </year> <month> 8 </month>
Reference-contexts: In general, the most efficient discretization is not known in advance and may change with the evolution of the simulation. Structured Adaptive Mesh Refinement (SAMR) methods explore the dynamical structure of the simulation and adapt their meshing to preserve numerical stability while conserving both computation and memory <ref> [4, 3] </ref>. SAMR methods are based on the observation that many problems have large regions of space which are nearly uniform (or slowly varying) and therefore require only coarse meshes to model correctly.
Reference: [5] <author> Greg L. Bryan. </author> <title> The Numerical Simulation of X-ray Clusters. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: The adaptation is often quite effective, dramatically reducing the computational effort compared to using a single grid with uniform, high-resolution, spacing. The particular code we are using has been successfully applied to a number of physical problems <ref> [23, 5] </ref>. Our particular code solves the equations of compressible fluid dynamics and is primarily designed for applications in astrophysical hydrodynamics, however SAMR methods have, in general, a much wider area of applicability (e.g. [2]). However, SAMR poses a number of significant challenges for parallelization.
Reference: [6] <author> Andrew A. Chien and Julian Dolby. </author> <title> The Illinois Concert system: A problem-solving environment for irregular applications. </title> <booktitle> In Proceedings of DAGS'94, The Symposium on Parallel Computation and Problem Solving Environments., </booktitle> <year> 1994. </year>
Reference-contexts: Object-level concurrency control maintains sequential consistency of the object state in the global namespace, enabling the safe composition of concurrent operations and freeing the programmer from managing explicit locking. The Concert system implementation <ref> [6] </ref> is a state-of-the-art implementation of a COOP programming model. On distributed memory machines, the execution model synthesizes a global namespace by detecting remote object invocations and translating them into communication operations and hides latency of remote invocations via software multithreading on commercial single-threaded microprocessors.
Reference: [7] <author> Andrew A. Chien and Julian Dolby. </author> <title> Parallel Programming Using C++, chapter ICC++. </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: The Concert system supports fine-grained, concurrent object-oriented programming on Actors [1] in an extension of C++ called ICC++ <ref> [8, 7] </ref>. Computation is expressed as method invocations on objects or collections of objects. Method invocations conceptually operate within dynamically created threads that are inherently concurrent. Thus, the user only thinks about the implementation of the algorithm, and not about managing concurrency.
Reference: [8] <author> Andrew A. Chien, Uday S. Reddy, John Plevyak, and Julian Dolby. </author> <title> Icc++ a c++ dialect for high-performance parallel computation. </title> <booktitle> In Proceedings of the 2nd International Symposium on Object Technologies for Advanced Software, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: The Concert system supports fine-grained, concurrent object-oriented programming on Actors [1] in an extension of C++ called ICC++ <ref> [8, 7] </ref>. Computation is expressed as method invocations on objects or collections of objects. Method invocations conceptually operate within dynamically created threads that are inherently concurrent. Thus, the user only thinks about the implementation of the algorithm, and not about managing concurrency.
Reference: [9] <author> Andrew S. Grimshaw. </author> <title> The mentat computation model data-driven support for object-oriented parallel processing. </title> <type> Technical report, </type> <institution> University of Virginia, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: We believe our system is more general, in the sense that we support objects of arbitrary structure as opposed to regular rectangular meshes that LPARX manipulates. Our goal is to show that this added flexibility comes at no additional cost in terms of performance. The Mentat <ref> [9] </ref> system also allows users to define concurrent objects and uses a Macro-Dataflow model to gain concurrency. A drawback of this approach is that it is only possible in this system to create parallel objects.
Reference: [10] <editor> J.H. Saltz, et al. </editor> <title> A manual for the CHAOS runtime library. </title> <type> Technical Report CS-TK-3437, </type> <institution> Department of Computer Science, University of Maryland, </institution> <year> 1995. </year>
Reference-contexts: A drawback of this approach is that it is only possible in this system to create parallel objects. This means that the object designer needs to think about parallelization of each object, and whether to specify the object as parallel or not. The CHAOS <ref> [10] </ref> system provides support for irregular applications by use of remapping data and creating communication and computation schedules at runtime.
Reference: [11] <author> Vijay Karamcheti and Andrew Chien. </author> <title> Concert efficient runtime support for concurrent object-oriented programming languages on stock hardware. </title> <booktitle> In Proceedings of Supercomputing'93, </booktitle> <year> 1993. </year>
Reference-contexts: The Concert runtime implements a flexible hybrid execution model [21], which utilizes stack-based sequential execution and creates threads lazily only when required. The runtime system and exposes a hierarchy of high performance COOP primitives <ref> [11] </ref> to allow compile-time specialization.
Reference: [12] <author> Vijay Karamcheti and Andrew A. Chien. </author> <title> A comparison of architectural support for messaging on the TMC CM-5 and the Cray T3D. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <year> 1995. </year> <note> Available from http://www-csag.cs.uiuc.edu/papers/cm5-t3d-messaging.ps. </note>
Reference-contexts: The runtime system and exposes a hierarchy of high performance COOP primitives [11] to allow compile-time specialization. In addition, communication is realized via low overhead messaging layers: Fast Messages <ref> [12, 13] </ref> on the CRAY T3D and Active Messages [24] on the TMC CM-5. 3 Application Structure Our implementation of SAMR code was originally written in C++ (making use of Fortran libraries) and then ported to the Illinois Concert system for parallel execution.
Reference: [13] <author> Vijay Karamcheti and Andrew A. Chien. </author> <title> FM|fast messaging on the Cray T3D. </title> <note> Available from http://www-csag.cs.uiuc.edu/papers/t3d-fm-manual.ps, February 1995. </note>
Reference-contexts: The runtime system and exposes a hierarchy of high performance COOP primitives [11] to allow compile-time specialization. In addition, communication is realized via low overhead messaging layers: Fast Messages <ref> [12, 13] </ref> on the CRAY T3D and Active Messages [24] on the TMC CM-5. 3 Application Structure Our implementation of SAMR code was originally written in C++ (making use of Fortran libraries) and then ported to the Illinois Concert system for parallel execution.
Reference: [14] <author> Scott R. Kohn and Scott B. Baden. </author> <title> A parallel software infrastructure for structured adaptive mesh methods. </title> <booktitle> In Supercomputing 1995, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: All of this points us to our final goal, which is to optimize the parallel version of the code on a massive scale using the Cray and SGI high-performance machines. We will be pursuing this goal in the coming months. <ref> [14] </ref> describes an implementation for SAMR methods, which is parallelized using the LPARX system [15]. The LPARX system provides primitives that manipulate parallel data 7 structures, hiding details of communication and data distribution from the programmer.
Reference: [15] <author> S.R. Kohn and S.B. Baden. </author> <title> Irregular coarse-grain data parallelism under lparx. </title> <journal> Scientific Programming, </journal> <volume> 5(3), </volume> <month> Fall </month> <year> 1996. </year>
Reference-contexts: We will be pursuing this goal in the coming months. [14] describes an implementation for SAMR methods, which is parallelized using the LPARX system <ref> [15] </ref>. The LPARX system provides primitives that manipulate parallel data 7 structures, hiding details of communication and data distribution from the programmer. We believe our system is more general, in the sense that we support objects of arbitrary structure as opposed to regular rectangular meshes that LPARX manipulates.
Reference: [16] <author> F. H. McMahon. </author> <title> The Livermore Fortran kernels: a computer test of the numerical performance range. </title> <type> Technical report UCRL-53745, </type> <institution> Lawerence Livermore National Laboratory, Livermore, California, </institution> <year> 1986. </year>
Reference-contexts: The optimizations eliminate virtual dispatch and a range of other inefficiencies and can achieve sequential performance equal to that of C for a large number of programs [17, 22] including the Livermore kernels <ref> [16] </ref>, a demanding numerical benchmark. The Concert runtime implements a flexible hybrid execution model [21], which utilizes stack-based sequential execution and creates threads lazily only when required. The runtime system and exposes a hierarchy of high performance COOP primitives [11] to allow compile-time specialization.
Reference: [17] <author> John Plevyak. </author> <title> Optimization of Object-Oriented and Concurrent Programs. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <year> 1996. </year>
Reference-contexts: On distributed memory machines, the execution model synthesizes a global namespace by detecting remote object invocations and translating them into communication operations and hides latency of remote invocations via software multithreading on commercial single-threaded microprocessors. The Concert compiler <ref> [17, 19, 22, 18, 20] </ref> implements a suite of interprocedural optimizations, including global 4 concrete type inference, inlining, and interprocedural cloning and constant propagation and conventional scalar optimizations. <p> The optimizations eliminate virtual dispatch and a range of other inefficiencies and can achieve sequential performance equal to that of C for a large number of programs <ref> [17, 22] </ref> including the Livermore kernels [16], a demanding numerical benchmark. The Concert runtime implements a flexible hybrid execution model [21], which utilizes stack-based sequential execution and creates threads lazily only when required. The runtime system and exposes a hierarchy of high performance COOP primitives [11] to allow compile-time specialization.
Reference: [18] <author> John Plevyak and Andrew Chien. </author> <title> Precise object-oriented type inference and its use in program optimization. </title> <note> Submitted for publication, TOPLAS, </note> <year> 1994. </year>
Reference-contexts: On distributed memory machines, the execution model synthesizes a global namespace by detecting remote object invocations and translating them into communication operations and hides latency of remote invocations via software multithreading on commercial single-threaded microprocessors. The Concert compiler <ref> [17, 19, 22, 18, 20] </ref> implements a suite of interprocedural optimizations, including global 4 concrete type inference, inlining, and interprocedural cloning and constant propagation and conventional scalar optimizations.
Reference: [19] <author> John Plevyak and Andrew A. Chien. </author> <title> Type directed cloning for object-oriented programs. </title> <booktitle> In Proceedings of the Workshop for Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 566-580, </pages> <year> 1995. </year>
Reference-contexts: On distributed memory machines, the execution model synthesizes a global namespace by detecting remote object invocations and translating them into communication operations and hides latency of remote invocations via software multithreading on commercial single-threaded microprocessors. The Concert compiler <ref> [17, 19, 22, 18, 20] </ref> implements a suite of interprocedural optimizations, including global 4 concrete type inference, inlining, and interprocedural cloning and constant propagation and conventional scalar optimizations.
Reference: [20] <author> John Plevyak, Vijay Karamcheti, and Andrew Chien. </author> <title> Analysis of dynamic structures for efficient parallel execution. </title> <booktitle> In Proceedings of the Sixth Workshop for Languages and Compilers for Parallel Machines, </booktitle> <pages> pages 37-56, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: On distributed memory machines, the execution model synthesizes a global namespace by detecting remote object invocations and translating them into communication operations and hides latency of remote invocations via software multithreading on commercial single-threaded microprocessors. The Concert compiler <ref> [17, 19, 22, 18, 20] </ref> implements a suite of interprocedural optimizations, including global 4 concrete type inference, inlining, and interprocedural cloning and constant propagation and conventional scalar optimizations.
Reference: [21] <author> John Plevyak, Vijay Karamcheti, Xingbin Zhang, and Andrew Chien. </author> <title> A hybrid execution model for fine-grained languages on distributed memory multicomputers. </title> <booktitle> In Proceedings of Supercomputing'95, </booktitle> <year> 1995. </year>
Reference-contexts: The optimizations eliminate virtual dispatch and a range of other inefficiencies and can achieve sequential performance equal to that of C for a large number of programs [17, 22] including the Livermore kernels [16], a demanding numerical benchmark. The Concert runtime implements a flexible hybrid execution model <ref> [21] </ref>, which utilizes stack-based sequential execution and creates threads lazily only when required. The runtime system and exposes a hierarchy of high performance COOP primitives [11] to allow compile-time specialization.
Reference: [22] <author> John Plevyak, Xingbin Zhang, and Andrew A. Chien. </author> <title> Obtaining sequential efficiency in concurrent object-oriented programs. </title> <booktitle> In Proceedings of the ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 311-321, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: On distributed memory machines, the execution model synthesizes a global namespace by detecting remote object invocations and translating them into communication operations and hides latency of remote invocations via software multithreading on commercial single-threaded microprocessors. The Concert compiler <ref> [17, 19, 22, 18, 20] </ref> implements a suite of interprocedural optimizations, including global 4 concrete type inference, inlining, and interprocedural cloning and constant propagation and conventional scalar optimizations. <p> The optimizations eliminate virtual dispatch and a range of other inefficiencies and can achieve sequential performance equal to that of C for a large number of programs <ref> [17, 22] </ref> including the Livermore kernels [16], a demanding numerical benchmark. The Concert runtime implements a flexible hybrid execution model [21], which utilizes stack-based sequential execution and creates threads lazily only when required. The runtime system and exposes a hierarchy of high performance COOP primitives [11] to allow compile-time specialization.
Reference: [23] <author> Erlendur Steinthorsson, David Modiano, William Y. Crutchfield, John B. Bell, , and Phillip Colella. </author> <title> Three dimensional adapative mesh refinement for hyperbolic conservation law. </title> <booktitle> In Proceedings of the 12th AIAA Computational Fluid Dynamics Conference, </booktitle> <pages> pages 902-912, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The adaptation is often quite effective, dramatically reducing the computational effort compared to using a single grid with uniform, high-resolution, spacing. The particular code we are using has been successfully applied to a number of physical problems <ref> [23, 5] </ref>. Our particular code solves the equations of compressible fluid dynamics and is primarily designed for applications in astrophysical hydrodynamics, however SAMR methods have, in general, a much wider area of applicability (e.g. [2]). However, SAMR poses a number of significant challenges for parallelization.
Reference: [24] <author> T. von Eicken, D. Culler, S. Goldstein, and K. Schauser. </author> <title> Active Messages: a mechanism for integrated communication and computation. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <year> 1992. </year>
Reference-contexts: The runtime system and exposes a hierarchy of high performance COOP primitives [11] to allow compile-time specialization. In addition, communication is realized via low overhead messaging layers: Fast Messages [12, 13] on the CRAY T3D and Active Messages <ref> [24] </ref> on the TMC CM-5. 3 Application Structure Our implementation of SAMR code was originally written in C++ (making use of Fortran libraries) and then ported to the Illinois Concert system for parallel execution.
References-found: 24

