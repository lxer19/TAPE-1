URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-224.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Differences in Algorithmic Parallelism in Control Flow and Call Multigraphs  
Author: Vincent Sgro and Barbara G. Ryder 
Date: May 17, 1994  
Affiliation: Rutgers University  
Abstract: Our parallel hybrid analysis methods facilitate the parallelization of the analysis phase of a software transformation system, by enabling deeper semantic analyses to be accomplished more efficiently than if performed sequentially. Our previous empirical studies profiled these hybrid techniques on the Reaching Definitions problem [LMR91, LR92a, LR92c]. Recently, we have applied our method to the Interprocedural May Alias Problem for Fortran programs in a prototype implementation. The interpretation of our results suggested further performance studies, comparing our region partition algorithms (both Bottom Up and Forward partitioning [LRF94]) on call multigraphs and control flow graphs. These comparisons yielded statistically significant differences in performance of our graph partitioning techniques applied to these two graph populations. This research is part of a larger effort to calculate the modification side effects problem (MOD) for Fortran programs using our parallel hybrid techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [AC76] <author> Frances E. Allen and John Cocke. </author> <title> A program data flow analysis procedure. </title> <journal> Communications of the ACM, </journal> <volume> 19(3) </volume> <pages> 137-147, </pages> <year> 1976. </year>
Reference-contexts: Therefore, we designed two region partition techniques, Forward and Bottom Up, to design more effective parallelism in our graph decompositions; both preserve the necessary single-entry node property (i.e, the entry constraint ) of our regions [LMR91, LR92b, LRF94]. The Forward clustering technique is based on Allen/Cocke intervals <ref> [AC76] </ref>, tempered with a maximal size (i.e., the size constraint ). 3 The Forward method forms regions by proceeding along the direction of execution flow on flow graph edges. <p> Although interesting in approach, this can only handle reducible flow graphs as formulated; a "by hand" comparison is offered on the effectiveness of graph decomposition by this algorithm and our unoptimized algorithm [LMR91]. Both Zobel and Gupta et al. designed parallel elimination algorithms. Zobel parallelized Allen-Cocke interval analysis <ref> [AC76] </ref> and reported some empirical experiences for the available expressions problem on five C functions [Zob90]. 8 Since her approach had no control over the flow graph partitioning, very large intervals limited parallelism and caused load imbalance. If a flow graph is acyclic, this approach offers no parallelism at all.
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: These algorithms are an amalgam of fixed point iteration (i.e., within the regions) and elimination methods (i.e., propagation from region to region). Previously, we profiled the performance of the original parallel hybrid algorithm on the Reaching Definitions problem <ref> [ASU86] </ref> on a distributed memory machine, an iPSC/2 at the Cornell Theory Center. We published empirical results for this unoptimized algorithm for Reaching Definitions on Fortran procedures from Linpack and BCF , a curve-fitting program [LMR91]. <p> Finally, we present our conclusions and plans for future work in Section 6. 2 Background 2.1 Data Flow Analysis Data flow analysis involves the collection of information about how variables and expressions are defined and used in a program <ref> [ASU86] </ref>. It is performed under the common assumption that all execution paths in the program are actually feasible, that is, traversable on some program execution. Barth terms this assumption precise up to symbolic execution [Bar78]. <p> In intraprocedural analysis, a procedure is abstracted as a control flow graph, in which a node represents a basic block, and an edge represents a possible control transfer from one basic block to another <ref> [ASU86] </ref>. <p> The Reaching Defini tions problem is intraprocedural; its solution at a flow graph node reveals which value-setting statements can affect the values of variables used in code at that node <ref> [ASU86] </ref>. The May Alias problem for Fortran is interprocedural; its solution for a procedure lists pairs of variables which refer to the same storage location during some execution of that procedure. May Alias is used in the solution of the Modification Side Effects problem, (MOD) [Ban79, Bur90, CK87, CK89]. <p> If our results are corroborated, then some obvious directions emerge. The statistics showed that the partitioning algorithms do not perform as well on call multigraphs as they do on control flow graphs. 8 The Available Expressions problem involves information necessary for common subexpression elimination <ref> [ASU86] </ref>. 10 Methods of improving this performance should be investigated. Currently, we are working on improving the Bottom Up algorithm by using heuristics to choose which of the children of a node in the dominator tree will be merged into its region.
Reference: [Ban79] <author> J. Banning. </author> <title> An efficient way to find the side effects of procedure calls and the aliases of variables. </title> <booktitle> In Conference Record of the Sixth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 29-41, </pages> <month> January </month> <year> 1979. </year>
Reference-contexts: The May Alias problem for Fortran is interprocedural; its solution for a procedure lists pairs of variables which refer to the same storage location during some execution of that procedure. May Alias is used in the solution of the Modification Side Effects problem, (MOD) <ref> [Ban79, Bur90, CK87, CK89] </ref>.
Reference: [Bar78] <author> Jeffrey M. Barth. </author> <title> A practical interprocedural data flow analysis algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 21(9) </volume> <pages> 724-736, </pages> <month> September </month> <year> 1978. </year>
Reference-contexts: It is performed under the common assumption that all execution paths in the program are actually feasible, that is, traversable on some program execution. Barth terms this assumption precise up to symbolic execution <ref> [Bar78] </ref>. In order to do this analysis, a program is transformed into an internal representation of its control and data flow, called a flow graph.
Reference: [Bur90] <author> M. Burke. </author> <title> An interval-based approach to exhaustive and incremental interprocedural data flow analysis. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 341-395, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The May Alias problem for Fortran is interprocedural; its solution for a procedure lists pairs of variables which refer to the same storage location during some execution of that procedure. May Alias is used in the solution of the Modification Side Effects problem, (MOD) <ref> [Ban79, Bur90, CK87, CK89] </ref>.
Reference: [CK87] <author> K. Cooper and K. Kennedy. </author> <title> Complexity of interprocedural side-effect analysis. </title> <institution> Computer Science Department Technical Report TR87-61, Rice University, </institution> <month> October </month> <year> 1987. </year>
Reference-contexts: The May Alias problem for Fortran is interprocedural; its solution for a procedure lists pairs of variables which refer to the same storage location during some execution of that procedure. May Alias is used in the solution of the Modification Side Effects problem, (MOD) <ref> [Ban79, Bur90, CK87, CK89] </ref>.
Reference: [CK89] <author> K. Cooper and K. Kennedy. </author> <title> Fast interprocedural alias analysis. </title> <booktitle> In Conference Record of the Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 49-59, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: The May Alias problem for Fortran is interprocedural; its solution for a procedure lists pairs of variables which refer to the same storage location during some execution of that procedure. May Alias is used in the solution of the Modification Side Effects problem, (MOD) <ref> [Ban79, Bur90, CK87, CK89] </ref>. <p> There are solutions for this problem for languages like Fortran where call by reference parameter passing methods are the only sources for dynamic aliasing <ref> [CK89] </ref>. These are formulated on the call multi-graph representing possible procedure calls in a program. Algorithms for Fortran May Alias depend on the following observations: Alias Introduction: There are specific constructs a program that introduce aliases: 1. A single variable occurs in more than one position in a call. <p> The example problem and its solution in Figure 5 shows May Alias formulated with our sequential hybrid algorithm. 5 3 Investigations 3.1 May Alias Implementation A team of undergraduate students coded a solution to the May Alias problem as previously described in <ref> [CK89] </ref> on call multigraphs using Bottom Up partitioning on an iPSC/2. Discouragingly, the reasonable speedups realized on control flow graphs were not obtained from our experiments with call multigraphs.
Reference: [GPS90] <author> Rajiv Gupta, Lori Pollock, and Mary Lou Soffa. </author> <title> Parallelizing data flow analysis. </title> <booktitle> In Proceedings of the Workshop on Parallel Compilation, </booktitle> <address> Kingston, Ontario, Canada, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: There seemed only to be a solid significant improvement with the effective call multigraphs at a 90% certainty. The results are shown in Table 4. 5 Related Work in Parallel Data Flow Analysis Previous work by others on parallel data flow algorithms was reported in <ref> [Zob90, GPS90, KGS94] </ref> Kramer et al. presented an approach based on parallel prefix operation (i.e., scan). Although interesting in approach, this can only handle reducible flow graphs as formulated; a "by hand" comparison is offered on the effectiveness of graph decomposition by this algorithm and our unoptimized algorithm [LMR91]. <p> If a flow graph is acyclic, this approach offers no parallelism at all. In their parallel elimination method, Gupta et al. attempted to partition a reducible flow graph into single-entry, single-exit regions instead of intervals using a syntax-directed method <ref> [GPS90] </ref>. Although their approach had some control over the size of regions in flow graph partitioning, the restriction that regions must be Single-entry and single-exit required the corresponding program to be well-structured. Thus, in practice, this technique is not sufficiently effective.
Reference: [Hec77] <author> Matthew S. Hecht. </author> <title> Flow Analysis of Computer Programs. </title> <publisher> Elsevier North-Holland, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1977. </year> <month> 11 </month>
Reference-contexts: In interprocedural analysis, a program is abstracted as a call multigraph, in which a node represents a procedure and an edge, a possible procedure call <ref> [Hec77] </ref>. 1 1 In the following discussions, we will use the term flow graph to mean either control flow graph (intraprocedural flow graph) or call multigraph (interprocedural flow graph). 2 A data flow problem is either intraprocedural , or interprocedural depending on whether the data flow information is propagated within one <p> by a lattice theoretic model termed a data flow frame work, which formally defines a lattice of solution values for the problem, a function space of functions that describe the semantic effect of traversing a node or edge in the flow graph, and the flow graph of this problem instance <ref> [Hec77, MR90b] </ref>. General purpose solution procedures for data flow analysis are explained as solving a set of equations, defined on the flow graph nodes and/or edges, that describe the data flow problem [RP86, MR90b]. <p> An iterative algorithm, based on fixed-point iteration, starts with a safe, initial solution, and then proceeds to a maximum fixed point for the equations; this technique requires that the data flow equations be monotone <ref> [Hec77] </ref>. An elimination algorithm has two phases and is conceptually similar to Gaussian elimination [RP86]. In the elimination phase, the flow graph is partitioned into intervals (or regions), local data flow information within an interval is summarized, and the interval is condensed into a node. <p> Flow graph condensation. Construct the flow graph and find its strongly connected components. Find a topological order for the strongly connected component condensation, whose nodes represent flow graph regions. 2 applied to a forward data flow problem in which information is propagated along the direction of execution <ref> [Hec77] </ref>. 3 2. Problem setup. Determine local information from flow graph nodes (e.g., variables, value-setting state-ments), setup the local data flow problem lattice on each region and set up the global problem lattice. 3. Local solution. In each region, iterate the local data flow problem to solution. 4. Global propagation.
Reference: [KGS94] <author> Robert Kramer, Rajiv Gupta, and Mary Lou Soffa. </author> <title> The combining DAG: A technique for parallel data flow analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <month> August </month> <year> 1994. </year> <note> to appear. </note>
Reference-contexts: There seemed only to be a solid significant improvement with the effective call multigraphs at a 90% certainty. The results are shown in Table 4. 5 Related Work in Parallel Data Flow Analysis Previous work by others on parallel data flow algorithms was reported in <ref> [Zob90, GPS90, KGS94] </ref> Kramer et al. presented an approach based on parallel prefix operation (i.e., scan). Although interesting in approach, this can only handle reducible flow graphs as formulated; a "by hand" comparison is offered on the effectiveness of graph decomposition by this algorithm and our unoptimized algorithm [LMR91].
Reference: [Lee92] <author> Yong-fong Lee. </author> <title> Performing Data Flow Analysis in Parallel. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Rutgers University, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: If we use a topsort order on the flow graph to order sibling nodes, we can show that the entry constraint will be maintained. We have shown that finding a minimal region partition for a fixed maximal region size is NP hard <ref> [Lee92] </ref>, so our techniques are actually approximation algorithms.
Reference: [LMR91] <author> Yong-fong Lee, Thomas J. Marlowe, and Barbara G. Ryder. </author> <title> Experiences with a parallel algorithm for data flow analysis. </title> <journal> The Journal of Supercomputing, </journal> <volume> 5(2) </volume> <pages> 163-188, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: We published empirical results for this unoptimized algorithm for Reaching Definitions on Fortran procedures from Linpack and BCF , a curve-fitting program <ref> [LMR91] </ref>. Subsequently, we developed the region partition optimization and presented empirical results [LR92a, LR92b] comparing optimized and unoptimized parallel hybrid algorithm performance on a larger data set, using the same Reaching Definitions problem. <p> A master task performs problem initialization and task creation. The worker tasks are associated with each region; some tasks are independent, while others, associated with propagation of global information through the condensed flow graph, are interdependent. The phases of the parallel hybrid algorithm 2 are <ref> [LMR91] </ref>: 1. Flow graph condensation. Construct the flow graph and find its strongly connected components. <p> Therefore, we designed two region partition techniques, Forward and Bottom Up, to design more effective parallelism in our graph decompositions; both preserve the necessary single-entry node property (i.e, the entry constraint ) of our regions <ref> [LMR91, LR92b, LRF94] </ref>. The Forward clustering technique is based on Allen/Cocke intervals [AC76], tempered with a maximal size (i.e., the size constraint ). 3 The Forward method forms regions by proceeding along the direction of execution flow on flow graph edges. <p> Although interesting in approach, this can only handle reducible flow graphs as formulated; a "by hand" comparison is offered on the effectiveness of graph decomposition by this algorithm and our unoptimized algorithm <ref> [LMR91] </ref>. Both Zobel and Gupta et al. designed parallel elimination algorithms.
Reference: [LR92a] <author> Yong-fong Lee and Barbara G. Ryder. </author> <title> A comprehensive approach to parallel data flow analysis. </title> <booktitle> In Proceedings of the ACM International Conference on Supercomputing, </booktitle> <pages> pages 236-247, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: We published empirical results for this unoptimized algorithm for Reaching Definitions on Fortran procedures from Linpack and BCF , a curve-fitting program [LMR91]. Subsequently, we developed the region partition optimization and presented empirical results <ref> [LR92a, LR92b] </ref> comparing optimized and unoptimized parallel hybrid algorithm performance on a larger data set, using the same Reaching Definitions problem. These newer studies included flow graph characteristics for our data that proved to be significant to algorithm performance. <p> sources of possible parallelism in data flow analysis: separate-unit parallelism gained from processing distinct program constructs separately (e.g., loops, procedures etc.); independent-problem parallelism gained from solving more than one data flow problem on the same flow graph; and algorithmic parallelism gained from finding possible parallelism in the solution procedure itself <ref> [LR92a] </ref>. Our parallel hybrid algorithms decompose the flow graph of a program into regions, perform local analyses on these regions, do a global propagation of information between regions and then propagate global information within regions. <p> We hypothesize that adding other problems to be solved in conjunction with the May Alias analysis will improve the situation. As stated previously, we intend to investigate the concurrent solution of several interprocedural data flow problems in the context of an implementation of the Fortran MOD problem <ref> [LR92a] </ref>. Parallelizing the entire data flow analysis phase of a software translation tool is appealing, in that it holds promise of generating enough work for overcoming the communication to computation cost ratio.
Reference: [LR92b] <author> Yong-fong Lee and Barbara G. Ryder. </author> <title> A comprehensive approach to parallel data flow analysis. </title> <type> Technical Report LCSR-TR-192, </type> <institution> Laboratory for Computer Science Research Technical Report, </institution> <month> August </month> <year> 1992. </year> <note> This is an expanded version of the ICS92 paper and has been submitted for journal publication. </note>
Reference-contexts: We published empirical results for this unoptimized algorithm for Reaching Definitions on Fortran procedures from Linpack and BCF , a curve-fitting program [LMR91]. Subsequently, we developed the region partition optimization and presented empirical results <ref> [LR92a, LR92b] </ref> comparing optimized and unoptimized parallel hybrid algorithm performance on a larger data set, using the same Reaching Definitions problem. These newer studies included flow graph characteristics for our data that proved to be significant to algorithm performance. <p> We developed two metrics, Region Size and Interregion Communication, to measure the relative goodness of a given decomposition and then used these metrics to compare the effectiveness of both of our Bottom Up and Forward partitioning techniques <ref> [LRF94, LR92b] </ref> on call multigraphs and control flow graphs. After statistical analyses of these measures on two data sets of 34 call multigraphs and 696 control flow graphs, we found a significant difference in the structure of these two graph populations that influenced the decompositions induced. <p> Therefore, we designed two region partition techniques, Forward and Bottom Up, to design more effective parallelism in our graph decompositions; both preserve the necessary single-entry node property (i.e, the entry constraint ) of our regions <ref> [LMR91, LR92b, LRF94] </ref>. The Forward clustering technique is based on Allen/Cocke intervals [AC76], tempered with a maximal size (i.e., the size constraint ). 3 The Forward method forms regions by proceeding along the direction of execution flow on flow graph edges.
Reference: [LR92c] <author> Yong-fong Lee and Barbara G. Ryder. </author> <title> Parallel hybrid data flow algorithms: A case study. </title> <booktitle> In Conference Record of 5th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <publisher> Yale University, </publisher> <pages> pages 296-310, </pages> <month> August </month> <year> 1992. </year> <note> Springer-Verlag Lecture Notes in Computer Science, Number 757. </note>
Reference-contexts: These newer studies included flow graph characteristics for our data that proved to be significant to algorithm performance. In <ref> [LR92c] </ref>, we offered an initial look at these flow graph properties for SPICE, one program in the Perfect Benchmarks, and also presented improvements in fl This work was supported, in part, by National Science Foundation grants CCR92-13518 and CCR90-23628. 1 algorithm performance for the SPICE procedures.
Reference: [LRF94] <author> Yong-fong Lee, Barbara G. Ryder, and Marc E. Fiuczynski. </author> <title> Region analysis: A parallel elimination method for data flow analysis. </title> <month> May </month> <year> 1994. </year> <note> to appear in Proceedings of the IEEE Conference on Computer Languages. </note>
Reference-contexts: We developed two metrics, Region Size and Interregion Communication, to measure the relative goodness of a given decomposition and then used these metrics to compare the effectiveness of both of our Bottom Up and Forward partitioning techniques <ref> [LRF94, LR92b] </ref> on call multigraphs and control flow graphs. After statistical analyses of these measures on two data sets of 34 call multigraphs and 696 control flow graphs, we found a significant difference in the structure of these two graph populations that influenced the decompositions induced. <p> Therefore, we designed two region partition techniques, Forward and Bottom Up, to design more effective parallelism in our graph decompositions; both preserve the necessary single-entry node property (i.e, the entry constraint ) of our regions <ref> [LMR91, LR92b, LRF94] </ref>. The Forward clustering technique is based on Allen/Cocke intervals [AC76], tempered with a maximal size (i.e., the size constraint ). 3 The Forward method forms regions by proceeding along the direction of execution flow on flow graph edges.
Reference: [Mar89] <author> T. J. Marlowe. </author> <title> Data Flow Analysis and Incremental Iteration. </title> <type> PhD thesis, </type> <institution> Rutgers University, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: Intuitively, the hybrid algorithm solves local data flow problems defined within regions iteratively and then propagates global information on the condensed region graph in an elimination-like manner. The hybrid algorithm is applicable to factorable data flow problems; most interesting intraprocedural and interprocedural problems have been shown to be factorable <ref> [MR90a, Mar89, MR91] </ref>, although constant propagation is not.
Reference: [MR90a] <author> T. J. Marlowe and B. G. Ryder. </author> <title> An efficient hybrid algorithm for incremental data flow analysis. </title> <booktitle> In Conference Record of the Seventeenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 184-196, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Our parallel hybrid data flow analysis algorithms are aimed at speeding up time-consuming analysis calculations by utilizing multiple processors that soon will be found in desktop workstations. Our parallel hybrid algorithms are general-purpose data flow solution procedures, based on the family of sequential hybrid data flow algorithms <ref> [MR90a] </ref>. These algorithms decompose a flow graph perinto regions, solve local problems on each region and stitch together their solutions to find the global solution on the entire graph. <p> The structure of the equations is determined by the problem-specific data flow functions and the shape of the flow graph. Solutions are elements in the problem lattice. There are three families of general-purpose solution procedures for data flow analysis: iterative, elimination and our hybrid technique <ref> [MR90a] </ref>, the latter an amalgam of the first two approaches. An iterative algorithm, based on fixed-point iteration, starts with a safe, initial solution, and then proceeds to a maximum fixed point for the equations; this technique requires that the data flow equations be monotone [Hec77]. <p> This continues in reverse order on the sequence of condensed graphs, until the original flow graph is solved. A hybrid data flow algorithm uses the strongly connected component (SCC) decomposition to divide a flow graph into single-entry node regions <ref> [MR90a] </ref>. Intuitively, the hybrid algorithm solves local data flow problems defined within regions iteratively and then propagates global information on the condensed region graph in an elimination-like manner. <p> Intuitively, the hybrid algorithm solves local data flow problems defined within regions iteratively and then propagates global information on the condensed region graph in an elimination-like manner. The hybrid algorithm is applicable to factorable data flow problems; most interesting intraprocedural and interprocedural problems have been shown to be factorable <ref> [MR90a, Mar89, MR91] </ref>, although constant propagation is not.
Reference: [MR90b] <author> T. J. Marlowe and B. G. Ryder. </author> <title> Properties of data flow frameworks: a unified model. </title> <journal> Acta Informatica, </journal> <volume> 28 </volume> <pages> 121-163, </pages> <year> 1990. </year>
Reference-contexts: by a lattice theoretic model termed a data flow frame work, which formally defines a lattice of solution values for the problem, a function space of functions that describe the semantic effect of traversing a node or edge in the flow graph, and the flow graph of this problem instance <ref> [Hec77, MR90b] </ref>. General purpose solution procedures for data flow analysis are explained as solving a set of equations, defined on the flow graph nodes and/or edges, that describe the data flow problem [RP86, MR90b]. <p> General purpose solution procedures for data flow analysis are explained as solving a set of equations, defined on the flow graph nodes and/or edges, that describe the data flow problem <ref> [RP86, MR90b] </ref>. The structure of the equations is determined by the problem-specific data flow functions and the shape of the flow graph. Solutions are elements in the problem lattice.
Reference: [MR91] <author> T. J. Marlowe and B. G. Ryder. </author> <title> Hybrid incremental alias algorithms. </title> <booktitle> In Proceedings of the Twentyfourth Hawaii International Conference on System Sciences, Volume II, Software, </booktitle> <month> January </month> <year> 1991. </year>
Reference-contexts: Intuitively, the hybrid algorithm solves local data flow problems defined within regions iteratively and then propagates global information on the condensed region graph in an elimination-like manner. The hybrid algorithm is applicable to factorable data flow problems; most interesting intraprocedural and interprocedural problems have been shown to be factorable <ref> [MR90a, Mar89, MR91] </ref>, although constant propagation is not. <p> are used as actuals in the call to procedure N; then the corresponding formals of procedure N will be aliased on entry to N: 2.4 May Alias Problem Formulation for Hybrid Algorithm The hybrid algorithm solution for this problem requires the definition of four local problems on each re gion <ref> [MR91] </ref>: Restricted Problem - R: This is the May Alias problem restricted to the region; that is, we solve for May Alias as though the region were the entire program. For this we use the same formulation as was described above, with alias introduction and propagation.
Reference: [RP86] <author> Barbara G. Ryder and Marvin C. Paull. </author> <title> Elimination algorithms for data flow analysis. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(3) </volume> <pages> 277-316, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: General purpose solution procedures for data flow analysis are explained as solving a set of equations, defined on the flow graph nodes and/or edges, that describe the data flow problem <ref> [RP86, MR90b] </ref>. The structure of the equations is determined by the problem-specific data flow functions and the shape of the flow graph. Solutions are elements in the problem lattice. <p> An iterative algorithm, based on fixed-point iteration, starts with a safe, initial solution, and then proceeds to a maximum fixed point for the equations; this technique requires that the data flow equations be monotone [Hec77]. An elimination algorithm has two phases and is conceptually similar to Gaussian elimination <ref> [RP86] </ref>. In the elimination phase, the flow graph is partitioned into intervals (or regions), local data flow information within an interval is summarized, and the interval is condensed into a node. The process continues until there is only one node left, for which the data flow problem is easily solved.
Reference: [Ryd89] <author> B. G. Ryder. </author> <title> Ismm: Incremental software maintenance manager. </title> <booktitle> In Proceedings of the IEEE Computer Society Conference on Software Maintenance, </booktitle> <pages> pages 142-164, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Seldom is information calculated across procedure boundaries; however, many software transformation tools need such information to be most effective. These include debuggers, data-flow-based testers, optimizing sequential compilers, parallelizing compilers, program slicers, semantic program browsers and semantic change analyzers <ref> [Ryd89] </ref>. Our parallel hybrid data flow analysis algorithms are aimed at speeding up time-consuming analysis calculations by utilizing multiple processors that soon will be found in desktop workstations. Our parallel hybrid algorithms are general-purpose data flow solution procedures, based on the family of sequential hybrid data flow algorithms [MR90a].
Reference: [Zad84] <author> F.K. Zadeck. </author> <title> Incremental data flow analysis in a structured program editor. </title> <booktitle> In Proceedings of the ACM SIGPLAN '84 Symposium on Compiler Construction, </booktitle> <pages> pages 132-143. </pages> <publisher> ACM Press, </publisher> <address> June 1984. Montreal, Canada. </address>
Reference-contexts: In addition to the above general-purpose algorithms, there is a family of data flow solution procedures for specific intraprocedural problem called the partitioned variable technique (PVT); these partition the solution of a data flow problem by variables and find the relevant information for a single variable, one at a time <ref> [Zad84] </ref>. 2.2 Parallel Hybrid Data Flow Algorithm Our parallel hybrid data flow analysis algorithms are fashioned from the sequential hybrid algorithm described briefly above by finding algorithmic parallelism in the solution process. The parallel hybrid algorithm is organized in a master-worker model of parallelism.

References-found: 23

