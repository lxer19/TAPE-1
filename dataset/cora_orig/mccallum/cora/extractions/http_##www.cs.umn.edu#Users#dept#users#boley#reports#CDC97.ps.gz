URL: http://www.cs.umn.edu/Users/dept/users/boley/reports/CDC97.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/boley/reports/
Root-URL: http://www.cs.umn.edu
Title: Fast Identification of Impulse Response Modes via Krylov Space Methods 1  
Author: Daniel L. Boley Franklin T. Luk David Vandevoorde 
Abstract: Consider an underlying signal which is a sum of r ex-ponentials plus noise. We present a novel combination of fast techniques which enables us to determine all the underlying modes in only O(r 2 ) operations, while filtering out most of the noise. Almost all previously known methods applied to noisy signals require at least O(r 3 ) operations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bjorck and V. Pereyra. </author> <title> Solution of Vander-monde system of equations. </title> <journal> Math. Comp., </journal> <volume> 24 </volume> <pages> 893-903, </pages> <year> 1970. </year>
Reference-contexts: of V , the diagonal entries of D appear in the first column of the matrix DV : DV = V T H: This first column is the solution d to the Vandermonde system: V T d = h 1 : This can be solved with a fast Vandermonde solver <ref> [1] </ref>, where Higham [9, p. 438] recommends ordering the eigenvalues with the Leja ordering to achieve numerical stability in the algorithm in spite of the possible ill-conditioned nature of V . A simple derivation of the fast algorithm can be found in [8, x4.6.2].
Reference: [2] <author> D. L. Boley, T. J. Lee, and F. T. Luk. </author> <title> The Lanc-zos algorithm and Hankel matrix factorization. </title> <journal> Lin. Alg. & Appl., </journal> <volume> 172 </volume> <pages> 109-133, </pages> <year> 1992. </year>
Reference-contexts: Hence we can replace the C in (11) with Z. The equivalence between this algorithm and the Berlekamp-Massey algorithm, as well as a symmetrized version [13] of this algorithm, are discussed in <ref> [2] </ref>. From this equivalence, it is shown that the complexity of this algorithm is O (r) flops per step, a total of O (r 2 ) flops for the r steps we require. This Lanczos method will be used to determine the eigenvalues of C.
Reference: [3] <author> D. L. Boley, F. T. Luk, and D. Vandevoorde. </author> <title> Factorization of Hankel matrices. </title> <booktitle> In Workshop on Scientific Computing 97, </booktitle> <month> March </month> <year> 1997. </year> <institution> Hong Kong, </institution> <note> to appear. </note>
Reference-contexts: Suppose 1 ; 2 ; : : : ; r denote the roots of the polynomial p () of (5), which we will assume for the purpose of this paper to be simple. The general case has been treated in <ref> [15, 3] </ref>. If the expansion (10) is carried out until the size of T becomes r fir, then the eigenvalues of C match those of T .
Reference: [4] <author> J. Cadzow. </author> <title> Signal enhancement a composite property mapping algorithm. </title> <journal> IEEE Trans. Acoust., Speech., Sig. Proc., </journal> <volume> 36 </volume> <pages> 49-62, </pages> <year> 1988. </year>
Reference-contexts: A second popular approach is to form the Hankel matrix generated by the signal, and then proceed to find a nearby Hankel matrix of a lower rank <ref> [4] </ref>. The Vandermonde decomposition of this nearby low-rank Hankel matrix yields the parameters in (2). The method of [4] iterates until it converges to a nearby Hankel matrix. Unfortunately, this method requires the repeated use of the SVD and hence costs up to O (r 3 ) operations per iteration. <p> A second popular approach is to form the Hankel matrix generated by the signal, and then proceed to find a nearby Hankel matrix of a lower rank <ref> [4] </ref>. The Vandermonde decomposition of this nearby low-rank Hankel matrix yields the parameters in (2). The method of [4] iterates until it converges to a nearby Hankel matrix. Unfortunately, this method requires the repeated use of the SVD and hence costs up to O (r 3 ) operations per iteration. We indicated in Section 3 how the Vandermonde decomposition can be computed quickly.
Reference: [5] <author> J. K. Cullum and R. A. Willoughby. </author> <title> A QL procedure for computing the eigenvalues of complex symmetric tridiagonal matrices. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 17(1) </volume> <pages> 83-109, </pages> <year> 1996. </year>
Reference-contexts: There are two variants of the QR-type algorithm that can be applied here that can preserve the tridiagonal structure even for non-Hermitian matrices. One possibility is the complex symmetric QR algorithm proposed in <ref> [5] </ref>, for which the matrix T must be symmetrized (unless we use the symmetrized Lanczos algorithm in step 1). Even when T is real, if the signs of the corresponding superdiagonal and subdiagonal entries of T are opposite, then the symmetrized matrix will be complex.
Reference: [6] <author> R. W. Freund, M. H. Gutknecht, and N. M. Nachtigal. </author> <title> An implementation of the look-ahead Lanc-zos algorithm for non-hermitian matrices. </title> <journal> SIAM J. Sci. Comp., </journal> <volume> 14(1) </volume> <pages> 137-158, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The Lanczos algorithm can suffer a breakdown situation if some column x k is orthogonal to the corresponding column y k . In this situation, a "look-head" variety of the Lanczos has been developed in <ref> [6] </ref>, where the biorthogonality conditions are relaxed to some extent, but the result is that the matrices T and e T are no longer tridiagonal.
Reference: [7] <author> F. R. Gantmacher. </author> <title> Theory of Matrices. </title> <publisher> Chelsea, </publisher> <address> New York, </address> <year> 1959. </year>
Reference-contexts: Assume that the matrix H of (1) has rank r. By a theorem of Gantmacher <ref> [7, vol. 2, p. 207] </ref>, the signal satisfies a recurrence relation of length r: h k = a r1 h k1 + a r2 h k2 + + a 0 h kr ; (4) which generates the entire signal once the r initial val ues fh 1 ; h 2 ;
Reference: [8] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins Univ. Press, 3rd edition, </publisher> <year> 1996. </year>
Reference-contexts: These scalars are assembled into the tridiagonal matrix T . The columns y k of Y are generated by an analogous recurrence using C T and generating the entries of e T . Implementation details for this standard Lanczos algorithm can be found in <ref> [8, x9.4.3] </ref>. Notice that the two relations (8) and (9) generate identical vectors, when limited to the first r entries of the first (r + 1) vectors. <p> A simple derivation of the fast algorithm can be found in <ref> [8, x4.6.2] </ref>. It is based on the fact that an implicit "UL" decomposition of the matrix V can be computed in O (r 2 ) time using divided differences [10, ch. 6].
Reference: [9] <author> N. J. Higham. </author> <title> Accuracy and Stability of Numerical Algorithms. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: the diagonal entries of D appear in the first column of the matrix DV : DV = V T H: This first column is the solution d to the Vandermonde system: V T d = h 1 : This can be solved with a fast Vandermonde solver [1], where Higham <ref> [9, p. 438] </ref> recommends ordering the eigenvalues with the Leja ordering to achieve numerical stability in the algorithm in spite of the possible ill-conditioned nature of V . A simple derivation of the fast algorithm can be found in [8, x4.6.2].
Reference: [10] <author> D. Kincaid and W. </author> <title> Cheney. Numerical Analysis. </title> <booktitle> Brooks/Cole, 2nd edition, </booktitle> <year> 1996. </year>
Reference-contexts: A simple derivation of the fast algorithm can be found in [8, x4.6.2]. It is based on the fact that an implicit "UL" decomposition of the matrix V can be computed in O (r 2 ) time using divided differences <ref> [10, ch. 6] </ref>.
Reference: [11] <author> S. Y. Kung. </author> <title> A new identification and model reduction algorithm via singular value decompositions. </title> <booktitle> In Proc. 12-th Asilomar Conf. Circ., Syst. Comp., </booktitle> <pages> pages 705-714, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: How can we recover the principal modes that generate the signal? A popular method by Kung <ref> [11] </ref> based on the singular value decomposition (SVD) is known to be an effective method for finding modes, but it suffers from the need to carry out both an SVD and a matrix eigensolu-tion, each costing O (r 3 ) operations.
Reference: [12] <author> H. Lu. </author> <title> Fast solution of confluent Vandermonde linear systems. </title> <journal> SIAM J. Matr. Anal., </journal> <volume> 15 </volume> <pages> 1277-1289, </pages> <year> 1994. </year>
Reference-contexts: It is based on the fact that an implicit "UL" decomposition of the matrix V can be computed in O (r 2 ) time using divided differences [10, ch. 6]. A more recent O (r log 2 r) algorithm has been proposed in <ref> [12] </ref>, and all these algorithms including this last one have been extended to the case of confluent Vandermonde matrices (arising when several i 's coincide). 4 Analysis of a Signal Consider a signal fh k g which suffers from the presence of noise.
Reference: [13] <author> J. L. Phillips. </author> <title> The triangular decomposition of Hankel matrices. </title> <journal> Math. Comp., </journal> <volume> 25(115) </volume> <pages> 599-602, </pages> <year> 1971. </year>
Reference-contexts: Hence we can replace the C in (11) with Z. The equivalence between this algorithm and the Berlekamp-Massey algorithm, as well as a symmetrized version <ref> [13] </ref> of this algorithm, are discussed in [2]. From this equivalence, it is shown that the complexity of this algorithm is O (r) flops per step, a total of O (r 2 ) flops for the r steps we require.
Reference: [14] <author> R. </author> <type> Prony. </type> <institution> Essai experimental et analytique sur les lois de la dilatabilite et sur celles de la force expansive de la vapeur de l'eau et de la vapeur de l'alkool, a differentes temperatures. J. de l' Ecole Polytechnique, </institution> <month> 1 </month> <pages> 24-76, 1795. </pages>
Reference-contexts: The general case has been treated in [15, 3]. If the expansion (10) is carried out until the size of T becomes r fir, then the eigenvalues of C match those of T . The result will be mathematically equivalent to Prony's method <ref> [14] </ref>, which consists of solving for the coefficients of the polynomial (5) using the Yule-Walker equations ( h 1 h 2 h r ) a = h r+1 ; and then finding the roots of the polynomial (5) determined by the solution a.
Reference: [15] <author> D. Vandevoorde. </author> <title> A Fast Exponential Decomposition Algorithm and its Applications to Structured Matrices. </title> <type> Ph.D. thesis, </type> <institution> Computer Science Department, Rensselaer Polytechnic Institute, </institution> <year> 1996. </year>
Reference-contexts: Vandevoorde <ref> [15] </ref> discusses the general case when the modes are not distinct. If this decomposition can be computed quickly, then this can be used to compute a fast decomposition of a noisy signal with the view of extracting the important "signal" modes. <p> Suppose 1 ; 2 ; : : : ; r denote the roots of the polynomial p () of (5), which we will assume for the purpose of this paper to be simple. The general case has been treated in <ref> [15, 3] </ref>. If the expansion (10) is carried out until the size of T becomes r fir, then the eigenvalues of C match those of T . <p> Many of the individual pieces to the algorithms are "off-the-shelf" methods, some are more experimental, and some have received very little discussion. Most details can be found in <ref> [15] </ref>. We begin with an outline of the basic steps: 1. Use a Lanczos algorithm to generate the tridiag onal matrix T . 2. Compute the "modes" generating the signal, i.e., the eigenvalues of T . 3. <p> Although our fast method has worked so well on this example, we should emphasize that the choice of criteria requires further study. Indeed, several more sophisticated selection criteria are presented and analyzed in <ref> [15] </ref>.
Reference: [16] <author> D. Watkins and L. Elsner. </author> <title> Chasing algorithms for the eigenvalue problem. </title> <journal> SIAM J. Matr. Anal., </journal> <volume> 12 </volume> <pages> 374-384, </pages> <year> 1991. </year>
Reference-contexts: The resulting Q in (12) is "complex orthogonal," meaning Q T Q = I; as opposed to "unitary," meaning Q H Q = I: It follows that the symmetry and the tridiagonal structure of T old are preserved. The other option is to use the LR algorithm <ref> [16] </ref>, which is based on the LU factorization without pivoting to preserve the tridiagonal structure. In this algorithm the Q in (12) is replaced by a lower triangular L computed using Gaussian elimination without pivoting. <p> If T is real, an implicit double-shift LR algorithm can in principle be carried out in real arithmetic <ref> [16] </ref>. Both algorithms require linear time for each iteration in a manner very similar to the Hermitian analog, and the number of iterations is generally O (r) in a manner very similar to the QR algorithm usually employed.
References-found: 16

