URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1995/tr-95-024.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1995.html
Root-URL: http://www.icsi.berkeley.edu
Title: Applying Large Vocabulary Hybrid HMM-MLP Methods to Telephone Recognition of Digits and Natural Numbers  
Phone: (510) 643-9153 FAX (510) 643-7684  
Author: Kristine W. Ma 
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Pubnum: TR-95-024  
Abstract: The hybrid Hidden Markov Model (HMM) / Neural Network (NN) speech recognition system at the International Computer Science Institute (ICSI) uses a single hidden layer MLP (Multi Layer Perceptron) to compute the emission probabilities of the states of the HMM. This recognition approach was developed and has traditionally been used for large vocabulary size continuous speech recognition. In this report, however, such a recognition scheme is applied directly to three much smaller vocabulary size corpora, the Bellcore isolated digits, the TI connected digits, and the Center for Spoken Language Understanding Numbers'93 database. The work reported here is not only on developing small baseline systems to facilitate all future research experiments, but also on using these systems to evaluate front-end research issues, and the feasibility of using context-dependency for speech recognition under the hybrid approach developed at ICSI. In addition, using the TI connected digits, the performance of ICSI's baseline system on small vocabulary size speaker-independent task is compared with those of other speech research institutes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bourlard and N. Morgan, </author> <title> Connectionist Speech Recognition: A Hybrid Approach. </title> <booktitle> The Kluwer International Series in Engineering and Computer Science. VLSI, Computer Architecture, and Digital Signal Processing, </booktitle> <address> Boston, Massachusetts, </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: performance, but the role of this set of experiments is to provide a faster testbed for ideas to be used on a range of tasks. 4 2 Baseline System The hybrid HMM-MLP speech recognition system at the International Computer Science Institute (ICSI) has the same basic structure as described in <ref> [1] </ref>. Its overall architecture is shown in Figure 1. A single hidden layer MLP is employed to estimate the posterior phonetic class probabilities, which are then converted, using Bayes' rule, to likelihood probabilities for Viterbi alignment in the HMM framework.
Reference: [2] <author> Regis Cardin, Yves Normandin and Evelyne Millien. </author> <title> "Inter-Word Coarticulation Modeling and MMIE Training for Improved Connected Digit Recognition," </title> <booktitle> Proceedings of the International Conference on Acoustics Speech and Signal Processing, </booktitle> <address> II.243-246, Minneapolis, MN, </address> <year> 1993. </year>
Reference-contexts: Some experiments of this type were performed previously at ICSI, but few variants were explored due to computational costs for the larger tasks. Finally, to compare our small vocabulary size recognition system performance with that of other speech research sites <ref> [2, 3, 5, 11] </ref>, a recognizer was developed on the TI connected digits using the hybrid HMM-MLP context-independent approach. <p> In the meantime, we tested our recognizer on the standard TI/NIST Connected-Digits Recognition Task ("TI-Digits") [9]. While this corpus is inherently less realistic since it was recorded in an artificial studio situation with wide bandwidth, it has been used by many well developed systems <ref> [2, 3, 5, 11] </ref>, so that it will be a calibration point for our methods on small vocabulary size tasks. Ever since this corpus was made available in 1984, it has became a quasi standard for benchmarking small vocabulary speaker-independent recognition systems. <p> As a result, the error rate is 0.28% on word level and 0.84% on string level. 17 * Another effort comes from Centre de recherche infromatique de Montreal (CRIM) <ref> [2] </ref>. They use Mel-cepstral-12, delta, and delta-delta features for the front end. Again, a whole-word gender dependent model was used with triphone context dependent and discrete HMM. This group used a discriminant training algorithm based on maximum mutual information estimation (MMIE).
Reference: [3] <author> W. Chou, C.-H. Lee, B.-H. Juang, </author> <title> "Minimum Error Rate Training of Inter-word Context Dependent Acoustic Model Units in Speech Recognition", </title> <booktitle> Proceedings of the International Conference on Spoken Language Processing, </booktitle> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Some experiments of this type were performed previously at ICSI, but few variants were explored due to computational costs for the larger tasks. Finally, to compare our small vocabulary size recognition system performance with that of other speech research sites <ref> [2, 3, 5, 11] </ref>, a recognizer was developed on the TI connected digits using the hybrid HMM-MLP context-independent approach. <p> In the meantime, we tested our recognizer on the standard TI/NIST Connected-Digits Recognition Task ("TI-Digits") [9]. While this corpus is inherently less realistic since it was recorded in an artificial studio situation with wide bandwidth, it has been used by many well developed systems <ref> [2, 3, 5, 11] </ref>, so that it will be a calibration point for our methods on small vocabulary size tasks. Ever since this corpus was made available in 1984, it has became a quasi standard for benchmarking small vocabulary speaker-independent recognition systems. <p> Most of the current state of the art TI-Digits recognizer systems use whole word modeling, cross word context-dependency, gender dependent models, and more elaborate training procedures. The following was obtained from a literature search: * The best recognition performance is currently from Bell Laboratories <ref> [3] </ref>. Their system yields word and string error rates of 0.24% and 0.72%, respectively. They use LPC-12, delta, and delta-delta features for the front end; whole word model with inter-word triphone context dependency, and continuous density HMM for acoustic modeling.
Reference: [4] <author> R.A. Cole, M. Fanty, and T. Lander, </author> <title> "Telephone Speech Corpus Development at CSLU," </title> <booktitle> Proceedings of the International Conference on Spoken Language Processing, </booktitle> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: It consists of numbers spoken spontaneously over telephone lines on the public-switched network. These numbers are extracted from the addresses spoken by the callers of CSLU's Spelled and Spoken Names Corpus <ref> [4] </ref>. The Numbers'93 database consists of 2167 speech files of spoken numbers produced by 1132 callers. I used 1534 of these utterances for training (1117749 frames) and development (86,630 frames), saving the remaining utterances for final testing purposes.
Reference: [5] <author> R. Haeb-Umbach, D. Geller, H. Ney, </author> <title> "Improvements in Connected Digit Recognition Using Linear Discriminant Analysis and Mixture Densities," </title> <booktitle> Proceedings of the International Conference on Acoustics Speech and Signal Processing, </booktitle> <address> II.239-242, Minneapo-lis, MN, </address> <year> 1993. </year>
Reference-contexts: Some experiments of this type were performed previously at ICSI, but few variants were explored due to computational costs for the larger tasks. Finally, to compare our small vocabulary size recognition system performance with that of other speech research sites <ref> [2, 3, 5, 11] </ref>, a recognizer was developed on the TI connected digits using the hybrid HMM-MLP context-independent approach. <p> In the meantime, we tested our recognizer on the standard TI/NIST Connected-Digits Recognition Task ("TI-Digits") [9]. While this corpus is inherently less realistic since it was recorded in an artificial studio situation with wide bandwidth, it has been used by many well developed systems <ref> [2, 3, 5, 11] </ref>, so that it will be a calibration point for our methods on small vocabulary size tasks. Ever since this corpus was made available in 1984, it has became a quasi standard for benchmarking small vocabulary speaker-independent recognition systems. <p> They use LPC-12, delta, and delta-delta features for the front end; whole word model with inter-word triphone context dependency, and continuous density HMM for acoustic modeling. The system uses a new training technique that minimizes string error rate, and N-best for decoding. * Another speech site is Philips Laboratory <ref> [5] </ref>. Their system also uses whole-word model, and with gender dependency and background noise model. Training and recognition were done using Viterbi search. One interesting twist is that they use continuous Laplacian (rather than Gaussian) emission density for the HMM.
Reference: [6] <author> Horacio Franco, Michael Cohen, Nelson Morgan, David Rumelhart, and Victor Abrash, </author> <title> "Hybrid Neural Network/Hidden Markov Model Continuous-Speech Recognition," </title> <booktitle> Proceedings of the International Conference on Spoken Language Processing, </booktitle> <pages> pp. 915-918, </pages> <year> 1992. </year>
Reference-contexts: a similar baseline system as described in Section 3, except that the generalized triphone and the triphone methods require an MLP with a larger output layer of 90 and 111 units respectively, while the multiple state phonetic model approach utilizes a different connectionist architecture similar to the one describe in <ref> [6] </ref>. To support the multiple state phonetic model formulation a connectionist probability estimator consisting of 17 MLPs is used, with 8 nets corresponding to each of the 8 generalized left-biphones, 8 nets for the generalized right-biphones, and 1 net for the context-independent states (see Figure 5). <p> The major problem encountered with training context-dependent systems is the lack of 12 data for training highly specific phonetic context classes. One solution, adapted from <ref> [6] </ref>, is to initialize the context specific MLP training with weights from a more general context net. Thus, the generalized triphone context-dependent network is trained by bootstrapping from the previously trained context-independent MLP. <p> The following heuristic is used <ref> [6] </ref>: p (xjq i ; c j ) = p (q i ; c j jx)(ff i p (q i ) j 1 )p (x); (3) where, ff i = N ci (i) + b (N cd (i; j)) The number N ci (i) is the amount of training examples for
Reference: [7] <author> H. Hermansky, </author> <title> "Perceptual Linear Predictive (PLP) Analysis for Speech," </title> <journal> J. Acoust. Soc. Am., </journal> <pages> pp. 1738-1752, </pages> <year> 1990. </year>
Reference-contexts: Three types of features (PLP, Log-RASTA, J-RASTA) were used to test the robustness of our hybrid recognizer in the presence of convolution and additive noise. Perceptual linear predictive analysis (PLP) is an extension of linear predictive analysis that takes into account some aspects of human sound perception <ref> [7] </ref>. Log-RASTA is based on PLP but also aims at reducing the effect of linear spectral distortion. J-RASTA tries to handle both linear spectral distortion and additive noise simultaneously. [8] The purpose of this set of experiments is two-fold.
Reference: [8] <author> Joachim Koehler, Nelson Morgan, Hynek Hermansky, H. Guenter Hirsch, </author> <title> and Grace Tong,"Integrating RASTA-PLP into Speech Recognition," </title> <booktitle> Proceedings of the International Conference on Acoustics Speech and Signal Processing, </booktitle> <address> Adelaide, Australia, </address> <year> 1994. </year>
Reference-contexts: The pronunciations are based on the most likely TIMIT pronunciations. A null grammar is used for both the Bellcore and the TI digits recognizers. The language model for the Numbers'93 context-dependent experiments will be described later. 5 3 Training Procedure Log-RASTA-PLP <ref> [8] </ref> is used as the acoustic pre-processor for both the TI digits and the Numbers'93 experiments. Each frame of the feature vector represents 25 msec of speech, with 12.5ms overlap of consecutive frames. <p> Log-RASTA is based on PLP but also aims at reducing the effect of linear spectral distortion. J-RASTA tries to handle both linear spectral distortion and additive noise simultaneously. <ref> [8] </ref> The purpose of this set of experiments is two-fold. First, we want to verify that the front-end research carried out earlier in [15, 8] on a mixture Gaussian based system will perform equally well using ICSI's hybrid approach. <p> J-RASTA tries to handle both linear spectral distortion and additive noise simultaneously. [8] The purpose of this set of experiments is two-fold. First, we want to verify that the front-end research carried out earlier in <ref> [15, 8] </ref> on a mixture Gaussian based system will perform equally well using ICSI's hybrid approach. Secondly, we want to compare the performance of the hybrid approach to that of the HTK based system. 7 4.3 Result The experimental results are reported in Table 1 and Table 2. <p> Highpass is then added to eliminate low frequency components of the signal. The frequency responses of the highpass (127 taps) and lowpass (183 taps) filters are given in Figure 6 and Figure 7, respectively. Both filters are designed using the Kaiser windowing method via esps. Log-RASTA-PLP <ref> [8] </ref> is then used as the acoustic pre-processor. The size of the system and the training procedure are as described in Section 2 and Section 3, respectively. 6.3 Result A recognizer was developed on the TI connected digits using the hybrid HMM-MLP context-independent approach.
Reference: [9] <author> R. Leonard, </author> <title> "A Database for Speaker-Independent Digit Recognition," </title> <booktitle> Proceedings of the International Conference on Acoustics Speech and Signal Processing, </booktitle> <address> pp.42.11.1-42.11.4, San Diego, CA, </address> <year> 1984. </year>
Reference-contexts: CSLU plans to distribute the Numbers corpus, and so we hope to see how other sites compare on this task in the coming year. In the meantime, we tested our recognizer on the standard TI/NIST Connected-Digits Recognition Task ("TI-Digits") <ref> [9] </ref>. While this corpus is inherently less realistic since it was recorded in an artificial studio situation with wide bandwidth, it has been used by many well developed systems [2, 3, 5, 11], so that it will be a calibration point for our methods on small vocabulary size tasks.
Reference: [10] <author> D. Lubensky, </author> <title> "Generalized Context-Dependent Phone Modeling Using Artificial Neural Networks," </title> <booktitle> Proceedings of EUROSPEECH'93, </booktitle> <address> September 21-23, Berlin, Germany. </address>
Reference-contexts: This is probably due to the lack of training data for those context specific examples (even though we smoothed the training with the context-dependent net). One solution is simply to use a more general context classification, or methods such as dynamic multi-level context clustering as proposed in <ref> [10] </ref>. The first three context-dependent experiments do not take into account of cross-word context. However, the fourth experiment does model cross-word context, which resulted in an improvement from 6.9% to 6.2% on word recognition error rate using "Context-dependent Prior".
Reference: [11] <author> D. Lubensky, A.O. Asadi, and J.M. Naik, </author> <title> "Connected Digit Recognition Using Connectionist Probability Estimators and Mixture-Gaussian Densities," </title> <booktitle> Proceedings of the International Conference on Spoken Language Processing, </booktitle> <address> Yokohama, Japan, </address> <month> Septem-ber </month> <year> 1994. </year>
Reference-contexts: Some experiments of this type were performed previously at ICSI, but few variants were explored due to computational costs for the larger tasks. Finally, to compare our small vocabulary size recognition system performance with that of other speech research sites <ref> [2, 3, 5, 11] </ref>, a recognizer was developed on the TI connected digits using the hybrid HMM-MLP context-independent approach. <p> In the meantime, we tested our recognizer on the standard TI/NIST Connected-Digits Recognition Task ("TI-Digits") [9]. While this corpus is inherently less realistic since it was recorded in an artificial studio situation with wide bandwidth, it has been used by many well developed systems <ref> [2, 3, 5, 11] </ref>, so that it will be a calibration point for our methods on small vocabulary size tasks. Ever since this corpus was made available in 1984, it has became a quasi standard for benchmarking small vocabulary speaker-independent recognition systems. <p> This group used a discriminant training algorithm based on maximum mutual information estimation (MMIE). The MMIE training is initialized with a few iterations of Baum-Welch. Their best performance is 0.28% word error rate and 0.84% string error rate. * The last speech site was from NYNEX <ref> [11] </ref>. They use a less elaborate system that does not model gender dependency nor context dependency. Nevertheless, their system is still whole-word model based. They use a hybrid MLP/HMM approach with 10 states per word. LPC-10, delta, and delta-delta features were used for front-end processing.
Reference: [12] <author> Nelson Morgan, </author> <type> Personal Communication, </type> <year> 1995. </year>
Reference-contexts: However, in previous work in the group, the number of parameters was increased by un-tying variances, etc. This did not appear to help performance for this task <ref> [12] </ref>. Another major difference between the two systems is that the HTK recognizer is whole-word model based, whereas the hybrid approach is phonemic based. I should also note that the local expertise at ICSI is focused on the hybrid approach.
Reference: [13] <author> T. Robinson, L. Almeida, J.M. Boite, H. Bourlard, F. Fallside, M. Hochberg, D. Ker-shaw, P. Kohn, Y. Konig, N. Morgan, J.P. Neto, S. Renals, M. Saerens, & C. Wooters. </author> <year> (1993). </year> <title> "A Neural Network Based, Speaker Independent, Large Vocabulary, Continuous Speech Recognition System: The WERNICKE Project," </title> <booktitle> Proceedings of EU-ROSPEECH'93, </booktitle> <address> September 21-23, Berlin, Germany. </address>
Reference-contexts: For the Bellcore digits and the Numbers'93 tasks, the MLP was scaled down from our usual range of 500-4000 hidden units to 200 hidden units. For context-independent recognition, the output layer has 61 units, corresponding to one unit per phonetic class. ICSI currently uses a decoder called Y0 <ref> [13] </ref> that applies the standard synchronous Viterbi algorithm. The lexicon consists of single pronunciation word models with repeated states to enforce minimum phonetic durations. The pronunciations are based on the most likely TIMIT pronunciations. A null grammar is used for both the Bellcore and the TI digits recognizers.
Reference: [14] <author> Gary Tajchman, </author> <type> Personal Communication, </type> <year> 1994. </year>
Reference-contexts: The TIMIT phone set is clustered as follow <ref> [14] </ref>: 0. Silence: bcl, dcl, gcl, pcl, tcl, kcl, h#, pau, epi, q 1. Labial (upper or lower lip): b, p, f, th, v, dh, m, em 2. Alveolar (tongue touching gum ridge): d, t, dx, jh, ch, s, sh, z, zh, n, nx, en, l, el 3.
Reference: [15] <author> Grace C.H. Tong. </author> <title> "Combating Additive Noise and Spectral Distortion in Speech Recognition Systems with JAH-RASTA," </title> <type> Masters Thesis, </type> <institution> University of California at Berke-ley, </institution> <year> 1994. </year> <month> 24 </month>
Reference-contexts: The first corpus consists of isolated digits collected over the telephone network by Bellcore. This database was used to conduct extensive testings of the robustness of various signal processing front ends (PLP, Log-RASTA, J-RASTA) in the presence of both convolution and additive noise. Such experiments were conducted earlier in <ref> [15] </ref> using the mixture Gaussian based hidden Markov toolkit (HTK). The work reported here is to integrate those front-end results with ICSI's hybrid HMM-MLP recognition system and compare the performance to that of the HTK system. The digits corpus is very useful for conducting preliminary research experiments. <p> J-RASTA tries to handle both linear spectral distortion and additive noise simultaneously. [8] The purpose of this set of experiments is two-fold. First, we want to verify that the front-end research carried out earlier in <ref> [15, 8] </ref> on a mixture Gaussian based system will perform equally well using ICSI's hybrid approach. Secondly, we want to compare the performance of the hybrid approach to that of the HTK based system. 7 4.3 Result The experimental results are reported in Table 1 and Table 2. <p> All systems are trained with clean (original data collected by Bellcore) data and tested with data that are artificially corrupted with convolutional and/or additive noise (see <ref> [15] </ref> for detailed description of the noise sources). Systems that are trained without delta features use a 400 hidden unit MLP, while systems with delta features use a 200 hidden unit MLP. Thus the number of parameters in both cases is kept at about 42.8k. <p> In other words, the hybrid approach performs better when the RASTA features are applied appropriately according to the noise scenario. In comparing the two systems, one should note that the hybrid approach uses 42.8k parameters, while the HTK system 8 uses only 7.1k parameters <ref> [15] </ref>. However, in previous work in the group, the number of parameters was increased by un-tying variances, etc. This did not appear to help performance for this task [12].
References-found: 15

