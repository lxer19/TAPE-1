URL: http://www.isi.edu/ariadne/papers/97-dmkd.ps
Refering-URL: http://www.isi.edu/~knoblock/
Root-URL: 
Title: Data Mining and Knowledge Discovery,  Discovering Robust Knowledge from Databases that Change  Editor:  
Author: CHUN-NAN HSU CRAIG A. KNOBLOCK 
Keyword: robustness, database transactions and changes, rule consistency, knowledge discovery  
Address: PO Box 875406, Tempe, AZ 85287, USA  4676 Admiralty Way, Marina del Rey, CA 90292, USA  
Affiliation: Department of Computer Science and Engineering Arizona State University,  Information Sciences Institute and Department of Computer Science University of Southern California,  
Note: c 1998 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Pubnum: 2,  
Email: chunnan@asu.edu  knoblock@isi.edu  
Date: 1-28 (1998)  Received March 27, 1996 Revised March 10,1997  
Abstract: Many applications of knowledge discovery and data mining such as rule discovery for semantic query optimization, database integration and decision support, require the knowledge to be consistent with the data. However, databases usually change over time and make machine-discovered knowledge inconsistent. Useful knowledge should be robust against database changes so that it is unlikely to become inconsistent after database updates. This paper defines this notion of robustness in the context of relational databases and describes how robustness of first-order Horn-clause rules can be estimated. Experimental results show that our estimation approach can accurately identify robust rules. We also present a rule antecedent pruning algorithm that improves the robustness and applicability of machine discovered rules to demonstrate the usefulness of robustness estimation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agrawal, R., Imielinski, T., and Swami, A. </author> <year> 1993. </year> <title> Database mining: A performance perspective. </title> <journal> IEEE Transactions on Knowledge and Data Engineering 5(6) </journal> <pages> 914-925. </pages>
Reference-contexts: geoloc ( , ,?country,?latitude, ) ^ ?country = ``Malta'' ) ?latitude 35.89 R2: ;All Maltese geographic locations are seaports. geoloc ( ,?glc cd,?country, , ) ^ ?country = ``Malta'' ) seaport ( ,?glc cd, , , , ) the confidence factors such as the "support" count for an association rule <ref> ( Agrawal et al., 1993 ) </ref> in that the support count expresses the probability that a data instance satisfies a rule, while robustness expresses the probability that an entire database state is consistent with a rule. <p> ( ,?code,?depth,?length,?crane) ^ seaport (?name,?code, , , , ) ^ geoloc (?name, ,?country, , ) ^ ?crane &gt; 0. r10:?length 1200 ( wharf ( ,?code,?depth,?length,?crane) ^ seaport (?name,?code, , , , ) ^ geoloc (?name, ,?country, , ). ample of the confidence factors is the support counts for association rules <ref> ( Agrawal et al., 1993 ) </ref> .
Reference: <author> Ambite, J.-L., and Knoblock, C. A. </author> <year> 1995. </year> <title> Reconciling distributed information sources. </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Information Gathering in Distributed Heterogeneous Environments, </booktitle> <publisher> AAAI Technical Report SS-95-08. </publisher>
Reference-contexts: Examples include rule discovery for semantic query optimization (SQO) ( Siegel et al., 1991, Shekhar et al., 1993, Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b, Hsu, 1996 ) , learning an integrated ontology of heterogeneous databases <ref> ( Dao and Perry, 1995, Ambite and Knoblock, 1995 ) </ref> , functional dependency discovery ( Mannila and Raiha, 1994, Bell, 1995 ) , knowledge discovery for decision support, etc. However, most approaches to these problems assume static databases, while in practice, databases are dynamic, that is, they change frequently. <p> Since the rules are increasingly robust, eventually the need of rule repair can be eliminated. Another application of the robustness estimation is integrating heterogeneous databases <ref> ( Dao and Perry, 1995, Ambite and Knoblock, 1995 ) </ref> . This problem requires the system to extract a compressed description (e.g. integrated view definitions, or a temporary concept description) of data and the consistency of the description and data is important.
Reference: <author> Arens, Y., Chee, C. Y., Hsu, C.-N., and Knoblock, C. A. </author> <year> 1993. </year> <title> Retrieving and integrating data from multiple information sources. </title> <journal> International Journal on Intelligent and Cooperative Information Systems 2(2) </journal> <pages> 127-159. </pages>
Reference: <author> Arens, Y., Knoblock, C. A., and Shen, W.-M. </author> <year> 1996. </year> <title> Query reformulation for dynamic information integration. </title> <journal> Journal of Intelligent Information Systems, Special Issue on Intelligent Information Integration </journal> 6(2/3):99-130. 
Reference: <author> Bacchus, F., Grove, A., Halpern, J. Y., and Koller, D. </author> <year> 1992. </year> <title> From statistics to beliefs. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> 602-608. </pages>
Reference-contexts: The formalism proposed by ( Bacchus et al., 1992, DATABASES THAT CHANGE 25 Bacchus et al., 1994 ) for uncertain reasoning, in spite of the different motivation, is quite similar to robustness. <ref> ( Bacchus et al., 1992 ) </ref> defines the degree of belief in a given logic sentence ' as the probability of the set of worlds where ' is true. They further define this probability as the ratio between the number of all possible worlds and worlds where ' is true. <p> They further define this probability as the ratio between the number of all possible worlds and worlds where ' is true. This is the same as Definition 1, if we consider a database as a model of "worlds." <ref> ( Bacchus et al., 1992 ) </ref> also surveys early philosophical work on probability that discusses related uncertainty measures.
Reference: <author> Bacchus, F., Grove, A., Halpern, J. Y., and Koller, D. </author> <year> 1994. </year> <title> Forming beliefs about a changing world. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> 222-229. </pages>
Reference: <author> Bell, S. </author> <year> 1995. </year> <title> Discovery and maintenance of functional dependencies by independencies. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD-95). </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Cestnik, B., and Bratko, I. </author> <year> 1991. </year> <title> On estimating probabilities in tree pruning. </title> <booktitle> In Machine Learning - EWSL-91, European Working Session on Learning. </booktitle> <address> Berlin, Germany: </address> <publisher> Springer-Verlag. </publisher> <pages> 138-150. </pages>
Reference-contexts: A detailed description and a proof of the Laplace law can be found in ( Howson and Urbach, 1988 ) . The Laplace law applies to any repeatable experiment (e.g., tossing a coin). The Laplace law is a special case of a modified estimate called m-Probability <ref> ( Cestnik and Bratko, 1991 ) </ref> . A prior probability of outcomes can be brought to bear in this more general estimate. m-Probability. Let r, n, and C be as in the description of the Laplace law. <p> The prior probability used here is that k outcomes are equally probable. The m-probability estimate has produced convincing results in noisy data handling and decision tree pruning when applied in many machine learning systems <ref> ( Cestnik and Bratko, 1991, Lavrac and Dzeroski, 1994 ) </ref> . The advantage of the Laplace estimate is that it takes both known relative frequency and prior probability into account.
Reference: <author> Clark, P., and Niblett, T. </author> <year> 1989. </year> <title> The CN2 induction algorithm. </title> <booktitle> Machine Learning 3(4) </booktitle> <pages> 261-283. </pages>
Reference-contexts: This is not enough for dynamic closed-world databases where updates and deletions may affect the validity of a rule, as we discussed earlier. Other uncertainty measures applied widely in rule induction and KDD applications are significance and rough set theory. Significance <ref> ( Clark and Niblett, 1989 ) </ref> is used to measure the correlation between the antecedents and consequent of a rule by computing their ratio of the instance coverage of a rule.
Reference: <author> Cohen, W. W. </author> <year> 1993. </year> <title> Efficient pruning methods for separate-and-conquer rule learning systems. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93). </booktitle>
Reference-contexts: This is because the search space of rule construction is already huge and evaluating robustness is not trivial. Previous work in classification rule induction <ref> ( Cohen, 1993, Furnkranz and Widmer, 1994 ) </ref> also shows that dividing a learning process into a two-stage rule construction and rule pruning can yield better results in terms of classification accuracy as well as the efficiency of learning.
Reference: <author> Cussens, J. </author> <year> 1993. </year> <title> Bayes and pesudo-Bayes estimates of conditional probabilities and their reliability. </title> <booktitle> In Machine Learning: ECML-93, </booktitle> <pages> 136-152. </pages> <address> Berlin, Germany: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Dao, S., and Perry, B. </author> <year> 1995. </year> <title> Applying a data miner to heterogeneous schema integration. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD-95). </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Examples include rule discovery for semantic query optimization (SQO) ( Siegel et al., 1991, Shekhar et al., 1993, Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b, Hsu, 1996 ) , learning an integrated ontology of heterogeneous databases <ref> ( Dao and Perry, 1995, Ambite and Knoblock, 1995 ) </ref> , functional dependency discovery ( Mannila and Raiha, 1994, Bell, 1995 ) , knowledge discovery for decision support, etc. However, most approaches to these problems assume static databases, while in practice, databases are dynamic, that is, they change frequently. <p> Since the rules are increasingly robust, eventually the need of rule repair can be eliminated. Another application of the robustness estimation is integrating heterogeneous databases <ref> ( Dao and Perry, 1995, Ambite and Knoblock, 1995 ) </ref> . This problem requires the system to extract a compressed description (e.g. integrated view definitions, or a temporary concept description) of data and the consistency of the description and data is important.
Reference: <author> Dzeroski, S. </author> <year> 1996. </year> <title> Inductive logic programming and knowledge discovery in databases. </title> <editor> In Fayyad, U. M., Piatetsky-Shapiro, G., Smyth, P., and Uthurusamy, R., eds., </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press/MIT Press. </publisher> <address> chapter 5. </address>
Reference-contexts: Our definition of robustness provides a new measure of uncertainty for Horn-clause rules discovered from those databases. This measure can be applied in inductive logic programming (ILP), an important data mining technique <ref> ( Dzeroski, 1996 ) </ref> . 2. This paper presents an efficient approach to the estimation and use of the new measure. The complexity of the estimation is not a function of the database size and therefore is scalable to large databases.
Reference: <author> Furnkranz, J., and Widmer, G. </author> <year> 1994. </year> <title> Incremental reduced error prunning. </title> <booktitle> In Machine Learning, Proceedings of the 11th International Conference(ML-94). </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Helmbold, D. P., and Long, P. M. </author> <year> 1994. </year> <title> Tracking drifting concepts by minimizing disagreement. </title> <booktitle> Machine Learning 14 </booktitle> <pages> 27-45. </pages>
Reference: <author> Howson, C., and Urbach, P. </author> <year> 1988. </year> <title> Scientific Reasoning: The Bayesian Approach. Open Court. </title> <editor> 28 HSU AND KNOBLOCK Hsu, C.-N., and Knoblock, C. A. </editor> <year> 1993. </year> <title> Reformulating query plans for multidatabase systems. </title> <booktitle> In Proceedings of the Second International Conference on Information and Knowledge Management (CIKM-93). </booktitle>
Reference-contexts: The probability that the outcome of the next experiment will be C can be estimated as (r + 1)=(n + k). A detailed description and a proof of the Laplace law can be found in <ref> ( Howson and Urbach, 1988 ) </ref> . The Laplace law applies to any repeatable experiment (e.g., tossing a coin). The Laplace law is a special case of a modified estimate called m-Probability ( Cestnik and Bratko, 1991 ) .
Reference: <author> Hsu, C.-N., and Knoblock, C. A. </author> <year> 1994. </year> <title> Rule induction for semantic query optimization. </title> <booktitle> In Machine Learning, Proceedings of the 11th International Conference (ML-94). </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hsu, C.-N., and Knoblock, C. A. </author> <year> 1996a. </year> <title> Discovering robust knowledge from dynamic closed-world data. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96). </booktitle>
Reference-contexts: To deal with this problem, we apply the robustness estimation approach to guide the data mining and evaluation of semantic rules. In the data mining stage, the discovery system uses a rule pruning approach <ref> ( Hsu and Knoblock, 1996a ) </ref> to prune antecedents of a discovered rule to increase its robustness. This approach estimates the robustness of a partially pruned rule and searches for a pruning that yields robust rules. <p> Meanwhile, basil estimated the robustness of these rules. We used another set of 202 sample transactions as the transaction log of the databases to assist the robustness estimation. Those transactions were synthesized for a previous experiment <ref> ( Hsu and Knoblock, 1996a ) </ref> . After generating the rules and collecting their robustness, we applied the set of 123 transactions to the two relational databases and created a new state for each databases.
Reference: <author> Hsu, C.-N., and Knoblock, C. A. </author> <year> 1996b. </year> <title> Using inductive learning to generate rules for semantic query optimization. </title> <editor> In Fayyad, U. M., Piatetsky-Shapiro, G., Smyth, P., and Uthurusamy, R., eds., </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press/MIT Press. </publisher> <address> chapter 17. </address>
Reference: <author> Hsu, C.-N. </author> <year> 1996. </year> <title> Learning Effective and Robust Knowledge for Semantic Query Optimization. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Southern California. </institution> <note> Available as USC/ISI Technical Report RR-96-451, or ftp://ftp.isi.edu/isi-pubs/rr-96-451.ps.Z. </note>
Reference-contexts: In the evaluation stage of the discovery, the system eliminates rules when their estimated robustness values are below a given threshold. Our experimental results show that the resulting rules are effective in query optimization and robust against database changes <ref> ( Hsu, 1996 ) </ref> . We can also apply the robustness estimation approach to rule maintenance in a manner similar to our rule pruning approach. <p> We can also cache the parameter values in advance (e.g., the size of a relation) to improve the efficiency. 4. Experimental Results We performed an empirical evaluation on the robustness estimation approach applied to large-scaled real-world databases. For this purpose, we used the rule discovery system basil <ref> ( Hsu, 1996 ) </ref> to derive rules from two large oracle relational databases. These databases are part of a transportation logistic planning application. Table 11 summarizes the contents and the sizes of these databases. <p> Generally speaking, a rule is more applicable if it is shorter. In other words, if the number of antecedent literals of a rule is smaller, then it is more widely applicable because it is less specific. Many knowledge discovery systems including the rule discovery systems for SQO <ref> ( Hsu, 1996 ) </ref> and ILP systems ( Raedt and Bruynooghe, 1993, Lavrac and Dzeroski, 1994, Dzeroski, 1996 ) can generate Horn-clause rules from data represented in relations similar to those in relational databases. However, the discovered rules are usually too specific and not robust against database changes. <p> Our previous experiment showed that long rules are less applicable and that there is approximately an inverse proportional relation between the applicability and estimated robust ness <ref> ( Hsu, 1996 ) </ref> . 3. Transactions in general can be considered as actions that change world states and we will refer to actions as transactions in the following discussion.
Reference: <author> King, J. J. </author> <year> 1981. </year> <title> Query Optimization by Semantic Reasoning. </title> <type> Ph.D. Dissertation, </type> <institution> Stanford University, Department of Computer Science. </institution>
Reference: <author> Knoblock, C. A., Arens, Y., and Hsu, C.-N. </author> <year> 1994. </year> <title> Cooperating agents for information retrieval. </title> <booktitle> In Proceedings of the Second International Conference on Intelligent and Cooperative Information Systems. </booktitle>
Reference: <author> Lavrac, N., and Dzeroski, S. </author> <year> 1994. </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood. </publisher>
Reference: <author> Lloyd, J. W. </author> <year> 1987. </year> <booktitle> Foundations of Logic Programming. </booktitle> <address> Berlin, Germany: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: A sequence of simple transactions is a compound transaction. We use the term "transaction" interchangeably with "simple transaction" in this paper. Table 1 also lists some Horn-clause rules that express the regularity of data. We adopt standard Prolog terminology and semantics as defined in <ref> ( Lloyd, 1987 ) </ref> in our discussion of rules. In addition, we refer to literals defined on database relations as database literals (e.g., seaport ( ,?glc cd,?storage, , , )) and literals on built-in relations as built-in literals (e.g., ?latitude 35.89). We distinguish between two classes of rules.
Reference: <author> Mannila, H., and Raiha, K.-J. </author> <year> 1994. </year> <title> Algorithms for inferring functional dependencies from relations. </title> <booktitle> Data and Knowledge Engineering 12 </booktitle> <pages> 83-99. </pages>
Reference-contexts: include rule discovery for semantic query optimization (SQO) ( Siegel et al., 1991, Shekhar et al., 1993, Hsu and Knoblock, 1994, Hsu and Knoblock, 1996b, Hsu, 1996 ) , learning an integrated ontology of heterogeneous databases ( Dao and Perry, 1995, Ambite and Knoblock, 1995 ) , functional dependency discovery <ref> ( Mannila and Raiha, 1994, Bell, 1995 ) </ref> , knowledge discovery for decision support, etc. However, most approaches to these problems assume static databases, while in practice, databases are dynamic, that is, they change frequently.
Reference: <author> Minton, S. </author> <year> 1988. </year> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <type> Ph.D. Dissertation, </type> <institution> Carnegie Mellon University, School of Computer Science. </institution>
Reference-contexts: Another example of rule pruning is the speedup learning system prodigy-ebl <ref> ( Minton, 1988 ) </ref> , which learns search-control rules for problem solving. To increase the applicability of its learned rules, prodigy-ebl contains a compressor to prune rules after they are 20 HSU AND KNOBLOCK Table 14. Rule antecedent pruning algorithm Algorithm 1. Pruning rule antecedents 1.
Reference: <author> Pawlak, Z. </author> <year> 1991. </year> <title> Rough Sets: Theoretical aspects of Reasoning about Data. </title> <address> Boston, MA: </address> <publisher> Kluwer. </publisher>
Reference-contexts: Significance ( Clark and Niblett, 1989 ) is used to measure the correlation between the antecedents and consequent of a rule by computing their ratio of the instance coverage of a rule. Rough set theory <ref> ( Pawlak, 1991 ) </ref> is useful for measuring whether a given set of attributes is sufficient to represent a target concept.
Reference: <author> Piatetsky-Shapiro, G. </author> <year> 1984. </year> <title> A Self-Organizing Database System A Different Approach To Query Optimization. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, New York University. </institution>
Reference: <author> Piatetsky-Shapiro, G. </author> <year> 1991. </year> <title> Discovery, analysis, and presentation of strong rules. </title> <editor> In Piatetsky-Shapiro, G., and Frawley, W. J., eds., </editor> <title> Knowledge Discovery in Databases. </title> <publisher> MIT Press. </publisher> <pages> 229-248. </pages>
Reference: <author> Raedt, L. D., and Bruynooghe, M. </author> <year> 1993. </year> <title> A theory of clausal discovery. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI-93). </booktitle>
Reference: <author> Ramsay, A. </author> <year> 1988. </year> <booktitle> Formal Methods in Artificial Intelligence. </booktitle> <address> Cambridge, U.K.: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: The robustness of r in accessible states from the current state d is defined as Robust (rjd) = Pr (:tjd) = 1 Pr (tjd). This definition of robustness is analogous in spirit to the notion of accessibility and the possible worlds semantics in modal logic <ref> ( Ramsay, 1988 ) </ref> . Definition 2 retains our intuitive notion of robustness, but allows us to estimate robustness without counting the intractably large number of possible database states. <p> Our emphasis on transactions in our definition of robustness is analogous in spirit to the notion of accessibility in the possible worlds semantics of modal logic <ref> ( Ramsay, 1988 ) </ref> .
Reference: <author> Shekhar, S., Hamidzadeh, B., Kohli, A., and Coyle, M. </author> <year> 1993. </year> <title> Learning transformation rules for semantic query optimization: A data-driven approach. </title> <journal> IEEE Transactions on Knowledge and Data Engineering 5(6) </journal> <pages> 950-964. </pages>
Reference: <author> Siegel, M. D., Sciore, E., and Salveter, S. </author> <year> 1991. </year> <title> Rule discovery for query optimization. </title> <editor> In Piatetsky-Shapiro, G., and Frawley, W. J., eds., </editor> <booktitle> Knowledge Discovery in Databases. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <pages> 411-427. </pages>
Reference: <author> Sun, W., and Yu, C. T. </author> <year> 1994. </year> <title> Semantic query optimization for tree and chain queries. </title> <journal> IEEE Trans. Knowledge and Data Engineering 6(1) </journal> <pages> 136-151. </pages>
Reference: <author> Ullman, J. D. </author> <year> 1988. </year> <title> Principles of Database and Knowledge-base Systems, </title> <booktitle> volume I,II. </booktitle> <address> Palo Alto, CA: </address> <publisher> Computer Science Press. </publisher>


References-found: 35

