URL: http://www.iro.umontreal.ca/~lisa/pointeurs/fessant_1995_ag.ps
Refering-URL: http://www.iro.umontreal.ca/labs/neuro/bib/journals/journals.html
Root-URL: http://www.iro.umontreal.ca
Email: email: bengio@iro.umontreal.ca  
Title: On the Prediction of Solar Activity Using Different Neural Network Models  
Author: F. Fessant S. Bengio D. Collobert 
Address: Technopole Anticipa, 2 avenue Pierre Marzin, 22307 Lannion Cedex, France.  
Affiliation: France Telecom CNET, LAB/RIO/TNT,  
Abstract: Accurate prediction of ionospheric parameters is crucial for telecommunication companies. These parameters strongly rely on solar activity. In this paper, we analyze the use of neural networks for sunspots time series prediction. Three types of models are tested and experimental results are reported for a particular sunspots time series: the IR5 index. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abarbanel, H., R. Brown, J. Sidorowich, and L. Tsimring. </author> <title> The analysis of observed chaotic data in physical systems. </title> <journal> Reviews of Modern Physics, </journal> <volume> 65:4, </volume> <pages> 1331-1392, </pages> <year> 1993. </year>
Reference: <author> Bourdila, A. and R. Hanbaba. </author> <title> Long term ionospheric radiopropagation predictions choices of indices. </title> <booktitle> In Solar Terrestrial Predictions Proceedings of a Workshop at Meudon, France, </booktitle> <pages> 491-499, </pages> <year> 1984. </year>
Reference: <author> Box, G. and G. Jenkins. </author> <title> Time Series Analysis, Forecasting and Control. </title> <publisher> Holden-Day, </publisher> <address> San Francisco, </address> <year> 1970. </year>
Reference: <author> Canu, S., R. Sobral, and R. Lengelle. </author> <title> Formal neural network as an adapta-tive model for water demand. </title> <booktitle> In Proceedings of the International Neural Network Conference (INNC), </booktitle> <pages> 131-135, </pages> <address> Paris, France, </address> <year> 1990. </year>
Reference: <author> Cottrell, G., P. Munro, and D. Zipser. </author> <title> Learning internal representations from gray-scale images: An example of extensional programming. </title> <booktitle> In Ninth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 462-473, </pages> <address> Seattle. </address> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, </address> <year> 1987. </year>
Reference: <author> Cybenko, G. </author> <title> Approximation by superposition of sigmoidal functions. </title> <journal> Mathematics of Control, Signal and Systems, </journal> <volume> 2, </volume> <pages> 303-314, </pages> <year> 1989. </year>
Reference: <author> Elman, J. L. </author> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14, </volume> <pages> 179-211, </pages> <year> 1990. </year>
Reference-contexts: The total number of free parameters in the modular model is still half the number of free parameters in the simple model. 4.2.3 Elman's Recurrent Network. <ref> (Elman, 1990) </ref> has proposed a partially recurrent neural network: a model intended to deal with the structural aspects of language as it varies in time. This model has been used by other authors and promises to be useful in various time related domains.
Reference: <author> Fahlman, S. and C. Lebiere. </author> <title> The Cascade-Correlation learning architecture. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems: Proceedings of the 1989 Conference, </booktitle> <pages> 524-532. </pages> <publisher> Morgan Kauffmann, </publisher> <year> 1990. </year>
Reference: <author> Funahashi, K. </author> <title> On the approximate realization of continuous mappings by neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 2, </volume> <pages> 183-192, </pages> <year> 1989. </year>
Reference: <author> Hertz, J., A. Krogh, and R. G. Palmer. </author> <title> Introduction to the theory of neural computation. Santa fe Institute studies in the Sciences of Complexity. </title> <publisher> Addison Wesley, </publisher> <year> 1991. </year>
Reference: <author> Hornik, K., M. Stinchcombe, and H. White. </author> <title> Multilayer feedforward networks are universal approximators. </title> <booktitle> Neural Networks, </booktitle> <volume> 2, </volume> <pages> 359-366, </pages> <year> 1989. </year>
Reference: <author> Jacobs, R. A., M. I. Jordan, S. J. Nowlan, and G. E. Hinton. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3, </volume> <pages> 79-87, </pages> <year> 1991. </year>
Reference-contexts: Many other models still need to be experimented, such as fully recurrent neural networks (Williams and Zipser, 1989), time-delay neural networks (Lang and Hin-ton, 1988), radial basis functions (Moody and Darken, 1989; Poggio and Girosi, 1990) and adaptive mixtures of experts <ref> (Jacobs et al., 1991) </ref>. We will also look at these models in a perspective where we mix different input windows (embedding dimension). 13
Reference: <author> Koons, H. and D. Gorney. </author> <title> A sunspot maximum prediction using a neural network. </title> <journal> Transactions of American Geophysical Union, </journal> <volume> 71:18, </volume> <pages> 677-688, </pages> <year> 1990. </year> <note> 14 Lang, </note> <author> K. J. and G. E. Hinton. </author> <title> The development of the time-delay neural net-work architecture for speech recognition. </title> <type> Technical Report CMU-CS-88-152, </type> <institution> Carnegie-Mellon University, Department of Computer Science, </institution> <year> 1988. </year>
Reference: <author> Lapedes, A. and R. Farber. </author> <title> Nonlinear signal processing using neural networks: prediction and system modelling. </title> <type> Technical Report LA-UR-87-2662, </type> <institution> Los Alamos National Laboratory, Theoretical Division, </institution> <year> 1987. </year>
Reference: <author> Le Cun, Y., B. Boser, J. Denker, D. Henderson, R. Howard, W. Hubbard, and L. Jackel. </author> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 541-551, </pages> <year> 1989. </year>
Reference: <author> Le Cun, Y., J. Denker, and S. Solla. </author> <title> Optimal brain damage. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems: Proceedings of the 1989 Conference, </booktitle> <pages> 598-605. </pages> <publisher> Morgan Kauffmann, </publisher> <year> 1990. </year>
Reference: <author> Lippmann, R. P. </author> <title> Review of neural networks for speech recognition. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 1-38, </pages> <year> 1989. </year>
Reference: <author> Lundstedt, H. </author> <title> Neural networks and predictions of solar-terrestrial effects. </title> <booktitle> Planet Space Science, 40:4, </booktitle> <pages> 457-464, </pages> <year> 1992. </year>
Reference: <author> Lundstedt, H. and P. Wintoft. </author> <title> Prediction of geomagnetic storms from solar wind data with the use of a neural network. </title> <journal> Annales Geophysicae, </journal> <volume> 12, </volume> <pages> 19-24, </pages> <year> 1994. </year>
Reference: <author> Macpherson, K. </author> <title> Neural network computation techniques applied to solar activity prediction. </title> <booktitle> Advanced Space Research, 13:9, </booktitle> <pages> 447-450, </pages> <year> 1993. </year>
Reference: <author> McNish, A. and J. Lincoln. </author> <title> Prediction of sunspot numbers. </title> <journal> Transactions of American Geophysical Union, </journal> <volume> 30:5, </volume> <pages> 673-685, </pages> <year> 1949. </year>
Reference: <author> Moody, J. and C. Darken. </author> <title> Fast learning in networks of locally-tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference: <author> Park, D. C., M. A. El-Sharkawi, and R. J. Marks II. </author> <title> Electric load forecasting using an artificial neural network. </title> <journal> IEEE Transaction on Power Systems, </journal> <volume> 6:2, </volume> <pages> 442-449, </pages> <year> 1991. </year>
Reference: <author> Poggio, T. and F. Girosi. </author> <title> Regularization algorithms for learning that are equivalent to multilayer networks. </title> <journal> Science, </journal> <volume> 247, </volume> <pages> 978-982, </pages> <year> 1990. </year>
Reference: <author> Rumelhart, D. E., G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E. and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1. </volume> <publisher> MIT Press, </publisher> <year> 1986. </year> <note> 15 Takens, </note> <author> F. </author> <title> Detecting strange attractors in turbulence. </title> <editor> In Rand, D. A. and L.-S. Young, editors, </editor> <booktitle> Dynamical Systems and Turbulence, volume 898 of Lecture Notes in Mathematics, </booktitle> <pages> 366-381, </pages> <address> Warwick 1980. </address> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference: <author> Tesauro, G. </author> <title> Practical issues in temporal difference learning. </title> <booktitle> Machine Learning, </booktitle> <address> 8:34, </address> <year> 1992. </year>
Reference: <author> Vapnik, V. N. </author> <title> Estimation of Dependencies Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New-York, NY, USA, </address> <year> 1982. </year>
Reference: <author> Varfis, A. and C. Versino. </author> <title> Univariate economic time series forecasting by connectionist methods. </title> <booktitle> In Proceedings of the International Neural Network Conference (INNC), </booktitle> <pages> 342-345, </pages> <address> Paris, France, </address> <year> 1990. </year>
Reference: <author> Weigend, A. S., B. A. Huberman, and D. E. Rumelhart. </author> <title> Predicting sunspots and exchange rates with connectionist networks. </title> <editor> In Casdagli, M. and S. Eu-bank, editors, </editor> <booktitle> Nonlinear modeling and forecasting, </booktitle> <pages> 395-431. </pages> <publisher> Addison Wes-ley, </publisher> <year> 1992. </year>
Reference: <author> Williams, R. and D. Zipser. </author> <title> A learning algorithm for continually running fully recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 270-280, </pages> <year> 1989. </year> <month> 16 </month>
Reference-contexts: In this paper, we proposed two particular models, namely a modular model and a partially recurrent model, specially chosen for the IR5 time series. Many other models still need to be experimented, such as fully recurrent neural networks <ref> (Williams and Zipser, 1989) </ref>, time-delay neural networks (Lang and Hin-ton, 1988), radial basis functions (Moody and Darken, 1989; Poggio and Girosi, 1990) and adaptive mixtures of experts (Jacobs et al., 1991). We will also look at these models in a perspective where we mix different input windows (embedding dimension). 13
References-found: 30

