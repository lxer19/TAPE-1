URL: http://dimacs.rutgers.edu/~tshaheen/onlinescheduling_survey.ps
Refering-URL: http://dimacs.rutgers.edu/~tshaheen/scheduling.html
Root-URL: http://www.cs.rutgers.edu
Email: E-mail: sgall@math.cas.cz  
Title: On-Line Scheduling A Survey  
Author: Jir Sgall 
Note: Mathematical Institute, AS CR Zitna 25 115 67 Praha 1 Czech Republic  
Web: http://www.math.cas.cz/~sgall/  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> S. Albers. </author> <title> Better bounds for online scheduling. </title> <booktitle> In Proc. of the 29th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 130-139. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: To keep the competitive ratio bounded away from 2 even for large m it is necessary to keep some constant fraction of machines lightly loaded. Such an algorithm was first developed in [8], later better algorithms based on this idea were designed in <ref> [55, 1] </ref> to give the currently best upper bounds for large m. The analysis of all these algorithms is relatively complicated. The current state of our knowledge is summarized in Table 1. <p> The other lower bounds for small m are due to [17]. The lower bound for large m is due to <ref> [1] </ref>, improving upon [9]. Very recently R. Chandrasekaran claimed a lower bound of p m = 4, which would significantly decrease the gap in this case. 10 4.2 Randomized algorithms Much less is known about randomized algorithms for the basic model studied in Section 4.1.
Reference: 2. <author> J. Aspnes, Y. Azar, A. Fiat, S. Plotkin, and O. Waarts. </author> <title> On-line load balancing with applications to machine scheduling and virtual circuit routing. </title> <journal> J. ACM, </journal> <volume> 44(3) </volume> <pages> 486-504, </pages> <year> 1997. </year>
Reference-contexts: The deterministic lower bounds apply both for algorithms with and without preemption, with the exception of arbitrary m where the lower bound is only 2 with preemption. 4.5 Different speeds For related machines, a simple doubling strategy leads to a constant competitive ratio <ref> [2] </ref>. We guess an estimate on the makespan, and schedule each job on the slowest machine such that the current makespan does not exceed the estimate; if this fail we double the estimate and continue. <p> For the restricted assignment the optimal competitive ratio is fi (log m) both for deterministic and randomized algorithms [6]. For unrelated machines with no restriction it is also possible to obtain O (log m)-competitive deterministic algorithm <ref> [2, 60] </ref>. By the previous lower bound this is optimal, too. It is interesting that both for related and unrelated machines the optimal algorithms are asymptotically better than List Scheduling. <p> For unrelated machines the competitive ratio of List Scheduling is exactly n <ref> [2] </ref>. For related machines the competitive ratio of List Scheduling is asymptotically fi (log m) [22, 2] (the lower and upper bounds, respectively). <p> For unrelated machines the competitive ratio of List Scheduling is exactly n [2]. For related machines the competitive ratio of List Scheduling is asymptotically fi (log m) <ref> [22, 2] </ref> (the lower and upper bounds, respectively). The exact competitive ratio for m = 2 is and for 3 m 6 it is equal to 1 + (m 1)=2 [22]; moreover for m = 2; 3 it can be checked easily that there is no better deterministic algorithm.
Reference: 3. <author> A. Avidor, Y. Azar, and J. Sgall. </author> <title> Ancient and new algorithms for load balancing in the L p norm. </title> <booktitle> To appear in Proc. of the 9th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <year> 1998. </year>
Reference-contexts: Gerhard Woeginger and the author observed that the randomized lower bound from the basic model which approaches e=(e 1) 1:5819 (see Table 1) can be modified to work for open shop, too. 4.7 Minimizing the L p norm <ref> [3] </ref> Here we minimize the L p norm of the load vector, instead of the makespan, which is equivalent to the L 1 norm.
Reference: 4. <author> B. Awerbuch, Y. Azar, E. F. Grove, M.-Y. Kao, P. Krishnan, and J. S. Vitter. </author> <title> Load balancing in the l p norm. </title> <booktitle> In Proc. of the 36th Ann. IEEE Symp. on Foundations of Computer Sci., </booktitle> <pages> pages 383-391. </pages> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: Another possibility is to consider general L p norms of the vector of loads of the machines, which is studied for load-balancing, where in particular L 2 norm has a natural interpretation <ref> [5, 4] </ref>. If we allow preemptions (see Section 2.6), we usually want to minimize the number of times we preempt a job. However, this is always a secondary criterion. <p> Of special interest is the Euclidean L 2 norm, the square root of the sum of squares of loads, which has a natural interpretation in load balancing <ref> [5, 4] </ref>. For L 2 norm, List Scheduling is p 4=3 competitive, and this is optimal. The performance of List Scheduling is not monotone in the number of machines.
Reference: 5. <author> Y. Azar. </author> <title> On-line load balancing. </title> <note> To appear in OnLine Algorithms, </note> <editor> eds. A. Fiat and G. Woeginger, </editor> <booktitle> Lecture Notes in Comput. </booktitle> <publisher> Sci. Springer-Verlag, </publisher> <year> 1998. </year>
Reference-contexts: We do not cover this paradigm in this survey. It is studied for example in the papers [83, 62, 32], and it is also related to load balancing <ref> [5] </ref>. 2.3 Objective functions The most common objective function is the makespan, which is the length of the schedule, or equivalently the time when the last job is completed. <p> Another possibility is to consider general L p norms of the vector of loads of the machines, which is studied for load-balancing, where in particular L 2 norm has a natural interpretation <ref> [5, 4] </ref>. If we allow preemptions (see Section 2.6), we usually want to minimize the number of times we preempt a job. However, this is always a secondary criterion. <p> It can be formulated in the language of on-line load balancing as the case where the jobs are permanent and the load is their only parameter corresponding to our running time (cf. <ref> [5] </ref>). In this paradigm we do not allow release times and precedence constraints, as these restrictions appear to be unnatural with scheduling jobs one by one. <p> The competitive ratio can be improved by using more sophisticated techniques instead of doubling, but its precise value is not known, see <ref> [5] </ref> for more references. For the restricted assignment the optimal competitive ratio is fi (log m) both for deterministic and randomized algorithms [6]. For unrelated machines with no restriction it is also possible to obtain O (log m)-competitive deterministic algorithm [2, 60]. <p> Of special interest is the Euclidean L 2 norm, the square root of the sum of squares of loads, which has a natural interpretation in load balancing <ref> [5, 4] </ref>. For L 2 norm, List Scheduling is p 4=3 competitive, and this is optimal. The performance of List Scheduling is not monotone in the number of machines.
Reference: 6. <author> Y. Azar, J. Naor, and R. </author> <title> Rom. The competitiveness of on-line assignments. </title> <journal> J. of Algorithms, </journal> <volume> 18 </volume> <pages> 221-237, </pages> <year> 1995. </year>
Reference-contexts: The competitive ratio can be improved by using more sophisticated techniques instead of doubling, but its precise value is not known, see [5] for more references. For the restricted assignment the optimal competitive ratio is fi (log m) both for deterministic and randomized algorithms <ref> [6] </ref>. For unrelated machines with no restriction it is also possible to obtain O (log m)-competitive deterministic algorithm [2, 60]. By the previous lower bound this is optimal, too. It is interesting that both for related and unrelated machines the optimal algorithms are asymptotically better than List Scheduling.
Reference: 7. <author> Y. Azar and O. Regev. </author> <title> Online bin-stretching. </title> <type> Manuscript, </type> <year> 1997. </year>
Reference-contexts: If the optimum is known, the problem is also called bin-stretching (because we know that the jobs fit into some number of bins of some height, and we ask how much we need to "stretch" the bins to fit the jobs on-line), and is studied in <ref> [7] </ref>. For two machines once again 4=3 is the correct and tight answer and for more machines a 1:625-competitive algorithm is presented. 8 Conclusions We have seen a variety of on-line scheduling problems. Many of them are understood satisfactorily, but there are also many interesting open problems.
Reference: 8. <author> Y. Bartal, A. Fiat, H. Karloff, and R. Vohra. </author> <title> New algorithms for an ancient scheduling problem. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 51(3) </volume> <pages> 359-366, </pages> <year> 1995. </year> <month> 32 </month>
Reference-contexts: To keep the competitive ratio bounded away from 2 even for large m it is necessary to keep some constant fraction of machines lightly loaded. Such an algorithm was first developed in <ref> [8] </ref>, later better algorithms based on this idea were designed in [55, 1] to give the currently best upper bounds for large m. The analysis of all these algorithms is relatively complicated. The current state of our knowledge is summarized in Table 1. <p> Only for the case of m = 2 we know an optimal randomized algorithm. A 4=3-competitive randomized algorithm for two machines was presented in <ref> [8] </ref>. First we prove that this is best possible. Theorem 2 [8]. No randomized algorithm for 2-machine scheduling can be better than 4=3-competitive. Proof. Consider the sequence of three jobs with running times 1, 1, and 2. Suppose we have an algorithm which is better than 4=3-competitive. <p> Only for the case of m = 2 we know an optimal randomized algorithm. A 4=3-competitive randomized algorithm for two machines was presented in <ref> [8] </ref>. First we prove that this is best possible. Theorem 2 [8]. No randomized algorithm for 2-machine scheduling can be better than 4=3-competitive. Proof. Consider the sequence of three jobs with running times 1, 1, and 2. Suppose we have an algorithm which is better than 4=3-competitive. <p> To implement this algorithm it is necessary to keep track of all possible schedules and their probabilities. The naive way of doing this uses 2 n1 configurations after n jobs, but it is possible to implement the algorithm with only n configurations <ref> [8] </ref>. Theorem 3 [8]. The algorithm Random is 4=3-competitive for two machines. Proof. <p> To implement this algorithm it is necessary to keep track of all possible schedules and their probabilities. The naive way of doing this uses 2 n1 configurations after n jobs, but it is possible to implement the algorithm with only n configurations <ref> [8] </ref>. Theorem 3 [8]. The algorithm Random is 4=3-competitive for two machines. Proof. After scheduling some sequence of jobs, let a be the expected makespan, b be the total running time of all jobs scheduled so far, and let T be the longest 11 running time among all jobs scheduled so far. <p> Namely, such an algorithm should preserve the ratio of expected loads described above. An algorithm based on this invariant would be a natural generalization of the optimal algorithm for two machines from <ref> [8] </ref>; it would also follow the suggestion from [18] (see Section 4.3). This faces several problems. First of all, it is not clear at all that we would be able to handle long jobs similarly as for m = 2.
Reference: 9. <author> Y. Bartal, H. Karloff, and Y. Rabani. </author> <title> A new lower bound for m-machine schedul-ing. </title> <journal> Inf. Process. Lett., </journal> <volume> 50 </volume> <pages> 113-116, </pages> <year> 1994. </year>
Reference-contexts: The other lower bounds for small m are due to [17]. The lower bound for large m is due to [1], improving upon <ref> [9] </ref>. Very recently R. Chandrasekaran claimed a lower bound of p m = 4, which would significantly decrease the gap in this case. 10 4.2 Randomized algorithms Much less is known about randomized algorithms for the basic model studied in Section 4.1.
Reference: 10. <author> Y. Bartal, S. Leonardi, A. Marchetti-Spaccamela, J. Sgall, and L. Stougie. </author> <title> Multiprocessor scheduling with rejection. </title> <booktitle> In Proc. of the 7th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 95-103. </pages> <note> ACM-SIAM, 1996. To appear in SIAM J. Disc. Math. </note>
Reference-contexts: Thus this on-line problem can be seen as a non-trivial generalization of the well-known ski rental problem. We first look at deterministic algorithms in the case when preemption is not allowed <ref> [10] </ref>. At first it would seem that a good algorithm has to do well both in deciding which jobs to accept, and on which machines to schedule the accepted jobs. <p> The lower bounds for small m from <ref> [10] </ref> work also for preemptive deterministic algorithms, but for large m yield only a lower bound of 2. An improved algorithm for deterministic preemptive scheduling was designed in [69]. It achieves competitive ratio 2:3875 for all m.
Reference: 11. <author> S. Baruah, G. Koren, B. Mishra, A. Raghunatan, L. Roiser, and D. Sasha. </author> <title> On-line scheduling in the presence of overload. </title> <booktitle> In Proc. of the 32nd Ann. IEEE Symp. on Foundations of Computer Sci., </booktitle> <pages> pages 100-110. </pages> <publisher> IEEE, </publisher> <year> 1991. </year>
Reference-contexts: and possibly different for each job. 2.10 Variants not covered in this survey A very different model of online scheduling in real-time systems, where each job has its deadline and value and the goal is to maximize the value of jobs finished before their deadline, is considered in several papers <ref> [28, 11, 52, 65] </ref>. Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in [51, 53].
Reference: 12. <author> S. Ben-David, A. Borodin, R. M. Karp, G. Tardos, and A. Wigderson. </author> <title> On the power of randomization in on-line algorithms. </title> <journal> Algorithmica, </journal> <volume> 11 </volume> <pages> 2-14, </pages> <year> 1994. </year>
Reference-contexts: A randomized algorithm is -competitive if for each instance this expectation is within a factor of of the optimal objective value. This corresponds to the so-called oblivious adversary <ref> [12] </ref>, which has to commit to an input instance beforehand, without any knowledge of the random bits or actions of the algorithm. 2.5 Release times and deadlines, precedence constraints and conflicting jobs Each job may have an individual release time, which is the earliest time when it may be scheduled, and
Reference: 13. <author> A. Borodin and R. El-Yaniv. </author> <title> Online Computation and Competitive Analysis. </title> <publisher> Cambridge University Press, </publisher> <year> 1998. </year>
Reference-contexts: Instead, it learns the input piece by piece, and has to react to the new requests with only a partial knowledge of the input. Such scheduling algorithms are the topic of this survey. (For a general reference on on-line algorithms see upcoming book <ref> [13] </ref>.) Scheduling have continuously been an active research area, reflecting the changes in the theoretical computer science.
Reference: 14. <author> S. Chakrabarti, C. A. Phillips, A. S. Schulz, D. B. Shmoys, C. Stein, and J. Wein. </author> <title> Improved scheduling algorithms for minsum criteria. </title> <booktitle> In Proc. of the 23th International Colloquium on Automata, Languages, and Programming, Lecture Notes in Comput. Sci. </booktitle> <volume> 1099, </volume> <pages> pages 646-657. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: in the paradigm with unknown running times; in that case it is optimal even if preemptions are allowed [20]. 6.2 Minimizing the total weighted completion time For minimizing the total completion time, and even total weighted completion time, it is possible to give a similar general theorem as Theorem 6 <ref> [47, 45, 14] </ref>. More surprisingly, it is possible to design schedules that are close to optimal simultaneously for the total completion time and the makespan [14]. For technical reasons we assume that all running times are at least 1. The algorithm for this general reduction is the following. <p> More surprisingly, it is possible to design schedules that are close to optimal simultaneously for the total completion time and the makespan <ref> [14] </ref>. For technical reasons we assume that all running times are at least 1. The algorithm for this general reduction is the following. <p> Theorem 7 <ref> [47, 45, 14] </ref>. For any variant of online scheduling of jobs arriving over time, Greedy-Interval is 4-competitive w.r.t. the total weighted completion time and simultaneously 3-competitive w.r.t. the makespan. Proof. First we prove that Greedy-Interval is competitive w.r.t. the total weighted completion time. Fix an optimal schedule. <p> This gives competitive ratio 4 w.r.t. both the makespan and the total completion time, if is the approximation ratio of the algorithm we use. Number of results that follows from using such approximation algorithms is described in <ref> [47, 45, 14] </ref>; for example for minimizing the total weighted completion time on identical 28 machines there exists an (1 + ")-approximation polynomial time algorithm, and hence we obtain (4 + ")-competitive polynomial time algorithm [45]. A general randomization technique can be used to improve upon the deterministic algorithm Greedy-Interval. <p> A general randomization technique can be used to improve upon the deterministic algorithm Greedy-Interval. If we use t = fi2 i in the algorithm for fi chosen uniformly between 1=2 and 1, the competitive ratios will be 2:89 w.r.t. the total completion time and 2:45 w.r.t. the makespan <ref> [14] </ref>. (Note that since the randomized competitive ratio is actually an expectation, we cannot guarantee that the schedule is actually simultaneously within the given factor of both objective functions.
Reference: 15. <author> C. Chekuri, R. Motwani, B. Natarajan, and C. Stein. </author> <title> Approximation techniques for average completion time scheduling. </title> <booktitle> In Proc. of the 8th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 609-618. ACM-SIAM, </pages> <year> 1997. </year>
Reference-contexts: the method of [64] is simply scheduling in the order of 1-points.) After using ff-point scheduling for off-line algorithms in [47], it was observed that choosing ff randomly, under a suitable distribution and starting from a suitable preemptive schedule that can be computed on-line, leads to new randomized on-line algorithms <ref> [15, 40] </ref>. These methods generally lead not only to c-competitive algorithms for non-preemptive scheduling, they in fact guarantee that the produced non-preemptive schedule is within the factor c of the optimal preemptive schedule. <p> In the case of a single machine ff-point scheduling leads to a randomized algorithm with competitive ratio w.r.t. the total completion time e=(e 1) 1:5819 <ref> [15] </ref>; this is also optimal [79, 81]. For the total weighted completion time ff-point scheduling gives a randomized 2-competitive algorithm for a single machine [40].
Reference: 16. <author> B. Chen, A. van Vliet, and G. J. Woeginger. </author> <title> A lower bound for randomized on-line scheduling algorithms. </title> <journal> Inf. Process. Lett., </journal> <volume> 51 </volume> <pages> 219-222, </pages> <year> 1994. </year>
Reference-contexts: Consequently, its competitive ratio approaches two as m grows. The analysis of this algorithm is again difficult, even involving extensive computations to obtain the best results. The idea of the lower bound for two machines can be extended to arbitrary number of machines <ref> [16, 72, 74] </ref>.
Reference: 17. <author> B. Chen, A. van Vliet, and G. J. Woeginger. </author> <title> New lower and upper bounds for on-line scheduling. </title> <journal> Oper. Res. Lett., </journal> <volume> 16 </volume> <pages> 221-230, </pages> <year> 1994. </year>
Reference-contexts: Thus this method cannot give a better competitive ratio than List Scheduling. To design a good algorithm, we need to avoid both of these extremes. Current results use two different approaches. One is to schedule each job on one of the two currently least loaded machines <ref> [37, 17] </ref>. This gives better results than List Scheduling for any m 4, and achieves the currently best upper bounds for small m. However, for large m, the competitive ratio still approaches 2. <p> For comparison we include also the competitive ratio of List Scheduling. (See Section 4.2 for a discussion of results for randomized algorithms.) The observation that List Scheduling is optimal for m = 2; 3 is due to [31]. The other lower bounds for small m are due to <ref> [17] </ref>. The lower bound for large m is due to [1], improving upon [9]. Very recently R. <p> It always assigns the new job on one of the two least loaded machines, similarly to the deterministic algorithms for small m from <ref> [37, 17] </ref>. Consequently, its competitive ratio approaches two as m grows. The analysis of this algorithm is again difficult, even involving extensive computations to obtain the best results. The idea of the lower bound for two machines can be extended to arbitrary number of machines [16, 72, 74].
Reference: 18. <author> B. Chen, A. van Vliet, and G. J. Woeginger. </author> <title> An optimal algorithm for preemptive on-line scheduling. </title> <journal> Oper. Res. Lett., </journal> <volume> 18 </volume> <pages> 127-131, </pages> <year> 1995. </year>
Reference-contexts: Namely, such an algorithm should preserve the ratio of expected loads described above. An algorithm based on this invariant would be a natural generalization of the optimal algorithm for two machines from [8]; it would also follow the suggestion from <ref> [18] </ref> (see Section 4.3). This faces several problems. First of all, it is not clear at all that we would be able to handle long jobs similarly as for m = 2. <p> However, for m &gt; 7 we have no randomized algorithm with a better competitive ratio than known deterministic algorithms; this means that we do not know how to make use of randomization for large m. See Table 1. 4.3 Preemptive scheduling <ref> [18] </ref> In this model preemption is allowed. Each job may be assigned to one or more machines and time slots (the time slots have to be disjoint, of course), and this assignment has to be determined completely as soon as the job is presented.
Reference: 19. <author> B. Chen and A. P. A. Vestjens. </author> <title> Scheduling on identical machines: </title> <note> How good is lpt in an online setting? Technical Report Memorandum COSOR 96-11, </note> <institution> Eindhoven University of Technology, </institution> <year> 1996. </year> <note> To appear in Oper. </note> <institution> Res. Lett. </institution>
Reference-contexts: If we consider scheduling without preemptions, we no longer can get a 1-competitive algorithm, even for identical machines. The best upper bound was obtained for the simple algorithm which always schedules the available job with the longest running time; this algorithm is 1:5-competitive <ref> [19, 81] </ref>. A lower bound of 1:3473 shows that this is close to the best possible [19, 81]. For open shop scheduling on two machines the greedy algorithm achieves the competitive ratio of 3=2; this is optimal for scheduling without preemptions [20]. <p> The best upper bound was obtained for the simple algorithm which always schedules the available job with the longest running time; this algorithm is 1:5-competitive <ref> [19, 81] </ref>. A lower bound of 1:3473 shows that this is close to the best possible [19, 81]. For open shop scheduling on two machines the greedy algorithm achieves the competitive ratio of 3=2; this is optimal for scheduling without preemptions [20]. With preemption, a 5=4 competitive algorithm exists and this is optimal [20].
Reference: 20. <author> B. Chen, A. P. A. Vestjens, and G. J. Woeginger. </author> <title> Online scheduling of two-machine open shops where jobs arrive over time. </title> <journal> J. of Combinatorial Optimization, </journal> <volume> 1 </volume> <pages> 355-365, </pages> <year> 1997. </year>
Reference-contexts: A lower bound of 1:3473 shows that this is close to the best possible [19, 81]. For open shop scheduling on two machines the greedy algorithm achieves the competitive ratio of 3=2; this is optimal for scheduling without preemptions <ref> [20] </ref>. With preemption, a 5=4 competitive algorithm exists and this is optimal [20]. Note that the greedy algorithm can also be used in the paradigm with unknown running times; in that case it is optimal even if preemptions are allowed [20]. 6.2 Minimizing the total weighted completion time For minimizing the <p> For open shop scheduling on two machines the greedy algorithm achieves the competitive ratio of 3=2; this is optimal for scheduling without preemptions <ref> [20] </ref>. With preemption, a 5=4 competitive algorithm exists and this is optimal [20]. Note that the greedy algorithm can also be used in the paradigm with unknown running times; in that case it is optimal even if preemptions are allowed [20]. 6.2 Minimizing the total weighted completion time For minimizing the total completion time, and even total weighted completion time, it is possible <p> ratio of 3=2; this is optimal for scheduling without preemptions <ref> [20] </ref>. With preemption, a 5=4 competitive algorithm exists and this is optimal [20]. Note that the greedy algorithm can also be used in the paradigm with unknown running times; in that case it is optimal even if preemptions are allowed [20]. 6.2 Minimizing the total weighted completion time For minimizing the total completion time, and even total weighted completion time, it is possible to give a similar general theorem as Theorem 6 [47, 45, 14].
Reference: 21. <author> B. Chen and G. J. Woeginger. </author> <title> A study of on-line scheduling two-stage shops. </title> <editor> In D.-Z. Du and P. M. Pardalos, editors, </editor> <booktitle> Minimax and Applications, </booktitle> <pages> pages 97-107. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: competitive ratio is better than for non-preemptive randomized scheduling for any s &gt; 1, moreover, it is also always better than for the identical machines (s = 1), in contrast without preemption the worst competitive ratio (both deterministic and randomized) is achieved for some s &gt; 1. 4.6 Shop scheduling <ref> [21] </ref> On-line shop scheduling was so far considered mainly for two machines. This variant of scheduling is somewhat different from all the ones we considered before, since here it may be necessary to introduce idle times on the machines.
Reference: 22. <author> Y. Cho and S. Sahni. </author> <title> Bounds for list schedules on uniform processors. </title> <journal> SIAM J. Comput., </journal> <volume> 9(1) </volume> <pages> 91-103, </pages> <year> 1980. </year>
Reference-contexts: For unrelated machines the competitive ratio of List Scheduling is exactly n [2]. For related machines the competitive ratio of List Scheduling is asymptotically fi (log m) <ref> [22, 2] </ref> (the lower and upper bounds, respectively). The exact competitive ratio for m = 2 is and for 3 m 6 it is equal to 1 + (m 1)=2 [22]; moreover for m = 2; 3 it can be checked easily that there is no better deterministic algorithm. <p> For related machines the competitive ratio of List Scheduling is asymptotically fi (log m) [22, 2] (the lower and upper bounds, respectively). The exact competitive ratio for m = 2 is and for 3 m 6 it is equal to 1 + (m 1)=2 <ref> [22] </ref>; moreover for m = 2; 3 it can be checked easily that there is no better deterministic algorithm. For two machines we are able to analyze the situation further [30]. Suppose that the speeds of the two machines are 1 and s 1.
Reference: 23. <author> E. Davis and J. M. Jaffe. </author> <title> Algorithms for scheduling tasks on unrelated processors. </title> <journal> J. ACM, </journal> <volume> 28(4) </volume> <pages> 721-736, </pages> <year> 1981. </year>
Reference-contexts: Clearly, this algorithm is no longer on-line in any of the paradigms we study. Other two early papers that contain results about on-line scheduling algorithms are <ref> [66, 23] </ref>. The first one gives an optimal algorithm for minimizing the makespan of a preemptive schedule on identical machines where jobs arrive over time, and mentions that the algorithm is on-line. <p> However, we assume that the speeds are known for each job, only 20 the running time is not known (i.e., for each job we know the relative speeds of machines). If no restarts are allowed, a simple example shows that the best competitive ratio is ( p m) <ref> [23] </ref>, even for uniformly related machines. Consider the case of m jobs to be scheduled on m machines, one with speed p m and the rest with speed 1. <p> A matching, O ( p m)-competitive, algorithm is known even for unrelated machines <ref> [23] </ref>. Next we consider the case when restarts are allowed, studied in [75].
Reference: 24. <author> X. Deng and P. Dymond. </author> <title> On multiprocessor system scheduling. </title> <booktitle> In Proc. of the 7th Ann. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 82-88. </pages> <publisher> ACM, </publisher> <year> 1996. </year>
Reference-contexts: factor increase in the competitive ratio [29]. (Note that here the jobs are allowed to change parallelism profile; in other models this would be treated e.g. as a sequence of distinct different jobs and the number of jobs n could increase significantly.) Another type of parallel jobs is studied in <ref> [24] </ref>. Here each job is represented as a directed graph of sequential (sub)jobs, and the competitive ratio achieved is 4. For algorithms with release times, we know that there are no good on-line algorithms w.r.t. total flow time even for sequential jobs.
Reference: 25. <author> X. Deng, N. Gu, T. Brecht, and K. Lu. </author> <title> Preemptive scheduling of parallel jobs on multiprocessors. </title> <booktitle> In Proc. of the 7th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 159-167. ACM-SIAM, </pages> <year> 1996. </year>
Reference-contexts: Interestingly, the results for batch-style scheduling can be generalized to parallel jobs. Here we consider only total completion time (note that waiting time is not well defined for malleable parallel jobs). For ideally malleable jobs there exists a 2-competitive deterministic algorithm <ref> [25] </ref>, matching the performance for sequential jobs (consequently, randomization cannot help in this case). A wide range of types of non-ideally malleable jobs together with various restrictions on the number of preemptions is studied in [29].
Reference: 26. <author> X. Deng and E. Koutsoupias. </author> <title> Competitive implementation of parallel programs. </title> <booktitle> In Proc. of the 4th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 455-461. ACM-SIAM, </pages> <year> 1993. </year>
Reference-contexts: Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in [51, 53]. Online scheduling in presence of delays in communication between processors is studied in <ref> [26, 27] </ref>. 3 General results and history The first proof of competitiveness of an on-line algorithm for a scheduling problem, and perhaps for any problem, was given by Graham already in 1966 [43]. He studied a simple deterministic greedy algorithm, now commonly called List Scheduling.
Reference: 27. <author> X. Deng, E. Koutsoupias, and P. MacKenzie. </author> <title> Competitive implementation of parallel programs. </title> <note> To appear in Algorithmica, 1997. 33 </note>
Reference-contexts: Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in [51, 53]. Online scheduling in presence of delays in communication between processors is studied in <ref> [26, 27] </ref>. 3 General results and history The first proof of competitiveness of an on-line algorithm for a scheduling problem, and perhaps for any problem, was given by Graham already in 1966 [43]. He studied a simple deterministic greedy algorithm, now commonly called List Scheduling.
Reference: 28. <author> M. Dertouzos and A. Mok. </author> <title> Multiprocessor on-line scheduling with release dates. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15 </volume> <pages> 1497-1506, </pages> <year> 1989. </year>
Reference-contexts: and possibly different for each job. 2.10 Variants not covered in this survey A very different model of online scheduling in real-time systems, where each job has its deadline and value and the goal is to maximize the value of jobs finished before their deadline, is considered in several papers <ref> [28, 11, 52, 65] </ref>. Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in [51, 53].
Reference: 29. <author> J. Edmonds, D. D. Chinn, T. Brecht, and X. Deng. </author> <title> Non-clairvoyant multiprocessor scheduling of jobs with changing execution characteristics. </title> <booktitle> In Proc. of the 29th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 120-129. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: For ideally malleable jobs there exists a 2-competitive deterministic algorithm [25], matching the performance for sequential jobs (consequently, randomization cannot help in this case). A wide range of types of non-ideally malleable jobs together with various restrictions on the number of preemptions is studied in <ref> [29] </ref>. <p> simple algorithm which assigns the same number of processors to each unfinished job has competitive ratio at most 2 + 3 3:74; the number of preemptions is n for each job, but it can be decreased to log n at the cost of constant factor increase in the competitive ratio <ref> [29] </ref>. (Note that here the jobs are allowed to change parallelism profile; in other models this would be treated e.g. as a sequence of distinct different jobs and the number of jobs n could increase significantly.) Another type of parallel jobs is studied in [24].
Reference: 30. <author> L. Epstein, J. Noga, S. S. Seiden, J. Sgall, and G. J. Woeginger. </author> <title> Randomized online scheduling for two related machines. </title> <booktitle> Work in progress, </booktitle> <year> 1997. </year>
Reference-contexts: For two machines we are able to analyze the situation further <ref> [30] </ref>. Suppose that the speeds of the two machines are 1 and s 1. It is easy to see that List Scheduling is the best deterministic online algorithm for any choice of s. For s the competitive ratio is 1 + s=(s + 1), increasing from 3=2 to .
Reference: 31. <author> U. Faigle, W. Kern, and G. Turan. </author> <title> On the performance of on-line algorithms for partition problems. </title> <journal> Acta Cybernetica, </journal> <volume> 9 </volume> <pages> 107-119, </pages> <year> 1989. </year>
Reference-contexts: In this section we are interested in deterministic algorithms. By Theorem 1 it follows that the competitive ratio of List Scheduling is 2 1 m . This is provably the best possible for m = 2 and m = 3 <ref> [31] </ref>, but for larger m it is possible to develop better algorithms. From the proof of Theorem 1 it is clear what is the main issue in designing algorithms better than List Scheduling. <p> The current state of our knowledge is summarized in Table 1. For comparison we include also the competitive ratio of List Scheduling. (See Section 4.2 for a discussion of results for randomized algorithms.) The observation that List Scheduling is optimal for m = 2; 3 is due to <ref> [31] </ref>. The other lower bounds for small m are due to [17]. The lower bound for large m is due to [1], improving upon [9]. Very recently R.
Reference: 32. <author> U. Faigle and W. M. Nawijn. </author> <title> Note on scheduling intervals online. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 58 </volume> <pages> 13-17, </pages> <year> 1995. </year>
Reference-contexts: For example, it is meaningless to measure the length of the schedule, as it is essentially fixed; instead we measure the weight (or the number) of accepted jobs. We do not cover this paradigm in this survey. It is studied for example in the papers <ref> [83, 62, 32] </ref>, and it is also related to load balancing [5]. 2.3 Objective functions The most common objective function is the makespan, which is the length of the schedule, or equivalently the time when the last job is completed.
Reference: 33. <author> A. Feldmann, M.-Y. Kao, J. Sgall, and S.-H. Teng. </author> <title> Optimal online scheduling of parallel jobs with dependencies. </title> <booktitle> In Proc. of the 25th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 642-651. </pages> <note> ACM, 1993. To appear in a special issue of J. of Combinatorial Optimization on scheduling. </note>
Reference-contexts: If we iterate this properly, we obtain a lower bound of m on the competitive ratio; a trivial algorithm which at each time schedules only one job achieves this <ref> [33] </ref>. This argument works also for randomized algorithms, and gives a lower bound of m=2 in this case [72]. Hence we turn our attention to ideally malleable jobs. <p> Hence we turn our attention to ideally malleable jobs. It turns out that the optimal competitive ratio for deterministic algorithms is 1 + 2:6180, and it is achieved by the following simple algorithm <ref> [33] </ref>. Algorithm Parallel (i) If an available job requests p machines and p machines are idle, schedule this job on p machines. (ii) If less than m= machines are busy and some job is available, schedule it on all available machines. <p> Note that this algorithm uses the fact that jobs are malleable only for large jobs. Accordingly, if there is an upper bound on the number of machines a job can use, we can get better algorithms and also algorithms for nonmalleable jobs. The tight tradeoffs are given in <ref> [33] </ref>. It is also interesting that this result improves on the best previously known offline algorithm, which only achieves an approximation ratio 3 [82]. 5.3 Parallel jobs on specific networks Here we consider a similar model as in the last section with an additional restriction. <p> Table 3 summarizes the results in this model. The results for deterministic batch-style algorithms are from [35], the results for deterministic algorithm with precedence constraints from <ref> [33] </ref>, and the results on randomized algorithms are from [72, 73]. 22 Network Batch-style With precedence constraints Deterministic Randomized Deterministic Randomized Hypercube 2 1 m 2 1 log log m ) O ( log m Linear array 2:5 2:5 fi ( log m log log m ) fi ( log m <p> For hypercubes there is no non-trivial lower bound, the claim of a tight bound for this case in <ref> [33] </ref> is incorrect. 5.4 Other objective functions In this section we consider the competitive ratio w.r.t. the total waiting time and completion time on identical machines. To minimize these objectives offline, we have to schedule first the jobs with small running times.
Reference: 34. <author> A. Feldmann, B. Maggs, J. Sgall, D. D. Sleator, and A. Tomkins. </author> <title> Competitive analysis of call admission algorithms that allow delay. </title> <type> Technical Report CMU-CS-95-102, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, U.S.A., </address> <year> 1995. </year>
Reference-contexts: The theorem now follows. ut The above reduction is completely satisfactory if we are interested only in the asymptotic behavior of the competitive ratio. However, if the competitive 19 ratio is a constant, we may be interested in a tighter result. In <ref> [34] </ref> it is proved that for a certain class of algorithms the competitive ratio is increased only by 1, instead of the factor of 2 in the previous theorem; this class of algorithms includes all algorithms that use a greedy approach similar to List Scheduling.
Reference: 35. <author> A. Feldmann, J. Sgall, and S.-H. Teng. </author> <title> Dynamic scheduling on parallel machines. </title> <journal> Theoretical Comput. Sci., </journal> <volume> 130(1) </volume> <pages> 49-72, </pages> <year> 1994. </year>
Reference-contexts: This leads to (2 1 m )-competitive algorithm, regardless of the rule by which we choose the job to be scheduled (note that here we have a meaningful choice, as we know how many machines each job requests) <ref> [35] </ref>. This is optimal by Theorem 5, as the basic model corresponds to the special case when each job requests only one machine. Moreover, this algorithm works even for non-malleable jobs. If we allow precedence constraints, no reasonable online algorithm exists for non-malleable parallel jobs. Consider the following situation. <p> Table 3 summarizes the results in this model. The results for deterministic batch-style algorithms are from <ref> [35] </ref>, the results for deterministic algorithm with precedence constraints from [33], and the results on randomized algorithms are from [72, 73]. 22 Network Batch-style With precedence constraints Deterministic Randomized Deterministic Randomized Hypercube 2 1 m 2 1 log log m ) O ( log m Linear array 2:5 2:5 fi (
Reference: 36. <author> A. Fiat and G. J. Woeginger. </author> <title> On-line scheduling on a single machine: Minimizing the total completion time. </title> <type> Technical Report Woe-04, </type> <institution> Department of Mathematics, TU Graz, Graz, Austria, </institution> <year> 1997. </year>
Reference-contexts: For a general p, the same approach leads also to an algorithm better than List Scheduling for large m. 4.8 Minimizing the total completion time <ref> [36] </ref> In this variant it is necessary to use idle times, as we have to finish the jobs with short running times first to minimize the total completion time.
Reference: 37. <author> G. Galambos and G. J. Woeginger. </author> <title> An on-line scheduling heuristic with better worst case ratio than Graham's list scheduling. </title> <journal> SIAM J. Comput., </journal> <volume> 22(2) </volume> <pages> 349-355, </pages> <year> 1993. </year>
Reference-contexts: Thus this method cannot give a better competitive ratio than List Scheduling. To design a good algorithm, we need to avoid both of these extremes. Current results use two different approaches. One is to schedule each job on one of the two currently least loaded machines <ref> [37, 17] </ref>. This gives better results than List Scheduling for any m 4, and achieves the currently best upper bounds for small m. However, for large m, the competitive ratio still approaches 2. <p> It always assigns the new job on one of the two least loaded machines, similarly to the deterministic algorithms for small m from <ref> [37, 17] </ref>. Consequently, its competitive ratio approaches two as m grows. The analysis of this algorithm is again difficult, even involving extensive computations to obtain the best results. The idea of the lower bound for two machines can be extended to arbitrary number of machines [16, 72, 74].
Reference: 38. <author> G. Galambos and G. J. Woeginger. </author> <title> Online bin packing a restricted survey. </title> <journal> ZOR Mathematical Methods of Operations Research, </journal> <volume> 42 </volume> <pages> 25-45, </pages> <year> 1995. </year>
Reference-contexts: The strip packing problem was also studied in the setting equivalent to our paradigm of scheduling jobs one by one as a variant of two-dimensional bin packing, see <ref> [38] </ref>. For scheduling with precedence constraints on two-dimensional meshes, both deterministic and randomized, there is a gap between the lower bound which follows from the lower bound for linear arrays and is (log m= log log m) and the upper bound which is the square of the lower bound.
Reference: 39. <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: a Guide to the Theory of NP-completeness. </title> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: When the theory of NP-completeness was developed, many scheduling problems have been shown to be NP-complete: Garey and Johnson <ref> [39] </ref> give 18 basic NP-complete scheduling problems; since then many new variants were considered and shown to be NP-complete. After the NP-completeness results, the focus shifted to designing approximation algorithms, often using quite nontrivial techniques and insights.
Reference: 40. <author> M. X. Goemans. </author> <title> Improved approximation algorithms for scheduling with release dates. </title> <booktitle> In Proc. of the 8th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 591-598. ACM-SIAM, </pages> <year> 1997. </year>
Reference-contexts: whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 [81].) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 [45]; later this was improved to 1 + p 2 2:414 by ff-point scheduling discussed below <ref> [40] </ref>. As in Theorem 6, it is possible to use an approximation algorithm instead of the infeasible optimal one and obtain accordingly larger competitive ratios. <p> the method of [64] is simply scheduling in the order of 1-points.) After using ff-point scheduling for off-line algorithms in [47], it was observed that choosing ff randomly, under a suitable distribution and starting from a suitable preemptive schedule that can be computed on-line, leads to new randomized on-line algorithms <ref> [15, 40] </ref>. These methods generally lead not only to c-competitive algorithms for non-preemptive scheduling, they in fact guarantee that the produced non-preemptive schedule is within the factor c of the optimal preemptive schedule. <p> In the case of a single machine ff-point scheduling leads to a randomized algorithm with competitive ratio w.r.t. the total completion time e=(e 1) 1:5819 [15]; this is also optimal [79, 81]. For the total weighted completion time ff-point scheduling gives a randomized 2-competitive algorithm for a single machine <ref> [40] </ref>. Recently, this has been improved to 1:6853-competitive algorithm, using a further modification that the ff is chosen randomly not once for the whole schedule but independently for each job [41]. Similar methods can be used also for other problems.
Reference: 41. <author> M. X. Goemans, M. Queyranne, A. S. Schulz, M. Skutella, and Y. Wang. </author> <type> Manuscript, </type> <year> 1997. </year>
Reference-contexts: For the total weighted completion time ff-point scheduling gives a randomized 2-competitive algorithm for a single machine [40]. Recently, this has been improved to 1:6853-competitive algorithm, using a further modification that the ff is chosen randomly not once for the whole schedule but independently for each job <ref> [41] </ref>. Similar methods can be used also for other problems. If preemption is allowed, a competitive ratio of 4=3 w.r.t. the total weighted completion time for a single machine can be achieved [67].
Reference: 42. <author> T. F. Gonzales and D. B. Johnson. </author> <title> A new algorithm for preemptive scheduling of trees. </title> <journal> J. ACM, </journal> <volume> 27 </volume> <pages> 287-312, </pages> <year> 1980. </year>
Reference-contexts: For the basic scheduling problems we can achieve even better results than using this reduction. The optimal, i.e., 1-competitive, online algorithms for preemptive scheduling on identical machines is given in <ref> [42, 48] </ref>. The idea of the algorithm is simple: whenever a new job arrives, we reschedule the unfinished parts of previous jobs and all unscheduled jobs so that they are finished as early as possible.
Reference: 43. <author> R. L. Graham. </author> <title> Bounds for certain multiprocessor anomalies. </title> <journal> Bell System Technical J., </journal> <volume> 45 </volume> <pages> 1563-1581, </pages> <month> Nov. </month> <year> 1966. </year>
Reference-contexts: Organization of the survey We define some of the variants of scheduling that have been studied in the online setting in Section 2. In Section 3 we discuss the early results on on-line scheduling, focusing on Graham's paper <ref> [43] </ref>. The three sections 4 to 6 survey the results divided according to the three different online paradigms described in Section 2.2. In Section 7 we discuss several papers which study various modification of competitive analysis in which the online algorithm is less restricted than in the standard situation. <p> Online scheduling in presence of delays in communication between processors is studied in [26, 27]. 3 General results and history The first proof of competitiveness of an on-line algorithm for a scheduling problem, and perhaps for any problem, was given by Graham already in 1966 <ref> [43] </ref>. He studied a simple deterministic greedy algorithm, now commonly called List Scheduling. The studied model is the basic one, where we have m identical machines and a sequence of sequential jobs characterized by their running times. The objective is to minimize the makespan. <p> This works only for the case with no precedence constraints, but we do not study precedence constraints in this paradigm (cf. Section 4). Theorem 1 <ref> [43, 46] </ref>. The competitive ratio of List Scheduling is 2 1 m . Proof. First we show that the competitive ratio of List Scheduling is not better than 2 1 m . <p> + 1. 18 Not only that, we even cannot prove that the competitive ratio increases if the number of machines for example doubles (this seems to be a more reasonable goal, as we could avoid some anomalies that occur when the increase of the number of machines is small, cf. <ref> [43] </ref>). The lack of our knowledge is demonstrated by the fact that we even cannot exclude that the maximal competitive ratio is actually attained for some m &lt; 1. The problems about behavior of the competitive ratio as a function of m are equally open for randomized scheduling.
Reference: 44. <author> R. L. Graham. </author> <title> Bounds on multiprocessor timing anomalies. </title> <journal> SIAM J. Appl. Math., </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <year> 1969. </year>
Reference-contexts: The case of reordering the list amounts to the competitiveness analysis given in Theorem 1, as the optimal schedule can be obtained by some particular ordering of the list. In the follow-up paper <ref> [44] </ref> Graham shows that the factor of 2 decreases if we modify the algorithm so that some number of long jobs is scheduled first using an optimal schedule, and the rest is scheduled by List Scheduling. Clearly, this algorithm is no longer on-line in any of the paradigms we study. <p> If we use List Scheduling on a sequence of jobs with non-increasing running times arriving one by one, the competitive ratio is 4=3 1=(3m), an improvement from 2 1=m <ref> [44] </ref>. For deterministic scheduling of jobs arriving one by one on two machines several such possibilities are considered in [57]. They show that the competitive ratio decreases from 3=2 to 4=3 in any of the following three scenarios. First, we know the total running 31 time of all jobs.
Reference: 45. <author> L. A. Hall, A. S. Schulz, D. B. Shmoys, and J. Wein. </author> <title> Scheduling to minimize average completion time: Off-line and online approximation algorithms. </title> <journal> Mathematics of Operations Research, </journal> <volume> 22 </volume> <pages> 513-544, </pages> <year> 1997. </year>
Reference-contexts: in the paradigm with unknown running times; in that case it is optimal even if preemptions are allowed [20]. 6.2 Minimizing the total weighted completion time For minimizing the total completion time, and even total weighted completion time, it is possible to give a similar general theorem as Theorem 6 <ref> [47, 45, 14] </ref>. More surprisingly, it is possible to design schedules that are close to optimal simultaneously for the total completion time and the makespan [14]. For technical reasons we assume that all running times are at least 1. The algorithm for this general reduction is the following. <p> Theorem 7 <ref> [47, 45, 14] </ref>. For any variant of online scheduling of jobs arriving over time, Greedy-Interval is 4-competitive w.r.t. the total weighted completion time and simultaneously 3-competitive w.r.t. the makespan. Proof. First we prove that Greedy-Interval is competitive w.r.t. the total weighted completion time. Fix an optimal schedule. <p> algorithms were given [64, 49, 78], moreover this is optimal [49, 78]. (An open question is whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 [81].) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 <ref> [45] </ref>; later this was improved to 1 + p 2 2:414 by ff-point scheduling discussed below [40]. As in Theorem 6, it is possible to use an approximation algorithm instead of the infeasible optimal one and obtain accordingly larger competitive ratios. <p> This gives competitive ratio 4 w.r.t. both the makespan and the total completion time, if is the approximation ratio of the algorithm we use. Number of results that follows from using such approximation algorithms is described in <ref> [47, 45, 14] </ref>; for example for minimizing the total weighted completion time on identical 28 machines there exists an (1 + ")-approximation polynomial time algorithm, and hence we obtain (4 + ")-competitive polynomial time algorithm [45]. A general randomization technique can be used to improve upon the deterministic algorithm Greedy-Interval. <p> Number of results that follows from using such approximation algorithms is described in [47, 45, 14]; for example for minimizing the total weighted completion time on identical 28 machines there exists an (1 + ")-approximation polynomial time algorithm, and hence we obtain (4 + ")-competitive polynomial time algorithm <ref> [45] </ref>. A general randomization technique can be used to improve upon the deterministic algorithm Greedy-Interval.
Reference: 46. <author> L. A. Hall and D. B. Shmoys. </author> <title> Approximation schemes for constrained scheduling problems. </title> <booktitle> In Proc. of the 30th Ann. IEEE Symp. on Foundations of Computer Sci., </booktitle> <pages> pages 134-139. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference-contexts: The objective is to minimize the makespan. The algorithm was designed for the case of precedence constraints, but it can be easily modified to handle also release times <ref> [46] </ref>. Preemption is not used. <p> This works only for the case with no precedence constraints, but we do not study precedence constraints in this paradigm (cf. Section 4). Theorem 1 <ref> [43, 46] </ref>. The competitive ratio of List Scheduling is 2 1 m . Proof. First we show that the competitive ratio of List Scheduling is not better than 2 1 m .
Reference: 47. <author> L. A. Hall, D. B. Shmoys, and J. Wein. </author> <title> Scheduling to minimize average completion time: Off-line and on-line algorithms. </title> <booktitle> In Proc. of the 7th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 142-151. ACM-SIAM, </pages> <year> 1996. </year> <month> 34 </month>
Reference-contexts: in the paradigm with unknown running times; in that case it is optimal even if preemptions are allowed [20]. 6.2 Minimizing the total weighted completion time For minimizing the total completion time, and even total weighted completion time, it is possible to give a similar general theorem as Theorem 6 <ref> [47, 45, 14] </ref>. More surprisingly, it is possible to design schedules that are close to optimal simultaneously for the total completion time and the makespan [14]. For technical reasons we assume that all running times are at least 1. The algorithm for this general reduction is the following. <p> Theorem 7 <ref> [47, 45, 14] </ref>. For any variant of online scheduling of jobs arriving over time, Greedy-Interval is 4-competitive w.r.t. the total weighted completion time and simultaneously 3-competitive w.r.t. the makespan. Proof. First we prove that Greedy-Interval is competitive w.r.t. the total weighted completion time. Fix an optimal schedule. <p> This gives competitive ratio 4 w.r.t. both the makespan and the total completion time, if is the approximation ratio of the algorithm we use. Number of results that follows from using such approximation algorithms is described in <ref> [47, 45, 14] </ref>; for example for minimizing the total weighted completion time on identical 28 machines there exists an (1 + ")-approximation polynomial time algorithm, and hence we obtain (4 + ")-competitive polynomial time algorithm [45]. A general randomization technique can be used to improve upon the deterministic algorithm Greedy-Interval. <p> Call an ff-point of a job the first time when ff fraction of this job is finished. Now schedule the jobs in the order of ff-points for some ff <ref> [47] </ref>. (Thus the method of [64] is simply scheduling in the order of 1-points.) After using ff-point scheduling for off-line algorithms in [47], it was observed that choosing ff randomly, under a suitable distribution and starting from a suitable preemptive schedule that can be computed on-line, leads to new randomized on-line <p> Now schedule the jobs in the order of ff-points for some ff <ref> [47] </ref>. (Thus the method of [64] is simply scheduling in the order of 1-points.) After using ff-point scheduling for off-line algorithms in [47], it was observed that choosing ff randomly, under a suitable distribution and starting from a suitable preemptive schedule that can be computed on-line, leads to new randomized on-line algorithms [15, 40].
Reference: 48. <author> K. S. Hong and J. Y.-T. Leung. </author> <title> On-line scheduling of real-time tasks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(10) </volume> <pages> 1326-1331, </pages> <year> 1992. </year>
Reference-contexts: In the case of preemptive scheduling of jobs arriving over time with known running times there exists an on-line algorithm which schedules all jobs before their common deadline if this is feasible; as soon as we allow two different deadlines no such on-line algorithm exists <ref> [48] </ref>. An often considered variant assumes that there are some precedence constraints between the jobs. They are generally given by a directed acyclic graph on the jobs; each directed edge indicates that one job has to be scheduled before another one. <p> For the basic scheduling problems we can achieve even better results than using this reduction. The optimal, i.e., 1-competitive, online algorithms for preemptive scheduling on identical machines is given in <ref> [42, 48] </ref>. The idea of the algorithm is simple: whenever a new job arrives, we reschedule the unfinished parts of previous jobs and all unscheduled jobs so that they are finished as early as possible.
Reference: 49. <author> J. A. Hoogeveen and A. P. A. Vestjens. </author> <title> Optimal on-line algorithms for single-machine scheduling. </title> <booktitle> In Proc. of the 5th Workshop on Algorithms and Data Structures, Lecture Notes in Comput. Sci. </booktitle> <volume> 1084, </volume> <pages> pages 404-414. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: The same rule yields a 2-competitive algorithm on identical machines [64]. In the case of single-machine non-preemptive scheduling it is also possible to get better bounds than in Theorem 7. For minimizing the total completion time 2-competitive algorithms were given <ref> [64, 49, 78] </ref>, moreover this is optimal [49, 78]. (An open question is whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 [81].) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 [45]; later this was <p> The same rule yields a 2-competitive algorithm on identical machines [64]. In the case of single-machine non-preemptive scheduling it is also possible to get better bounds than in Theorem 7. For minimizing the total completion time 2-competitive algorithms were given [64, 49, 78], moreover this is optimal <ref> [49, 78] </ref>. (An open question is whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 [81].) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 [45]; later this was improved to 1 + p 2 2:414
Reference: 50. <author> S. Irani and V. Leung. </author> <title> Scheduling with conflicts, and applications to traffic signal control. </title> <booktitle> In Proc. of the 7th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 85-94. ACM-SIAM, </pages> <year> 1996. </year>
Reference-contexts: We assume that we have infinitely many machines, which allows us to focus on the issue of conflicts, and also corresponds to some practical motivation, cf. <ref> [50] </ref>. <p> This bound follows directly from Theorem 4, even for arbitrary known running times, and it was rediscovered in [63], who also proved the matching lower bound. If we consider maximal flow time instead of the makespan, some partial results were obtained by <ref> [50] </ref>.
Reference: 51. <author> B. Kalyanasundaram and K. R. Pruhs. </author> <title> Fault-tolerant scheduling. </title> <booktitle> In Proc. of the 26th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 115-124. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in <ref> [51, 53] </ref>. Online scheduling in presence of delays in communication between processors is studied in [26, 27]. 3 General results and history The first proof of competitiveness of an on-line algorithm for a scheduling problem, and perhaps for any problem, was given by Graham already in 1966 [43].
Reference: 52. <author> B. Kalyanasundaram and K. R. Pruhs. </author> <title> Speed is as powerful as clairvoyance. </title> <booktitle> In Proc. of the 36th Ann. IEEE Symp. on Foundations of Computer Sci., </booktitle> <pages> pages 214-221. </pages> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: and possibly different for each job. 2.10 Variants not covered in this survey A very different model of online scheduling in real-time systems, where each job has its deadline and value and the goal is to maximize the value of jobs finished before their deadline, is considered in several papers <ref> [28, 11, 52, 65] </ref>. Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in [51, 53]. <p> can sometimes overcome these problems and obtain reasonable algorithms. 7.1 Algorithms with more computational power If we allow the on-line algorithm to use machines with speed 1 + ", there exists a (1 + 1=")-competitive algorithm for minimizing total flow time with preemptions and unknown running times on one machine <ref> [52] </ref>; in contrast without the additional power we have seen that the competitive ratio has to depend on the number of jobs.
Reference: 53. <author> B. Kalyanasundaram and K. R. Pruhs. </author> <title> Fault-tolerant real-time scheduling. </title> <booktitle> In Proc. of the 5th Ann. European Symp. on Algorithms, Lecture Notes in Comput. Sci. </booktitle> <volume> 1284, </volume> <pages> pages 296-307. </pages> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in <ref> [51, 53] </ref>. Online scheduling in presence of delays in communication between processors is studied in [26, 27]. 3 General results and history The first proof of competitiveness of an on-line algorithm for a scheduling problem, and perhaps for any problem, was given by Graham already in 1966 [43].
Reference: 54. <author> D. Karger, C. Stein, and J. Wein. </author> <title> Scheduling algorithms. </title> <note> To appear in Handbook of Algorithms and Theory of Computation, </note> <editor> M. J. Atallah, editor. </editor> <publisher> CRC Press, </publisher> <year> 1997. </year>
Reference-contexts: After the NP-completeness results, the focus shifted to designing approximation algorithms, often using quite nontrivial techniques and insights. There is extensive literature on these subjects, for a recent surveys see e.g. <ref> [59, 54] </ref>. Many natural heuristics for scheduling are in fact online algorithms. Hence when the study of on-line algorithms using competitive analysis became usual, this approach was naturally and quite successfully applied to scheduling.
Reference: 55. <author> D. R. Karger, S. J. Phillips, and E. Torng. </author> <title> A better algorithm for an ancient scheduling problem. </title> <journal> J. of Algorithms, </journal> <volume> 20 </volume> <pages> 400-430, </pages> <year> 1996. </year>
Reference-contexts: To keep the competitive ratio bounded away from 2 even for large m it is necessary to keep some constant fraction of machines lightly loaded. Such an algorithm was first developed in [8], later better algorithms based on this idea were designed in <ref> [55, 1] </ref> to give the currently best upper bounds for large m. The analysis of all these algorithms is relatively complicated. The current state of our knowledge is summarized in Table 1.
Reference: 56. <author> H. Keller, T. Tautenhahn, and G. J. Woeginger. </author> <title> Approximability and nonaprox-imability results for minimizing total flow time on a single machine. </title> <booktitle> In Proc. of the 28th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 418-426. </pages> <note> ACM, 1996. To appear in SIAM J. Comput. </note>
Reference: 57. <author> H. Kellerer, V. Kotov, M. G. Speranza, and Z. Tuza. </author> <title> Semi online algorithms for the partition problem. </title> <note> To appear in Oper. </note> <institution> Res. Lett., </institution> <year> 1996. </year>
Reference-contexts: If we use List Scheduling on a sequence of jobs with non-increasing running times arriving one by one, the competitive ratio is 4=3 1=(3m), an improvement from 2 1=m [44]. For deterministic scheduling of jobs arriving one by one on two machines several such possibilities are considered in <ref> [57] </ref>. They show that the competitive ratio decreases from 3=2 to 4=3 in any of the following three scenarios. First, we know the total running 31 time of all jobs.
Reference: 58. <author> J. Labetoulle, E. L. Lawler, J. K. Lenstra, and A. H. G. Rinnooy Kan. </author> <title> Preemptive scheduling of uniform machines subject to release dates. </title> <editor> In W. R. Pulleyblank, editor, </editor> <booktitle> Progress in Combinatorial Optimization, </booktitle> <pages> pages 245-261. </pages> <publisher> Academic Press, </publisher> <year> 1984. </year>
Reference-contexts: All these algorithms use fi (mn) preemptions, and this is actually necessary [80, 81]. For uniformly related machines with arbitrary speeds there exist optimal algorithms that are nearly on-line <ref> [66, 58] </ref>. This means that at each time we know when the next job will be released, in addition to the running times of already released jobs.
Reference: 59. <author> E. L. Lawler, J. K. Lenstra, A. H. G. Rinnooy Kan, and D. B. Shmoys. </author> <title> Sequencing and scheduling: Algorithms and complexity. </title> <editor> In S. C. Graves, A. H. G. Rin-nooy Kan, and P. Zipkin, editors, </editor> <booktitle> Handbooks in Operations Research and Management Science, </booktitle> <volume> Vol. 4: </volume> <booktitle> Logistics of Production and Inventory, </booktitle> <pages> pages 445-552. </pages> <publisher> North-Holland, </publisher> <year> 1993. </year>
Reference-contexts: After the NP-completeness results, the focus shifted to designing approximation algorithms, often using quite nontrivial techniques and insights. There is extensive literature on these subjects, for a recent surveys see e.g. <ref> [59, 54] </ref>. Many natural heuristics for scheduling are in fact online algorithms. Hence when the study of on-line algorithms using competitive analysis became usual, this approach was naturally and quite successfully applied to scheduling.
Reference: 60. <author> S. Leonardi and A. Marchetti-Spaccamela. </author> <title> On-line resource management with application to routing and scheduling. </title> <booktitle> In Proc. of the 22th International Colloquium on Automata, Languages, and Programming, Lecture Notes in Comput. Sci. </booktitle> <volume> 944, </volume> <pages> pages 303-314. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> To appear in Algorithmica. </note>
Reference-contexts: For the restricted assignment the optimal competitive ratio is fi (log m) both for deterministic and randomized algorithms [6]. For unrelated machines with no restriction it is also possible to obtain O (log m)-competitive deterministic algorithm <ref> [2, 60] </ref>. By the previous lower bound this is optimal, too. It is interesting that both for related and unrelated machines the optimal algorithms are asymptotically better than List Scheduling.
Reference: 61. <author> S. Leonardi and D. Raz. </author> <title> Approximating total flow time with preemption. </title> <booktitle> In Proc. of the 29th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 110-119. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: Note that also the off-line problem is hard, it is NP-hard to achieve an approximation ratio n 1 With preemptions the optimal competitive ratio still depends on the number of jobs; it is fi (log (n=m)) <ref> [61] </ref>. Only in the case when the ratio between the maximum and the minimum running time is bounded by P , we can obtain a bound independent of n, namely fi (log P ); this is again tight [61]. 6.4 Conflicting jobs The last variant we consider in this section is <p> still depends on the number of jobs; it is fi (log (n=m)) <ref> [61] </ref>. Only in the case when the ratio between the maximum and the minimum running time is bounded by P , we can obtain a bound independent of n, namely fi (log P ); this is again tight [61]. 6.4 Conflicting jobs The last variant we consider in this section is very different than all the ones considered before. Here some jobs may conflict with each other, in which case we cannot schedule them at the same time.
Reference: 62. <author> R. J. Lipton and A. Tomkins. </author> <title> Online interval scheduling. </title> <booktitle> In Proc. of the 5th Ann. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 302-305. ACM-SIAM, </pages> <year> 1994. </year>
Reference-contexts: For example, it is meaningless to measure the length of the schedule, as it is essentially fixed; instead we measure the weight (or the number) of accepted jobs. We do not cover this paradigm in this survey. It is studied for example in the papers <ref> [83, 62, 32] </ref>, and it is also related to load balancing [5]. 2.3 Objective functions The most common objective function is the makespan, which is the length of the schedule, or equivalently the time when the last job is completed.
Reference: 63. <author> R. Motwani, S. Phillips, and E. Torng. </author> <title> Non-clairvoyant scheduling. </title> <journal> Theoretical Comput. Sci., </journal> <volume> 130 </volume> <pages> 17-47, </pages> <year> 1994. </year>
Reference-contexts: In turns out that the optimal competitive ratio is obtained by the simple Round Robin algorithm. It cycles through all unfinished jobs and assigns to each of them to one of the machines and time slot of length t fixed beforehand. This algorithm has competitive ratio 2 <ref> [63] </ref> even w.r.t. the total waiting time. (More precisely, if t approaches zero, the competitive ratio approaches 2 from above.) This is optimal even for randomized algorithms, and even if we consider the total completion time instead of waiting time [63]. <p> This algorithm has competitive ratio 2 <ref> [63] </ref> even w.r.t. the total waiting time. (More precisely, if t approaches zero, the competitive ratio approaches 2 from above.) This is optimal even for randomized algorithms, and even if we consider the total completion time instead of waiting time [63]. It is somewhat unsatisfactory that in the previous algorithm the number of preemption is fi (t) for a job with running time t. <p> Then the competitive ratio is the same, approaching 2 from above for small starting t and a small step of the geometric sequence, and the number of preemption decreases to fi (log t) <ref> [63] </ref>. This is optimal for deterministic algorithms, as any algorithm with o (log t) preemptions has competitive ratio at least (n) [63]. Interestingly, the results for batch-style scheduling can be generalized to parallel jobs. <p> is the same, approaching 2 from above for small starting t and a small step of the geometric sequence, and the number of preemption decreases to fi (log t) <ref> [63] </ref>. This is optimal for deterministic algorithms, as any algorithm with o (log t) preemptions has competitive ratio at least (n) [63]. Interestingly, the results for batch-style scheduling can be generalized to parallel jobs. Here we consider only total completion time (note that waiting time is not well defined for malleable parallel jobs). <p> For algorithms with release times, we know that there are no good on-line algorithms w.r.t. total flow time even for sequential jobs. The competitive ratio is at least (n 1=3 ) for deterministic algorithms and (log n) for randomized algorithms <ref> [63] </ref>. 25 5.5 Open problems This on-line paradigm seems to be understood relatively well, including such issues like randomization. Perhaps the most interesting problem concerns the general reduction in Theorem 4. <p> At any time we find the coloring of the available jobs by the smallest number of colors and schedule one of these colors. This bound follows directly from Theorem 4, even for arbitrary known running times, and it was rediscovered in <ref> [63] </ref>, who also proved the matching lower bound. If we consider maximal flow time instead of the makespan, some partial results were obtained by [50].
Reference: 64. <author> C. Philips, C. Stein, and J. Wein. </author> <title> Minimizing average completion time in the presence of release dates. </title> <booktitle> In Proc. of the 4th Workshop on Algorithms and Data Structures, Lecture Notes in Comput. Sci. </booktitle> <volume> 955, </volume> <pages> pages 86-97. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> To appear in Math. Programming. 35 </note>
Reference-contexts: The same rule yields a 2-competitive algorithm on identical machines <ref> [64] </ref>. In the case of single-machine non-preemptive scheduling it is also possible to get better bounds than in Theorem 7. <p> The same rule yields a 2-competitive algorithm on identical machines [64]. In the case of single-machine non-preemptive scheduling it is also possible to get better bounds than in Theorem 7. For minimizing the total completion time 2-competitive algorithms were given <ref> [64, 49, 78] </ref>, moreover this is optimal [49, 78]. (An open question is whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 [81].) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 [45]; later this was <p> and within a factor of 3 of the optimal makespan.) One method to obtain deterministic 2-competitive algorithms w.r.t. the total completion time is to take the optimal preemptive schedule (which is easy to compute even online) and schedule the jobs in the order of their completion in this auxiliary schedule <ref> [64] </ref>. This idea led to a generalization which turned to be very useful for off-line approximation algorithms and also for randomized on-line scheduling. Call an ff-point of a job the first time when ff fraction of this job is finished. <p> Call an ff-point of a job the first time when ff fraction of this job is finished. Now schedule the jobs in the order of ff-points for some ff [47]. (Thus the method of <ref> [64] </ref> is simply scheduling in the order of 1-points.) After using ff-point scheduling for off-line algorithms in [47], it was observed that choosing ff randomly, under a suitable distribution and starting from a suitable preemptive schedule that can be computed on-line, leads to new randomized on-line algorithms [15, 40].
Reference: 65. <author> C. A. Phillips, C. Stein, E. Torng, and J. Wein. </author> <title> Optimal time-critical scheduling via resource augmentation. </title> <booktitle> In Proc. of the 29th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 140-149. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: and possibly different for each job. 2.10 Variants not covered in this survey A very different model of online scheduling in real-time systems, where each job has its deadline and value and the goal is to maximize the value of jobs finished before their deadline, is considered in several papers <ref> [28, 11, 52, 65] </ref>. Other papers study models with additional obstacles. On-line scheduling in the presence of processor faults is studied in [51, 53]. <p> For scheduling of jobs arriving over time with known running times several results of this kind are obtained by <ref> [65] </ref>; they either use O (log n) machines instead of one in the non-preemptive one-machine version or increase the speed of the machines by a factor of two in the preemptive m-machine version, and in both cases they obtain the optimal sum of flow times.
Reference: 66. <author> S. Sahni and Y. Cho. </author> <title> Nearly on line scheduling of a uniform processor system with release times. </title> <journal> SIAM J. Comput., </journal> <volume> 8(2) </volume> <pages> 275-285, </pages> <year> 1979. </year>
Reference-contexts: Clearly, this algorithm is no longer on-line in any of the paradigms we study. Other two early papers that contain results about on-line scheduling algorithms are <ref> [66, 23] </ref>. The first one gives an optimal algorithm for minimizing the makespan of a preemptive schedule on identical machines where jobs arrive over time, and mentions that the algorithm is on-line. <p> All these algorithms use fi (mn) preemptions, and this is actually necessary [80, 81]. For uniformly related machines with arbitrary speeds there exist optimal algorithms that are nearly on-line <ref> [66, 58] </ref>. This means that at each time we know when the next job will be released, in addition to the running times of already released jobs.
Reference: 67. <author> A. S. Schulz and M. Skutella. </author> <title> Scheduling-LPs bear probabilities: Randomized approximations for min-sum criteria. </title> <type> Technical Report 533/1996, </type> <institution> Department of Mathematics, Technical University of Berlin, </institution> <address> Berlin, Germany, </address> <year> 1996 </year> <month> (revised </month> <year> 1997). </year>
Reference-contexts: Similar methods can be used also for other problems. If preemption is allowed, a competitive ratio of 4=3 w.r.t. the total weighted completion time for a single machine can be achieved <ref> [67] </ref>. On parallel identical machines without preemptions a randomized algorithm 2-competitive w.r.t. the total weighted completion time was given in [68]. 6.3 Minimizing the total flow time Minimizing the total flow time is much harder than to minimize the total completion time also with known running times.
Reference: 68. <author> A. S. Schulz and M. Skutella. </author> <title> Scheduling-LPs bear probabilities. </title> <booktitle> In Proc. of the 5th Ann. European Symp. on Algorithms, Lecture Notes in Comput. Sci. </booktitle> <volume> 1284, </volume> <pages> pages 416-429. </pages> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: If preemption is allowed, a competitive ratio of 4=3 w.r.t. the total weighted completion time for a single machine can be achieved [67]. On parallel identical machines without preemptions a randomized algorithm 2-competitive w.r.t. the total weighted completion time was given in <ref> [68] </ref>. 6.3 Minimizing the total flow time Minimizing the total flow time is much harder than to minimize the total completion time also with known running times. Without preemption we have strong lower bound even for a single machine.
Reference: 69. <author> S. S. Seiden. </author> <title> More multiprocessor scheduling with rejection. </title> <type> Manuscript, </type> <year> 1997. </year>
Reference-contexts: The lower bounds for small m from [10] work also for preemptive deterministic algorithms, but for large m yield only a lower bound of 2. An improved algorithm for deterministic preemptive scheduling was designed in <ref> [69] </ref>. It achieves competitive ratio 2:3875 for all m. The scheme for rejecting jobs is similar as in the previous case, but the optimal algorithm for preemptive scheduling is used instead of List Scheduling. <p> An interesting question is whether a better than 2-competitive algorithm can be found for m = 3: we now know several different 2-competitive algorithms even without preemption, but the lower bound does not match this barrier. Randomized algorithms for this problem were designed in <ref> [70, 69] </ref>. The general idea is to use modifications of the deterministic algorithms where the thresholds for rejection are parameterized, and certain random choice of these parameters is made. In the non-preemptive case the competitive ratios are 1:5, 1:8358, and 2:0545 for m = 2; 3, and 4.
Reference: 70. <author> S. S. Seiden. </author> <title> Randomization in Online Computation. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> Irvine, CA, U.S.A., </address> <year> 1997. </year>
Reference-contexts: However, this does not change the conclusion.) ut Very recently new randomized algorithms for small m were developed in <ref> [71, 70] </ref>. It is provably better than any deterministic algorithm for m = 3; 4; 5 and better than the currently best deterministic algorithm for m = 6; 7. <p> An interesting question is whether a better than 2-competitive algorithm can be found for m = 3: we now know several different 2-competitive algorithms even without preemption, but the lower bound does not match this barrier. Randomized algorithms for this problem were designed in <ref> [70, 69] </ref>. The general idea is to use modifications of the deterministic algorithms where the thresholds for rejection are parameterized, and certain random choice of these parameters is made. In the non-preemptive case the competitive ratios are 1:5, 1:8358, and 2:0545 for m = 2; 3, and 4.
Reference: 71. <author> S. S. Seiden. </author> <title> A randomized algorithm for that ancient scheduling problem. </title> <booktitle> In Proc. of the 5th Workshop on Algorithms and Data Structures, Lecture Notes in Comput. Sci. </booktitle> <volume> 1272, </volume> <pages> pages 210-223. </pages> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: However, this does not change the conclusion.) ut Very recently new randomized algorithms for small m were developed in <ref> [71, 70] </ref>. It is provably better than any deterministic algorithm for m = 3; 4; 5 and better than the currently best deterministic algorithm for m = 6; 7. <p> For any m &gt; 2 it is an open question whether there exists an algorithm matching this lower bound. (Seiden <ref> [71] </ref> demonstrated that his algorithm does not match this bound.) The insight from the proof of the lower bound leads to a natural invariant that should be preserved by any algorithm matching it. Namely, such an algorithm should preserve the ratio of expected loads described above.
Reference: 72. <author> J. Sgall. </author> <title> OnLine Scheduling on Parallel Machines. </title> <type> PhD thesis, Technical Report CMU-CS-94-144, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, U.S.A., </address> <year> 1994. </year>
Reference-contexts: Consequently, its competitive ratio approaches two as m grows. The analysis of this algorithm is again difficult, even involving extensive computations to obtain the best results. The idea of the lower bound for two machines can be extended to arbitrary number of machines <ref> [16, 72, 74] </ref>. <p> If we iterate this properly, we obtain a lower bound of m on the competitive ratio; a trivial algorithm which at each time schedules only one job achieves this [33]. This argument works also for randomized algorithms, and gives a lower bound of m=2 in this case <ref> [72] </ref>. Hence we turn our attention to ideally malleable jobs. It turns out that the optimal competitive ratio for deterministic algorithms is 1 + 2:6180, and it is achieved by the following simple algorithm [33]. <p> Table 3 summarizes the results in this model. The results for deterministic batch-style algorithms are from [35], the results for deterministic algorithm with precedence constraints from [33], and the results on randomized algorithms are from <ref> [72, 73] </ref>. 22 Network Batch-style With precedence constraints Deterministic Randomized Deterministic Randomized Hypercube 2 1 m 2 1 log log m ) O ( log m Linear array 2:5 2:5 fi ( log m log log m ) fi ( log m Two-dimensional mesh O ( p log log m )
Reference: 73. <author> J. Sgall. </author> <title> Randomized online scheduling of parallel jobs. </title> <journal> J. of Algorithms, </journal> <volume> 21 </volume> <pages> 149-175, </pages> <year> 1996. </year>
Reference-contexts: Table 3 summarizes the results in this model. The results for deterministic batch-style algorithms are from [35], the results for deterministic algorithm with precedence constraints from [33], and the results on randomized algorithms are from <ref> [72, 73] </ref>. 22 Network Batch-style With precedence constraints Deterministic Randomized Deterministic Randomized Hypercube 2 1 m 2 1 log log m ) O ( log m Linear array 2:5 2:5 fi ( log m log log m ) fi ( log m Two-dimensional mesh O ( p log log m )
Reference: 74. <author> J. Sgall. </author> <title> A lower bound for randomized online multiprocessor scheduling. </title> <journal> Inf. Process. Lett., </journal> <volume> 63(1) </volume> <pages> 51-55, </pages> <year> 1997. </year>
Reference-contexts: Consequently, its competitive ratio approaches two as m grows. The analysis of this algorithm is again difficult, even involving extensive computations to obtain the best results. The idea of the lower bound for two machines can be extended to arbitrary number of machines <ref> [16, 72, 74] </ref>. <p> For three machines this is no longer true, and hence the structure of the problem is much more difficult. Second, it is not clear whether we would be able to preserve the invariant ratio of expected loads even if all jobs are small. In <ref> [74] </ref> it is demonstrated that even for m = 3 it is impossible to preserve this invariant inductively, meaning that there exists a probability distribution on the configurations such that the expected loads have the desired ratio, but after the next job this ratio cannot be maintained; moreover this configuration is
Reference: 75. <author> D. B. Shmoys, J. Wein, and D. P. Williamson. </author> <title> Scheduling parallel machines online. </title> <journal> SIAM J. Comput., </journal> <volume> 24 </volume> <pages> 1313-1331, </pages> <year> 1995. </year>
Reference-contexts: the performance ratio of any on-line algorithm for some scheduling problem, namely the bound 8 of ( n) for non-preemptive scheduling jobs with unknown running times on uniformly related machines; the paper even mentions the possible usefulness of restarts, which later indeed proved to be quite useful in this case <ref> [75] </ref>. Around 1990 new results were discovered concerning many variants of online scheduling, both old and new. Most of the results use the makespan as the objective function, consequently our understanding of this measure is most complete. <p> The next general reduction theorem explains why the batch-style algorithms are so important. Theorem 4 <ref> [75] </ref>. Suppose that we have a batch-style -competitive algorithm (w.r.t. the makespan). Then there exists a 2-competitive algorithm which allows release times. Proof. Consider an online algorithm that works in phases as follows. <p> This competitive ratio is tight for deterministic algorithms and almost tight for randomized algorithms, even restricted to the batch-style model. Theorem 5 <ref> [75] </ref>. For batch-style scheduling with unknown running times, no deterministic algorithm is better than (2 1 m )-competitive and no randomized algorithm is better than (2 O ( 1 p m ))-competitive. Proof. In the deterministic case we use the same instance as in Theorem 1. <p> A matching, O ( p m)-competitive, algorithm is known even for unrelated machines [23]. Next we consider the case when restarts are allowed, studied in <ref> [75] </ref>. <p> Thus from Theorem 4 we get the following result. Theorem 6 <ref> [75] </ref>. For any variant of online scheduling of jobs arriving over time (with all characteristics known), there exists a 2-competitive algorithm w.r.t. the makespan. As most of the scheduling variants are NP-hard, algorithms obtained by the previous theorem may not be computationally feasible.
Reference: 76. <author> D. D. Sleator. </author> <title> A 2.5 times optimal algorithm for packing in two dimensions. </title> <journal> Inf. Process. Lett., </journal> <volume> 10 </volume> <pages> 37-40, </pages> <year> 1980. </year>
Reference-contexts: For a long time the best algorithm for this off-line problem gave approximation ratio 2:5 <ref> [76] </ref>, which was matched by the on-line algorithm mentioned in the table. Later, the off-line solution was improved to approximation ratio 2 [77], and it would be interesting to see if this can be achieved by an on-line algorithm, too.
Reference: 77. <author> A. Steinberg. </author> <title> A strip-packing algorithm with absolute performance bound 2. </title> <journal> SIAM J. Comput., </journal> <volume> 26(2) </volume> <pages> 401-409, </pages> <year> 1997. </year>
Reference-contexts: For a long time the best algorithm for this off-line problem gave approximation ratio 2:5 [76], which was matched by the on-line algorithm mentioned in the table. Later, the off-line solution was improved to approximation ratio 2 <ref> [77] </ref>, and it would be interesting to see if this can be achieved by an on-line algorithm, too. The strip packing problem was also studied in the setting equivalent to our paradigm of scheduling jobs one by one as a variant of two-dimensional bin packing, see [38].
Reference: 78. <author> L. Stougie. </author> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: The same rule yields a 2-competitive algorithm on identical machines [64]. In the case of single-machine non-preemptive scheduling it is also possible to get better bounds than in Theorem 7. For minimizing the total completion time 2-competitive algorithms were given <ref> [64, 49, 78] </ref>, moreover this is optimal [49, 78]. (An open question is whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 [81].) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 [45]; later this was <p> The same rule yields a 2-competitive algorithm on identical machines [64]. In the case of single-machine non-preemptive scheduling it is also possible to get better bounds than in Theorem 7. For minimizing the total completion time 2-competitive algorithms were given [64, 49, 78], moreover this is optimal <ref> [49, 78] </ref>. (An open question is whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 [81].) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 [45]; later this was improved to 1 + p 2 2:414
Reference: 79. <author> L. Stougie and A. P. A. Vestjens. </author> <title> Randomized online scheduling: How low can't you go? Manuscript, </title> <year> 1997. </year>
Reference-contexts: In the case of a single machine ff-point scheduling leads to a randomized algorithm with competitive ratio w.r.t. the total completion time e=(e 1) 1:5819 [15]; this is also optimal <ref> [79, 81] </ref>. For the total weighted completion time ff-point scheduling gives a randomized 2-competitive algorithm for a single machine [40]. Recently, this has been improved to 1:6853-competitive algorithm, using a further modification that the ff is chosen randomly not once for the whole schedule but independently for each job [41]. <p> Even if the al-gorithm is randomized, no algorithm is better than ( p n) competitive <ref> [79, 81] </ref>, and if a deterministic algorithm is allowed to restart jobs, the lower bound is ( 4 p n) [81].
Reference: 80. <author> A. P. A. Vestjens. </author> <title> Scheduling uniform machines on-line requires nondecreasing speed ratios. </title> <type> Technical Report Memorandum COSOR 94-35, </type> <institution> Eindhoven University of Technology, </institution> <year> 1994. </year> <note> To appear in Math. Programming. </note>
Reference-contexts: For uniformly related machines with different speeds an optimal online algorithm exists if and only if the speeds satisfy s i1 =s i s i =s i+1 , where 26 s i is the speed of ith fastest machine <ref> [80, 81] </ref>. All these algorithms use fi (mn) preemptions, and this is actually necessary [80, 81]. For uniformly related machines with arbitrary speeds there exist optimal algorithms that are nearly on-line [66, 58]. <p> machines with different speeds an optimal online algorithm exists if and only if the speeds satisfy s i1 =s i s i =s i+1 , where 26 s i is the speed of ith fastest machine <ref> [80, 81] </ref>. All these algorithms use fi (mn) preemptions, and this is actually necessary [80, 81]. For uniformly related machines with arbitrary speeds there exist optimal algorithms that are nearly on-line [66, 58]. This means that at each time we know when the next job will be released, in addition to the running times of already released jobs. <p> Note that this online algorithm is 1-competitive if we allow an additive term in the definition of competitiveness, but it is not optimal and not 1-competitive if we allow no additive term. Thus, using the results of <ref> [80, 81] </ref>, for uniformly related machines with certain speed ratios we have a curious situation where (1 + ")-competitive algorithms do exist for any " &gt; 0, but no optimal online algorithm exists.
Reference: 81. <author> A. P. A. Vestjens. </author> <title> On-line Machine Scheduling. </title> <type> PhD thesis, </type> <institution> Eindhoven University of Technology, </institution> <address> The Netherlands, </address> <year> 1997. </year>
Reference-contexts: For uniformly related machines with different speeds an optimal online algorithm exists if and only if the speeds satisfy s i1 =s i s i =s i+1 , where 26 s i is the speed of ith fastest machine <ref> [80, 81] </ref>. All these algorithms use fi (mn) preemptions, and this is actually necessary [80, 81]. For uniformly related machines with arbitrary speeds there exist optimal algorithms that are nearly on-line [66, 58]. <p> machines with different speeds an optimal online algorithm exists if and only if the speeds satisfy s i1 =s i s i =s i+1 , where 26 s i is the speed of ith fastest machine <ref> [80, 81] </ref>. All these algorithms use fi (mn) preemptions, and this is actually necessary [80, 81]. For uniformly related machines with arbitrary speeds there exist optimal algorithms that are nearly on-line [66, 58]. This means that at each time we know when the next job will be released, in addition to the running times of already released jobs. <p> Note that this online algorithm is 1-competitive if we allow an additive term in the definition of competitiveness, but it is not optimal and not 1-competitive if we allow no additive term. Thus, using the results of <ref> [80, 81] </ref>, for uniformly related machines with certain speed ratios we have a curious situation where (1 + ")-competitive algorithms do exist for any " &gt; 0, but no optimal online algorithm exists. <p> If we consider scheduling without preemptions, we no longer can get a 1-competitive algorithm, even for identical machines. The best upper bound was obtained for the simple algorithm which always schedules the available job with the longest running time; this algorithm is 1:5-competitive <ref> [19, 81] </ref>. A lower bound of 1:3473 shows that this is close to the best possible [19, 81]. For open shop scheduling on two machines the greedy algorithm achieves the competitive ratio of 3=2; this is optimal for scheduling without preemptions [20]. <p> The best upper bound was obtained for the simple algorithm which always schedules the available job with the longest running time; this algorithm is 1:5-competitive <ref> [19, 81] </ref>. A lower bound of 1:3473 shows that this is close to the best possible [19, 81]. For open shop scheduling on two machines the greedy algorithm achieves the competitive ratio of 3=2; this is optimal for scheduling without preemptions [20]. With preemption, a 5=4 competitive algorithm exists and this is optimal [20]. <p> For minimizing the total completion time 2-competitive algorithms were given [64, 49, 78], moreover this is optimal [49, 78]. (An open question is whether it helps if we allow restarts, a lower bound for deterministic algorithms is 1:112 <ref> [81] </ref>.) For minimizing the total weighted completion time a slight modification of Greedy-Interval yields a competitive ratio of 3 [45]; later this was improved to 1 + p 2 2:414 by ff-point scheduling discussed below [40]. <p> In the case of a single machine ff-point scheduling leads to a randomized algorithm with competitive ratio w.r.t. the total completion time e=(e 1) 1:5819 [15]; this is also optimal <ref> [79, 81] </ref>. For the total weighted completion time ff-point scheduling gives a randomized 2-competitive algorithm for a single machine [40]. Recently, this has been improved to 1:6853-competitive algorithm, using a further modification that the ff is chosen randomly not once for the whole schedule but independently for each job [41]. <p> Even if the al-gorithm is randomized, no algorithm is better than ( p n) competitive <ref> [79, 81] </ref>, and if a deterministic algorithm is allowed to restart jobs, the lower bound is ( 4 p n) [81]. <p> Even if the al-gorithm is randomized, no algorithm is better than ( p n) competitive [79, 81], and if a deterministic algorithm is allowed to restart jobs, the lower bound is ( 4 p n) <ref> [81] </ref>. Note that also the off-line problem is hard, it is NP-hard to achieve an approximation ratio n 1 With preemptions the optimal competitive ratio still depends on the number of jobs; it is fi (log (n=m)) [61].
Reference: 82. <author> Q. Wang and K. H. Cheng. </author> <title> A heuristic of scheduling parallel tasks and its analysis. </title> <journal> SIAM J. Comput., </journal> <volume> 21(2) </volume> <pages> 281-294, </pages> <year> 1992. </year>
Reference-contexts: The tight tradeoffs are given in [33]. It is also interesting that this result improves on the best previously known offline algorithm, which only achieves an approximation ratio 3 <ref> [82] </ref>. 5.3 Parallel jobs on specific networks Here we consider a similar model as in the last section with an additional restriction. We require that each parallel job is scheduled on some subset of machines with a specific structure, not an arbitrary subset as before.
Reference: 83. <author> G. J. Woeginger. </author> <title> On-line scheduling of jobs with fixed start and end times. </title> <journal> Theoretical Comput. Sci., </journal> <volume> 130 </volume> <pages> 5-16, </pages> <year> 1994. </year> <title> This article was processed using the L a T E X macro package with LLNCS style 36 </title>
Reference-contexts: For example, it is meaningless to measure the length of the schedule, as it is essentially fixed; instead we measure the weight (or the number) of accepted jobs. We do not cover this paradigm in this survey. It is studied for example in the papers <ref> [83, 62, 32] </ref>, and it is also related to load balancing [5]. 2.3 Objective functions The most common objective function is the makespan, which is the length of the schedule, or equivalently the time when the last job is completed.
References-found: 83

