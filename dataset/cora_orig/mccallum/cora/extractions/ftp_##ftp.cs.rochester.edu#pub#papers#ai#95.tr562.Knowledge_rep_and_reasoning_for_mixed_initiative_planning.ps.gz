URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/95.tr562.Knowledge_rep_and_reasoning_for_mixed_initiative_planning.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/ferguson/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Knowledge Representation and Reasoning for Mixed-Initiative Planning  
Author: by George Montague Ferguson 
Degree: Submitted in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy Supervised by Professor James F. Allen Department of Computer Science The College Arts and Sciences  
Date: 1995  
Address: Rochester, New York  
Affiliation: University of Rochester  
Abstract-found: 0
Intro-found: 1
Reference: [Allen, 1979] <author> James F. Allen, </author> <title> A plan-based approach to speech act recognition, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto, Toronto, Ont., </institution> <year> 1979. </year>
Reference: [Allen, 1983a] <author> James F. Allen, </author> <title> "Maintaining knowledge about temporal intervals," </title> <journal> Communications of the ACM, </journal> <volume> 26(11) </volume> <pages> 832-843, </pages> <year> 1983. </year> <note> Also in Readings in Knowledge Representation, R.J. </note> <editor> Brachman and H.J. Levesque (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1985, </year> <pages> pp. 509-522. </pages>
Reference-contexts: We write this as "i ./ j" and define it by i ./ j i : j _ j : i: The computational properties of the interval calculus and algorithms for maintaining networks of temporal constraints are presented in <ref> [Allen, 1983a; Vilain and Kautz, 1986; Vilain et al., 1990] </ref>. A period can be classified by the relationships that it can have with other periods.
Reference: [Allen, 1983b] <author> James F. Allen, </author> <title> "Recognizing Intentions From Natural Language Utterances," </title> <editor> in M. Brady and R. Berwick, editors, </editor> <booktitle> Computational Models of Discourse. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference: [Allen, 1984] <author> James F. Allen, </author> <title> "Towards a general theory of action and time," </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 123-154, </pages> <year> 1984. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 464-479. </pages>
Reference-contexts: There are several characteristics of propositions that allow them to be broadly classified based on their inferential properties. These distinctions were originally proposed by Vendler [1967], and variants have been proposed under various names throughout linguistics, philosophy, and artificial intelligence ever since (e.g., <ref> [Mourelatos, 1978; Allen, 1984; Dowty, 1986; Shoham, 1988] </ref>). For the most part we will not be concerned with all the distinctions considered by these authors. However one important property mentioned previously is homogeneity. <p> A significant difference between our approaches is that we use an interval-based logic, while McDermott uses a continuous point-based model. These differences have been discussed in detail elsewhere (e.g., <ref> [van Benthem, 1983; Allen, 1984; Shoham, 1988] </ref>). 2.3 Reasoning about Action in Simple Domains This section discusses prediction in theories of action, in particular the frame problem, and describes our approach based on explanation closure.
Reference: [Allen, 1991a] <author> James F. Allen, </author> <title> "Planning as temporal reasoning," </title> <editor> in James Allen, Richard Fikes, and Eric Sandewall, editors, </editor> <booktitle> Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning (KR-91), </booktitle> <pages> pages 3-14, </pages> <address> Cambridge, MA, 22-25 May 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: foundations of the interval temporal logic representation and clarify some of the formal details, such as the issue of discrete variation and the TRPT theorem used extensively to reason about change. * A clarification and elaboration of the approach to causal reasoning based on, e.g., [Allen and Koomen, 1983] or <ref> [Allen, 1991a] </ref>. This includes the uniform use of role functions and the semantics of the T ry predicate. * Adaptation of the explanation closure technique to the temporal logic approach, which adds support to the argument that these explicit "frame" axioms produce an attractive and viable theory.
Reference: [Allen, 1991b] <author> James F. Allen, </author> <title> "Temporal Reasoning and Planning," </title> <booktitle> in Reasoning about Plans, </booktitle> <pages> pages 1-68. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: We can now assert an axiom defining the conditions sufficient to guarantee successful action attempts. In the case of stacking, whenever the agent tries to stack x on y 3 In previous work (e.g., <ref> [Allen, 1991b] </ref>), we included the event "caused" by attempting the action as an argument to the T ry predicate.
Reference: [Allen and Ferguson, 1994] <author> James F. Allen and George Ferguson, </author> <title> "Actions and events in interval temporal logic," </title> <journal> Journal of Logic and Computation, </journal> <volume> 4(5) </volume> <pages> 531-579, </pages> <year> 1994. </year> <note> A much earlier version appeared in Working notes of the Second Symposium on Logical Formalizations of Commonsense Reasoning, </note> <institution> Austin, TX, </institution> <month> 11-13 January, </month> <year> 1993. </year>
Reference-contexts: Possible external events should 1 The work described in the chapter is based on a paper entitled "Actions and Events in Interval Temporal Logic," Journal of Logic and Computation 4 (5), 1994. <ref> [Allen and Ferguson, 1994] </ref> 6 be an important factor when reasoning about what effects an action might have.
Reference: [Allen and Hayes, 1989] <author> James F. Allen and Patrick J. Hayes, </author> <title> "Moments and points in an interval-based temporal logic," </title> <journal> Computational Intelligence, </journal> <volume> 5(4) </volume> <pages> 225-238, </pages> <year> 1989. </year>
Reference-contexts: We start by describing the basic temporal structure to be used in the logic, namely the interval representation of time developed by Allen [1983a; 1984] and discussed in detail in <ref> [Allen and Hayes, 1989] </ref>. We then describe the temporal logic used to represent knowledge of properties, events, and actions. We conclude this section with a comparison of related formalisms. <p> This functional notation is justified because we can prove that the result of j + k is unique <ref> [Allen and Hayes, 1989] </ref>. Next, periods uniquely define an equivalence class of periods that meet them. <p> In particular, moments are true periods and may meet other periods, and if M eets (i; m) ^ M eets (m; j) for any moment m, then i is before j. Points, on the other hand, are not periods and cannot meet periods. Full details can be found in <ref> [Allen and Hayes, 1989] </ref>. Any semantic model that allows these distinctions would be a possible model of time. In particular, a discrete time model can be given for this logic, where periods map to pairs of integers hI ; J i where I &lt; J.
Reference: [Allen and Koomen, 1983] <author> James F. Allen and Johannes A. Koomen, </author> <title> "Planning using a temporal world model," </title> <editor> in Alan Bundy, editor, </editor> <booktitle> Proceedings of the Eighth International Joint Conference on Artificial Intelligence (IJCAI-83), </booktitle> <pages> pages 741-747, </pages> <address> Karlsruhe, West Germany, </address> <month> 8-12 August </month> <year> 1983. </year> <note> William Kaufmann. Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 559-565. 162 </pages>
Reference-contexts: Axioms like this can be very useful in defining simple planning systems similar to non-linear planners (e.g., <ref> [Allen and Koomen, 1983] </ref>). 2.5.2 Synergistic Effects It is also easy to define additional synergistic effects that occur when two actions occur simultaneously. For instance, you can define events that occur only when several actions 53 are performed simultaneously. <p> * To revisit the logical foundations of the interval temporal logic representation and clarify some of the formal details, such as the issue of discrete variation and the TRPT theorem used extensively to reason about change. * A clarification and elaboration of the approach to causal reasoning based on, e.g., <ref> [Allen and Koomen, 1983] </ref> or [Allen, 1991a].
Reference: [Allen and Perrault, 1980] <author> James F. Allen and C. Raymond Perrault, </author> <title> "Analyzing Intention in Utterances," </title> <journal> Artificial Intelligence, </journal> <volume> 15(3) </volume> <pages> 143-178, </pages> <year> 1980. </year>
Reference: [Allen et al., 1995] <author> James F. Allen, Lenhart K. Schubert, George Ferguson, Peter Hee-man, Chung Hee Hwang, Tsuneaki Kato, Marc Light, Nathaniel G. Martin, Brad-ford W. Miller, Massimo Poesio, and David R. Traum, </author> <title> "The TRAINS Project: A case study in defining a conversational planning agent," </title> <journal> Journal of Experimental and Theoretical AI, </journal> <note> 1995. To appear. Also available as TRAINS Technical Note 93-4, </note> <institution> Department of Computer Science, University of Rochester. </institution>
Reference-contexts: We prefer to use a more complex domain than that of the YTS to illustrate these cases. The TRAINS domain is a transportation and manufacturing domain developed for use in the TRAINS project <ref> [Allen et al., 1995] </ref>. The goal of the project is to build an intelligent planning assistant that is conversationally proficient in natural language. The domain involves several cities connected by rail links, warehouses and factories at various cities, and engines, boxcars, etc., to transport goods between them. <p> The participants could not see each other and communicated solely through headsets. They each had a map of the TRAINS domain, shown in projects based on TRAINS (cf. <ref> [Allen et al., 1995] </ref>). The transcripts are available in [Gross et al., 1993]. 63 64 3.1.1 Sample Mixed-Initiative Planning Scenario I would like to consider one of the collected dialogues in order to highlight the roles of plan representation and reasoning in mixed-initiative planning. <p> The overall system architecture is shown in Figure 4.1. This section describes the role of each module and the flow of information between them. A more detailed description of the system, especially the language-oriented components is presented in <ref> [Allen et al., 1995] </ref>. Recall from the example in Section 3.1.1 and Figure 3.1 (page 63) that the TRAINS domain is a transportation world with cities, rail links between them, engines, boxcars, and the like to move things around, and a variety of commodities. <p> For the sample dialogue, we broke the utterance into separate contributions. Real incremental processing of user input including speech is one of the current research goals of the TRAINS project (see <ref> [Allen et al., 1995] </ref> for some more details).
Reference: [Allen and Miller, 1989] <author> J.F. Allen and B.W. Miller, </author> <title> "The Rhetorical knowledge representation system: A user's manual (for Rhet version 15.25)," </title> <type> Technical Report 238 (revised), </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: This section describes the syntax of EBTL, our implementation of the event-based temporal logic from Chapter 2. EBTL is implemented in Common Lisp on top of the Rhet knowledge representation system <ref> [Allen and Miller, 1989] </ref>. Although Rhet provides a complete logic programming environment, for several reasons EBTL is implemented as a Lisp toolkit rather than a theorem-proving system.
Reference: [Austin, 1962] <author> John L. Austin, </author> <title> How to Do Things With Words, </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1962. </year>
Reference: [Bacchus et al., 1989] <author> Fahiem Bacchus, Josh Tenenberg, and Johannes A. Koomen, </author> <title> "A non-reified temporal logic," </title> <editor> in R.J. Brachman, H.J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR-89), </booktitle> <pages> pages 2-10, </pages> <address> Toronto, Ont., </address> <month> 15-18 May </month> <year> 1989. </year>
Reference: [Baker, 1991] <author> Andrew Baker, </author> <title> "Nonmonotonic reasoning in the framework of the situation calculus," </title> <journal> Artificial Intelligence, </journal> <volume> 49 </volume> <pages> 5-24, </pages> <year> 1991. </year>
Reference-contexts: The second issue is what mechanism is used to make the assumptions. There are two main approaches here: explicitly adding axioms that encode the assumptions (e.g., [Green, 1969; Schubert, 1990]) or using a nonmonotonic model theory that defines a new notion of entailment that includes the assumptions (e.g., <ref> [McCarthy, 1980; Shoham, 1988; Baker, 1991; Sandewall, 1994] </ref>). Of course, the work on circumscription shows that model-theoretic techniques always have an equivalent axiomatic formulation, although it may require going beyond standard first-order logic. This equivalence suggests that there is really a continuum of approaches here. Everyone must make assumptions.
Reference: [Balkanski, 1990] <author> Cecile T. Balkanski, </author> <title> "Modelling Act-Type Relations in Collaborative Activity," </title> <type> Technical Report 23-90, </type> <institution> Center for Research in Computing Technology, Harvard University, </institution> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [Brown, 1987] <author> Frank M. Brown, </author> <title> editor, </title> <booktitle> Proceedings of the 1987 Workshop: The Frame Problem in Artificial Intelligence. </booktitle> <publisher> Lawrence, KA, Morgan Kaufmann, </publisher> <month> 12-15 April </month> <year> 1987. </year>
Reference-contexts: The question is whether Fred is dead or not, or rather whether an axiomatization of the problem in some logical system allows the conclusion that Fred is dead to be derived. This simple problem has generated an extensive body of literature (cf. <ref> [Brown, 1987] </ref>).
Reference: [Carberry, 1990] <author> Sandra Carberry, </author> <title> Plan Recognition in Natural Language, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: However, as was the case with plans as structured intentions, there are many aspects of the work on the SharedPlan model that need to be incorporated into my approach. Finally, some of the work most closely related to mine on mixed-initiative planning is Carberry's work on collaborative information-seeking dialogues <ref> [Carberry, 1990] </ref>. This is based on a "context model" consisting of a tree of goals with associated plans, and Car-berry shows how it can be used to handle some complicated discourse phenomena such as ill-formed queries and inter-sentential ellipsis.
Reference: [Carberry, 1991] <author> Sandra Carberry, </author> <title> "Incorporating default inferences into plan recognition," </title> <editor> in John Mylopoulos and Ray Reiter, editors, </editor> <booktitle> Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pages 471-478, </pages> <address> Sydney, Australia, </address> <month> 24-30 August </month> <year> 1991. </year>
Reference: [Cavalli-Sforza and Suthers, 1994] <author> Violetta Cavalli-Sforza and Daniel D. Suthers, "Belvedere: </author> <title> An environment for practicing scientific argumentations," </title> <editor> in Ronald P. Loui and Thomas Gordon, editors, </editor> <booktitle> Working Notes of the AAAI-94 Workshop on Computational Dialectics, </booktitle> <address> Seattle, WA, </address> <month> 30 July </month> <year> 1994. </year>
Reference-contexts: Regarding plan representation, these diagrams are interesting as a per 105 6 Warrant Claim Backing Datum 106 haps more intuitive representation of an argument. Accordingly, they are being used in the design of user interfaces for computer-aided instruction systems (e.g., <ref> [Cavalli-Sforza and Suthers, 1994] </ref>), although these applications generally do not do much reasoning about what they are displaying. As the development of mixed-initiative planning systems starts to include additional modalities of communication such as graphical user interfaces, however, there will need to be more interaction between these communities.
Reference: [Chapman, 1987] <author> David Chapman, </author> <title> "Planning for conjunctive goals," </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 537-558. 163 </pages>
Reference-contexts: By exploiting this property, the plan can be constructed in this interleaved backwards/forwards fashion, and once a plan is found, it is guaranteed to achieve the goal given the two assumptions above. 30 The same prediction model underlies the formalisms based on non-linear planning as in TWEAK <ref> [Chapman, 1987] </ref> and SNLP [McAllester and Rosenblitt, 1991] and systems based on these techniques. These systems, however, use the notion of goal protection [Waldinger, 1977] rather than any explicit forward prediction at all.
Reference: [Cheeseman, 1988] <author> Peter Cheeseman, </author> <title> "An inquiry into computer understanding," </title> <journal> Computational Intelligence, </journal> <volume> 4(1) </volume> <pages> 58-66, </pages> <year> 1988. </year>
Reference: [Chu-Carroll and Carberry, 1994] <author> Jennifer Chu-Carroll and Sandra Carberry, </author> <title> "A plan-based model for response generation in collaborative plan-based dialogues," </title> <booktitle> in Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pages 799-805, </pages> <address> Seattle, WA, 31 July-4 August 1994. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: As well, I believe that that the argumentation approach is appropriate for expressing the kind of meta-knowledge and heuristics that Carberry indicates are necessary for resolving problems between the participants. Finally on this topic, I would like to note the similarities between the model of collaboration presented in <ref> [Chu-Carroll and Carberry, 1994] </ref> and my approach based on argumentation. Their "Propose-Evaluate-Modify" cycle is exactly the dialectical process underlying argument-based reasoning. They note that it is recursive, since the modification phase can involve collaboration.
Reference: [Cohen, 1978] <author> Philip R. Cohen, </author> <title> "On knowing what to say: Planning speech acts," </title> <type> Technical Report 118, </type> <institution> Department of Computer Science, University of Toronto, Toronto, Ont., </institution> <year> 1978. </year>
Reference: [Cohen and Perrault, 1979] <author> Philip R. Cohen and C. Raymond Perrault, </author> <title> "Elements of a plan-based theory of speech acts," </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 177-212, </pages> <year> 1979. </year>
Reference: [Darwiche and Pearl, 1994a] <author> Adnan Darwiche and Judea Pearl, </author> <title> "Symbolic causal networks," </title> <booktitle> in Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pages 238-244, </pages> <address> Seattle, WA, 31 July-4 August 1994. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: In the context of causal reasoning such as we are concerned with in planning, the nodes of the network represent events and propositions and the links encode the "flow of causality," again seen as conditional dependence. In the symbolic causal networks of <ref> [Darwiche and Pearl, 1994a; Darwiche and Pearl, 1994b] </ref>, this "causal structure" is augmented with a set of "domain micro-theories" that specify logical relationships between propositions and their direct causes. The results look very much like arguments.
Reference: [Darwiche and Pearl, 1994b] <author> Adnan Darwiche and Judea Pearl, </author> <title> "Symbolic causal networks for reasoning about actions and plans," </title> <booktitle> in Working Notes of the AAAI Spring Symposium on Decision-Theoretic Planning, </booktitle> <pages> pages 41-47, </pages> <address> Stanford, Ca, </address> <month> 21-23 March </month> <year> 1994. </year>
Reference-contexts: In the context of causal reasoning such as we are concerned with in planning, the nodes of the network represent events and propositions and the links encode the "flow of causality," again seen as conditional dependence. In the symbolic causal networks of <ref> [Darwiche and Pearl, 1994a; Darwiche and Pearl, 1994b] </ref>, this "causal structure" is augmented with a set of "domain micro-theories" that specify logical relationships between propositions and their direct causes. The results look very much like arguments. <p> But this would only be one dimension for evaluation, and the idea of arguments interfering with and being preferred over one and other allows other metrics to be applied as well. I think this is more realistic than the treatment of plans in <ref> [Darwiche and Pearl, 1994b] </ref> that basically replicates the network for each time step and allows cross-links to represent temporally-sequenced causality.
Reference: [Davidson, 1967] <author> Donald Davidson, </author> <title> "The logical form of action sentences," </title> <editor> in N. Rescher, editor, </editor> <title> The Logic of Decision and Action. </title> <institution> University of Pittsburgh Press, </institution> <year> 1967. </year> <title> Excerpted in The Logic of Grammar, </title> <editor> D. Davison and G. Harmon (eds.), </editor> <publisher> Dick-enson Publishing Co., </publisher> <year> 1975, </year> <pages> pp. 235-245. </pages>
Reference: [Davis, 1992] <author> Ernest Davis, </author> <title> "Infinite loops in finite time: Some observations," </title> <editor> in Bernard Nebel, Charles Rich, and William Swartout, editors, </editor> <booktitle> Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning (KR92), </booktitle> <pages> pages 47-58, </pages> <address> Boston, MA, 25-29 October 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Further discussion of discrete variation and its relation to infinite series in calculus and physics can be found in <ref> [Davis, 1992] </ref>.
Reference: [Dean and McDermott, 1987] <author> Tom Dean and Drew McDermott, </author> <title> "Temporal data base management," </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 1-55, </pages> <year> 1987. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 596-623. </pages>
Reference-contexts: Thus the gun must have initially been loaded, i.e., Loaded (t0). 2 We see that the temporal logic is immune to the "direction" of the proof with respect to the direction of time, as expected. In contrast, most other models allow temporal prediction only in a forward direction (e.g., <ref> [Dean and McDermott, 1987] </ref>) and must use a completely different approach for "persisting" backwards in time. Interestingly, the proof for the SMM does not use the fact that we tried to shoot (AX3). <p> These semantics of the N C assumption are given directly in the temporal logic axioms, rather than being defined in a nonmonotonic semantic theory (e.g., [Shoham, 1988]) or via a procedural technique (e.g., TMM <ref> [Dean and McDermott, 1987] </ref>). 3.3.3 Formal Properties of Plans as Arguments We are now ready to define various properties of plans-as-arguments based on the de-feasible causal rules and consider the relationships between them.
Reference: [Dowty, 1986] <author> David R. </author> <title> Dowty, "The Effects of Aspectual Class on the Temporal Structure of Discourse: Semantics or Pragmatics?," </title> <journal> Linguistics and Philosophy, </journal> <volume> 9(1), </volume> <year> 1986. </year>
Reference-contexts: These issues have been studied extensively in work on the semantics of natural language sentences. While there are many proposals, 8 everyone agrees on a few basic distinctions (e.g., <ref> [Vendler, 1967; Mourelatos, 1978; Dowty, 1986] </ref>). <p> There are several characteristics of propositions that allow them to be broadly classified based on their inferential properties. These distinctions were originally proposed by Vendler [1967], and variants have been proposed under various names throughout linguistics, philosophy, and artificial intelligence ever since (e.g., <ref> [Mourelatos, 1978; Allen, 1984; Dowty, 1986; Shoham, 1988] </ref>). For the most part we will not be concerned with all the distinctions considered by these authors. However one important property mentioned previously is homogeneity.
Reference: [Doyle, 1980a] <author> John Doyle, </author> <title> A Model for Deliberation, Action, and Introspection, </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambidge, MA, </address> <year> 1980. </year>
Reference-contexts: It is not clear that default logic's fixed-point definition of extensions could be adapted to provide the sort of object we need to use arguments as a representation of plans (or anything else, for that matter). Interestingly, Doyle's TMS <ref> [Doyle, 1980b; Doyle, 1980a] </ref>, although subsequently co-opted by the nonmonotonic reasoning community as "simply" an implementation of default logic (or other formalisms), is in fact much closer in spirit to the type of dialectical argument-based defeasible reasoning described here.
Reference: [Doyle, 1980b] <author> John Doyle, </author> <title> "A truth maintenance system," </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 231-272, </pages> <year> 1980. </year> <note> Also in Readings in Nonmonotonic Reasoning, M.L. </note> <editor> Ginsberg (ed.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1987, </year> <pages> pp. 259-279. 164 </pages>
Reference-contexts: It is not clear that default logic's fixed-point definition of extensions could be adapted to provide the sort of object we need to use arguments as a representation of plans (or anything else, for that matter). Interestingly, Doyle's TMS <ref> [Doyle, 1980b; Doyle, 1980a] </ref>, although subsequently co-opted by the nonmonotonic reasoning community as "simply" an implementation of default logic (or other formalisms), is in fact much closer in spirit to the type of dialectical argument-based defeasible reasoning described here.
Reference: [Elkan, 1990] <author> C. Elkan, </author> <title> "Incremental, approximate planning," </title> <booktitle> in Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90), </booktitle> <pages> pages 145-150, </pages> <address> Boston, MA, </address> <month> July 29-August 3 </month> <year> 1990. </year>
Reference: [Eshghi, 1988] <author> Kave Eshghi, </author> <title> "Abductive planning with event calculus," </title> <editor> in R.A. Kowal-ski and K.A. Bowen, editors, </editor> <booktitle> Proceedings of the Fifth International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 562-579, </pages> <address> Cambridge, MA, 1988. </address> <publisher> MIT Press. </publisher>
Reference-contexts: With this addition, the new prediction model validates the proposed search strategies. Similar methods using the event calculus are proposed in <ref> [Eshghi, 1988; Shanahan, 1989; Kowalski, 1992] </ref>. 2.3.2 Frame Axioms and Explanation Closure The problem with the above approach is that the STRIPS assumptions do not hold in most realistic situations that one needs to reason about.
Reference: [Ferguson, 1992] <author> George Ferguson, </author> <title> "Explicit Representation of Events, Actions, and Plans for Assumption-Based Plan Reasoning," </title> <type> Technical Report 428, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: There are two directions in which to pursue this. First, we can try to formalize the definitions of defeat, etc., axiomatically using sentences of the meta-language, its "is true" predicate, and some set theory. In previous work <ref> [Ferguson, 1992] </ref>, I did this for 109 a similar representation of plans that was not based directly on arguments but on less well-founded "plan graphs." The exercise really didn't illuminate what was interesting about the representation, although it did result in an "executable specification" (which would never halt in practice, of
Reference: [Ferguson and Allen, 1993] <author> George Ferguson and James F. Allen, </author> <title> "Cooperative Plan Reasoning for Dialogue Systems," </title> <booktitle> in Papers from the AAAI-93 Fall Symposium on Human-Computer Collaboration: Reconciling Theory, Synthesizing Practice, AAAI Technical Report FS-93-05, </booktitle> <address> Raleigh, NC, </address> <month> 22-24 October </month> <year> 1993. </year>
Reference-contexts: Ramshaw [1991] proposes a similar three-layer model. My work on plans-as-arguments has so far concentrated on only the domain level, although the relationship between plans and discourse actions has been explored in the context of the TRAINS project described in the next chapter (see also <ref> [Traum and Allen, 1994; Traum, 1994; Ferguson and Allen, 1993] </ref>). As I noted previously, arguments provide a framework for recipes (plans) that is suitable for both the linguistically complex discourse phenomena and the complicated domain-level reasoning.
Reference: [Ferguson and Allen, 1994] <author> George Ferguson and James F. Allen, </author> <title> "Arguing about Plans: Plan Representation and Reasoning for Mixed-Initiative Planning," </title> <booktitle> in Proceedings of the Second International Conference on AI Planning Systems (AIPS-94), </booktitle> <address> Chicago, IL, </address> <month> 13-15 June </month> <year> 1994. </year>
Reference-contexts: To relate this to traditional planning, I then present a reconstruction of one formal model of STRIPS planning within the defeasible reasoning 1 Some aspects of the work presented in this chapter were presented previously at the Second International Conference on AI Planning Systems <ref> [Ferguson and Allen, 1994] </ref>. 62 paradigm. Since this work is really represents first steps towards a full theory of plan representation, I present a fairly detailed examination of related work and issues for future consideration.
Reference: [Fikes and Nilsson, 1971] <author> Richard E. Fikes and N.J. Nilsson, </author> <title> "STRIPS: A new approach to the application of theorem proving to problem solving," </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 198-208, </pages> <year> 1971. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 88-97. </pages>
Reference-contexts: The chances 10 of integrating such representations into a more general knowledge representation system for tasks such as real-world planning or natural language understanding seem remote. 2.1.3 The STRIPS Representation The STRIPS representation <ref> [Fikes and Nilsson, 1971] </ref> adds additional constraints to the situation calculus model and is used by most implemented planning systems built to date.
Reference: [Gelfond et al., 1991] <author> Michael Gelfond, Vladimir Lifschitz, and Arkady Rabinov, </author> <title> "What are the limitations of the situation calculus?," </title> <booktitle> in Proceedings of the AAAI Symposium on Logical Formalizations of Commonsense Reasoning, </booktitle> <pages> pages 59-59. </pages> <institution> Stanford University, </institution> <month> 26-28 March </month> <year> 1991. </year>
Reference-contexts: In this way, the situation calculus defines a point-based branching time 27 model. A duration function on actions can be defined that allows one to compute the time of the resulting situation given the initial situation <ref> [Schubert, 1990; Gelfond et al., 1991] </ref>. Without the introduction of a time line, however, the range of temporal reasoning that can be performed is severely limited. <p> The situation calculus shows more promise with the introduction of action composition operators. For instance, given two actions a 1 and a 2 , then the action a 1 + a 2 is the action of performing the two simultaneously (e.g., <ref> [Gelfond et al., 1991; Schubert, 1990] </ref>). Explicit axioms can then be given for these complex actions, and mechanisms can be introduced to automatically derive such axioms from the individual actions if they are independent of each other (e.g., [Lin and Shoham, 1992]). <p> Pelavin [1991] contains an extensive analysis of the problems that arise in general with simultaneous interacting actions. As noted in Section 2.2.5, some work has explored the possibility of allowing a duration for each action <ref> [Schubert, 1990; Gelfond et al., 1991] </ref>. Then the duration of a sequence of actions would simply be the sum of the individual action durations. But there is little point to doing this unless one allows these extended actions to overlap with other actions and external events.
Reference: [Georgeff, 1986a] <author> Michael P. Georgeff, </author> <title> "Actions, Processes, and Causality," </title> <editor> in Michael P. Georgeff and Amy L. Lansky, editors, </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <address> Los Altos, CA, 30 June-2 July 1986. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Other approaches work instead by minimizing event or action occurrences. Properties are assumed to change only as a result of events defined in the representation, and logically unnecessary events do not occur (e.g., <ref> [Georgeff, 1986b; Georgeff, 1986a; Morgenstern and Stein, 1988] </ref>). These approaches show more promise at handling more complex situations and have many similarities to our work. The approach we take, however, retains the flavor of explicit frame axioms.
Reference: [Georgeff, 1986b] <author> Michael P. Georgeff, </author> <title> "The representation of events in multiagent domains," </title> <booktitle> in Proceedings of the Fifth National Conference on Artificial Intelligence (AAAI-86), </booktitle> <pages> pages 70-75, </pages> <address> Philadelphia, PA, </address> <month> 11-15 August </month> <year> 1986. </year> <institution> University of Penn-sylvania. </institution>
Reference-contexts: Other approaches work instead by minimizing event or action occurrences. Properties are assumed to change only as a result of events defined in the representation, and logically unnecessary events do not occur (e.g., <ref> [Georgeff, 1986b; Georgeff, 1986a; Morgenstern and Stein, 1988] </ref>). These approaches show more promise at handling more complex situations and have many similarities to our work. The approach we take, however, retains the flavor of explicit frame axioms.
Reference: [Gerevini and Schubert, 1994] <author> Alfonso Gerevini and Lenhart Schubert, </author> <title> "Efficient Algorithms for Qualitative Reasoning about Time," </title> <type> Technical Report 496, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> NY, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: As noted in Section 2.6 regarding the event-based temporal logic, the inability to represent and reason with metric time is a serious shortcoming, particularly in the TRAINS domain. It is hoped that by using a combined interval-metric temporal rea-soner <ref> [Gerevini and Schubert, 1994; Gerevini et al., 1994] </ref> we can express the required metric constraints.
Reference: [Gerevini et al., 1994] <author> Alfonso Gerevini, Lenhart Schubert, and Stephanie Schaeffer, </author> <title> "The Temporal Reasoning Systems Timegraph I-II," </title> <type> Technical Report 494, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> NY, </address> <month> April </month> <year> 1994. </year> <month> 165 </month>
Reference-contexts: As noted in Section 2.6 regarding the event-based temporal logic, the inability to represent and reason with metric time is a serious shortcoming, particularly in the TRAINS domain. It is hoped that by using a combined interval-metric temporal rea-soner <ref> [Gerevini and Schubert, 1994; Gerevini et al., 1994] </ref> we can express the required metric constraints.
Reference: [Ginsberg, 1994a] <author> Matthew L. Ginsberg, </author> <title> "Approximate Planning," </title> <journal> Artificial Intelligence, </journal> <note> 1994. To appear. </note>
Reference: [Ginsberg, 1994b] <author> Matthew L. Ginsberg, </author> <title> "Approximate Planning (extended abstract)," </title> <editor> in Kristian Hammond, editor, </editor> <booktitle> Proceedings of the Second International Conference on Artificial Intelligence Planning Systems (AIPS-94), </booktitle> <address> Chicago, IL, </address> <month> 13-15 June </month> <year> 1994. </year> <institution> University of Chicago. </institution>
Reference: [Goebel and Goodwin, 1987] <author> Randy G. Goebel and Scott D. Goodwin, </author> <title> "Applying theory formation to the planning problem," </title> <editor> in Frank M. Brown, editor, </editor> <booktitle> Proceedings of the 1987 Workshop: The Frame Problem in Artificial Intelligence, </booktitle> <pages> pages 207-232. </pages> <publisher> Lawrence, KA, Morgan Kaufmann, </publisher> <month> 12-15 April </month> <year> 1987. </year>
Reference-contexts: I noted previously (Section 3.2.4) the intellectual closeness of the argument-based approach to defeasible reasoning and the approach based on theory formation [Poole et al., 1987; Poole, 1988]. The application of theory formation to planning in particular is presented in <ref> [Goebel and Goodwin, 1987] </ref>. Although much of the discussion of action representation and reasoning about change parallels that presented here, planning is treated as a process of competing predictions (for the goal and its negation) being resolved using theory preference knowledge.
Reference: [Goldman, 1970] <author> Alvin I. Goldman, </author> <title> A Theory of Human Action, </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1970. </year>
Reference-contexts: Actions may be arbitrarily complex activities, and can be decomposable into other less complex actions, which themselves may be decomposable, until a certain basic level of action is attained. The primitive actions are called the basic actions following <ref> [Goldman, 1970] </ref>. The predicate T ry is defined on programs, such that T ry (; t) is true only if the program is executed over time t. 3 As with event predicates, T ry is anti-homogeneous.
Reference: [Goodwin, 1991] <author> S.D. Goodwin, </author> <title> Statistically Motivated Defaults, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Alberta, Edmonton, Alta., </institution> <note> Fall 1991. Also available as U. of Regina TR CS-91-03. </note>
Reference: [Gordon, 1993] <author> Thomas F. Gordon, </author> <title> The Pleadings Game: An Artificial Intelligence Model of Procedural Justice, </title> <type> PhD thesis, </type> <institution> TU Darmstadt, Darmstadt, Germany, </institution> <year> 1993. </year>
Reference-contexts: The work on formal dialectical models mentioned previously is probably the best place to start. For example, Gordon's model of legal reasoning <ref> [Gordon, 1993] </ref> allows discussion of rules, their backing, the meta-rules governing such discussion, and so on. Something similar is needed for talking about plans, the defeasible causal rules, the persistence assumptions, properties of plans, planning strategies, and so on. 3.7 Summary and Contributions This chapter has made two main contributions.
Reference: [Green, 1969] <author> Cordell Green, </author> <title> "An application of theorem proving to problem solving," </title> <editor> in Donald E. Walker, editor, </editor> <booktitle> Proceedings of the First International Joint Conference on Artificial Intelligence (IJCAI-69), </booktitle> <pages> pages 741-747, </pages> <address> Washington, DC, </address> <month> 7-9 May </month> <year> 1969. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 67-87. </pages>
Reference-contexts: In addition, as we show in the subsequent sections, this approach naturally handles a wide range of more complex problems. The second issue is what mechanism is used to make the assumptions. There are two main approaches here: explicitly adding axioms that encode the assumptions (e.g., <ref> [Green, 1969; Schubert, 1990] </ref>) or using a nonmonotonic model theory that defines a new notion of entailment that includes the assumptions (e.g., [McCarthy, 1980; Shoham, 1988; Baker, 1991; Sandewall, 1994]).
Reference: [Grice, 1975] <author> H. Paul Grice, </author> <title> "Logic and conversation," </title> <editor> in P. Cole and J. L. Morgan, editors, </editor> <booktitle> Syntax and Semantics, </booktitle> <volume> vol. 3, </volume> <booktitle> Speech Acts, </booktitle> <pages> pages 41-58. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: This is easily accomplished through the use of a graphical user interface, perhaps in combination with a simplified natural language query language. This would perhaps allow us to use the work on protocols for language games more directly, or adapt the informal protocols such as Gricean maxims <ref> [Grice, 1975] </ref> to the formal argument system. Gordon makes another point regarding the relationship between argumentation and nonmonotonic reasoning that I think is worth paraphrasing.
Reference: [Gross et al., 1993] <author> Derek Gross, James F. Allen, and David R. Traum, </author> <title> "The TRAINS-91 Dialogues," </title> <type> TRAINS Technical Note 92-1, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, 14627, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: The participants could not see each other and communicated solely through headsets. They each had a map of the TRAINS domain, shown in projects based on TRAINS (cf. [Allen et al., 1995]). The transcripts are available in <ref> [Gross et al., 1993] </ref>. 63 64 3.1.1 Sample Mixed-Initiative Planning Scenario I would like to consider one of the collected dialogues in order to highlight the roles of plan representation and reasoning in mixed-initiative planning.
Reference: [Grosz and Sidner, 1990] <author> Barbara J. Grosz and Candice L. Sidner, </author> <title> "Plans for Discourse," </title> <editor> in P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Pollack also notes the philosophical, empirical, and engineering problems that result from attempting to design intelligent systems that do not use plans. The use of plans in collaborative behavior is the basis of the SharedPlan model <ref> [Grosz and Sidner, 1990] </ref> that extends the notion of plans as structured sets of beliefs and intentions to situations where several agents are collaborating. In its original formulation, the domain plan (termed a "recipe" in [Pollack, 1986a]) was restricted to very simple sets of events related via event generation.
Reference: [Haas, 1992] <author> Andrew R. Haas, </author> <title> "A reactive planner that uses explanation closure," </title> <editor> in Bernard Nebel, Charles Rich, and William Swartout, editors, </editor> <booktitle> Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning (KR92), </booktitle> <pages> pages 93-102, </pages> <address> Boston, MA, 25-29 October 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [Haas, 1987] <author> Andrew W. Haas, </author> <title> "The case for domain-specific frame axioms," </title> <editor> in Frank M. Brown, editor, </editor> <booktitle> Proceedings of the 1987 Workshop: The Frame Problem in Artificial Intelligence, </booktitle> <pages> pages 343-348. </pages> <publisher> Lawrence, KA, Morgan Kaufmann, </publisher> <month> 12-15 April </month> <year> 1987. </year> <month> 166 </month>
Reference: [Hamblin, 1972] <author> C. L. Hamblin, </author> <title> "Instants and Intervals," </title> <editor> in J. T. Fraser, F. C. Haber, and G. H. Muller, editors, </editor> <booktitle> The Study of Time, </booktitle> <pages> pages 324-328. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1972. </year>
Reference: [Hanks and McDermott, 1986] <author> S. Hanks and D. McDermott, </author> <title> "Default reasoning, non-monotonic logic, and the frame problem," </title> <booktitle> in Proceedings of the Fifth National Conference on Artificial Intelligence (AAAI-86), </booktitle> <pages> pages 328-333, </pages> <address> Philadelphia, PA, </address> <month> 11-15 August </month> <year> 1986. </year> <institution> University of Pennsylvania. </institution>
Reference-contexts: These are mostly variants of the Yale Shooting Problem <ref> [Hanks and McDermott, 1986] </ref>, a basic AI test case for reasoning about action. Each scenario involves a very simple domain where a single problem is presented and thus it is not the best vehicle for demonstrating the generality of our approach.
Reference: [Hwang and Schubert, 1993a] <author> Chung Hee Hwang and Lenhart K. Schubert, </author> <title> "Episodic logic: A comprehensive, natural representation for language understanding," </title> <journal> Minds and Machines, </journal> <volume> 3 </volume> <pages> 381-419, </pages> <year> 1993. </year>
Reference-contexts: Natural language input is first processed by a GPSG-style parser into a preliminary unscoped logical form. This logical form is expressed in Episodic Logic <ref> [Hwang and Schubert, 1993a; Hwang and Schubert, 1993b] </ref>, a highly-expressive situational logic developed expressly for the purpose of representing the content of natural language utterances and reasoning about them.
Reference: [Hwang and Schubert, 1993b] <author> Chung Hee Hwang and Lenhart K. Schubert, </author> <title> "Episodic Logic: A situational logic for natural language processing," </title> <editor> in P. Aczel, D. Israel, Y. Katagiri, and S. Peters, editors, </editor> <booktitle> Situation Theory and its Applications, </booktitle> <volume> volume 3. </volume> <publisher> CSLI, Stanford, </publisher> <address> CA, </address> <year> 1993. </year>
Reference-contexts: Natural language input is first processed by a GPSG-style parser into a preliminary unscoped logical form. This logical form is expressed in Episodic Logic <ref> [Hwang and Schubert, 1993a; Hwang and Schubert, 1993b] </ref>, a highly-expressive situational logic developed expressly for the purpose of representing the content of natural language utterances and reasoning about them.
Reference: [Jearl and Verma, 1991] <author> Judea Jearl and T.S. Verma, </author> <title> "A theory of inferred causation," </title> <editor> in James Allen, Richard Fikes, and Eric Sandewall, editors, </editor> <booktitle> Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning (KR-91), </booktitle> <pages> pages 441-453, </pages> <address> Cambridge, MA, 22-25 May 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [Kambhampati, 1989] <author> Subbarao Kambhampati, </author> <title> Flexible reuse and modification in hierarchical planning: A validation structure based approach, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland, College Park, MD, </institution> <year> 1989. </year> <note> Available as CS Technical Report 2334, </note> <institution> Dept. of Computer Science, University of Maryland. </institution>
Reference-contexts: We noted several places where relaxing these constraints might lead to interesting types of plans. Work on traditional planning becomes more interesting when it is extended beyond the original toy domains and black-box planning problems. For example, the work on plan modification and replanning <ref> [Kambhampati, 1989; Kambhampati and Hendler, 1992] </ref> is based on a representation of plans (PRIAR) that annotates them with causal dependency links. This additional information turns out to be identical to the information contained in arguments about plans.
Reference: [Kambhampati, 1994] <author> Subbarao Kambhampati, </author> <title> "Exploiting causal structure to control retrieval and refitting during plan reuse," </title> <journal> Computational Intelligence, </journal> <volume> 10(2) </volume> <pages> 212-245, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: This additional information turns out to be identical to the information contained in arguments about plans. For example, the Blocks World stacking example in <ref> [Kambhampati, 1994] </ref> has validation links corresponding to the CLINK rules of the SNLP plan in Figure 3.11 or to the N C assumptions of event non-occurrence in The validation links of the PRIAR model are one class of assumptions and, as shown in the previous section, are sufficient for STRIPS planning.
Reference: [Kambhampati and Hendler, 1992] <author> Subbarao Kambhampati and James A. Hendler, </author> <title> "A validation-structure-based theory of plan modification and reuse," </title> <journal> Artificial Intelligence, </journal> <volume> 55 </volume> <pages> 193-258, </pages> <year> 1992. </year>
Reference-contexts: We noted several places where relaxing these constraints might lead to interesting types of plans. Work on traditional planning becomes more interesting when it is extended beyond the original toy domains and black-box planning problems. For example, the work on plan modification and replanning <ref> [Kambhampati, 1989; Kambhampati and Hendler, 1992] </ref> is based on a representation of plans (PRIAR) that annotates them with causal dependency links. This additional information turns out to be identical to the information contained in arguments about plans.
Reference: [Kautz, 1986] <author> Henry A. Kautz, </author> <title> "The logic of persistence," </title> <booktitle> in Proceedings of the Fifth National Conference on Artificial Intelligence (AAAI-86), </booktitle> <pages> pages 401-405, </pages> <address> Philadel-phia, PA, </address> <month> 11-15 August </month> <year> 1986. </year> <institution> University of Pennsylvania. </institution>
Reference-contexts: Rather, the representation only makes sense when these assumptions are made. The other major approach focuses on minimizing property change, with additional constraints based on the temporal ordering of properties (e.g., <ref> [Shoham, 1988; Kautz, 1986] </ref>) or minimizing causal relationships (e.g., [Lifschitz, 1987]). Sandewall [1994] examines the advantages and limitations of each of these approaches in detail.
Reference: [Kautz, 1987] <author> Henry A. Kautz, </author> <title> A Formal Theory of Plan Recognition, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> May </month> <year> 1987. </year> <note> Available as Technical Report 215. </note>
Reference-contexts: This is similar in spirit to my approach based on explicitly constructing arguments. Finally regarding traditional nonmonotonic reasoning approaches to plan reasoning, one of the most successful such efforts is Kautz's formalization of plan recognition in terms of circumscription <ref> [Kautz, 1987; Kautz, 1991] </ref>. One reason for this is that it made concrete an aspect of plan reasoning that had formerly only been studied informally in terms of linguistic theory and pragmatics.
Reference: [Kautz, 1991] <author> Henry A. Kautz, </author> <title> "A Formal Theory of Plan Recognition and its Implementation," </title> <booktitle> in Reasoning about Plans, </booktitle> <pages> pages 69-126. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: This is similar in spirit to my approach based on explicitly constructing arguments. Finally regarding traditional nonmonotonic reasoning approaches to plan reasoning, one of the most successful such efforts is Kautz's formalization of plan recognition in terms of circumscription <ref> [Kautz, 1987; Kautz, 1991] </ref>. One reason for this is that it made concrete an aspect of plan reasoning that had formerly only been studied informally in terms of linguistic theory and pragmatics. <p> And again, the use of circumscription meant that the resulting system was more a specification of what acceptable plan recognition was than it was a way of 100 computing them, although the well-described implementation <ref> [Kautz, 1991] </ref> probably deserves more credit than this. As with circumscription in general, the fact that the important information contained in the circumscription policy is outside the language limits its usefulness for mixed-initiative planning where we need to be able to discuss these issues.
Reference: [Keynes, 1921] <author> John Maynard Keynes, </author> <title> A Treatise on Probability, </title> <publisher> Macmillan and Co., </publisher> <address> London, </address> <year> 1921. </year> <month> 167 </month>
Reference-contexts: Loui [1991a], in his excellent survey of the history of non-demonstrative argument-based reasoning, credits Keynes with reviving its formal study, citing such passages as "probability is concerned with arguments" <ref> [Keynes, 1921, page 116] </ref>. The field of computational dialectics is an emerging union of work on nonmono-tonic reasoning, AI and law, computer-aided instruction, philosophy of language, and philosophical logic.
Reference: [Knoblock, 1992] <author> Craig A. Knoblock, </author> <title> "An analysis of ABSTRIPS," </title> <booktitle> in Proceedings of the First International Conference on AI Planning Systems, </booktitle> <pages> pages 126-135, </pages> <address> College Park, MD, 15-17 June 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: As well, the fact that partial plans can arise naturally in mixed-initiative planning and be reasoned about without reference to their completions is an important aspect missed by the TWEAK model. There has been work on partial STRIPS plans in the context of abstraction <ref> [Yang and Tenenberg, 1990; Knoblock, 1992] </ref>, but it is not clear that abstraction as developed in ABSTRIPS is the same thing as the kind of incompleteness found in argumentation. 101 Finally, Ginsberg [1994a; 1994b] has recently argued that planners, instead of being guaranteed correct and complete, should be approximate, a term
Reference: [Konolige, 1988] <author> Kurt Konolige, </author> <title> "Defeasible argumentation in reasoning about events," </title> <editor> in Zbigniew W. Ras and Lorenza Saitta, editors, </editor> <booktitle> Methodologies for Intelligent Systems 3, Proceedings of the Third International Symposium, </booktitle> <pages> pages 380-390, </pages> <address> Turin, Italy, 12-15 October 1988. </address> <publisher> North-Holland. </publisher>
Reference-contexts: Since the indirect methods do not represent 75 the concepts involved in such reasoning (rules, defeat, reinstatement, etc.) naturally, "the results of trying to formalize defeasible reasoning within such a system are often surprising and counterintuitive." <ref> [Konolige, 1988] </ref> I made these same observations in Chapter 2 regarding the application of the indirect methods to the prediction problem. In this chapter I will concentrate on the fact that the arguments being constructed are explicit objects that I will use as the representation of plans.
Reference: [Konolige and Pollack, 1989] <author> Kurt Konolige and Martha E. Pollack, </author> <title> "Ascribing plans to agents, preliminary report," </title> <editor> in Natesa Sastri Sridharan, editor, </editor> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 924-930, </pages> <address> Detroit, MI, </address> <month> 20-25 August </month> <year> 1989. </year>
Reference-contexts: The result was a view of plans as complex mental attitudes. In <ref> [Konolige and Pollack, 1989] </ref> this is combined with Konolige's [1988] system of explicit defeasi-ble reasoning discussed in Section 3.2.4. The motivation is that plan recognition is a process of belief and intention ascription that is necessarily defeasible. <p> In fact, "Contributes" is formalized as the transitive closure of the various one-step links that appear in the act-type relation ontology. Lochbaum et al. note that the belief 103 ascription process is defeasible, and indicate that argumentation as in <ref> [Konolige and Pollack, 1989] </ref> is one way of performing such reasoning. Lochbaum [Lochbaum, 1991] describes an algorithm for explaining the role of a particular activity in an augmented recipe. The approach seems very similar to the constraint-based search used by my implementation of recognition (cf. Section 4.5.2).
Reference: [Koomen, 1989] <author> Johannes A.G.M. Koomen, </author> <title> "The TIMELOGIC Temporal Reasoning System in Common Lisp," </title> <type> Technical Report 231, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> NY, </address> <month> March </month> <year> 1989. </year> <note> Revised. </note>
Reference-contexts: The special predicates :eq and :ineq are used in formulas, for example, asserting (:eq [David] [father George]) would add the equality, and querying it would test the equality. Time: Temporal reasoning in EBTL is supported using the Timelogic interval temporal reasoner <ref> [Koomen, 1989] </ref> and terms and variables of type T-Time. The special predicate :time-reln is used in formulas. The interval relations are referred to using keywords (e.g., :b for Bef ore) or a list of keywords (representing a disjunction).
Reference: [Kowalski, 1992] <author> Robert Kowalski, </author> <title> "Database updates in the event calculus," </title> <journal> Journal of Logic Programming, </journal> <volume> 12 </volume> <pages> 121-146, </pages> <year> 1992. </year>
Reference-contexts: With this addition, the new prediction model validates the proposed search strategies. Similar methods using the event calculus are proposed in <ref> [Eshghi, 1988; Shanahan, 1989; Kowalski, 1992] </ref>. 2.3.2 Frame Axioms and Explanation Closure The problem with the above approach is that the STRIPS assumptions do not hold in most realistic situations that one needs to reason about. <p> Work on the frame problem investigates methods of making assumptions about the world to predict the likely consequences of actions. There are therefore two separable issues to consider, which have been called the "epistemological" and "computational" aspects of the problem (cf. <ref> [Kowalski, 1992] </ref>, but also [McCarthy and Hayes, 1969] regarding epistemological and heuristic adequacy). The epistemological aspect concerns what assumptions one makes about the world, while the computational aspect concerns how to compute and use these assumptions in the formalism.
Reference: [Kowalski and Sergot, 1986] <author> Robert Kowalski and Marek Sergot, </author> <title> "A logic-based calculus of events," </title> <journal> New Generation Computing, </journal> <volume> 4 </volume> <pages> 67-95, </pages> <year> 1986. </year>
Reference-contexts: This does not seem particularly workable, and recent approaches introduce an explicit new construct for events (e.g., [Miller and Shanahan, 1994]). The resulting formalism is again closer to what we propose, and we question the advantage of retaining the original situation calculus framework. The event calculus <ref> [Kowalski and Sergot, 1986] </ref> has an explicit notion of event that corresponds more closely to our notion of events. This is not surprising as both this formalism and our own development of the temporal logic are based on intuitions about the close relationship between time and events.
Reference: [Kushmerick et al., 1994] <author> Nicholas Kushmerick, Steve Hanks, and Daniel Weld, </author> <title> "An Algorithm for Probabilistic Least-Commitment Planning," </title> <booktitle> in Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <address> Seattle, WA, 31 July-4 August 1994. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: This model marked the beginning of a rekindling of interest in the formal foundations of STRIPS planning. It has since led to work such as the UCPOP model [Penberthy and Weld, 1992] and the BURIDAN planner <ref> [Kushmerick et al., 1994] </ref>. I then reconstruct the SNLP model as a defeasible knowledge base with facts and rules and show how SNLP plans correspond to arguments satisfying certain criteria.
Reference: [Kyburg, 1974] <author> Henry E. Kyburg, Jr., </author> <title> The Logical Foundations of Statistical Inference, </title> <address> D. </address> <publisher> Reidel, </publisher> <address> Dordrecht, </address> <year> 1974. </year>
Reference-contexts: As I stated in Section 3.2.4 when comparing defeasible reasoning and decision theory, one way of viewing defeasible rules is as qualitative conditional probability statements. Specificity and defeat can then be justified by appeal to principles of statistical inference such as <ref> [Kyburg, 1974] </ref>. But I think it's clear that we need more quantitative statistical reasoning in order to reason effectively about plans. One of the most promising recent developments in uncertain inference has been the study of Bayesian networks [Pearl, 1988].
Reference: [Kyburg, 1990] <author> Henry E. Kyburg, Jr., </author> <title> "Probabilistic inference and probabilistic reasoning," </title> <booktitle> Philosophical Topics, </booktitle> <volume> 18(2) </volume> <pages> 107-116, </pages> <month> Fall </month> <year> 1990. </year>
Reference: [Kyburg, 1994] <author> Henry E. Kyburg, Jr., </author> <title> "Believing on the basis of the evidence," </title> <journal> Computational Intelligence, </journal> <volume> 10(1) </volume> <pages> 3-20, </pages> <month> February </month> <year> 1994. </year>
Reference: [Kyburg Jr., 1991] <author> Henry E. Kyburg Jr., </author> <title> "Beyond specificity," </title> <editor> in B. Bouchon-Meunier, R. R. Yager, and L. A. Zadeh, editors, </editor> <booktitle> Uncertainty in Knowledge Bases, </booktitle> <pages> pages 204-212. </pages> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: In the definition of conflict between and defeat among arguments (Section 3.2.2), we defined the specificity criterion for defeat and noted that others were possible. Perhaps Kyburg [1974] is right and what we need are his three fundamental principles of statistical reasoning (specificity, Bayesian construction, and supersample) <ref> [Kyburg Jr., 1991] </ref>. Or perhaps the appropriate set of principles is that described by Pollock [1991; 1992a; 1992b], including some classical logic, the statistical syllogism, some induction principles, and an analysis of phenomena such as collective defeat and self-defeat.
Reference: [Ladkin and Maddux, 1988] <author> Peter Ladkin and R. Maddux, </author> <title> "Representation and reasoning with convex time intervals," </title> <type> Technical report KES.U.88.2, </type> <institution> Kestrel Institution, </institution> <address> Palo Alto, CA, </address> <year> 1988. </year>
Reference-contexts: A similar model built out of pairs of real numbers does not allow moments. A more complex model can be specified out of the reals, however, that does allow continuous time, or models that are sometimes discrete and sometimes continuous are possible. Ladkin and Maddux <ref> [Ladkin and Maddux, 1988] </ref> have characterized the set of possible models as precisely the arbitrary unbounded linear orders. 2.2.2 Interval Temporal Logic The most obvious way to add times into a logic is to add an extra argument to each predicate.
Reference: [Lam and Bacchus, 1994] <author> Wai Lam and Fahiem Bacchus, </author> <title> "Learning Bayesian belief networks: An approach based on the MDL principle," </title> <journal> Computational Intelligence, </journal> <volume> 10(3) </volume> <pages> 270-293, </pages> <month> August </month> <year> 1994. </year> <month> 168 </month>
Reference: [Lambert and Carberry, 1991] <author> Lynn Lambert and Sandra Carberry, </author> <title> "A tripartite plan-based model of dialogue," </title> <booktitle> in Proceedings of the Twenty-Ninth Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 47-54, </pages> <address> Berkeley, CA, </address> <month> 18-21 June </month> <year> 1991. </year> <institution> University of California. </institution>
Reference-contexts: This is based on a "context model" consisting of a tree of goals with associated plans, and Car-berry shows how it can be used to handle some complicated discourse phenomena such as ill-formed queries and inter-sentential ellipsis. In <ref> [Lambert and Carberry, 1991] </ref> this is extended to a three layer model involving plans at the domain level, the problem-solving level, and the discourselevel. Ramshaw [1991] proposes a similar three-layer model.
Reference: [Lifschitz, 1987] <author> Vladimir Lifschitz, </author> <title> "Formal theories of action," </title> <editor> in Frank M. Brown, editor, </editor> <booktitle> Proceedings of the 1987 Workshop: The Frame Problem in Artificial Intelligence, </booktitle> <pages> pages 35-58. </pages> <publisher> Lawrence, KA, Morgan Kaufmann, </publisher> <month> 12-15 April </month> <year> 1987. </year>
Reference-contexts: There are several ways to try to overcome this problem. Many researchers abandon frame axioms altogether, and have built models that use persistence or inertia assumptions (e.g., <ref> [Lifschitz, 1987; Shoham, 1988] </ref>). These approaches assume that all changes caused by an action are specified, and every property not asserted to change does not change. <p> Rather, the representation only makes sense when these assumptions are made. The other major approach focuses on minimizing property change, with additional constraints based on the temporal ordering of properties (e.g., [Shoham, 1988; Kautz, 1986]) or minimizing causal relationships (e.g., <ref> [Lifschitz, 1987] </ref>). Sandewall [1994] examines the advantages and limitations of each of these approaches in detail. Most of the approaches that minimize property change cannot handle Sandewall's test suite of problems, let alone be extended to handle external events and simultaneous actions.
Reference: [Lifschitz and Rabinov, 1989] <author> Vladimir Lifschitz and Arkady Rabinov, </author> <title> "Miracles in formal theories of action (research note)," </title> <journal> Artificial Intelligence, </journal> <volume> 38(2) </volume> <pages> 225-238, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Similarly, the constructive situation calculus has the same problem|since there is no way to express information about what the state of the world is while the action is happening, there is no mechanism for allowing an event to occur while an action is being performed. Lifschitz and Rabinov <ref> [Lifschitz and Rabinov, 1989] </ref> present a limited mechanism to handle this by allowing "miracles" to occur while an action is performed to explain why its effects are not as expected.
Reference: [Lin and Shoham, 1989] <author> F. Lin and Y. Shoham, </author> <title> "Argument systems: A uniform basis for nonmonotonic reasoning," </title> <editor> in R.J. Brachman, H.J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR-89), </booktitle> <pages> pages 245-255, </pages> <address> Toronto, Ont., 15-18 May 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [Lin and Shoham, 1992] <author> Fangzhen Lin and Yoav Shoham, </author> <title> "Concurrent actions in the situation calculus," </title> <booktitle> in Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> pages 580-585, </pages> <address> San Jose, CA, </address> <month> 12-16 July </month> <year> 1992. </year>
Reference-contexts: For instance, the axioms above say nothing about what would happen if the agent simultaneously lifts a small block and a large block. This reflects the fact that the agent doesn't know. With a technique based on predicate minimization (such as <ref> [Lin and Shoham, 1992] </ref>), the agent would assume that it would not tip over, possibly a dangerous assumption. We would instead use explanation closure techniques on the Ab predicate which allow us to leave such cases uncertain. <p> Explicit axioms can then be given for these complex actions, and mechanisms can be introduced to automatically derive such axioms from the individual actions if they are independent of each other (e.g., <ref> [Lin and Shoham, 1992] </ref>). If the actions are not independent of each other, some reasonable solutions can be found and, as long as actions are instantaneous, it appears that the theory can remain constructive.
Reference: [Litman, 1985] <author> Diane Litman, </author> <title> Plan recognition and discourse analysis: an integrated approach for understanding dialogues, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <year> 1985. </year> <note> Available as Technical Report 170. </note>
Reference-contexts: Similarly, the hearer could use the same knowledge to determine the intentions of the speaker from her speech acts by recognizing her plan <ref> [Litman, 1985; Litman and Allen, 1987] </ref>. The most intriguing part of Allen's work as regards my development of plans-as-arguments is the "rating heuristics" applied to plans during plan inferencing.
Reference: [Litman and Allen, 1987] <author> Diane Litman and James F. Allen, </author> <title> "A plan-recognition model for subdialogues in conversations," </title> <journal> Cognitive Science, </journal> <volume> 11(2), </volume> <year> 1987. </year>
Reference-contexts: Similarly, the hearer could use the same knowledge to determine the intentions of the speaker from her speech acts by recognizing her plan <ref> [Litman, 1985; Litman and Allen, 1987] </ref>. The most intriguing part of Allen's work as regards my development of plans-as-arguments is the "rating heuristics" applied to plans during plan inferencing.
Reference: [Lochbaum, 1991] <author> Karen E. Lochbaum, </author> <title> "An algorithm for plan recognition in collaborative discourse," </title> <booktitle> in Proceedings of the Twenty-Ninth Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 33-38, </pages> <address> Berkeley, CA, </address> <month> 18-21 June </month> <year> 1991. </year> <institution> University of California. </institution>
Reference-contexts: Lochbaum et al. note that the belief 103 ascription process is defeasible, and indicate that argumentation as in [Konolige and Pollack, 1989] is one way of performing such reasoning. Lochbaum <ref> [Lochbaum, 1991] </ref> describes an algorithm for explaining the role of a particular activity in an augmented recipe. The approach seems very similar to the constraint-based search used by my implementation of recognition (cf. Section 4.5.2).
Reference: [Lochbaum et al., 1990] <author> Karen E. Lochbaum, Barbara J. Grosz, and Candace L. Sidner, </author> <title> "Models of plans to support communication: An initial report," </title> <booktitle> in Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90), </booktitle> <pages> pages 485-490, </pages> <address> Boston, MA, </address> <month> July 29-August 3 </month> <year> 1990. </year>
Reference-contexts: The defeasible nature of this reasoning and the role of assumptions during reasoning about recipes (plan reasoning) is also not addressed. Plan recognition based on the SharedPlan model augmented with the more expressive recipe language is described in <ref> [Lochbaum et al., 1990] </ref>. The goal is to describe how the structure of the recipes influences recognition.
Reference: [Loui, 1990a] <author> Ronald Loui, </author> <title> "Defeasible Specification of Utilities," </title> <editor> in Henry E. Kyburg, Jr., Ronald P. Loui, and Greg N. Carlson, editors, </editor> <booktitle> Knowledge Representation and Defeasible Reasoning, </booktitle> <pages> pages 345-360. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Dordrecht, The Netherlands, </address> <year> 1990. </year>
Reference: [Loui, 1990b] <author> Ronald P. Loui, </author> <title> "Defeasible decisions: What the proposal is and isn't," </title> <editor> in M. Henrion, R. D. Schacter, L. N. Kanal, and J. F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 5, </booktitle> <pages> pages 99-116. </pages> <publisher> Elsevier Science Publishers (North-Holland), </publisher> <year> 1990. </year> <month> 169 </month>
Reference-contexts: He writes that "the next question to be studied is how to interpret the planning ideas of goal-directed search" <ref> [Loui, 1990b] </ref> and offers some suggestions. I believe that the view of planning based on ar 77 gumentation presented in the rest of this chapter also addresses part of this question.
Reference: [Loui, 1991a] <author> Ronald P. Loui, </author> <title> "Argument and belief: Where we stand in the Keynesian tradition," </title> <journal> Minds and Machines, </journal> <volume> 1 </volume> <pages> 357-365, </pages> <year> 1991. </year>
Reference-contexts: Loui [1991b] refers to this as ampliativity, and emphasizes that this type of nonmonotonicity in computation is different from and more important than the nonmonotonicity in evidence more commonly studied in work on nonmonotonic reasoning (see also <ref> [Loui, 1991a] </ref> in this regard). 3. The arguments produced by direct inference systems serve as an explanation for their conclusions. Konolige cites the usefulness of this for "debugging," but for my purposes the benefits are much greater.
Reference: [Loui, 1991b] <author> Ronald P. Loui, "Dialectic, </author> <title> computation, and ampliative inference," </title> <editor> in R. Cummins and J. Pollock, editors, </editor> <booktitle> Philosophy and AI. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference: [Loui, 1987] <author> R.P. Loui, </author> <title> "Defeat among arguments: A system of defeasible inference," </title> <journal> Computational Intelligence, </journal> <volume> 3(2) </volume> <pages> 100-106, </pages> <year> 1987. </year>
Reference: [Martin, 1993] <author> Nathaniel G. Martin, </author> <title> Using Statistical Inference to Plan Under Uncertainty, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <year> 1993. </year> <note> To appear as a Technical Report. </note>
Reference-contexts: This is another motivation for favoring the explanation closure technique. It makes the assumptions that are made explicit, and thus potentially available for probabilistic analysis. Some initial work on this is described in <ref> [Martin, 1993; Martin and Allen, 1993] </ref>. It is much more difficult to see how techniques that build the assumptions into the semantic model could be extended to support probabilistic reasoning. Finally, it needs to be acknowledged that formalizing knowledge using the more expressive temporal representation can be difficult. <p> The dialogue manager can also interact with the generation component (currently only partially implemented) to generate utterances and with the execution component to dispatch completed plans for execution and monitoring <ref> [Martin, 1993] </ref>. One final thing to note about the system architecture is that the system's utterances are themselves processed by the entire system (with the speaker-hearer modality reversed, of course).
Reference: [Martin and Allen, 1993] <author> Nathaniel G. Martin and James F. Allen, </author> <title> "Statistical Probabilities for Planning," </title> <type> Technical Report 474, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: This is another motivation for favoring the explanation closure technique. It makes the assumptions that are made explicit, and thus potentially available for probabilistic analysis. Some initial work on this is described in <ref> [Martin, 1993; Martin and Allen, 1993] </ref>. It is much more difficult to see how techniques that build the assumptions into the semantic model could be extended to support probabilistic reasoning. Finally, it needs to be acknowledged that formalizing knowledge using the more expressive temporal representation can be difficult.
Reference: [McAllester and Rosenblitt, 1991] <author> David McAllester and David Rosenblitt, </author> <title> "Systematic nonlinear planning," </title> <booktitle> in Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> pages 634-639. </pages> <publisher> MIT Press, </publisher> <month> 12-19 July </month> <year> 1991. </year>
Reference-contexts: exploiting this property, the plan can be constructed in this interleaved backwards/forwards fashion, and once a plan is found, it is guaranteed to achieve the goal given the two assumptions above. 30 The same prediction model underlies the formalisms based on non-linear planning as in TWEAK [Chapman, 1987] and SNLP <ref> [McAllester and Rosenblitt, 1991] </ref> and systems based on these techniques. These systems, however, use the notion of goal protection [Waldinger, 1977] rather than any explicit forward prediction at all. <p> The defeasible reasoning system benefits from being applied to a problem of fundamental importance to AI, rather than the more abstract "birds fly" problems more commonly used to illustrate them. This section proceeds as follows. First, I will review the definitions of the SNLP model of planning <ref> [McAllester and Rosenblitt, 1991] </ref>. This model marked the beginning of a rekindling of interest in the formal foundations of STRIPS planning. It has since led to work such as the UCPOP model [Penberthy and Weld, 1992] and the BURIDAN planner [Kushmerick et al., 1994]. <p> Finally, I summarize what I think is gained from this admittedly somewhat artificial, technical exercise. 92 3.4.1 The SNLP Formalism The following definitions are taken from <ref> [McAllester and Rosenblitt, 1991] </ref>. Definition 16 An SNLP operator is a tuple ho; P; A; Di where o is the operator name, P a set of prerequisites, A a set of propositions added by the operator, and D a set of propositions deleted by the operator.
Reference: [McCarthy, 1980] <author> J. McCarthy, </author> <title> "Circumscription A form of non-monotonic reasoning," </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):27-39, </volume> <year> 1980. </year>
Reference-contexts: The second issue is what mechanism is used to make the assumptions. There are two main approaches here: explicitly adding axioms that encode the assumptions (e.g., [Green, 1969; Schubert, 1990]) or using a nonmonotonic model theory that defines a new notion of entailment that includes the assumptions (e.g., <ref> [McCarthy, 1980; Shoham, 1988; Baker, 1991; Sandewall, 1994] </ref>). Of course, the work on circumscription shows that model-theoretic techniques always have an equivalent axiomatic formulation, although it may require going beyond standard first-order logic. This equivalence suggests that there is really a continuum of approaches here. Everyone must make assumptions. <p> As well, such a solution might well give answers at the wrong level of detail for them to be useful in a commonsense reasoner. We could also use something like McCarthy's Ab predicate <ref> [McCarthy, 1980] </ref> in ETRY1, which would allow us to incrementally add conditions that entail an abnormal lifting attempt. However, if we used a standard nonmonotonic method to minimize Ab, we would risk losing information about cases where the robot is uncertain. <p> Konolige [1988] describes the application of a system of argumentation to reasoning about events in the Yale Shooting Problem. He refers to this form of reasoning as direct inference, since arguments are explicit objects of the theory, as opposed to indirect model-theoretic approaches such as circumscription <ref> [McCarthy, 1980] </ref> or indirect modal approaches such as default logic [Reiter, 1980] or autoepistemic logic [Moore, 1985]. Konolige cites the following points in favour of direct over indirect inference (to each of which I have added some further comments): 1.
Reference: [McCarthy and Hayes, 1969] <author> John McCarthy and Patrick J. Hayes, </author> <title> "Some philosophical problems from the standpoint of artificial intelligence," </title> <editor> in B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 4, </volume> <pages> pages 463-502. </pages> <publisher> American El-sevier Publishing Co., Inc., </publisher> <year> 1969. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 393-435. </pages>
Reference-contexts: Rather, we will draw on an analogy with the robot situation, and view actions as programs. Thus, performing an action will be described in terms of running a program. 2.1.2 The Situation Calculus The situation calculus means different things to different researchers. In its original formulation <ref> [McCarthy and Hayes, 1969] </ref>, which we will call the general theory of the situation calculus, situations are introduced into the ontology as a complete snapshot of the universe at some instant in time. In effect, the situation calculus is equivalent to a point-based temporal logic with a branching time model. <p> Rather the properties of the resulting state must be specified axiomatically, and the frame problem involves how best to specify these properties. The original proposal for the situation calculus <ref> [McCarthy and Hayes, 1969] </ref> was to use frame axioms, which explicitly stated which properties are not changed by the actions. Explicit frame axioms have come under criticism, primarily because there are too many of them, both to write down explicitly and to reason with efficiently. <p> Work on the frame problem investigates methods of making assumptions about the world to predict the likely consequences of actions. There are therefore two separable issues to consider, which have been called the "epistemological" and "computational" aspects of the problem (cf. [Kowalski, 1992], but also <ref> [McCarthy and Hayes, 1969] </ref> regarding epistemological and heuristic adequacy). The epistemological aspect concerns what assumptions one makes about the world, while the computational aspect concerns how to compute and use these assumptions in the formalism.
Reference: [McDermott, 1985] <author> Drew McDermott, </author> <title> "Reasoning about plans," </title> <editor> in J.R. Hobbs and R.C. Moore, editors, </editor> <booktitle> Formal Theories of the Commonsense World, </booktitle> <pages> pages 269-318. </pages> <publisher> Ablex Publishing, </publisher> <address> Norwood, NJ, </address> <year> 1985. </year>
Reference: [Miller and Shanahan, 1994] <author> Rob Miller and Murray Shanahan, </author> <title> "Narratives in the situation calculus," </title> <journal> Journal of Logic and Computation, Special Issue on Actions and Processes, </journal> <year> 1994. </year>
Reference-contexts: One would have to quantify over all action sequences and 28 ensure that the event or action was present. This does not seem particularly workable, and recent approaches introduce an explicit new construct for events (e.g., <ref> [Miller and Shanahan, 1994] </ref>). The resulting formalism is again closer to what we propose, and we question the advantage of retaining the original situation calculus framework. The event calculus [Kowalski and Sergot, 1986] has an explicit notion of event that corresponds more closely to our notion of events. <p> With this, one can introduce an Occurs predicate that asserts that a particular action occurs at a specific time and that is defined by an axiom that quantifies over all situations at that time (e.g., <ref> [Pinto, 1994; Miller and Shanahan, 1994] </ref>). This development moves the formalism closer to what we are proposing. Ultimately, the main difference between our approach and these extended situation calculus representations with explicit time will probably be one of approach.
Reference: [Moore, 1985] <author> Robert C. Moore, </author> <title> "A formal theory of knowledge of action," </title> <editor> in J.R. Hobbs and R.C. Moore, editors, </editor> <title> Formal Theories of the Commonsense World. </title> <publisher> Ablex Publishing, </publisher> <address> Norwood, NJ, </address> <year> 1985. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 480-520. </pages>
Reference-contexts: He refers to this form of reasoning as direct inference, since arguments are explicit objects of the theory, as opposed to indirect model-theoretic approaches such as circumscription [McCarthy, 1980] or indirect modal approaches such as default logic [Reiter, 1980] or autoepistemic logic <ref> [Moore, 1985] </ref>. Konolige cites the following points in favour of direct over indirect inference (to each of which I have added some further comments): 1. Domain knowledge often includes information about the way defeasible arguments in that domain are related.
Reference: [Morgenstern and Stein, 1988] <author> Leora Morgenstern and Lynn A. Stein, </author> <title> "Why things go wrong: A formal theory of causal reasoning," </title> <booktitle> in Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI-88), </booktitle> <address> St. Paul, MN, </address> <month> 21-26 August </month> <year> 1988. </year> <institution> University of Minnesota. </institution> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 641-646. 170 </pages>
Reference-contexts: Other approaches work instead by minimizing event or action occurrences. Properties are assumed to change only as a result of events defined in the representation, and logically unnecessary events do not occur (e.g., <ref> [Georgeff, 1986b; Georgeff, 1986a; Morgenstern and Stein, 1988] </ref>). These approaches show more promise at handling more complex situations and have many similarities to our work. The approach we take, however, retains the flavor of explicit frame axioms.
Reference: [Mourelatos, 1978] <author> A.P.D. Mourelatos, </author> <title> "Events, processes and states," </title> <journal> Linguistics and Philosophy, </journal> <volume> 2 </volume> <pages> 415-434, </pages> <year> 1978. </year>
Reference-contexts: These issues have been studied extensively in work on the semantics of natural language sentences. While there are many proposals, 8 everyone agrees on a few basic distinctions (e.g., <ref> [Vendler, 1967; Mourelatos, 1978; Dowty, 1986] </ref>). <p> There are several characteristics of propositions that allow them to be broadly classified based on their inferential properties. These distinctions were originally proposed by Vendler [1967], and variants have been proposed under various names throughout linguistics, philosophy, and artificial intelligence ever since (e.g., <ref> [Mourelatos, 1978; Allen, 1984; Dowty, 1986; Shoham, 1988] </ref>). For the most part we will not be concerned with all the distinctions considered by these authors. However one important property mentioned previously is homogeneity.
Reference: [Nebel and Backstrom, 1994] <author> Bernhard Nebel and Christer Backstrom, </author> <title> "On the computational complexity of temporal projection, planning, and plan validation," </title> <journal> Artificial Intelligence, </journal> <volume> 66 </volume> <pages> 125-160, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: I have argued that planning and plan reasoning does not really fit that form of reasoning, except in the trivial sense of generating possible complete plans and asking the nonmonotonic reasoner if they are "correct," whatever that means (i.e., plan validation, see <ref> [Nebel and Backstrom, 1994] </ref> for an interesting discussion of the relationship between planning and validation). I emphasized in Section 3.2.4 that argumentation is concerned with the process of drawing conclusions, rather than just what those conclusions should be.
Reference: [Nilsson, 1980] <author> Nils J. Nilsson, </author> <booktitle> Principles of Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1980. </year>
Reference-contexts: In fact, most planning algorithms exploit a specific prediction model in order to suggest actions likely to produce a good plan, but all systems are based on some prediction model. As a concrete example, consider the standard backward chaining planning algorithm using the STRIPS representation (e.g., <ref> [Nilsson, 1980] </ref>). The algorithm chains backwards from the goal state. First, the goal state is compared to the initial state and a set of propositions that differ in truth value between the two states are found.
Reference: [Pearl, 1988] <author> Judea Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <publisher> Morgan Kauffman, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: But I think it's clear that we need more quantitative statistical reasoning in order to reason effectively about plans. One of the most promising recent developments in uncertain inference has been the study of Bayesian networks <ref> [Pearl, 1988] </ref>. Recall that the nodes of a Bayesian network represent variables under analysis and the links represent conditional dependence. Importantly, the absence of a link between two nodes implies their conditional independence. Belief in propositions can then be effectively computed given appropriate prior distributions and observations.
Reference: [Pednault, 1986] <author> Edwin P.D. Pednault, </author> <title> "Formulating multi-agent, dynamic-world problems in the classical planning framework," in M.P. </title> <editor> Georgeff and A.L. Lansky, editors, </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <pages> pages 47-82, </pages> <address> Los Altos, CA, </address> <month> 30 June-2 July </month> <year> 1986. </year> <note> Morgan Kaufmann. Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 675-710. </pages>
Reference-contexts: It may be true that we could characterize all interactions between simultaneous actions in terms of events in this way. Ultimately, however, this would require reducing everything to events characterizing physical force equations. In fact, this is what is suggested in many papers addressing simultaneous action (e.g., <ref> [Pednault, 1986] </ref>). We do not believe this is appropriate for a commonsense theory of action, as it requires agents to understand the physics of the world at a fairly deep level in order to understand simple everyday interactions. <p> As mentioned earlier, STRIPS-based systems (e.g., [Tate, 1977; Vere, 1983; Wilkins, 1988]) only allow simultaneity when the actions are independent. A few others (e.g., <ref> [Pednault, 1986] </ref>) allow for synergistic effects cast in terms of domain constraints on states (e.g., in any state s, if the left side of the piano is lifted, and the right side is lifted, then the piano is lifted).
Reference: [Pelavin, 1991] <author> Richard N. Pelavin, </author> <title> "Planning With Simultaneous Actions and External Events," </title> <booktitle> in Reasoning about Plans, </booktitle> <pages> pages 127-212. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference: [Penberthy and Weld, 1992] <author> J. Scott Penberthy and Daniel S. Weld, "UCPOP: </author> <title> A sound, complete, partial order planner for ADL," </title> <editor> in Bernard Nebel, Charles Rich, and William Swartout, editors, </editor> <booktitle> Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning (KR92), </booktitle> <pages> pages 103-114, </pages> <address> Boston, MA, 25-29 October 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This section proceeds as follows. First, I will review the definitions of the SNLP model of planning [McAllester and Rosenblitt, 1991]. This model marked the beginning of a rekindling of interest in the formal foundations of STRIPS planning. It has since led to work such as the UCPOP model <ref> [Penberthy and Weld, 1992] </ref> and the BURIDAN planner [Kushmerick et al., 1994]. I then reconstruct the SNLP model as a defeasible knowledge base with facts and rules and show how SNLP plans correspond to arguments satisfying certain criteria.
Reference: [Pinto, 1994] <author> Javier Pinto, </author> <title> Temporal Reasoning in the Situation Calculus, </title> <type> PhD thesis, </type> <institution> University of Toronto, Toronto, </institution> <address> Ontario, Canada, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: As a result, he can define notions such as a successful action attempt, and explicitly reason about an agent's actions and what events they will cause. His representation of time has many similarities to the work that extends the situation calculus with a time line <ref> [Pinto, 1994] </ref>, and he explores the consequences of adding explicit time to such a model in depth. A significant difference between our approaches is that we use an interval-based logic, while McDermott uses a continuous point-based model. <p> With this, one can introduce an Occurs predicate that asserts that a particular action occurs at a specific time and that is defined by an axiom that quantifies over all situations at that time (e.g., <ref> [Pinto, 1994; Miller and Shanahan, 1994] </ref>). This development moves the formalism closer to what we are proposing. Ultimately, the main difference between our approach and these extended situation calculus representations with explicit time will probably be one of approach.
Reference: [Poesio, 1993a] <author> Massimo Poesio, </author> <title> "Assigning a Semantic Scope to Operators," </title> <booktitle> in Proceedings of the Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Columbus, OH, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This underspecified logical form representing the content of the utterance is then processed by a scope and dereferencing module that resolves contextually-dependent expressions <ref> [Poesio, 1993b; Poesio, 1993a] </ref>. This involves scoping operators to their proper position and resolving anaphoric references based on discourse context. The approach is based on a DRT-like representation named Conversation Representation Theory (CRT) that extends Episodic Logic to better describe the context of interpretation of an utterance [Poesio, 1994].
Reference: [Poesio, 1993b] <author> Massimo Poesio, </author> <title> "A Situation-Theoretic Formalization of Definite Description Interpretation in Plan Elaboration Dialogues," </title> <editor> in P. Aczel, D. Israel, Y. Katagiri, and S. Peters, editors, </editor> <title> Situations Theory and its Applications, </title> <journal> vol.3, </journal> <volume> chapter 12, </volume> <pages> pages 343-378. </pages> <publisher> CSLI, Stanford, </publisher> <year> 1993. </year>
Reference-contexts: This underspecified logical form representing the content of the utterance is then processed by a scope and dereferencing module that resolves contextually-dependent expressions <ref> [Poesio, 1993b; Poesio, 1993a] </ref>. This involves scoping operators to their proper position and resolving anaphoric references based on discourse context. The approach is based on a DRT-like representation named Conversation Representation Theory (CRT) that extends Episodic Logic to better describe the context of interpretation of an utterance [Poesio, 1994].
Reference: [Poesio, 1994] <author> Massimo Poesio, </author> <title> Discourse Interpretation and the Scope of Operators, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> June </month> <year> 1994. </year> <note> Available as Technical Report 518. </note>
Reference-contexts: This involves scoping operators to their proper position and resolving anaphoric references based on discourse context. The approach is based on a DRT-like representation named Conversation Representation Theory (CRT) that extends Episodic Logic to better describe the context of interpretation of an utterance <ref> [Poesio, 1994] </ref>. According to CRT, what takes place after an utterance is produced is best seen as a process during which alternative hypotheses about the change in the discourse situation brought about by that utterance are obtained.
Reference: [Poesio et al., 1994] <author> Massimo Poesio, George Ferguson, Peter Heeman, Chung Hee Hwang, David R. Traum, James F. Allen, Nathaniel G. Martin, and Lenhart K. Schubert, </author> <title> "Knowledge Representation in the TRAINS System". </title> <booktitle> To be presented at AAAI 1994 Fall Symposium on Knowledge Representation for Natural Language Processing in Implemented Systems, </booktitle> <month> November </month> <year> 1994. </year> <month> 171 </month>
Reference-contexts: Further discussion of the use of multiple knowledge representations in the TRAINS system can be found in <ref> [Poesio et al., 1994] </ref>. In any case, the Episodic Logic logical form is converted to a speech act representation based on events, which then undergoes Conversation Act analysis to determine the roles the utterance may play in the conversation [Traum and Hinkelman, 1992].
Reference: [Pollack, 1986a] <author> Martha E. Pollack, </author> <title> Inferring domain plans in question-answering, </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: The use of plans in collaborative behavior is the basis of the SharedPlan model [Grosz and Sidner, 1990] that extends the notion of plans as structured sets of beliefs and intentions to situations where several agents are collaborating. In its original formulation, the domain plan (termed a "recipe" in <ref> [Pollack, 1986a] </ref>) was restricted to very simple sets of events related via event generation. It is clear that this is insufficient in general, especially when the subject under discussion is a plan, as it is in collaborative problem solving and mixed-initiative planning.
Reference: [Pollack, 1986b] <author> Martha E. Pollack, </author> <title> "A model of plan inference that distinguishes between the beliefs of actors and observers," </title> <booktitle> in Proceedings of the Twenty-Fourth Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 207-214, </pages> <address> New York, NY, </address> <month> 10-13 June </month> <year> 1986. </year> <institution> Columbia University. </institution>
Reference: [Pollack, 1990] <author> Martha E. Pollack, </author> <title> "Plans as complex mental attitudes," </title> <editor> in P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference: [Pollack, 1992] <author> Martha E. Pollack, </author> <title> "The uses of plans," </title> <journal> Artificial Intelligence, </journal> <volume> 57, </volume> <booktitle> 1992. Revised transcription of the Computers and Thought Award lecture delivered at the Twelth International Joint Conference on Artifical Intelligence (IJCAI-91), </booktitle> <month> August 26, </month> <year> 1991, </year> <title> in Sydney, </title> <address> Australia. </address>
Reference-contexts: These viewpoints are certainly not incompatible and, given the other similarities, can probably be combined in a straightforward manner. I would like to also note here Pollack's excellent IJCAI Computers and Thought Award lecture on the uses of plans <ref> [Pollack, 1992] </ref>. Many of the motivations I have given for my work are well laid out there, including the critical observation that, the history of AI notwithstanding, "agents use plans not only to guide action, but also to control reasoning and enable inter-agent coordination" (page 44). <p> I do think that it is more important to set one's sights high and aim for a natural, comprehensive representation, as I have done, than it is to artificially restrict the data under consideration in order to prove theorems. Or, to quote Martha Pollack, "theories before theorems." <ref> [Pollack, 1992, page 65] </ref> The next step is to build systems based on the theories and take what lessons we can from them in refining the theories, which is the subject of the next chapter. 113 4 The TRAINS-93 Domain Plan Reasoner This chapter describes the TRAINS-93 domain plan reasoner, which
Reference: [Pollock, 1987] <author> John L. Pollock, </author> <title> "Defeasible reasoning," </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 481-518, </pages> <year> 1987. </year>
Reference: [Pollock, 1991] <author> John L. Pollock, </author> <title> "Self-defeating arguments," </title> <journal> Minds and Machines, </journal> <volume> 1 </volume> <pages> 367-392, </pages> <year> 1991. </year>
Reference-contexts: We would be left with the result that both A and B are undefeated, despite their defeating each other! This phenomenon has been termed collective defeat by Pollock <ref> [Pollock, 1991] </ref>, and requires that we amend the definition of undefeated arguments as follows: Principle of Collective Defeat (Pollock) If is a set of arguments such that (1) each argument in is defeated by some other argument in ; and (2) no argument in is defeated by any argument not in <p> Pollock [1992a], defines warrant in terms of ultimately undefeated conclusions, and takes into account such phenomena as collective defeat and the related issue of self-defeat (see also <ref> [Pollock, 1991] </ref>). He then considers the approximation process of justifying conclusions and proves the desired relationship to warrant. I am not going to pursue these questions here. In the first place, it's not clear how much more I can say about warrant mathematically beyond the work cited above.
Reference: [Pollock, 1992a] <author> John L. Pollock, </author> <title> "How to reason defeasibly," </title> <journal> Artificial Intelligence, </journal> <volume> 57 </volume> <pages> 1-42, </pages> <year> 1992. </year>
Reference: [Pollock, 1992b] <author> John L. Pollock, </author> <title> "New foundations for practical reasoning," </title> <journal> Minds and Machines, </journal> <volume> 2 </volume> <pages> 113-144, </pages> <year> 1992. </year>
Reference: [Poole, 1988] <author> D. Poole, </author> <title> "A logical framework for default reasoning," </title> <journal> Artificial Intelligence, </journal> <volume> 36(1) </volume> <pages> 27-48, </pages> <year> 1988. </year>
Reference-contexts: The other close cousin of argument systems among the nonmonotonic reasoning approaches is the theory formation approach to defeasible reasoning <ref> [Poole et al., 1987; Poole, 1988] </ref>. Like my argument-based approach, the emphasis is not on model-theoretic characterizations of desirable conclusions, but rather on the process of finding such conclusions. <p> The emphasis on incrementality, however, is one of the features of argument systems and not of nonmonotonic logics by themselves. I noted previously (Section 3.2.4) the intellectual closeness of the argument-based approach to defeasible reasoning and the approach based on theory formation <ref> [Poole et al., 1987; Poole, 1988] </ref>. The application of theory formation to planning in particular is presented in [Goebel and Goodwin, 1987].
Reference: [Poole et al., 1987] <author> D.L. Poole, R. Goebel, and R. Aleliunas, </author> <title> "Theorist: a logical reasoning system for defaults and diagnosis," in N.J. </title> <editor> Cercone and G. McCalla, editors, </editor> <booktitle> The Knowledge Frontier: Essays in the Representation of Knowledge, </booktitle> <pages> pages 331-352. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The other close cousin of argument systems among the nonmonotonic reasoning approaches is the theory formation approach to defeasible reasoning <ref> [Poole et al., 1987; Poole, 1988] </ref>. Like my argument-based approach, the emphasis is not on model-theoretic characterizations of desirable conclusions, but rather on the process of finding such conclusions. <p> The emphasis on incrementality, however, is one of the features of argument systems and not of nonmonotonic logics by themselves. I noted previously (Section 3.2.4) the intellectual closeness of the argument-based approach to defeasible reasoning and the approach based on theory formation <ref> [Poole et al., 1987; Poole, 1988] </ref>. The application of theory formation to planning in particular is presented in [Goebel and Goodwin, 1987].
Reference: [Ramshaw, 1991] <author> Lance A. Ramshaw, </author> <title> "A three-level model for plan exploration," </title> <booktitle> in Proceedings of the Twenty-Ninth Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Berkeley, CA, </address> <month> 18-21 June </month> <year> 1991. </year> <institution> University of California. </institution>
Reference: [Reiter, 1980] <author> R. Reiter, </author> <title> "A logic for default reasoning," </title> <journal> Artificial Intelligence, </journal> <volume> 13(1,2):81-132, </volume> <year> 1980. </year>
Reference-contexts: He refers to this form of reasoning as direct inference, since arguments are explicit objects of the theory, as opposed to indirect model-theoretic approaches such as circumscription [McCarthy, 1980] or indirect modal approaches such as default logic <ref> [Reiter, 1980] </ref> or autoepistemic logic [Moore, 1985]. Konolige cites the following points in favour of direct over indirect inference (to each of which I have added some further comments): 1. Domain knowledge often includes information about the way defeasible arguments in that domain are related.
Reference: [Reiter, 1992] <author> Raymond Reiter, </author> <title> "The projection problem in the situation calculus: A soundness and completeness result, with an application to database updates," </title> <booktitle> in Proceedings of the First International Conference on AI Planning Systems, </booktitle> <pages> pages 198-203, </pages> <address> College Park, MD, 15-17 June 1992. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 172 </pages>
Reference-contexts: In addition, just because the theory is based on these axioms doesn't mean that a programmer would have to write them all down. In some cases, the axioms can be automatically computed <ref> [Reiter, 1992] </ref> or generated on the fly. In an actual application, we can take advantage of such methods whenever possible.
Reference: [Rescher, 1976] <author> Nicholas Rescher, </author> <title> Plausible Reasoning, </title> <publisher> van Gorcum Publishing, </publisher> <address> Ams-terdam, The Netherlands, </address> <year> 1976. </year>
Reference: [Rescher, 1977] <author> Nicholas Rescher, </author> <month> Dialectics, </month> <institution> State University of New York Press, Albany, </institution> <address> NY, </address> <year> 1977. </year>
Reference: [Sacerdoti, 1975] <author> Earl D. Sacerdoti, </author> <title> "The nonlinear nature of plans," </title> <booktitle> in Proceedings of the Fourth International Joint Conference on Artificial Intelligence (IJCAI-75), </booktitle> <pages> pages 206-214, </pages> <address> Tbilisi, Georgia, USSR, </address> <month> 3-8 September </month> <year> 1975. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 162-170. </pages>
Reference: [Sacerdoti, 1977] <author> E.D. Sacerdoti, </author> <title> A Structure for Plans and Behaviour, </title> <publisher> Elsevier, North-Holland, </publisher> <address> New York, NY, </address> <year> 1977. </year>
Reference-contexts: Much of this remains for future work on mixed-initiative planning systems, although Chapter 4 describes our implemented plan reasoning system based on arguments but using heuristic search. I think a good place to start furthering the connection between defeasible reasoning and planning would be a reconstruction of Sacerdoti's "critics" <ref> [Sacerdoti, 1977] </ref> (or their derivatives) in terms of argument preference criteria.
Reference: [Sandewall, 1994] <author> Erik Sandewall, </author> <title> Features and Fluents, </title> <publisher> Oxford University Press, </publisher> <year> 1994. </year>
Reference-contexts: (ETRY) and event generation (EGEN) axioms. 2.3.3 The Sandewall Test Suite for Reasoning about Action and Change By way of illustrating the application of the logic and the explanation closure technique, we now present formalizations of some of the standard problems from the literature on reasoning about action gathered in <ref> [Sandewall, 1994] </ref>. These are mostly variants of the Yale Shooting Problem [Hanks and McDermott, 1986], a basic AI test case for reasoning about action. <p> This would allow one to shoot things that are already dead, for example. In the remainder of this section, we use these axioms for several of the core problems of the Sandewall test suite <ref> [Sandewall, 1994] </ref>. Each of these problems deals with prediction from a given situation, sometimes predicting previous facts (retrodicting). For each problem, we provide an axiomatization of the problem description and a proof (or proof sketch) of the conclusion. <p> The second issue is what mechanism is used to make the assumptions. There are two main approaches here: explicitly adding axioms that encode the assumptions (e.g., [Green, 1969; Schubert, 1990]) or using a nonmonotonic model theory that defines a new notion of entailment that includes the assumptions (e.g., <ref> [McCarthy, 1980; Shoham, 1988; Baker, 1991; Sandewall, 1994] </ref>). Of course, the work on circumscription shows that model-theoretic techniques always have an equivalent axiomatic formulation, although it may require going beyond standard first-order logic. This equivalence suggests that there is really a continuum of approaches here. Everyone must make assumptions.
Reference: [Schubert, 1990] <author> Lenhart Schubert, </author> <title> "Monotonic Solution of The Frame Problem in The Situation Calculus: An Efficient Method for Worlds with Fully Specified Actions," </title> <editor> in Henry E. Kyburg, Jr., Ronald P. Loui, and Greg N. Carlson, editors, </editor> <booktitle> Knowledge Representation and Defeasible Reasoning, </booktitle> <pages> pages 23-68. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Dordrecht, The Netherlands, </address> <year> 1990. </year> <note> Also available as University of Rochester TR 306, </note> <month> August </month> <year> 1989. </year>
Reference-contexts: In proving this, the situation is constructed by action composition, and thus the desired sequence of actions (the plan) can be extracted from the proof. As others have pointed out (e.g., <ref> [Schubert, 1990] </ref>), most of the criticisms about the expressibility of the situation calculus concern its use when the only actions allowed are primitive, non-compositional ones, as were often used in planning examples. <p> In this way, the situation calculus defines a point-based branching time 27 model. A duration function on actions can be defined that allows one to compute the time of the resulting situation given the initial situation <ref> [Schubert, 1990; Gelfond et al., 1991] </ref>. Without the introduction of a time line, however, the range of temporal reasoning that can be performed is severely limited. <p> In addition, as we show in the subsequent sections, this approach naturally handles a wide range of more complex problems. The second issue is what mechanism is used to make the assumptions. There are two main approaches here: explicitly adding axioms that encode the assumptions (e.g., <ref> [Green, 1969; Schubert, 1990] </ref>) or using a nonmonotonic model theory that defines a new notion of entailment that includes the assumptions (e.g., [McCarthy, 1980; Shoham, 1988; Baker, 1991; Sandewall, 1994]). <p> The situation calculus shows more promise with the introduction of action composition operators. For instance, given two actions a 1 and a 2 , then the action a 1 + a 2 is the action of performing the two simultaneously (e.g., <ref> [Gelfond et al., 1991; Schubert, 1990] </ref>). Explicit axioms can then be given for these complex actions, and mechanisms can be introduced to automatically derive such axioms from the individual actions if they are independent of each other (e.g., [Lin and Shoham, 1992]). <p> Pelavin [1991] contains an extensive analysis of the problems that arise in general with simultaneous interacting actions. As noted in Section 2.2.5, some work has explored the possibility of allowing a duration for each action <ref> [Schubert, 1990; Gelfond et al., 1991] </ref>. Then the duration of a sequence of actions would simply be the sum of the individual action durations. But there is little point to doing this unless one allows these extended actions to overlap with other actions and external events.
Reference: [Schubert, 1992] <author> Lenhart K. Schubert, </author> <title> "Explanation Closure, Action Closure, and the Sandewall Test Suite for Reasoning about Change," </title> <type> Technical Report 440, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> October </month> <year> 1992. </year>
Reference: [Searle, 1969] <author> John R. Searle, </author> <title> Speech Acts: An essay in the philosophy of language, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1969. </year>
Reference: [Shanahan, 1989] <author> Murray Shanahan, </author> <title> "Prediction is deduction but explanation is abduction," </title> <editor> in Natesa Sastri Sridharan, editor, </editor> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 1055-1060, </pages> <address> Detroit, MI, </address> <month> 20-25 August </month> <year> 1989. </year>
Reference-contexts: With this addition, the new prediction model validates the proposed search strategies. Similar methods using the event calculus are proposed in <ref> [Eshghi, 1988; Shanahan, 1989; Kowalski, 1992] </ref>. 2.3.2 Frame Axioms and Explanation Closure The problem with the above approach is that the STRIPS assumptions do not hold in most realistic situations that one needs to reason about.
Reference: [Shanahan, 1990] <author> Murray Shanahan, </author> <title> "Representing continuous change in the situation calculus," </title> <editor> in Luigia Carlucci Aiello, editor, </editor> <booktitle> Proceedings of the European Conference on Artificial Intelligence (ECAI-90), </booktitle> <pages> pages 598-603, </pages> <address> Stockholm, Sweden, 6-10 August 1990. </address> <publisher> Pitman Publishing Co. </publisher>
Reference-contexts: These intervals are independent of each other, and so we can reason about how long P remains true without worrying about how long Q holds. Of course, if one introduces a time line, then more complicated scenarios can be represented. In fact, in some approaches (e.g., <ref> [Shanahan, 1990] </ref>) even continuous change has been represented. The primary mechanism that enables this, however, is the exploitation of the mapping from situations to times.
Reference: [Shoham, 1987] <author> Yoav Shoham, </author> <title> "Temporal Logics in AI: Semantical and ontological considerations," </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 89-104, </pages> <year> 1987. </year>
Reference: [Shoham, 1988] <author> Yoav Shoham, </author> <title> Reasoning about change: Time and Causation from the Standpoint of Artificial Intelligence, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: There are several characteristics of propositions that allow them to be broadly classified based on their inferential properties. These distinctions were originally proposed by Vendler [1967], and variants have been proposed under various names throughout linguistics, philosophy, and artificial intelligence ever since (e.g., <ref> [Mourelatos, 1978; Allen, 1984; Dowty, 1986; Shoham, 1988] </ref>). For the most part we will not be concerned with all the distinctions considered by these authors. However one important property mentioned previously is homogeneity. <p> A significant difference between our approaches is that we use an interval-based logic, while McDermott uses a continuous point-based model. These differences have been discussed in detail elsewhere (e.g., <ref> [van Benthem, 1983; Allen, 1984; Shoham, 1988] </ref>). 2.3 Reasoning about Action in Simple Domains This section discusses prediction in theories of action, in particular the frame problem, and describes our approach based on explanation closure. <p> There are several ways to try to overcome this problem. Many researchers abandon frame axioms altogether, and have built models that use persistence or inertia assumptions (e.g., <ref> [Lifschitz, 1987; Shoham, 1988] </ref>). These approaches assume that all changes caused by an action are specified, and every property not asserted to change does not change. <p> Rather, the representation only makes sense when these assumptions are made. The other major approach focuses on minimizing property change, with additional constraints based on the temporal ordering of properties (e.g., <ref> [Shoham, 1988; Kautz, 1986] </ref>) or minimizing causal relationships (e.g., [Lifschitz, 1987]). Sandewall [1994] examines the advantages and limitations of each of these approaches in detail. <p> The second issue is what mechanism is used to make the assumptions. There are two main approaches here: explicitly adding axioms that encode the assumptions (e.g., [Green, 1969; Schubert, 1990]) or using a nonmonotonic model theory that defines a new notion of entailment that includes the assumptions (e.g., <ref> [McCarthy, 1980; Shoham, 1988; Baker, 1991; Sandewall, 1994] </ref>). Of course, the work on circumscription shows that model-theoretic techniques always have an equivalent axiomatic formulation, although it may require going beyond standard first-order logic. This equivalence suggests that there is really a continuum of approaches here. Everyone must make assumptions. <p> Such an assumption places strong constraints on what events can or cannot occur over the appropriate interval, as we desire. These semantics of the N C assumption are given directly in the temporal logic axioms, rather than being defined in a nonmonotonic semantic theory (e.g., <ref> [Shoham, 1988] </ref>) or via a procedural technique (e.g., TMM [Dean and McDermott, 1987]). 3.3.3 Formal Properties of Plans as Arguments We are now ready to define various properties of plans-as-arguments based on the de-feasible causal rules and consider the relationships between them.
Reference: [Simari and Loui, 1992] <author> G.R. Simari and R.P. Loui, </author> <title> "A mathematical treatment of de-feasible reasoning and its implementation," </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 53(2-3), </pages> <month> February </month> <year> 1992. </year> <month> 173 </month>
Reference-contexts: The idea is that in the limit the justified conclusions converge to the warranted ones. Loui [1987] defines warrant (which he calls justification), but doesn't consider the process of constructing the arguments explicitly (although he does so elsewhere <ref> [Simari and Loui, 1992] </ref>). Pollock [1992a], defines warrant in terms of ultimately undefeated conclusions, and takes into account such phenomena as collective defeat and the related issue of self-defeat (see also [Pollock, 1991]). He then considers the approximation process of justifying conclusions and proves the desired relationship to warrant.
Reference: [Simon, 1977] <author> Herbert A. Simon, </author> <title> Models of Discovery, </title> <publisher> Reidel, </publisher> <address> Dordrecht, </address> <year> 1977. </year>
Reference: [Sprites et al., 1990] <author> P. Sprites, G. Glymour, and R. Scheines, </author> <title> "Causality from probability," </title> <booktitle> in Evolving Knowledge in Natural Science and Artificial Intelligence, </booktitle> <pages> pages 181-199. </pages> <year> 1990. </year>
Reference: [Tate, 1977] <author> Austin Tate, </author> <title> "Generating project networks," </title> <booktitle> in Proceedings of the Fifth International Joint Conference on Artificial Intelligence (IJCAI-77), </booktitle> <pages> pages 888-889, </pages> <address> Cambridge, MA, </address> <year> 1977. </year> <institution> MIT. </institution> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 291-296. </pages>
Reference-contexts: Thus, to capture all this information in a single framework, the engine running should be formalized by an event. 57 2.5.4 Discussion and Related Work For the most part, treatments of simultaneous actions in the literature are limited. As mentioned earlier, STRIPS-based systems (e.g., <ref> [Tate, 1977; Vere, 1983; Wilkins, 1988] </ref>) only allow simultaneity when the actions are independent. <p> In subsequent discussion, McAllester and Rosenblitt state that considering operators that add P to be threats is only necessary for systematicity, and that in practice only operators that delete P need to be considered (as in NONLIN <ref> [Tate, 1977] </ref>). Again, I will ignore the mapping from steps to operators and talk about a step being a threat if its operator is a threat.
Reference: [Toulmin, 1958] <author> Stephen Toulmin, </author> <title> The Uses of Argument, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1958. </year>
Reference: [Traum, 1994] <author> David R. Traum, </author> <title> A Computational Theory of Grounding in Natural Language Conversation, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> July </month> <year> 1994. </year> <note> To appear as a Technical Report. </note>
Reference-contexts: Ramshaw [1991] proposes a similar three-layer model. My work on plans-as-arguments has so far concentrated on only the domain level, although the relationship between plans and discourse actions has been explored in the context of the TRAINS project described in the next chapter (see also <ref> [Traum and Allen, 1994; Traum, 1994; Ferguson and Allen, 1993] </ref>). As I noted previously, arguments provide a framework for recipes (plans) that is suitable for both the linguistically complex discourse phenomena and the complicated domain-level reasoning. <p> The set of candidate acts is then passed to the dialogue manager that determines which of them are appropriate given the current context and acts upon those <ref> [Traum, 1994; Traum and Allen, 1994] </ref>. The dialogue manager maintains belief contexts for the system and manager reflecting its knowledge of the state of the dialogue. It also maintains sets of goals, intentions, and obligations, which form the basis for a reactive model of system 116 behaviour.
Reference: [Traum and Allen, 1994] <author> David R. Traum and James F. Allen, </author> <title> "Discourse Obligations in Dialogue Processing," </title> <booktitle> in Proceedings of the Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1994. </year>
Reference-contexts: Ramshaw [1991] proposes a similar three-layer model. My work on plans-as-arguments has so far concentrated on only the domain level, although the relationship between plans and discourse actions has been explored in the context of the TRAINS project described in the next chapter (see also <ref> [Traum and Allen, 1994; Traum, 1994; Ferguson and Allen, 1993] </ref>). As I noted previously, arguments provide a framework for recipes (plans) that is suitable for both the linguistically complex discourse phenomena and the complicated domain-level reasoning. <p> The set of candidate acts is then passed to the dialogue manager that determines which of them are appropriate given the current context and acts upon those <ref> [Traum, 1994; Traum and Allen, 1994] </ref>. The dialogue manager maintains belief contexts for the system and manager reflecting its knowledge of the state of the dialogue. It also maintains sets of goals, intentions, and obligations, which form the basis for a reactive model of system 116 behaviour. <p> In the current system, the dialogue manager determines when to call elaborate, based on turn-taking and the discourse state (cf. <ref> [Traum and Allen, 1994] </ref>). An example of this is the TRAINS-93 sample dialogue presented in the next section. This led to a primary emphasis on the development of a flexible and powerful incorporation component to the detriment of the elaboration component.
Reference: [Traum and Hinkelman, 1992] <author> David R. Traum and Elizabeth A. Hinkelman, </author> <title> "Conversation Acts in Task-oriented Spoken Dialogue," </title> <journal> Computational Intelligence, </journal> <volume> 8(3) </volume> <pages> 575-599, </pages> <year> 1992. </year> <note> Also available as University of Rochester TR 425. </note>
Reference-contexts: In any case, the Episodic Logic logical form is converted to a speech act representation based on events, which then undergoes Conversation Act analysis to determine the roles the utterance may play in the conversation <ref> [Traum and Hinkelman, 1992] </ref>. The set of candidate acts is then passed to the dialogue manager that determines which of them are appropriate given the current context and acts upon those [Traum, 1994; Traum and Allen, 1994].
Reference: [van Beek et al., 1993] <author> Peter van Beek, Robin Cohen, and Ken Schmidt, </author> <title> "From plan critquing to clarification dialogues for cooperative response generation," </title> <journal> Computational Intelligence, </journal> <volume> 9(2) </volume> <pages> 132-154, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: An interesting application of Kautz's approach in an interactive planning system that does consider these issues is presented in <ref> [van Beek et al., 1993] </ref>. 3.5.2 Planning Moving from nonmonotonic reasoning in the abstract, the next related area is the large body of work in AI planning.
Reference: [van Benthem, 1983] <editor> Johan F. A. K. van Benthem, </editor> <booktitle> The Logic of Time, </booktitle> <address> D. </address> <publisher> Reidel and Kluwer, </publisher> <address> Dordrecht and Boston, </address> <year> 1983. </year>
Reference-contexts: A significant difference between our approaches is that we use an interval-based logic, while McDermott uses a continuous point-based model. These differences have been discussed in detail elsewhere (e.g., <ref> [van Benthem, 1983; Allen, 1984; Shoham, 1988] </ref>). 2.3 Reasoning about Action in Simple Domains This section discusses prediction in theories of action, in particular the frame problem, and describes our approach based on explanation closure.
Reference: [Vendler, 1967] <editor> Zeno Vendler, </editor> <booktitle> Linguistics in Philosophy, </booktitle> <publisher> Cornell University Press, </publisher> <address> New York, </address> <year> 1967. </year>
Reference-contexts: These issues have been studied extensively in work on the semantics of natural language sentences. While there are many proposals, 8 everyone agrees on a few basic distinctions (e.g., <ref> [Vendler, 1967; Mourelatos, 1978; Dowty, 1986] </ref>).
Reference: [Vere, 1983] <author> Stephen A. Vere, </author> <title> "Planning in time: Windows and durations for activities and goals," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(3) </volume> <pages> 246-267, </pages> <year> 1983. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 297-318. </pages>
Reference-contexts: Thus, to capture all this information in a single framework, the engine running should be formalized by an event. 57 2.5.4 Discussion and Related Work For the most part, treatments of simultaneous actions in the literature are limited. As mentioned earlier, STRIPS-based systems (e.g., <ref> [Tate, 1977; Vere, 1983; Wilkins, 1988] </ref>) only allow simultaneity when the actions are independent.
Reference: [Vilain and Kautz, 1986] <author> Marc Vilain and Henry Kautz, </author> <title> "Constraint Propagation Algorithms for Temporal Reasoning," </title> <booktitle> in Proceedings of the Fifth National Conference on Artificial Intelligence (AAAI-86), </booktitle> <pages> pages 377-382, </pages> <address> Philadelphia, PA, </address> <month> 11-15 August </month> <year> 1986. </year> <institution> University of Pennsylvania. </institution>
Reference-contexts: We write this as "i ./ j" and define it by i ./ j i : j _ j : i: The computational properties of the interval calculus and algorithms for maintaining networks of temporal constraints are presented in <ref> [Allen, 1983a; Vilain and Kautz, 1986; Vilain et al., 1990] </ref>. A period can be classified by the relationships that it can have with other periods.
Reference: [Vilain et al., 1990] <author> Marc Vilain, Henry Kautz, and Peter van Beek, </author> <title> "Constraint propagation algorithms for temporal reasoning: A revised report," </title> <booktitle> in Readings in Qualitative Reasoning about Physical Systems, </booktitle> <pages> pages 373-381. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <month> 174 </month>
Reference-contexts: We write this as "i ./ j" and define it by i ./ j i : j _ j : i: The computational properties of the interval calculus and algorithms for maintaining networks of temporal constraints are presented in <ref> [Allen, 1983a; Vilain and Kautz, 1986; Vilain et al., 1990] </ref>. A period can be classified by the relationships that it can have with other periods.
Reference: [Waldinger, 1977] <author> R. Waldinger, </author> <title> "Achieving several goals simultaneously," </title> <booktitle> in Machine Intelligence, </booktitle> <volume> volume 8. </volume> <publisher> Ellis Horwood, </publisher> <address> Chichester, England, </address> <year> 1977. </year> <note> Also in Readings in Planning, </note> <editor> J. Allen, J. Hendler, and A. Tate (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 118-139. </pages>
Reference-contexts: These systems, however, use the notion of goal protection <ref> [Waldinger, 1977] </ref> rather than any explicit forward prediction at all. The additional complication is that actions are partially ordered, and so systems must distinguish between predictions that are necessarily true (in any allowable action ordering) or only possibly true (in some allowable action orderings).
Reference: [Walton, 1992] <author> Douglas N. Walton, </author> <title> Plausible Argument in Everyday Conversation, </title> <institution> State University of New York Press, Albany, </institution> <address> NY, </address> <year> 1992. </year>
Reference: [Wilkins, 1988] <author> David E. Wilkins, </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Thus, to capture all this information in a single framework, the engine running should be formalized by an event. 57 2.5.4 Discussion and Related Work For the most part, treatments of simultaneous actions in the literature are limited. As mentioned earlier, STRIPS-based systems (e.g., <ref> [Tate, 1977; Vere, 1983; Wilkins, 1988] </ref>) only allow simultaneity when the actions are independent.
Reference: [Yampratoom, 1994] <author> Ed Yampratoom, </author> <title> "Using Simulation-based Projection to Plan in an Uncertain and Temporally Complex World," </title> <type> Technical Report 531, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: This leads to problems in effectively determining whether preconditions hold at required times, although the assumption-based unification covers some of the cases more traditionally handled by projection. Work is currently underway on the construction of a probabilistic projection module based on the interval temporal logic <ref> [Yampratoom, 1994] </ref>. This would support plan projection as well as stochastic simulation of plan execution to gather statistics for future decision-making.
Reference: [Yang and Tenenberg, 1990] <author> Qiang Yang and Josh Tenenberg, "ABTWEAK: </author> <title> Abstracting a non-linear, least commitment planner," </title> <booktitle> in Proceedings of the Eighth National Conference on Artificial Int elligence (AAAI-90), </booktitle> <pages> pages 204-209, </pages> <address> Boston, MA, </address> <month> 29 July-3 August </month> <year> 1990. </year> <month> 175 </month>
Reference-contexts: As well, the fact that partial plans can arise naturally in mixed-initiative planning and be reasoned about without reference to their completions is an important aspect missed by the TWEAK model. There has been work on partial STRIPS plans in the context of abstraction <ref> [Yang and Tenenberg, 1990; Knoblock, 1992] </ref>, but it is not clear that abstraction as developed in ABSTRIPS is the same thing as the kind of incompleteness found in argumentation. 101 Finally, Ginsberg [1994a; 1994b] has recently argued that planners, instead of being guaranteed correct and complete, should be approximate, a term
References-found: 160

