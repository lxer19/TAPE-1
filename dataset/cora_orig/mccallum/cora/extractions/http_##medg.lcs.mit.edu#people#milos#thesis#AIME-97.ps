URL: http://medg.lcs.mit.edu/people/milos/thesis/AIME-97.ps
Refering-URL: http://medg.lcs.mit.edu/people/milos/thesis/
Root-URL: 
Email: E-mail: milos@medg.lcs.mit.edu  
Title: Dynamic Decision Making in Stochastic Partially Observable Medical Domains: Ischemic Heart Disease Example.  
Author: Milos Hauskrecht 
Address: NE43-421, 545 Technology Square, Cambridge, MA 02139  
Affiliation: MIT Lab for Computer Science,  
Abstract: The focus of this paper is the framework of partially observable Markov decision processes (POMDPs) and its role in modeling and solving complex dynamic decision problems in stochastic and partially observable medical domains. The paper summarizes some of the basic features of the POMDP framework and explores its potential in solving the problem of the management of the patient with chronic ischemic heart disease. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> K.J. Astrom. </author> <title> Optimal control of Markov decision processes with incomplete state estimation. </title> <journal> Journal of Mathematical Analysis and Applications, </journal> <volume> 10, </volume> <pages> pp. 174-205, </pages> <year> 1965 </year>
Reference-contexts: In such cases careful evaluation of costs and benefits associated with both treatment and investigative actions with regard to the global objectives is necessary. A framework that allows one to model both sources of uncertainty is the partially observable Markov decision process <ref> [1] </ref> [9] [7] [2] [3]. In the following I will summarize the POMDP framework and illustrate its potential on the problem of the management of patients with chronic ischemic heart disease.
Reference: 2. <author> A.R. Cassandra. </author> <title> Optimal policies for partially observable Markov decision processes. Brown Uni versity, </title> <type> Technical report CS-94-14, </type> <year> 1994. </year>
Reference-contexts: In such cases careful evaluation of costs and benefits associated with both treatment and investigative actions with regard to the global objectives is necessary. A framework that allows one to model both sources of uncertainty is the partially observable Markov decision process [1] [9] [7] <ref> [2] </ref> [3]. In the following I will summarize the POMDP framework and illustrate its potential on the problem of the management of patients with chronic ischemic heart disease. <p> An even worse situation emerges when one is required to find the solution for all initial information states | the so called policy problem. Although exact methods for solving both decision and policy problems are available for standard POMDP models [9] <ref> [2] </ref> [3], the computational complexity of such methods leads to the exploration of various approximations that allow good solutions with less computation. Efficient approximation methods are mostly based on the idea of approximate dynamic programming (for the finite horizon case) and approximate value iteration (for the infinite discounted horizon). <p> Description of the exact and approximate solution methods is outside the scope of this paper (see [7] <ref> [2] </ref> [3]). Management of Ischemic Heart Disease The POMDP framework can be exploited in representing various complex problems of patient management, e.g. the management of chronic ischemic heart disease (IHD) [10] [6] [4].
Reference: 3. <author> M. Hauskrecht. </author> <title> Planning and control in stochastic domains with imperfect information. </title> <type> MIT EECS PhD thesis proposal, </type> <month> August </month> <year> 1996, </year> <pages> 133 pages. </pages>
Reference-contexts: In such cases careful evaluation of costs and benefits associated with both treatment and investigative actions with regard to the global objectives is necessary. A framework that allows one to model both sources of uncertainty is the partially observable Markov decision process [1] [9] [7] [2] <ref> [3] </ref>. In the following I will summarize the POMDP framework and illustrate its potential on the problem of the management of patients with chronic ischemic heart disease. <p> Solving the POMDP Problem For the n step-to-go problem the optimal value of the objective function, so called value function, and the optimal control can be computed using the Markov property of the information state process and Bellman's principle of optimality via standard recursive formulas <ref> [3] </ref>: V fl a2A X o2fi next P (ojI n ; a)V fl fl n (I n ) = argmin a2A (I n ; a) + fl X o2fi next P (ojI n ; a)V fl where V fl (:) and fl (:) are optimal value and control functions, I n <p> An even worse situation emerges when one is required to find the solution for all initial information states | the so called policy problem. Although exact methods for solving both decision and policy problems are available for standard POMDP models [9] [2] <ref> [3] </ref>, the computational complexity of such methods leads to the exploration of various approximations that allow good solutions with less computation. Efficient approximation methods are mostly based on the idea of approximate dynamic programming (for the finite horizon case) and approximate value iteration (for the infinite discounted horizon). <p> Description of the exact and approximate solution methods is outside the scope of this paper (see [7] [2] <ref> [3] </ref>). Management of Ischemic Heart Disease The POMDP framework can be exploited in representing various complex problems of patient management, e.g. the management of chronic ischemic heart disease (IHD) [10] [6] [4]. <p> In the paper I have described the basics of the POMDP framework and its solution methods. More detailed description of various exact and approximation methods can be found in <ref> [3] </ref>. The usefulness of the framework in medical settings is being examined with the example of the management of ischemic heart disease. Challenging problems in building and using the model include reliably estimating the many parameters and choosing appropriate approximation methods that yield timely and useful solutions.
Reference: 4. <author> M. Hauskrecht. </author> <title> Dynamic decision making in stochastic partially observable medical domains. </title> <booktitle> AAAI Spring symposium, </booktitle> <pages> pp. </pages> <address> 69- 72, </address> <year> 1996. </year>
Reference-contexts: Description of the exact and approximate solution methods is outside the scope of this paper (see [7] [2] [3]). Management of Ischemic Heart Disease The POMDP framework can be exploited in representing various complex problems of patient management, e.g. the management of chronic ischemic heart disease (IHD) [10] [6] <ref> [4] </ref>. The objective is to determine the optimal plan for managing the patient's chronic disease relative to cost criteria, including, e.g., invasiveness of the treatment, risk of death etc.
Reference: 5. <author> R. Hovorka et.al. </author> <title> Causal probabilistic network modelling An illustration of its role in the man agement of chronic diseases. </title> <journal> IBM Systems Journal, 31:4, </journal> <volume> pp.635-648, </volume> <year> 1992. </year>
Reference-contexts: While most of the work on dynamic decision making addresses the issue of action outcome uncertainty, the feature of partial observability is often considered irrelevant or is abstracted out. Research work falling into this category includes the management of diabetes <ref> [5] </ref> or chronic heart disease [6]. The assumption of perfect observability may not work well for problems in which observations are imprecise indicators of the patient state and when investigative actions have significant cost (invasiveness, economic cost).
Reference: 6. <author> T.-Y. Leong. </author> <title> An integrated approach to dynamic decision making under uncertainty. </title> <address> MIT/LCS/TR-631, </address> <year> 1994. </year>
Reference-contexts: While most of the work on dynamic decision making addresses the issue of action outcome uncertainty, the feature of partial observability is often considered irrelevant or is abstracted out. Research work falling into this category includes the management of diabetes [5] or chronic heart disease <ref> [6] </ref>. The assumption of perfect observability may not work well for problems in which observations are imprecise indicators of the patient state and when investigative actions have significant cost (invasiveness, economic cost). <p> Description of the exact and approximate solution methods is outside the scope of this paper (see [7] [2] [3]). Management of Ischemic Heart Disease The POMDP framework can be exploited in representing various complex problems of patient management, e.g. the management of chronic ischemic heart disease (IHD) [10] <ref> [6] </ref> [4]. The objective is to determine the optimal plan for managing the patient's chronic disease relative to cost criteria, including, e.g., invasiveness of the treatment, risk of death etc.
Reference: 7. <author> W.S. Lovejoy. </author> <title> A survey of algorithmic methods for partially observed Markov decision processes. </title> <journal> Annals of Operations Research, </journal> <volume> 28, </volume> <pages> pp. 47-66, </pages> <year> 1991. </year>
Reference-contexts: In such cases careful evaluation of costs and benefits associated with both treatment and investigative actions with regard to the global objectives is necessary. A framework that allows one to model both sources of uncertainty is the partially observable Markov decision process [1] [9] <ref> [7] </ref> [2] [3]. In the following I will summarize the POMDP framework and illustrate its potential on the problem of the management of patients with chronic ischemic heart disease. <p> Methods can be based on sampling schemes combined with function approximation and fitting strategies, or based on reducing the complexity of the information vector space in various ways, e.g. through feature extraction mappings. Description of the exact and approximate solution methods is outside the scope of this paper (see <ref> [7] </ref> [2] [3]). Management of Ischemic Heart Disease The POMDP framework can be exploited in representing various complex problems of patient management, e.g. the management of chronic ischemic heart disease (IHD) [10] [6] [4].
Reference: 8. <author> C.H. Papadimitriou, J.N. Tsitsiklis. </author> <title> The complexity of Markov decision processes. </title> <journal> Mathematics of Operations Research, </journal> <volume> 12:3, </volume> <pages> pp. 441-450, </pages> <year> 1987. </year>
Reference-contexts: The problem of finding optimal actions or policies can be computationally very expensive. It has been shown to be PSPACE-hard even for a single initial state and finite horizon cost function <ref> [8] </ref>. This is because the number of information states one potentially needs to visit grows exponentially with the number of steps to be explored. An even worse situation emerges when one is required to find the solution for all initial information states | the so called policy problem.
Reference: 9. <author> R.D. Smallwood, E.J. Sondik. </author> <title> The optimal control of partially observable processes over a finite horizon. </title> <journal> Operations Research, </journal> <volume> 21, </volume> <pages> pp. 1071-1088. </pages>
Reference-contexts: In such cases careful evaluation of costs and benefits associated with both treatment and investigative actions with regard to the global objectives is necessary. A framework that allows one to model both sources of uncertainty is the partially observable Markov decision process [1] <ref> [9] </ref> [7] [2] [3]. In the following I will summarize the POMDP framework and illustrate its potential on the problem of the management of patients with chronic ischemic heart disease. <p> An even worse situation emerges when one is required to find the solution for all initial information states | the so called policy problem. Although exact methods for solving both decision and policy problems are available for standard POMDP models <ref> [9] </ref> [2] [3], the computational complexity of such methods leads to the exploration of various approximations that allow good solutions with less computation. Efficient approximation methods are mostly based on the idea of approximate dynamic programming (for the finite horizon case) and approximate value iteration (for the infinite discounted horizon).
Reference: 10. <author> J.B. Wong et.al. </author> <title> Myocardial revascularization for chronic stable angina. </title> <journal> Annals of Internal Medicine, </journal> <volume> 113 (1), </volume> <pages> pp. 852-871, </pages> <year> 1990. </year>
Reference-contexts: Description of the exact and approximate solution methods is outside the scope of this paper (see [7] [2] [3]). Management of Ischemic Heart Disease The POMDP framework can be exploited in representing various complex problems of patient management, e.g. the management of chronic ischemic heart disease (IHD) <ref> [10] </ref> [6] [4]. The objective is to determine the optimal plan for managing the patient's chronic disease relative to cost criteria, including, e.g., invasiveness of the treatment, risk of death etc.
References-found: 10

