URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/opitz.thesis.ps.Z
Refering-URL: http://www.lehigh.edu/~ob00/integrated/references-new.html
Root-URL: 
Title: AN ANYTIME APPROACH TO CONNECTIONIST THEORY REFINEMENT: REFINING THE TOPOLOGIES OF KNOWLEDGE-BASED NEURAL NETWORKS  
Author: By David William Opitz 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Date: 1995  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: <author> Ackley, D. </author> <year> (1987). </year> <title> A Connectionist Machine for Genetic Hillclimbing. </title> <publisher> Kluwer, Norwell, </publisher> <address> MA. </address>
Reference-contexts: As a future research topic, I plan to investigate incorporating diversity-promoting techniques once I am able to consider tens of thousands of networks. Regent can be considered a Lamarckian 2 , genetic-hillclimbing algorithm <ref> (Ackley, 1987) </ref>, since it performs local optimizations on individuals, then passes the successful optimizations on to offspring. The ability of individuals to learn can smooth the fitness landscape and facilitate learning (Hinton & Nowlan, 1987).
Reference: <author> Ackley, D. & Littman, M. </author> <year> (1994). </year> <title> A case for Lamarckian evolution. </title> <editor> In Langton, C., editor, </editor> <booktitle> Artificial Life III, </booktitle> <pages> (pp. 3-10), </pages> <address> Redwood City, CA. </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Alpaydin, E. </author> <year> (1993). </year> <title> Multiple networks for function learning. </title> <booktitle> In Proceedings of the 1993 IEEE International Conference on Neural Networks (volume I), </booktitle> <pages> (pp. 27-32), </pages> <address> San Fransisco. </address>
Reference-contexts: Most approaches, however, fail in that they do not actively try to generate such a set of networks. These approaches either randomly create their networks (Lincoln & Skrzypek, 1989; Hansen & Salamon, 1990), or indirectly try to create diverse networks by training each network with dissimilar learning parameters <ref> (Alpaydin, 1993) </ref>, different network architectures (Hashem et al., 1994), various initial weight settings (Maclin & Shavlik, 1995), or separate partitions of the training set (Breiman, 1994; Krogh & Vedelsby, 1995).
Reference: <author> Ash, T. </author> <year> (1989). </year> <title> Dynamic node creation in backpropagation networks. </title> <journal> Connection Science, </journal> <volume> 1 </volume> <pages> 365-376. </pages>
Reference: <author> Atlas, L., Cole, R., Connor, J., El-Sharkawi, M., Marks II, R., Muthusamy, Y., & Barnard, E. </author> <year> (1989). </year> <title> Performance comparisons between backpropagation networks and classification trees on three real-world applications. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 622-629), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Baffes, P. & Mooney, R. </author> <year> (1993). </year> <title> Symbolic revision of theories with M-of-N rules. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 1135-1140), </pages> <address> Chambery, France. </address>
Reference: <author> Baum, E. & Haussler, D. </author> <year> (1989). </year> <title> What size net gives valid generalization? Neural Computation, </title> <booktitle> 1 </booktitle> <pages> 151-160. </pages>
Reference: <author> Baum, E. & Lang, K. </author> <year> (1991). </year> <title> Constructing hidden units using examples and queries. </title> <editor> In Lippmann, R., Moody, J., & Touretzky, D., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 3), </booktitle> <pages> (pp. 904-910), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Baxt, W. </author> <year> (1992). </year> <title> Improving the accuracy of an artificial neural network using multiple differently trained networks. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 772-780. </pages>
Reference: <author> Berenji, H. </author> <year> (1991). </year> <title> Refinement of approximate reasoning-based controllers by reinforcement learning. </title> <booktitle> In Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> (pp. 475-479), </pages> <address> Evanston, IL. </address> <note> 126 127 Blumer, </note> <author> A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. </author> <year> (1987). </year> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380. </pages>
Reference: <author> Bookman, L. & Sun, R. </author> <year> (1993). </year> <title> Integrating neural and symbolic processes. </title> <journal> Connection Science, </journal> <volume> 5 </volume> <pages> 203-204. </pages>
Reference-contexts: Symbolic methods, on the other hand, have advantages that make them attractive to problems that require explanation and understanding their rules are generally intelligible to a human, background knowledge can be encoded in an easily manipulative form, and they allow easy control of information flow <ref> (Bookman & Sun, 1993) </ref>. Both neural and symbolic techniques have their disadvantages as well. <p> Alternately, symbol-processing systems usually generalize poorly on complex, imprecise problems, do not handle noisy data well, and do not gracefully degrade with a slight change of concept <ref> (Bookman & Sun, 1993) </ref>. An architecture that can incorporate both symbolic and neural methods can potentially produce a better system than either individually (Fu, 1989; Towell, 1991; Lacher et al., 1992; Mahoney & Mooney, 1994). Ideally, such a system should have the best of both worlds.
Reference: <author> Breiman, L. </author> <year> (1994). </year> <title> Bagging predictors. </title> <type> Technical Report 421, </type> <institution> Department of Statistics, University of California, Berkeley. </institution>
Reference-contexts: Experiments demonstrate that my method is able to find an effective set of KNNs for its ensemble. Addemup showed statistically significant improvements in generalization over (a) the single best network seen during the search, (b) a previously proposed ensemble method called bagging <ref> (Breiman, 1994) </ref> applied to both randomly generated networks and the Kbann network, (c) simply combining Regent's population, and (d) a run of Addemup where it randomly created the network topologies of its initial population.
Reference: <author> Breiman, L., Friedman, J., Olshen, R., & Stone, C. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA. </address>
Reference: <author> Bryson, A. & Ho, Y. </author> <year> (1969). </year> <title> Applied Optimal Control. </title> <publisher> Blaisdell, </publisher> <address> New York. </address>
Reference: <author> Burks, C. </author> <year> (1990). </year> <title> Genbank: Current status and future directions. </title> <editor> In Doolittle, R. F., editor, </editor> <booktitle> Methods in Enzymology (volume 183). </booktitle> <publisher> Academic Press. </publisher>
Reference-contexts: The dataset consists of 3,190 examples containing 751 acceptors, 745 donors, knd 1694 negative examples (Towell, 1991). The positive examples are all the documented "split" genes described as complete from the primate gene entries in release 64.1 of Genbank <ref> (Burks, 1990) </ref>. 1 Each example is 60-nucleotides long, with the center being the reference point for the existence of a splice junction; thus, the numbering for the location of each nucleotide range from 30 to +30. <p> As with the previous three DNA domains, M. Noordewier also created this section's dataset and domain theory. The dataset contains 142 positive examples and 5,178 negative examples. The positive examples where taken from the file "gbbct.seq" in release 60 of Genbank <ref> (Burks, 1990) </ref>. The sequences are 50 nucleotides long, spanning from location 20 to location +30. The point of reference in this case is transcription-termination sites.
Reference: <author> Cain, T. </author> <year> (1991). </year> <title> The DUCTOR: A theory revision system for propositional domains. </title> <booktitle> In Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> (pp. 485-489), </pages> <address> Evanston, IL. </address>
Reference-contexts: Several systems, including mine, have been proposed for refining propositional rule bases. Early such approaches could only handle improvements to overly specific theories (Danyluk, 1989) or specializations to overly general theories (Flann & Dietterich, 1989). Later systems such as Rtls (Ginsberg, 1990), Ductor <ref> (Cain, 1991) </ref>, Either (Ourston & Mooney, 1994), Ptr (Koppel et al., 1994), and Tgci (Donoho & Rendell, 1995) were later able to handle both types of refinements. I discuss the Either system as a representative of these propositional systems next.
Reference: <author> Chauvin, Y. </author> <year> (1988). </year> <title> A back-propagation algorithm with optimal use of hidden units. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 1), </booktitle> <pages> (pp. 519-525), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Clemen, R. </author> <year> (1989). </year> <title> Combining forecasts: A review and annotated bibliography. </title> <journal> International Journal of Forecasting, </journal> <volume> 5 </volume> <pages> 559-583. </pages>
Reference-contexts: Thus I define my weights for combining the networks as follows: w i = P : (21) While simply averaging the outputs can generate a good composite model <ref> (Clemen, 1989) </ref>, I include the predicted accuracy in my weights since one should believe accurate models more than inaccurate ones.
Reference: <author> Clocksin, W. & Mellish, C. </author> <year> (1987). </year> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: Figure 6b represents the hierarchical structure of these rules, with solid lines representing necessary dependencies and dotted lines representing prohibitory dependencies. Figure 6c represents the network Kbann creates from this 25 shows a sample propositional rule set in Prolog <ref> (Clocksin & Mellish, 1987) </ref> notation, panel (b) illustrates this rule set's corresponding dependency tree, and panel (c) shows the resulting network created by Kbann's translation. translation. <p> Assume we are given the domain theory in Figure 10a (this is a repeat of we are trying to learn should have also included the rule: b :- not d, e, g. 38 shows a sample propositional rule domain theory in Prolog <ref> (Clocksin & Mellish, 1987) </ref> notation, panel (b) illustrates this rule set's corresponding dependency tree, and panel (c) shows the resulting network created from Kbann's translation. (This is a repeat of then Kbann is unable to completely learn when a is true. <p> The domain theories and datasets for these tasks are explained in this appendix. The domain theories are presented in Prolog notation <ref> (Clocksin & Mellish, 1987) </ref> that is extended at times (as explained below). A.1 A Chess Sub-Problem: An Artificial Domain While real-world domains are clearly useful in exploring the utility of an algorithm, they are difficult to use in closely-controlled studies that examine different aspects of an algorithm.
Reference: <author> Cohen, W. </author> <year> (1992). </year> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> (pp. 102-110), </pages> <address> Aberdeen, Scotland. </address>
Reference-contexts: Systems such as Focl (Pazzani & Kibler, 1992) and Forte (Richards, 1995) are first-order, theory-refinement systems that revise predicate-logic theories. One drawback to these systems is that they currently do not generalize as well as connectionist approaches on many real-world problems, such as the DNA promoter task <ref> (Cohen, 1992) </ref>. Regal (Giordana & Saitta, 1993; Giordana et al., 1994) is an example of a first-order, theory-refinement system that uses genetic algorithms to help refine an incomplete or inconsistent domain theory.
Reference: <author> Cooper, N. G., </author> <title> editor (1994). The Human Genome Project: Deciphering the Blueprint of Heredity. </title> <publisher> University Science Books, </publisher> <address> Mill Valley, CA. </address>
Reference-contexts: Researchers are currently sequencing large volumes of DNA; however, biologist are only able to study small sections of DNA at a time. Thus, the Human Genome Project <ref> (Cooper, 1994) </ref> will produce long runs of DNA that have not 110 Table 12: Domain theory for the artificial chess problem. The OR in the following rules means that only one of the two antecedents needs to be satisfied in order for the rule to be satisfied.
Reference: <author> Craven, M. & Shavlik, J. </author> <year> (1993). </year> <title> Learning symbolic rules using artificial neural networks. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> (pp. 73-80), </pages> <address> Amherst, MA. </address>
Reference: <author> Craven, M. & Shavlik, J. </author> <year> (1994a). </year> <title> Machine learning approaches to gene recognition. </title> <journal> IEEE Expert, </journal> <volume> 9 </volume> <pages> 2-10. </pages>
Reference: <author> Craven, M. & Shavlik, J. </author> <year> (1994b). </year> <title> Using sampling and queries to extract rules from trained neural networks. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 37-45), </pages> <address> New Brunswick, NJ. 128 Danyluk, </address> <publisher> A. </publisher> <year> (1989). </year> <title> Finding new rules for incomplete theories: Explicit biases for induction with contextual information. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> (pp. 34-36), </pages> <address> Ithaca, NY. </address>
Reference: <author> Darwin, C. </author> <title> (1859). On the Origin of Species by Means of Natural Selection. </title> <publisher> John Murray, London. </publisher>
Reference: <author> Das, A., Giles, C., & Sun, G. </author> <year> (1992). </year> <title> Using prior knowledge in an NNPDA to learn context-free languages. </title> <editor> In Hanson, S., Cowan, J., & Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 5), </booktitle> <pages> (pp. 65-72), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These include finite-state automata (Omlin & Giles, 1992; Maclin & Shavlik, 1993), push-down automata <ref> (Das et al., 1992) </ref>, fuzzy-logic rules (Masuoka et al., 1990; Berenji, 1991), probabilistic rules (Fu, 1989; Mahoney & Mooney, 1994), mathematical equations (Roscheisen et al., 1991; Scott et al., 1992), and other types of rules.
Reference: <author> Dean, T. & Boddy, M. </author> <year> (1988). </year> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 49-54), </pages> <address> St. Paul, MN. </address>
Reference: <author> Dodd, N. </author> <year> (1990). </year> <title> Optimization of network structure using genetic techniques. </title> <booktitle> In Proceedings of the IEEE International Joint Conference on Neural Networks (volume III), </booktitle> <pages> (pp. 965-970), </pages> <address> Paris. </address>
Reference: <author> Donoho, S. & Rendell, L. </author> <year> (1995). </year> <title> Rerepresenting and restructuring domain theories: A constructive induction approach. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 411-446. </pages>
Reference-contexts: Early such approaches could only handle improvements to overly specific theories (Danyluk, 1989) or specializations to overly general theories (Flann & Dietterich, 1989). Later systems such as Rtls (Ginsberg, 1990), Ductor (Cain, 1991), Either (Ourston & Mooney, 1994), Ptr (Koppel et al., 1994), and Tgci <ref> (Donoho & Rendell, 1995) </ref> were later able to handle both types of refinements. I discuss the Either system as a representative of these propositional systems next. <p> My algorithms do not suffer from this in that they translate the theory into the less restricting representation of neural networks <ref> (Donoho & Rendell, 1995) </ref>. Also, Regent and Addemup are able to further reconfigure the structure of the domain with genetic algorithms. 6.2 Finding Appropriate Network Topologies My second area of related work covers techniques that attempt to find a good domain-dependent topology by dynamically refining their network's topology during training.
Reference: <author> Drucker, H., Schapire, R., & Simard, P. </author> <year> (1992). </year> <title> Improving performance in neural networks using a boosting algorithm. </title> <editor> In Hanson, J., Cowan, J., & Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 5), </booktitle> <pages> (pp. 42-49), </pages> <address> Palo Alto, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Efron, B. & Tibshirani, R. </author> <year> (1993). </year> <title> An introduction to the Bootstrap. </title> <publisher> Chapman and Hall, </publisher> <address> New York. </address>
Reference-contexts: I also tried other ensemble approaches, such as randomly creating varying multi-layer network topologies and initial weight settings, but bagging did significantly better on all datasets (by 15-25% on all three DNA domains). Bagging is a "bootstrap" <ref> (Efron & Tibshirani, 1993) </ref> ensemble method that trains each network in the ensemble with a different partition of the training set. It generates each partition by randomly drawing, with replacement, N examples from the training set, where N is the size of the training set.
Reference: <author> Fahlman, S. & Lebiere, C. </author> <year> (1989). </year> <title> The cascade-correlation learning architecture. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 524-532), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Mezard and Nadal (1989) proposed a tiling algorithm that starts from the bottom and works upwards, with each successive layer correcting the errors of the previous layer. The cascade-correlation algorithm <ref> (Fahlman & Lebiere, 1989) </ref> builds a hierarchy of hidden nodes in a cascaded manner, where each new node receives activation from all input nodes and all previously added hidden nodes. Another approach is to start with a large network, then prune unimportant connections during training.
Reference: <author> Farmer, J. & Belin, A. </author> <year> (1992). </year> <title> Artificial life: The coming evolution. </title> <editor> In Langton, C., Taylor, C., Farmer, J. D., & Rasmussen, S., editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> (pp. 815-840), </pages> <address> Redwood City, CA. </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Fisher, D. & McKusick, K. </author> <year> (1989). </year> <title> An empirical comparison of ID3 and backpropagation. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 788-793), </pages> <address> Detroit, MI. </address>
Reference: <author> Flann, N. & Dietterich, T. </author> <year> (1989). </year> <title> A study of explanation-based methods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 187-226. </pages> <note> 129 Fletcher, </note> <author> J. & Obradovic, Z. </author> <year> (1993). </year> <title> Combining prior symbolic knowledge and constructive neural network learning. </title> <journal> Connection Science, </journal> 5:365-375. 
Reference-contexts: Several systems, including mine, have been proposed for refining propositional rule bases. Early such approaches could only handle improvements to overly specific theories (Danyluk, 1989) or specializations to overly general theories <ref> (Flann & Dietterich, 1989) </ref>. Later systems such as Rtls (Ginsberg, 1990), Ductor (Cain, 1991), Either (Ourston & Mooney, 1994), Ptr (Koppel et al., 1994), and Tgci (Donoho & Rendell, 1995) were later able to handle both types of refinements.
Reference: <author> Fletcher, R. </author> <year> (1987). </year> <title> Practical Methods of Optimization. </title> <publisher> John Wiley and Sons, </publisher> <address> Chich-ester, </address> <note> second edition. </note>
Reference-contexts: The momentum term, similar to that of conjugate gradient's <ref> (Fletcher, 1987, Chapter 4) </ref>, helps prevent the updates from oscillating wildly, encouraging changes that are made in the direction of the average downhill force. The momentum parameter, ff, should be between 0 and 1; I use the commonly chosen value of 0.9.
Reference: <author> Forrest, S. & Mitchell, M. </author> <year> (1993). </year> <title> What makes a problem hard for a genetic algorithm? Some anomalous results and their explanation. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 285-319. </pages>
Reference: <author> Frean, M. </author> <year> (1990). </year> <title> The upstart algorithm: A method for constructing and training feedforward neural networks. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 198-209. </pages>
Reference-contexts: An improved version of Rapture (Mahoney & Mooney, 1994), however, is able to dynamically refine the topology of its network. It does this by using the Upstart algorithm <ref> (Frean, 1990) </ref> to add new nodes to the network. Aside from being designed for probabilistic rules, Rapture differs from the framework of my algorithms in that it adds nodes with the intention of completely learning the training set, not generalizing well.
Reference: <author> Fu, L. </author> <year> (1989). </year> <title> Integration of neural heuristics into knowledge-based inference. </title> <journal> Connection Science, </journal> <volume> 1 </volume> <pages> 325-340. </pages>
Reference: <author> Fu, L. </author> <year> (1991). </year> <title> Rule learning by searching on adapted nets. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 590-595), </pages> <address> Anaheim, CA. </address>
Reference: <author> Geman, S., Bienenstock, E., & Doursat, R. </author> <year> (1992). </year> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58. </pages>
Reference-contexts: The best function, then, will be the smoothest function that also fits the data well. How much importance is placed on either term is called the bias/variance tradeoff <ref> (Geman et al., 1992) </ref>. High belief in the bias (or smoothness) will produce an answer that is smooth, but may not fit the data well. Low belief in the bias, on the other hand, may produce an answer that is complex, but fits the data well.
Reference: <author> Ginsberg, A. </author> <year> (1990). </year> <title> Theory reduction, theory revision, </title> <booktitle> and retranslation. In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 777-782), </pages> <address> Boston, MA. </address>
Reference-contexts: Several systems, including mine, have been proposed for refining propositional rule bases. Early such approaches could only handle improvements to overly specific theories (Danyluk, 1989) or specializations to overly general theories (Flann & Dietterich, 1989). Later systems such as Rtls <ref> (Ginsberg, 1990) </ref>, Ductor (Cain, 1991), Either (Ourston & Mooney, 1994), Ptr (Koppel et al., 1994), and Tgci (Donoho & Rendell, 1995) were later able to handle both types of refinements. I discuss the Either system as a representative of these propositional systems next.
Reference: <author> Giordana, A. & Saitta, L. </author> <year> (1993). </year> <title> REGAL: An integrated system for relations using genetic algorithms. </title> <booktitle> In Proceedings of the Second International Workshop on Multi-strategy Learning, </booktitle> <pages> (pp. 234-249), </pages> <address> Harpers Ferry, WV. </address>
Reference: <author> Giordana, A., Saitta, L., & Zini, F. </author> <year> (1994). </year> <title> Learning disjunctive concepts by means of genetic algorithms. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 96-104), </pages> <address> New Brunswick, NJ. </address>
Reference: <author> Goldberg, D. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: This is done by continually creating new members with the crossover and mutation operators, and replacing existing members of the population with the new individuals. Many replacement strategies, such a simply replacing the lowest-fit individual, have been proposed <ref> (Goldberg, 1989) </ref>. are the individuals crossed over in Figure 16). Crossover works by first picking two parents at random proportional to their fitness. <p> For instance, there is no way to crossover two members of Figure 16 to generate an individual that has a one in the third bit. Mutation is typically a secondary operation that is only sparingly used <ref> (Goldberg, 1989) </ref>. 4.1.2 Why Genetic Algorithms Work The power of genetic search lies in its continual recombination of good building blocks. The underlying assumption is that fit individuals are made from good parts. <p> When Regent replaces a member, it chooses the member having the lowest correctness (ties are broken by choosing the oldest member). Other techniques <ref> (Goldberg, 1989) </ref>, such as replacing the member nearest the new candidate network, can promote diverse populations; however, I do not want to promote diversity at the expense of decreased generalization.
Reference: <author> Granger, C. </author> <year> (1989). </year> <title> Combining forecasts: Twenty years later. </title> <journal> Journal of Forecasting, </journal> <volume> 8 </volume> <pages> 167-173. </pages>
Reference: <author> Grefenstette, J. & Ramsey, C. </author> <year> (1992). </year> <title> An approach to anytime learning. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> (pp. 189-195), </pages> <address> Aberdeen, Scotland. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hampshire, J. & Waibel, A. </author> <year> (1989). </year> <title> The meta-pi network: Building distributed knowledge representations for robust pattern recognition. </title> <type> Technical Report TR CMU-CS-89-166, </type> <address> CMU, Pittsburgh, PA. </address> <note> 130 Hansen, </note> <author> L. & Salamon, P. </author> <year> (1990). </year> <title> Neural network ensembles. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12 </volume> <pages> 993-1001. </pages>
Reference-contexts: The key idea of these techniques is that a decomposition of the problem into specific subtasks might lead to more efficient representations and training <ref> (Hampshire & Waibel, 1989) </ref>. Once a problem is broken into subtasks, the resulting solutions need to be combined. Jacobs et al. (1991) propose having the gating function be a network that learns how to allocate examples to the experts.
Reference: <author> Hanson, S. </author> <year> (1989). </year> <title> Meiosis networks. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 533-541), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hanson, S. & Pratt, L. </author> <year> (1988). </year> <title> Comparing biases for minimal network construction with back-propagation. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 1), </booktitle> <pages> (pp. 177-185), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Harp, S., Samad, T., & Guha, A. </author> <year> (1989). </year> <title> Designing application-specific neural networks using the genetic algorithm. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 447-454), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hashem, S., Schmeiser, B., & Yih, Y. </author> <year> (1994). </year> <title> Optimal linear combinations of neural networks: An overview. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Neural Networks, </booktitle> <address> Orlando, FL. </address>
Reference-contexts: These approaches either randomly create their networks (Lincoln & Skrzypek, 1989; Hansen & Salamon, 1990), or indirectly try to create diverse networks by training each network with dissimilar learning parameters (Alpaydin, 1993), different network architectures <ref> (Hashem et al., 1994) </ref>, various initial weight settings (Maclin & Shavlik, 1995), or separate partitions of the training set (Breiman, 1994; Krogh & Vedelsby, 1995). Unlike Addemup however, these approaches do not directly address how to generate such networks that are optimized for the ensemble as a whole.
Reference: <author> Hassibi, B. & Stork, D. </author> <year> (1992). </year> <title> Second order derivatives for network pruning: Optimal brain surgeon. </title> <editor> In Hanson, S., Cowan, J., & Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 5), </booktitle> <pages> (pp. 164-171), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hertz, J., Krogh, A., & Palmer, R. </author> <year> (1991). </year> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, CA. </address>
Reference-contexts: The particular type of learning algorithms I focus on are feed-forward neural networks <ref> (Hertz et al., 3 1991) </ref>. <p> Chapter 2 What is a Knowledge-Based Neural Network? The learning method I concentrate on in this thesis is that of neural networks <ref> (Hertz et al., 1991) </ref>. Specifically, my algorithms translate a given domain theory directly into a neural network, then continually improve this knowledge-based network over time. <p> Although a single layer of hidden nodes can approximate any Boolean as well as any continuous function, they are incapable of creating higher-order features that may aid learning <ref> (Hertz et al., 1991) </ref>. Also, as indicated above, the number of hidden nodes 21 in single-hidden-layer networks does not matter as much as does finding a good point to stop training. There have also been attempts to build multi-layered networks while learning progresses. <p> One remaining difficulty is recursion; however, one can handle recursion by either unrolling the recursive rule to a predefined depth, or by using a "recurrent" network <ref> (Hertz et al., 1991) </ref> containing feedback links that create loops in the network. 105 rules, and the neural network obtained from the propositional rules. Part (b) is the same as part (a) with an additional predicate-logic rule.
Reference: <author> Hinton, G. </author> <year> (1986). </year> <title> Learning distributed representations of concepts. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> (pp. 1-12), </pages> <address> Amherst, MA. </address>
Reference-contexts: Perhaps the most common prior term takes the form of weight decay <ref> (Hinton, 1986) </ref>. <p> That is, there is a trade-off between changing the domain theory and disregarding the misclassified training examples as noise. To help address this, TopGen uses a variant of weight decay <ref> (Hinton, 1986) </ref>. Weights that are part of the original domain theory decay toward their initial value, while other weights decay toward zero.
Reference: <author> Hinton, G. & Nowlan, S. </author> <year> (1987). </year> <title> How learning can guide evolution. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 495-502. </pages>
Reference-contexts: Regent can be considered a Lamarckian 2 , genetic-hillclimbing algorithm (Ackley, 1987), since it performs local optimizations on individuals, then passes the successful optimizations on to offspring. The ability of individuals to learn can smooth the fitness landscape and facilitate learning <ref> (Hinton & Nowlan, 1987) </ref>. Thus, Lamarckian learning can lead to a large increase in learning speed and solution quality (Farmer & Belin, 1992; Ackley & Littman, 1994). 4.3 Experimental Results In this section, I test Regent on three real-world problems from the Human Genome Project.
Reference: <author> Holder, L. </author> <year> (1991). </year> <title> Maintaining the Utility of Learned Knowledge Using Model-Based Control. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of Illinois at Urbana-Champaign. </institution>
Reference-contexts: Most standard inductive learners such as backpropagation (Rumelhart et al., 1986) and ID3 (Quinlan, 1986), however, are unable to continually improve their answers (at least until they receive additional training examples). In fact, if run too long, these algorithms tend to "overfit" the training set <ref> (Holder, 1991) </ref>. Overfitting occurs when the learning algorithm produces a concept that captures too much information about the training examples, and not enough about the general characteristics of the domain as a whole.
Reference: <author> Holland, J. </author> <year> (1975). </year> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> University of Michi-gan Press, </publisher> <address> Ann Arbor, MI. </address>
Reference: <author> Jacobs, R., Jordan, M., Nowlan, S., & Hinton, G. </author> <year> (1991). </year> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 79-87. </pages>
Reference: <author> Kitano, H. </author> <year> (1990a). </year> <title> Designing neural networks using genetic algorithms with graph generation system. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 461-476. </pages> <note> 131 Kitano, </note> <author> H. </author> <year> (1990b). </year> <title> Empirical studies on the speed of convergence of neural network training using genetic algorithms. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 789-795), </pages> <address> Boston, MA. </address>
Reference: <author> Koppel, M., Feldman, R., & Segre, A. </author> <year> (1994). </year> <title> Bias-driven revision of logical domain theories. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 159-208. </pages>
Reference-contexts: Early such approaches could only handle improvements to overly specific theories (Danyluk, 1989) or specializations to overly general theories (Flann & Dietterich, 1989). Later systems such as Rtls (Ginsberg, 1990), Ductor (Cain, 1991), Either (Ourston & Mooney, 1994), Ptr <ref> (Koppel et al., 1994) </ref>, and Tgci (Donoho & Rendell, 1995) were later able to handle both types of refinements. I discuss the Either system as a representative of these propositional systems next.
Reference: <author> Koza, J. </author> <year> (1992). </year> <title> Genetic Programming. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: One could prune weights and nodes during Regent's search; however, such pruning can prematurely reduce the variety of structures available for recombination during crossover <ref> (Koza, 1992) </ref>. Real-life organisms, for instance, have superfluous DNA that are believed to enhance the rate of evolution (Watson et al., 1987; Suzuki et al., 1989). <p> As stated earlier, the framework of Addemup and the theory it builds upon can be applied to any inductive learner, not just neural networks. Future work then, is to investigate applying Addemup to these other learning algorithms as well. With genetic programming <ref> (Koza, 1992) </ref>, for instance, I could translate perturbations of the domain theory into a set of dependency trees (see Figure 6b), then continually create new candidate trees via crossover and mutation.
Reference: <author> Koza, J. & Rice, J. </author> <year> (1991). </year> <title> Genetic generation of both the weights and architectures for a neural network. </title> <booktitle> In International Joint Conference on Neural Networks (volume 2), </booktitle> <pages> (pp. 397-404), </pages> <address> Seattle, WA. </address>
Reference: <author> Krogh, A. & Vedelsby, J. </author> <year> (1995). </year> <title> Neural network ensembles, cross validation, and active learning. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 7), </booktitle> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Lacher, R., Hruska, S., & Kuncicky, D. </author> <year> (1992). </year> <title> Back-propagation learning in expert networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3 </volume> <pages> 62-72. </pages>
Reference: <author> Le Cun, Y., Denker, J., & Solla, S. </author> <year> (1989). </year> <title> Optimal brain damage. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 598-605), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Mezard and Nadal (1989) proposed a tiling algorithm that starts from the bottom and works upwards, with each successive layer correcting the errors of the previous layer. The cascade-correlation algorithm <ref> (Fahlman & Lebiere, 1989) </ref> builds a hierarchy of hidden nodes in a cascaded manner, where each new node receives activation from all input nodes and all previously added hidden nodes. Another approach is to start with a large network, then prune unimportant connections during training. <p> Thus I define my weights for combining the networks as follows: w i = P : (21) While simply averaging the outputs can generate a good composite model <ref> (Clemen, 1989) </ref>, I include the predicted accuracy in my weights since one should believe accurate models more than inaccurate ones. <p> Of these methods, many directly encode each link in the network (Miller et al., 1989; Oliker et al., 1992; Schiffmann et al., 1992). These methods are relatively straightforward to implement, and are good at fine tuning small networks <ref> (Miller et al., 1989) </ref>; however, they do not scale well since they require very large matrices to represent all the links in large networks (Yao, 1993).
Reference: <author> LeCun, Y. & Bengio, Y. </author> <year> (1995). </year> <title> Pattern recognition. </title> <editor> In Arbib, M., editor, </editor> <booktitle> The Handbook of Brain Theory and Neural Network, </booktitle> <pages> (pp. 711-715), </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Batch learning, on the other hand, only updates the weights after all training examples have been presented and can thus be viewed as pure gradient descent; however, online learning has proven to be a more accurate training method <ref> (LeCun & Bengio, 1995) </ref>. Also, Mangasarian and Solodov (1994) proved that, under certain natural assumptions, online backpropagation converges. Error Functions Naturally, the @E=@a i term for the output nodes depends on the error function, E, being minimized.
Reference: <author> Liepins, G. & Vose, M. </author> <year> (1990). </year> <title> Representational issues in genetic optimization. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 101-115. </pages>
Reference: <author> Lincoln, W. & Skrzypek, J. </author> <year> (1989). </year> <title> Synergy of clustering multiple back propagation networks. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 650-659), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Litzkow, M., Livny, M., & Mutka, M. </author> <year> (1988). </year> <title> Condor | a hunter of idle workstations. </title> <booktitle> In Proceedings of the Eighth International Conference on Distributed Computing Systems, </booktitle> <pages> (pp. 104-111), </pages> <address> San Jose, CA. </address>
Reference-contexts: As it searches, Regent keeps the network that has the lowest validation-set error as the best concept seen so far, breaking ties by choosing the smaller network in an application of Occam's Razor. A parallel version trains many candidate networks at the same time using the Condor system <ref> (Litzkow et al., 1988) </ref>, which runs jobs on idle workstations.
Reference: <author> MacKay, D. </author> <year> (1992). </year> <title> A practical Bayesian framework for backpropagation networks. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 448-472. </pages>
Reference-contexts: Drawbacks of using a validation set are that the size of the training set is decreased; its effectiveness can be sensitive to the particular stopping criteria used 19 (Weigend et al., 1990); and it can be a noisy estimator of future performance <ref> (MacKay, 1992) </ref>. Above, I focused on the accuracy term, lnP (DjN ) of Equation 7; I now switch to the prior-probability term, lnP (N ), while again following the discussion in Rumelhart et al. (1995). We can potentially avoid overfitting by selecting an appropriate prior. <p> Two techniques that try to take into account the effective size of the network are Generalized Prediction Error (Moody, 1991) and Bayesian methods <ref> (MacKay, 1992) </ref>. These 102 techniques use only training examples when predicting generalization error. Therefore, my algorithms would be able to use the entire training set to train each considered network. Future work, then, is to investigate utilizing these techniques as appropriate scoring functions for KNNs.
Reference: <author> Maclin, R. & Shavlik, J. </author> <year> (1993). </year> <title> Using knowledge-based neural networks to improve algorithms: Refining the Chou-Fasman algorithm for protein folding. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 195-215. </pages> <note> 132 Maclin, </note> <author> R. & Shavlik, J. </author> <year> (1994). </year> <title> Incorporating advice into agents that learn from reinforcements. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 694-699), </pages> <address> Seattle, WA. </address> <publisher> AAAI/MIT Press. </publisher>
Reference-contexts: Following network initialization, Kbann uses the available training instances to refine the network links. Refer to Towell (1991) or Towell and Shavlik (1994) for more details. Kbann has been successfully applied to many real-world problems, such as the control of a chemical plant (Scott et al., 1992), protein folding <ref> (Maclin & Shavlik, 1993) </ref>, finding genes in a sequence of DNA (Opitz & Shavlik, 1993; Towell & Shavlik, 1994), and ECG patient monitoring (Watrous et al., 1995). In each case, Kbann was shown to produce improvements in generalization over standard neural networks for small numbers of training examples.
Reference: <author> Maclin, R. & Shavlik, J. </author> <year> (1995). </year> <title> Combining the predictions of multiple classifiers: Using competitive learning to initialize neural networks. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada. </address>
Reference-contexts: These approaches either randomly create their networks (Lincoln & Skrzypek, 1989; Hansen & Salamon, 1990), or indirectly try to create diverse networks by training each network with dissimilar learning parameters (Alpaydin, 1993), different network architectures (Hashem et al., 1994), various initial weight settings <ref> (Maclin & Shavlik, 1995) </ref>, or separate partitions of the training set (Breiman, 1994; Krogh & Vedelsby, 1995). Unlike Addemup however, these approaches do not directly address how to generate such networks that are optimized for the ensemble as a whole.
Reference: <author> Mahoney, J. & Mooney, R. </author> <year> (1993). </year> <title> Combining connectionist and symbolic learning to refine certainty-factor rule-bases. </title> <journal> Connection Science, </journal> <volume> 5 </volume> <pages> 339-364. </pages>
Reference-contexts: Daid will therefore suffer with impoverished domain theories. Also notice that since Daid is an improvement for training KNNs, my algorithms can use Daid to train each network they consider during their search (however, I have not done so). 89 The RAPTURE Algorithm Rapture <ref> (Mahoney & Mooney, 1993) </ref> is designed for domain theories containing probabilistic rules. Like most connectionist theory-refinement systems, Rapture first translates the domain theory into a neural network, then refines the weights of the network with a modified backpropagation algorithm.
Reference: <author> Mahoney, J. & Mooney, R. </author> <year> (1994). </year> <title> Comparing methods for refining certainty-factor rule-bases. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 173-180), </pages> <address> New Brunswick, NJ. </address>
Reference-contexts: Like most connectionist theory-refinement systems, Rapture first translates the domain theory into a neural network, then refines the weights of the network with a modified backpropagation algorithm. An improved version of Rapture <ref> (Mahoney & Mooney, 1994) </ref>, however, is able to dynamically refine the topology of its network. It does this by using the Upstart algorithm (Frean, 1990) to add new nodes to the network.
Reference: <author> Mangasarian, O. & Solodov, M. </author> <year> (1994). </year> <title> Backpropagation convergence via deterministic nonmonotone perturbed minimization. </title> <editor> In Cowan, J., Tesauro, G., & Alspector, J., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 6), </booktitle> <pages> (pp. 383-390), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Thus online backpropagation is not true gradient descent, rather it should be viewed as a nonmonotone perturbed gradient algorithm <ref> (Mangasarian & Solodov, 1994) </ref>. Batch learning, on the other hand, only updates the weights after all training examples have been presented and can thus be viewed as pure gradient descent; however, online learning has proven to be a more accurate training method (LeCun & Bengio, 1995).
Reference: <author> Mani, G. </author> <year> (1991). </year> <title> Lowering variance of decisions by using artificial neural network portfolios. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 484-486. </pages>
Reference: <author> Masuoka, R., Watanabe, N., Kawamura, A., Owada, Y., & Asakawa, K. </author> <year> (1990). </year> <title> Neu-rofuzzy system | fuzzy inference using a structured neural network. </title> <booktitle> In Proceedings of the International Conference on Fuzzy Logic & Neural Networks, </booktitle> <pages> (pp. 173-177), </pages> <address> Iizuka, Japan. </address>
Reference: <author> Mezard, M. & Nadal, J.-P. </author> <year> (1989). </year> <title> Learning in feedforward layered networks: The tiling algorithm. </title> <journal> Journal of Physics A, </journal> <volume> 22 </volume> <pages> 2191-2204. </pages>
Reference: <author> Michalski, R. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 111-161. </pages>
Reference-contexts: In Section 2.2.2, I demonstrated that Kbann can effectively remove rules, but it is less effective at adding antecedents to rules and is unable to invent <ref> (constructively induce, Michalski, 1983) </ref> new terms as antecedents. Thus TopGen adds new nodes, intended to decrease false positives, in a fashion that is analogous to adding new constructively induced antecedents to the network. Figures 9b and 9d illustrates how this is done (analogous to Figures 9a and 9c explained above).
Reference: <author> Miller, G., Todd, P., & Hegde, S. </author> <year> (1989). </year> <title> Designing neural networks using genetic algorithms. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> (pp. 379-384), </pages> <address> Arlington, VA. </address>
Reference-contexts: Of these methods, many directly encode each link in the network (Miller et al., 1989; Oliker et al., 1992; Schiffmann et al., 1992). These methods are relatively straightforward to implement, and are good at fine tuning small networks <ref> (Miller et al., 1989) </ref>; however, they do not scale well since they require very large matrices to represent all the links in large networks (Yao, 1993).
Reference: <author> Mitchell, T. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 203-226. </pages>
Reference: <author> Montana, D. & Davis, L. </author> <year> (1989). </year> <title> Training feedforward networks using genetic algorithms. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 762-767), </pages> <address> Detroit, MI. </address> <note> 133 Moody, J. </note> <year> (1991). </year> <title> The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems. </title> <editor> In Moody, J., Hanson, S., & Lipp-mann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 4), </booktitle> <pages> (pp. 847-854), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Mooney, R., Shavlik, J., Towell, G., & Gove, A. </author> <year> (1989). </year> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 775-780), </pages> <address> Detroit, MI. </address>
Reference: <author> Mozer, M. C. & Smolensky, P. </author> <year> (1989). </year> <title> Using relevance to reduce network size automatically. </title> <journal> Connection Science, </journal> <volume> 1 </volume> <pages> 3-16. </pages>
Reference: <author> Nowlan, S. & Hinton, G. </author> <year> (1992). </year> <title> Simplifying neural networks by soft weight-sharing. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 473-493. </pages>
Reference-contexts: The most likely network will be the one with the smallest weights that best classifies the data. This decay term suffers, however, in that it prefers two smaller weights over one large weight <ref> (Nowlan & Hinton, 1992) </ref>. For example, if a node receives input from two highly correlated nodes, it would prefer two connections with weights (w=2) over the similarly behaved weights of w and 0 (since (w=2) 2 + (w=2) 2 &lt; w 2 + 0 2 ). <p> If an algorithm knew that it needed to correct false-negatives for the predicate-logic rule a, it could add all three nodes at once, in the appropriate places. The learning algorithm can cluster weights that correspond to the same variable in a predicate-logic rule using ideas similar to soft-weight sharing <ref> (Nowlan & Hinton, 1992) </ref>, thus allowing weights to dynamically change clusters during training.
Reference: <author> Nowlan, S. & Sejnowski, T. </author> <year> (1992). </year> <title> Filter selection model for generating visual motion signals. </title> <editor> In Hanson, S., Cowan, J., & Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 5), </booktitle> <pages> (pp. 369-376), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The most likely network will be the one with the smallest weights that best classifies the data. This decay term suffers, however, in that it prefers two smaller weights over one large weight <ref> (Nowlan & Hinton, 1992) </ref>. For example, if a node receives input from two highly correlated nodes, it would prefer two connections with weights (w=2) over the similarly behaved weights of w and 0 (since (w=2) 2 + (w=2) 2 &lt; w 2 + 0 2 ). <p> If an algorithm knew that it needed to correct false-negatives for the predicate-logic rule a, it could add all three nodes at once, in the appropriate places. The learning algorithm can cluster weights that correspond to the same variable in a predicate-logic rule using ideas similar to soft-weight sharing <ref> (Nowlan & Hinton, 1992) </ref>, thus allowing weights to dynamically change clusters during training.
Reference: <author> Oliker, S., Furst, M., & Maimon, O. </author> <year> (1992). </year> <title> A distributed genetic algorithm for neural network design and training. </title> <journal> Complex Systems, </journal> <volume> 6 </volume> <pages> 459-477. </pages>
Reference: <author> Oliver, W. & Schneider, W. </author> <year> (1988). </year> <title> Using rules and task division to augment connectionist learning. </title> <booktitle> In Proceedings of the Tenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> (pp. 55-61), </pages> <address> Montreal, Canada. </address>
Reference: <author> Omlin, C. & Giles, C. </author> <year> (1992). </year> <title> Training second-order recurrent neural networks using hints. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> (pp. 361-366), </pages> <address> Aberdeen, Scotland. </address>
Reference: <author> Opitz, D. & Shavlik, J. </author> <year> (1993). </year> <title> Heuristically expanding knowledge-based neural networks. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 1360-1365), </pages> <address> Chambery, France. </address>
Reference: <author> Opitz, D. & Shavlik, J. </author> <year> (1994a). </year> <title> Genetically refining topologies of knowledge-based neural networks. </title> <booktitle> In International Symposium on Integrating Knowledge and Neural Heuristics, </booktitle> <pages> (pp. 57-66), </pages> <address> Pensacola, FL. </address>
Reference: <author> Opitz, D. & Shavlik, J. </author> <year> (1994b). </year> <title> Using genetic search to refine knowledge-based neural networks. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 208-216), </pages> <address> New Brunswick, NJ. </address>
Reference: <author> Opitz, D. & Shavlik, J. </author> <year> (1995a). </year> <title> Dynamically adding symbolically meaningful nodes to knowledge-based neural networks. Knowledge-Based Systems. 134 Opitz, </title> <editor> D. & Shavlik, J. </editor> <year> (1995b). </year> <title> Using heuristic search to expand knowledge-based neural networks. </title> <editor> In Petsche, T., Hanson, S., & Shavlik, J., editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems (volume 3). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Ourston, D. & Mooney, R. </author> <year> (1994). </year> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66 </volume> <pages> 273-309. </pages>
Reference-contexts: Several systems, including mine, have been proposed for refining propositional rule bases. Early such approaches could only handle improvements to overly specific theories (Danyluk, 1989) or specializations to overly general theories (Flann & Dietterich, 1989). Later systems such as Rtls (Ginsberg, 1990), Ductor (Cain, 1991), Either <ref> (Ourston & Mooney, 1994) </ref>, Ptr (Koppel et al., 1994), and Tgci (Donoho & Rendell, 1995) were later able to handle both types of refinements. I discuss the Either system as a representative of these propositional systems next.
Reference: <author> Pazzani, M. & Kibler, D. </author> <year> (1992). </year> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 57-94. </pages>
Reference-contexts: Systems such as Focl <ref> (Pazzani & Kibler, 1992) </ref> and Forte (Richards, 1995) are first-order, theory-refinement systems that revise predicate-logic theories. One drawback to these systems is that they currently do not generalize as well as connectionist approaches on many real-world problems, such as the DNA promoter task (Cohen, 1992).
Reference: <author> Perrone, M. </author> <year> (1992). </year> <title> A soft-competitive splitting rule for adaptive tree-structured neural networks. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <pages> (pp. 689-693), </pages> <address> Baltimore, MD. </address>
Reference: <author> Pomerleau, D. </author> <year> (1991). </year> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 88-97. </pages>
Reference: <author> Provost, F. & Danyluk, A. </author> <year> (1995). </year> <title> Learning from bad data. </title> <booktitle> In Workshop on Applying Machine Learning in Practice, held at the Twelfth International Conference on Machine Learning, </booktitle> <address> Tahoe City, CA. </address>
Reference-contexts: In fact, for every 1% reduction in dispatch error rate, $3 million annually is saved by the company <ref> (Provost & Danyluk, 1995) </ref>. Max's current knowledge base consists of about 75 ART-Lisp rules, many of which involve inequalities. I converted these rules into an equivalent set of 95 propositional, Prolog-style rules. Due to proprietary reasons, however, I am unable to present this rule base in my thesis.
Reference: <author> Quinlan, J. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106. </pages>
Reference-contexts: To generate such an algorithm, you might first try gathering examples of gene and 1 2 non-gene sequences from previously studied DNA. You could then apply an inductive-learning algorithm <ref> (e.g., backpropagation, Rumelhart et al., 1986, or C4.5, Quinlan, 1993) </ref> on these examples, producing a concept that predicts which ones encode genes. <p> Most standard inductive learners such as backpropagation (Rumelhart et al., 1986) and ID3 <ref> (Quinlan, 1986) </ref>, however, are unable to continually improve their answers (at least until they receive additional training examples). In fact, if run too long, these algorithms tend to "overfit" the training set (Holder, 1991). <p> Thus, while Rapture hillclimbs until the training set is learned, my algorithms continually search topology space looking for a network that minimizes validation-set error. Also, Rapture initially only creates links that are specified in the domain theory, and only explicitly adds links through ID3's <ref> (Quinlan, 1986) </ref> information-gain metric. <p> Either uses these operators to make revisions to the domain theory that correctly classify some of the previously misclassified training examples without undoing any of the correctly classified examples. Either uses inductive learning algorithms to invent new rules; it currently uses ID3 <ref> (Quinlan, 1986) </ref> as its induction component. Even though my algorithms add nodes in a manner analogous to how a symbolic system adds antecedents and rules, my underlying learning algorithm is "connectionist." Towell (1991) showed that Kbann was superior to Either on the promoter task, and my algorithms outperform Kbann.
Reference: <author> Quinlan, J. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Quinlan, J. & Cameron-Jones, R. </author> <year> (1995). </year> <title> Lookahead and pathology in decision tree induction. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada. </address>
Reference: <author> Rabinowitz, H., Flamholz, J., Wolin, E., & Euchner, J. </author> <year> (1991). </year> <title> NYNEX MAX: A telephone trouble screening expert. </title> <booktitle> In Innovative Applications of Artificial Intelligence 3, </booktitle> <pages> (pp. 213-230), </pages> <address> Menlo Park, CA. </address>
Reference-contexts: Nonetheless, as was the case with the promoters, this theory still contains useful information about the presence of a transcription-termination site. A.3 NYNEX's MAX System: Finding Errors in Tele phone Lines The last domain I used is Nynex's Max system <ref> (Rabinowitz et al., 1991) </ref>. The following discussion is derived from Rabinowitz et al. (1991) and Provost and Danyluk (1995). Max is an expert system that was designed by Nynex to diagnose the location of customer-reported telephone problems. Figure 29 illustrates Max's task.
Reference: <author> Rich, E. </author> <year> (1983). </year> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference-contexts: Making this assumption allows us to alter the network in a fashion similar to refining symbolic rules. Towell (1991) demonstrated that making a similar assumption about Kbann networks was valid. In a symbolic rule base that uses negation-by-failure <ref> (Rich, 1983, Chapter 5) </ref>. one can decrease false negatives by either dropping antecedents from existing rules or adding new rules to the rule base. I showed (in Section 2.2.2) that Kbann is effective at removing antecedents from existing rules, but is unable to add new rules.
Reference: <author> Richards, B. </author> <year> (1995). </year> <title> Automated refinement of first-order horn-clause domain theories. </title> <journal> Machine Learning, </journal> <volume> 19 </volume> <pages> 95-131. </pages>
Reference-contexts: Systems such as Focl (Pazzani & Kibler, 1992) and Forte <ref> (Richards, 1995) </ref> are first-order, theory-refinement systems that revise predicate-logic theories. One drawback to these systems is that they currently do not generalize as well as connectionist approaches on many real-world problems, such as the DNA promoter task (Cohen, 1992).
Reference: <author> Roscheisen, M., Hofmann, R., & Tresp, V. </author> <year> (1991). </year> <title> Neural control for rolling mills: Incorporating domain theories to overcome data deficiency. </title> <editor> In Moody, J., Hanson, S., & Lippmann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 4), </booktitle> <pages> (pp. 659-666), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Rost, B. & Sander, C. </author> <year> (1993). </year> <title> Prediction of protein secondary structure at better than 70% accuracy. </title> <journal> Journal of Molecular Biology, </journal> <volume> 232 </volume> <pages> 584-599. </pages> <note> 135 Rumelhart, </note> <author> D., Durbin, D., Golden, R., & Chauvin, Y. </author> <year> (1995). </year> <title> Backpropagation: The basic theory. </title> <editor> In Chauvin, W. & Rumelhart, D., editors, Backpropagation: </editor> <booktitle> Theory, Architectures, and Applications, </booktitle> <pages> (pp. 1-34), </pages> <address> Hillsdale, NJ. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Rumelhart, D., Hinton, G., & Williams, R. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. & McClelland, J., editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the microstructure of cognition. Volume 1: Foundations. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: To generate such an algorithm, you might first try gathering examples of gene and 1 2 non-gene sequences from previously studied DNA. You could then apply an inductive-learning algorithm <ref> (e.g., backpropagation, Rumelhart et al., 1986, or C4.5, Quinlan, 1993) </ref> on these examples, producing a concept that predicts which ones encode genes. <p> These systems proceed by first translating the domain theory directly into a neural network, thereby determining the network's topology and initial weight settings. They then refine these reformulated rules using standard neural-learning techniques such as backpropagation <ref> (Rumelhart et al., 1986) </ref>. One of the most successful of these approaches is the Kbann system (Towell, 1991; Towell & Shavlik, 1994). Kbann is designed for domain theories represented by Prolog-style, propositional rules. <p> Most standard inductive learners such as backpropagation <ref> (Rumelhart et al., 1986) </ref> and ID3 (Quinlan, 1986), however, are unable to continually improve their answers (at least until they receive additional training examples). In fact, if run too long, these algorithms tend to "overfit" the training set (Holder, 1991). <p> My algorithms start by having the Kbann algorithm translate the domain theory directly into a neural network. Given the proven effectiveness of this method, this gives a good initial guess for an appropriate network topology and weight settings. I then train this network with standard learning techniques <ref> (Rumelhart et al., 1986) </ref> and score it according to its estimated generalization ability. I set aside a validation set 2 for use 2 A validation set is a subset of the training instances that is set aside before training. <p> = k @E fi @net k fi w ki : (4) Because we wish to reduce error, the magnitude of the actual weight change is: w ij (t) = fi @w ij where the scalar is the learning rate, and ff fi w ij (t 1) is the momentum term <ref> (Rumelhart et al., 1986) </ref>. The momentum term, similar to that of conjugate gradient's (Fletcher, 1987, Chapter 4), helps prevent the updates from oscillating wildly, encouraging changes that are made in the direction of the average downhill force. <p> The negative of the log of this probability gives us an error function, E, that is proportional to squared error. This is backpropagation's original, and still most common, error function. The activation function of the output nodes in this case was originally assumed to be the sigmoidal function <ref> (Rumelhart et al., 1986) </ref>; however, given the Guassian assumption of error, Rumelhart et al. (1995) show it makes more sense to have the output node's activation be a linear function of its net input. (Note the activation function for the hidden nodes is still commonly the sigmoidal function.) Making this assumption <p> Use the counters to order possible node corrections. High correctable-false negative counts suggest adding a disjunct, while high correctable-false-positive counts suggest adding a conjunct. 33 algorithm to create an initial guess for the network's topology. This network is trained using backpropagation <ref> (Rumelhart et al., 1986) </ref> and is placed on an OPEN list. In each cycle, TopGen takes the best network (as measured by validation-set-2) from the OPEN list, decides possible ways to add new nodes, trains these new networks, and places them on the OPEN list. <p> However, because a single first-order rule may map to many propositional rules over a set of inputs (variable-bindings), information is lost, such as which nodes and weights correspond to the same first-order rule. One may use weight sharing <ref> (Rumelhart et al., 1986) </ref> to cluster these weights, however these weights would then be unable to split into different clusters during training.
Reference: <author> Schiffmann, W., Joost, M., & Werner, R. </author> <year> (1992). </year> <title> Synthesis and performance analysis of multilayer neural network architectures. </title> <type> Technical Report 16, </type> <institution> University of Koblenz, Institute for Physics. </institution>
Reference: <author> Scott, G., Shavlik, J., & Ray, W. </author> <year> (1992). </year> <title> Refining PID controllers using neural networks. </title> <journal> Neural Computation, </journal> <volume> 5 </volume> <pages> 746-757. </pages>
Reference-contexts: Following network initialization, Kbann uses the available training instances to refine the network links. Refer to Towell (1991) or Towell and Shavlik (1994) for more details. Kbann has been successfully applied to many real-world problems, such as the control of a chemical plant <ref> (Scott et al., 1992) </ref>, protein folding (Maclin & Shavlik, 1993), finding genes in a sequence of DNA (Opitz & Shavlik, 1993; Towell & Shavlik, 1994), and ECG patient monitoring (Watrous et al., 1995).
Reference: <author> Sejnowski, T. & Rosenberg, C. </author> <year> (1987). </year> <title> Parallel networks that learn to pronounce English text. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 145-168. </pages>
Reference: <author> Sestito, S. & Dillon, T. </author> <year> (1990). </year> <title> Using multi-layered neural networks for learning symbolic knowledge. </title> <booktitle> In Proceedings of the 1990 Australian Artificial Intelligence Conference, </booktitle> <address> Perth, Australia. </address>
Reference: <author> Shapire, R. </author> <year> (1990). </year> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 197-227. </pages>
Reference: <author> Shavlik, J. </author> <year> (1994). </year> <title> Combining symbolic and neural learning. </title> <journal> Machine Learning, </journal> <volume> 14 </volume> <pages> 321-331. </pages>
Reference-contexts: I do this since some of the weights correspond to rules in a domain theory (as explained later in this chapter), and decaying weights toward their initial value helps prevent unnecessary changes to the domain theory <ref> (Shavlik, 1994) </ref>. 2.1.2 Finding an Appropriate Network Topology While Weigend (1993) showed that large networks with many parameters can generalize as well as small networks if training is stopped in time, his experiments only involved standard single-hidden-layer networks. <p> There are many proposed methods for combining symbolic and connectionist learning; however, in this thesis I concentrate only on the popular approach shown in Figure 5 <ref> (Shavlik, 1994) </ref>. <p> In fact, Towell and Shavlik (1993) presented an algorithm, called NofM, that is effectively able to extract rules from KNNs. Many systems, designed for different types of rule bases, have been successfully implemented within this framework. For instance, systems have been designed for Prolog-style proposition rules <ref> (Towell & Shavlik, 1994) </ref>, probabilistic rules (Fu, 1989; Mahoney & Mooney, 1994), finite-state grammars (Omlin & Giles, 1992; Maclin & Shav-lik, 1993), mathematical equations (Roscheisen et al., 1991; Scott et al., 1992), statements in an imperative programming language (Maclin & Shavlik, 1994), and finally fuzzy-logic rules (Berenji, 1991; Masuoka et al., <p> For instance, systems have been designed for Prolog-style proposition rules (Towell & Shavlik, 1994), probabilistic rules (Fu, 1989; Mahoney & Mooney, 1994), finite-state grammars (Omlin & Giles, 1992; Maclin & Shav-lik, 1993), mathematical equations (Roscheisen et al., 1991; Scott et al., 1992), statements in an imperative programming language <ref> (Maclin & Shavlik, 1994) </ref>, and finally fuzzy-logic rules (Berenji, 1991; Masuoka et al., 1990). As stated before, many of these approaches have been shown to generalize better than other learning systems. <p> As stated before, many of these approaches have been shown to generalize better than other learning systems. The reason for much of this success has been attributed to the domain theory (a) suggesting potentially useful intermediate terms and (b) focusing attention on relevant inputs <ref> (Shavlik, 1994) </ref>.
Reference: <author> Shavlik, J. & Dietterich, T., </author> <title> editors (1990). </title> <booktitle> Readings in Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Shavlik, J. & Towell, G. </author> <year> (1989). </year> <title> An approach to combining explanation-based and neural learning algorithms. </title> <journal> Connection Science, </journal> <volume> 1 </volume> <pages> 233-255. </pages>
Reference: <author> Stone, M. </author> <year> (1974). </year> <title> Cross-validation choice and assessment of statistical predictions. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 36 </volume> <pages> 111-147. </pages>
Reference: <author> Stormo, G. </author> <year> (1987). </year> <title> Identifying coding sequences. </title> <editor> In Bishop, M. J. & Rawlings, C. J., editors, </editor> <title> Nucleic Acid and Protein Sequence Analysis: A Practical Approach. </title> <publisher> IRL Press, Oxford, </publisher> <address> England. </address>
Reference-contexts: It then transcribes the DNA sequence into a similar RNA sequence, except that the nucleotide thymine is replaced with the nucleotide uracil (U). Translation occurs when the ribosome molecule reads the mRNA strand and assembles a protein chain. One common approach to finding genes is called search-by-signal <ref> (Stormo, 1987) </ref>. 112 input to the neural network is a subsequence (called a window) of DNA, and the classification task is to learn when the signal its learning to recognize is present at the reference point.
Reference: <author> Suzuki, D., Griffiths, A., Miller, J., & Lewontin, R. </author> <year> (1989). </year> <title> An Introduction to Genetic Analysis. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <note> fourth edition. </note>
Reference: <author> Tishby, N., Levin, E., & Solla, S. </author> <year> (1989). </year> <title> Consistent inference on probabilities in layered networks, predictions and generalization. </title> <booktitle> In International Joint Conference on Neural Networks, </booktitle> <pages> (pp. 403-410), </pages> <address> Washington, D.C. </address> <note> 136 Towell, </note> <author> G. </author> <year> (1991). </year> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement, and Extraction. </title> <type> PhD thesis, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, WI. </institution>
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1992). </year> <title> Using symbolic learning to improve knowledge-based neural networks. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 177-182), </pages> <address> San Jose, CA. </address>
Reference-contexts: Thus, their system does not take advantage of Kbann's strength of removing unwanted antecedents and rules from the original rule base. The DAID Algorithm The Daid algorithm <ref> (Towell & Shavlik, 1992) </ref> is an extension to Kbann that uses the domain theory to help train the Kbann network. As demonstrated in Section 2.2.2 and in Towell and Shavlik (1994), Kbann is more effective at dropping antecedents than adding them.
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1993). </year> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 71-101. </pages>
Reference-contexts: In particular, such systems are restricted in the types of refinements they can make to the theory. Hence when given impoverished domain theories, generalization suffers and the systems must significantly alter their original rules during training <ref> (which makes subsequent rule extraction, Towell and Shavlik, 1993, much harder) </ref>. * This thesis demonstrates the importance of anytime learning. <p> Future work, then, is to extract from trained networks human-comprehensible symbolic rules that are in a form similar to the initial rule set (Sestito & Dillon, 1990; Fu, 1991; Towell & Shavlik, 1993). One rule-extraction method designed specifically for KNNs is the NofM algorithm <ref> (Towell & Shavlik, 1993) </ref>. Since Kbann only adds and subtracts antecedents from existing rules, extracting rules from Kbann networks is relatively straight forward; however, it is more difficult to extract rules from neural networks that have not been initialized with a domain theory (Fu, 1991; Craven & Shavlik, 1993).
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1994). </year> <title> Knowledge-based artificial neural networks. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 119-165. </pages>
Reference-contexts: In fact, Towell and Shavlik (1993) presented an algorithm, called NofM, that is effectively able to extract rules from KNNs. Many systems, designed for different types of rule bases, have been successfully implemented within this framework. For instance, systems have been designed for Prolog-style proposition rules <ref> (Towell & Shavlik, 1994) </ref>, probabilistic rules (Fu, 1989; Mahoney & Mooney, 1994), finite-state grammars (Omlin & Giles, 1992; Maclin & Shav-lik, 1993), mathematical equations (Roscheisen et al., 1991; Scott et al., 1992), statements in an imperative programming language (Maclin & Shavlik, 1994), and finally fuzzy-logic rules (Berenji, 1991; Masuoka et al.,
Reference: <author> Tresp, V., Hollatz, J., & Ahmad, S. </author> <year> (1992). </year> <title> Network structuring and training using rule-based knowledge. </title> <editor> In Moody, J., Hanson, S., & Lippmann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 5), </booktitle> <pages> (pp. 871-878), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tresp, V. & Taniguchi, M. </author> <year> (1995). </year> <title> Combining estimators using non-constant weighting functions. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 7), </booktitle> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Tsoi, A. & Pearson, R. </author> <year> (1990). </year> <title> Comparison of three classification techniques, CART, C4.5, and multi-layer perceptrons. </title> <editor> In Lippmann, R., Moody, J., & Touretzky, D., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 3), </booktitle> <pages> (pp. 963-969), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Turney, P. </author> <year> (1995). </year> <title> Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 369-409. </pages>
Reference: <author> Uberbacher, E. C. & Mural, R. J. </author> <year> (1991). </year> <title> Locating protein coding regions in human DNA sequences using a neural network multiple sensor approach. </title> <booktitle> Proceedings of the National Academy of Sciences (USA), </booktitle> <volume> 88 </volume> <pages> 11261-11265. </pages>
Reference: <author> Wan, E. </author> <year> (1993). </year> <title> Time series prediction using a connectionist network with internal delay lines. </title> <editor> In Weigend, A. & Gershenfeld, N., editors, </editor> <title> Time Series Prediction: </title> <booktitle> Forecasting the Future and Understanding the Past, </booktitle> <pages> (pp. 195-217), </pages> <address> Reading, MA. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The winner on one dataset at The Santa Fe Time Series Prediction and Analysis Competition (Weigend & Gershenfeld, 1992), for instance, had a network with more potential parameters than training instances <ref> (Wan, 1993) </ref>. One approach to stop training at the right moment is to use a validation set (Weigend et al., 1990). This set is part of the training instances, but is not used during the training of the network.
Reference: <author> Watrous, R., Towell, G., & Glassman, M. </author> <year> (1995). </year> <title> Synthesize, optimize, analyze, repeat (SOAR): Application of neural network tools to ECG patient monitoring. </title> <booktitle> In Proceedings of the Workshop on Environmental and Energy Applications of Neural Networks, </booktitle> <address> Richland, WA. </address> <institution> 137 Watson, J. </institution> <year> (1990). </year> <title> The Human Genome Project: Past, present, and future. </title> <journal> Science, </journal> <volume> 248 </volume> <pages> 44-48. </pages>
Reference-contexts: Kbann has been successfully applied to many real-world problems, such as the control of a chemical plant (Scott et al., 1992), protein folding (Maclin & Shavlik, 1993), finding genes in a sequence of DNA (Opitz & Shavlik, 1993; Towell & Shavlik, 1994), and ECG patient monitoring <ref> (Watrous et al., 1995) </ref>. In each case, Kbann was shown to produce improvements in generalization over standard neural networks for small numbers of training examples.
Reference: <author> Watson, J. D., Hopkins, N. H., Roberts, J. W., Argetsinger Steitz, J., & Weiner, A. M. </author> <year> (1987). </year> <title> Molecular Biology of the Gene. </title> <address> Benjamin/Cummings, Menlo Park, CA, </address> <note> fourth edition. </note>
Reference: <author> Weigend, A. </author> <year> (1993). </year> <title> On overfitting and the effective number of hidden units. </title> <booktitle> In Proceedings of the 1993 Connectionist Models Summer School, </booktitle> <pages> (pp. 335-342), </pages> <address> Boulder, </address> <publisher> CO. </publisher>
Reference-contexts: Only as training progresses do the nodes start to diverge in their function. Therefore, the effective number of parameters is initially small, then increases during training. In fact, if training is stopped at the appropriate time, large networks tend to do as well as small, even "optimally" sized, networks <ref> (Weigend, 1993) </ref>. The winner on one dataset at The Santa Fe Time Series Prediction and Analysis Competition (Weigend & Gershenfeld, 1992), for instance, had a network with more potential parameters than training instances (Wan, 1993). <p> The complexity of the network cannot simply be estimated by counting the number of possible parameters, since there tends to be large duplication in the function of each weight in a network, especially early in the training process <ref> (Weigend, 1993) </ref>. Note that the standard weight-decay terms (Rumelhart et al., 1995) would be insufficient as smoothness terms, since these terms only take into account the distribution of the weights and ignore functional duplication.
Reference: <author> Weigend, A. & Gershenfeld, N. </author> <year> (1992). </year> <title> Time Series Prediction: Forecasting the Future and Understanding the Past. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: In fact, if training is stopped at the appropriate time, large networks tend to do as well as small, even "optimally" sized, networks (Weigend, 1993). The winner on one dataset at The Santa Fe Time Series Prediction and Analysis Competition <ref> (Weigend & Gershenfeld, 1992) </ref>, for instance, had a network with more potential parameters than training instances (Wan, 1993). One approach to stop training at the right moment is to use a validation set (Weigend et al., 1990).
Reference: <author> Weigend, A., Huberman, B., & Rumelhart, D. </author> <year> (1990). </year> <title> Predicting the future: A connectionist approach. </title> <journal> International Journal of Neural Systems, I:193-209. </journal>
Reference-contexts: The winner on one dataset at The Santa Fe Time Series Prediction and Analysis Competition (Weigend & Gershenfeld, 1992), for instance, had a network with more potential parameters than training instances (Wan, 1993). One approach to stop training at the right moment is to use a validation set <ref> (Weigend et al., 1990) </ref>. This set is part of the training instances, but is not used during the training of the network. Instead, one uses the validation set to estimate the performance of the network, and training is stopped when the performance of the validation set starts to decrease. <p> Drawbacks of using a validation set are that the size of the training set is decreased; its effectiveness can be sensitive to the particular stopping criteria used 19 <ref> (Weigend et al., 1990) </ref>; and it can be a noisy estimator of future performance (MacKay, 1992). Above, I focused on the accuracy term, lnP (DjN ) of Equation 7; I now switch to the prior-probability term, lnP (N ), while again following the discussion in Rumelhart et al. (1995).
Reference: <author> Weiss, S. M. & Kulikowski, C. A. </author> <year> (1990). </year> <title> Computer Systems that Learn. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: These differences are important since they determine 4 which concepts a classifier will induce. Experimental methods, based on setting aside a "test set" of instances, judge the generalization performance of the inductive learner <ref> (Weiss & Kulikowski, 1990, Chapter2) </ref>. The instances in the test set are not used during the training process, but only to estimate the learner's predictive accuracy.
Reference: <author> Werbos, P. </author> <year> (1974). </year> <title> Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences. </title> <type> PhD thesis, </type> <institution> Harvard University. </institution>
Reference: <author> Whitley, D. & Hanson, T. </author> <year> (1989). </year> <title> Optimizing neural networks using faster, more accurate genetic search. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> (pp. 391-396), </pages> <address> Arlington, VA. </address>
Reference: <author> Wilson, S. </author> <year> (1991). </year> <title> GA-easy does not imply steepest-ascent optimizable. </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> (pp. 85-89), </pages> <address> San Diego, CA. </address>
Reference: <author> Winston, P. </author> <year> (1975). </year> <title> Learning structural descriptions from examples. </title> <editor> In Winston, P., editor, </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <pages> (pp. 157-210), </pages> <address> New York. </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: TopGen increments a node's false-negatives counter in a similar fashion. By checking for single points of failure, TopGen looks for rules that are near misses <ref> (Winston, 1975) </ref>. After the counter values have been determined, TopGen sorts these counters in descending order, breaking ties by preferring nodes farthest from the output node. TopGen then creates N new networks, where each network contains a single correction (as determined by the first N sorted counters).
Reference: <author> Wolpert, D. </author> <year> (1992). </year> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 241-259. </pages>
Reference: <author> Wynne-Jones, M. </author> <year> (1991). </year> <title> Node splitting: A constructive algorithm for feed-forward neural networks. </title> <editor> In Moody, J., Hanson, S., & Lippmann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 4), </booktitle> <pages> (pp. 1072-1079), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Yao, X. </author> <year> (1993). </year> <title> Evolutionary artificial neural networks. </title> <journal> International Journal of Neural Systems, </journal> <volume> 4 </volume> <pages> 203-221. </pages>
Reference-contexts: Techniques that solely use genetic algorithms to optimize weights (Whitley & Hanson, 1989; Montana & Davis, 1989) have performed competitively with gradient-based training algorithms; however, one problem with genetic algorithms is their inefficiency in fine-tuned local search, thus the scalability of these methods are in question <ref> (Yao, 1993) </ref>. Kitano (1990b) presents a method that combines genetic algorithms with backpropagation. He does this by using the genetic algorithm to determine the starting weights for a network, which are then refined by backpropagation. <p> These methods are relatively straightforward to implement, and are good at fine tuning small networks (Miller et al., 1989); however, they do not scale well since they require very large matrices to represent all the links in large networks <ref> (Yao, 1993) </ref>. Other techniques (Harp et al., 1989; Kitano, 1990a; Dodd, 1990) only encode the most important features of the network, such as the number of hidden layers, the number of hidden nodes at each layer, etc. <p> These indirect encoding schemes can evolve different sets of parameters along with the network's topology and 93 have been shown to have good scalability <ref> (Yao, 1993) </ref>. Some techniques (Koza & Rice, 1991; Oliker et al., 1992) evolve both the architecture and connection weights at the same time; however, the combination of the two levels of evolution greatly increases the search space.
Reference: <author> Zhang, X., Mesirov, J., & Waltz, D. </author> <year> (1992). </year> <title> Hybrid system for protein secondary structure prediction. </title> <journal> Journal of Molecular Biology, </journal> <volume> 225 </volume> <pages> 1049-1063. </pages>
References-found: 143

