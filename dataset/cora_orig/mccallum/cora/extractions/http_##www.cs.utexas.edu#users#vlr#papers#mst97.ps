URL: http://www.cs.utexas.edu/users/vlr/papers/mst97.ps
Refering-URL: http://www.cs.utexas.edu/users/vlr/pub.html
Root-URL: 
Email: Email: ckpoon@cs.cityu.edu.hk.  Email: vlr@cs.utexas.edu.  
Phone: 2  
Title: A Randomized Linear Work EREW PRAM Algorithm to Find a Minimum Spanning Forest  
Author: Chung Keung Poon and Vijaya Ramachandran 
Address: Hong Kong, 83 Tat Chee Avenue, Kowloon, Hong Kong.  Austin, Austin, TX 78712, USA.  
Affiliation: 1 Department of Computer Science, City University of  Department of Computer Sciences, The University of Texas at  
Note: An Extended Abstract appears in Proc. ISAAC'97, LNCS 1350, pp. 212-222.  
Abstract: We present a randomized EREW PRAM algorithm to find a minimum spanning forest in a weighted undirected graph. On an n-vertex graph the algorithm runs in o((log n) 1+* ) expected time for any * &gt; 0 and performs linear expected work. This is the first linear work, polylog time algorithm on the EREW PRAM for this problem. This also gives parallel algorithms that perform expected linear work on two general-purpose models of parallel computation the QSM and the BSP.
Abstract-found: 1
Intro-found: 1
Reference: [Bor26] <editor> O. Boruvka. O jistem problemu minimalnim. Praca Moravske Prirodovedecke Spolecnosti, </editor> <volume> 3 </volume> <pages> 37-58, </pages> <year> 1926. </year> <note> In Czech. </note>
Reference-contexts: In each iteration of step 2, the parent pointers are set using a Bor ffi u vka step <ref> [Bor26] </ref>, and by the cut property, the corresponding edges are in the MSF for H [KKT95]. Thus F is a subset of the MSF for H. In each iteration of step 2a, each active vertex will hook to another active vertex.
Reference: [Cho96] <author> K. W. Chong. </author> <title> Finding minimum spanning trees on the EREW PRAM. </title> <booktitle> In Proceedings of the 1996 International Conference on Algorithms, </booktitle> <pages> pages 7-14, </pages> <address> Taiwan, </address> <year> 1996. </year>
Reference-contexts: Prior to our work, the best results known for the EREW PRAM were a deterministic algorithm by Chong <ref> [Cho96] </ref> which runs in O (log n log log n) time and performs O (m log n log log n) work, and a randomized algorithm reported in [Kar95] which, with high probability, runs in O (log n) time and performs O (m + n 1+* ) work for any constant * <p> Moreover, we stop the recursion when the size of the graph is reduced to a polylog factor of the original one. At this point, we switch to the deterministic algorithm of Chong <ref> [Cho96] </ref> which runs in O (log n 0 log log n 0 ) time and O (m 0 log n 0 log log n 0 ) work on a graph with n 0 vertices and m 0 edges.
Reference: [CKT94] <author> R. Cole, P.N. Klein, and R.E. Tarjan. </author> <title> A linear-work parallel algorithm for finding minimum spanning trees. </title> <booktitle> In Proceedings of the 1994 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 11-15, </pages> <year> 1994. </year>
Reference-contexts: There have been many algorithms designed for the MSF problem that run in close to linear time (see, e.g., [CLR91]). Recently a randomized linear-time algorithm for this problem was presented in [KKT95]. Based on this work <ref> [CKT94] </ref> presented a randomized parallel algorithm on the CRCW PRAM which runs in O (2 log fl n log n) expected time while performing linear work. The expected time was later improved to logarithmic by [CKT96]. <p> We also assume that G does not contain isolated vertices, so we have m dn=2e. Our algorithm can be viewed as a parallelization of [KKT95] and has a recursive structure similar to that of <ref> [CKT94] </ref>. As in these two algorithms, our algorithm makes use of the following well known properties (see [Tar83]). Cycle Property: For any cycle C in a graph, the heaviest edge in C does not appear in the MSF. <p> However, there will be l = fi (log k n) = fi (log n) levels of recursion and hence the parallel running time is (n * ) for some * &gt; 0. In <ref> [CKT94] </ref> a linear-work CRCW PRAM algorithm was presented by setting the reduction factor of a recursive call to the exponential of that of its parent call. With this reduction factor, the number of recursion levels was reduced to O (log fl m). The algorithm in [CKT94] requires a randomized CRCW PRAM <p> In <ref> [CKT94] </ref> a linear-work CRCW PRAM algorithm was presented by setting the reduction factor of a recursive call to the exponential of that of its parent call. With this reduction factor, the number of recursion levels was reduced to O (log fl m). The algorithm in [CKT94] requires a randomized CRCW PRAM in order to achieve logarithmic time in the local computation of each recursive call, and has an overall running time of O (log n 2 log fl m ). <p> In this paper we present a randomized linear-work parallel algorithm on the more restricted EREW PRAM model. As in <ref> [CKT94] </ref> our algorithm has O (log fl m) levels of recursion, but we perform each recursive call on an EREW PRAM in O (log n log log n) time, by designing an appropriate contraction procedure, and by using the O (log n) time, linear work EREW algorithm of [KPRS97] for the
Reference: [CKT96] <author> R. Cole, P.N. Klein, and R.E. Tarjan. </author> <title> Finding minimum spanning trees in logarithmic time and linear work using random sampling. </title> <booktitle> In Proceedings of the 1996 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 213-219, </pages> <year> 1996. </year>
Reference-contexts: Based on this work [CKT94] presented a randomized parallel algorithm on the CRCW PRAM which runs in O (2 log fl n log n) expected time while performing linear work. The expected time was later improved to logarithmic by <ref> [CKT96] </ref>. In this paper we consider the design of a linear-work parallel algorithm on a more restricted model of parallel computation the EREW PRAM. A major motivation for considering the EREW PRAM is the adaptability of an algorithm developed on this model to more realistic parallel computation models.
Reference: [CLR91] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction The design of efficient algorithms to find a minimum spanning forest (MSF) in a weighted undirected graph is a fundamental problem that has received much attention. There have been many algorithms designed for the MSF problem that run in close to linear time (see, e.g., <ref> [CLR91] </ref>). Recently a randomized linear-time algorithm for this problem was presented in [KKT95]. Based on this work [CKT94] presented a randomized parallel algorithm on the CRCW PRAM which runs in O (2 log fl n log n) expected time while performing linear work. <p> In deriving the above expression it was assumed that if the algorithm exceeds the time bound in Claim 11, the MSF is computed sequentially on one BSP processor using a standard sequential algorithm such as Kruskal's algorithm (see, e.g., <ref> [CLR91] </ref>). By choosing c sufficiently large (c &gt; 2 + log (g+L) log n should suffice) the second term can be made smaller than the first term, resulting in the desired result. ut Soon after hearing of our result, [DJR97] announced some results for finding an MSF on the BSP.
Reference: [DG97] <author> F. Dehne and S. Gotz. </author> <title> Efficient parallel minimum spanning algorithms for coarse grained multicomputers and BSP, </title> <month> June </month> <year> 1997. </year> <type> Manuscript, </type> <institution> Carleton University, </institution> <address> Ottawa, Canada. </address>
Reference-contexts: We have also been informed of recent independent work by <ref> [DG97] </ref> on BSP algorithms for the MSF problem. Both of these results are for minimizing the number of `supersteps' in the BSP computation, and they perform super-linear work on a general input graph.
Reference: [DJR97] <author> W. Dittrich, B. Juurlink, and I. Rieping, </author> <month> June </month> <year> 1997. </year> <title> Private communication by Ingo Rieping. </title>
Reference-contexts: By choosing c sufficiently large (c &gt; 2 + log (g+L) log n should suffice) the second term can be made smaller than the first term, resulting in the desired result. ut Soon after hearing of our result, <ref> [DJR97] </ref> announced some results for finding an MSF on the BSP. We have also been informed of recent independent work by [DG97] on BSP algorithms for the MSF problem.
Reference: [GMR94] <author> P.B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The QRQW PRAM: Accounting for contention in parallel algorithms. </title> <booktitle> In Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 638-648, </pages> <year> 1994. </year>
Reference-contexts: A major motivation for considering the EREW PRAM is the adaptability of an algorithm developed on this model to more realistic parallel computation models. In particular, the EREW PRAM (and the more powerful QRQW PRAM <ref> [GMR94] </ref>) are special cases of the Queuing Shared Memory (QSM) model [GMR97], which is a general-purpose shared-memory model of parallel computation.
Reference: [GMR97] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Can a shared-memory model serve as a bridging model for parallel computation? In Proceedings of the 1997 ACM Symposium on Parallel Algorithms and Architectures, </title> <address> pages 72-83, </address> <year> 1997. </year>
Reference-contexts: A major motivation for considering the EREW PRAM is the adaptability of an algorithm developed on this model to more realistic parallel computation models. In particular, the EREW PRAM (and the more powerful QRQW PRAM [GMR94]) are special cases of the Queuing Shared Memory (QSM) model <ref> [GMR97] </ref>, which is a general-purpose shared-memory model of parallel computation. It is shown in [GMR97] that the QSM (and hence the EREW PRAM) has a randomized work-preserving emulation with small slow-down on the Bulk Synchronous Parallel (BSP) computer [Val90], which is a general-purpose distributed-memory model of parallel computation. <p> In particular, the EREW PRAM (and the more powerful QRQW PRAM [GMR94]) are special cases of the Queuing Shared Memory (QSM) model <ref> [GMR97] </ref>, which is a general-purpose shared-memory model of parallel computation. It is shown in [GMR97] that the QSM (and hence the EREW PRAM) has a randomized work-preserving emulation with small slow-down on the Bulk Synchronous Parallel (BSP) computer [Val90], which is a general-purpose distributed-memory model of parallel computation. However, these results are not known to hold for the CRCW PRAM. <p> expected work on an EREW PRAM, where f = 1 + (log n log log n p the MSF can be computed in O (log n log log n) expected time and O (m) expected work on an EREW PRAM. 7 Adaptation to QSM and BSP Models The QSM model <ref> [GMR97] </ref> and the BSP model [Val90] are general-purpose models of parallel computation that take into account some of the important features of real parallel machines that are not reflected in the PRAM model. The QSM is a shared-memory model with a gap parameter g for access to global memory. <p> The BSP is a distributed memory model that consists of processor-memory units interconnected by a general-purpose interconnection network whose performance is parameterized by a gap parameter g as well as a periodicity parameter L. For a precise definition of the two models, see <ref> [Val90, GMR97] </ref>. It is straightforward to see ([GMR97]) that any EREW PRAM algorithm that runs in time t and work w is a QSM algorithm that runs in time g t and work g w. <p> For a precise definition of the two models, see [Val90, GMR97]. It is straightforward to see (<ref> [GMR97] </ref>) that any EREW PRAM algorithm that runs in time t and work w is a QSM algorithm that runs in time g t and work g w. Also, it is shown in [GMR97] that any QSM algorithm that needs to access r distinct memory locations must perform work (g r). <p> A minimum spanning forest for G can be computed on the QSM in expected time O (g T (n; m)) and expected work O (g (n + m)). The work bound is optimal. A randomized work-preserving emulation of the QSM on the BSP is presented in <ref> [GMR97] </ref> (see also [Ram97]) with the following performance. Claim 10. ([GMR97]) An algorithm that runs in time t 0 on a p 0 -processor QSM with gap parameter g can be emulated on a p-processor BSP with gap parameter g and periodicity parameter L in time t = O (t 0
Reference: [HZ96] <author> S. Halperin and U. Zwick. </author> <title> Optimal randomized EREW PRAM algorithms for finding spanning forests and for other basic graph connectivity problems. </title> <booktitle> In Proceedings of the Seventh ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 438-447, </pages> <year> 1996. </year>
Reference: [JM97] <author> D. B. Johnson and P. Metaxas. </author> <title> Connected components in O(log 3=2 n) parallel time for CREW PRAM. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 54 </volume> <pages> 227-242, </pages> <year> 1997. </year>
Reference-contexts: Proof. Step 1 requires O (1) time and O (jHj) work. In each iteration of step 2, step 2a takes O (log n) time and O (jHj) work, step 2b takes O (1) time and O (jHj) work using the edge plugging technique of Johnson and Metaxes <ref> [JM97] </ref>, and step 2c takes O (log jHj) = O (log n) time and O (jHj) work (this step is performed by broadcasting the name of the root to all elements in the newly-formed adjacency list, relabeling each edge by its new endpoints and then removing those edges whose two endpoints
Reference: [Kar93] <author> D. R. Karger. </author> <title> Random sampling in matroids, with applications to graph connectivity and minimum spanning trees. </title> <booktitle> In 34th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 84-93, </pages> <year> 1993. </year>
Reference-contexts: We can reduce the number of edges in G c by a factor = p k by using a random sampling technique first employed for the MSF problem by <ref> [Kar93, KKT95] </ref>. This method samples the edges in G c independently with probability p = 1= and then recursively computes the MSF, F , of the sampled graph, which has on average O (mp) = O (m=) edges. This is the first recursive call.
Reference: [Kar95] <author> D. R. Karger. </author> <title> Random Sampling in Graph Optimization Problems. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1995. </year>
Reference-contexts: Prior to our work, the best results known for the EREW PRAM were a deterministic algorithm by Chong [Cho96] which runs in O (log n log log n) time and performs O (m log n log log n) work, and a randomized algorithm reported in <ref> [Kar95] </ref> which, with high probability, runs in O (log n) time and performs O (m + n 1+* ) work for any constant * &gt; 0. 2 Outline of the algorithm Let G be a graph with n vertices and m edges. <p> Note that if m = (n (log n log log n) 2 ), then f = O (1). Otherwise, f = O (log n log log n). When m = (n (log n log log n) 2 ), this algorithm has the same performance as an algorithm in <ref> [Kar95] </ref> for the CREW PRAM, and it matches the time of (and performs less work than) Chong's algorithm. For m not much smaller than n (log n log log n) 2 , this algorithm runs faster than FindMSF, and it is no worse than it in any case. <p> We first describe a randomized EREW PRAM algorithm which computes the MSF in expected time O (log n log log n) and expected work O (mf ). The algorithm can be viewed as a combination (and generalization) of a CREW PRAM MSF algorithm in <ref> [Kar95] </ref> and the EREW PRAM MSF verification algorithm in [KPRS97]. Hence we will call it the K-KPRS algorithm. The generalization of the CREW PRAM algorithm of [Kar95] lies in the sampling probability used in K-KPRS - f =(log n log log n) in place of 1=(log n log log n) used <p> The algorithm can be viewed as a combination (and generalization) of a CREW PRAM MSF algorithm in <ref> [Kar95] </ref> and the EREW PRAM MSF verification algorithm in [KPRS97]. Hence we will call it the K-KPRS algorithm. The generalization of the CREW PRAM algorithm of [Kar95] lies in the sampling probability used in K-KPRS - f =(log n log log n) in place of 1=(log n log log n) used in [Kar95] (which is independent of the edge density). Algorithm K-KPRS requires mf =(log n log log n) processors and has the following steps. 1. <p> Hence we will call it the K-KPRS algorithm. The generalization of the CREW PRAM algorithm of <ref> [Kar95] </ref> lies in the sampling probability used in K-KPRS - f =(log n log log n) in place of 1=(log n log log n) used in [Kar95] (which is independent of the edge density). Algorithm K-KPRS requires mf =(log n log log n) processors and has the following steps. 1. Sample the edges in G independently with probability f =(log n log log n).
Reference: [KKT95] <author> D. R. Karger, P. N. Klein, and R. E. Tarjan. </author> <title> A randomized linear-time algorithm to find minimum spanning trees. </title> <journal> Journal of the ACM, </journal> <volume> 42 </volume> <pages> 321-328, </pages> <year> 1995. </year>
Reference-contexts: There have been many algorithms designed for the MSF problem that run in close to linear time (see, e.g., [CLR91]). Recently a randomized linear-time algorithm for this problem was presented in <ref> [KKT95] </ref>. Based on this work [CKT94] presented a randomized parallel algorithm on the CRCW PRAM which runs in O (2 log fl n log n) expected time while performing linear work. The expected time was later improved to logarithmic by [CKT96]. <p> We assume that edges in G have distinct weights, so the graph has a unique minimum spanning forest (MSF). We also assume that G does not contain isolated vertices, so we have m dn=2e. Our algorithm can be viewed as a parallelization of <ref> [KKT95] </ref> and has a recursive structure similar to that of [CKT94]. As in these two algorithms, our algorithm makes use of the following well known properties (see [Tar83]). Cycle Property: For any cycle C in a graph, the heaviest edge in C does not appear in the MSF. <p> We can reduce the number of edges in G c by a factor = p k by using a random sampling technique first employed for the MSF problem by <ref> [Kar93, KKT95] </ref>. This method samples the edges in G c independently with probability p = 1= and then recursively computes the MSF, F , of the sampled graph, which has on average O (mp) = O (m=) edges. This is the first recursive call. <p> This is the first recursive call. Although F is probably not the MSF of G c , it can be used to identify some edges in G c that are not in the MSF of G c . Following <ref> [KKT95] </ref>, an edge in G c is said to be F heavy if it forms a cycle when added to F and is heavier than every edge in that cycle. Edges in G c which are not F -heavy are said to be F light. <p> By the cycle property, F -heavy edges cannot be in the MSF of G c . Thus, to compute the MSF we need to consider only the F -light edges. By the sampling lemma (Lemma 2.1) of <ref> [KKT95] </ref>, the expected number of F -light edges in G c is at most O ((n=k)=p) = O (n=). <p> By setting k to a sufficiently large constant and recursing until the size of the graph is reduced to a constant, one can obtain a linear work algorithm <ref> [KKT95] </ref>. However, there will be l = fi (log k n) = fi (log n) levels of recursion and hence the parallel running time is (n * ) for some * &gt; 0. <p> Hence the sampling in step 3 produces a graph H s with O (m=k 3 j1 ) expected edges. Consequently, the recursive call to FindMSF (H s ; j 1; F ) in step 4 will satisfy the claim. By Lemma 2.1 in <ref> [KKT95] </ref> and Claim 7, expected number of edges in H 0 is O ((n=k 6 j1 ) = O (m=k 3 j1 ). Again, this bound is true even though H c may contain multiple edges. <p> In each iteration of step 2, the parent pointers are set using a Bor ffi u vka step [Bor26], and by the cut property, the corresponding edges are in the MSF for H <ref> [KKT95] </ref>. Thus F is a subset of the MSF for H. In each iteration of step 2a, each active vertex will hook to another active vertex. Done vertices are either isolated vertices or have given up all their edges to their roots in the previous iteration.
Reference: [KPRS97] <author> V. King, C. K. Poon, V. Ramachandran, and S. Sinha. </author> <title> An optimal EREW PRAM algorithm for minimum spanning tree verification. </title> <journal> Information Processing Letters, </journal> <volume> 62(3) </volume> <pages> 153-159, </pages> <year> 1997. </year>
Reference-contexts: As in [CKT94] our algorithm has O (log fl m) levels of recursion, but we perform each recursive call on an EREW PRAM in O (log n log log n) time, by designing an appropriate contraction procedure, and by using the O (log n) time, linear work EREW algorithm of <ref> [KPRS97] </ref> for the filtering step that detects F -heavy edges. Moreover, we stop the recursion when the size of the graph is reduced to a polylog factor of the original one. <p> We adapt the MSF verification algorithm in <ref> [KPRS97] </ref> to identify and remove the F -heavy edges. One method used to avoid concurrent reads in the algorithm in [KPRS97] is to convert the graph so that all endpoints of nontree edges are distinct. <p> We adapt the MSF verification algorithm in <ref> [KPRS97] </ref> to identify and remove the F -heavy edges. One method used to avoid concurrent reads in the algorithm in [KPRS97] is to convert the graph so that all endpoints of nontree edges are distinct. This is done using a scheme of [Ram96] that transforms each rooted tree in F by appending a chain to each vertex, with one copy of the vertex for each nontree edge incident on it. <p> It is not difficult to see that the least common ancestor of an edge is unaltered by this transformation. The same scheme when applied to the multigraph H will convert it into a simple graph in which all nontree edges have distinct endpoints. The algorithm in <ref> [KPRS97] </ref> can now be adapted in a straightforward way to identify F -heavy edges. Although that algorithm only determines whether or not there is an F -heavy edge in the graph, it is straightforward to modify it to identify all F -heavy edges within the same time and work bounds. <p> The algorithm can be viewed as a combination (and generalization) of a CREW PRAM MSF algorithm in [Kar95] and the EREW PRAM MSF verification algorithm in <ref> [KPRS97] </ref>. Hence we will call it the K-KPRS algorithm.
Reference: [Ram96] <author> V. Ramachandran. </author> <title> Private communication to Uri Zwick, </title> <month> January, </month> <year> 1996. </year> <note> To be included in journal version of [HZ96]. </note>
Reference-contexts: We adapt the MSF verification algorithm in [KPRS97] to identify and remove the F -heavy edges. One method used to avoid concurrent reads in the algorithm in [KPRS97] is to convert the graph so that all endpoints of nontree edges are distinct. This is done using a scheme of <ref> [Ram96] </ref> that transforms each rooted tree in F by appending a chain to each vertex, with one copy of the vertex for each nontree edge incident on it. It is not difficult to see that the least common ancestor of an edge is unaltered by this transformation.
Reference: [Ram97] <author> V. Ramachandran. </author> <title> A general purpose shared-memory model for parallel computation. </title> <type> Technical Report TR97-16, </type> <institution> Univ. of Texas at Austin, </institution> <year> 1997. </year>
Reference-contexts: A minimum spanning forest for G can be computed on the QSM in expected time O (g T (n; m)) and expected work O (g (n + m)). The work bound is optimal. A randomized work-preserving emulation of the QSM on the BSP is presented in [GMR97] (see also <ref> [Ram97] </ref>) with the following performance.
Reference: [Tar83] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1983. </year>
Reference-contexts: Our algorithm can be viewed as a parallelization of [KKT95] and has a recursive structure similar to that of [CKT94]. As in these two algorithms, our algorithm makes use of the following well known properties (see <ref> [Tar83] </ref>). Cycle Property: For any cycle C in a graph, the heaviest edge in C does not appear in the MSF. Cut Property: For any proper nonempty subset X of the vertices, the lightest edge with exactly one endpoint in X belongs to the MSF.
Reference: [Val90] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <year> 1990. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: It is shown in [GMR97] that the QSM (and hence the EREW PRAM) has a randomized work-preserving emulation with small slow-down on the Bulk Synchronous Parallel (BSP) computer <ref> [Val90] </ref>, which is a general-purpose distributed-memory model of parallel computation. However, these results are not known to hold for the CRCW PRAM. <p> PRAM, where f = 1 + (log n log log n p the MSF can be computed in O (log n log log n) expected time and O (m) expected work on an EREW PRAM. 7 Adaptation to QSM and BSP Models The QSM model [GMR97] and the BSP model <ref> [Val90] </ref> are general-purpose models of parallel computation that take into account some of the important features of real parallel machines that are not reflected in the PRAM model. The QSM is a shared-memory model with a gap parameter g for access to global memory. <p> The BSP is a distributed memory model that consists of processor-memory units interconnected by a general-purpose interconnection network whose performance is parameterized by a gap parameter g as well as a periodicity parameter L. For a precise definition of the two models, see <ref> [Val90, GMR97] </ref>. It is straightforward to see ([GMR97]) that any EREW PRAM algorithm that runs in time t and work w is a QSM algorithm that runs in time g t and work g w.
References-found: 19

