URL: ftp://ftp.cs.utexas.edu/pub/garbage/swizz.ps
Refering-URL: http://www.cs.utexas.edu/users/oops/papers.html
Root-URL: 
Email: wilson@cs.utexas.edu  
Title: Pointer Swizzling at Page Fault Time: Efficiently and Compatibly Supporting Huge Address Spaces on Standard
Author: Paul R. Wilson and Sheetal V. Kakkad W. Shakespeare, Hamlet, II:ii 
Address: Austin, Texas 78712-1188  
Affiliation: Department of Computer Sciences University of Texas  
Abstract: Pointers are translated ("swizzled") from a long format to a shorter hardware-supported format at page fault time. No extra hardware is required, and no continual software overhead is incurred by presence checks or indirection of pointers. This pagewise technique exploits temporal and spatial locality in much the same way as a normal virtual memory; this gives it many desirable performance characteristics, especially given the trend toward larger main memories. It is easy to implement using common compilers and operating systems. 
Abstract-found: 1
Intro-found: 1
Reference: [ABC + 83] <author> M.P. Atkinson, P.J. Bailey, K.J. Chis holm, P. W. Cockshott, and R. Morri-son. </author> <title> An approach to persistent programming. </title> <journal> The Computer Journal, </journal> <volume> 26(4) </volume> <pages> 360-365, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: Workshop on Object Orientation in Operating Systems, Paris, France, Sept. 24-25, 1992, pp. 364-377. (IEEE Press.) hardware can specify directly. Applications of large address spaces include distributed shared memories (e.g., [Li86]) operating systems with a single shared address space (e.g., [CLLBH92]), and persistent object stores (e.g., <ref> [ABC + 83, DSZ90] </ref>).
Reference: [AEL88] <author> Andrew W. Appel, John R. Ellis, and Kai Li. </author> <title> Real-time concurrent garbage collection on stock multiprocessors. </title> <booktitle> In Proceedings of SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20. </pages> <publisher> SIGPLAN ACM Press, </publisher> <month> June </month> <year> 1988. </year> <institution> Atlanta, Georgia. </institution>
Reference-contexts: This allows the checks to occur in parallel, as part of the normal functioning of the virtual memory system, and avoids continual overhead in software. Our approach is analogous to that of Appel, El-lis, and Li's incremental garbage collection scheme <ref> [AEL88] </ref>. Their system copies live (reachable) objects incrementally from "fromspace" to "tospace," to separate them from garbage objects 3 ; ours relocates pages of objects from persistent memory transient memory so that they may be directly addressed. Still, the basic principles of operation are the same. <p> These requirements are not much different from those of garbage collected systems that must perform pagewise (or "cardwise") operations <ref> [AEL88, WM89b] </ref> within the heap; there is no major difficulty supporting such operations efficiently for languages like Lisp or ML.
Reference: [AL91] <author> Andrew W. Appel and Kai Li. </author> <title> Virtual memory primitives for user programs. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV), </booktitle> <pages> pages 96-107, </pages> <address> April 1991. Santa Clara, CA. </address>
Reference-contexts: Compressed storage is likely to become increasingly important, whether at the level of file storage or as part of the virtual memory system <ref> [AL91, Wil91] </ref>. The problems of variable-sized units of storage are thus likely to be solved anyway, for entirely different reasons. Compressed storage is attractive for reducing storage costs, and for reducing average latency (by storing more data in fast memory and/or decreasing communication costs).
Reference: [Bak78] <author> Henry G. Baker, Jr. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: The pagewise wavefront of compression mappings is a purely pagewise analogue of Baker's "read barrier" technique for traversing objects in incremental tracing garbage collection <ref> [Bak78, Bak92, Wil92] </ref>.
Reference: [Bak92] <author> Henry G. Baker, Jr. </author> <title> The Treadmill: Real-time garbage collection without motion sickness. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(3) </volume> <pages> 66-70, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The pagewise wavefront of compression mappings is a purely pagewise analogue of Baker's "read barrier" technique for traversing objects in incremental tracing garbage collection <ref> [Bak78, Bak92, Wil92] </ref>.
Reference: [Bar88] <author> Joel F. Bartlett. </author> <title> Compacting garbage collection with ambiguous roots. </title> <type> Technical Report 88/2, </type> <institution> Digital Equipment Corporation Western Research Laboratory, Palo Alto, California, </institution> <month> February </month> <year> 1988. </year>
Reference-contexts: It is even possible to do pointer swizzling for programs compiled with standard off-the-shelf compilers. It is only necessary to treat the stack conservatively, as is done by garbage collectors developed for off-the-shelf compilers <ref> [BW88, Bar88, Det90, WH91, Det92] </ref>. Any bit pattern within the stack which could represent a pointer must be conservatively assumed to be a pointer. The pointed-to page is then "pinned" in the transient address space, because the page can't be relocated without invalidating the (possible) pointer.
Reference: [BMBC91] <author> Hans-Juergen Boehm, Eliot Moss, Joel Bartlett, and David Chase. </author> <title> Panel discussion: Conservative vs. accurate garbage collection. (Summary appears in Wilson and Hayes' OOPSLA '91 GC workshop report.), </title> <year> 1991. </year>
Reference-contexts: A better technique in the long term is to ensure that compilers don't violate the invariants unnecessarily [Boe91], or that they record clarifying information when they do <ref> [DMH92, WH91, BMBC91] </ref>; we believe compilers should retain this kind of information anyway, to support "de-optimizing" in source-level debuggers (e.g., [HCU92]). 13 It is not difficult to swap a page from one machine's address space to another's, and back.
Reference: [Boe91] <author> Hans-Juergen Boehm. </author> <title> Hardware and operating system support for conservative garbage collection. </title> <booktitle> In International Workshop on Memory Management, </booktitle> <pages> pages 61-67, </pages> <address> Palo Alto, California, </address> <month> October </month> <year> 1991. </year> <note> IEEE Press. </note>
Reference-contexts: A more expensive upgrade would be a full-blown 64-bit CPU. 10 The main restriction is the avoidance of untagged unions holding pointers in the variant part. Another is the avoidance of storing intermediate values from pointer arithmetic expressions, without retaining an actual pointer to the object <ref> [BW88, Boe91] </ref>. 11 Untagged unions are not very attractive in C++, because of its object-oriented features, and most pointer arithmetic that breaks garbage collection (or pointer swizzling) relies on un-portable assumptions anyway. 12 The easy way is to forgo certain advanced optimizations, as is done by several systems that use C <p> A better technique in the long term is to ensure that compilers don't violate the invariants unnecessarily <ref> [Boe91] </ref>, or that they record clarifying information when they do [DMH92, WH91, BMBC91]; we believe compilers should retain this kind of information anyway, to support "de-optimizing" in source-level debuggers (e.g., [HCU92]). 13 It is not difficult to swap a page from one machine's address space to another's, and back.
Reference: [BW88] <author> Hans-Juergen Boehm and Mark Weiser. </author> <title> Garbage collection in an uncooperative environment. </title> <journal> Software Practice and Experience, </journal> <volume> 18(9) </volume> <pages> 807-820, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Slightly conservative versions of these schemes will work well for languages with derived pointers and (limited) pointer arithmetic, in much the same way that conservative garbage collectors operate with languages like C <ref> [BW88] </ref>. The main modifications are to the allocation and deallocation routines, which must provide headers and/or groupings and/or alignment restrictions to allow objects to be identified. Large objects still pose a potential problem for our system, in terms of exhaustion of the hardware address space. <p> A more expensive upgrade would be a full-blown 64-bit CPU. 10 The main restriction is the avoidance of untagged unions holding pointers in the variant part. Another is the avoidance of storing intermediate values from pointer arithmetic expressions, without retaining an actual pointer to the object <ref> [BW88, Boe91] </ref>. 11 Untagged unions are not very attractive in C++, because of its object-oriented features, and most pointer arithmetic that breaks garbage collection (or pointer swizzling) relies on un-portable assumptions anyway. 12 The easy way is to forgo certain advanced optimizations, as is done by several systems that use C <p> It is even possible to do pointer swizzling for programs compiled with standard off-the-shelf compilers. It is only necessary to treat the stack conservatively, as is done by garbage collectors developed for off-the-shelf compilers <ref> [BW88, Bar88, Det90, WH91, Det92] </ref>. Any bit pattern within the stack which could represent a pointer must be conservatively assumed to be a pointer. The pointed-to page is then "pinned" in the transient address space, because the page can't be relocated without invalidating the (possible) pointer.
Reference: [Cat91] <author> R. G. G. Cattell. </author> <title> An engineering database benchmark. </title> <editor> In Jim Gray, editor, </editor> <booktitle> The Benchmark Handbook for Database and Transaction Processing Systems, </booktitle> <pages> pages 247-281. </pages> <address> Morgan-Kaufman, </address> <year> 1991. </year>
Reference-contexts: The virtual memory system and file caches were flushed to disk by reading and writing unrelated data before the start of the benchmark.) The plots show the time taken to perform each of 10 iterations of the "traversal" component of the OO1 benchmark <ref> [Cat91] </ref>, using the standard small OO1 test database. The database consists of 20,000 "part" objects, representing parts in a hypothetical engineering database application. <p> Only the calls to new () were changed, so that objects would be allocated on the persistent heap pages that are already in memory by repeating previous iterations. against the large OO1 database (including 200,000 part objects), which will not fit in memory <ref> [Cat91] </ref>. The startup effects of filesystem fetching quickly diminish, and the performance of both systems is dominated by virtual memory paging costs. After the first 30 iterations or so, the performance of Texas is about 93% of the performance of C++.
Reference: [CLLBH92] <author> Jeffrey S. Chase, Henry M. Levy, Ed ward D. Lazowska, and Miche Baker-Harvey. </author> <title> Lightweight shared objects in a 64-bit operating system. </title> <booktitle> In ACM SIG-PLAN 1992 Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '92), </booktitle> <address> Van-couver, British Columbia, Canada, </address> <month> Octo-ber </month> <year> 1992. </year>
Reference-contexts: Workshop on Object Orientation in Operating Systems, Paris, France, Sept. 24-25, 1992, pp. 364-377. (IEEE Press.) hardware can specify directly. Applications of large address spaces include distributed shared memories (e.g., [Li86]) operating systems with a single shared address space (e.g., <ref> [CLLBH92] </ref>), and persistent object stores (e.g., [ABC + 83, DSZ90]). <p> And if current trends change toward lower-density, higher-speed materials (e.g., GaAs or Joseph-son junctions), word size may again become critical, and we can provide a graceful "downgrade" path. In <ref> [CLLBH92] </ref>, Chase et al. argue that 64-bit computers eliminate the need to play tricks with address spaces, either in the conventional way of interpreting addresses differently for each process, or by pointer swizzling. <p> We also believe that it may be desirable to adopt a no-reuse policy toward virtual addresses|that is, when an object is deallocated, its (long, conceptual) address should not be reused. Just as <ref> [CLLBH92] </ref> advocates the separation of addressing from protection, we advocate the separation of addressing and protection from storage. Reusing memory should not necessarily entail reusing part of the global address space, even within a single thread of computation. This separation of concerns could have several benefits.
Reference: [Det90] <author> David L. Detlefs. </author> <title> Concurrent garbage col lection for C++. </title> <type> Technical Report CMU-CS-90-119, </type> <institution> Carnegie-Mellon University, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: It is even possible to do pointer swizzling for programs compiled with standard off-the-shelf compilers. It is only necessary to treat the stack conservatively, as is done by garbage collectors developed for off-the-shelf compilers <ref> [BW88, Bar88, Det90, WH91, Det92] </ref>. Any bit pattern within the stack which could represent a pointer must be conservatively assumed to be a pointer. The pointed-to page is then "pinned" in the transient address space, because the page can't be relocated without invalidating the (possible) pointer.
Reference: [Det92] <author> David L. Detlefs. </author> <title> Garbage collection and runtime typing as a C++ library. </title> <booktitle> In USENIXC++ Conference, </booktitle> <address> Portland, Oregon, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: It is even possible to do pointer swizzling for programs compiled with standard off-the-shelf compilers. It is only necessary to treat the stack conservatively, as is done by garbage collectors developed for off-the-shelf compilers <ref> [BW88, Bar88, Det90, WH91, Det92] </ref>. Any bit pattern within the stack which could represent a pointer must be conservatively assumed to be a pointer. The pointed-to page is then "pinned" in the transient address space, because the page can't be relocated without invalidating the (possible) pointer.
Reference: [DMH92] <author> Amer Diwan, Eliot Moss, and Richard Hudson. </author> <title> Compiler support for garbage collection in a statically-typed language. </title> <booktitle> In SIGPLAN Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 273-282, </pages> <address> San Francisco, Cali-fornia, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: A better technique in the long term is to ensure that compilers don't violate the invariants unnecessarily [Boe91], or that they record clarifying information when they do <ref> [DMH92, WH91, BMBC91] </ref>; we believe compilers should retain this kind of information anyway, to support "de-optimizing" in source-level debuggers (e.g., [HCU92]). 13 It is not difficult to swap a page from one machine's address space to another's, and back.
Reference: [DSZ90] <author> Alan Dearle, Gail M. Shaw, and Stan ley B. Zdonik, </author> <title> editors. Implementing Persistent Object Bases: </title> <booktitle> Principles and Practice (Proceedings of the Fourth International Workshop on Persistent Object Systems). </booktitle> <publisher> Morgan Kauf-man, </publisher> <address> Martha's Vineyard, Massachusetts, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Workshop on Object Orientation in Operating Systems, Paris, France, Sept. 24-25, 1992, pp. 364-377. (IEEE Press.) hardware can specify directly. Applications of large address spaces include distributed shared memories (e.g., [Li86]) operating systems with a single shared address space (e.g., [CLLBH92]), and persistent object stores (e.g., <ref> [ABC + 83, DSZ90] </ref>). <p> When stored in compressed format, they may be broken into smaller blocks to reduce fragmentation problems. 9 Related Work While there are quite a few persistent storage systems (see, e.g., <ref> [DSZ90] </ref>), to the best of our knowledge only one uses virtual memory techniques to allow pointer swizzling at page fault time (avoiding continual runtime overhead) and supports a very large address space. That is ObjectStore, a commercially available system [LLOW91] from Object Design, Inc.
Reference: [FB88] <author> Stuart I. Feldman and Channing B. Brown. IGOR: </author> <title> A system for program debugging via reversible execution. </title> <booktitle> In ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <month> May </month> <year> 1988. </year> <note> Also distributed as SIGPLAN Notices 24(1) 112-123, </note> <month> January, </month> <year> 1989, </year> <pages> pp. 112-123. </pages>
Reference-contexts: One would be that debugging long-lived processes would be much easier, because distinct objects would have distinct addresses over time|an address would not be reused for a new object. (This would be especially desirable in the context of a time-travel debugging system <ref> [WM89a, FB88, TA90] </ref>.) Along with this ability to distinguish distinct objects over time comes the possibility of detecting most uses of dangling pointers. If empty virtual pages are not reused, they can simply be access protected and have their storage reclaimed.
Reference: [FP91] <author> Matthew Farrens and Arvin Park. </author> <title> Dy namic base register caching: A technique for reducing address bus width. </title> <booktitle> In Proc. 18th Annual Int'l Symposium on Computer Architecture, </booktitle> <pages> pages 128-137, </pages> <month> May </month> <year> 1991. </year> <institution> Toronto, Canada. </institution>
Reference-contexts: It is therefore philosophically akin to dynamic base register caching <ref> [FP91] </ref>, but entirely different in its implementation. Our scheme incrementally constructs a compression table (mapping long persistent page numbers to short transient ones), which is rebuilt when its alphabet is exhausted (that is, when the transient page numbers are used up).
Reference: [Gri89] <author> Knut S. Grimsrud. </author> <title> Multiple prefetch adaptive disk caching with strategic data layout. </title> <type> Master's thesis, </type> <institution> Brigham Young University, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: log structured file systems|that is, the location of a block may change over time to maximize effective write bandwidth [RO91] and possibly adapt 15 Our attitude toward address space might be summed up as "crunch all you want|we'll make more." to observed patterns of disk usage to reduce read latencies <ref> [Gri89, Wil91] </ref>. Compressed storage is likely to become increasingly important, whether at the level of file storage or as part of the virtual memory system [AL91, Wil91]. The problems of variable-sized units of storage are thus likely to be solved anyway, for entirely different reasons.
Reference: [Hay91] <author> Barry Hayes. </author> <title> Using key object oppor tunism to collect old objects. </title> <booktitle> In ACM SIGPLAN 1991 Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '91), </booktitle> <pages> pages 33-46, </pages> <address> Phoenix, Arizona, </address> <month> October </month> <year> 1991. </year> <note> ACM Press. </note>
Reference-contexts: We believe that the clustered births and deaths of objects <ref> [Hay91] </ref> will frequently cause entire pages to become empty, however; small pages and/or sub-page protections would also make this more effective. 11 Current Status and Future Work Our initial prototype persistent store for Scheme [Wil91] lacked recovery features and a body of data-intensive programs to truly stress it, so was little
Reference: [HCU92] <author> Urs Hoelzle, Craig Chambers, and David Ungar. </author> <title> Debugging optimized code with dynamic deoptimization. </title> <booktitle> In SIGPLAN Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 32-43, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: A better technique in the long term is to ensure that compilers don't violate the invariants unnecessarily [Boe91], or that they record clarifying information when they do [DMH92, WH91, BMBC91]; we believe compilers should retain this kind of information anyway, to support "de-optimizing" in source-level debuggers (e.g., <ref> [HCU92] </ref>). 13 It is not difficult to swap a page from one machine's address space to another's, and back.
Reference: [Kae81] <author> T. Kaehler. </author> <title> Virtual memory for an object-oriented language. </title> <journal> Byte, </journal> <volume> 6(8) </volume> <pages> 378-387, </pages> <month> August </month> <year> 1981. </year>
Reference-contexts: One problem in implementing such large memories is that it involves addressing a huge number of objects, potentially more than can be 1 specified by the hardware's address bits. Schemes for supporting large virtual addresses on normal hardware (e.g., LOOM <ref> [Kae81, Sta82] </ref>, E [WD92], and Mneme [Mos90]) typically incur significant overhead. Two approaches are commonly used to implement large address spaces in software. One is to indirect pointers through an object table, and translate large identifiers into object table offsets when objects are brought into memory.
Reference: [Lev84] <author> Henry M. Levy. </author> <title> Capability-Based Com puter Systems. </title> <publisher> Digital Press, </publisher> <address> Bedford, Massachusetts, </address> <year> 1984. </year>
Reference-contexts: Ideally, we would like this mechanism to operate efficiently on standard hardware, rather than requiring an exotic "object-oriented" hardware memory hierarchy such as that of the MUSHROOM project [WWH87] or capability-based addressing schemes (e.g., <ref> [Lev84] </ref>, [Ros91].). For simplicity, much of this paper is cast in terms of persistent memories, because our current implementation focus is on persistent object stores.
Reference: [Li86] <author> Kai Li. </author> <title> Shared Virtual Memory on Loosely-Coupled Processors. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1986. </year>
Reference-contexts: Workshop on Object Orientation in Operating Systems, Paris, France, Sept. 24-25, 1992, pp. 364-377. (IEEE Press.) hardware can specify directly. Applications of large address spaces include distributed shared memories (e.g., <ref> [Li86] </ref>) operating systems with a single shared address space (e.g., [CLLBH92]), and persistent object stores (e.g., [ABC + 83, DSZ90]).
Reference: [LLOW91] <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The Ob-jectStore database system. </title> <journal> Communica tions of the ACM, </journal> <volume> 34(10) </volume> <pages> 50-63, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: mismatches between representations (e.g., one 1 This terminology is appropriate in terms of our address translation scheme as well|long addresses conceptually endure over time, but they may be mapped in changing (transient) ways to different virtual memory addresses. 2 A similar approach (developed independently) appears to be used in ObjectStore <ref> [LLOW91] </ref>, a commercial product from Object Design, Inc. <p> That is ObjectStore, a commercially available system <ref> [LLOW91] </ref> from Object Design, Inc. Their system was designed independently of ours, and apparently predates it. We believe that it operates by similar means, but no details have been published.
Reference: [MG89] <author> Jose Alves Marques and Paulo Guedes. </author> <title> Extending the operating system to support an object-oriented environment. </title> <booktitle> In ACM SIGPLAN 1989 Conference on Object Oriented Programming Systems, Languages and Applications (OOP-SLA '89), </booktitle> <pages> pages 113-122, </pages> <address> New Orleans, Louisiana, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: on 64-bit machines, and also on 32-bit machines|but only half of the field is used for transient pointers on 32-bit machines. (As mentioned above, the other half of the field goes to waste, but this space cost is relatively small.) This is similar to the approach used in the Commandos <ref> [MG89] </ref> operating system, where object identifiers are used on disk, but they are swizzled to actual pointers in memory.
Reference: [Mos90] <author> J. Eliot B. Moss. </author> <title> Working with objects: To swizzle or not to swizzle? Technical Report 90-38, </title> <institution> University of Mas-sachusetts, Amherst, Massachusetts, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: One problem in implementing such large memories is that it involves addressing a huge number of objects, potentially more than can be 1 specified by the hardware's address bits. Schemes for supporting large virtual addresses on normal hardware (e.g., LOOM [Kae81, Sta82], E [WD92], and Mneme <ref> [Mos90] </ref>) typically incur significant overhead. Two approaches are commonly used to implement large address spaces in software. One is to indirect pointers through an object table, and translate large identifiers into object table offsets when objects are brought into memory. <p> This may involve checking each pointer at each use, to see if it is an actual address. White and Dewitt refer to this as swizzling on discovery [WD92]; it is also possible to swizzle all of the pointers in an object at once, the first time it is touched <ref> [Mos90] </ref>. In either case, pointer fields or objects must be checked very frequently to see if they've been swizzled yet, so that unswizzled pointers can be swizzled before being traversed.
Reference: [RO91] <author> Mendel Rosenblum and John K. Ouster hout. </author> <title> The design and implementation of a log-structured file system. </title> <booktitle> In Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 1-15, </pages> <address> Pacific Grove, California, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Block mobility is increasingly important, as in the case of log structured file systems|that is, the location of a block may change over time to maximize effective write bandwidth <ref> [RO91] </ref> and possibly adapt 15 Our attitude toward address space might be summed up as "crunch all you want|we'll make more." to observed patterns of disk usage to reduce read latencies [Gri89, Wil91].
Reference: [Ros91] <author> John Rosenberg. </author> <title> Architectural support for persistent objects. </title> <booktitle> In 1991 Int'l Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 48-60. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1991. </year> <institution> Palo Alto, California. </institution>
Reference-contexts: Ideally, we would like this mechanism to operate efficiently on standard hardware, rather than requiring an exotic "object-oriented" hardware memory hierarchy such as that of the MUSHROOM project [WWH87] or capability-based addressing schemes (e.g., [Lev84], <ref> [Ros91] </ref>.). For simplicity, much of this paper is cast in terms of persistent memories, because our current implementation focus is on persistent object stores.
Reference: [SKW92] <author> Vivek Singhal, Sheetal V. Kakkad, and Paul R. Wilson. </author> <title> Texas: an efficient, portable persistent store. </title> <booktitle> In Fifth International Workshop on Persistent Object Systems, </booktitle> <address> Pisa, Italy, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: It is not necessary to recompile libraries, for example, as long as transient objects are not expected to persist or survive across crashes. Transient objects may hold pointers to persistent objects, and vice versa, as long as they follow a few simple rules <ref> [SKW92] </ref>. (Naturally, more alternatives are possible if the source is available. <p> to perform address translation at page fault time. (Performance problems with our (bytecoded) Scheme system also prevented us from precisely measuring the overheads of pointer swizzling|the swizzling cost were too low compared to the overhead of interpretation.) We have recently constructed a new, highly-portable persistent store for C++, called Texas <ref> [SKW92] </ref>. The current implementation, running on unmodified ULTRIX, incurs unnecessary costs due to difficulties in avoiding allocating backing store and bypassing file system caching. <p> The database consists of 20,000 "part" objects, representing parts in a hypothetical engineering database application. The parts are indexed by 19 We are currently implementing several improvements; these will be reported in <ref> [SKW92] </ref>, including with details of our new log-structured storage manager and its effects on checkpointing costs. part number, with the index implemented as an AVL tree 20 .
Reference: [Sta82] <author> James William Stamos. </author> <title> A large object oriented virtual memory: Grouping strategies, measurements, and performance. </title> <type> Technical Report SCG-82-2, </type> <institution> Xe-rox Palo Alto Research Centers, Palo Alto, California, </institution> <month> May </month> <year> 1982. </year>
Reference-contexts: One problem in implementing such large memories is that it involves addressing a huge number of objects, potentially more than can be 1 specified by the hardware's address bits. Schemes for supporting large virtual addresses on normal hardware (e.g., LOOM <ref> [Kae81, Sta82] </ref>, E [WD92], and Mneme [Mos90]) typically incur significant overhead. Two approaches are commonly used to implement large address spaces in software. One is to indirect pointers through an object table, and translate large identifiers into object table offsets when objects are brought into memory. <p> and persistent addresses|only the page numbers must be recorded, not individual objects. (It also comports well with page faulting|we believe it is desirable to bring objects into memory a whole page at a time anyway; caching pages is usually more attractive than object faulting when main memories are not small <ref> [Sta82, Wil91, WD92] </ref>.) the figure shows some data objects in pages of the persistent store, with persistent-format (i.e., long) pointers between them. When a program is given access to 4 Thanks to Ralph Johnson for this; our original conception adhered too slavishly to the Appel-Ellis-Li model and relocated individual objects.
Reference: [TA90] <author> Andrew Tolmach and Andrew Appel. </author> <title> De bugging Standard ML without reverse engineering. </title> <booktitle> In SIGPLAN Symposium on LISP and Functional Programming, </booktitle> <year> 1990. </year>
Reference-contexts: One would be that debugging long-lived processes would be much easier, because distinct objects would have distinct addresses over time|an address would not be reused for a new object. (This would be especially desirable in the context of a time-travel debugging system <ref> [WM89a, FB88, TA90] </ref>.) Along with this ability to distinguish distinct objects over time comes the possibility of detecting most uses of dangling pointers. If empty virtual pages are not reused, they can simply be access protected and have their storage reclaimed.
Reference: [WD92] <author> Seth J. White and David J. Dewitt. </author> <title> A performance study of alternative object faulting and pointer swizzling strategies. </title> <booktitle> In 18th International Conference on Very Large Data Bases, </booktitle> <address> Vancouver, British Columbia, Canada, </address> <month> October </month> <year> 1992. </year> <note> To appear. </note>
Reference-contexts: One problem in implementing such large memories is that it involves addressing a huge number of objects, potentially more than can be 1 specified by the hardware's address bits. Schemes for supporting large virtual addresses on normal hardware (e.g., LOOM [Kae81, Sta82], E <ref> [WD92] </ref>, and Mneme [Mos90]) typically incur significant overhead. Two approaches are commonly used to implement large address spaces in software. One is to indirect pointers through an object table, and translate large identifiers into object table offsets when objects are brought into memory. <p> This may involve checking each pointer at each use, to see if it is an actual address. White and Dewitt refer to this as swizzling on discovery <ref> [WD92] </ref>; it is also possible to swizzle all of the pointers in an object at once, the first time it is touched [Mos90]. <p> and persistent addresses|only the page numbers must be recorded, not individual objects. (It also comports well with page faulting|we believe it is desirable to bring objects into memory a whole page at a time anyway; caching pages is usually more attractive than object faulting when main memories are not small <ref> [Sta82, Wil91, WD92] </ref>.) the figure shows some data objects in pages of the persistent store, with persistent-format (i.e., long) pointers between them. When a program is given access to 4 Thanks to Ralph Johnson for this; our original conception adhered too slavishly to the Appel-Ellis-Li model and relocated individual objects. <p> Both C++ and Texas approach the same speed as the virtual memory "warms up", i.e., as more and more pages have been faulted into main memory. This is to be expected, since Texas incurs little or no overhead except at page fault time. Following White and Dewitt <ref> [WD92] </ref>, we also show the "hot" traversal time, traversing only 20 We used the standard AVLMap template (parameterized) class from the Free Software Foundation's GNU C++ library.
Reference: [WH91] <author> Paul R. Wilson and Barry Hayes. </author> <booktitle> The 1991 OOPSLA Workshop on Garbage Collection in Object Oriented Systems (organizers' report). In Addendum to the proceedings of OOPSLA '91, </booktitle> <address> Phoenix, Arizona, </address> <year> 1991. </year>
Reference-contexts: It is even possible to do pointer swizzling for programs compiled with standard off-the-shelf compilers. It is only necessary to treat the stack conservatively, as is done by garbage collectors developed for off-the-shelf compilers <ref> [BW88, Bar88, Det90, WH91, Det92] </ref>. Any bit pattern within the stack which could represent a pointer must be conservatively assumed to be a pointer. The pointed-to page is then "pinned" in the transient address space, because the page can't be relocated without invalidating the (possible) pointer. <p> A better technique in the long term is to ensure that compilers don't violate the invariants unnecessarily [Boe91], or that they record clarifying information when they do <ref> [DMH92, WH91, BMBC91] </ref>; we believe compilers should retain this kind of information anyway, to support "de-optimizing" in source-level debuggers (e.g., [HCU92]). 13 It is not difficult to swap a page from one machine's address space to another's, and back.
Reference: [Wil91] <author> Paul R. Wilson. </author> <title> Operating system sup port for small objects. </title> <booktitle> In International Workshop on Object Orientation in Operating Systems, </booktitle> <address> Palo Alto, California, </address> <month> Oc-tober </month> <year> 1991. </year> <note> IEEE Press. Revised version to appear in Computing Systems. </note>
Reference-contexts: Persistent memories, like file systems, may outlive the processes that create them. 1 .) 2 Address Translation at Page-Fault Time Our approach is to fault pages into conventional virtual memory on demand, translating long persistent-memory addresses into normal hardware-supported addresses at page-fault time <ref> [Wil91] </ref>. 2 This strategy exploits locality of reference in much the same way as a normal virtual memory; we believe this pagewise approach is increasingly attractive as main memories grow larger. (As the number of instructions executed between page faults goes up, the cost of address translation can be amortized across <p> and persistent addresses|only the page numbers must be recorded, not individual objects. (It also comports well with page faulting|we believe it is desirable to bring objects into memory a whole page at a time anyway; caching pages is usually more attractive than object faulting when main memories are not small <ref> [Sta82, Wil91, WD92] </ref>.) the figure shows some data objects in pages of the persistent store, with persistent-format (i.e., long) pointers between them. When a program is given access to 4 Thanks to Ralph Johnson for this; our original conception adhered too slavishly to the Appel-Ellis-Li model and relocated individual objects. <p> In that implementation, all fields were twice as big in the persistent store <ref> [Wil91] </ref>, and persistent pages were twice as big as normal virtual memory pages. <p> machines which require large hardware addresses with those that don't, and allow the sharing of most data between them. 7 Compatibility We see pointer swizzling at page fault time as part of a general purpose reconciliation layer that can be used to structure systems very flexibly at little performance cost <ref> [Wil91] </ref>. It can be used to support data formats that allow flexible sharing of data across machines with different word sizes, and even to support binary code compatibility within families of machines that have different address sizes. These capabilities only require very slight changes to existing programs and/or compilers. <p> log structured file systems|that is, the location of a block may change over time to maximize effective write bandwidth [RO91] and possibly adapt 15 Our attitude toward address space might be summed up as "crunch all you want|we'll make more." to observed patterns of disk usage to reduce read latencies <ref> [Gri89, Wil91] </ref>. Compressed storage is likely to become increasingly important, whether at the level of file storage or as part of the virtual memory system [AL91, Wil91]. The problems of variable-sized units of storage are thus likely to be solved anyway, for entirely different reasons. <p> Compressed storage is likely to become increasingly important, whether at the level of file storage or as part of the virtual memory system <ref> [AL91, Wil91] </ref>. The problems of variable-sized units of storage are thus likely to be solved anyway, for entirely different reasons. Compressed storage is attractive for reducing storage costs, and for reducing average latency (by storing more data in fast memory and/or decreasing communication costs). <p> If compression is used, long persistent addresses should typically take up considerably less space than the in-memory format| presumably, the actual information content will not be much higher despite the very horizontal pointer format. While such compressed storage techniques are beyond the scope of this paper (but see <ref> [WLM91, Wil91] </ref>), we would like to make one observation about why these problems are not as difficult as they may seem at first glance: it is not necessary to store the compressed pages contiguously. <p> We believe that the clustered births and deaths of objects [Hay91] will frequently cause entire pages to become empty, however; small pages and/or sub-page protections would also make this more effective. 11 Current Status and Future Work Our initial prototype persistent store for Scheme <ref> [Wil91] </ref> lacked recovery features and a body of data-intensive programs to truly stress it, so was little more than an existence proof, showing that it is possible (and, in fact, easy) to perform address translation at page fault time. (Performance problems with our (bytecoded) Scheme system also prevented us from precisely
Reference: [Wil92] <author> Paul R. Wilson. </author> <title> Uniprocessor garbage collection techniques. </title> <booktitle> In International Workshop on Memory Management, </booktitle> <address> St. Malo, France, </address> <month> September </month> <year> 1992. </year> <booktitle> Springer-Verlag Lecture Notes in Computer Science series. </booktitle>
Reference-contexts: The pagewise wavefront of compression mappings is a purely pagewise analogue of Baker's "read barrier" technique for traversing objects in incremental tracing garbage collection <ref> [Bak78, Bak92, Wil92] </ref>.
Reference: [WLM91] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Effective static-graph reorganization to improve locality in garbage-collected systems. </title> <booktitle> In SIG-PLAN Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 177-191, </pages> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: If compression is used, long persistent addresses should typically take up considerably less space than the in-memory format| presumably, the actual information content will not be much higher despite the very horizontal pointer format. While such compressed storage techniques are beyond the scope of this paper (but see <ref> [WLM91, Wil91] </ref>), we would like to make one observation about why these problems are not as difficult as they may seem at first glance: it is not necessary to store the compressed pages contiguously.
Reference: [WM89a] <author> Paul R. Wilson and Thomas G. Moher. </author> <title> Demonic memory for process histories. </title> <booktitle> In SIGPLAN Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 330-343, </pages> <address> Portland, Oregon, </address> <month> June </month> <year> 1989. </year> <note> Also distributed as SIGPLAN Notices 24, 7, </note> <month> July, </month> <year> 1989. </year>
Reference-contexts: One would be that debugging long-lived processes would be much easier, because distinct objects would have distinct addresses over time|an address would not be reused for a new object. (This would be especially desirable in the context of a time-travel debugging system <ref> [WM89a, FB88, TA90] </ref>.) Along with this ability to distinguish distinct objects over time comes the possibility of detecting most uses of dangling pointers. If empty virtual pages are not reused, they can simply be access protected and have their storage reclaimed.
Reference: [WM89b] <author> Paul R. Wilson and Thomas G. Mo her. </author> <title> Design of the opportunistic garbage collector. </title> <booktitle> In ACM SIGPLAN 1989 Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '89), </booktitle> <pages> pages 23-35, </pages> <address> New Orleans, Louisiana, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: These requirements are not much different from those of garbage collected systems that must perform pagewise (or "cardwise") operations <ref> [AEL88, WM89b] </ref> within the heap; there is no major difficulty supporting such operations efficiently for languages like Lisp or ML.
Reference: [WWH87] <author> Ifor W. Williams, Mario I. Wolkzko, and Trevor P. Hopkins. </author> <title> Dynamic grouping in an object-oriented virtual memory hierarchy. </title> <booktitle> In 1987 European Conference on Object-Oriented Programming, </booktitle> <pages> pages 87-96, </pages> <address> Paris, France, June 1987. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Ideally, we would like this mechanism to operate efficiently on standard hardware, rather than requiring an exotic "object-oriented" hardware memory hierarchy such as that of the MUSHROOM project <ref> [WWH87] </ref> or capability-based addressing schemes (e.g., [Lev84], [Ros91].). For simplicity, much of this paper is cast in terms of persistent memories, because our current implementation focus is on persistent object stores.
References-found: 39

