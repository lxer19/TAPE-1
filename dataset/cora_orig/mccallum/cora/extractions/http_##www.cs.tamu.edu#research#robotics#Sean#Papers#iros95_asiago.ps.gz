URL: http://www.cs.tamu.edu/research/robotics/Sean/Papers/iros95_asiago.ps.gz
Refering-URL: http://www.cs.tamu.edu/research/robotics/Sean/Papers/sean_bib.html
Root-URL: http://www.cs.tamu.edu
Title: Action Selection in Teleautonomous Systems  
Author: Sean Graves Richard Volz 
Address: College Station, TX, 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Abstract: Numerous generalized architectures for telerobotic systems have been proposed. Most are hard-wired in-stantiations of a specific approach, which rarely address the interactions between human and autonomous elements of teleautonomous systems. The work described here provides a more general, easily extensible and modifiable architecture. Specific issues addressed include methods that fuse decisions from multiple sources (such as human, reactive, or deliberative), integrate multiple command sources, and accommodate multi-purpose event recognizers to change operating modes. These methods may be dynamically altered to generate a variety of control modes. A result of the research described in this paper is a modifiable, extensible framework for the unification of the many modes of control, such as shared, teleoperative, and supervisory, which are described in the telerobotics literature. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Conway, R. A. Volz, and M. W. Walker, </author> <title> "Teleautonomous systems: Projecting and coordinating intelligent action at a distance," </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> vol. 6, </volume> <pages> pp. 146-158, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Teleautonomous Systems (TaS's) <ref> [1] </ref> combine the advantages of teleoperation with those of autonomous systems by including the projection of cognitive processing. An integral part of teleautonomous system theory is that the remote system is intelligent and capable of sharing cognition with the operator.
Reference: [2] <author> T. Tyrrell, </author> <title> Computational Mechanisms for Action Selection. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Teleautonomous Systems (TaS's) [1] combine the advantages of teleoperation with those of autonomous systems by including the projection of cognitive processing. An integral part of teleautonomous system theory is that the remote system is intelligent and capable of sharing cognition with the operator. An action selection mechanism (ASM) <ref> [2] </ref> is a computational mechanism which can produce a selected action as output when given different stimuli as inputs. In a TaS, inputs from various sources are combined to control remote systems. The particular method used to combine inputs is referred to as a control mode.
Reference: [3] <author> G. Hirzinger, B. Brunner, J. Dietrich, and J. Heindl, </author> <title> "Sensor-based space robotics | RO-TEX and its telerobotic features," </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> vol. 9, </volume> <pages> pp. 649 - 663, </pages> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: The authors may be contacted via Internet at sean@cs.tamu.edu. This research builds on previous work such as the MOTES (Modular Telerobot Task Execution System) of Backes and colleagues, the ROTEX telerobotic experiment <ref> [3] </ref>, the NASREM specification [4], and Sato and Hirai's [5] MEISTER architecture. The primary goals of this research are to develop a generalized architecture for teleautonomous system that flexibly supports distribution of control and work sites.
Reference: [4] <author> J. S. Albus, H. G. McCain, and R. Lumia, </author> <title> "NASA/NBS standard reference model for teler-obot control system architecture (NASREM)," </title> <note> NIST Technical Note 1235, 1989 Edition, </note> <institution> National Institute of Standards and Technology, Robot Systems Division, </institution> <address> Washington, DC, </address> <month> Apr. </month> <year> 1989. </year>
Reference-contexts: The authors may be contacted via Internet at sean@cs.tamu.edu. This research builds on previous work such as the MOTES (Modular Telerobot Task Execution System) of Backes and colleagues, the ROTEX telerobotic experiment [3], the NASREM specification <ref> [4] </ref>, and Sato and Hirai's [5] MEISTER architecture. The primary goals of this research are to develop a generalized architecture for teleautonomous system that flexibly supports distribution of control and work sites.
Reference: [5] <author> T. Sato and S. Hirai, "MEISTER: </author> <title> A model enhanced intelligent and skillful teleoperation robot system," </title> <booktitle> in Robotics Research The Fourth International Symposium, </booktitle> <pages> pp. 155 - 162, </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: The authors may be contacted via Internet at sean@cs.tamu.edu. This research builds on previous work such as the MOTES (Modular Telerobot Task Execution System) of Backes and colleagues, the ROTEX telerobotic experiment [3], the NASREM specification [4], and Sato and Hirai's <ref> [5] </ref> MEISTER architecture. The primary goals of this research are to develop a generalized architecture for teleautonomous system that flexibly supports distribution of control and work sites. In addition, we have developed methods for selecting actions by fusing control decisions from a variety of command sources.
Reference: [6] <author> P. Backes, M. Long, and R. Steele, </author> <title> "The modular telerobot task execution system for space teler-obotics," </title> <booktitle> in Proc. IEEE Int. Conf. Robotics and Automation, </booktitle> <address> Atlanta, GA, </address> <pages> pp. 524 - 530, </pages> <year> 1993. </year>
Reference-contexts: In addition, we have developed methods for selecting actions by fusing control decisions from a variety of command sources. While this idea has been investigated in the past (in particular <ref> [6] </ref>), a blending approach that allows non-motion commands to be integrated has been developed. 2 Architectural Overview In our view, a generalized teleautonomous architecture must support multiple sites engaged in a collaborative manipulation effort.
Reference: [7] <author> B. S. Graves, </author> <title> A Generalized Teleautonomous Architecture Using Situation-Based Action Selection. </title> <type> PhD thesis, </type> <institution> Texas A&M University, College Station, TX, </institution> <year> 1995. </year>
Reference-contexts: We have performed an object-oriented analysis of the requirements of such a teleautonomous system <ref> [7] </ref>; the analysis provides the foundation for our ongoing work in teleautonomy.
Reference: [8] <author> S. Hayati and S. T. Venkataraman, </author> <title> "Design and implementation of a robot control system with traded and shared control capability," </title> <booktitle> in Proc. IEEE Int. Conf. Robotics and Automation, </booktitle> <address> Scottsdale, AZ, </address> <pages> pp. 1310-1315, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Thus, C is a sfid matrix of input commands, which will be called the input matrix. Given an input matrix C, we may define a matrix M called the blending matrix. The blending matrix is similar in purpose to the mixing matrix described in <ref> [8] </ref>. A blending matrix M is a s fi d matrix of coefficients m ij which regulate the contribution of inputs towards generating a particular degree of freedom of the action vector.
Reference: [9] <institution> Lynx Real-Time Systems, Inc., </institution> <note> LynxOS Version 2.1 Reference Manual. </note> <institution> Lynx Real-Time Systems, Inc., Los Gatos, </institution> <address> CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: M 0 S and M 0 At time t of the transition, the Integrator calculates the current blending matrix as: M 0 = (1 )M 0 F (24) where is calculated according to Equation 17. 4 Implementation ASIAGO is implemented in ANSI C, and runs under the LynxOS operating system <ref> [9] </ref> on a 50 MHz Intel 486 personal computer. The devices used for testing purposes included a American Robot Merlin 6 DOF arm, a JR3 force/moment sensor, and a pneumatic gripper. These devices were interfaced to the PC using RCCL (Robot Control C Library) [10].
Reference: [10] <author> V. Hayward and R. Paul, </author> <title> "Robot manipulator control under UNIX: RCCL, a robot control C library," </title> <journal> Int. J. Robotics Research, </journal> <volume> vol. 5, no. 4, </volume> <pages> pp. 94-111, </pages> <year> 1986. </year>
Reference-contexts: The devices used for testing purposes included a American Robot Merlin 6 DOF arm, a JR3 force/moment sensor, and a pneumatic gripper. These devices were interfaced to the PC using RCCL (Robot Control C Library) <ref> [10] </ref>. To test the scalability of ASIAGO, a set of 36 modes were created consisting of from one to six degrees of freedom and from one to six inputs. Each of these modes were in turn assigned to an Integrator, and an action was requested.
Reference: [11] <author> L. J. Everett and R. C. Redfield, </author> <title> "A robust, automated alignment concept for robotics," </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> vol. 10, </volume> <pages> pp. 530 - 534, </pages> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: A screw is to be tightened into a fixture by a teleautonomously controlled robot. The location of the fixture is unknown, but is assumed to be within the operational workspace of the robot. In addition to the screw, the fixture contains a TRAC target. TRAC <ref> [11] </ref> is a camera-based optical alignment system which uses a retroreflective target. A known transformation relates the positions of the TRAC target and the screw. The robot is equipped with a TRAC sensor, a screwdriver attachment, and a simulated proximity sensor.
Reference: [12] <author> C. P. Sayers and R. P. Paul, </author> <title> "An operator interface for teleprogramming employing synthetic fixtures," </title> <journal> Presence, </journal> <volume> vol. 3, </volume> <pages> pp. 309 - 320, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: Analogical control with obstacle avoidance and synthetic fixture used after the TRAC system has identified the exact position of the screw. The mode is defined as an extension of the previous mode by adding a synthetic fixture <ref> [12] </ref> which assists the operator in aligning the screwdriver with the screw. When the operator moves the screwdriver within 5 cm of the synthetic fixture, the attractive force brings the screwdriver into alignment with the screw.
References-found: 12

