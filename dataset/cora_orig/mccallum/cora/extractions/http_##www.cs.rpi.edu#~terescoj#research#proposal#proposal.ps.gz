URL: http://www.cs.rpi.edu/~terescoj/research/proposal/proposal.ps.gz
Refering-URL: http://www.cs.rpi.edu/~terescoj/research/proposal/
Root-URL: http://www.cs.rpi.edu
Title: A Partition Model for Distributing Computational Load in an Object-Oriented Analysis Framework for Parallel Adaptive
Author: James D. Teresco Joseph E. Flaherty, 
Degree: Thesis Advisor  
Affiliation: Department of Computer Science and Scientific Computation Research Center  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Charbel Farhat amd Michel Lesoinne. </author> <title> Automatic partitioning of unstructured meshes for the parallel solution of problems in computational mechanics. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 36 </volume> <pages> 745-764, </pages> <year> 1993. </year>
Reference-contexts: Static partitioning methods based on coordinate [6], inertial <ref> [1] </ref>, and spectral [42] bisection are used to reduce communication cost when distributing initial meshes. A parallel version of the inertial partitioning method [38] may also be used for dynamic rebalancing. However, in an adaptive computation, global partitioning strategies can be costly relative to solution time. <p> At each recursive step, the cartesian coordinate of the longest dimension of the domain under consideration is bisected, elements are sorted according to the bisecting coordinate, and half of the elements are assigned to each subdomain. Inertial Recursive Bisection (IRB) <ref> [1] </ref>, like ORB, repeatedly bisects a domain, but in a direction orthogonal to its principal axis of inertia. Recursive Spectral Bisection (RSB) [42] is generally considered to be among the best static mesh partitioning procedures. However, RSB is costly and may be too expensive for use with adaptive computation.
Reference: [2] <author> Jose Nagib Cotrim Arabe, Adam Beguelin, Bruce Lowekamp, Erik Selig-man, Mike Starkey, and Peter Stephan. Dome: </author> <title> Parallel programming in a heterogeneous multi-user environment. </title> <type> Technical Report CMU-CS-95-137, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: The Scalable Distributed Dynamic Array (SDDA) [18] forms the basis for a parallel adaptive finite element system. P++ [35] is a parallel implementation of the A++ array class library which has been used in the AMR++ [3] Adaptive Mesh Refinement system. The Distributed Object Migration Environment (DOME) <ref> [2] </ref> provides a general parallel programming environment including fault tolerance and dynamic load balancing.
Reference: [3] <author> D. Balsara, M. Lemke, and Daniel Quinlan. Amr++, </author> <title> a c++ object oriented class library for parallel adaptive mesh refinement fluid dynamics applications. </title> <booktitle> In Proceedings of the American Society of Mechanical Engineers, Winter Annual Meeting, Symposium on Adaptive, Multilevel, and Hierarchical Computational Strategies, </booktitle> <address> Anaheim, CA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: The Scalable Distributed Dynamic Array (SDDA) [18] forms the basis for a parallel adaptive finite element system. P++ [35] is a parallel implementation of the A++ array class library which has been used in the AMR++ <ref> [3] </ref> Adaptive Mesh Refinement system. The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing.
Reference: [4] <author> Mark W. Beall and Mark S. Shephard. </author> <title> A general topology-based mesh data structure. </title> <note> International Journal of Numerical Methods in Engineering, 1996. to appear. 25 </note>
Reference-contexts: We will use the message passing library MPI, 3 but create our own communication class which is customized to perform the types of communication we need most often with our system. 3 Existing System 3.1 SCOREC Mesh Database The SCOREC Mesh Database (MDB) <ref> [4] </ref> provides an object-oriented hierarchical representation of a finite element mesh. It also includes a set of operators to query and update the mesh data structure.
Reference: [5] <author> Adam Beguelin, Jack Dongarra, Al Geist, and Vaidy Sunderam. </author> <title> Visual--ization and debugging in a heterogeneous environment. </title> <journal> IEEE Computer, </journal> <volume> 26(6) </volume> <pages> 88-95, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing. General-purpose parallelization tools such as P4 [10], Linda [14], Isis [8], and Express [19] and message passing libraries such as Chameleon [26], Parallel Virtual Machine (PVM) <ref> [5, 20, 21] </ref> and the Message Passing Interface (MPI) [25] have gone a long way toward providing a parallel programming interface which is portable across parallel architectures. Many recent efforts have focused on creating a C++-based object oriented communications class library.
Reference: [6] <author> Marsha J. Berger and Shahid H. Bokhari. </author> <title> A partitioning strategy for nonuniform problems on multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(5) </volume> <pages> 570-580, </pages> <year> 1987. </year>
Reference-contexts: Static partitioning methods based on coordinate <ref> [6] </ref>, inertial [1], and spectral [42] bisection are used to reduce communication cost when distributing initial meshes. A parallel version of the inertial partitioning method [38] may also be used for dynamic rebalancing. However, in an adaptive computation, global partitioning strategies can be costly relative to solution time. <p> Three static partitioning procedures are available in PMDB to distribute mesh data initially. Orthogonal Recursive Bisection (ORB) <ref> [6] </ref>, also called Recursive Coordinate Bisection, uses the coordinates of element centroids to partition the mesh.
Reference: [7] <author> Kim S. Bey, Abani Patra, and J. Tinsley Oden. </author> <title> hp-version discontinuous Galerkin methods for hyperbolic conservation laws: a parallel adaptive strategy. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 38(22) </volume> <pages> 3889-3907, </pages> <year> 1995. </year>
Reference-contexts: However, in an adaptive computation, global partitioning strategies can be costly relative to solution time. Thus, a number of iterative dynamic load balancing techniques that incrementally migrate data from heavily to lightly loaded processors have been developed <ref> [7, 12, 27, 17, 34, 51, 52] </ref>. An iterative method based on load imbalance trees [38, 41] is used in our system. While these methods provide inexpensive ways to achieve a balanced computation, they can lead to degradation in partition quality.
Reference: [8] <author> Kenneth Birman and Keith Marzullo. </author> <title> Isis and the meta project. </title> <booktitle> Sun Technology, </booktitle> <pages> pages 90-104, </pages> <month> Summer </month> <year> 1989. </year>
Reference-contexts: The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing. General-purpose parallelization tools such as P4 [10], Linda [14], Isis <ref> [8] </ref>, and Express [19] and message passing libraries such as Chameleon [26], Parallel Virtual Machine (PVM) [5, 20, 21] and the Message Passing Interface (MPI) [25] have gone a long way toward providing a parallel programming interface which is portable across parallel architectures.
Reference: [9] <author> Shahid H. Bokhari. </author> <title> Communication overhead on the intel paragon, ibm sp2, and meiko cs-2. </title> <type> Contractor Report 198211, </type> <institution> ICASE, NASA, </institution> <year> 1995. </year>
Reference-contexts: This is true on a machine like the IBM SP2 which has a high communication latency <ref> [9] </ref> and would be even more critical when using a cluster of workstations. A possibly remedy to this situation would be to use "ghost" copies of off-processor data which is cached locally.
Reference: [10] <author> J. Boyle, R. Butler, T. Disz, B. Glickfeld, E. Lusk, R. Overbeek, J. Peter-son, and R. Stevens, </author> <title> editors. Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart, and Winston, Inc., </publisher> <year> 1987. </year>
Reference-contexts: The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing. General-purpose parallelization tools such as P4 <ref> [10] </ref>, Linda [14], Isis [8], and Express [19] and message passing libraries such as Chameleon [26], Parallel Virtual Machine (PVM) [5, 20, 21] and the Message Passing Interface (MPI) [25] have gone a long way toward providing a parallel programming interface which is portable across parallel architectures.
Reference: [11] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <year> 1988. </year>
Reference-contexts: Here p o is the id of the owning processor and a o is the address of the entity on p o . This ownership information can be used to implement an owner-computes rule <ref> [11] </ref>, for example, during scalar product computation in an iterative linear solver. Since (p o ,a o ) functions as a global key for an entity, there is no need to generate and store a separate key by computing the centroid of the entity [53].
Reference: [12] <author> Carlo L. Bottasso, Hugues L. De Cougny, Mustafa Dindar, Joseph E. Flaherty, Can Ozturan, Zvi Rusak, and Mark S. Shephard. </author> <title> Compressible aerodynamics using a parallel adaptive time-discontinuous Galerkin least-squares finite element method. </title> <booktitle> In Proceedings of the 12th AIAA Applied Aerodynamics Conference, </booktitle> <address> number 94-1888, Colorado Springs, CO, </address> <month> June 20-22 </month> <year> 1994. </year> <institution> American Institute for Aeronautics and Astronautics. </institution>
Reference-contexts: However, in an adaptive computation, global partitioning strategies can be costly relative to solution time. Thus, a number of iterative dynamic load balancing techniques that incrementally migrate data from heavily to lightly loaded processors have been developed <ref> [7, 12, 27, 17, 34, 51, 52] </ref>. An iterative method based on load imbalance trees [38, 41] is used in our system. While these methods provide inexpensive ways to achieve a balanced computation, they can lead to degradation in partition quality.
Reference: [13] <author> Carlo L. Bottasso, Joseph E. Flaherty, Can Ozturan, Mark S. Shephard, Boleslaw K. Szymanski, James D. Teresco, and Louis H. Ziantz. </author> <title> The quality of partitions produced by an iterative load balancer. </title> <booktitle> In Proceedings Third Workshop on Languages, Compilers, and Runtime Systems, </booktitle> <pages> pages 265-277, </pages> <address> Boston, 1995. </address> <publisher> Kluwer. </publisher> <pages> 26 </pages>
Reference-contexts: We appraise the cost of interprocessor communication by computing two surface index metrics of partitions <ref> [13] </ref>. The maximum local surface index measures the maximum percentage of mesh faces on the boundary of any processor, and the global surface index measures the percentage of all faces which are on interprocesor boundaries. <p> With current technology, interconnection network latency is a significant component of communication cost; therefore, interprocessor connectivity (the number of processors with which each processor must exchange information during the solution phase) is as significant a factor in performance <ref> [13] </ref> as the number of boundary faces. Three static partitioning procedures are available in PMDB to distribute mesh data initially. Orthogonal Recursive Bisection (ORB) [6], also called Recursive Coordinate Bisection, uses the coordinates of element centroids to partition the mesh.
Reference: [14] <author> Nicholas Carriero and David Gelernter. </author> <title> How to write parallel programs: A guide to the perplexed. </title> <journal> ACM Computing Surveys, </journal> <pages> pages 323-357, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing. General-purpose parallelization tools such as P4 [10], Linda <ref> [14] </ref>, Isis [8], and Express [19] and message passing libraries such as Chameleon [26], Parallel Virtual Machine (PVM) [5, 20, 21] and the Message Passing Interface (MPI) [25] have gone a long way toward providing a parallel programming interface which is portable across parallel architectures.
Reference: [15] <author> K. Clark, J. E. Flaherty, and M. S. Shephard. </author> <title> Applied Numerical Mathematics, special ed. on Adaptive Methods for Partial Differential Equations, </title> <booktitle> 14 </booktitle> <pages> 255-283, </pages> <year> 1994. </year>
Reference-contexts: During the solution process, portions of the discrete domain are spatially refined or coarsened (h-refinement), the method order is varied (p-refinement), and/or the mesh is moved to follow evolving phenomena (r-refinement), each of which concentrates the computational effort in areas where the solution resolution would otherwise be inadequate <ref> [15] </ref>. Parallel computation is essential for computationally demanding three-dimensional problems; however, it introduces complications such as the need to balance processor loading, coordinate interprocessor communication, and manage distributed data. The standard methodology for optimizing parallel FEM programs relies on a static partitioning of the mesh across the cooperating processors.
Reference: [16] <author> Olivier Coulaud and Eric Dillon. </author> <title> PARA++: C++ Bindings for Message Passing Libraries User Guide. </title> <institution> National Research Institue in Software Engineering and Automatism (INRIA), Villers-les-Nancy, France, </institution> <year> 1996. </year>
Reference-contexts: Many recent efforts have focused on creating a C++-based object oriented communications class library. One example is PARA++ <ref> [16] </ref>, which is independent of the underlying message passing library used. Many others are based on the widely accepted message passing standard MPI, including MPI++ [48], mpi++ [31], and Object Oriented MPI (OOMPI) [36, 49].
Reference: [17] <author> K.D. Devine, J.E. Flaherty, R.M. Loy, and S.R. Wheat. </author> <title> Parallel partitioning strategies for the adaptive solution of conservation laws. </title> <editor> In I. Babuska, J.E. Flaherty, W.D. Henshaw, J.E. Hopcroft, J.E. Oliger, and T. Tezduyar, editor, </editor> <title> Modeling, Mesh Generation, and Adaptive Numerical Methods for Partial Differential Equations, </title> <booktitle> volume 75, </booktitle> <pages> pages 215-242. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin-Heidelberg, </address> <year> 1995. </year>
Reference-contexts: However, in an adaptive computation, global partitioning strategies can be costly relative to solution time. Thus, a number of iterative dynamic load balancing techniques that incrementally migrate data from heavily to lightly loaded processors have been developed <ref> [7, 12, 27, 17, 34, 51, 52] </ref>. An iterative method based on load imbalance trees [38, 41] is used in our system. While these methods provide inexpensive ways to achieve a balanced computation, they can lead to degradation in partition quality. <p> While these methods provide inexpensive ways to achieve a balanced computation, they can lead to degradation in partition quality. We also use an octree-based partitioning, which takes advantage of an underlying tree structure to achieve balance and 8 to maintain reasonable communication costs <ref> [17, 39] </ref>. The manner in which mesh data is distributed among the cooperating processors in a parallel computation has a profound impact on the performance of analysis software. A balance of computational load is necessary to avoid idle processors, but this alone does not ensure efficient parallel computation. <p> Iterative Tree Balancing [38, 41] (ITB) migrates entities to neighboring partitions to achieve balance. Parallel Sort Inertial Recursive Bisection [38] (PSIRB) is a parallel repartitioning procedure based on the IRB static partitioning algorithm. The Octree partitioning procedure <ref> [17] </ref> (OCTPART) uses the octree structure underlying the mesh to achieve load balance. The measure of imbalance or "cost function" that reflects the computational load on each processor is generally chosen as the number of elements on a processor with h-refinement.
Reference: [18] <author> H. Carter Edwards. </author> <note> http://www.ticam.utexas.edu/ carter/projects.html#sdda. URL, </note> <year> 1996. </year>
Reference-contexts: Charm++ [33] is also an explicitly parallel extension of C++. Converse [32] is a framework which allows multiple languages and their run-time libraries into a single parallel program. The Scalable Distributed Dynamic Array (SDDA) <ref> [18] </ref> forms the basis for a parallel adaptive finite element system. P++ [35] is a parallel implementation of the A++ array class library which has been used in the AMR++ [3] Adaptive Mesh Refinement system.
Reference: [19] <author> J. Flower, A. Kolawa, and S. Bharadwaj. </author> <title> The express way to distributed processing. </title> <booktitle> Supercomputing Review, </booktitle> <pages> pages 54-55, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing. General-purpose parallelization tools such as P4 [10], Linda [14], Isis [8], and Express <ref> [19] </ref> and message passing libraries such as Chameleon [26], Parallel Virtual Machine (PVM) [5, 20, 21] and the Message Passing Interface (MPI) [25] have gone a long way toward providing a parallel programming interface which is portable across parallel architectures.
Reference: [20] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> Pvm 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing. General-purpose parallelization tools such as P4 [10], Linda [14], Isis [8], and Express [19] and message passing libraries such as Chameleon [26], Parallel Virtual Machine (PVM) <ref> [5, 20, 21] </ref> and the Message Passing Interface (MPI) [25] have gone a long way toward providing a parallel programming interface which is portable across parallel architectures. Many recent efforts have focused on creating a C++-based object oriented communications class library.
Reference: [21] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam, </author> <title> editors. PVM: Parallel Virtual Machine </title>
Reference-contexts: The Distributed Object Migration Environment (DOME) [2] provides a general parallel programming environment including fault tolerance and dynamic load balancing. General-purpose parallelization tools such as P4 [10], Linda [14], Isis [8], and Express [19] and message passing libraries such as Chameleon [26], Parallel Virtual Machine (PVM) <ref> [5, 20, 21] </ref> and the Message Passing Interface (MPI) [25] have gone a long way toward providing a parallel programming interface which is portable across parallel architectures. Many recent efforts have focused on creating a C++-based object oriented communications class library.
References-found: 21

