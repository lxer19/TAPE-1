URL: http://www.isi.edu/~cheang/tipaper.ps
Refering-URL: http://www.isi.edu/~cheang/
Root-URL: http://www.isi.edu
Title: Transitive Indexing in a Distributed Information System  
Author: Sio Man Cheang B. Clifford Neuman 
Affiliation: Information Sciences Institute University of Southern California  
Abstract: Several tools have emerged recently for organizing, indexing, and discovering information on the Internet. These tools allow users to browse hierarchically structured information and issue searches upon databases that index the information. This paper introduces transitive indexing, a new form of indexing that exploits the hierarchical structure of existing data. This indexing scheme is scalable in database size. It achieves this by distributing the indices over the hierarchy rather than using a central database. It supports information hierarchy across the network and allows decentralized administrative control. Transitive indexing allows users to start a search from any node, reducing the scope of the search and resulting in improved relevance of the objects found. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Tim Berners-Lee, Robert Cailliau, Jean-Francois Groff, and Bernd Pollermann. </author> <title> World-wide web: The information universe. </title> <journal> Electronic Networking: Research, Applications and Policy, </journal> <volume> 2(1), </volume> <month> Spring </month> <year> 1992. </year>
Reference-contexts: The Gopher service [9] provides a hierarchical system of menus and documents through which users navigate. The World-Wide Web (WWW) <ref> [1] </ref> supports a hypertext environment across the network. A hypertext document is similar to a directory with the outgoing hyper-links corresponding to links in the directory.
Reference: [2] <author> C. Mic Bowman, Peter B. Danzig, Darren R. Hardy, Udi Manber, Michael F. Schwartz, and Duane P. Wessels. Harvest: </author> <title> A scalable, customizable discovery and access system. </title> <type> Technical Report CU-CS-732-94, </type> <institution> Department of Computer Science, University of Colorado Boulder, </institution> <month> August </month> <year> 1994. </year> <note> Also available from ftp://ftp.cs.colorado.edu/pub/cs/techreports/ schwart/Harvest.Jour.ps.Z. </note>
Reference-contexts: The Semantic File System relies on an index generated by a single authority, and requires coordination of the indexing process. In the Harvest <ref> [2] </ref> system, customizable Harvest Gatherers collect information locally or from other information providers to improve index quality and reduce indexing traffic. Brokers, which index information exported by the Gatherers, can be flexibly constructed to suit different optimization requirements, like space-efficient trade-off.
Reference: [3] <author> P. DeBra and R. Post. </author> <title> Information retrieval in the world-wide web: Making client-based searching feasible. </title> <booktitle> In Proceedings of the First International World-Wide Web Conference, </booktitle> <month> May </month> <year> 1994. </year> <note> Also available from http://www1.cern.ch/PapersWWW94/reinpost.ps. </note>
Reference-contexts: The size and complexity of the information space makes finding things through pure navigation sometimes time-consuming. Many search tools have emerged to help users locate relevant information. Fish Search <ref> [3] </ref> is a client-based search engine for the World-Wide Web which finds related documents by recursively following the outgoing links from a document. The search favors links with high relevance for expansion. Multiple invocations of the same or similar searches are potentially overlapping.
Reference: [4] <author> David K. Gifford, Pierre Jouvelot, Mark A. Sheldon, and James W. O'Toole Jr. </author> <title> Semantic file systems. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 16-25, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: This abstract is usually very small, consisting of a human readable description of the subject of the database, and is updated manually. The Semantic File System <ref> [4] </ref> builds a database of attributes extracted from files on a local system, and allows users to access the files through virtual directories where directory names correspond to attributes. The Semantic File System relies on an index generated by a single authority, and requires coordination of the indexing process.
Reference: [5] <author> Brewster Kahle and Art Medlar. </author> <title> An information system for corporate users: Wide area information systems. </title> <type> Technical Report TMC-199, </type> <institution> Thinking Machines Corporation, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: Our experimental implementation is described in Section 6. 1 2 Related Work To put Transitive Indexing into perspective, this section describes several other Internet information organization and discovery tools. We will discuss ... The Wide Area Information Service (WAIS) <ref> [5] </ref> supports full-text searching within a document database. To make the search scale across multiple databases, a directory of servers allows the user to select a database by searching for keywords in abstracts of the databases.
Reference: [6] <author> John Leavitt. </author> <note> Webants home page. Available from http://thule.mt.cs.cmu.edu:8001/webants/. </note>
Reference-contexts: These approaches which gather information in a centralized manner suffer from scalability problems and heavy resource load on centralized servers. To solve this problem, WebAnts <ref> [6] </ref> devises a scheme to use cooperative engines distributed over the web for the indexing task and share results to shed the resource load. Queries can be served by a local server which in turn can get help from other cooperating engines to provide the answer.
Reference: [7] <author> Michael Mauldin and John Leavitt. Lycos: </author> <note> Hunting www information. Available from http:// fuzine.mt.cs.cmu.edu/mlm/signidr94-03.html/. </note>
Reference-contexts: The breadth first search avoids putting excessive loads on a given server during indexing while representing the Web broadly. However, arguably, all sites are not equal. Information on a Web server with more users might have been missed. Lycos <ref> [7] </ref>, on the other hand, uses a random scheme to pick which document to explore with preference toward more popularly referenced documents and shorter depth from the search starting point. These approaches which gather information in a centralized manner suffer from scalability problems and heavy resource load on centralized servers.
Reference: [8] <author> Michael Mauldin and John Leavitt. </author> <title> Yahoo! frequently asked questions. </title> <note> Available from http:// fuzine.mt.cs.cmu.edu/mlm/signidr94-04.html/. </note>
Reference: [9] <author> Mark McCahill. </author> <title> The Internet gopher: A distributed server information system. </title> <journal> ConneXions - The Interoperability Report, </journal> <volume> 6(7) </volume> <pages> 10-14, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Transitive Indexing, on the other hand, while having the similar idea of collecting indexing data from other brokers/index databases, is embedded into the information hierarchy and allows searching along the navigation path rather than based on the brokers. The Gopher service <ref> [9] </ref> provides a hierarchical system of menus and documents through which users navigate. The World-Wide Web (WWW) [1] supports a hypertext environment across the network. A hypertext document is similar to a directory with the outgoing hyper-links corresponding to links in the directory.
Reference: [10] <author> B. Clifford Neuman. </author> <title> The Prospero File System: A global file system based on the Virtual System Model. </title> <journal> Computing Systems, </journal> <volume> 5(4) </volume> <pages> 407-432, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: Our discussion of transitive indexing begins with a discussion of other resource discovery tools and their relationship to our work. Section 3 describes the Transitive Indexing design. The integration of Transitive Indexing with the Prospero Distributed Information System <ref> [10] </ref> is described in Section 4. Section 5 discusses how Transitive Indexing can be used on the Web. Our experimental implementation is described in Section 6. 1 2 Related Work To put Transitive Indexing into perspective, this section describes several other Internet information organization and discovery tools. <p> But the propagation of counts can not be prevented because information about the individual objects beneath a node is not propagated upward. Further research is needed to solve this problem. 4 Transitive Indexing on Prospero An experimental transitive indexing system was built using the Prospero Distributed Information System <ref> [10] </ref>. Prospero is a distributed file system structured as a customizable directed graph where users add links to objects distributed across the Internet. Prospero supports extensible attributes which Transitive Indexing can use for indexing.
Reference: [11] <author> Brian Pinkerton. </author> <title> Finding what people want: Experiences with the webcrawler. </title> <booktitle> In Proceedings of the Second International World-Wide Web Conference, </booktitle> <month> October </month> <year> 1994. </year> <note> Also available from ftp://webcrawler.cs.washington.edu/pub/WebCrawler.ps.gz or http:// www.ncsa.uiuc.edu/SDG/IT94/Proceedings/Searching/pinkerton/WebCrawler.html. 8 </note>
Reference-contexts: The search favors links with high relevance for expansion. Multiple invocations of the same or similar searches are potentially overlapping. The Lagoon cache described in the same paper helps to alleviate but does not actually solve this problem. WebCrawler <ref> [11] </ref> employs a breadth first search indexing engine which tries to index as many Web sites as possible. The breadth first search avoids putting excessive loads on a given server during indexing while representing the Web broadly. However, arguably, all sites are not equal.
References-found: 11

