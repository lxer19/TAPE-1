URL: http://www.cs.toronto.edu/~mackay/ldpc-irreg.ps.gz
Refering-URL: http://www.cs.toronto.edu/~mackay/README.html
Root-URL: http://www.cs.toronto.edu
Email: mackay|stw11|mcdavey@mrao.cam.ac.uk  
Title: Comparison of Constructions of Irregular Gallager Codes  
Author: David J. C. MacKay, Simon T. Wilson and Matthew C. Davey 
Date: 30 July 1998.  
Note: Submitted to IEEE Transactions on Communications  
Address: Madingley Road, Cambridge, CB3 0HE, United Kingdom.  
Affiliation: Department of Physics, University of Cambridge Cavendish Laboratory,  
Abstract: The low density parity check codes whose performance is closest to the Shan-non limit are `Gallager codes' based on irregular graphs. We compare alternative methods for constructing these graphs and present two results. First, we find a `super-Poisson' construction which gives a small improvement in empirical performance over a random construction. Second, whereas Gallager codes normally take N 2 time to encode, we investigate constructions of regular and irregular Gallager codes which allow more rapid encoding and have smaller memory requirements in the encoder. We find that these `fast-encoding' Gallager codes have equally good performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. C. Davey and D. J. C. MacKay. </author> <title> Low density parity check codes over GF(q). </title> <booktitle> In Proceedings of the 1998 IEEE Information Theory Workshop. IEEE, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: The best known Gallager codes of all are Gallager codes defined over finite fields GF (q) <ref> [2, 1] </ref>. The remaining two solid curves in figure 1 show the performance of a regular Gallager code over GF (16) [2] and an irregular code over GF (8) with bit error probability of 10 4 at E b =N 0 = 0:05dB [1]. <p> The remaining two solid curves in figure 1 show the performance of a regular Gallager code over GF (16) [2] and an irregular code over GF (8) with bit error probability of 10 4 at E b =N 0 = 0:05dB <ref> [1] </ref>. <p> 0.8 Empirical Bit-Error Probability Eb/No (dB) Turbo Irreg GF (8) Reg Irreg GF (2) GF (16) GF (8) blocklength 24000 bits; JPL Turbo, blocklength 65536 bits; Regular LDPC, GF (16), blocklength 24448 bits; Irregular LDPC , GF (2), blocklength 64000 bits; Regular LDPC, GF (2), blocklength 40000 bits. (Reproduced from <ref> [1] </ref>.) should be noted. (1) The transmitted blocklength of the irregular Gallager code is only 24000 bits, whereas that of the Turbo code is 65536 bits. (2) The errors made by the Gallager codes were all detected errors, whereas Turbo codes make undetected errors at high signal to noise ratio.
Reference: [2] <author> M. C. Davey and D. J. C. MacKay. </author> <title> Low density parity check codes over GF(q). </title> <journal> IEEE Communications Letters, </journal> <volume> 2(6) </volume> <pages> 165-167, </pages> <month> June </month> <year> 1998. </year>
Reference-contexts: The best known Gallager codes of all are Gallager codes defined over finite fields GF (q) <ref> [2, 1] </ref>. The remaining two solid curves in figure 1 show the performance of a regular Gallager code over GF (16) [2] and an irregular code over GF (8) with bit error probability of 10 4 at E b =N 0 = 0:05dB [1]. <p> The best known Gallager codes of all are Gallager codes defined over finite fields GF (q) [2, 1]. The remaining two solid curves in figure 1 show the performance of a regular Gallager code over GF (16) <ref> [2] </ref> and an irregular code over GF (8) with bit error probability of 10 4 at E b =N 0 = 0:05dB [1]. <p> In the experiments presented here, we study binary codes with rate 1=2 and block-length about N = 10; 000. We simulate an additive white Gaussian noise channel in the usual way <ref> [2] </ref> and examine the block error probability as a function of the signal to noise ratio.
Reference: [3] <author> R. G. Gallager. </author> <title> Low density parity check codes. </title> <journal> IRE Trans. Info. Theory, </journal> <volume> IT-8:21-28, </volume> <month> Jan </month> <year> 1962. </year>
Reference-contexts: 1 Introduction Gallager codes <ref> [3, 4] </ref> are low density parity check codes constructed at random subject to constraints on the weight of each row and of each column. <p> 6 (a) shows the variability of performance of these codes. the ordinary-encoding codes. 5 Discussion The detection of error floors in some Gallager codes reminds us that it is a good idea, though not essential, to avoid cycles of length 4 when building these codes, as was standard practice in <ref> [3, 9, 6] </ref>. This is not so easy to enforce in irregular Gallager codes with high weight columns, but the present results indicate that what is really important is to ensure that no pairs of low weight columns (with weights less than 4) have overlaps greater than one.
Reference: [4] <author> R. G. Gallager. </author> <title> Low Density Parity Check Codes. Number 21 in Research monograph series. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1963. </year>
Reference-contexts: 1 Introduction Gallager codes <ref> [3, 4] </ref> are low density parity check codes constructed at random subject to constraints on the weight of each row and of each column. <p> Turbo Codes make undetected errors because they have low-weight codewords. For Gallager codes, the rate of occurrence of undetected errors is extremely small because they have good distance properties (the minimum distance scales linearly with the blocklength) <ref> [4] </ref>. In all our experiments with Gallager codes of block length greater than 1000 and column weight at least 3, undetected errors have never occurred. The excellent performance of irregular Gallager codes is the motivation for this paper, in which we explore ways of further enhancing these codes. <p> Permutations. We can build parity check matrices by superposing random permutation matrices <ref> [4] </ref>. The convenience of this method depends on the profile. There are many ways of laying out these permutation matrices to satisfy a given profile. <p> The straight line has slope -8.5. Above 50, iterations were binned into intervals of 5. constructed codes the minimum distance increases linearly with the blocklength, for almost all codes <ref> [4] </ref>. We discard the two codes with error floors in the subsequent comparisons. 3.2.3 Comparison of constructions The six families are compared with each other in figure 3. There are no detectable differences between the regular codes 3 and 33.
Reference: [5] <author> M. G. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. A. Spielman. </author> <title> Improved low-density parity-check codes using irregular graphs and belief propagation. </title> <booktitle> In Proceedings of the 1998 IEEE International Symposium on Information Theory, </booktitle> <address> Boston USA, </address> <note> page 117. </note>
Reference-contexts: Recent advances in the performance of Gallager codes are summarised in figure 1. The rightmost curve shows the performance of a regular binary Gallager code with rate 1/4. The best known binary Gallager codes are irregular codes whose parity check matrices have nonuniform weight per column <ref> [5] </ref>; the performance of one such code is shown by the second curve from the right. The best known Gallager codes of all are Gallager codes defined over finite fields GF (q) [2, 1]. <p> The excellent performance of irregular Gallager codes is the motivation for this paper, in which we explore ways of further enhancing these codes. The irregular codes of Luby, Mitzenmacher, Shokrollahi and Spielman <ref> [5] </ref> have parity check matrices with both nonuniform weight per row and nonuniform weight per column. It has not yet been established whether both of these non-uniformities are desirable. In our experience with codes for noisy channels, performance is more sensitive to the distribution of column weights. <p> the list a number of times equal to its weight, then make a similar list of all the rows in the matrix, each row appearing with multiplicity equal to its weight, and then map one list onto the other by a random permutation, taking care not to create duplicate entries <ref> [5] </ref>.
Reference: [6] <author> D. J. C. MacKay. </author> <title> Good error correcting codes based on very sparse matrices. </title> <journal> IEEE transactions on Information Theory, </journal> <note> 1999. In press. Available from http://wol.ra.phy.cam.ac.uk/. </note>
Reference-contexts: for codes which have nearly uniform weight columns and rows | for example, codes which have some weight 2 columns and some weight 3 columns.] These codes are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm giving near Shannon limit performance when large block lengths are used <ref> [8, 9, 6] </ref>. Regular Gallager codes have also been found to be competitive codes for short block-length CDMA applications [11]. Recent advances in the performance of Gallager codes are summarised in figure 1. The rightmost curve shows the performance of a regular binary Gallager code with rate 1/4. <p> 6 (a) shows the variability of performance of these codes. the ordinary-encoding codes. 5 Discussion The detection of error floors in some Gallager codes reminds us that it is a good idea, though not essential, to avoid cycles of length 4 when building these codes, as was standard practice in <ref> [3, 9, 6] </ref>. This is not so easy to enforce in irregular Gallager codes with high weight columns, but the present results indicate that what is really important is to ensure that no pairs of low weight columns (with weights less than 4) have overlaps greater than one.
Reference: [7] <author> D. J. C. MacKay and J. Lafferty. </author> <title> Codes from Cayley graphs. </title> <booktitle> Work in progress, </booktitle> <year> 1997. </year>
Reference: [8] <author> D. J. C. MacKay and R. M. Neal. </author> <title> Good codes based on very sparse matrices. In Colin Boyd, editor, Cryptography and Coding. </title> <booktitle> 5th IMA Conference, number 1025 in Lecture Notes in Computer Science, </booktitle> <pages> pages 100-111. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: for codes which have nearly uniform weight columns and rows | for example, codes which have some weight 2 columns and some weight 3 columns.] These codes are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm giving near Shannon limit performance when large block lengths are used <ref> [8, 9, 6] </ref>. Regular Gallager codes have also been found to be competitive codes for short block-length CDMA applications [11]. Recent advances in the performance of Gallager codes are summarised in figure 1. The rightmost curve shows the performance of a regular binary Gallager code with rate 1/4.
Reference: [9] <author> D. J. C. MacKay and R. M. Neal. </author> <title> Near Shannon limit performance of low density parity check codes. </title> <journal> Electronics Letters, </journal> <volume> 32(18) </volume> <pages> 1645-1646, </pages> <month> August </month> <year> 1996. </year> <journal> Reprinted Electronics Letters, </journal> 33(6):457-458, March 1997. 
Reference-contexts: for codes which have nearly uniform weight columns and rows | for example, codes which have some weight 2 columns and some weight 3 columns.] These codes are asymptotically good, and can be practically decoded with Gallager's sum-product algorithm giving near Shannon limit performance when large block lengths are used <ref> [8, 9, 6] </ref>. Regular Gallager codes have also been found to be competitive codes for short block-length CDMA applications [11]. Recent advances in the performance of Gallager codes are summarised in figure 1. The rightmost curve shows the performance of a regular binary Gallager code with rate 1/4. <p> A variation of this construction is to require that no two columns in the parity check matrix have an overlap greater than one, i.e., forbid cycles of length 4 in the graph. [Similar to construction 1A in <ref> [9] </ref>.] A second variation requires that the graph to have no cycles of length less than some l. [Similar to construction 1B in [9].] This constraint can be quite hard to enforce if the profile includes high weight rows or columns. Permutations. <p> two columns in the parity check matrix have an overlap greater than one, i.e., forbid cycles of length 4 in the graph. [Similar to construction 1A in <ref> [9] </ref>.] A second variation requires that the graph to have no cycles of length less than some l. [Similar to construction 1B in [9].] This constraint can be quite hard to enforce if the profile includes high weight rows or columns. Permutations. We can build parity check matrices by superposing random permutation matrices [4]. The convenience of this method depends on the profile. <p> As the block length of the code is increased, the probability of this topology's occurrence falls. It is also possible to modify the construction algorithm for Gallager codes such that cycles of length 4, like this checks bits (2) are forbidden (as in construction 1A of <ref> [9] </ref>). This modification is sufficient to prevent the topology shown in (1) from occurring. In principle it is possible for a code to have a minimum distance of 4 even when the minimum cycle length is 6. <p> 6 (a) shows the variability of performance of these codes. the ordinary-encoding codes. 5 Discussion The detection of error floors in some Gallager codes reminds us that it is a good idea, though not essential, to avoid cycles of length 4 when building these codes, as was standard practice in <ref> [3, 9, 6] </ref>. This is not so easy to enforce in irregular Gallager codes with high weight columns, but the present results indicate that what is really important is to ensure that no pairs of low weight columns (with weights less than 4) have overlaps greater than one.
Reference: [10] <author> R. J. McEliece, D. J. C. MacKay, and J.-F. Cheng. </author> <title> Turbo decoding as an instance of Pearl's `belief propagation' algorithm. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 16(2) </volume> <pages> 140-152, </pages> <year> 1998. </year>
Reference-contexts: This difference is not caused by a difference in the decoding algorithm: both codes are decoded by the sum-product algorithm <ref> [10] </ref>. Turbo Codes make undetected errors because they have low-weight codewords. For Gallager codes, the rate of occurrence of undetected errors is extremely small because they have good distance properties (the minimum distance scales linearly with the blocklength) [4].
Reference: [11] <author> V. Sorokine, F. R. Kschischang, and S. Pasupathy. </author> <title> Gallager codes for CDMA applications II: Implementations, complexity and system capacity. </title> <journal> IEEE Trans. Communications, </journal> <note> 1998. submitted. </note>
Reference-contexts: Regular Gallager codes have also been found to be competitive codes for short block-length CDMA applications <ref> [11] </ref>. Recent advances in the performance of Gallager codes are summarised in figure 1. The rightmost curve shows the performance of a regular binary Gallager code with rate 1/4. <p> In the second part (section 4) we examine regular and irregular constructions which lend themselves to rapid encoding. One motivation for this second study is that the only drawback of regular Gallager codes compared to Turbo codes for CDMA applications appears to be their greater encoding complexity <ref> [11] </ref>. In the experiments presented here, we study binary codes with rate 1=2 and block-length about N = 10; 000. We simulate an additive white Gaussian noise channel in the usual way [2] and examine the block error probability as a function of the signal to noise ratio. <p> This reduction would be more than sufficient to cancel out the factor of fourteen encoding complexity disadvantage with respect to Turbo codes of the example mentioned in <ref> [11] </ref>. The smaller the ratio M &lt; =M , the greater the reduction in encoding cost. It will be interesting to investigate how small M &lt; can be made without deterioration in performance.
Reference: [12] <author> D. A. Spielman. </author> <title> Linear-time encodable and decodable error-correcting codes. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 42(6.1):1723-1731, </volume> <year> 1996. </year>
Reference-contexts: For example, at E b =N 0 = 0:7dB the error rates are 0.035 and 0.097. 4 Fast-encoding Gallager codes One of the possible drawbacks of Gallager codes is that their encoding time generally scales as N 2 . Inspired by Spielman's <ref> [12] </ref> work, we have investigated constructions of Gal-lager codes whose profiles are similar to or identical to the 3 and 93 profiles above, but which are fast-encoding. The general form of parity check matrix for a fast-encoding Gal-lager code is shown in figure 5.
References-found: 12

