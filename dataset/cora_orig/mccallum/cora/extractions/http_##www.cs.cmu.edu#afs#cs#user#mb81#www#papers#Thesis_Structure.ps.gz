URL: http://www.cs.cmu.edu/afs/cs/user/mb81/www/papers/Thesis_Structure.ps.gz
Refering-URL: http://www.cs.cmu.edu/~mb81/
Root-URL: 
Title: Reconfigurable Architectures for Mixed-Initiative Planning and Scheduling June 29, 1998  
Author: Marcel Antoine Becker 
Degree: Dissertation submitted in partial fulfillment of the requirements for the degree of Doctor in Philosophy in  
Note: DRAFT VERSION: DO NOT DISTRIBUTE  
Affiliation: Management of Manufacturing and Automation Graduate School of Industrial Administration and The Robotics Institute Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: [ Abadi and Cardelli, 1996 ] <author> M. Abadi and L. Cardelli. </author> <title> A Theory of Objects, </title> <booktitle> chapter 1. Monographs in COmputer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1996. </year>
Reference-contexts: In the current ontology, the term object cannot be used as a synonym for entity. Object: An object is a component of a software model <ref> [ Abadi and Cardelli, 1996 ] </ref> . Object-oriented programming is based on a correspondence between a software simulating a physical system and the physical system itself.
Reference: [ Alexander, 1979 ] <author> C. Alexander. </author> <title> The Timeless Way of Building. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Based on Christopher Alexander's principles presented in The Timeless Way of Building <ref> [ Alexander, 1979 ] </ref> , patterns are recurring design constructs or predefined design structures that can be used as building blocks to describe and implement software systems.
Reference: [ Allen, 1984 ] <author> J.F. Allen. </author> <title> Towards a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23(2) </volume> <pages> 123-154, </pages> <year> 1984. </year>
Reference-contexts: In the rest of the section each of the abstract domain concepts is discussed in details. 3.4.1 Temporal Primitives In what follows, we assume the existence of basic temporal concepts such as time intervals and time points (c.f. <ref> [ Allen, 1984 ] </ref> ). Additional useful time concepts are: CALENDAR: a system for dividing up time that establishes a point of reference and units for counting time. TIME-UNIT: The granularity of the time representation. It could be one hour, one minute, one second, one day.
Reference: [ Allen, 1997 ] <author> R.J. Allen. </author> <title> A Formal Approach to Software Architecture. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: This interface correspond to low level computational entities that are "exported" or "imported" by the module. Shaw and Garlan [ Shaw and Garlan, 1994 ] argue that the high-level programming languages currently available do not provide the semantic entities and the abstraction level required to describe system's architecture. Allen <ref> [ Allen, 1997 ] </ref> identifies three limitations that makes this kind of languages inappropriate for architectural description: (1) they do not allow the separation between the overall structure of the system from the component packages; (2) packages and modules do not provide means of capturing and analyzing patterns of interactions; and <p> SOFTWARE REUSE 53 description of the individual components. In this class we include Module Interconnection Languages (MIL), Module Interconnection Formalisms (MIF), Interface Definition Languages (IDL), coordination languages, and wide-spectrum languages <ref> [ Allen, 1997 ] </ref> . MILs describe program structure through bindings that associate definitions of program constructs like data structures and functions with the use of such constructs. MILs do not provide constructs for specifying patterns of interaction. <p> Formal Methods: Several attempts of using formal methods, like Z, or logic-based descriptions, like first-order logic, to characterize architectural styles have been reported in the literature <ref> [ Allen, 1997, Medvidovic and Taylor, 1997 ] </ref> . Although these formal descriptions are very precise and allow a number of different types of analysis, it is not appropriate for most practical uses. First of all, the cost associated with the development of such descriptions is usually high. <p> These properties are not used by ACME and can be used by tools implemented to perform analysis, translation, or manipulation of the description. ACME itself, does not provide facilities to perform such tasks. (f) WRIGHT: designed to support the formal description of the architectural description of software systems, WRIGHT <ref> [ Allen, 1997 ] </ref> permits both the description of architectural styles and architectural instances. <p> THE OZONE SOFTWARE ARCHITECTURE ONTOLOGY 233 3.3.1 COMPONENT 3.3.1.1 Concept Definition Architectural Description Languages like ACME [ Garlan et al., 1997 ] , UniCon [ Shaw et al., 1995 ] , and Wright <ref> [ Allen, 1997 ] </ref> define a component to be the primary computational element and data store of the system that provides a localized, independent functional capability to the system. Based on these ADLs, a component is defined as the representation of the basic compositional unit of the architecture.
Reference: [ Arango and Prieto-Daz, 1991 ] <author> G Arango and R. Prieto-Daz. </author> <title> Domain analysis concepts and research directions. </title> <editor> In R. Prieto-Daz and G Arango, editors, </editor> <booktitle> Domain Analysis and Software Modeling, </booktitle> <pages> pages 9-32. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: The first task, creation of domain models, can be accomplished by performing domain analysis <ref> [ Arango and Prieto-Daz, 1991 ] </ref> or some kind of knowledge acquisition process. In the software engineering literature, several methods have been proposed. The goal of domain analysis, from a software engineering view point, is software reusability. <p> Domain analysis has also evolved from a process of extracting application specific knowledge to one that entails the higher level modeling of the relations among applications and their surrounding environment. Several domain analysis techniques has been proposed in the literature <ref> [ Arango and Prieto-Daz, 1991, Arango, 1989 ] </ref> and a more comprehensive approach, Model Based Software Engineering [ Whithey, 1994 ] , provides guidelines for both Domain Analysis and Application Engineering. Methodologies and guidelines for ontology design and implementation can greatly benefit from existing Domain Analysis techniques. <p> According to Arango and Prieto-Daz <ref> [ Arango and Prieto-Daz, 1991 ] </ref> , the expression "domain analysis" in the context of software reuse has been first introduced by Neighbors in his Phd Thesis [ Neighbors, 1981 ] . <p> Some software synthesizers are capable of generating code directly from domain models. The majority of graphical and textual representations, however, are useless without an infrastructure that provides the link between these representations and a machine executable representation. This infrastructure will be called the reuse infrastructure <ref> [ Arango and Prieto-Daz, 1991 ] </ref> . This infrastructure can be composed, for example, of a component library, component indexing and retrieving mechanisms, component description language, and a language for describing how the components can be assembled together.
Reference: [ Arango, 1989 ] <author> G. Arango. </author> <title> Domain analysis: From art to engineering. </title> <booktitle> In Proc. of 5th Int. Workshop on Soft. Spec. and Design, </booktitle> <pages> pages 152-159, </pages> <year> 1989. </year>
Reference-contexts: Domain analysis has also evolved from a process of extracting application specific knowledge to one that entails the higher level modeling of the relations among applications and their surrounding environment. Several domain analysis techniques has been proposed in the literature <ref> [ Arango and Prieto-Daz, 1991, Arango, 1989 ] </ref> and a more comprehensive approach, Model Based Software Engineering [ Whithey, 1994 ] , provides guidelines for both Domain Analysis and Application Engineering. Methodologies and guidelines for ontology design and implementation can greatly benefit from existing Domain Analysis techniques.
Reference: [ Arango, 1994 ] <author> G. Arango. </author> <title> Domain analysis methods. </title> <editor> In W. Schafer, R. Prieto-Daz, and M. Mat-sumoto, editors, </editor> <booktitle> Software Reusability, chapter 2. </booktitle> <publisher> Ellis Horwood, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: Some methods focus on supporting formal or semi-formal reasoning about domains. Others focus on compositional software construction. This section discusses the latter category. A reviews and comparisons of several of these reuse-oriented domain analysis methods is presented in 2.1. SOFTWARE REUSE 85 [ Wartik and Prieto-Daz, 1992 ] , <ref> [ Arango, 1994 ] </ref> , and [ Nilson et al., 1994 ] . These methods provide guidelines on what kind of information we should look for and how to represent it in order to support systematic software reuse. <p> Although these methods differ on how they breakdown and represent the domain knowledge, the general domain analysis process is basically the same for all methods. Identifying the fact that the differences between these method are accidental rather than essential, Arango proposes a Common Process for domain analysis <ref> [ Arango, 1994 ] </ref> . <p> Model: A model, according to the dictionary, is "a tentative description of a theory or system 86 CHAPTER 2. LITERATURE REVIEW that accounts for all its known properties; a preliminary pattern; a type or design" [ Col, ] . Arango in <ref> [ Arango, 1994 ] </ref> uses Apostel definition that states that ... any subject using a system A that is neither nor directly interacting with a system B to obtain information about the system B, is using A as a model for B. <p> The domain model is, then, a formal system of terms, relations between terms, rules to compose terms into expressions; rules to reason using these terms, and rules for mapping from entities in the real-world environment to expressions 2.1. SOFTWARE REUSE 87 in the model and vice-versa <ref> [ Arango, 1994 ] </ref> . A domain model in isolation is not in general an answer to the reusability problem. It may or may not be directly useful for operational reuse. Some software synthesizers are capable of generating code directly from domain models. <p> From the domain theory perspective it means the process of creating models that would allow reasoning about the domain. From the ontology perspective it means both. In the next paragraph I summarize the relevant domain analysis methods presented in [ Nilson et al., 1994 ] , <ref> [ Arango, 1994 ] </ref> . and [ Wartik and Prieto-Daz, 1992 ] . The emphasis here, as in the previous section, is on identifying the terminology used to describe the structural components of the domain model. In other words, I focus on identifying the meta-ontology used by these techniques. <p> Features are the central modeling concept that links assets with design rationales, information on functionality, performance, development method, operational constraints, and so on <ref> [ Arango, 1994 ] </ref> . A feature is usually described by a brief phrase. The reusable asset is stored in KAPTUR's knowledge-base with the corresponding feature explanation. <p> The method presented, however, bias the selection towards generative approaches based on application specific languages. 2.1. SOFTWARE REUSE 99 2.1.7.8 Arango's Common Process The Common Process is an approach proposed by Arango to unify several reuse-based domain analysis techniques <ref> [ Arango, 1994 ] </ref> . The Common Process can be seen as a general process that covers the commonalities of the methods presented in this section. This approach divides Domain Analysis into five activities: 1.
Reference: [ Balzer, 1985 ] <author> R. Balzer. </author> <title> A 15 year perspective on automatic programming. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 11(11) </volume> <pages> 1257-68, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: Advice is then required to select the refinements to be applied. Some examples of very high-level languages are SETL [ Krutchen et al., 1984, Schonberg et al., 1986 ] , Gist, <ref> [ Balzer, 1985 ] </ref> , V [ Smith et al., 1985 ] , and Refine [ Smith et al., 1985 ] . SETL , a language based on the use of set and set operations, was one of the first very high level languages. <p> A third example of a very high level language is Gist, that attempts to minimize the translation from the way we think about processes to the way we write about them by formalizing the constructs used in natural language <ref> [ Balzer, 1985 ] </ref> . Balzer points out 76 CHAPTER 2. LITERATURE REVIEW that although the language allowed designers to create specifications which were cogni-tively close to their system conceptualization, the specifications were difficult to read.
Reference: [ Barstow, 1986a ] <author> D. Barstow. </author> <title> An experiment in knowledge-based automatic programming. </title> <editor> In C. Rich and R.C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 133-156, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher> <address> 483 484 BIBLIOGRAPHY </address>
Reference-contexts: user guidance like the Program Development System (PDS) [ Cheatham, 1986 ] ; and those that allow more complex implementation but requires user guidance like CHI [ Smith et al., 1985 ] , KIDS [ Smith, 1990 ] , NIX [ Barstow, 1986b, Barstow, 1991 ] . and PSI system <ref> [ Barstow, 1986a ] </ref> . * Component-Based Methods: System implemented based on this approach rely on libraries of parametrized, plug-compatible, and reusable components to transform high-level specifications of target systems into source code [ Batory and Geraci, 1997 ] .
Reference: [ Barstow, 1986b ] <author> D. Barstow. </author> <title> A perspective on automatic programming. </title> <editor> In C. Rich and R.C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 537-59, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: To minimize this problem, a paraphraser that translates formal specifications into natural language descriptions has been added to the system. * Domain Specific Languages: Earlier work on program synthesis has focused on the roles played by deduction and programming knowledge in the programming process <ref> [ Barstow, 1986b ] </ref> . Motivated by one of the basic assumptions behind automatic programming that end-users are interested in the application use and not in its programming, researchers started emphasizing more and more the importance of domain knowledge in these kind of systems. <p> The wide-spectrum language has a pattern matching mechanism that triggers transformations, or rules, that maps domain-specific descriptions in terms of more generic, and less domain-specific constructs. This is the approach taken by Barstow's system NIX <ref> [ Barstow, 1986b, Barstow, 1991 ] </ref> . The language used, ANG, is a wide-spectrum language that has no domain-specific component built-in. In this system, an informal problem description written in a domain-specific language is translated into mathematical formalisms that require no domain knowledge. <p> those that are relatively limited in power but require no user guidance like the Program Development System (PDS) [ Cheatham, 1986 ] ; and those that allow more complex implementation but requires user guidance like CHI [ Smith et al., 1985 ] , KIDS [ Smith, 1990 ] , NIX <ref> [ Barstow, 1986b, Barstow, 1991 ] </ref> . and PSI system [ Barstow, 1986a ] . * Component-Based Methods: System implemented based on this approach rely on libraries of parametrized, plug-compatible, and reusable components to transform high-level specifications of target systems into source code [ Batory and Geraci, 1997 ] .
Reference: [ Barstow, 1991 ] <author> D. Barstow. </author> <title> Automatic programming for device-control software. </title> <editor> In M. Lowry and R. McCartney, editors, </editor> <booktitle> Automating Software Design, </booktitle> <pages> pages 123-40. </pages> <publisher> AAAI Press/The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The wide-spectrum language has a pattern matching mechanism that triggers transformations, or rules, that maps domain-specific descriptions in terms of more generic, and less domain-specific constructs. This is the approach taken by Barstow's system NIX <ref> [ Barstow, 1986b, Barstow, 1991 ] </ref> . The language used, ANG, is a wide-spectrum language that has no domain-specific component built-in. In this system, an informal problem description written in a domain-specific language is translated into mathematical formalisms that require no domain knowledge. <p> those that are relatively limited in power but require no user guidance like the Program Development System (PDS) [ Cheatham, 1986 ] ; and those that allow more complex implementation but requires user guidance like CHI [ Smith et al., 1985 ] , KIDS [ Smith, 1990 ] , NIX <ref> [ Barstow, 1986b, Barstow, 1991 ] </ref> . and PSI system [ Barstow, 1986a ] . * Component-Based Methods: System implemented based on this approach rely on libraries of parametrized, plug-compatible, and reusable components to transform high-level specifications of target systems into source code [ Batory and Geraci, 1997 ] .
Reference: [ Batory and Geraci, 1997 ] <author> D. Batory and B.J. Geraci. </author> <title> Composition validation and subjectivity in GenVoca generators. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 23(2) </volume> <pages> 67-82, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: KIDS [ Smith, 1990 ] , NIX [ Barstow, 1986b, Barstow, 1991 ] . and PSI system [ Barstow, 1986a ] . * Component-Based Methods: System implemented based on this approach rely on libraries of parametrized, plug-compatible, and reusable components to transform high-level specifications of target systems into source code <ref> [ Batory and Geraci, 1997 ] </ref> . Application generators based on a library of patterns, like the Pattern Based Simulator Generator (PSiGene) [ Schuetze et al., 1997 ] , are typical examples. Rich and Waters refer to these approaches as Inspection Methods [ Rich and Waters, 1988 ] .
Reference: [ Batory and O'Malley, 1992 ] <author> D. Batory and S. O'Malley. </author> <title> The design and implementation of hierarchical software systems with reusable components. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: These compositional constraints represent the architectural assumptions of the modeling framework; they define a 30 CHAPTER 1. INTRODUCTION grammar for describing systems from components. Batory refers to a software tool that implements rules of composition as a component layout editor <ref> [ Batory and O'Malley, 1992 ] </ref> . The configuration tool implemented enforces the compositional constraints and act as a component layout editor.
Reference: [ Batory et al., 1994 ] <author> D. Batory, V. Singhal, J. Thomas, S. Dasari, B. Geraci, and M. Sirkin. </author> <title> The GenVoca model of software system generators. </title> <journal> IEEE Software, </journal> <pages> pages 89-94, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: LITERATURE REVIEW design patterns, are at a higher level of abstraction and define a vocabulary for communicating advice and explanations for system implementation decisions. The GenVoca model proposed by Batory et al. <ref> [ Batory et al., 1994 ] </ref> is an example of a family of system generators in which an application is synthesized by the combination of sub-systems. Domain-specific components are described by parametrized, standard interfaces.
Reference: [ Becker and Daz-Herrera, 1994 ] <author> M.A. Becker and J.L. Daz-Herrera. </author> <title> Creating domain specific libraries: a methodology, design guidelines and an implementation. </title> <booktitle> In Proceedings of 1994 3rd International Conference on Software Reuse, </booktitle> <address> Rio de Janeiro, Brazil, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: INTRODUCTION methods into our ontology. From previous experience in building application systems [ Lassila et al., 1996, Wilkins et al., 1996, Smith, 1994 ] , from revising several different system architectures [ Becker, 1993 ] , and from previous domain analysis models <ref> [ Becker and Daz-Herrera, 1994 ] </ref> , developed for different projects, an informal ontological model has been defined [ Smith and Becker, 1997b ] . This model corresponds to the abstract model of the framework. It defines entities, relations, and associates capabilities to concepts, but does not provide any functionality. <p> The class library design and implementation underlying the ozone framework, and the ontology which provides its conceptual foundation, have followed from retrospective analysis of these scheduling domains and systems (e.g., <ref> [ Becker and Daz-Herrera, 1994 ] </ref> ), together with application of object-oriented analysis and design principles [ Smith and Lassila, 1994a ] . <p> From our experience building scheduling systems for several different problem domains [ Smith, 1987, Lassila et al., 1996, Wilkins et al., 1996, Muscettola et al., 1992 ] , and from revising several existing knowledge-based scheduling architectures <ref> [ Becker, 1993, Becker and Daz-Herrera, 1994 ] </ref> (see Chapter 2 section 2.3,) we have identified a collection of generic behaviors that can be adapted with little effort to implement applications for several different scheduling situations.
Reference: [ Becker, 1993 ] <author> M.A. Becker. </author> <title> Revision of reactive scheduling architectures. </title> <type> Technical report, </type> <institution> Graduate School Of Industrial Administration, Carnegie Mellon Iniversity, </institution> <year> 1993. </year>
Reference-contexts: INTRODUCTION methods into our ontology. From previous experience in building application systems [ Lassila et al., 1996, Wilkins et al., 1996, Smith, 1994 ] , from revising several different system architectures <ref> [ Becker, 1993 ] </ref> , and from previous domain analysis models [ Becker and Daz-Herrera, 1994 ] , developed for different projects, an informal ontological model has been defined [ Smith and Becker, 1997b ] . This model corresponds to the abstract model of the framework. <p> From our experience building scheduling systems for several different problem domains [ Smith, 1987, Lassila et al., 1996, Wilkins et al., 1996, Muscettola et al., 1992 ] , and from revising several existing knowledge-based scheduling architectures <ref> [ Becker, 1993, Becker and Daz-Herrera, 1994 ] </ref> (see Chapter 2 section 2.3,) we have identified a collection of generic behaviors that can be adapted with little effort to implement applications for several different scheduling situations.
Reference: [ Bell and Han, 1991 ] <author> C.E. Bell and J. Han. </author> <title> A new heuristic solution method in resource-constrained project scheduling. </title> <journal> Naval Research Logistics, </journal> <volume> 38 </volume> <pages> 315-331, </pages> <year> 1991. </year>
Reference-contexts: 6.4 The Problem Solving Ontology for the Benchmark Problems Exact solutions to the Resource Constrained Project Scheduling problem using mathematical programming techniques like integer programming, dynamic programming, bounded enumeration, implicit enumeration, and branch and bound are generally appropriate for small or moderate size projects projects with less than fifty activities <ref> [ Kolisch and Drexl, 1996, Bell and Han, 1991 ] </ref> . This relative lack of success of optimization techniques in problems of realistic size motivated the development of heuristic procedures which can generate reasonably good feasible solutions. <p> In terms of priority rules used to select the next activity to schedule, several studies comparing the results obtained by different resource related or temporally related heuristics have already been published <ref> [ Bell and Han, 1991 ] </ref> . Temporally related heuristics include minimum slack, minimum late finish time, and shortest job first. Resource related heuristics include greatest resource utilization, greatest total resource demand, etc. <p> to solve the benchmark problems: one in which the priority rule selects, at any point in time, one activity among all the "schedulable" activities; one in which only the activities in the critical path and corresponding predecessors are included in the set of "schedulable" activities; and the algorithm described in <ref> [ Bell and Han, 1991 ] </ref> that adds precedence constraints between activities competing for the same 444 CHAPTER 6. AN APPLICATION FOR PROJECT SCHEDULING resource. The implementation of the Bell & Han algorithm did not generate comparative results, and will not be included in the discussion. <p> Nitin Agarwal from SAS Institute (sasnza@unx.sas.com) using "Critical Path Method." In the comparison tables, we designate his results as AGARWAL. 3. Colin Bell form University of Iowa (cbell@scout-po.biz.uiowa.edu) using the method described in <ref> [ Bell and Han, 1991 ] </ref> . In the comparison tables, we designate his results as BELL. 4.
Reference: [ Benjamins and Pierret-Golbreich, 1996 ] <author> R. Benjamins and C. Pierret-Golbreich. </author> <title> Assumptions of problem-solving methods. </title> <editor> In Nigel Shadbolt, Guus Schreiber, and Kieron O'Hara, editors, </editor> <booktitle> Advances in Knowledge Acquisition, Ninth European Knowledge Acquisition Workshop, volume 1076 of Lectures Notes in Artificial Intelligence, </booktitle> <address> United Kingdom, </address> <month> May </month> <year> 1996. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: Likewise, the information requirements imposed by the problem-solving methods affects the scope and organization of the domain ontology. Studer et al [ Studer et al., 1998 ] argues that an ontology for methods and tasks that makes explicit the interaction between problem-solving and domain knowledge <ref> [ Benjamins and Pierret-Golbreich, 1996 ] </ref> can help minimize this interaction problem. <p> No method-specific ontology for control is discussed. The goal that indexes the problem-solving method is referred to as the method competence. The format in which the method expects the domain knowledge is called method assumptions. Benjamins & Pierret-Golbreich vocabulary for describing assumptions <ref> [ Benjamins and Pierret-Golbreich, 1996 ] </ref> is discussed in the next paragraph. Chandrasekaran's ontology does not contribute with any new element to the field of problem-solving ontologies. It just state the obvious about well known concepts in the field. <p> Assumptions of Problem Solving Methods The task and problem type taxonomies discussed in section 2.2.3.2.1 describe problem-solving in terms of "what" has to be achieved; the majority of problem-solving method ontologies discussed in the current section address the problem of "how" to solve the problem. Benjamins & Pierret-Golbreich <ref> [ Benjamins and Pierret-Golbreich, 1996 ] </ref> address the problem of defining "when" a problem-solving method is applicable to a particular task. They refer to these applicability conditions as assumptions of problem-solving methods. <p> To address these problems, a classification scheme and a first-order based formal language for describing assumptions is proposed in <ref> [ Benjamins and Pierret-Golbreich, 1996 ] </ref> . The assumption classification is a conceptual organization consisting of two parts: a horizontal and a vertical organization. For the horizontal organization, a taxonomy is defined. Three basic types of assumptions are identified: epistemological, pragmatic, and teleological.
Reference: [ Benjamins, 1994 ] <author> R. </author> <title> Benjamins. On a role of problem-solving methods in knowledge acquisitions - experiments with diagnostic strategies. </title> <editor> In Luc Steels, Guus Schreiber, and Walter Van de Velde, editors, </editor> <title> A Future for Knowledge Acquisition, </title> <booktitle> Eighth European Knowledge Acquisition Workshop, BIBLIOGRAPHY 485 volume 867 of Lectures Notes in Artificial Intelligence, </booktitle> <pages> pages 137-157, </pages> <address> Belgium, </address> <month> September </month> <year> 1994. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: Benjamins & Pierret-Golbreich [ Benjamins and Pierret-Golbreich, 1996 ] address the problem of defining "when" a problem-solving method is applicable to a particular task. They refer to these applicability conditions as assumptions of problem-solving methods. Benjamins in <ref> [ Benjamins, 1994 ] </ref> defines task as a specification of "what" needs to be achieved by the problem-solver. A task has a goal, is characterized by its input and output, and can be decomposed into subtasks. <p> The problem-solving method, therefore, describes "how" to achieve the goal represented by the task . Similar definitions are provided by Chandrasekaran [ Chandrasekaran and Johnson, 1993 ] , Gennari et al. [ Gennari et al., 1998 ] , and Benjamins <ref> [ Benjamins, 1994 ] </ref> . A knowledge source is an implemented instance of a problem solving method, specifically tailored for the representation used to describe the domain 292 CHAPTER 3.
Reference: [ Boose, 1988 ] <author> J. H. Boose. </author> <title> Knowledge acquisition techniques and tools: Current research strategies and approaches. In Institute for New Generation Computer Technology (ICOT), editor, </title> <booktitle> Proceedings of the International Conference on Fifth Generation Computer Systems. </booktitle> <volume> Volume 3, </volume> <pages> pages 1221-1235, </pages> <address> Berlin, FRG, November 1988. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: Domain analysis methods specify a set of models to represent the acquired domain information. Domain Analysis methods resemble previous knowledge acquisitions approaches that defined protocols for interviewing domain experts. The basic idea was to collect and replicate the human problem solving behavior <ref> [ Boose, 1988 ] </ref> . This view has changed in the last years. More recent approaches consider knowledge acquisition as a model building activity.
Reference: [ Breuker and Van de Velde, 1994 ] <author> J. Breuker and W. Van de Velde. </author> <title> CommonKADS Library for Expertise Modeling, </title> <booktitle> volume 21 of Frontiers in Artificial Intelligence and Applications. </booktitle> <publisher> IOS Press, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1994. </year>
Reference-contexts: To support the implementation of CommonKADS' models of expertise, a suite of problem solving types is proposed by Breuker [ Breuker, 1994b, Breuker, 1994a ] , and ontologies for describing tasks and problem-solving methods related to these problem solving types is presented in <ref> [ Breuker and Van de Velde, 1994 ] </ref> . More recent efforts on defining method and task ontologies, like [ Coelho and Lapalme, 1996 ] , [ Chandrasekaran and Josephson, 2.2. <p> Later, McDermott and his group propose a series of special purpose problem-solvers 136 CHAPTER 2. LITERATURE REVIEW based on Role Limiting Methods [ McDermott, 1988 ] , and the CommonKADS group in Europe implements a library of problem-solving methods <ref> [ Breuker and Van de Velde, 1994 ] </ref> indexed by a suite of problem types identified by Breuker [ Breuker, 1994b ] . An extensive and well structured classification of problem-solving methods, based on the research previously mentioned, can be found in [ Puppe, 1993 ] . <p> The dependencies between problems provide a more consistent way of organizing problem types. These problem types serve as an indexing mechanism for a library of problem-solving methods described in details in <ref> [ Breuker and Van de Velde, 1994 ] </ref> . Breuker and his colleagues precisely define concepts like problem, solution, task, methods, and inference. Breuker is the first among the authors reviewed to establish a distinction between the concept of problem and the concept of task. <p> Detailed description of each problem type and appropriate problem-solving methods implemented in the CommonKADS library of expertise is provided in <ref> [ Breuker and Van de Velde, 1994 ] </ref> . Among all these problem types, we are particularly interested in the assignment problem. An ontology for describing problem-solving concepts for scheduling is described in [ Sundin, 1994 ] and summarized in the next section. <p> Sundin describes the method in the context of the CommonKADS library of reusable problem-solving components <ref> [ Breuker and Van de Velde, 1994 ] </ref> . Puppe also discusses a problem-solving method for the assignment problem in [ Puppe, 1993 ] .
Reference: [ Breuker, 1994a ] <author> J. Breuker. </author> <title> Components of problem solving and types of problems. </title> <editor> In Luc Steels, Guus Schreiber, and Walter Van de Velde, editors, </editor> <title> A Future for Knowledge Acquisition, </title> <booktitle> Eighth European Knowledge Acquisition Workshop, volume 867 of Lectures Notes in Artificial Intelligence, </booktitle> <address> Belgium, </address> <month> September </month> <year> 1994. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: To support the implementation of CommonKADS' models of expertise, a suite of problem solving types is proposed by Breuker <ref> [ Breuker, 1994b, Breuker, 1994a ] </ref> , and ontologies for describing tasks and problem-solving methods related to these problem solving types is presented in [ Breuker and Van de Velde, 1994 ] .
Reference: [ Breuker, 1994b ] <author> J. Breuker. </author> <title> A suite of problem types. </title> <editor> In J. Breuker and W. Van de Velde, editors, </editor> <title> CommonKADS Library for Expertise Modeling, </title> <booktitle> volume 21 of Frontiers in Artificial Intelligence and Applications, chapter 4, </booktitle> <pages> pages 57-87. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1994. </year>
Reference-contexts: To support the implementation of CommonKADS' models of expertise, a suite of problem solving types is proposed by Breuker <ref> [ Breuker, 1994b, Breuker, 1994a ] </ref> , and ontologies for describing tasks and problem-solving methods related to these problem solving types is presented in [ Breuker and Van de Velde, 1994 ] . <p> LITERATURE REVIEW based on Role Limiting Methods [ McDermott, 1988 ] , and the CommonKADS group in Europe implements a library of problem-solving methods [ Breuker and Van de Velde, 1994 ] indexed by a suite of problem types identified by Breuker <ref> [ Breuker, 1994b ] </ref> . An extensive and well structured classification of problem-solving methods, based on the research previously mentioned, can be found in [ Puppe, 1993 ] . <p> Identifying certain problems with current taxonomies for problem solving, specially problems related to multiple inheritance of problem classes, Breuker proposes a classification scheme that he defines as a suite of problem-solving types <ref> [ Breuker, 1994b ] </ref> : a typology described as sequences of dependent problems. The dependencies between problems provide a more consistent way of organizing problem types. <p> The solution generation or extension is clearly an assignment problem, but the cycle implemented by the control architecture goes through a sequence of problem-solving activities that involves the formulation and solution of problems that can be classified, according to Breuker's suite of problem types <ref> [ Breuker, 1994b ] </ref> , as monitoring, diagnosis, assessment, and assignment. If tasks related to the application development are also included into the picture, modeling and design problems also have to be addressed. With the possible exception of prediction, the full suite of Breuker's problem types has to be considered.
Reference: [ Burke and Prosser, 1989 ] <author> P. Burke and P. Prosser. </author> <title> A distributed asynchronous system for predictive and reactive scheduling. </title> <type> Technical Report Technical Report AISL42, </type> <institution> Dept. of Computer Science, University of Strathclyde, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: This aspect identifies the repair actions available to the systems and how they are selected. The systems analyzed are: OPIS [ Smith, 1994 ] , SONIA [ Collinot et al., 1988 ] , REDS [ Hadavi et al., 1992 ] , Distributed Asynchronous Scheduler ( DAS ) <ref> [ Burke and Prosser, 1989 ] </ref> , GERRY ( Zweben's Iterative Repair ) [ Zweben et al., 1992a ] , Minton's Min-Conflicts Heuristic [ Minton et al., 1992a ] , Le Pape's Reactive Schedule Model [ Le Pape, 1991 ] . <p> It is not specified what module has or would be able to have such capability. The remaining types of events are treated according to the description given above. 2.3.5 Distributed Asynchronous Scheduler In the Distributed Asynchronous Scheduler <ref> [ Burke and Prosser, 1989 ] </ref> the scheduling problem is decomposed across a hierarchy of communicating agents where each agent explicitly represents and exploits opportunities, learns problem-solving knowledge, identifies and explains conflicts, and communicates and negotiates with other agents. This hierarchical decomposition of the scheduling 2.3. <p> and REDS have the capability of switching between an order-based and a resource-based scheduling perspective, DAS can focus the problem solving effort at a finer level of granularity: it is able to focus the problem solving effort at the level of individual operations on resources over specific intervals of time <ref> [ Burke and Prosser, 1989 ] </ref> . The rationale for this solution is based on the fact that the criticality of a resource usually occurs only over a certain interval of time and the crit-icality of an order only occurs over a subset of operations of the order. <p> This assistant module is an auxiliary module similar to REDS' Statistician but that only communicates with one type of agent. The assistant interprets the conflict set as a conjunction of assumptions that are illegal. The assistant performs negative hyper-resolution <ref> [ Burke and Prosser, 1989 ] </ref> on the conflicting operations and derives conflict sets across subordinate resources. The output of the assistant module is a set of operations in disjunctive normal form, where each conjunction is a possible set of operations to be retracted in order to solve the conflict.
Reference: [ Bushmann et al., 1996 ] <author> T. J. Bushmann, R. Meunier, H. Rohnert, P. Sommerlad, and M. Stal. </author> <title> Pattern-Oriented Software Architecture: A System of Pattern. </title> <publisher> John Wiley and Sons, </publisher> <address> Chichester, West Sussex, England, </address> <year> 1996. </year>
Reference-contexts: To address this issue, Buschman and Meunier <ref> [ Bushmann et al., 1996 ] </ref> list two characteristics of patterns that distinguish them from traditional software components. <p> In other words, a pattern language accounts for the architectural mismatches [ Garlan et al., 1995 ] caused by the use of independently developed components. Based on these two characteristics, Buschman and Meunier <ref> [ Bushmann et al., 1996 ] </ref> propose a classification schema for patterns based on three different dimensions: granularity, functionality, and structural principles.
Reference: [ Cacciabue, 1997 ] <author> P.C. Cacciabue. </author> <title> A methodology of human factors analysis for systems engineering: </title> <journal> Theory and applications. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, </journal> <volume> 27(3) </volume> <pages> 325-339, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: This brought additional complications into the application building process. Understanding the system behavior was not enough anymore. The user cognitive process should also be accounted for during the system design in order to provide the appropriate interfaces and procedures <ref> [ Cacciabue, 1997 ] </ref> . AI systems that support this kind of co-operation between different agents will be referred as mixed-initiative systems [ Novick and Sutton, 1997 ] .
Reference: [ Chandrasekaran and Johnson, 1993 ] <author> B. Chandrasekaran and T.R. Johnson. </author> <title> Generic tasks and task structure: History, critique, and new directions. </title> <editor> In J.M. David, J.P. Krivine, and R. Simmons, editors, </editor> <booktitle> Second Generation Expert Systems, </booktitle> <pages> pages 232-272. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <note> 486 BIBLIOGRAPHY </note>
Reference-contexts: Following this initial effort on defining a taxonomy for problem-solving types, McDermott defines a taxonomy based on what he refers to as role-limiting-methods [ McDermott, 1988 ] , and Chandrasekaran improve the Generic Task concept into Task Structures <ref> [ Chandrasekaran and Johnson, 1993 ] </ref> . A comprehensive extension of these classifications is proposed by Puppe in [ Puppe, 1993 ] . <p> Clancey's work on heuristic classification [ Clancey, 1985 ] and Chandrasekaran's notion of Generic Tasks <ref> [ Chandrasekaran and Johnson, 1993 ] </ref> are considered the first proposals for the development of knowledge-based systems from reusable problem-solving components. Later, McDermott and his group propose a series of special purpose problem-solvers 136 CHAPTER 2. <p> His answer to the criticism that some methods are applicable to all or many tasks and, as a result, should not be indexed by task is that tasks as instances of problem can be partially ordered in a generalization hierarchy <ref> [ Chandrasekaran and Johnson, 1993 ] </ref> ; methods that seems to be independent of the tasks are either very general problem-solving strategies, or are very specific methods that can be used as components to solve sub-tasks of a large number of tasks. <p> In answer to several criticisms raised by the AI community to his approach, Chandrasekaran extended the concept of Generic Tasks into a framework called Task Structure <ref> [ Chandrasekaran and Johnson, 1993 ] </ref> . The task structure framework, solved, among others problems, the lack of flexibility in method specification encountered in generic task. <p> In this definition, the concept of task is defined as a description of "what" has to be achieved by the problem-solver. The problem-solving method, therefore, describes "how" to achieve the goal represented by the task . Similar definitions are provided by Chandrasekaran <ref> [ Chandrasekaran and Johnson, 1993 ] </ref> , Gennari et al. [ Gennari et al., 1998 ] , and Benjamins [ Benjamins, 1994 ] . A knowledge source is an implemented instance of a problem solving method, specifically tailored for the representation used to describe the domain 292 CHAPTER 3.
Reference: [ Chandrasekaran and Josephson, 1997 ] <author> B. Chandrasekaran and J.R. Josephson. </author> <title> The ontology of tasks and methods. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Ontological Engineering, </booktitle> <pages> pages 9-16, </pages> <address> Palo Alto, CA, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: The main difficulty here was in defining the ontology for problem solving methods. Although the idea of reusing problem solving methods and knowledge is quite common, ontologies for problem solving has not gotten much attention from the knowledge-based community <ref> [ Chandrasekaran and Josephson, 1997 ] </ref> . Once the ontology has been defined, the mechanism to establish the relation between the functional behavior of the concepts, or capabilities, and their corresponding implementation was developed. We had already implemented an extensive class library for building scheduling systems. <p> In philosophy, the term Ontology designates the systematic study of the kind of things that exists. In the AI community, although there is no agreed upon definition, the term has been used to designate or (1) a representation vocabulary specialized to some particular problem domain <ref> [ Chandrasekaran and Josephson, 1997 ] </ref> , like an ontology for planning and scheduling, or (2) a meta-model for a body of knowledge describing some common-sense knowledge domain [ Wielinga and Schreiber, 1993 ] , like a knowledge base for medical diagnosis. <p> As research progressed, it become clear that there were certain regularities on how domain knowledge was used to solve certain types of problems. This motivated attempts to separate the representation of knowledge about the objects and relations in the application domain, the domain factual knowledge <ref> [ Chandrasekaran and Josephson, 1997 ] </ref> , from the knowledge about algorithms and methods to solve the problems, the problem-solving knowledge. <p> Recent examples of ontologies that pursue these ideas are Studer et al.'s ontologies for configuring problem-solving methods [ Studer et al., 1996 ] , Fensel et al.'s task ontology for parametric design [ Fensel et al., 1997 ] , Chandrasekaran's ontology of tasks and methods <ref> [ Chandrasekaran and Josephson, 1997 ] </ref> , Gennari et al's method description language [ Gennari et al., 1998 ] , and Coelho & Lapalme's method ontology [ Coelho and Lapalme, 1996 ] . <p> Given its goal, this ontology is neither formal nor implemented. Its description, <ref> [ Chandrasekaran and Josephson, 1997 ] </ref> , is just a set of natural language definitions of a number of concepts. Some of concepts are not really defined; most of the "definitions" are just some examples of the concept in a particular domain. <p> ONTOLOGIES 161 mapping mechanism based on the use of adapters. Here, in agreement with Chandrasekaran comment that there is no such a thing as a task-independent method <ref> [ Chandrasekaran and Josephson, 1997 ] </ref> , we assume a task-independent method to be a method defined for a very general class of problems.
Reference: [ Chandrasekaran, 1983 ] <author> B. Chandrasekaran. </author> <title> Towards a taxonomy of problem solving types. </title> <journal> AI Magazine, </journal> <volume> 4(1) </volume> <pages> 9-17, </pages> <month> Winter/Spring </month> <year> 1983. </year>
Reference-contexts: ONTOLOGIES 141 knowledge in terms of different substructures each of which specializes in one type of problem-solving <ref> [ Chandrasekaran, 1983 ] </ref> . This formulation evolved into the notion of Generic Tasks [ Chandrasekaran, 1985 ] . <p> According to this generic task model, there is no distinction between the knowledge-base and the problem solver: problem-solving is embedded in the knowledge structure and the knowledge in the system is distributed among problem-solvers that know how to use that knowledge <ref> [ Chandrasekaran, 1983 ] </ref> . The Generic Task approach subscribes to the strong interaction hypothesis since the representation and organization of the knowledge is defined by its intended use. The concept of task introduced by Generic Tasks does not separate the problem type from the problem-solving method.
Reference: [ Chandrasekaran, 1985 ] <author> B. Chandrasekaran. </author> <title> Generic tasks in expert system design and their role in explanation of problem solving. </title> <booktitle> In Proceedings of the National Academy of Science/Office of Naval Research Workshop on AI and Distributed Problem Solving, </booktitle> <address> Washington, DC, </address> <year> 1985. </year>
Reference-contexts: The third and last area of interest is research on ontologies to describe the knowledge about problem solving methods. The separation between problem solving knowledge and domain knowledge has its origins in Clancey's heuristic classification [ Clancey, 1985 ] and Chandrasekaran's generic tasks <ref> [ Chandrasekaran, 1985 ] </ref> . Clancey's and Chandrasekaran's work can be seen, from an ontology perspective, as the first efforts to define a taxonomy for problem and problem-solving types. <p> ONTOLOGIES 141 knowledge in terms of different substructures each of which specializes in one type of problem-solving [ Chandrasekaran, 1983 ] . This formulation evolved into the notion of Generic Tasks <ref> [ Chandrasekaran, 1985 ] </ref> .
Reference: [ Chapman, 1987 ] <author> D. Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-78, </pages> <year> 1987. </year>
Reference-contexts: This state-based representation have strong influence on the representations used by knowledge-based 1.1. PROBLEM DESCRIPTION 11 scheduling systems. The solution to a generic planning problem is basically a total, or partial, order on a finite set of steps or actions <ref> [ Chapman, 1987 ] </ref> . The plan is the sequence of actions required to attain a desired world state, and, if necessary, the temporal allocation of the required resources. The temporal allocation of resources to activities over time constitutes what is usually called a schedule. <p> As an illustration, the problem of determining if a certain formula is true at a certain point in time has been proved by Chapman to be NP-complete <ref> [ Chapman, 1987 ] </ref> . The scheduling problem is also known to be NP-hard. A number of algorithms and software systems have been developed to solve problems in several different planning domains. <p> Operations Research problem solving is characterized by its focus on the use of mathematical 1.1. PROBLEM DESCRIPTION 15 formulations and optimization techniques. As has already been discussed, the characteristics of the planning and scheduling problems make them not suitable for pure optimization methods. Most problems are NP-hard <ref> [ Chapman, 1987, Garey and Johnson, 1979 ] </ref> . Optimal solutions are only attainable for simplified or idealized models [ Simon, 1981a ] .
Reference: [ Cheatham, 1986 ] <author> T.E. Cheatham. </author> <title> Reusability through program transformation. </title> <editor> In C. Rich and R.C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 185-190, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: As a consequence, transformational systems must either request advice from the user, or restrict the set of applicable transformations. Existing transformational implementations can be divided into two groups: those that are relatively limited in power but require no user guidance like the Program Development System (PDS) <ref> [ Cheatham, 1986 ] </ref> ; and those that allow more complex implementation but requires user guidance like CHI [ Smith et al., 1985 ] , KIDS [ Smith, 1990 ] , NIX [ Barstow, 1986b, Barstow, 1991 ] . and PSI system [ Barstow, 1986a ] . * Component-Based Methods: System
Reference: [ Clancey, 1985 ] <author> W.J. Clancey. </author> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 289-350, </pages> <year> 1985. </year>
Reference-contexts: The third and last area of interest is research on ontologies to describe the knowledge about problem solving methods. The separation between problem solving knowledge and domain knowledge has its origins in Clancey's heuristic classification <ref> [ Clancey, 1985 ] </ref> and Chandrasekaran's generic tasks [ Chandrasekaran, 1985 ] . Clancey's and Chandrasekaran's work can be seen, from an ontology perspective, as the first efforts to define a taxonomy for problem and problem-solving types. <p> The first step in the direction of creating reusable representations of this problem-solving knowledge was the identification of the different types of problems and the creation of general problem-solving strategies to approach these different classes of problems. Clancey's work on heuristic classification <ref> [ Clancey, 1985 ] </ref> and Chandrasekaran's notion of Generic Tasks [ Chandrasekaran and Johnson, 1993 ] are considered the first proposals for the development of knowledge-based systems from reusable problem-solving components. Later, McDermott and his group propose a series of special purpose problem-solvers 136 CHAPTER 2. <p> The analysis of the "heuristic classification method" is often mentioned as the main contribution of the work described in <ref> [ Clancey, 1985 ] </ref> . <p> ONTOLOGIES 139 (source <ref> [ Clancey, 1985 ] </ref> ) Adopting a system-oriented approach, in which a system is defined as a complex of interacting objects that have some process (I/O) behavior, Clancey recasted Stefik & Hayes-Roth's classification into a hierarchy of possible generic operations that can be performed on or with a system.
Reference: [ Coelho and Lapalme, 1996 ] <author> E. Coelho and G. Lapalme. </author> <title> Describing reusable problem-solving methods with a method ontology. </title> <booktitle> In Proceedings of Tenth Knowledge Acquisition for Knowledge-Based Systems Workshop, </booktitle> <address> Banff, Alberta, Canada, </address> <year> 1996. </year> <note> Available from http://ksi.cpsc.ucalgary.ca:80/KAW/KAW96/KAW96Proc.html. </note>
Reference-contexts: More recent efforts on defining method and task ontologies, like <ref> [ Coelho and Lapalme, 1996 ] </ref> , [ Chandrasekaran and Josephson, 2.2. <p> 1996 ] , Fensel et al.'s task ontology for parametric design [ Fensel et al., 1997 ] , Chandrasekaran's ontology of tasks and methods [ Chandrasekaran and Josephson, 1997 ] , Gennari et al's method description language [ Gennari et al., 1998 ] , and Coelho & Lapalme's method ontology <ref> [ Coelho and Lapalme, 1996 ] </ref> . In the next paragraphs we summarize the main classification schemes for problem types and problem-solving methods, and present the main concepts and definitions proposed in some of the previously mentioned task and method ontologies. <p> Coelho & Lapalme's Method Ontology Assuming the view that a problem-solving method is a set of operations over a particular structure of knowledge, Coelho & Lapalme's Method Ontology <ref> [ Coelho and Lapalme, 1996 ] </ref> 2.2. ONTOLOGIES 163 aims at clarifying the organization and content of this knowledge structure in order to facilitate method reuse. Similar to McDermott's role-limiting approach, the knowledge structure is defined in terms of the roles the knowledge play in the problem solving process. <p> Since the operations performed by the method are the inferences that act upon an ontology, a method ontology to formally define the knowledge roles and inferences has been developed. The ontology, according to their view, acts as an interface for an implemented problem-solving method. The method ontology described in <ref> [ Coelho and Lapalme, 1996 ] </ref> is implemented in an extended version of Ontolingua. The inference structure used in the ontology is based on CommonKADS conceptual model that separates control knowledge into task and inference knowledge.
Reference: [ Cohen, 1987 ] <author> D. Cohen. </author> <title> Automatic compilation of logical specifications into efficient programs. </title> <booktitle> In Proceedings of the 5th National Conference on Artificial Intelligence, </booktitle> <pages> pages 20-25. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1987. </year>
Reference-contexts: The GTE-ISI research group has applied this approach to message handling in command and control systems. The project created a domain-specific message handling language for describing the format, validating, and processing of messages. A program generator then translates this DSSA language into a domain-independent specification language, AP5 <ref> [ Cohen, 1987 ] </ref> , which is then translated into the target programming language. Initial tests showed a 100-fold decrease in the amount of code required to format, validate, and process messages used in the Army Tactical Command and Control System (ATCCS) [ Mettala and Graham, 1992 ] .
Reference: [ Col, ] <editor> Collins Cobuild. </editor> <publisher> American Heritage Dictionary. </publisher>
Reference-contexts: Model: A model, according to the dictionary, is "a tentative description of a theory or system 86 CHAPTER 2. LITERATURE REVIEW that accounts for all its known properties; a preliminary pattern; a type or design" <ref> [ Col, ] </ref> . Arango in [ Arango, 1994 ] uses Apostel definition that states that ... any subject using a system A that is neither nor directly interacting with a system B to obtain information about the system B, is using A as a model for B.
Reference: [ Collinot et al., 1988 ] <author> A. Collinot, C. Le Pape, and G. Pinoteau. SONIA: </author> <title> a knowledge-based scheduling system. </title> <journal> Artificial Intelligence in Engineering, </journal> <volume> 3(2), </volume> <year> 1988. </year>
Reference-contexts: The choice of the action can be guided by, for example, conflict type, conflict magnitude, resource affected, and order affected. This aspect identifies the repair actions available to the systems and how they are selected. The systems analyzed are: OPIS [ Smith, 1994 ] , SONIA <ref> [ Collinot et al., 1988 ] </ref> , REDS [ Hadavi et al., 1992 ] , Distributed Asynchronous Scheduler ( DAS ) [ Burke and Prosser, 1989 ] , GERRY ( Zweben's Iterative Repair ) [ Zweben et al., 1992a ] , Minton's Min-Conflicts Heuristic [ Minton et al., 1992a ] , <p> Based on the conflict type, on the metric values computed during the conflict analysis phase, and on the capabilities of each revision method above, a repair action is selected. 2.3.3 SONIA The SONIA system <ref> [ Collinot et al., 1988 ] </ref> is very similar to the OPIS scheduling system. It also integrates predictive and reactive scheduling components but do not consider the initial schedule generation as a special case of the reactive process.
Reference: [ Crawford, 1996 ] <author> J.M. Crawford. </author> <title> An approach to resource constrained project scheduling. In G.F. </title> <editor> Luger, editor, </editor> <booktitle> Artificial Intelligence and Manufacturing Research Planning Workshop, </booktitle> <address> Albu-querque, NM. </address> <note> Also available from http://www.cirl.uoregon.edu/crawford/papers/papers.html, 1996. The AAAI Press. BIBLIOGRAPHY 487 </note>
Reference-contexts: They have used a multi-pass mechanism, called limited discrepancy search [ Harvey and Ginsberg, 1995 ] , followed by a post-processing optimization technique called a doubleback optimization <ref> [ Crawford, 1996 ] </ref> . The limited discrepancy search mechanism generates several different seed solutions that are then passed to the optimization mechanism. <p> The basic idea provided in <ref> [ Crawford, 1996 ] </ref> is to sort all the activities in the existing schedule by start/end-time, cancel all the reservations, and re-schedule them as early/late as possible. Our implementation uses this idea as an optimization, and as a repair mechanism as well. 6.4.2.2 Properties 1. <p> In the comparison tables, we designate his results as BELL. 4. James Crawford, Matthew Ginsberg, Ari Jonsson, and the CIRL Team from the Computational Intelligence Research Laboratory at the University of Oregon (jc@cs.uoregon.edu) using a combination of "Limited Discrepancy Search" [ Harvey and Ginsberg, 1995 ] and "Double-back Optimization" <ref> [ Crawford, 1996 ] </ref> . In the comparison tables, we designate their results as CIRL-DBO, when obtained with the doubleback optimization, and as CIRL-LDS when the results have been obtained with least discrepancy search followed by doubleback optimization.
Reference: [ Domain Engineering, 1997 ] <institution> Domain engineering home page. </institution> <address> http://www.sei.cmu.edu/technology/domain engineering/domain eng.html, </address> <year> 1997. </year>
Reference-contexts: The products (or software assets) of these activities are domain model (s), design model (s), domain-specific languages, code generators, and code components <ref> [ Domain Engineering, 1997 ] </ref> . Since our approach is based on ontologies and we advocate that an ontological model can be seen as representing the model of a domain, from our perspective, domain analysis is the most relevant activity.
Reference: [ Dorn et al., 1997 ] <author> J. Dorn, M. Girsch, and N. Vidakis. </author> <title> Deja Vu a reusable framework for the construction of intelligent interactive schedulers. </title> <type> Technical report, </type> <institution> Institut fur Informationssys-teme, Technische Universitat Wien, </institution> <note> available from http://www.dbai.tuwien.ac.at/proj/DejaVu/, Viena, </note> <institution> Austria, </institution> <year> 1997. </year>
Reference-contexts: An example of a system implemented using this approach is the Kestrel Transportation Scheduler [ Smith et al., 1996a ] . The second approach is the creation of a library of components for scheduling systems. ILOG's SCHEDULER and SOLVER [ Le Pape, 1994 ] and Deja Vu <ref> [ Dorn et al., 1997 ] </ref> are two examples of solutions using the library approach. SOLVER is described as a library of object classes, functions, and class structures available in Le-Lisp or C++ programming language [ Le Pape, 1994 ] . Deja Vu is a framework of C++ 2.3.
Reference: [ Fadel et al., 1994 ] <institution> F.G. Fadel, M.S. M.S. </institution> <note> Fox, </note> <author> and M. Gruninger. </author> <title> A generic enterprise resource ontology. </title> <booktitle> In Proc. of 3rd. IEEE Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, </booktitle> <address> West Virginia, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Generic level descriptions, or micro-theories, for several different areas of the enterprise have already been implemented: ontologies for describing organization structure [ Fox et al., 1996 ] , process and activities [ Gruninger and Fox, 1994, Gruninger and Pinto, 1995 ] , resources <ref> [ Fadel et al., 1994 ] </ref> , cost [ Tham et al., 1994 ] , and quality [ Kim and Fox, 1994 ] are currently available as part of the TOVE ontology. In enterprise modeling, the notion of time, activity, and resource plays a 124 CHAPTER 2. <p> This motivates the creation of a micro-theory of resources. Representing and answering questions about resource commitment and availability are the main objectives of this theory. According to Fadel et al. <ref> [ Fadel et al., 1994 ] </ref> , being a resource is not an innate property of an object, but it is a property derived from the role this object play in relation to an activity. Based on this activity-centered view, resource properties are determined by the activities using the resource. <p> Most typically, a resource is modeled as providing some amount of capacity, a numeric quantity which varies over time as a function of allocating the resource to various activities and its associated allocation semantics. This is the approach taken in <ref> [ Fadel et al., 1994, Uschold et al., 1996 ] </ref> . <p> We say that the activity consumes the resource. Though we could further distinguish a third class, renewable resources, to refer to resources that have their capacity increased by activities <ref> [ Fadel et al., 1994 ] </ref> , we instead consider production of resource capacity to be a separable issue. In our model, activities utilize resources to produce products. <p> SIMPLE-CAPACITY POOL: A homogeneous resource pool which is composed of n unit-capacity-resources and can thus simultaneously support n independent activities. This corresponds to the definition of capacitated resource given in <ref> [ Fadel et al., 1994 ] </ref> . ii. STRUCTURED-CAPACITY POOL: A homogeneous resource pool composed of n batch-capacity resources or n aggregate resources of capacity c, having total capacity n fl c.
Reference: [ Farquhar et al., 1995 ] <author> A. Farquhar, R. Fikes, W. Pratt, and J. Rice. </author> <title> Collaborative ontology construction for information integration. </title> <type> Technical Report KSL-95-63, </type> <institution> Kowledge Systems Laboratory, Stanford University, </institution> <address> Palo Alto, CA, </address> <year> 1995. </year>
Reference-contexts: Here it seems that they are strongly suggesting the use the Ontology Server at KSL <ref> [ Farquhar et al., 1995 ] </ref> . 6. Evaluation: This is the only method that proposes some more "concrete" means of evaluating an ontology. Evaluation here subsumes verification and validation.
Reference: [ Fensel and Benjamins, 1998 ] <author> D. </author> <title> Fensel and V.R. Benjamins. Key issues for automated problem-solving methods reuse. </title> <editor> In Henri Prade, editor, </editor> <booktitle> Proceedings of the 13th European Conference on Artificial Intelligence, </booktitle> <address> ECAI'98. </address> <publisher> John Wiley & Sons, Ltd., </publisher> <year> 1998. </year>
Reference-contexts: Adapters are discussed in more details in <ref> [ Fensel and Benjamins, 1998 ] </ref> where, similar to the approach taken in this thesis, a closer connection to the discipline of software architecture is established. <p> The operational description is not included in this representation. Adapters are described in <ref> [ Fensel and Benjamins, 1998 ] </ref> as means to enable the adaptation process of methods to task and domains. They manipulate the syntactical nature of the input and output of components. The use of adapters in a library of problem-solving methods prevents the combinatorial explosion of the method population.
Reference: [ Fensel and Straatman, 1996 ] <author> D. Fensel and R. Straatman. </author> <title> Problem-solving methods: Making assumptions for efficiency reasons. </title> <editor> In Nigel Shadbolt, Guus Schreiber, and Kieron O'Hara, editors, </editor> <booktitle> Advances in Knowledge Acquisition, Ninth European Knowledge Acquisition Workshop, volume 1076 of Lectures Notes in Artificial Intelligence, </booktitle> <pages> pages 17-32, </pages> <address> United Kingdom, </address> <month> May </month> <year> 1996. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: Finally, the relation between problem-solving methods and domain knowledge is defined by the applicability conditions or assumptions. The assumptions represents requirements that reflect the features of the problem-solving method. According to Fensel & Straatman <ref> [ Fensel and Straatman, 1996 ] </ref> , assumptions are the way through which problem-solving methods achieve efficient realizations of their functionalities. The assumptions put restrictions on the context of the method and these restrictions allow methods to be performed in an efficient manner. <p> This task specification is refined into a functional specification by making assumptions about the problem-solving paradigm and available domain model. Further assumptions are introduced in the process of defining an operational specification of the method <ref> [ Fensel and Straatman, 1996 ] </ref> . Although these applicability conditions have received several different names in the knowledge engineering literature, Benjamins & Pierret-Golbreich notice that currently there is neither a principled organization nor a well defined language to express assumptions. <p> Based on this horizontal organization of assumptions, application knowledge can be divided into domain knowledge, external knowledge, and task knowledge. The assumptions can be viewed as proof obligations for the domain knowledge <ref> [ Fensel and Straatman, 1996 ] </ref> . In a formal verification system, one would have to prove that the domain knowledge satisfies the epistemological assumptions, the external knowledge satisfies the pragmatic assumptions, and the task knowledge satisfies the teleological assumptions. <p> Here, in agreement with Chandrasekaran comment that there is no such a thing as a task-independent method [ Chandrasekaran and Josephson, 1997 ] , we assume a task-independent method to be a method defined for a very general class of problems. In <ref> [ Fensel and Straatman, 1996 ] </ref> and [ Fensel et al., 1997 ] , a method-independent task ontology for parametric design and a task-independent method-ontology for propose & revise is formally specified using a logic description language called sloppy-logic. [ Fensel et al., 1997 ] discusses how to connect the task-independent <p> The concept of task and its structure is not formally defined; only the problem specific terminology is defined. For example, the ontology for parametric design task presented in <ref> [ Fensel and Straatman, 1996 ] </ref> uses the following top-level concepts to describe the task: problem-space, requirements and constraints, possible designs, required designs, valid design, solution, preference, and optimal solution. The formalization of the description in sloppy-logic is presented in [ Fensel et al., 1997 ] . <p> A problem-solving method is defined as a description of the reasoning steps and the types of knowledge needed to perform a task: a problem solving method translates a declarative goal description into a set of assumptions about domain knowledge required to achieve the goal <ref> [ Fensel and Straatman, 1996 ] </ref> . This description is composed of four main parts: Functional Description: describes the problem-solving behavior of the method in terms of relations between the input and output. Cost Description: describes performance related metrics associated to the implementation of the method. 162 CHAPTER 2. <p> Different instances of each one of these knowledge sources are currently available in the library. All the knowledge sources have a standard interface through which they interact with the Control Manager. Following mainly the ideas presented by Fensel et al. in <ref> [ Fensel and Straatman, 1996 ] </ref> and [ Fensel et al., 1997 ] , a knowledge source can be described in terms of its pre-conditions or assumptions, its required input, its competence, its functional and operational descriptions, and its output. <p> In the task & method ontologies presented in Chapter 2 the term method has been used as a synonym for problem-solving method. Here a distinction is established: the problem-solving method, as defined by Fensel & Straatman <ref> [ Fensel and Straatman, 1996 ] </ref> , is a description of the reasoning steps, and the types of knowledge required to solve a task; the method is the implementation of these reasoning steps. <p> Fensel and Straatman define a problem-solving method as a description of the reasoning steps and the types of knowledge needed to perform a task <ref> [ Fensel and Straatman, 1996 ] </ref> . In this definition, the concept of task is defined as a description of "what" has to be achieved by the problem-solver. The problem-solving method, therefore, describes "how" to achieve the goal represented by the task .
Reference: [ Fensel et al., 1997 ] <author> D. Fensel, E. Motta, and Zdrahal. </author> <title> Using ontologies for defining tasks, problem-solving methods, and their mappings. </title> <editor> In Enric Plaza and Richard Benjamins, editors, </editor> <title> Knowledge Acquisition, </title> <booktitle> Modeling and Management, Tenth European Knowledge Acquisition Workshop, volume 1319 of Lectures Notes in Artificial Intelligence, </booktitle> <address> Spain, </address> <month> October </month> <year> 1997. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: More recent efforts on defining method and task ontologies, like [ Coelho and Lapalme, 1996 ] , [ Chandrasekaran and Josephson, 2.2. ONTOLOGIES 119 1997 ] , [ Studer et al., 1996 ] , [ Gennari et al., 1998 ] , <ref> [ Fensel et al., 1997 ] </ref> emphasize the separation between what constitutes a task and what constitutes the problem solving method, and how to relate problem-solving and domain knowledge using the ontology definitions. <p> Recent examples of ontologies that pursue these ideas are Studer et al.'s ontologies for configuring problem-solving methods [ Studer et al., 1996 ] , Fensel et al.'s task ontology for parametric design <ref> [ Fensel et al., 1997 ] </ref> , Chandrasekaran's ontology of tasks and methods [ Chandrasekaran and Josephson, 1997 ] , Gennari et al's method description language [ Gennari et al., 1998 ] , and Coelho & Lapalme's method ontology [ Coelho and Lapalme, 1996 ] . <p> Here, in agreement with Chandrasekaran comment that there is no such a thing as a task-independent method [ Chandrasekaran and Josephson, 1997 ] , we assume a task-independent method to be a method defined for a very general class of problems. In [ Fensel and Straatman, 1996 ] and <ref> [ Fensel et al., 1997 ] </ref> , a method-independent task ontology for parametric design and a task-independent method-ontology for propose & revise is formally specified using a logic description language called sloppy-logic. [ Fensel et al., 1997 ] discusses how to connect the task-independent version of propose & revise to the <p> In [ Fensel and Straatman, 1996 ] and <ref> [ Fensel et al., 1997 ] </ref> , a method-independent task ontology for parametric design and a task-independent method-ontology for propose & revise is formally specified using a logic description language called sloppy-logic. [ Fensel et al., 1997 ] discusses how to connect the task-independent version of propose & revise to the task of parametric design through the use of adapters. <p> The formalization of the description in sloppy-logic is presented in <ref> [ Fensel et al., 1997 ] </ref> . <p> The control is described in terms of the order of inference execution. Assumptions: are the necessary and sufficient criteria for applying the method as have previously been discussed in this section. A different structure for describing a problem-solving method is used in <ref> [ Fensel et al., 1997 ] </ref> . The formalization using sloppy-logic presented in [ Fensel et al., 1997 ] divides a method in three parts: a terminology section that declares all the terms used in the other two parts; a competence that seems to include the cost and functional description; and <p> Assumptions: are the necessary and sufficient criteria for applying the method as have previously been discussed in this section. A different structure for describing a problem-solving method is used in <ref> [ Fensel et al., 1997 ] </ref> . The formalization using sloppy-logic presented in [ Fensel et al., 1997 ] divides a method in three parts: a terminology section that declares all the terms used in the other two parts; a competence that seems to include the cost and functional description; and a knowledge requirements section that represents the assumptions of the problem-solving method. <p> Different instances of each one of these knowledge sources are currently available in the library. All the knowledge sources have a standard interface through which they interact with the Control Manager. Following mainly the ideas presented by Fensel et al. in [ Fensel and Straatman, 1996 ] and <ref> [ Fensel et al., 1997 ] </ref> , a knowledge source can be described in terms of its pre-conditions or assumptions, its required input, its competence, its functional and operational descriptions, and its output. <p> Competence: competence is defined by Gennari et al. [ Gennari et al., 1998 ] as a list of constraints relating the output of the method to its input. Fensel et al. <ref> [ Fensel et al., 1997 ] </ref> refer to this property as the functional description of the method. More generally, the competence of a knowledge source describes the type of changes, or effects, caused in the state of the system by the execution of the method.
Reference: [ Ferguson et al., 1996 ] <author> G. Ferguson, J. Allen, and B. Miller. TRAINS-95: </author> <title> Towards a mixed-initiative planning assistant. </title> <editor> In Brian Drabble, editor, </editor> <booktitle> Proceedings of the Third International Conference on Artificial Intelligence Planning Systems, </booktitle> <pages> pages 70-77, </pages> <address> Edinburgh, Scotland, </address> <month> May </month> <year> 1996. </year> <note> 488 BIBLIOGRAPHY </note>
Reference: [ Fernandez et al., 1997 ] <author> M. Fernandez, A. Gomez-Perez, and N. Juristo. METHONTOLOGY: </author> <title> From ontological art towards ontological engineering. </title> <booktitle> In Proceedings AAAI Spring Symposium on Ontological Engineering, </booktitle> <address> Palo Alto, CA., </address> <month> March </month> <year> 1997. </year>
Reference-contexts: In this section we examine three of these proposals: Gruber's criteria for ontology design [ Gruber, 1993 ] , Uschold's proposal for creating a unified methodology [ Uschold, 1995, Uschold, 1996 ] , and METHONTOLOGY, a method proposed by Fernandez, Gomes-Perez, and Juristo <ref> [ Gomez-Perez et al., 1996, Fernandez et al., 1997 ] </ref> . A common characteristic of these guidelines is the similarity they have to the software engineering methods for analysis and design. Gruber [ Gruber, 1993 ] proposes five design criteria for creating ontologies for knowledge sharing. <p> Document Ontology: No specific guidelines for documenting an ontology is provided. The need of documenting all important assumptions about both main and primitive concepts is identified but no format or content is proposed. METHONTOLOGY <ref> [ Fernandez et al., 1997 ] </ref> is a better structured method that precisely defines a life-cycle for ontology design and implementation. This method not only provides general guidelines for each phase but also propose formats for the output of each of these phases. An 2.2.
Reference: [ Fikes et al., 1981 ] <author> R. Fikes, P. Hart, and N Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <editor> In Nilsson and Webber, editors, </editor> <booktitle> Readings in Artificial Inteligence, </booktitle> <pages> pages 231-249. </pages> <publisher> Tioga Publishing, </publisher> <address> Palo Alto, CA, </address> <year> 1981. </year>
Reference-contexts: According to Wilkins, the frame problem is what makes reasoning about actions inherently hard, and what distinguishes reasoning about actions from similar problems that do not require this problem to be addressed [ Wilkins, 1988 ] . Certain planners systems like STRIPS <ref> [ Fikes et al., 1981 ] </ref> , deal with this problem by using the simplifying assumption that the only changes 12 CHAPTER 1. INTRODUCTION in the world are the ones explicitly represented by the operator's post-condition or effects.
Reference: [ Fox and Gruninger, 1994 ] <author> M.S. Fox and M. Gruninger. </author> <title> Ontologies for enterprise integration. </title> <booktitle> In Proceedings of the 2nd Conference on Cooperative Information Systems, </booktitle> <address> Ontario, Canada, </address> <year> 1994. </year>
Reference-contexts: Duration for the remaining status values can also be defined. All activities require that some objects, resources, be available during the time the activity is executed <ref> [ Fox and Gruninger, 1994 ] </ref> . Furthermore, the status of a state or the status of an activity depends on the the status of the resource required by the activity. This motivates the creation of a micro-theory of resources.
Reference: [ Fox and Gruninger, 1997 ] <author> M.S. Fox and M. Gruninger. </author> <title> On ontologies and enterprise modelling. </title> <booktitle> In International Conference on Enterprise Integration Modelling Technology 97, </booktitle> <year> 1997. </year>
Reference-contexts: The efficiency of the ontology can then be measured in terms of the efficiency of the inference mechanism. Other evaluation criteria, besides competency and efficiency, proposed in <ref> [ Fox et al., 1993, Fox and Gruninger, 1997 ] </ref> are: functional completeness, generality, perspicuity, transformability, precision/granularity, minimality and scalability. No concrete means of evaluating these other criteria is provided. 2.2. ONTOLOGIES 127 The TOVE ontology is one of the few representations concerned with generating an operational model.
Reference: [ Fox and Ringer, 1995 ] <author> B. Fox and M. Ringer. </author> <title> Resource constrained project scheduling: Planning and scheduling benchmark. </title> <note> Available from http://www.neosoft.com/ ~ benchmrk, </note> <month> July </month> <year> 1995. </year>
Reference-contexts: Chapter 6 An Application for Pro ject Scheduling This chapter describes one application for Resource Constrained Project Scheduling developed using the ozone modeling framework. This application has been implemented to solve a set of twelve planning and scheduling problems created by Barry Fox and Mark Ringer <ref> [ Fox and Ringer, 1995 ] </ref> . to serve as a benchmark for scheduling systems. The problems and associated data set are based on a large scale assembly problem that can be generally described as resource constrained project scheduling. <p> This series of problems is based upon some of the most common problems faced by production managers. Some of the questions the solution to this set of problems should address are <ref> [ Fox and Ringer, 1995 ] </ref> : 1. How long it will take to finish this work if there are no resource constraints ? (Problem 1) 2. How long it will take to finish the work if some resource constraints are relaxed ? (Problem 2) 3. <p> The data set for the the resource constrained project scheduling problems used to implement the application presented in this chapter are available at http://www.neosoft.com/~benchmrk and the problems are described in <ref> [ Fox and Ringer, 1995 ] </ref> , also available in this web site. The physical problem represented by the data set is the process of creating a large assembly consisting of a large number of discrete PRODUCTION STEPS. <p> Precedence constraints between activities define the temporal network presented in figure 6.1. In the figure, the nodes represent the activities, and the arcs 434 CHAPTER 6. AN APPLICATION FOR PROJECT SCHEDULING represent the precedence constraints. The description of each one of the twelve problems, as described in <ref> [ Fox and Ringer, 1995 ] </ref> is: * Problem 1: Precedence Scheduling: Ignore all labor and zone constraints, but respect all precedence constraints and determine the minimum cycle time for the completion of this assembly.
Reference: [ Fox and Smith, 1984 ] <author> M.S. Fox and S.F. Smith. </author> <title> Isis: A knowledge-based system for factory scheduling. </title> <journal> Expert Systems, </journal> <volume> 1(1) </volume> <pages> 25-49, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: The knowledge representation technique used is frame-based and provides a hierarchical description of the application domain. OPIS uses this domain knowledge to guide the search through the space of possible solutions. 2.3.2.3 Representation of Constraints OPIS, based on the earlier ISIS scheduling system <ref> [ Fox and Smith, 1984 ] </ref> , emphasizes the complete representation of all constraints that impact the decision making process. This representation, however, is not explicit but embedded in the description of activities and resources. The frame-based knowledge representation techniques used allow production plans and resources to be represented hierarchically.
Reference: [ Fox et al., 1993 ] <editor> M.S. Fox, J. Chionglo, and F.G. Fadel. </editor> <title> A common-sense model of the enterprise. </title> <booktitle> In Proc. of the Second Industrial Engineering Research Conference, </booktitle> <address> Norcross, GA, </address> <year> 1993. </year>
Reference-contexts: WorldModelSpecification 2.2. ONTOLOGIES 123 8. Plan 9. Process 10. Objective 11. Issue 12. EvaluationCriteria 13. ActivitySpecification 2.2.3.1.4 TOVE Enterprise Ontology The ontology developed by the Toronto Virtual Enterprise project is a comprehensive and very formal ontology implemented to facilitate enterprise modeling and integration. The goal of the TOVE project <ref> [ Fox et al., 1993 ] </ref> is to create a data model that: (1) provides a shared terminology that each and all agents in the enterprise can use and understand; (2) defines the meaning of each term in this terminology as precise and unambiguous as possible; (3) and expresses this "enterprise <p> The efficiency of the ontology can then be measured in terms of the efficiency of the inference mechanism. Other evaluation criteria, besides competency and efficiency, proposed in <ref> [ Fox et al., 1993, Fox and Gruninger, 1997 ] </ref> are: functional completeness, generality, perspicuity, transformability, precision/granularity, minimality and scalability. No concrete means of evaluating these other criteria is provided. 2.2. ONTOLOGIES 127 The TOVE ontology is one of the few representations concerned with generating an operational model.
Reference: [ Fox et al., 1996 ] <author> M.S. Fox, M. Barbuceanu, and M. Gruninger. </author> <title> An organisation ontology for enterprise modelling: Preliminary concepts for linking structure and behaviour. </title> <booktitle> Computers in Industry,, </booktitle> <volume> 29 </volume> <pages> 123-134, </pages> <year> 1996. </year>
Reference-contexts: The ontology is implemented in a logic-based formalism that can be used as input to a Prolog like theorem-prover. Generic level descriptions, or micro-theories, for several different areas of the enterprise have already been implemented: ontologies for describing organization structure <ref> [ Fox et al., 1996 ] </ref> , process and activities [ Gruninger and Fox, 1994, Gruninger and Pinto, 1995 ] , resources [ Fadel et al., 1994 ] , cost [ Tham et al., 1994 ] , and quality [ Kim and Fox, 1994 ] are currently available as part of <p> Like in AI planning, an enterprise analyst would like to determine what are the set of possible future states given the current situation and the set of possible course of actions. To add this temporal projection <ref> [ Fox et al., 1996 ] </ref> capability to the ontology representation, a theory of complex actions based on an extended situation calculus [ Gruninger and Pinto, 1995 ] is developed to provide the formal foundation for the ontology construction. The situation calculus is a second order logical language with equality.
Reference: [ Fox, 1992 ] <author> M.S. Fox. </author> <title> The TOVE project: Towards a common-sense model of the enterprise. </title> <booktitle> In Proceedings of the International Conference on Object Oriented Manufacturing Systems, </booktitle> <address> Calgary, Canada, </address> <year> 1992. </year>
Reference-contexts: To accomplish the first goal, the TOVE group has been looking into reference models for enterprise modeling. The approach to achieve the second goal is to define generic level representations in terms of which the representation for different applications are defined. These generic level representations are implemented as micro-theories <ref> [ Fox, 1992 ] </ref> : a locally consistent syntax and semantics for the representation of some portion of the required knowledge.
Reference: [ Frakes and Isoda, 1994 ] <author> W.B. Frakes and S. Isoda. </author> <title> Success factors of systematic reuse. </title> <journal> IEEE Software, </journal> <pages> pages 14-19, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: A key concept on systematic reuse is the domain, which may be defined as an application area or as a set of systems that share a certain set of design decisions. Systematic software reuse <ref> [ Frakes and Isoda, 1994 ] </ref> . 2.1.1 Approaches to Software Reuse Since 1968, several different approaches to software reuse have been attempted. <p> More generally, design for systematic reuse requires domain engineering. Domain engineering is composed of two phases: domain analysis and domain implementation. The domain implementation is the use of the information provided by domain analysis to create reusable artifacts and new systems <ref> [ Frakes and Isoda, 1994 ] </ref> . 3. The higher the abstraction level of the component, the higher the reuse benefit.
Reference: [ Gamma et al., 1994 ] <author> E. Gamma, R. Helm, R. Johnsosn, and J. Vlissides. </author> <title> Design Patterns: Elements of Reusable Object-Oriented Design. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year> <note> BIBLIOGRAPHY 489 </note>
Reference-contexts: More recent approaches have concentrated on reusing larger pieces of code inside a coherent structure or architecture. Software architecture [ Garlan and Shaw, 1994 ] , domain specific software architectures [ Tracz, 1994 ] , software patterns <ref> [ Gamma et al., 1994 ] </ref> , and object-oriented frameworks [ Johnson, 1997 ] are examples of recent software reuse efforts that relates to this architectural reconfigurability here advocated. <p> An idiom describes how to implement the components of a pattern. They are closely related to a particular programming language. The description of a pattern, to be useful as a reusable asset, should go beyond a single description or a graphical representation. According to Gamma et al. <ref> [ Gamma et al., 1994 ] </ref> , to reuse 2.1. SOFTWARE REUSE 69 design, one must also record the decisions, alternatives, and trade-offs that led to it. Concrete examples of its use are also important.
Reference: [ Garey and Johnson, 1979 ] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman & Co., </publisher> <year> 1979. </year>
Reference-contexts: Operations Research problem solving is characterized by its focus on the use of mathematical 1.1. PROBLEM DESCRIPTION 15 formulations and optimization techniques. As has already been discussed, the characteristics of the planning and scheduling problems make them not suitable for pure optimization methods. Most problems are NP-hard <ref> [ Chapman, 1987, Garey and Johnson, 1979 ] </ref> . Optimal solutions are only attainable for simplified or idealized models [ Simon, 1981a ] .
Reference: [ Garlan and Shaw, 1994 ] <author> D. Garlan and M. Shaw. </author> <title> An introduction to software architecture. </title> <type> Technical Report CMU-CS-94-166, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA., </address> <month> January </month> <year> 1994. </year>
Reference-contexts: Early attempts of achieving large scale software reusability by using a building blocks approach have not been very successful. More recent approaches have concentrated on reusing larger pieces of code inside a coherent structure or architecture. Software architecture <ref> [ Garlan and Shaw, 1994 ] </ref> , domain specific software architectures [ Tracz, 1994 ] , software patterns [ Gamma et al., 1994 ] , and object-oriented frameworks [ Johnson, 1997 ] are examples of recent software reuse efforts that relates to this architectural reconfigurability here advocated. <p> The goal, from a software engineering perspective, of a reconfigurable architecture is to achieve a high level of software reusability. This chapter reviews some software reuse efforts emphasizing the more recent trend of the field towards using, and re-using, higher level descriptions and representations of system structure or architecture <ref> [ Garlan and Shaw, 1994 ] </ref> . A similar trend can also be identified in the Artificial Intelligence community. The use of ontologies as a modeling tool is motivated by the perceived need of sharing knowledge across several different applications. <p> The tradeoff here is between the effort required to generate these large components and the gains obtained in the creation of new applications. 2.1.2 Software Architecture According to Garlan and Shaw <ref> [ Garlan and Shaw, 1994, Shaw and Garlan, 1994 ] </ref> , as the size and complexity of software systems increase, the design and specification of overall system structure 2.1. SOFTWARE REUSE 51 become a more significant issue than the choice of algorithms and data structure. <p> The software architecture discipline deals with what is called architectural styles and how these styles affect system properties [ Shaw, 1995 ] . The conceptual foundations of software architecture as a major discipline in the field of software engineering was established by Shaw and Garlan <ref> [ Shaw, 1989, Garlan and Shaw, 1994 ] </ref> , and Perry and Wolf [ Perry and Wolf, 1992 ] . <p> A number of ADLs have been proposed for modeling architectures both within a specific application domain or as general purpose modeling languages. Most ADLs are based on the conceptual model proposed by Garlan and Shaw <ref> [ Garlan and Shaw, 1994 ] </ref> . This model is based on two main abstractions: components and connectors. According to this model, architectural styles are defined as sets of component and connector types, plus a set of rules on how these elements can be combined to generate an architectural configuration.
Reference: [ Garlan et al., 1995 ] <author> D. Garlan, R. Allen, and J. Ockerbloom. </author> <title> Architectural mismatch: Why reuse is so hard. </title> <journal> IEEE Software, </journal> <pages> pages 17-26, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: Second, individual patterns in a language or system are not isolated pieces. Each pattern depends on the smaller patterns it contains, on the patterns it interacts with, and on the larger patterns it is contained within. In other words, a pattern language accounts for the architectural mismatches <ref> [ Garlan et al., 1995 ] </ref> caused by the use of independently developed components. Based on these two characteristics, Buschman and Meunier [ Bushmann et al., 1996 ] propose a classification schema for patterns based on three different dimensions: granularity, functionality, and structural principles.
Reference: [ Garlan et al., 1997 ] <author> D. Garlan, R.T. Monroe, and D. Wile. ACME: </author> <title> An architecture description interchange language. </title> <note> Submitted to publication, </note> <month> January </month> <year> 1997. </year>
Reference-contexts: Most of the software architecture ontology presented in the current work has been based on the concepts provided by UniCon. 62 CHAPTER 2. LITERATURE REVIEW (e) ACME: This language has been developed as a joint effort of several research groups to serve as a common interchange language. ACME <ref> [ Garlan et al., 1997 ] </ref> is based on the premise that there is sufficient commonality in the requirements and capabilities of different Architectural Description Languages such that there is a subset of language independent information that can be shared across different descriptions. <p> In this sense, the role of ACME to the software architecture community is similar to the role of ON-TOLINGUA to the ontology community. The goals that motivated the design of ACME, presented in <ref> [ Garlan et al., 1997 ] </ref> and summarized here, can be generalized to the ontology building effort described in this thesis: i. To provide an interchange format for system development ii. To provide a scheme that would allow analysis and visualization of system structure. iii. <p> Figure 3.2 is a schematic view of how the main components in ozone software architecture ontology relate to each other. 3.3. THE OZONE SOFTWARE ARCHITECTURE ONTOLOGY 233 3.3.1 COMPONENT 3.3.1.1 Concept Definition Architectural Description Languages like ACME <ref> [ Garlan et al., 1997 ] </ref> , UniCon [ Shaw et al., 1995 ] , and Wright [ Allen, 1997 ] define a component to be the primary computational element and data store of the system that provides a localized, independent functional capability to the system.
Reference: [ Garlan, 1995 ] <author> D. Garlan. </author> <booktitle> What is style ? Proceedings of the Dagshtul Workshop on Software Architecture, </booktitle> <month> February </month> <year> 1995. </year>
Reference-contexts: Although the concept of architectural style is not explicitly defined, it can be seen as a set of recurring organizational patterns that characterize a family of similar applications <ref> [ Garlan, 1995 ] </ref> . An architectural style provides a specialized design language for a specific class of systems [ Monroe 52 CHAPTER 2. LITERATURE REVIEW et al., 1997 ] . Garlan [ Garlan, 1995 ] and Monroe et al. [ Monroe et al., 1997 ] list some practical benefits of <p> it can be seen as a set of recurring organizational patterns that characterize a family of similar applications <ref> [ Garlan, 1995 ] </ref> . An architectural style provides a specialized design language for a specific class of systems [ Monroe 52 CHAPTER 2. LITERATURE REVIEW et al., 1997 ] . Garlan [ Garlan, 1995 ] and Monroe et al. [ Monroe et al., 1997 ] list some practical benefits of using architectural styles: (1) it promotes design reuse; (2) it can lead to code reuse; (3) it makes it easier to understand the system's organization; (4) it supports interoperability; (5) by constraining <p> From the perspective of the current thesis, the fourth and fifth reasons are of secondary relevance. The first three practical benefits are the main reasons for our interest in architectural styles and descriptions. Besides, styles provide a vocabulary of design elements, and design rules, or topological constraints <ref> [ Garlan, 1995 ] </ref> , that determine which compositions of those elements are permitted [ Monroe et al., 1997 ] . Using our terminology, software architecture provides the ontology for describing system components and configurations.
Reference: [ Genesereth and Fikes, 1991 ] <author> M.R. . Genesereth and R.E. Fikes. </author> <title> Knowledge Interchange Format, version 3.0 reference manual. </title> <type> Technical Report LOGIC-92-1, </type> <institution> Computer Science Department, Stanford University, </institution> <address> Palo Alto, CA, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: He 112 CHAPTER 2. LITERATURE REVIEW proposes a single-source/multiple-translation approach in which ontologies are maintained in a simple format that is compatible with multiple representations. Ontologies written in this format are then translated into the different executable representations used by different problem-solving agents. The Knowledge Interchange Format (KIF) <ref> [ Genesereth and Fikes, 1991 ] </ref> , On-tolingua [ Gruber, 1992 ] , and the Conceptual Modeling Language (CML) [ Wielinga et al., 1992, Schreiber et al., 1994 ] are examples of formalisms that implement this approach. <p> As in previous sections, the emphasis here is in identifying the terminology used. 2.2.2.1 Knowledge Interchange Format The Knowledge Interchange Format is defined as a formal language for the interchange of knowledge among disparate computer programs written by different programmers, at different times, in different languages <ref> [ Genesereth and Fikes, 1991 ] </ref> . It is intended to be neither a language for human interaction nor an internal representation for knowledge within a computer programs. When a program reads a knowledge-base written in KIF, it translates the data into its own internal representation.
Reference: [ Gennari et al., 1998 ] <author> J.H. Gennari, W. Grosso, and M. Musen. </author> <title> A method-description language: An initial ontology with examples. </title> <booktitle> In Proceedings of Eleventhth Knowledge Acquisition for Knowledge-Based Systems Workshop, </booktitle> <address> Banff, Alberta, Canada, </address> <year> 1998. </year> <note> Available from http://ksi.cpsc.ucalgary.ca/KAW/KAW98/KAW98Proc.html. </note>
Reference-contexts: More recent efforts on defining method and task ontologies, like [ Coelho and Lapalme, 1996 ] , [ Chandrasekaran and Josephson, 2.2. ONTOLOGIES 119 1997 ] , [ Studer et al., 1996 ] , <ref> [ Gennari et al., 1998 ] </ref> , [ Fensel et al., 1997 ] emphasize the separation between what constitutes a task and what constitutes the problem solving method, and how to relate problem-solving and domain knowledge using the ontology definitions. <p> are Studer et al.'s ontologies for configuring problem-solving methods [ Studer et al., 1996 ] , Fensel et al.'s task ontology for parametric design [ Fensel et al., 1997 ] , Chandrasekaran's ontology of tasks and methods [ Chandrasekaran and Josephson, 1997 ] , Gennari et al's method description language <ref> [ Gennari et al., 1998 ] </ref> , and Coelho & Lapalme's method ontology [ Coelho and Lapalme, 1996 ] . <p> According to Puppe, least commitment, and case-based construction can also be used but have limited applicability. Propose-and-revise is not considered but in a mixed-initiative problem-solving environment, this method is also applicable. 2.2.3.2.2 Task and Method Ontologies Gennari et al's Method Description Language The Method Description Language <ref> [ Gennari et al., 1998 ] </ref> focuses on supporting the task of mapping problem-solving methods, selected from a library of reusable methods, to specific application domains. <p> The problem-solving method, therefore, describes "how" to achieve the goal represented by the task . Similar definitions are provided by Chandrasekaran [ Chandrasekaran and Johnson, 1993 ] , Gennari et al. <ref> [ Gennari et al., 1998 ] </ref> , and Benjamins [ Benjamins, 1994 ] . A knowledge source is an implemented instance of a problem solving method, specifically tailored for the representation used to describe the domain 292 CHAPTER 3. <p> Any event generated during scheduling method activity are side effects of the decisions made, and not direct consequence of the action. 3. Competence: competence is defined by Gennari et al. <ref> [ Gennari et al., 1998 ] </ref> as a list of constraints relating the output of the method to its input. Fensel et al. [ Fensel et al., 1997 ] refer to this property as the functional description of the method.
Reference: [ Gibbs, 1994 ] <author> W.W. Gibbs. </author> <title> Software's chronic crisis. </title> <publisher> Scientific American, </publisher> <pages> pages 86-95, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The average software development project overshoots its schedule by half; larger projects generally do worse. And some three quarters of all large systems 1 2 CHAPTER 1. INTRODUCTION are operating failures that either do not function as intended or are not used at all" <ref> [ Gibbs, 1994 ] </ref> . The essence of this so called software crisis is related to the limitations of the human mind to deal with complexity: "When a system becomes so complex that no manager can comprehend its entirety, traditional development process breakdown." [ Gibbs, 1994 ] . <p> intended or are not used at all" <ref> [ Gibbs, 1994 ] </ref> . The essence of this so called software crisis is related to the limitations of the human mind to deal with complexity: "When a system becomes so complex that no manager can comprehend its entirety, traditional development process breakdown." [ Gibbs, 1994 ] . Associated to this limitation is the apparent inadequacy of currently available tools. Software development is a problem solving activity, and software engineering techniques and tools are used to assist humans in this activity.
Reference: [ Gilb, 1996 ] <author> T. Gilb. </author> <title> Level 6: Why can't get there from here. </title> <journal> IEEE Software, </journal> <pages> pages 97-98, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: By extending this adaptability and interactivity uniformly to all levels of the problem solving process, better solutions are likely to be generated. Despite the benefits promised by traditional software development techniques and software reuse efforts, the software development activity has not yet achieved the status of an engineering activity <ref> [ Gilb, 1996 ] </ref> . Studies have shown that "for every six new large-scale systems that are put into operation, two others are canceled. The average software development project overshoots its schedule by half; larger projects generally do worse.
Reference: [ Gomes et al., 1996 ] <author> C. Gomes, D. Smith, and S. Westfold. </author> <title> Synthesis of schedulers for planned shutdowns of power plants. </title> <booktitle> In The Eleventh Knowledge-Based Software Engineering Conference, </booktitle> <pages> pages 12-20, </pages> <address> Syracuse, NY, September 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Variations of the approaches discussed above are still the current sate of the practice in more recent systems like Amphion [ Lowry et al., 1994 ] and KIDS <ref> [ Smith, 1990, Gomes et al., 1996 ] </ref> . * Programming by Examples: An alternative representation for program specification is the use of examples of program behavior.
Reference: [ Gomez-Perez et al., 1996 ] <author> A. Gomez-Perez, M. Fernandez, and A.J. Vicente. </author> <title> Towards a method to conceptualize domain ontologies. </title> <booktitle> In Proceedings of the 12th European Conference on Artificial Intelligence, </booktitle> <pages> pages 41-51, </pages> <institution> Budapest University of Economic Sciences, Hungary, </institution> <month> August </month> <year> 1996. </year> <note> 490 BIBLIOGRAPHY </note>
Reference-contexts: Methods for developing ontologies have recently been proposed [ Gruber, 1993, Uschold, 1996 ] . A particularly interesting one, based on a structured approach that a series of intermediate representation, is presented by Gomes-Perez in <ref> [ Gomez-Perez et al., 1996 ] </ref> . Other methods for ontology development are discussed in chapter 2. In the development of the ozone ontology, we did not applied any particular methodology. <p> Consistent with this modeling view, knowledge acquisition should capture the inherent structure of the domain to support a wide range of different tasks. Ontologies are examples of models that capture such structure. Research on ontologies has focused on methodologies and guidelines for ontology design <ref> [ Uschold, 1996, Gomez-Perez et al., 1996 ] </ref> , languages and formalisms for ontology representation [ Gruber, 1992 ] , , and domain specific examples [ Fadel et al., 1994, Gruninger and Fox, 1994, Tate, 1996b, Uschold et al., 1996, Chandrasekaran and Josephson, 1997, Smith and Becker, 1997b ] . 41 <p> In this section we examine three of these proposals: Gruber's criteria for ontology design [ Gruber, 1993 ] , Uschold's proposal for creating a unified methodology [ Uschold, 1995, Uschold, 1996 ] , and METHONTOLOGY, a method proposed by Fernandez, Gomes-Perez, and Juristo <ref> [ Gomez-Perez et al., 1996, Fernandez et al., 1997 ] </ref> . A common characteristic of these guidelines is the similarity they have to the software engineering methods for analysis and design. Gruber [ Gruber, 1993 ] proposes five design criteria for creating ontologies for knowledge sharing. <p> This method not only provides general guidelines for each phase but also propose formats for the output of each of these phases. An 2.2. ONTOLOGIES 109 implemented tool that partially supports this method is described in <ref> [ Gomez-Perez et al., 1996 ] </ref> . The construction process is divided into seven phases: 1. Specification: This phase produces a specification document of the ontology written in natural language or some other intermediate representation. <p> Specification: This phase produces a specification document of the ontology written in natural language or some other intermediate representation. The purpose, level of formality, and scope of the ontology should also be identified and documented. It is suggested to group concepts using classification trees <ref> [ Gomez-Perez et al., 1996 ] </ref> . The specification tree should be consistent, concise, and provide a partial cover of the domain. 2. Knowledge Acquisition: This is an independent activity in the ontology generation process that can occur in all phases.
Reference: [ Gruber and G.R., 1994 ] <author> T.R. Gruber and Olsen G.R. </author> <title> An ontology for engineering mathematics. </title> <type> Technical Report KSL-94-18, </type> <institution> Knowledge Systems Laboratory, Stanford University, </institution> <address> Palo Alto, CA., </address> <year> 1994. </year>
Reference-contexts: Almost every ontology written in Ontolingua includes this theory. For practical purposes, the Frame Ontology can be considered as being part of the Ontolingua representation language. Other theories describing for example basic mathematical concepts, time, and physical measurement <ref> [ Gruber and G.R., 1994 ] </ref> are also available. 2.2.2.3 Conceptual Modeling Language As described in [ Schreiber et al., 1994 ] , the Conceptual Modeling Language is a highly structured, semi-formal notation. It was developed for the specification of CommonKADS [ Wielinga et al., 1992 ] expertise models.
Reference: [ Gruber, 1992 ] <author> T.R. Gruber. Ontolingua: </author> <title> A mechanism to support portable ontologies. </title> <type> Technical Report KSL-91-66, </type> <institution> Knowledge Systems Laboratory, Stanford University, </institution> <address> Palo Alto, CA., </address> <month> March </month> <year> 1992. </year>
Reference-contexts: The next step in the process was to define a structure for the ontology and to describe the concepts using a semi-formal representation. The initial intention was to generate a more formal description of the ontology using some knowledge representation language like Ontolingua <ref> [ Gruber, 1992 ] </ref> or Loom [ MacGregor, 1991 ] . However, after some initial evaluation, we concluded that 1.2. THESIS DESCRIPTION 33 the effort involved in generating this formal representation was not justified. This decision was motivated by the lack of an operational model supporting these languages. <p> Ontologies are examples of models that capture such structure. Research on ontologies has focused on methodologies and guidelines for ontology design [ Uschold, 1996, Gomez-Perez et al., 1996 ] , languages and formalisms for ontology representation <ref> [ Gruber, 1992 ] </ref> , , and domain specific examples [ Fadel et al., 1994, Gruninger and Fox, 1994, Tate, 1996b, Uschold et al., 1996, Chandrasekaran and Josephson, 1997, Smith and Becker, 1997b ] . 41 42 CHAPTER 2. <p> Given this large number of formalisms, implementing a translator for every pair of them does not seem like a feasible solution. A more practical solution is proposed by Gruber in <ref> [ Gruber, 1992 ] </ref> . He 112 CHAPTER 2. LITERATURE REVIEW proposes a single-source/multiple-translation approach in which ontologies are maintained in a simple format that is compatible with multiple representations. Ontologies written in this format are then translated into the different executable representations used by different problem-solving agents. <p> Ontologies written in this format are then translated into the different executable representations used by different problem-solving agents. The Knowledge Interchange Format (KIF) [ Genesereth and Fikes, 1991 ] , On-tolingua <ref> [ Gruber, 1992 ] </ref> , and the Conceptual Modeling Language (CML) [ Wielinga et al., 1992, Schreiber et al., 1994 ] are examples of formalisms that implement this approach. Being an ontology, or meta-ontology, for defining ontologies, these languages provide a vocabulary and a certain structure for representing ontologies. <p> When it needs to communicate with other programs, it maps its internal data structures into KIF. KIF is intended to make the "epistemological level" content of a knowledge base clear to the reader, but not to support automated reasoning in that form <ref> [ Gruber, 1992 ] </ref> . KIF is based on predicate calculus and the formalization of knowledge using it requires a conceptualization of the world in terms of objects, functions, and relations. Objects can be concrete or abstract, primitive or composite, fictional or real.
Reference: [ Gruber, 1993 ] <author> T.R. Gruber. </author> <title> Towards principles for the design of ontologies used for knowledge sharing. </title> <type> Technical Report KSL-93-04, </type> <institution> Stanford University, </institution> <address> Palo Alto, CA., </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: This model corresponds to the abstract model of the framework. It defines entities, relations, and associates capabilities to concepts, but does not provide any functionality. Methods for developing ontologies have recently been proposed <ref> [ Gruber, 1993, Uschold, 1996 ] </ref> . A particularly interesting one, based on a structured approach that a series of intermediate representation, is presented by Gomes-Perez in [ Gomez-Perez et al., 1996 ] . Other methods for ontology development are discussed in chapter 2. <p> The definitions provided in the literature are usually based more on the intended uses of a particular ontology than on the precise characterization of what the term really means to the community in general. In the context of this thesis, the preferred definition is the one provided by Gruber <ref> [ Gruber, 1993 ] </ref> that states that an ontology is an explicit specification of a conceptualization. <p> In summary, from a pragmatic point of view, an ontology defines the vocabulary with which information can be exchanged among intelligent agents, and ontological commitments are agreements to use this vocabulary in a coherent and consistent manner <ref> [ Gruber, 1993 ] </ref> . The current interest of the AI community on the development of ontologies is a result of a change in the research perspective in the area of knowledge engineering. <p> Despite the large number of ontologies currently available in the literature, proposed design methods are more a collection of common sense guidelines than concrete efforts to define a process for ontology creation. In this section we examine three of these proposals: Gruber's criteria for ontology design <ref> [ Gruber, 1993 ] </ref> , Uschold's proposal for creating a unified methodology [ Uschold, 1995, Uschold, 1996 ] , and METHONTOLOGY, a method proposed by Fernandez, Gomes-Perez, and Juristo [ Gomez-Perez et al., 1996, Fernandez et al., 1997 ] . <p> A common characteristic of these guidelines is the similarity they have to the software engineering methods for analysis and design. Gruber <ref> [ Gruber, 1993 ] </ref> proposes five design criteria for creating ontologies for knowledge sharing. Neither a process nor a particular format is specified. No guidelines are provided to enforce or to verify if the generated design satisfies the proposed criteria. <p> The first research area focus on formalizing what is usually described as common use, domain independent knowledge. This research also addresses the formalization of ambiguous, controversial, or ill-structured natural language constructs. These generic or "top-level models," referred in the ontology literature as upper-models <ref> [ Gruber, 1993 ] </ref> or core ontologies, provide the basic primitive constructs that, in principle, would be needed to describe every practical application domain. Terminology for describing time, space, part-whole structures, and cause-effect relations are some examples of concepts described in upper-model ontologies. <p> More details about these types of representations can be found, for example, in Guarino's work [ Guarino, 1995 ] . Terminology for describing the structure of the ontology, also called meta-ontologies, model ontologies [ Wielinga et al., 1992 ] , or even representation ontologies <ref> [ Gruber, 1993 ] </ref> , can also be included in this upper-level category and has already been discussed in the previous sub-section. <p> As discussed in the previous chapter, an ontological model provides a domain specific language to formally describe concepts in a certain universe of discourse. "Formally, an ontology is the statement of a logical theory; pragmatically, a common ontology defines a vocabulary with which queries and assertions are exchanged among agents" <ref> [ Gruber, 1993 ] </ref> . In this thesis, this concept of ontology as a vocabulary is extended by assigning capabilities or behaviors to the concepts. This notion of capabilities subsumes a functional model underlying the concept descriptions.
Reference: [ Gruninger and Fox, 1994 ] <author> M. Gruninger and M.S. Fox. </author> <title> An activity ontology for enterprise modeling. </title> <type> Technical Report Technical Report, </type> <institution> Ind. Eng. Department, University of Toronto, </institution> <year> 1994. </year>
Reference-contexts: Generic level descriptions, or micro-theories, for several different areas of the enterprise have already been implemented: ontologies for describing organization structure [ Fox et al., 1996 ] , process and activities <ref> [ Gruninger and Fox, 1994, Gruninger and Pinto, 1995 ] </ref> , resources [ Fadel et al., 1994 ] , cost [ Tham et al., 1994 ] , and quality [ Kim and Fox, 1994 ] are currently available as part of the TOVE ontology. <p> A central element in TOVE's Model is the representation of an Activity and its associated enabling and caused states. An activity is the basic transformational primitive with which processes and operations can be represented; it specifies how the world changes <ref> [ Gruninger and Fox, 1994 ] </ref> . <p> All the requirements specified in the demand, the special conditions established by the product, and the physical and technological aspects of resource usage are translated into a set constraints that directly affect the activities. <ref> [ Gruninger and Fox, 1994 ] </ref> defines activity as the basic transformational action primitive with which processes and operations can be represented; it specifies how the world is changed.
Reference: [ Gruninger and Pinto, 1995 ] <author> M. Gruninger and J.A. Pinto. </author> <title> A theory of complex actions for enterprise modelling. </title> <booktitle> In Working Notes AAAI Spring Symposium Series 1995: Extending Theories of Action: Formal Theory and Practical Applications, </booktitle> <address> Stanford University, Palo Alto,CA, </address> <year> 1995. </year>
Reference-contexts: Generic level descriptions, or micro-theories, for several different areas of the enterprise have already been implemented: ontologies for describing organization structure [ Fox et al., 1996 ] , process and activities <ref> [ Gruninger and Fox, 1994, Gruninger and Pinto, 1995 ] </ref> , resources [ Fadel et al., 1994 ] , cost [ Tham et al., 1994 ] , and quality [ Kim and Fox, 1994 ] are currently available as part of the TOVE ontology. <p> To add this temporal projection [ Fox et al., 1996 ] capability to the ontology representation, a theory of complex actions based on an extended situation calculus <ref> [ Gruninger and Pinto, 1995 ] </ref> is developed to provide the formal foundation for the ontology construction. The situation calculus is a second order logical language with equality.
Reference: [ Guarino, 1995 ] <author> Nicola Guarino. </author> <title> Formal ontology, conceptual analysis and knowledge representation. </title> <journal> International Journal of Human-Computer Studies, </journal> <volume> 43(5,6):625-640, </volume> <year> 1995. </year>
Reference-contexts: This view has changed in the last years. More recent approaches consider knowledge acquisition as a model building activity. According to this view, a knowledge base is the result of a modeling activity whose object is the observed behavior of an intelligent agent embbeded in an external environment <ref> [ Guarino, 1995 ] </ref> . Using ontologies as a tool for domain model corresponds to this modeling view of the knowledge acquisition process in contrast to the transfer view promoted by domain analysis techniques based on software engineering concepts. <p> Therefore, upper-level ontologies will not be discussed. More details about these types of representations can be found, for example, in Guarino's work <ref> [ Guarino, 1995 ] </ref> .
Reference: [ Hadavi and Voigt, 1990 ] <author> M.S. Hadavi, K. Shahraray and K. Voigt. </author> <title> An environment for planning, scheduling, and control of factories. </title> <journal> Journal of Manufacturing Systems, </journal> <volume> 9(4) </volume> <pages> 332-344, </pages> <year> 1990. </year>
Reference-contexts: When a conflict event is posted, the Conflict Analyzer is called. The Analyzer then post suggested actions to be executed. The actions are selected based on the information posted in the Policies region of the control blackboard. 2.3.4 REDS REDS <ref> [ Hadavi and Voigt, 1990, Hadavi et al., 1992 ] </ref> , Real-Time Distributed Scheduling, is a distributed architecture for real-time scheduling. It has been developed under the assumption that, as scheduling objectives typically conflict, it is desirable to have a scheduling system capable of observing the environment from different perspectives. <p> It also helps to meet due dates by reducing cycle times. REDS' architecture is based on the conceptual division of the scheduling tasks into four subtasks that are assigned to independent scheduling agents <ref> [ Hadavi and Voigt, 1990 ] </ref> . Each scheduling agent works at a designated level of the problem-solving hierarchy and coordinates its action with other module's action through message passing. <p> The sequencing algorithm selection is based on domain-specific information and on the objectives established by the management. It usually attempts to maximize throughput and machine use, and minimize flow time and WIP. A sequencing rule called Dynamic Sequencing Rule <ref> [ Hadavi and Voigt, 1990 ] </ref> was developed as a priority rule for sequencing. These four tasks can operate under predictive or reactive mode and they have a different behavior according to the mode they are operating. <p> With each node of the tree is associated a set of constraints. The set of constraints associated to a node is called constraint pool <ref> [ Hadavi and Voigt, 1990 ] </ref> and represents the set of active constraints over the time interval defined by the node. There exists a function called abstraction function [ Hadavi and Voigt, 1990 ] that maps the constraint pool associated with a given node to its descendents The abstraction function maps <p> The set of constraints associated to a node is called constraint pool <ref> [ Hadavi and Voigt, 1990 ] </ref> and represents the set of active constraints over the time interval defined by the node. There exists a function called abstraction function [ Hadavi and Voigt, 1990 ] that maps the constraint pool associated with a given node to its descendents The abstraction function maps the constraints across abstraction levels. The constraint pool is composed of two parts. One part corresponds to global constraints like management objectives and goals.
Reference: [ Hadavi et al., 1992 ] <author> K. Hadavi, W.L. Hsu, T. Chen, and C.N. Lee. </author> <title> An architecture for real-time distributed scheduling. </title> <journal> AI Magazine, </journal> <pages> pages 46-56, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: This aspect identifies the repair actions available to the systems and how they are selected. The systems analyzed are: OPIS [ Smith, 1994 ] , SONIA [ Collinot et al., 1988 ] , REDS <ref> [ Hadavi et al., 1992 ] </ref> , Distributed Asynchronous Scheduler ( DAS ) [ Burke and Prosser, 1989 ] , GERRY ( Zweben's Iterative Repair ) [ Zweben et al., 1992a ] , Minton's Min-Conflicts Heuristic [ Minton et al., 1992a ] , Le Pape's Reactive Schedule Model [ Le Pape, <p> When a conflict event is posted, the Conflict Analyzer is called. The Analyzer then post suggested actions to be executed. The actions are selected based on the information posted in the Policies region of the control blackboard. 2.3.4 REDS REDS <ref> [ Hadavi and Voigt, 1990, Hadavi et al., 1992 ] </ref> , Real-Time Distributed Scheduling, is a distributed architecture for real-time scheduling. It has been developed under the assumption that, as scheduling objectives typically conflict, it is desirable to have a scheduling system capable of observing the environment from different perspectives. <p> The distributed nature of the architecture should attend these tow perspectives simultaneously. In REDS, both predictive and reactive scheduling are incorporated along with a release control strategy called FORCE ( Factory Order Release Control and Evaluation ) <ref> [ Hadavi et al., 1992 ] </ref> . 184 CHAPTER 2. LITERATURE REVIEW The use of a release control is advocated as a strategy to reduce job waiting times, WIP, finished goods inventory. It also helps to meet due dates by reducing cycle times.
Reference: [ Harvey and Ginsberg, 1995 ] <author> W.D. Harvey and M.L. Ginsberg. </author> <title> Limited discrepancy search. In Proceedings of the IJCAI'95, </title> <note> available from http://www.cirl.uoregon.edu/research/search.html, 1995. </note>
Reference-contexts: The best results generated so far for the first four benchmark problems have been obtained by the CIRL group at the University of Oregon. They have used a multi-pass mechanism, called limited discrepancy search <ref> [ Harvey and Ginsberg, 1995 ] </ref> , followed by a post-processing optimization technique called a doubleback optimization [ Crawford, 1996 ] . The limited discrepancy search mechanism generates several different seed solutions that are then passed to the optimization mechanism. <p> In the comparison tables, we designate his results as BELL. 4. James Crawford, Matthew Ginsberg, Ari Jonsson, and the CIRL Team from the Computational Intelligence Research Laboratory at the University of Oregon (jc@cs.uoregon.edu) using a combination of "Limited Discrepancy Search" <ref> [ Harvey and Ginsberg, 1995 ] </ref> and "Double-back Optimization" [ Crawford, 1996 ] . In the comparison tables, we designate their results as CIRL-DBO, when obtained with the doubleback optimization, and as CIRL-LDS when the results have been obtained with least discrepancy search followed by doubleback optimization.
Reference: [ Hayes-Roth et al., 1983 ] <author> F. Hayes-Roth, D. Waterman, and D. Lenat. </author> <title> Building Expert Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: As a first step, Clancey transformed a previously existing problem type classification, Stefik & Hayes-Roth's <ref> [ Hayes-Roth et al., 1983 ] </ref> , into a hierarchical scheme, and made a distinction between generic and compound problem types.
Reference: [ Hayes-Roth et al., 1995 ] <author> B. Hayes-Roth, K. Pfleger, P. Lalanda, P. Morignot, and M. Balabanovic. </author> <title> A domain-specific software architecture for adaptative intelligent systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(4) </volume> <pages> 288-301, </pages> <month> April </month> <year> 1995. </year> <note> BIBLIOGRAPHY 491 </note>
Reference-contexts: Another characteristic of WRIGHT is that configurations are completely static descriptions. 2.1.3 Domain Specific Software Architectures According to <ref> [ Hayes-Roth et al., 1995 ] </ref> , a good software architecture facilitates application system development, promotes achievement of functional requirements, and support system reconfiguration. However, the design and implementation of a good architecture is usually difficult and expensive.
Reference: [ Hayes-Roth, 1985 ] <author> B. Hayes-Roth. </author> <title> A blackboard architecture for control. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 26 </volume> <pages> 251-321, </pages> <year> 1985. </year>
Reference-contexts: Its architecture is motivated by the desire of dynamically adapting its problem-solving behavior according to the active or current constraint set. To implement this behavior, a control architecture based on the principles of the blackboard control architecture <ref> [ Hayes-Roth, 1985 ] </ref> is used. This control framework coordinates the action of a collection of scheduling and analysis methods that interact to generate, revise, and analyze the schedule. Two components provide the control infra-structure that characterize OPIS as an opportunistic, multi-perspective scheduling system. <p> This architecture is a modified version of the traditional blackboard control model <ref> [ Hayes-Roth, 1985 ] </ref> . The modified version used in our framework is an agenda-based control architecture. In the traditional blackboard model, all problem-solving "agents" have access to a common data-structure that represents the "state" of the system. This data-structure, the blackboard, is usually divided into a number of regions. <p> prioritize the space of possible relaxations of a constraint and provide a basis for measuring solution quality. 3.5 The OZONE Control Ontology All scheduling applications developed using the ozone framework have their problem-solving activities coordinated by an control mechanism based on a modified version of the blackboard model of control <ref> [ Hayes-Roth, 1985, Jagannathan et al., 1989 ] </ref> . This modified version is called an agenda-based control model, and its implementation an agenda-based control architecture.
Reference: [ Heirdon, 1986 ] <author> G.E. Heirdon. </author> <title> Automatic programming through natural language dialogue: A survey. </title> <editor> In Charles Rich and Richard C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 205-221, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: LITERATURE REVIEW ing a complete implementation is the ultimate goal in automatic programming. Vocabulary, informality and syntax are the three features that makes natural language very attractive [ Rich and Waters, 1988 ] . Early works <ref> [ Heirdon, 1986 ] </ref> , however, has shown that one of these characteristics, informality, is a very difficult aspect of using natural language as a specification language. To overcome this problem, researchers tried to separate natural languages processing from informality issues.
Reference: [ Hoare, 1985 ] <author> C.A. Hoare. </author> <title> Communicating Sequential Processes. </title> <publisher> Prentice Hall, </publisher> <year> 1985. </year>
Reference-contexts: To accomplish these goals, WRIGHT extends the basic component-connector notation provided by traditional Architecture Description Languages like UniCon [ Shaw et al., 1995 ] or Rapide [ Luckham et al., 1995 ] , with a modified version of the formal notation CSP <ref> [ Hoare, 1985 ] </ref> . The result is a language that allows not only the specification of the structure of a particular architecture or architectural style, but also allows the precise specification of patterns of behavior and interaction between components.
Reference: [ Hollingsworth, 1994 ] <author> D. Hollingsworth. </author> <title> Workflow management coalition: The workflow reference model. </title> <type> Technical Report WFMC-TC-1003, </type> <institution> Available from http://www.aiim.org/wfmc/, Work-flow Management Coalition, </institution> <address> Brussels, Belgium, </address> <year> 1994. </year>
Reference-contexts: Its primary characteristics is the automation of processes involving combination of human and machine based activities, particularly those involving interaction with computer application <ref> [ Hollingsworth, 1994 ] </ref> . Several workflow products are currently offered by a number of different software vendors. The lack of established standards in this area makes it difficult for products to work together, creating incompatible "islands" of automation. <p> A "Reference Model" for workflow management application together with a Workflow Application Programming Interface & Interchange have been proposed <ref> [ Hollingsworth, 1994 ] </ref> . Since the the effectiveness and efficiency of a workflow management process in any realistic application heavily depends on the allocation of limited resources over time, planning and scheduling applications are likely to play a central role in this area. <p> An example of how a scheduling system can be used in a workflow management environment is presented in [ Smith et al., 1998 ] . In the next paragraphs the main workflow concepts relevant to scheduling are presented. The terminology and definitions presented are based on <ref> [ Hollingsworth, 1994 ] </ref> and [ Workflow Management Coalition Members, 1996 ] . These two documents represent the workflow terminology as an alphabetized list of terms with a natural language definition. Although no attempts of formalizing or structuring the 2.2.
Reference: [ Jagannathan et al., 1989 ] <author> V. Jagannathan, R. Dodhiawala, </author> <title> and L.S. Baum. Blackboard Architectures and Applications. </title> <booktitle> Perspectives in Artificial Intelligence. </booktitle> <publisher> Academic Press, </publisher> <year> 1989. </year>
Reference-contexts: prioritize the space of possible relaxations of a constraint and provide a basis for measuring solution quality. 3.5 The OZONE Control Ontology All scheduling applications developed using the ozone framework have their problem-solving activities coordinated by an control mechanism based on a modified version of the blackboard model of control <ref> [ Hayes-Roth, 1985, Jagannathan et al., 1989 ] </ref> . This modified version is called an agenda-based control model, and its implementation an agenda-based control architecture.
Reference: [ Johnson, 1997 ] <author> R.E. Johnson. </author> <title> Components, frameworks, patterns. In Workshop on Object Oriented Methods for Distributed Control Architectures, </title> <address> Albuquerque, NM, </address> <month> April </month> <year> 1997. </year> <booktitle> IEEE International Conference on Robotics and Automation. </booktitle>
Reference-contexts: More recent approaches have concentrated on reusing larger pieces of code inside a coherent structure or architecture. Software architecture [ Garlan and Shaw, 1994 ] , domain specific software architectures [ Tracz, 1994 ] , software patterns [ Gamma et al., 1994 ] , and object-oriented frameworks <ref> [ Johnson, 1997 ] </ref> are examples of recent software reuse efforts that relates to this architectural reconfigurability here advocated. To avoid the pitfalls associated with overly general solutions, we decided to start with a domain specific architecture and generalize it on demand. <p> The 5 developer decides what is plugged into it and might even make some new components that are plugged in. The developers code gets called by the framework code. The framework determines the overall structures and flow of control of the program" <ref> [ Johnson, 1997 ] </ref> . The novelty of the approach is in the use of ontologies as the modeling representation, the integration of software-architecture concepts to the modeling framework, the implementation of a software tool to support system configuration, and in the addition of mixed-initiative to the modeling phase. <p> Although the component library is an essential part of any framework, the most important part is how the system is decomposed into components and how these components interface and interact with each other <ref> [ Johnson, 1997 ] </ref> . There is a large number of object-oriented frameworks implemented for several different domains. The most popular are the ones used to build Graphical User Interfaces. Smalltalk 80, developed in the late 70's is the first user interface framework widely used. <p> Some examples of framework applications outside the user interface arena includes VLSI routing algorithms, operating systems, manufacturing control, system architecture configuration, distributed systems, information management, and structured drawing editors. An extensive discussion of frameworks is presented by Johnson in <ref> [ Johnson, 1997 ] </ref> . In this section, we summarize the relevant aspects of object-oriented framework based on Johnson's paper. 70 CHAPTER 2. LITERATURE REVIEW The characteristic that distinguishes development using frameworks from traditional reusable components is what Johnson calls the inversion of control.
Reference: [ Joint-Pub-1-02, 1994 ] <author> Joint-Pub-1-02. </author> <title> Department of Defense Dictionary of Military and Associated Terms. </title> <address> http://www.dtic.mil/doctrine/jel/index.html, March 1994. </address>
Reference-contexts: of operations to a medical facility or to a safe area; and RE-DEPLOYMENT defined as the transfer of a unit, an individual, or supplies deployed in one area to another area, or to another location within the area, or to the zone of interior for the purpose of further employment <ref> [ Joint-Pub-1-02, 1994 ] </ref> . These phases can then be further decomposed according to the characteristics and requirements of the transportation activities involved. We will focus on the force deployment and sustainment phase as a means of presenting the ontology for the multi-modal transportation problem. <p> THE DOMAIN ONTOLOGY FOR LOGISTICS DEPLOYMENT 353 alphanumeric code that uniquely identifies the location. Two types of transport terminals are modeled: (a) SEAPORT or just PORTS (b) AERIAL PORTS or AIRPORTS The term PORT should not be used in conjunction with air facilities <ref> [ Joint-Pub-1-02, 1994 ] </ref> TERMINAL capacity is discussed in more details in section 4.2.4.3. 3. AUXILIARY RESOURCES: secondary resources needed to support terminal operations and transport activities. Examples of these types of resources are equipment to on/o*oad cargo, pallets, containers, forklifts, ground crews. <p> MEDICAL TREATMENT FACILITY (MTF): The medical treatment facility (MTF) is a facility established for the purpose of furnishing medical and/or dental care to eligible individuals <ref> [ Joint-Pub-1-02, 1994 ] </ref> . The medical treatment facility is the resource capable of providing the medical treatment required by a patient. The capacity of an MTF is the number of beds available for each medical specialty supported by the facility. 5.2. THE DOMAIN ONTOLOGY FOR AEROMEDICAL EVACUATION 397 2.
Reference: [ Joint-Pub-3-17, 1995 ] <author> Joint-Pub-3-17. </author> <title> Joint Tactics, Techniques, and Procedures for Theater Airlift Operations. </title> <note> http://www.dtic.mil/doctrine/jel/index.html, July 1995. </note>
Reference-contexts: The OFFLOAD for AIRLIFT ACTIVITIES, depending on the method of delivery, can be specialized into: (a) AIR-LAND ACTIVITY: airlifted personnel and material are disembarked, unloaded, or unslung from an aircraft after it has landed <ref> [ Joint-Pub-3-17, 1995 ] </ref> . airland activities may also involve OFFLOADING the plane and MARSHALLING the cargo. (b) AERIAL DELIVERY: airlifted personnel and material are disembarked or unloaded from the aircraft still in flight. Types of aerial delivery of airdrop are: i. FREE DROP: no parachute used. ii.
Reference: [ Joint-Pub-4-01, 1997 ] <author> Joint-Pub-4-01. </author> <title> Joint Doctrine for the Defense Transportation System. </title> <note> http://www.dtic.mil/doctrine/jel/index.html, June 1997. </note>
Reference-contexts: PRIORITY: A system of priority is defined for movement requirements. When requirements exceed lift capacity, the requirements should be ordered by decreasing priority and higher priority requirements should be serviced first. The decreasing priority categories are <ref> [ Joint-Pub-4-01, 1997 ] </ref> : 338 CHAPTER 4. AN APPLICATION FOR MULTI-MODAL LOGISTICS DEPLOYMENT (a) PRIORITY 1: i. PRIORITY 1A: A. PRIORITY 1A1: A Presidentially directed mission. B. PRIORITY 1A2: US Forces and other forces in combat. C. PRIORITY 1A3: Programs approved by the President as national pri ority. D.
Reference: [ Joint-Pub-4-01.3, 1996 ] <author> Joint-Pub-4-01.3. </author> <title> Joint Tatics, Techniques, and Procedures for Movement Control. </title> <note> http://www.dtic.mil/doctrine/jel/index.html, June 1996. </note>
Reference-contexts: It coordinates the transportation assets of all modes as well as terminal usage. We will refer to the process of planning, routing, scheduling, and controlling transportation assets, and maintaining in-transit visibility to assist commanders and operations staffs in force tracking as MOVEMENT CONTROL. <ref> [ Joint-Pub-4-01.3, 1996 ] </ref> . According to this definition, the movement control process involves PLANNING, APPORTIONING TRANSPORTATION, ALLOCATING TRANSPORTATION, DE-CONFLICTING PRIORITIES, VALIDATION OF REQUESTS, COORDINATION, and guaranteeing IN-TRANSIT VISIBILITY as well as FORCE TRACKING. A request for moving personnel or cargo in a military operation is a MOVEMENT REQUIREMENT. <p> The deliberate planning process focuses on the time-phasing of movements and the assigning of transportation resources to support initial deployment for a set period, normally around 90 days after deployment commences <ref> [ Joint-Pub-4-01.3, 1996 ] </ref> . This process is divided into five phases: INITIATION, CONCEPT DEVELOPMENT, PLAN DEVELOPMENT, PLAN REVIEW, and SUPPORTING PLAN DEVELOPMENT.
Reference: [ Joint-Pub-4-02.2, 1996 ] <author> Joint-Pub-4-02.2. </author> <title> Joint Tatics, Techniques, and Procedures for Patient Movement in Joint Operations. </title> <note> http://www.dtic.mil/doctrine/jel/index.html, December 1996. </note>
Reference-contexts: A more detailed description of how USTRANSCOM handles evacuation of patients can be found in <ref> [ Joint-Pub-4-02.2, 1996 ] </ref> . The ontology presented is based on this last document. <p> The decisions involved in evacuation of patients entails identifying patients requiring medical care beyond that which is available at their present location, locating and assigning a a patient to a hospital or MEDICAL TREATMENT FACILITY with appropriate capabilities, and coordinating the transportation means for movement <ref> [ Joint-Pub-4-02.2, 1996 ] </ref> . The evacuation and treatment of PATIENTS is organized according to a phased health care systems. <p> A PROTOTYPE FOR AEROMEDICAL EVACUATION A patient movement request is similar to the movement requirement described in chapter 4. It can even be defined as a movement requirement in which the cargo is the patient to be evacuated. 5.2.1.2 Properties In <ref> [ Joint-Pub-4-02.2, 1996 ] </ref> there is no pre-specified format for the patient movement request record.
Reference: [ Joint-Pub-4.01.2, 1996 ] <author> Joint-Pub-4.01.2. </author> <title> Joint Tatics, Techniques, and Procedures for Sealift Support to Joint Operations. </title> <note> http://www.dtic.mil/doctrine/jel/index.html, October 1996. 492 BIBLIOGRAPHY </note>
Reference-contexts: COMMON USER SEALIFT ASSETS and NONCOMMON USER SEALIFT ASSETS. common user or conventional resources are those militarily useful merchant ships available for joint support of all Service's movement requirements. noncommon user resources are not generally available to transport joint movement requirements <ref> [ Joint-Pub-4.01.2, 1996 ] </ref> . common user resources can be divided into two categories: 1. DRY CARGO or FREIGHTERS: dry cargo ships are considered militarily useful if they can carry a minimum of 2,000 long tons of cargo and the ability to carry unit equipment, ammunition, or sustaining supply.
Reference: [ Joint-Pub-5-03.1, 1993 ] <author> Joint-Pub-5-03.1. </author> <title> Joint Operation Planning and Execution System-Volume I. </title> <note> http://www.dtic.mil/doctrine/jel/index.html, August 1993. </note>
Reference-contexts: phases or types of transportation activities: DEPLOYMENT that corresponds to the relocation of forces and material to the area of operations; SUSTAINMENT that is defined as the provision of personnel, logistics, and other support required to maintain and prolong operations or combat until accomplishment or revision of the mission objectives <ref> [ Joint-Pub-5-03.1, 1993 ] </ref> ; EVACUATION of patients, prisoners of war, and non-combatant personnel from the area of operations to a medical facility or to a safe area; and RE-DEPLOYMENT defined as the transfer of a unit, an individual, or supplies deployed in one area to another area, or to another <p> The planning for movement control follows different processes according to the focus and nature of operations. These planning processes are currently supported by the Joint Operation Planning and Execution System (JOPES) and the description here presented follows the terminology used in JOPES' manuals and publications <ref> [ Joint-Pub-5-03.1, 1993 ] </ref> . The two main process types are DELIBERATE PLANNING and CRISIS ACTION PLANNING . Campaign planning 4.2. THE DOMAIN ONTOLOGY FOR LOGISTICS DEPLOYMENT 333 is a more general process that begins with deliberate planning and continues through crisis action planning. <p> Before proceeding to a discussion of demands and movement requirements, we introduce some basic temporal concepts that are to be assumed. 4.2.1 Temporal Primitives Some useful military terms for describing specific time point are <ref> [ Joint-Pub-5-03.1, 1993 ] </ref> : 4.2. THE DOMAIN ONTOLOGY FOR LOGISTICS DEPLOYMENT 335 C-day: The unnamed day on which a deployment operations commences or is to commence. D-day: The unnamed day on which a particular operation commences or is to commence.
Reference: [ Kang et al., 1990 ] <author> K.C. Kang, S.G. Cohen, J.A. Hess, </author> <title> W.E. Novak, and A.S Peterson. Feature-oriented domain analysis: Feasibility study. </title> <type> Technical Report SEI-90-TR-21, </type> <institution> Software Engineering Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: Domain analysis can be defined as the process of identifying, collecting, organizing, and representing the relevant information in a domain, based upon the study of existing systems and their development histories, knowledge captured from domain experts, underlying theory, and emerging technology within a domain <ref> [ Kang et al., 1990 ] </ref> . According to Arango and Prieto-Daz [ Arango and Prieto-Daz, 1991 ] , the expression "domain analysis" in the context of software reuse has been first introduced by Neighbors in his Phd Thesis [ Neighbors, 1981 ] .
Reference: [ Kant et al., 1991 ] <author> E. Kant, F. Daube, W. MacGregor, and J. Wald. </author> <title> Scientific programming by automated synthesis. </title> <editor> In M. Lowry and R. McCartney, editors, </editor> <booktitle> Automating Software Design, </booktitle> <pages> pages 169-205. </pages> <publisher> AAAI Press/The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: In this system, an informal problem description written in a domain-specific language is translated into mathematical formalisms that require no domain knowledge. All the domain information is used only in this translation process. In the SINAPSE system <ref> [ Kant et al., 1991 ] </ref> , an environment for scientific computation, a system is described in terms of application-domain key-words. This description is guided through menus provided by a graphical user interface.
Reference: [ Kaptur, 1996 ] <editor> KAPTUR user's guide. </editor> <address> http://groucho.gsfc.nasa.gov/Code 520/Code 522/Projects/KAPTUR/, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Some of the views supported are, for example, entity-relationship, data flow, object communication, state transition, and stimulus response. These architectures are representations of specified requirements and design components, not the components themselves. KAPTUR does not store the actual software assets in its database, but stores their representations <ref> [ Kaptur, 1996 ] </ref> . These representations are the domain models. The reusable artifacts are classified according to their features. This features represent a significant design or programmatic decision, or it may represent the use of a particular technology or method for a system whose architecture is kept in KAPTUR. <p> The reusable asset is stored in KAPTUR's knowledge-base with the corresponding feature explanation. An explanation for a single feature contains the decision represented by the feature, what tradeoffs were considered while making the decision, and the rationale (s) for making the decision. According to <ref> [ Kaptur, 1996 ] </ref> , the concept of a feature is broader than the one adopted in FODA. In FODA, a feature is a prominent or distinctive user-visible aspect, quality, or characteristic.
Reference: [ Kerth and Cunningham, 1997 ] <author> N.L. Kerth and W. Cunningham. </author> <title> Using patterns to improve our architectural vision. </title> <journal> IEEE Software, </journal> <pages> pages 53-59, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: A collection of patterns organized in a structure that guides how they can be used and/or implemented constitutes a pattern language. According to <ref> [ Kerth and Cunningham, 1997 ] </ref> patterns assembled into a pattern language order our thought processes in the same way as a grammar orders our sentence structure.
Reference: [ Kiczales et al., 1991 ] <author> G. Kiczales, des Rivieres, J., and G. Bobrow. </author> <title> The Art of the Metaobject Protocol. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The problem with this dynamic behavior is that Common Lisp does not implement any mechanism to verify and enforce any constraints on the valid modification. On the other hand, the Common Lisp Metaobject Protocol <ref> [ Kiczales et al., 1991 ] </ref> defines an interface that can be used to customize instance creation and re-initialization, as well as class inheritance update. By writing tailored versions of these meta-level methods, such constraints can be verified and enforced.
Reference: [ Kim and Fox, 1994 ] <author> H. Kim and M.S. Fox. </author> <title> Formal models of quality and ISO 9000 compliance: An information systems approach. </title> <booktitle> In American Quality Congress (AQC) Conference, American Society for Quality Control, </booktitle> <address> Las Vegas, NV, </address> <year> 1994. </year>
Reference-contexts: the enterprise have already been implemented: ontologies for describing organization structure [ Fox et al., 1996 ] , process and activities [ Gruninger and Fox, 1994, Gruninger and Pinto, 1995 ] , resources [ Fadel et al., 1994 ] , cost [ Tham et al., 1994 ] , and quality <ref> [ Kim and Fox, 1994 ] </ref> are currently available as part of the TOVE ontology. In enterprise modeling, the notion of time, activity, and resource plays a 124 CHAPTER 2. LITERATURE REVIEW central role. Cost and quality are of course important but beyond the scope of this thesis.
Reference: [ Kolisch and Drexl, 1996 ] <author> R. Kolisch and A. Drexl. </author> <title> Adaptative search for solving hard project scheduling problems. </title> <journal> Naval Research Logistics, </journal> <volume> 43 </volume> <pages> 23-40, </pages> <year> 1996. </year>
Reference-contexts: 6.4 The Problem Solving Ontology for the Benchmark Problems Exact solutions to the Resource Constrained Project Scheduling problem using mathematical programming techniques like integer programming, dynamic programming, bounded enumeration, implicit enumeration, and branch and bound are generally appropriate for small or moderate size projects projects with less than fifty activities <ref> [ Kolisch and Drexl, 1996, Bell and Han, 1991 ] </ref> . This relative lack of success of optimization techniques in problems of realistic size motivated the development of heuristic procedures which can generate reasonably good feasible solutions. <p> This relative lack of success of optimization techniques in problems of realistic size motivated the development of heuristic procedures which can generate reasonably good feasible solutions. Although a number of more elaborated heuristic methods like truncated branch and bound and integer programming based heuristics are currently available <ref> [ Kolisch and Drexl, 1996 ] </ref> , we are more interested in heuristic methods known as priority dispatching rules. This type of heuristic methods have the advantage of being robust, intuitive, easy to implement, and computationally efficient. 6.4.
Reference: [ Kowalski, 1979 ] <author> R.A. Kowalski. </author> <title> Algorithm = logic + control. </title> <journal> Communications of the ACM, </journal> <volume> 22(7) </volume> <pages> 424-436, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: These systems provide a general, domain-independent, lower-level reasoning mechanism, that solve problems by manipulating a rich representation that encodes all the application domain knowledge needed to solve the problem. These systems are based on the assumption of separating problem specification from problem-solving behavior <ref> [ Kowalski, 1979 ] </ref> . Once the knowledge is acquired and represented in the appropriate format, the problem is considered as solved. In practice, that is not exactly what happens. <p> The use of logic as a programming language has been the subject of research in the areas of logic-programming and formal specification languages. Logic programming is based on the assumption that is possible to completely separate problem specification from problem execution <ref> [ Kowalski, 1979 ] </ref> . It assumes a general problem solving mechanism, a theorem prover, capable of executing a logic specification.
Reference: [ Krueger, 1992 ] <author> C.W. Krueger. </author> <title> Software reuse. </title> <journal> Computing Surveys, </journal> <volume> 24(2) </volume> <pages> 131-183, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Systematic software reuse [ Frakes and Isoda, 1994 ] . 2.1.1 Approaches to Software Reuse Since 1968, several different approaches to software reuse have been attempted. Krueger <ref> [ Krueger, 1992 ] </ref> presents a taxonomy that characterizes each of these approaches in terms of its reusable artifacts and the way these artifacts are abstracted, selected, specialized, and integrated. According to this classification, eight categories of artifacts are proposed. <p> An essential element of any reuse approach is the mechanism or language used for describing the abstractions. According to Krueger, the effectiveness of abstractions in a software reuse technique can be evaluated in terms of the intellectual effort required to use them <ref> [ Krueger, 1992 ] </ref> . He defines this unquantifiable amount of intellectual effort required to take a software system from one development stage to the next, as the cognitive distance.
Reference: [ Krut Jr., 1993 ] <author> R.W. Krut Jr. </author> <title> Integrating 001 tool support into the feature oriented domain analysis methodology. </title> <type> Technical Report SEI-93-TR-11, </type> <institution> Software Engineering Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA., </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Two distinctive characteristics of this method are, number one, the emphasis the authors put on clarifying the activities in the process, and on recommending specific approaches and formats for identifying and representing domain objects and operations; and, number two, the implicit inclusion of model validation activities in the process <ref> [ Krut Jr., 1993 ] </ref> . The method tries to cover all phases from domain preparation to architectural modeling. However, the transition from the domain models produced by the analysis activities to architecture design and implementation is not very well defined.
Reference: [ Krutchen et al., 1984 ] <author> P. Krutchen, E. Schonberg, and J. Schwartz. </author> <title> Software prototyping using the SETL programming language. </title> <journal> IEEE Software, </journal> <volume> 1(4) </volume> <pages> 66-75, </pages> <month> October </month> <year> 1984. </year> <note> BIBLIOGRAPHY 493 </note>
Reference-contexts: The goal of VHLL implementors is to find abstractions that are more natural and expressive than the one provided by high level languages like C, Lisp, Fortran. Examples of VHLLs are languages that implement set theoretical abstractions like SETL <ref> [ Krutchen et al., 1984 ] </ref> and PAISLey [ Zave and Schell, 1986 ] , or declarative constraint-based languages like MODEL [ Prywes and Lock, 1989 ] . Problems with this approach are poor run-time performance and the difficulty associated to using high-level mathematical abstractions. <p> The favored technique is the use of program transformation systems that provide a library of refinements, or rules, on how to translate these high-level constructs into more tractable expressions. Advice is then required to select the refinements to be applied. Some examples of very high-level languages are SETL <ref> [ Krutchen et al., 1984, Schonberg et al., 1986 ] </ref> , Gist, [ Balzer, 1985 ] , V [ Smith et al., 1985 ] , and Refine [ Smith et al., 1985 ] .
Reference: [ Larkin and Simon, 1987 ] <author> J.H. Larkin and H.A. Simon. </author> <title> Why a diagram is (sometimes) worth ten thousand words. </title> <journal> Cognitive Science, </journal> <volume> 11(1) </volume> <pages> 65-99, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: One important characteristic of a language is its expressive power: what concepts can be represented and how easy it is to work with this representation <ref> [ Larkin and Simon, 1987 ] </ref> . I am using expressive power in a loose sense. It can mean different things in different contexts.
Reference: [ Lassila et al., 1996 ] <author> O. Lassila, M.A. Becker, and S.F. Smith. </author> <title> An exploratory prototype for aeromedical evacuation planning. </title> <type> Technical Report CMU-RI-TR-96-02, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA., </address> <month> January </month> <year> 1996. </year>
Reference-contexts: ontology is the result of considerable prior experience in building planning and scheduling systems, in application domains ranging from manufacturing production scheduling [ Smith, 1994 ] to space mission planning [ Muscettola et al., 1992 ] to military deployment [ Smith and Lassila, 1994a ] , and aero-medical evacuation planning <ref> [ Lassila et al., 1996 ] </ref> .
Reference: [ Le Pape, 1991 ] <author> C. Le Pape. </author> <title> Constraint propagation in planning and scheduling. </title> <type> Technical report, </type> <institution> Stanford University, </institution> <year> 1991. </year>
Reference-contexts: , REDS [ Hadavi et al., 1992 ] , Distributed Asynchronous Scheduler ( DAS ) [ Burke and Prosser, 1989 ] , GERRY ( Zweben's Iterative Repair ) [ Zweben et al., 1992a ] , Minton's Min-Conflicts Heuristic [ Minton et al., 1992a ] , Le Pape's Reactive Schedule Model <ref> [ Le Pape, 1991 ] </ref> . OPIS is the system in which architecture the OZONE class library is based. Several of the representation and algorithms used by OZONE are improved versions of the ones used in OPIS. <p> The selection of the assignment to move or the new assignment is not guided by the type of constraints violated but only by the number of conflicts. The objective is to minimize the number of future conflicts. 2.3.8 Le Pape's Reactive Architecture Le Pape <ref> [ Le Pape, 1991 ] </ref> describes a system that is a constraint propagation based implementation of the ideas presented by Smith in [ S.F. Smith et al., 1990 ] . <p> This section focuses on the repair capabilities of the local dispatcher. 2.3. KNOWLEDGE-BASED SCHEDULING ARCHITECTURES 209 2.3.8.1 Control Architecture The implementation proposed by Le Pape in <ref> [ Le Pape, 1991 ] </ref> assumes three agents operating in parallel and asynchronously exchanging messages: Global Scheduler: generates a predictive schedule and occasionally updates it. It establishes and maintains execution constraints according to the specified objective function. <p> The operations already processed are placed in a set called Finished. The Waiting set represent the frontier between the local dispatcher and the global scheduler. In Le Pape's implementation <ref> [ Le Pape, 1991 ] </ref> , this frontier is enforced by the use of the interface agent. Le Pape defines specific protocols for the communication between the local dispatcher and the interface, and between the global dispatcher and the interface. <p> Schedule Objects have to be transferred from Waiting to Next and new objects have to be requested from the interface to update the Waiting set. This involves a search through the space of objects dependencies. For this purpose, a simple breadth-first search is implemented <ref> [ Le Pape, 1991 ] </ref> . Both the local dispatcher and the global scheduler have access to the data model of the environment and to a knowledge base. <p> This can be a consequence of a machine going on emergency repair or problems with the job processing. Le Pape's implementation uses a simplified version of SONIA with the simplest possible dispatcher <ref> [ Le Pape, 1991 ] </ref> . The dispatcher implemented uses the solution maintenance component of SONIA and performs constraint propagation by only updating the earliest and the latest start 214 CHAPTER 2. <p> This aspect of the reaction was left unspecified by Smith [ S.F. Smith et al., 1990 ] and a possible approach to its 2.3. KNOWLEDGE-BASED SCHEDULING ARCHITECTURES 215 implementation, although incomplete, is described by Le Pape <ref> [ Le Pape, 1991 ] </ref> . It is not difficult however to imagine a system like OPIS or SONIA operating as global schedulers.
Reference: [ Le Pape, 1994 ] <author> C. Le Pape. </author> <title> Implementation of resource constraints in ILOG schedule: A library for the development of constraint-based scheduling systems. </title> <journal> Intelligent Systems Eng., </journal> <month> Summer, </month> <year> 1994. </year>
Reference-contexts: An example of a system implemented using this approach is the Kestrel Transportation Scheduler [ Smith et al., 1996a ] . The second approach is the creation of a library of components for scheduling systems. ILOG's SCHEDULER and SOLVER <ref> [ Le Pape, 1994 ] </ref> and Deja Vu [ Dorn et al., 1997 ] are two examples of solutions using the library approach. SOLVER is described as a library of object classes, functions, and class structures available in Le-Lisp or C++ programming language [ Le Pape, 1994 ] . <p> ILOG's SCHEDULER and SOLVER <ref> [ Le Pape, 1994 ] </ref> and Deja Vu [ Dorn et al., 1997 ] are two examples of solutions using the library approach. SOLVER is described as a library of object classes, functions, and class structures available in Le-Lisp or C++ programming language [ Le Pape, 1994 ] . Deja Vu is a framework of C++ 2.3. KNOWLEDGE-BASED SCHEDULING ARCHITECTURES 169 classes to support developers in the construction of scheduling systems for industrial production processes. <p> This assignment should satisfy a set of pre-defined constraints and, at the same time, guarantee the quality of the schedule in terms of some utility metric. The set of constraints define the space of admissible solutions <ref> [ Le Pape, 1994 ] </ref> . The approach of establishing scheduling decisions based on a set of production objectives and on a static description of the application domain is called predictive scheduling.
Reference: [ Lee et al., 1996 ] <author> J. Lee, G. Yost, </author> <title> and PIF Working Group. The PIF process interchange format and framework. </title> <type> Technical Report Working Paper No. 180, </type> <institution> MIT Center for Coordination Science, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: With similar goals, the Process Interchange Format <ref> [ Lee et al., 1996 ] </ref> and the emerging NIST's effort to create a Unified Process Specification Language [ Schlenoff et al., 1996 ] target the creation of a representation capable of supporting the exchange of process descriptions across different representations. <p> However, no single application exists, or is likely to exist, that supports all aspects. Application inter-operability is then a desired feature of systems supporting business process redesign. The PIF project supports sharing process description through a description format called PIF (Process Interchange Format) <ref> [ Lee et al., 1996 ] </ref> . 130 CHAPTER 2. LITERATURE REVIEW Similar to Ontolingua, PIF provides an interlingua for process representation: tools interoperate by translating between their native representation and PIF. <p> Entity: Everything in the ontology is an entity. An entity is the basic primitive concept, concrete or abstract, that exists in the universe of discourse. Some ontologies refer to this basic concept as a thing or an object. We follow the approach taken by PIF <ref> [ Lee et al., 1996 ] </ref> and the Enterprise Ontology [ Uschold et al., 1996 ] and adopt the entity as our primitive concept. In the current ontology, the term object cannot be used as a synonym for entity.
Reference: [ Leveson, 1997 ] <author> N.G. Leveson. </author> <title> Software engineering: Stretching the limits of complexity. </title> <journal> Communications of the ACM, </journal> <volume> 40(2) </volume> <pages> 129-131, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: Methods and tools for software development often enforce particular problem solving strategies preferred by the method designer. They do not account for the fact that different people have different problem solving strategies, and even that individuals dynamically change their strategies during the same problem solving session <ref> [ Leveson, 1997 ] </ref> . Artificial Intelligence, and not software engineering, is the area of computer science traditionally concerned with cognitive aspects of human problem solving. Initial AI research focused on attempts to make computers perform tasks that usually require human intelligence.
Reference: [ Lowry and McCartney, 1991 ] <author> M. Lowry and R. </author> <title> McCartney, editors. Automating Software Design. </title> <publisher> AAAI Press/The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: A more recent collection, edited by Lowry & McCartney <ref> [ Lowry and McCartney, 1991 ] </ref> , shows a trend in the direction of addressing particular phases of the software life-cycle. The ultimate goal is the complete automation and integration of all phases, from requirements to maintenance.
Reference: [ Lowry et al., 1994 ] <author> M. Lowry, A. Philpot, T. Pressburger, and I. Underwood. </author> <title> A formal approach to domain-oriented software design environments. </title> <booktitle> In The Ninth Knowledge-Based Software Engineering Conference, </booktitle> <pages> pages 48-57, </pages> <address> Monterey, CA, September 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Variations of the approaches discussed above are still the current sate of the practice in more recent systems like Amphion <ref> [ Lowry et al., 1994 ] </ref> and KIDS [ Smith, 1990, Gomes et al., 1996 ] . * Programming by Examples: An alternative representation for program specification is the use of examples of program behavior.
Reference: [ Lubars, 1991 ] <author> M. Lubars. </author> <title> Domain analysis and domain engineering in IDeA. </title> <editor> In R. Prieto-Daz and G Arango, editors, </editor> <booktitle> Domain Analysis and Software Modeling, </booktitle> <pages> pages 163-178. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: LITERATURE REVIEW 2.1.7.5 Lubar's Domain Analysis in IDeA The Intelligent Design Aid, IDeA <ref> [ Lubars, 1991 ] </ref> , is an environment developed to assist software design. The goal of this environment is to promote software reuse at the design level. The reusable artifacts in IDeA are abstract software designs represented as design schemas.
Reference: [ Luckham et al., 1995 ] <author> D.C. Luckham, J.J. Kenney, L.M. Augustin, J. Vera, D. Bryan, and W. Mann. </author> <title> Specification and analysis of system architecture using Rapide. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(4) </volume> <pages> 336-355, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: SOFTWARE REUSE 57 The weakness of this language is the lack of mechanisms to describe component interaction and the absence of means for describing the properties of components and services. (c) Rapide: Specifically designed for prototyping architectures of distributed systems, Rapide <ref> [ Luckham et al., 1995 ] </ref> is described as an event-based, concurrent object-oriented language. <p> To accomplish these goals, WRIGHT extends the basic component-connector notation provided by traditional Architecture Description Languages like UniCon [ Shaw et al., 1995 ] or Rapide <ref> [ Luckham et al., 1995 ] </ref> , with a modified version of the formal notation CSP [ Hoare, 1985 ] .
Reference: [ MacGregor, 1991 ] <author> R. MacGregor. </author> <title> Inside the loom classifier. </title> <journal> SIGART Bulletin, </journal> <volume> 3(2) </volume> <pages> 70-76, </pages> <year> 1991. </year> <note> 494 BIBLIOGRAPHY </note>
Reference-contexts: The next step in the process was to define a structure for the ontology and to describe the concepts using a semi-formal representation. The initial intention was to generate a more formal description of the ontology using some knowledge representation language like Ontolingua [ Gruber, 1992 ] or Loom <ref> [ MacGregor, 1991 ] </ref> . However, after some initial evaluation, we concluded that 1.2. THESIS DESCRIPTION 33 the effort involved in generating this formal representation was not justified. This decision was motivated by the lack of an operational model supporting these languages.
Reference: [ Mackworth, 1977 ] <author> A.K. Mackworth. </author> <title> Consistency in networks of relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8(1) </volume> <pages> 98-118, </pages> <year> 1977. </year>
Reference-contexts: The time-bound propagation is a capability associated to the activity entity. The implementation of the propagator currently available in the library is based on a path-consistency algorithm described in 438 CHAPTER 6. AN APPLICATION FOR PROJECT SCHEDULING <ref> [ Mackworth, 1977 ] </ref> , and has been previously used only for small activity networks. The requirements imposed by the network defined for this domain brought to surface several problems with several aspects of the propagation mechanism that have never been exercised before. <p> Problem 1: Precedence Scheduling The first problem corresponds to the simple initialization of time bounds for all activities in the project. This initialization considers only precedence constraints, and does not check for initial resource availability. The implemented propagation mechanism is a modified version of the path-consistency algorithm described in <ref> [ Mackworth, 1977 ] </ref> . The results are summarized in table 6.1. 458 CHAPTER 6.
Reference: [ Magee et al., 1995 ] <author> J. Magee, N. Dulay, S. Eisenbach, and J. Kramer. </author> <title> Specifying distributed software architectures. </title> <editor> In Wilhelm Schafer and Pere Botella, editors, </editor> <booktitle> Proceedings of the 5th European Software Engineering Conference-ESEC'95, volume 989 of Lecture Notes in Computer Science, </booktitle> <pages> pages 137-153, </pages> <address> Spain, </address> <month> September </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: A particularly interesting aspect of this model is the explicit representation of the three different views of the architecture: processing, data, and connections. (b) Darwin: Focusing on providing sound and practical means for the design and construction of distributed systems, Darwin <ref> [ Magee et al., 1995 ] </ref> is a declarative binding language that supports the specification of both the static and dynamic composition of interconnected components. The central abstractions provided by this language are COMPONENTS and SERVICES. Complex components are defined by the composition of primitive components.
Reference: [ Manna and Waldinger, 1986 ] <author> Z. Manna and R. Waldinger. </author> <title> A deductive approach to program synthesis. </title> <editor> In C. Rich and R.C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 3-34, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: In principle, any method for automatic theorem proof can be used. A proposal for an approach based on automatic theorem proof that combines unification and mathematical induction is presented in <ref> [ Manna and Waldinger, 1986 ] </ref> . There are two fundamental difficulties associated with this approach [ Rich and Waters, 1988, McCartney, 1991 ] . First, the proof procedures are very expensive.
Reference: [ Marcus, 1988 ] <author> S. Marcus. </author> <title> Automatic Knowledge Acquisition for Expert Systems. </title> <publisher> Kluwer Academic, </publisher> <year> 1988. </year>
Reference-contexts: Five types of role-limiting methods have been identified and knowledge-acquisition tools based on each of these methods have been developed <ref> [ Marcus, 1988 ] </ref> . The role-limiting methods are described in terms of the requirements they impose on the characteristics the task must have to use the method.
Reference: [ McCabe et al., 1993 ] <author> R. McCabe, G. Campbell, and N. Burkhard. </author> <title> Reuse-driven software processes guidebook. </title> <type> Technical Report SPC-92019-CMC, Version 02.00.03, </type> <institution> Software Productivity Consortium, </institution> <address> Herndon, Virginia, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: The applications is a family share many common aspects and vary in well-defined ways. By analyzing these applications, a set of domain concepts can be identified. An engineering process for developing applications can then be designed using these domain concepts. In Synthesis <ref> [ McCabe et al., 1993 ] </ref> , domain analysis is part of the domain engineering, the object of which is to produce a process and environment for developing applications in the domain [ Wartik and Prieto-Daz, 1992 ] . During domain implemen 92 CHAPTER 2.
Reference: [ McCain, 1991 ] <author> R. McCain. </author> <title> Reusable software component construction: A product-oriented paradigm. </title> <editor> In R. Prieto-Daz and G Arango, editors, </editor> <booktitle> Domain Analysis and Software Modeling, </booktitle> <pages> pages 70-80. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: In other words, I focus on identifying the meta-ontology used by these techniques. The mechanics of the analysis process is of secondary importance. 2.1.7.1 McCains's Product Oriented Paradigm McCain in <ref> [ McCain, 1991 ] </ref> proposes an approach for developing software components with the objective of maximizing their reuse and minimizing costs associated to component customization. The central task in this approach is domain analysis. 88 CHAPTER 2. LITERATURE REVIEW The process is divided into three tasks: 1.
Reference: [ McCartney, 1991 ] <author> R.D. </author> <title> McCartney. Knowledge-based software engineering: Where we are and where are we going. </title> <editor> In Mike Lowry and Robert McCartney, editors, </editor> <title> Automating Software Design. </title> <publisher> AAAI Press/The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Nevertheless, the technology is progressing. Foundational work on automatic software synthesis has been published in the Artificial Intelligence literature and included in the field of research designated as knowledge-based software engineering (KBSE) <ref> [ McCartney, 1991 ] </ref> . It is clear that all the reuse techniques presented in the previous sections of this chapter have similar, or even the same goals as software synthesis fast 2.1. SOFTWARE REUSE 73 production of high quality software applications. <p> Translation Mechanisms: In the process of automatically generating source code from a high level description language, four main translation mechanisms can be considered: procedure-based, deduction-based, transformation-based, and component-based. Combinations and variations of these approaches can also be identified. A fifth approach that is also considered by some authors <ref> [ McCartney, 1991 ] </ref> is the use of interactive tools that support user guidance during the translation process. This interaction capability does not add any 78 CHAPTER 2. LITERATURE REVIEW new feature in terms of how the underlying translation mechanisms behaves. <p> In principle, any method for automatic theorem proof can be used. A proposal for an approach based on automatic theorem proof that combines unification and mathematical induction is presented in [ Manna and Waldinger, 1986 ] . There are two fundamental difficulties associated with this approach <ref> [ Rich and Waters, 1988, McCartney, 1991 ] </ref> . First, the proof procedures are very expensive. Deduction is basically a problem of searching for an inference path from some initial set of facts to a goal fact. <p> Very high-level languages and transformation systems are the dominant technology in automatic programming <ref> [ McCartney, 1991 ] </ref> . An implementation of a program transformation rule has three parts: a pattern that matches against parts of the program specification, a set of applicability conditions that 2.1.
Reference: [ McDermott, 1988 ] <author> J. McDermott. </author> <title> Preliminary stept towards a taxonomy of problem-solving method. </title> <editor> In S. Marcus, editor, </editor> <title> Automatic Knowledge Acquisition for Expert Systems, </title> <booktitle> chapter 8, </booktitle> <pages> pages 225-266. </pages> <publisher> Kluwer Academic, </publisher> <year> 1988. </year>
Reference-contexts: Clancey's and Chandrasekaran's work can be seen, from an ontology perspective, as the first efforts to define a taxonomy for problem and problem-solving types. Following this initial effort on defining a taxonomy for problem-solving types, McDermott defines a taxonomy based on what he refers to as role-limiting-methods <ref> [ McDermott, 1988 ] </ref> , and Chandrasekaran improve the Generic Task concept into Task Structures [ Chandrasekaran and Johnson, 1993 ] . A comprehensive extension of these classifications is proposed by Puppe in [ Puppe, 1993 ] . <p> Later, McDermott and his group propose a series of special purpose problem-solvers 136 CHAPTER 2. LITERATURE REVIEW based on Role Limiting Methods <ref> [ McDermott, 1988 ] </ref> , and the CommonKADS group in Europe implements a library of problem-solving methods [ Breuker and Van de Velde, 1994 ] indexed by a suite of problem types identified by Breuker [ Breuker, 1994b ] . <p> Task independent methods are also referred to as weak methods, and task specific as strong methods <ref> [ McDermott, 1988 ] </ref> . Chandrasekaran, however, does not subscribe to this separation. In his task-structure framework, methods are all-ways connected to tasks and do not exist independently. <p> A taxonomy of problem-solving methods represents a step towards defining a classification of problem types or tasks. In <ref> [ McDermott, 1988 ] </ref> , problem solving is presented as the identification, selection, and implementation of a sequence of actions that accomplishes some type of problem or task.
Reference: [ McIlroy, 1968 ] <author> M.D. McIlroy. </author> <title> Mass produced software components. </title> <editor> In P.Naur and B. Randall, editors, </editor> <booktitle> Software Engineering: Report on a conference by the NATO Science Committe, </booktitle> <pages> pages 138-150. </pages> <institution> NATO Scientific Affair Division, </institution> <year> 1968. </year>
Reference-contexts: The uniform interactivity for defining models and generating solutions is associated to the concept of mixed-initiative problem 28 CHAPTER 1. INTRODUCTION solving. The concept of reconfigurable architectures can be related to the discipline of software reuse. Software engineering has long been advocating the concept of the software factory <ref> [ McIlroy, 1968 ] </ref> that would allow the construction of software systems from existing reusable building blocks. Despite the appeal of the idea, little has been accomplished and software reusability is still very limited. <p> The idea of complex software systems being built by the combination of existing building blocks or the software factory, dates back to the sixties. The seminal paper in software reuse was presented by McIlroy as an invited paper at the 1968 NATO Software Engineering Conference <ref> [ McIlroy, 1968 ] </ref> . The focus of the conference was the software crisis the problem of building large, reliable software systems in a controlled and cost effective manner.
Reference: [ Medvidovic and Taylor, 1997 ] <author> N. Medvidovic and R.N. Taylor. </author> <title> A framework for classifying and comparing architecture description languages. In Mehdi Jazayeri and Helmut Schauer, edi BIBLIOGRAPHY 495 tors, </title> <booktitle> Proceedings of the Sixth European Software Engineering Conference-ESEC'97, volume 22 of ACM SIGSOFT Software Engineering Notes, </booktitle> <pages> pages 60-76, </pages> <address> Zurich, Switzerland, </address> <month> November </month> <year> 1997. </year> <note> Springer-Verlag. </note>
Reference-contexts: Formal Methods: Several attempts of using formal methods, like Z, or logic-based descriptions, like first-order logic, to characterize architectural styles have been reported in the literature <ref> [ Allen, 1997, Medvidovic and Taylor, 1997 ] </ref> . Although these formal descriptions are very precise and allow a number of different types of analysis, it is not appropriate for most practical uses. First of all, the cost associated with the development of such descriptions is usually high. <p> These languages provide an ontology for describing the structure of software systems in terms of hierarchical configuration of interacting components. ADLs provide a concrete syntax and a conceptual framework for characterizing architectures. The conceptual framework usually subsumes an underlying semantic theory like CSP, Petri Nets, or finite state machines <ref> [ Medvidovic and Taylor, 1997 ] </ref> . A number of ADLs have been proposed for modeling architectures both within a specific application domain or as general purpose modeling languages. Most ADLs are based on the conceptual model proposed by Garlan and Shaw [ Garlan and Shaw, 1994 ] .
Reference: [ Menga et al., 1997 ] <author> G. Menga, D. Brugali, and A. Aaarsten. G++: </author> <title> A pattern language for concurrent and distributed control systems. In Workshop on Object Oriented Methods for Distributed Control Architectures, </title> <address> Albuquerque, NM, </address> <month> April </month> <year> 1997. </year> <booktitle> IEEE International Conference on Robotics and Automation. </booktitle>
Reference: [ Mettala and Graham, 1992 ] <author> E. Mettala and M.H. Graham. </author> <title> The domain-specific software architecture program. </title> <type> Technical Report Special Report CMU/SEI-92-SR-9, </type> <institution> Software Engineering Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA., </address> <month> June </month> <year> 1992. </year>
Reference-contexts: However, the design and implementation of a good architecture is usually difficult and expensive. Replicating this activity across many projects that have similar characteristics may be a waste of resources. The Domain-Specific Software Architecture Program <ref> [ Mettala and Graham, 1992 ] </ref> was a five-year DARPA-sponsored effort started in 1991 that addressed the issue of generating good software architectures for a family of systems. <p> Initial tests showed a 100-fold decrease in the amount of code required to format, validate, and process messages used in the Army Tactical Command and Control System (ATCCS) <ref> [ Mettala and Graham, 1992 ] </ref> . Tracz, based on domain engineering concepts, proposes an engineering process for the generation of a Domain Specific Software Architecture [ Tracz, 1993 ] .
Reference: [ Milner et al., 1992 ] <author> R. Milner, J. Parrow, and D. Walker. </author> <title> A calculus for mobile processes, parts i and ii. </title> <journal> Journal of Information and Computation, </journal> <volume> 100 </volume> <pages> 1-77, </pages> <year> 1992. </year>
Reference-contexts: Composite components are defined by declaring the instances of other components they contain and the BINDINGS between the components. The BINDINGS associate services provided by one components with services provided by another. Darwin modeling language uses Robin Milner's calculus of mobile processes the-calculus <ref> [ Milner et al., 1992 ] </ref> . The -calculus is an elementary calculus for describing and analyzing concurrent systems. A system in this formalism is a collection of independent processes that communicate via channels.
Reference: [ Minton et al., 1992a ] <author> S. Minton, M.D. Johnston, A.B. Philips, and P. Laird. </author> <title> Minimizing conflicts: a heuristic repair method for constraint satisfaction and scheduling problems. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 161-205, </pages> <year> 1992. </year>
Reference-contexts: [ Smith, 1994 ] , SONIA [ Collinot et al., 1988 ] , REDS [ Hadavi et al., 1992 ] , Distributed Asynchronous Scheduler ( DAS ) [ Burke and Prosser, 1989 ] , GERRY ( Zweben's Iterative Repair ) [ Zweben et al., 1992a ] , Minton's Min-Conflicts Heuristic <ref> [ Minton et al., 1992a ] </ref> , Le Pape's Reactive Schedule Model [ Le Pape, 1991 ] . OPIS is the system in which architecture the OZONE class library is based. Several of the representation and algorithms used by OZONE are improved versions of the ones used in OPIS. <p> At the end of each iteration, the cost function is re-evaluated. If the new schedule cost is not better than the previous value, the new solution can be accepted or discarded according to the escape function described before. 2.3.7 Min-Conflicts Heuristic Minton <ref> [ Minton et al., 1992b, Minton et al., 1992a ] </ref> describes a simple heuristic method for solving constraint satisfaction problems. Similar to GERRY's strategy, given an inconsistent set of value assignments for the variables of the problem, that is, a conflicting assignment of operations to 206 CHAPTER 2.
Reference: [ Minton et al., 1992b ] <author> S. Minton, M.D. Johnston, A.B. Philips, and P. Laird. </author> <title> Solving large-scale constraint satisfaction scheduling problems using a heuristic repair method. In Sigman Workshop on Knowledge-Based Production Planning, Scheduling & Control, </title> <address> San Jose, CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: At the end of each iteration, the cost function is re-evaluated. If the new schedule cost is not better than the previous value, the new solution can be accepted or discarded according to the escape function described before. 2.3.7 Min-Conflicts Heuristic Minton <ref> [ Minton et al., 1992b, Minton et al., 1992a ] </ref> describes a simple heuristic method for solving constraint satisfaction problems. Similar to GERRY's strategy, given an inconsistent set of value assignments for the variables of the problem, that is, a conflicting assignment of operations to 206 CHAPTER 2. <p> Several search techniques can be used. The Min-Conflict heuristic was inspired by a neural network developed by Adorf and Johnston for scheduling the Hubble Space Telescope operation. According to Johnston and Adorf <ref> [ Minton et al., 1992b ] </ref> , the Guarded Discrete Stochastic Network performs very well in solving constraint satisfaction problems.
Reference: [ Minton, 1996 ] <author> S. Minton. </author> <title> Automatically configuring constraint satisfaction programs: A case study. Constraints: </title> <journal> An International Journal, </journal> <pages> pages 7-43, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: Artificial intelligence planners like the General Problem Solver [ Newell and Simon, 1963 ] , Prodigy [ Veloso et al., 1995 ] , and SIPE [ Wilkins, 1984 ] , are described as domain independent planner systems. The problem is that generality is at odds with efficiency <ref> [ Minton, 1996 ] </ref> . These systems provide a general, domain-independent, lower-level reasoning mechanism, that solve problems by manipulating a rich representation that encodes all the application domain knowledge needed to solve the problem.
Reference: [ Monroe et al., 1997 ] <author> R.T. Monroe, A. Kompanek, R. Melton, and D. Garlan. </author> <title> Architectural styles, design, patterns, and objects. </title> <journal> IEEE Software, </journal> <pages> pages 43-52, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: Both groups agree that an architectural specification should characterize a system structure in terms of high level computational elements, provide abstractions to describe interactions between components, and allow system's behavior analysis <ref> [ Monroe et al., 1997 ] </ref> . Perry and Wolf motivates the use of architectural descriptions in software design by drawing an analogy with the field of building architecture. <p> An architectural style provides a specialized design language for a specific class of systems [ Monroe 52 CHAPTER 2. LITERATURE REVIEW et al., 1997 ] . Garlan [ Garlan, 1995 ] and Monroe et al. <ref> [ Monroe et al., 1997 ] </ref> list some practical benefits of using architectural styles: (1) it promotes design reuse; (2) it can lead to code reuse; (3) it makes it easier to understand the system's organization; (4) it supports interoperability; (5) by constraining the design space, it permits specialized, style-specific analysis; <p> The first three practical benefits are the main reasons for our interest in architectural styles and descriptions. Besides, styles provide a vocabulary of design elements, and design rules, or topological constraints [ Garlan, 1995 ] , that determine which compositions of those elements are permitted <ref> [ Monroe et al., 1997 ] </ref> . Using our terminology, software architecture provides the ontology for describing system components and configurations. Papers describing actual system implementations usually provide an informal block diagram describing the major architectural components of the system. <p> Diagrams used in OOD usually capture static dependencies between components like definitional and referential relations. The vocabulary provided by traditional OOD notations is not sufficient to describe the complex pattern of interactions between objects, and to determine system properties <ref> [ Monroe et al., 1997 ] </ref> . There are several lines of research trying to extend object-oriented models to support more architecture related terminology. Particularly relevant to the current thesis is the recent development of design patterns. <p> Although a pattern language does not assume, in general, any particular implementation paradigm, most of the research in this area has focused on patterns for Object-Oriented Design. This is motivated by two primary limitation of Object-Oriented techniques that are addressed by the use of Design Patterns: <ref> [ Monroe et al., 1997 ] </ref> : the difficulty in specifying how groups of objects interact, and in specifying and packaging related collections of objects for reuse. In this sense, design patterns and software architectures are closely related technologies.
Reference: [ Moore and Bailin, 1991 ] <author> J. Moore and S. Bailin. </author> <title> Domain analysis: Framework for reuse. </title> <editor> In R. Prieto-Daz and G Arango, editors, </editor> <booktitle> Domain Analysis and Software Modeling, </booktitle> <pages> pages 179-203. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: This definition of feature is actually broader than the ones used by any of the other methods presented. The domain analysis process in KAPTUR is divided into five activities <ref> [ Moore and Bailin, 1991 ] </ref> : 1. Examine existing systems: This activity corresponds to the domain preparation activity proposed in other methods. There is no great emphasis on economic aspect of the analysis.
Reference: [ Morton and Pentico, 1993 ] <author> T.E. Morton and D.W. Pentico. </author> <title> Heuristic Scheduling Systems. </title> <publisher> John Wiley & Sons, Inc, </publisher> <year> 1993. </year> <note> 496 BIBLIOGRAPHY </note>
Reference-contexts: In scheduling, the goal is to produce a feasible sequence of actions and respective temporal resource allocation. Associated to this goal is the concept of objective function. The objective function defines some quantitative metrics the solution should satisfy <ref> [ Morton and Pentico, 1993 ] </ref> . The generic problem solving approach to planning is to successively decompose the goals into sub-goals until it is possible to identify a sequence of actions that would satisfy them. <p> This led to approaches that would produce what Simon calls satisficing solutions [ Simon, 1981a ] . Near-optimal solution techniques include myopic decision-making and heuristic-based reasoning. Myopic techniques are methods that make decisions considering restricted or incomplete information. Under certain situations, myopic solutions can provide very good solutions <ref> [ Morton and Pentico, 1993 ] </ref> . Heuristic reasoning involves making decision based on experience or past knowledge instead of mathematical formulas that can be proved correct.
Reference: [ Muscettola et al., 1992 ] <author> N. Muscettola, S.F. Smith, Cesta A., and D. D'Aloisi. </author> <title> Coordinating space telescope operations within an integrated planning and scheduling framework. </title> <journal> IEEE Control Systems, </journal> <volume> 12(2), </volume> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: REDS deals with issues of real-time execution of previously generated schedules. Iterative Repair and Min-Conflict heuristic are two examples of how general constraint satisfaction mechanisms are adapted to be used in a scheduling architecture. Although some well-known systems like MICRO-BOSS [ Sadeh, 1994 ] , HSTS <ref> [ Muscettola et al., 1992 ] </ref> , and O-PLAN [ Tate et al., 1994 ] have not been included in the current review, we consider that the set of architectures presented is representative enough to constitute the foundation for our domain model. 2.3.2 OPIS OPIS [ Smith, 1989, Smith et al., <p> Several of these efforts have been extensively reviewed in the previous chapter. The ozone scheduling ontology is the result of considerable prior experience in building planning and scheduling systems, in application domains ranging from manufacturing production scheduling [ Smith, 1994 ] to space mission planning <ref> [ Muscettola et al., 1992 ] </ref> to military deployment [ Smith and Lassila, 1994a ] , and aero-medical evacuation planning [ Lassila et al., 1996 ] .
Reference: [ Myers, 1996 ] <author> K.L. Myers. </author> <title> Strategic advice for hierarchical planners. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proceedings of the Fifth International Conference (KR'96). </booktitle> <publisher> Mor-gan Kaufmann Publishers, </publisher> <month> November </month> <year> 1996. </year>
Reference-contexts: Prodigy's meta-operators and Sipe's advisable planner are example of the explicit use of problem-solving knowledge to solve planning problems <ref> [ Perez and Carbonell, 1994, Myers, 1996 ] </ref> In the same line, OR algorithms have very clean and general descriptions. The problem here is their implementation. Algorithms are evaluated based on the solution quality and processing times.
Reference: [ Neighbors, 1981 ] <author> J.M. Neighbors. </author> <title> Software Construction Using Components. </title> <type> PhD thesis, </type> <institution> University of California, Irvine, </institution> <year> 1981. </year>
Reference-contexts: According to Arango and Prieto-Daz [ Arango and Prieto-Daz, 1991 ] , the expression "domain analysis" in the context of software reuse has been first introduced by Neighbors in his Phd Thesis <ref> [ Neighbors, 1981 ] </ref> . In [ Neighbors, 1986 ] , while describing the Draco approach for building software applications, Neighbors proposes the use of a domain language for describing programs in different problem areas. This language is an ontology for describing objects and operations in the domain.
Reference: [ Neighbors, 1986 ] <author> J.M. Neighbors. </author> <title> The Draco approach to constructing software from reusable components. </title> <editor> In C. Rich and R.C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 525-35, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: Based on domain model and symbolic manipulation, this description is then translated into a more complete mathematical description from which algorithm schemas are elaborated. The system is implemented in MATHEMATICA, that is a software package that provides the basic mathematical primitives required by the system. The Draco system <ref> [ Neighbors, 1986 ] </ref> is the only one that advocates the use of a domain 2.1. SOFTWARE REUSE 77 language instead of a wide-spectrum language. According to Neighbors, objects and operations in a domain language represent analysis information about a problem domain. <p> According to Arango and Prieto-Daz [ Arango and Prieto-Daz, 1991 ] , the expression "domain analysis" in the context of software reuse has been first introduced by Neighbors in his Phd Thesis [ Neighbors, 1981 ] . In <ref> [ Neighbors, 1986 ] </ref> , while describing the Draco approach for building software applications, Neighbors proposes the use of a domain language for describing programs in different problem areas. This language is an ontology for describing objects and operations in the domain. <p> This "sandwich" version corresponds to an extension of the basic method presented in [ Prieto-Daz, 1987 ] . Based on Neighbors' original definition of domain analysis <ref> [ Neighbors, 1986 ] </ref> , this method focuses on identifying objects, functions, and relationships. The process establishes four main activities: 1.
Reference: [ Newell and Simon, 1963 ] <author> A. Newell and H.A. Simon. </author> <title> GPS: a program that simulates human thought. In E.A. </title> <editor> Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought, </booktitle> <address> New York, 1963. </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: Three problems we identify with some of these algorithms are: lack or excess of generality, simplified modeling assumptions, and static nature of the solution. Artificial intelligence planners like the General Problem Solver <ref> [ Newell and Simon, 1963 ] </ref> , Prodigy [ Veloso et al., 1995 ] , and SIPE [ Wilkins, 1984 ] , are described as domain independent planner systems. The problem is that generality is at odds with efficiency [ Minton, 1996 ] .
Reference: [ Newell, 1982 ] <author> A. Newell. </author> <title> The knowledge level. </title> <journal> Artificial Intelligence, </journal> <volume> 18(1) </volume> <pages> 87-127, </pages> <year> 1982. </year>
Reference-contexts: This shift in perspective was strongly motivated by Newell's concept of "knowledge-level" representation <ref> [ Newell, 1982 ] </ref> . The "knowledge-level hypothesis" was presented by Newell as an attempt to resolve some confusion related to the usage of terms like knowledge and representation. According to him, this 102 CHAPTER 2.
Reference: [ Nilson et al., 1994 ] <author> R. Nilson, P. Kogut, and G. Jackelen. </author> <title> Component provider's and tool developer's handbook central archive for reusable defense software (CARDS). </title> <type> Technical Report STARS Informal Technical Report STARS-VC-B017/001/00, </type> <institution> Unisys Corporation, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: The goal of a DSSA, as well as the goal of this thesis, is to support the generation of applications within a particular domain. A DSSA is a software architecture based on the actual and projected commonalities and differences of applications in a domain <ref> [ Nilson et al., 1994 ] </ref> . It not only provides a framework for reusable software components to fit into, but also captures the design rationale and provides for some degree of adaptability. Within the DSSA program, three different approaches to architectures have been considered. <p> Others focus on compositional software construction. This section discusses the latter category. A reviews and comparisons of several of these reuse-oriented domain analysis methods is presented in 2.1. SOFTWARE REUSE 85 [ Wartik and Prieto-Daz, 1992 ] , [ Arango, 1994 ] , and <ref> [ Nilson et al., 1994 ] </ref> . These methods provide guidelines on what kind of information we should look for and how to represent it in order to support systematic software reuse. <p> process and methods, it is useful to define more precisely the meaning of some of the keywords used by all methods: Problem Domain: A problem domain or simply a domain can be defined as an area of activity or knowledge containing applications which share a set of capabilities and data <ref> [ Nilson et al., 1994 ] </ref> . <p> From the domain theory perspective it means the process of creating models that would allow reasoning about the domain. From the ontology perspective it means both. In the next paragraph I summarize the relevant domain analysis methods presented in <ref> [ Nilson et al., 1994 ] </ref> , [ Arango, 1994 ] . and [ Wartik and Prieto-Daz, 1992 ] . The emphasis here, as in the previous section, is on identifying the terminology used to describe the structural components of the domain model. <p> Facets are characteristics by which the domain objects can be described <ref> [ Nilson et al., 1994 ] </ref> . Associated to each facet is a set of values defining the possible values for that facet. An example of the use of this classification schema is presented in section 2.1.1. <p> It focus on integrating domain and application engineering into one coherent process. The FODA method centers around the concept of feature, a prominent, user-visible aspect of the system <ref> [ Nilson et al., 1994 ] </ref> . Being user-visible functionalities or properties of a system, the set of features models the user requirements on a class of applications. By classifying features as required, optional, or alternative, domain analysts can identify commonalities and differences between similar applications.
Reference: [ Novick and Sutton, 1997 ] <author> D.G. Novick and S. Sutton. </author> <title> What is mixed-initiative interaction. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Computational Models for Mixed Initiative In-tercation, </booktitle> <pages> pages 114-116, </pages> <address> Palo Alto, CA., </address> <month> April </month> <year> 1997. </year>
Reference-contexts: The user cognitive process should also be accounted for during the system design in order to provide the appropriate interfaces and procedures [ Cacciabue, 1997 ] . AI systems that support this kind of co-operation between different agents will be referred as mixed-initiative systems <ref> [ Novick and Sutton, 1997 ] </ref> . Some examples of systems implementing mixed-initiative problem solving can be found in the planning, and scheduling literature [ Prietula et al., 1994, Ferguson et al., 1996, Smith et al., 1996b ] . <p> Work on heuristics for incremental scheduling repair has provided a collection of methods for minimally disrupting an existing solution during plan revision. Solution visibility through the use of graphic tools, and interactive approaches like mixed-initiative problem solving <ref> [ Novick and Sutton, 1997 ] </ref> addresses the issues related to the understanding, manipulation, and improvement of the solution generated. The access to the specifics of the problem solving mechanism is still very restricted and few applications provide manipulation capabilities at that level.
Reference: [ Noy and Hafner, 1997 ] <author> N.F. Noy and C.D. Hafner. </author> <title> The state of the art in ontology design: A comparative review. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Ontological Engineering, </booktitle> <pages> pages 84-94, </pages> <address> Palo Alto, CA, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: The role of ontologies in systems engineering, domain analysis, and software reuse has already been discussed in previous sections. Considering the specific purpose for which the ontology has been created, Noy & Hafner <ref> [ Noy and Hafner, 1997 ] </ref> provide a more application oriented view of the motivations behind ontology research. In their study, they reviewed ten representative ontology projects. The selection criteria for the projects were ontology size, level of documentation and implementation, and relevance of the domain modeled.
Reference: [ Pease and Carrico, 1997 ] <author> R.A. </author> <title> Pease and T.M. Carrico. JFT ATD core plan representation. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Ontological Engineering, </booktitle> <pages> pages 95-99, </pages> <address> Palo Alto, CA, </address> <month> April </month> <year> 1997. </year> <note> BIBLIOGRAPHY 497 </note>
Reference-contexts: Furthermore, a scheduling system can be, and usually is, a sub-component of any application developed for these domains. To integrate and inter-operate with different applications in these domains, the scheduling system has to at least commit to a shared ontology. In the AI planning domain, the Core Plan Representation <ref> [ Pease and Carrico, 1997 ] </ref> , Tate's Plan Ontology based on the IN-OVA Model [ Tate, 1996b, Tate, 1996a ] , and the Shared Planning and Activity Representation [ Tate, 1997 ] are examples of attempts to define an ontology to promote a unified representation for planning systems. <p> According to Pease and Carrico, one of the identified areas where CPR can be of immediate utility is scheduling: CPR enables the creation of generic scheduling tools which eliminate the need to build these tools from scratch each time a new scheduling domain is targeted <ref> [ Pease and Carrico, 1997 ] </ref> . The interesting aspect of CPR is that it tries to define a planning ontology at the "basic level," the level at which humans associate the largest amount of information, and at which terms are used in neutral contexts.
Reference: [ Perez and Carbonell, 1994 ] <author> M.A. Perez and J.G. Carbonell. </author> <title> Control knowledge to improve plan quality. </title> <booktitle> In Proceedings of the Second International Conference on AI Planning Systems, </booktitle> <address> Chicago, IL., </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Prodigy's meta-operators and Sipe's advisable planner are example of the explicit use of problem-solving knowledge to solve planning problems <ref> [ Perez and Carbonell, 1994, Myers, 1996 ] </ref> In the same line, OR algorithms have very clean and general descriptions. The problem here is their implementation. Algorithms are evaluated based on the solution quality and processing times.
Reference: [ Perry and Wolf, 1992 ] <author> D.E. Perry and A.L. Wolf. </author> <title> Foundations for the study of software architecture. </title> <booktitle> ACM SIGSOFT Software Engineering Notes, </booktitle> <volume> 17(4) </volume> <pages> 40-52, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: The conceptual foundations of software architecture as a major discipline in the field of software engineering was established by Shaw and Garlan [ Shaw, 1989, Garlan and Shaw, 1994 ] , and Perry and Wolf <ref> [ Perry and Wolf, 1992 ] </ref> . While the latter group is concerned with establishing a generic foundation, or a conceptual framework, for a discipline of software architecture, the former focuses on identifying, describing, and analyzing different architectural styles using the same set of abstractions. <p> SOFTWARE REUSE 55 Languages from traditional programming languages, MILs, IDLs, formal methods, and OO languages. The ontology used in this thesis to describe system configuration is based on the idioms provided by the ADLs reviewed in this section: (a) Perry & Wolf Model: Although Perry & Wolf's model <ref> [ Perry and Wolf, 1992 ] </ref> does not constitute an implemented ADL, it provides some idioms for describing software architectures. For this reason this model is also include in our description of relevant ADLs. <p> The model is based on the concepts of traditional building architecture that defines the concept of architecture as "a unifying or coherent form of structure" <ref> [ Perry and Wolf, 1992 ] </ref> . A software architecture is a set of architectural elements that have a particular form, and a rationale to justify the choice of elements and form. In accordance with this definition, this model is characterized by three first level entities: i.
Reference: [ Peterson and J.L. Stanley, 1994 ] <author> A.S. Peterson and J.L. J.L. Stanley. </author> <title> Mapping a domain model and architecture to a generic design. </title> <type> Technical Report SEI-94-TR-08, </type> <institution> Software Engineering Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA., </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The method tries to cover all phases from domain preparation to architectural modeling. However, the transition from the domain models produced by the analysis activities to architecture design and implementation is not very well defined. A first attempt to formalize this translation is described in <ref> [ Peterson and J.L. Stanley, 1994 ] </ref> , but the process presented is too architecture dependent. The Model Based Software Engineering (MBSE) project at the Software Engineering Institute [ Whithey, 1994 ] is a more recent effort aimed at overcoming this deficiency of this method.
Reference: [ Pfleeger, 1991 ] <author> S. H. Pfleeger. </author> <title> Software Engineering: The Production of Software Quality. </title> <publisher> Macmil-lan Publishing Co., </publisher> <address> 2nd edition, </address> <year> 1991. </year>
Reference-contexts: The output solution 10 CHAPTER 1. INTRODUCTION quality or solution related qualities are not good measures for implementation quality. The system that generates the best solution output is not necessarily the best implemented system. Software quality is a concept hard to define. According to Pfeegler <ref> [ Pfleeger, 1991 ] </ref> software quality depends on who is analyzing the software. According to her, "users judge software to be of high quality if it does what they want in a way that is easy to learn and easy to use. <p> These aspects are also relative ill defined and hard to quantify. Metrics for their estimation have been proposed in the software engineering literature <ref> [ Pfleeger, 1991 ] </ref> and provide little guidance on really accessing software quality. 1.1.1 The Planning and Scheduling Problem The execution of most human everyday activities follow a sequence of actions, or a plan; use some kind of resource; and have a certain temporal dimension, a schedule.
Reference: [ Pree, 1995 ] <author> W. Pree. </author> <title> Design patterns for object-oriented software development. </title> <publisher> Addison-Wesley Pub. Co., </publisher> <address> Wokingham, England ; Reading, Mass., </address> <year> 1995. </year>
Reference-contexts: The set of abstract classes and the interface between them constitute the basis of the framework <ref> [ Pree, 1995 ] </ref> . An abstract class is a class that cannot be instantiated, that is, no objects of this class can exist; it is used as a template for creating subclasses. Abstract classes usually provide no implementation for some, or all, of their operations.
Reference: [ Prieto-Daz and Freeman, 1987 ] <author> R. Prieto-Daz and P. Freeman. </author> <title> Classifying software for reusability. </title> <journal> IEEE Software, </journal> <volume> 4(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: These abstract descriptions, or schemas, correspond to program templates that are instantiated to generate source code. Abstraction representations and descriptions for the schemas is one of the major challenges to schema developers. As an example of a classification schema, Prieto-Daz provides one based on his faceted domain analysis technique <ref> [ Prieto-Daz and Freeman, 1987 ] </ref> : Functionality: describes the function the component is intended to perform. <p> Specification and Implementation of Reusable Resources: Each identified abstraction should be implemented following the recommendations generated during the component domain analysis phase. 2.1.7.2 Prieto-Daz's Domain Analysis for Reusability This approach, also called Domain Analysis for Faceted Classification <ref> [ Prieto-Daz and Freeman, 1987 ] </ref> , is based on library science classification schemas and system analysis methods; it is strongly influenced by the desire of representing a domain model as a collection of components organized according to a faceted classification scheme.
Reference: [ Prieto-Daz, 1987 ] <author> R. Prieto-Daz. </author> <title> Domain analysis for reusability. </title> <booktitle> In Proceedings of COMPSAC 87, </booktitle> <pages> pages 23-29, </pages> <address> Tokyo, Japan, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: SOFTWARE REUSE 89 This method is described in [ Wartik and Prieto-Daz, 1992 ] as "sandwich" approach where bottom-up activities are supported by the classification process, and top-down activities are supported by system analysis methods. This "sandwich" version corresponds to an extension of the basic method presented in <ref> [ Prieto-Daz, 1987 ] </ref> . Based on Neighbors' original definition of domain analysis [ Neighbors, 1986 ] , this method focuses on identifying objects, functions, and relationships. The process establishes four main activities: 1.
Reference: [ Prieto-Daz, 1993 ] <author> R. Prieto-Daz. </author> <title> Status report: </title> <booktitle> Software reusability. IEEE Software, </booktitle> <pages> pages 61-66, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Only in the late eighties, the definition of reuse was broadened to include more than simply source code fragments, but also design structures, module-level implementation structure, specifications, documentation, transformations, and even the knowledge involved in developing the system or components <ref> [ Prieto-Daz, 1993 ] </ref> . More recent work tries to integrate not only technical but also nontechnical factors like management, economics, culture, and law, into the idea of institutionalized reuse. <p> The system developer only works with the higher level language that is highly domain dependent. Software architectures can be used as either standalone application generators to create end-user applications or as building blocks for creating higher level architectures. Prieto-Daz <ref> [ Prieto-Daz, 1993 ] </ref> provides a more complete classification that includes other perspectives of reuse besides the artifact being reused. He views software reuse according to six different perspectives or facets: 1. By-Substance: defines the essence or the nature of the entity being reused.
Reference: [ Prietula et al., 1994 ] <author> M.J. Prietula, W.L. Hsu, P.S. Ow, and G.L. Thompson. MACMERL: </author> <title> Mixed-initiative scheduling with coincident problem spaces. </title> <editor> In M. Zweben and M.S. Fox, editors, </editor> <title> Intelligent Scheduling, </title> <booktitle> chapter 23, </booktitle> <pages> pages 655-682. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA., </address> <year> 1994. </year>
Reference: [ Prywes and Lock, 1989 ] <author> N.S. Prywes and E.D. </author> <title> Lock. Use of the model equational language and program generator by management professionals. </title> <editor> In T.J. Biggerstaff and A.J. Perlis, editors, </editor> <title> Frontier Series: Software Reusability: </title> <journal> Volume II-Applications and Experience, </journal> <volume> chapter 5, </volume> <pages> pages 103-129. </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Examples of VHLLs are languages that implement set theoretical abstractions like SETL [ Krutchen et al., 1984 ] and PAISLey [ Zave and Schell, 1986 ] , or declarative constraint-based languages like MODEL <ref> [ Prywes and Lock, 1989 ] </ref> . Problems with this approach are poor run-time performance and the difficulty associated to using high-level mathematical abstractions.
Reference: [ Puppe, 1993 ] <author> F. Puppe. </author> <title> Systematic Introduction to Expert Systems, Knowledge Representations and Problem Solving Methods. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <note> 498 BIBLIOGRAPHY </note>
Reference-contexts: A comprehensive extension of these classifications is proposed by Puppe in <ref> [ Puppe, 1993 ] </ref> . The separation between problem-solving and domain has been further elaborated and refined by Steels' concept of Components of Expertise [ Steels, 1990 ] and CommonKADS expertise models already described [ Wielinga et al., 1992, Wielinga et al., 1994 ] . <p> An extensive and well structured classification of problem-solving methods, based on the research previously mentioned, can be found in <ref> [ Puppe, 1993 ] </ref> . <p> In practice however, a toolkit composed of only six generic tasks has not proved very useful in many practical applications <ref> [ Puppe, 1993 ] </ref> . In answer to several criticisms raised by the AI community to his approach, Chandrasekaran extended the concept of Generic Tasks into a framework called Task Structure [ Chandrasekaran and Johnson, 1993 ] . <p> Figure 2.2 summarizes Puppe's method classification. 150 CHAPTER 2. LITERATURE REVIEW (source <ref> [ Puppe, 1993 ] </ref> ) In [ Puppe, 1993 ] , for each type of problem-solving method, a brief description of the characteristics of the domain for which the method would be appropriate as well as the requirements the method imposes on knowledge representation is provided. <p> Figure 2.2 summarizes Puppe's method classification. 150 CHAPTER 2. LITERATURE REVIEW (source <ref> [ Puppe, 1993 ] </ref> ) In [ Puppe, 1993 ] , for each type of problem-solving method, a brief description of the characteristics of the domain for which the method would be appropriate as well as the requirements the method imposes on knowledge representation is provided. <p> Sundin describes the method in the context of the CommonKADS library of reusable problem-solving components [ Breuker and Van de Velde, 1994 ] . Puppe also discusses a problem-solving method for the assignment problem in <ref> [ Puppe, 1993 ] </ref> . More concerned with the lower level details of implementing the method, Puppe discusses a specialization of the propose & revise called propose & exchange that, according to him, is more appropriate for assignment problem than the basic propose & revise . <p> In Chapter 2, section 2.2.3.2, several classifications and ontologies for describing problem-solving knowledge have been presented. The scheduling problem is usually considered to belong to the class of assignment problems <ref> [ Puppe, 1993 ] </ref> [ Sundin, 1994 ] . However, in a mixed-initiative, reactive problem-solving environment, this classification is too restrictive.
Reference: [ Rich and Knight, 1993 ] <author> E. Rich and K. Knight. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> Mc Graw Hill Inc., </publisher> <address> 2nd edition, </address> <year> 1993. </year>
Reference-contexts: These models incorporates knowledge about the constraints and objectives that affect the behavior of the actual system. 16 CHAPTER 1. INTRODUCTION Constraint satisfaction is an example of a search techniques that reduces substantially the amount of search required to generate a solution <ref> [ Rich and Knight, 1993 ] </ref> . and is also one of the techniques widely used in implemented knowledge-based scheduling systems [ Smith, 1992a ] . <p> I am using expressive power in a loose sense. It can mean different things in different contexts. For example, for a knowledge representation application, the expressive power of a representation would be characterized by properties like representational adequacy, inferential adequacy, inferential efficiency, and acquisional efficiency <ref> [ Rich and Knight, 1993 ] </ref> . From a system development perspective, given the multitude of models generated, important aspects include how to move from one model to the next in the process, and how to represent the same concepts in different models.
Reference: [ Rich and Waters, 1986a ] <author> C. Rich and R.C. Waters. </author> <title> Introduction. </title> <editor> In C. Rich and R.C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, pages xi-xxii, </booktitle> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: To overcome this problem, researchers tried to separate natural languages processing from informality issues. The focus of research has then shifted towards more formal language where a certain level of semantic informality is allowed <ref> [ Rich and Waters, 1986a ] </ref> . These languages are called Very High Level Languages. * Logical Formalisms: First Order Logic and other logic formalisms are very general, precise, and powerful formal description languages. <p> What is needed is a program that operates on whole classes of input data in a similar manner. As the problem becomes more complex, the number of possible generalizations grows astronomically <ref> [ Rich and Waters, 1986a ] </ref> , affecting the practicality of this approach. 2. Translation Mechanisms: In the process of automatically generating source code from a high level description language, four main translation mechanisms can be considered: procedure-based, deduction-based, transformation-based, and component-based. <p> SOFTWARE REUSE 79 are logical sentences that further constrains the transformation, and a procedural action that is evaluated to generate code to substitute the specification pattern. Two types of transformations are identified <ref> [ Rich and Waters, 1986a ] </ref> : vertical transformations, that map construct at one level of abstraction into constructs at a lower level of abstraction, and lateral transformations, that perform only optimizations, mapping constructs into more efficient implementations.
Reference: [ Rich and Waters, 1986b ] <editor> Charles Rich and Richard C. Waters, editors. </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: That they are "software environments" means they are intended to provide automated support to the entire software life-cycle [ Smith et al., 1985 ] . The collection of papers on Artificial Intelligence and Software Engineering edited by Charles Rich & Richard Waters <ref> [ Rich and Waters, 1986b ] </ref> and the November 1985 special edition of IEEE Transactions on Software Engineering on the same topic cover several of the initial approaches to automating software generation.
Reference: [ Rich and Waters, 1988 ] <author> C. Rich and R.C. Waters. </author> <title> Automatic programming: Myths and prospects. </title> <journal> Computer, </journal> <volume> 21(8) </volume> <pages> 40-51, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Although this thesis does not make any claims on completely automatic application synthesis, automatic programming corresponds to the first concrete link between Software Engineering and Artificial Intelligence. The idea of automatic synthesizing code is not new. It has been around since the first programmer faced the difficulties of programming <ref> [ Rich and Waters, 1988 ] </ref> . Earlier assemblers and compilers were the first examples of practical use of code synthesizers. However, progress in achieving the full promise of complete automated, general purpose, end-user oriented software-synthesizers has been slow [ Setliff et al., 1993 ] . <p> <ref> [ Rich and Waters, 1988 ] </ref> . Earlier assemblers and compilers were the first examples of practical use of code synthesizers. However, progress in achieving the full promise of complete automated, general purpose, end-user oriented software-synthesizers has been slow [ Setliff et al., 1993 ] . Rich and Waters in [ Rich and Waters, 1988 ] claim that such an ambitious goal is maybe unachievable given the faulty assumptions on which they are based. <p> LITERATURE REVIEW ing a complete implementation is the ultimate goal in automatic programming. Vocabulary, informality and syntax are the three features that makes natural language very attractive <ref> [ Rich and Waters, 1988 ] </ref> . Early works [ Heirdon, 1986 ] , however, has shown that one of these characteristics, informality, is a very difficult aspect of using natural language as a specification language. To overcome this problem, researchers tried to separate natural languages processing from informality issues. <p> It assumes a general problem solving mechanism, a theorem prover, capable of executing a logic specification. Two main problems with this approach are, first, logical notations are usually hard for most people to read and understand, second, some interesting problems in logical systems are computationally intractable <ref> [ Rich and Waters, 1988 ] </ref> . More details on how systems based on logic formalisms work is provided in the paragraph that addresses translation mechanisms. * Very High Level Languages: This has been the focus of the research on representation formalisms for automatic programming. <p> The program produced has to be more general than strictly implied by the examples given. It is trivial, but useless, to construct a problem that duplicates a particular set of examples and does nothing else <ref> [ Rich and Waters, 1988 ] </ref> . What is needed is a program that operates on whole classes of input data in a similar manner. <p> size of the procedural program increases, the more difficult it is to modify and maintain the code. * Deduction-Based Methods: This approach is based on the idea that the problem of synthesizing a program satisfying a certain specification is formally equivalent to finding a constructive proof of the specifications satisfiability <ref> [ Rich and Waters, 1988 ] </ref> . Each step in the construction of the proof for the theorem described by the program specification can be interpreted as a computational step. In principle, any method for automatic theorem proof can be used. <p> In principle, any method for automatic theorem proof can be used. A proposal for an approach based on automatic theorem proof that combines unification and mathematical induction is presented in [ Manna and Waldinger, 1986 ] . There are two fundamental difficulties associated with this approach <ref> [ Rich and Waters, 1988, McCartney, 1991 ] </ref> . First, the proof procedures are very expensive. Deduction is basically a problem of searching for an inference path from some initial set of facts to a goal fact. <p> Application generators based on a library of patterns, like the Pattern Based Simulator Generator (PSiGene) [ Schuetze et al., 1997 ] , are typical examples. Rich and Waters refer to these approaches as Inspection Methods <ref> [ Rich and Waters, 1988 ] </ref> . According to them, human programmers seldom think in terms of primitive elements like assignments and tests. Rather, they think in terms of cliched combinations of elements corresponding to familiar concepts.
Reference: [ Sadeh and Kott, 1996 ] <author> N. Sadeh and A. </author> <title> Kott. Models and techniuqes for dynamic demand responsive transportation planning. </title> <type> Technical Report CMU-RI-TR-96-09, </type> <institution> The Robotics Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1996. </year>
Reference-contexts: In the next sections we present an ontology for the aeromedical evacuation problem, and describe in more details the extensions and customizations implemented during the development of this prototype. 5.1 The Aeromedical Evacuation Problem A brief description of the Aeromedical Evacuation Problem is provided in <ref> [ Sadeh and Kott, 1996 ] </ref> . A more detailed description of how USTRANSCOM handles evacuation of patients can be found in [ Joint-Pub-4-02.2, 1996 ] . The ontology presented is based on this last document. <p> Problem is provided in <ref> [ Sadeh and Kott, 1996 ] </ref> . A more detailed description of how USTRANSCOM handles evacuation of patients can be found in [ Joint-Pub-4-02.2, 1996 ] . The ontology presented is based on this last document. The medical evacuation problem is described by Sadeh & Kott [ Sadeh and Kott, 1996 ] as a "Dynamic Dial-a-Ride Problem with Multiple Acceptable Destinations and/or Origins" (D-DARP-MADO.) The traditional dial-a-ride problem is a vehicle-routing problem where entities should be picked up at a certain location and delivered to a different location, such that the pick up occurs before the delivery.
Reference: [ Sadeh, 1994 ] <editor> N. Sadeh. Micro-opportunistic schedule. In M. Zweben and M. Fox, editors, </editor> <title> Intelligent Scheduling, chapter 4. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1994. </year>
Reference-contexts: REDS deals with issues of real-time execution of previously generated schedules. Iterative Repair and Min-Conflict heuristic are two examples of how general constraint satisfaction mechanisms are adapted to be used in a scheduling architecture. Although some well-known systems like MICRO-BOSS <ref> [ Sadeh, 1994 ] </ref> , HSTS [ Muscettola et al., 1992 ] , and O-PLAN [ Tate et al., 1994 ] have not been included in the current review, we consider that the set of architectures presented is representative enough to constitute the foundation for our domain model. 2.3.2 OPIS OPIS
Reference: [ Schlenoff et al., 1996 ] <author> C. Schlenoff, A. Knutilla, and S. Ray. </author> <title> Unified process language: Requirements for modeling process. </title> <type> Technical Report NISTIR-5910, </type> <institution> National Institute of Standards and Technology, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: With similar goals, the Process Interchange Format [ Lee et al., 1996 ] and the emerging NIST's effort to create a Unified Process Specification Language <ref> [ Schlenoff et al., 1996 ] </ref> target the creation of a representation capable of supporting the exchange of process descriptions across different representations. A brief summary and main concepts defined in these ontologies is presented in the next sub-section. <p> The NIST Process Specification Language project has goals similar to PIF's: the creation of a process specification language that can be common to all manufacturing applications, generic enough to be decoupled from any application, and robust enough to be able to represent the necessary process information for any given application. <ref> [ Schlenoff et al., 1996 ] </ref> . As the writing of this thesis, a requirement document for modeling process was the only PSL reference available.
Reference: [ Schonberg et al., 1986 ] <author> E. Schonberg, J. Scwartz, and M Sharir. </author> <title> An automatic technique for selection of data representationa in SETL programs. </title> <editor> In Charles Rich and Richard C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 235-243, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: Very high level languages add powerful abstract data types to conventional programming languages. According to Schonberg et al. <ref> [ Schonberg et al., 1986 ] </ref> a language of high level should provide high level abstract objects and operations between them, high level control structures, and the ability to select data representation in an easy and flexible manner. <p> The favored technique is the use of program transformation systems that provide a library of refinements, or rules, on how to translate these high-level constructs into more tractable expressions. Advice is then required to select the refinements to be applied. Some examples of very high-level languages are SETL <ref> [ Krutchen et al., 1984, Schonberg et al., 1986 ] </ref> , Gist, [ Balzer, 1985 ] , V [ Smith et al., 1985 ] , and Refine [ Smith et al., 1985 ] . <p> To deal with efficiency issues, a declaration language is provided that allows the programmer to specify, at a lower level of abstraction, how to efficiently implement certain abstractions <ref> [ Schonberg et al., 1986 ] </ref> . Languages that have the capability of representing high-level and low-level constructs are called wide-spectrum language [ Smith et al., 1985 ] .
Reference: [ Schreiber et al., 1994 ] <author> G. Schreiber, B. Wielinga, H. Akkermans, W. Van de Velde, and Anjew-ierden. </author> <title> CML: The CommonKADS conceptual modeling language. </title> <editor> In L. Steels, G. Schreiber, and W. Van de Velde, editors, </editor> <title> A Future for Knowledge Acqusition, </title> <booktitle> 8th European Knowlwdge Acquisition Workshop, EKAW'94, number 867 in Lectures Notes in Artificial Intelligence, </booktitle> <pages> pages 1-25, </pages> <address> Hoegaarden, Belgium, </address> <month> September </month> <year> 1994. </year> <note> Springer-Verlag. BIBLIOGRAPHY 499 </note>
Reference-contexts: Ontologies written in this format are then translated into the different executable representations used by different problem-solving agents. The Knowledge Interchange Format (KIF) [ Genesereth and Fikes, 1991 ] , On-tolingua [ Gruber, 1992 ] , and the Conceptual Modeling Language (CML) <ref> [ Wielinga et al., 1992, Schreiber et al., 1994 ] </ref> are examples of formalisms that implement this approach. Being an ontology, or meta-ontology, for defining ontologies, these languages provide a vocabulary and a certain structure for representing ontologies. <p> For practical purposes, the Frame Ontology can be considered as being part of the Ontolingua representation language. Other theories describing for example basic mathematical concepts, time, and physical measurement [ Gruber and G.R., 1994 ] are also available. 2.2.2.3 Conceptual Modeling Language As described in <ref> [ Schreiber et al., 1994 ] </ref> , the Conceptual Modeling Language is a highly structured, semi-formal notation. It was developed for the specification of CommonKADS [ Wielinga et al., 1992 ] expertise models. It has neither an operational nor a formal semantics specified.
Reference: [ Schuetze et al., 1997 ] <author> M. Schuetze, J.P. Riegel, and G. Zimmerman. </author> <title> A pattern-based application generator for building simulation. </title> <journal> ACM Sigsoft-Software Engineering Notes, </journal> <volume> 22(6) </volume> <pages> 468-82, </pages> <month> November </month> <year> 1997. </year>
Reference-contexts: Application generators based on a library of patterns, like the Pattern Based Simulator Generator (PSiGene) <ref> [ Schuetze et al., 1997 ] </ref> , are typical examples. Rich and Waters refer to these approaches as Inspection Methods [ Rich and Waters, 1988 ] . According to them, human programmers seldom think in terms of primitive elements like assignments and tests.
Reference: [ Setliff et al., 1993 ] <author> D. Setliff, E. Kant, and T. Cain. </author> <title> Practical software synthesis. </title> <journal> IEEE Software, </journal> <pages> pages 6-10, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Earlier assemblers and compilers were the first examples of practical use of code synthesizers. However, progress in achieving the full promise of complete automated, general purpose, end-user oriented software-synthesizers has been slow <ref> [ Setliff et al., 1993 ] </ref> . Rich and Waters in [ Rich and Waters, 1988 ] claim that such an ambitious goal is maybe unachievable given the faulty assumptions on which they are based. <p> P++ is the language for describing system specifications using GenVoca generators. Transformational systems like KIDS [ Smith, 1990 ] can simulate the components behavior by defining a library of domain theories. These libraries describe the application's underlying properties <ref> [ Setliff et al., 1993 ] </ref> . However, building these domain theories requires a deep understanding of both the domain and the details of the transformation process. * Interactive Systems: No matter what translation method is used, complete automated software synthesis is still an unreachable goal.
Reference: [ S.F. Smith et al., 1990 ] <author> S.F. S.F. Smith, N. Keng, and K. Kempf. </author> <title> Exploiting local flexibility during execution of pre-computed schedules. </title> <type> Technical Report CMU-RI-TR-90-13, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: The objective is to minimize the number of future conflicts. 2.3.8 Le Pape's Reactive Architecture Le Pape [ Le Pape, 1991 ] describes a system that is a constraint propagation based implementation of the ideas presented by Smith in <ref> [ S.F. Smith et al., 1990 ] </ref> . Smith presents a scheduling framework where decision-making responsibility is shared between a global scheduler and a local dispatcher and Le Pape designs a protocol to implement the interface for solving the problem of non-interference between the local dispatcher and the global scheduler. <p> The sets under the responsibility of the global dispatcher are 1 : 1 The original set names given by Smith in <ref> [ S.F. Smith et al., 1990 ] </ref> are changed for convenience. 210 CHAPTER 2. LITERATURE REVIEW Unscheduled: initial set of Schedule Objects created in response to production or maintenance requests. <p> In this case, the local dispatcher will have to appeal to the global scheduler to perform a repair. This aspect of the reaction was left unspecified by Smith <ref> [ S.F. Smith et al., 1990 ] </ref> and a possible approach to its 2.3. KNOWLEDGE-BASED SCHEDULING ARCHITECTURES 215 implementation, although incomplete, is described by Le Pape [ Le Pape, 1991 ] . It is not difficult however to imagine a system like OPIS or SONIA operating as global schedulers.
Reference: [ Shadbolt et al., 1996 ] <editor> Nigel Shadbolt, Guus Schreiber, and Kieron O'Hara, editors. </editor> <booktitle> Advances in Knowledge Acquisition, Ninth European Knowledge Acquisition Workshop, volume 1076 of Lectures Notes in Artificial Intelligence, </booktitle> <address> United Kingdom, </address> <month> May </month> <year> 1996. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: Recent approaches have focused more on understanding the structure of the domains, and on the reuse of this knowledge <ref> [ Shadbolt et al., 1996 ] </ref> . In the AI community, this new trend is reflected in the current effort on ontologies as a means of describing reusable knowledge models.
Reference: [ Shaw and Garlan, 1994 ] <author> M. Shaw and D. Garlan. </author> <title> Characteristics of high-level languages for software architecture. </title> <type> Technical Report CMU/SEI-94-TR-23, </type> <institution> School of Computer Science and Software Engineering Institute , Carnegie Mellon University, </institution> <address> Pittsburgh, PA., </address> <month> December </month> <year> 1994. </year>
Reference-contexts: The tradeoff here is between the effort required to generate these large components and the gains obtained in the creation of new applications. 2.1.2 Software Architecture According to Garlan and Shaw <ref> [ Garlan and Shaw, 1994, Shaw and Garlan, 1994 ] </ref> , as the size and complexity of software systems increase, the design and specification of overall system structure 2.1. SOFTWARE REUSE 51 become a more significant issue than the choice of algorithms and data structure. <p> The rationale behind modularization is to reduce complexity by decomposing the system into modules that explicitly define their interface. This interface correspond to low level computational entities that are "exported" or "imported" by the module. Shaw and Garlan <ref> [ Shaw and Garlan, 1994 ] </ref> argue that the high-level programming languages currently available do not provide the semantic entities and the abstraction level required to describe system's architecture. <p> High-level specifications are successively refined until an executable description is obtained. Interconnection Languages in general, support only low-level interactions and do not provide a fully general way of describing reusable patterns of composition between components <ref> [ Shaw and Garlan, 1994 ] </ref> . 3. Formal Methods: Several attempts of using formal methods, like Z, or logic-based descriptions, like first-order logic, to characterize architectural styles have been reported in the literature [ Allen, 1997, Medvidovic and Taylor, 1997 ] .
Reference: [ Shaw et al., 1995 ] <author> M. Shaw, R. DeLine, D.V. Klein, T.L. Ross, D.M. Young, and G. Zelesnik. </author> <title> Abstractions for software architecture and tools to support them. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(4) </volume> <pages> 314-335, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: A similar division is used to present the ontology that is the subject of this thesis. (d) UniCon: Based on the component-connection paradigm, UniCon <ref> [ Shaw et al., 1995 ] </ref> is a general purpose architectural description language that aims at supporting architectural abstractions, localizing and codifying the ways components interact, and distinguish among the various packagings of components that require different forms of interaction. <p> A rich ontology for describing components, connectors, and their properties is provided in <ref> [ Shaw et al., 1995 ] </ref> and summarized here: 2.1. SOFTWARE REUSE 59 * COMPONENT: represent the locus of computation and state. The COMPO NENT defines the computational capability. The specification of a COMPONENT in UniCon has two parts: i. <p> To accomplish these goals, WRIGHT extends the basic component-connector notation provided by traditional Architecture Description Languages like UniCon <ref> [ Shaw et al., 1995 ] </ref> or Rapide [ Luckham et al., 1995 ] , with a modified version of the formal notation CSP [ Hoare, 1985 ] . <p> Figure 3.2 is a schematic view of how the main components in ozone software architecture ontology relate to each other. 3.3. THE OZONE SOFTWARE ARCHITECTURE ONTOLOGY 233 3.3.1 COMPONENT 3.3.1.1 Concept Definition Architectural Description Languages like ACME [ Garlan et al., 1997 ] , UniCon <ref> [ Shaw et al., 1995 ] </ref> , and Wright [ Allen, 1997 ] define a component to be the primary computational element and data store of the system that provides a localized, independent functional capability to the system.
Reference: [ Shaw, 1989 ] <author> M. Shaw. </author> <title> Large scale systems require higher level abstractions. </title> <booktitle> In Proceedings of the Fifth Intrnational Workshop on Software Specification and Design, volume 14 of ACM Sigsoft Notes, </booktitle> <pages> pages 143-146, </pages> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: The software architecture discipline deals with what is called architectural styles and how these styles affect system properties [ Shaw, 1995 ] . The conceptual foundations of software architecture as a major discipline in the field of software engineering was established by Shaw and Garlan <ref> [ Shaw, 1989, Garlan and Shaw, 1994 ] </ref> , and Perry and Wolf [ Perry and Wolf, 1992 ] .
Reference: [ Shaw, 1995 ] <author> M. Shaw. </author> <title> Comparing architectural design styles. </title> <journal> IEEE Software, </journal> <pages> pages 27-40, </pages> <month> Novem-ber </month> <year> 1995. </year>
Reference-contexts: This corresponds to the software architecture level of design. The software architecture discipline deals with what is called architectural styles and how these styles affect system properties <ref> [ Shaw, 1995 ] </ref> . The conceptual foundations of software architecture as a major discipline in the field of software engineering was established by Shaw and Garlan [ Shaw, 1989, Garlan and Shaw, 1994 ] , and Perry and Wolf [ Perry and Wolf, 1992 ] .
Reference: [ Simon, 1973 ] <author> H.A. Simon. </author> <title> The structure of ill structured problems. </title> <journal> Artificial Intelligence, </journal> <volume> 4 </volume> <pages> 181-201, </pages> <year> 1973. </year>
Reference-contexts: Developing myopic and heuristic reasoning systems has been the focus of the AI research The AI research goal is to make computers perform tasks that usually require human intelligence. These tasks belong to the class of problems Simon calls ill-structured <ref> [ Simon, 1973 ] </ref> . The AI problem-solving paradigm is based on a search through the space of possible solutions for one that satisfies a certain set of conditions. The space of possible solutions is called the state-space; the conditions imposed on the solutions are the constraints.
Reference: [ Simon, 1981a ] <author> H.A. Simon. </author> <booktitle> The Sciences of the Artificial. </booktitle> <publisher> MIT Press, </publisher> <address> 2nd edition, </address> <year> 1981. </year>
Reference-contexts: As has already been discussed, the characteristics of the planning and scheduling problems make them not suitable for pure optimization methods. Most problems are NP-hard [ Chapman, 1987, Garey and Johnson, 1979 ] . Optimal solutions are only attainable for simplified or idealized models <ref> [ Simon, 1981a ] </ref> . Added to this, the dynamic nature of the problems makes it even harder to generate a persistent solution, one that would keep its static properties as the world evolves. <p> At the top-level management, on the other hand, the mathematical formalization required by OR approaches must discard essential facets of the real-world situations, and postulate parameters and variables that cannot be measured <ref> [ Simon, 1981a ] </ref> . Besides, the computational cost of these solutions do not make them suitable for highly dynamic environments. To overcome these intractability issues, the OR community started looking for near-optimal methods. This led to approaches that would produce what Simon calls satisficing solutions [ Simon, 1981a ] . <p> that cannot be measured <ref> [ Simon, 1981a ] </ref> . Besides, the computational cost of these solutions do not make them suitable for highly dynamic environments. To overcome these intractability issues, the OR community started looking for near-optimal methods. This led to approaches that would produce what Simon calls satisficing solutions [ Simon, 1981a ] . Near-optimal solution techniques include myopic decision-making and heuristic-based reasoning. Myopic techniques are methods that make decisions considering restricted or incomplete information. Under certain situations, myopic solutions can provide very good solutions [ Morton and Pentico, 1993 ] . <p> Planning and scheduling applications are complex systems. Although this statement is usually accepted to be true, it is a weak one. According to Simon "how complex or simple a structure is depends critically on the way we describe it" <ref> [ Simon, 1981a ] </ref> . This is the motivation for using models to reduce the complexity of the description. Abstract models work fine for human beings. Not for computers. Computers do not have abstraction capabilities.
Reference: [ Simon, 1981b ] <author> H.A. Simon. </author> <booktitle> The Sciences of the Artificial, chapter 7, </booktitle> <pages> page 209. </pages> <publisher> MIT Press, 2nd. </publisher> <address> edition, </address> <year> 1981. </year> <note> 500 BIBLIOGRAPHY </note>
Reference-contexts: Our modeling mechanism is based on the assumption that complex systems will evolve from simple systems much more rapidly if there are stable intermediate forms than if there are not. The resulting complex forms in the former case will be hierarchical. <ref> [ Simon, 1981b ] </ref> Therefore, models should be built on top of a hierarchical library of stable primitive components.
Reference: [ Simos, 1991 ] <author> M. Simos. </author> <title> The growing of an Organon: A hibrid knowledge-based technology and methodology for software reuse. </title> <editor> In R. Prieto-Daz and G Arango, editors, </editor> <booktitle> Domain Analysis and Software Modeling, </booktitle> <pages> pages 204-221. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: generic architecture and feature model are identified, possible sources for the asset implementation are located, and the rationales for selecting among alternatives are documented. 2.1.7.7 Simos' Domain Analysis for Building an Organon Advocating that the higher return on reuse investments can be obtained by vertical or domain specific reuse, Simos <ref> [ Simos, 1991 ] </ref> proposes a hybrid generative-constructive approach for the incremental development of a domain specific library of reusable software components. These libraries would be structured around an explicit domain model and would actively guide user access to components. Knowledge-based techniques are a key component in this approach.
Reference: [ Smith and Becker, 1997a ] <author> S.F. Smith and M.A. Becker. </author> <title> Configurability and reuse in scheduling system design. In Workshop on Object Oriented Methods for Distributed Control Architectures, </title> <address> Albuquerque, NM, </address> <month> April </month> <year> 1997. </year> <booktitle> IEEE International Conference on Robotics and Automation. </booktitle>
Reference-contexts: These capabilities can be defined as designate encapsulated behaviors that are intrinsic to various domain concepts. These behaviors are then implemented by specific software components in the underlying ozone class library <ref> [ Smith and Becker, 1997a ] </ref> . The concepts in the ontology are the building blocks for configuring and customizing the models. Rules on how to compose these building blocks is established by constraints described in the ontology and enforced by the implemented configuration mechanism.
Reference: [ Smith and Becker, 1997b ] <author> S.F. Smith and M.A. Becker. </author> <title> An ontology for constructing scheduling systems. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Ontological Engineering, </booktitle> <pages> pages 120-129, </pages> <address> Palo Alto, CA, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: This language is defined based on a common terminology for planning and scheduling. This terminology defines an ontological model for planning and scheduling <ref> [ Smith and Becker, 1997b ] </ref> . The operationalization of the concepts in this ontology through an implemented object-oriented class library, and the mechanism to guide system configuration provide the modeling environment described in this thesis, the ozone modeling framework. <p> application systems [ Lassila et al., 1996, Wilkins et al., 1996, Smith, 1994 ] , from revising several different system architectures [ Becker, 1993 ] , and from previous domain analysis models [ Becker and Daz-Herrera, 1994 ] , developed for different projects, an informal ontological model has been defined <ref> [ Smith and Becker, 1997b ] </ref> . This model corresponds to the abstract model of the framework. It defines entities, relations, and associates capabilities to concepts, but does not provide any functionality. Methods for developing ontologies have recently been proposed [ Gruber, 1993, Uschold, 1996 ] .
Reference: [ Smith and Lassila, 1994a ] <author> S.F. Smith and O. Lassila. </author> <title> Configurable systems for reactive production management. In Knowledge-Based Reactive Scheduling, </title> <address> Amsterdam (The Netherlands), </address> <year> 1994. </year> <title> IFIP Transactions B-15, </title> <publisher> North-Holland. </publisher>
Reference-contexts: The remaining alternative is to simplify the problem by ignoring or relaxing certain constraints. The consequence is that the solutions generated have limited relevance and utility to the operational decision-making process <ref> [ Smith and Lassila, 1994a ] </ref> . The last aspect relates to the static nature of the solutions generated. The solution to practical planning and scheduling problems are known not to be a static optimization problem but an ongoing reactive process [ Smith and Lassila, 1994b ] . <p> Associated to the visualization aspect, is interactivity. As an initial plan is generated, a useful decision support system should provide means for identifying problematic and unsatisfactory aspects of the result, as well as means to relax and/or strength requirements <ref> [ Smith and Lassila, 1994a ] </ref> . <p> The ozone scheduling ontology is the result of considerable prior experience in building planning and scheduling systems, in application domains ranging from manufacturing production scheduling [ Smith, 1994 ] to space mission planning [ Muscettola et al., 1992 ] to military deployment <ref> [ Smith and Lassila, 1994a ] </ref> , and aero-medical evacuation planning [ Lassila et al., 1996 ] . <p> The class library design and implementation underlying the ozone framework, and the ontology which provides its conceptual foundation, have followed from retrospective analysis of these scheduling domains and systems (e.g., [ Becker and Daz-Herrera, 1994 ] ), together with application of object-oriented analysis and design principles <ref> [ Smith and Lassila, 1994a ] </ref> . The methods used in the design and development of ozone class library and ontology have been strongly influenced by domain analysis techniques, provided by the software engineering community, and by general guidelines for ontology development provided by the knowledge representation community.
Reference: [ Smith and Lassila, 1994b ] <author> S.F. Smith and O. Lassila. </author> <title> Towards the development of flexible mixed-initiative transportation scheduling tools. </title> <booktitle> In Proc. of the ARPA/Rome Labs. Planning Workshop'94, </booktitle> <address> Tucson, AZ., </address> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: The last aspect relates to the static nature of the solutions generated. The solution to practical planning and scheduling problems are known not to be a static optimization problem but an ongoing reactive process <ref> [ Smith and Lassila, 1994b ] </ref> . In a real world environment, the quality of a schedule is measured by how well it executes in practice, and not by some metrics based on a static solution.
Reference: [ Smith et al., 1985 ] <author> D.R. Smith, </author> <title> G.B. </title> <journal> Kotik, and S.J. Westfold. Research on knowledge-based software environments at Kestrel Institute. IEEE Transactions on Software Engineering, </journal> <volume> 11(11) </volume> <pages> 1278-95, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: That they are "software environments" means they are intended to provide automated support to the entire software life-cycle <ref> [ Smith et al., 1985 ] </ref> . <p> Advice is then required to select the refinements to be applied. Some examples of very high-level languages are SETL [ Krutchen et al., 1984, Schonberg et al., 1986 ] , Gist, [ Balzer, 1985 ] , V <ref> [ Smith et al., 1985 ] </ref> , and Refine [ Smith et al., 1985 ] . SETL , a language based on the use of set and set operations, was one of the first very high level languages. <p> Advice is then required to select the refinements to be applied. Some examples of very high-level languages are SETL [ Krutchen et al., 1984, Schonberg et al., 1986 ] , Gist, [ Balzer, 1985 ] , V <ref> [ Smith et al., 1985 ] </ref> , and Refine [ Smith et al., 1985 ] . SETL , a language based on the use of set and set operations, was one of the first very high level languages. The SETL compiler decides how the data structures, specified at a high level of abstraction, should be implemented. <p> Languages that have the capability of representing high-level and low-level constructs are called wide-spectrum language <ref> [ Smith et al., 1985 ] </ref> . <p> The V language, implemented as the specification language for the CHI system <ref> [ Smith et al., 1985 ] </ref> is another example of very high level language with wide-spectrum capabilities. This language has been designed with two main requirements: self-description, the ability of describing itself, and uniform closure, the ability of describing all objects in the environment from system components to knowledge base. <p> Existing transformational implementations can be divided into two groups: those that are relatively limited in power but require no user guidance like the Program Development System (PDS) [ Cheatham, 1986 ] ; and those that allow more complex implementation but requires user guidance like CHI <ref> [ Smith et al., 1985 ] </ref> , KIDS [ Smith, 1990 ] , NIX [ Barstow, 1986b, Barstow, 1991 ] . and PSI system [ Barstow, 1986a ] . * Component-Based Methods: System implemented based on this approach rely on libraries of parametrized, plug-compatible, and reusable components to transform high-level specifications
Reference: [ Smith et al., 1990 ] <editor> S.F. Smith, P.S. Ow, J.Y. Potvin, N. Muscetola, and D.C. Matthys. </editor> <title> An integrated framework for generating and revising factory schedules. </title> <journal> Journal of Operational Research Society, </journal> <volume> 41(6) </volume> <pages> 539-552, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Sadeh, 1994 ] , HSTS [ Muscettola et al., 1992 ] , and O-PLAN [ Tate et al., 1994 ] have not been included in the current review, we consider that the set of architectures presented is representative enough to constitute the foundation for our domain model. 2.3.2 OPIS OPIS <ref> [ Smith, 1989, Smith et al., 1990, Smith, 1992b ] </ref> presents an approach to incremental reactive management of schedules based on a view of scheduling as an iterative, constraint-directed process.
Reference: [ Smith et al., 1996a ] <author> D.R. Smith, </author> <title> E.A. Parra, and S.J. Westfold. Synthesis of planning and scheduling software. </title> <editor> In Austin Tate, editor, </editor> <booktitle> ARPI Advanced Planning Technology, </booktitle> <pages> pages 226-234, </pages> <address> Menlo Park, CA, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: In the area of scheduling applications, we can identify two different approaches that also address some of these issues. One is the use of software generators ( see section 2.1.6 ) for implementing scheduling algorithms. An example of a system implemented using this approach is the Kestrel Transportation Scheduler <ref> [ Smith et al., 1996a ] </ref> . The second approach is the creation of a library of components for scheduling systems. ILOG's SCHEDULER and SOLVER [ Le Pape, 1994 ] and Deja Vu [ Dorn et al., 1997 ] are two examples of solutions using the library approach.
Reference: [ Smith et al., 1996b ] <author> S.F. Smith, O. Lassila, and M.A. Becker. </author> <title> Configurable, mixed-initiative systems for planning and scheduling. </title> <editor> In A. Tate, editor, </editor> <title> Advanced Planning Technology. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, </address> <year> 1996. </year> <note> BIBLIOGRAPHY 501 </note>
Reference-contexts: As more and more domains are analyzed, the more complete the ontology gets. To implement and operationalize the ontological model, the existing ozone class library developed by the Intelligent Coordination and Logistics Laboratory <ref> [ Smith et al., 1996b ] </ref> was used as a starting point. As the ontology matured and the configuration tool was being implemented, extensions and modifications to the original library were introduced. The ozone class library provides the object-oriented framework described in the previous paragraphs. <p> The user would then verify the sensitivity of the solution to each of these parameters and select a setting that would provide him/her with what s/he considers to be a good solution. Ditops <ref> [ Smith et al., 1996b ] </ref> is an example of a system in which reaction in both dimensions are allowed: the user can modify a previously generated schedule by acting on a solution and by interactively changing the problem solving behavior. 1.1.2 Problem Solving Approaches Concerning the problem solving approaches, we <p> Once the ontology has been defined, the mechanism to establish the relation between the functional behavior of the concepts, or capabilities, and their corresponding implementation was developed. We had already implemented an extensive class library for building scheduling systems. This class library, the ozone library <ref> [ Smith et al., 1996b ] </ref> , is the object-oriented framework previously mentioned. The library has been extended and modified to support the requirements imposed by this mechanism. <p> They provide an operational semantics to the concepts defined in the ontology, in a form that reflects a specific bias with respect to application system design. In particular, the ozone ontology presumes an underlying constraint-based solution framework and scheduling system architecture <ref> [ Smith, 1994, Smith et al., 1996b ] </ref> ; this commitment follows directly from the strong match of constraint-based techniques to the decision-support requirements of practical scheduling environments. Capabilities, then, encapsulate reusable components for configuring and customizing constraint-based solution methods.
Reference: [ Smith et al., 1998 ] <author> S.f. Smith, D.W. Hildum, and M.A. Becker. </author> <title> Agenda task scheduling for the JFACC-After-Next workflow manager application. </title> <type> Technical Report Working Paper, </type> <institution> Available from http://www.ozone.cimds.ri.cmu.edu/, Robotics Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1998. </year>
Reference-contexts: An example of how a scheduling system can be used in a workflow management environment is presented in <ref> [ Smith et al., 1998 ] </ref> . In the next paragraphs the main workflow concepts relevant to scheduling are presented. The terminology and definitions presented are based on [ Hollingsworth, 1994 ] and [ Workflow Management Coalition Members, 1996 ] .
Reference: [ Smith, 1987 ] <author> S.F. Smith. </author> <title> A constrained-based framework for reactive management of factory schedules. </title> <booktitle> In Proc. Int. Conf. on Expert Systems and the Leading Edge in Production Planning and Control, </booktitle> <address> Charleston, South Carolina, </address> <month> May </month> <year> 1987. </year>
Reference: [ Smith, 1989 ] <author> S.F. Smith. </author> <title> The OPIS framework for modeling manufacturing systems. </title> <type> Technical Report CMU-RI-TR-89-30, </type> <institution> The Robotics Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA., </address> <month> December </month> <year> 1989. </year>
Reference-contexts: Sadeh, 1994 ] , HSTS [ Muscettola et al., 1992 ] , and O-PLAN [ Tate et al., 1994 ] have not been included in the current review, we consider that the set of architectures presented is representative enough to constitute the foundation for our domain model. 2.3.2 OPIS OPIS <ref> [ Smith, 1989, Smith et al., 1990, Smith, 1992b ] </ref> presents an approach to incremental reactive management of schedules based on a view of scheduling as an iterative, constraint-directed process.
Reference: [ Smith, 1990 ] <author> D.R. Smith. KIDS: </author> <title> A semiautomatic program development system. </title> <journal> IEEE Transaction of Software Engineering, </journal> <volume> 16(9) </volume> <pages> 1024-43, </pages> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: The missing link is basically how these components are put together. Automatic software synthesis is an alternative approach that would take care of this problem. It requires a detailed formal domain theory, and efficient software synthesizers systems. Results obtained by using software synthesizers have been extremely encouraging <ref> [ Smith, 1990 ] </ref> . Given the complexity of developing such domain theories, and the difficulty in understanding both the code generated and the problem solving behavior, the interactivity at the level here advocated would be as complex as editing source code. <p> Variations of the approaches discussed above are still the current sate of the practice in more recent systems like Amphion [ Lowry et al., 1994 ] and KIDS <ref> [ Smith, 1990, Gomes et al., 1996 ] </ref> . * Programming by Examples: An alternative representation for program specification is the use of examples of program behavior. <p> can be divided into two groups: those that are relatively limited in power but require no user guidance like the Program Development System (PDS) [ Cheatham, 1986 ] ; and those that allow more complex implementation but requires user guidance like CHI [ Smith et al., 1985 ] , KIDS <ref> [ Smith, 1990 ] </ref> , NIX [ Barstow, 1986b, Barstow, 1991 ] . and PSI system [ Barstow, 1986a ] . * Component-Based Methods: System implemented based on this approach rely on libraries of parametrized, plug-compatible, and reusable components to transform high-level specifications of target systems into source code [ Batory <p> All the components in a realm have the same interface. Complex systems are modeled in GenVoca as a layered or hierarchical composition of components. P++ is the language for describing system specifications using GenVoca generators. Transformational systems like KIDS <ref> [ Smith, 1990 ] </ref> can simulate the components behavior by defining a library of domain theories. These libraries describe the application's underlying properties [ Setliff et al., 1993 ] .
Reference: [ Smith, 1992a ] <author> S.F. Smith. </author> <title> Knowledge-based production management: Approaches, results and prospects. </title> <journal> In Production Planning and Control, </journal> <volume> volume 3, </volume> <pages> pages 350-380. </pages> <publisher> Morgan Kaufmann Inc., </publisher> <year> 1992. </year>
Reference-contexts: INTRODUCTION Constraint satisfaction is an example of a search techniques that reduces substantially the amount of search required to generate a solution [ Rich and Knight, 1993 ] . and is also one of the techniques widely used in implemented knowledge-based scheduling systems <ref> [ Smith, 1992a ] </ref> . <p> Most of the production systems available in the market are based on some kind of mathematical programming, or heuristic problem solving method that generates a solution and feeds a simulator to evaluate solution quality <ref> [ Smith, 1992a ] </ref> . Few systems provide graphical interfaces that allows a better visualization of the solution. Gantt charts, spreadsheets and some types of charts are some examples of the usual graphical displays provided. <p> If the execution system uses a different set of criteria to correct the solution as unexpected events occur, conflicts are expected to appear and the final quality of the solution will be affected. Recent research in knowledge-based production systems tries to address some of the usability issues discussed here <ref> [ Smith, 1992a ] </ref> . Work on heuristics for incremental scheduling repair has provided a collection of methods for minimally disrupting an existing solution during plan revision. <p> LITERATURE REVIEW 2.3 Knowledge-Based Scheduling Architectures A large number of planning and scheduling systems for different application domains is currently available in the literature. A comprehensive review of several different approaches on knowledge-based systems applied to production planning and scheduling can be found in <ref> [ Smith, 1992a ] </ref> . and [ Zweben and Fox, 1994 ] is a collection that summarizes the state-of-the-art in terms of knowledge-based scheduling system implementations. This section reviews some of the relevant work in this area.
Reference: [ Smith, 1992b ] <author> S.F. Smith. Opis: </author> <title> a methodology and architecture for reactive scheduling. </title> <type> Technical report, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <address> Prittsburgh, PA, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: The need for schedule revision or repair is consequence of these two factors: the assumptions made when modeling the domain and generating the schedule; and the dynamic characteristic of the process environment. Smith <ref> [ Smith, 1992b ] </ref> identifies the generation of an advance schedule as an important step to guarantee the achievement of a coordinated behavior of the production process. <p> Sadeh, 1994 ] , HSTS [ Muscettola et al., 1992 ] , and O-PLAN [ Tate et al., 1994 ] have not been included in the current review, we consider that the set of architectures presented is representative enough to constitute the foundation for our domain model. 2.3.2 OPIS OPIS <ref> [ Smith, 1989, Smith et al., 1990, Smith, 1992b ] </ref> presents an approach to incremental reactive management of schedules based on a view of scheduling as an iterative, constraint-directed process.
Reference: [ Smith, 1994 ] <author> S.F. Smith. OPIS: </author> <title> A methodology and architecture for reactive scheduling. </title> <editor> In M. Zweben and M. Fox, editors, </editor> <title> Intelligent Scheduling, chapter 2. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1994. </year>
Reference-contexts: Very problem specific solutions are then implemented without a clear separation between the domain specific information and the generic algorithm framework. The second problem we identified is the simplified modeling assumptions used by these methods. Most decision support systems operate on models that ignore important operating constraints and conditions <ref> [ Smith, 1994 ] </ref> . Representing and enforcing a large and complex constraint set usually makes the problem too hard, if not impossible, to be solved. In certain cases, an over-constrained problem would be easier to solve but representing and verifying all the constraints can also be expensive. <p> The choice of the action can be guided by, for example, conflict type, conflict magnitude, resource affected, and order affected. This aspect identifies the repair actions available to the systems and how they are selected. The systems analyzed are: OPIS <ref> [ Smith, 1994 ] </ref> , SONIA [ Collinot et al., 1988 ] , REDS [ Hadavi et al., 1992 ] , Distributed Asynchronous Scheduler ( DAS ) [ Burke and Prosser, 1989 ] , GERRY ( Zweben's Iterative Repair ) [ Zweben et al., 1992a ] , Minton's Min-Conflicts Heuristic [ <p> Several of these efforts have been extensively reviewed in the previous chapter. The ozone scheduling ontology is the result of considerable prior experience in building planning and scheduling systems, in application domains ranging from manufacturing production scheduling <ref> [ Smith, 1994 ] </ref> to space mission planning [ Muscettola et al., 1992 ] to military deployment [ Smith and Lassila, 1994a ] , and aero-medical evacuation planning [ Lassila et al., 1996 ] . <p> They provide an operational semantics to the concepts defined in the ontology, in a form that reflects a specific bias with respect to application system design. In particular, the ozone ontology presumes an underlying constraint-based solution framework and scheduling system architecture <ref> [ Smith, 1994, Smith et al., 1996b ] </ref> ; this commitment follows directly from the strong match of constraint-based techniques to the decision-support requirements of practical scheduling environments. Capabilities, then, encapsulate reusable components for configuring and customizing constraint-based solution methods.
Reference: [ Smith, 1996 ] <author> S.F Smith. </author> <title> Configuring and coordinating system avtivity whithin OZONE. </title> <note> Internal Working Paper, </note> <month> July </month> <year> 1996. </year>
Reference-contexts: The concept of knowledge source can be considered either a control or a problem-solving concept. It has been included in the problem-solving ontology only for presentation purposes. The detailed description of the implementation of the agenda-based and multi-perspective scheduling architecture can be found in <ref> [ Smith, 1996 ] </ref> . In this section, the main ontological concepts and associated sub-concepts used in the implementation are defined. Similar to the concepts defined in the domain ontology, a layered approach can also be used for control concepts.
Reference: [ Steele, 1990 ] <author> G.L. Steele. </author> <title> Common Lisp The Language. </title> <note> Digital Press, second edition, </note> <year> 1990. </year>
Reference-contexts: In Common Lisp, however, instances are object that cannot generate any new instances: a class is an object that determines the structure and behavior of a set of other objects, which are called instances <ref> [ Steele, 1990 ] </ref> . A class in Common Lisp, as an object, is an instance of a special type of class called a meta-class, and, because of that, can be instantiated. The definition of class can be a source of confusion. <p> A class whose definition refers to other classes for the purpose of inheriting from them is said to be a subclass of each of those classes; the inverse relation establishes the superclasses of the inheriting class. Meta-Class: A meta-class is a class that has instances that are themselves classes <ref> [ Steele, 1990 ] </ref> . The same comments made for classes apply to meta-class. Meta-classes are used to define a structure for the object-oriented framework that reflect the structure of the ontology. In Common Lisp, all class objects are instances of a meta-class called standard-class.
Reference: [ Steels, 1990 ] <author> L. Steels. </author> <title> Components of expertise. </title> <journal> AI Magazine, </journal> <volume> 11(2) </volume> <pages> 29-49, </pages> <year> 1990. </year>
Reference-contexts: For example, Steels in Components of Expertise <ref> [ Steels, 1990 ] </ref> partitions knowledge into domain models, tasks, and problem-solving methods. Wielinga et al. divide CommonKADS knowledge [ Wielinga et al., 1992 ] into domain knowledge, task knowledge, inference knowledge, and strategic knowledge. <p> A comprehensive extension of these classifications is proposed by Puppe in [ Puppe, 1993 ] . The separation between problem-solving and domain has been further elaborated and refined by Steels' concept of Components of Expertise <ref> [ Steels, 1990 ] </ref> and CommonKADS expertise models already described [ Wielinga et al., 1992, Wielinga et al., 1994 ] .
Reference: [ Studer et al., 1996 ] <author> R. Studer, H. Eriksson, J. Gennari, S. Tu, D. Fensel, and M. Musen. </author> <title> Ontologies and the configuration of problem-solving methods. </title> <booktitle> In Proceedings of Tenth Knowledge Acquisition for Knowledge-Based Systems Workshop, </booktitle> <address> Banff, Alberta, Canada, </address> <year> 1996. </year> <note> Available from http://ksi.cpsc.ucalgary.ca:80/KAW/KAW96/KAW96Proc.html. 502 BIBLIOGRAPHY </note>
Reference-contexts: More recent efforts on defining method and task ontologies, like [ Coelho and Lapalme, 1996 ] , [ Chandrasekaran and Josephson, 2.2. ONTOLOGIES 119 1997 ] , <ref> [ Studer et al., 1996 ] </ref> , [ Gennari et al., 1998 ] , [ Fensel et al., 1997 ] emphasize the separation between what constitutes a task and what constitutes the problem solving method, and how to relate problem-solving and domain knowledge using the ontology definitions. <p> Recent examples of ontologies that pursue these ideas are Studer et al.'s ontologies for configuring problem-solving methods <ref> [ Studer et al., 1996 ] </ref> , Fensel et al.'s task ontology for parametric design [ Fensel et al., 1997 ] , Chandrasekaran's ontology of tasks and methods [ Chandrasekaran and Josephson, 1997 ] , Gennari et al's method description language [ Gennari et al., 1998 ] , and Coelho & <p> This is currently one of the problems with our current implementations. Possible solutions for this issue will be discussed later in the thesis. Studer et al.'s Ontologies for Configuring PSMs Studer et al. <ref> [ Studer et al., 1996 ] </ref> proposes a problem-solving method ontology to facilitate the configuration of problem solving methods from more elementary sub-methods. Configuration in this context means selecting appropriate sub-methods to solve the subtasks in which a method is decomposed. <p> This involves establishing a correspondence between method and task knowledge roles specified in the interface. An example describing in details of how this mapping can be achieved is described in <ref> [ Studer et al., 1996 ] </ref> . This is a very short and informal ontology. The interesting aspect of this ontology is the attempt to separate method and task ontology.
Reference: [ Studer et al., 1998 ] <editor> R. Studer, V.R. Benjamins, and D. Fensel. </editor> <booktitle> Knowledge engineering: Principles and methods,. Data and Knowledge Engineering, </booktitle> <pages> 25(1-2), </pages> <month> March </month> <year> 1998. </year>
Reference-contexts: A domain model, as described by the software engineering community, can be considered an ontology if, in addition to defining all terms and relationships among them, two conditions are satisfied <ref> [ Studer et al., 1998 ] </ref> : (1) different levels of generality corresponding to different levels of reusability are identified; and (2) the model reflect the common understanding or consensus of the domain. <p> Considering the different roles played by knowledge during application development and problem solving, it is possible to distinguish ontologies according to levels of generality. Studer et al. identify five different types of ontologies <ref> [ Studer et al., 1998 ] </ref> : Generic Ontologies: ontologies that are valid across several domains. These type of ontologies are referred to as upper-models, super-ontologies, or core ontologies. Representational Ontologies: these ontologies do not commit to any particular domain and provide representational entities without stating what should be represented. <p> Independent of being task specific or not, developers cannot reuse problem-solving knowledge without considering the domain knowledge required by the problem-solving method. Here also there are two views. One of them is based on the strong interaction problem hypothesis <ref> [ Studer et al., 1998 ] </ref> that assumes that the structure and representation of the domain knowledge is completely determined by its use. According to this view, domain ontologies and problem-solving methods 2.2. <p> ONTOLOGIES 137 cannot be viewed in isolation and the design of a domain ontology affects how well methods can use the ontology. Likewise, the information requirements imposed by the problem-solving methods affects the scope and organization of the domain ontology. Studer et al <ref> [ Studer et al., 1998 ] </ref> argues that an ontology for methods and tasks that makes explicit the interaction between problem-solving and domain knowledge [ Benjamins and Pierret-Golbreich, 1996 ] can help minimize this interaction problem.
Reference: [ Sundin, 1994 ] <author> Ulf Sundin. </author> <title> Assignment and scheduling. </title> <editor> In J. Breuker and W. Van de Velde, editors, </editor> <title> CommonKADS Library for Expertise Modeling, </title> <booktitle> volume 21 of Frontiers in Artificial Intelligence and Applications. </booktitle> <publisher> IOS Press, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1994. </year>
Reference-contexts: Among all these problem types, we are particularly interested in the assignment problem. An ontology for describing problem-solving concepts for scheduling is described in <ref> [ Sundin, 1994 ] </ref> and summarized in the next section. Breuke's classification and terminology provides us with a basic vocabulary for describing our control and problem-solving ontology. In the implementation of the OZONE control architecture, we make a distinction between task and problem similar to the one described here. <p> As a synthesis problem, a general problem-solving method appropriate for the assignment problem is propose & revise. Although there are several representations in the literature for the propose & revise problem-solving method, we will focus on the one provided by Sundin in <ref> [ Sundin, 1994 ] </ref> . The reason for selecting this description is that it has been tailored for the assignment problem and describes the components in level of detail that makes it possible to relate it to the OZONE description. <p> In Chapter 2, section 2.2.3.2, several classifications and ontologies for describing problem-solving knowledge have been presented. The scheduling problem is usually considered to belong to the class of assignment problems [ Puppe, 1993 ] <ref> [ Sundin, 1994 ] </ref> . However, in a mixed-initiative, reactive problem-solving environment, this classification is too restrictive.
Reference: [ Tate et al., 1994 ] <author> A. Tate, B. Drabble, and R. Kirby. </author> <title> O-Plan-2; an open architecture for command, planning, and control. </title> <editor> In M. Zweben and M. Fox, editors, </editor> <title> Intelligent Scheduling, chapter 7. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1994. </year>
Reference-contexts: Iterative Repair and Min-Conflict heuristic are two examples of how general constraint satisfaction mechanisms are adapted to be used in a scheduling architecture. Although some well-known systems like MICRO-BOSS [ Sadeh, 1994 ] , HSTS [ Muscettola et al., 1992 ] , and O-PLAN <ref> [ Tate et al., 1994 ] </ref> have not been included in the current review, we consider that the set of architectures presented is representative enough to constitute the foundation for our domain model. 2.3.2 OPIS OPIS [ Smith, 1989, Smith et al., 1990, Smith, 1992b ] presents an approach to incremental
Reference: [ Tate, 1994 ] <author> A. Tate. </author> <title> A plan ontology-a working document-october 31, </title> <booktitle> 1994. In Proceedings of the Workshop on Ontology Development and Use, </booktitle> <address> La Jolla, CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: OZONE, however, has a richer representations and a full structured lower-level ontology to support the implementation of concrete scheduling applications. 120 CHAPTER 2. LITERATURE REVIEW 2.2.3.1.2 Tate's Plan Ontology The plan ontology proposed by Tate in <ref> [ Tate, 1994 ] </ref> is an initial proposal for a plan ontology that was further refined in the &lt;I-N-OVA&gt; model [ Tate, 1996a ] . The SPAR ontology described below can be considered a more recent version of this plan ontology. <p> The SPAR ontology described below can be considered a more recent version of this plan ontology. The initial document describing the plan ontology <ref> [ Tate, 1994, Tate, 1996b ] </ref> is a poor attempt of describing an ontology. Being a working document, it is mainly a list of terms with shallow, informal, and incomplete definitions.
Reference: [ Tate, 1996a ] <author> A. Tate. </author> <title> Representing plans as a set of constraints-the &lt;I-N-OVA&gt; model. </title> <booktitle> In Proceedings of the Third International Conference on Planning Systems, </booktitle> <address> AIPS'96, Edinburgh, Scotland, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: To integrate and inter-operate with different applications in these domains, the scheduling system has to at least commit to a shared ontology. In the AI planning domain, the Core Plan Representation [ Pease and Carrico, 1997 ] , Tate's Plan Ontology based on the IN-OVA Model <ref> [ Tate, 1996b, Tate, 1996a ] </ref> , and the Shared Planning and Activity Representation [ Tate, 1997 ] are examples of attempts to define an ontology to promote a unified representation for planning systems. <p> LITERATURE REVIEW 2.2.3.1.2 Tate's Plan Ontology The plan ontology proposed by Tate in [ Tate, 1994 ] is an initial proposal for a plan ontology that was further refined in the &lt;I-N-OVA&gt; model <ref> [ Tate, 1996a ] </ref> . The SPAR ontology described below can be considered a more recent version of this plan ontology. The initial document describing the plan ontology [ Tate, 1994, Tate, 1996b ] is a poor attempt of describing an ontology.
Reference: [ Tate, 1996b ] <author> A Tate. </author> <title> Towards a plan ontology. </title> <journal> AI*IA Notizie (Journal of the Italian Association for AI), </journal> <volume> 9(1), </volume> <month> March </month> <year> 1996. </year>
Reference-contexts: To integrate and inter-operate with different applications in these domains, the scheduling system has to at least commit to a shared ontology. In the AI planning domain, the Core Plan Representation [ Pease and Carrico, 1997 ] , Tate's Plan Ontology based on the IN-OVA Model <ref> [ Tate, 1996b, Tate, 1996a ] </ref> , and the Shared Planning and Activity Representation [ Tate, 1997 ] are examples of attempts to define an ontology to promote a unified representation for planning systems. <p> The SPAR ontology described below can be considered a more recent version of this plan ontology. The initial document describing the plan ontology <ref> [ Tate, 1994, Tate, 1996b ] </ref> is a poor attempt of describing an ontology. Being a working document, it is mainly a list of terms with shallow, informal, and incomplete definitions. <p> The state of the world in the enterprise ontology is designated by STATE of AFFAIRS. An important concept associated to this definition of activity is the concept of DOER, ACTOR or AGENT, the entity that performs the activity. Considering the actor entity, <ref> [ Tate, 1996b ] </ref> makes a distinction between ACTION and EVENT: An action is an activity done, performed, or executed by a known agent; while an event is an activity done by an unknown agent.
Reference: [ Tate, 1997 ] <author> A. Tate. </author> <title> Planning Initiative Shared Planning and Activity Representation-SPAR. </title> <note> http://www.aiai.ed.ac.uk/~arpi/spar, October 1997. </note>
Reference-contexts: In the AI planning domain, the Core Plan Representation [ Pease and Carrico, 1997 ] , Tate's Plan Ontology based on the IN-OVA Model [ Tate, 1996b, Tate, 1996a ] , and the Shared Planning and Activity Representation <ref> [ Tate, 1997 ] </ref> are examples of attempts to define an ontology to promote a unified representation for planning systems. <p> Auxiliary constraints are sub-divided into authority, conditions, resources, and other constraints. The name &lt;I-N-OVA&gt; stands for the types of constraints considered: Issues, Node Constraints, Ordering Constraints, Variable Constraints, and Auxiliary Constraints. 2.2.3.1.3 Shared Planning and Activity Representation The Shared Planning and Activity Representation (SPAR) <ref> [ Tate, 1997 ] </ref> is an effort to create a shared model of what constitutes a plan. <p> Its scope is to represent past, present, and possible future activity and the command, planning and control processes that create and execute plans meant to guide or constrain future activity. <ref> [ Tate, 1997 ] </ref> . The definitions are semi-formal. They are expressed in natural language and no axioms or mathematical formulas are used. SPAR meta-concepts are: entity, relationship, function, attribute, value, and role. The entity is the basic, fundamental concept in the domain being modeled. <p> Activities external to the system, events in the SPAR terminology, are 122 CHAPTER 2. LITERATURE REVIEW internally mapped into a special type of control object called external-change. External-change is a sub-type of OZONE event. The ontology hierarchical structure described in <ref> [ Tate, 1997 ] </ref> has some presentation inconsistencies that I tried to remove. Therefore, the hierarchy here presented may not exactly reflect the current SPAR model. 1. Environment 2. Activity (a) Action (b) Event 3. TimePoint 4. Object (a) Agent (b) Location (c) Calendar 5. Relationship (a) Constraint i. <p> Given a solution method that incorporates these capabilities, the ontology provides a direct basis for its customization to match the resources in any target domain. According to <ref> [ Tate, 1997 ] </ref> , a relationship is an association between two or more entities, and are separate entities in their own right rather than being incorporated into attributes or properties of the entities related. In ozone however, relationships other than constraints are not explicitly represented. <p> Therefore relations among different entities are presented as properties of both entities; a property induces an implicit relation between the entity having the property and the entity that assumes the value of the property. Using <ref> [ Tate, 1997 ] </ref> example, the relation performs (activity, agent) is represented by the activity having an agent property, and by the agent having an activity (or activity to perform) property. In the remainder of this section, we summarize the basic components of the ozone scheduling ontology. <p> In this sense, an agent uses a resource to process an activity. In some cases, (e.g., the crew of an aircraft) a resource may simultaneously assume the role of the agent. For administrative purposes, three types of agents can be identified: * ACTOR: the motive force behind the activity <ref> [ Tate, 1997 ] </ref> . The actor is the agent that create the conditions necessary for the execution of the activity. * RESPONSIBLE AGENT or OWNER: the agent responsible for the execution of the activity [ Uschold et al., 1996 ] .
Reference: [ Tham et al., 1994 ] <author> D. Tham, M.S. Fox, and M. Gruninger. </author> <title> A cost ontology for enterprise mod-elling. </title> <booktitle> In Proceedings of the Third Workshop on Enabling Technologies Infrastructures for Collaborative Enterprises, </booktitle> <institution> West Virginia University, </institution> <year> 1994. </year>
Reference-contexts: level descriptions, or micro-theories, for several different areas of the enterprise have already been implemented: ontologies for describing organization structure [ Fox et al., 1996 ] , process and activities [ Gruninger and Fox, 1994, Gruninger and Pinto, 1995 ] , resources [ Fadel et al., 1994 ] , cost <ref> [ Tham et al., 1994 ] </ref> , and quality [ Kim and Fox, 1994 ] are currently available as part of the TOVE ontology. In enterprise modeling, the notion of time, activity, and resource plays a 124 CHAPTER 2. LITERATURE REVIEW central role.
Reference: [ Tracz, 1993 ] <author> W. Tracz. </author> <title> A domain-specific software architecture engineering process outline. </title> <booktitle> ACM SIGSOFT Software Engineering Notes, </booktitle> <volume> 18(2) </volume> <pages> 40-49, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Tracz, based on domain engineering concepts, proposes an engineering process for the generation of a Domain Specific Software Architecture <ref> [ Tracz, 1993 ] </ref> . The goal of this process, according to Tracz, is to map user needs into system requirements that, once constrained by implementation restrictions, define a DSSA.
Reference: [ Tracz, 1994 ] <author> W. Tracz. </author> <title> DSSA frequently asked questions. </title> <booktitle> Software Engineering Notes, </booktitle> <pages> pages 52-56, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Early attempts of achieving large scale software reusability by using a building blocks approach have not been very successful. More recent approaches have concentrated on reusing larger pieces of code inside a coherent structure or architecture. Software architecture [ Garlan and Shaw, 1994 ] , domain specific software architectures <ref> [ Tracz, 1994 ] </ref> , software patterns [ Gamma et al., 1994 ] , and object-oriented frameworks [ Johnson, 1997 ] are examples of recent software reuse efforts that relates to this architectural reconfigurability here advocated. <p> A Domain-Specific Software Architecture is a process and infrastructure that supports the development of a Domain Model, Reference Requirements, and Reference Architecture for a family of applications within a particular problem domain <ref> [ Tracz, 1994 ] </ref> . The goal of a DSSA, as well as the goal of this thesis, is to support the generation of applications within a particular domain.
Reference: [ Uschold and Gruninger, 1996 ] <author> M. Uschold and M. Gruninger. Ontologies: </author> <title> Principles, methods and applications. </title> <type> Technical Report AIAI-TR-191, </type> <institution> University of Edinburgh, </institution> <month> February </month> <year> 1996. </year> <note> BIBLIOGRAPHY 503 </note>
Reference-contexts: address some of these issues: the important distinction between ontologies and more traditional AI approaches to knowledge acquisition and representation is that ontologies are representation at the "knowledge-level." The high-level goal of the majority of efforts related to ontology development in the knowledge engineering community is knowledge sharing and reuse <ref> [ Uschold and Gruninger, 1996 ] </ref> . Software reuse, as advocated by the Software Engineering community, is only one aspect of the problem. <p> The high-level goal of knowledge sharing is sub-divided by Uschold & Gruniger <ref> [ Uschold and Gruninger, 1996 ] </ref> into three basic categories: Communication: ontologies enable shared understanding and communication between people with different needs and viewpoints. <p> Minimal Ontological Commitment: The ontology should only define those terms that are essential for the knowledge sharing activity; it should make as few claims as possible about the world been modeled. Uschold <ref> [ Uschold, 1995, Uschold, 1996, Uschold and Gruninger, 1996 ] </ref> in an attempt to create a unified method, describes a process for ontology design and implementation that is very similar to the system analysis and design techniques proposed by the software engineering community.
Reference: [ Uschold et al., 1996 ] <author> M. Uschold, M. King, S. Moralee, and Y Zorgios. </author> <title> The enterprise ontology v. </title> <institution> 1.1. http://www.aiai.ed.ac.uk/~enterprise/enterprise/ontology.html, University of Edinburgh, UK., </institution> <month> March </month> <year> 1996. </year>
Reference-contexts: The Toronto Virtual Enterprise ontology [ Fox et al., 1993, Fadel et al., 1994, Gruninger and Fox, 1994 ] and Uschold's Enterprise Ontology <ref> [ Uschold et al., 1996 ] </ref> are ontologies designed and implemented with the goal of creating a core representation for enterprise modeling. <p> However, in its current state, the modeling capabilities provided by the TOVE ontology are very limited. From our experience building ontologies and scheduling systems, the set of concepts provided by TOVE is not sufficient for the practical implementation of executable applications. 2.2.3.1.5 Enterprise Ontology The Enterprise Ontology <ref> [ Uschold et al., 1996 ] </ref> was developed as part of the Enterprise Project at the University of Edinburgh. <p> An entity is the basic primitive concept, concrete or abstract, that exists in the universe of discourse. Some ontologies refer to this basic concept as a thing or an object. We follow the approach taken by PIF [ Lee et al., 1996 ] and the Enterprise Ontology <ref> [ Uschold et al., 1996 ] </ref> and adopt the entity as our primitive concept. In the current ontology, the term object cannot be used as a synonym for entity. Object: An object is a component of a software model [ Abadi and Cardelli, 1996 ] . <p> Most typically, a resource is modeled as providing some amount of capacity, a numeric quantity which varies over time as a function of allocating the resource to various activities and its associated allocation semantics. This is the approach taken in <ref> [ Fadel et al., 1994, Uschold et al., 1996 ] </ref> . <p> One determining characteristic is whether resource capacity is used or consumed by an activity when it is allocated: (a) A REUSABLE RESOURCE, is a resource whose capacity becomes available for reuse after an activity to which it has been allocated finishes. We say that the activity uses the resource <ref> [ Uschold et al., 1996 ] </ref> (b) A CONSUMABLE RESOURCE, is one whose capacity, once allocated to an activity does not become available again. We say that the activity consumes the resource. <p> The conditions that should hold in order for the activity be executed are called ENABLING STATE, and the conditions that hold after the activity has been executed are called CAUSED STATE. A similar definition of activity is provided by <ref> [ Uschold et al., 1996 ] </ref> : an activity is something done over a particular time interval. An activity has PRE-CONDITIONS, EFFECTS, 254 CHAPTER 3. <p> The actor is the agent that create the conditions necessary for the execution of the activity. * RESPONSIBLE AGENT or OWNER: the agent responsible for the execution of the activity <ref> [ Uschold et al., 1996 ] </ref> . Being responsible means having the capability of performing the activity but does not mean actually executing the activity.
Reference: [ Uschold, 1995 ] <author> M. Uschold. </author> <title> Towards a methodology for building ontologies. </title> <type> Technical Report AIAI-TR-183, </type> <institution> University of Edinburgh, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: ONTOLOGIES 101 and their inter-relationships [ Uschold, 1996 ] . Uschold uses the term concept <ref> [ Uschold, 1995 ] </ref> to designate any thing, notion, or idea, and defines the term conceptualization as an intentional semantic structure which encodes the implicit rules constraining the structure of a piece of reality. <p> In this section we examine three of these proposals: Gruber's criteria for ontology design [ Gruber, 1993 ] , Uschold's proposal for creating a unified methodology <ref> [ Uschold, 1995, Uschold, 1996 ] </ref> , and METHONTOLOGY, a method proposed by Fernandez, Gomes-Perez, and Juristo [ Gomez-Perez et al., 1996, Fernandez et al., 1997 ] . A common characteristic of these guidelines is the similarity they have to the software engineering methods for analysis and design. <p> Minimal Ontological Commitment: The ontology should only define those terms that are essential for the knowledge sharing activity; it should make as few claims as possible about the world been modeled. Uschold <ref> [ Uschold, 1995, Uschold, 1996, Uschold and Gruninger, 1996 ] </ref> in an attempt to create a unified method, describes a process for ontology design and implementation that is very similar to the system analysis and design techniques proposed by the software engineering community.
Reference: [ Uschold, 1996 ] <author> M. Uschold. </author> <title> Building ontologies: Towards a unified methodology. </title> <type> Technical Report AIAI-TR-197, </type> <institution> University of Edinburgh, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: This model corresponds to the abstract model of the framework. It defines entities, relations, and associates capabilities to concepts, but does not provide any functionality. Methods for developing ontologies have recently been proposed <ref> [ Gruber, 1993, Uschold, 1996 ] </ref> . A particularly interesting one, based on a structured approach that a series of intermediate representation, is presented by Gomes-Perez in [ Gomez-Perez et al., 1996 ] . Other methods for ontology development are discussed in chapter 2. <p> Consistent with this modeling view, knowledge acquisition should capture the inherent structure of the domain to support a wide range of different tasks. Ontologies are examples of models that capture such structure. Research on ontologies has focused on methodologies and guidelines for ontology design <ref> [ Uschold, 1996, Gomez-Perez et al., 1996 ] </ref> , languages and formalisms for ontology representation [ Gruber, 1992 ] , , and domain specific examples [ Fadel et al., 1994, Gruninger and Fox, 1994, Tate, 1996b, Uschold et al., 1996, Chandrasekaran and Josephson, 1997, Smith and Becker, 1997b ] . 41 <p> A conceptualization is an abstract, simplified view of the world; it corresponds to the way of thinking about some domain, and it is typically conceived or expressed in terms of a set of domain entities or concepts, their definitions, 2.2. ONTOLOGIES 101 and their inter-relationships <ref> [ Uschold, 1996 ] </ref> . Uschold uses the term concept [ Uschold, 1995 ] to designate any thing, notion, or idea, and defines the term conceptualization as an intentional semantic structure which encodes the implicit rules constraining the structure of a piece of reality. <p> The ontology definitions constrain the possible interpretations of the terminology and reflects the ontological commitments the shared understanding of a domain that is agreed between a number of parties <ref> [ Uschold, 1996 ] </ref> , made by intelligent agents using the ontology. <p> In this section we examine three of these proposals: Gruber's criteria for ontology design [ Gruber, 1993 ] , Uschold's proposal for creating a unified methodology <ref> [ Uschold, 1995, Uschold, 1996 ] </ref> , and METHONTOLOGY, a method proposed by Fernandez, Gomes-Perez, and Juristo [ Gomez-Perez et al., 1996, Fernandez et al., 1997 ] . A common characteristic of these guidelines is the similarity they have to the software engineering methods for analysis and design. <p> Minimal Ontological Commitment: The ontology should only define those terms that are essential for the knowledge sharing activity; it should make as few claims as possible about the world been modeled. Uschold <ref> [ Uschold, 1995, Uschold, 1996, Uschold and Gruninger, 1996 ] </ref> in an attempt to create a unified method, describes a process for ontology design and implementation that is very similar to the system analysis and design techniques proposed by the software engineering community.
Reference: [ Veloso et al., 1995 ] <author> M. Veloso, J.G. Carbonell, M.A. Perez, D. Borrajo, E. Fink, and J. Blythe. </author> <title> Integrating planning and learning: The PRODIGY architecture. </title> <journal> Journal of Theoretical and Experimental Artificial Intelligence, </journal> <volume> 7(1), </volume> <year> 1995. </year>
Reference-contexts: Three problems we identify with some of these algorithms are: lack or excess of generality, simplified modeling assumptions, and static nature of the solution. Artificial intelligence planners like the General Problem Solver [ Newell and Simon, 1963 ] , Prodigy <ref> [ Veloso et al., 1995 ] </ref> , and SIPE [ Wilkins, 1984 ] , are described as domain independent planner systems. The problem is that generality is at odds with efficiency [ Minton, 1996 ] .
Reference: [ Wartik and Prieto-Daz, 1992 ] <author> S. Wartik and Prieto-Daz. </author> <title> Criteria for comparing reuse-oriented domain analysis approaches. </title> <journal> International Journal of Software Engineering and Knowledge Engineering, </journal> <volume> 2(3) </volume> <pages> 403-431, </pages> <year> 1992. </year>
Reference-contexts: Some methods focus on supporting formal or semi-formal reasoning about domains. Others focus on compositional software construction. This section discusses the latter category. A reviews and comparisons of several of these reuse-oriented domain analysis methods is presented in 2.1. SOFTWARE REUSE 85 <ref> [ Wartik and Prieto-Daz, 1992 ] </ref> , [ Arango, 1994 ] , and [ Nilson et al., 1994 ] . These methods provide guidelines on what kind of information we should look for and how to represent it in order to support systematic software reuse. <p> From the ontology perspective it means both. In the next paragraph I summarize the relevant domain analysis methods presented in [ Nilson et al., 1994 ] , [ Arango, 1994 ] . and <ref> [ Wartik and Prieto-Daz, 1992 ] </ref> . The emphasis here, as in the previous section, is on identifying the terminology used to describe the structural components of the domain model. In other words, I focus on identifying the meta-ontology used by these techniques. <p> An example of the use of this classification schema is presented in section 2.1.1. The main goal of this approach is the creation of a library, or repository, of reusable components. 2.1. SOFTWARE REUSE 89 This method is described in <ref> [ Wartik and Prieto-Daz, 1992 ] </ref> as "sandwich" approach where bottom-up activities are supported by the classification process, and top-down activities are supported by system analysis methods. This "sandwich" version corresponds to an extension of the basic method presented in [ Prieto-Daz, 1987 ] . <p> An engineering process for developing applications can then be designed using these domain concepts. In Synthesis [ McCabe et al., 1993 ] , domain analysis is part of the domain engineering, the object of which is to produce a process and environment for developing applications in the domain <ref> [ Wartik and Prieto-Daz, 1992 ] </ref> . During domain implemen 92 CHAPTER 2. LITERATURE REVIEW tation, domain developers, in contrast to application developers, use the domain specifications and the process provided by the analysis to build reusable components.
Reference: [ Waters, 1986 ] <author> R.C. Waters. </author> <title> The programmer's apprentice: A session with KBEmacs. </title> <editor> In C. Rich and R.C. Waters, editors, </editor> <booktitle> Readings in artificial intelligence and software engineering, </booktitle> <pages> pages 351-375, </pages> <address> Los Altos, CA, </address> <year> 1986. </year> <editor> M. </editor> <publisher> Kaufmann Publishers. </publisher>
Reference-contexts: Possible approaches for user interaction include: lower-level annotations in the high-level specifications, as provided by wide-spectrum languages; graphical user interfaces for selecting a specific transformation among a set of possible ones, as provided by systems like KIDS; and intelligent assistants <ref> [ Waters, 1986 ] </ref> that act as junior programmers taking care of the easy parts of the programming activity while the programmer focuses on the hard part of the process. The problems faced by adding interaction to software synthesizers are similar to the ones faced by mixed-initiative scheduling systems.
Reference: [ Whithey, 1994 ] <author> J. Whithey. </author> <title> Implementing MBSE in your organization: An approach to domain engineering. </title> <type> Technical Report CMU/SEI-94-TR-1, </type> <institution> Software Engineering Institue, Carnegie Mel-lon University, </institution> <address> Pittsburgh, PA, </address> <year> 1994. </year>
Reference-contexts: Several domain analysis techniques has been proposed in the literature [ Arango and Prieto-Daz, 1991, Arango, 1989 ] and a more comprehensive approach, Model Based Software Engineering <ref> [ Whithey, 1994 ] </ref> , provides guidelines for both Domain Analysis and Application Engineering. Methodologies and guidelines for ontology design and implementation can greatly benefit from existing Domain Analysis techniques. <p> A first attempt to formalize this translation is described in [ Peterson and J.L. Stanley, 1994 ] , but the process presented is too architecture dependent. The Model Based Software Engineering (MBSE) project at the Software Engineering Institute <ref> [ Whithey, 1994 ] </ref> is a more recent effort aimed at overcoming this deficiency of this method. It focus on integrating domain and application engineering into one coherent process.
Reference: [ Wielinga and Schreiber, 1993 ] <author> B.J. Wielinga and A.T. Schreiber. </author> <title> Reusable and sharable knowledge bases: A european perspective. </title> <booktitle> In Proc. Int. Conf. on Building and Sharing Very Large-Scaled Knowledge Bases '93, </booktitle> <address> Tokyo, </address> <year> 1993. </year> <note> Japan Information Processing Dev. Center. </note>
Reference-contexts: no agreed upon definition, the term has been used to designate or (1) a representation vocabulary specialized to some particular problem domain [ Chandrasekaran and Josephson, 1997 ] , like an ontology for planning and scheduling, or (2) a meta-model for a body of knowledge describing some common-sense knowledge domain <ref> [ Wielinga and Schreiber, 1993 ] </ref> , like a knowledge base for medical diagnosis. The definitions provided in the literature are usually based more on the intended uses of a particular ontology than on the precise characterization of what the term really means to the community in general. <p> This decomposition of the ontologies into sub-ontologies, also referred as micro-theories, follows the emerging view in knowledge-acquisition that considers a knowledge-level description to be constituted of different types of knowledge, and that these forms of knowledge play different roles during the problem solving process, and require different structuring principles <ref> [ Wielinga and Schreiber, 1993 ] </ref> . For example, Steels in Components of Expertise [ Steels, 1990 ] partitions knowledge into domain models, tasks, and problem-solving methods. Wielinga et al. divide CommonKADS knowledge [ Wielinga et al., 1992 ] into domain knowledge, task knowledge, inference knowledge, and strategic knowledge.
Reference: [ Wielinga et al., 1992 ] <author> B.J. Wielinga, W.V. Velde, G. Schreiber, and H. Akkernamans. </author> <title> The KADS knowledge modelling approach. </title> <booktitle> In Proc. </booktitle> <editor> 2nd Japanese K. A. </editor> <booktitle> for Knowledge-Based Systems Workshop. </booktitle> <institution> Hitachi Advanced Research Lab., </institution> <year> 1992. </year>
Reference-contexts: A more recent view, treats knowledge engineering as a modeling activity in which the development of knowledge-based systems is seen as the construction of a set of models of problem-solving behavior in its concrete organizational and application context <ref> [ Wielinga et al., 1992 ] </ref> . This shift in perspective was strongly motivated by Newell's concept of "knowledge-level" representation [ Newell, 1982 ] . The "knowledge-level hypothesis" was presented by Newell as an attempt to resolve some confusion related to the usage of terms like knowledge and representation. <p> The knowledge-base used by an agent corresponds to the symbol level description of its knowledge. [ Wielinga et al., 1994 ] . The purpose of a knowledge-level model of this knowledge-base is to make the organization of the knowledge in the system explicit <ref> [ Wielinga et al., 1992 ] </ref> . This description should be able to explain the rational behind the solution strategy used by the system in a vocabulary understandable for humans. <p> For example, Steels in Components of Expertise [ Steels, 1990 ] partitions knowledge into domain models, tasks, and problem-solving methods. Wielinga et al. divide CommonKADS knowledge <ref> [ Wielinga et al., 1992 ] </ref> into domain knowledge, task knowledge, inference knowledge, and strategic knowledge. In order to describe an application at the knowledge-level it is necessary to provide knowledge, and therefore an ontology, for each of these categories. A similar decomposition is used 2.2. <p> Ontologies written in this format are then translated into the different executable representations used by different problem-solving agents. The Knowledge Interchange Format (KIF) [ Genesereth and Fikes, 1991 ] , On-tolingua [ Gruber, 1992 ] , and the Conceptual Modeling Language (CML) <ref> [ Wielinga et al., 1992, Schreiber et al., 1994 ] </ref> are examples of formalisms that implement this approach. Being an ontology, or meta-ontology, for defining ontologies, these languages provide a vocabulary and a certain structure for representing ontologies. <p> It was developed for the specification of CommonKADS <ref> [ Wielinga et al., 1992 ] </ref> expertise models. It has neither an operational nor a formal semantics specified. The KACTUS project [ Wielinga et al., 1994 ] intends to develop a translator from CML to Ontolingua. Therefore, KIF would ultimately be the formal semantics to be used in CML. <p> A domain-model is a coherent collection of expressions about a domain that represents the particular viewpoint taken by the ontology. The inference knowledge specifies the basic inferences that can be made in the domain knowledge <ref> [ Wielinga et al., 1992 ] </ref> . It describes how domain knowledge can be used to create new information The inference knowledge is described using the following terms: inference-knowledge, inference, operation-type, input-roles, output-roles, and static-roles. <p> Therefore, upper-level ontologies will not be discussed. More details about these types of representations can be found, for example, in Guarino's work [ Guarino, 1995 ] . Terminology for describing the structure of the ontology, also called meta-ontologies, model ontologies <ref> [ Wielinga et al., 1992 ] </ref> , or even representation ontologies [ Gruber, 1993 ] , can also be included in this upper-level category and has already been discussed in the previous sub-section. <p> A comprehensive extension of these classifications is proposed by Puppe in [ Puppe, 1993 ] . The separation between problem-solving and domain has been further elaborated and refined by Steels' concept of Components of Expertise [ Steels, 1990 ] and CommonKADS expertise models already described <ref> [ Wielinga et al., 1992, Wielinga et al., 1994 ] </ref> .
Reference: [ Wielinga et al., 1994 ] <author> B.J. Wielinga, G. Schreiber, W. Jansweijer, A. Anjewierden, and F. van Hamerlen. </author> <title> Framework and formalism for ex 504 BIBLIOGRAPHY pressing ontologies. </title> <type> Technical Report Espirit Project 8145 Deliverable DO1b1, </type> <institution> University of Amsterdam, </institution> <note> http://www.swi.psy.uva.nl/projects/Kactus/Reports.html, November 1994. </note>
Reference-contexts: The knowledge-base used by an agent corresponds to the symbol level description of its knowledge. <ref> [ Wielinga et al., 1994 ] </ref> . The purpose of a knowledge-level model of this knowledge-base is to make the organization of the knowledge in the system explicit [ Wielinga et al., 1992 ] . <p> An ontology for describing a particular application domain depends on several different ontological components. An application ontology is constructed from a library of small scale ontologies <ref> [ Wielinga et al., 1994 ] </ref> : domain specific concepts are described in terms of general, common knowledge concepts; ontologies for describing problem solving and implementation dependent concepts are usually needed. <p> In AI, although the focus is on problem-solving at the knowledge-level, the assumption is still valid. For the AI community, a domain model represents a particular viewpoint an intelligent agent has on the domain knowledge, such that it is suitable for performing its problem-solving task <ref> [ Wielinga et al., 1994 ] </ref> . The ontology reflects this viewpoint. By committing to an existing ontology, an agent agrees to act consistently with the structure and definitions provided by the ontology. <p> It was developed for the specification of CommonKADS [ Wielinga et al., 1992 ] expertise models. It has neither an operational nor a formal semantics specified. The KACTUS project <ref> [ Wielinga et al., 1994 ] </ref> intends to develop a translator from CML to Ontolingua. Therefore, KIF would ultimately be the formal semantics to be used in CML. The goal of this specification language is to provide means of using natural language or semi-formal specifications for definitions the 2.2. <p> A comprehensive extension of these classifications is proposed by Puppe in [ Puppe, 1993 ] . The separation between problem-solving and domain has been further elaborated and refined by Steels' concept of Components of Expertise [ Steels, 1990 ] and CommonKADS expertise models already described <ref> [ Wielinga et al., 1992, Wielinga et al., 1994 ] </ref> .
Reference: [ Wilkins et al., 1996 ] <author> D.E. Wilkins, K.L. Myers, M. desJardins, S.F. Smith, and M.A. Becker. </author> <title> Multiagent planning architecture. </title> <booktitle> Annual Report ECU-7150, SRI International, </booktitle> <address> Menlon Park, CA, </address> <month> November </month> <year> 1996. </year>
Reference: [ Wilkins, 1984 ] <author> D.E. Wilkins. </author> <title> Domain independent planning: Representation and plan generation. </title> <journal> Artificial Intelligence, </journal> <volume> 22 </volume> <pages> 269-301, </pages> <year> 1984. </year>
Reference-contexts: case-based, or any other possible approach, the automation of planning in a computer program involves representing the state of the world, representing the valid actions, representing and reasoning about the effect of applying a sequence of actions, and controlling the search so that plans can be found with reasonably efficiency <ref> [ Wilkins, 1984 ] </ref> . The complexity of these problems varies greatly from domain to domain. Even for moderately complex goals, the number of possible action sequences and resource allocation alternatives can be extremely high, making the solution by exhaustive enumeration almost impossible. <p> Three problems we identify with some of these algorithms are: lack or excess of generality, simplified modeling assumptions, and static nature of the solution. Artificial intelligence planners like the General Problem Solver [ Newell and Simon, 1963 ] , Prodigy [ Veloso et al., 1995 ] , and SIPE <ref> [ Wilkins, 1984 ] </ref> , are described as domain independent planner systems. The problem is that generality is at odds with efficiency [ Minton, 1996 ] .
Reference: [ Wilkins, 1988 ] <author> D.E. Wilkins. </author> <title> Practical Planning. </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Reasoning about these actions is one of the essential components of human problem solving, and one of the basis of what is described as intelligent behavior <ref> [ Wilkins, 1988 ] </ref> . A large number of practical problems would benefit from the automation of this reasoning by computers. However, research in related areas like AI and cognitive psychology have shown that this human capability is extremely hard to formalize. <p> Besides, little is understood about how human beings reason about actions. One may even argue that humans often do not plan at all but just react to stimuli without planning ahead <ref> [ Wilkins, 1988 ] </ref> . Nevertheless, it is useful to introduce the classical concept of planning as defined by the AI community. The classical formulation of the planning problem assumes a state-based representation of the world. <p> According to Wilkins, the frame problem is what makes reasoning about actions inherently hard, and what distinguishes reasoning about actions from similar problems that do not require this problem to be addressed <ref> [ Wilkins, 1988 ] </ref> . Certain planners systems like STRIPS [ Fikes et al., 1981 ] , deal with this problem by using the simplifying assumption that the only changes 12 CHAPTER 1. INTRODUCTION in the world are the ones explicitly represented by the operator's post-condition or effects. <p> They do not provide good guidance in short-term decision making because they do not provide means for clearly understanding the interactions between processes, and do not explicitly state the causal relations between actions used in different circumstances <ref> [ Wilkins, 1988 ] </ref> . At the top-level management, on the other hand, the mathematical formalization required by OR approaches must discard essential facets of the real-world situations, and postulate parameters and variables that cannot be measured [ Simon, 1981a ] .
Reference: [ Workflow Management Coalition Members, 1996 ] <institution> Workflow Management Coalition Members. Workflow management coalition: </institution> <note> Terminology & glossary. Technical Report WFMC-TC-1011, Available from http://www.aiim.org/wfmc/, Workflow Management Coalition, Brussels, Bel-gium, </note> <year> 1996. </year>
Reference-contexts: In the next paragraphs the main workflow concepts relevant to scheduling are presented. The terminology and definitions presented are based on [ Hollingsworth, 1994 ] and <ref> [ Workflow Management Coalition Members, 1996 ] </ref> . These two documents represent the workflow terminology as an alphabetized list of terms with a natural language definition. Although no attempts of formalizing or structuring the 2.2.
Reference: [ Zave and Schell, 1986 ] <author> P. Zave and W. Schell. </author> <title> Salient features of an executable specification language. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(2):312-325, </volume> <month> February </month> <year> 1986. </year>
Reference-contexts: The goal of VHLL implementors is to find abstractions that are more natural and expressive than the one provided by high level languages like C, Lisp, Fortran. Examples of VHLLs are languages that implement set theoretical abstractions like SETL [ Krutchen et al., 1984 ] and PAISLey <ref> [ Zave and Schell, 1986 ] </ref> , or declarative constraint-based languages like MODEL [ Prywes and Lock, 1989 ] . Problems with this approach are poor run-time performance and the difficulty associated to using high-level mathematical abstractions.
Reference: [ Zweben and Fox, 1994 ] <author> M. Zweben and M.S. Fox. </author> <title> Intelligent Scheduling. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA., </address> <year> 1994. </year>
Reference-contexts: The scheduling problem is also known to be NP-hard. A number of algorithms and software systems have been developed to solve problems in several different planning domains. There is a considerable literature currently available on planning and scheduling algorithms and systems <ref> [ Zweben and Fox, 1994 ] </ref> . One additional characteristic of this kind of problems that is often overlooked is its dynamic nature. A plan or a schedule is supposed to be executed on a real world environment where things not always happen as expected. <p> A comprehensive review of several different approaches on knowledge-based systems applied to production planning and scheduling can be found in [ Smith, 1992a ] . and <ref> [ Zweben and Fox, 1994 ] </ref> is a collection that summarizes the state-of-the-art in terms of knowledge-based scheduling system implementations. This section reviews some of the relevant work in this area.
Reference: [ Zweben et al., 1992a ] <author> M. Zweben, E. Davis, B. Daun, and M. Deale. </author> <title> Rescheduling with iterative repair. In Sigman Workshop on Knowledge-Based Production Planning, Scheduling & Control, </title> <address> San Jose, CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The systems analyzed are: OPIS [ Smith, 1994 ] , SONIA [ Collinot et al., 1988 ] , REDS [ Hadavi et al., 1992 ] , Distributed Asynchronous Scheduler ( DAS ) [ Burke and Prosser, 1989 ] , GERRY ( Zweben's Iterative Repair ) <ref> [ Zweben et al., 1992a ] </ref> , Minton's Min-Conflicts Heuristic [ Minton et al., 1992a ] , Le Pape's Reactive Schedule Model [ Le Pape, 1991 ] . OPIS is the system in which architecture the OZONE class library is based. <p> Due date relaxation is the S-agent's last resort to solve a conflict and involves a right shift of the start times of operations succeeding the operation relaxed. 2.3.6 GERRY Constraint Based Iterative Repair According to Zweben <ref> [ Zweben et al., 1992a ] </ref> a rescheduling system should satisfy domain constraints, address optimization concerns, minimize perturbation to the original schedule, produce modified schedules in a time efficient manner, and be able to be interrupted during its execution and to output an executable solution.
Reference: [ Zweben et al., 1992b ] <author> M. Zweben, E. Davis, B. Daun, and M. Deale. </author> <title> Scheduling and rescheduling with iterative repair. </title> <type> Technical Report Tech. </type> <institution> Rept. FIA-92-16, NASA Ames Research Center, Moffett Field, </institution> <address> CA., </address> <year> 1992. </year>
Reference-contexts: But SONIA tries to schedule the entire operation and only considers the breaking of an operation across working shifts if it is really needed. GERRY, on the other hand, uses an approach called fixed preemptive scheduling <ref> [ Zweben et al., 1992b ] </ref> . This approach is used because of the characteristics of the domain that requires long duration activities to obey a pre-defined work calendar. Activities are split into the shortest sequence of continuous subtasks that can be performed during the work shift period.
Reference: [ Zweben et al., 1992c ] <author> M. Zweben, E. Davis, B. Daun, E. Drascher, M. Deale, and M. Eskey. </author> <title> Learning to improve constraint-based scheduling. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 271-296, </pages> <year> 1992. </year>
Reference-contexts: If the solution is rejected, new repairs are tried in the original schedule. The rescheduling algorithm is search intensive since it performs local repair and use iterations to minimize the number of additional constraints violations. Zweben <ref> [ Zweben et al., 1992c ] </ref> describes an experiment where a learning mechanism is used to select the heuristic to be used as a guide in the search process.
References-found: 224

