URL: ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1997/CSRP-97-13.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: fR.Poli,W.B.Langdong@cs.bham.ac.uk  
Title: Genetic Programming with One-Point Crossover and Point Mutation  
Author: Riccardo Poli and W.B. Langdon 
Address: (UK)  
Affiliation: School of Computer Science The University of Birmingham  
Abstract: Technical Report: CSRP-97-13 April 1997 Abstract In recent theoretical and experimental work on schemata in genetic programming we have proposed a new simpler form of crossover in which the same crossover point is selected in both parent programs. We call this operator one-point crossover because of its similarity with the corresponding operator in genetic algorithms. One point crossover presents very interesting properties from the theory point of view. In this paper we describe this form of crossover as well as a new variant called strict one-point crossover highlighting their useful theoretical and practical features. We also present experimental evidence which shows that one-point crossover compares favourably with standard crossover.
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Peter J. Angeline and K. E. Kinnear, Jr., editors. </editor> <booktitle> Advances in Genetic Programming 2. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references).
Reference: [2] <author> Patrik D'haeseleer. </author> <title> Context preserving crossover in genetic programming. </title> <booktitle> In Proceedings of the 1994 IEEE World Congress on Computational Intelligence, </booktitle> <volume> volume 1, </volume> <pages> pages 256-261, </pages> <address> Orlando, Florida, USA, 27-29 June 1994. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: random crossover point is selected with a uniform probability among the links belonging to the common parts identified in step (a). inherit the common structure (emphasised with thick lines) of the upper part of the parents. (One-point crossover has some similarity to the strong context preserving crossover operator proposed in <ref> [2] </ref> but context preserving crossover is less restrictive than one-point crossover as to which links can be selected as crossover points.) One-point crossover has a very important property: it makes the calculations necessary to model the disruption of GP schemata feasible.
Reference: [3] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references). Holland's schema theorem (see [4] and <ref> [3] </ref>) is often used to explain why genetic algorithms (GAs) work. For binary GAs, a schema is a string of symbols taken from the alphabet f0,1,#g. The character # is a "don't care" symbol, so that a schema can represent several bit strings. <p> For this reason we call them hyperspaces of programs. We denote 9 non-zero-order schemata with the term hyperplanes, as they can be seen as sub-spaces of the spaces of programs identified by different G (H)'s. Our schema theorem is more complicated than the corresponding version for GAs <ref> [3, 4, 21] </ref>. This is due to the fact that in GP the trees undergoing optimisation have variable size and shape.
Reference: [4] <author> John Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <note> second edition, </note> <year> 1992. </year>
Reference-contexts: However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references). Holland's schema theorem (see <ref> [4] </ref> and [3]) is often used to explain why genetic algorithms (GAs) work. For binary GAs, a schema is a string of symbols taken from the alphabet f0,1,#g. The character # is a "don't care" symbol, so that a schema can represent several bit strings. <p> For this reason we call them hyperspaces of programs. We denote 9 non-zero-order schemata with the term hyperplanes, as they can be seen as sub-spaces of the spaces of programs identified by different G (H)'s. Our schema theorem is more complicated than the corresponding version for GAs <ref> [3, 4, 21] </ref>. This is due to the fact that in GP the trees undergoing optimisation have variable size and shape.
Reference: [5] <editor> K. E. Kinnear, Jr., editor. </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references).
Reference: [6] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references). <p> Unfortunately, until very recently the efforts in this direction have given limited results. In the last few years alternative definitions of schema have been proposed <ref> [6, 12, 20] </ref>. All these definitions are based on the idea that a schema is composed of one or more trees or fragments of trees and that each schema represents all the programs in which such trees or tree fragments are present. <p> Therefore, the initialisation method and parameters chosen for the creation of the initial population can modify significantly the behaviour of the algorithm. For example, if one uses the "full" initialisation method <ref> [6] </ref> which produces balanced trees with a fixed depth, then the search will be limited to programs 1 Obviously the lower parts of the trees moved around by crossover influence the fitness of the fixed-size upper parts, but they are not modified by crossover at this stage. 3 with a fixed <p> If on the contrary the "ramped half-and-half" initialisation method is used <ref> [6] </ref>, which produces trees of variable shape and size with depths ranging from 0 to the prefixed maximum initial tree depth D, then the entire space of programs with maximum depth D will be searched (at least if the population is big enough). 2 An interesting variant of one-point crossover, which <p> It is quite clear that 2 The "ramped half-and-half" initialisation method used in <ref> [6] </ref> enforced a minimum depth of 2. In our work we use a minimum depth of 0. 4 number for the XOR problem. <p> crossover does. 3 Experimental Results The behaviour of the two forms of one-point crossover introduced in the previous section has been studied and compared to standard crossover in over 3,000 runs on the even-n parity problems with n=3, 4 and 5, which have been extensively studied in the GP literature <ref> [6, 7] </ref>. An even-n parity problem consists of finding a combination of functions from the set F =fOR, AND, NOR, NANDg and terminals from the set T =fx1, x2, x3, ..., xng which returns true if an even number of the n inputs xi is true and false otherwise. <p> We also measured the average size of the solutions found. On the even-n parity problems Koza <ref> [6, 7] </ref> obtained the results shown in Table 1 (we report them for an easier 5 comparison with our experiments). <p> 7,840,000 (N/A) 4,000, with ADFs N/A 80,000 (N/A) 152,000 (N/A) 16,000, no ADFs 96,000 (45) 384,000 (113) 6,528,000 (300) 16,000, with ADFs 64,000 (48) 176,000 (60) 464,000 (157) Table 1: Computational effort E and average solution size (in parenthesis) for standard GP with and without ADFs reported by Koza in <ref> [6, 7] </ref>.
Reference: [7] <author> John R. Koza. </author> <title> Genetic Programming II: Automatic Discovery of Reusable Programs. </title> <publisher> MIT Pres, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references). <p> crossover does. 3 Experimental Results The behaviour of the two forms of one-point crossover introduced in the previous section has been studied and compared to standard crossover in over 3,000 runs on the even-n parity problems with n=3, 4 and 5, which have been extensively studied in the GP literature <ref> [6, 7] </ref>. An even-n parity problem consists of finding a combination of functions from the set F =fOR, AND, NOR, NANDg and terminals from the set T =fx1, x2, x3, ..., xng which returns true if an even number of the n inputs xi is true and false otherwise. <p> We also measured the average size of the solutions found. On the even-n parity problems Koza <ref> [6, 7] </ref> obtained the results shown in Table 1 (we report them for an easier 5 comparison with our experiments). <p> 7,840,000 (N/A) 4,000, with ADFs N/A 80,000 (N/A) 152,000 (N/A) 16,000, no ADFs 96,000 (45) 384,000 (113) 6,528,000 (300) 16,000, with ADFs 64,000 (48) 176,000 (60) 464,000 (157) Table 1: Computational effort E and average solution size (in parenthesis) for standard GP with and without ADFs reported by Koza in <ref> [6, 7] </ref>.
Reference: [8] <editor> John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors. </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references).
Reference: [9] <author> W. B. Langdon and R. Poli. </author> <title> Fitness causes bloat. </title> <type> Technical Report CSRP-97-09, </type> <institution> University of Birmingham, School of Computer Science, Birmingham, </institution> <address> B15 2TT, UK, </address> <month> 24 February </month> <year> 1997. </year>
Reference-contexts: This is can be very useful to avoid the typical undesirable growth of program size (bloating) observed in GP runs (see for example <ref> [9] </ref>), which slows down the search for solutions and, in some cases, can lead to overfitting. One-point crossover does this without the need of any extra machinery (e.g. parsimony terms in the fitness function).
Reference: [10] <author> William B. Langdon. </author> <title> A bibliography for genetic programming. </title> <editor> In Peter J. Angeline and K. E. Kinnear, Jr., editors, </editor> <booktitle> Advances in Genetic Programming 2, chapter B, </booktitle> <pages> pages 507-532. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA, </address> <year> 1996. </year>
Reference-contexts: However, only a relatively small number of theoretical results are available which try and explain why and how it works (see <ref> [10, pages 517-519] </ref> for a list of references). Holland's schema theorem (see [4] and [3]) is often used to explain why genetic algorithms (GAs) work. For binary GAs, a schema is a string of symbols taken from the alphabet f0,1,#g.
Reference: [11] <author> Ben McKay, Mark J. Willis, and Geoffrey W. Barton. </author> <title> Using a tree structured genetic algorithm to perform symbolic regression. </title> <editor> In A. M. S. Zalzala, editor, </editor> <booktitle> First International Conference on Genetic Algorithms in Engineering Systems: Innovations and Applications, GALESIA, </booktitle> <volume> volume 414, </volume> <pages> pages 487-492, </pages> <address> Sheffield, UK, </address> <month> 12-14 September </month> <year> 1995. </year> <pages> IEE. </pages>
Reference-contexts: We also chose a simple form of mutation, point mutation, in which a function in the tree is substituted with another function with the same arity or a terminal is substituted with another terminal <ref> [11] </ref>. With these genetic operators we were able to derive very naturally a schema theory [18] which has a considerable explanatory power (see Appendix A).
Reference: [12] <author> Una-May O'Reilly and Franz Oppacher. </author> <title> The troubling aspects of a building block hypothesis for genetic programming. </title> <editor> In L. Darrell Whitley and Michael D. Vose, editors, </editor> <booktitle> Foundations of Genetic Algorithms 3, </booktitle> <pages> pages 73-88, </pages> <address> Estes Park, Colorado, USA, 31 July-2 August 1994 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Unfortunately, until very recently the efforts in this direction have given limited results. In the last few years alternative definitions of schema have been proposed <ref> [6, 12, 20] </ref>. All these definitions are based on the idea that a schema is composed of one or more trees or fragments of trees and that each schema represents all the programs in which such trees or tree fragments are present.
Reference: [13] <author> Riccardo Poli. </author> <title> Evolution of recursive transistion networks for natural language recognition with parallel distributed genetic programming. </title> <type> Technical Report CSRP-96-19, </type> <institution> School of Computer Science, University of Birmingham, </institution> <address> B15 2TT, UK, </address> <month> December </month> <year> 1996. </year> <booktitle> Presented at AISB-97 workshop on Evolutionary Computation. </booktitle> <pages> 10 </pages>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references).
Reference: [14] <author> Riccardo Poli. </author> <title> Genetic programming for image analysis. </title> <editor> In John R. Koza, David E. Goldberg, David B. Fogel, and Rick L. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> pages 363-368, </pages> <address> Stanford University, CA, USA, 28-31 July 1996. </address> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references).
Reference: [15] <author> Riccardo Poli. </author> <title> Discovery of symbolic, neuro-symbolic and neural networks with parallel distributed genetic programming. </title> <booktitle> In 3rd International Conference on Artificial Neural Networks and Genetic Algorithms, ICANNGA'97, </booktitle> <year> 1997. </year>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references).
Reference: [16] <author> Riccardo Poli and Stefano Cagnoni. </author> <title> Evolution of psuedo-colouring algorithms for image enhancement with interactive genetic programming. </title> <type> Technical Report CSRP-97-5, </type> <institution> School of Computer Science, The University of Birmingham, </institution> <address> B15 2TT, UK, </address> <month> January </month> <year> 1997. </year> <note> To be presented at GP-97. </note>
Reference-contexts: 1 Introduction Genetic Programming (GP) has been applied successfully to a large number of difficult problems like automatic design, pattern recognition, robotic control, synthesis of neural architectures, symbolic regression, image analysis, natural language processing, etc. <ref> [6, 7, 5, 8, 1, 14, 16, 15, 13] </ref>. However, only a relatively small number of theoretical results are available which try and explain why and how it works (see [10, pages 517-519] for a list of references).
Reference: [17] <author> Riccardo Poli and W. B. Langdon. </author> <title> An experimental analysis of schema creation, propagation and disruption in genetic programming. </title> <type> Technical Report CSRP-97-8, </type> <institution> University of Birmingham, School of Computer Science, </institution> <month> February </month> <year> 1997. </year> <note> To be presented at ICGA-97. </note>
Reference-contexts: With these genetic operators we were able to derive very naturally a schema theory [18] which has a considerable explanatory power (see Appendix A). Indeed, the predictions of the theory have been later corroborated by an experimental study <ref> [17] </ref> on the creation, propagation and disruption of GP schemata in small populations using the XOR problem. In this paper we experimentally study the performance of our genetic operators and compare them to standard GP on larger parity problems. The paper is organised as follows. <p> Appendix A summarises our GP schema theorem. More on it can be found in [18] and <ref> [17] </ref>. Here we want only to recall the most important predicted and observed effect of one-point crossover: unlike standard crossover, in the absence of mutation, one-point 2 crossover makes the population converge quite quickly like a standard GA (in some cases with help from genetic drift). <p> A difference is that in GP with strict one-point crossover the search zooms into the subtrees of a converged node automatically, without the need for maintaining global convergence statistics. The convergence property of the two forms of one-point crossover has been observed in real runs with the XOR problem <ref> [17] </ref>. Figure 3 shows the diversity in the population (averaged over 10 independent runs) as a function of the generation number for standard crossover and for the two types of one-point crossover in the absence of mutation (the experimental conditions are as in [17]). <p> in real runs with the XOR problem <ref> [17] </ref>. Figure 3 shows the diversity in the population (averaged over 10 independent runs) as a function of the generation number for standard crossover and for the two types of one-point crossover in the absence of mutation (the experimental conditions are as in [17]). It is quite clear that 2 The "ramped half-and-half" initialisation method used in [6] enforced a minimum depth of 2. In our work we use a minimum depth of 0. 4 number for the XOR problem. <p> A Schema Theorem for Genetic Programming with One-point Crossover and Point Mutation In order to understand the importance of one-point crossover from the theory point of view it is necessary to introduce some additional definitions (see [18] and <ref> [17] </ref> for a more details on our schema theory). The number of non-= symbols in a schema H is called the order O (H) of the schema, while the total number of nodes in the schema is called the length N (H) of the schema. <p> However, both the theoretical analysis presented in [18] and the experimental work in <ref> [17] </ref> suggest that after a first phase in which GP really behaves differently from a standard GA, the number of hyperspaces is considerably reduced and GP behaves like a GA, i.e. the GP schema theorem asymptotically tends to the GA schema theorem.
Reference: [18] <author> Riccardo Poli and W. B. Langdon. </author> <title> A new schema theory for genetic programming with one-point crossover and point mutation. </title> <type> Technical Report CSRP-97-3, </type> <institution> School of Computer Science, The University of Birmingham, </institution> <address> B15 2TT, UK, </address> <month> January </month> <year> 1997. </year> <note> To be presented at GP-97. </note>
Reference-contexts: The problem with the definitions of schema for GP mentioned above is not that they are not clear or concise, it is that they make the effects on schemata of the genetic operators used in GP too difficult to evaluate mathematically. 1 In recent work <ref> [18] </ref> we have reconsidered all this and proposed a new definition of schema for GP which is very close to the original concept of schema in GAs. <p> We also chose a simple form of mutation, point mutation, in which a function in the tree is substituted with another function with the same arity or a terminal is substituted with another terminal [11]. With these genetic operators we were able to derive very naturally a schema theory <ref> [18] </ref> which has a considerable explanatory power (see Appendix A). Indeed, the predictions of the theory have been later corroborated by an experimental study [17] on the creation, propagation and disruption of GP schemata in small populations using the XOR problem. <p> Appendix A summarises our GP schema theorem. More on it can be found in <ref> [18] </ref> and [17]. Here we want only to recall the most important predicted and observed effect of one-point crossover: unlike standard crossover, in the absence of mutation, one-point 2 crossover makes the population converge quite quickly like a standard GA (in some cases with help from genetic drift). <p> A Schema Theorem for Genetic Programming with One-point Crossover and Point Mutation In order to understand the importance of one-point crossover from the theory point of view it is necessary to introduce some additional definitions (see <ref> [18] </ref> and [17] for a more details on our schema theory). The number of non-= symbols in a schema H is called the order O (H) of the schema, while the total number of nodes in the schema is called the length N (H) of the schema. <p> This is accounted for by the presence of the terms m (G (H); t) and f (G (H); t), which summarise the characteristics of the programs belonging to the same hyperspace in which H is a hyperplane. However, both the theoretical analysis presented in <ref> [18] </ref> and the experimental work in [17] suggest that after a first phase in which GP really behaves differently from a standard GA, the number of hyperspaces is considerably reduced and GP behaves like a GA, i.e. the GP schema theorem asymptotically tends to the GA schema theorem.
Reference: [19] <author> N. N. Schraudolph and R. K. Belew. </author> <title> Dynamic parameter encoding for genetic algorithms. </title> <journal> Machine Learning, </journal> <volume> 9(1) </volume> <pages> 9-21, </pages> <year> 1992. </year>
Reference-contexts: In the case of strict one-point crossover the search seems to proceed very similarly to the search performed by a GA with Dynamic Parameter Encoding (DPE) <ref> [19] </ref>, a technique for overcoming the precision/speed dilemma when encoding real-valued parameters with binary strings. In DPE the resolution of the encoding of one parameter is increased at run time when the most significant bit of such parameter has (nearly) converged in the whole population.
Reference: [20] <author> P. A. Whigham. </author> <title> A schema theorem for context-free grammars. </title> <booktitle> In 1995 IEEE Conference on Evolutionary Computation, </booktitle> <volume> volume 1, </volume> <pages> pages 178-181, </pages> <address> Perth, Australia, </address> <month> 29 November - 1 December </month> <year> 1995. </year> <note> IEEE Press. </note>
Reference-contexts: Unfortunately, until very recently the efforts in this direction have given limited results. In the last few years alternative definitions of schema have been proposed <ref> [6, 12, 20] </ref>. All these definitions are based on the idea that a schema is composed of one or more trees or fragments of trees and that each schema represents all the programs in which such trees or tree fragments are present.
Reference: [21] <author> Darrel Whitley. </author> <title> A genetic algorithm tutorial. </title> <type> Technical Report CS-93-103, </type> <institution> Department of Computer Science, Colorado State University, </institution> <month> August </month> <year> 1993. </year> <month> 11 </month>
Reference-contexts: For this reason we call them hyperspaces of programs. We denote 9 non-zero-order schemata with the term hyperplanes, as they can be seen as sub-spaces of the spaces of programs identified by different G (H)'s. Our schema theorem is more complicated than the corresponding version for GAs <ref> [3, 4, 21] </ref>. This is due to the fact that in GP the trees undergoing optimisation have variable size and shape.
References-found: 21

