URL: ftp://ftp.cnl.salk.edu/pub/alex/JCN93.ps.Z
Refering-URL: http://www.cnl.salk.edu/cgi-bin/pub-search/
Root-URL: 
Email: Email: alex@salk.edu  
Phone: Phone: (619) 453 4100 x1463 Fax: (619) 587-0417  
Title: Egocentric spatial representation in early vision  
Author: Alexandre Pouget, Steven A. Fisher and Terrence J. Sejnowski Alexandre Pouget 
Address: La Jolla, CA 92037  10010 North Torrey Pines Rd. La Jolla, CA 92037  
Affiliation: Howard Hughes Medical Institute The Salk Institute and Department of Biology University of California, San Diego  The Salk Institute. CNL.  
Note: Journal of Cognitive Neuroscience. 5(2):150-161. 1993.  To whom correspondence should be addressed:  
Abstract-found: 0
Intro-found: 1
Reference: <author> Andersen, R. A. </author> <year> (1989). </year> <title> Visual and eye movement functions of the posterior parietal cortex. </title> <journal> Ann. Rev. Neurosci., </journal> <volume> 12, </volume> <pages> 377-403. </pages>
Reference-contexts: Object-centered reference frames have been suggested for the representation of objects in the inferior temporal cortex and egocentric reference frames have been proposed for the representation of spatial location in the parietal cortex <ref> (Andersen, 1989) </ref>. Goodale and Milner (Goodale & Milner, 1990) have recently proposed that the dorsal pathway to parietal cortex could also be involved in object manipulation as opposed to just localization. They suggest that the "where" pathway might be better called the "how" pathway. <p> As shown by Goodman and Andersen these saccades are consistent with the distributed representation found in the Zipser and An-dersen model of the PPC <ref> (Goodman & Andersen, 1989) </ref>. <p> Typically, nine initial eye positions were used, evenly spread in the 2-D visual field. This procedure was first proposed by Goodman and Andersen who applied it to the Zipser and Andersen model of the parietal cortex <ref> (Goodman & Andersen, 1989) </ref>. As a control, we first stimulated retinal inputs. The retina is clearly using eye-centered coordinates so that stimulation at a given retinal location should induce an eye movement to that location. <p> This pattern of eye movements has already been observed in parietal area LIP <ref> (Goodman & Andersen, 1989,Thier91) </ref>. 3.1 Network output representation The type of units that we used in the output layer of our network, namely units which encode explicitly head-centered position, have never been found in the cortex.
Reference: <author> Andersen, R. A., Essick, G. K., & Siegel, R. M. </author> <year> (1985). </year> <title> Encoding of spatial location by posterior parietal neurons. </title> <journal> Science, </journal> <volume> 230, </volume> <pages> 456-458. </pages> <note> 23 Andersen, </note> <author> R. A., & Zipser, D. </author> <year> (1988). </year> <title> The role of the posterior parietal cortex in coordinate transformations for visuo-motor coordination. Can. </title> <journal> J. Physiol. Pharmac., </journal> <volume> 66, </volume> <pages> 488-501. </pages>
Reference: <author> Brotchie, P. R., & Andersen, R. A. </author> <year> (1991). </year> <title> A body-centered coordinate system in posterior parietal cortex. </title> <journal> Abst. Soc. Neurosci., </journal> <volume> 17, </volume> <pages> 1281. </pages>
Reference: <author> Feldman, J. A. </author> <year> (1985). </year> <title> Four frames suffice: A provisional model of vision and space. Behavior. </title> <journal> Brain Sci., </journal> <volume> 8, </volume> <pages> 265-289. </pages>
Reference-contexts: In a purely spatiotopic map, neurons would respond to visual features such as orientation or color of an object at a fixed spatial location. Such maps would have receptive fields in egocentric rather than retinal coordinates. Feldman <ref> (Feldman, 1985) </ref> has advocated such egocentric maps, arguing that they would have important computational advantages for object recognition.
Reference: <author> Felleman, D. J., & Van Essen, D. C. </author> <year> (1991). </year> <title> Distributed hierarchical processing in the primate cerebral cortex. </title> <journal> Cer. Cortex, </journal> <volume> 1, </volume> <pages> 1-47. </pages>
Reference-contexts: Eye-centered representations have been proposed for early vision mainly because the neurons in primary visual cortex and most extrastriate areas are organized into retino-topic maps <ref> (Felleman & Van Essen, 1991) </ref>. Most psychophysical experiments designed to determine the nature of spatial representation at early visual stages have reached the same conclusion, as we review in the discussion. The other two types of representation are believed to be used at the highest stages of visual processing.
Reference: <author> Galleti, C., & Battaglini, P. P. </author> <year> (1989). </year> <title> Gaze-dependent visual neurons in area V3A of monkey prestriate cortex. </title> <journal> J. Neurosci., </journal> <volume> 9, </volume> <pages> 1112-1125. </pages>
Reference-contexts: Neurons sensitive to eye position have been reported in the lateral geniculate nucleus (LGN) (Lal & Friedlander, 1989), primary visual cortex area V1 (Trotter, Celebrini, Thorpe, & Imbert, 1991; Weyand & Malpeli, 1989) and extrastriate area V3a <ref> (Galleti & Battaglini, 1989) </ref>. The static eye position signal seems to mainly control the gain of the neuronal response without changing the selectivity of the cell. <p> In V3a, there is a correlation between the retinotopic position of a cell and its preferred eye position direction (PEPD) such that neurons in the right cortex, encoding the left visual field, tend to fire more when the eyes fixate also in the left part of the visual field <ref> (Galleti & Battaglini, 1989) </ref>.
Reference: <author> Gauthier, G. M., Nommay, D., & Vercher, J. L. </author> <year> (1990). </year> <title> The role of proprioception in visual localization of targets. </title> <journal> Science, </journal> <volume> 249, </volume> <pages> 58-61. </pages>
Reference-contexts: This conclusion has been seriously questioned by MacKay (MacKay, 1970) and O'Regan (O'Regan, 1984), but a recent experiment performed by Gauthier et al. <ref> (Gauthier, Nommay, & Vercher, 1990) </ref> provides new evidence in favor of the ERS. This experiment tested the influence of eye position on hand-pointing to visual targets.
Reference: <author> Goodale, M. A., & Milner, A. D. </author> <year> (1990). </year> <title> Separate visual pathways for proprioception and action. </title> <journal> Trends Neurosci., </journal> <volume> 15, </volume> <pages> 20-25. </pages>
Reference-contexts: Object-centered reference frames have been suggested for the representation of objects in the inferior temporal cortex and egocentric reference frames have been proposed for the representation of spatial location in the parietal cortex (Andersen, 1989). Goodale and Milner <ref> (Goodale & Milner, 1990) </ref> have recently proposed that the dorsal pathway to parietal cortex could also be involved in object manipulation as opposed to just localization. They suggest that the "where" pathway might be better called the "how" pathway.
Reference: <author> Goodman, S. J., & Andersen, R. A. </author> <year> (1989). </year> <title> Microstimulation of a neural network model for visually guided saccades. </title> <journal> J. Cog. Neurosci., </journal> <volume> 1, </volume> <pages> 317-326. </pages>
Reference-contexts: As shown by Goodman and Andersen these saccades are consistent with the distributed representation found in the Zipser and An-dersen model of the PPC <ref> (Goodman & Andersen, 1989) </ref>. <p> Typically, nine initial eye positions were used, evenly spread in the 2-D visual field. This procedure was first proposed by Goodman and Andersen who applied it to the Zipser and Andersen model of the parietal cortex <ref> (Goodman & Andersen, 1989) </ref>. As a control, we first stimulated retinal inputs. The retina is clearly using eye-centered coordinates so that stimulation at a given retinal location should induce an eye movement to that location. <p> This pattern of eye movements has already been observed in parietal area LIP <ref> (Goodman & Andersen, 1989,Thier91) </ref>. 3.1 Network output representation The type of units that we used in the output layer of our network, namely units which encode explicitly head-centered position, have never been found in the cortex.
Reference: <author> Goodman, S. J., & Andersen, R. A. </author> <year> (1990). </year> <title> Algorithm programmed by a neural model for coordinate transformation. </title> <booktitle> Proc. Inter. Joint Conf. Neur. Net., </booktitle> <volume> 2, </volume> <pages> 381. </pages>
Reference: <author> Heilman, K. M., Watson, R. T., & Valenstein, E. </author> <year> (1985). </year> <title> Neglect and related disorders. </title> <editor> In K. M. Heilman & E. Valenstein (Eds.), </editor> <booktitle> Clinical Neuropsychology (pp. </booktitle> <pages> 243-294). </pages> <address> New York: </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: Following ischemic lesions in the PPC, patients often display egocentric neglect, though of variable extent <ref> (Heilman, Watson, & Valenstein, 1985) </ref>. This neglect usually extend to multiple sensory modalities, typically vision, audition and touch, in the contralateral side of the lesion.
Reference: <author> Irwin, D. E. </author> <year> (1991). </year> <title> Information integration across saccadic eye movements. Cog. </title> <journal> Psychol., </journal> <volume> 23, </volume> <pages> 420-456. </pages>
Reference: <author> Irwin, D. E., Brown, J. S., & Sun, J. </author> <year> (1988). </year> <title> Visual masking and visual integration across saccadic eye movements. </title> <journal> J. Exp. Psychol., </journal> <volume> 117, </volume> <pages> 276-287. </pages>
Reference: <author> Irwin, D. E., Zachs, J. L., & Brown, J. S. </author> <year> (1990). </year> <title> Visual memory and the perception of a stable environment. </title> <journal> Percep. Psychophy., </journal> <volume> 47, 35-46.. 24 Kawanura, </volume> <editor> H., & Marchiafava, P. L. </editor> <year> (1966). </year> <title> Modulation of transmission of optic nerve impulses in alert cat: Evidence of presynaptic inhibition of primary afferents during ocular movements. </title> <journal> Brain Res., </journal> <volume> 1, </volume> <pages> 213-215. </pages>
Reference-contexts: Another example is a study by Irwin et al. <ref> (Irwin, Zachs, & Brown, 1990) </ref> on orientation masking which showed that, with the eyes fixed, the detection threshold of an oriented test grating was increased by the presentation of a 40 ms prime grating of similar orientation. <p> Since most psychophysical experiments have been performed under the assumption that spatiotopic 21 representation ought to involve spatiotopic topology, they could not distinguish purely retinotopic map from RSM. Consider, for example, the orientation masking by Irwin et al. <ref> (Irwin, et al., 1990) </ref>. When the prime and target gratings are flashed on the same retinal position, a masking is expected whether the maps are retinotopic or retinospatiotopic.
Reference: <author> Kohler, I. </author> <year> (1964). </year> <title> The formation and transformation of the perceptual world. </title> <booktitle> Psychol. Issues, </booktitle> <volume> 3, </volume> <pages> 62-86. </pages>
Reference-contexts: We predict, however, that it should be possible to demonstrate contingent after-effect with translation motion or other elementary visual attribute such as orientation or disparity. Such result would suggest that these features are part of a retinospatiotopic map. Kohler reported a positive result for color after-effects <ref> (Kohler, 1964) </ref>, but these experiments have not been replicated (Mc Cullough, 1965).
Reference: <author> Kurylo, D. D., & Skavenski, A. </author> <year> (1991). </year> <title> Eye movements elicited by electrical stimulation of area PG in the monkey. </title> <journal> J. Neurophysiol., </journal> <volume> 65, </volume> <pages> 1243-1253. </pages>
Reference: <author> Lal, R., & Friedlander, M. J. </author> <year> (1989). </year> <title> Gating of the retinal transmission by afferent eye position and movement signals. </title> <journal> Science, </journal> <volume> 243, </volume> <pages> 93-96. </pages>
Reference-contexts: Recent physiological studies suggest that neurons in the earliest stages of visual processing may be encoding spatial representations similar to those found in parietal cortex. Neurons sensitive to eye position have been reported in the lateral geniculate nucleus (LGN) <ref> (Lal & Friedlander, 1989) </ref>, primary visual cortex area V1 (Trotter, Celebrini, Thorpe, & Imbert, 1991; Weyand & Malpeli, 1989) and extrastriate area V3a (Galleti & Battaglini, 1989). The static eye position signal seems to mainly control the gain of the neuronal response without changing the selectivity of the cell.
Reference: <author> LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., & Jackel, L. D. </author> <year> (1990). </year> <title> Backpropagation applied to handwritten zip code recognition. </title> , <booktitle> 1, </booktitle> <pages> 540-566. </pages>
Reference-contexts: It is important to note that the 3-5 hidden units at each location had different weights, hence different receptive fields. Thus, this small group of units could be considered a highly simplified cortical column. Details about this weight sharing method can be found in LeCun et al. <ref> (LeCun, Boser, Denker, Henderson, Howard, Hubbard, et al., 1990) </ref>. Weights were adjusted using the backpropagation training algorithm (Rumel-hart, Hinton, & Williams, 1986). All simulations were performed with the SN2 simulator developed by Botou and LeCun (Neuristic).
Reference: <author> Lehky, S. R., Pouget,A., & Sejnowski, T. J. </author> <year> (1990). </year> <title> Neural models of binocular depth perception. </title> <editor> In E. R. Kandel, T. J. Sejnowski, C. F. Stevens, & J. </editor> <address> D. </address>
Reference-contexts: Models have already been developed for representing distance using disparity selective neurons whose gain is modulated by vergence angle <ref> (Lehky, Pouget, & Sejnowski, 1990) </ref>. Neurons with these properties have been reported in area V1 of behaving monkeys (Trotter, et al., 1991)(There is also indirect evidence for vergence modulation of monocular neurons in the LGN (Kawanura & Marchiafava, 1966; Richards, 1968)).
Reference: <editor> Watson (Eds.), </editor> <booktitle> Cold Spring Harbor Symposium on Quantitative Biology: </booktitle> <address> The Brain New York: </address> <publisher> Cold Spring Harbor Press. </publisher>
Reference: <author> MacKay, D. M. </author> <year> (1970). </year> <title> Mislocalization of test flashes during saccadic image displacements. </title> <journal> Nature, </journal> <volume> 227, </volume> <pages> 731-733. </pages>
Reference-contexts: This suggests that the subject had access to an extra retinal signal (ERS) encoding eye position for use in computing the position of the flash on the screen during the eye movement. This conclusion has been seriously questioned by MacKay <ref> (MacKay, 1970) </ref> and O'Regan (O'Regan, 1984), but a recent experiment performed by Gauthier et al. (Gauthier, Nommay, & Vercher, 1990) provides new evidence in favor of the ERS. This experiment tested the influence of eye position on hand-pointing to visual targets.
Reference: <author> Mateef, S. </author> <year> (1978). </year> <title> Saccadic eye movements and localization of visual stimuli. </title> <journal> Percept. Psychophys., </journal> <volume> 24, </volume> <pages> 215-224. </pages>
Reference-contexts: Several experiments have addressed the issue of whether eye position signals are used for localizing an object. Matin ((Matin & Pearce, 1965), see also <ref> (Mateef, 1978) </ref>) first demonstrated that a human subject can accurately localize a point of light briefly flashed on a screen while making a saccadic eye movement.
Reference: <author> Matin, L., & Pearce, D. G. </author> <year> (1965). </year> <title> Visual perception of direction for stimuli flashed during voluntary saccadic eye movements. </title> <journal> Science, </journal> <volume> 248, </volume> <pages> 1485-1488. </pages>
Reference: <author> Mayhew, J. E. W. </author> <year> (1973). </year> <title> After-effects of movement contingent on direction of gaze. </title> <journal> Vision Res., </journal> <volume> 13, </volume> <pages> 877-880. </pages>
Reference-contexts: These experiments looked for after-effects contingent on eye position. After seeing repetitively clockward motion while looking left and anti-clockwise motion while right, subjects reported an anti-clockwise motion after-effect when looking right and clockwise motion when looking left <ref> (Mayhew, 1973) </ref>. Neurons sensitive to rotational motion have been found in area MST and other relatively late stages of processing (Sakata, Shibutani, & Tsurugai, 1986). We predict, however, that it should be possible to demonstrate contingent after-effect with translation motion or other elementary visual attribute such as orientation or disparity.
Reference: <author> Mc Cullough, C. </author> <year> (1965). </year> <title> Conditioning of color perception. </title> <journal> Am. J. Psychol., </journal> <volume> 78, </volume> <pages> 362-378. </pages>
Reference-contexts: Such result would suggest that these features are part of a retinospatiotopic map. Kohler reported a positive result for color after-effects (Kohler, 1964), but these experiments have not been replicated <ref> (Mc Cullough, 1965) </ref>. Color may not be one of the visual attributes that are combined with eye position since the areas where eye-position modulation have been reported belong mainly to the 'dorsal' pathway to the parietal cortex (V3a, 7a, LIP) where color is not a primary feature being represented.
Reference: <author> Mc Ilwain, J. T. </author> <year> (1988). </year> <title> Saccadic eye movements evoked by electrical stimulation of the cat visual cortex. Vis. </title> <journal> Neurosci., </journal> <volume> 1, </volume> <pages> 135-143. </pages> <note> 25 Mishkin, </note> <author> M., Ungerleider, L. G., & Macko, K. A. </author> <year> (1983). </year> <title> Object vision and spatial vision: Two cortical pathways. </title> <booktitle> Trends Neurosci., </booktitle> <month> Oct, </month> <pages> 414-417. </pages>
Reference-contexts: Furthermore, strong negative evidence comes from a study by McIlwain of saccadic eye movements elicited by electrical stimulation of area V1 <ref> (Mc Ilwain, 1988) </ref>. McIlwain has shown that the directions of electrically-evoked saccades in cats appear to be mainly a function of the position of the stimulation site in V1 and largely independent of the initial eye position. <p> Right plot: same for a position 55 right, 12 up. In both cases, the direction of the saccades were primarily determined by the position of the stimulation on V1 and is largely independent of the initial eye position (from <ref> (Mc Ilwain, 1988) </ref>). 7 are consistent with an egocentric representation despite the fact that those areas are retinotopic. <p> The eye movement pattern obtained by stimulating a position at the middle left or middle right of the retina can be directly compared with the experimental results reported by McIlwain shown in Figure 3 <ref> (Mc Ilwain, 1988) </ref>. Stimulation in the hidden layers led to different results depending on how many units were stimulated per position. Each location had between 3 to 5 13 network. <p> Nevertheless, the pattern of eye movement could still be easily distinguished from the pattern obtained after stimulating the input layer or from the experimental pattern reported by McIlwain <ref> (Mc Ilwain, 1988) </ref>. When all the units sharing the same position were activated together, the output pattern resembled the one obtained by stimulating the input layer (Fig. 8). <p> As our simulation shown, in such conditions, even if static eye position modulates the gain of V1 neurons, one would expect to obtain fixed vector saccades which are consistent with the results reported by McIlwain. <ref> (Mc Ilwain, 1988) </ref>. Furthermore, many cells in V1 do not show any eye position modulation of their response and when they do, the modulation appears to be weaker than that reported in the posterior parietal cortex.
Reference: <author> O'Regan, J. K. </author> <year> (1983). </year> <title> Integrating visual information from successive fixations : Does trans-saccadic fusion exist? Vision Res., </title> <booktitle> 23, </booktitle> <pages> 765-768. </pages>
Reference: <author> O'Regan, J. K. </author> <year> (1984). </year> <title> Retinal versus extraretinal influences in flash localization during saccadic eye movements in the presence of visible background. </title> <journal> Percept. Psychophys., </journal> <volume> 36, </volume> <pages> 1-14. </pages>
Reference: <author> Otto, I., Grandguillaume, P., Boutkhil, L., Burnod, Y., & Guigon, E. </author> <year> (1992). </year> <title> Direct and indirect cooperation between temporal and parietal networks for invariant visual recognition. </title> <journal> J. Cog. Neurosci., </journal> <volume> 4, </volume> <pages> 35-57. </pages>
Reference-contexts: With few exceptions, attempts to find evidence for an early spatiotopic buffer have failed. The consensus of opinion is that spatial transformations occurs at a late stage of visual processing (see for example <ref> (Otto, Grandguillaume, Boutkhil, Burnod, & Guigon, 1992) </ref>). How can we account for this major discrepancy? Most experiments have tested for a spatial representation that is quite different from the retinospatial maps used in our model.
Reference: <author> Pollatsek, A., Rayner, K., & Henderson, J. M. </author> <year> (1990). </year> <title> Role of spatial location in integration of pictorial information across saccades. </title> <journal> J. Exp. Psychol. : Hum. Percept. Perf., </journal> <volume> 16, </volume> <pages> 199-210. </pages>
Reference: <author> Rayner, K., & Pollatsek, A. </author> <year> (1983). </year> <title> Is visual information integrated across saccades? Percept. </title> <journal> Psychophys., </journal> <volume> 34, </volume> <pages> 39-48. </pages>
Reference: <author> Richards, W. </author> <year> (1968). </year> <title> Spatial remapping in the primate visual system. </title> <journal> Bio. Cyber., </journal> <volume> 4, </volume> <pages> 146-156. </pages>
Reference: <author> Robinson, D. A., & Fuchs, A. F. </author> <year> (1969). </year> <title> Eye movements evoked by stimulation of the frontal eye field. </title> <journal> J. Neurophysiol., </journal> <volume> 32, </volume> <pages> 637-648. </pages>
Reference-contexts: In contrast to these results in the PPC, eye movements of the fixed vector type have been observed after stimulation of the frontal eye fields (FEF) <ref> (Robinson & Fuchs, 1969) </ref>, suggesting that the PPC and the FEF have different representation of eye movements. Recent physiological studies suggest that neurons in the earliest stages of visual processing may be encoding spatial representations similar to those found in parietal cortex. <p> The large dots indicates the initial eye position while the lines show the amplitude and direction of the evoked saccades. A.) Fixed vector type. Amplitude and direction are independent of initial eye position. Typical of stimulation in Frontal Eye Field (FEF) <ref> (Robinson & Fuchs, 1969) </ref> B) Amplitude varying saccades (LIP)(Thier & Andersen, 1992). Amplitude varies with initial position of eye. C) Convergent saccades. All saccades end in the same zone regardless of initial eye position.
Reference: <author> Rumelhart, D. E., Hinton, G. E., & Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart & J. L. McClelland (Eds.), </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. </booktitle> <volume> Vol. 1: </volume> <booktitle> Foundations Cambridge, </booktitle> <address> MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Sakata, H., Shibutani, H., & Tsurugai, K. </author> <year> (1986). </year> <title> Parietal cortical neurons responding to rotary movement of visual stimulus in space. Exp. </title> <journal> Brain Res., </journal> <volume> 61, </volume> <pages> 658-663. </pages>
Reference-contexts: After seeing repetitively clockward motion while looking left and anti-clockwise motion while right, subjects reported an anti-clockwise motion after-effect when looking right and clockwise motion when looking left (Mayhew, 1973). Neurons sensitive to rotational motion have been found in area MST and other relatively late stages of processing <ref> (Sakata, Shibutani, & Tsurugai, 1986) </ref>. We predict, however, that it should be possible to demonstrate contingent after-effect with translation motion or other elementary visual attribute such as orientation or disparity. Such result would suggest that these features are part of a retinospatiotopic map.
Reference: <author> Shibutani, H., Sakata, H., & Hyvarinen, J. </author> <year> (1986). </year> <title> Saccade and blinking evoked by microstimulation of the posterior parietal association cortex of the monkey. Exp. </title> <journal> Brain Res., </journal> <volume> 55, </volume> <pages> 1-8. </pages> <note> 26 Sun, </note> <author> J. S., & Irwin, D. E. </author> <year> (1987). </year> <title> Retinal masking during pursuit eye movements: Implications for spatiotopic visual persistence. </title> <journal> J. Exp. Psychol.: Hum. Percept. Perf., </journal> <volume> 13, </volume> <pages> 140-145. </pages>
Reference-contexts: After seeing repetitively clockward motion while looking left and anti-clockwise motion while right, subjects reported an anti-clockwise motion after-effect when looking right and clockwise motion when looking left (Mayhew, 1973). Neurons sensitive to rotational motion have been found in area MST and other relatively late stages of processing <ref> (Sakata, Shibutani, & Tsurugai, 1986) </ref>. We predict, however, that it should be possible to demonstrate contingent after-effect with translation motion or other elementary visual attribute such as orientation or disparity. Such result would suggest that these features are part of a retinospatiotopic map.
Reference: <author> Thier, P., & Andersen, R.A. </author> <year> (1992). </year> <title> Electrical microstimulation delineates 3 distinct eye-movement related areas in the posterior parietal cortex of the Rhesus monkey. </title> <journal> Abst. Soc. Neurosci., </journal> <volume> 17, </volume> <pages> 1281. </pages>
Reference-contexts: These are the eye movements expected for an attempt to foveate an illusory object whose position was at the site of stimulation as given in eye-centered coordinates. In contrast, electrical stimulation in area 7a produces convergent eye movements <ref> (Thier & Andersen, 1992) </ref>(see Fig. 2-C). We attempt to reconcile the conclusions drawn from electrical stimulation experiment with the gain modulation of neurons reported in the LGN, V1 and V3a. <p> Eye Field (FEF) (Robinson & Fuchs, 1969) B) Amplitude varying saccades (LIP)<ref> (Thier & Andersen, 1992) </ref>. Amplitude varies with initial position of eye. C) Convergent saccades. All saccades end in the same zone regardless of initial eye position. Such eye movements have been reported following stimulations in ventral intraparietal area (VIP) (Thier & Andersen, 1992). 6 area V1. Left plot: Stimulation on a site in V1 representing a position in the visual field 24 left 4 down. Right plot: same for a position 55 right, 12 up.
Reference: <author> Trotter, Y., Celebrini, S., Thorpe, S.J., & Imbert, M. </author> <year> (1991). </year> <title> Modulation of stereoscopic processing in primate visual cortex V1 by the distance fixation. </title> <journal> Abst. Soc. Neurosci., </journal> <volume> 17, </volume> <pages> 1016. </pages>
Reference-contexts: Models have already been developed for representing distance using disparity selective neurons whose gain is modulated by vergence angle (Lehky, Pouget, & Sejnowski, 1990). Neurons with these properties have been reported in area V1 of behaving monkeys <ref> (Trotter, et al., 1991) </ref>(There is also indirect evidence for vergence modulation of monocular neurons in the LGN (Kawanura & Marchiafava, 1966; Richards, 1968)). This model could be extended to include retinotopic maps, so that a similar retinospatial representation of egocentric distance might also be found in visual cortex. <p> Neurons involved in coding low-level features, such as orientation, in three-dimensional space would have to be selective for disparity as well as for eye position (in this case vergence angle). Such neurons have already been reported in V1 <ref> (Trotter, et al., 1991) </ref>. Eye-position modulation of neurons at early stages of the visual system may not be limited to the representation of egocentric space.
Reference: <author> Weyand, T. G., & Malpeli, J.G. </author> <year> (1989). </year> <title> Responses of neurons in primary visual cortex are influenced by eye position. </title> <journal> Abst. Soc. Neurosci., </journal> <volume> 15, </volume> <pages> 1016. </pages>
Reference: <author> Zipser, D., & Andersen, R. A. </author> <year> (1988). </year> <title> A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons. </title> <journal> Nature, </journal> <volume> 331, </volume> <pages> 679-684. 27 </pages>
Reference-contexts: Each hidden units encoded eye position with a rate code, that is, the rate of firing in the absence of visual stimulation was a monotonic function of eye position. Retinal position, on the other hand, was encoded through the organization of the receptive field of the hidden units <ref> (Zipser & Andersen, 1988) </ref>. The main point from the model was that no single hidden unit unambiguously coded the egocentric position, although they all carried partial information about both the eye and retinal position. The hidden layer of the network contained what is called a distributed representation of egocentric position. <p> Responses were plotted as circles with diameters proportional to activity; the set of nine circles has been termed by Zipser and Andersen <ref> (Zipser & Andersen, 1988) </ref> the spatial gain field of a unit because it shows how the amplitude, or gain, of the response varies with spatial position. <p> These gain fields are very similar to those reported by Zipser and Andersen <ref> (Zipser & Andersen, 1988) </ref>. The major difference is that the hidden units in our model had restricted receptive fields covering only a small portion of the retina, whereas theirs covered the whole retina.
References-found: 40

