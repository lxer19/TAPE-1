URL: file://ftp.it.kth.se/Reports/paradis/sl.ps.Z
Refering-URL: http://www.it.kth.se/~lisper/
Root-URL: http://www.it.kth.se
Title: Total Unfolding: Theory and Applications  
Author: Bjorn Lisper and 
Address: Electrum/204 S-164 40 Kista, SWEDEN  P.O. Box 1263 S-164 28 Kista, SWEDEN  
Affiliation: The Royal Institute of Technology Dept. of Teleinformatics  Swedish Institute of Computer Science  
Note: Journal of Functional Programming (1993), vol. 11, pp. 1-000  
Abstract: Unfolding is a common technique in program transformations. Here, we present a computation model where unfolding is a simple generalization of the usual concept of evaluation. The model is a variant of the well-known full substitution evaluation rule for recursive programs. The evaluation mechanism involved is symbolic substitution of function definitions followed by simplification. Simplification is expressed as a confluent rewrite strategy which uses three kinds of reductions: fi-reduction, non-erasing reduction, and erasing reduction. Non-erasing reductions include simplification of constant subexpressions. Erasing reductions formalize the behaviour of nonstrict operations. In this computation model, we prove a termination theorem of symbolic unfolding relative to more instantiated calls. A possible application of the model is a technique called total unfolding, where a partially instantiated function call is unfolded until no more calls exist. Under certain conditions the result will be a first order term: such terms correspond to basic blocks in imperative programs and can be efficiently implemented by scheduling techniques. Possible applications are hardware synthesis, and code generation for parallel machines. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aho, A. V., Sethi, R., & Ullman, J. D. </author> <year> 1986. </year> <title> Compilers: </title> <booktitle> Principles, techniques, and tools. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In extreme cases, repeated unfolding can be done until termination. This means that there are no function calls left in the specialized function. Often the residual will be a first order term. Such terms correspond to basic blocks <ref> (Aho et al. , 1986) </ref> in imperative languages. Powerful code optimization techniques are applicable to first order terms, due to the fact that their data dependence graph is fully known. Such optimizations include the sharing of subexpressions, scheduling of operations and register allocation.
Reference: <author> Arsac, J., & Kodratoff, Y. </author> <year> 1982. </year> <title> Some techniques for recursion removal from recursive functions. </title> <journal> ACM trans. program. lang. syst., </journal> <volume> 4(2), </volume> <pages> 295-322. </pages>
Reference-contexts: Such optimizations include the sharing of subexpressions, scheduling of operations and register allocation. As a simple example, consider the following function definition (similar to Dijkstra's "obfuscation function" (Dijkstra, 1982), also cf. <ref> (Arsac & Kodratoff, 1982, sec. 4.3.4) </ref>): f (x; n) if (n = 1; x; f (x; dn=2e) f (x; bn=2c)): Obviously, this recursion equation describes a balanced algorithm for computing x n when n 1. Consider now the partially instantiated function call f (x; 5).
Reference: <author> Barendregt, H. P. </author> <year> 1981. </year> <title> The lambda calculus its syntax and semantics. </title> <booktitle> Studies in Logic and the Foundations of Mathematics, </booktitle> <volume> vol. </volume> <pages> 103. </pages> <address> Amsterdam: </address> <publisher> North-Holland. </publisher>
Reference-contexts: F is terminating for a if there exists some n 0 such that F n (a) is a normal form. We then write F fl (a) for F n (a). F is terminating if it is terminating for all a under consideration. Cf. <ref> (Barendregt, 1981, p. 351) </ref>. We have the following: Proposition 2 If F is confluent and terminating, then a fl Total Unfolding: Theory and Applications 7 Proof Exactly analogous to the proof of lemma 2.1 in (Huet, 1980).
Reference: <author> Berlin, Andrew, & Weise, Daniel. </author> <year> 1990. </year> <title> Compiling scientific code using partial evaluation. </title> <journal> Computer, </journal> <volume> 23(12), </volume> <pages> 25-37. </pages>
Reference-contexts: It has been argued that total unfolding is rarely possible except for trivial cases (Sestoft, 1988). This is, however, very dependent on the application and the typical structure of its algorithms: scientific computing seems to be an area where total unfolding often is possible and beneficial <ref> (Berlin & Weise, 1990) </ref>. The reason is that numerical algorithms often are controlled by simple "size" parameters, like, say, matrix dimensions: once these parameters are known, total unfolding will then succeed and first-order residuals will most often result. <p> Numerical algorithms are often defined by straightforward recurrences that in many cases should be possible to treat by total unfolding techniques. Recent work regarding partial evaluation in scientific computing show encouraging results <ref> (Berlin & Weise, 1990) </ref>. Total unfolding and scheduling may provide new compilation methods for applicative languages that make them more suitable to scientific computing.
Reference: <author> Berry, Gerard, & Levy, Jean-Jacques. </author> <year> 1979. </year> <title> Minimal and optimal computations of recursive programs. </title> <journal> J. assoc. comput. mach., </journal> <volume> 26(1), </volume> <pages> 148-175. </pages>
Reference-contexts: A rewrite rule (s; t) is erasing if FV (s) oe FV (t), otherwise non-erasing. One more technical definition is needed. In order to keep track of where subterms go when a term is rewritten, we must define the notion of residual (Cf. <ref> (Berry & Levy, 1979) </ref>). Formally, we express this as a relation between "old" and "new" positions. This relation is a function of the term e to be rewritten, the position p of the redex, and the matching rewrite rule (s; t).
Reference: <editor> Bjorner, Dines, Ershov, A. P., & Jones, Neil D. (eds). </editor> <year> 1988. </year> <title> Partial evaluation and mixed computation. </title> <booktitle> proceedings of the IFIP TC2 workshop, </booktitle> <address> Gammel Avernaes, Denmark, Oct. 1987. </address> <publisher> North-Holland. </publisher>
Reference-contexts: Unfolding is most often followed by a simplification phase where constant subexpressions are evaluated, branches are selected in conditionals with known conditions etc. Unfolding and simplification are key techniques in partial evaluation <ref> (Bjorner et al. , 1988) </ref>. In partial evaluation a general function, called with partially known arguments, is replaced by a specialized version, the "residual", where the information about the arguments has been used to increase the efficiency of the code.
Reference: <author> Bondorf, A., & Danvy, O. </author> <year> 1991. </year> <title> Automatic autoprojection of recursive equations with global variables and abstract data types. </title> <booktitle> Science of computer programming, </booktitle> <volume> 16, </volume> <pages> 151-195. </pages>
Reference-contexts: These tests typically succeed when conditionals or the alike can be evaluated and a branch be selected, which simplifies the control structure of the resulting code and often enables further simplifications. The partial evaluator Similix uses this kind of condition <ref> (Bondorf & Danvy, 1991) </ref>. In extreme cases, repeated unfolding can be done until termination. This means that there are no function calls left in the specialized function. Often the residual will be a first order term. Such terms correspond to basic blocks (Aho et al. , 1986) in imperative languages.
Reference: <author> Burstall, R. M., & Darlington, J. </author> <year> 1977. </year> <title> A transformation system for developing recursive programs. </title> <journal> J. assoc. comput. mach., </journal> <volume> 24(1), </volume> <pages> 44-67. </pages>
Reference: <author> Cadiou, J. M. </author> <year> 1972. </year> <title> Recursive definitions of partial functions and their computation. </title> <type> Ph.D. thesis, </type> <institution> Stanford University, Stanford, California. </institution>
Reference-contexts: See (Courcelle, 1990) for a thorough introduction. Recursive Applicative Program Schemes have been used to prove properties of different evaluation orders for applicative languages, like correctness (implements the least fixpoint solution) <ref> (Cadiou, 1972) </ref> and optimality (Berry & Levy, 1979; Vuillemin, 1974). A salient feature of this kind of semantics is that it directly extends into symbolic computation: thus, it can be used to model various program transformations and prove properties of them. <p> In order to do this, we develop an operational model of recursive symbolic computation where program transformations like unfolding can be readily expressed. The model is a higher order variant of recursive applicative program schemes and essentially formalizes the full substitution computation rule <ref> (Cadiou, 1972) </ref>. This is a fixpoint computation rule: thus, our computation model is denotationally equivalent to lazy evaluation. Within the model we then show some theorems about total unfolding. Theorem 1 gives sufficient conditions for the unfolding to yield first order terms whenever it terminates. <p> Reconsider the example in section 1. The definition of the balanced x n -algorithm can be formally put as the substitution ff xn: if (n = 1; x; f (x; dn=2e) f (x; bn=2c))g: The full substitution evaluation rule is known to be a fixpoint computation rule <ref> (Cadiou, 1972) </ref>, i.e. it terminates with the correct answer exactly when the function that is least fixpoint solution of the recursive definition is defined. It can be 10 Bjorn Lisper informally described as follows.
Reference: <author> Chen, Marina C. </author> <year> 1986a. </year> <title> A design methodology for synthesizing parallel algorithms and architectures. </title> <journal> J. parallel distrib. comput., </journal> <pages> 461-491. </pages>
Reference: <author> Chen, Marina C. </author> <year> 1986b </year> <month> (Jan.). </month> <title> A parallel language and its compilation to multiprocessor machines or VLSI. </title> <booktitle> Pages 131-139 of: Proc. principles of programming languages. </booktitle>
Reference: <author> Courcelle, Bruno. </author> <year> 1990. </year> <title> Recursive applicative program schemes. </title> <journal> Chap. </journal> <volume> 9, </volume> <pages> pages 459-492 of: </pages> <editor> van Leeuwen, J. (ed), </editor> <booktitle> Handbook of theoretical computer science. </booktitle> <publisher> Elsevier Science Publishers B. V. </publisher>
Reference-contexts: 1 Introduction Operational semantics for applicative languages can be given by term rewriting systems. An example is Recursive Applicative Program Schemes, where recursive function definitions are considered as rewrite rules, possibly accompanied by additional rules that model "basic operations" in the language. See <ref> (Courcelle, 1990) </ref> for a thorough introduction. Recursive Applicative Program Schemes have been used to prove properties of different evaluation orders for applicative languages, like correctness (implements the least fixpoint solution) (Cadiou, 1972) and optimality (Berry & Levy, 1979; Vuillemin, 1974). <p> For instance, one can prove conditions for the correctness of the fold-unfold transformations pioneered by Burstall and Darlington (1977; 1976). See <ref> (Courcelle, 1990) </ref>. A particular kind of program transformation is unfolding, where function definitions are substituted for function calls and formal arguments are replaced by actual 2 Bjorn Lisper (possibly symbolic) arguments. <p> Again, we refer to the survey (Klop, 1992) for a comprehensive discussion of proof techniques. 4 Recursive programs In this section we give a formalization of recursive programs. Essentially it is a kind of recursive applicative program scheme <ref> (Courcelle, 1990) </ref>, albeit put in a form somewhat more convenient for our purposes. The operators of the language under consideration have their semantics defined by term rewriting systems and * as defined in section 3. <p> Cf. <ref> (Courcelle, 1990) </ref>, where a similar result is given. We now consider termination. It is essential to have a criterion that decides when a function call can be unfolded without risk of nontermination.
Reference: <author> Darlington, J., & Burstall, R. M. </author> <year> 1976. </year> <title> A system which automatically improves programs. </title> <journal> Acta inform., </journal> <volume> 6(1), </volume> <pages> 41-60. </pages>
Reference: <author> Delosme, Jean-Marc, & Ipsen, Ilse. </author> <year> 1987. </year> <title> Efficient systolic arrays for the solution of Toeplitz systems: an illustration of a methodology for the construction of systolic architectures in VLSI. Pages 37-46 of: </title> <editor> Moore, W., McCabe, A., & Urquhart, R. (eds), </editor> <title> Systolic arrays. </title> <address> Bristol, UK: Adam Hilger. </address>
Reference: <author> Dershowitz, Nachum, & Jouannaud, Jean-Pierre. </author> <year> 1991. </year> <title> Notations for rewriting. </title> <journal> Bulletin of the European Association for Theoretical Computer Science, </journal> <month> Feb., </month> <pages> 162-172. </pages>
Reference-contexts: For completeness, we give the main definitions involved, and some results that will be of use later. Details can be found in (Huet, 1980) and the survey 6 Bjorn Lisper (Klop, 1992). The notation is a mix of Huet's and the one suggested by Dershowitz and Jouannaud <ref> (Dershowitz & Jouannaud, 1991) </ref>.
Reference: <author> Dijkstra, E. W. </author> <year> 1982. </year> <title> An exercise for Dr. </title> <editor> R. M. Burstall. </editor> <booktitle> Pages 215-216 of: Selected writings a personal perspective on computer science. </booktitle> <address> Berlin: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Powerful code optimization techniques are applicable to first order terms, due to the fact that their data dependence graph is fully known. Such optimizations include the sharing of subexpressions, scheduling of operations and register allocation. As a simple example, consider the following function definition (similar to Dijkstra's "obfuscation function" <ref> (Dijkstra, 1982) </ref>, also cf. (Arsac & Kodratoff, 1982, sec. 4.3.4)): f (x; n) if (n = 1; x; f (x; dn=2e) f (x; bn=2c)): Obviously, this recursion equation describes a balanced algorithm for computing x n when n 1. Consider now the partially instantiated function call f (x; 5).
Reference: <author> Dougherty, Daniel J. </author> <year> 1992. </year> <title> Adding algebraic rewriting to the untyped lambda calculus. </title> <journal> Information and computation, </journal> <volume> 101, </volume> <pages> 251-267. </pages>
Reference-contexts: This relation is closed under replacement and substitution since it is a union of such relations. Of particular interest are term rewriting systems , * where ! fi* is also confluent and terminating, since then every reduction strategy must be confluent and terminating as well. A result of Dougherty <ref> (Dougherty, 1992) </ref> is particularly useful in this context and we give it below.
Reference: <author> Hindley, J. Roger, & Seldin, Jonathan P. </author> <year> 1986. </year> <title> Introduction to combinators and -calculus. </title> <journal> London Mathematical Society Student Texts, </journal> <volume> vol. </volume> <pages> 1. </pages> <address> Cambridge, UK: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Substitutions on higher-order terms must include some renaming scheme to avoid capturing of free variables, see for instance <ref> (Hindley & Seldin, 1986) </ref>. Composition of substitutions is defined as oe 1 oe 2 = f x oe 1 (oe 2 (x)) j x 2 dom (oe 2 ) g [oe 1 j dom (oe 1 )ndom (oe 2 ) ("j" denotes restriction of function).
Reference: <author> Huang, Chua-Huang, & Lengauer, Christian. </author> <year> 1987. </year> <title> The derivation of systolic implementations of programs. </title> <journal> Acta inform., </journal> <volume> 24, </volume> <pages> 595-632. </pages>
Reference: <author> Huet, Gerard. </author> <year> 1980. </year> <title> Confluent reductions: Abstract properties and applications to term rewriting systems. </title> <journal> J. assoc. comput. mach., </journal> <volume> 27(4), </volume> <pages> 797-821. </pages>
Reference-contexts: This proof method will be frequently used here. See <ref> (Huet, 1980) </ref> for a more thorough introduction to noetherian relations and induction. <p> The two types of non-fi-simplifications above will be modelled by term rewriting systems. For completeness, we give the main definitions involved, and some results that will be of use later. Details can be found in <ref> (Huet, 1980) </ref> and the survey 6 Bjorn Lisper (Klop, 1992). The notation is a mix of Huet's and the one suggested by Dershowitz and Jouannaud (Dershowitz & Jouannaud, 1991). <p> F is terminating if it is terminating for all a under consideration. Cf. (Barendregt, 1981, p. 351). We have the following: Proposition 2 If F is confluent and terminating, then a fl Total Unfolding: Theory and Applications 7 Proof Exactly analogous to the proof of lemma 2.1 in <ref> (Huet, 1980) </ref>. Proposition 3 If F is terminating and if ! is confluent, then F is confluent. Proof F fl (x) exists for all x since F is terminating. <p> The following lemma is the direct generalization of Proposition 3.4 in <ref> (Huet, 1980) </ref>. Lemma 1 If no variable in dom (oe) [ rg (oe) is bound in t, then it holds that: 1. Pos (oe (t)) = Pos (t) [ p2VPos (t) f pp 0 j p 0 2 Pos (oe (t=p)) g. 2.
Reference: <author> Karp, R. M., Miller, R. E., & Winograd, S. </author> <year> 1967. </year> <title> The organization of computations for uniform recurrence equations. </title> <journal> J. assoc. comput. mach., </journal> <volume> 14(3), </volume> <pages> 563-590. </pages>
Reference: <author> Klop, Jan Willem. </author> <year> 1992. </year> <title> Term rewriting systems. </title> <journal> Chap. </journal> <volume> 1, </volume> <pages> pages 1-116 of: </pages> <editor> Abramsky, Samson, Gabbay, Dov M., & Maibaum, T. S. E. (eds), </editor> <booktitle> Handbook of logic in computer science, </booktitle> <volume> vol. 2. </volume> <publisher> Oxford: Oxford University Press. </publisher>
Reference-contexts: The two types of non-fi-simplifications above will be modelled by term rewriting systems. For completeness, we give the main definitions involved, and some results that will be of use later. Details can be found in (Huet, 1980) and the survey 6 Bjorn Lisper <ref> (Klop, 1992) </ref>. The notation is a mix of Huet's and the one suggested by Dershowitz and Jouannaud (Dershowitz & Jouannaud, 1991). <p> Thus, under the weak condition of R-stability, the question whether ! fi* is confluent and terminating reduces to the question whether ! * is confluent and terminating. How to prove such properties of term rewriting systems is a well researched subject. Again, we refer to the survey <ref> (Klop, 1992) </ref> for a comprehensive discussion of proof techniques. 4 Recursive programs In this section we give a formalization of recursive programs. Essentially it is a kind of recursive applicative program scheme (Courcelle, 1990), albeit put in a form somewhat more convenient for our purposes.
Reference: <author> Kung, H. T. </author> <year> 1982. </year> <title> Why systolic architectures? Computer, </title> <booktitle> 15(Jan.), </booktitle> <pages> 37-46. </pages> <note> 20 Bjorn Lisper Kung, </note> <author> S. Y. </author> <year> 1987. </year> <title> VLSI array processors. Pages 7-24 of: </title> <editor> Moore, Will, McCabe, Andrew, & Urquhart, Roddy (eds), </editor> <title> Systolic arrays. </title> <address> Bristol, UK: Adam Hilger. </address>
Reference-contexts: Here, the scheduling can take place already at "design-time". Once a schedule is determined, a parallel system that supports the schedule with a minimum of control can be designed. In particular, regular hardware systems like systolic arrays <ref> (Kung, 1982) </ref> are amenable to synthesis by scheduling methods (Chen, 1986a; Delosme & Ipsen, 1987; Huang & Lengauer, 1987; Kung, 1987; Lisper, 1989; Lisper, 1990b; Moldovan, 1982; Quinton, 1984; Rajopadye & Fujimoto, 1990; Rao & Kailath, 1988).
Reference: <author> Lisper, Bjorn. </author> <year> 1989. </year> <title> Synthesis of synchronous systems by static scheduling in space-time. </title> <booktitle> Lecture Notes in Comput. Sci., </booktitle> <volume> vol. </volume> <pages> 362. </pages> <address> Heidelberg: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Lisper, Bjorn. </author> <year> 1990a. </year> <title> The Interactive Space-Time Scheduler. </title> <journal> Microprocessing and microprogramming, </journal> <pages> 30(1-5), 109-116. </pages>
Reference: <author> Lisper, Bjorn. </author> <year> 1990b. </year> <title> Synthesis of time-optimal systolic arrays with cells with inner structure. </title> <journal> J. parallel distrib. comput., </journal> <volume> 10(2), </volume> <pages> 182-187. </pages>
Reference: <author> Moldovan, Dan I. </author> <year> 1982. </year> <title> On the analysis and synthesis of VLSI algorithms. </title> <journal> IEEE trans. comput., </journal> <volume> C-31(Oct.), </volume> <pages> 1121-1126. </pages>
Reference: <author> Quinton, Patrice. </author> <year> 1984 </year> <month> (June). </month> <title> Automatic synthesis of systolic arrays from uniform recurrent equations. </title> <booktitle> Pages 208-214 of: Proc. 11th annual int. symp. on comput. </booktitle> <pages> arch. </pages>
Reference: <author> Rajopadye, Sanjay V., & Fujimoto, Richard M. </author> <year> 1990. </year> <title> Synthesizing systolic arrays from recurrence equations. </title> <journal> Parallel computing, </journal> <volume> 14, </volume> <pages> 163-189. </pages>
Reference: <author> Rao, Sailesh K., & Kailath, Thomas. </author> <year> 1988. </year> <title> Regular iterative algorithms and their implementation on processor arrays. </title> <journal> Proc. IEEE, </journal> <volume> 76(3), </volume> <pages> 259-269. </pages>
Reference: <author> Raoult, Jean-Claude, & Vuillemin, Jean. </author> <year> 1980. </year> <title> Operational and semantic equivalence between recursive programs. </title> <journal> J. assoc. comput. mach., </journal> <volume> 27(4), </volume> <pages> 772-796. </pages>
Reference-contexts: Proof t ! fi* F fl t implies oet ! fi* oeF fl t. Proposition 2 now gives the result. An immediate consequence of lemma 2 is that (F fl ) n t = F fl n t for all n &gt; 0. Proposition 11 of <ref> (Raoult & Vuillemin, 1980) </ref> says essentially the same thing, but in a somewhat more restricted computation model. Theorem 2 (Correctness of unfolding) (F fl ) fl (F fl ) fl t = (F fl ) fl t, whenever (F fl ) fl is defined for the terms in question.
Reference: <author> Sestoft, Peter. </author> <year> 1985. </year> <title> The structure of a self-applicable partial evaluator. Pages 236-256 of: </title> <editor> Ganzinger, H., & Jones, N. P. (eds), </editor> <title> Programs as data objects. Berlin: </title> <booktitle> Volume 217 of Lecture Notes in Comput. </booktitle> <publisher> Sci., Springer-Verlag. </publisher>
Reference-contexts: It follows that for any value of n 0, f (x; n) will be unfolded to a finite first-order term. Apparently, techniques like Known/Unknown abstract interpretation <ref> (Sestoft, 1985) </ref>, normally used for binding-time analysis, can be useful. Methods to schedule dependence graphs directly from function definitions, without actually creating the graphs, have a potentially great practical importance, since in practice the unfolded graphs can be prohibitively large.
Reference: <author> Sestoft, Peter. </author> <year> 1988. </year> <title> Automatic call unfolding in a partial evaluator. Pages 485-506 of: </title> <editor> Bjorner, Dines, Ershov, Andrei P., & Jones, Neil D. (eds), </editor> <title> Partial evaluation and mixed computation. </title> <booktitle> proceedings of the IFIP TC2 workshop, </booktitle> <address> Gammel Avernaes, Denmark, Oct. 1987. </address> <publisher> North-Holland. </publisher>
Reference-contexts: Thus, it is important to have conditions when unfolding can proceed safely without risk of non-termination. Such conditions can be divided into two classes. The first class consists of conditions that really ensure termination. An example is Sestoft's structural induction condition <ref> (Sestoft, 1988) </ref>. While these conditions yields safe results when succeeding, their applicability is limited: the reason is that the problem to be solved is the undecidable halting problem for symbolic computation. In practice one is restricted to a number of easily recognizable cases, unless theorem proving methods are used. <p> We may coin unfolding until termination "total unfolding". It has been argued that total unfolding is rarely possible except for trivial cases <ref> (Sestoft, 1988) </ref>. This is, however, very dependent on the application and the typical structure of its algorithms: scientific computing seems to be an area where total unfolding often is possible and beneficial (Berlin & Weise, 1990).
Reference: <author> Shang, Weijia, & Fortes, Jose A. B. </author> <year> 1989. </year> <title> On the optimality of linear schedules. </title> <journal> J. VLSI signal processing, </journal> <volume> 1, </volume> <pages> 209-220. </pages>
Reference: <author> Thompson, Simon. </author> <year> 1991. </year> <title> Type theory and functional programming. </title> <booktitle> International computer science series. </booktitle> <publisher> Addison-Wesley. </publisher>
Reference-contexts: We denote the finest relation containing fi, closed under replacement, by ! fi . ! fi is confluent, closed under substitution, and for certain -calculi, most notably the simply typed -calculus, it is also terminating. See, for instance, <ref> (Thompson, 1991) </ref>. Next comes non-erasing reductions: we model these by a term rewrite system with only non-erasing rules. In particular, can have ffi-rules (t; t 0 ) where t and t 0 are closed terms.
Reference: <author> Vuillemin, Jean. </author> <year> 1974. </year> <title> Correct and optimal implementations of recursion in a simple programming language. </title> <journal> Journal of computer and system sciences, </journal> <volume> 9, </volume> <pages> 332-254. </pages>
References-found: 36

