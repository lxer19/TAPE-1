URL: ftp://speech.cse.ogi.edu/pub/docs/verify_icassp96.ps.gz
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Email: (johans@cse.ogi.edu)  
Title: SPEAKER VERIFICATION WITH LOW STORAGE REQUIREMENTS  
Author: Johan Schalkwyk, Neena Jain and Etienne Barnard 
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000, USA,  
Affiliation: Center for Spoken Language Understanding, Oregon Graduate Institute of Science and Technology,  
Abstract: As speaker verification continues to gain acceptance for security applications, the day is drawing near when millions of users worldwide will be using some form of speaker verification system to gain access to secure information. These accesses will most probably be via the telephone network. Within this scenario a huge data flow across long distances is expected, in order to have the speaker's templates available for verification. This paper presents initial work on reducing the data requirements for text-dependent speaker verification. It is shown how data storage and accuracy can be traded off in such systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. P. Eatock and J. S. Mason, </author> <title> "A quantitative assessment of the relative speaker discriminating properties of phonemes," </title> <booktitle> in ICASSP, </booktitle> <volume> vol. 1, </volume> <pages> pp. 133-136, </pages> <year> 1994. </year>
Reference-contexts: For more information contact noel@cse.ogi.edu 3. DATA REDUCTION EXPERIMENTS 3.1. Comparing acoustic features of specific phonemes It is clear that different phonemes will contain different amounts of information for distinguishing between speakers, since different aspects of the articulators are involved. This intuition has been verified theoretically <ref> [1, 2] </ref>, and suggests that data storage requirements can be reduced by focusing on the more informative phonemes. We thus wish to use these distinguishing phonemes for verification. During training, the phonetic string representing the password is estimated by a speaker-independent phoneme classifier as described in [3]. <p> The following algorithmic considerations were investigated * Effect of class of phonemes The aim of this experiment was to decide which group of phonemes should be used for representing the speaker. Since nasals and vowels have been shown to be more distinguishing than other phonemes <ref> [1] </ref>, experiments were performed wherein 2 phonemes were picked from the class of (a) all vowels, (b) only stressed vowels, (c) nasals and all vowels, and (d) nasals and stressed vowels. 20 cepstral coefficients computed from a 20'th order LPC model were averaged over the interval corresponding to the first two
Reference: [2] <author> E. S. Parris and M. J. Carey, </author> <title> "Discriminative phonemes for speaker identification," </title> <booktitle> in ICSLP, </booktitle> <volume> vol. 4, </volume> <pages> pp. 1843-1846, </pages> <year> 1994. </year>
Reference-contexts: For more information contact noel@cse.ogi.edu 3. DATA REDUCTION EXPERIMENTS 3.1. Comparing acoustic features of specific phonemes It is clear that different phonemes will contain different amounts of information for distinguishing between speakers, since different aspects of the articulators are involved. This intuition has been verified theoretically <ref> [1, 2] </ref>, and suggests that data storage requirements can be reduced by focusing on the more informative phonemes. We thus wish to use these distinguishing phonemes for verification. During training, the phonetic string representing the password is estimated by a speaker-independent phoneme classifier as described in [3].
Reference: [3] <author> N. Jain, "Ms-thesis: </author> <title> A new approach for voice-dialing," </title> <type> tech. rep., </type> <institution> Oregon Graduate Institute, </institution> <year> 1995. </year> <note> http://www.cse.ogi.edu/CSLU/cslu.publications.html. </note>
Reference-contexts: We thus wish to use these distinguishing phonemes for verification. During training, the phonetic string representing the password is estimated by a speaker-independent phoneme classifier as described in <ref> [3] </ref>. Specific phonemes are then selected as they are considered to be more representative of the speaker than other phonemes. Features are computed from the speech signal corresponding to the selected phonemes. These feature vectors along with the phonetic string form the speaker model.
Reference: [4] <author> S. Furui, </author> <title> "An overview of speaker recogntion technology," in Workshop on Automatic Speaker Recognition Identification and Verification, </title> <journal> pp. </journal> <pages> 1-9, ESCA, </pages> <year> 1994. </year>
Reference-contexts: Equal error rate as a function of # bytes used for the DTW with subsampling algorithm. 3.4. Dynamic time warping and Vector quantiza tion One of the pitfalls of text dependent recognition algorithms, such as dynamic time warping, is their inability to take advantage of cohort speaker normalization techniques <ref> [4] </ref>. Although our database has many other speakers repeating the same password, in reality though it is highly unlikely that a speaker will have the same chosen password as other speakers in the database.
Reference: [5] <author> J. Bonifas, I. Hernaez Rioja, B. Etxebarra Gonzales, and S. Saoudi, </author> <title> "Text-dependent speaker verification using dynamic time warping and vector quantization of lsf," </title> <booktitle> in Eurospeech, </booktitle> <volume> vol. 1, </volume> <year> 1995. </year>
Reference-contexts: Template matching techniques which are a necessary part of text dependent speaker verification therefore have limitations due to this problem. Similar to <ref> [5] </ref> we propose a combination of dynamic time warping and vector quantization. Here we use a text independent verification method in combination with the template matching algorithm. <p> EXPERIMENTS IN CHANNEL ROBUSTNESS Under matched channel conditions we can achieve a high level of false speaker rejection while still maintaining a respectable true speaker acceptance rate. Similar results have been reported in literature <ref> [5, 7] </ref>.
Reference: [6] <author> Y. Muthusamy, R. Cole, and B. Oshika, </author> <title> "The ogi-multi language telephone speech corpus," </title> <booktitle> in ICSLP, </booktitle> <pages> pp. 895-898, </pages> <year> 1992. </year>
Reference-contexts: The vector code-book was trained on all English phonemes extracted from multiple speakers in the OGI-TS <ref> [6] </ref> database. The vector code-book therefore presents a speaker-independent description of the feature space over all English phonemes in this corpus. As in the previous section, we use dynamic time warping with a total of 60 segments, each of width 50 ms, as the template matching algorithm.
Reference: [7] <author> K. Farrel, </author> <title> "Text-dependent speaker verification using data fusion," </title> <booktitle> in ICASSP, </booktitle> <volume> vol. 1, </volume> <pages> pp. 349-352, </pages> <year> 1995. </year>
Reference-contexts: EXPERIMENTS IN CHANNEL ROBUSTNESS Under matched channel conditions we can achieve a high level of false speaker rejection while still maintaining a respectable true speaker acceptance rate. Similar results have been reported in literature <ref> [5, 7] </ref>.
Reference: [8] <author> H. Hermansky, N. Morgan, A. Baya, and P. Kohn, </author> <title> "Compensation for the effect of the communication channel in auditory-like analysis of speech (rasta-plp)," </title> <booktitle> in Eurospeech, </booktitle> <volume> vol. 1, </volume> <pages> pp. 1367-1370, </pages> <year> 1991. </year>
Reference-contexts: This results in a total of 594 true speaker verifications and 19008 imposter speaker verifications per password. To compensate for linear channel distortions we integrated RASTA <ref> [8] </ref> processing with the LPC model. In effect the RASTA filter, band-passes each cepstral coefficient. Linear channel distortions appear as an additive constant in the cepstral domain. The high-pass portion of the equivalent band-pass filter alleviates the effect of convolutional noise introduced in the channel.
References-found: 8

