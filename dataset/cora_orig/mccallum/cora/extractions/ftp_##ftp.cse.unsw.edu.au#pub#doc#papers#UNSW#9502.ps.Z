URL: ftp://ftp.cse.unsw.edu.au/pub/doc/papers/UNSW/9502.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/research/tr.html
Root-URL: http://www.cse.unsw.edu.au
Email: jinsong,gernot@cse.unsw.edu.au  
Title: Checkpointing and Recovery for Distributed Shared Memory Applications  
Author: Jinsong Ouyang and Gernot Heiser 
Date: June, 1995  
Address: Sydney 2052, Australia  
Affiliation: School of Computer Science and Engineering University of New South Wales  
Pubnum: UNSW-CSE-TR-9502  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Adve and M. Hill. </author> <title> Weak ordering Anew definition. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-14, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: DSM runtime system; 5. processes communicate with each other through distributed shared memory 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models <ref> [1, 4, 6, 8, 11, 13] </ref> on which our system is built|release consistency [4, 8]. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses.
Reference: [2] <author> M. Ahuja. </author> <title> Flush primitives for asynchronous distributed systems. </title> <journal> Information Processing Letters 34, </journal> <pages> pages 5-12, </pages> <year> 1990. </year> <month> 12 </month>
Reference: [3] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency control and recovery in database systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference: [4] <author> J.B. Carter. </author> <title> Efficient distributed shared memory based on multi-protocol release consistency. </title> <type> Ph.D thesis, </type> <institution> Rice University. </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: DSM runtime system; 5. processes communicate with each other through distributed shared memory 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models <ref> [1, 4, 6, 8, 11, 13] </ref> on which our system is built|release consistency [4, 8]. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses. <p> 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models [1, 4, 6, 8, 11, 13] on which our system is built|release consistency <ref> [4, 8] </ref>. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses. <p> In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses. Formally, a system is release consistent if <ref> [4] </ref>: 1. before any ordinary access is allowed to perform with respect to any other processor, all previous acquires must be performed; 2. before a release is allowed to perform with respect to any other processor, all previous ordinary accesses must be performed; 3. synchronisation accesses must be sequentially consistent with
Reference: [5] <author> K. Chandy and L. Lamport. </author> <title> Distributed snapshots: Determining global states of distributed systems. </title> <journal> ACM Trans. Comput. Systems, </journal> <volume> vol. 3, no. 1, </volume> <pages> pages 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: We present the conclusion in Section 6. 2 Background The key issue of supporting fault tolerance in distributed systems using checkpointing and rollback recovery is how to obtain a consistent state of a distributed system. Chandy and Lamport <ref> [5] </ref> formally defined the concept of a consistent distributed system state, and introduced an algorithm by which a process in a distributed system determines a global state of the system during a computation.
Reference: [6] <author> M. Dubois and C. Scheurich. </author> <title> Memory access dependencies in shared-memory multiprocessor. </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> 16(6) </volume> <pages> 660-673, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: DSM runtime system; 5. processes communicate with each other through distributed shared memory 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models <ref> [1, 4, 6, 8, 11, 13] </ref> on which our system is built|release consistency [4, 8]. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses.
Reference: [7] <author> E.N. Elnozahy, D.B. Johnson, and W. Zwaenepoel. </author> <title> The performance of consistent check-pointing. </title> <booktitle> In Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 39-47, </pages> <month> October, </month> <year> 1992. </year>
Reference-contexts: So, this type of approach focusses on reducing communication overhead during the checkpointing and message logging phases, and puts most work into the recovery phase. It is assumed in these systems that failures are infrequent. 2. Consistent checkpointing: This type of system <ref> [7, 10, 12, 17, 19, 22] </ref> attempts to construct a consistent distributed system state in a checkpointing phase. Checkpointing of processes is synchronised in such a way that the resulting set of checkpoints forms a consistent distributed system state; consequently, this makes rollback recovery less expensive. <p> We first describe the techniques used for consistent checkpointing. * For each distributed application, there is one distinguished FTSM on a node which acts as the coordinator of checkpointing and recovery. * Like some other systems <ref> [7, 17, 19] </ref>, each consistent checkpoint is uniquely identified by an increasing checkpointing sequence number (CSN), and each normal message delivered in the system is tagged with the current CSN of the sender. Besides, each normal message is also tagged with the status bit of the sender.
Reference: [8] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: DSM runtime system; 5. processes communicate with each other through distributed shared memory 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models <ref> [1, 4, 6, 8, 11, 13] </ref> on which our system is built|release consistency [4, 8]. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses. <p> 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models [1, 4, 6, 8, 11, 13] on which our system is built|release consistency <ref> [4, 8] </ref>. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses.
Reference: [9] <author> D.B. Johnson and W. Zwaenepoel. </author> <title> Recovery in distributed systems using optimistic message Logging and checkpointing. </title> <journal> Journal of Algorithms, </journal> <volume> vol. 11, </volume> <pages> pages 462-491, </pages> <year> 1990. </year>
Reference-contexts: According to when and how a consistent state of a distributed system is built, the existing systems can be divided into two classes as follows: 1. Independent checkpointing and message logging: In this type of system <ref> [9, 20, 21] </ref>, the main idea is that processes do not need to synchronise with one another during the checkpointing and message logging phases, which means that individual processes perform their message logging and checkpointing independently, reducing communication overhead in this phase.
Reference: [10] <author> D.B. Johnson. </author> <title> Efficient transparent optimistic rollback recovery for distributed application programs. </title> <booktitle> In Proceedings of the 12th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 86-95, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: So, this type of approach focusses on reducing communication overhead during the checkpointing and message logging phases, and puts most work into the recovery phase. It is assumed in these systems that failures are infrequent. 2. Consistent checkpointing: This type of system <ref> [7, 10, 12, 17, 19, 22] </ref> attempts to construct a consistent distributed system state in a checkpointing phase. Checkpointing of processes is synchronised in such a way that the resulting set of checkpoints forms a consistent distributed system state; consequently, this makes rollback recovery less expensive. <p> distributed shared memory model, release consistency, we can make the following optimisation to further reduce the consistent checkpointing overhead: A new consistent checkpoint can be triggered by such events as the expiry of a time interval, a certain number of release accesses performed, or an output to the outside world <ref> [10] </ref>. For example, when the processor on which the coordinator resides is about to perform a release, and the number of releases performed exceeds a predefined number, the coordinator may start a new consistent checkpoint at this time.
Reference: [11] <author> P. Keleher, A.L. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: DSM runtime system; 5. processes communicate with each other through distributed shared memory 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models <ref> [1, 4, 6, 8, 11, 13] </ref> on which our system is built|release consistency [4, 8]. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses.
Reference: [12] <author> R. Koo and S. Toueg. </author> <title> Checkpointing and rollback-recovery for distributed systems. </title> <journal> IEEE Trans. Software Eng, </journal> <volume> vol. 13, no. 1, </volume> <pages> pages 23-31, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: So, this type of approach focusses on reducing communication overhead during the checkpointing and message logging phases, and puts most work into the recovery phase. It is assumed in these systems that failures are infrequent. 2. Consistent checkpointing: This type of system <ref> [7, 10, 12, 17, 19, 22] </ref> attempts to construct a consistent distributed system state in a checkpointing phase. Checkpointing of processes is synchronised in such a way that the resulting set of checkpoints forms a consistent distributed system state; consequently, this makes rollback recovery less expensive.
Reference: [13] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Trans. Computers, </journal> <volume> C-28(9):241-248, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: DSM runtime system; 5. processes communicate with each other through distributed shared memory 1 . 1 Our model can be built on either message-passing systems or distributed shared memory systems. 3 3.2 Distributed shared memory model In this section, we briefly describe one of the typical distributed shared memory models <ref> [1, 4, 6, 8, 11, 13] </ref> on which our system is built|release consistency [4, 8]. In the release consistency model, not only is each shared memory access classified either as a synchronisation access or an ordinary access, but synchronisation accesses must be classified as acquire and release accesses.
Reference: [14] <author> T.H. Lai and T.H. Yang. </author> <title> On distributed snapshots. </title> <journal> Information Processing Letters, </journal> <volume> 25, </volume> <pages> pages 153-158, </pages> <month> May </month> <year> 1987. </year>
Reference: [15] <author> K. Li, J.F. Naughton, and J.S. Plank. </author> <title> Real-time, concurrent checkpoint for parallel programs. </title> <booktitle> In Proceedings of the 1990 Conference on the Principles and Practice of Parallel Programming, </booktitle> <pages> pages 79-88, </pages> <month> March </month> <year> 1990. </year>
Reference: [16] <author> K. Li, J.F. Naughton, and J.S. Plank. </author> <title> Low-latency, concurrent checkpointing for parallel programs. </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 8, </volume> <pages> pages 874-879, </pages> <month> August </month> <year> 1994. </year>
Reference: [17] <author> K. Li, J.F. Naughton, and J.S. Plank. </author> <title> Checkpointing multicomputer applications. </title> <booktitle> In Pro--ceedings of the 10th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 66-75, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: So, this type of approach focusses on reducing communication overhead during the checkpointing and message logging phases, and puts most work into the recovery phase. It is assumed in these systems that failures are infrequent. 2. Consistent checkpointing: This type of system <ref> [7, 10, 12, 17, 19, 22] </ref> attempts to construct a consistent distributed system state in a checkpointing phase. Checkpointing of processes is synchronised in such a way that the resulting set of checkpoints forms a consistent distributed system state; consequently, this makes rollback recovery less expensive. <p> Systems using a one-phase commit protocol must always keep the two most recent checkpoints for each process. 3 System model 3.1 Assumption Our work is partially motivated by the systems <ref> [17, 18, 19] </ref>, and focusses on the above issues which were not addressed in the previous systems. We make the following assumptions about the distributed environment on which our model is built: 1. nodes fail by stopping. <p> We first describe the techniques used for consistent checkpointing. * For each distributed application, there is one distinguished FTSM on a node which acts as the coordinator of checkpointing and recovery. * Like some other systems <ref> [7, 17, 19] </ref>, each consistent checkpoint is uniquely identified by an increasing checkpointing sequence number (CSN), and each normal message delivered in the system is tagged with the current CSN of the sender. Besides, each normal message is also tagged with the status bit of the sender.
Reference: [18] <author> F. Mattern. </author> <title> Efficient algorithms for distributed snapshots and global virtual time approximation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 18, </volume> <pages> pages 423-434, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Systems using a one-phase commit protocol must always keep the two most recent checkpoints for each process. 3 System model 3.1 Assumption Our work is partially motivated by the systems <ref> [17, 18, 19] </ref>, and focusses on the above issues which were not addressed in the previous systems. We make the following assumptions about the distributed environment on which our model is built: 1. nodes fail by stopping. <p> sections we propose two mechanisms to deal with this issue. 2 A message is in transit if it is sent before the sender takes the current checkpoint, and is received after the receiver takes the current checkpoint. 6 4.2.1 Mechanism 1 This mechanism is derived from the approach by Mattern <ref> [18] </ref>. It differs from Mattern's system in two respects: 1.
Reference: [19] <author> L.M. Silva and J.G. Silva. </author> <title> Global checkpointing for distributed programs. </title> <booktitle> In Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 155-162, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: So, this type of approach focusses on reducing communication overhead during the checkpointing and message logging phases, and puts most work into the recovery phase. It is assumed in these systems that failures are infrequent. 2. Consistent checkpointing: This type of system <ref> [7, 10, 12, 17, 19, 22] </ref> attempts to construct a consistent distributed system state in a checkpointing phase. Checkpointing of processes is synchronised in such a way that the resulting set of checkpoints forms a consistent distributed system state; consequently, this makes rollback recovery less expensive. <p> Systems using a one-phase commit protocol must always keep the two most recent checkpoints for each process. 3 System model 3.1 Assumption Our work is partially motivated by the systems <ref> [17, 18, 19] </ref>, and focusses on the above issues which were not addressed in the previous systems. We make the following assumptions about the distributed environment on which our model is built: 1. nodes fail by stopping. <p> We first describe the techniques used for consistent checkpointing. * For each distributed application, there is one distinguished FTSM on a node which acts as the coordinator of checkpointing and recovery. * Like some other systems <ref> [7, 17, 19] </ref>, each consistent checkpoint is uniquely identified by an increasing checkpointing sequence number (CSN), and each normal message delivered in the system is tagged with the current CSN of the sender. Besides, each normal message is also tagged with the status bit of the sender.
Reference: [20] <author> R. Strom and S. Yemini. </author> <title> Optimistic recovery in distributed systems. </title> <journal> ACM Trans. Comput. Systems, </journal> <volume> vol. 3, no. 3, </volume> <pages> pages 204-226, </pages> <year> 1985. </year>
Reference-contexts: According to when and how a consistent state of a distributed system is built, the existing systems can be divided into two classes as follows: 1. Independent checkpointing and message logging: In this type of system <ref> [9, 20, 21] </ref>, the main idea is that processes do not need to synchronise with one another during the checkpointing and message logging phases, which means that individual processes perform their message logging and checkpointing independently, reducing communication overhead in this phase.
Reference: [21] <author> A.P. Sistla and J.L. Welch. </author> <title> Efficient distributed recovery using message logging. </title> <booktitle> In Proceedings of the 8th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August, </month> <year> 1989. </year>
Reference-contexts: According to when and how a consistent state of a distributed system is built, the existing systems can be divided into two classes as follows: 1. Independent checkpointing and message logging: In this type of system <ref> [9, 20, 21] </ref>, the main idea is that processes do not need to synchronise with one another during the checkpointing and message logging phases, which means that individual processes perform their message logging and checkpointing independently, reducing communication overhead in this phase.
Reference: [22] <author> T.J. Wilkinson. </author> <title> Implementing fault tolerance in a 64-bit distributed operating system. </title> <type> Ph.D thesis, </type> <institution> City Univ., </institution> <address> London, </address> <month> July </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: So, this type of approach focusses on reducing communication overhead during the checkpointing and message logging phases, and puts most work into the recovery phase. It is assumed in these systems that failures are infrequent. 2. Consistent checkpointing: This type of system <ref> [7, 10, 12, 17, 19, 22] </ref> attempts to construct a consistent distributed system state in a checkpointing phase. Checkpointing of processes is synchronised in such a way that the resulting set of checkpoints forms a consistent distributed system state; consequently, this makes rollback recovery less expensive.
References-found: 22

