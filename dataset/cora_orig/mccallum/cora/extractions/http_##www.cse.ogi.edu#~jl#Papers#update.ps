URL: http://www.cse.ogi.edu/~jl/Papers/update.ps
Refering-URL: http://www.cse.ogi.edu/~jl/biblio-analysis.html
Root-URL: http://www.cse.ogi.edu
Title: Avoiding Unnecessary Updates  
Author: John Launchbury, Andy Gill, John Hughes, Simon Marlow, Simon Peyton Jones, Philip Wadler 
Affiliation: Computing Science Department, Glasgow University  
Abstract: Graph reduction underlies most implementations of lazy functional languages, allowing separate computations to share results when sub-terms are evaluated. Once a term is evaluated, the node of the graph representing the computation is updated with the value of the term. However, in many cases, no other computation requires this value, so the update is unnecessary. In this paper we take some steps towards an analysis for determining when these updates may be omitted.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Girard, Scedrov, and Scott, </author> <title> Bounded Linear Logic, </title> <journal> J of Theoretical Computer Science, </journal> <volume> 97 </volume> <pages> 1-66, </pages> <year> 1992. </year>
Reference-contexts: Whether the relatively small gain in accuracy would be worth while or not is not clear. 6 Relationship to Linear Logic There is obviously a close relationship between linear logic the rules presented here. The version of linear logic most closely related is bounded linear logic <ref> [1] </ref>, where annotations are placed on the "bangs" to indicate how often a term is used. So rather than using !T which describes a type that can be copied as often as required (ie. an unbounded number of times), types such as ! n T are used.
Reference: [2] <author> J.Fairbairn and S.Wray, </author> <title> A Simple Lazy Abstract-Machine to Execute Su-percombinators, </title> <booktitle> in Proc. FPCA, Portland, </booktitle> <pages> pp 34-45, </pages> <address> S-V, </address> <year> 1987. </year>
Reference-contexts: On the parallel machine GRIP [5] updates are particularly expensive because the updated node has to be flushed from local memory out to the global store. Similarly, the need for updates creates a major complication in the TIM abstract machine <ref> [2] </ref>, and the presence of the update markers interrupts the flow of evaluation. Indeed, Fairbain and Wray used a local analysis to cut down on such update markers, but unfortunately the analysis assumed a fairly naive model of implementation and precluded more efficient alternative implementations.
Reference: [3] <author> J.Launchbury, </author> <title> A Natural Semantics for Lazy Evaluation, </title> <booktitle> in Proc. ACM SIGPLAN Principles of Programming Languages, </booktitle> <address> Charleston, South Car-olina, </address> <year> 1993. </year>
Reference-contexts: The denotational seman-tics is too high|it doesn't distinguish between normal-order reduction and lazy evaluation|and the operation semantics is too low as it explicitly describes the heap, stack pointers and the like. New work has recently developed an intermediate level semantics <ref> [3] </ref> which, we hope, will turn out to be appropriate not merely for this proof, but for others that exploit lazy evaluation.
Reference: [4] <author> J.-J.Levy, </author> <title> Optimal Reductions in the Lambda Calculus, </title> <editor> in Seldin and Hind-ley eds., </editor> <booktitle> To H.B.Curry: Essays in Combinatory Logic, Lambda Calculus and Formalism, </booktitle> <pages> pp 159-191, </pages> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: Semantically, lazy evaluation is equivalent to normal-order reduction|only terms which are known to be required are evaluated. Operationally, however, lazy evaluation matches exactly the applicative order behaviour in avoiding repeated evaluation. (Note that neither applicative-order reduction nor lazy evaluation is an optimal evaluation strategy in the sense of Levy <ref> [4] </ref>, so both may sometimes repeat reductions.) One common method by which lazy evaluation achieves its behaviour is graph reduction. When substitution takes place, a reference to an expression is substituted, rather than the expression itself.
Reference: [5] <author> S.Peyton Jones, C.Clack, J.Salkild, M.Hardie, </author> <title> GRIP a high-performance architecture for parallel graph reduction. </title> <booktitle> Proc IFIP conference on Functional Programming Languages and Computer Architecture, </booktitle> <address> Portland. </address> <publisher> Springer Verlag LNCS 274, </publisher> <pages> pp 98-112, </pages> <year> 1987. </year>
Reference-contexts: Updating the reference always costs instructions, and the cost of interrupting the computation at the appropriate time may be even greater. Normally of course this cost is very small when compared with the cost of recomputing a value, but it exists nonetheless. On the parallel machine GRIP <ref> [5] </ref> updates are particularly expensive because the updated node has to be flushed from local memory out to the global store. Similarly, the need for updates creates a major complication in the TIM abstract machine [2], and the presence of the update markers interrupts the flow of evaluation.
Reference: [6] <author> S.Peyton Jones, </author> <title> Implementing Lazy Functional Languages on Stock Hardware: </title> <journal> the Spineless Tagless G-Machine, Journal of Functional Programming, </journal> <note> CUP, 1992, to appear. </note>
Reference-contexts: The form of expressions is a simplification of the Spineless, Tagless, G-machine implementation language (STG) <ref> [6] </ref> used in the Glasgow Haskell compiler. The underlying philosophy of the language is that it has a direct operational reading, a sort of "abstract machine-code" for functional languages. Closures are named explicitly using lets, and functions accept only such closures as arguments.
References-found: 6

