URL: http://www.cacs.usl.edu/Departments/CACS/Publications/Raghavan/ChRa97b.ps.Z
Refering-URL: http://www.cacs.usl.edu/~raghavan/raghavan-1.html
Root-URL: http://www.cacs.usl.edu/~raghavan/raghavan-1.html
Title: Generic and Fully Automatic Content Based Retrieval Using Texture  
Author: Suresh K Choubey Vijay V. Raghavan 
Keyword: Image database, image retrieval, content-based, feature-based, automatic, generic  
Address: Waukesha, WI 53188, USA  Lafayette, LA 70504, USA  
Affiliation: Magnetic Resonance Imaging General Electric Medical Systems  Center for Advanced Computer Studies University of Southwestern Louisiana  
Abstract: A method for generic and fully automatic content-based image retrieval using texture has been proposed. Initially a small subset of the images that are to be populated into an image database is considered. Image content based on low-level feature is used to compute real interimage distances. Texture is used as low-level feature. High-level image feature vectors are computed from the real interimage distances in such a way that the in-terimage distances between the images are preserved by the resulting image feature vectors. These feature vectors are used to populate the database as well as generate a training set. This training set is used uniquely and efficiently for obtaining the feature vector of the query image for image retrieval and on-line addition of new images. The experiments indicate a substantial reduction in the feature space size, once high-level image feature vectors are computed. It also demonstrates a high retrieval accuracy. The accuracy is maintained at high level for larger image databases. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Gudivada and V. Raghavan, </author> <title> "Content-Based Image Retrieval Systems," </title> <journal> IEEE Computer, </journal> <volume> vol. 28, no. 9, </volume> <pages> pp. 18-22, </pages> <year> 1995. </year>
Reference-contexts: These features can be derived automatically or semiautomatically. However, CBIR remains a very difficult problem as the technology for storing, managing, and doing retrieval is still in the process of getting matured. It is very difficult to extract semantics associated with a given image <ref> [1] </ref>. Approaches to CBIR can be classified into two broad classes of attribute-based and feature-based. In attribute-based approach, the image contents are modeled as a set of attributes extracted manually or semiautomatically and managed within the framework of conventional DBMS [1]. Images are represented at a very high-level of abstraction. <p> very difficult to extract semantics associated with a given image <ref> [1] </ref>. Approaches to CBIR can be classified into two broad classes of attribute-based and feature-based. In attribute-based approach, the image contents are modeled as a set of attributes extracted manually or semiautomatically and managed within the framework of conventional DBMS [1]. Images are represented at a very high-level of abstraction. Queries are also specified using these attributes.
Reference: [2] <author> M. Stonebraker, E. Anderson, E. Hanson, and B.Rubenstein, </author> <title> "Quel as a Datatype," </title> <type> Tech. Rep. </type> <institution> UCB/ERL M83/73, University of California, Berkeley, </institution> <year> 1983. </year>
Reference-contexts: Here, either the relational data models are extended or are provided with built-in extensibility to accommodate solutions to image related problems. In such systems, the images are either treated as complex or unformatted data by incorporating features such as variable length arrays, procedure fields, ADT's <ref> [2, 3] </ref> and BLOBS [4]. Non-first normal form (N F 2 ) relational model [5] was also introduced to provide support for complex data types and some implementations were reported [6, 7, 8].
Reference: [3] <author> M. Stonebraker and L. Rowe, </author> <title> "The POSTGRES Papers," </title> <type> Tech. Rep. Mem. </type> <institution> No.UCM/ERL M83/85, University of California, Berkeley, </institution> <year> 1987. </year>
Reference-contexts: Here, either the relational data models are extended or are provided with built-in extensibility to accommodate solutions to image related problems. In such systems, the images are either treated as complex or unformatted data by incorporating features such as variable length arrays, procedure fields, ADT's <ref> [2, 3] </ref> and BLOBS [4]. Non-first normal form (N F 2 ) relational model [5] was also introduced to provide support for complex data types and some implementations were reported [6, 7, 8].
Reference: [4] <author> R. Cattell, </author> <title> "Next-Generation Database Systems," </title> <journal> Communications of ACM, </journal> <volume> vol. 30, no. 10, </volume> <year> 1991. </year>
Reference-contexts: Here, either the relational data models are extended or are provided with built-in extensibility to accommodate solutions to image related problems. In such systems, the images are either treated as complex or unformatted data by incorporating features such as variable length arrays, procedure fields, ADT's [2, 3] and BLOBS <ref> [4] </ref>. Non-first normal form (N F 2 ) relational model [5] was also introduced to provide support for complex data types and some implementations were reported [6, 7, 8].
Reference: [5] <author> H. Schek and P. Pistor, </author> <title> "Data Structures for an Integrated Database Management and Retreival System," </title> <booktitle> 8th International Conference on Very Large Databases, </booktitle> <year> 1982. </year>
Reference-contexts: In such systems, the images are either treated as complex or unformatted data by incorporating features such as variable length arrays, procedure fields, ADT's [2, 3] and BLOBS [4]. Non-first normal form (N F 2 ) relational model <ref> [5] </ref> was also introduced to provide support for complex data types and some implementations were reported [6, 7, 8]. In a feature-based CBIR, images are represented by their contents and the comparison is made between the contents of the query and the images in the image database.
Reference: [6] <author> P. Dadam et al., </author> <title> "A DBMS Prototype to Support Extended N F 2 -Relations: An Integrated View on Flat Tables and Hierarchies," </title> <booktitle> in ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pp. 376-387, </pages> <publisher> ACM, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Non-first normal form (N F 2 ) relational model [5] was also introduced to provide support for complex data types and some implementations were reported <ref> [6, 7, 8] </ref>. In a feature-based CBIR, images are represented by their contents and the comparison is made between the contents of the query and the images in the image database. By content, we mean computable and low-level features, such as color, shape, texture, object centroids and boundaries, and others.
Reference: [7] <author> A. Kemper and M. Wallrath, </author> <title> "An Analysis of Geometric Modeling in Database Systems," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 19, no. 1, </volume> <pages> pp. 47-91, </pages> <year> 1987. </year>
Reference-contexts: Non-first normal form (N F 2 ) relational model [5] was also introduced to provide support for complex data types and some implementations were reported <ref> [6, 7, 8] </ref>. In a feature-based CBIR, images are represented by their contents and the comparison is made between the contents of the query and the images in the image database. By content, we mean computable and low-level features, such as color, shape, texture, object centroids and boundaries, and others.
Reference: [8] <author> V. Gudivada, </author> <title> A Unified Framework for Retrieval in Image Databases. </title> <type> PhD thesis, </type> <institution> University of Southwestern Louisiana, Lafayette, LA, </institution> <year> 1993. </year>
Reference-contexts: Non-first normal form (N F 2 ) relational model [5] was also introduced to provide support for complex data types and some implementations were reported <ref> [6, 7, 8] </ref>. In a feature-based CBIR, images are represented by their contents and the comparison is made between the contents of the query and the images in the image database. By content, we mean computable and low-level features, such as color, shape, texture, object centroids and boundaries, and others.
Reference: [9] <author> L. Goldfarb, </author> <title> "A Unified Approach to Pattern Recognition," </title> <journal> Pattern Recognition, </journal> <volume> vol. 17, no. 5, </volume> <pages> pp. 575-582, </pages> <year> 1984. </year>
Reference-contexts: For example, in the case of retrieval by color, accounting for the effect of color correlations is very time consuming. We have proposed here a generic and fully-automatic feature-based CBIR using color, shape, and texture properties. This is based on the work done by Goldfarb <ref> [9] </ref> to bridge the gap between syntactic and statistical pattern representation for classification problems. In this paper, we report the experimental results for retrieval by texture only. Our approach directly compares the texture contents of query image with those of images in the database. <p> In this paper, we carry out the retrieval by color only. Our approach directly compares the color contents of query image with those of images in the database. This is based on the work done by Goldfarb <ref> [9] </ref> to bridge the gap between syntactic and statistical pattern representation for classification problems. The complete image storage and retrieval process is done in two phases of database population and image retrieval. <p> This set of images is also referred as the initial set. Let jP j = k; where k n. The value of k should be as small as possible, in order to achieve faster training period. According to Goldfarb <ref> [9] </ref>, the dissimilarity measure between two objects can be defined as follows: Let a pseudometric space be a pair (P; ), where P is a set of images and is a non negative real-valued mapping: : P fi P ! R + (1) satisfying following two conditions : (a) 8O 1 <p> Here fi, a vector representation of low-level image features, is defined as fi : P ! '; (3) where ' is the space of possible representation of low-level image features. As per Goldfarb <ref> [9] </ref> , following discussion leads to a theorem that lays the condition for preserving the interimage distance of a inter-distance matrix into the derived feature space. The theorem proposed by Goldfarb [9], requires definitions 1 through 5. <p> As per Goldfarb <ref> [9] </ref> , following discussion leads to a theorem that lays the condition for preserving the interimage distance of a inter-distance matrix into the derived feature space. The theorem proposed by Goldfarb [9], requires definitions 1 through 5. <p> In other words, (p; q) is the vector signature of a finite pseudomet-ric space (P; ), if R (p;q) is a minimal pseudo-Euclidean vector space, where (P; ) can be isometrically represented. That is, if there exists a distance preserving mapping <ref> [9] </ref>: Definition 2: Let (P; ) be the vector space over R of dimension k 1, and let fF i g 1ik1 be a basis of such a vector space.
Reference: [10] <author> R. M. Haralick, </author> <title> "Statistical and Structural Approaches to Texture," </title> <booktitle> in Proceedings of IEEE, </booktitle> <volume> no. 67, </volume> <pages> pp. 786-804, </pages> <month> May </month> <year> 1979. </year>
Reference-contexts: to a visual pattern and has properties of homogeneity that do not result from the presence of only a single color or intensity. "Image Texture can be qualitatively evaluated as having one or more of the properties of fineness, coarseness, smoothness, granulation, randomness, lineation, or being mottled, irregular or hummocky" <ref> [10, 11] </ref>. Different textural prop erties of part of an image is representative of the image contents. Texture consists of set of elements arranged in some fashion. These elements can be represented by a set of features.
Reference: [11] <author> M. D. Levine, </author> <booktitle> Vision in Man and Machine. </booktitle> <address> NewYork, USA: </address> <publisher> McGraw Hill Book Company, </publisher> <year> 1985. </year>
Reference-contexts: to a visual pattern and has properties of homogeneity that do not result from the presence of only a single color or intensity. "Image Texture can be qualitatively evaluated as having one or more of the properties of fineness, coarseness, smoothness, granulation, randomness, lineation, or being mottled, irregular or hummocky" <ref> [10, 11] </ref>. Different textural prop erties of part of an image is representative of the image contents. Texture consists of set of elements arranged in some fashion. These elements can be represented by a set of features.
Reference: [12] <author> W. Y. Ma and B. S. Manjunath, </author> <title> "Texture Features and Learning Similarity," </title> <booktitle> in IEEE International Conference on Computer Vision and Pattern Recognition (CVPR'96), </booktitle> <address> (San Francisco, California), </address> <pages> pp. 2677-2690, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Texture has also been found to play a significant role in the area of CBIR. Large databases of images and videos can be queried using texture as a visual feature <ref> [12] </ref>. The example query can be: "Retrieve all landsat images with less than 20% cloud cover", "Retrieve all images where the texture is similar to that of the given image", "Retrieve all citrus plantations which look like a given pattern", or "Retrieve all wetland images with no vegetation". <p> An image can be considered as a mosaic of different regions, segmented on the basis of texture information. Regions then, can be associated with a feature set, which in turn can be used for image storage and retrieval <ref> [12] </ref>. An image database can then be queried to retrieve similar patterns. Recent work on texture-based retrieval range from random field models, co-occurrence matrices to multiresolution wavelet transforms. Model-based methods exploit the embedded statistical properties obtained from the grey level image. <p> In spatial-frequency approach, the frequency contents of local patches are extracted to identify homogeneous textured regions by clustering or grouping techniques [13]. However, multiresolution wavelet transforms have been used for achieving good performance [14]. Manjunath et al. <ref> [12] </ref> compute features for texture-based image retrieval by filtering images with a bank of Gabor filters. These features are used to create texture-based feature dictionary. They have shown that Gabor wavelet transform outperforms other types of wavelet transforms. <p> The Euclidean distance is computed as Z (O i ; Q) = k=1 # 1 (9) 5 Experiments and Results Two sets of experiments (EXPT I and EXPT II) were conducted using texture features computed from texture images by Manjunath et al. <ref> [12] </ref> The purpose of first set of the experiments was to measure the retrieval effectiveness and retrieval accuracy of image database system. The second set of experiments were carried out to study the effect of scaling on size of image database. <p> spatial arrangement of grey values of neighboring pixels (difference in texture) plays a decisive role [17] as a discriminating feature in IR problems may play an important role. 5.1 Interimage Distance Computa tion We use an interimage distance function for retrieval by image texture content, proposed by Manjunath et al. <ref> [12] </ref>. <p> possible number of S + : It should be noted that the calculation of S + ; S ; and S + max is based on the ranking of image pairs in est relative to the ranking of corresponding image pairs in real : 5.3 Experimental Set-up Manjunath et al. <ref> [12] </ref> have created a database of 1856 texture images from 116 different texture classes by dividing each of the 512 fi 512 images into 16 128 fi 128 non-overlapping subimages. This texture image repository is maintained at University of California, Santa Barbara by them. <p> The on-line computation time is reduced substantially, as we have only eight high-level features in the feature vector of all the images. Hence, there is going to be substantial saving in computation time compared to that used by Manjunath and Ma <ref> [12] </ref>. Also top 16 images retrieved are from the query image class (16 images) for most of the query images. 5.5 EXPT II Results We have computed estimated distances to images in the database from all the query images for different number of high-level features. <p> However, there is some gain. Hence, for applications requiring higher accuracy, higher number of high-level features can be used at the slight cost of increased computation. The computation will still be much less compared to that of Manjunath et al. <ref> [12] </ref> even with 14 high-level image features. 6 Conclusion We have proposed a generic and fully automatic CBIR using texture. Except for the computation of inter-image distances, our method is generic relative to image properties such as shape, or color instead of texture.
Reference: [13] <author> C. Chang and S. Chatterjee, </author> <title> "A Hybrid Approach Towards Model-Based Texture Segmentation," </title> <journal> Pattern Recognition, </journal> <volume> vol. 25, </volume> <pages> pp. 519-531, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Model-based methods exploit the embedded statistical properties obtained from the grey level image. In spatial-frequency approach, the frequency contents of local patches are extracted to identify homogeneous textured regions by clustering or grouping techniques <ref> [13] </ref>. However, multiresolution wavelet transforms have been used for achieving good performance [14]. Manjunath et al. [12] compute features for texture-based image retrieval by filtering images with a bank of Gabor filters. These features are used to create texture-based feature dictionary.
Reference: [14] <author> W. Y. Ma and B. S. Manjunath, </author> <title> "A Comparison of Wavelet Transform Features for Texture Image Annotation," </title> <booktitle> in IEEE International Conference on Image Processing, </booktitle> <address> (Washington DC), </address> <month> October </month> <year> 1995. </year>
Reference-contexts: Model-based methods exploit the embedded statistical properties obtained from the grey level image. In spatial-frequency approach, the frequency contents of local patches are extracted to identify homogeneous textured regions by clustering or grouping techniques [13]. However, multiresolution wavelet transforms have been used for achieving good performance <ref> [14] </ref>. Manjunath et al. [12] compute features for texture-based image retrieval by filtering images with a bank of Gabor filters. These features are used to create texture-based feature dictionary. They have shown that Gabor wavelet transform outperforms other types of wavelet transforms.
Reference: [15] <author> J. R.Smith and S. fu Chang, </author> <title> "QUAD-Tree Segmentation for Texture-Based Image Query," </title> <booktitle> in Proceedings of ACM 2nd International conference on Multimedia '94, </booktitle> <address> (San Francisco), </address> <publisher> ACM Press, </publisher> <month> Octo-ber </month> <year> 1994. </year>
Reference-contexts: In this approach, the computation of real distance is quite complex and computationally very expensive. Number of features are also substantially very high. Chang and Smith <ref> [15] </ref> have proposed an automatic extraction method of texture features from image spatial-frequency data. Texture features can be obtained by thresholding and morphologically filtering image spatial/spatial-frequency subbands [15]. Texture is represented by a binary feature set. <p> Number of features are also substantially very high. Chang and Smith <ref> [15] </ref> have proposed an automatic extraction method of texture features from image spatial-frequency data. Texture features can be obtained by thresholding and morphologically filtering image spatial/spatial-frequency subbands [15]. Texture is represented by a binary feature set. Each element in the feature set indicates the energy relative to the threshold in a corresponding spatial/spatial-frequency subband. This process identifies spatially localized and arbitrarily shaped regions of texture within each image (segmentation), preserving the logical spatial relationships between texture regions.
Reference: [16] <author> L. Goldfarb, </author> <title> "A New Approach to Pattern Recognition," </title> <booktitle> in Progress in Machine Intelligence and Pattern Recognition, </booktitle> <editor> eds: L.N. Kanal and A. Rosenfeld, </editor> <volume> vol. 2, </volume> <publisher> North Holland Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: Then the ordered pair of integers (p; q) is called the signature of the form . Theorem 1 A finite pseudometric space (P; ) has the vector signature (p; q), iff the quadratic form has the signature (p; q). The proof of Theorem 1 is given in <ref> [16] </ref>.
Reference: [17] <author> A. K. Jain and F. Farrokhnia, </author> <title> "Unsupervised Texture Segmentation Using Ga-bor Filters," </title> <journal> Pattern Recognition, </journal> <volume> vol. 24, </volume> <pages> pp. 1167-1186, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Use of color as a discriminating feature will be of no use in case of grey level images. In such cases, differences in the spatial arrangement of grey values of neighboring pixels (difference in texture) plays a decisive role <ref> [17] </ref> as a discriminating feature in IR problems may play an important role. 5.1 Interimage Distance Computa tion We use an interimage distance function for retrieval by image texture content, proposed by Manjunath et al. [12].
Reference: [18] <author> P. Bollmann et al., </author> <title> "The LIVE-Project| Retrieval Experiments Based on Evaluation Viewpoints," </title> <booktitle> in ACM/SIGIR Conference on Research & Development in Information Retrieval, </booktitle> <address> (Montreal, Canada), </address> <pages> pp. 213-214, </pages> <month> June </month> <year> 1985. </year> <note> Query Image R norm 0 0.979839 2 0.967742 4 0.959677 6 0.975806 8 0.971774 10 0.973790 12 0.985887 14 0.969758 16 0.977823 18 0.963710 20 0.983871 22 0.979839 24 0.975806 26 0.977823 28 0.975806 30 0.975806 AVG. 0.975050 Table 1: </note> <editor> TEXTURE: </editor> <title> R norm for Query Images. Number of High R norm Level Features 8 0.9394 10 0.9456 12 0.9520 14 0.9577 Table 2: R norm for EXPT II. </title>
Reference-contexts: fi fi ; where ff ( mn ) and ff (oe mn ) are the standard deviations of the respective features over the entire database and are used to normalize the individual feature components. 5.2 R norm We have used R norm performance measure, which was first introduced in LIVE-Project <ref> [18] </ref>. R norm measure is another variation of normalized precision and recall. Definition of R norm can be given as follows : Let I be a finite set of images with a preference relation , based on estimated distance, that is complete and transitive (weak order).
References-found: 18

