URL: http://www.cs.unr.edu/src/techreports/sushil/andrew94.ps
Refering-URL: http://www.cs.unr.edu/src/techreports/TechReports.html
Root-URL: 
Email: email: murray@cs.unr.edu  email: sushil@cs.unr.edu  
Title: Design Strategies for Evolutionary Robotics  
Author: Andrew Murray Sushil J. Louis 
Keyword: Genetic Algorithms, Computational Design, Autonomous Agents, Robot.  
Date: August 10, 1994  
Address: Reno 89557  Reno 89557  
Affiliation: Dept. of Computer Science University of Nevada  Dept. of Computer Science University of Nevada  
Abstract: This paper deals with the question of how to balance evolutionary design and human expertise in order to best design robots which can learn specific tasks. We study two behavioral tasks, approach and avoidance, and provide some preliminary results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Valentino Braitenberg. </author> <title> Vehicles. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: made it more difficult to find an effective control strategy because the only way to turn in the opposite direction when sensing an obstacle is to decrease the velocity of the motor opposite to the side of the touch sensor, assuming that full speed ahead is the normal operating state <ref> [1] </ref>. Switching to a cross mapping, where the left sensors had a higher probability of influencing the right motor was more effective (see figure 2).
Reference: [2] <author> D. Cliff, P. Husbands, and I. Harvey. </author> <title> "evolving visually guided robots". </title> <type> Technical Report CSRP 220, </type> <institution> School of Cognitive and Computing Science, University of Sussex, </institution> <year> 1992. </year>
Reference-contexts: We believe sensible human design must be balanced with evolutionary design to reduce human design time and maximize performance and flexibility. Previous work in this field has concentrated more on the learning of control strategies although some recent work has explored the evolution of structure and control <ref> [2, 3, 6] </ref>. We use a genetic algorithm (GA) to design both the structure and to find a control-strategy for our agent [5, 4]. We use a simulated autonomous robot or SIMBOT, that learns two basic types of behavior, approach and avoidance.
Reference: [3] <editor> Marco Dorigo and Marco Colombetti. </editor> <title> "robot shaping: Developing situated agents through learning". </title> <type> Technical Report TR-92-040 Revised, </type> <institution> International Computer Science Institute, University of California, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: We believe sensible human design must be balanced with evolutionary design to reduce human design time and maximize performance and flexibility. Previous work in this field has concentrated more on the learning of control strategies although some recent work has explored the evolution of structure and control <ref> [2, 3, 6] </ref>. We use a genetic algorithm (GA) to design both the structure and to find a control-strategy for our agent [5, 4]. We use a simulated autonomous robot or SIMBOT, that learns two basic types of behavior, approach and avoidance.
Reference: [4] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Previous work in this field has concentrated more on the learning of control strategies although some recent work has explored the evolution of structure and control [2, 3, 6]. We use a genetic algorithm (GA) to design both the structure and to find a control-strategy for our agent <ref> [5, 4] </ref>. We use a simulated autonomous robot or SIMBOT, that learns two basic types of behavior, approach and avoidance. For approach, the simbot has "ears" which "hear" food sources placed in a simulated environment.
Reference: [5] <author> J. Holland. </author> <title> Adaptation In Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbour, </address> <year> 1975. </year>
Reference-contexts: Previous work in this field has concentrated more on the learning of control strategies although some recent work has explored the evolution of structure and control [2, 3, 6]. We use a genetic algorithm (GA) to design both the structure and to find a control-strategy for our agent <ref> [5, 4] </ref>. We use a simulated autonomous robot or SIMBOT, that learns two basic types of behavior, approach and avoidance. For approach, the simbot has "ears" which "hear" food sources placed in a simulated environment.
Reference: [6] <editor> John R. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: We believe sensible human design must be balanced with evolutionary design to reduce human design time and maximize performance and flexibility. Previous work in this field has concentrated more on the learning of control strategies although some recent work has explored the evolution of structure and control <ref> [2, 3, 6] </ref>. We use a genetic algorithm (GA) to design both the structure and to find a control-strategy for our agent [5, 4]. We use a simulated autonomous robot or SIMBOT, that learns two basic types of behavior, approach and avoidance.
References-found: 6

