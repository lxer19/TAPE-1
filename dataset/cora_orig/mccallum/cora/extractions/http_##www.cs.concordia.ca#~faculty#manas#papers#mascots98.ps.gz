URL: http://www.cs.concordia.ca/~faculty/manas/papers/mascots98.ps.gz
Refering-URL: http://www.cs.concordia.ca/~faculty/manas/research/sel-pubs.html
Root-URL: http://www.cs.concordia.ca
Note: IEEE COPYRIGHT NOTICE  
Abstract: c fl1998 IEEE. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anna Charny and K. K. Ramakrishnan. </author> <title> Time scale analysis of explicit rate allocation in ATM networks. </title> <booktitle> In Proceedings of IEEE INFOCOM, </booktitle> <address> San Fransisco, California, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: the average end-to-end throughput. 1 We use normalized throughput, or throughput efficiency as a metric for evaluating performance, which is defined as: End-to-End Throughput Bandwidth Fair-Share (1) where the Bandwidth Fair-Share is the bandwidth available to the connection in "steady-state" as computed by (an ideal) ABR max-min fair allocation algorithm <ref> [1] </ref>. Ideally, it would be desirable to achieve a throughput efficiency equal to 1 for each connection. This would imply both efficient utilization of (ATM) network resources and perfect fair-sharing. Using per-connection throughput efficiencies we derive two performance measures: (1) link utilization and (2) fairness. <p> The TCP traffic sources use TCP-Reno, which includes fast-retransmit and fast-recovery mechanisms [12]. For ABR, we use an explicit rate allocation algorithm proposed by K. K. Ramakr-ishnan et. al. <ref> [1] </ref>. This algorithm allocate rates to individual VCs at each switch so as to try to achieve the goal of max-min fairness. We also use a Use-it-or-Lose-it policy, in which an idle source reduces its transmitting rate using an exponential-decrease function [9].
Reference: [2] <author> S. Floyd and V. Jacobson. </author> <title> Random Early Detection Gateways for Congestion Avoidance. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <pages> pages 397-413, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Second, there is more per-connection state available at an IP/ATM gateway, as compared to an IP-router, and this additional state information can be used, in principle, to improve performance. Our results indicate that buffer management policies developed in the context of IP routers (e.g., Random Early Drop <ref> [2] </ref>) and ATM switches (e.g., Fair Buffer Allocation [5]), are not suitable for IP/ATM gateways when extrapolated in a straightforward manner. <p> In this policy an arriving cell is dropped if the buffer occupancy exceeds the aggregate threshold (like EPD) and if the connection is using more than its own fair share of buffers. We also use Random Early Drop <ref> [2] </ref>, as a scheme representative of buffer management in IP-routers. We compare these traditional schemes with two new schemes, referred to as RPBA-LQD and RPBA-RRD policies. These schemes have two key aspects to them, namely rate-proportional buffering, and synchronization avoidance. <p> The EPD drop threshold was chosen to be the maximum possible value such that a non-initial fragment is always guaranteed to be accepted. The FBA and RED algorithm parameters were chosen based on [4] and <ref> [2] </ref> respectively, and the maximum drop probability in RED was experimentally determined to give the best performance in our simulations. We assume that each TCP connection is mapped to a separate ABR VC.
Reference: [3] <author> ATM Forum. </author> <title> Atm forum traffic management specification version 4.0. ATM FORUM AF-TM-00756.000, </title> <month> April </month> <year> 1996. </year>
Reference-contexts: The ABR service class uses feedback-based flow control at the ATM layer to dynamically partition bandwidth among active ABR VCs <ref> [3] </ref>. It is likely that the ABR service will be operated in a manner designed to achieve nearly loss free operation in the core of the ATM network, causing most of the buffering requirements to be pushed to the ingress points of the ATM network.
Reference: [4] <author> R. Goyal, R. Jain, S. Kalyanaraman, and S-C. Kim S. Fahmy. </author> <title> Performance of TCP over UBR+. </title> <type> Technical Report AF-TM 96-1269, ATM Forum, </type> <month> October </month> <year> 1996. </year>
Reference-contexts: A more sophisticated scheme for ATM switches is the Fair Buffer Allocation <ref> [5, 4] </ref>, which uses a dynamically defined, per-connection buffer fair-share to ensure fair usage of buffers. In this policy an arriving cell is dropped if the buffer occupancy exceeds the aggregate threshold (like EPD) and if the connection is using more than its own fair share of buffers. <p> The EPD drop threshold was chosen to be the maximum possible value such that a non-initial fragment is always guaranteed to be accepted. The FBA and RED algorithm parameters were chosen based on <ref> [4] </ref> and [2] respectively, and the maximum drop probability in RED was experimentally determined to give the best performance in our simulations. We assume that each TCP connection is mapped to a separate ABR VC.
Reference: [5] <author> J. Heinanen and K. Kilkki. </author> <title> A fair buffer allocation scheme. </title> <type> Unpublished Manuscript. </type>
Reference-contexts: Our results indicate that buffer management policies developed in the context of IP routers (e.g., Random Early Drop [2]) and ATM switches (e.g., Fair Buffer Allocation <ref> [5] </ref>), are not suitable for IP/ATM gateways when extrapolated in a straightforward manner. <p> A more sophisticated scheme for ATM switches is the Fair Buffer Allocation <ref> [5, 4] </ref>, which uses a dynamically defined, per-connection buffer fair-share to ensure fair usage of buffers. In this policy an arriving cell is dropped if the buffer occupancy exceeds the aggregate threshold (like EPD) and if the connection is using more than its own fair share of buffers.
Reference: [6] <author> R. Jain. </author> <title> The Art of Computer Systems Performance Analysis. </title> <publisher> John Wiley and Sons, </publisher> <year> 1991. </year>
Reference-contexts: The measure indicates absolute fairness, i.e., relative to the maximum possible efficiency (i.e., 1), rather than relative fairness. An indication of relative unfairness can be obtained by comparing it with the average throughput efficiency. We found that the commonly used measure of fairness, the fairness index <ref> [6] </ref> was not very useful and gave values of 0.99 or 1 in most cases. 3 Buffer Management Policies Over the years, many buffer management schemes have been designed for use in IP-routers as well as ATM switches.
Reference: [7] <author> Y-C. Lai and Y-D. Lin. </author> <title> Interoperability of EFCI and ER Switches for ABR Service in ATM Networks. </title> <journal> IEEE Network, </journal> <volume> 12(1), </volume> <year> 1998. </year>
Reference-contexts: For each bottleneck link, we compute the efficiency of the link by taking the average of the throughput efficiencies of connections going over the link. This provides a measure of the bottleneck link utilization. We use the fairness measure defined in <ref> [7] </ref>, which is given by: Fairness = max (1 max i where x i is the throughput efficiency of TCP connection i. The measure indicates absolute fairness, i.e., relative to the maximum possible efficiency (i.e., 1), rather than relative fairness.
Reference: [8] <author> T. V. Lakshman and U. Madhow. </author> <title> Performance Analysis of Window-based Flow Control using TCP-IP. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <month> April </month> <year> 1997. </year>
Reference-contexts: These schemes have two key aspects to them, namely rate-proportional buffering, and synchronization avoidance. It has been shown that the throughput efficiency of a TCP connection critically depends on the amount of buffering available at the bottleneck <ref> [8] </ref>. In a rate-controlled situation, it is therefore desirable to give a connection a large share of buffers if it has been allocated a larger rate, so that it can better make use of the allocated rate.
Reference: [9] <author> K. K. Ramakrishnan, Partho Mishra, and Kerry Fendick. </author> <title> A proposal for Use-it-or-Lose-it in ATM Networks. </title> <type> Technical Report AF-TM 97-1599, ATM Forum, </type> <month> December </month> <year> 1995. </year>
Reference-contexts: K. Ramakr-ishnan et. al. [1]. This algorithm allocate rates to individual VCs at each switch so as to try to achieve the goal of max-min fairness. We also use a Use-it-or-Lose-it policy, in which an idle source reduces its transmitting rate using an exponential-decrease function <ref> [9] </ref>. The EPD drop threshold was chosen to be the maximum possible value such that a non-initial fragment is always guaranteed to be accepted.
Reference: [10] <author> R. Restrick. </author> <type> Personal communication. </type> <year> 1994. </year>
Reference-contexts: The connection is then moved out of the round-robin queue until it becomes over-limit again. In the longest-queue-drop policy (RPBA-LQD), which is a variant of the policy first proposed by Robert Re-strick <ref> [10] </ref>, the connection with the largest number of packets is chosen as the victim. In this scheme, we drop all queued packets from the victim connection when the aggregate buffer occupancy exceeds the EPD threshold.
Reference: [11] <author> A. Romanow and S. Floyd. </author> <title> Dynamics of TCP Traffic over ATM Networks. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <address> London, Great Britain, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The simplest scheme is the Early Packet Discard <ref> [11] </ref>, which is like a tail-drop policy, but uses a drop-threshold less than the total buffer size to avoid 1 Achieving other performance objectives, for example, ensuring low-delays for remote login or web browsing kind of applications, or isolating TCP traffic from non flow controlled (e.g., UDP) traffic, are not addressed
Reference: [12] <author> W. R. </author> <title> Stevens. </title> <journal> TCP/IP Illustrated, </journal> <volume> Vol. </volume> <editor> I. Addi-son Wesley, </editor> <year> 1994. </year> <month> 6 </month>
Reference-contexts: The TCP traffic sources use TCP-Reno, which includes fast-retransmit and fast-recovery mechanisms <ref> [12] </ref>. For ABR, we use an explicit rate allocation algorithm proposed by K. K. Ramakr-ishnan et. al. [1]. This algorithm allocate rates to individual VCs at each switch so as to try to achieve the goal of max-min fairness.
References-found: 12

