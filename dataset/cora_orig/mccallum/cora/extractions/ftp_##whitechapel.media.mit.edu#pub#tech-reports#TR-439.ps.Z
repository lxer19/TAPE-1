URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-439.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: sandyg@media.mit.edu  
Title: Augmenting the Billiards Experience with Probabilistic Vision and Wearable Computers  
Author: Tony Jebara, Cyrus Eyster, Josh Weaver, Thad Starner, Alex Pentland fjebara, cyruse, joshw, thad, 
Address: Cambridge, MA 02139, (617) 253-0370  
Affiliation: Media Laboratory, Massachusetts Institute of Technology  
Note: Stochasticks:  
Abstract: MIT Media Laboratory, Perceptual Computing Technical Report #439 Appears in: Proc. of the Intl. Symposium on Wearable Computers, Cambridge MA, Oct. 1997 Abstract We propose a practical application of wearable computing and augmented reality which enhances the game of billiards. A vision algorithm is implemented which operates in interactive-time with the user to assist planning and aiming. Probabilistic color models and symmetry operations are used to localize the table, pockets and balls through a video camera near the user's eye. Classification of the objects of interest is performed and each possible shot is ranked in order to determine its relative usefulness. The system allows the user to proceed through a regular pool game while it automatically determines strategic shots. The resulting trajectories are rendered as graphical overlays on a head mounted live video display. The wearable video output and the computer vision system provide an integration of real and virtual environments which enhances the experience of playing and learning the game of billiards without encumbering the player. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.D. </author> <title> Alter, "3D Pose from 3 Corresponding Points under Weak-Perspective Projection", </title> <journal> A.I. </journal> <volume> Memo No. 1378, </volume> <year> 1992. </year>
Reference-contexts: This would maintain virtual positions of balls and pockets that fell out of the current image view. 3D recursive estimation and 3D alignment algorithms could increase the precision and stability of the output [9] [2] <ref> [1] </ref>. In addition, we are using the recovery of 3D structure to combine the system's output on the user's natural binocular field (instead of the video camera's images).
Reference: [2] <author> A. Azarbayejani and A. Pentland, </author> <title> "Recursive Estimation of Motion, Structure and Focal Length", </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <month> June </month> <year> 1995. </year>
Reference-contexts: This would maintain virtual positions of balls and pockets that fell out of the current image view. 3D recursive estimation and 3D alignment algorithms could increase the precision and stability of the output [9] <ref> [2] </ref> [1]. In addition, we are using the recovery of 3D structure to combine the system's output on the user's natural binocular field (instead of the video camera's images).
Reference: [3] <author> M. Bolduc, G. Sela and M.D. Levine, </author> <title> "Fast Computation of Multiscalar Symmetry in Foveated Images", </title> <booktitle> Proceedings of the Conference on Computer Architectures for Machine Perception, </booktitle> <pages> pp. 2-11, </pages> <year> 1995. </year>
Reference-contexts: It is possible to compute intersections to find pool table corners and to determine the lengths of the sides. In addition, we can accurately specify the interior and periphery of the pool table. 4.3 Symmetry Detection We then propose the use of the general symmetry transform <ref> [3] </ref> [11] [13] [10]. This is an annular sampling region which detects edge configurations that enclose an object. Unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected. When applied at the appropriate scale this transform consistently detects circular objects.
Reference: [4] <author> T. Cover and J. Thomas, </author> <title> Elements of Information Theory, </title> <publisher> John Wiley & Sons Inc. </publisher> <year> 1991. </year>
Reference-contexts: This model, shown in Figure 14 (b), is called p t (x). To classify our test distribution data t we use a common distance metric between probabilistic mod (a) RGB Data (b) Color Model (a) RGB Data (b) Color Model els. This metric is the Kullback-Liebler divergence <ref> [4] </ref> 1 . By measuring the 'distance' between test data p t (x) and our training data, p i (x) for i*[1; 20] we can see how similar it is to other objects. We determine the closest model i for each symmetry peak and label that peak accordingly.
Reference: [5] <author> A. Dempster, N. Laird and D. Rubin, </author> <title> "Maximum Likelihood from Incomplete Data via the EM Algorithm", </title> <journal> Journal of the Royal Statistical Society, B39, </journal> <pages> pp. 1-38, </pages> <year> 1977. </year>
Reference-contexts: We perform clustering on this distribution of pixels which is shown in Figure 5. The clustering uses Expectation Maximization (EM) to find a probability distribution model for pool table colors <ref> [5] </ref> [19]. This model is a mixture of Gaussians (the appropriate number of Gaussians is determined a priori with cross-validation). The EM algorithm iterates by adjusting the parameters of the Gaussian probability model to maximize the likelihood of the training samples.
Reference: [6] <author> S. Feiner, B. MacIntyre, D. Seligmann, </author> <title> "Annotating the Real World with Knowledge-Based Graphics on a See-Through Head-Mounted Display", </title> <booktitle> Proceedings of Graphics Interface '92, </booktitle> <pages> p 78-85, </pages> <year> 1992. </year>
Reference-contexts: A middle ground between these two extremes can be achieved by using computer vision to map real world data into a virtual context. Similarly, a head mounted display could remap the virtual results of any strategic analysis onto an image of the user's surroundings <ref> [6] </ref>. The use of a wearable computer allows the user to navigate freely in an arbitrary physical space without special preparation. This paper describes a wearable computer-based system that uses probabilistic computer vision to guide the user's game play throughout a match. <p> These help maintain the rich multi-modality we have come to expect [7]. For instance, Ishii and Ullmer [8] include physical objects as input to the computer to preserve tangibility in the virtual experience. Feiner et. al. <ref> [6] </ref> use the notion of overlayed graphical output on see-through head-mounted displays to keep the rich visual stimuli of the real world. 3 System Overview The following is a coarse description of the Stocha-sticks system along with some important design issues and practical considerations. <p> The use of the camera display as a virtual "third eye" avoids alignment discrepancies between the vision algorithm and the user's view point. Thus, any graphical overlays that are produced as a result of video processing can be directly projected to the user's eye display <ref> [6] </ref>. Although the change of perspective induced by looking through a "third eye" (the camera) is unusual for first timers, we have found that users can adapt quite quickly if the camera is only slightly offset from the eyes [14].
Reference: [7] <editor> EP. Glinert and MM. Blattner, </editor> <title> "Multimodal Interaction", </title> <booktitle> IEEE Multimedia, </booktitle> <address> 3(4):13, </address> <month> Winter </month> <year> 1996. </year>
Reference-contexts: Other current research in interactive environments has stressed the importance of maintaining intermediate representations between the real and the virtual. These help maintain the rich multi-modality we have come to expect <ref> [7] </ref>. For instance, Ishii and Ullmer [8] include physical objects as input to the computer to preserve tangibility in the virtual experience.
Reference: [8] <author> H. Ishii and B. Ullmer, </author> <title> "Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms", </title> <booktitle> Human Factors in Computing Systems: CHI '97 Conference Proceedings, </booktitle> <pages> pp. 234-241, </pages> <year> 1997. </year>
Reference-contexts: This pastime involves a complex blend of physical dexterity as well as analytic geometry and strategy. To enhance the experience, it would be desirable to supplement the user's ability to select, visualize and aim without reducing the tactile feedback of the real game <ref> [8] </ref>. This intermediate form of integration lies conceptually somewhere between a merely physical game of billiards and a sterile and unnatural computerized version of it. A middle ground between these two extremes can be achieved by using computer vision to map real world data into a virtual context. <p> Other current research in interactive environments has stressed the importance of maintaining intermediate representations between the real and the virtual. These help maintain the rich multi-modality we have come to expect [7]. For instance, Ishii and Ullmer <ref> [8] </ref> include physical objects as input to the computer to preserve tangibility in the virtual experience.
Reference: [9] <author> T. Jebara and A. Pentland, </author> <title> "Parametrized Structure from Motion for 3D Adaptive Feedback Tracking of Faces", </title> <booktitle> IEEE International Conference on Computer Vision and Pattern Recognition, </booktitle> <year> 1997. </year>
Reference-contexts: These trace out the paths of the cue ball and the ball to sink. 4 Vision Processing 4.1 Color Feature Detection To find the pool table, we train a probabilistic color model of the green felt that covers it [18] <ref> [9] </ref>. This is done by taking multiple training samples of several (a) Random Initialization (b) EM Convergence (a) Input Image (b) Color Classification images of a pool table under many imaging situations (o*ine). <p> This would maintain virtual positions of balls and pockets that fell out of the current image view. 3D recursive estimation and 3D alignment algorithms could increase the precision and stability of the output <ref> [9] </ref> [2] [1]. In addition, we are using the recovery of 3D structure to combine the system's output on the user's natural binocular field (instead of the video camera's images).
Reference: [10] <author> T. Jebara, </author> <title> "3D Pose Estimation and Normalization for Face Recognition", </title> <institution> Bachelor's The-sisMcGill Centre for Intelligent Machines, </institution> <year> 1996. </year>
Reference-contexts: It is possible to compute intersections to find pool table corners and to determine the lengths of the sides. In addition, we can accurately specify the interior and periphery of the pool table. 4.3 Symmetry Detection We then propose the use of the general symmetry transform [3] [11] [13] <ref> [10] </ref>. This is an annular sampling region which detects edge configurations that enclose an object. Unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected. When applied at the appropriate scale this transform consistently detects circular objects.
Reference: [11] <author> M.F. Kelly and M.D. Levine, </author> <title> "Annular Symmetry Operators: A Method for Locating and Describing Objects", </title> <booktitle> Fifth International Conference on Computer Vision, </booktitle> <pages> pp. 1016-1021, </pages> <year> 1995. </year>
Reference-contexts: It is possible to compute intersections to find pool table corners and to determine the lengths of the sides. In addition, we can accurately specify the interior and periphery of the pool table. 4.3 Symmetry Detection We then propose the use of the general symmetry transform [3] <ref> [11] </ref> [13] [10]. This is an annular sampling region which detects edge configurations that enclose an object. Unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected. When applied at the appropriate scale this transform consistently detects circular objects.
Reference: [12] <author> S. Mann, "Smart Clothing: </author> <title> Wearable Multimedia Computing and Personal Imaging...", </title> <booktitle> Proceedings of ACM Multimedia pp. </booktitle> <pages> 163-174, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: Wearable computers are a particularly convenient platform for this symbiosis and make this integration as seamless as possible [17] <ref> [12] </ref>. One area where this cooperation would be especially interesting is in the game of billiards. This pastime involves a complex blend of physical dexterity as well as analytic geometry and strategy. <p> The natural progression would be a totally wearable, person-centric augmented reality with head mounted displays where vision would track the world instead of the user. The use of such personal imaging and augmented reality has been discussed and investigated in [17], <ref> [12] </ref> and [16]. This previous research has shown some of the advantages and issues of using computer vision on the external environment to assist the wearable augmented reality experience. Other current research in interactive environments has stressed the importance of maintaining intermediate representations between the real and the virtual.
Reference: [13] <author> D. Reisfeld and Y. Yeshurun, </author> <title> "Robust Detection of Facial Features by Generalized Symmetry", </title> <booktitle> 11th IAPR International Conference on Pattern Recognition, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 117-120, </pages> <year> 1992. </year>
Reference-contexts: It is possible to compute intersections to find pool table corners and to determine the lengths of the sides. In addition, we can accurately specify the interior and periphery of the pool table. 4.3 Symmetry Detection We then propose the use of the general symmetry transform [3] [11] <ref> [13] </ref> [10]. This is an annular sampling region which detects edge configurations that enclose an object. Unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected. When applied at the appropriate scale this transform consistently detects circular objects.
Reference: [14] <author> J. Rolland, F. Biocca, T. Barlow and A. Kancherla, </author> <title> "Quantification of Adaptation to Virtual-Eye Location in See-Thru Head-Mounted Displays", </title> <booktitle> IEEE Annual Virtual Reality International Symposium p. </booktitle> <pages> 56-66, </pages> <year> 1995. </year>
Reference-contexts: Although the change of perspective induced by looking through a "third eye" (the camera) is unusual for first timers, we have found that users can adapt quite quickly if the camera is only slightly offset from the eyes <ref> [14] </ref>. We are currently investigating more advanced display techniques which combine the graphical overlays directly onto the user's natural binocular field.
Reference: [15] <author> K. Russell, T. Starner and A. Pentland, </author> <title> "Unencumbered Virtual Environments", </title> <booktitle> 1995 International Joint Conference on Artificial Intelligence Entertainment and AI/ALife Workshop, </booktitle> <year> 1995. </year>
Reference-contexts: For example, flight simulators and even heads-up-displays (HUDs) have required large, powerful and immobile equipment. However, recent work has reduced the requirements for virtual reality to 1 or 2 workstations, a display and a single camera. For instance, the Pfinder [18] and the Survive <ref> [15] </ref> systems require relatively minimal computational resources to produce a virtual interactive experience. This virtual experience involves visual tracking of the user and includes interacting with agents as well as arcade gaming.
Reference: [16] <author> R. Sharma and J. Molineros, </author> <title> "Role of Computer Vision in Augmented Virtual Reality", </title> <booktitle> Proceedings of SPIE The International Society for Optical Engineering, </booktitle> <pages> 2409 pp. 220-231, </pages> <year> 1995. </year>
Reference-contexts: The natural progression would be a totally wearable, person-centric augmented reality with head mounted displays where vision would track the world instead of the user. The use of such personal imaging and augmented reality has been discussed and investigated in [17], [12] and <ref> [16] </ref>. This previous research has shown some of the advantages and issues of using computer vision on the external environment to assist the wearable augmented reality experience. Other current research in interactive environments has stressed the importance of maintaining intermediate representations between the real and the virtual.
Reference: [17] <author> T. Starner, S. Mann, B. Rhodes, J. Levine, J. Healey, D. Kirsch, R. Picard, and A. Pentland, </author> <title> "Augmented Reality through Wearable Computing", Presence, </title> <year> 1997. </year>
Reference-contexts: Wearable computers are a particularly convenient platform for this symbiosis and make this integration as seamless as possible <ref> [17] </ref> [12]. One area where this cooperation would be especially interesting is in the game of billiards. This pastime involves a complex blend of physical dexterity as well as analytic geometry and strategy. <p> The natural progression would be a totally wearable, person-centric augmented reality with head mounted displays where vision would track the world instead of the user. The use of such personal imaging and augmented reality has been discussed and investigated in <ref> [17] </ref>, [12] and [16]. This previous research has shown some of the advantages and issues of using computer vision on the external environment to assist the wearable augmented reality experience. Other current research in interactive environments has stressed the importance of maintaining intermediate representations between the real and the virtual.
Reference: [18] <author> C. Wren, A. Azarbayejani, T. Darrell, A. Pent-land, "Pfinder: </author> <title> Real-Time Tracking of the Human Body", </title> <booktitle> Proceedings of the Second International Conference on Automatic Face and Gesture Recognition, </booktitle> <year> 1996 </year> . 
Reference-contexts: For example, flight simulators and even heads-up-displays (HUDs) have required large, powerful and immobile equipment. However, recent work has reduced the requirements for virtual reality to 1 or 2 workstations, a display and a single camera. For instance, the Pfinder <ref> [18] </ref> and the Survive [15] systems require relatively minimal computational resources to produce a virtual interactive experience. This virtual experience involves visual tracking of the user and includes interacting with agents as well as arcade gaming. <p> The easiest shot is then displayed on-screen using linear trajectories. These trace out the paths of the cue ball and the ball to sink. 4 Vision Processing 4.1 Color Feature Detection To find the pool table, we train a probabilistic color model of the green felt that covers it <ref> [18] </ref> [9]. This is done by taking multiple training samples of several (a) Random Initialization (b) EM Convergence (a) Input Image (b) Color Classification images of a pool table under many imaging situations (o*ine).
Reference: [19] <author> L. Xu and M. Jordan, </author> <title> "On Convergence Properties of the EM Algorithm for Gaussian Mixtures", </title> <journal> Neural Computation, </journal> <volume> 8, </volume> <pages> 129-151, </pages> <year> 1996. </year>
Reference-contexts: We perform clustering on this distribution of pixels which is shown in Figure 5. The clustering uses Expectation Maximization (EM) to find a probability distribution model for pool table colors [5] <ref> [19] </ref>. This model is a mixture of Gaussians (the appropriate number of Gaussians is determined a priori with cross-validation). The EM algorithm iterates by adjusting the parameters of the Gaussian probability model to maximize the likelihood of the training samples.
References-found: 19

