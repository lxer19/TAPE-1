URL: ftp://ftp.cogsci.indiana.edu/pub/wang.heuristic.ps
Refering-URL: http://www.cogsci.indiana.edu/farg/peiwang/papers.html
Root-URL: 
Title: Heuristics and Normative Models of Judgment under Uncertainty  
Author: Pei Wang 
Keyword: Subjective probability, normative and descriptive mod els, heuristics and bias, insufficient knowledge and resources, non-axiomatic reasoning system.  
Affiliation: Indiana University  
Note: Center for Research on Concepts and Cognition  
Abstract: Psychological evidence shows that probability theory is not a proper descriptive model of intuitive human judgment. Instead, some heuristics have been proposed as such a descriptive model. This paper argues that probability theory has limi tations even as a normative model. A new normative model of judgment under uncertainty is designed under the assumption that the system's knowledge and resources are insufficient with respect to the questions that the system needs to answer. The proposed heuristics in human reasoning can also be observed in this new model, and can be justified according to the assumption. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> N. Anderson. </author> <title> A cognitive theory of judgment and decision. </title> <editor> In B. Brehmer, H. Jungermann, P. Lourens, and G. Sevon, editors, </editor> <booktitle> New Directions in Research on Decision Making, </booktitle> <pages> pages 63-108. </pages> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference-contexts: can be interpreted differently, such as in the "fre quentist" [9] or "propensity" [4] interpretation. 3 * There are alternative normative models that compete with Pascal probability theory, such as Baconian probability [4] and belief func tion [16]. * Some formal descriptive models are proposed, such as information integration theory <ref> [1] </ref>. <p> When a relative measurement is preferred, the same information can be represented by a pair of real numbers in <ref> [0; 1] </ref>, &lt; f; c &gt;, where f = w + =w, the frequency (or proportion) of positive evidence among all relevant evidence, and c = w=(w + 1), a monotonically increasing function of the total weight of relevant evidence. c is referred to as the confidence of the judgment, because <p> Adjustment and anchoring For any system that accepts new knowledge or makes judgments by in crementally considering available knowledge, there must be a rule by which a previous probability judgment is adjusted in light of new evidence or fur ther consideration <ref> [1] </ref>. The anchoring phenomenon, or insufficient adjustment from the initial point, is observed in human thinking [18]. By calling the observed ad justments "insufficient", it is assumed that the correct adjustment rule is Bayes' theorem, or its extension, Jeffrey's rule. <p> It is in situations where Bayesian approach cannot or should not be applied that approaches like NARS will take over. NARS is not proposed as a descriptive model for actual human thinking, such as Anderson's model <ref> [1] </ref>. Its behavior is still different from that of a human being. The approach is not justified by psychological data, but by logical analysis. Therefore there is no psychological experiment conducted to verify the theory.
Reference: 2. <author> H. Arkes. </author> <title> Costa and benefits of judgment errors: implications for debias ing. </title> <journal> Psychological Bulletin, </journal> <volume> 110 </volume> <pages> 486-498, </pages> <year> 1991. </year>
Reference-contexts: Which part of the system's knowledge is consulted is determined by several factors, such as relevance, importance, usefulness, and so on. Therefore, it is not surprising that certain events, like priming and association, influence the availability distribution <ref> [2] </ref>.
Reference: 3. <author> P. Cheeseman. </author> <title> In defense of probability. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1002-1009, </pages> <year> 1985. </year> <month> 14 </month>
Reference-contexts: This opinion is also advocated by some authors in the study of uncertainty reasoning in artificial intelligence <ref> [3, 15, 17] </ref>. It is well known that the axioms of probability theory can be derived from several assumptions about the relationships between evidence and belief [5]. These assumptions, though reasonable for many situations, set up limitations for Bayesian approach at the same time. 4 2.1.
Reference: 4. <author> L. Cohen. </author> <title> Can human irrationality be experimentally demonstrated? The Behavioral and Brain Sciences, </title> <booktitle> 4 </booktitle> <pages> 317-331, </pages> <year> 1981. </year>
Reference-contexts: Bayes' theorem is applied to revise one's beliefs with new evidence. However, besides the mainstream opinion expressed above, there are opinions to explain the discrepancy as a challenge to Bayesian approach: * Probability theory can be interpreted differently, such as in the "fre quentist" [9] or "propensity" <ref> [4] </ref> interpretation. 3 * There are alternative normative models that compete with Pascal probability theory, such as Baconian probability [4] and belief func tion [16]. * Some formal descriptive models are proposed, such as information integration theory [1]. <p> expressed above, there are opinions to explain the discrepancy as a challenge to Bayesian approach: * Probability theory can be interpreted differently, such as in the "fre quentist" [9] or "propensity" <ref> [4] </ref> interpretation. 3 * There are alternative normative models that compete with Pascal probability theory, such as Baconian probability [4] and belief func tion [16]. * Some formal descriptive models are proposed, such as information integration theory [1].
Reference: 5. <author> R. Cox. </author> <title> Probability, frequency and reasonable expectation. </title> <journal> American Journal of Physics, </journal> <volume> 14(1), </volume> <year> 1946. </year>
Reference-contexts: Probability theory has a solid foundation. Its conclusions are derived deductively from a set of intuitive, or even self-evident axioms <ref> [5] </ref>. 2. Most of the people who make the fallacy are disposed, after explana tion, to accept that they made a mistake [19]. As a result, the research activities in this domain often consist of the following steps [9, 12]: 1. <p> This opinion is also advocated by some authors in the study of uncertainty reasoning in artificial intelligence [3, 15, 17]. It is well known that the axioms of probability theory can be derived from several assumptions about the relationships between evidence and belief <ref> [5] </ref>. These assumptions, though reasonable for many situations, set up limitations for Bayesian approach at the same time. 4 2.1. Consistency All applications of Bayesian approach begin with a consistent prior prob ability distribution on a predefined proposition (or event) space.
Reference: 6. <author> D. Dubois and H. Prade. </author> <title> Updating with belief functions, ordinal condi tional functions and possibility measures. </title> <editor> In P. Bonissone, M. Henrion, L. Kanal, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 311-329. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference-contexts: In updating, a probability distribution is modified according to a (new) single probability assignment on a proposition, whereas the previous probability assignment on the proposition is completely ignored. As a result, updating is asymmet ric, but revision (or evidence combination [16]) is symmetric <ref> [6] </ref>. Although updating is a valid operation, it cannot be used to replace revision. 2.3. Extensional interpretation Probability theory is traditional interpreted in an extensional way [19], which means the following: 1.
Reference: 7. <author> H. Einhorn and R. Hogarth. </author> <title> Confidence in judgment: persistence of illusion of validity. </title> <journal> Psychological Review, </journal> <volume> 35 </volume> <pages> 395-416, </pages> <year> 1978. </year>
Reference-contexts: c is referred to as the confidence of the judgment, because of the familiar phenomenon: the more evidence one has collected, the more confident one feels when making a judgment on the issue, though it does not follow that the judgment become "truer" or "more accurate" in an objective sense <ref> [7, 8] </ref>. For a detailed discussion of the related semantics issues, see [22]. 3.3. Inference rules In NARS there are two types of rules, one is for new judgments derivation (including deduction, induction, abduction, and so on), and the other is for conflict management.
Reference: 8. <author> B. Fischhoff, P. Solvic, and S. Lichtenstein. </author> <title> Knowing with certainty: the appropriateness of extreme confidence. </title> <journal> Journal of Experimental Psychol ogy: Human Perception and Performance, </journal> <volume> 3 </volume> <pages> 552-564, </pages> <year> 1977. </year>
Reference-contexts: c is referred to as the confidence of the judgment, because of the familiar phenomenon: the more evidence one has collected, the more confident one feels when making a judgment on the issue, though it does not follow that the judgment become "truer" or "more accurate" in an objective sense <ref> [7, 8] </ref>. For a detailed discussion of the related semantics issues, see [22]. 3.3. Inference rules In NARS there are two types of rules, one is for new judgments derivation (including deduction, induction, abduction, and so on), and the other is for conflict management.
Reference: 9. <author> G. Gigerenzer. </author> <title> How to make cognitive illusions disappear: beyond "heuris tics and biases". </title> <editor> In W. Stroebe and M. Hewstone, editors, </editor> <booktitle> European Review of Social Psychology, </booktitle> <volume> Volume 2, chapter 4, </volume> <pages> pages 83-115. </pages> <publisher> John Wiley & Sons Ltd, </publisher> <year> 1991. </year>
Reference-contexts: Most of the people who make the fallacy are disposed, after explana tion, to accept that they made a mistake [19]. As a result, the research activities in this domain often consist of the following steps <ref> [9, 12] </ref>: 1. To identify the problem by carrying out psychological experiments, and compare the results with the conclusions of probability theory; 2. <p> Bayes' theorem is applied to revise one's beliefs with new evidence. However, besides the mainstream opinion expressed above, there are opinions to explain the discrepancy as a challenge to Bayesian approach: * Probability theory can be interpreted differently, such as in the "fre quentist" <ref> [9] </ref> or "propensity" [4] interpretation. 3 * There are alternative normative models that compete with Pascal probability theory, such as Baconian probability [4] and belief func tion [16]. * Some formal descriptive models are proposed, such as information integration theory [1].
Reference: 10. <author> I. </author> <title> Good. Good Thinking: The Foundations of Probability and Its Applica tions. </title> <publisher> University of Minnesota Press, </publisher> <address> Minneapolis, </address> <year> 1983. </year>
Reference-contexts: It is true that when applied into a practical domain, NARS may produce wrong expectations, but so does probability theory. NARS is not proposed to replace Bayesian models. In Good's terms <ref> [10] </ref>, Bayesian approach is toward a "Type I" rationality by maximizing the expected utility, while NARS is toward a "Type II" rationality where the cost of computing must be taken into account.
Reference: 11. <author> R. Hogarth. </author> <title> Beyond discrete biases: Functional and dysfunctional aspects of judgmental heuristics. </title> <journal> Psychological Bulletin, </journal> <volume> 90 </volume> <pages> 197-217, </pages> <year> 1981. </year>
Reference-contexts: The re quirement for consistency, though looks reasonable, is not always satisfi able, for the following reasons: 1. When a system is open to new evidence, that is, the system works in a continuous, incremental, or adaptive manner <ref> [11] </ref>, it is always possible for new knowledge to conflict with previous knowledge. 2. Under a time pressure, it is often impossible for the system to locate and consider all relevant knowledge when a judgment is made, so the judgments based on different knowledge may conflict with each other.
Reference: 12. <author> D. Kahneman and A. Tversky. </author> <title> On the study of statistical intuitions. </title> <editor> In D. Kahneman, P. Slovic, and A. Tversky, editors, </editor> <title> Judgment under Un certainty: Heuristics and Biases, </title> <booktitle> chapter 34, </booktitle> <pages> pages 493-508. </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1982. </year>
Reference-contexts: Most of the people who make the fallacy are disposed, after explana tion, to accept that they made a mistake [19]. As a result, the research activities in this domain often consist of the following steps <ref> [9, 12] </ref>: 1. To identify the problem by carrying out psychological experiments, and compare the results with the conclusions of probability theory; 2. <p> statements: * "The subjective assessment of probability resembles the subjective assessment of physical quantities such as distance or size." [18] * "Although the language of probability can be used to express any form of uncertainty, the laws of probability do not apply to all variants of uncertainty with equal force." <ref> [12] </ref> Some authors even take such a radical position by claiming that "the world operates according to Bayes' Theorem" [14].
Reference: 13. <author> J. </author> <title> Keynes. A Treatise on Probability. </title> <publisher> Macmillan, </publisher> <address> London, </address> <year> 1921. </year>
Reference-contexts: Ignorance and revision Though a probability distribution is a useful way to express one's un certainty about some events or propositions, it does not contain the infor mation about the amount of evidence that supports the probability distri bution <ref> [13] </ref>. This type of information is referred to by various authors as "ignorance", "confidence", "reliability", and so on [16, 21].
Reference: 14. <author> D. Lyon and P. Slovic. </author> <title> Dominance of accuracy information and neglect of base rates in probability estimation. </title> <journal> Acta Psychologica, </journal> <volume> 40 </volume> <pages> 287-298, </pages> <year> 1976. </year>
Reference-contexts: [18] * "Although the language of probability can be used to express any form of uncertainty, the laws of probability do not apply to all variants of uncertainty with equal force." [12] Some authors even take such a radical position by claiming that "the world operates according to Bayes' Theorem" <ref> [14] </ref>. According to this opinion, Bayesian approach is the normative model for judgment under uncertainty, and it always gives the correct or optimal answer, although sometimes it is not easy to apply the model.
Reference: 15. <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: This opinion is also advocated by some authors in the study of uncertainty reasoning in artificial intelligence <ref> [3, 15, 17] </ref>. It is well known that the axioms of probability theory can be derived from several assumptions about the relationships between evidence and belief [5]. These assumptions, though reasonable for many situations, set up limitations for Bayesian approach at the same time. 4 2.1. <p> This type of information is referred to by various authors as "ignorance", "confidence", "reliability", and so on [16, 21]. Some people argue that this information can be derived from a probabil ity distribution <ref> [15, 17] </ref>, but this argument is invalid, because it is actually based on a confusion between the background knowledge that supports a probability assignment and the proposition that appears within a condi tional probability assignment as the condition. A detailed discussion on this issue can be found in [20]. <p> On the contrary, Bayesian approach uses "global" rules. For example, when Bayes' theorem (or Jeffrey's rule) is used to update a distribution function, most probability assignments in the whole proposition space need to be re-calculated. Pearl correctly argues in <ref> [15] </ref> that local rules cause incorrect conclusions by neglect relevant information. For a system with insufficient resources, however, local rules become the only choice. The incorrect conclusions can be revised when the rele vant information is located in a later time [21]. 4.
Reference: 16. <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1976. </year>
Reference-contexts: to explain the discrepancy as a challenge to Bayesian approach: * Probability theory can be interpreted differently, such as in the "fre quentist" [9] or "propensity" [4] interpretation. 3 * There are alternative normative models that compete with Pascal probability theory, such as Baconian probability [4] and belief func tion <ref> [16] </ref>. * Some formal descriptive models are proposed, such as information integration theory [1]. <p> This type of information is referred to by various authors as "ignorance", "confidence", "reliability", and so on <ref> [16, 21] </ref>. <p> In updating, a probability distribution is modified according to a (new) single probability assignment on a proposition, whereas the previous probability assignment on the proposition is completely ignored. As a result, updating is asymmet ric, but revision (or evidence combination <ref> [16] </ref>) is symmetric [6]. Although updating is a valid operation, it cannot be used to replace revision. 2.3. Extensional interpretation Probability theory is traditional interpreted in an extensional way [19], which means the following: 1.
Reference: 17. <author> D. Spiegelhalter. </author> <title> A statistical view of uncertainty in expert systems. </title> <editor> In W. Gale, editor, </editor> <booktitle> Artificial Intelligence and Statistics, </booktitle> <pages> pages 17-56. </pages> <publisher> Addison Wesley, </publisher> <address> Reading, </address> <year> 1986. </year>
Reference-contexts: This opinion is also advocated by some authors in the study of uncertainty reasoning in artificial intelligence <ref> [3, 15, 17] </ref>. It is well known that the axioms of probability theory can be derived from several assumptions about the relationships between evidence and belief [5]. These assumptions, though reasonable for many situations, set up limitations for Bayesian approach at the same time. 4 2.1. <p> This type of information is referred to by various authors as "ignorance", "confidence", "reliability", and so on [16, 21]. Some people argue that this information can be derived from a probabil ity distribution <ref> [15, 17] </ref>, but this argument is invalid, because it is actually based on a confusion between the background knowledge that supports a probability assignment and the proposition that appears within a condi tional probability assignment as the condition. A detailed discussion on this issue can be found in [20].
Reference: 18. <author> A. Tversky and D. Kahneman. </author> <title> Judgment under uncertainty: heuristics and biases. </title> <journal> Science, </journal> <volume> 185 </volume> <pages> 1124-1131, </pages> <year> 1974. </year>
Reference-contexts: Address correspondence to 510 North Fess, Bloomington, IN 47408, USA E-mail: pwang@cogsci.indiana.edu International Journal of Approximate Reasoning 1994 11:1-158 c fl 1994 Elsevier Science Inc. 655 Avenue of the Americas, New York, NY 10010 0888-613X/94/$7.00 1 2 theory <ref> [18] </ref>, that is, between what we should do (according to probability theory) and what we do (according to psychological experiments). There fore, probability theory is not a good descriptive theory for human reason ing under uncertainty, though it is still referred to as a good normative theory. <p> Heuristics, as methods to assess subjective probability, "are highly eco nomical and usually effective, but they lead to systematic and predictable errors" <ref> [18] </ref>. Compared with normative theories, such as probability the ory, heuristics are not optimal, not formal, not systematic, and not always correct. According to this opinion, the fact that probability theory cannot match actual human reasoning is not a problem of the theory. <p> A typical opinion on this issue can be found in the following statements: * "The subjective assessment of probability resembles the subjective assessment of physical quantities such as distance or size." <ref> [18] </ref> * "Although the language of probability can be used to express any form of uncertainty, the laws of probability do not apply to all variants of uncertainty with equal force." [12] Some authors even take such a radical position by claiming that "the world operates according to Bayes' Theorem" [14]. <p> The probability of "A B", where both A and B are sets, is usually closely related to jA " Bj=jAj. For instance, this ratio is often used as an estimation of the probability, and its limit, if known, is often taken as the probability <ref> [18] </ref>. 3. The probability of "a 2 B", where a is an object and B is a set, is often determined via another set R, the "reference class". <p> Heuristics and NARS Though designed as a normative model, NARS shows some behaviors that are usually explained in term of "heuristics and biases", when these phenomena happen in human judgments <ref> [18] </ref>. 10 4.1. Availability Availability, "the ease with which instances or occurrences can be brought to mind", is a common heuristics in intuitive judgment of probability. It is "affected by factors other than frequency and probability", therefore "leads to predictable biases" [18]. The same phenomenon happens in NARS. <p> and biases", when these phenomena happen in human judgments <ref> [18] </ref>. 10 4.1. Availability Availability, "the ease with which instances or occurrences can be brought to mind", is a common heuristics in intuitive judgment of probability. It is "affected by factors other than frequency and probability", therefore "leads to predictable biases" [18]. The same phenomenon happens in NARS. Because NARS is built un der the assumption of insufficient knowledge and resources, the following properties are implied: 1. The system has to base its judgments on the available, though usually incomplete, knowledge. <p> Representativeness Representativeness, or degree of similarity, is often used as probability by human beings. "This approach to the judgment of probability leads to serious errors, because similarity, or representativeness, is not influenced by several factors that should affect judgments of probability" <ref> [18] </ref>. The basic difference between them is that "the laws of probability derive from extensional considerations" [19], but similarity judgments are based on the sharing of properties, so they are intensional. As mentioned previously, here we need to distinguish three different meanings of "probability": 1. <p> The anchoring phenomenon, or insufficient adjustment from the initial point, is observed in human thinking <ref> [18] </ref>. By calling the observed ad justments "insufficient", it is assumed that the correct adjustment rule is Bayes' theorem, or its extension, Jeffrey's rule. As discussed previously, in NARS, two different cases are distinguished when judgments conflict with each other. <p> Its behavior is still different from that of a human being. The approach is not justified by psychological data, but by logical analysis. Therefore there is no psychological experiment conducted to verify the theory. However, psychological observations, as those reported in <ref> [18] </ref>, do have a strong relation to the study of normative models. From the above dis cussion we conclude that there is no unique normative model for judgment under uncertainty | different models can be established according to dif ferent theoretical assumptions.
Reference: 19. <author> A. Tversky and D. Kahneman. </author> <title> Extensional versus intuitive reasoning: the conjunction fallacy in probability judgment. </title> <journal> Psychological Review, </journal> <volume> 90:293 315, </volume> <year> 1983. </year>
Reference-contexts: Probability theory has a solid foundation. Its conclusions are derived deductively from a set of intuitive, or even self-evident axioms [5]. 2. Most of the people who make the fallacy are disposed, after explana tion, to accept that they made a mistake <ref> [19] </ref>. As a result, the research activities in this domain often consist of the following steps [9, 12]: 1. To identify the problem by carrying out psychological experiments, and compare the results with the conclusions of probability theory; 2. <p> As a result, updating is asymmet ric, but revision (or evidence combination [16]) is symmetric [6]. Although updating is a valid operation, it cannot be used to replace revision. 2.3. Extensional interpretation Probability theory is traditional interpreted in an extensional way <ref> [19] </ref>, which means the following: 1. All sets are well-defined, that is, whether an object belongs to a set has a (maybe unknown) "Yes/No" answer. 2. The probability of "A B", where both A and B are sets, is usually closely related to jA " Bj=jAj. <p> The basic difference between them is that "the laws of probability derive from extensional considerations" <ref> [19] </ref>, but similarity judgments are based on the sharing of properties, so they are intensional. As mentioned previously, here we need to distinguish three different meanings of "probability": 1. As a pure mathematical concept, probability is neither extensional nor intensional. 11 2.
Reference: 20. <author> P. Wang. </author> <title> Belief revision in probability theory. </title> <booktitle> In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 519-526. </pages> <publisher> Mor gan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1993. </year>
Reference-contexts: A detailed discussion on this issue can be found in <ref> [20] </ref>. In the following, we will summarize the argument briefly. Suppose we are talking about the uncertainty of the propositions in a space S. For this purpose, we collect some background knowledge C, and accordingly set up a prior probability distribution on S. <p> As a result, NARS may contain (explicitly or implicitly) conflicting judgments. To handle them, NARS has both updating rule and re vision rule, whereas the latter is not available in a Bayesian model, because the information about confidence is absent there <ref> [20] </ref>. In spite of the differences, there are still many similar properties in the two models. Both of them are normative models for judgment under uncer tainty, but they are based on different assumptions about the environment where the model is applied. 4. <p> If conditionalization (Bayes' theorem and Jeffrey's rule) is the correct way of adjustment, NARS shows the anchoring bias, too. However, as argued above and in <ref> [20] </ref>, it is not always valid to use updating as revision, or to assume sufficient resources for global updating. Again, there is nothing wrong in NARS. 5.
Reference: 21. <author> P. Wang. </author> <title> From inheritance relation to non-axiomatic logic. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 11(4) </volume> <pages> 281-319, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: This type of information is referred to by various authors as "ignorance", "confidence", "reliability", and so on <ref> [16, 21] </ref>. <p> NARS as a Normative Model Non-Axiomatic Reasoning System (NARS) is an intelligent reasoning sys tem which adapts to its environment under insufficient knowledge and re sources. A formal and complete description about the system's logical kernel has been published, also in the International Journal of Approxi mate Reasoning <ref> [21] </ref>. It is assumed that the readers of the current paper have access to that paper, therefore in the following we only introduce the aspects of the system that are most closely related to our current issue. 3.1. <p> The system also needs rules to make plausible inference from given knowledge, and to revise previous beliefs in the light of new knowledge. Therefore, among other things, NARS attempts to provide a normative model for reasoning with uncertainty. 3.2. Uncertainty measurement In the simplest version of NARS <ref> [21] </ref>, each judgment has the form "S P [t]", where "S" is the subject term of the judgment, "P " is the predicate term, "" can be intuitively understood as "is a kind of" and "has the properties of" (see [21] for its formal definition), and "t" measures the uncertainty of <p> Uncertainty measurement In the simplest version of NARS <ref> [21] </ref>, each judgment has the form "S P [t]", where "S" is the subject term of the judgment, "P " is the predicate term, "" can be intuitively understood as "is a kind of" and "has the properties of" (see [21] for its formal definition), and "t" measures the uncertainty of the judgment. Because all judgments in NARS are based on the system's experience, the uncertainty of a judgment is actually represented by the weights of its (positive and negative) evidence. <p> By "correlated evidence", we mean that some evidence is used to evaluate the uncertainty of both judgments (for an exact definition and how the system can recognize its happening, see <ref> [21] </ref>). The correlation may be either full (i.e., the evidence of one judgment is included by that of the other) or partial. For partially correlated evidence, an ideal solution is to merge the evidence without repeatedly counting the shared part. <p> Therefore, confidence in dicates the stability of a frequency assignment in the face of confliction judgments. For how the uncertainty measurement is used to predict future situations, see <ref> [21] </ref>. 3.4. Compared with Bayesian approach NARS and Bayesian approach are based on different assumptions. In Bayesian model, whether an event will happen, or whether a proposition is true, is uncertain, but their probability, or degree of uncertainty, is usually certain. <p> Pearl correctly argues in [15] that local rules cause incorrect conclusions by neglect relevant information. For a system with insufficient resources, however, local rules become the only choice. The incorrect conclusions can be revised when the rele vant information is located in a later time <ref> [21] </ref>. 4. As a result, NARS may contain (explicitly or implicitly) conflicting judgments. To handle them, NARS has both updating rule and re vision rule, whereas the latter is not available in a Bayesian model, because the information about confidence is absent there [20]. <p> NARS is an attempt to equally treat extension and intension. When the uncertainty of a judgment is determined, both the extensional factor (shared instances) and intensional factor (shared properties) are considered <ref> [21, 22] </ref>. By doing this, it does not mean that they are not different, but that their effects are the same in the judgment. <p> However, as argued above and in [20], it is not always valid to use updating as revision, or to assume sufficient resources for global updating. Again, there is nothing wrong in NARS. 5. Conclusions This paper is a follow-up of <ref> [21] </ref>, and its purpose is to show some im plications of the formal model defined in the previous paper. For a more recent and complete description of the NARS project, see [23]. <p> NARS is no less normative than probability theory in the sense that it is developed from some basic principles and assumptions about what should a system (human or computer) do with incomplete and inaccurate knowledge <ref> [21] </ref>. It is true that when applied into a practical domain, NARS may produce wrong expectations, but so does probability theory. NARS is not proposed to replace Bayesian models.
Reference: 22. <author> P. Wang. </author> <title> Grounded on experience: Semantics for intelligence. </title> <type> Tech nical Report 96, </type> <institution> Center for Research on Concepts and Cognition, In 15 diana University, Bloomington, Indiana, </institution> <year> 1995. </year> <note> Available via WWW at http://www.cogsci.indiana.edu/farg/peiwang/papers.html. </note>
Reference-contexts: For a detailed discussion of the related semantics issues, see <ref> [22] </ref>. 3.3. Inference rules In NARS there are two types of rules, one is for new judgments derivation (including deduction, induction, abduction, and so on), and the other is for conflict management. For our current purpose, we will concentrate on the latter. <p> NARS is an attempt to equally treat extension and intension. When the uncertainty of a judgment is determined, both the extensional factor (shared instances) and intensional factor (shared properties) are considered <ref> [21, 22] </ref>. By doing this, it does not mean that they are not different, but that their effects are the same in the judgment.
Reference: 23. <author> P. Wang. </author> <title> Non-Axiomatic Reasoning System: Exploring the Essence of Intelligence. </title> <type> PhD thesis, </type> <institution> Indiana University, </institution> <year> 1995. </year>
Reference-contexts: Again, there is nothing wrong in NARS. 5. Conclusions This paper is a follow-up of [21], and its purpose is to show some im plications of the formal model defined in the previous paper. For a more recent and complete description of the NARS project, see <ref> [23] </ref>. Though the above discussions only address some, but not all, aspects of the system, we can still get some conclusions about the models of judgment under uncertainty.
Reference: 24. <author> P. Wang. </author> <title> Reference classes and multiple inheritances. </title> <booktitle> International Jour nal of Uncertainty, Fuzziness and and Knowledge-based Systems, </booktitle> <volume> 3(1):79 91, </volume> <year> 1995. </year>
Reference-contexts: The probability of "a 2 B", where a is an object and B is a set, is often determined via another set R, the "reference class". When "a 2 R" is true and the probability of "R B" is known, this value can be inherited by "a 2 B" <ref> [24] </ref>. Though this is a very useful and reasonable way to apply probability theory to everyday life, we should keep the following points in mind. First, this is a way to interpret probability, but not necessarily the only way to do it.
References-found: 24

