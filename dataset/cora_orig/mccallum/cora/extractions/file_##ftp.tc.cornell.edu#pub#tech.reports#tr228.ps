URL: file://ftp.tc.cornell.edu/pub/tech.reports/tr228.ps
Refering-URL: http://www.tc.cornell.edu/Software/ARCH/
Root-URL: http://www.tc.cornell.edu
Title: ARCH, An Object-Oriented Library for Asynchronous and Loosely Synchronous System Programming a C++-based library for
Author: Jean-Marc Adamo 
Degree: Also a Professor  
Date: 14, 1996  
Note: January  ARCH is  has been designed so that the C++ compiler is able to check  
Address: Ithaca, NY 14853-3801  
Affiliation: Cornell Theory Center  of Computer Science at Universite Claude-Bernard, Lyon, France.  
Abstract: Technical Report CTC95TR228, Revised abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> AT&T, </author> <title> "C++ Language System Library Manual", </title> <year> 1991. </year>
Reference-contexts: qt_rcd_buff_ptr = qt_rcd_ptr; qt_heap_buff_ptr = qt_heap_ptr; current_task = task; read_req = r; done = d; exit = e; - void body (); void read_branch (int, void *); void exit_branch (); -; 2.3 Scheduler data All the scheduling functions above perform on two data structure Sched data [0] and Sched data <ref> [1] </ref> that are created when the MAIN () macro is executed (see A.environment file). The size of each scheduling queue has a default value: SCHED QUEUE SIZE, set in the A.setconfig file. <p> This actually amounts to a ring construction. In the second example, a table of (PROC NB-1) remote channels pointers is created on each node. Then a new remote channel is created for each table slot. for i in the range <ref> [1, PROC NB] </ref>, remote channel (i-1) on node n declares node (n+i)%PROC NB as its target. This actually amounts to building a communication network that is a complete graph over the set of nodes. Both examples relate to constructing regular structures. What about irregular ones.
Reference: [2] <author> Adamo J-M. </author> <title> "Object-Oriented Parallel Programming: Library Design and Development for SPMD Programming", </title> <type> ICSI, </type> <institution> Berkeley, TR-94-011, </institution> <year> 1994. </year>
Reference-contexts: The process constantly waits for either a read-request signal or an exit signal to occur. Depending on which signal is received, the process executes either the read branch or the exit branch member function. void Read_proc::body ()- AltL branch_read (read_req, (Pmf2_ptr)&Read_proc::read_branch, 0); AltL branch_exit (exit, (Pmf2_ptr)&Read_proc::exit_branch, 0); Alts *alt_table <ref> [2] </ref> = -&branch_read, &branch_exit-; AltCtrl altctrl (2, alt_table); while (keep_running) alt (&altctrl); - 4 GLOBAL DATA 44 4 Global Data A global data is a type of data that can be accessed from any processor, be it remote or not. There are two sorts of global data: 1. <p> The range of possible degrees has arbitrarily 5 REMOTE READ AND WRITE FUNCTIONS 57 been set to the range <ref> [2, 16] </ref>. the upper bound can be changed by changing DEGREE MAX in the A.setconfig file (needs recompiling). 6 GLOBAL POINTERS 58 6 Global pointers Global pointers are a generalization of C++ pointers that allow for addressing global data at any place over the distributed memory. <p> Example The explicit declaration given earlier can be turned into this implicit one: int s ptr <ref> [2] </ref> = f4, 5g; SpreadArray&lt;int&gt; SA (tag, s ptr, i ptr, 2, 1); Getting the local base of a SpreadArray template&lt;class T&gt; T *SpreadArray&lt;T&gt;::to local ptr (); The function is to be used for access to the local section of a SpreadArray. 7 SPREAD AND REMOTE ARRAYS AND POINTERS 87 Data <p> Example the declaration below generates a 3-dimensional RemoteArray on each node. int dim ptr <ref> [2] </ref> = f4, 5, 2g; RemoteArray&lt;int&gt; SA (tag, dim ptr, 3); Getting the local base of a RemoteArray template&lt;class T&gt; T *RemoteArray&lt;T&gt;::to local ptr (); The function is to be used for access to the local section of a RemoteArray. 7 SPREAD AND REMOTE ARRAYS AND POINTERS 93 Data structures generated
Reference: [3] <author> Adamo J-M., Anguita D., </author> <title> "Object-Oriented Design of Parallel BP Neural Network Simulator and Implementation on the connection machine CM-5", </title> <institution> IWANN'95, Malaga, Spain, </institution> <month> June 95. </month>
Reference: [4] <author> Alpern B., </author> <title> "The Myth of Scalability Analysis", </title> <institution> Cornell Theory Center Seminar, </institution> <month> August 29, </month> <year> 1995. </year>
Reference-contexts: Do not need to check the boolean value //returned by the function //creating communication and synchronization channels ChanL *read_req <ref> [4] </ref>; ChanL *exit [4]; ChanL *done [4]; for (i = 0; i &lt; 4; i++)- read_req [i] = new ChanL; exit [i] = new ChanL; done [i] = new ChanL; - ChanL *starving = new ChanL; ChanL *new_load_available = new ChanL; ChanL *no_load_available = new ChanL; 2 THREADS AND PROCESSES 26 <p> Do not need to check the boolean value //returned by the function //creating communication and synchronization channels ChanL *read_req <ref> [4] </ref>; ChanL *exit [4]; ChanL *done [4]; for (i = 0; i &lt; 4; i++)- read_req [i] = new ChanL; exit [i] = new ChanL; done [i] = new ChanL; - ChanL *starving = new ChanL; ChanL *new_load_available = new ChanL; ChanL *no_load_available = new ChanL; 2 THREADS AND PROCESSES 26 ChanRD&lt;int&gt; *load_request = <p> Do not need to check the boolean value //returned by the function //creating communication and synchronization channels ChanL *read_req <ref> [4] </ref>; ChanL *exit [4]; ChanL *done [4]; for (i = 0; i &lt; 4; i++)- read_req [i] = new ChanL; exit [i] = new ChanL; done [i] = new ChanL; - ChanL *starving = new ChanL; ChanL *new_load_available = new ChanL; ChanL *no_load_available = new ChanL; 2 THREADS AND PROCESSES 26 ChanRD&lt;int&gt; *load_request = new ChanRD&lt;int&gt;(4, (self_address <p> i &lt; PROC_NB; i++) load_supply [i - 1] = new ChanRD&lt;Load&gt;(i+4, (self_address + i)%PROC_NB); //i-1 is the nb of processors between source and target ChanR *over = new ChanR (PROC_NB+4, (self_address + 1)%PROC_NB); barrier (); //creating the processes Process *proc_table [6]; proc_table [0] = new Compute_proc ( &qt_ptr [0], qt_rcd_buff_ptr <ref> [4] </ref>, qt_heap_buff_ptr [4], &current_task,&current_load, neighbor_heap_ptr, edge_heap_ptr, &read_req [0], &done [0], &exit [0], starving, new_load_available, no_load_available); for (i = 1; i &lt; 5; i++) proc_table [i] = new Read_proc ( i-1, &qt_ptr [i-1], qt_rcd_buff_ptr [i-1], qt_heap_buff_ptr [i-1], &current_task, read_req [i-1], done [i-1], exit [i-1]); proc_table [5] = new Load_balancing_proc ( &current_load, &current_task, <p> PROC_NB; i++) load_supply [i - 1] = new ChanRD&lt;Load&gt;(i+4, (self_address + i)%PROC_NB); //i-1 is the nb of processors between source and target ChanR *over = new ChanR (PROC_NB+4, (self_address + 1)%PROC_NB); barrier (); //creating the processes Process *proc_table [6]; proc_table [0] = new Compute_proc ( &qt_ptr [0], qt_rcd_buff_ptr <ref> [4] </ref>, qt_heap_buff_ptr [4], &current_task,&current_load, neighbor_heap_ptr, edge_heap_ptr, &read_req [0], &done [0], &exit [0], starving, new_load_available, no_load_available); for (i = 1; i &lt; 5; i++) proc_table [i] = new Read_proc ( i-1, &qt_ptr [i-1], qt_rcd_buff_ptr [i-1], qt_heap_buff_ptr [i-1], &current_task, read_req [i-1], done [i-1], exit [i-1]); proc_table [5] = new Load_balancing_proc ( &current_load, &current_task, starving, new_load_available, <p> ChanL *read_req <ref> [4] </ref>; ChanL *exit [4]; ChanL *done [4]; for (i = 0; i &lt; 4; i++)- read_req [i] = new ChanL; exit [i] = new ChanL; done [i] = new ChanL; - ChanL *starving = new ChanL; ChanL *new_load_available = new ChanL; ChanL *no_load_available = new ChanL; ChanRD&lt;int&gt; *load_request = new ChanRD&lt;int&gt;(4, <p> ChanL *read_req <ref> [4] </ref>; ChanL *exit [4]; ChanL *done [4]; for (i = 0; i &lt; 4; i++)- read_req [i] = new ChanL; exit [i] = new ChanL; done [i] = new ChanL; - ChanL *starving = new ChanL; ChanL *new_load_available = new ChanL; ChanL *no_load_available = new ChanL; ChanRD&lt;int&gt; *load_request = new ChanRD&lt;int&gt;(4, (self_address + 1)%PROC_NB); <p> ChanL *read_req <ref> [4] </ref>; ChanL *exit [4]; ChanL *done [4]; for (i = 0; i &lt; 4; i++)- read_req [i] = new ChanL; exit [i] = new ChanL; done [i] = new ChanL; - ChanL *starving = new ChanL; ChanL *new_load_available = new ChanL; ChanL *no_load_available = new ChanL; ChanRD&lt;int&gt; *load_request = new ChanRD&lt;int&gt;(4, (self_address + 1)%PROC_NB); ChanRD&lt;Load&gt; **load_supply =
Reference: [5] <author> Baden S. et al., </author> <title> "The LPARX User's Guide, </title> <publisher> V2.0", DCSE, Univ. </publisher> <address> California San Diego, </address> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: The code below uses ARCH point-to-point communication that is described in section 3. void make_vertex_rcd_list (int local_max_nb_of_leaves)- //local_max_nb_of_leaves: leaf max-nb per block over set of local blocks //global_max_nb_of_leaves: leaf max-nb per block over set of all spread blocks int global_max_nb_of_leaves; allreduce_max (&local_max_nb_of_leaves, &global_max_nb_of_leaves); //creating buffers and working areas Quadtree_rcd *qt_rcd_buff_ptr <ref> [5] </ref>; for (int i = 0; i &lt; 5; i++) qt_rcd_buff_ptr [i] = new Quadtree_rcd; 2 THREADS AND PROCESSES 25 Qt_heap_rcd *qt_heap_buff_ptr [5]; for (i = 0; i &lt; 5; i++) qt_heap_buff_ptr [i] = new Qt_heap_rcd [(7*global_max_nb_of_leaves*global_max_nb_of_leaves - 1)/3]; //see comment in split () function that explains the size used above <p> over set of local blocks //global_max_nb_of_leaves: leaf max-nb per block over set of all spread blocks int global_max_nb_of_leaves; allreduce_max (&local_max_nb_of_leaves, &global_max_nb_of_leaves); //creating buffers and working areas Quadtree_rcd *qt_rcd_buff_ptr <ref> [5] </ref>; for (int i = 0; i &lt; 5; i++) qt_rcd_buff_ptr [i] = new Quadtree_rcd; 2 THREADS AND PROCESSES 25 Qt_heap_rcd *qt_heap_buff_ptr [5]; for (i = 0; i &lt; 5; i++) qt_heap_buff_ptr [i] = new Qt_heap_rcd [(7*global_max_nb_of_leaves*global_max_nb_of_leaves - 1)/3]; //see comment in split () function that explains the size used above Quadtree_rcd *qt_ptr [5]; Neighbor_heap *neighbor_heap_ptr = new Neighbor_heap (global_max_nb_of_leaves); Edge_heap *edge_heap_ptr = new Edge_heap (global_max_nb_of_leaves); Load current_load (self_address, 0, 0, (C_VIS/C_IBS)/C_VPS - <p> i = 0; i &lt; 5; i++) qt_rcd_buff_ptr [i] = new Quadtree_rcd; 2 THREADS AND PROCESSES 25 Qt_heap_rcd *qt_heap_buff_ptr <ref> [5] </ref>; for (i = 0; i &lt; 5; i++) qt_heap_buff_ptr [i] = new Qt_heap_rcd [(7*global_max_nb_of_leaves*global_max_nb_of_leaves - 1)/3]; //see comment in split () function that explains the size used above Quadtree_rcd *qt_ptr [5]; Neighbor_heap *neighbor_heap_ptr = new Neighbor_heap (global_max_nb_of_leaves); Edge_heap *edge_heap_ptr = new Edge_heap (global_max_nb_of_leaves); Load current_load (self_address, 0, 0, (C_VIS/C_IBS)/C_VPS - 1, (C_HIS/C_IBS)/C_HPS - 1 ); Task current_task; current_load.next_task (&current_task); //can't have empty load the first time next_task is //executed. <p> new Compute_proc ( &qt_ptr [0], qt_rcd_buff_ptr [4], qt_heap_buff_ptr [4], &current_task,&current_load, neighbor_heap_ptr, edge_heap_ptr, &read_req [0], &done [0], &exit [0], starving, new_load_available, no_load_available); for (i = 1; i &lt; 5; i++) proc_table [i] = new Read_proc ( i-1, &qt_ptr [i-1], qt_rcd_buff_ptr [i-1], qt_heap_buff_ptr [i-1], &current_task, read_req [i-1], done [i-1], exit [i-1]); proc_table <ref> [5] </ref> = new Load_balancing_proc ( &current_load, &current_task, starving, new_load_available, no_load_available, load_request, &load_supply [0]); //start processing int pri [6] = -1, 1, 1, 1, 1, 0-; root_proc-&gt;par (6, proc_table, pri); //end processing if (!self_address) //processor 0 plays a special role end_monitoring_0 (load_request, over); 2 THREADS AND PROCESSES 27 else end_monitoring_i (load_request, over);
Reference: [6] <author> Bader D.A. et al., </author> <title> "Parallel Algorithms for Image segmentation Enhencement and Segmentation by Region Growing with an Experimental Study", </title> <institution> IACS, Univ. of Maryland, College Park, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: = new ChanRD&lt;Load&gt; *[PROC_NB - 1]; for (i = 1; i &lt; PROC_NB; i++) load_supply [i - 1] = new ChanRD&lt;Load&gt;(i+4, (self_address + i)%PROC_NB); //i-1 is the nb of processors between source and target ChanR *over = new ChanR (PROC_NB+4, (self_address + 1)%PROC_NB); barrier (); //creating the processes Process *proc_table <ref> [6] </ref>; proc_table [0] = new Compute_proc ( &qt_ptr [0], qt_rcd_buff_ptr [4], qt_heap_buff_ptr [4], &current_task,&current_load, neighbor_heap_ptr, edge_heap_ptr, &read_req [0], &done [0], &exit [0], starving, new_load_available, no_load_available); for (i = 1; i &lt; 5; i++) proc_table [i] = new Read_proc ( i-1, &qt_ptr [i-1], qt_rcd_buff_ptr [i-1], qt_heap_buff_ptr [i-1], &current_task, read_req [i-1], done [i-1], <p> [0], starving, new_load_available, no_load_available); for (i = 1; i &lt; 5; i++) proc_table [i] = new Read_proc ( i-1, &qt_ptr [i-1], qt_rcd_buff_ptr [i-1], qt_heap_buff_ptr [i-1], &current_task, read_req [i-1], done [i-1], exit [i-1]); proc_table [5] = new Load_balancing_proc ( &current_load, &current_task, starving, new_load_available, no_load_available, load_request, &load_supply [0]); //start processing int pri <ref> [6] </ref> = -1, 1, 1, 1, 1, 0-; root_proc-&gt;par (6, proc_table, pri); //end processing if (!self_address) //processor 0 plays a special role end_monitoring_0 (load_request, over); 2 THREADS AND PROCESSES 27 else end_monitoring_i (load_request, over); //deleting all stuff used in this function for (i = 5; i &gt; -1; i--) delete proc_table
Reference: [7] <author> Chapman B. M., Mehrotra P., Zima H. P., </author> <title> "Vienna Fortran, A Fortran Language Extension for Distributed Memory Multiprocessors", Compilers and Run-time Environments for Distributed Memory Machines, </title> <publisher> Elsevier 1992. </publisher>
Reference: [8] <author> Chang Y-L. et al. </author> <title> "Adaptative Image Region Growing", </title> <journal> IEEE Trans on Image Processing, </journal> <volume> 3(6), </volume> <pages> 868-872, </pages> <year> 1994. </year>
Reference: [9] <author> Copty N. et al., </author> <title> "A Data Parallel Algorithm for solving the Region Growing Problem on the Connection Machine", </title> <journal> JPDC, </journal> <volume> 21(1), </volume> <pages> 160-168, </pages> <month> April </month> <year> 1994. </year>
Reference: [10] <author> Culler D.E. et al., </author> <title> "Introduction to Split-C", </title> <institution> Computer Science Dept. U.C .Berkeley, </institution> <month> April </month> <year> 1993. </year>
Reference: [11] <author> Culler D.E. et al., </author> <title> "Parallel Programming in Split-C", </title> <institution> Computer Science Dept. U.C. Berkeley, </institution> <year> 1993. </year>
Reference: [12] <author> Culler D.E. et al., </author> <title> "Generic Active Message Interface Specification, </title> <institution> Version1.1", Computer Science Dept. UC Berkeley, </institution> <month> Nov. </month> <year> 1994. </year>
Reference: [13] <author> Dongarra J., Pozo R., Walker D., </author> <title> "An object Oriented Design for High Performance Linear Algebra on Distributed Memory Architectures", </title> <booktitle> Proc. OON-SKI Object oriented numeric conf., </booktitle> <address> pp268-269, </address> <month> April </month> <year> 1993. </year>
Reference: [14] <author> Ellis M.A., Stroustrup B., </author> <title> "The Annotated C++ Reference Manual", </title> <publisher> Addison Wesley, </publisher> <year> 1990. </year> <note> REFERENCES 102 </note>
Reference: [15] <author> Franke H., </author> <title> "MPI-F An MPI Implementation for IBM SP-1/SP-2, </title> <type> Version 1.41", </type> <institution> IBM, Watson Research Center, </institution> <month> May, </month> <year> 1995. </year>
Reference: [16] <author> Franke H. et al, </author> <title> "MPI Programming Environment for IBM SP-1/SP-2", </title> <institution> IBM, Watson Research Center, </institution> <year> 1995. </year>
Reference-contexts: The range of possible degrees has arbitrarily 5 REMOTE READ AND WRITE FUNCTIONS 57 been set to the range <ref> [2, 16] </ref>. the upper bound can be changed by changing DEGREE MAX in the A.setconfig file (needs recompiling). 6 GLOBAL POINTERS 58 6 Global pointers Global pointers are a generalization of C++ pointers that allow for addressing global data at any place over the distributed memory.
Reference: [17] <author> Gil J., </author> <title> "Renaming and Dispersion Techniques for Parallel Computers", </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 23, </volume> <month> 149-157 </month> <year> (1994). </year> <title> [18] "High Performance Fortran, Language Specification, Version 1.0", High Performance Fortran Forum, </title> <month> May 3, </month> <year> 1993. </year>
Reference: [19] <author> INMOS ldt., "OCCAM2, </author> <title> Reference Manual", Prentice, </title> <booktitle> series in computer science, </booktitle> <year> 1988. </year>
Reference: [20] <editor> Kumar V. et al., </editor> <title> "Scalable Load Balancing Techniques for Parallel Computers", </title> <journal> Journal of Parallel and Distributed Computing 22, </journal> <month> 60-79 </month> <year> (1994). </year>
Reference: [21] <author> Lippman S.B. "C++ Primer", Addison-Weysley, </author> <year> 1992. </year>
Reference: [22] <author> Malki D., Snir M., Nicke, </author> <title> "C Extensions for Programming on Distributed-Memory Machines", Compilers and Run-time Environments for Distributed Memory Machines, </title> <publisher> Elsevier 1992. </publisher>
Reference: [23] <author> Rosing M., Schnabel R. B., Weaver R. P., </author> <title> "Scientific Progamming Languages for Distributed Memory Multiprocessors: Paradigms and Research issues, Languages", Compilers and Run-time Environments for Distributed Memory Machines, </title> <publisher> Elsevier 1992. </publisher>
Reference: [24] <author> Stunkel C B. et al., </author> <title> "The SP2 Communication Subsystem", </title> <institution> IBM, Watson Research Center, </institution> <month> August, </month> <year> 1994. </year> <title> [25] "Thinking Machine Corporation, CMMD Reference Manual", manual, </title> <note> Version 3.0, </note> <month> May </month> <year> 1993. </year>
Reference: [26] <author> Thorsten von Eicken, </author> " <title> Active Messages: a Mechanism for Integrated Communication and Computation", </title> <type> Report UCB/CSD 92/#675, </type> <month> march </month> <year> 1992. </year>
References-found: 24

