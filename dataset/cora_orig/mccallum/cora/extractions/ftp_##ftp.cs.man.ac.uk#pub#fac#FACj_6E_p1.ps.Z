URL: ftp://ftp.cs.man.ac.uk/pub/fac/FACj_6E_p1.ps.Z
Refering-URL: http://www.cs.man.ac.uk/fmethods/facj/e-papers/index.html
Root-URL: http://www.cs.man.ac.uk
Title: of Computing Principles for Sequential Reasoning About Distributed Algorithms  
Author: F. A. Stomp and W. -P. de Roever 
Keyword: Phases in distributed algorithms; Proof rules for phased design; Soundness; Assertional reasoning; Temporal logic; Normal form reasoning; Layering of correctness proofs; Communication closed layers; True concurrency; Correctness of Gallager, Humblet, and Spira's distributed minumum-weight spanning tree algorithm  
Address: Kiel, Germany  
Affiliation: Christian-Albrechts-Universitat, Institut fur Informatik und Praktische Mathematik II,  
Note: Formal Aspects of Computing (1994) 6E: 1-70 c 1994 BCS Formal Aspects  
Abstract: Designers of network algorithms give elegant informal descriptions of the intuition behind their algorithms (see [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80]). Usually, these descriptions are structured according to (logical) subtasks. We present four design principles for formally designing algorithms along these lines. In particular, one principle is formulated for the case that tasks or subtasks are performed sequentially from a logical point of view, whereas from an operational point of view they are performed concurrently. The design principles are formulated in Manna and Pnueli's linear time temporal logic [MaP83]. These principles underly the correctness of large classes of algorithms, such as those for computing minimum-paths, connectivity, network flow, and minimum-weight spanning trees. In particular, the distributed minimum-weight spanning tree algorithm of Gallager, Humblet, and Spira [GHS83] is demonstrated to be structured according to these principles. A complete proof of Segall's PIF-protocol [Seg83], featuring application of one of these principles, is presented. 
Abstract-found: 1
Intro-found: 1
Reference: [AbL91] <author> Abadi, M. and Lamport, L.: </author> <title> The existence of refinement mappings. </title> <booktitle> Theoretical Computer Science, </booktitle> <month> 82(2) </month> <year> (1991). </year>
Reference-contexts: For this reason, other equivalence relations are proposed in [SiS94] which merge and generalize such permutation equivalences and stutter equivalences <ref> [AbL91] </ref>. Acknowledgements This work was partially supported by ESPRIT BRA project 6021 REACT-P. We thank R. Back, N. van Diepen, R. Gerth, W. Janssen, R. Koymans, H. Partsch, D. Peled, M. Siegel, and Xu Qiwen for valuable discussions and remarks.
Reference: [AFR80] <author> Apt, K.R., Francez, N., and de Roever, </author> <title> W.P.: A proof system for communicating sequential processes. </title> <journal> ACM TOPLAS, </journal> <month> 2(3) </month> <year> (1980). </year>
Reference: [Bor26] <author> Boruvka, O.: O jistem problemu minimalnim. </author> <note> Praca Moravske Prirodovedecke Spolecnosti (1926) (in Czech.). </note>
Reference-contexts: Welch, Lamport, and Lynch [WLL88] give a correctness proof in the context of I=O-automata, using a (partially-ordered) hierarchy of algorithms. Chou and Gafni [ChG88] consider a simplified version of the GHS-algorithm, a distributed version of Boruvka's algorithm <ref> [Bor26] </ref>. The problem of finding a simple proof principle for the sequentially phased reasoning of the full version of GHS-algorithm clearly emerges in [ChG88], since in the full version of that algorithm one has to cope with temporal disturbances of the kind discussed above. <p> Hereafter, we assume that function w is injective, i.e., for all edges e, e 0 2 E, e6=e 0 implies w (e)6=w (e 0 ). (Distinct edges have distinct weights.) The correctness of the GHS-algorithm, as well as Boruvka's algorithm <ref> [Bor26] </ref>, and other minimum-weight spanning tree algorithms is based on the following theorem, which ensures the existence and uniqueness of the minimum-weight spanning tree of such a weighted graph (V , E, w). (The proof of this theorem can be found in [GHS83].) Theorem 8.1.
Reference: [BoF88] <author> Bouge, L. and Francez, N.: </author> <title> A compositional approach to superposition. </title> <booktitle> Proc. of the 14th ACM Conference on Principles of Programming Languages (1988). </booktitle>
Reference-contexts: wishes to construct program A, whose set of atomic actions is the union of the sets B and C, such that A solves both subtasks solved by the programs B and C. 8 Many examples employing superposition can be found in [ChM88]. 9 Other superposition principles have been formulated in <ref> [BoF88, BaK90, Kat94] </ref>. The basic idea of superposing program C upon program B is to simply define program A as &lt;V 0 [ V 00 , fp j j j2V 0 [ V 00 g, B [ C&gt;.
Reference: [BaK88] <author> Back, R.J.R. and Kurki-Suonio, R.: </author> <title> Distributed Cooperation with action systems. </title> <journal> ACM TOPLAS 10(4) (1988). </journal>
Reference-contexts: Here, X and Y are auxiliary proof variables. The above program could have been represented in Back and Kurki-Suonio's language of action systems <ref> [BaK88] </ref> as follows. (Two fresh local variables l and m have been introduced to mimic the location counters of the two nodes in the program above. Furthermore, matching communication pairs have been represented by an assignment.
Reference: [BaK90] <author> Back, R.J.R. and Kurki-Suonio, R.: </author> <title> Superposition and fairness in action system refinement. </title> <booktitle> To appear in the proc. of the IFIP conference held in Jerusalem (1990). </booktitle>
Reference-contexts: wishes to construct program A, whose set of atomic actions is the union of the sets B and C, such that A solves both subtasks solved by the programs B and C. 8 Many examples employing superposition can be found in [ChM88]. 9 Other superposition principles have been formulated in <ref> [BoF88, BaK90, Kat94] </ref>. The basic idea of superposing program C upon program B is to simply define program A as &lt;V 0 [ V 00 , fp j j j2V 0 [ V 00 g, B [ C&gt;.
Reference: [BaS89] <author> Back, R.J.R. and Sere, K.: </author> <title> Stepwise refinement of action systems. </title> <booktitle> Proc. of the International Conference of Mathematics and Program Construction (1989). </booktitle> <editor> [deB80] de Bakker, J. W.: </editor> <title> Mathematical Theory and Program Correctness. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address> <year> (1980). </year>
Reference-contexts: Their (informal) descriptions are often structured as if groups of nodes in the network perform these (sub)tasks sequentially, although in reality (i.e., operationally speaking) they are performed concurrently. Current design methodologies (see, e.g., <ref> [ChM88, BaS89] </ref>) lack appropriate principles for formally developing such sequentially phased algorithms. In this paper we formulate four design principles, which formally characterize those informal descriptions. The heart of this paper consists of a principle that captures the (high-level) sequential structure in network algorithms. <p> Principles for Sequential Reasoning about Distributed Algorithms 3 in which temporal disturbances of the kind mentioned above occur. In section 8 we describe how these principles combine when proving correctness of the GHS-algorithm. In essence, we represent programs, as in [ChM88] and <ref> [BaS89] </ref>, by a collection of guarded atomic actions. This normal form (of programs) requires explicit encoding of the flow-of-control using locations, as illustrated in appendix A.2, and is partially motivated by the implicit statements and ditto assumptions which developers of distributed network algorithms are inclined to make (see appendix A.1). <p> In order to design a distributed program that solves a certain task which can be split up logically into subtasks as if they are performed sequentially, we propose the following strategy. First develop distributed programs which solve the subtasks. Methodologies for doing so are described in [ChM88] and <ref> [BaS89] </ref>. Next, combine these programs to construct one which solves the whole task. Our first design principle describes how to accomplish this combination. <p> Such a decomposition enables us to concentrate on one subject at a time. Methodologies for developing these programs are described in [ChM88] and <ref> [BaS89] </ref>. In the second stage A itself is designed by combining the programs B and C. Our design principle describes how to accomplish this combination. <p> Let these subtasks be solved by distributed programs B=&lt; V 0 ; fp i j i 2 V 0 g; B &gt; and C=&lt; V 0 ; fr i j i 2 V 0 g; C &gt; (for certain sets B and C of actions), cf. [ChM88] and <ref> [BaS89] </ref>. The remainder of this section describes our principle for combining these programs in order to obtain program A. 3.2. Verification Conditions We now present conditions of two kinds which are required for a sound application of our principle.
Reference: [ChG88] <author> Chou, C.T. and Gafni, E.: </author> <title> Understanding and verifying distributed algorithms using stratified decomposition. </title> <booktitle> Proc. of the ACM Symp. on Principles of Distr. Comp. </booktitle> <year> (1988). </year>
Reference-contexts: Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants. Methods for verifying the GHS-algorithm appear in <ref> [StR87a, StR87b, ChG88, WLL88] </ref>. We [StR87a, StR87b] have reasoned about its correctness on the basis of (sub)tasks. We have not formulated in those papers, however, the underlying proof principles. Neither has a syntactic formalism for them been given. <p> Welch, Lamport, and Lynch [WLL88] give a correctness proof in the context of I=O-automata, using a (partially-ordered) hierarchy of algorithms. Chou and Gafni <ref> [ChG88] </ref> consider a simplified version of the GHS-algorithm, a distributed version of Boruvka's algorithm [Bor26]. The problem of finding a simple proof principle for the sequentially phased reasoning of the full version of GHS-algorithm clearly emerges in [ChG88], since in the full version of that algorithm one has to cope with <p> Chou and Gafni <ref> [ChG88] </ref> consider a simplified version of the GHS-algorithm, a distributed version of Boruvka's algorithm [Bor26]. The problem of finding a simple proof principle for the sequentially phased reasoning of the full version of GHS-algorithm clearly emerges in [ChG88], since in the full version of that algorithm one has to cope with temporal disturbances of the kind discussed above. In [ChG88] no principle has been formulated for reasoning about such kind of disturbances. <p> The problem of finding a simple proof principle for the sequentially phased reasoning of the full version of GHS-algorithm clearly emerges in <ref> [ChG88] </ref>, since in the full version of that algorithm one has to cope with temporal disturbances of the kind discussed above. In [ChG88] no principle has been formulated for reasoning about such kind of disturbances. In our case, due to the collection of assertions (I j ; T j ) for nodes j, in essence, merely an interference-freedom argument for I j must be given. <p> The model in [GHS83] is an asynchronous one. We will assume a synchronous model of communication, however. Essentially the same proof applies to an asynchronous model of computation [Sto89]. We remark that in <ref> [ChG88] </ref> and [WLL88], by means of buffers, asynchronous communication has been modeled by synchronous communication. 8.1.
Reference: [ChL85] <author> Chandy, K.M and Lamport, L.: </author> <title> Distributed snapshots: determining global states of distributed systems. </title> <journal> ACM Trans. on Comp. Syst. </journal> <month> 3(1) </month> <year> (1985). </year>
Reference: [ChM88] <author> Chandy, K.M. and Misra, J.: </author> <title> Parallel Program Design: a Foundation. </title> <publisher> Addison-Wesley Publishing Company, Inc. </publisher> <year> (1988). </year>
Reference-contexts: Their (informal) descriptions are often structured as if groups of nodes in the network perform these (sub)tasks sequentially, although in reality (i.e., operationally speaking) they are performed concurrently. Current design methodologies (see, e.g., <ref> [ChM88, BaS89] </ref>) lack appropriate principles for formally developing such sequentially phased algorithms. In this paper we formulate four design principles, which formally characterize those informal descriptions. The heart of this paper consists of a principle that captures the (high-level) sequential structure in network algorithms. <p> Principles for Sequential Reasoning about Distributed Algorithms 3 in which temporal disturbances of the kind mentioned above occur. In section 8 we describe how these principles combine when proving correctness of the GHS-algorithm. In essence, we represent programs, as in <ref> [ChM88] </ref> and [BaS89], by a collection of guarded atomic actions. <p> In order to design a distributed program that solves a certain task which can be split up logically into subtasks as if they are performed sequentially, we propose the following strategy. First develop distributed programs which solve the subtasks. Methodologies for doing so are described in <ref> [ChM88] </ref> and [BaS89]. Next, combine these programs to construct one which solves the whole task. Our first design principle describes how to accomplish this combination. <p> Such a decomposition enables us to concentrate on one subject at a time. Methodologies for developing these programs are described in <ref> [ChM88] </ref> and [BaS89]. In the second stage A itself is designed by combining the programs B and C. Our design principle describes how to accomplish this combination. <p> Let these subtasks be solved by distributed programs B=&lt; V 0 ; fp i j i 2 V 0 g; B &gt; and C=&lt; V 0 ; fr i j i 2 V 0 g; C &gt; (for certain sets B and C of actions), cf. <ref> [ChM88] </ref> and [BaS89]. The remainder of this section describes our principle for combining these programs in order to obtain program A. 3.2. Verification Conditions We now present conditions of two kinds which are required for a sound application of our principle. <p> I.e., one wishes to construct program A, whose set of atomic actions is the union of the sets B and C, such that A solves both subtasks solved by the programs B and C. 8 Many examples employing superposition can be found in <ref> [ChM88] </ref>. 9 Other superposition principles have been formulated in [BoF88, BaK90, Kat94]. The basic idea of superposing program C upon program B is to simply define program A as &lt;V 0 [ V 00 , fp j j j2V 0 [ V 00 g, B [ C&gt;. <p> part of a computation 7 As before, the preconditions p j are assumed to be satisfiable (j2V 0 [V 00 ). 8 This means that one program solves the subtasks, whereas prior to the construction they were solved by two programs. 9 We do not impose the restriction, as in <ref> [ChM88] </ref>, that (programming) variables in a C-action may not modify (programming) variables occurring in a B-action. 10 The principle formulated in theorem 5.2 is an example of a superposition-principle: clearly, program A, thus obtained, has the appropriate form; it also solves the subtasks described by the preconditions fp j j j2V
Reference: [DiS80] <author> Dijkstra, </author> <title> E.W. and Scholten, C.S.: Termination detecting for diffusing computations. </title> <note> Information Processing Letters 1(4) (1980). </note>
Reference-contexts: Furthermore, these principles can also be used for the formal design of new algorithms [Sto90b]. The sequential decomposition of a concurrently performed task into subtasks can already be discerned in Segall's PIF-protocol [Seg83] (cf. also <ref> [DiS80] </ref> and [Fra80]).
Reference: [Eve79] <author> Even, S.: </author> <title> Graph Algorithms. </title> <publisher> Computer Science Press, Inc. </publisher> <address> USA, </address> <year> (1979). </year>
Reference-contexts: Assume, furthermore, that each edge e 2 E has weight w (e), w (e)2R and w (e)&gt;0, associated with it. The GHS-algorithm has been designed to compute the minimum-weight spanning tree of (V , E). Such a tree always exists <ref> [Eve79] </ref>, but it is, in general, not unique. 14 We assume the reader to be familiar with the basic notions from graph-theory [Eve79]. 15 Recall that nodes in the graph are identified with processors; and that edges in the graph are identified with communication channels. <p> The GHS-algorithm has been designed to compute the minimum-weight spanning tree of (V , E). Such a tree always exists <ref> [Eve79] </ref>, but it is, in general, not unique. 14 We assume the reader to be familiar with the basic notions from graph-theory [Eve79]. 15 Recall that nodes in the graph are identified with processors; and that edges in the graph are identified with communication channels. Principles for Sequential Reasoning about Distributed Algorithms 45 Example 8.1. Consider the graph r r A A 1 1 (all edges having weight 1).
Reference: [ElF82] <author> Elrad, T. and Francez, N.: </author> <title> Decomposition of distributed programs into communication closed layers. </title> <booktitle> Science of Computer programming, </booktitle> <month> 2 </month> <year> (1982). </year>
Reference-contexts: Moreover, if two finite computation sequences are equivalent, then their last states coincide. This argument underlies the two safe decomposition principles of Elrad and Francez <ref> [ElF82] </ref>. (In the discussion of their work we restrict ourselves to the case of two nodes and two subtasks.) We formulate their simpler principle: If S 1;1 k S 2;1 is partially correct w.r.t. precondition p 0 and postcondition p 1 , S 1;2 k S 2;2 is partially correct w.r.t. <p> In the terminology of <ref> [ElF82] </ref>, the layers S 1;1 k S 2;1 and S 1;2 k S 2;2 , i.e., the programs describing the subtasks, are communication closed if no communication between S i;1 and S j;2 occurs (i; j as above). The second (and more complex) principle in [ElF82] deals with decompositions of S <p> In the terminology of <ref> [ElF82] </ref>, the layers S 1;1 k S 2;1 and S 1;2 k S 2;2 , i.e., the programs describing the subtasks, are communication closed if no communication between S i;1 and S j;2 occurs (i; j as above). The second (and more complex) principle in [ElF82] deals with decompositions of S 1 k S 2 in case S 1 and S 2 are loops. This is also the case for our principle. However, in contrast with the principle in [ElF82] and the one presented in [FiF89], our principle requires invariants to be proved. <p> The second (and more complex) principle in <ref> [ElF82] </ref> deals with decompositions of S 1 k S 2 in case S 1 and S 2 are loops. This is also the case for our principle. However, in contrast with the principle in [ElF82] and the one presented in [FiF89], our principle requires invariants to be proved. Gerth and Shrira [GeS86] (cf. also [Pan88]) have addressed the problem of verifying the communication closedness of layers, and have offered a solution for the simpler of the two principles. <p> Now our principle for sequentially phased reasoning justifies that one can reason formally about this protocol as if first A 1 programs are executed by the nodes, and thereafter only A 2 programs. In contrast with the principles in <ref> [ElF82] </ref> and the one described in [FiF89], our principle requires invariants to be proved. Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants.
Reference: [Fra80] <author> Francez, N.: </author> <title> Distributed termination. </title> <address> ACM-TOPLAS, </address> <month> 2(1) </month> <year> (1980). </year>
Reference-contexts: Furthermore, these principles can also be used for the formal design of new algorithms [Sto90b]. The sequential decomposition of a concurrently performed task into subtasks can already be discerned in Segall's PIF-protocol [Seg83] (cf. also [DiS80] and <ref> [Fra80] </ref>).
Reference: [FiF89] <author> Fix, L. and Francez, N.: </author> <title> Semantics-driven decompositions for the verification of distributed programs, </title> <type> manuscript (1989). </type>
Reference-contexts: The second (and more complex) principle in [ElF82] deals with decompositions of S 1 k S 2 in case S 1 and S 2 are loops. This is also the case for our principle. However, in contrast with the principle in [ElF82] and the one presented in <ref> [FiF89] </ref>, our principle requires invariants to be proved. Gerth and Shrira [GeS86] (cf. also [Pan88]) have addressed the problem of verifying the communication closedness of layers, and have offered a solution for the simpler of the two principles. As observed by Fix, Francez, and Grumberg [FiF89] no verification technique for the <p> and the one presented in <ref> [FiF89] </ref>, our principle requires invariants to be proved. Gerth and Shrira [GeS86] (cf. also [Pan88]) have addressed the problem of verifying the communication closedness of layers, and have offered a solution for the simpler of the two principles. As observed by Fix, Francez, and Grumberg [FiF89] no verification technique for the general case has been presented so far. The current paper studies such a technique. To reason formally about such arguments, Katz and Peled have introduced interleaving set temporal logic [KaP87, KaP88] as a formalism. <p> Now our principle for sequentially phased reasoning justifies that one can reason formally about this protocol as if first A 1 programs are executed by the nodes, and thereafter only A 2 programs. In contrast with the principles in [ElF82] and the one described in <ref> [FiF89] </ref>, our principle requires invariants to be proved. Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants. Methods for verifying the GHS-algorithm appear in [StR87a, StR87b, ChG88, WLL88].
Reference: [GHS83] <author> Gallager R.T., </author> <title> Humblet P.A., and Spira P.M., A distributed algorithm for minimum-weight spanning trees. </title> <journal> ACM TOPLAS, </journal> <month> 5(1) </month> <year> (1983). </year>
Reference-contexts: 1. Introduction Designers of complex network algorithms (see, e.g., <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>), usually describe their algorithms on the basis of tasks or subtasks sometimes referred to as phases and subphases [RaH90]. <p> A fully worked out correctness proof of the PIF-protocol, featuring application of this principle, is presented in appendix A.3. Following the same pattern of sequential reasoning the main part of the distributed minimum-weight spanning tree algorithm of Gallager, Humblet, and Spira <ref> [GHS83] </ref>, hereafter referred to as the GHS-algorithm, can be described (see [StR87a, StR87b]). In that algorithm groups of nodes, recording which of their adjacent edges are part of the minimum-weight spanning tree, are gradually enlarged until the required tree has been constructed. <p> Now a task performed by one group can be disturbed temporarily 1 due to interaction with the task of another group. In order to capture the description given in <ref> [GHS83] </ref>, we present, apart from the principle for sequentially phased reasoning, three other principles: One describes how to enlarge the set of "participating" nodes in a subtask without (essentially) modifying (the specification of) that subtask; the next one describes how to reason about subtasks performed completely independently from each other; the <p> case for the program in Fig. 1 below, which describes the PIF-protocol [Seg83] (for the sake of expo sition, it is assumed that the network constitutes a tree). [We employ in Fig. 1 a programming notation which is standard in the description of distributed network algorithms (see, e.g., [Seg83] and <ref> [GHS83] </ref>). Statements for receiving a message together with an identification of the edge along which the message has been received are not incorporated in the program. Message queues are not represented in the program. One reasons about the above-mentioned statements and queues on a semantic level, however. <p> Fig. 3. Counterexample against omitting condition (A5) from the premise of our principle. 8. The GHS-algorithm 14 We next examine the distributed minimum-weight algorithm of Gallager, Hum-blet, and Spira, and sketch how our principles combine to prove its correctness. The model in <ref> [GHS83] </ref> is an asynchronous one. We will assume a synchronous model of communication, however. Essentially the same proof applies to an asynchronous model of computation [Sto89]. We remark that in [ChG88] and [WLL88], by means of buffers, asynchronous communication has been modeled by synchronous communication. 8.1. <p> Without additional assumptions the nodes in the network will not be able to achieve their task, since they might not agree on the edges that have to occur in the tree. For this reason, it has been assumed in <ref> [GHS83] </ref> that distinct edges have distinct weights. This ensures a unique minimum-weight spanning tree of graph (V , E) (see theorem 8.1). <p> of the GHS-algorithm, as well as Boruvka's algorithm [Bor26], and other minimum-weight spanning tree algorithms is based on the following theorem, which ensures the existence and uniqueness of the minimum-weight spanning tree of such a weighted graph (V , E, w). (The proof of this theorem can be found in <ref> [GHS83] </ref>.) Theorem 8.1. There exists a unique minimum-weight spanning tree of the weighted graph (V , E, w). Let, from now on, T denote the (unique) minimum-weight spanning tree of (V , E, w). Its existence and uniqueness are justified by the previous theorem. <p> There exists a unique minimum-weight spanning tree of the weighted graph (V , E, w). Let, from now on, T denote the (unique) minimum-weight spanning tree of (V , E, w). Its existence and uniqueness are justified by the previous theorem. Neither the theorem nor its proof in <ref> [GHS83] </ref> describes, however, how to con struct T . Such a construction is suggested by theorem 8.2 below. As a preparation of that theorem, we first introduce two auxiliary notions. <p> Conclusion and Future Work Four principles for reasoning about (complex) network algorithms have been presented. These principles apply to a large class of algorithms, such as those described in <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, and allows structuring the reasoning about them on the basis of logical (sub)tasks. Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic [MaP83]. <p> We have argued that the collection of all the principles presented in this paper can be applied to the distributed minimum-weight spanning algorithm of Gallager, Humblet, and Spira <ref> [GHS83] </ref>. Of the four principles defined here, only one, viz., the principle for sequentially phased reasoning, has been justified on the basis of permuting independent events. (The other ones have been justified by more conventional techniques.) The first author and M. Siegel [SiS94] have recently shown that there 56 F.A.
Reference: [GeS86] <author> Gerth, R.T. and Shrira, L.: </author> <title> On Proving Closedness of Distributed Layers. </title> <month> LNCS-241 </month> <year> (1986). </year>
Reference-contexts: This is also the case for our principle. However, in contrast with the principle in [ElF82] and the one presented in [FiF89], our principle requires invariants to be proved. Gerth and Shrira <ref> [GeS86] </ref> (cf. also [Pan88]) have addressed the problem of verifying the communication closedness of layers, and have offered a solution for the simpler of the two principles. As observed by Fix, Francez, and Grumberg [FiF89] no verification technique for the general case has been presented so far.
Reference: [Hum83] <author> Humblet P.A.: </author> <title> A distributed algorithm for minimum-weight directed spanning trees. </title> <journal> IEEE Trans. on Comm., </journal> <month> 31(6) </month> <year> (1983). </year>
Reference-contexts: 1. Introduction Designers of complex network algorithms (see, e.g., <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>), usually describe their algorithms on the basis of tasks or subtasks sometimes referred to as phases and subphases [RaH90]. <p> Astonishingly, this simple design principle underlies the development of many complicated algorithms as those described in <ref> [Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, the major part of the GHS-algorithm, and algorithms described in Raynal and Helary's book [RaH90]. 4 F.A. <p> Conclusion and Future Work Four principles for reasoning about (complex) network algorithms have been presented. These principles apply to a large class of algorithms, such as those described in <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, and allows structuring the reasoning about them on the basis of logical (sub)tasks. Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic [MaP83].
Reference: [JPZ91] <author> Janssen, W., Poel, M. and Zwiers, J.: </author> <title> Action systems and action refinement in the development of parallel systems, an algebraic approach. </title> <editor> LNCS-527, Baeten J.C.M. and Groote J.F. </editor> <booktitle> (Editors) (1991). </booktitle>
Reference-contexts: As shown in the present paper, however, LTL is sufficiently expressive for our purposes. Katz and Peled have also presented a principle for sequentially phased reasoning in [KaP91]. They use predicates to express when actions may be permuted. Also, Janssen, Poel, and Zwiers <ref> [JPZ91] </ref> have presented such a principle, this time in a compositional setting. They work in the framework of action systems and extend the conventional semantics of action systems by a so-called conflict operator.
Reference: [Kat94] <author> Katz, S.: </author> <title> A superimposition control construct for distributed systems, To appear in TOPLAS (1994). Principles for Sequential Reasoning about Distributed Algorithms 57 </title>
Reference-contexts: wishes to construct program A, whose set of atomic actions is the union of the sets B and C, such that A solves both subtasks solved by the programs B and C. 8 Many examples employing superposition can be found in [ChM88]. 9 Other superposition principles have been formulated in <ref> [BoF88, BaK90, Kat94] </ref>. The basic idea of superposing program C upon program B is to simply define program A as &lt;V 0 [ V 00 , fp j j j2V 0 [ V 00 g, B [ C&gt;.
Reference: [KaP87] <author> Katz, S. and Peled, D.: </author> <title> Interleaving set temporal logic. </title> <booktitle> Proc. of the ACM Symp. on Principles of Distr. Comp. </booktitle> <year> (1987). </year>
Reference-contexts: As observed by Fix, Francez, and Grumberg [FiF89] no verification technique for the general case has been presented so far. The current paper studies such a technique. To reason formally about such arguments, Katz and Peled have introduced interleaving set temporal logic <ref> [KaP87, KaP88] </ref> as a formalism. Their logic allows one to reason about a program's behavior by considering only particular representatives of the program's computation sequences, such as the very sequences in the normal form introduced above. <p> We have, however, decided to apply Manna and Pnueli's linear time temporal logic [MaP83], because it is sufficiently expressive for our purposes. (As shown in <ref> [KaP87] </ref>, interleaving set temporal logic is more expressive than linear time temporal logic.) From the discussion above it follows that if in some program, solving a certain Principles for Sequential Reasoning about Distributed Algorithms 5 task which can be split up logically into two subtasks as if they are performed sequentially, <p> This has been shown by Stomp in [Sto90a, Sto90b], where the PIF-protocol has been derived by means of stepwise refinement. For the kind of arguments applied in the soundness proof of the principle for sequentially phased reasoning, Katz and Peled <ref> [KaP87] </ref> have introduced Interleaving Set Temporal Logic (ISTL) as a formalism. Their logic is far more expressive than Linear Time Temporal Logic (LTL). We have applied ISTL in [StR88] to formulate the same principle. As shown in the present paper, however, LTL is sufficiently expressive for our purposes.
Reference: [KaP88] <author> Katz, S. and Peled, D.: </author> <title> An efficient verification method for parallel and distributed programs. </title> <booktitle> Proc. of the REX-workshop (1988). </booktitle>
Reference-contexts: As observed by Fix, Francez, and Grumberg [FiF89] no verification technique for the general case has been presented so far. The current paper studies such a technique. To reason formally about such arguments, Katz and Peled have introduced interleaving set temporal logic <ref> [KaP87, KaP88] </ref> as a formalism. Their logic allows one to reason about a program's behavior by considering only particular representatives of the program's computation sequences, such as the very sequences in the normal form introduced above.
Reference: [KaP91] <author> Katz, S. and Peled, D.: </author> <title> Defining conditional independence using collapses, </title> <note> to appear in TCS (1991). </note>
Reference-contexts: We have applied ISTL in [StR88] to formulate the same principle. As shown in the present paper, however, LTL is sufficiently expressive for our purposes. Katz and Peled have also presented a principle for sequentially phased reasoning in <ref> [KaP91] </ref>. They use predicates to express when actions may be permuted. Also, Janssen, Poel, and Zwiers [JPZ91] have presented such a principle, this time in a compositional setting. They work in the framework of action systems and extend the conventional semantics of action systems by a so-called conflict operator.
Reference: [Lam85] <author> Lamport, L.: </author> <title> Paradigms for Distributed Programs: Computing Global States. </title> <month> LNCS-190 </month> <year> (1985). </year>
Reference-contexts: In order to define this notion of equivalence (see <ref> [Lam85] </ref>) the notion of an event is needed: an event is an occurrence of the execution of some atomic action. Now each computation sequence induces a certain partial ordering of its events.
Reference: [MaP83] <author> Manna, Z. and Pnueli, A.: </author> <title> Verification of concurrent programs: A temporal proof system, </title> <booktitle> Foundations of Computer Science IV, part 2, </booktitle> <month> MC-tracts 159 </month> <year> (1983). </year>
Reference-contexts: The principle for sequentially phased reasoning can be formulated in interleaving set temporal logic. (This has been done in [StR88].) This is also true for the other principles described in this paper. We have, however, decided to apply Manna and Pnueli's linear time temporal logic <ref> [MaP83] </ref>, because it is sufficiently expressive for our purposes. (As shown in [KaP87], interleaving set temporal logic is more expressive than linear time temporal logic.) From the discussion above it follows that if in some program, solving a certain Principles for Sequential Reasoning about Distributed Algorithms 5 task which can be <p> Next, we define the formal interpretation of a correctness formula in linear time temporal logic <ref> [MaP83] </ref>. <p> formula D sat &lt;fI j jj 2 V 0 g, fT j jj 2 V 0 g, fpost j jj 2 V 0 g&gt; is an abbreviation of the conjunction of the conditions (SAT -D 1) through (SAT -D 4) below. (2 denotes the always-operator from linear time temporal logic <ref> [MaP83] </ref>.) The conditions below are interpreted over all computation sequences of program D. * 8j 2 V 0 .2I j . (SAT -D 1) For all nodes j in V 0 , I j continuously holds. (This implies that initially I j holds for all nodes j in V 0 .) <p> Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic <ref> [MaP83] </ref>. We have considered a synchronous model of computation. Along the same lines, as shown in [Sto89] where Schlichting and Schneider's results [ScS84] have been used, one can reformulate the principles for an asynchronous model of computation.
Reference: [MeS79] <author> Merlin, P.M. and Segall, A.: </author> <title> A failsafe distributed routing protocol, </title> <journal> IEEE Trans. on Comm., </journal> <month> 27-9 </month> <year> (1979). </year>
Reference-contexts: 1. Introduction Designers of complex network algorithms (see, e.g., <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>), usually describe their algorithms on the basis of tasks or subtasks sometimes referred to as phases and subphases [RaH90]. <p> Astonishingly, this simple design principle underlies the development of many complicated algorithms as those described in <ref> [Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, the major part of the GHS-algorithm, and algorithms described in Raynal and Helary's book [RaH90]. 4 F.A. <p> Conclusion and Future Work Four principles for reasoning about (complex) network algorithms have been presented. These principles apply to a large class of algorithms, such as those described in <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, and allows structuring the reasoning about them on the basis of logical (sub)tasks. Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic [MaP83].
Reference: [OwG76] <author> Owicki, S.S. and Gries, D.: </author> <title> An axiomatic proof technique for parallel programs I, </title> <note> Acta Informatica 6 (1976). </note>
Reference-contexts: to enlarge the set of "participating" nodes in a subtask without (essentially) modifying (the specification of) that subtask; the next one describes how to reason about subtasks performed completely independently from each other; the last principle deals with subtasks 1 What we call temporary disturbance is an instance of interference <ref> [OwG76] </ref>. This notion will be explained in more detail in section 5.3. Principles for Sequential Reasoning about Distributed Algorithms 3 in which temporal disturbances of the kind mentioned above occur. In section 8 we describe how these principles combine when proving correctness of the GHS-algorithm.
Reference: [Pan88] <author> Pandya, P.K.: </author> <title> Compositional verification of distributed programs, </title> <type> Ph.D. thesis, </type> <institution> Tata institute of fundamental research, Bombay, </institution> <address> India (1988). </address>
Reference-contexts: This is also the case for our principle. However, in contrast with the principle in [ElF82] and the one presented in [FiF89], our principle requires invariants to be proved. Gerth and Shrira [GeS86] (cf. also <ref> [Pan88] </ref>) have addressed the problem of verifying the communication closedness of layers, and have offered a solution for the simpler of the two principles. As observed by Fix, Francez, and Grumberg [FiF89] no verification technique for the general case has been presented so far.
Reference: [RaH90] <author> Raynal, M. and Helary, J.-P.: </author> <title> Synchronization and Control of Distributed Systems and Programs. </title> <publisher> Wiley (1990). </publisher>
Reference-contexts: 1. Introduction Designers of complex network algorithms (see, e.g., [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80]), usually describe their algorithms on the basis of tasks or subtasks sometimes referred to as phases and subphases <ref> [RaH90] </ref>. Their (informal) descriptions are often structured as if groups of nodes in the network perform these (sub)tasks sequentially, although in reality (i.e., operationally speaking) they are performed concurrently. Current design methodologies (see, e.g., [ChM88, BaS89]) lack appropriate principles for formally developing such sequentially phased algorithms. <p> Astonishingly, this simple design principle underlies the development of many complicated algorithms as those described in [Hum83, MeS79, Seg82, Seg83, ZeS80], the major part of the GHS-algorithm, and algorithms described in Raynal and Helary's book <ref> [RaH90] </ref>. 4 F.A.
Reference: [Seg82] <author> Segall, A.: </author> <title> Decentralized maximum-flow algorithms. </title> <booktitle> Networks 12 (1982). </booktitle>
Reference-contexts: 1. Introduction Designers of complex network algorithms (see, e.g., <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>), usually describe their algorithms on the basis of tasks or subtasks sometimes referred to as phases and subphases [RaH90]. <p> Astonishingly, this simple design principle underlies the development of many complicated algorithms as those described in <ref> [Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, the major part of the GHS-algorithm, and algorithms described in Raynal and Helary's book [RaH90]. 4 F.A. <p> Conclusion and Future Work Four principles for reasoning about (complex) network algorithms have been presented. These principles apply to a large class of algorithms, such as those described in <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, and allows structuring the reasoning about them on the basis of logical (sub)tasks. Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic [MaP83].
Reference: [Seg83] <author> Segall, A.: </author> <title> Distributed network protocols. </title> <journal> IEEE Trans. on Inf. Theory. </journal> <month> IT29-1 </month> <year> (1983). </year>
Reference-contexts: 1. Introduction Designers of complex network algorithms (see, e.g., <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>), usually describe their algorithms on the basis of tasks or subtasks sometimes referred to as phases and subphases [RaH90]. <p> Furthermore, these principles can also be used for the formal design of new algorithms [Sto90b]. The sequential decomposition of a concurrently performed task into subtasks can already be discerned in Segall's PIF-protocol <ref> [Seg83] </ref> (cf. also [DiS80] and [Fra80]). <p> Astonishingly, this simple design principle underlies the development of many complicated algorithms as those described in <ref> [Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, the major part of the GHS-algorithm, and algorithms described in Raynal and Helary's book [RaH90]. 4 F.A. <p> This is, e.g., the case for the program in Fig. 1 below, which describes the PIF-protocol <ref> [Seg83] </ref> (for the sake of expo sition, it is assumed that the network constitutes a tree). [We employ in Fig. 1 a programming notation which is standard in the description of distributed network algorithms (see, e.g., [Seg83] and [GHS83]). <p> e.g., the case for the program in Fig. 1 below, which describes the PIF-protocol <ref> [Seg83] </ref> (for the sake of expo sition, it is assumed that the network constitutes a tree). [We employ in Fig. 1 a programming notation which is standard in the description of distributed network algorithms (see, e.g., [Seg83] and [GHS83]). Statements for receiving a message together with an identification of the edge along which the message has been received are not incorporated in the program. Message queues are not represented in the program. One reasons about the above-mentioned statements and queues on a semantic level, however. <p> Conclusion and Future Work Four principles for reasoning about (complex) network algorithms have been presented. These principles apply to a large class of algorithms, such as those described in <ref> [GHS83, Hum83, MeS79, Seg82, Seg83, ZeS80] </ref>, and allows structuring the reasoning about them on the basis of logical (sub)tasks. Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic [MaP83].
Reference: [SiS94] <author> Siegel, M. and Stomp, F. A.: </author> <title> Extending the limits of sequentially phased reasoning. </title> <note> Submitted for publication (1994). </note>
Reference-contexts: Of the four principles defined here, only one, viz., the principle for sequentially phased reasoning, has been justified on the basis of permuting independent events. (The other ones have been justified by more conventional techniques.) The first author and M. Siegel <ref> [SiS94] </ref> have recently shown that there 56 F.A. Stomp and W.-P. de Roever are classes of algorithms where applying equivalences based on permuting independent events do not always lead to decompositions designers had in mind when they developed their algorithms. For this reason, other equivalence relations are proposed in [SiS94] which <p> Siegel <ref> [SiS94] </ref> have recently shown that there 56 F.A. Stomp and W.-P. de Roever are classes of algorithms where applying equivalences based on permuting independent events do not always lead to decompositions designers had in mind when they developed their algorithms. For this reason, other equivalence relations are proposed in [SiS94] which merge and generalize such permutation equivalences and stutter equivalences [AbL91]. Acknowledgements This work was partially supported by ESPRIT BRA project 6021 REACT-P. We thank R. Back, N. van Diepen, R. Gerth, W. Janssen, R. Koymans, H. Partsch, D. Peled, M. Siegel, and Xu Qiwen for valuable discussions and remarks.
Reference: [StR87a] <author> Stomp, F.A. and de Roever, </author> <title> W.P.: A correctness proof of a distributed minimum-weight spanning tree algorithm (extended abstract). </title> <booktitle> Proc. of the 7th ICDCS (1987). </booktitle>
Reference-contexts: Following the same pattern of sequential reasoning the main part of the distributed minimum-weight spanning tree algorithm of Gallager, Humblet, and Spira [GHS83], hereafter referred to as the GHS-algorithm, can be described (see <ref> [StR87a, StR87b] </ref>). In that algorithm groups of nodes, recording which of their adjacent edges are part of the minimum-weight spanning tree, are gradually enlarged until the required tree has been constructed. <p> Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants. Methods for verifying the GHS-algorithm appear in <ref> [StR87a, StR87b, ChG88, WLL88] </ref>. We [StR87a, StR87b] have reasoned about its correctness on the basis of (sub)tasks. We have not formulated in those papers, however, the underlying proof principles. Neither has a syntactic formalism for them been given. <p> Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants. Methods for verifying the GHS-algorithm appear in [StR87a, StR87b, ChG88, WLL88]. We <ref> [StR87a, StR87b] </ref> have reasoned about its correctness on the basis of (sub)tasks. We have not formulated in those papers, however, the underlying proof principles. Neither has a syntactic formalism for them been given. <p> The last principle shows how to reason about programs solving (sub)tasks, which may be disturbed by each other due to disturbance of the kind mentioned in section 1. The motivation for formulating these principles comes from our correctness proof in <ref> [StR87a] </ref> of the GHS-algorithm. We illustrate the principles presented in the present paper in section 8, dealing with aspects of that correctness proof. 5.1. <p> Formal Specification Now, we formulate formally the specification proved in <ref> [StR87a] </ref>. It expresses that the program describing the GHS-algorithm is totally correct w.r.t. some precondition p and some postcondition q, where p and q are defined later in this subsection. <p> We have, in this section, merely sketched how our principles apply to a correctness proof of the GHS-algorithm. Also, we have only described the essentials of the GHS-algorithm. We remark that one has to introduce a number of freeze variables to apply our principles. The proofs <ref> [StR87a, Sto89] </ref> show that the principles introduced in this paper allow one to structure correctness proofs of (complex) distributed algorithms, in particular the GHS-algorithm, according to the designer's intuition. 9. Conclusion and Future Work Four principles for reasoning about (complex) network algorithms have been presented.
Reference: [StR87b] <author> Stomp, F.A. and de Roever, </author> <title> W.P.: A fully worked out correctness proof of Gallager, Humblet, and Spira's minimum-weight spanning tree algorithm. </title> <type> Internal Report 87-4, </type> <institution> University of Nijmegen (1987). </institution>
Reference-contexts: Following the same pattern of sequential reasoning the main part of the distributed minimum-weight spanning tree algorithm of Gallager, Humblet, and Spira [GHS83], hereafter referred to as the GHS-algorithm, can be described (see <ref> [StR87a, StR87b] </ref>). In that algorithm groups of nodes, recording which of their adjacent edges are part of the minimum-weight spanning tree, are gradually enlarged until the required tree has been constructed. <p> Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants. Methods for verifying the GHS-algorithm appear in <ref> [StR87a, StR87b, ChG88, WLL88] </ref>. We [StR87a, StR87b] have reasoned about its correctness on the basis of (sub)tasks. We have not formulated in those papers, however, the underlying proof principles. Neither has a syntactic formalism for them been given. <p> Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants. Methods for verifying the GHS-algorithm appear in [StR87a, StR87b, ChG88, WLL88]. We <ref> [StR87a, StR87b] </ref> have reasoned about its correctness on the basis of (sub)tasks. We have not formulated in those papers, however, the underlying proof principles. Neither has a syntactic formalism for them been given.
Reference: [StR88] <author> Stomp, F.A. and de Roever, </author> <title> W.P.: A formalization of sequentially phased intuition in network protocols. </title> <type> Internal Report 88-15, </type> <institution> University of Nijmegen (1988). </institution>
Reference-contexts: The principle for sequentially phased reasoning can be formulated in interleaving set temporal logic. (This has been done in <ref> [StR88] </ref>.) This is also true for the other principles described in this paper. <p> For the kind of arguments applied in the soundness proof of the principle for sequentially phased reasoning, Katz and Peled [KaP87] have introduced Interleaving Set Temporal Logic (ISTL) as a formalism. Their logic is far more expressive than Linear Time Temporal Logic (LTL). We have applied ISTL in <ref> [StR88] </ref> to formulate the same principle. As shown in the present paper, however, LTL is sufficiently expressive for our purposes. Katz and Peled have also presented a principle for sequentially phased reasoning in [KaP91]. They use predicates to express when actions may be permuted.
Reference: [StR89] <author> Stomp, F.A. and de Roever, </author> <title> W.P.: Designing distributed algorithms by means of formal sequentially phased reasoning (extended abstract). </title> <booktitle> Proc. of the Third International Workshop on Distributed Algorithms (LNCS 392) (1989). </booktitle>
Reference-contexts: Section 6 deals with the soundness proofs of the principles formulated in the sections 3 and 5. In order to give the reader insight in the subtilities involved in formulating these kinds of principles, we discuss in section 7 errors in earlier versions <ref> [StR89, Sto89] </ref>. In particular, by means of examples we demonstrate that those principles are not sound. The examples given in section 7 justify the rigorous soundness proofs given in section 6. <p> Proof. Similar to the previous proofs. We conclude that, as a consequence of the lemmata 6.5.1 through 6.5.4, theorem 5.3 holds. I.e., the principle formulated in subsection 5.3 is sound. 7. Errors in Earlier Versions In this section we discuss two earlier versions <ref> [StR89, Sto89] </ref> of our principle for sequentially phased reasoning. In essence, we have required in [StR89] explicit interference freedom tests (as formulated below) instead of the syntactic restriction on assertions in the definition of correctness formulae in the present paper. <p> I.e., the principle formulated in subsection 5.3 is sound. 7. Errors in Earlier Versions In this section we discuss two earlier versions [StR89, Sto89] of our principle for sequentially phased reasoning. In essence, we have required in <ref> [StR89] </ref> explicit interference freedom tests (as formulated below) instead of the syntactic restriction on assertions in the definition of correctness formulae in the present paper. <p> The motivation for proving interference freedom of specifications has been to ensure that the reasoning about one program is not invalidated due to actions in another program. Proving interference freedom explicitly, as done in <ref> [StR89] </ref>, is, in general, a too weak requirement: as shown in subsection 7.1, by means of an example, the principle in [StR89] is not sound. In [Sto89], the requirement of proving interference freedom of specifications has been replaced by (the stronger) syntactic restriction on assertions. <p> Proving interference freedom explicitly, as done in <ref> [StR89] </ref>, is, in general, a too weak requirement: as shown in subsection 7.1, by means of an example, the principle in [StR89] is not sound. In [Sto89], the requirement of proving interference freedom of specifications has been replaced by (the stronger) syntactic restriction on assertions. <p> In subsection 7.2 we show, by means of an example, that omitting verification condition (A5) from the premise of the principle leads to an unsound principle, too. 7.1. Unsoundness of the Principle in <ref> [StR89] </ref> First Source At first, we consider the formulation in [StR89]. <p> In subsection 7.2 we show, by means of an example, that omitting verification condition (A5) from the premise of the principle leads to an unsound principle, too. 7.1. Unsoundness of the Principle in <ref> [StR89] </ref> First Source At first, we consider the formulation in [StR89]. There the premise of the principle differs from the one presented here in two aspects: verification condition (A5), requiring that if a certain node is participating in the first subtask then its termination condition for the second subtask cannot hold, has not been incorporated in [StR89], and instead of the <p> consider the formulation in <ref> [StR89] </ref>. There the premise of the principle differs from the one presented here in two aspects: verification condition (A5), requiring that if a certain node is participating in the first subtask then its termination condition for the second subtask cannot hold, has not been incorporated in [StR89], and instead of the syntactic restriction on assertions used in proofs, which requires that assertions attached to some node may not refer to programming variables of other nodes, a weaker condition has been imposed in [StR89]. <p> its termination condition for the second subtask cannot hold, has not been incorporated in <ref> [StR89] </ref>, and instead of the syntactic restriction on assertions used in proofs, which requires that assertions attached to some node may not refer to programming variables of other nodes, a weaker condition has been imposed in [StR89]. It has been required that assertions attached to some node j associated with a certain subtask cannot be invalidated by actions of nodes different from j when these nodes participate in the other subtask. <p> In essence, correctness formulae D sat' &lt; fI D j j j 2 V 0 g, fT D fpost j j j 2 V 0 g&gt; have been defined in <ref> [StR89] </ref> as the conjunction of (SAT -D 1), , (SAT -D 4), and 8j 2 V 0 :2 (T D j ). The latter condition does not follow from the other ones, because we have not imposed any syntactic restriction on assertions used in correctness formulae. <p> , then P 1 is not invalidated. (In terms of transitions, see definition 2.2, this means that whenever for transition t corresponding with action a, b (t) holds in some state s satisfying P 1 ^ P 2 , then t (s) satisfies P 1 .) We have required in <ref> [StR89] </ref> that (A 0 ) Int-f ree (I B j , I C k , act (C, k)), j ^ T B k ^ :T C Int-f ree (I C j , I B k , act (B, k)), and j ^ T C k ^ :T B k , act <p> In program C node ` has an internal action c and node k has none. The premise of the principle in <ref> [StR89] </ref> holds, indeed. In the union A=&lt; fk; `g, fp k ; p ` g, fb; cg&gt; of programs B and C , first action c can be executed in initial state x=0 ^ y=0 resulting in state x=0 ^ y=1, thus violating the invariant I B ` . <p> This complication justifies the rigorous soundness proof of our prin ciple for sequentially phased reasoning in subsection 6.1. Fig. 2. Example that the principle in <ref> [StR89] </ref> is unsound. Of course, one can also give a formal proof that the premise of the principle is satisfied. We consider some cases. (i) Int-free (I B k ^ :T B ` ^ :T C ` , fcg) is true. <p> Again, Principles for Sequential Reasoning about Distributed Algorithms 43 since act (B, `)=; holds, Int-f ree (I C k ^ T C ` ^ :T B ` , act (B, `)) is clearly satisfied. As another example that the premise of the principle in <ref> [StR89] </ref> holds, we show that verification condition (A3) holds. I.e., we show that for all computation sequences of program B, (I) :T B (II) :T B ` ) 8a 2 act (C, `). :en ` (a) continuously hold. <p> Condition (I) above vacuously holds, because the set act (C, k) is empty. Condi tion (II) above is true as a consequence of the observation that I B ` ^ :T B ` never holds. Since all verification conditions in <ref> [StR89] </ref> are satisfied, we would conclude that the conclusion of the principle there is also true. Consequently, for j=k, `, I B j would continuously hold during execution of the combined program A=&lt;fk,`g,fp k ,p ` g,fb,cg&gt;. This would hold, in particular, for node k. <p> There exists a computation sequence of program A in which in the initial state action c is executed. The resulting state satisfies x=0 ^ y=1. Thus, I B k _ I C k does not hold continuously. Therefore, the principle in <ref> [StR89] </ref> is unsound. The problem with the principle in [StR89] is intuitively due to the following. <p> The resulting state satisfies x=0 ^ y=1. Thus, I B k _ I C k does not hold continuously. Therefore, the principle in <ref> [StR89] </ref> is unsound. The problem with the principle in [StR89] is intuitively due to the following. <p> Since our reasoning is based on computation sequences of those programs, we cannot assert anything about this state s. 7.2. Unsoundness of the Principle in [S89] Second Source We have observed that the principle in <ref> [StR89] </ref> is unsound. When correcting it, we have replaced the explicit interference freedom test of specifications (verification condition (A 0 ) above) by the syntactic restriction that assertions attached to a node cannot refer to programming variables of other nodes. The latter implies interference freedom of specifications. <p> The principle for sequentially phased reasoning involves intricate considerations. As shown in this paper, our earlier formulations in <ref> [StR89] </ref> and [Sto89] are incorrect. By means of counterexamples we have proved that those principles are unsound. For that reason we have provided a detailed and rigorous proof of the principle formulated in the current paper. The applicability of this principle has been illustrated.
Reference: [Sto89] <author> Stomp, </author> <title> F.A.: Design and verification of distributed network algorithms: Foundations and applications. </title> <type> Ph. D. thesis, </type> <institution> Eindhoven University of Technology (1989). </institution>
Reference-contexts: For ease of exposition we have formulated all the principles for a synchronous model of computation. (Along the same lines, using the results of Schlichting and Schneider [ScS84], one can formulate these principle for an asynchronous model of computation, as done in <ref> [Sto89] </ref>.) Each of the principles is formulated in linear time temporal logic. Section 6 deals with the soundness proofs of the principles formulated in the sections 3 and 5. <p> Section 6 deals with the soundness proofs of the principles formulated in the sections 3 and 5. In order to give the reader insight in the subtilities involved in formulating these kinds of principles, we discuss in section 7 errors in earlier versions <ref> [StR89, Sto89] </ref>. In particular, by means of examples we demonstrate that those principles are not sound. The examples given in section 7 justify the rigorous soundness proofs given in section 6. <p> We claim in appendix 9 that every program can be represented by a collection of atomic actions as done in the present paper. We also prove correctness of the synchronous version of the PIF-protocol. This result, the discussion in section 8, and Stomp's work in <ref> [Sto89, Sto90a, Sto90b] </ref> show that our principles are applicable to complex distributed algorithms. 2. Conventions and Notations A distributed program is performed by processes in a fixed, finite, and undirected network represented by graph (V , E). <p> As already mentioned, it is shown in <ref> [Sto89] </ref> how one may reformulate the principles presented here for an asynchronous model of computation. We have decided not to include those reformulations in the present paper for two reasons: First, they do not contribute to a better insight in the principles. <p> For ease of exposition, we shall concentrate here on a small example. A larger example can be found in appendix 9, where the principle is applied to a synchronous version of the PIF-protocol. Other examples can be found in <ref> [Sto89, Sto90a, Sto90b] </ref>, where the asynchronous version of the PIF-protocol and the GHS-algorithm have been analyzed. 4.1. A Small Example Consider a network consisting of four nodes k, `, m, and n. <p> Proof. Similar to the previous proofs. We conclude that, as a consequence of the lemmata 6.5.1 through 6.5.4, theorem 5.3 holds. I.e., the principle formulated in subsection 5.3 is sound. 7. Errors in Earlier Versions In this section we discuss two earlier versions <ref> [StR89, Sto89] </ref> of our principle for sequentially phased reasoning. In essence, we have required in [StR89] explicit interference freedom tests (as formulated below) instead of the syntactic restriction on assertions in the definition of correctness formulae in the present paper. <p> Proving interference freedom explicitly, as done in [StR89], is, in general, a too weak requirement: as shown in subsection 7.1, by means of an example, the principle in [StR89] is not sound. In <ref> [Sto89] </ref>, the requirement of proving interference freedom of specifications has been replaced by (the stronger) syntactic restriction on assertions. There, however, verification condition (A5), requiring that if a certain node is participating in the first subtask then its termination condition for the second subtask cannot hold, has not been included. <p> When correcting it, we have replaced the explicit interference freedom test of specifications (verification condition (A 0 ) above) by the syntactic restriction that assertions attached to a node cannot refer to programming variables of other nodes. The latter implies interference freedom of specifications. In <ref> [Sto89] </ref> the "corrected" version is the same as the principle formulated in subsection 3.3 except that verification condition (A5) has been omitted. This condition requires that, if a node participates in the first subtask then its termination condition for the second subtask cannot hold. <p> and W.-P. de Roever I B k jy=1, I C k jtrue, and T C One may visualize the situation as follows: Program B: * ! * ! I B T B Program C: * ! * I C k : true T C The premise of the principle in <ref> [Sto89] </ref> is satisfied. <p> The model in [GHS83] is an asynchronous one. We will assume a synchronous model of communication, however. Essentially the same proof applies to an asynchronous model of computation <ref> [Sto89] </ref>. We remark that in [ChG88] and [WLL88], by means of buffers, asynchronous communication has been modeled by synchronous communication. 8.1. <p> We have, in this section, merely sketched how our principles apply to a correctness proof of the GHS-algorithm. Also, we have only described the essentials of the GHS-algorithm. We remark that one has to introduce a number of freeze variables to apply our principles. The proofs <ref> [StR87a, Sto89] </ref> show that the principles introduced in this paper allow one to structure correctness proofs of (complex) distributed algorithms, in particular the GHS-algorithm, according to the designer's intuition. 9. Conclusion and Future Work Four principles for reasoning about (complex) network algorithms have been presented. <p> Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic [MaP83]. We have considered a synchronous model of computation. Along the same lines, as shown in <ref> [Sto89] </ref> where Schlichting and Schneider's results [ScS84] have been used, one can reformulate the principles for an asynchronous model of computation. The main part of this paper consists of the formulation and the soundness proof of a principle, called the principle for sequentially phased reasoning (about concurrently performed subtasks). <p> The principle for sequentially phased reasoning involves intricate considerations. As shown in this paper, our earlier formulations in [StR89] and <ref> [Sto89] </ref> are incorrect. By means of counterexamples we have proved that those principles are unsound. For that reason we have provided a detailed and rigorous proof of the principle formulated in the current paper. The applicability of this principle has been illustrated. <p> For that reason we have provided a detailed and rigorous proof of the principle formulated in the current paper. The applicability of this principle has been illustrated. A larger example can be found in appendix 9, where the principle is applied to a synchronous version of the PIF-protocol. (In <ref> [Sto89] </ref> the asynchronous version of this protocol has been studied.) These examples show that it is feasible to apply this principle as a verification principle to network algorithms. It can, however, also been applied as a design principle.
Reference: [Sto90a] <author> Stomp, </author> <title> F.A.: A derivation of a broadcasting protocol using sequentially phased reasoning (extended abstract). Protocol Specification, Testing, and Verification, </title> <editor> X. Logrippo L., Probert R.L., Ural H. (editors), </editor> <publisher> Elsevier Science Publishers B.V. (North Holland) (1990). </publisher>
Reference-contexts: We claim in appendix 9 that every program can be represented by a collection of atomic actions as done in the present paper. We also prove correctness of the synchronous version of the PIF-protocol. This result, the discussion in section 8, and Stomp's work in <ref> [Sto89, Sto90a, Sto90b] </ref> show that our principles are applicable to complex distributed algorithms. 2. Conventions and Notations A distributed program is performed by processes in a fixed, finite, and undirected network represented by graph (V , E). <p> For ease of exposition, we shall concentrate here on a small example. A larger example can be found in appendix 9, where the principle is applied to a synchronous version of the PIF-protocol. Other examples can be found in <ref> [Sto89, Sto90a, Sto90b] </ref>, where the asynchronous version of the PIF-protocol and the GHS-algorithm have been analyzed. 4.1. A Small Example Consider a network consisting of four nodes k, `, m, and n. <p> It can, however, also been applied as a design principle. This has been shown by Stomp in <ref> [Sto90a, Sto90b] </ref>, where the PIF-protocol has been derived by means of stepwise refinement. For the kind of arguments applied in the soundness proof of the principle for sequentially phased reasoning, Katz and Peled [KaP87] have introduced Interleaving Set Temporal Logic (ISTL) as a formalism.
Reference: [Sto90b] <author> Stomp, </author> <title> F.A.: A derivation of a broadcasting protocol using sequentially phased reasoning. Stepwise Refinement of Distributed Systems: Models, Formalisms, Correctness (LNCS 430), </title> <editor> de Bakker J. W., de Roever W. P., Rozenberg G. </editor> <booktitle> (editors) (1990). </booktitle>
Reference-contexts: All the principles closely resemble the designers' intuitions as given by the informal descriptions and thus preserve the natural flavor of their original explanation. Furthermore, these principles can also be used for the formal design of new algorithms <ref> [Sto90b] </ref>. The sequential decomposition of a concurrently performed task into subtasks can already be discerned in Segall's PIF-protocol [Seg83] (cf. also [DiS80] and [Fra80]). <p> We claim in appendix 9 that every program can be represented by a collection of atomic actions as done in the present paper. We also prove correctness of the synchronous version of the PIF-protocol. This result, the discussion in section 8, and Stomp's work in <ref> [Sto89, Sto90a, Sto90b] </ref> show that our principles are applicable to complex distributed algorithms. 2. Conventions and Notations A distributed program is performed by processes in a fixed, finite, and undirected network represented by graph (V , E). <p> For ease of exposition, we shall concentrate here on a small example. A larger example can be found in appendix 9, where the principle is applied to a synchronous version of the PIF-protocol. Other examples can be found in <ref> [Sto89, Sto90a, Sto90b] </ref>, where the asynchronous version of the PIF-protocol and the GHS-algorithm have been analyzed. 4.1. A Small Example Consider a network consisting of four nodes k, `, m, and n. <p> It can, however, also been applied as a design principle. This has been shown by Stomp in <ref> [Sto90a, Sto90b] </ref>, where the PIF-protocol has been derived by means of stepwise refinement. For the kind of arguments applied in the soundness proof of the principle for sequentially phased reasoning, Katz and Peled [KaP87] have introduced Interleaving Set Temporal Logic (ISTL) as a formalism.
Reference: [ScS84] <author> Schlichting, R.D. and Schneider, </author> <title> F.B.: Using message passing for distributed programming, Proof rules and disciplines. </title> <journal> ACM TOPLAS 6-3 (1984). </journal>
Reference-contexts: The applicability of this principle is illustrated in section 4. Then, in section 5, we formulate three other principles. For ease of exposition we have formulated all the principles for a synchronous model of computation. (Along the same lines, using the results of Schlichting and Schneider <ref> [ScS84] </ref>, one can formulate these principle for an asynchronous model of computation, as done in [Sto89].) Each of the principles is formulated in linear time temporal logic. Section 6 deals with the soundness proofs of the principles formulated in the sections 3 and 5. <p> Principles for Sequential Reasoning about Distributed Algorithms 55 All the principles presented in this paper have been formulated in linear time temporal logic [MaP83]. We have considered a synchronous model of computation. Along the same lines, as shown in [Sto89] where Schlichting and Schneider's results <ref> [ScS84] </ref> have been used, one can reformulate the principles for an asynchronous model of computation. The main part of this paper consists of the formulation and the soundness proof of a principle, called the principle for sequentially phased reasoning (about concurrently performed subtasks).
Reference: [WLL88] <author> Welch, J.L., Lamport, L., and Lynch, N.A.: </author> <title> A lattice-structured proof of a minimum spanning tree algorithm. </title> <booktitle> Proc. of the ACM Symp. on Principles of Distr. Comp. </booktitle> <year> (1988). </year>
Reference-contexts: Due to these invariants in the formalism one then has the ability to reason about disturbances, as occurring in the GHS-algorithm, by proving interference-freedom w.r.t. these invariants. Methods for verifying the GHS-algorithm appear in <ref> [StR87a, StR87b, ChG88, WLL88] </ref>. We [StR87a, StR87b] have reasoned about its correctness on the basis of (sub)tasks. We have not formulated in those papers, however, the underlying proof principles. Neither has a syntactic formalism for them been given. <p> Neither has a syntactic formalism for them been given. The purpose of the present paper is to formulate these principles explicitly, prove their soundness (since their formulation turns out to be rather intricate), and illustrate their application to the PIF-protocol and to the GHS-algorithm. Welch, Lamport, and Lynch <ref> [WLL88] </ref> give a correctness proof in the context of I=O-automata, using a (partially-ordered) hierarchy of algorithms. Chou and Gafni [ChG88] consider a simplified version of the GHS-algorithm, a distributed version of Boruvka's algorithm [Bor26]. <p> The model in [GHS83] is an asynchronous one. We will assume a synchronous model of communication, however. Essentially the same proof applies to an asynchronous model of computation [Sto89]. We remark that in [ChG88] and <ref> [WLL88] </ref>, by means of buffers, asynchronous communication has been modeled by synchronous communication. 8.1.

References-found: 41

