URL: ftp://ftp.cc.gatech.edu/pub/ai/symposia/aaai-spring-95/papers/cox-freed.ps.Z
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mcox/Public/Www/papers.html
Root-URL: 
Email: cox@cc.gatech.edu freed@picasso.arc.nasa.gov  
Title: Using Knowledge of Cognitive Behavior to Learn from Failure  
Author: Michael T. Cox Michael Freed 
Keyword: self-knowledge, plan execution, story understanding, failure-driven learning  
Address: Atlanta, GA 30332-0280 Moffett Field, CA 94035  
Affiliation: College of Computing NASA Ames Research Center Georgia Institute of Technology Artificial Intelligence Branch  
Abstract: When learning from reasoning failures, knowledge of how a system behaves is a powerful lever for deciding what went wrong with the system and in deciding what the system needs to learn. A number of benefits arise when systems possess knowledge of their own operation and of their own knowledge. Abstract knowledge about cognition can be used to select diagnosis and repair strategies from among alternatives. Specific kinds of self-knowledge can be used to distinguish between failure hypothesis candidates. Making self-knowledge explicit can also facilitate the use of such knowledge across domains and can provide a principled way to incorporate new learning strategies. To illustrate the advantages of self-knowledge for learning, we provide implemented examples from two different systems: A plan execution system called RAPTER and a story understanding system called Meta-AQUA. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Birnbaum, L., Collins, G., Freed, M., and Krulwich, B. </author> <booktitle> (1990); Model-Based Diagnosis of Planning Failures; Proceedings of the Eight National Conference on Artificial Intelligence, </booktitle> <publisher> MIT Press (pp. </publisher> <pages> 318-323) Collins, </pages> <editor> G. </editor> <title> (1987); Plan Creation: Using Strategies as Blueprints; doctoral thesis, </title> <type> Tech. Rep. No. 599, </type> <institution> Yale Univ. </institution>
Reference: <author> Cox, M. T. </author> <title> (1994); Machines that Forget: </title> <booktitle> Learning from Retrieval Failure of Mis-Indexed Explanations; In Proceedings of the Sixteenth Annual Conferences of the Cognitive Science Society, </booktitle> <editor> LEA Firby, R. J. </editor> <title> (1989); Adaptive Execution in Complex Dynamic Worlds; doctoral thesis, </title> <institution> Yale Univ. </institution>
Reference-contexts: We illustrate our arguments with two introspective learners that use such knowledge in complementary ways. The RAPTER system (Freed and Collins, 1994) is a plan execution system that learns to prevent task interactions; the Meta-AQUA system <ref> (Ram and Cox, 1994) </ref> is a multistrategy learner in the domain of story understanding. Both systems are introspective learners that are failure-driven and are concerned with representations of internal events and states. The performance task in RAPTER is planning for robot truck navigation. <p> Because the input is actually an unknown exception to the concepts definition, the agent does not have the correct knowledge with which to interpret the input properly. Instead it chooses some related but causally misleading explanation with which to understand the input. Previous publications <ref> (Ram and Cox, 1994) </ref> have shown it to be useful in the task of understanding drug-smuggling stories. Moreover, the original AQUA system dealt with a similar pattern in the domain of terrorist stories. For example, the AQUA program believes that those who commit suicides must be depressed.
Reference: <author> Firby, R. J., and Hanks, S. </author> <title> (1987); The Simulator Manual; Tech. </title> <type> Rep. </type> <institution> YaleU/CSD/RR No. 563, Yale Univ. </institution>
Reference-contexts: Using Self-Knowledge to Adapt Plan Execution RAPTER (RAP adapTER) is a failure-driven adaptation component for refining routine plans executed by the Reactive Action Package (RAP) plan-execution system (Firby, 1989). The RAP system controls a robot delivery-truck as it encounters unpredictable setbacks and opportunities in the Truckworld simulator <ref> (Firby and Hanks, 1987) </ref>. When one of RAPTERs routine plans fails, the system attempts to adapt existing RAPs in order to prevent recurrence of the failure.


References-found: 3

