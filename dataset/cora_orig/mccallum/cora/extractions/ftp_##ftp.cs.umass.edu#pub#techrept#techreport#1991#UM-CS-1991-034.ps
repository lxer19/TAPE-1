URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1991/UM-CS-1991-034.ps
Refering-URL: http://dis.cs.umass.edu/~klassner/pubs.html
Root-URL: 
Title: Integrated Signal Processing and Signal Understanding 1  
Author: Victor Lesser, Hamid Nawab Malini Bhandaru, Norman Carver, Zarko Cvetanovic, Izaskun Gallastegi, Frank Klassner 
Address: 44 Cummington Street Boston, Massachusetts 02125  
Affiliation: Electrical and Computer Engineering Dept. Boston University  
Abstract: COINS Technical Report 91-34 November 1991 Abstract This report outlines the IPUS paradigm, named for Integrated Processing and Understanding of Signals, which permits sophisticated interaction between theory-based problem solving in signal processing and heuristic problem-solving in signal interpretation. The need for such a paradigm arises in signal understanding domains that require the processing of complicated interacting signals under variable signal-to-noise ratios. One such application is sound understanding, in the context of which we report on a testbed experiment illustrating the functionality of key IPUS architecture components. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bregman, </author> <title> Auditory Scene Analysis: The Perceptual Organization of Sound, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The effect of negative evidence at the microstream level is computed using the time region covered by the negative evidence, the total length of the microstream (a function of the form 1 e x where we map the total length of the microstream to the interval <ref> [1; 8] </ref> and x is the SOU's time coverage) and the microstream region (attack, steady or decay) in which the negative evidence is located.
Reference: [2] <author> N. Carver, </author> <title> "A New Framework for sensor Interpretation: Planning to Resolve Sources of Uncertainty", </title> <booktitle> AAAI '91 Proceedings, </booktitle> <pages> pp 724-731. </pages>
Reference-contexts: The control mechanism must be able to focus on particular uncertainties in a situation-dependent manner and 4 must support problem-solving strategies for reducing these uncertainties in a timely, yet intelligent, manner. To meet this specification, IPUS uses the RESUN <ref> [2, 3] </ref> framework to control knowledge source 2 execution. RESUN views interpretation as a process of gathering evidence to resolve sources of uncertainty in interpretation hypotheses. The framework uses an explicit symbolic representation for the sources of uncertainty (SOU) in the various hypotheses. <p> bound on the duration of the source's stream and the source itself, while the lack of a high-energy microstream indicates a greater belief that its source isn't actually present in the monitored environment, etc.) through the hypothesis-set. 5.6 Control Issues Control in IPUS is based on the RESUN control framework <ref> [2, 3] </ref>, which models interpretation as a process that gathers evidence to resolve particular sources of uncertainty in interpretation hypotheses. This section first provides an overview of the RESUN framework components and then describes how they are used within IPUS in the context of the testbed trace.
Reference: [3] <author> N. Carver, </author> <title> Sophisticated Control for Interpretation: Planning to Resolve Uncertainty, </title> <type> Ph.D. Thesis, </type> <institution> Computer and Information Science Department, University of Massachusetts, </institution> <year> 1990. </year>
Reference-contexts: The control mechanism must be able to focus on particular uncertainties in a situation-dependent manner and 4 must support problem-solving strategies for reducing these uncertainties in a timely, yet intelligent, manner. To meet this specification, IPUS uses the RESUN <ref> [2, 3] </ref> framework to control knowledge source 2 execution. RESUN views interpretation as a process of gathering evidence to resolve sources of uncertainty in interpretation hypotheses. The framework uses an explicit symbolic representation for the sources of uncertainty (SOU) in the various hypotheses. <p> bound on the duration of the source's stream and the source itself, while the lack of a high-energy microstream indicates a greater belief that its source isn't actually present in the monitored environment, etc.) through the hypothesis-set. 5.6 Control Issues Control in IPUS is based on the RESUN control framework <ref> [2, 3] </ref>, which models interpretation as a process that gathers evidence to resolve particular sources of uncertainty in interpretation hypotheses. This section first provides an overview of the RESUN framework components and then describes how they are used within IPUS in the context of the testbed trace.
Reference: [4] <author> Coombs, Dawes, Tversky, </author> <title> ch 6, Mathematical Psychology, An Elementary Introduction, </title> <publisher> Prentice-Hall, </publisher> <year> 1970. </year>
Reference-contexts: A cost-benefit model based on decision theory or signal-detection theory may prove useful in this research problem <ref> [4] </ref>. The development of this testbed thus far has had a strong empirical nature. That is, given knowledge of the range of scenarios we could generate, we supplied IPUS with a set of SPAs we believed adequate for the interpretation tasks it could face.
Reference: [5] <author> B. Dawant, B. Jansen, </author> <title> "Coupling Numerical and Symbolic Methods for Signal Interpretation", </title> <journal> IEEE Transactions on Systems, Man and Cybernetics. </journal> <month> Jan/Feb </month> <year> 1991. </year>
Reference-contexts: Thus, the interaction between the interpretation problem-solving and the signal processing is limited to a sequential scheme in which the former accepts the latter's output data. Some recent systems <ref> [7, 9, 10, 5] </ref> have used architectures in which the signal processing is not immutable and can be affected by the results of interpretation activity. However, the interaction between signal processing and higher-level interpretation has been limited in these systems. <p> Through these problem solving approaches, IPUS-based systems can decide when to reprocess data previously examined under one SPA with another SPA to obtain evidence for resolving uncertainties. 3 Related Work As stated earlier, some recent systems <ref> [7, 9, 10, 5] </ref> have begun to explore the interaction between interpretation activity and numeric-level signal processing. For example, Hayes-Roth [9] incorporates an input-data management component that controls the sampling rate of signals in response to overall system time and workload constraints. <p> The model of interaction does not appear adequate for signals containing complex structures that must be modeled over time. Dawant <ref> [5] </ref> uses a more general approach in which signal interpretation knowledge is separated from signal processing knowledge, yet can guide the re-application of the signal processing knowledge.
Reference: [6] <author> K. Decker, V. Lesser, R. Whitehair, </author> <title> "Extending a Blackboard Architecture for Approximate Processing", </title> <booktitle> Journal of Real-Time Systems 2, </booktitle> <pages> pp 47-79, </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1990. </year>
Reference-contexts: How the knowledge will be incorporated and how it will interact with other reprocessing knowledge based on SPA theory are open questions. In the area of real-time system design, our IPUS research will focus on developing a framework for parameterizing knowledge sources to engage in approximate processing <ref> [6, 11] </ref>. The goal of this work will be to develop knowledge sources that 44 are responsive to real-time constraints; if time constraints are tight, the knowledge sources should utilize approximate search algorithms and approximate data representations to provide less precise interpretations that are still useful to the system.
Reference: [7] <author> W. Dove, </author> <title> Knowledge-Based Pitch Detection, </title> <type> PhD Thesis, </type> <institution> MIT, </institution> <year> 1986. </year>
Reference-contexts: Thus, the interaction between the interpretation problem-solving and the signal processing is limited to a sequential scheme in which the former accepts the latter's output data. Some recent systems <ref> [7, 9, 10, 5] </ref> have used architectures in which the signal processing is not immutable and can be affected by the results of interpretation activity. However, the interaction between signal processing and higher-level interpretation has been limited in these systems. <p> Through these problem solving approaches, IPUS-based systems can decide when to reprocess data previously examined under one SPA with another SPA to obtain evidence for resolving uncertainties. 3 Related Work As stated earlier, some recent systems <ref> [7, 9, 10, 5] </ref> have begun to explore the interaction between interpretation activity and numeric-level signal processing. For example, Hayes-Roth [9] incorporates an input-data management component that controls the sampling rate of signals in response to overall system time and workload constraints.
Reference: [8] <author> L. Erman, R. Hayes-Roth, V. Lesser, D. Reddy, </author> <title> "The Hearsay II Speech Understanding System: Integrating Knowledge to Resolve Uncertainty", </title> <journal> Computing Surveys, v. </journal> <volume> 12, </volume> <month> June </month> <year> 1980. </year>
Reference-contexts: 1 Introduction In traditional signal understanding systems <ref> [8, 17] </ref>, the front-end signal processing is usually fixed for all input signals, and these signals are not re-processed on the basis of higher-level problem-solving dynamics. <p> The effect of negative evidence at the microstream level is computed using the time region covered by the negative evidence, the total length of the microstream (a function of the form 1 e x where we map the total length of the microstream to the interval <ref> [1; 8] </ref> and x is the SOU's time coverage) and the microstream region (attack, steady or decay) in which the negative evidence is located.
Reference: [9] <author> B. Hayes-Roth, R. Washington, R. Hewett, M. Hewett, and A. Seiver. </author> <title> "Intelligent Monitoring and Control", </title> <booktitle> IJCAI '89 Proceedings, </booktitle> <pages> pp 243-249. </pages>
Reference-contexts: Thus, the interaction between the interpretation problem-solving and the signal processing is limited to a sequential scheme in which the former accepts the latter's output data. Some recent systems <ref> [7, 9, 10, 5] </ref> have used architectures in which the signal processing is not immutable and can be affected by the results of interpretation activity. However, the interaction between signal processing and higher-level interpretation has been limited in these systems. <p> Through these problem solving approaches, IPUS-based systems can decide when to reprocess data previously examined under one SPA with another SPA to obtain evidence for resolving uncertainties. 3 Related Work As stated earlier, some recent systems <ref> [7, 9, 10, 5] </ref> have begun to explore the interaction between interpretation activity and numeric-level signal processing. For example, Hayes-Roth [9] incorporates an input-data management component that controls the sampling rate of signals in response to overall system time and workload constraints. <p> For example, Hayes-Roth <ref> [9] </ref> incorporates an input-data management component that controls the sampling rate of signals in response to overall system time and workload constraints.
Reference: [10] <author> C. Kohl, A. Hanson and E. Reisman, </author> <title> "A Goal-Directed Intermediate Level Executive for Image Interpretation", </title> <booktitle> IJCAI '87 Proceedings, </booktitle> <pages> pp 811-814. </pages>
Reference-contexts: Thus, the interaction between the interpretation problem-solving and the signal processing is limited to a sequential scheme in which the former accepts the latter's output data. Some recent systems <ref> [7, 9, 10, 5] </ref> have used architectures in which the signal processing is not immutable and can be affected by the results of interpretation activity. However, the interaction between signal processing and higher-level interpretation has been limited in these systems. <p> Through these problem solving approaches, IPUS-based systems can decide when to reprocess data previously examined under one SPA with another SPA to obtain evidence for resolving uncertainties. 3 Related Work As stated earlier, some recent systems <ref> [7, 9, 10, 5] </ref> have begun to explore the interaction between interpretation activity and numeric-level signal processing. For example, Hayes-Roth [9] incorporates an input-data management component that controls the sampling rate of signals in response to overall system time and workload constraints. <p> Any deviations between observed signal behavior and available signal event models are attributed to chance variations in the source being monitored, never to the source signal's interaction with the environment or unsuitable processing algorithms. In GOLDIE <ref> [10] </ref>, Kohl describes an image segmentation system that permits high-level interpretation goals to guide the choice of numeric-level segmentation algorithms, their sensitivity settings, and region of application within an image.
Reference: [11] <author> V. Lesser, J. Pavlin, and E. Durfee, </author> <title> "Approximate Processing in Real-Time Problem Solving", </title> <journal> AI Magazine, </journal> <volume> Spring 88, Vol. 9, No. 1, </volume> <pages> pp 49-61. </pages>
Reference-contexts: How the knowledge will be incorporated and how it will interact with other reprocessing knowledge based on SPA theory are open questions. In the area of real-time system design, our IPUS research will focus on developing a framework for parameterizing knowledge sources to engage in approximate processing <ref> [6, 11] </ref>. The goal of this work will be to develop knowledge sources that 44 are responsive to real-time constraints; if time constraints are tight, the knowledge sources should utilize approximate search algorithms and approximate data representations to provide less precise interpretations that are still useful to the system.
Reference: [12] <author> H. Nawab, V. Lesser, E. Milios, </author> <title> "Diagnosis Using the Underlying Theory of a Signal Processing System", </title> <journal> IEEE Transactions on Systems, Man and Cybernetics. </journal> <note> Special Issue on Diagnostic Reasoning. May/June 1987. </note>
Reference-contexts: If these regions contain many short contours, the violation detection KS assumes that short contour clusters in these regions could represent a source's distorted presence in the contouring KS's output. 5.2 Discrepancy Diagnosis The discrepancy diagnosis KS, which is based on <ref> [12] </ref>, models the reasoning of a signal processing expert and carries out a discrepancies-to-distortions inverse mapping. A major part of the expert reasoning makes use of knowledge regarding the underlying Fourier theory for the signal processing algorithms. <p> In the short example illustrated, this operator effectively reduces the differences between the expected state and the observed state. inserted into the original operator sequence and verification continues. One issue not originally dealt with in <ref> [12] </ref> that arises in the IPUS framework is the problem of incorrect explanations. Sometimes the first explanation offered by the diagnosis process will not enable the reprocessing mechanism to eliminate a discrepancy.
Reference: [13] <author> H. Nawab and T. Quatieri, </author> <title> "Short-Time Fourier Transform", </title> <booktitle> Advanced Topics in Signal Processing, </booktitle> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1988. </year>
Reference-contexts: An SPA instance is created by the specification of particular values for the parameters, and has capabilities and limitations stemming from those parameter values. As an example of this instantiation concept, consider the class of short-time Fourier transform (STFT) algorithms <ref> [13] </ref>, which can be used for time-dependent frequency analysis of signals.
Reference: [14] <author> H. Nawab and V. Lesser, </author> <title> "High-Level Adaptive Signal Processing", </title> <journal> NAIC Final Report, </journal> <volume> vol 17, </volume> <month> October </month> <year> 1989. </year> <month> 47 </month>
Reference-contexts: The need for a paradigm such as IPUS arises in applications where the situation-dependent nature of signal processing requirements leads to a combinatorial explosion in the number of different signal processing algorithms that a signal understanding system must have at its disposal. One such application is sound understanding <ref> [14] </ref>, which involves real-time processing of acoustic signals in order to determine the types of sound sources (such as telephones, crying infants, household appliances, etc.) that may have generated those signals. Specific instances of sound understanding include robotic hearing and speech recognition in environments with non-speech background sound sources. <p> Thus, the search for appropriate signal interpretations is intimately connected with the search for appropriate SPA instances. At the heart of the IPUS architecture lies an iterative technique <ref> [14] </ref> for converging to the appropriate SPAs and parameter values. The following description is meant to serve as a summary of this iterative technique's stages. Section 5 provides a more detailed view of each stage. <p> This implies that discrepancy detection mechanisms must be able to work with ranges of permissible values as well as specific values. This requires a representation in which qualitative calculus can be performed. In <ref> [14] </ref> we discuss the range calculus used in the testbed implementation described in this report. The task of detecting discrepancies is distributed among all the knowledge sources responsible for interpreting lower-level data as higher-level concepts (e.g., interpreting 5 contours as 1 microstream).
Reference: [15] <author> H. Nawab and V. Lesser, </author> <title> "Integrated Processing and Understanding of Signals", Knowledge-Based Signal Processing, </title> <editor> A. Oppenheim and H. Nawab, eds. </editor> <year> 1991. </year>
Reference-contexts: However, no formal analysis was ever performed on the scenarios to determine a priori what algorithms would be needed and where in the data streams processing by two or more SPAs would be required. Work in this area is closely linked to the SPA model variety problem <ref> [15] </ref>. This problem focuses on the relationship between SPAs and the classes of signals for which they can produce undistorted outputs.
Reference: [16] <author> A. Newell and H. Simon, </author> <title> "GPS: A Program that Simulates Human Thought". Computers and Thought, </title> <editor> Feigenbaum and Feldman, </editor> <booktitle> eds. </booktitle> <pages> pp 279-293. </pages> <publisher> McGraw-Hill, </publisher> <year> 1963. </year>
Reference-contexts: A major part of the expert reasoning makes use of knowledge regarding the underlying Fourier theory for the signal processing algorithms. This diagnostic reasoning is captured within a means-ends analysis framework <ref> [16] </ref> using multiple levels of abstraction and a verification phase. Furthermore, the reasoning is carried out with a qualitative description of the various signal quantities involved in order to deal with uncertain and approximate information. Figure 10 outlines the plan-and-verify strategy of the diagnostic process.
Reference: [17] <author> H. Nii, E. Feigenbaum, J. Anton, A. Rockmore, </author> <title> "Signal-to-Symbol Transformation: HASP/SIAP Case Study", </title> <journal> AI Magazine, </journal> <volume> vol 3, </volume> <month> Spring </month> <year> 1982. </year>
Reference-contexts: 1 Introduction In traditional signal understanding systems <ref> [8, 17] </ref>, the front-end signal processing is usually fixed for all input signals, and these signals are not re-processed on the basis of higher-level problem-solving dynamics.
Reference: [18] <author> Y. Peng and J. Reggia, </author> <title> "Plausibility of Diagnositic Hypotheses: The Nature of Simplicity," </title> <booktitle> AAAI '86 Proceedings, </booktitle> <pages> pp 140-145, </pages> <year> 1986. </year>
Reference-contexts: That is, the diagnosis process mimics the diagnostic reasoning of experts in that they first offer explanations (i.e., operator sequences) that are as uncomplicated as possible <ref> [18] </ref>. Once a candidate sequence has been obtained, the diagnostic process enters into its verify phase. At this point, the diagnostic process "drops" to to the lowest abstraction level at which a description of the initial state is known.
Reference: [19] <author> D. Seborg, et al, </author> <title> "Adaptive Control Strategies for Process Control: A Survey", </title> <journal> AIChE Journal, </journal> <volume> vol. 32, no. 6, </volume> <pages> pp. 881-913, </pages> <month> June </month> <year> 1986. </year> <month> 48 </month>
Reference-contexts: In view of the adaptive nature of the IPUS architecture, it is important to distinguish between the IPUS approach and the classic adaptive control theory approach <ref> [19] </ref>. Control theory uses stochastic-process concepts to characterize signals, and these characterizations are limited to probabilistic moments, usually no higher than second-order. Discrepancies between these stochastic characterizations and an SPA's output data are used to adapt future signal processing.
References-found: 19

