URL: http://www.cs.cornell.edu/Info/People/hayden/trace.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/hayden/publications.htm
Root-URL: 
Title: Optimizing Layered Communication Protocols  
Author: Mark Hayden, Robbert van Renesse 
Affiliation: Dept. of Computer Science, Cornell University  
Abstract: Layering of protocols offers several well-known advantages, but typically leads to performance inefficiencies. We present a model for layering, and point out where the performance problems occur in stacks of layers using this model. We then investigate the common execution paths in these stacks and how to identify them. These paths are optimized using three techniques: optimizing the computation, compressing protocol headers, and delaying processing. All of the optimizations can be automated in a compiler with the help of minor annotations by the protocol designer. We describe the performance that we obtain after implementing the optimizations by hand on a full-scale system. 
Abstract-found: 1
Intro-found: 1
Reference: [BBVvE95] <author> Anindya Basu, Vineet Buch, Werner Vogels, and Thorsten von Eicken. U-Net: </author> <title> A user-level network interface for parallel and distributed computing. </title> <booktitle> In Proc. of the Fifteenth ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 40-53, </pages> <address> Copper Mountain Resort, CO, </address> <month> December </month> <year> 1995. </year> <month> 15 </month>
Reference-contexts: These could be further optimized by rewriting this infrastructure in C. There are no delayed operations in the unoptimized protocol stack. The time line for one round-trip of the C protocol is depicted in fig. 6. Two Sparcstation 20s are communicating over an ATM network using U-net <ref> [BBVvE95] </ref> which has one-way latencies of 35s. At 0s, process A receives a message from process B off the network. 26s later the application has received the message and the next message is sent on the network.
Reference: [BJ87] <author> Kenneth P. Birman and Thomas A. Joseph. </author> <title> Exploiting virtual synchrony in distributed systems. </title> <booktitle> In Proc. of the Eleventh ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 123-138, </pages> <address> Austin, TX, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: The daemons are in daily use in the Cornell Computer Science Department. 12 protocol suite code-latency delayed operations normal 1500s none trace/ML 41s 28 63s trace/C 26s 37s The protocols measured here implement FIFO virtual synchrony <ref> [BJ87] </ref> and consist of 10 or more protocol layers. All the performance measurements are made on groups with 2 members, where the properties are roughly equivalent to those of TCP.
Reference: [BvR94] <author> Kenneth P. Birman and Robbert van Renesse. </author> <title> Reliable Distributed Computing with the Isis Toolkit. </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994. </year>
Reference-contexts: The other 4 bytes is a sequence number (for instance). There is not much room for improvement. This 8 byte header can be compared with those in similar communication protocols, such as TCP (40 bytes, 20 bytes for TCP with header compression) 1 , Isis <ref> [BvR94] </ref> (over 80 bytes), and Horus [RBM96] (over 50 bytes). Managing multiple formats. Two related problems arise when additional header formats are introduced to protocol stacks that expect only a single format.
Reference: [Jac90] <author> Van Jacobson. </author> <title> Compressing TCP/IP headers for low-speed serial links. </title> <type> RFC 1144, </type> <institution> Network Working Group, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: These headers are compressed by our approach when they appear in the common path. Non-constant headers: These include any other headers, such as sequence numbers or headers used in negotiating reconfigurations. These are not compressed. 9 These optimizations are based on the use of connection identifiers <ref> [vR96, Jac90, Kay95] </ref>. Connection identifiers are tuples containing addressing headers which do not change very often. All the information in these tuples are hashed into 32-bit values which are then used along with hash tables to route messages to the protocol stacks.
Reference: [Kay95] <author> Jonathan Kay. </author> <title> Path IDS: A Mechanism for Reducing Network Software Latency. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1995. </year>
Reference-contexts: These headers are compressed by our approach when they appear in the common path. Non-constant headers: These include any other headers, such as sequence numbers or headers used in negotiating reconfigurations. These are not compressed. 9 These optimizations are based on the use of connection identifiers <ref> [vR96, Jac90, Kay95] </ref>. Connection identifiers are tuples containing addressing headers which do not change very often. All the information in these tuples are hashed into 32-bit values which are then used along with hash tables to route messages to the protocol stacks.
Reference: [Ler96] <author> Xavier Leroy. </author> <title> The Objective Caml system release 1.02. </title> <institution> INRIA, France, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: By limiting the use of features of ML, we were confident that if we ran into performance problems from ML, we could translate the system back to C with minimal effort. The performance of ML has not been a problem. The compiler we use (Objective Caml <ref> [Ler96] </ref>) generates adequately efficient code for us. We believe this is partly because we avoid expensive language constructs. Further optimizations are squeezed out of Ensemble by translating trace handlers by hand into C in order to improve performance even more.
Reference: [MPBO96] <author> David Mosberger, Larry L. Peterson, Patrick G. Bridges, and Sean O'Malley. </author> <title> Analysis of techniques to improve protocol processing latency. </title> <booktitle> In Proc. of the Proceedings of the 1996 ACM SIGCOMM Conference, </booktitle> <address> Stanford, </address> <month> Septem-ber </month> <year> 1996. </year>
Reference-contexts: The optimizations are not a necessary part of the layering model: protocol layers execute 14 with or without the optimizations. This simplifies development because optimizations only need to be considered in the final stages of development. Other related work has been done on Integrated Layer Processing <ref> [PHOA93, MPBO96] </ref>. ILP encompasses optimizations on multiple protocol layers. The optimizations we describe here are a form of ILP, but much of the ILP tends to focus on integrating data manipulations across protocol layers, whereas our optimizations focus on optimizing control operations and message header compression.
Reference: [PHOA93] <author> Larry L. Peterson, Norm Hutchinson, Sean O'Malley, and Mark Abbott. </author> <title> RPC in the x-Kernel: Evaluating new design techniques. </title> <booktitle> In Proc. of the Fourteenth ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 91-101, </pages> <address> Asheville, NC, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: The optimizations are not a necessary part of the layering model: protocol layers execute 14 with or without the optimizations. This simplifies development because optimizations only need to be considered in the final stages of development. Other related work has been done on Integrated Layer Processing <ref> [PHOA93, MPBO96] </ref>. ILP encompasses optimizations on multiple protocol layers. The optimizations we describe here are a form of ILP, but much of the ILP tends to focus on integrating data manipulations across protocol layers, whereas our optimizations focus on optimizing control operations and message header compression.
Reference: [RBM96] <author> Robbert van Renesse, Kenneth P. Birman, and Silvano Maffeis. Horus, </author> <title> a flexible group communication system. </title> <journal> Communications of the ACM, </journal> <month> April </month> <year> 1996. </year>
Reference-contexts: There is not much room for improvement. This 8 byte header can be compared with those in similar communication protocols, such as TCP (40 bytes, 20 bytes for TCP with header compression) 1 , Isis [BvR94] (over 80 bytes), and Horus <ref> [RBM96] </ref> (over 50 bytes). Managing multiple formats. Two related problems arise when additional header formats are introduced to protocol stacks that expect only a single format. <p> However, protocols can be annotated to specify which operations can and which cannot be delayed. 5 Comments on Using the ML Programming Language The Ensemble system is implemented entirely in the ML programming language. Ensemble is derived from a previous system, Horus <ref> [RBM96] </ref>, written in C, and embodies a great deal of experience gained from Horus. ML has encouraged structural changes that have improved performance: with the optimizations in this paper, Ensemble is much faster than Horus, even though C programs generally execute faster than ML programs.
Reference: [vR96] <author> Robbert van Renesse. </author> <title> Masking the overhead of protocol layering. </title> <booktitle> In Proc. of the Proceedings of the 1996 ACM SIGCOMM Conference, </booktitle> <address> Stanford, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: These headers are compressed by our approach when they appear in the common path. Non-constant headers: These include any other headers, such as sequence numbers or headers used in negotiating reconfigurations. These are not compressed. 9 These optimizations are based on the use of connection identifiers <ref> [vR96, Jac90, Kay95] </ref>. Connection identifiers are tuples containing addressing headers which do not change very often. All the information in these tuples are hashed into 32-bit values which are then used along with hash tables to route messages to the protocol stacks. <p> The reformatting function needs to be stored with compressed messages, but this cost is offset by the decreased size of messages being buffered. 4.3 Delayed processing The third class of optimizations improves the latency of the trace handlers without decreasing the amount of computation. The approach in <ref> [vR96] </ref> relies heavily on this class of optimization, whereas in our work this optimizations is made in addition to others that are more significant in our case. <p> Process A completes its delayed updates by time 62s. The total round-trip time is 122s, of which Ensemble contributes 52s. 7 Previous Work Other approaches have been made to improve the performance of layered communication protocols. Work done in our research group on this problem has been described in <ref> [vR96] </ref>. In that work, protocols are optimized through the use of pre- and post-processing to move computation overhead out of the common path. Through this approach, the latency is greatly reduced, though the computation is not.
References-found: 10

