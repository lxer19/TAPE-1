URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/TM175.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts93.htm
Root-URL: http://www.mcs.anl.gov
Title: A Summary of Block Schemes for Reducing a General Matrix to Hessenberg Form  
Author: by Christian Bischof 
Note: This work was supported by the Office of Scientific Computing, U.S. Department of Energy, under Contract W-31-109-Eng-38.  
Date: February 1993  
Web: ANL/MCS-TM-175  
Address: 9700 South Cass Avenue Argonne, IL 60439  
Affiliation: ARGONNE NATIONAL LABORATORY  Mathematics and Computer Science Division  
Pubnum: Technical Memorandum No. 175  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. DuCroz, A. Greenbaum, S. Ham-marling, A. McKenney, and D. Sorensen. </author> <title> LAPACK User's Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, Penna., </address> <year> 1992. </year>
Reference-contexts: As a result, the block approach is preferable for machines employing a memory hierarchy, as do (in one form or another) most high-performance computers, from workstations to massively parallel machines. Thus, block algorithms play a prominent role in the LAPACK library of portable linear algebra codes for high-performance architectures <ref> [1] </ref>. <p> In particular, the one based on the compact WY representation seems to be appropriate, since it allows economical storage of the block transforms for subsequent back transformations of the eigenvectors of the Hessenberg matrix. Hence, the "Q compactWY" scheme was chosen for the final release of LAPACK <ref> [1] </ref>. fl We assume here that Au and A T u are computed separately using BLAS 2 calls.
Reference: [2] <author> E. Anderson and J. Dongarra. </author> <title> Evaluating block algorithm variants in LAPACK. </title> <type> Technical Report CS-90-103, </type> <institution> Computer Science Department, The University of Tennessee, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: In particular, the left-looking algorithm requires storage of the block transformations Q 1 ; : : : ; Q j . Hence the rightlooking algorithm is usually preferred (see <ref> [2] </ref> for a thorough discussion of the leftlooking vs. rightlooking issue).
Reference: [3] <author> C. H. Bischof. </author> <title> A block QR factorization algorithm using restricted pivoting. </title> <booktitle> In Proceedings SUPERCOMPUTING '89, </booktitle> <pages> pages 248-256, </pages> <address> Baltimore, Md., 1989. </address> <publisher> ACM Press. </publisher>
Reference: [4] <author> C. H. Bischof. </author> <title> Fundamental linear algebra computations on high-performance computers, </title> <booktitle> in volume 250 of Informatik Fachberichte, </booktitle> <pages> pages 167-182. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference: [5] <author> C. H. Bischof and J. J. Dongarra. </author> <title> A project for developing a linear algebra library for high-performance computers. </title> <editor> In Graham Carey, editor, </editor> <booktitle> Parallel and Vector Supercomputing: Methods and Algorithms, </booktitle> <pages> pages 45-56. </pages> <publisher> John Wiley & Sons, </publisher> <address> Somerset, N.J., </address> <year> 1989. </year>
Reference: [6] <author> C. H. Bischof and C. F. Van Loan. </author> <title> The WY representation for products of Householder matrices. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 8:s2-s13, </volume> <year> 1987. </year>
Reference-contexts: Dongarra, Hammarling, and Sorensen [8] suggested B = A U V T W U T . Dubrulle [9], on the other hand, uses a block formulation of Q p = P 1 P p based on the WY representation <ref> [6] </ref> to express B = (I U Y T ) T (A ZY T ). U; V; W; Y , and Z are all n fi p matrices. <p> The relative merits of the various approaches are discussed in x 4. 2 Block Representations for Representing Products of Householder Matrices There are several ways for representing a product Q i = P 1 P i of Householder transformations. 1 WY1: <ref> [6] </ref> i (1) Q i = I W i U T compactWY: [12] Q i = I U i S i U T In all those schemes, U i is the matrix of Householder vectors, and extra storage is required for the other matrices.
Reference: [7] <author> J. Dongarra and S. Hammarling. </author> <title> Evolution of Numerical Software for Dense Linear Algebra, </title> <address> pages 297-327. </address> <publisher> Oxford University Press, Oxford, </publisher> <address> U.K., </address> <year> 1989. </year>
Reference: [8] <author> J. J. Dongarra, S. J. Hammarling, and D. C. Sorensen. </author> <title> Block reduction of matrices to condensed form for eigenvalue computations. </title> <type> Technical Report MCS-TM-99, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: It mainly employs matrix-vector multiplications and symmetric rank-one updates, which require more memory references than matrix-matrix operations [5,4,7]. On the other hand, so-called block reduction methods allow the formulation of most of the computation in terms of matrix-matrix operations <ref> [8] </ref>, which, at a small increase in the number of floating-point operations, dramatically reduce the number of memory accesses. As a result, the block approach is preferable for machines employing a memory hierarchy, as do (in one form or another) most high-performance computers, from workstations to massively parallel machines. <p> Dongarra, Hammarling, and Sorensen <ref> [8] </ref> suggested B = A U V T W U T . Dubrulle [9], on the other hand, uses a block formulation of Q p = P 1 P p based on the WY representation [6] to express B = (I U Y T ) T (A ZY T ).
Reference: [9] <author> A. A. Dubrulle. </author> <title> On block Householder algorithms for the reduction of a marix to Hessenberg form. </title> <editor> In Joanne L. Martin and Stephen F. Lundstrom, editors, </editor> <booktitle> Supercomputing '88: Volume II, Science and Applications, </booktitle> <address> Washington, DC, 1989. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Dongarra, Hammarling, and Sorensen [8] suggested B = A U V T W U T . Dubrulle <ref> [9] </ref>, on the other hand, uses a block formulation of Q p = P 1 P p based on the WY representation [6] to express B = (I U Y T ) T (A ZY T ). U; V; W; Y , and Z are all n fi p matrices. <p> Dubrulle <ref> [9] </ref> compared a rightlooking algorithm using formulations "implicit Q2" and "Q WY" on the IBM 3090/VF using straight Fortran. In these experiments he found the "Q WY" formulation to be superior to the "implicit Q2" formulation.
Reference: [10] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1983. </year>
Reference-contexts: 1 Introduction Let A be an n fi n symmetric matrix. Our goal is to compute an orthogonal matrix Q, Q T Q = I such that Q T AQ = H where H is of upper Hessenberg form. The standard algorithm <ref> [10] </ref> reduces A one column at a time through Householder transformation at a cost of O (4=3n 3 ) flops. It mainly employs matrix-vector multiplications and symmetric rank-one updates, which require more memory references than matrix-matrix operations [5,4,7].
Reference: [11] <author> C. Puglisi. </author> <title> Modification of the Householder method based on the compact WY representation. </title> <type> CERFACS Report TR/PA/90/29, </type> <year> 1990. </year>
Reference-contexts: Examples of the use of block orthogonal transformations in the computation of the QR factorization A = QR, where Q is orthogonal and R upper triangular, can be found in [6,5,3]. We also mention that Walker [13] and Puglisi <ref> [11] </ref> suggested a variant of the compact WY representation which represents Q i = I U i (T i ) 1 U T Computationally, the formulation (8) behaves very much like (3) and can be easily substituted in formulae based on (3).
Reference: [12] <author> R. Schreiber and C. Van Loan. </author> <title> A storage efficient WY representation for products of Householder transformations. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 10(1) </volume> <pages> 53-57, </pages> <year> 1989. </year>
Reference-contexts: of the various approaches are discussed in x 4. 2 Block Representations for Representing Products of Householder Matrices There are several ways for representing a product Q i = P 1 P i of Householder transformations. 1 WY1: [6] i (1) Q i = I W i U T compactWY: <ref> [12] </ref> Q i = I U i S i U T In all those schemes, U i is the matrix of Householder vectors, and extra storage is required for the other matrices. In the above formulas, U i , Y i , and W i are m fi i matrices.
Reference: [13] <author> H. F. Walker. </author> <title> Implementation of the GMRES method using Householder transformations. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9(1) </volume> <pages> 152-163, </pages> <year> 1988. </year> <month> 6 </month>
Reference-contexts: Examples of the use of block orthogonal transformations in the computation of the QR factorization A = QR, where Q is orthogonal and R upper triangular, can be found in [6,5,3]. We also mention that Walker <ref> [13] </ref> and Puglisi [11] suggested a variant of the compact WY representation which represents Q i = I U i (T i ) 1 U T Computationally, the formulation (8) behaves very much like (3) and can be easily substituted in formulae based on (3).
References-found: 13

