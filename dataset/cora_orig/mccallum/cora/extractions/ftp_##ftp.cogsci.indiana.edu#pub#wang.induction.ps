URL: ftp://ftp.cogsci.indiana.edu/pub/wang.induction.ps
Refering-URL: http://www.cogsci.indiana.edu/farg/peiwang/papers.html
Root-URL: 
Email: pwang@cogsci.indiana.edu  
Title: A New Approach for Induction: From a Non-Axiomatic Logical Point of View  
Author: Pei Wang 
Date: September 21, 1995  
Address: 510 N. Fess, Bloomington, IN 47408  
Affiliation: Indiana University  
Note: Center for Research on Concepts and Cognition  
Abstract: Non-Axiomatic Reasoning System (NARS) is designed to be a general-purpose intelligent reasoning system, which is adaptive and works under insufficient knowledge and resources. This paper focuses on the components of NARS that contribute to the system's induction capacity, and shows how the traditional problems in induction are addressed by the system. The NARS approach of induction uses an term-oriented formal language with an experience-grounded semantics that consistently interprets various types of uncertainty. An induction rule generates conclusions from common instance of terms, and a revision rule combines evidence from different sources. In NARS, induction and other types of inference, such as deduction and abduction, are based on the same semantic foundation, and they cooperate in inference activities of the system. The system's control mechanism makes knowledge-driven, context-dependent inference possible.
Abstract-found: 1
Intro-found: 1
Reference: <editor> Aristotle (1989). Prior Analytics. </editor> <publisher> Hackett Publishing Company, </publisher> <address> Indianapolis, Indiana. </address>
Reference-contexts: This family is very influential in machine learning (Michalski, 1993). The third family uses term logic. This kind of logic, exemplified by Aristotle's system, is characterized by the use of subject-predicate sentence and syllogistic rules. Though Aristotle discussed induction briefly in his work <ref> (Aristotle, 1989) </ref>, it was Peirce who first defined different types of inference in term logic, roughly in the following manner (Peirce, 1931): deduction induction abduction M P M P P M |||| |||| |||| One interesting fact is that though Peirce's distinction of deduction, induction, and abduction is widely accepted, his
Reference: <author> Translated by R. </author> <title> Smith. </title>
Reference: <author> Bonissone, P. and Decker, K. </author> <year> (1986). </year> <title> Selecting uncertain calculi and granularity. </title> <editor> In Kanal, L. and Lemmer, J., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 217-247. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> Carnap, R. </author> <year> (1950). </year> <title> Logical Foundations of Probability. </title> <publisher> The University of Chicago Press, Chicago. </publisher>
Reference-contexts: After Hume, most philosophical and logical work on induction are about the justification of the process. The mainstream approach is to use probability theory, with the hope that though inductive conclusions cannot be absolutely true, they can have certain probabilities <ref> (Carnap, 1950) </ref>. In recent years, the study of induction has been enriched by AI researchers. With computer systems as tools and platform, different formalizations and algorithms are proposed and tested. <p> As mentioned before, in NARS truth value indicates the support the statement gets from evidence. Given the statement and the evidence, the value of f is uniquely determined. This is similar to the logical interpretation of probability suggested by Keynes (Keynes, 1921) and Carnap <ref> (Carnap, 1950) </ref>. Different from them, in NARS the evidence is not explicitly expressed in a judgment, so f cannot be determined by logical analysis within the language. Instead, f is defined as the frequency of favorite evidence, which makes it similar to the probability under an empirical interpretation (Reichenbach, 1949). <p> However, since NARS is designed to be an open system, future evidence is always possible, therefore there is no way for the system to get "complete evidence" for an inductive conclusion. A reasonable retreat is to use all evidence known to the system | the so-called "total evidence" <ref> (Carnap, 1950) </ref>. Unfortunately, this is also impossible, because NARS has insufficient resource. The system has to answer questions under a time pressure, which makes exhaustive search in knowledge space not affordable. <p> These steps are linked together in run-time in a context-dependent manner, so the process does not follow a predetermined algorithm. Therefore, NARS is not an "inductive machine" which uses an effective algorithm to generate inductive conclusions from given evidence. Carnap's argument against the possibility of this kind of machine <ref> (Carnap, 1950) </ref> is still valid. However, this argument does not prevent us from building a computer system that can do induction.
Reference: <author> Cheeseman, P. </author> <year> (1985). </year> <title> In defense of probability. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1002-1009. </pages>
Reference: <author> Cohen, L. </author> <year> (1989). </year> <title> The Philosophy of Induction and Probability. </title> <publisher> Clarendon Press, Oxford. </publisher>
Reference-contexts: It was Bacon who for the first time proposed a systematical inductive method, with the hope that it could provide a general methodology for empirical science <ref> (Cohen, 1989) </ref>. However, such an approach was seriously challenged by Hume, who argued that the inferences that extend past experience to future situations cannot have a logical justification (Hume, 1748). After Hume, most philosophical and logical work on induction are about the justification of the process. <p> We know the statement is false as soon as we find a non-black raven, but we need to exhaust all ravens in the universe to know it is true. Such a formalization of inductive conclusions is shared by the Baconian tradition of induction <ref> (Cohen, 1989) </ref>. According to an approach proposed by Cohen, induction is a sequence of tests with increasing complexity, and the (Baconian) probability of a hypothesis indicates how many tests the hypothesis passed in the process. <p> As put by Cohen, "what level of support for a proposition, in the light of available evidence, justifies belief in its truth or acceptance of it as being true?" <ref> (Cohen, 1989) </ref>. In NARS, there is no such a thing as "accepted as being true". <p> In this way, an inductive conclusion also benefits from the refutation of competing conclusions, which is stressed by the Baconian tradition of induction <ref> (Cohen, 14 1989) </ref> | though its truth value may not change in this process, its relative ranking becomes higher. According to the definition given be Peirce, the difference among deduction, abduction, and induction is the position of the shared term in the two premises.
Reference: <author> Dean, T. and Boddy, M. </author> <year> (1988). </year> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 49-54. </pages>
Reference-contexts: In this situation, even a predetermined "satisfying threshold" become inapplicable | such a threshold is sometimes too low and sometimes too high. The control mechanism used in NARS is similar to "anytime algorithm" <ref> (Dean and Boddy, 1988) </ref>.
Reference: <author> Dubois, D. and Prade, H. </author> <year> (1982). </year> <title> A class of fuzzy measures based on triangular norms. </title> <journal> International Journal of General Systems, </journal> <volume> 8 </volume> <pages> 43-61. </pages>
Reference: <author> Giraud-Carrier, C. and Martinez, T. </author> <year> (1995). </year> <title> An integrated framework for learning and reasoning. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3 </volume> <pages> 147-185. </pages>
Reference: <author> Good, I. </author> <year> (1983). </year> <title> Good Thinking: The Foundations of Probability and Its Applications. </title> <publisher> University of Minnesota Press, </publisher> <address> Minneapolis. </address>
Reference: <author> Haussler, D. </author> <year> (1988). </year> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 177-221. </pages>
Reference: <author> Hempel, C. </author> <year> (1943). </year> <title> A purely syntactical definition of confirmation. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 8 </volume> <pages> 122-143. </pages>
Reference-contexts: Though it is natural to say that a black raven is a piece of positive evidence for "Ravens are black", and a white raven is its negative evidence, Hempel points out that the concept of positive/negative evidence cannot be easily defined in the first-order (predicate-oriented) language in general <ref> (Hempel, 1943) </ref>. Let us suppose that "Ravens are black" is formulated as (8x)(Raven (x) ! Black-thing (x)), and that a piece of positive evidence is a constant that when substituted into the variable x makes both the condition and the conclusion true.
Reference: <author> Holland, J., Holyoak, K., Nisbett, R., and Thagard, P. </author> <year> (1986). </year> <title> Induction. </title> <publisher> The MIT Press. </publisher> <address> 16 Hume, D. </address> <month> (1748). </month> <title> An enquiry concerning human understanding. </title> <publisher> London. </publisher>
Reference-contexts: Most philosophical/logical study and some AI study on induction belong to this category (Cohen, 1989; Kyburg, 1970; Michalski, 1993). In the third kind of model, "induction" is defined as the process from specific instances to learn general cognitive skills. Such a treatment of induction can be found in <ref> (Holland et al., 1986) </ref>. In this paper, we will focus our attention to the second kind of model. We will first describe the related theories and introduce a new approach. Then, we will discuss how the new approach deals with the problems related to induction.
Reference: <author> Keynes, J. </author> <year> (1921). </year> <title> A Treatise on Probability. </title> <publisher> Macmillan, London. </publisher>
Reference-contexts: Just as our intuition tells us, in NARS the existence of a green shirt is irrelevant to whether ravens are black. Now let us see how the amount of evidence is measured. Such a measurement, weight of evidence, is suggested by <ref> (Keynes, 1921) </ref>. Intuitively, when we get new (relevant) evidence for a statement, the weight of evidence about that statement increases, because now our judgment are based on more evidence. From the definition of evidence given previously, we know when a term M becomes positive/negative evidence for statement "S P ". <p> As mentioned before, in NARS truth value indicates the support the statement gets from evidence. Given the statement and the evidence, the value of f is uniquely determined. This is similar to the logical interpretation of probability suggested by Keynes <ref> (Keynes, 1921) </ref> and Carnap (Carnap, 1950). Different from them, in NARS the evidence is not explicitly expressed in a judgment, so f cannot be determined by logical analysis within the language. <p> It is important to notice that f and c are two independent measurements, in the sense that given the value of either of them, the value of the other cannot be determined, or even bounded. Keynes argued for a similar relation between probability and weight of evidence <ref> (Keynes, 1921) </ref>. Roughly speaking, frequency and probability indicate the relative balance between positive and negative evidence, which influences the system's preference among alternative conclusions; confidence and weight of evidence indicate the absolute amount of available evidence, which influence the system's sensitivity to new evidence.
Reference: <author> Korb, K. </author> <year> (1995). </year> <title> Inductive learning and defeasible infernce. </title> <journal> Journal of Experimental & Theoretical Artificial Intelligence, </journal> <volume> 7 </volume> <pages> 291-324. </pages>
Reference-contexts: Only in mathematics, where truth values are determined according to fixed axioms, universal statements become available. The above argument also serves as a criticism to the AI induction projects within the framework of binary logic <ref> (Korb, 1995) </ref>. To define induction as "finding a pattern to fit all data" makes it a luxury that can only be enjoyed in a laboratory. Though such a paradigm can produce research results, these results are hardly extendable to practical situations.
Reference: <author> Kuhn, T. </author> <year> (1970). </year> <title> The Structure of Scientific Revolutions. </title> <publisher> Chicago University Press. </publisher>
Reference-contexts: If we accept the above definition of scientific theory, all conclusions of Popper and Cohen follow logically. However, why should we accept the definition? As a matter of fact, many empirical scientific theories have counterexamples, and we do not throw them away <ref> (Kuhn, 1970) </ref>. It is even more obvious when we consider our common-sense knowledge. A general statement like "Ravens are black" works well as our guide of life, even when we know that it has counterexamples.
Reference: <author> Kyburg, H. </author> <year> (1970). </year> <title> Probability and Inductive Logic. </title> <publisher> Macmillan, London. </publisher>
Reference-contexts: Obviously, this measurement is often used in everyday life. It is also closely related to probability, though it is still different from probability under the traditional interpretations <ref> (Kyburg, 1970) </ref> | logical (degree of confirmation), empirical (relative frequency), and subjective (degree of belief). As mentioned before, in NARS truth value indicates the support the statement gets from evidence. Given the statement and the evidence, the value of f is uniquely determined.
Reference: <author> Kyburg, H. </author> <year> (1994). </year> <title> Believing on the basis of the evidence. </title> <journal> Computational Intelligence, </journal> <volume> 10 </volume> <pages> 3-20. </pages>
Reference-contexts: The system will never say that "This is the final conclusion and I will stop working on the problem." The above discussion is directly related to the "acceptance" problem in inductive logic <ref> (Kyburg, 1994) </ref>. As put by Cohen, "what level of support for a proposition, in the light of available evidence, justifies belief in its truth or acceptance of it as being true?" (Cohen, 1989). In NARS, there is no such a thing as "accepted as being true".
Reference: <author> Michalski, R. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 111-116. </pages>
Reference: <author> Michalski, R. </author> <year> (1993). </year> <title> Inference theory of learning as a conceptual basis for multistrategy learning. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 111-151. </pages>
Reference-contexts: Because the inference from H and B to E is deduction, induction thus defined, as the inference from E and B to H, is often referred to as "reverse deduction". This family is very influential in machine learning <ref> (Michalski, 1993) </ref>. The third family uses term logic. This kind of logic, exemplified by Aristotle's system, is characterized by the use of subject-predicate sentence and syllogistic rules. <p> Instead, the above definition is rephrased within the frame of first-order predicate logic <ref> (Michalski, 1993) </ref>. We will see the subtle difference between these two formalizations later. NARS, the new approach of induction that will be discussed in this paper, belongs to the term-logic family. NARS stands for Non-Axiomatic Reasoning System. <p> If all premises are absolutely certain, so are their deductive conclusions, but no are their inductive conclusions. Compared with other multi-strategy inference models using first-order predicate language <ref> (Michalski, 1993) </ref>, attribute-value language (Giraud-Carrier and Martinez, 1995), or integrated symbolic/connectionist representation (Sun, 1995), the term logic model, proposed by Peirce and extended in NARS, puts different types of inference in the same framework in a more natural, elegant, and consistent manner.
Reference: <author> Mitchell, T. </author> <year> (1980). </year> <title> The need for biases in learning generalizations. </title> <editor> In Shavlik, J. and Dietterich, T., editors, </editor> <booktitle> Readings in Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address> <year> 1990. </year> <note> Originally published as a Rutgers Technical report. </note>
Reference: <author> Paa, G. </author> <year> (1991). </year> <title> Second order probabilities for uncertain and conflicting evidence. </title> <editor> In Bonissone, P., Henrion, M., Kanal, L., and Lemmer, J., editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 447-456. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: One attractive idea would be to define a "second-order probability". The frequency defined above can be considered to be an estimate of the "first-order probability" (of the given inheritance relation), and the second-order probability is used to describe how good the first-order estimate is <ref> (Paa, 1991) </ref>. However, under the assumption of insufficient knowledge, it makes little sense to talk about the "probability" that "the frequency is an accurate estimate of an objective first-order probability of the inheritance relation".
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California. </address>
Reference-contexts: Therefore, the susceptibility represented in the Bayesian approach, such as the confidence defined in <ref> (Pearl, 1988) </ref>, only reflects the stability of a probability assignment to certain relevant evidence, and the restrictions upon new knowledge severely limits the learning ability of the system.
Reference: <author> Peirce, C. </author> <year> (1931). </year> <title> Collected papers of Charles Sanders Peirce, volume 2. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: This kind of logic, exemplified by Aristotle's system, is characterized by the use of subject-predicate sentence and syllogistic rules. Though Aristotle discussed induction briefly in his work (Aristotle, 1989), it was Peirce who first defined different types of inference in term logic, roughly in the following manner <ref> (Peirce, 1931) </ref>: deduction induction abduction M P M P P M |||| |||| |||| One interesting fact is that though Peirce's distinction of deduction, induction, and abduction is widely accepted, his formalization in term logic is seldom followed.
Reference: <author> Popper, K. </author> <year> (1959). </year> <title> The logic of Scientific Discovery. </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: This opinion is against a well-known conclusion proposed by Popper. He argues that there is an asymmetry between verifiability and falsifiability | "a positive decision can only temporarily support the theory, for subsequent negative decisions may always overthrow it" <ref> (Popper, 1959) </ref>. <p> Positive (negative) evidence is that which increase (decrease) the probability of the hypothesis in this process, and irrelevant evidence leave the probability unchanged. As discussed previously, this approach limits the evidence that is acceptable by the system. Besides, it also cause a paradox revealed by Popper <ref> (Popper, 1959) </ref>. Let H be a hypothesis whose prior probability (according to the background knowledge of the system) is P (H).
Reference: <author> Quinlan, J. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106. </pages>
Reference: <author> Reichenbach, H. </author> <year> (1949). </year> <title> The Theory of Probability. </title> <institution> University of California Press, Berkeley, California. </institution> <note> Translated by E. Hutten and M. Reichenbach. </note>
Reference-contexts: Different from them, in NARS the evidence is not explicitly expressed in a judgment, so f cannot be determined by logical analysis within the language. Instead, f is defined as the frequency of favorite evidence, which makes it similar to the probability under an empirical interpretation <ref> (Reichenbach, 1949) </ref>. However, f is not the limit of the frequency, but its value at a certain moment in a certain system, thus it is subjective and context-dependent.
Reference: <author> Savage, L. </author> <year> (1954). </year> <title> The Foundations of Statistics. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: However, f is not the limit of the frequency, but its value at a certain moment in a certain system, thus it is subjective and context-dependent. These features are stressed by the subjectivists, though they refuse to explicitly ground probability on the frequency of 7 favorable evidence <ref> (Savage, 1954) </ref>. To represent a truth value by a frequency value alone is not enough for NARS: in addition, the system needs to know the the value of w in order to figure out how to revise frequency with new evidence (Wang, 1993).
Reference: <author> Schweizer, B. and Sklar, A. </author> <year> (1983). </year> <title> Probabilistic Metric Spaces. </title> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: For the current purpose, we also want it to be continuous and strictly increasing, so that changes in any one argument will cause a change in the function value. The most simple function that satisfy the above requirements are multiplication <ref> (Schweizer and Sklar, 1983) </ref>. Consequently, for the inductive conclusion, we have f = f 1 where k is the constant introduced previously. To apply this formula to the "tomato" example, we can see that the truth values of the two premises play different roles in induction.
Reference: <author> Spiegelhalter, D. </author> <year> (1986). </year> <title> A statistical view of uncertainty in expert systems. </title> <editor> In Gale, W., editor, </editor> <booktitle> Artificial Intelligence and Statistics, </booktitle> <pages> pages 17-56. </pages> <publisher> Addison Wesley, </publisher> <address> Reading. </address>
Reference: <author> Sun, R. </author> <year> (1995). </year> <title> Robust reasoning: integrating rule-based and similarity-based reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 75 </volume> <pages> 241-295. </pages> <note> 17 Wang, </note> <author> P. </author> <year> (1993). </year> <title> Belief revision in probability theory. </title> <booktitle> In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 519-526. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California. </address>
Reference-contexts: If all premises are absolutely certain, so are their deductive conclusions, but no are their inductive conclusions. Compared with other multi-strategy inference models using first-order predicate language (Michalski, 1993), attribute-value language (Giraud-Carrier and Martinez, 1995), or integrated symbolic/connectionist representation <ref> (Sun, 1995) </ref>, the term logic model, proposed by Peirce and extended in NARS, puts different types of inference in the same framework in a more natural, elegant, and consistent manner.
Reference: <author> Wang, P. </author> <year> (1994a). </year> <title> From inheritance relation to nonaxiomatic logic. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 11(4) </volume> <pages> 281-319. </pages>
Reference-contexts: The other way around, if all X that satisfy "X S" also satisfy "X P ", and all X that satisfy "P X" also satisfy "S X", then we have "S P " <ref> (Wang, 1994a) </ref>. In English, "S P " roughly corresponds to "S is P", if we ignore the singular/plural distinction. As mentioned previously, NARS is an adaptive system, and always open to new knowledge, meaning that all judgments the system makes are based on its experience. <p> It is easy to calculate w and w + from f and c, and therefore the truth value of a judgment can also be represented as a pair of ratios &lt; f; c &gt; <ref> (Wang, 1994a) </ref>. In particular, "S P &lt; 1; 1 &gt;" means that "S P " is absolutely true. Though such a truth value cannot be achieved by finite amount of evidence, it serves as a limit and an idealized situation.
Reference: <author> Wang, P. </author> <year> (1994b). </year> <title> On the working definition of intelligence. </title> <type> Technical Report 94, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, </institution> <note> Indiana. Available via WWW at http://www.cogsci.indiana.edu/farg/peiwang/papers.html. </note>
Reference: <author> Wang, P. </author> <year> (1995a). </year> <title> Grounded on experience: Semantics for intelligence. </title> <type> Technical Report 96, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indi-ana. </institution> <note> Available via WWW at http://www.cogsci.indiana.edu/farg/peiwang/papers.html. </note>
Reference: <author> Wang, P. </author> <year> (1995b). </year> <title> Non-Axiomatic Reasoning System: Exploring the Essence of Intelligence. </title> <type> PhD thesis, </type> <institution> Indiana University. </institution>
Reference-contexts: In NARS, a serial number system is used to approximately record the evidence that supports each judgment. See <ref> (Wang, 1995b) </ref> for details. 12 In the Bayesian approach, the evidence is accumulated by repeatedly applying Bayes's theorem to new evidence. Positive (negative) evidence is that which increase (decrease) the probability of the hypothesis in this process, and irrelevant evidence leave the probability unchanged. <p> In NARS, all 13 these rules are established according to the same semantics introduced previously, where the truth value of a judgment indicates the evidential support the judgment obtained. Different rules correspond to different ways to collect evidence for various inheritance relations <ref> (Wang, 1995b) </ref>. Though, as discussed previously, in NARS induction is not ampliative in a certain sense, the traditional distinction between "truth-preserving" and "ampliative" inferences is still there. <p> The system has to answer questions under a time pressure, which makes exhaustive search in knowledge space not affordable. Moreover, in NARS the time pressure is variable, depending to the request of the user and the existence of other information-processing tasks <ref> (Wang, 1995b) </ref>. In this situation, even a predetermined "satisfying threshold" become inapplicable | such a threshold is sometimes too low and sometimes too high. The control mechanism used in NARS is similar to "anytime algorithm" (Dean and Boddy, 1988). <p> If the system is asked to evaluate the truth value of a statement, it reports the best conclusion (i.e., with the highest confidence) as soon as such a conclusion is found, then continue to look for a better one, until no resource is available for this task (see <ref> (Wang, 1995b) </ref> for how the system's resources are allocated among tasks). In this way, from the user's point of view, the system may change its mind from time to time, when new evidence is taken into consideration. <p> In each inference step, the system does not decide what rule to use, then look for corresponding knowledge. Instead, it picks up two pieces of most accessible knowledge (provided by its memory-management mechanism, see <ref> (Wang, 1995b) </ref>) which share a term, and decide what rule to apply according to the position of the shared term. In general, an inference process in NARS consists many steps. Each step carries out a certain type of inference, such as deduction abduction, induction, and so on.
Reference: <author> Wang, P. </author> <year> (1995c). </year> <title> Reference classes and multiple inheritances. </title> <journal> International Journal of Uncertainty, Fuzziness and and Knowledge-based Systems, </journal> <volume> 3(1) </volume> <pages> 79-91. 18 </pages>
Reference-contexts: Given the same evidence, a system with a larger k will assign lower confidence to inductive conclusions, because it considers what may happen in a further horizon. Consequently, such a system is more prudent, compared with a system with a smaller k <ref> (Wang, 1995c) </ref>. For our current purposes, there is no best k for a implementation of NARS | it is a "personal parameter", and different values generate different behaviors. In the following discussions, let us take k = 1 for simplicity.
References-found: 36

