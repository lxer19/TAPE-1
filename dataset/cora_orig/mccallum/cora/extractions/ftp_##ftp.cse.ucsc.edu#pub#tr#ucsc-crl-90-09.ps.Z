URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-90-09.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Voting with Regenerable Volatile Witnesses  
Author: Darrell D.E. Long 
Keyword: distributed file systems, replicated data, voting, witnesses.  
Note: July 1990  
Address: Santa Cruz, CA 95064 Jehan-Franc, ois Paris  Houston, TX 77204-3475  
Affiliation: Computer and Information Sciences University of California  Department of Computer Science University of Houston  
Abstract: Voting protocols ensure the consistency of replicated objects by requiring all read and write requests to collect an appropriate quorum of replicas. We propose to replace some of these replicas by volatile witnesses that have no data and require no stable storage, and to regenerate them instead of waiting for recovery. The small size of volatile witnesses allows them to be regenerated much easier than full replicas. Regeneration attempts are much more likely to succeed since volatile witnesses can be stored on diskless nodes. We show that under standard Markovian assumptions two full replicas and one regenerable volatile witness managed by a two-tier dynamic voting protocol provide a higher data availability than three full replicas managed by majority consensus voting or optimistic dynamic voting provided site failures can be detected significantly faster than they can be repaired. 
Abstract-found: 1
Intro-found: 1
Reference: [AhAm89] <author> M. Ahamad and M. H. Ammar, </author> <title> ``Performance Characterization of Quorum-Consensus Algorithms for Replicated Data,'' </title> <journal> IEEE Transactions on Software Engineering, SE-15, </journal> <volume> 4 (1989), </volume> <pages> pp. 492-496. </pages>
Reference-contexts: No attempt is made to model failures of LAN segments, repeaters or gateways. The assumptions that we have made are required for a steady-state analysis to be tractable [GBS69]. They have been made in most recent probabilistic analyses of the availability of replicated data <ref> [Pari86, JaMu87, AhAm89, BeCi89] </ref>.
Reference: [AgEl88] <author> D. Agrawal and A. El Abbadi, </author> <title> ``Reducing Storage for Quorum Consensus Algorithms," </title> <booktitle> Proc. 14th VLDB Conference (1988), </booktitle> <pages> pp. 419-430. </pages>
Reference-contexts: Voting with witnesses [Pari86, BeCi89] reduces the number of full replicas necessary to achieve a given level of fault-tolerance by replacing some replicas by witnesses that hold no data but can attest to the status of the replicated object. Agrawal and El Abbadi <ref> [AgEl88] </ref> have recently proposed storing overlapping fragments of the object instead of whole replicas. Both of these techniques significantly reduce storage costs but still require at least three voting entities to be kept in stable storage. One of the authors has recently proposed [Pari90] storing witnesses in volatile memory. <p> Finally, regenerable volatile witnesses can be combined with two-tier voting to provide a high level of fault-tolerance with as few as two replicas in stable storage. Unlike other replication control protocols that require only two replicas <ref> [BeGo84, AgEl88, Pari86, ReTa88, Pari89] </ref>, our novel technique requires only two sites - 3 - providing stable storage, operates correctly in the presence of communication failures, and does not require any knowledge of the network topology.
Reference: [BeGo84] <author> P. A. Bernstein and N. Goodman, </author> <title> ``An Algorithm for Concurrency Control and Recovery in Replicated Distributed Databases,'' </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9, 4 (1984), </volume> <pages> pp. 596-615. </pages>
Reference-contexts: Finally, regenerable volatile witnesses can be combined with two-tier voting to provide a high level of fault-tolerance with as few as two replicas in stable storage. Unlike other replication control protocols that require only two replicas <ref> [BeGo84, AgEl88, Pari86, ReTa88, Pari89] </ref>, our novel technique requires only two sites - 3 - providing stable storage, operates correctly in the presence of communication failures, and does not require any knowledge of the network topology.
Reference: [BeCi89] <author> J. Bechta Dugan and G. Ciardo, </author> <title> ``Stochastic Petri Net Analysis of a Replicated File System,'' </title> <journal> IEEE Transactions on Software Engineering, SE-15, </journal> <volume> 4 (1989), </volume> <pages> pp. 394-401. </pages>
Reference-contexts: Both greatly improve availability when applied to replicated objects composed of more than three replicas, but do not perform significantly better - 2 - than majority consensus voting when fewer than four replicas are present. Voting with witnesses <ref> [Pari86, BeCi89] </ref> reduces the number of full replicas necessary to achieve a given level of fault-tolerance by replacing some replicas by witnesses that hold no data but can attest to the status of the replicated object. <p> No attempt is made to model failures of LAN segments, repeaters or gateways. The assumptions that we have made are required for a steady-state analysis to be tractable [GBS69]. They have been made in most recent probabilistic analyses of the availability of replicated data <ref> [Pari86, JaMu87, AhAm89, BeCi89] </ref>.
Reference: [BGS89] <author> D. Barbara, H. Garcia-Molina, and A. Spauster, </author> <title> ``Increasing Availability Under Mutual Exclusion Constraints with Dynamic Vote Reassignment,'' </title> <journal> ACM Transaction on Computer Systems, </journal> <volume> 7, 4 (1989), </volume> <pages> pp. 394-426. </pages>
Reference: [DaBu85] <author> D. Davcev and W. A. Burkhard, </author> <title> ``Consistency and Recovery Control for Replicated Files,'' </title> <booktitle> Proc. 10th ACM Symposium on Operating System Principles (1985) pp. </booktitle> <pages> 87-96. </pages>
Reference-contexts: The simplest replication control protocol, majority consensus voting (MCV), requires a minimum of three replicas to be of any practical use. Even then, quorum requirements disallow a large fraction of read and write operations. Several solutions have been proposed to surmount these limitations. Dynamic voting <ref> [DaBu85] </ref> and dynamic-linear voting [JaMu87] adjust quorums to reflect changes in replica availability and network topology.
Reference: [Elli77] <author> C. A. Ellis, </author> <title> ``Consistency and Correctness of Duplicate Database Systems,'' </title> <journal> Operating Systems Review, </journal> <volume> 11 (1977). </volume> - <pages> 20 </pages> - 
Reference: [Giff79] <author> D. K. Gifford, </author> <title> ``Weighted Voting for Replicated Data,'' </title> <booktitle> Proc. 7th ACM Symposium on Operating System Principles (1979), </booktitle> <pages> pp. 150-161. </pages>
Reference: [GBS69] <author> B. V. Gnedenko, Yu. K. Belyayev and A. D. Solovyev, </author> <title> Mathematical Methods of Reliability Theory, (English translation of ``Matematicheskiye Metody v Teorii Nadezhnosti''), </title> <publisher> Academic Press, </publisher> <address> New York (1969). </address>
Reference-contexts: No attempt is made to model failures of LAN segments, repeaters or gateways. The assumptions that we have made are required for a steady-state analysis to be tractable <ref> [GBS69] </ref>. They have been made in most recent probabilistic analyses of the availability of replicated data [Pari86, JaMu87, AhAm89, BeCi89].
Reference: [JaMu87] <author> S. Jajodia and D. Mutchler, </author> <title> ``Enhancements to the Voting Algorithm,'' </title> <booktitle> Proc. 13th VLDB Conference (1987), </booktitle> <pages> pp. 399-405. </pages>
Reference-contexts: The simplest replication control protocol, majority consensus voting (MCV), requires a minimum of three replicas to be of any practical use. Even then, quorum requirements disallow a large fraction of read and write operations. Several solutions have been proposed to surmount these limitations. Dynamic voting [DaBu85] and dynamic-linear voting <ref> [JaMu87] </ref> adjust quorums to reflect changes in replica availability and network topology. Both greatly improve availability when applied to replicated objects composed of more than three replicas, but do not perform significantly better - 2 - than majority consensus voting when fewer than four replicas are present. <p> No attempt is made to model failures of LAN segments, repeaters or gateways. The assumptions that we have made are required for a steady-state analysis to be tractable [GBS69]. They have been made in most recent probabilistic analyses of the availability of replicated data <ref> [Pari86, JaMu87, AhAm89, BeCi89] </ref>.
Reference: [LCS89] <author> D. D. E. Long, J. L. Carroll and K. Stewart, </author> <title> ``Estimating the Reliability of Regeneration-Based Replica Control Protocols,'' </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38, 12 (1989), </volume> <pages> pp. 1691-1702. </pages>
Reference-contexts: VOLATILE REGENERABLE WITNESSES The notion of regenerating replicas to replace those lost due to site failures was first introduced by the regeneration algorithm (RA) [PNP88], which provided mutual and serial consistency of replicated objects in a partition-free distributed system. Since then, it has been shown <ref> [LoPa89, LCS89] </ref> that regeneration is a generally applicable technique that can be profitably combined with many replication control protocols. In a partitionable distributed system, consensus protocols are required to maintain consistency. <p> In a partitionable distributed system, consensus protocols are required to maintain consistency. Regeneration has been combined with majority consensus voting to obtain a simple protocol for maintaining mutual consistency, and has also been combined with dynamic voting protocols to provide an increased level of fault tolerance <ref> [LoPa89, LCS89] </ref>. The penalty for using regeneration with these protocols is an increase in both network traffic and peak storage requirements. A witness [Pari86] requires very little storage: only enough so that it can attest to the state of the replicated object.
Reference: [LoPa88] <author> D. D. E. Long and J.-F. </author> <title> Pa ris, ``A Realistic Evaluation of Optimistic Dynamic Voting,'' </title> <booktitle> Proc. 7th Symposium on Reliable Distributed Systems, </booktitle> <year> (1988), </year> <pages> pp. 129-137. </pages>
Reference-contexts: This is similar to the information required by optimistic dynamic voting (ODV) <ref> [LoPa88] </ref>. Partition sets are used by ODV to determine which replicas can form a quorum. For ODV, a quorum is formed either by a majority of the replicas in a current partition set, or by one half of the current replicas with the tie broken according to lexicographic order.
Reference: [LoPa89] <author> D. D. E. Long and J.-F. </author> <title> Pa ris, ``Regeneration Protocols for Replicated Objects,'' </title> <booktitle> Proc. 5th International Conference on Data Engineering, </booktitle> <year> (1989), </year> <pages> pp. 538-545. </pages>
Reference-contexts: VOLATILE REGENERABLE WITNESSES The notion of regenerating replicas to replace those lost due to site failures was first introduced by the regeneration algorithm (RA) [PNP88], which provided mutual and serial consistency of replicated objects in a partition-free distributed system. Since then, it has been shown <ref> [LoPa89, LCS89] </ref> that regeneration is a generally applicable technique that can be profitably combined with many replication control protocols. In a partitionable distributed system, consensus protocols are required to maintain consistency. <p> In a partitionable distributed system, consensus protocols are required to maintain consistency. Regeneration has been combined with majority consensus voting to obtain a simple protocol for maintaining mutual consistency, and has also been combined with dynamic voting protocols to provide an increased level of fault tolerance <ref> [LoPa89, LCS89] </ref>. The penalty for using regeneration with these protocols is an increase in both network traffic and peak storage requirements. A witness [Pari86] requires very little storage: only enough so that it can attest to the state of the replicated object.
Reference: [PaLo90] <author> J.-F. Paris and D.D.E. </author> <title> Long ``On the Performance of Available Copy Protocols,'' Performance Evaluation, </title> <booktitle> 11 (1990), </booktitle> <pages> pp 9-30. </pages>
Reference-contexts: First, the available copy protocol provides the highest availability of all replication protocols that do not regenerate replicas. Its performance is indeed so close to optimum that it is unlikely that a protocol providing higher availabilities without regenerating failed replicas will be found <ref> [PaLo90] </ref>. Second, the available copy protocol is an idealized protocol that assumes that failures can be instantaneously detected; variants that do not make this assumption, such as naive available copy and optimistic available copy [PaLo90], provide somewhat lower data - 16 - Availability Failure rate to repair rate ratio 0 .05 <p> it is unlikely that a protocol providing higher availabilities without regenerating failed replicas will be found <ref> [PaLo90] </ref>. Second, the available copy protocol is an idealized protocol that assumes that failures can be instantaneously detected; variants that do not make this assumption, such as naive available copy and optimistic available copy [PaLo90], provide somewhat lower data - 16 - Availability Failure rate to repair rate ratio 0 .05 .10 .15 .20 .90 .94 .98 ODV (3) f = 5 . . . .. . . .. . . .. . . .. . . . .. . . . .. . .
Reference: [Pari86] <author> J.-F. </author> <title> Pa ris, ``Voting with Witnesses: A Consistency Scheme for Replicated Files,'' </title> <booktitle> Proc. 6th International Conference on Distributed Computing Systems, </booktitle> <year> (1986), </year> <pages> pp. 606-612. </pages>
Reference-contexts: Both greatly improve availability when applied to replicated objects composed of more than three replicas, but do not perform significantly better - 2 - than majority consensus voting when fewer than four replicas are present. Voting with witnesses <ref> [Pari86, BeCi89] </ref> reduces the number of full replicas necessary to achieve a given level of fault-tolerance by replacing some replicas by witnesses that hold no data but can attest to the status of the replicated object. <p> Finally, regenerable volatile witnesses can be combined with two-tier voting to provide a high level of fault-tolerance with as few as two replicas in stable storage. Unlike other replication control protocols that require only two replicas <ref> [BeGo84, AgEl88, Pari86, ReTa88, Pari89] </ref>, our novel technique requires only two sites - 3 - providing stable storage, operates correctly in the presence of communication failures, and does not require any knowledge of the network topology. <p> The penalty for using regeneration with these protocols is an increase in both network traffic and peak storage requirements. A witness <ref> [Pari86] </ref> requires very little storage: only enough so that it can attest to the state of the replicated object. We describe a method that combines regeneration, a two-tier dynamic voting protocol, and volatile witnesses to create a superior protocol for replicated data management. <p> No attempt is made to model failures of LAN segments, repeaters or gateways. The assumptions that we have made are required for a steady-state analysis to be tractable [GBS69]. They have been made in most recent probabilistic analyses of the availability of replicated data <ref> [Pari86, JaMu87, AhAm89, BeCi89] </ref>.
Reference: [Pari89] <author> J.-F. </author> <title> Paris ``Voting with Bystanders,'' </title> <booktitle> Proc. 9th International Conference on Distributed Computing Systems, </booktitle> <year> (1989), </year> <pages> pp. 394-401. </pages>
Reference-contexts: Finally, regenerable volatile witnesses can be combined with two-tier voting to provide a high level of fault-tolerance with as few as two replicas in stable storage. Unlike other replication control protocols that require only two replicas <ref> [BeGo84, AgEl88, Pari86, ReTa88, Pari89] </ref>, our novel technique requires only two sites - 3 - providing stable storage, operates correctly in the presence of communication failures, and does not require any knowledge of the network topology.
Reference: [Pari90] <author> J.-F. </author> <title> Pa ris, ``Efficient Voting Protocols with Witnesses,'' </title> <booktitle> Proc. 3rd International Conference on Database Theory, Lecture Notes in Computer Science, </booktitle> <address> Springer Verlag (1990), </address> <note> to appear. </note>
Reference-contexts: Agrawal and El Abbadi [AgEl88] have recently proposed storing overlapping fragments of the object instead of whole replicas. Both of these techniques significantly reduce storage costs but still require at least three voting entities to be kept in stable storage. One of the authors has recently proposed <ref> [Pari90] </ref> storing witnesses in volatile memory. Since these light-weight or volatile witnesses are likely to be left in an incorrect state after a site failure, recovering volatile witnesses must be prevented from participating in elections until they can determine the current status of the replicated object.
Reference: [PNP88] <author> C. Pu, J. D. Noe and A. Proudfoot, </author> <title> ``Regeneration of Replicated Objects: A Technique and its Eden Implementation,'' </title> <journal> IEEE Transactions on Software Engineering, SE-14, </journal> <volume> 7 (1988), </volume> <pages> pp. 936-945. </pages>
Reference-contexts: Section three contains a stochastic analysis of the availability of the data provided by our protocol. Our conclusions follow in section four. 2. VOLATILE REGENERABLE WITNESSES The notion of regenerating replicas to replace those lost due to site failures was first introduced by the regeneration algorithm (RA) <ref> [PNP88] </ref>, which provided mutual and serial consistency of replicated objects in a partition-free distributed system. Since then, it has been shown [LoPa89, LCS89] that regeneration is a generally applicable technique that can be profitably combined with many replication control protocols. <p> They have been made in most recent probabilistic analyses of the availability of replicated data [Pari86, JaMu87, AhAm89, BeCi89]. Purely combinational models that do not require assumptions about failure and repair distributions have been proposed <ref> [PNP88, ReTa88] </ref> but these models cannot distinguish among live replicas that belong to the current majority partition and live replicas that do not. - 12 - The availability analysis of a replicated object with witnesses is complicated by the problem of distinguishing between witnesses and full replicas and by taking into
Reference: [ReTa88] <author> R. van Renesse and A. Tanenbaum, </author> <title> ``Voting with Ghosts,'' </title> <booktitle> Proc. 8th International Conference on Distributed Computing Systems, </booktitle> <year> (1988), </year> <pages> pp. 456-462. </pages>
Reference-contexts: Finally, regenerable volatile witnesses can be combined with two-tier voting to provide a high level of fault-tolerance with as few as two replicas in stable storage. Unlike other replication control protocols that require only two replicas <ref> [BeGo84, AgEl88, Pari86, ReTa88, Pari89] </ref>, our novel technique requires only two sites - 3 - providing stable storage, operates correctly in the presence of communication failures, and does not require any knowledge of the network topology. <p> They have been made in most recent probabilistic analyses of the availability of replicated data [Pari86, JaMu87, AhAm89, BeCi89]. Purely combinational models that do not require assumptions about failure and repair distributions have been proposed <ref> [PNP88, ReTa88] </ref> but these models cannot distinguish among live replicas that belong to the current majority partition and live replicas that do not. - 12 - The availability analysis of a replicated object with witnesses is complicated by the problem of distinguishing between witnesses and full replicas and by taking into
References-found: 19

