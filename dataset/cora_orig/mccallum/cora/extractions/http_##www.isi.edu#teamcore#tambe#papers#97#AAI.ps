URL: http://www.isi.edu/teamcore/tambe/papers/97/AAI.ps
Refering-URL: http://www.isi.edu/teamcore/tambe/agent.html
Root-URL: http://www.isi.edu
Email: tambe@isi.edu  
Title: Implementing Agent Teams in Dynamic Multi-agent Environments two implementations of agent teams based on the
Author: Milind Tambe 
Note: This article describes  1  
Date: March 28, 1997  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: Teamwork is becoming increasingly critical in multi-agent environments ranging from virtual environments for training and education, to information integration on the internet, to potential multi-robotic space missions. Teamwork in such complex, dynamic environments is more than a simple union of simultaneous individual activity, even if supplemented with preplanned coordination. Indeed in these dynamic environments, unanticipated events can easily cause a breakdown in such preplanned coordination. The central hypothesis in this article is that for effective teamwork, agents should be provided explicit representation of team goals and plans, as well as an explicit representation of a model of teamwork to support the execution of team plans. In our work, this model of teamwork takes the form of a set of domain independent rules that clearly outline an agent's commitments and responsibilities as a participant in team activities, and thus guide the agent's social activities while executing team plans. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bates, A. B. Loyall, and W. S. Reilly. </author> <title> Integrating reactivity, goals and emotions in a broad agent. </title> <type> Technical Report CMU-CS-92-142, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Many AI researchers are today striving to build agents for complex, dynamic multi-agent domains, such as, virtual theatre [7], realistic virtual training environments (e.g., for emergency drill [18] or combat [28, 20]), virtual interactive fiction <ref> [1] </ref>, and robotic collaboration by observation [14]. Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains. One promising approach that has emerged is the use of hierarchical reactive plans. <p> machine learning programs: (i) learning the team operator hierarchy illustrated in Figure 5; and (ii) learning the general or common-sense rules for teamwork that have been handcoded in this work. 8 Summary and Discussion In a variety of dynamic multi-agent environments currently under development, achieving flexibility in teamwork is critical <ref> [7, 28, 1, 13] </ref>. Yet, given the uncertainty in such domains, preplanned coordination cannot sustain such flexible teamwork.
Reference: [2] <author> R. B. Calder, J. E. Smith, A. J. Courtemanche, J. M. F. Mar, and A. Z. Ceranowicz. </author> <title> Modsaf behavior simulation and control. </title> <booktitle> In Proceedings of the Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <year> 1993. </year>
Reference-contexts: this article are not specific to Soar however; they are common to the entire family of agent architectures mentioned above. 2 Initial Experiences in a Real-World Domain As mentioned earlier, we are building intelligent pilot agents for synthetic aircraft in a battlefield simulator, commercially developed for the military for training <ref> [2] </ref>. These pilot agents have participated in large scale combat exercises, some involving expert human pilots [28].
Reference: [3] <author> P. R. Cohen and H. J. Levesque. </author> <title> Teamwork. </title> <journal> Nous, </journal> <volume> 35, </volume> <year> 1991. </year>
Reference-contexts: These activities are being reflected in many of the multi-agent domains discussed above. Such team activities are not merely a union of simultaneous, coordinated individual activities <ref> [6, 3] </ref>. To re-iterate an illustrative example provided by Cohen and Levesque [3]: ordinary automobile traffic is not considered teamwork, despite the simultaneous activity, coordinated by traffic signs. <p> These activities are being reflected in many of the multi-agent domains discussed above. Such team activities are not merely a union of simultaneous, coordinated individual activities [6, 3]. To re-iterate an illustrative example provided by Cohen and Levesque <ref> [3] </ref>: ordinary automobile traffic is not considered teamwork, despite the simultaneous activity, coordinated by traffic signs. Indeed, our common-sense notion of teamwork involves more than simple coordination, e.g., the American Heritage Dictionary defines it as cooperative effort by the members of a team to achieve a common goal. <p> Indeed, the recent formal theories of collaborative have begun to provide the required models for flexible reasoning about teamwork <ref> [3, 15, 12, 6] </ref>. <p> To execute such team plans, team members must be provided an explicit model of teamwork their commitments and responsibilities as team members so they can flexibly reason about coordination and communication. In our work, this model is based on the formal joint intentions framework <ref> [3] </ref>, which we have modified in key ways to accommodate the constraints that appear typical in (some) real-world dynamic domains. <p> recover when the scout crashes (Item 1, Figure 3) there is no explicit representation of the company's team goal at the holding point and the scout's part in it. 3 Explicit Model of Teamwork To provide agents with an explicit model of teamwork, we rely on the joint intentions framework <ref> [3, 15] </ref>, since currently it is perhaps the most well-understood framework. In this framework, a team Q jointly intends a team action if team members are jointly committed to completing that team action, while mutually believing that they were doing it. <p> Further contributions of this paper include: * Detailed illustration of implementations of the modified joint intentions framework <ref> [3] </ref>, one in a real-world multi-agent domain, and one in the RoboCup domain; * Key modifications to the joint intentions framework to reflect important constraints in the domain; * Introduction and implementation of team operators (reactive team plans); * Techniques for recovery from failure of team activities. * Preliminary comparison of
Reference: [4] <author> R. Davis. </author> <title> Expert systems: where are we? and where do we go from here? AI Magazine, </title> <type> 3(2), </type> <month> Spring </month> <year> 1982. </year>
Reference-contexts: To achieve such flexibility we apply one key lesson from the arena of knowledge-based systems an agent must be provided explicit deep or causal models of its domains of operation <ref> [4] </ref>. The key here is to recognize that when an agent participates in a team activity, teamwork is itself one of the domains, and hence the agent must be provided an explicit model of teamwork.
Reference: [5] <author> J. Firby. </author> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <year> 1987. </year>
Reference-contexts: Selecting high-level abstract plans for execution leads to subgoals and thus a hierarchical expansion of reactive-plans ensues. Activated plans terminate via terminating conditions. Agents built in architectures such as PRS [9], BB1 [7], RAP <ref> [5] </ref> and Soar [17] for dynamic domains may be (at least abstractly) characterized in this fashion. Instead of individuals, this paper focuses on agent teams in dynamic domains.
Reference: [6] <author> B. J. Grosz and C. L. Sidner. </author> <title> Plans for discourse. </title> <booktitle> In Intentions in Communication, </booktitle> <pages> pages 417-445. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: These activities are being reflected in many of the multi-agent domains discussed above. Such team activities are not merely a union of simultaneous, coordinated individual activities <ref> [6, 3] </ref>. To re-iterate an illustrative example provided by Cohen and Levesque [3]: ordinary automobile traffic is not considered teamwork, despite the simultaneous activity, coordinated by traffic signs. <p> Indeed, the recent formal theories of collaborative have begun to provide the required models for flexible reasoning about teamwork <ref> [3, 15, 12, 6] </ref>.
Reference: [7] <author> B. Hayes-Roth, L. Brownston, and R. V. Gen. </author> <title> Multiagent collaobration in directed improvisation. </title> <booktitle> In Proceedings of the International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <year> 1995. </year>
Reference-contexts: 1 Introduction Many AI researchers are today striving to build agents for complex, dynamic multi-agent domains, such as, virtual theatre <ref> [7] </ref>, realistic virtual training environments (e.g., for emergency drill [18] or combat [28, 20]), virtual interactive fiction [1], and robotic collaboration by observation [14]. Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains. <p> Selecting high-level abstract plans for execution leads to subgoals and thus a hierarchical expansion of reactive-plans ensues. Activated plans terminate via terminating conditions. Agents built in architectures such as PRS [9], BB1 <ref> [7] </ref>, RAP [5] and Soar [17] for dynamic domains may be (at least abstractly) characterized in this fashion. Instead of individuals, this paper focuses on agent teams in dynamic domains. <p> machine learning programs: (i) learning the team operator hierarchy illustrated in Figure 5; and (ii) learning the general or common-sense rules for teamwork that have been handcoded in this work. 8 Summary and Discussion In a variety of dynamic multi-agent environments currently under development, achieving flexibility in teamwork is critical <ref> [7, 28, 1, 13] </ref>. Yet, given the uncertainty in such domains, preplanned coordination cannot sustain such flexible teamwork.
Reference: [8] <author> M. Huber and E. Durfee. </author> <title> On acting together: Without communication. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Reasoning about Mental states, </booktitle> <year> 1995. </year>
Reference-contexts: Jennings's implementation of the joint intentions framework in an industrial multi-agent setting is one notable exception [11]. Huber and Durfee describe a similar implementation, although in a smaller scale testbed <ref> [8] </ref>. There are several key differences in our work. First, in both these efforts, agents' collaborative activity appears to involve a two level hierarchy of a joint goal and a joint plan, with individuals engaged in specific roles in the plan. <p> However, agents have to explicitly check if lower-level team operators are unachievable, and recover from failures. Recovery is important, else the entire team effort will go to waste. Finally, in [11] issues of communication risk are not considered (although they are considered in <ref> [8] </ref>). Our recent work on team tracking [26] can also be classified within the above category, as it is based on the joint intentions framework. This work focused on inferring other team's joint goals and intentions based on observations of their actions is the predecessor to the work reported here.
Reference: [9] <author> F. F. Ingrand, M. P. Georgeff, , and A. S. Rao. </author> <title> An architecture for real-time reasoning and system control. </title> <journal> IEEE EXPERT, </journal> <volume> 7(6), </volume> <year> 1992. </year>
Reference-contexts: Selecting high-level abstract plans for execution leads to subgoals and thus a hierarchical expansion of reactive-plans ensues. Activated plans terminate via terminating conditions. Agents built in architectures such as PRS <ref> [9] </ref>, BB1 [7], RAP [5] and Soar [17] for dynamic domains may be (at least abstractly) characterized in this fashion. Instead of individuals, this paper focuses on agent teams in dynamic domains.
Reference: [10] <author> N. Jennings. </author> <title> Commitments and conventions: the foundation of coordination in multi-agent systems. </title> <journal> The Knowledge Engineering Review, </journal> <volume> 8, </volume> <year> 1994. </year>
Reference-contexts: Unfortunately, few implemented multi-agent systems have exploited these models, i.e., in implemented multi-agent systems, team activities and the underlying model of teamwork are usually not represented explicitly <ref> [10, 11] </ref>. 2 Instead, individual agents are often provided individual plans to achieve individual goals, with detailed precomputed plans for coordination and communication.
Reference: [11] <author> N. Jennings. </author> <title> Controlling cooperative problem solving in industrial multi-agent systems using joint intentions. </title> <journal> Artificial Intelligence, </journal> <volume> 75, </volume> <year> 1995. </year>
Reference-contexts: Unfortunately, few implemented multi-agent systems have exploited these models, i.e., in implemented multi-agent systems, team activities and the underlying model of teamwork are usually not represented explicitly <ref> [10, 11] </ref>. 2 Instead, individual agents are often provided individual plans to achieve individual goals, with detailed precomputed plans for coordination and communication. <p> Our central hypothesis is that for effective teamwork in complex, dynamic domains, individual team members should be provided (reactive) team plans, that explicitly express a team's joint 2 One notable exception is <ref> [11] </ref>, discussed in Section 7. 2 activities. Such reactive team plans may hierarchically expand out into reactive plans for an individual's role in the team. <p> With respect to the first area of related work, as mentioned earlier, few research efforts have implemented theories of collaboration. Jennings's implementation of the joint intentions framework in an industrial multi-agent setting is one notable exception <ref> [11] </ref>. Huber and Durfee describe a similar implementation, although in a smaller scale testbed [8]. There are several key differences in our work. <p> More specifically, even if a single agent is incapacitated, the team 16 operator hierarchy does not completely fall apart. However, agents have to explicitly check if lower-level team operators are unachievable, and recover from failures. Recovery is important, else the entire team effort will go to waste. Finally, in <ref> [11] </ref> issues of communication risk are not considered (although they are considered in [8]). Our recent work on team tracking [26] can also be classified within the above category, as it is based on the joint intentions framework.
Reference: [12] <author> D. Kinny, M. Ljungberg, A. Rao, E. Sonenberg, G. Tidhard, and E. Werner. </author> <title> Planned team activity. </title> <editor> In C. Castelfranchi and E. Werner, editors, </editor> <booktitle> Artificial Social Systems, Lecture notes in AI 830. </booktitle> <publisher> Springer, </publisher> <address> NY, </address> <year> 1992. </year>
Reference-contexts: Indeed, the recent formal theories of collaborative have begun to provide the required models for flexible reasoning about teamwork <ref> [3, 15, 12, 6] </ref>.
Reference: [13] <author> H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, and E. Osawa. </author> <title> Robocup: The robot world cup initiative. </title> <booktitle> In Proceedings of IJCAI-95 Workshop on Entertainment and AI/Alife, </booktitle> <year> 1995. </year>
Reference-contexts: This enables the wait-while-bp-scouted Q operator to be re-established for execution. Next, Cheetah422, the next in command, will replace Cheetah421 as the commander. 11 5 Applying Team Operators in RoboCup Synthetic RoboCup is proposed as a standard problem and a common testbed for multi-agent research <ref> [13] </ref>. It provides a dynamic, real-time multi-agent simulation of Soccer, a game that is both entertaining and popular worldwide. 8 The application of team operators in building a player-agent team for the RoboCup soccer simulation is aimed at testing their (team operator) generality. <p> machine learning programs: (i) learning the team operator hierarchy illustrated in Figure 5; and (ii) learning the general or common-sense rules for teamwork that have been handcoded in this work. 8 Summary and Discussion In a variety of dynamic multi-agent environments currently under development, achieving flexibility in teamwork is critical <ref> [7, 28, 1, 13] </ref>. Yet, given the uncertainty in such domains, preplanned coordination cannot sustain such flexible teamwork.
Reference: [14] <author> Y. Kuniyoshi, S. Rougeaux, M. Ishii, N. Kita, S. Sakane, and M. Kakikura. </author> <title> Cooperation by observation: the framework and the basic task pattern. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Many AI researchers are today striving to build agents for complex, dynamic multi-agent domains, such as, virtual theatre [7], realistic virtual training environments (e.g., for emergency drill [18] or combat [28, 20]), virtual interactive fiction [1], and robotic collaboration by observation <ref> [14] </ref>. Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains. One promising approach that has emerged is the use of hierarchical reactive plans.
Reference: [15] <author> H. J. Levesque, P. R. Cohen, and J. Nunes. </author> <title> On acting together. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <address> Menlo Park, Calif.: </address> <publisher> AAAI press, </publisher> <year> 1990. </year>
Reference-contexts: Indeed, the recent formal theories of collaborative have begun to provide the required models for flexible reasoning about teamwork <ref> [3, 15, 12, 6] </ref>. <p> recover when the scout crashes (Item 1, Figure 3) there is no explicit representation of the company's team goal at the holding point and the scout's part in it. 3 Explicit Model of Teamwork To provide agents with an explicit model of teamwork, we rely on the joint intentions framework <ref> [3, 15] </ref>, since currently it is perhaps the most well-understood framework. In this framework, a team Q jointly intends a team action if team members are jointly committed to completing that team action, while mutually believing that they were doing it.
Reference: [16] <author> H. Matsubara, I. Noda, and K. Hiraki. </author> <title> Learning of cooperative actions in multi-agent systems: a case study of pass play in soccer. </title> <editor> In S. Sen, editor, </editor> <booktitle> AAAI Spring Symposium on Adaptation, Coevolution and Learning in multi-agent systems, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: Instead, there is more emphasis on agent- and team-tracking, performed using RESC [29, 26], with about 8% operators. 7 Related Work There are two areas of related work one focused on implementing theories of collaboration, and a second focused on collaboration in RoboCup <ref> [16, 24] </ref>. With respect to the first area of related work, as mentioned earlier, few research efforts have implemented theories of collaboration. Jennings's implementation of the joint intentions framework in an industrial multi-agent setting is one notable exception [11]. <p> on tracking other teams, issues such as communication, recovery from unachievable team operators were all explicitly excluded from consideration. (The domain there was tracking the behaviors of a team of simulated enemy fighter jets, rather than helicopters.) The second related area mentioned above is work focused on collaboration in RoboCup <ref> [16, 24] </ref>. This work has largely focused on learning either via neural networks or decision trees to improve passing skills. The work reported in this article complements that work, by building a higher-level layer of teamwork skills given such basic (lower level) passing techniques.
Reference: [17] <author> A. Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard Univ. Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year>
Reference-contexts: Selecting high-level abstract plans for execution leads to subgoals and thus a hierarchical expansion of reactive-plans ensues. Activated plans terminate via terminating conditions. Agents built in architectures such as PRS [9], BB1 [7], RAP [5] and Soar <ref> [17] </ref> for dynamic domains may be (at least abstractly) characterized in this fashion. Instead of individuals, this paper focuses on agent teams in dynamic domains. <p> Section 6 presents some experimental observations and Section 7 discusses related work. Finally, Section 8 concludes. All agents described in this article are based on the Soar integrated architecture <ref> [17, 22] </ref>. We assume some familiarity with Soar's problem-solving model, which involves applying an operator hierarchy to states to reach a desired state.
Reference: [18] <author> K. Pimentel and K. Teixeira. </author> <title> Virtual reality: Through the new looking glass. Windcrest/McGraw-Hill, Blue Ridge Summit, </title> <address> PA, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Many AI researchers are today striving to build agents for complex, dynamic multi-agent domains, such as, virtual theatre [7], realistic virtual training environments (e.g., for emergency drill <ref> [18] </ref> or combat [28, 20]), virtual interactive fiction [1], and robotic collaboration by observation [14]. Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains. One promising approach that has emerged is the use of hierarchical reactive plans.
Reference: [19] <author> S. Rajput and C. R. Karr. </author> <title> Cooperative behavior in modsaf. </title> <type> Technical Report IST-CR-95-35, </type> <institution> Institute for simulation and training, University of Central Florida, </institution> <year> 1995. </year>
Reference-contexts: To coordinate among multiple pilot agents we used techniques quite comparable to previous such efforts, including our own, in the synthetic battlefield domain <ref> [28, 19, 31] </ref>. In particular, each individual was provided specific plans to coordinate with others.
Reference: [20] <author> A. S. Rao, A. Lucas, D. Morley, M. Selvestrel, and G. Murray. </author> <title> Agent-oriented architecture for air-combat simulation. </title> <type> Technical Report Technical Note 42, </type> <institution> The Australian Artificial Intelligence Institute, </institution> <year> 1993. </year>
Reference-contexts: 1 Introduction Many AI researchers are today striving to build agents for complex, dynamic multi-agent domains, such as, virtual theatre [7], realistic virtual training environments (e.g., for emergency drill [18] or combat <ref> [28, 20] </ref>), virtual interactive fiction [1], and robotic collaboration by observation [14]. Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains. One promising approach that has emerged is the use of hierarchical reactive plans.
Reference: [21] <author> B. Robson. </author> <title> Soccer skills. </title> <publisher> Sterling Publishers, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: This test in turn also provides a preliminary illustration of some of the strengths and weaknesses of RoboCup as a common testbed for multi-agent research. 5.1 Team Operators in RoboCup We begin with the issue of the adequacy of team-operator expressiveness for RoboCup. Soccer is a quintessential team sport <ref> [21] </ref>, and provides the challenge of execution of complex team tactics in a dynamic environment. For instance, up to five of the eleven team members may be involved in a flank-attack tactic [21], where two of the five may act as decoys to attract defenders away from the goal, while three <p> Soccer is a quintessential team sport <ref> [21] </ref>, and provides the challenge of execution of complex team tactics in a dynamic environment. For instance, up to five of the eleven team members may be involved in a flank-attack tactic [21], where two of the five may act as decoys to attract defenders away from the goal, while three players are actually attack. Team operators are well-suited to capture such team behaviors. 9 The hierarchy in Figure 5 illustrates a portion of the team operator hierarchy for player-agents in RoboCup. <p> In the figure, the currently implemented operators are shown by solid lines. The dashed lines are indicative of the types of team operators yet to be included. The flank-attack operator does not fully implement the flank-attack tactic <ref> [21] </ref>. 5.2 Team Operator Communication in RoboCup A second issue is one of communication within a team. <p> instance, information about winning or losing a game, the success or failure of a team's defensive or offensive tactic, throw-ins, penalties is all common 8 We will assume some familiarity on the part of the readers with soccer. 9 Interestingly, while Soccer books recognize the very important role of teamwork <ref> [21] </ref> there is little elaboration on the "model of teamwork" employed, i.e., explicit listing of the responsibilities of team members towards the team and each other. <p> The key here is to recognize that Soccer systems e.g., 4-3-3 system or 4-4-2 system which place players in formations on the field indeed create specialized roles for team members. For instance, formations involve roles such as a goalee, a sweeper, full-backs, mid-fielders, and strikers <ref> [21] </ref>. The issues of detecting team operator failures and recovery by substitution for teammates (as discussed in Section 4.3) are thus likely to prove useful in RoboCup.
Reference: [22] <author> P. S. Rosenbloom, J. E. Laird, A. Newell, , and R. McCarl. </author> <title> A preliminary analysis of the soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 47(1-3):289-325, </volume> <year> 1991. </year>
Reference-contexts: Section 6 presents some experimental observations and Section 7 discusses related work. Finally, Section 8 concludes. All agents described in this article are based on the Soar integrated architecture <ref> [17, 22] </ref>. We assume some familiarity with Soar's problem-solving model, which involves applying an operator hierarchy to states to reach a desired state.
Reference: [23] <author> The DIS steering committee. </author> <title> The dis vision: A map to the future of distributed simulation. </title> <type> Technical Report IST-SP-94-01, </type> <institution> Institute for simulation and training, University of Central Florida, </institution> <address> Orlando, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Based on the above hypothesis, we have implemented agent-teams for two dynamic multi-agent domains: a pilot-agent teams for real-world combat simulation <ref> [28, 23] </ref>, and a player-agent team for the RoboCup soccer simulation (proposed as a common testbed for multi-agent systems)[13].
Reference: [24] <author> P. Stone and M. Veloso. </author> <title> Towards collaborative and adversarial learning: a case study in robotic soccer. </title> <editor> In S. Sen, editor, </editor> <booktitle> AAAI Spring Symposium on Adaptation, Coevolution and Learning in multi-agent systems, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: Instead, there is more emphasis on agent- and team-tracking, performed using RESC [29, 26], with about 8% operators. 7 Related Work There are two areas of related work one focused on implementing theories of collaboration, and a second focused on collaboration in RoboCup <ref> [16, 24] </ref>. With respect to the first area of related work, as mentioned earlier, few research efforts have implemented theories of collaboration. Jennings's implementation of the joint intentions framework in an industrial multi-agent setting is one notable exception [11]. <p> on tracking other teams, issues such as communication, recovery from unachievable team operators were all explicitly excluded from consideration. (The domain there was tracking the behaviors of a team of simulated enemy fighter jets, rather than helicopters.) The second related area mentioned above is work focused on collaboration in RoboCup <ref> [16, 24] </ref>. This work has largely focused on learning either via neural networks or decision trees to improve passing skills. The work reported in this article complements that work, by building a higher-level layer of teamwork skills given such basic (lower level) passing techniques.
Reference: [25] <author> M. Tambe. </author> <title> Teamwork in real-world, dynamic environments. </title> <booktitle> In Proceedings of the International Conference on Multi-agent Systems (ICMAS), </booktitle> <month> December </month> <year> 1996. </year>
Reference: [26] <author> M. Tambe. </author> <title> Tracking dynamic team activity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: As mentioned in Section 3.2, it is useful for an agent to monitor other agents' role performance. This is accomplished in one of three ways. First, the other agent may itself communicate. Second, it is possible to track the other agent's role performance, via techniques such as RESC <ref> [29, 26] </ref>, that dynamically infer other agents' higher-level goals and behaviors from observation of that agents actions. Given its expense, however, such detailed tracking is performed selectively instead, an agent often only monitors the participation of other team members. <p> Figure 7-b shows the percentage from an actual run with the modified joint intentions framework. Communication percentage decreases more than 10-fold (just about 2% on communication). Instead, there is more emphasis on agent- and team-tracking, performed using RESC <ref> [29, 26] </ref>, with about 8% operators. 7 Related Work There are two areas of related work one focused on implementing theories of collaboration, and a second focused on collaboration in RoboCup [16, 24]. <p> Recovery is important, else the entire team effort will go to waste. Finally, in [11] issues of communication risk are not considered (although they are considered in [8]). Our recent work on team tracking <ref> [26] </ref> can also be classified within the above category, as it is based on the joint intentions framework. This work focused on inferring other team's joint goals and intentions based on observations of their actions is the predecessor to the work reported here.
Reference: [27] <author> M. Tambe. </author> <title> Agent architectures for flexible, practical teamwork. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: One or two scout helicopters in the company fly forward 3 More recent work <ref> [27] </ref>, completed after this article was submitted for publication, provides more details on this inter-domain reuse capability. 4 This basic simulation technology, once proven promising in training for military applications, is leading to other possible applications ranging from training for disaster relief to interactive entertainment. 3 to check the battle position,
Reference: [28] <author> M. Tambe, W. L. Johnson, R. Jones, F. Koss, J. E. Laird, P. S. Rosenbloom, and K. Schwamb. </author> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine, </journal> <volume> 16(1), </volume> <month> Spring </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Many AI researchers are today striving to build agents for complex, dynamic multi-agent domains, such as, virtual theatre [7], realistic virtual training environments (e.g., for emergency drill [18] or combat <ref> [28, 20] </ref>), virtual interactive fiction [1], and robotic collaboration by observation [14]. Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains. One promising approach that has emerged is the use of hierarchical reactive plans. <p> Based on the above hypothesis, we have implemented agent-teams for two dynamic multi-agent domains: a pilot-agent teams for real-world combat simulation <ref> [28, 23] </ref>, and a player-agent team for the RoboCup soccer simulation (proposed as a common testbed for multi-agent systems)[13]. <p> These pilot agents have participated in large scale combat exercises, some involving expert human pilots <ref> [28] </ref>. <p> To coordinate among multiple pilot agents we used techniques quite comparable to previous such efforts, including our own, in the synthetic battlefield domain <ref> [28, 19, 31] </ref>. In particular, each individual was provided specific plans to coordinate with others. <p> machine learning programs: (i) learning the team operator hierarchy illustrated in Figure 5; and (ii) learning the general or common-sense rules for teamwork that have been handcoded in this work. 8 Summary and Discussion In a variety of dynamic multi-agent environments currently under development, achieving flexibility in teamwork is critical <ref> [7, 28, 1, 13] </ref>. Yet, given the uncertainty in such domains, preplanned coordination cannot sustain such flexible teamwork.
Reference: [29] <author> M. Tambe and P. S. Rosenbloom. RESC: </author> <title> An approach for real-time, dynamic agent tracking. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), </booktitle> <year> 1995. </year>
Reference-contexts: As mentioned in Section 3.2, it is useful for an agent to monitor other agents' role performance. This is accomplished in one of three ways. First, the other agent may itself communicate. Second, it is possible to track the other agent's role performance, via techniques such as RESC <ref> [29, 26] </ref>, that dynamically infer other agents' higher-level goals and behaviors from observation of that agents actions. Given its expense, however, such detailed tracking is performed selectively instead, an agent often only monitors the participation of other team members. <p> Figure 7-b shows the percentage from an actual run with the modified joint intentions framework. Communication percentage decreases more than 10-fold (just about 2% on communication). Instead, there is more emphasis on agent- and team-tracking, performed using RESC <ref> [29, 26] </ref>, with about 8% operators. 7 Related Work There are two areas of related work one focused on implementing theories of collaboration, and a second focused on collaboration in RoboCup [16, 24].
Reference: [30] <author> M. Tambe, K. Schwamb, and P. S. Rosenbloom. </author> <title> Building intelligent pilots for simulated rotary wing aircraft. </title> <booktitle> In Proceedings of the Fifth Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: These pilot agents have participated in large scale combat exercises, some involving expert human pilots [28]. This paper will focus on pilot agents for a company of (up to eight) attack helicopters, which execute missions in a synthetic 3D terrain with hills, valleys and ridges (e.g., southern California) <ref> [30] </ref>. 4 As shown in Figure 1, in a typical attack mission, the company may fly 25-50 kilometers at varying altitudes, to halt at a holding point. <p> The helicopter then quickly masks and moves as protection against return fire, before popping up again. When the mission completes, the helicopters regroup and return to base. In our first implementation of the helicopter company, each pilot agent was provided an operator (reactive plan) hierarchy to execute its mission <ref> [30] </ref>. Figure 2 illustrates a portion of this operator hierarchy (at any one time, only one path in this hierarchy from the root to a leaf node is active).
Reference: [31] <author> G. Tidhar, M. Selvestrel, and C. Heinze. </author> <title> Modeling teams and team tactics in whole air mission modelling. </title> <type> Technical Report Technical Note 60, </type> <institution> The Australian Artificial Intelligence Institute, </institution> <year> 1995. </year> <month> 20 </month>
Reference-contexts: To coordinate among multiple pilot agents we used techniques quite comparable to previous such efforts, including our own, in the synthetic battlefield domain <ref> [28, 19, 31] </ref>. In particular, each individual was provided specific plans to coordinate with others.
References-found: 31

