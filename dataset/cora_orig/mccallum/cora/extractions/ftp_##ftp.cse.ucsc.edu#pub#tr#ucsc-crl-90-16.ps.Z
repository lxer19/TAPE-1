URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-90-16.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: [17] D. Haussler. Generalizing the PAC model for neu-ral net and other learning applications. Informa
Author: [] D. Haussler. . [] D. Haussler. [] D. Haussler, M. Kearns, N. Littlestone, and M. K. Warmuth. [] D. Haussler, N. Littlestone, and M. War-muth. [] M. Kearns, M. Li, L. Pitt, and L. Valiant. [] M. Kearns and R. Schapire. [] M. Kearns and L. Valiant. [] N. Littlestone. N. Littlestone. [] N. Littlestone. [] N. Littlestone and M. K. Warmuth. B. K. Natarajan. [] L. Pitt. [] L. Pitt and L. Valiant. , . [] R. Rivest, D. Haussler, and M. Warmuth, editors. [] R. L. Rivest. G. Tesauro and D. Cohn. V. N. Vapnik. 
Date: 256-261, 1989.  August 1985.  
Affiliation: University of  U. Illinois at Urbana-Champaign,  San  
Address: San Mateo, CA, 1988.  295, New York, 1987.  Seattle, WA, 1989.  Calif., Santa Cruz, 1989.  1989.  Mateo, CA, 1989.  
Note: drawn points. In Proceedings of the 29th Annual Symposium on the Foundations of Computer Sci ence, pages 100-109, IEEE, 1988. [22] D. Haussler and L. Pitt, editors. Proceedings of the 1988 Workshop on Computational Learning The ory. Morgan Kaufmann,  [24] M. Kearns and M. Li. Learning in the presence of malicious errors. In 20th ACM Symposium on Theory of Computing, pages 267-279, Chicago,  In 19th ACM Symposium on Theory of Computing, pages 285  In 21st ACM Symposium on Theory of Computing, pages 433-444,  In Proceedings of the 2nd Workshop on Computational Learning Theory, pages 269-284, published by Morgan Kaufmann, 1989. [29]  PhD thesis,  In 30th Annual IEEE Symposium on Foundations of Computer Science, pages  [33]  Proceedings of the 1989 Workshop on Computational Learning Theory. Morgan Kaufmann,  Learning, 2:229-246, 1987. [38] D. Rumelhart. 1990. personal communication. [40]  published manuscript. [41] L. G. Valiant. Learning disjunctions of conjunctions. In Proc. 9th IJCAI, pages 560-6, Los Ange les,  [42] L. G. Valiant. A theory of the learnable. Comm. ACM, 27(11):1134-42, 1984. [43]  Springer-Verlag, New York, 1982.  
Pubnum: Technical Report UIUCDCS-R-89-1530,  
Abstract: 23] M. A. John Shawe-Taylor and N. Biggs. Bounding Sample Size with the Vapnik-Chervonenkis Dimension. Technical Report CSD-TR-618, University of London, Surrey, England, 1989. [32] T. Mitchell. The need for biases in learning generalizations. Technical Report CBM-TR-117, Rut gers University, New Brunswick, NJ, 1980. [39] W. Sarrett and M. Pazzani. Average case analysis of empirical and explanation-based learning algo rithms. Technical Report 89-35, UC Irvine, 1989. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. </author> <title> Amsterdam. The Valiant Learning Model: Extensions and Assessment. </title> <type> Master's thesis, </type> <institution> MIT Department of Electrical Engineering and Computer Science, </institution> <month> Jan. </month> <year> 1988. </year>
Reference: [2] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Information and Computation, </journal> <volume> 75 </volume> <pages> 87-106, </pages> <month> Nov. </month> <year> 1987. </year>
Reference-contexts: there are polynomial time algorithms that make polynomially many membership queries and have polynomial worst case mistake bounds for learning 1. monotone DNF concepts (Disjunctive Normal Form with no negated variables) [3], 2. -formulae (Boolean formulae in which each vari able appears at most once) [5], 3. deterministic finite automata <ref> [2] </ref>, and 4. Horn sentences (propositional PROLOG pro grams) [4].
Reference: [3] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: It has been shown that there are polynomial time algorithms that make polynomially many membership queries and have polynomial worst case mistake bounds for learning 1. monotone DNF concepts (Disjunctive Normal Form with no negated variables) <ref> [3] </ref>, 2. -formulae (Boolean formulae in which each vari able appears at most once) [5], 3. deterministic finite automata [2], and 4. Horn sentences (propositional PROLOG pro grams) [4].
Reference: [4] <author> D. Angluin, M. Frazier, and L. Pitt. </author> <title> Learning conjunctions of horn clauses. 1990. </title> <type> manuscript. </type>
Reference-contexts: Horn sentences (propositional PROLOG pro grams) <ref> [4] </ref>. In addition, there is a general method for converting an efficient learning algorithm that makes membership queries and has a polynomial worst case mistake bound into a PAC learning algorithm, as long as the PAC algorithm is also allowed to make membership queries.
Reference: [5] <author> D. Angluin, L. Hellerstein, and M. Karpinski. </author> <title> Learning read-once formulas with queries. </title> <journal> JACM, </journal> <note> 1990. to appear. </note>
Reference-contexts: It has been shown that there are polynomial time algorithms that make polynomially many membership queries and have polynomial worst case mistake bounds for learning 1. monotone DNF concepts (Disjunctive Normal Form with no negated variables) [3], 2. -formulae (Boolean formulae in which each vari able appears at most once) <ref> [5] </ref>, 3. deterministic finite automata [2], and 4. Horn sentences (propositional PROLOG pro grams) [4].
Reference: [6] <author> D. Angluin and P. Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference: [7] <author> E. Baum. </author> <title> When are k-nearest neighbor and back propogation accurate for feasible sized sets of examples. </title> <booktitle> In Snowbird conference on Neural Networks for Computing, </booktitle> <year> 1990. </year> <type> unpublished manuscript. </type>
Reference: [8] <author> G. M. Benedek and A. Itai. </author> <title> Learnability by fixed distributions. </title> <booktitle> In Proc. 1988 Workshop on Comp. Learning Theory, </booktitle> <pages> pages 80-90, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference: [9] <author> F. Bergadano and L. Saitta. </author> <title> On the error prob-abilty of boolean concept descriptions. </title> <booktitle> In Proceedings of the 1989 European Working Session on Learning, </booktitle> <pages> pages 25-35, </pages> <year> 1989. </year>
Reference: [10] <author> A. Blum and R. L. Rivest. </author> <title> Training a three-neuron neural net is NP-Complete. </title> <booktitle> In Proceedings of the 1988 Workshop on Computational Learning Theory, </booktitle> <pages> pages 9-18, </pages> <publisher> published by Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference: [11] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> JACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference: [12] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <year> 1987. </year>
Reference: [13] <author> W. Buntine. </author> <title> A Theory of Learning Classification Rules. </title> <type> PhD thesis, </type> <institution> University of Technology, Syd-ney, </institution> <year> 1990. </year> <month> Forthcoming. </month>
Reference: [14] <author> T. M. </author> <title> Cover. Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition. </title> <journal> IEEE Trans. on Electronic Computers, </journal> <volume> EC-14:326-334, </volume> <year> 1965. </year>
Reference: [15] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>

References-found: 15

