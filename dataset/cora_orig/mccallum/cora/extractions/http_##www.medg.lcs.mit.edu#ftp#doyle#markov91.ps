URL: http://www.medg.lcs.mit.edu/ftp/doyle/markov91.ps
Refering-URL: http://www.medg.lcs.mit.edu/ftp/doyle/
Root-URL: 
Title: Markov Analysis of Qualitative Dynamics  
Author: by Jon Doyle and Elisha P. Sacks. Jon Doyle Elisha P. Sacks 
Address: 545 Technology Square, Cambridge, Massachusetts 02139  Princeton, New Jersey 08544  
Affiliation: Laboratory for Computer Science, Massachusetts Institute of Technology  Department of Computer Science, Princeton University,  
Date: 1 (February 1991),  1989, 1990, 1991, 1994  
Note: Reset reproduction of article published in Computational Intelligence, Vol. 7, No.  pp. 1-10. Reprinted July 1994. Reprinting c Copyright  
Abstract: Commonsense sometimes predicts events to be likely or unlikely rather than merely possible. We extend methods of qualitative reasoning to predict the relative likelihoods of possible qualitative behaviors by viewing the dynamics of a system as a Markov chain over its transition graph. This involves adding qualitative or quantitative estimates of transition probabilities to each of the transitions and applying the standard theory of Markov chains to distinguish persistent states from transient states and to calculate recurrence times, settling times, and probabilities for ending up in each state. Much of the analysis depends solely on qualitative estimates of transition probabilities, which follow directly from theoretical considerations and which lead to qualitative predictions about entire classes of systems. Quantitative estimates for specific systems are derived empirically and lead to qualitative and quantitative conclusions, most of which are insensitive to small perturbations in the estimated transition probabilities. The algorithms are straightforward and efficient.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1974. </year>
Reference-contexts: Using these probabilities, we partition the associated Markov chain into ergodic sets and transient states, drawing the qualitative conclusions that the former, but not the latter, persist asymptotically. We employ the topological sorting algorithm of Tarjan <ref> [1, Sec. 5.5] </ref> to find the ergodic sets. When nonuniform initial conditions are specified, we filter the sorted graph to find the ergodic states reachable from initial states with positive probabilities. The entire analysis takes time and space linear in the size of the transition graph. <p> For numeric probability estimates, straightforward implementations 12 Markov Analysis of Qualitative Dynamics of these operations require O (n 3 ) time and O (n 2 ) space for a graph with n nodes <ref> [1, Chap. 6] </ref>. Hsu [7] implements and demonstrates the calculations on several examples including chaotic ones. <p> Even this system, arguably the simplest nonlinear one possible, can exhibit extremely complicated behavior. Following May, we substitute bx=a for x to obtain the canonical form f (x) = ax (1 x); which is called the quadratic map. Trajectories that leave the interval <ref> [0; 1] </ref> approach 1 monotonically and f (1) = 0, implying that large enough populations always die out. The problem is to identify and characterize the trajectories that remain in (0; 1) forever, which represent the stable patterns of population fluctuation. The answer depends on a. <p> Rigorous derivation of these conclusions requires great mathematical expertise. More complicated equations defy analysis altogether. Markov analysis, although more limited, provides many of the same answers and applies uniformly to all equations. We define a Markov chain with two states <ref> [0; 1] </ref> and its complement C = (1; 0) [ (1; 1). For a 4, we obtain two absorbing states because trajectories never cross between regions. For a &gt; 4, we obtain an absorbing chain with absorbing state C, implying that trajectories in [0; 1] eventually escape to C with probability <p> define a Markov chain with two states <ref> [0; 1] </ref> and its complement C = (1; 0) [ (1; 1). For a 4, we obtain two absorbing states because trajectories never cross between regions. For a &gt; 4, we obtain an absorbing chain with absorbing state C, implying that trajectories in [0; 1] eventually escape to C with probability 1. In physical terms, the population survives for a &lt; 4 and dies out otherwise. Markov theory also predicts the extinction time for a &gt; 4, which equals the absorption time into C. The transition probability from [0; 1] to C equals the <p> C, implying that trajectories in <ref> [0; 1] </ref> eventually escape to C with probability 1. In physical terms, the population survives for a &lt; 4 and dies out otherwise. Markov theory also predicts the extinction time for a &gt; 4, which equals the absorption time into C. The transition probability from [0; 1] to C equals the measure of the set of points in [0; 1] that map directly into C. This set is the subinterval " 2 r 4 1 ; 2 r 4 1 # so the transition probability is p = p 1 4=a. <p> In physical terms, the population survives for a &lt; 4 and dies out otherwise. Markov theory also predicts the extinction time for a &gt; 4, which equals the absorption time into C. The transition probability from <ref> [0; 1] </ref> to C equals the measure of the set of points in [0; 1] that map directly into C. This set is the subinterval " 2 r 4 1 ; 2 r 4 1 # so the transition probability is p = p 1 4=a. The expected absorption time equals 1=p, as explained in Section 4.1. <p> The small relative error indicates that the chain assumption applies well. In a more refined analysis, we could investigate the behavior of the quadratic map within the interval <ref> [0; 1] </ref> by partitioning that interval into small subintervals. Markov analysis would estimate the distribution of states within each region. This approach provides a statistical understanding of systems whose individual trajectories defy analysis. For example, it demonstrates that most iterates of the map 4x (1 x) on [0; 1] cluster near <p> within the interval <ref> [0; 1] </ref> by partitioning that interval into small subintervals. Markov analysis would estimate the distribution of states within each region. This approach provides a statistical understanding of systems whose individual trajectories defy analysis. For example, it demonstrates that most iterates of the map 4x (1 x) on [0; 1] cluster near the endpoints, a result that Lasota and Mackey [9] confirm by analytic means.
Reference: [2] <author> R. L. Devaney. </author> <title> An Introduction to Chaotic Dynamical Systems. </title> <address> Benjamin/Cummings, Menlo Park, California, </address> <year> 1986. </year>
Reference-contexts: Dynamic systems theory seeks to determine the qualitative properties of a system's trajectories from its evolution law. For example, a trajectory is fixed if f (x) = x and periodic with period p if f p (x) = x. Devaney <ref> [2] </ref> provides a good elementary introduction to discrete dynamic systems, including the example below. Discrete systems are useful in modeling population dynamics.
Reference: [3] <author> J. Doyle and E. P. Sacks. </author> <title> Stochastic analysis of qualitative dynamics. </title> <editor> In N. S. Srid-haran, editor, </editor> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1187-1192, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For example, the probability that the pendulum approaches its unstable equilibrium when released in arbitrary position is zero because the set of sequences that either start or terminate at the unstable equilibrium has measure fl This paper extends and improves on the earlier paper <ref> [3] </ref>. Authors listed alphabetically. Doyle & Sacks zero. Calculating the probabilities is straightforward in systems whose exact limiting behavior is known for all initial conditions. The challenge is to estimate the probabilities when the limiting behavior is unknown.
Reference: [4] <author> W. Feller. </author> <title> An Introduction to Probability Theory and Its Applications, volume I. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1957. </year>
Reference-contexts: Readers familiar with Markov theory may skip to Section 4.5. Readers unfamiliar with Markov theory may find more details in Feller <ref> [4] </ref>, Kemeny and Snell [8], or Roberts [11]. For simplicity, we will treat only finite Markov chains, and so restrict attention to systems whose qualitative dynamics involves only finitely many regions of interest.
Reference: [5] <author> J. Guckenheimer and P. Holmes. </author> <title> Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Qualitative probability estimates follow directly from the transition graph and fixed point types of a system. The transition probability is zero from a region to an unreachable region by definition of the graph. By the stable manifold theorem <ref> [5, p. 13] </ref>, the dimension of the basin of a fixed point equals the number of eigenvalues of its Jacobian matrix that have negative real parts. 1 Unstable fixed points have positive eigenvalues, so their basins form lower-dimensional, hence measure zero, subspaces.
Reference: [6] <author> M. W. Hirsch and S. Smale. </author> <title> Differential Equations, Dynamical Systems, and Linear Algebra. </title> <publisher> Academic Press College Division, </publisher> <address> Orlando, Florida, </address> <year> 1974. </year>
Reference-contexts: For example, the set of flows for the Lottka-Volterra model of population sizes of competing species divides into four classes of flows, each with qualitatively different dynamics <ref> [6] </ref>. Each of these has a small number of attractors, and can be analyzed for expected asymptotic behavior just as was done with the charged pendulum in Section 5.2.
Reference: [7] <author> C. S. Hsu. </author> <title> Cell-to-Cell Mapping. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: One approach to dealing with such time-dependence involves iterative improvement of the model, following Hsu <ref> [7] </ref> or Sacks [13] (though unlike that work, we have not automated this refinement process). If one observes time-dependent behavior in constructing the transition probabilities, one subdivides or otherwise refines the set of regions and starts over. <p> For numeric probability estimates, straightforward implementations 12 Markov Analysis of Qualitative Dynamics of these operations require O (n 3 ) time and O (n 2 ) space for a graph with n nodes [1, Chap. 6]. Hsu <ref> [7] </ref> implements and demonstrates the calculations on several examples including chaotic ones. <p> The likelihoods of the long term behaviors are never sensitive to perturbations in the transition probabilities, whereas the expected settling times can be sensitive. Markov analysis of dynamical systems has also been pursued by Hsu <ref> [7] </ref>, whose analysis of "generalized cell-to-cell mappings" is similar to our analysis of dynamics over qualitative states. Hsu develops algorithms which yield the same numerical information as ours for numerically formulated systems.
Reference: [8] <author> J. G. Kemeny and J. L. Snell. </author> <title> Finite Markov Chains. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: Readers familiar with Markov theory may skip to Section 4.5. Readers unfamiliar with Markov theory may find more details in Feller [4], Kemeny and Snell <ref> [8] </ref>, or Roberts [11]. For simplicity, we will treat only finite Markov chains, and so restrict attention to systems whose qualitative dynamics involves only finitely many regions of interest.
Reference: [9] <author> A. Lasota and M. C. Mackey. </author> <title> Probabilistic Properties of Deterministic Systems. </title> <publisher> Cam-bridge University Press, </publisher> <address> Cambridge, </address> <year> 1985. </year>
Reference-contexts: This approach provides a statistical understanding of systems whose individual trajectories defy analysis. For example, it demonstrates that most iterates of the map 4x (1 x) on [0; 1] cluster near the endpoints, a result that Lasota and Mackey <ref> [9] </ref> confirm by analytic means.
Reference: [10] <author> R. M. </author> <month> May. </month> <title> Simple mathematical models with very complicated dynamics. </title> <journal> Nature, </journal> <volume> 261(5560) </volume> <pages> 459-467, </pages> <year> 1976. </year>
Reference-contexts: Discrete systems are useful in modeling population dynamics. Here x 0 denotes an initial population, x i denotes the population after i generations, and f (x) expresses the birth rate. 16 Markov Analysis of Qualitative Dynamics May <ref> [10] </ref> studies the system f (x) = ax bx 2 with a and b positive parameters that represent natural reproduction and the negative effects of overcrowding. The birth rate increases from 0 to a maximum then decreases to 0 as x increases from 0 to a=b.
Reference: [11] <author> F. S. Roberts. </author> <title> Discrete Mathematical Models. </title> <publisher> Prentice-Hall Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1976. </year>
Reference-contexts: Readers familiar with Markov theory may skip to Section 4.5. Readers unfamiliar with Markov theory may find more details in Feller [4], Kemeny and Snell [8], or Roberts <ref> [11] </ref>. For simplicity, we will treat only finite Markov chains, and so restrict attention to systems whose qualitative dynamics involves only finitely many regions of interest. <p> Even when the natural time scale for modeling yields a non-regular chain, the analysis involves only a few additional calculations, not any new ideas or additional computational complexity. See Roberts <ref> [11] </ref> for details. The powers P t of the transition matrix of an ergodic chain approach a stochastic matrix W as t approaches infinity.
Reference: [12] <author> E. P. Sacks. </author> <title> Piecewise linear abstraction of intractable dynamic systems. </title> <journal> International Journal of Artificial Intelligence in Engineering, </journal> <volume> 3(3) </volume> <pages> 151-155, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: We follow standard AI practice and equate all trajectories that go through a specific sequence of regions in phase space. Our qualitative dynamics consists of a partition of phase space into regions along with a graph of possible transitions between regions. Sacks <ref> [12, 13] </ref> presents a system that automatically identifies such regions and the possible transitions between them for second-order systems of ordinary differential equations. Most of the ideas extend directly to larger systems.
Reference: [13] <author> E. P. Sacks. </author> <title> Automatic qualitative analysis of ordinary differential equations using piecewise linear approximations. </title> <journal> Artificial Intelligence, </journal> <volume> 41(3) </volume> <pages> 313-364, </pages> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: We follow standard AI practice and equate all trajectories that go through a specific sequence of regions in phase space. Our qualitative dynamics consists of a partition of phase space into regions along with a graph of possible transitions between regions. Sacks <ref> [12, 13] </ref> presents a system that automatically identifies such regions and the possible transitions between them for second-order systems of ordinary differential equations. Most of the ideas extend directly to larger systems. <p> One approach to dealing with such time-dependence involves iterative improvement of the model, following Hsu [7] or Sacks <ref> [13] </ref> (though unlike that work, we have not automated this refinement process). If one observes time-dependent behavior in constructing the transition probabilities, one subdivides or otherwise refines the set of regions and starts over. <p> Incorporating global properties of flows into stochastic analysis is another topic for future research. Our current analysis derives the qualitative dynamics of a system from local properties of its flow: where it vanishes and whether it crosses certain curves. Sacks <ref> [13] </ref> shows how to increase the accuracy of the qualitative dynamics by ruling out locally consistent behaviors that violate global constraints, thus reducing the size of a transition graph. For example, his program uses an energy argument to prove that a pendulum cannot spin forever.
Reference: [14] <author> E. P. Sacks. </author> <title> A dynamic systems perspective on qualitative simulation. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):349-362, </volume> <year> 1990. </year>
Reference-contexts: For concreteness, we illustrate the method by using the classical mathematical theory of dynamic systems to derive a set of qualitative states and transition graph from the phase space of a system, following Sacks <ref> [14] </ref>. Our method can derive useful results at many levels of detail, ranging from the abstract level of the qualitative reasoning formalisms in the AI literature to fully specified ordinary differential equations. <p> Sacks [12, 13] presents a system that automatically identifies such regions and the possible transitions between them for second-order systems of ordinary differential equations. Most of the ideas extend directly to larger systems. Sacks <ref> [14] </ref> shows how to translate traditional qualitative reasoning into our qualitative dynamics without loss of information or increase in complexity. Qualitative states correspond to rectangular regions in phase space, and qualitative simulation amounts to finding the possible transitions between regions. <p> We assign a positive probability to transitions between adjacent regions, such as h; i and h; +i. This decision is justified by the continuous dependence of trajectories on initial conditions and by the definition of the transition graph <ref> [14] </ref>. Using these probabilities, we partition the associated Markov chain into ergodic sets and transient states, drawing the qualitative conclusions that the former, but not the latter, persist asymptotically. We employ the topological sorting algorithm of Tarjan [1, Sec. 5.5] to find the ergodic sets.
Reference: [15] <author> S. Smale. </author> <title> The Mathematics of Time: Essays on Dynamical Systems, Economic Processes, and Related Topics. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1980. </year> <title> 20 Markov Analysis of Qualitative Dynamics </title>
Reference-contexts: Energy conservation also implies that the pendulum cannot spin forever without resort to the chain assumption, thus lightening the burden on stochastic analysis. Deriving and exploiting the relations between the stochastic model and the global phase flow is a more ambitious task. Incorporating global analysis <ref> [15] </ref> with stochastic analysis is another direction for future research. Global analysis considers not just one flow, but a class of flows. This is useful when we do not know the exact equations describing a system, and wish to make predictions based on what we do know about them.
Reference: [16] <author> K. M.-K. Yip. </author> <title> Generating global behaviors using deep knowledge of local dynamics. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 280-285. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference-contexts: Automating the model refinement procedure for stochastic qualitative analysis is a major challenge. To do so requires answering some fundamental questions about the stability of the stochastic predictions under changes in the underlying qualitative graph, such as dividing phase space into overly-fine regions. Yip <ref> [16] </ref> presents some methods for sampling and observing the behaviors of dynamical systems. Perhaps they can be extended to the model construction task. Machine learning techniques may also prove relevant.
References-found: 16

