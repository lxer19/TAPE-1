URL: http://www.isi.edu/~blythe/papers/postscript/ewsp95.ps
Refering-URL: http://www.isi.edu/~blythe/papers/ewsp95.html
Root-URL: http://www.isi.edu
Email: jblythe@cs.cmu.edu  
Title: The Footprint Principle for Heuristics for Probabilistic Planners  
Author: Jim Blythe 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science, Carnegie Mellon University,  
Abstract: Probabilistic back-chaining planners, which use probabilities to represent and reason about uncertainty in the planning domain, typically have a larger search space than their classical counterparts. Therefore heuristics that can reduce their search effectively are even more important. The footprint principle leads to a family of heuristics for probabilistic planners produced by attempting to make subsequent refinements to a plan apply to disjoint sets of planning cases. Heuristics derived by this principle are shown to be effective for two probabilistic planners, Buridan and Weaver, which are organised around quite different search techniques. Probabilistic planners are needed that can use more compact representations of uncertainty than those that currently exist, and these planners will depend even more on the footprint principle and others like it.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jim Blythe. </author> <title> Planning with external events. </title> <editor> In Ramon Lopez de Mantaras and David Poole, editors, </editor> <booktitle> Proc. Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 94-101, </pages> <address> Seattle, WA, July 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1 Introduction Probabilistic planners that use classical back-chaining algorithms, such as <ref> [6, 1, 4, 7] </ref>, extend the range of problems addressable by classical AI planners to include uncertainty, which might be present in the initial state, in the outcomes of actions and in external events in the domain, using representations based on probability theory. <p> The next section provides a formal description of planning under uncertainty that is used to motivate and explain the footprint principle, and the related coherence principle. The following two sections show examples of heuristics derived with the footprint principle for two different probabilistic planners, Buridan [6] and Weaver <ref> [1] </ref>. Finally I argue that planners should be based on more compact representations of uncertainty than either Buridan or Weaver are currently, one which will more naturally deal with sets of states. <p> Despite the dramatic difference between link-disjoint-minus and link-disjoint-plus, the footprint principle is at least as important a factor in the success of link-disjoint-minus, since the link-seeking variants of default and link-prob performed very poorly. 4 Case study: Weaver Our second case study is with Weaver <ref> [1] </ref>, a probabilistic planner based on Prodigy [3] and therefore a total-order planner. Weaver repeatedly calls Prodigy as a subroutine, choosing an initial state for Prodigy and a goal so that the result can be inserted into the emerging plan as a refinement. <p> This is beyond the scope of this paper but is described in <ref> [1] </ref>. A simplified version of Weaver's algorithm that ignores external events can be summarised circles correspond to actions, the others to literals at different stages of the plan's execution. as follows: Initialise P to the empty plan, and initialise the belief net B to describe the initial state distribution.
Reference: [2] <author> Craig Boutilier, Thomas Dean, and Steve Hanks. </author> <title> Planning under uncertainty: structural assumptions and computational leverage. </title> <booktitle> In Proc. European Workshop on Planning, </booktitle> <address> Assissi, Italy, September 1995. </address> <publisher> IOS Press. </publisher>
Reference-contexts: If p is true, Operator O 3 adds g with probability 0.5 (outcome fl) and has no effect with probability 0.5 (outcome 1 In the terms of Markov decision processes as described in <ref> [2] </ref>, a trace is a trajectory in the MDP corresponding to the problem. ffi). If p is false, it has no effect.
Reference: [3] <author> Jaime G. Carbonell, Jim Blythe, Oren Etzioni, Yolanda Gil, Robert Joseph, Dan Kahn, Craig Knoblock, Steven Minton, Alicia Perez, Scott Reilly, Manuela Veloso, and Mei Wang. PRODIGY4.0: </author> <title> The manual and tutorial. </title> <type> Technical Report CMU-CS-92-150, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: dramatic difference between link-disjoint-minus and link-disjoint-plus, the footprint principle is at least as important a factor in the success of link-disjoint-minus, since the link-seeking variants of default and link-prob performed very poorly. 4 Case study: Weaver Our second case study is with Weaver [1], a probabilistic planner based on Prodigy <ref> [3] </ref> and therefore a total-order planner. Weaver repeatedly calls Prodigy as a subroutine, choosing an initial state for Prodigy and a goal so that the result can be inserted into the emerging plan as a refinement.
Reference: [4] <author> Robert P. Goldman and Mark S. Boddy. </author> <title> Epsilon-safe planning. </title> <editor> In Ramon Lopez de Mantaras and David Poole, editors, </editor> <booktitle> Proc. Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 253-261, </pages> <address> Seattle, WA, July 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1 Introduction Probabilistic planners that use classical back-chaining algorithms, such as <ref> [6, 1, 4, 7] </ref>, extend the range of problems addressable by classical AI planners to include uncertainty, which might be present in the initial state, in the outcomes of actions and in external events in the domain, using representations based on probability theory. <p> Kushmerick, Hanks and Weld briefly discuss the possibility of using information from the plan evaluator to guide the search in [5], but do not mention specific heuristics. Goldman and Boddy discuss expanding the plan node with highest probability in their *-safe planners <ref> [4] </ref>. There are interesting relations between this work and machine learning research on boosting learning algorithms [10]. <p> The success of heuristics based on the footprint principle in two very different probabilistic planners makes it likely that it will be widely applicable in probabilistic planners. As well as existing planners, such as the *-safe planners of Goldman and Boddy <ref> [4] </ref>, I anticipate applying the footprint principle to planners that can represent initial state distributions and outcomes of actions that are composed of independent sources of uncertainty efficiently.
Reference: [5] <author> Nicholas Kushmerick, Steve Hanks, and Daniel Weld. </author> <title> An algorithm for probabilistic planning. </title> <type> Technical Report 93-06-03, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Most of the previous work on probabilistic planning has not paid much attention to planning heuristics. Kushmerick, Hanks and Weld briefly discuss the possibility of using information from the plan evaluator to guide the search in <ref> [5] </ref>, but do not mention specific heuristics. Goldman and Boddy discuss expanding the plan node with highest probability in their *-safe planners [4]. There are interesting relations between this work and machine learning research on boosting learning algorithms [10].
Reference: [6] <author> Nicholas Kushmerick, Steve Hanks, and Daniel Weld. </author> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proc. Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1073-1078. </pages> <publisher> AAAI Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Probabilistic planners that use classical back-chaining algorithms, such as <ref> [6, 1, 4, 7] </ref>, extend the range of problems addressable by classical AI planners to include uncertainty, which might be present in the initial state, in the outcomes of actions and in external events in the domain, using representations based on probability theory. <p> The next section provides a formal description of planning under uncertainty that is used to motivate and explain the footprint principle, and the related coherence principle. The following two sections show examples of heuristics derived with the footprint principle for two different probabilistic planners, Buridan <ref> [6] </ref> and Weaver [1]. Finally I argue that planners should be based on more compact representations of uncertainty than either Buridan or Weaver are currently, one which will more naturally deal with sets of states. <p> It is likely that such planners will make more use of the coherence and footprint principles than do present planners. 2 Uncertain planning and the footprint principle I begin with a formal description of planning under uncertainty, similar to <ref> [6] </ref> that is used to discuss the coherence and footprint heuristics and describe the different algorithms. 2.1 Description of planning under uncertainty A planning domain is defined by a state space, W, and a set of actions A that map a state to a probability distribution over W. <p> Alternatively, these refinements can be viewed as having a high-probability footprint, conditional on the original plan failing. 3 Case study: Buridan 3.1 Buridan's algorithm and a worked example Buridan <ref> [6] </ref> is based on the causal-link planner SNLP [8], and searches the space of possible plans. Actions in Buridan follow the representation described in section 2.1, with a tree of effect distributions. <p> The linked action is ordered before a i in the partial order. 2. Specialise the partial order to resolve a threat, as in SNLP 3. Confront a threat by planning to reduce the probability of the threatening effect taking place. More details about Buridan's algorithm can be found in <ref> [6] </ref>. The following example shows how Buridan works and is also used to describe a heuristic for Buridan's planner based on the footprint principle. The actions are defined as shown in example, A has three triggers, p, :p ^ q and :p ^ :q.
Reference: [7] <author> Todd Michael Mansell. </author> <title> A method for planning given uncertain and incomplete information. </title> <editor> In David Heckerman and Abe Mamdani, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> volume 9, </volume> <pages> pages 350-358, </pages> <address> Washington, D.C., July 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1 Introduction Probabilistic planners that use classical back-chaining algorithms, such as <ref> [6, 1, 4, 7] </ref>, extend the range of problems addressable by classical AI planners to include uncertainty, which might be present in the initial state, in the outcomes of actions and in external events in the domain, using representations based on probability theory.
Reference: [8] <author> David McAllester and David Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 634-639. </pages> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference-contexts: Alternatively, these refinements can be viewed as having a high-probability footprint, conditional on the original plan failing. 3 Case study: Buridan 3.1 Buridan's algorithm and a worked example Buridan [6] is based on the causal-link planner SNLP <ref> [8] </ref>, and searches the space of possible plans. Actions in Buridan follow the representation described in section 2.1, with a tree of effect distributions.
Reference: [9] <author> Stuart Russell and Eric Wefald. </author> <title> Do the Right Thing. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The heuristics based on the footprint principle aim to increase the rate of convergence to a good plan, by choosing improvements to an existing plan that are more likely to significantly increase the probability of success. This is similar to the maximum expected utility approach of Russel and Wefald <ref> [9] </ref>. While the exact heuristics may differ between different planners, the underlying principles are unchanged, and they are explained in this section. I begin with two observations about the process of improving the probability of success of plans in uncertain domains. <p> They in turn can be viewed as attempts to maximise the expected utility of the refinement to the plan, in the spirit of Russel and Wefald <ref> [9] </ref>, under a neutral assumption of the relative difficulties of planning in the different parts of the state space. 3 This is the behaviour with depth-first search, and it can be avoided using a scheme based on depth-first iterative deepening.
Reference: [10] <author> Robert E. Schapire. </author> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 197-227, </pages> <year> 1990. </year>
Reference-contexts: Goldman and Boddy discuss expanding the plan node with highest probability in their *-safe planners [4]. There are interesting relations between this work and machine learning research on boosting learning algorithms <ref> [10] </ref>. Boosting essentially improves the performance of a learning algorithm by manipulating the probability distribution of learning examples to give a higher weight to those not covered by the algorithm's current output, a similar approach to the Bayesian view of the footprint principle.
References-found: 10

