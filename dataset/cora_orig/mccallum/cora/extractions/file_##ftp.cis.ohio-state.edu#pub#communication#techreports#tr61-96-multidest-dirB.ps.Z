URL: file://ftp.cis.ohio-state.edu/pub/communication/techreports/tr61-96-multidest-dirB.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/wormhole_pub.html
Root-URL: 
Title: Efficient Schemes for Limited Directory-Based DSMs Using Multidestination Message Passing  
Abstract: Donglai Dai and Dhabaleswar K. Panda Technical Report OSU-CISRC-11/96-TR61 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, R. Simoni, J. Hennesy, and M. Horowitz. </author> <title> An Evaluation of Directory Schemes for Cache Coherence. </title> <booktitle> In Proceedings of the 15th Int'l Symposium on Computer Architecture, </booktitle> <year> 1988. </year>
Reference-contexts: Using less number of messages in case of directory overflow is critical to system performance. Otherwise, both network traffic and node occupancy [14] increases. This gets translated into increased write-latency. and overall performance degradation. Examples of some limited-directory schemes are: coarse-vector [18], Limitless [22], Superset <ref> [1] </ref>, and Eviction [6]. These schemes use either hardware or software mechanisms to detect and manage directory overflow. It is to be noted that all the above directory schemes have been designed and evaluated with networks having only point-to-point (unicast) message passing capability. <p> However, the amount of memory overhead for maintaining the fully-mapped directory is quite high. Thus, this scheme is only suitable for small or medium-sized systems. In order to have reduced overhead for maintaining the directory, many limited pointer schemes have been proposed in the literature <ref> [18, 22, 1, 6] </ref>. These schemes typically contain a small number (i) of pointers for any given memory block. When a memory block is cached by no more than i processing nodes at a given time, the scheme behaves exactly the same as that of the fully-mapped scheme. <p> Earlier research [18] has shown that for a medium sized DSM system using 3-4 pointers per directory entry, the dir i CV r scheme can perform reasonable well compared to the fully-mapped scheme. Several other limited directory schemes have been proposed in the literature. These include Limitless [22], Superset <ref> [1] </ref>, Eviction [6], and Dynamic-vector [28]. Our main objective in this paper is to demonstrate how efficient limited directory schemes can be designed by taking advantage of multidestination message passing support from underlying network. <p> Some representative ones are eviction [6], superset <ref> [1] </ref>, gray-code [29], and dynamic-vector [28]. The dir i N B [6] scheme tries to completely avoid any invalidation broadcast by evicting an existing sharing node under pointer overflow. The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. <p> Some representative ones are eviction [6], superset <ref> [1] </ref>, gray-code [29], and dynamic-vector [28]. The dir i N B [6] scheme tries to completely avoid any invalidation broadcast by evicting an existing sharing node under pointer overflow. The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. A variation known as gray-code scheme [29] optimizes the superset scheme for near-neighbor sharing.
Reference: [2] <author> C. Amza, A. L. Cox, and et al. Treadmarks: </author> <title> Shared memory computing on networks of workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: In this paper, we 26 27 have focused only on hardware assisted limited directories. The concepts can also be extended to the software assisted schemes. Besides hardware cache coherency, much research has been done for complete software DSM systems <ref> [24, 2] </ref>. Here the emphasis has been on avoiding false sharing as well as reducing coherence traffic. For networks supporting multicasting capability, our proposed schemes can also be used for reducing coherence traffic.
Reference: [3] <author> ATM Forum. </author> <title> ATM User-Network Interface Specification, </title> <note> Version 3.1, </note> <month> September </month> <year> 1994. </year>
Reference-contexts: This leads to an interesting problem: can efficient and cost-effective directory schemes can be designed for DSM systems by taking advantage of the support available on new generation networks to implement fast broadcast/multicast and reduction? Many networks currently provide hardware support for fast broadcast/multicast. Examples include ATM switch-based interconnection <ref> [3] </ref>, Meiko CS-2 [5], and NEC Cenju [21]. Unlike the CM-5 system [36], these networks do not have a separate control network and they support broadcast/multicast in the data network.
Reference: [4] <author> M. Banikazemi and D. K. Panda. </author> <title> Efficient Scatter Communication in Wormhole k-ary n cubes with Multidestination Message Passing. </title> <type> Technical Report OSU-CISRC-9/96-TR46, </type> <institution> The Ohio State Univeristy, </institution> <year> 1996. </year>
Reference-contexts: Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction [32], and scatter <ref> [4] </ref>. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in [34, 7].
Reference: [5] <author> J. Beecroft, M. Homewood, and M. McLaren. </author> <title> Meiko CS-2 Interconnect Elan-Elite Design. </title> <journal> Parallel Computing, </journal> <volume> 20 </volume> <pages> 1627-1638, </pages> <month> Nov </month> <year> 1994. </year>
Reference-contexts: Examples include ATM switch-based interconnection [3], Meiko CS-2 <ref> [5] </ref>, and NEC Cenju [21]. Unlike the CM-5 system [36], these networks do not have a separate control network and they support broadcast/multicast in the data network.
Reference: [6] <author> M. Censier and P. Feautier. </author> <title> A New Solution to Coherence Problems in Multicache Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 27 </volume> <pages> 1112-1118, </pages> <month> December </month> <year> 1978. </year>
Reference-contexts: Using less number of messages in case of directory overflow is critical to system performance. Otherwise, both network traffic and node occupancy [14] increases. This gets translated into increased write-latency. and overall performance degradation. Examples of some limited-directory schemes are: coarse-vector [18], Limitless [22], Superset [1], and Eviction <ref> [6] </ref>. These schemes use either hardware or software mechanisms to detect and manage directory overflow. It is to be noted that all the above directory schemes have been designed and evaluated with networks having only point-to-point (unicast) message passing capability. <p> However, the amount of memory overhead for maintaining the fully-mapped directory is quite high. Thus, this scheme is only suitable for small or medium-sized systems. In order to have reduced overhead for maintaining the directory, many limited pointer schemes have been proposed in the literature <ref> [18, 22, 1, 6] </ref>. These schemes typically contain a small number (i) of pointers for any given memory block. When a memory block is cached by no more than i processing nodes at a given time, the scheme behaves exactly the same as that of the fully-mapped scheme. <p> Several other limited directory schemes have been proposed in the literature. These include Limitless [22], Superset [1], Eviction <ref> [6] </ref>, and Dynamic-vector [28]. Our main objective in this paper is to demonstrate how efficient limited directory schemes can be designed by taking advantage of multidestination message passing support from underlying network. <p> These trends suggests that future generation systems can take advantage of multidestination message passing with less number of pointers (even 1) to build scalable and cost-effective DSM systems. 6 Related Work A number of other limited directory schemes have been proposed in the literature. Some representative ones are eviction <ref> [6] </ref>, superset [1], gray-code [29], and dynamic-vector [28]. The dir i N B [6] scheme tries to completely avoid any invalidation broadcast by evicting an existing sharing node under pointer overflow. The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. <p> Some representative ones are eviction <ref> [6] </ref>, superset [1], gray-code [29], and dynamic-vector [28]. The dir i N B [6] scheme tries to completely avoid any invalidation broadcast by evicting an existing sharing node under pointer overflow. The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. A variation known as gray-code scheme [29] optimizes the superset scheme for near-neighbor sharing.
Reference: [7] <author> C.-M. Chiang and L. M. Ni. </author> <title> Deadlock-Free Multi-Head Wormhole Routing. </title> <booktitle> In Proceedings of the First High Performance Computing-Asia, </booktitle> <year> 1995. </year>
Reference-contexts: Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction [32], and scatter [4]. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in <ref> [34, 7] </ref>.
Reference: [8] <author> A. A. Chien and J. H. Kim. </author> <title> Planar-Adaptive Routing: Low-Cost Adaptive Networks for Multiprocessors. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 268-277, </pages> <year> 1992. </year>
Reference-contexts: For the rest of the paper, we focus on 2D k fi k mesh DSM systems with e-cube base routing. However, the proposed variations are general and can be equally applied to other k-ary n-cube topologies (3D and higher dimensional meshes/tori) and other routing schemes (planar <ref> [8] </ref>, fully-adaptive [13], and turn-model [17]). 4.1 Enhanced Broadcast Scheme (m dir i B) This scheme is similar to the dir i B scheme previously discussed in section 2 except that the invalidation broadcasts and acknowledgment collections are handled using multidestination DSM mechanisms.
Reference: [9] <institution> Convex Computer Corporation. Convex SPP 1000 System Overview, </institution> <year> 1994. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems are the current trend in building high-performance computing systems <ref> [19, 22, 9] </ref>. These systems use directory-based protocols to enforce cache coherence. Due to the large amount of storage required by a fully-mapped directory scheme [15, 35], many cost-effective limited directory schemes using less amount of storage have been proposed in the literature.
Reference: [10] <author> D. Dai and D. K. Panda. </author> <title> Reducing Cache Invalidation Overheads in Wormhole DSMs Using Multidestination Message Passing. </title> <booktitle> In International Conference on Parallel Processing, pages I:138-145, </booktitle> <address> Chicago, IL, </address> <month> Aug </month> <year> 1996. </year>
Reference-contexts: For wormhole meshes with multidesti-nation message-passing, it has been shown <ref> [10] </ref> that the performance of SPLASH2 applications 1 [16] using fully-mapped directory schemes can be improved up to 10-15% using multidestination--based multicast and reduction. <p> Next, we show how it can be used to implement fast invalidation and acknowledgment collection in a DSM system with fully-mapped directory organization <ref> [10, 11] </ref>. 3.1 Basic Concept of Multidestination Message Passing Originally, the multidestination message passing mechanism was proposed for interconnection networks used in distributed memory parallel systems [31, 32, 33]. Traditional wormhole-routed systems have supported only point-to-point (unicast) message passing mechanism. <p> Sending invalidation messages from home node to the sharers is nothing but a multicast communication pattern. Similarly, collection of acknowledgment from sharers is a reduction operation. Since multidestination message passing allows fast multicast and reduction operations, it has been demonstrated in <ref> [10] </ref> how they can be used to provide performance benefits for DSM systems with fully-mapped directories. In this section, we briefly describe the operational principles behind applying multidesti-nation message passing to such DSM systems. Detailed description of these principles can be obtained from [10, 11]. <p> In this section, we briefly describe the operational principles behind applying multidesti-nation message passing to such DSM systems. Detailed description of these principles can be obtained from <ref> [10, 11] </ref>. Two types of multidestination worms, multicast and gather, are used in these systems. <p> For adaptive routed systems, depending on the adaptivity, less than 2k worms can be used to cover all nodes. Thus, multidestination multicast worms have capability to significantly reduce network traffic as well as home node occupancy for sending invalidation messages to sharers <ref> [10] </ref>. It has also been shown in [10] that a column-oriented directory organization can significantly reduce the overhead of grouping and generating multidestination worms. <p> For adaptive routed systems, depending on the adaptivity, less than 2k worms can be used to cover all nodes. Thus, multidestination multicast worms have capability to significantly reduce network traffic as well as home node occupancy for sending invalidation messages to sharers <ref> [10] </ref>. It has also been shown in [10] that a column-oriented directory organization can significantly reduce the overhead of grouping and generating multidestination worms. <p> The gather worm is used for collecting invalidation acknowledgments (ack) from the sharers in a cumulative manner. Since each multidestination gather worm can collect acks from multiple nodes, it reduces the number of messages required for the acknowledgment phase of a cache coherency protocol <ref> [10] </ref>. 3.5 I-ack Buffers and the Complete Picture Even though multidestination multicast and gather worms are quite powerful for distributing and collecting acknowledgment signals, it is a challenge to make them work together to implement cache coherency with reduced latency. <p> This has potential to increase the ack-collection latency considerably, defeating the purpose of multidestination message passing. To alleviate such bottlenecks and to facilitate fast collection of invalidation signals, each router interface is equipped with a small (2-4) number of buffers, known as i-ack buffers <ref> [10] </ref>. A multidestination-based multicast worm, as it proceeds through the router interface of the sharers, drops a copy of the invalidation message at each sharer. <p> If a multicast worm is able to reserve an i-ack buffer at the router interface it is known as i-ack hit; otherwise it is known as i-ack miss <ref> [10] </ref>. It is shown in [10] that 2-4 i-ack buffers are sufficient to provide around 98% i-ack hit. Thus, a gather worm collects acknowledgment signals from all sharers where i-ack hit occurs. The last sharer of a gather worm sends back this count to the home node. <p> If a multicast worm is able to reserve an i-ack buffer at the router interface it is known as i-ack hit; otherwise it is known as i-ack miss <ref> [10] </ref>. It is shown in [10] that 2-4 i-ack buffers are sufficient to provide around 98% i-ack hit. Thus, a gather worm collects acknowledgment signals from all sharers where i-ack hit occurs. The last sharer of a gather worm sends back this count to the home node. <p> Thus, for any invalidation, the home node receives appropriate number of ack signals from the sharers. Fig. 1 shows the organization of the router interface to support i-ack buffers. More detailed description of the router interface and the operational principles of multicast and gather worms can be obtained from <ref> [10, 11] </ref>. In these papers, such architectural support has been provided for systems with fully-mapped directories.
Reference: [11] <author> Donglai Dai and D. K. Panda. </author> <title> Reducing Cache Invalidation Overheads in Wormhole Routed DSMs Using Multidestination Message Passing. </title> <type> Technical Report OSU-CISRC-4/96-TR24, </type> <institution> Dept. of Computer and Information Science, The Ohio State University, </institution> <month> Apr </month> <year> 1996. </year>
Reference-contexts: Next, we show how it can be used to implement fast invalidation and acknowledgment collection in a DSM system with fully-mapped directory organization <ref> [10, 11] </ref>. 3.1 Basic Concept of Multidestination Message Passing Originally, the multidestination message passing mechanism was proposed for interconnection networks used in distributed memory parallel systems [31, 32, 33]. Traditional wormhole-routed systems have supported only point-to-point (unicast) message passing mechanism. <p> In this section, we briefly describe the operational principles behind applying multidesti-nation message passing to such DSM systems. Detailed description of these principles can be obtained from <ref> [10, 11] </ref>. Two types of multidestination worms, multicast and gather, are used in these systems. <p> Thus, for any invalidation, the home node receives appropriate number of ack signals from the sharers. Fig. 1 shows the organization of the router interface to support i-ack buffers. More detailed description of the router interface and the operational principles of multicast and gather worms can be obtained from <ref> [10, 11] </ref>. In these papers, such architectural support has been provided for systems with fully-mapped directories.
Reference: [12] <author> W. J. Dally and C. L. Seitz. </author> <title> Deadlock-Free Message Routing in Multiprocessor Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 547-553, </pages> <month> May </month> <year> 1987. </year> <month> 29 </month>
Reference-contexts: Examples include ATM switch-based interconnection [3], Meiko CS-2 [5], and NEC Cenju [21]. Unlike the CM-5 system [36], these networks do not have a separate control network and they support broadcast/multicast in the data network. For networks supporting wormhole switching <ref> [12] </ref>, there has been a lot of research recently to provide architectural and communication support for implementing fast collective communication operations. One such effort is providing multidestination message-passing mechanism [25, 33] on the data network.
Reference: [13] <author> J. Duato. </author> <title> A New Theory of Deadlock-Free Adaptive Routing in Wormhole Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(12) </volume> <pages> 1320-1331, </pages> <year> 1993. </year>
Reference-contexts: For the rest of the paper, we focus on 2D k fi k mesh DSM systems with e-cube base routing. However, the proposed variations are general and can be equally applied to other k-ary n-cube topologies (3D and higher dimensional meshes/tori) and other routing schemes (planar [8], fully-adaptive <ref> [13] </ref>, and turn-model [17]). 4.1 Enhanced Broadcast Scheme (m dir i B) This scheme is similar to the dir i B scheme previously discussed in section 2 except that the invalidation broadcasts and acknowledgment collections are handled using multidestination DSM mechanisms.
Reference: [14] <author> C. Holt et al. </author> <title> The Effects of Latency, Occupancy, and Bandwidth in Distributed Shared Memory Multiprocessors. </title> <type> Technical Report CSL-TR-95-660, </type> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: The basic idea behind limited directory schemes is to handle invalidations in an intelligent manner when the directory overflow occurs. Using less number of messages in case of directory overflow is critical to system performance. Otherwise, both network traffic and node occupancy <ref> [14] </ref> increases. This gets translated into increased write-latency. and overall performance degradation. Examples of some limited-directory schemes are: coarse-vector [18], Limitless [22], Superset [1], and Eviction [6]. These schemes use either hardware or software mechanisms to detect and manage directory overflow. <p> In general, 2 (k 2 1) messages with k 2 communication steps (best case) are required for a k fi k mesh using the u dir i B scheme. Let us compare the home node occupancy <ref> [14] </ref> between these two schemes. It can be observed that a home node in u dir i B scheme requires handling of 2 (k 2 1) unicast messages. In m dir i B scheme, it needs to handle only (k + 2) messages.
Reference: [15] <author> D. Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems are the current trend in building high-performance computing systems [19, 22, 9]. These systems use directory-based protocols to enforce cache coherence. Due to the large amount of storage required by a fully-mapped directory scheme <ref> [15, 35] </ref>, many cost-effective limited directory schemes using less amount of storage have been proposed in the literature. The basic idea behind limited directory schemes is to handle invalidations in an intelligent manner when the directory overflow occurs.
Reference: [16] <author> S. C. Woo et al. </author> <title> The SPLASH-2 Programs: Chracterization and Methodological Considerations. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <year> 1995. </year>
Reference-contexts: For wormhole meshes with multidesti-nation message-passing, it has been shown [10] that the performance of SPLASH2 applications 1 <ref> [16] </ref> using fully-mapped directory schemes can be improved up to 10-15% using multidestination--based multicast and reduction. Since fully-mapped directories are not practical for larger size systems, in this paper, we take on the challenging problem of deriving efficient limited directory schemes under multidestination message-passing. <p> We propose an efficient two-level broadcast scheme with multidestination messages and evaluate different dir i B schemes, 1 i 3. Simulation-based evaluations are done for two different system sizes (4 fi 8 and 8 fi 8) and four different applications from the SPLASH2 benchmark <ref> [16] </ref>. The simulations consider detailed instruction count for computational steps, detailed network behavior including flit-level link contention and network interface contention for message passing steps, and synchronization overheads. <p> For multidestination-based messages, this overhead was assumed to be 15 clock cycles. Table 2 lists all system parameters used in our simulation. We considered four different applications, ported to our simulator from the Stanford SPLASH2 benchmark suite <ref> [16] </ref>. The characteristics of these applications are listed in Table 3. 5.2 Simulation Results For each experiment, we observed five important parameters: total number of invalidation messages (including messages for acknowledgment collection), total number of network messages, average latency per invalidation, average latency per write operation, and overall execution time.
Reference: [17] <author> C. J. Glass and L. Ni. </author> <title> The Turn Model for Adaptive Routing. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 278-287, </pages> <year> 1992. </year>
Reference-contexts: However, the proposed variations are general and can be equally applied to other k-ary n-cube topologies (3D and higher dimensional meshes/tori) and other routing schemes (planar [8], fully-adaptive [13], and turn-model <ref> [17] </ref>). 4.1 Enhanced Broadcast Scheme (m dir i B) This scheme is similar to the dir i B scheme previously discussed in section 2 except that the invalidation broadcasts and acknowledgment collections are handled using multidestination DSM mechanisms.
Reference: [18] <author> A. Gupta, W.-D. Weber, and T. Mowry. </author> <title> Reducing Memory and Traffic Requirements for Scalable Directory-Based Cache Coherence Schemes. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages I:312-321, </pages> <month> Aug </month> <year> 1990. </year>
Reference-contexts: Using less number of messages in case of directory overflow is critical to system performance. Otherwise, both network traffic and node occupancy [14] increases. This gets translated into increased write-latency. and overall performance degradation. Examples of some limited-directory schemes are: coarse-vector <ref> [18] </ref>, Limitless [22], Superset [1], and Eviction [6]. These schemes use either hardware or software mechanisms to detect and manage directory overflow. It is to be noted that all the above directory schemes have been designed and evaluated with networks having only point-to-point (unicast) message passing capability. <p> However, on systems supporting only unicast message passing, such broadcast requires a large number of message transfers in the system and it quickly leads to performance degradation. Thus, researchers have proposed non-broadcast-based schemes like coarse-vector (dir i CV r ) <ref> [18] </ref>. In this scheme, when directory overflow occurs, the storage space for i entries are reorganized and used as region bits. During invalidation, such region bits help in significantly reducing the number of messages needed to be sent to nodes with possible sharers. <p> However, the amount of memory overhead for maintaining the fully-mapped directory is quite high. Thus, this scheme is only suitable for small or medium-sized systems. In order to have reduced overhead for maintaining the directory, many limited pointer schemes have been proposed in the literature <ref> [18, 22, 1, 6] </ref>. These schemes typically contain a small number (i) of pointers for any given memory block. When a memory block is cached by no more than i processing nodes at a given time, the scheme behaves exactly the same as that of the fully-mapped scheme. <p> This dir i B scheme performs poorly if the typical degree of sharing in an application is just larger than i. However, this scheme is advantageous due to its simplicity and low cost of implementation. 2.3 Coarse Vector Scheme (dir i CV r ) In the coarse vector scheme <ref> [18] </ref>, when pointer overflow occurs, the memory used for storing the pointers is reorganized to store a coarse bit vector. Each bit in this vector represents a predefined fixed region consisting of r processing nodes. <p> The value of r is typically determined by the number of bits available in a directory entry. The coarse vector scheme results in some extra invalidation traffic. However, such extra invalidations can be kept to a minimum by using regions with fewer nodes. Earlier research <ref> [18] </ref> has shown that for a medium sized DSM system using 3-4 pointers per directory entry, the dir i CV r scheme can perform reasonable well compared to the fully-mapped scheme. Several other limited directory schemes have been proposed in the literature. <p> The main idea is to use multidestination messages to send the invalidations and collect the acknowledgments as required by the coherence protocols. First we show a variation of the dir i B scheme. Next, we show how the coarse vector scheme (dir i CV r ) <ref> [18] </ref> can be enhanced. For the rest of the paper, we focus on 2D k fi k mesh DSM systems with e-cube base routing.
Reference: [19] <author> M. Heinrich, J. Kuskin, and Others. </author> <title> The performance impact of flexibility in the stanford flash multiprocessor. </title> <booktitle> In The sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems are the current trend in building high-performance computing systems <ref> [19, 22, 9] </ref>. These systems use directory-based protocols to enforce cache coherence. Due to the large amount of storage required by a fully-mapped directory scheme [15, 35], many cost-effective limited directory schemes using less amount of storage have been proposed in the literature.
Reference: [20] <author> R. Kesavan and D. K. Panda. </author> <title> Minimizing Node Contention in Multiple Multicast on Wormhole k-ary n-cube Networks. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, pages I:188-195, </booktitle> <address> Chicago, IL, </address> <month> Aug </month> <year> 1996. </year>
Reference-contexts: Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast <ref> [20] </ref>, barrier synchronization [30], reduction [32], and scatter [4]. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in [34, 7].
Reference: [21] <author> N. Koike. </author> <title> NEC Cenju-3: A Microprocessor-based Parallel Computer. </title> <booktitle> In Proceedings of the 8th Int'l Parallel Processing Symposium, </booktitle> <pages> pages 396-401, </pages> <year> 1994. </year>
Reference-contexts: Examples include ATM switch-based interconnection [3], Meiko CS-2 [5], and NEC Cenju <ref> [21] </ref>. Unlike the CM-5 system [36], these networks do not have a separate control network and they support broadcast/multicast in the data network. For networks supporting wormhole switching [12], there has been a lot of research recently to provide architectural and communication support for implementing fast collective communication operations.
Reference: [22] <author> David Kranz, Kirk Johnson, Anant Agrawal, John Kubiatowicz, and Beng-Hom Lim. </author> <title> Integrating Message-Passing and Shared Memory: Early Experience. </title> <booktitle> In Proceedings of Practice and Principle of Parallel Programming. ACM, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems are the current trend in building high-performance computing systems <ref> [19, 22, 9] </ref>. These systems use directory-based protocols to enforce cache coherence. Due to the large amount of storage required by a fully-mapped directory scheme [15, 35], many cost-effective limited directory schemes using less amount of storage have been proposed in the literature. <p> Using less number of messages in case of directory overflow is critical to system performance. Otherwise, both network traffic and node occupancy [14] increases. This gets translated into increased write-latency. and overall performance degradation. Examples of some limited-directory schemes are: coarse-vector [18], Limitless <ref> [22] </ref>, Superset [1], and Eviction [6]. These schemes use either hardware or software mechanisms to detect and manage directory overflow. It is to be noted that all the above directory schemes have been designed and evaluated with networks having only point-to-point (unicast) message passing capability. <p> However, the amount of memory overhead for maintaining the fully-mapped directory is quite high. Thus, this scheme is only suitable for small or medium-sized systems. In order to have reduced overhead for maintaining the directory, many limited pointer schemes have been proposed in the literature <ref> [18, 22, 1, 6] </ref>. These schemes typically contain a small number (i) of pointers for any given memory block. When a memory block is cached by no more than i processing nodes at a given time, the scheme behaves exactly the same as that of the fully-mapped scheme. <p> Earlier research [18] has shown that for a medium sized DSM system using 3-4 pointers per directory entry, the dir i CV r scheme can perform reasonable well compared to the fully-mapped scheme. Several other limited directory schemes have been proposed in the literature. These include Limitless <ref> [22] </ref>, Superset [1], Eviction [6], and Dynamic-vector [28]. Our main objective in this paper is to demonstrate how efficient limited directory schemes can be designed by taking advantage of multidestination message passing support from underlying network. <p> The resulting complexity and performance gain can vary from one scheme to another depending on how well the multidestination messages are used in the schemes. In addition to the hardware schemes discussed so far, there are some interesting software assisted limited directory schemes, like LimitLESS scheme <ref> [22] </ref> and dir 1 SW + [37]. The main focus of such schemes is to use the existing hardware as effectively as possible to cope with lower sharing degrees and to deal with larger sharing degrees through software.
Reference: [23] <author> A. Kumar, P. Mannava, and L. N. Bhuyan. </author> <title> Efficient and Scalable Cache Coherence Schemes for Shared Memory Hypercube Multiprocessors. </title> <booktitle> In Supercomputing, </booktitle> <year> 1994. </year>
Reference-contexts: For networks supporting multicasting capability, our proposed schemes can also be used for reducing coherence traffic. In the context of evaluating cache-coherence protocols together with network behavior, Bhuyan et al have recently proposed novel schemes <ref> [23, 26] </ref>. They have shown that a single invalidation message with implicit multiple destinations along hierarchical rings, statically defined using embedded virtual channels on a hypercube machine, can be used to broadcast invalidation messages quickly. A distributed hierarchical directory organization/protocol is cleverly used in the proposed scheme.
Reference: [24] <author> K. Li and P. Hudak. </author> <title> Memory Coherence in Shared Virtual Memory Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <month> November </month> <year> 1989. </year>
Reference-contexts: In this paper, we 26 27 have focused only on hardware assisted limited directories. The concepts can also be extended to the software assisted schemes. Besides hardware cache coherency, much research has been done for complete software DSM systems <ref> [24, 2] </ref>. Here the emphasis has been on avoiding false sharing as well as reducing coherence traffic. For networks supporting multicasting capability, our proposed schemes can also be used for reducing coherence traffic.
Reference: [25] <author> X. Lin and L. M. Ni. </author> <title> Deadlock-free Multicast Wormhole Routing in Multicomputer Networks. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 116-124, </pages> <year> 1991. </year>
Reference-contexts: For networks supporting wormhole switching [12], there has been a lot of research recently to provide architectural and communication support for implementing fast collective communication operations. One such effort is providing multidestination message-passing mechanism <ref> [25, 33] </ref> on the data network. Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction [32], <p> One such effort is providing multidestination message-passing mechanism <ref> [25, 33] </ref> on the data network. Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction [32], and scatter [4]. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in [34, 7]. <p> This mechanism allows a worm (message) to have exactly one destination. This leads to a significant amount of overhead to implement collective communication operations (like broadcast, multicast, reduction, synchronization, etc.). In order to implement such operations with reduced latency, a new multidestination message passing mechanism has been recently proposed <ref> [25, 33] </ref>. This mechanism allows a worm (message) to have multiple destinations. This capability helps a message to distribute information to several nodes or gather information from several nodes with a single message passing step. Originally, this mechanism was proposed for wormhole systems with Hamiltonian routing [25]. <p> This mechanism allows a worm (message) to have multiple destinations. This capability helps a message to distribute information to several nodes or gather information from several nodes with a single message passing step. Originally, this mechanism was proposed for wormhole systems with Hamiltonian routing <ref> [25] </ref>. Later, it has been generalized to e-cube and other adaptive wormhole systems [33]. This mechanism has been used in k-ary n-cube wormhole networks to support fast broadcast/multicast [33], barrier synchronization [30], and global reduction [32]. It has also been used to demonstrate fast multicast/broadcast on MINs [34].
Reference: [26] <author> P. Mannava, A. Kumar, and L. N. Bhuyan. </author> <title> An Efficient Implementation of Limted Directory Cache Coherence Schemes for Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the Fifth Workshop on Scalable Shared Memory Multiprocessors, Int'l Symposium on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: For networks supporting multicasting capability, our proposed schemes can also be used for reducing coherence traffic. In the context of evaluating cache-coherence protocols together with network behavior, Bhuyan et al have recently proposed novel schemes <ref> [23, 26] </ref>. They have shown that a single invalidation message with implicit multiple destinations along hierarchical rings, statically defined using embedded virtual channels on a hypercube machine, can be used to broadcast invalidation messages quickly. A distributed hierarchical directory organization/protocol is cleverly used in the proposed scheme.
Reference: [27] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> Mar </month> <year> 1994. </year>
Reference-contexts: In recent years, significant advancement has taken place in the designing of high performance interconnection networks. Many networks are trying to provide cost-effective architectural support to implement collective communication operations, as defined by the MPI standard <ref> [27] </ref>. Such collective communication operations include broadcast, multicast, reduction, synchronization, etc. In the context of the DSM paradigm, cache-invalidation broadcast/multicast operations are nothing but broadcast/multicast messages from the home node to the sharers. Similarly, reduction operation is equivalent to collection of acknowledgment signals from the sharers after invalidation.
Reference: [28] <author> W. Michael. </author> <title> A Scalable Coherent Cache System with A Dynamic Pointing Scheme. </title> <booktitle> In Proceedings of the Supercomputing, </booktitle> <pages> pages 358-367, </pages> <year> 1992. </year>
Reference-contexts: Several other limited directory schemes have been proposed in the literature. These include Limitless [22], Superset [1], Eviction [6], and Dynamic-vector <ref> [28] </ref>. Our main objective in this paper is to demonstrate how efficient limited directory schemes can be designed by taking advantage of multidestination message passing support from underlying network. Thus, without loss of generality, we only consider two representative limited directory schemes (broadcast schemes and coarse-vector scheme) in this paper. <p> Some representative ones are eviction [6], superset [1], gray-code [29], and dynamic-vector <ref> [28] </ref>. The dir i N B [6] scheme tries to completely avoid any invalidation broadcast by evicting an existing sharing node under pointer overflow. The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. <p> The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. A variation known as gray-code scheme [29] optimizes the superset scheme for near-neighbor sharing. A dynamic-vector scheme (dir i DV r ) <ref> [28] </ref> optimizes the dir i CV r scheme by allowing the coarse vector granularity to vary dynamically according to the sharing pattern. All of the above schemes have been proposed in the context of unicast message-passing.
Reference: [29] <author> S. S. Mukherjee and M. D. Hill. </author> <title> An Evaluation of Directory Protocols for Medium-Scale Shared-Memory Multiprocessors. </title> <booktitle> In International Conference on Supercomputing (ISC), </booktitle> <pages> pages 64-74, </pages> <year> 1994. </year> <month> 30 </month>
Reference-contexts: Some representative ones are eviction [6], superset [1], gray-code <ref> [29] </ref>, and dynamic-vector [28]. The dir i N B [6] scheme tries to completely avoid any invalidation broadcast by evicting an existing sharing node under pointer overflow. The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. A variation known as gray-code scheme [29] optimizes <p> gray-code <ref> [29] </ref>, and dynamic-vector [28]. The dir i N B [6] scheme tries to completely avoid any invalidation broadcast by evicting an existing sharing node under pointer overflow. The superset scheme [1] allows tri-state information with each directory entry being 2 log P bits. A variation known as gray-code scheme [29] optimizes the superset scheme for near-neighbor sharing. A dynamic-vector scheme (dir i DV r ) [28] optimizes the dir i CV r scheme by allowing the coarse vector granularity to vary dynamically according to the sharing pattern.
Reference: [30] <author> D. K. Panda. </author> <title> Fast Barrier Synchronization in Wormhole k-ary n-cube Networks with Multidestination Worms. </title> <booktitle> In International Symposium on High Performance Computer Architecture, </booktitle> <pages> pages 200-209, </pages> <year> 1995. </year>
Reference-contexts: Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization <ref> [30] </ref>, reduction [32], and scatter [4]. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in [34, 7]. <p> Originally, this mechanism was proposed for wormhole systems with Hamiltonian routing [25]. Later, it has been generalized to e-cube and other adaptive wormhole systems [33]. This mechanism has been used in k-ary n-cube wormhole networks to support fast broadcast/multicast [33], barrier synchronization <ref> [30] </ref>, and global reduction [32]. It has also been used to demonstrate fast multicast/broadcast on MINs [34].
Reference: [31] <author> D. K. Panda. </author> <title> Fast Barrier Synchronization in Wormhole k-ary n-cube Networks with Multidestination Worms. </title> <journal> Future Generation Computer Systems, </journal> <volume> 11 </volume> <pages> 585-602, </pages> <month> Nov </month> <year> 1995. </year>
Reference-contexts: Next, we show how it can be used to implement fast invalidation and acknowledgment collection in a DSM system with fully-mapped directory organization [10, 11]. 3.1 Basic Concept of Multidestination Message Passing Originally, the multidestination message passing mechanism was proposed for interconnection networks used in distributed memory parallel systems <ref> [31, 32, 33] </ref>. Traditional wormhole-routed systems have supported only point-to-point (unicast) message passing mechanism. This mechanism allows a worm (message) to have exactly one destination. This leads to a significant amount of overhead to implement collective communication operations (like broadcast, multicast, reduction, synchronization, etc.).
Reference: [32] <author> D. K. Panda. </author> <title> Global Reduction in Wormhole k-ary n-cube Networks with Multidestination Exchange Worms. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <pages> pages 652-659, </pages> <month> Apr </month> <year> 1995. </year>
Reference-contexts: Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction <ref> [32] </ref>, and scatter [4]. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in [34, 7]. <p> Next, we show how it can be used to implement fast invalidation and acknowledgment collection in a DSM system with fully-mapped directory organization [10, 11]. 3.1 Basic Concept of Multidestination Message Passing Originally, the multidestination message passing mechanism was proposed for interconnection networks used in distributed memory parallel systems <ref> [31, 32, 33] </ref>. Traditional wormhole-routed systems have supported only point-to-point (unicast) message passing mechanism. This mechanism allows a worm (message) to have exactly one destination. This leads to a significant amount of overhead to implement collective communication operations (like broadcast, multicast, reduction, synchronization, etc.). <p> Originally, this mechanism was proposed for wormhole systems with Hamiltonian routing [25]. Later, it has been generalized to e-cube and other adaptive wormhole systems [33]. This mechanism has been used in k-ary n-cube wormhole networks to support fast broadcast/multicast [33], barrier synchronization [30], and global reduction <ref> [32] </ref>. It has also been used to demonstrate fast multicast/broadcast on MINs [34].
Reference: [33] <author> D. K. Panda, S. Singal, and P. Prabhakaran. </author> <title> Multidestination Message Passing Mechanism Conforming to Base Wormhole Routing Scheme. </title> <booktitle> In Proceedings of the Parallel Computer Routing and Communication Workshop, </booktitle> <pages> pages 131-145, </pages> <year> 1994. </year>
Reference-contexts: For networks supporting wormhole switching [12], there has been a lot of research recently to provide architectural and communication support for implementing fast collective communication operations. One such effort is providing multidestination message-passing mechanism <ref> [25, 33] </ref> on the data network. Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction [32], <p> One such effort is providing multidestination message-passing mechanism <ref> [25, 33] </ref> on the data network. Using this mechanism it has been shown that many collective communication operations can be implemented with significantly reduced latency compared to implementations with unicast message-passing. Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction [32], and scatter [4]. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in [34, 7]. <p> Next, we show how it can be used to implement fast invalidation and acknowledgment collection in a DSM system with fully-mapped directory organization [10, 11]. 3.1 Basic Concept of Multidestination Message Passing Originally, the multidestination message passing mechanism was proposed for interconnection networks used in distributed memory parallel systems <ref> [31, 32, 33] </ref>. Traditional wormhole-routed systems have supported only point-to-point (unicast) message passing mechanism. This mechanism allows a worm (message) to have exactly one destination. This leads to a significant amount of overhead to implement collective communication operations (like broadcast, multicast, reduction, synchronization, etc.). <p> This mechanism allows a worm (message) to have exactly one destination. This leads to a significant amount of overhead to implement collective communication operations (like broadcast, multicast, reduction, synchronization, etc.). In order to implement such operations with reduced latency, a new multidestination message passing mechanism has been recently proposed <ref> [25, 33] </ref>. This mechanism allows a worm (message) to have multiple destinations. This capability helps a message to distribute information to several nodes or gather information from several nodes with a single message passing step. Originally, this mechanism was proposed for wormhole systems with Hamiltonian routing [25]. <p> This capability helps a message to distribute information to several nodes or gather information from several nodes with a single message passing step. Originally, this mechanism was proposed for wormhole systems with Hamiltonian routing [25]. Later, it has been generalized to e-cube and other adaptive wormhole systems <ref> [33] </ref>. This mechanism has been used in k-ary n-cube wormhole networks to support fast broadcast/multicast [33], barrier synchronization [30], and global reduction [32]. It has also been used to demonstrate fast multicast/broadcast on MINs [34]. <p> Originally, this mechanism was proposed for wormhole systems with Hamiltonian routing [25]. Later, it has been generalized to e-cube and other adaptive wormhole systems <ref> [33] </ref>. This mechanism has been used in k-ary n-cube wormhole networks to support fast broadcast/multicast [33], barrier synchronization [30], and global reduction [32]. It has also been used to demonstrate fast multicast/broadcast on MINs [34]. <p> During invalidation, instead of sending individual unicast messages to the sharers, multidestination messages can be used to cover them in less number of communication steps. Based on valid multidestination routing paths in a network <ref> [33] </ref>, the sharers can be grouped in order to be covered by multidestination multicast worms. For example, on an e-cube routed 2D mesh, a source node can group sharers along a column into two groups.
Reference: [34] <author> R. Sivaram, D. K. Panda, and C. B. Stunkel. </author> <title> Efficient Broadcast and Multicast on Multistage Interconnection Networks using Multiport Encoding. </title> <booktitle> In Proceedings of the Eighth IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 36-45, </pages> <month> Oct </month> <year> 1996. </year> <note> http://www.cis.ohio-state.edu/~panda/paper.html. </note>
Reference-contexts: Examples of such operations on k-ary n-cube networks include broadcast/multicast [25, 33], multiple multicast [20], barrier synchronization [30], reduction [32], and scatter [4]. Similarly, fast broadcast/multicast on MINs using multidestination message passing has been shown in <ref> [34, 7] </ref>. <p> Later, it has been generalized to e-cube and other adaptive wormhole systems [33]. This mechanism has been used in k-ary n-cube wormhole networks to support fast broadcast/multicast [33], barrier synchronization [30], and global reduction [32]. It has also been used to demonstrate fast multicast/broadcast on MINs <ref> [34] </ref>. It has also been shown in these papers that very little additional logic is required for the current generation routers (supporting unicast message passing) to incorporate multidestination message passing. 3.2 Applying Multidestination Message Passing to DSM Systems As mentioned earlier, inherent communication requirements for implementing cache coherency are two-fold.
Reference: [35] <author> Per Stenstrom. </author> <title> A survey of cache coherence schemes for multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 23(6) </volume> <pages> 12-24, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Distributed shared memory (DSM) systems are the current trend in building high-performance computing systems [19, 22, 9]. These systems use directory-based protocols to enforce cache coherence. Due to the large amount of storage required by a fully-mapped directory scheme <ref> [15, 35] </ref>, many cost-effective limited directory schemes using less amount of storage have been proposed in the literature. The basic idea behind limited directory schemes is to handle invalidations in an intelligent manner when the directory overflow occurs. <p> However, when a block is cached by more than i processing nodes, some mechanism is used to handle the pointer overflow <ref> [35] </ref>. For a system with P processing nodes, each pointer needs log P bits for identification of the sharing node of a block. Assuming B memory blocks per processing node, the total storage requirement for directories is (iP B log P ) bits. <p> There are two major classes of limited directory schemes. These are presented next. 2.2 Broadcast Scheme (dir i B) In this scheme, when pointer overflow occurs, a broadcast bit is set in the directory entry <ref> [35] </ref>. Subsequent reads to this block get the expected copy of the block leaving the associated directory entry state unchanged. The first write to the block after the pointer overflow triggers invalidations to be sent to all processing nodes in the system.
Reference: [36] <institution> Thinking Machine Corporation. </institution> <type> CM5 Technical Summary, </type> <year> 1991. </year>
Reference-contexts: Examples include ATM switch-based interconnection [3], Meiko CS-2 [5], and NEC Cenju [21]. Unlike the CM-5 system <ref> [36] </ref>, these networks do not have a separate control network and they support broadcast/multicast in the data network. For networks supporting wormhole switching [12], there has been a lot of research recently to provide architectural and communication support for implementing fast collective communication operations.
Reference: [37] <author> D. A. Wood, S. Chandra, B. Falsafi, M. D. Hill, J. R. Larus, A. R. Lebeck, J. C. Lewis, S. S. Mukherjee, S. Palacharla, and S. K. Reinhardt. </author> <title> Mechanisms for Cooperative Shared Memory. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 156-167, </pages> <year> 1993. </year>
Reference-contexts: In addition to the hardware schemes discussed so far, there are some interesting software assisted limited directory schemes, like LimitLESS scheme [22] and dir 1 SW + <ref> [37] </ref>. The main focus of such schemes is to use the existing hardware as effectively as possible to cope with lower sharing degrees and to deal with larger sharing degrees through software. In this paper, we 26 27 have focused only on hardware assisted limited directories.
References-found: 37

