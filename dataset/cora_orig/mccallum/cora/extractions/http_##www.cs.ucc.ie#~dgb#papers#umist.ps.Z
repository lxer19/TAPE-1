URL: http://www.cs.ucc.ie/~dgb/papers/umist.ps.Z
Refering-URL: http://www.cs.ucc.ie/~dgb/publist.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fmiles,dgbg@minster.york.ac.uk  
Title: More for less: learning a wide covering grammar from a small training set when using
Author: Miles Osborne and Derek Bridge 
Keyword: Corpus-based NLP, Statistical NLP, Deductive NLP, Hybrid approaches.  2: System overview Architecture (binary) (unary)  
Note: 1: Introduction case  The binary rule says (roughly) that any category rewrites as any two other categories, and the unary rule says (roughly) that any category rewrites as any other category. The categories  
Address: York, Heslington, York YO1 5DD, U. K.  
Affiliation: Department of Computer Science, University of  
Abstract: This paper describes a grammar learning system which combines model-based and data-driven learning within a single framework. Results from learning grammars with the Spoken English Corpus (SEC) suggest that a combined model-based and data-driven learner can acquire a wide coverage grammar from only a small training corpus. In this paper, we present some results of our grammar learning system. We show that using unification-based grammars, with a hybrid learning system allows a rapid rate of convergence upon a test corpus with only a modest amount of training material. In contrast to other researchers (for example (BMMS92; GLS87; Bak79; LY90; VB87)), we try to learn competence grammars and not performance grammars. We also try to learn grammars that assign linguistically plausible parses to sentences. Learning competence grammars that assign plausible parses is achieved by combining model-based and data-driven learning within a single framework (OB93b; OB93a; Os-bng). Model-based (deductive) methods are sound (MKKC86) (assuming that the model is consistent), but suffer from incompleteness, whilst data-driven (inductive) methods are unsound (they cannot guarantee that natural languages can be learnt (Gol67)), but complete. Note that `completeness' here means that the learner is always in a position to make a decision. We let both of the learning styles compensate for each other's weaknesses. A recent result showed that the combined use of induction and deduction produced a grammar that assigned quantitatively more plausible parses to sentences taken from the Spoken English Corpus (SEC) (LG91) than is the The structure of this paper is as follows. Section 2 gives an overview of the combined model-based and data-driven learner. Section 3 then describes the method used to generate the results, which are then presented in section 4 . Section 5 discusses these results and points the way forward. We assume that the system has some initial grammar fragment, G, from the outset. Presented with an input string, W, an attempt is made to parse W using G. If this fails, the learning system is invoked. Learning takes place through the interleaved operation of a parse completion process and a parse rejection process. In the parse completion process, the learning system tries to generate rules that, had they been members of G, would have enabled a derivation sequence for W to be found. This is done by trying to extend incomplete derivations using what we call super rules. Super rules are the following unification-based grammar rules: 
Abstract-found: 1
Intro-found: 1
Reference: <author> J. K. Baker. </author> <title> Trainable grammars for speech recognition. </title> <editor> In D. H. Klatt and J. J. Wolf, editors, </editor> <booktitle> Speech Communication Papers for the 97 th Meeting of the Acoustical Society of America, </booktitle> <pages> pages 547-550. </pages> <year> 1979. </year>
Reference: <author> Robert C. Berwick. </author> <title> The acquisition of syntactic knowledge. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference: <editor> Ezra Black, Roger Garside, and Geoffrey Leech, editors. </editor> <title> Statistically driven computer grammars of English the IBM-Lancaster approach. </title> <address> Rodopi, </address> <year> 1993. </year>
Reference: <author> Eric Brill, David Magerman, Mitchell Marcus, and Beatrice Santorini. </author> <title> Deducing Linguistic Structure from the Statistics of Large Corpora. </title> <booktitle> In AAAI-92 Workshop Program: Statistically-Based NLP Techniques, </booktitle> <address> San Jose, California, </address> <year> 1992. </year>
Reference: <author> Claudia Casadio. </author> <title> Semantic Categories and the Development of Categorial Grammars. </title> <editor> In Richard T. Oehrle, editor, </editor> <booktitle> Categorial Grammars and Natural Language Structures, </booktitle> <pages> pages 95-123. </pages> <address> D. </address> <publisher> Reidel, </publisher> <year> 1988. </year>
Reference: <author> John Carroll, Claire Grover, Ted Briscoe, and Bran Boguraev. </author> <title> A Development Environment for Large Natural Language Grammars. </title> <type> Technical report number 127, </type> <institution> University of Cambridge Computer Laboratory, </institution> <year> 1988. </year>
Reference: <author> Noam Chomsky. </author> <title> Reflections on Language. </title> <address> Pantheon, </address> <year> 1975. </year>
Reference: <author> Noam Chomsky. </author> <title> Lectures on Government and Binding. </title> <publisher> Dordrecht: Foris, </publisher> <year> 1981. </year>
Reference: <author> D.R. Dowty, R.E. Wall, and S. Peters. </author> <title> Introduction to Montague Semantics. </title> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <year> 1981. </year>
Reference: <author> G. Gadzar, E. Klein, G.K. Pullum, and I.A. Sag. </author> <title> Generalized Phrase Structure Grammar. </title> <publisher> Harvard University Press, </publisher> <year> 1985. </year>
Reference: <editor> R. Garside, G. Leech, and G. Sampson, editors. </editor> <title> The Computational Analysis of English: A Corpus-based Approach. </title> <publisher> Longman, </publisher> <year> 1987. </year>
Reference: <author> E. M. Gold. </author> <title> Language Identification to the Limit. </title> <journal> Information and Control, </journal> <volume> 10 </volume> <pages> 447-474, </pages> <year> 1967. </year>
Reference: <author> Ray S. Jackendoff. </author> <title> X-Bar Syntax: A Study of Phrase Structure. </title> <publisher> The M.I.T Press, </publisher> <year> 1977. </year>
Reference: <author> S. Johansson, G. Leech, and H. Goodluck. </author> <title> Manual of Information to Accompany the Lancaster-Oslo/Bergen Corpus of British English, for Use with Digital Computers. </title> <type> Technical report, </type> <institution> Department of English, University of Oslo, </institution> <year> 1978. </year>
Reference: <author> Fanny Leech. </author> <title> An approach to probabilistic parsing. </title> <booktitle> MPhil Dissertation, </booktitle> <year> 1987. </year> <institution> University of Lancaster. </institution>
Reference: <author> Geoffrey Leech and Roger Garside. </author> <title> Running a grammar factory: The production of syntactically analysed corpora or "treebanks". </title> <editor> In Stig Johansson and Anna-Brita Sten-strom, editors, </editor> <title> English Computer Corpora: Selected Papers and Research Guide. </title> <publisher> Mouten de Gruyter, </publisher> <year> 1991. </year>
Reference: <author> K. Lari and S. J. Young. </author> <title> The estimation of stochastic context-free grammars using the Inside-Outside Algorithm. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 4 </volume> <pages> 35-56, </pages> <year> 1990. </year>
Reference: <author> David M. Magerman. </author> <title> Natural Language Parsing as Statistical Pattern Recognition. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> February </month> <year> 1994. </year>
Reference: <author> T. Mitchell, R. Keller, and S. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <booktitle> Machine Learning, </booktitle> <address> 1.1:47-80, </address> <year> 1986. </year>
Reference: <author> D. Magerman and M. Marcus. Pearl: </author> <title> a probabilistic chart parser. </title> <booktitle> In Proceedings of the 2 nd International Workshop on Parsing Technologies, Cancun, Mexico, </booktitle> <pages> pages 193-199, </pages> <year> 1991. </year>
Reference: <author> Miles Osborne and Derek Bridge. </author> <title> Inductive and deductive grammar learning: dealing with incomplete theories. In Grammatical Inference Colloquium, </title> <publisher> Essex University, </publisher> <year> 1993. </year>
Reference: <author> Miles Osborne and Derek Bridge. </author> <title> Learning unification-based grammars and the treatment of undergeneration. </title> <booktitle> In Workshop on Machine Learning Techniques and Text Analysis, </booktitle> <address> Vienna, Austria, </address> <year> 1993. </year>
Reference: <author> Miles Osborne and Derek Bridge. </author> <title> Learning unification-based grammars using the Spoken English Corpus. </title> <booktitle> In The Second International Grammatical Inference Colloquim, </booktitle> <address> Alicante, Spain, </address> <year> 1994. </year>
Reference: <author> Miles Osborne. </author> <title> Learning Unification-based Natural Language Grammars. </title> <type> PhD thesis, </type> <institution> University of York, forthcoming. </institution>
Reference: <author> R. A. Sharman, F. Jelinek, and R. L. Mercer. </author> <title> Generating a grammar for statistical training. </title> <booktitle> In Proceedings of the IBM Conference on Natural Language Processing, </booktitle> <year> 1988. </year>
Reference: <author> Kurt Vanlehn and William Ball. </author> <title> A Version Space Approach to Learning Context-free Grammars. </title> <booktitle> Machine Learning, </booktitle> <address> 2.1:39-74, </address> <year> 1987. </year>
Reference: <author> Lydia White. </author> <title> Universal Grammar and second language acquisition. </title> <publisher> John Benjamins Publishing Company, </publisher> <year> 1989. </year>
References-found: 27

