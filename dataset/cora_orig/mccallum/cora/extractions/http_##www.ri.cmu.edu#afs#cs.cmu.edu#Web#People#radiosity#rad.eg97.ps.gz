URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/radiosity/rad.eg97.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/radiosity/rad.eg97.html
Root-URL: 
Title: An Empirical Comparison of Progressive and Wavelet Radiosity  
Author: Andrew J. Willmott and Paul S. Heckbert 
Address: Pittsburgh, PA 15213, USA  
Affiliation: Computer Science Department Carnegie Mellon University  
Date: June 97 1  
Note: Eurographics Workshop on Rendering,  
Abstract: This paper presents a comparison of basic progressive and wavelet ra-diosity algorithms. Several variants of each algorithm were run on a set of scenes at several parameter settings, and results were examined in terms of their error, speed, and memory consumption. We did not compare more advanced variations such as clustering or discontinuity meshing. Our results show that progressive ra-diosity with substructuring works fairly well for all scenes. Among wavelet methods, the Haar basis works best, while higher order methods suffer because of extreme memory consumption and because poor visibility handling causes dis continuous, blocky shadows.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gladimir V. Baranoski, Randall Bramley, and Peter Shirley. </author> <title> Fast Radiosity Solutions for High Average Re-ectance Environments. </title> <booktitle> In Rendering Techniques 95 (Proceedings of the Sixth Eurographics Workshop on Rendering), </booktitle> <pages> pages 345356. </pages> <address> Springer-Verlag/Wien, </address> <year> 1995. </year> <note> (Technical report: http://swarm.cs.wustl.edu/~hart/ mirror/indiana-biblo.html.) </note>
Reference-contexts: While the papers introducing these techniques have demonstrated the strengths of each radiosity algorithm, and some have offered theoretical complexity analyses, radiosity algorithms have not been compared extensively in terms of actual speed and accuracy. The existing comparisons focus on matrix and progressive radiosity, and their variations <ref> [7, 19, 1] </ref>. To our knowledge, wavelet and progressive radiosity have not been thoroughly compared.
Reference: [2] <author> Michael Cohen, Donald P. Greenberg, Dave S. Immel, and Philip J. Brock. </author> <title> An efficient radiosity approach for realistic image synthesis. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 6(3):2635, </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: This method can be made adaptive by the introduction of a two-level mesh; the coarser patches shoot light to a finer set of adaptively refined elements <ref> [2] </ref>. This process is known as substructuring. Wavelet Radiosity employs multilevel meshes to represent the radiosity function, and allows inter-patch interactions to take place between arbitrary levels of the mesh hierarchy [9,8].
Reference: [3] <author> Michael F. Cohen, Shenchang Eric Chen, John R. Wallace, and Donald P. Greenberg. </author> <title> A progressive refinement approach to fast radiosity image generation. </title> <booktitle> Computer Graphics (SIGGRAPH 88 Proceedings), </booktitle> <address> 22(4):7584, </address> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: We discuss each of these issues in turn below. 2.1 Implementation The two algorithms examined in this paper: Progressive radiosity iteratively shoots light from the brightest light sources and reective surfaces, effectively computing one column of the form factor matrix at a time <ref> [3] </ref>. This method can be made adaptive by the introduction of a two-level mesh; the coarser patches shoot light to a finer set of adaptively refined elements [2]. This process is known as substructuring.
Reference: [4] <author> Michael F. Cohen and John R. Wallace. </author> <title> Radiosity and Realistic Image Synthesis. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction A number of variations on the radiosity method have been published in the last decade <ref> [4] </ref>. The algorithmic options are quite numerous. They include: matrix radiosity, progressive radiosity, wavelet radiosity, hemicube form factors, ray-traced form factors, discontinuity meshing, importance-driven radiosity, and clustering. <p> In wavelet radiosity, refinement is controlled by the oracles described in the original papers, which also depend on a single epsilon parameter. In regions of partial visibility this epsilon is reduced in order to encourage subdivision around shadows <ref> [4] </ref>. The algorithm is terminated when no more links need refinement and the residual error has dropped below a fraction of the original. Visibility. Ray-casting is used for all inter-patch visibility tests, in order to standardize visibility testing between the algorithms. <p> In either of these cases, we switch to the polygon-to-point form factor, which is more accurate and contains no singularity, but is more expensive <ref> [4, 18] </ref>. Multiwavelets require quadrature rules to calculate the coupling coefficients between basis functions. The presence of a singularity in the form-factor kernel where surfaces touch can cause problems, because the function diverges from the lower-order-polynomial assumption of these rules [20].
Reference: [5] <author> Reid Gershbein, Peter Schrder, and Pat Hanrahan. </author> <title> Textures and radiosity: Controlling emission and reec-tion with texture maps. </title> <booktitle> In Computer Graphics (Proceedings of SIGGRAPH 94), </booktitle> <pages> pages 5158, </pages> <month> July </month> <year> 1994. </year> <month> ht-tp://www-graphics.stanford.edu/papers/texture. </month>
Reference-contexts: to be close to completely visible from the elements of the receiver. 3.5 Wavelet Shadow Handling We tried two quadrature methods for the higher order wavelets, fractional visibility, which scales the results of quadrature with the estimated visibility between two patches [9,8], and visibility-in-quadrature, which leaves visibility in the integrand <ref> [5] </ref>. Neither of these methods performed particularly well in the complex experiment. The bottom-left image in Figure 7 shows a solution using the M2 basis and the fractional-visibility method, where visibility is factored out of the quadrature: it is overly blocky.
Reference: [6] <author> Simon Gibson and R. J. Hubbold. </author> <title> Efficient hierarchical refinement and clustering for radiosity in complex environments. </title> <journal> Computer Graphics Forum, </journal> <volume> 15(5):297310, </volume> <month> December </month> <year> 1996. </year>
Reference-contexts: The higher order methods produced a scene with higher error than the Haar basis, so they were not trying to do too much work compared to Haar. Clustering has been shown to help this problem; in particular Gibson et al. <ref> [6] </ref> have impressive results for high-complexity scenes, and have managed to run wavelet radiosity with the Haar basis against a 225,000 polygon scene in 180Mb of memory. Unfortunately, clustering techniques have not yet been applied to higher-order methods, only the Haar basis. Even assuming linear storage Fig. 3.
Reference: [7] <author> Steven J. Gortler, Michael F. Cohen, and Phillipp Slusallek. </author> <title> Radiosity and Relaxation Methods. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 14(6):4858, </volume> <month> November </month> <year> 1994. </year> <note> http://www.cs.princeton.edu/gfx/papers/relax. </note>
Reference-contexts: While the papers introducing these techniques have demonstrated the strengths of each radiosity algorithm, and some have offered theoretical complexity analyses, radiosity algorithms have not been compared extensively in terms of actual speed and accuracy. The existing comparisons focus on matrix and progressive radiosity, and their variations <ref> [7, 19, 1] </ref>. To our knowledge, wavelet and progressive radiosity have not been thoroughly compared.
Reference: [8] <author> Steven J. Gortler, Peter Schrder, Michael F. Cohen, and Pat Hanrahan. </author> <title> Wavelet radiosity. </title> <booktitle> Computer Graphics (SIGGRAPH 93 Proceedings), </booktitle> <month> August </month> <year> 1993. </year> <note> http://www-graphics.stanford.edu/papers/wavrad. </note>
Reference-contexts: Within the wavelet framework, radiosity functions can be represented with a variety of different basis functions. We implemented the methods most widely discussed in the literature: the Haar basis [15], atlets of order 2 and 3 (F2, F3) [12], and multiwavelets, also of order 2 and 3 (M2, M3) <ref> [8] </ref>. The lower-order methods are easier to integrate and require fewer coefficients per link, while the higher order methods create sparser approximations to the kernel. We use multigridding with brightness-weighted refinement. In the remainder of this section we discuss the most salient of our implementation choices. <p> For methods using piecewise-constant basis functions, it is common to perform post-process smoothing to eliminate step discontinuities. We use this approach for the progressive and Haar wavelet methods. For multiwavelets, we display directly from the basis functions, as did Gortler et al. <ref> [8] </ref>. The resulting functions will thus be piecewise linear or piecewise quadratic, with possible discontinuities between elements; we attempt to minimise these by ensuring the mesh is balanced.
Reference: [9] <author> Pat Hanrahan, David Salzman, and Larry Aupperle. </author> <title> A rapid hierarchical radiosity algorithm. </title> <booktitle> Computer Graphics (SIGGRAPH 91 Proceedings), </booktitle> <address> 25(4):197206, </address> <month> July </month> <year> 1991. </year> <note> http://www-graphics.stanford.edu/papers/rad. </note>
Reference-contexts: For the progressive methods, visibility is tested by casting a single ray from a patch to each other element in the scene [16]. For the wavelet methods, a 4 4 jittered sampling scheme is used [14], along with triage <ref> [9] </ref>: refined links have their visibility recalculated only in areas of partial occlusion. Meshing. For progressive radiosity, each polygon in the scene is subdivided into a mesh such that the edge-lengths of all mesh elements are smaller than a specified maximum. <p> Interestingly, for the scenes tested, the extra link term dominated for Haar (hence its linear time cost in Figure 3) and the initial links dominated for the higher order methods, yielding near-quadratic time cost.These results extend the existing theoretical analysis <ref> [9] </ref>. #links = Q (1/epsilon). For small enough epsilon, the number of links generated by the wavelet methods for a fixed scene is proportional to 1/epsilon, as we see in Figure 5.
Reference: [10] <author> Holly Rushmeier, Greg Ward, Christine Piatko, Phil Sanders, and Bert Rust. </author> <title> Comparing real and synthetic images: Some ideas about metrics. </title> <booktitle> In Rendering Techniques 95, </booktitle> <pages> pages 8291. </pages> <address> Springer-Verlag/Wien, </address> <year> 1995. </year> <month> ht-tp://radsite.lbl.gov/mgf/compare.html. </month>
Reference-contexts: Discontinuity meshing, importance-driven radiosity, clustering, and distribution raytracing [17], for example, were neglected. Specular radiosity and participating media were also not examined. The accuracy of simulations was measured using a simple, view-independent error metric, rather than attempt to account for perception <ref> [10] </ref>. We feel that error metrics that model colour sensitivity and nonlinearity alone would not change our results significantly, but that metrics that model sensitivity to spatial frequencies would emphasize shadow problems and bring our objective error measure closer to a subjective one. <p> Investigating performance on a range of complex real-world scenes, such as architectural models. Comparing the radiosity approaches investigated here to Wards RADIANCE system [17]. Producing results for the standard library of scene files due to Rushmeier et. al. <ref> [10] </ref>. Considering perceptually-based error measures. To assist others in the research community with the investigation of these areas, and for evaluation of our experiments, we plan to place our radiosity renderer and experimental system on the internet at the following URL: http://www.cs.cmu.edu/~radiosity/. Substruct.
Reference: [11] <author> Peter Schrder. </author> <title> Numerical integration for radiosity in the presence of singularities. </title> <booktitle> In Fourth Eurographics Workshop on Rendering, </booktitle> <address> Paris, </address> <month> June </month> <year> 1993. </year> <note> http://www.cs.princeton.edu/gfx/papers/integration/. </note>
Reference-contexts: Multiwavelets require quadrature rules to calculate the coupling coefficients between basis functions. The presence of a singularity in the form-factor kernel where surfaces touch can cause problems, because the function diverges from the lower-order-polynomial assumption of these rules [20]. In such situations we swap to the C-C transfer functions <ref> [11] </ref>. 2.2 Test Scenes We chose test scenes that explore among others the following properties: Interreection. High reectance makes some algorithms quite slow, and exposes aws in others. Occlusion. Hard shadows are a difficult test for most radiosity algorithms. Complexity.
Reference: [12] <author> Peter Schrder and Pat Hanrahan. </author> <title> On the form factor between two polygons. </title> <booktitle> In Computer Graphics (Proceedings of SIGGRAPH 93), </booktitle> <pages> pages 163164, </pages> <year> 1993. </year> <note> http://csvax.cs.caltech.edu/~ps/formfactor/ffpaper.ps.gz. </note>
Reference-contexts: Within the wavelet framework, radiosity functions can be represented with a variety of different basis functions. We implemented the methods most widely discussed in the literature: the Haar basis [15], atlets of order 2 and 3 (F2, F3) <ref> [12] </ref>, and multiwavelets, also of order 2 and 3 (M2, M3) [8]. The lower-order methods are easier to integrate and require fewer coefficients per link, while the higher order methods create sparser approximations to the kernel. We use multigridding with brightness-weighted refinement. <p> Flatlets are first converted to the same order multiwavelet basis, and then displayed in a similar manner, and thus may also exhibit discontinuities. Form-Factors. While a closed-form solution for the double integral that defines the area-to-area form factor exists <ref> [12] </ref>, it is too expensive to use in most situations. We follow the standard practice of approximating the form factor by its point-to-point counterpart, which works well when two patches are sufficiently far apart.
Reference: [13] <author> Philipp Slusallek, Michael Schroder, Marc Stamminger, and Hans-Peter Seidel. </author> <title> Smart Links and Efficient Reconstruction for Wavelet Radiosity. </title> <booktitle> In Rendering Techniques 95 (Proceedings of the Sixth Eurographics Workshop on Rendering), </booktitle> <pages> pages 240251. </pages> <address> Springer-Verlag/Wien, </address> <year> 1995. </year> <note> http://www9.informatik.uni-erlan-gen.de/eng/research/pub95/. </note>
Reference-contexts: A solution to these problems is to subdivide even more heavily in areas of partial visibility. However, this wastes transfer and basis coefficients, especially for higher order wavelets. Slusallek et al. <ref> [13] </ref> have addressed this problem by applying the shadow masks proposed by Zatz [20]; this is a generalisation of fractional visibility in which visibility is evaluated at a finer resolution, smoothed by interpolation, and multiplied into the radiosity function. <p> These edge errors accumulate as the link hierarchy deepens, so that the more heavily the mesh is subdivided, the worse the problem gets. This phenomenon has also been observed by Slusallek et al. <ref> [13] </ref>, who propose as a solution splitting the form-factor into constant and cos (q) dependent parts, and re-evaluating the latter at lower levels of the hierarchy.
Reference: [14] <author> Brian Smits, James Arvo, and Donald Greenberg. </author> <title> A clustering algorithm for radiosity in complex environments. </title> <booktitle> In Proceedings of SIGGRAPH 94 (Orlando, </booktitle> <address> Florida, </address> <month> July 2429, </month> <year> 1994), </year> <booktitle> Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 435442. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year> <note> http:// csvax.cs.caltech.edu/~arvo/papers.html. </note>
Reference-contexts: For the progressive methods, visibility is tested by casting a single ray from a patch to each other element in the scene [16]. For the wavelet methods, a 4 4 jittered sampling scheme is used <ref> [14] </ref>, along with triage [9]: refined links have their visibility recalculated only in areas of partial occlusion. Meshing. For progressive radiosity, each polygon in the scene is subdivided into a mesh such that the edge-lengths of all mesh elements are smaller than a specified maximum. <p> Future Work Now that we have our testbed in place, and have completed our initial investigation of radiosity methods, there are a number of avenues for future work. These include: Implementing and investigating clustering for all wavelet methods <ref> [14] </ref>. Testing more sophisticated meshing schemes. Evaluating the effect a final-gather pass has on the accuracy of the simulation. Investigating performance on a range of complex real-world scenes, such as architectural models. Comparing the radiosity approaches investigated here to Wards RADIANCE system [17].
Reference: [15] <author> Eric J. Stollnitz, Tony D. DeRose, and David H. Salesin. </author> <title> Wavelets for Computer Graphics. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA, </address> <year> 1996. </year> <note> http://www.amath.washington.edu/~stoll/pub.html. </note>
Reference-contexts: Within the wavelet framework, radiosity functions can be represented with a variety of different basis functions. We implemented the methods most widely discussed in the literature: the Haar basis <ref> [15] </ref>, atlets of order 2 and 3 (F2, F3) [12], and multiwavelets, also of order 2 and 3 (M2, M3) [8]. The lower-order methods are easier to integrate and require fewer coefficients per link, while the higher order methods create sparser approximations to the kernel.
Reference: [16] <author> John R. Wallace, Kells A. Elmquist, and Eric A. Haines. </author> <title> A ray tracing algorithm for progressive radiosity. </title> <booktitle> In Computer Graphics (SIGGRAPH 89 Proceedings), </booktitle> <volume> volume 23, </volume> <pages> pages 315324, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Visibility. Ray-casting is used for all inter-patch visibility tests, in order to standardize visibility testing between the algorithms. For the progressive methods, visibility is tested by casting a single ray from a patch to each other element in the scene <ref> [16] </ref>. For the wavelet methods, a 4 4 jittered sampling scheme is used [14], along with triage [9]: refined links have their visibility recalculated only in areas of partial occlusion. Meshing.
Reference: [17] <author> Gregory J. Ward. </author> <title> The RADIANCE lighting simulation and rendering system. </title> <booktitle> In SIGGRAPH 94 Proc., </booktitle> <pages> pages 459472, </pages> <month> July </month> <year> 1994. </year> <note> http://radsite.lbl.gov/radiance/papers/sg94.1/paper.html. </note>
Reference-contexts: In the real world, constant factors and expected case behaviour are often more important than asymptotic, worst case behaviour. To keep the project manageable, we did not attempt to test all of the algorithmic options in the literature. Discontinuity meshing, importance-driven radiosity, clustering, and distribution raytracing <ref> [17] </ref>, for example, were neglected. Specular radiosity and participating media were also not examined. The accuracy of simulations was measured using a simple, view-independent error metric, rather than attempt to account for perception [10]. <p> Testing more sophisticated meshing schemes. Evaluating the effect a final-gather pass has on the accuracy of the simulation. Investigating performance on a range of complex real-world scenes, such as architectural models. Comparing the radiosity approaches investigated here to Wards RADIANCE system <ref> [17] </ref>. Producing results for the standard library of scene files due to Rushmeier et. al. [10]. Considering perceptually-based error measures.
Reference: [18] <author> Andrew J. Willmott and Paul S. Heckbert. </author> <title> An empirical comparison of radiosity algorithms. </title> <type> Technical Report CMU-CS-97-115, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> April </month> <year> 1997. </year> <note> http:// www.cs.cmu.edu/~radiosity/emprad-tr.html. </note>
Reference-contexts: In all, 500 different experimental runs were executed, generating a total of 0.5 gigabytes of data and requiring a week of CPU time. The radiosity and testing software comprises 40,000 lines of C++ code. A more complete report on the full study is available <ref> [18] </ref>; in this paper we summarize the most important results for progressive and wavelet radiosity. 2 Experimental Method Designing the tests involved a choice of which algorithms to implement, what scenes to run them on, and how to collect and compare results. <p> We use multigridding with brightness-weighted refinement. In the remainder of this section we discuss the most salient of our implementation choices. Further details can be found in <ref> [18] </ref>. Control Algorithms. For progressive radiosity with substructuring, elements are subdivided un Eurographics Workshop on Rendering, June 97 3 til their radiosity gradient drops below a preset epsilon, and the algorithm is terminated when the residual error drops below a preset fraction of the original residual error. <p> In either of these cases, we switch to the polygon-to-point form factor, which is more accurate and contains no singularity, but is more expensive <ref> [4, 18] </ref>. Multiwavelets require quadrature rules to calculate the coupling coefficients between basis functions. The presence of a singularity in the form-factor kernel where surfaces touch can cause problems, because the function diverges from the lower-order-polynomial assumption of these rules [20]. <p> There are 5 + 27m polygons in this scene, and the rooms surface area scales in proportion to m. We scale the geometry as the complexity grows because we feel that this is typically the way detail is added to a scene. Elsewhere we examined an unscaled scene <ref> [18] </ref>. 2.3 Testing The testing process involved applying a subset of the radiosity methods available to us to each scene variant in each experiment. A batch renderer was used to produce radiosity simulations and statistics for each of the experiments scenes. <p> To compute this we used Monte Carlo sampling over the base polygons. As the total emitted radiosity in the scene scales any error, we then define the relative error as the absolute error divided by the average re-ected radiosity over the reference solution <ref> [18] </ref>. Parameters were typically set to drive the relative error below 5% or so. We do not use the residual as our error measure, as some previous studies have done, because it does not support comparison of solutions from different meshes well. Equalised Plots.
Reference: [19] <author> Wei Xu and Donald S. Fussell. </author> <title> Constructing Solvers for Radiosity Equation Systems. </title> <booktitle> Fifth Eurographics Workshop on Rendering, </booktitle> <pages> pages 207217, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: While the papers introducing these techniques have demonstrated the strengths of each radiosity algorithm, and some have offered theoretical complexity analyses, radiosity algorithms have not been compared extensively in terms of actual speed and accuracy. The existing comparisons focus on matrix and progressive radiosity, and their variations <ref> [7, 19, 1] </ref>. To our knowledge, wavelet and progressive radiosity have not been thoroughly compared.
Reference: [20] <author> Harold R. Zatz. </author> <title> Galerkin radiosity: A higher-order solution method for global illumination. </title> <booktitle> Computer Graphics (SIGGRAPH 93 Proceedings), </booktitle> <month> August </month> <year> 1993. </year> <note> http://www.rhythm.com/~hzatz/. Eurographics Workshop on Rendering, June 97 13 </note>
Reference-contexts: Multiwavelets require quadrature rules to calculate the coupling coefficients between basis functions. The presence of a singularity in the form-factor kernel where surfaces touch can cause problems, because the function diverges from the lower-order-polynomial assumption of these rules <ref> [20] </ref>. In such situations we swap to the C-C transfer functions [11]. 2.2 Test Scenes We chose test scenes that explore among others the following properties: Interreection. High reectance makes some algorithms quite slow, and exposes aws in others. Occlusion. Hard shadows are a difficult test for most radiosity algorithms. <p> A solution to these problems is to subdivide even more heavily in areas of partial visibility. However, this wastes transfer and basis coefficients, especially for higher order wavelets. Slusallek et al. [13] have addressed this problem by applying the shadow masks proposed by Zatz <ref> [20] </ref>; this is a generalisation of fractional visibility in which visibility is evaluated at a finer resolution, smoothed by interpolation, and multiplied into the radiosity function. But visibility and irradiance are not independent, so a more correct approach would be to use visibility-in-quadrature with dis 1 3 Fig. 6.
References-found: 20

