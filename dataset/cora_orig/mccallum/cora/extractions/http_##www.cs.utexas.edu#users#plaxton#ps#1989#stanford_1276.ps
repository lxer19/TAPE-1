URL: http://www.cs.utexas.edu/users/plaxton/ps/1989/stanford_1276.ps
Refering-URL: http://www.cs.utexas.edu/users/plaxton/html/abc.html
Root-URL: 
Title: On the Network Complexity of Selection  
Author: C. Greg Plaxton 
Note: This work was supported in part by a grant from the AT&T Foundation, NSF grant DCR-8351757 and ONR grant N00014-88-K-0166. The author is primarily supported by a 1967 Science and Engineering Scholarship from the Natural Sciences and Engineering Research Council of Canada.  
Address: Stanford, CA 94305  
Affiliation: Department of Computer Science Stanford University  
Abstract: The selection problem is to determine the kth largest out of a given set of n keys, and its sequential complexity is well known to be linear. Thus, given a p processor parallel machine, it is natural to ask whether or not an O(n=p) selection algorithm can be devised for that machine. For the EREW PRAM, Vishkin has exhibited a straightforward selection algorithm that achieves optimal speedup for n = (p log p log log p) [18]. For the network model, the sorting result of Leighton [12] and the token distribution result of Peleg and Upfal [13] together imply that Vishkin's algorithm can be adapted to run in the same asymptotic time bound on a certain class of bounded degree expander networks. On the other hand, none of the network families currently of practical interest have sufficient expansion to permit an efficient implementation of Vishkin's algorithm. The main result of this paper is an ((n=p) log log p+log p) lower bound for selection on any network that satisfies a particular low expansion property. The class of networks satisfying this property includes all of the common network families such as the tree, multi-dimensional mesh, hypercube, butterfly and shu*e exchange. When n=p is sufficiently large (for example, greater than log 2 p on the butterfly, hypercube and shu*e exchange), this result is matched by the upper bound presented in [14]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal and M.-D. A. Huang. </author> <title> Network complexity of sorting and graph problems and simulating CRCW PRAMs by interconnection networks. </title> <editor> In J. H. Reif, editor, </editor> <booktitle> VLSI Algorithms and Architectures: Proceedings of the 3rd Aegean Workshop on Computing, Lecture Notes in Computer Science, </booktitle> <volume> volume 319, </volume> <pages> pages 339-350. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: The lower bound is proven in Sections 4 and 5. Note that this lower bound disproves a claim of Aggarwal and Huang stating that optimal speedup is possible for selection on the hypercube and shu*e-exchange <ref> [1] </ref>. When n=p is sufficiently large (for example, greater than log 2 p on the hypercube and shu*e-exchange), the lower bound is tight to within a multiplicative constant. The matching upper bound is provided by the algorithm Select presented in [14].
Reference: [2] <author> M. Ajtai, J. Komlos, W. L. Steiger, and E. Szemeredi. </author> <title> Deterministic selection in O(log log n) parallel time. </title> <booktitle> In Proceedings of the 18th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 188-195, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: The only operations allowed on keys are copy and comparison. The sequential complexity of selection is well known to be linear [5], [16]. The parallel complexity of selection has been studied extensively under a variety of different models of computation; see for example <ref> [2] </ref>, [9], [15] and [18]. For parallel models, the complexity of selection is a function of both p, the number of processors available, as well as n, the size of the set S.
Reference: [3] <author> K. E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <volume> vol. 32, </volume> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: An expander network is a network with expansion (1). Now consider implementing Vishkin's algorithm on a network such as the hypercube (1-port communication). Sorting n = p keys can be performed in O (log 2 p) time <ref> [3] </ref>, which only causes an increase in the additive term above, but the redistribution step cannot be implemented efficiently due to insufficient expansion.
Reference: [4] <author> G. Baudet and D. Stevenson. </author> <title> Optimal sorting algorithms for parallel computers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27:84-87, </volume> <year> 1978. </year>
Reference-contexts: As with the related problem of sorting n keys, most research has focused on obtaining tight asymptotic bounds for the case n = p. For sorting, the existence of an O (log p) time comparison-exchange based algorithm for the case n = p implies optimal speedup for n p <ref> [4] </ref>. For selection, however, a tight bound for the case n = p can be expected to be non-constant. Hence, simulating a fast algorithm for the case n = p will not yield optimal speedup for n &gt; p.
Reference: [5] <author> M. Blum, R. W. Floyd, V. R. Pratt, and R. L. Rivest. </author> <title> Time bounds for selection. </title> <journal> J. Comput. Sys. Sci., </journal> <volume> 7 </volume> <pages> 448-461, </pages> <year> 1973. </year>
Reference-contexts: The only operations allowed on keys are copy and comparison. The sequential complexity of selection is well known to be linear <ref> [5] </ref>, [16]. The parallel complexity of selection has been studied extensively under a variety of different models of computation; see for example [2], [9], [15] and [18].
Reference: [6] <author> A. Borodin, L. J. Guibas, N. A. Lynch, and A. C. Yao. </author> <title> Efficient searching using partial ordering. </title> <journal> Information Processing Letters, </journal> <volume> 12 </volume> <pages> 71-75, </pages> <year> 1981. </year>
Reference-contexts: The corresponding sequential tradeoff between preprocessing time and search time is well understood, see <ref> [6] </ref> and [11]. The running time of the ith stage is readily shown to be O (2 i (n=p) log log p + T 1 + T 2 log p), which implies the overall time bound for Select stated in Equation (1). <p> The adversary maintains such a comparison tree for every block. A comparison tree of the same sort was used by Borodin et al. <ref> [6] </ref> to obtain an easy (though not their strongest) sequential tradeoff between preprocessing time and search time in a partial order. A comparison tree is a binary tree with tokens placed at certain nodes.
Reference: [7] <author> R. Cole. </author> <title> An optimal selection algorithm. </title> <type> Technical Report #209, </type> <institution> Ultracomputer Research Laboratory, </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: For the EREW PRAM, Vishkin has exhibited a straightforward selection algorithm that achieves optimal speedup for n = (p log p log log p) [18]. This result has been improved by Cole, who obtained optimal speedup for n = (p log p log fl p) <ref> [7] </ref>. Vishkin's algorithm is based on two ideas.
Reference: [8] <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM J. Comput., </journal> <volume> 17 </volume> <pages> 770-785, </pages> <year> 1988. </year>
Reference-contexts: Iterating this process of elimination and redistribution, one finds that the number of keys remaining decreases geometrically and the complexity of Vishkin's algorithm is O (n=p + log p log log p), where Cole's parallel merge sort has been used to make the additive term small <ref> [8] </ref>. Given that optimal speedup of selection is attainable on the EREW PRAM, for n=p sufficiently large, one is led to ask whether a similar result can be achieved under a more realistic model of computation such as the network model to be defined in Section 2.
Reference: [9] <author> R. Cole and C. K. Yap. </author> <title> A parallel median algorithm. </title> <journal> Information Processing Letters, </journal> <volume> 20 </volume> <pages> 137-139, </pages> <year> 1985. </year>
Reference-contexts: The only operations allowed on keys are copy and comparison. The sequential complexity of selection is well known to be linear [5], [16]. The parallel complexity of selection has been studied extensively under a variety of different models of computation; see for example [2], <ref> [9] </ref>, [15] and [18]. For parallel models, the complexity of selection is a function of both p, the number of processors available, as well as n, the size of the set S.
Reference: [10] <author> A. Gottlieb and C. P. Kruskal. </author> <title> Complexity results for permuting data and other computations on parallel processors. </title> <journal> JACM, </journal> <volume> 31 </volume> <pages> 193-209, </pages> <year> 1984. </year>
Reference-contexts: so that the lower bound of Theorem 5.2 applies with an improved multiplicative constant of 1o (1) 6 Concluding Remarks The upper and lower bounds for network selection discussed in this paper significantly improve on previously known results when the number of keys at each processor, n=p, is sufficiently large <ref> [10] </ref>. In proving lower bounds, it was assumed that n and p are powers of 2, and that every processor begins with exactly n=p keys.
Reference: [11] <author> R. M. Karp, R. Motwani, and P. Raghavan. </author> <title> Deferred data structuring. </title> <journal> SIAM J. Comput., </journal> <volume> 17 </volume> <pages> 883-902, </pages> <year> 1988. </year> <month> 16 </month>
Reference-contexts: The corresponding sequential tradeoff between preprocessing time and search time is well understood, see [6] and <ref> [11] </ref>. The running time of the ith stage is readily shown to be O (2 i (n=p) log log p + T 1 + T 2 log p), which implies the overall time bound for Select stated in Equation (1).
Reference: [12] <author> F. T. Leighton. </author> <title> Tight bounds on the complexity of parallel sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34:344-354, </volume> <year> 1985. </year>
Reference-contexts: In fact, networks exist for which optimal speedup of selection is attainable. The sorting result of Leighton <ref> [12] </ref> and the token distribution result of Peleg and Upfal [13] together imply that Vishkin's algorithm can be implemented to run in O (n=p + log p log log p) time on a certain class of bounded degree expander networks.
Reference: [13] <author> D. Peleg and E. Upfal. </author> <title> The token distribution problem. </title> <journal> SIAM J. Comput., </journal> <volume> 18 </volume> <pages> 229-243, </pages> <year> 1989. </year>
Reference-contexts: In fact, networks exist for which optimal speedup of selection is attainable. The sorting result of Leighton [12] and the token distribution result of Peleg and Upfal <ref> [13] </ref> together imply that Vishkin's algorithm can be implemented to run in O (n=p + log p log log p) time on a certain class of bounded degree expander networks.
Reference: [14] <author> C. G. Plaxton. </author> <title> Load balancing, selection and sorting on the hypercube. </title> <booktitle> In Proceedings of the 1st Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 64-73, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: When n=p is sufficiently large (for example, greater than log 2 p on the hypercube and shu*e-exchange), the lower bound is tight to within a multiplicative constant. The matching upper bound is provided by the algorithm Select presented in <ref> [14] </ref>. Section 3 contains a brief description of this algorithm, along with a few additional remarks. 2 The Network Model A p processor fixed interconnection network may be viewed as an undirected graph, where vertices correspond to processors and edges correspond to communication channels. <p> It will also be assumed that n = O (p c ) for some positive constant c. Having bounded n in this manner, it may be assumed without loss of generality that all of the keys are distinct <ref> [14] </ref>. 2 The selection algorithm presented in [14] obeys all of the above restrictions. Section 3 contains a brief outline of that algorithm along with a summary of its asymptotic performance on a variety of networks. <p> It will also be assumed that n = O (p c ) for some positive constant c. Having bounded n in this manner, it may be assumed without loss of generality that all of the keys are distinct <ref> [14] </ref>. 2 The selection algorithm presented in [14] obeys all of the above restrictions. Section 3 contains a brief outline of that algorithm along with a summary of its asymptotic performance on a variety of networks. <p> For such networks, the algorithm Select presented in <ref> [14] </ref> achieves nearly optimal speedup when the ratio n=p is sufficiently large. To be precise, assume that a particular network is capable of sorting n = p keys located one per processor in time T 1 and can perform broadcasting and summing operations in time T 2 . <p> This median is the desired key y and, as proven in <ref> [14] </ref>, it can be used to eliminate half of the live items at every processor.
Reference: [15] <author> M. Rodeh. </author> <title> Finding the median distributively. </title> <journal> JCSS, </journal> <volume> 24 </volume> <pages> 162-166, </pages> <year> 1982. </year>
Reference-contexts: The only operations allowed on keys are copy and comparison. The sequential complexity of selection is well known to be linear [5], [16]. The parallel complexity of selection has been studied extensively under a variety of different models of computation; see for example [2], [9], <ref> [15] </ref> and [18]. For parallel models, the complexity of selection is a function of both p, the number of processors available, as well as n, the size of the set S.
Reference: [16] <author> A. Schonhage, M. Paterson, and N. Pippenger. </author> <title> Finding the median. </title> <journal> JCSS, </journal> <volume> 13 </volume> <pages> 184-199, </pages> <year> 1976. </year>
Reference-contexts: The only operations allowed on keys are copy and comparison. The sequential complexity of selection is well known to be linear [5], <ref> [16] </ref>. The parallel complexity of selection has been studied extensively under a variety of different models of computation; see for example [2], [9], [15] and [18].
Reference: [17] <author> L. G. Valiant. </author> <title> Parallelism in comparison problems. </title> <journal> SIAM J. Comput., </journal> <volume> 4 </volume> <pages> 348-355, </pages> <year> 1975. </year>
Reference-contexts: In other words, one may envision a global controller that receives the outcome of every comparison query made in a given time step, and then performs an unbounded amount of computation in order to determine the next set of comparison queries. This is essentially Valiant's parallel comparison model <ref> [17] </ref>, except for the added restriction imposed by Definition 4.1. The description and analysis of the adversary argument has been divided into a number of parts. Section 4.1 describes the information that the adversary gives away at the outset of the computation. Section 4.2 provides some useful definitions.
Reference: [18] <author> U. Vishkin. </author> <title> An optimal parallel algorithm for selection. </title> <type> Technical Report 106, </type> <institution> Courant Institute of Mathematical Sciences, Department of Computer Science, </institution> <month> December </month> <year> 1983. </year> <month> 17 </month>
Reference-contexts: The only operations allowed on keys are copy and comparison. The sequential complexity of selection is well known to be linear [5], [16]. The parallel complexity of selection has been studied extensively under a variety of different models of computation; see for example [2], [9], [15] and <ref> [18] </ref>. For parallel models, the complexity of selection is a function of both p, the number of processors available, as well as n, the size of the set S. <p> On the other hand, optimal speedup for selection is often possible when n=p is sufficiently large. For the EREW PRAM, Vishkin has exhibited a straightforward selection algorithm that achieves optimal speedup for n = (p log p log log p) <ref> [18] </ref>. This result has been improved by Cole, who obtained optimal speedup for n = (p log p log fl p) [7]. Vishkin's algorithm is based on two ideas.
References-found: 18

