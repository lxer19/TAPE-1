URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1995/umsi-95-78.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1995/
Root-URL: http://www.cs.umn.edu
Title: ILUS: An Incomplete LU Preconditioner in Sparse Skyline Format  
Author: Edmond Chow and Yousef Saad 
Keyword: Key words. incomplete LU preconditioning, skyline format, stability, approx imate inverse, lid-driven cavity  
Note: Work supported in part by the National Science Foundation under grant NSF/CCR-9214116 and in part by NASA under grant NAG2-904.  
Date: November 24, 1997  
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science, and Minnesota Supercomputer Institute University of Minnesota  
Abstract: Incomplete LU factorizations are among the most effective preconditioners for solving general large, sparse linear systems arising from practical engineering problems. This paper shows how an ILU factorization may be easily computed in sparse skyline storage format, as opposed to traditional row-by-row schemes. This organization of the factorization has many advantages, including its amenability when the original matrix is in skyline format, the ability to dynamically monitor the stability of the factorization, and the fact that factorizations may be produced with symmetric structure. Numerical results are presented for Galerkin Finite Element matrices arising from the standard square lid-driven cavity problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Axelsson. </author> <title> Iterative Solution Methods. </title> <address> Cambridge, Cambridge, </address> <year> 1994. </year>
Reference-contexts: Their most common application has been to independently approximate all the rows or columns of an inverse [2, 6, 8, 18, 15] or its factors <ref> [1, 19] </ref>, and use it as a precon-ditioner.
Reference: [2] <author> M. W. Benson and P. O. Frederickson. </author> <title> Iterative solution of large sparse linear systems arising in certain multidimensional approximation problems. </title> <journal> Utilitas Math., </journal> <volume> 22 (1982), </volume> <pages> pp. 127-140. </pages>
Reference-contexts: Yet another possible strategy will be mentioned in Section 2.4. 2.2.2 Approximate inverse techniques A second, much cheaper approximation for (1) comes from approximate inverse techniques. Their most common application has been to independently approximate all the rows or columns of an inverse <ref> [2, 6, 8, 18, 15] </ref> or its factors [1, 19], and use it as a precon-ditioner.
Reference: [3] <author> C. H. Bischof, J. G. Lewis and D. J. Pierce. </author> <title> Incremental condition estimation for sparse matrices, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11 (1990), </volume> <pages> pp. 644-659. </pages>
Reference-contexts: Unfortunately, this cannot be done for the upper triangular factor. In this case, we estimate the infinity norm of its transpose. Other more complicated condition estimates are possible <ref> [3, 9, 14] </ref>, but we have not found them to be necessary for our purpose. An interesting way to determine how badly L k and U k are conditioned is to examine the residual norm reduction in the approximate inverse iteration.
Reference: [4] <author> A. M. Bruaset, A. Tveito and R. Winther. </author> <title> On the stability of relaxed incomplete LU factorizations, </title> <journal> Math. Comp., </journal> <volume> 54 (1990), </volume> <pages> pp. 701-719. </pages>
Reference-contexts: In these cases, an ILU factorization may produce L and U factors such that the norm of (LU ) 1 is very large. The long recurrences associated with solving with these factors are unstable <ref> [4, 11] </ref>, producing solutions with extremely large components. A sign of this severely poor preconditioning is the erratic behavior of the iterative method, for example, divergence of the iterations due to large numerical errors.
Reference: [5] <author> P. Chin, E. F. D'Azevedo, P. A. Forsyth and W.-P. Tang. </author> <title> Preconditioned conjugate gradient methods for the incompressible Navier-Stokes equations, </title> <journal> Int. J. Numer. Methods Fluids, </journal> <volume> 15 (1992), </volume> <pages> pp. 273-295. </pages>
Reference-contexts: These indeed have been very successful for many fluid flow problems, for example, see <ref> [5] </ref>. For indefinite matrices, however, techniques based solely on level-of-fill may be inappropriate, because they ignore the numerical values. Threshold methods, on the other hand, are much more expensive, and it is difficult to determine their storage requirements beforehand.
Reference: [6] <author> E. Chow and Y. Saad. </author> <title> Approximate inverse preconditioners via sparse-sparse iterations, </title> <note> SIAM J. Sci. Comput., to appear. </note>
Reference-contexts: Yet another possible strategy will be mentioned in Section 2.4. 2.2.2 Approximate inverse techniques A second, much cheaper approximation for (1) comes from approximate inverse techniques. Their most common application has been to independently approximate all the rows or columns of an inverse <ref> [2, 6, 8, 18, 15] </ref> or its factors [1, 19], and use it as a precon-ditioner. <p> The minimization may be done in many ways, most obviously by using a QR factorization. However, since the exact minimum is not required, it may be cheaper to use a few steps of a descent-type method starting with a sparse initial guess <ref> [6] </ref>. It is useful in many circumstances to regard (5) as a general method to find a sparse approximate solution to a linear system [7].
Reference: [7] <author> E. Chow and Y. Saad. </author> <title> Approximate inverse techniques for block-partitioned matrices, </title> <note> SIAM J. Sci. Comput., to appear. </note>
Reference-contexts: It is useful in many circumstances to regard (5) as a general method to find a sparse approximate solution to a linear system <ref> [7] </ref>. In our context, to solve Lz = v approximately, we focus on the minimization problem min kv Lzk 2 (6) with respect to all sparse z. By constraining the nonzero pattern of z to be the same as that of v, we have a type of ILU (0) factorization.
Reference: [8] <author> J. D. F. Cosgrove, J. C. Daz and A. Griewank. </author> <title> Approximate inverse preconditioning for sparse linear systems. </title> <journal> Intl. J. Comp. Math., </journal> <volume> 44 (1992), </volume> <pages> pp. 91-110. </pages>
Reference-contexts: Yet another possible strategy will be mentioned in Section 2.4. 2.2.2 Approximate inverse techniques A second, much cheaper approximation for (1) comes from approximate inverse techniques. Their most common application has been to independently approximate all the rows or columns of an inverse <ref> [2, 6, 8, 18, 15] </ref> or its factors [1, 19], and use it as a precon-ditioner.
Reference: [9] <author> I. S. Duff, R. G. Grimes and J. G. Lewis. </author> <title> Direct Methods for Sparse Matrices, </title> <publisher> Oxford University Press, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: Unfortunately, this cannot be done for the upper triangular factor. In this case, we estimate the infinity norm of its transpose. Other more complicated condition estimates are possible <ref> [3, 9, 14] </ref>, but we have not found them to be necessary for our purpose. An interesting way to determine how badly L k and U k are conditioned is to examine the residual norm reduction in the approximate inverse iteration. <p> ILUS in its simplest form does not circumvent instability any better than ILUT, for example. Techniques for augmenting the diagonal elements to enhance stability are possible for various forms of incomplete factorization, see e.g., <ref> [9, p. 196] </ref>. The ILUS algorithm may be summarized as follows. Algorithm 2.2 ILUS 1. Set D 1 = a 11 ; L 1 = U 1 = 1 3. Compute a sparse z k D 1 k L 1 4.
Reference: [10] <author> L. C. Dutto. </author> <title> The effect of ordering on preconditioned GMRES algorithms, for solving the compressible Navier-Stokes equations, </title> <journal> Int. J. Numer. Methods Engrg., </journal> <volume> 36 (1993), </volume> <pages> pp. 457-497. </pages>
Reference-contexts: Various stability issues have also been discussed, such as systematically checking some estimate of the norm of (LU ) 1 , furthering some understanding of what is required for robust preconditioners. As for any complete or incomplete factorization, the ordering of the matrix plays an important role <ref> [10] </ref>. Whereas `preordering' the matrix does not cause any more difficulties with ILUS than with other ILU factorizations, one disadvantage of ILUS is that it cannot easily accommodate `dynamic' orderings, i.e., orderings that can be generated as the factorization progresses.
Reference: [11] <author> H. C. Elman. </author> <title> A stability analysis of incomplete LU factorizations. </title> <journal> Math. Comp., </journal> <volume> 47 (1986), </volume> <pages> pp. 191-217. </pages>
Reference-contexts: In these cases, an ILU factorization may produce L and U factors such that the norm of (LU ) 1 is very large. The long recurrences associated with solving with these factors are unstable <ref> [4, 11] </ref>, producing solutions with extremely large components. A sign of this severely poor preconditioning is the erratic behavior of the iterative method, for example, divergence of the iterations due to large numerical errors.
Reference: [12] <author> M. Engelman. FIDAP: </author> <title> Examples Manual, Revision 6.0. </title> <booktitle> Fluid Dynamics International, </booktitle> <address> Evanston, Illinois, </address> <year> 1991. </year>
Reference-contexts: A sign of this severely poor preconditioning is the erratic behavior of the iterative method, for example, divergence of the iterations due to large numerical errors. As an example to illustrate the seriousness of the stability problem, we chose Example 7 from the FIDAP fluid dynamics analysis package <ref> [12] </ref>. This example models natural convection, and the matrix for the first step of the first nonlinear iteration has order 1633 and 46626 nonzeros.
Reference: [13] <author> U. Ghia, K. N. Ghia and C. T. Shin. </author> <title> High-Re solutions for incompressible flow using the Navier-Stokes equations and a multigrid method, </title> <journal> J. Comp. Phys., </journal> <volume> 48 (1982), </volume> <pages> pp. 387-411. </pages>
Reference-contexts: In typical operation, the factorization would have been aborted when the bounds exceeded some level. We tested ILUS by using it as a preconditioner for GMRES for solving the linear systems arising from the square lid-driven cavity problem <ref> [13] </ref>. The problem is modeled by the incompressible Navier-Stokes equations Re (u ru) = rp + r 2 u (7) over the unit square, where u denotes the velocity variables, p denotes the pressure variables, and Re is the Reynolds number.
Reference: [14] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations, 2nd edition. </title> <publisher> John Hopkins, </publisher> <address> Baltimore, </address> <year> 1989. </year> <note> ILUS 13 </note>
Reference-contexts: Unfortunately, this cannot be done for the upper triangular factor. In this case, we estimate the infinity norm of its transpose. Other more complicated condition estimates are possible <ref> [3, 9, 14] </ref>, but we have not found them to be necessary for our purpose. An interesting way to determine how badly L k and U k are conditioned is to examine the residual norm reduction in the approximate inverse iteration.
Reference: [15] <author> M. Grote and H. D. Simon. </author> <title> Parallel preconditioning and approximate inverses on the Connection Machine. </title> <editor> In R. F. Sincovec, D. E. Keyes, L. R. Petzold and D. A. Reed, eds., </editor> <booktitle> Parallel Processing for Scientific Computing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 519-523. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, Pennsylvania, </address> <year> 1993. </year>
Reference-contexts: Yet another possible strategy will be mentioned in Section 2.4. 2.2.2 Approximate inverse techniques A second, much cheaper approximation for (1) comes from approximate inverse techniques. Their most common application has been to independently approximate all the rows or columns of an inverse <ref> [2, 6, 8, 18, 15] </ref> or its factors [1, 19], and use it as a precon-ditioner.
Reference: [16] <author> I. Gustafsson. </author> <title> A class of first order factorization methods, </title> <journal> BIT, </journal> <volume> 18 (1978), </volume> <pages> pp. 142-156. </pages>
Reference-contexts: It is usually possible to produce a usable ILU factorization by allowing enough fill-in. Starting with ILU (0) or IC (0), where the nonzero pattern of the factorization is the same as that of the original matrix A, fill-in may be introduced by level-of-fill <ref> [16, 20, 28] </ref> or by threshold [21]. These indeed have been very successful for many fluid flow problems, for example, see [5]. For indefinite matrices, however, techniques based solely on level-of-fill may be inappropriate, because they ignore the numerical values.
Reference: [17] <author> Y. Hasbani and M. Engelman. </author> <title> Out-of-core solution of linear equations with nonsymmetric coefficient matrix, </title> <journal> Computers and Fluids, </journal> <note> 7 (1979), pp.13-31. </note>
Reference-contexts: The latter parameter allows the maximum storage for the preconditioner to be known beforehand. The regular skyline format, where all elements within the profile of the matrix are stored, is very commonly used in finite element computations, particularly when direct methods are employed, for example, see <ref> [17] </ref>. This new factorization is directed suited to matrices in this format. The preconditioner, which we call ILUS, is described in the next section. ILUS defines the procedure for computing an incomplete factorization by threshold for nonsymmetric matrices in sparse skyline format.
Reference: [18] <author> M. Grote and T. Huckle. </author> <title> Parallel preconditioning with sparse approximate inverses. </title> <note> SIAM J. Sci. Comput., to appear. </note>
Reference-contexts: Yet another possible strategy will be mentioned in Section 2.4. 2.2.2 Approximate inverse techniques A second, much cheaper approximation for (1) comes from approximate inverse techniques. Their most common application has been to independently approximate all the rows or columns of an inverse <ref> [2, 6, 8, 18, 15] </ref> or its factors [1, 19], and use it as a precon-ditioner.
Reference: [19] <author> L. Yu. Kolotilina and A. Yu. Yeremin. </author> <title> Factorized sparse approximate inverse precon-ditionings I. </title> <journal> Theory. SIAM J. Matrix Anal. Appl., </journal> <volume> 14 (1993), </volume> <pages> pp. 45-58. </pages>
Reference-contexts: Their most common application has been to independently approximate all the rows or columns of an inverse [2, 6, 8, 18, 15] or its factors <ref> [1, 19] </ref>, and use it as a precon-ditioner.
Reference: [20] <author> J. A. Meijerink and H. A. van der Vorst. </author> <title> An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix, </title> <journal> Math. Comput., </journal> <volume> 31 (1977), </volume> <pages> pp. 148-162. </pages>
Reference-contexts: It is usually possible to produce a usable ILU factorization by allowing enough fill-in. Starting with ILU (0) or IC (0), where the nonzero pattern of the factorization is the same as that of the original matrix A, fill-in may be introduced by level-of-fill <ref> [16, 20, 28] </ref> or by threshold [21]. These indeed have been very successful for many fluid flow problems, for example, see [5]. For indefinite matrices, however, techniques based solely on level-of-fill may be inappropriate, because they ignore the numerical values.
Reference: [21] <author> N. Munksgaard. </author> <title> Solving sparse symmetric sets of linear equations by preconditioned conjugate gradients, </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 6 (1980), </volume> <pages> pp. 206-219. </pages>
Reference-contexts: Starting with ILU (0) or IC (0), where the nonzero pattern of the factorization is the same as that of the original matrix A, fill-in may be introduced by level-of-fill [16, 20, 28] or by threshold <ref> [21] </ref>. These indeed have been very successful for many fluid flow problems, for example, see [5]. For indefinite matrices, however, techniques based solely on level-of-fill may be inappropriate, because they ignore the numerical values.
Reference: [22] <author> J. M. Ortega. </author> <title> Introduction to Parallel and Vector Solution of Linear Systems, </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: In Section 3, we show the numerical results of ILUS on the standard square lid-driven cavity problem, and in Section 4, we draw some conclusions. 2 ILUS 2.1 Factorization based on bordering ILUS is an incomplete form of LDU Gaussian elimination based on bordering <ref> [22, 25] </ref>. Let A k+1 be the (k + 1)-st leading principal submatrix of A and assume we have the decomposition A k = L k D k U k .
Reference: [23] <author> Y. Saad. </author> <title> A flexible inner-outer preconditioned GMRES algorithm. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 14 (1993), </volume> <pages> pp. 461-469. </pages>
Reference-contexts: Dropping may be applied at the end of each step if the number of steps is large, to reduce the cost of the method. Dropping may also be applied to the Krylov basis vectors if necessary, in which case a flexible version of GMRES <ref> [23] </ref> should be used. ILUS 6 Note that if no dropping is applied, the residual norm kv Lzk 2 is guaranteed to decrease. However, this is no longer true whenever elements are dropped in the solution vector.
Reference: [24] <author> Y. Saad. ILUT: </author> <title> A dual threshold incomplete LU factorization. </title> <journal> Num. Lin. Alg. Appl., </journal> <volume> 1 (1994), </volume> <pages> pp. 387-402. </pages>
Reference-contexts: For indefinite matrices, however, techniques based solely on level-of-fill may be inappropriate, because they ignore the numerical values. Threshold methods, on the other hand, are much more expensive, and it is difficult to determine their storage requirements beforehand. A middle-ground between these two approaches is ILUT <ref> [24] </ref>, ILUS 3 which uses a threshold for dropping fill-ins, and an additional threshold that limits the number of fill-ins per row in the factors L and U . Careful implementation of the sparse SAXPY and numerical dropping operations makes ILUT efficient.
Reference: [25] <author> Y. Saad. </author> <title> Preconditioned Krylov subspace methods for CFD applications, Proceedings of the International Workshop on Solution Techniques for Large-Scale CFD Problems, </title> <address> Montreal, </address> <month> Sept. </month> <pages> 26-28, </pages> <year> 1994, </year> <pages> pp. 179-195. </pages>
Reference-contexts: In Section 3, we show the numerical results of ILUS on the standard square lid-driven cavity problem, and in Section 4, we draw some conclusions. 2 ILUS 2.1 Factorization based on bordering ILUS is an incomplete form of LDU Gaussian elimination based on bordering <ref> [22, 25] </ref>. Let A k+1 be the (k + 1)-st leading principal submatrix of A and assume we have the decomposition A k = L k D k U k .
Reference: [26] <author> Y. Saad. SPARSKIT: </author> <title> a basic tool kit for sparse matrix computations. </title> <type> Technical Report 90-20, </type> <institution> Research Institute for Advanced Computer Science, NASA Ames Research Center, Moffet Field, </institution> <address> CA, </address> <year> 1990. </year>
Reference-contexts: The data structure for storing the triangular matrices must be augmented by a linked-list companion structure, which points to the entries in the matrix column by column. We describe this structure now. Suppose the matrix L is generated row by row and stored in compressed sparse row (CSR) format <ref> [26] </ref>, using the arrays A (NNZ), JA (NNZ), IA (N+1), where NNZ is the number of nonzeros in the matrix, and N is the order of the matrix. (The sparse skyline format is this structure combined with the matrix U stored in compressed sparse column (CSC) format, with the diagonal stored
Reference: [27] <author> Y. Saad and M. Schultz. </author> <title> GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 7 (1986), </volume> <pages> pp. 856-869. </pages> <address> ILUS 14 </address>
Reference-contexts: Another typical feature is that the norm bound decreases again for small lfil. The GMRES iterative procedure <ref> [27] </ref> preconditioned with these factorizations could not succeed in solving the linear system.
Reference: [28] <author> J. W. Watts-III. </author> <title> A conjugate gradient truncated direct method for the iterative solution of the reservoir simulation pressure equation, </title> <journal> Soc. Pet. Eng. J., </journal> <volume> 21 (1981), </volume> <pages> pp. 345-353. </pages>
Reference-contexts: It is usually possible to produce a usable ILU factorization by allowing enough fill-in. Starting with ILU (0) or IC (0), where the nonzero pattern of the factorization is the same as that of the original matrix A, fill-in may be introduced by level-of-fill <ref> [16, 20, 28] </ref> or by threshold [21]. These indeed have been very successful for many fluid flow problems, for example, see [5]. For indefinite matrices, however, techniques based solely on level-of-fill may be inappropriate, because they ignore the numerical values.
References-found: 28

