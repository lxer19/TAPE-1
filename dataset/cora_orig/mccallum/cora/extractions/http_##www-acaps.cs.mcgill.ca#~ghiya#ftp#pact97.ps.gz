URL: http://www-acaps.cs.mcgill.ca/~ghiya/ftp/pact97.ps.gz
Refering-URL: http://www.csd.uu.se/~thomasl/wpo/alias-papers.html
Root-URL: 
Title: Heap Analysis and Optimizations for Threaded Programs  
Author: Xinan Tang, Rakesh Ghiya, Laurie J. Hendren Guang R. Gao 
Address: Montreal, Quebec H3A 2A7 Newark, DE, USA 19716  
Affiliation: School of Computer Science Dept. of Electrical Engineering McGill University University of Delaware  
Abstract: Traditional compiler optimizations such as loop invariant removal and common sub-expression elimination are standard in all optimizing compilers. The purpose of this paper is to present new versions of these optimizations that apply to programs using dynamically-allocated data structures, and to show the effect of these optimizations on the performance of multithreaded programs. In this paper we show how heap pointer analyses can be used to support better dependence testing, new applications of the above traditional optimizations, and high-quality code generation for multithreaded architectures. We have implemented these analyses and optimizations in the EARTH-C compiler to study their impact on the performance of generated multithreaded code. We provide both static and dynamic measurements showing the effect of the optimizations applied individually, and together. We note several general trends, and discuss the performance tradeoffs, and suggest when specific optimizations are generally beneficial. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bentley. </author> <title> A parallel algorithm for constructing minimum spanning trees. </title> <journal> J. of Algorithms, </journal> <volume> 1, </volume> <year> 1980. </year>
Reference-contexts: The unit square image is recursively divided into four quadrants until each one has only one point. The tree is then traversed bottom-up to compute the perimeter of each quadrant. Mst computes the minimum spanning tree of a graph using Bentley's algorithm <ref> [1] </ref>. The vertices of the graph are divided evenly among the processors. At each step, each processor nominates one vertex to be added to the spanning tree, and the closest vertex to the partial spanning tree is selected. This process repeats until all vertices have been searched.
Reference: [2] <author> U. Bruening, W. K. Giloi, and W. Schroeder-Preikschat. </author> <title> Latency hiding in message-passing architectures. </title> <booktitle> In Proc. of the 8th Intl. Parallel Processing Symp., </booktitle> <pages> pages 704-709, </pages> <address> Cancun, Mexico, </address> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: The Threaded-C code contains lower-level thread primitives. The final executable code, which runs on the MANNA parallel architecture <ref> [2] </ref>, is compiled by the Portland pgcc compiler by linking with the EARTH threaded runtime library. <p> In each run, we measure the total program execution time including the tree (graph) building phase. Thus, the runtime improvement we achieved is for the whole program instead of some "kernel". Our experiments have been done using a multi-threaded emulator built on top of the MANNA parallel machine <ref> [2] </ref>. Each MANNA node consists of two Intel i860 XP CPUs, clocked at 50MHz, 32MB of dynamic RAM and a bidirectional network interface capable of transferring 50MB/s in each direction. The two processors on each node are mapped to the EARTH Execution Unit (EU) and Synchronization Unit (SU).
Reference: [3] <author> D. Callahan, S. Carr, and K. Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <booktitle> In Proc. of SIGPLAN PLDI '90, </booktitle> <pages> pages 53-65, </pages> <address> White Plains, N. Y., </address> <month> Jun. </month> <year> 1990. </year>
Reference-contexts: A location invariant access can be replaced by a scalar access, under some constraints. This optimization is similar in spirit to the scalar replacement technique proposed for array references <ref> [3] </ref>. Consider the loop in Figure 7 (a). In this loop the pointer reference r-&gt;item is location invariant as the pointer r is not written inside the loop.
Reference: [4] <author> M. C. Carlisle. </author> <title> Olden: Parallelizing Programs with Dynamic Data Structures on Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Princeton University Department of Computer Science, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: After listing both static and run-time statistics of threaded programs, we analyze the optimization effects on performance as well as examine the influence of other parallel performance factors on optimizations. 4.1 Benchmarks and EARTH-Manna system We have implemented four Olden <ref> [4, 15] </ref> benchmarks: health, em3d, perimeter, and mst to test the effect of our optimizations. Health simulates the Colombian health-care system using a 4-way tree [12]. Each village has four child villages, and a village hospital, treating patients from the villages in the same subtree.
Reference: [5] <author> M. Emami, R. Ghiya, and L. J. Hendren. </author> <title> Context-sensitive interprocedural points-to analysis in the presence of function pointers. </title> <booktitle> In Proc. of SIGPLAN PLDI '94, </booktitle> <pages> pages 242-256, </pages> <address> Orlando, Flor., </address> <month> Jun. </month> <year> 1994. </year>
Reference-contexts: with the keyword atomic, operates on a shared variable that is given as the first parameter, and it must not refer to remote memory, nor call any remote functions. 2.2 Heap Analysis To accurately disambiguate memory references via pointer indirections, our compiler presently uses two pointer analyses: (i) points-to analysis <ref> [5] </ref> and connection analysis [6]. Points-to analysis computes points-to pairs of the form (ptr, target). It accurately estimates the set of possible target locations for pointers that point to named memory locations (typically allocated on the stack).
Reference: [6] <author> R. Ghiya and L. J. Hendren. </author> <title> Connection Analaysis: A practical interprocedural heap analysis for C. </title> <journal> Intl. J. of Parallel Programming, </journal> <volume> 24(6) </volume> <pages> 547-578, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: operates on a shared variable that is given as the first parameter, and it must not refer to remote memory, nor call any remote functions. 2.2 Heap Analysis To accurately disambiguate memory references via pointer indirections, our compiler presently uses two pointer analyses: (i) points-to analysis [5] and connection analysis <ref> [6] </ref>. Points-to analysis computes points-to pairs of the form (ptr, target). It accurately estimates the set of possible target locations for pointers that point to named memory locations (typically allocated on the stack). <p> Similarly any access to the list pointed to by c must be disjoint from any access to the list pointed to by d. Complete details about connection analysis can be found in <ref> [6] </ref>. In order to enable optimizing transformations to treat both direct and indirect memory references, our compiler uses a read-write set analysis, which computes the sets of variables read and written by each statement.
Reference: [7] <author> R. Ghiya and L. J. Hendren. </author> <title> Putting pointer analysis to work. </title> <type> ACAPS Tech. Memo 107, </type> <institution> Sch. of Comp. Sci., McGill U., Montreal, Que., </institution> <month> Sep. </month> <year> 1997. </year>
Reference-contexts: Thus we need to capture connection relationships between specific incarnations of heap pointers. To this end, we introduce special new names, anchor handles, of the form ptr@Stmt which capture the connection relationships of a pointer at a given statement <ref> [7] </ref>. These anchor pointers are included in connection analysis by introducing ghost copy assignments of the form ptr@Stmt = ptr while analyzing the given statement. <p> Detailed algorithms for safely performing these optimizations using stack and heap read-write sets, are presented in <ref> [7] </ref>. while (p != NULL) - S: r-&gt;item = r-&gt;item + p-&gt;item; T: p = p-&gt;next; - temp_0 = r-&gt;item; while (p != NULL) - S: temp_0 = temp_0 + p-&gt;item; T: p = p-&gt;next; - r-&gt;item = temp_0; (b) /* LIR-1 */ invar_17 = (*village).hosp.free_personnel; /* LIR */ invar_18 = <p> The heap analysis techniques and optimizations presented in this paper can be applied to any C program. Actually, sequential programs also benefit from these optimizations <ref> [7] </ref>. The preprocessing and partitioning techniques used in our thread partitioner can also be applied to other non-preemptive multithreaded architectures, especially, the transformations designed to take advantage of more accurate heap analysis.
Reference: [8] <author> L. Hendren, C. Donawa, M. Emami, G. Gao, Justiani, and B. Sridharan. </author> <title> Designing the McCAT compiler based on a family of structured intermediate representations. </title> <booktitle> In Proc. of the 5th Intl. Work. on Languages and Compilers for Parallel Computing, number 757 in LNCS, </booktitle> <pages> pages 406-420, </pages> <address> New Haven, Conn., </address> <month> Aug. </month> <year> 1992. </year> <note> Springer-Verlag. Publ. in 1993. </note>
Reference-contexts: Thus, another goal of this paper is to study the effect of the optimizations and to find some general principles for when to apply certain optimizations. We have integrated the heap analyses and transformations into the EARTH-McCAT C compiler <ref> [8, 9] </ref>, and studied the effect of the optimizations on the performance of a collection of benchmark programs. We provide both static and dynamic measurements to show which optimizations give performance improvement, and we suggest some general guidelines on when to apply different optimizations on multithreaded architectures. <p> The EARTH-C compiler takes either C or EARTH-C programs as input, performs thread partitioning based on data-flow analyses such as side-effect (read-write) analysis and heap dependence analysis provided by the McCAT compiler <ref> [8] </ref>, and generates the Threaded-C code as output [10, 14]. The Threaded-C code contains lower-level thread primitives. The final executable code, which runs on the MANNA parallel architecture [2], is compiled by the Portland pgcc compiler by linking with the EARTH threaded runtime library.
Reference: [9] <author> L. J. Hendren, X. Tang, Y. Zhu, S. Ghobrial, G. R. Gao, X. Xue, H. Cai, and P. Ouellet. </author> <title> Compiling C for the EARTH multithreaded architecture. </title> <journal> Intl. J. of Parallel Programming, </journal> <volume> 25(4) </volume> <pages> 305-337, </pages> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: In this paper we address the problem of applying analyses and transformations designed for heap-allocated data structures. In particular, we integrate new kinds of standard optimizing transformations into our EARTH-C compiler that translates a parallel dialect of C, EARTH-C <ref> [9] </ref>, to a low-level multithreaded language, Threaded-C [10, 14]. The overall philosophy of the EARTH-C project is that we wish to present a high-level language to the programmer, and have the compiler apply appropriate analyses and transformations in order to automatically produce efficient low-level threaded programs. <p> Thus, another goal of this paper is to study the effect of the optimizations and to find some general principles for when to apply certain optimizations. We have integrated the heap analyses and transformations into the EARTH-McCAT C compiler <ref> [8, 9] </ref>, and studied the effect of the optimizations on the performance of a collection of benchmark programs. We provide both static and dynamic measurements to show which optimizations give performance improvement, and we suggest some general guidelines on when to apply different optimizations on multithreaded architectures. <p> The programmer can then add information such as coarse-grain parallelism and data locality to the program to enhance performance. A detailed description of the EARTH-C language has been given previously <ref> [9] </ref>, and a very brief summary is given here. <p> The remote level of a node represents the minimum number of thread boundaries from the root to the current node. Merging nodes with the same remote level into one thread is the partition strategy used in the EARTH-C compiler <ref> [9] </ref>. Even though other advanced thread partitioning algorithms have also been studied [22], we found that when the size of DDG is small (less than 50), this remote-level-based thread partitioning algorithm achieves competitive partitions as compared to other advanced partition algorithms. <p> We also implemented another optimization we call location invariant removal (LIR-1). Any pointer reference that 1 The remote level is also called the earliest thread number in <ref> [9] </ref> accesses the same memory location in all iterations of a loop is considered to be location invariant. A location invariant access can be replaced by a scalar access, under some constraints. This optimization is similar in spirit to the scalar replacement technique proposed for array references [3].
Reference: [10] <author> H. H. J. Hum, O. Maquelin, K. B. Theobald, X. Tian, G. R. Gao, and L. J. Hendren. </author> <title> A study of the EARTH-MANNA multithreaded system. </title> <journal> Intl. J. of Parallel Programming, </journal> <volume> 24(4) </volume> <pages> 319-347, </pages> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: In this paper we address the problem of applying analyses and transformations designed for heap-allocated data structures. In particular, we integrate new kinds of standard optimizing transformations into our EARTH-C compiler that translates a parallel dialect of C, EARTH-C [9], to a low-level multithreaded language, Threaded-C <ref> [10, 14] </ref>. The overall philosophy of the EARTH-C project is that we wish to present a high-level language to the programmer, and have the compiler apply appropriate analyses and transformations in order to automatically produce efficient low-level threaded programs. <p> The EARTH-C compiler takes either C or EARTH-C programs as input, performs thread partitioning based on data-flow analyses such as side-effect (read-write) analysis and heap dependence analysis provided by the McCAT compiler [8], and generates the Threaded-C code as output <ref> [10, 14] </ref>. The Threaded-C code contains lower-level thread primitives. The final executable code, which runs on the MANNA parallel architecture [2], is compiled by the Portland pgcc compiler by linking with the EARTH threaded runtime library.
Reference: [11] <author> A. Krishnamurthy and K. Yelick. </author> <title> Optimizing parallel programs with explicit synchronization. </title> <booktitle> In Proc. of SIGPLAN PLDI '95, </booktitle> <pages> pages 196-204, </pages> <address> La Jolla, Calif., </address> <month> Jun. </month> <year> 1995. </year>
Reference-contexts: Three of the most related works to this paper are: (1) Krishnamurthy and Yelick's work on using explicit synchronization provided by the programmer to optimize Split-C programs <ref> [11] </ref>; (2) Roh et. al's work on evaluating the impact of optimizations on threaded code generation [16]; and (3) Sohn et. al's work on identifying the capability of overlapping computation with communication [20].
Reference: [12] <author> G. Lomow, J. Cleary, B. Unger, and D. West. </author> <title> A performance study of Time Warp. </title> <booktitle> In Proc. of the SCS Multiconference on Distributed Simulation, </booktitle> <year> 1988. </year>
Reference-contexts: Health simulates the Colombian health-care system using a 4-way tree <ref> [12] </ref>. Each village has four child villages, and a village hospital, treating patients from the villages in the same subtree. At each time step, the tree is traversed, and patients, once assessed, are either treated or passed up to the parent.
Reference: [13] <author> N. Madsen. </author> <title> Divergence preserving discrete surface integral methods for maxwell's curl equations using non-orthogonal unstructured grids. </title> <type> Technical Report 92.04, </type> <institution> RIACS, </institution> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: The 4-way tree is distributed as evenly as possible among the processors for certain levels. Em3d is a computational problem based on an irregular bipartite graph containing nodes representing electric and magnetic field values (E nodes and H nodes, respectively) <ref> [13] </ref>. At each time step, new values for the E nodes are computed from a weighted sum of the neighboring H nodes, and then the same is done for the H nodes.
Reference: [14] <author> O. C. Maquelin, H. H. J. Hum, and G. R. Gao. </author> <title> Costs and benefits of multithreading with off-the-shelf RISC processors. </title> <booktitle> In Proc. of EURO-PAR '95, number 966 in LNCS, </booktitle> <pages> pages 117-128, </pages> <address> Stockholm, Sweden, Aug. 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In this paper we address the problem of applying analyses and transformations designed for heap-allocated data structures. In particular, we integrate new kinds of standard optimizing transformations into our EARTH-C compiler that translates a parallel dialect of C, EARTH-C [9], to a low-level multithreaded language, Threaded-C <ref> [10, 14] </ref>. The overall philosophy of the EARTH-C project is that we wish to present a high-level language to the programmer, and have the compiler apply appropriate analyses and transformations in order to automatically produce efficient low-level threaded programs. <p> The EARTH-C compiler takes either C or EARTH-C programs as input, performs thread partitioning based on data-flow analyses such as side-effect (read-write) analysis and heap dependence analysis provided by the McCAT compiler [8], and generates the Threaded-C code as output <ref> [10, 14] </ref>. The Threaded-C code contains lower-level thread primitives. The final executable code, which runs on the MANNA parallel architecture [2], is compiled by the Portland pgcc compiler by linking with the EARTH threaded runtime library.
Reference: [15] <author> A. Rogers, M. C. Carlisle, J. H. Reppy, and L. J. Hendren. </author> <title> Supporting dynamic data structures on distributed-memory machines. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 17(2) </volume> <pages> 233-263, </pages> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: After listing both static and run-time statistics of threaded programs, we analyze the optimization effects on performance as well as examine the influence of other parallel performance factors on optimizations. 4.1 Benchmarks and EARTH-Manna system We have implemented four Olden <ref> [4, 15] </ref> benchmarks: health, em3d, perimeter, and mst to test the effect of our optimizations. Health simulates the Colombian health-care system using a 4-way tree [12]. Each village has four child villages, and a village hospital, treating patients from the villages in the same subtree.
Reference: [16] <author> L. Roh, W. A. Najjar, B. Shankar, and A. P. W. Bohm. </author> <title> An evaluation of optimized threaded code generation. </title> <booktitle> In Proc. of the Conf. on Parallel Architectures and Compilation Techniques, </booktitle> <pages> pages 37-46, </pages> <address> Montreal, Que., </address> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: Three of the most related works to this paper are: (1) Krishnamurthy and Yelick's work on using explicit synchronization provided by the programmer to optimize Split-C programs [11]; (2) Roh et. al's work on evaluating the impact of optimizations on threaded code generation <ref> [16] </ref>; and (3) Sohn et. al's work on identifying the capability of overlapping computation with communication [20]. Krishnamurthy and Yelick use dataflow analysis for synchronization, barriers, and locks to eliminate unnecessary spurious cycles caused by accessing shared variables from different processors.
Reference: [17] <author> L. J. Roh. </author> <title> Code Generation, Evaluation, and Optimizations in Multithreaded Executions. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Colorado State University, </institution> <address> Fort Collins, Co 80523-1873, </address> <year> 1995. </year>
Reference-contexts: For a complete coverage, please refer to <ref> [17, 19] </ref>. There is relatively little research which has been done on studying the optimization impact on threaded programs, especially the heap-based optimization transformations we studied in this paper.
Reference: [18] <author> H. Samet. </author> <title> Computing perimeters of regions in images represented by quadtrees. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 3(6), </volume> <month> Nov. </month> <year> 1981. </year>
Reference-contexts: The main computation loop consists of each processor walking down its list of nodes, reading the values from neighbors and using them to update the current node. Perimeter computes the perimeter of a quad-tree encoded raster image <ref> [18] </ref>. The unit square image is recursively divided into four quadrants until each one has only one point. The tree is then traversed bottom-up to compute the perimeter of each quadrant. Mst computes the minimum spanning tree of a graph using Bentley's algorithm [1].
Reference: [19] <author> K. E. Schauser. </author> <title> Compiling Lenient Languages for Parallel Asynchronous Execution. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Division of Computer Science, University of California, Berkeley, Calif., </institution> <year> 1995. </year>
Reference-contexts: For a complete coverage, please refer to <ref> [17, 19] </ref>. There is relatively little research which has been done on studying the optimization impact on threaded programs, especially the heap-based optimization transformations we studied in this paper.
Reference: [20] <author> A. Sohn, J. Ku, Y. Kodama, M. Sato, H. Sakane, H.Yamana, S. Sakai, and Y. Yamaguchi. </author> <title> Identifying the capability of overlapping computation with communication. </title> <booktitle> In Proc. of the PACT'96, </booktitle> <address> Boston, Mass., Oct. 1996. </address> <publisher> North-Holland Pub. Co. </publisher>
Reference-contexts: are: (1) Krishnamurthy and Yelick's work on using explicit synchronization provided by the programmer to optimize Split-C programs [11]; (2) Roh et. al's work on evaluating the impact of optimizations on threaded code generation [16]; and (3) Sohn et. al's work on identifying the capability of overlapping computation with communication <ref> [20] </ref>. Krishnamurthy and Yelick use dataflow analysis for synchronization, barriers, and locks to eliminate unnecessary spurious cycles caused by accessing shared variables from different processors. They use more precise ordering information to overlap communication, eliminate redundant messages, and to pipeline messages.
Reference: [21] <author> B. Sridharan. </author> <title> An analysis framework for the McCAT compiler. </title> <type> Master's thesis, </type> <institution> McGill U., Montreal, Que., </institution> <month> Sep. </month> <year> 1992. </year>
Reference-contexts: on heap-based programs, in other sections we use more specific terms like heap analysis and heap dependence tests interchangeably with pointer analysis and pointer dependence tests. 2.3 Thread Generation in the EARTH-C compiler As shown in Figure 6, the input to the EARTH-C thread generator is a SIMPLE AST representation <ref> [21] </ref>. In SIMPLE, complicated expressions have been simplified into three-address format while the high-level control structures are still retained. For the EARTH-C compiler, the SIMPLE representation is further simplified so that each assignment statement contains at most one remote variable.
Reference: [22] <author> X. Tang, J. Wang, K. B. Theobald, and G. R. Gao. </author> <title> Thread partitioning and scheduling based on cost model. </title> <booktitle> In Proc. of SPAA `97, </booktitle> <pages> pages 272-281, </pages> <address> Newport, Rhode Island, </address> <month> Jun. </month> <year> 1997. </year>
Reference-contexts: Merging nodes with the same remote level into one thread is the partition strategy used in the EARTH-C compiler [9]. Even though other advanced thread partitioning algorithms have also been studied <ref> [22] </ref>, we found that when the size of DDG is small (less than 50), this remote-level-based thread partitioning algorithm achieves competitive partitions as compared to other advanced partition algorithms.
References-found: 22

