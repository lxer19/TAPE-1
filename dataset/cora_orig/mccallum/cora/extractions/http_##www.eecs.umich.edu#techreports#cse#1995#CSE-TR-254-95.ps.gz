URL: http://www.eecs.umich.edu/techreports/cse/1995/CSE-TR-254-95.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse95.html
Root-URL: http://www.eecs.umich.edu
Email: ganger,patt@eecs.umich.edu  
Title: Soft Updates: A Solution to the Metadata Update Problem in File Systems  
Author: Gregory R. Ganger, Yale N. Patt 
Address: Michigan  
Affiliation: Department of EECS, University of  
Abstract: Structural changes, such as file creation and block allocation, have consistently been identified as a source of problems (performance, integrity, security and availability) for file systems. This report describes soft updates, an implementation technique that allows a file system to safely use delayed writes for metadata updates. We show that a file system using soft updates asymptotically approaches memory-based file system performance while providing stronger integrity and security guarantees than most UNIX file systems. For metadata update intensive benchmarks, this improves performance by more than a factor of two when compared to the conventional synchronous write approach. In addition, soft updates can improve file system availability by relegating crash-recovery assistance (e.g., the fsck utility) to an optional and/or background role, reducing file system recovery time to a few seconds. 
Abstract-found: 1
Intro-found: 1
Reference: [Baker91] <author> M. Baker, J. Hartman, M. Kupfer, K. Shirriff, J. Ousterhout, </author> <title> "Measurements of a Distributed File System", </title> <booktitle> ACM Symposium on Operating Systems Principles, </booktitle> <year> 1991, </year> <pages> pp. 198-212. </pages>
Reference-contexts: Such a process's task would be very similar to garbage collection in object-oriented systems, except that it is needed only after a system failure. Most UNIX file system caches do a poor job of exploiting disk idle time. Workload studies (e.g., <ref> [Ousterhout85, McNutt86, Baker91, Ramakrishnan92] </ref>) have consistently demonstrated that file system activity is very bursty, consisting of interspersed periods of intense and near-zero usage. UNIX disk activity is also very bursty [Ruemmler93]. Disk idle time could be used by the file system cache to flush dirty blocks to disk.
Reference: [Carson92] <author> S. Carson, S. Setia, </author> <title> "Analysis of the Periodic Update Write Policy for Disk Cache", </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 18, No. 1, </volume> <month> January </month> <year> 1992, </year> <pages> pp. 44-54. </pages>
Reference-contexts: Disk idle time could be used by the file system cache to flush dirty blocks to disk. Such an approach is much less likely to suffer from the collisions between user-awaited disk activity and background disk activity that plague most UNIX systems <ref> [Carson92] </ref>. To provide data hardness guarantees, idle time flushing could be combined with a more conventional time-based approach, such as a syncer daemon or per-block timers [Mogul94].
Reference: [Chamberlin81] <author> D. Chamberlin, M. Astrahan, et. al., </author> <title> "A History and Evaluation of System R", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 24, No. 10, </volume> <year> 1981, </year> <pages> pp. 632-646. </pages>
Reference-contexts: Also, all disk schedulers (generally located in storage device drivers) must support the modified interface and the corresponding sequencing rules. Most other approaches to maintaining metadata integrity entail some form of logging (e.g., [Hagmann87, Chutani92, Journal92]) or shadow-paging (e.g., <ref> [Chamberlin81, Ston87, Chao92, Seltzer93] </ref>).
Reference: [Chao92] <author> C. Chao, R. English, D. Jacobson, A. Stepanov, J. Wilkes, "Mime: </author> <title> A High-Performance Parallel Storage Device with Strong Recovery Guarantees", </title> <institution> Hewlett-Packard Laboratories Report, </institution> <note> HPL-CSP-92-9 rev 1, </note> <month> November </month> <year> 1992. </year>
Reference-contexts: Also, all disk schedulers (generally located in storage device drivers) must support the modified interface and the corresponding sequencing rules. Most other approaches to maintaining metadata integrity entail some form of logging (e.g., [Hagmann87, Chutani92, Journal92]) or shadow-paging (e.g., <ref> [Chamberlin81, Ston87, Chao92, Seltzer93] </ref>). <p> Write-ahead logging provides the same protection as soft updates, but must use delayed group commit to achieve the same performance levels, increasing implementation complexity. Using shadow-paging to maintain integrity is difficult to do with delayed writes. Combined with soft updates, however, late binding of disk addresses to logical blocks <ref> [Chao92] </ref> could provide very high performance. The log-structured file system [Seltzer93] is a special case of shadow-paging that protects integrity by grouping many writes atomically (with a checksum to enforce atomicity).
Reference: [Chutani92] <author> S. Chutani, O. Anderson, M. Kazar, B. Leverett, W. Mason, R. Sidebotham, </author> <title> "The Episode File System", </title> <booktitle> Winter USENIX Conference, </booktitle> <month> January </month> <year> 1992, </year> <pages> pp. 43-60. </pages>
Reference-contexts: However, with scheduler-enforced ordering, delayed writes cannot safely be used when sequencing is required. Also, all disk schedulers (generally located in storage device drivers) must support the modified interface and the corresponding sequencing rules. Most other approaches to maintaining metadata integrity entail some form of logging (e.g., <ref> [Hagmann87, Chutani92, Journal92] </ref>) or shadow-paging (e.g., [Chamberlin81, Ston87, Chao92, Seltzer93]).
Reference: [Gaede81] <author> S. </author> <title> Gaede, "Tools for Research in Computer Workload Characterization", Experimental Computer Performance and Evaluation, 1981, </title> <editor> ed. by D. Ferrari and M. </editor> <publisher> Spadoni. </publisher>
Reference-contexts: The read-only phases (3 and 4) are practically indistinguishable. The compute-intensive compile phase improves by about 5 percent with Soft Updates and No Order. The compile phase dominates the total benchmark time because of aggressive compilation techniques and a slow CPU (by 1995 standards). 4.5 Sdet benchmarks. This benchmark <ref> [Gaede81, Gaede82] </ref> concurrently executes one or more scripts of user commands designed to emulate a typical software-development environment (e.g., editing, compiling, file creation and various UNIX utilities). The scripts are generated randomly from a predetermined mix of functions. The reported metric is scripts/hour as a function of the script concurrency.
Reference: [Gaede82] <author> S. </author> <title> Gaede, "A Scaling Technique for Comparing Interactive System Capacities", </title> <booktitle> 13th International Conference on Management and Performance Evaluation of Computer Systems, </booktitle> <year> 1982, </year> <pages> pp. 62-67. </pages>
Reference-contexts: The read-only phases (3 and 4) are practically indistinguishable. The compute-intensive compile phase improves by about 5 percent with Soft Updates and No Order. The compile phase dominates the total benchmark time because of aggressive compilation techniques and a slow CPU (by 1995 standards). 4.5 Sdet benchmarks. This benchmark <ref> [Gaede81, Gaede82] </ref> concurrently executes one or more scripts of user commands designed to emulate a typical software-development environment (e.g., editing, compiling, file creation and various UNIX utilities). The scripts are generated randomly from a predetermined mix of functions. The reported metric is scripts/hour as a function of the script concurrency.
Reference: [Ganger94] <author> G. Ganger, Y. Patt, </author> <title> "Metadata Update Performance in File Systems", </title> <booktitle> USENIX Symposium on Operating Systems Design and Implementation (OSDI), </booktitle> <month> November </month> <year> 1994, </year> <pages> pp. 49-60. </pages>
Reference-contexts: Also, many file systems do not guarantee the state of the on-disk free block/inode maps, electing to reconstruct them after a system failure (e.g., with the fsck utility [McKusick94]). <ref> [Ganger94] </ref> evaluates an alternative approach to update sequencing, called scheduler-enforced ordering, in which the file system uses asynchronous writes for metadata and passes any sequencing restrictions to the disk scheduler with each request. <p> This report describes soft updates, an implementation technique that allows a file system to safely use delayed writes for metadata updates <ref> [Ganger94] </ref>. With soft updates, the cost of maintaining integrity is low and performance asymptotically approaches that of a memory-based file system (within a few percent). For metadata update intensive benchmarks, this improves performance by more than a factor of two when compared to the conventional approach. <p> No changes to the on-disk metadata structures are required. Having learned key lessons from an initial implementation, we completed a partial soft updates implementation (described in <ref> [Ganger94] </ref>) in three weeks.
Reference: [Gingell87] <author> R. Gingell, J. Moran, W. Shannon, </author> <title> "Virtual Memory Architecture in SunOS", </title> <booktitle> Summer USENIX Conference, </booktitle> <month> June </month> <year> 1987, </year> <pages> pp. 81-94. </pages>
Reference-contexts: We use the ufs file system for our experiments, which is based on the Berkeley fast file system [McKusick84]. File system caching is well integrated with the virtual memory system, which is similar to that of SunOS <ref> [Gingell87, Moran87] </ref>. One important aspect of the file system's reliability and performance is the syncer daemon. This background process executes at regular intervals, writing out dirty buffer cache blocks.
Reference: [Hagmann87] <author> R. Hagmann, </author> <title> "Reimplementing the Cedar File System Using Logging and Group Commit", </title> <booktitle> ACM Symposium on Operating Systems Principles, </booktitle> <month> November </month> <year> 1987, </year> <pages> pp. 155-162. </pages>
Reference-contexts: However, with scheduler-enforced ordering, delayed writes cannot safely be used when sequencing is required. Also, all disk schedulers (generally located in storage device drivers) must support the modified interface and the corresponding sequencing rules. Most other approaches to maintaining metadata integrity entail some form of logging (e.g., <ref> [Hagmann87, Chutani92, Journal92] </ref>) or shadow-paging (e.g., [Chamberlin81, Ston87, Chao92, Seltzer93]).
Reference: [Howard88] <author> J. Howard, M. Kazar, S. Menees, D. Nichols, M. Satyanarayanan, R. Sidebotham, M. West, </author> <title> "Scale and Performance in a Distributed File System", </title> <journal> IEEE Transactions on Computer Systems, </journal> <volume> Vol. 6, No. 1, </volume> <month> February </month> <year> 1988, </year> <pages> pp. 51-81. 19 </pages>
Reference-contexts: Each value (in seconds) represents an average of 100 independent executions. The values in parentheses are the standard deviations. 4.4 Andrew Benchmark Table 3 compares the three implementations using the original Andrew file system benchmark <ref> [Howard88] </ref>, which consists of five phases: (1) create a directory tree, (2) copy the data files, (3) examine the status of every file, (4) read every byte of each file, (5) compile several of the files.
Reference: [HP92] <author> Hewlett-Packard Company, </author> <title> "HP C2244/45/46/47 3.5-inch SCSI-2 Disk Drive Technical Refer--ence Manual", Part Number 5960-8346, </title> <address> Edition 3, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: The HP C2447 disk drive used in the experiments is a high performance, 3.5-inch, 1 GB SCSI storage device <ref> [HP92] </ref>. The scheduling code in the device driver combines sequential requests, and the disk prefetches sequentially into its on-board cache. Command queueing at the disk is not utilized. We run all experiments with the network disconnected and with no other non-essential activity. We obtain our measurement data from two sources.
Reference: [Journal92] <author> NCR Corporation, </author> <title> "Journaling File System Administrator Guide, Release 2.00", NCR Document D1-2724-A, </title> <month> April </month> <year> 1992. </year>
Reference-contexts: However, with scheduler-enforced ordering, delayed writes cannot safely be used when sequencing is required. Also, all disk schedulers (generally located in storage device drivers) must support the modified interface and the corresponding sequencing rules. Most other approaches to maintaining metadata integrity entail some form of logging (e.g., <ref> [Hagmann87, Chutani92, Journal92] </ref>) or shadow-paging (e.g., [Chamberlin81, Ston87, Chao92, Seltzer93]).
Reference: [McKusick84] <author> M. McKusick, W. Joy, S. Le*er, R. Fabry, </author> <title> "A Fast File System for UNIX", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 2, No. 3, </volume> <month> August </month> <year> 1984, </year> <pages> pp. 181-197. </pages>
Reference-contexts: Synchronous 3 writes are used for metadata update sequencing by many variants of both the original UNIX T M file system [Ritchie78] and the Berkeley fast file system (FFS) <ref> [McKusick84] </ref>. As a result, metadata updates in these file systems proceed at disk speeds rather than processor/memory speeds [Ousterhout90, McVoy91, Seltzer93]. The performance degradation can be so dramatic that many implementations choose to ignore certain update dependencies, reducing integrity, security and/or availability. <p> We use the ufs file system for our experiments, which is based on the Berkeley fast file system <ref> [McKusick84] </ref>. File system caching is well integrated with the virtual memory system, which is similar to that of SunOS [Gingell87, Moran87]. One important aspect of the file system's reliability and performance is the syncer daemon. This background process executes at regular intervals, writing out dirty buffer cache blocks.
Reference: [McKusick90] <author> M. McKusick, M. Karels, K. Bostic, </author> <title> "A pageable memory based filesystem", </title> <booktitle> United Kingdom UNIX systems User Group (UKUUG) Summer Conference, </booktitle> <month> July </month> <year> 1990, </year> <pages> pp. 9-13. </pages>
Reference-contexts: This baseline has the same performance and lack of reliability as the delayed mount option described in [Ohta90]. It is also very similar to the memory-based file system described in <ref> [McKusick90] </ref>. The Conventional implementation uses synchronous writes to sequence metadata updates.
Reference: [McKusick94] <author> M. McKusick, T.J. Kowalski, </author> <title> "Fsck The UNIX File System Check Program", 4.4 BSD System Manager's Manual, </title> <publisher> O'Reilley & Associates, Inc., </publisher> <address> Sebastopol, CA, </address> <year> 1994, </year> <pages> pp. 3 1-21. </pages>
Reference-contexts: Also, many file systems do not guarantee the state of the on-disk free block/inode maps, electing to reconstruct them after a system failure (e.g., with the fsck utility <ref> [McKusick94] </ref>). [Ganger94] evaluates an alternative approach to update sequencing, called scheduler-enforced ordering, in which the file system uses asynchronous writes for metadata and passes any sequencing restrictions to the disk scheduler with each request.
Reference: [McNutt86] <author> B. McNutt, </author> <title> "An Empirical Study of Variations in DASD Volume Activity", </title> <booktitle> Computer Measurement Group (CMG) Conference, </booktitle> <year> 1986, </year> <pages> pp. 274-283. </pages>
Reference-contexts: Such a process's task would be very similar to garbage collection in object-oriented systems, except that it is needed only after a system failure. Most UNIX file system caches do a poor job of exploiting disk idle time. Workload studies (e.g., <ref> [Ousterhout85, McNutt86, Baker91, Ramakrishnan92] </ref>) have consistently demonstrated that file system activity is very bursty, consisting of interspersed periods of intense and near-zero usage. UNIX disk activity is also very bursty [Ruemmler93]. Disk idle time could be used by the file system cache to flush dirty blocks to disk.
Reference: [McVoy91] <author> L. McVoy, S. Kleiman, </author> <title> "Extent-like Performance from a UNIX File System", </title> <booktitle> Winter USENIX Conference, </booktitle> <month> January </month> <year> 1991, </year> <pages> pp. 1-11. </pages>
Reference-contexts: Synchronous 3 writes are used for metadata update sequencing by many variants of both the original UNIX T M file system [Ritchie78] and the Berkeley fast file system (FFS) [McKusick84]. As a result, metadata updates in these file systems proceed at disk speeds rather than processor/memory speeds <ref> [Ousterhout90, McVoy91, Seltzer93] </ref>. The performance degradation can be so dramatic that many implementations choose to ignore certain update dependencies, reducing integrity, security and/or availability. <p> fragment extension was added and debugged. 16 Software locking schemes that use lock files may encounter surprises because of this. 17 6 Conclusions and Future Work The use of synchronous writes and the fsck utility to protect metadata integrity has been identified as a file system performance and availability problem <ref> [Ousterhout90, McVoy91, Seltzer93] </ref>. We have described a new mechanism, soft updates, that can be used to achieve memory-based file system performance while providing stronger integrity and security guarantees (e.g., allocation initialization) and higher availability (via shorter recovery times) than most UNIX file systems.
Reference: [Mogul94] <author> J. Mogul, </author> <title> "A Better Update Policy", </title> <booktitle> Summer USENIX Conference, </booktitle> <year> 1994, </year> <pages> pp. 99-111. </pages>
Reference-contexts: To provide data hardness guarantees, idle time flushing could be combined with a more conventional time-based approach, such as a syncer daemon or per-block timers <ref> [Mogul94] </ref>. Because the soft updates mechanism appears so promising, we plan to compare it with other successful methods of protecting metadata integrity, such as non-volatile RAM (NVRAM), logging and shadow-paging.
Reference: [Moran87] <author> J. Moran, </author> <title> "SunOS Virtual Memory Implementation", </title> <booktitle> European UNIX Users Group (EUUG) Conference, Spring 1988, </booktitle> <pages> pp. 285-300. </pages>
Reference-contexts: We use the ufs file system for our experiments, which is based on the Berkeley fast file system [McKusick84]. File system caching is well integrated with the virtual memory system, which is similar to that of SunOS <ref> [Gingell87, Moran87] </ref>. One important aspect of the file system's reliability and performance is the syncer daemon. This background process executes at regular intervals, writing out dirty buffer cache blocks.
Reference: [Ohta90] <author> M. Ohta, H. Tezuka, </author> <title> "A fast /tmp file system by delay mount option", </title> <booktitle> Summer USENIX Conference, </booktitle> <month> June </month> <year> 1990, </year> <pages> pp. 145-150. </pages>
Reference-contexts: As a baseline (and a goal), we ignore ordering constraints (No Order) and use delayed writes for all metadata updates. This baseline has the same performance and lack of reliability as the delayed mount option described in <ref> [Ohta90] </ref>. It is also very similar to the memory-based file system described in [McKusick90]. The Conventional implementation uses synchronous writes to sequence metadata updates.
Reference: [Ousterhout85] <author> J. Ousterhout, H. Da Costa, D. Harrison, J. Kunze, M. Kupfer, J. Thompson, </author> <title> "A Trace-Driven Analysis of the UNIX 4.2 BSD File System", </title> <booktitle> ACM Symposium on Operating System Principles, </booktitle> <year> 1985, </year> <pages> pp. 15-24. </pages>
Reference-contexts: Such a process's task would be very similar to garbage collection in object-oriented systems, except that it is needed only after a system failure. Most UNIX file system caches do a poor job of exploiting disk idle time. Workload studies (e.g., <ref> [Ousterhout85, McNutt86, Baker91, Ramakrishnan92] </ref>) have consistently demonstrated that file system activity is very bursty, consisting of interspersed periods of intense and near-zero usage. UNIX disk activity is also very bursty [Ruemmler93]. Disk idle time could be used by the file system cache to flush dirty blocks to disk.
Reference: [Ousterhout90] <author> J. Ousterhout, </author> <title> "Why Aren't Operating Systems Getting Faster As Fast as Hardware?", </title> <booktitle> Summer USENIX Conference, </booktitle> <month> June </month> <year> 1990, </year> <pages> pp. 247-256. </pages>
Reference-contexts: Synchronous 3 writes are used for metadata update sequencing by many variants of both the original UNIX T M file system [Ritchie78] and the Berkeley fast file system (FFS) [McKusick84]. As a result, metadata updates in these file systems proceed at disk speeds rather than processor/memory speeds <ref> [Ousterhout90, McVoy91, Seltzer93] </ref>. The performance degradation can be so dramatic that many implementations choose to ignore certain update dependencies, reducing integrity, security and/or availability. <p> fragment extension was added and debugged. 16 Software locking schemes that use lock files may encounter surprises because of this. 17 6 Conclusions and Future Work The use of synchronous writes and the fsck utility to protect metadata integrity has been identified as a file system performance and availability problem <ref> [Ousterhout90, McVoy91, Seltzer93] </ref>. We have described a new mechanism, soft updates, that can be used to achieve memory-based file system performance while providing stronger integrity and security guarantees (e.g., allocation initialization) and higher availability (via shorter recovery times) than most UNIX file systems.
Reference: [Ramakrishnan92] <author> K. Ramakrishnan, P. Biswas, R. Karelda, </author> <title> "Analysis of File I/O Traces in Commercial Computing Environments", </title> <booktitle> ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <year> 1992, </year> <pages> pp. 78-90. </pages>
Reference-contexts: Such a process's task would be very similar to garbage collection in object-oriented systems, except that it is needed only after a system failure. Most UNIX file system caches do a poor job of exploiting disk idle time. Workload studies (e.g., <ref> [Ousterhout85, McNutt86, Baker91, Ramakrishnan92] </ref>) have consistently demonstrated that file system activity is very bursty, consisting of interspersed periods of intense and near-zero usage. UNIX disk activity is also very bursty [Ruemmler93]. Disk idle time could be used by the file system cache to flush dirty blocks to disk.
Reference: [Ritchie78] <author> D. Ritchie, K. Thompson, </author> <title> "The UNIX Time-Sharing System", </title> <journal> Bell System Technical Journal, </journal> <volume> Vol. 57, No. 6, </volume> <month> July/August </month> <year> 1978, </year> <pages> pp. 1905-1930. </pages>
Reference-contexts: Synchronous 3 writes are used for metadata update sequencing by many variants of both the original UNIX T M file system <ref> [Ritchie78] </ref> and the Berkeley fast file system (FFS) [McKusick84]. As a result, metadata updates in these file systems proceed at disk speeds rather than processor/memory speeds [Ousterhout90, McVoy91, Seltzer93]. The performance degradation can be so dramatic that many implementations choose to ignore certain update dependencies, reducing integrity, security and/or availability.
Reference: [Ruemmler93] <author> C. Ruemmler, J. Wilkes, </author> <title> "UNIX Disk Access Patterns", </title> <booktitle> Winter USENIX Conference, </booktitle> <month> January </month> <year> 1993, </year> <pages> pp. 405-420. </pages>
Reference-contexts: Most UNIX file system caches do a poor job of exploiting disk idle time. Workload studies (e.g., [Ousterhout85, McNutt86, Baker91, Ramakrishnan92]) have consistently demonstrated that file system activity is very bursty, consisting of interspersed periods of intense and near-zero usage. UNIX disk activity is also very bursty <ref> [Ruemmler93] </ref>. Disk idle time could be used by the file system cache to flush dirty blocks to disk. Such an approach is much less likely to suffer from the collisions between user-awaited disk activity and background disk activity that plague most UNIX systems [Carson92].
Reference: [Seltzer93] <author> M. Seltzer, K. Bostic, M. McKusick, C. Staelin, </author> <title> "An Implementation of a Log-Structured File System for UNIX", </title> <booktitle> Winter USENIX Conference, </booktitle> <month> January </month> <year> 1993, </year> <pages> pp. 201-220. </pages>
Reference-contexts: Synchronous 3 writes are used for metadata update sequencing by many variants of both the original UNIX T M file system [Ritchie78] and the Berkeley fast file system (FFS) [McKusick84]. As a result, metadata updates in these file systems proceed at disk speeds rather than processor/memory speeds <ref> [Ousterhout90, McVoy91, Seltzer93] </ref>. The performance degradation can be so dramatic that many implementations choose to ignore certain update dependencies, reducing integrity, security and/or availability. <p> Also, all disk schedulers (generally located in storage device drivers) must support the modified interface and the corresponding sequencing rules. Most other approaches to maintaining metadata integrity entail some form of logging (e.g., [Hagmann87, Chutani92, Journal92]) or shadow-paging (e.g., <ref> [Chamberlin81, Ston87, Chao92, Seltzer93] </ref>). <p> fragment extension was added and debugged. 16 Software locking schemes that use lock files may encounter surprises because of this. 17 6 Conclusions and Future Work The use of synchronous writes and the fsck utility to protect metadata integrity has been identified as a file system performance and availability problem <ref> [Ousterhout90, McVoy91, Seltzer93] </ref>. We have described a new mechanism, soft updates, that can be used to achieve memory-based file system performance while providing stronger integrity and security guarantees (e.g., allocation initialization) and higher availability (via shorter recovery times) than most UNIX file systems. <p> Using shadow-paging to maintain integrity is difficult to do with delayed writes. Combined with soft updates, however, late binding of disk addresses to logical blocks [Chao92] could provide very high performance. The log-structured file system <ref> [Seltzer93] </ref> is a special case of shadow-paging that protects integrity by grouping many writes atomically (with a checksum to enforce atomicity).

References-found: 27

