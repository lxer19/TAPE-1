URL: http://www.cs.toronto.edu/~greiner/PAPERS/impure-ml95.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: Email: greiner@scr.siemens.com  
Phone: Phone: (609) 734-3627  
Title: The Challenge of Revising an Impure Theory  
Author: Russell Greiner 
Date: July 1995.  
Note: To appear in the Proceedings of the Twelfth International Conference on Machine Learning (MLC-95),  
Address: 755 College Road East Princeton, NJ 08540-6632  Lake Tahoe,  
Affiliation: Siemens Corporate Research  
Abstract: A pure rule-based program will return a set of answers to each query; and will return the same answer set even if its rules are re-ordered. However, an impure program, which includes the Prolog cut "!" and not() operators, can return different answers if the rules are re-ordered. There are also many reasoning systems that return only the first answer found for each query; these first answers, too, depend on the rule order, even in pure rule-based systems. A theory revision algorithm, seeking a revised rule-base whose expected accuracy, over the distribution of queries, is optimal, should therefore consider modifying the order of the rules. This paper first shows that a polynomial number of training "labeled queries" (each a query coupled with its correct answer) provides the distribution information necessary to identify the optimal ordering. It then proves, however, that the task of determining which ordering is optimal, once given this information, is intractable even in trivial situations; e.g., even if each query is an atomic literal, we are seeking only a "perfect" theory, and the rule base is propositional. We also prove that this task is not even approximable: Unless P = N P , no polynomial time algorithm can produce an ordering of an n-rule theory whose accuracy is within n fl of optimal, for some fl &gt; 0. We also prove similar hardness, and non-approximatability, results for the related tasks of determining, in these impure contexts, (1) the optimal ordering of the antecedents; (2) the optimal set of rules to add or (3) to delete; and (4) the optimal priority values for a set of defaults. 
Abstract-found: 1
Intro-found: 1
Reference: [ALM + 92] <author> Sanjeev Arora, Carsten Lund, Rajeev Mot wani, Madhu Sudan, and Mario Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> In FOCS, </booktitle> <year> 1992. </year>
Reference-contexts: Following [CP91, Kan92], we define Definition 2 A maximization problem Max is Not-PolyApprox if there is a fl 2 &lt; + such that 8B 2 Poly ( Max ); 9x 2 Max; MaxPerf Max ( B; x ) jxj fl : Arora et al. <ref> [ALM + 92] </ref> prove that the "Maximum Independent Set maximization problem" is Not-PolyApprox. We can use that result to prove: Theorem 4 Unless P = N P , each of MAX Imp;P rop ( OR ) and MAX P ur;P C ( OR ) is NotPolyApprox.
Reference: [BCH90] <author> E. Boros, Y. Crama, and P.L. Hammer. </author> <title> Polynomial-time inference of all valid implications for horn and related formulae. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 21-32, </pages> <year> 1990. </year>
Reference-contexts: Our results show that the task of finding the optimal theory is intractable even given a poly-time oracle for these arbitrary derivations. Of course, as we are considering only Horn theories, these computations are guaranteed to be poly-time in the propositional case <ref> [BCH90] </ref>. 4 Following Prolog's conventions, we will capitalize each variable, as in the "X i " above.
Reference: [BGT93] <author> Francesco Bergadeno, Daniele Gunetti, and Umberto Trinchero. </author> <title> The difficulties of learning logic programs with cut. </title> <journal> Journal of AI Research, </journal> <volume> 1 </volume> <pages> 91-107, </pages> <year> 1993. </year>
Reference-contexts: Among other results, it proves that the task of finding the optimal set of new rules to add (resp., existing rules to delete) is intractable, but can be approximated to within a factor of 2, in this context. Second, Bergadeno et al. <ref> [BGT93] </ref> note that learning impure logic programs, which include the cut operator, is more difficult than learning pure programs; our paper gives additional teeth to this claim, by showing a particular task (viz., learning the best set of rules to add or to delete) that can be trivially approximated in the
Reference: [BI88] <author> G. Benedek and A. Itai. </author> <title> Nonuniform learn ability. </title> <booktitle> In ICALP-88, </booktitle> <pages> pages 82-92, </pages> <year> 1988. </year>
Reference-contexts: Observe however that AR (T) = k AR k (T)j) is polynomial in jTj. Hence, the number of samples required is polynomial in the "size" of the revised theory, which means we can apply the techniques from "nonuniform" pac-learning <ref> [BI88] </ref> to learn such classes. 4 Prioritizing Default Theories This section first provides a brief motivation and introduction to prioritized Theorist-style default theories, then shows that our basic results apply here as well.
Reference: [Bre89] <author> Gerhard Brewka. </author> <title> Preferred subtheories: An extended logical framework for default reasoning. </title> <booktitle> In IJCAI-89, </booktitle> <pages> pages 1043-48, </pages> <address> Detroit, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: Unfortunately, there are now two assumables that qualify, which give contradictory answers to this question. We can address this problem by assigning priorities to the defaults, with the understanding that lower priorities will be tried first <ref> [Bre89, vA90] </ref>.
Reference: [CM81] <author> William F. Clocksin and Christopher S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: any knowledge-based system written in a shell that uses operators corresponding to Prolog's cut "!" or not (), as well as any system that returns only the first answer found; this class of shells includes TestBench 1 and other fault-hierarchy systems, and prioritized default theories [Gro91], as well as Pro-log <ref> [CM81] </ref>. The goal of a theory revision process is to improve the accuracy of the reasoning system on its performance task of answering queries. <p> A theory is considered "impure" if it includes any rule whose antecedents use either the Prolog cut "!" or negation-as-failure "not ()" operator. See <ref> [CM81] </ref> for a description of how Prolog answers queries in general, and in particular, how it uses these operators.
Reference: [CP91] <author> P. Crescenzi and A. Panconesi. </author> <title> Complete ness in approximation classes. </title> <journal> Information and Computation, </journal> <volume> 93(2) </volume> <pages> 241-62, </pages> <year> 1991. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt; + , then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 5 However, not all problems can be approximated. Following <ref> [CP91, Kan92] </ref>, we define Definition 2 A maximization problem Max is Not-PolyApprox if there is a fl 2 &lt; + such that 8B 2 Poly ( Max ); 9x 2 Max; MaxPerf Max ( B; x ) jxj fl : Arora et al. [ALM + 92] prove that the "Maximum Independent
Reference: [DP91] <author> Jon Doyle and Ramesh Patil. </author> <title> Two the ses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3), </volume> <year> 1991. </year>
Reference-contexts: Borrowing from <ref> [Lev84, DP91] </ref>, we also view a theory T as a function that maps each query to its proposed answer; hence, T : Q 7! A, where Q is a (possibly infinite) set of queries, and A = f No; Yes g is the set of possible answers.
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Section 3 then presents our main results, showing first that this task is intractable 2 even in trivial situations | e.g., even if each query is 1 TestBench is a trademark of Carnegie Group, Inc. 2 Throughout, we will assume that P 6= N P <ref> [GJ79] </ref>, which implies that any NP-hard problem is intractable. This also implies certain approximation claims, presented below. an atomic literal, we are only seeking a "perfect" ordering (which returns the correct answer to each given query), and the knowledge base is propositional. <p> Approximatability: Many decision problems correspond immediately to optimization problems; for example, the IndependentSet decision problem (given a graph G = hN; Ei and a positive integer K, is there a subset M N of at least jM j K nodes that are not connected to one another <ref> [GJ79, p194] </ref>) corresponds to the obvious maximization problem: Given a graph G = hN; Ei, find the largest independent subset of N . <p> For example, there is a polynomial-time algorithm that computes a solution whose cost is (es-sentially) within a factor of 11=9 for any MaxBinPacking maximization problem; see <ref> [GJ79, Theorem 6.2] </ref>. ity, computational complexity and approximatability). Here, we obtain the same results, mutatis mutandis: First, note that j OA (T)j = Q c2T (#Ants (c))! = O (jTj jT j ), where #Ants (c) 2 Z 0 refers to the number of antecedents in the clause c. <p> Finally, this paper also proves non-approximatable the task of determining the best priority values of a set of defaults. A Proof Sketches of Some Theorems Proof of Theorem 2 (sketch): 8 We reduce DP P erf;Imp;P rop ( OR ) to 3sat <ref> [GJ79, p259] </ref>: Determine if there is an variable assignment that satisfies a given 3-CNF formula (which is a conjunction of clauses, where each clause is a disjunction of at most three literals). <p> The query/answer set is fhc j ; Yesi for c j 2 'g: Now observe there is a perfect re-ordering of T ' 's clauses iff ' has a satisfying assignment. The proof for DP P erf;P ur;P C ( OR ) is a more cumbersome reduction to Monotone3sat <ref> [GJ79, p259] </ref>, which is an NP-complete special case of 3sat where each clause contains either all positive, or all negative, literals. <p> The query/answer pairs are S (P C) Once again, there is a perfect ordering of T (P C) clauses iff ' is satisfiable. 2 Proof of Theorem 3 (sketch): The proof for DP P erf;Imp;P rop ( OR K ) is a reduction to x3c (Exact Cover by 3-Sets <ref> [GJ79, p221] </ref>): Given a set of elements X = fx i g 3K i=1 and collection of 3-element subsets C = fc j g M j=1 of elements of X, determine if there is a subcollection C 0 C of disjoint sets whose union covers all of X.
Reference: [Gre91] <author> Russell Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50(1) </volume> <pages> 95-116, </pages> <year> 1991. </year>
Reference-contexts: Our results show that this "optimal deletion" task is not just intractable, but is in fact, non-approximatable, even in the (impure) propositional case, when all rules have unit weight and a single successful rule is sufficient to establish a conclusion. Finally, this paper has some superficial similarities with <ref> [Gre91] </ref>, as both articles consider the complexity of (in essence) ordering a set of rules. However, while [Gre91] deals with the efficiency of finding any answer to a given query, this paper deals with the accuracy of the particular answer returned. 2 Framework Section 2.1 first describes propositional Prolog programs; Section <p> Finally, this paper has some superficial similarities with <ref> [Gre91] </ref>, as both articles consider the complexity of (in essence) ordering a set of rules. However, while [Gre91] deals with the efficiency of finding any answer to a given query, this paper deals with the accuracy of the particular answer returned. 2 Framework Section 2.1 first describes propositional Prolog programs; Section 2.2 then extends this description to predicate calculus.
Reference: [Gre95a] <author> Russell Greiner. </author> <title> The challenge of revis ing impure theories. </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1995. </year> <note> (See also ftp://scr.siemens.com/pub/learning/ Papers/greiner/impure.ps). </note>
Reference-contexts: Section 5.1 presents several generalizations of our framework. The appendix includes proof sketches of many of the theorems; the complete set of proofs appear in the extended paper <ref> [Gre95a] </ref>. We first close this introduction by describing some related research. Related Research: This paper describes the complexity of a particular form of theory revision. <p> We first state the results known about the standard pure context: Theorem 7 (from <ref> [Gre95a] </ref>) In the pure context, for each 2 f AR ; DR g, * DP P erf;P rop;Pur ( ) is NP-complete, * MAX P ur ( ) is trivial to approximate: 9B 2 Poly ( MAX P ur ( ) ), 8x 2 MAX P ur ( ) ; MaxPerf
Reference: [Gre95b] <author> Russell Greiner. </author> <title> The complexity of the ory revision. </title> <booktitle> In IJCAI-95, </booktitle> <year> 1995. </year> <note> (See also ftp://scr.siemens.com/pub/learning/ Papers/greiner/comp-tr.ps). </note>
Reference-contexts: The companion paper <ref> [Gre95b] </ref> analyses the classes of transformations used by those other systems: adding or deleting either a rule or an antecedent within a rule, in the standard pure context.
Reference: [Gro91] <author> Benjamin Grosof. </author> <title> Generalizing prioritiza tion. </title> <booktitle> In KR-91, </booktitle> <pages> pages 289-300, </pages> <address> Boston, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: effectively modify the performance of any knowledge-based system written in a shell that uses operators corresponding to Prolog's cut "!" or not (), as well as any system that returns only the first answer found; this class of shells includes TestBench 1 and other fault-hierarchy systems, and prioritized default theories <ref> [Gro91] </ref>, as well as Pro-log [CM81]. The goal of a theory revision process is to improve the accuracy of the reasoning system on its performance task of answering queries.
Reference: [Kan92] <author> Viggo Kann. </author> <title> On the Approximability of NP-Complete Optimization Problems. </title> <type> PhD thesis, </type> <institution> Royal Institute of Technology, Stockholm, </institution> <year> 1992. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt; + , then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 5 However, not all problems can be approximated. Following <ref> [CP91, Kan92] </ref>, we define Definition 2 A maximization problem Max is Not-PolyApprox if there is a fl 2 &lt; + such that 8B 2 Poly ( Max ); 9x 2 Max; MaxPerf Max ( B; x ) jxj fl : Arora et al. [ALM + 92] prove that the "Maximum Independent
Reference: [LDRG94] <author> Pat Langley, George Drastal, R. Bharat Rao, and Russell Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Fifth International Workshop on Principles of Diagnosis (DX-94), </booktitle> <address> New Paltz, NY, </address> <year> 1994. </year>
Reference-contexts: We first close this introduction by describing some related research. Related Research: This paper describes the complexity of a particular form of theory revision. While there are many implemented theory revision systems (including Audrey [WP93], Fonte [MB88], Either [OM94] and <ref> [LDRG94] </ref>), most deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query; they therefore do not consider the particular class of transformations described in this paper.
Reference: [Lev84] <author> Hector J. Levesque. </author> <title> Foundations of a func tional approach to knowledge representation. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 155-212, </pages> <year> 1984. </year>
Reference-contexts: Borrowing from <ref> [Lev84, DP91] </ref>, we also view a theory T as a function that maps each query to its proposed answer; hence, T : Q 7! A, where Q is a (possibly infinite) set of queries, and A = f No; Yes g is the set of possible answers.
Reference: [LV91] <author> Charles Ling and Marco Valtorta. </author> <title> Revision of reduced theories. </title> <booktitle> In MLC-91, </booktitle> <pages> pages 519-23, </pages> <year> 1991. </year>
Reference-contexts: Third, Valtorta <ref> [Val89, Val90, LV91] </ref> also considers the computational complexity of modifying a theory. Those papers, however, deal with a different type of modifications: viz., adjusting the numeric "weights" within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by arranging rules or antecedents.
Reference: [MB88] <author> S. Muggleton and W. Buntine. </author> <title> Machine in vention of first order predicates by inverting resolution. </title> <booktitle> In MLC-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: We first close this introduction by describing some related research. Related Research: This paper describes the complexity of a particular form of theory revision. While there are many implemented theory revision systems (including Audrey [WP93], Fonte <ref> [MB88] </ref>, Either [OM94] and [LDRG94]), most deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query; they therefore do not consider the particular class of transformations described in this paper.
Reference: [OM94] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66(2) </volume> <pages> 273-310, </pages> <year> 1994. </year>
Reference-contexts: We first close this introduction by describing some related research. Related Research: This paper describes the complexity of a particular form of theory revision. While there are many implemented theory revision systems (including Audrey [WP93], Fonte [MB88], Either <ref> [OM94] </ref> and [LDRG94]), most deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query; they therefore do not consider the particular class of transformations described in this paper.
Reference: [PGA87] <author> David Poole, Randy Goebel, and Romas Aleliunas. </author> <title> Theorist: A logical reasoning system for default and diagnosis. The Knowledge Frontier: </title> <booktitle> Essays in the Representation of Knowledge, </booktitle> <pages> pages 331-52, </pages> <address> New York, 1987. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: Unless, of course, we learn that b is in an airplane, etc etc etc. [Rei87] The Theorist system <ref> [PGA87] </ref> provides one way to encode such information. 7 Its knowledge base consists of a set of facts F = ff i g which are the unchallengable claims and a set of "assumables" D = fd j g, which correspond to the defaults.
Reference: [Rei87] <author> Raymond Reiter. </author> <title> Nonmonotonic reason ing. </title> <booktitle> In Annual Review of Computing Sciences, </booktitle> <volume> volume 2, </volume> <pages> pages 147-87. </pages> <publisher> Annual Reviews Incorporated, </publisher> <address> Palo Alto, </address> <year> 1987. </year>
Reference-contexts: Unless, of course, we learn that b is in an airplane, etc etc etc. <ref> [Rei87] </ref> The Theorist system [PGA87] provides one way to encode such information. 7 Its knowledge base consists of a set of facts F = ff i g which are the unchallengable claims and a set of "assumables" D = fd j g, which correspond to the defaults.
Reference: [vA90] <author> Paul van Arragon. </author> <title> Nested default rea soning with priority levels. </title> <booktitle> In CSCSI-90, </booktitle> <pages> pages 77-83, </pages> <address> Ottawa, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Unfortunately, there are now two assumables that qualify, which give contradictory answers to this question. We can address this problem by assigning priorities to the defaults, with the understanding that lower priorities will be tried first <ref> [Bre89, vA90] </ref>.
Reference: [Val89] <author> Marco Valtorta. </author> <title> Some results on the com plexity of knowledge-base refinement. </title> <booktitle> In MLC-89 pages 326-31, </booktitle> <year> 1989. </year>
Reference-contexts: Third, Valtorta <ref> [Val89, Val90, LV91] </ref> also considers the computational complexity of modifying a theory. Those papers, however, deal with a different type of modifications: viz., adjusting the numeric "weights" within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by arranging rules or antecedents.
Reference: [Val90] <author> Marco Valtorta. </author> <title> More results on the com plexity of knowledge base refinement: Belief networks. </title> <booktitle> In MLC-90, </booktitle> <pages> pages 419-26, </pages> <year> 1990. </year>
Reference-contexts: Third, Valtorta <ref> [Val89, Val90, LV91] </ref> also considers the computational complexity of modifying a theory. Those papers, however, deal with a different type of modifications: viz., adjusting the numeric "weights" within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by arranging rules or antecedents.
Reference: [Vap82] <author> V.N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Of course, as we are considering only Horn theories, these computations are guaranteed to be poly-time in the propositional case [BCH90]. 4 Following Prolog's conventions, we will capitalize each variable, as in the "X i " above. Theorem 1 (from <ref> [Vap82, Theorem 6.2] </ref>) Given a class of theories = (T ) and constants *; ffi &gt; 0, let T fl 2 be the theory with the largest empirical accuracy after M upper (; *; ffi) = ~ * 2 ln jj samples (each a labeled query), drawn from the stationary distribution.
Reference: [Vor91] <author> David Vormittag. </author> <title> Evaluating answers to questions, </title> <month> May </month> <year> 1991. </year> <type> Bachelors Thesis, </type> <institution> University of Toronto. </institution>
Reference-contexts: There are obvious ways of extending our analysis to allow a more comprehensive accuracy function a (T; ) that could apply different rewards and penalties for different queries (e.g., to permit different penalties for incorrectly identifying the location of a salt-shaker, versus the location of a stalking tiger <ref> [Vor91] </ref>).
Reference: [WM94] <author> David C. Wilkins and Yong Ma. </author> <title> The re finement of probabilistic rule sets: sociopathic interactions. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 1-32, </pages> <year> 1994. </year>
Reference-contexts: Those papers, however, deal with a different type of modifications: viz., adjusting the numeric "weights" within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by arranging rules or antecedents. Wilkins and Ma <ref> [WM94] </ref> show the intractability of determin ing the best set of rules to delete in the context of such weighted rules, where a conclusion is believed if a specified function of the weights of the supporting rules exceeds a threshold.
Reference: [WP93] <author> James Wogulis and Michael J. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In IJCAI-93, </booktitle> <pages> pages 1128-1134, </pages> <year> 1993. </year>
Reference-contexts: We first close this introduction by describing some related research. Related Research: This paper describes the complexity of a particular form of theory revision. While there are many implemented theory revision systems (including Audrey <ref> [WP93] </ref>, Fonte [MB88], Either [OM94] and [LDRG94]), most deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query; they therefore do not consider the particular class of transformations described in this paper.
References-found: 28

