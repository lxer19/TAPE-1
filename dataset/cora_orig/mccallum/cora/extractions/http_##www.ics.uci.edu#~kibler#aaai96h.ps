URL: http://www.ics.uci.edu/~kibler/aaai96h.ps
Refering-URL: http://www.ics.uci.edu/~kibler/
Root-URL: 
Email: fyhu, kiblerg@ics.uci.edu  
Title: A Wrapper Approach for Constructive Induction  
Author: Yuh-Jyh Hu and Dennis Kibler 
Address: Irvine  
Affiliation: Information and Computer Science Department University of California,  
Abstract: Inductive algorithms rely strongly on their representational biases. Representational inadequacy can be mitigated by constructive induction. This paper introduces the notion of a relative gain measure and describes a new constructive induction algorithm (GALA) which is independent of the learning algorithm. GALA generates a small number of new boolean attributes from existing boolean, nominal or real-valued attributes. Unlike most previous research on constructive induction, our methods are designed as preprocessing step before standard machine learning algorithms are applied. We present results which demonstrate the effectiveness of GALA on both artificial and real domains for both symbolic and subsymbolic learners. For symbolic learners, we used C4.5 and CN2. For subsymbolic learners, we used perceptron and backpropagation. In all cases, the GALA preprocessor increased the performance of the learning algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. </author> <title> "Incremental Constructive Induction: An Instanced-Based Approach", </title> <booktitle> in Proceeding of the 8th Machine Learning Workshop, </booktitle> <address> p117-121, </address> <year> 1991. </year>
Reference: <author> Clark, P. & Boswell, R. </author> <title> "Rule Induction with CN2: some recent improvements", </title> <booktitle> European Working Session on Learning, </booktitle> <address> p151-161, </address> <year> 1991. </year>
Reference: <author> Clark, P. & Niblett, T. </author> <title> "The CN2 Induction Algorithm", </title> <booktitle> Machine Learning 3, </booktitle> <address> p261-283, </address> <year> 1989. </year>
Reference: <author> Dietterich, T. G. & Michalski, R. S. </author> <title> "Inductive Learning of Structural Description : Evaluation Criteria and Comparative Review of Selected Methods", </title> <booktitle> Artificial Intelligence 16 (3), </booktitle> <address> p257-294, </address> <year> 1981. </year>
Reference: <author> Fawcett, T. E. & Utgoff, P. E. </author> <title> "Automatic Feature Generation for Problem Solving Systems", </title> <booktitle> in Proceeding of the 9th International Workshop on Machine Learning, </booktitle> <address> p144-153, </address> <year> 1992. </year>
Reference: <author> Flann, N. S. & Dietterich, T. G. </author> <title> "Selecting Appropriate Representations for Learning from Examples", </title> <booktitle> in Proceeding of the 5th National Conference on Artificial Intelligence, </booktitle> <address> p460-466, </address> <year> 1986. </year>
Reference: <author> Kadie, C. M. </author> <title> "Quantifying the Value of Constructive Induction, Knowledge, and Noise Filtering on Inductive Learning", </title> <booktitle> in Proceeding of the 8th Machine Learning Workshop, </booktitle> <address> p153-157, </address> <year> 1991. </year> <note> 16 Matheus, </note> <author> C. J. & Rendell, L. A. </author> <title> "Constructive Induction on Decision Trees", </title> <booktitle> in Proceeding of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <address> p645-650, </address> <year> 1989. </year>
Reference: <author> Matheus, C. J. </author> <title> "The Need for Constructive Induction", </title> <booktitle> in Proceeding of the 8th Machine Learning Workshop, </booktitle> <address> p173-177, </address> <year> 1991. </year>
Reference: <author> Mehra, P., Rendell, L. A., Wah, B. W. </author> <title> "Principled Constructive Induction", </title> <booktitle> in Proceeding of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <address> p651-656, </address> <year> 1989. </year>
Reference: <author> Norton, S. W. </author> <title> "Generating better Decision Trees", </title> <booktitle> in Proceeding of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <address> p800-805, </address> <year> 1989. </year>
Reference: <author> Pagallo, G. </author> <title> "Learning DNF by Decision Trees", </title> <booktitle> in Proceeding of the 11th International Joint Conference on Artificial Intelligence. </booktitle>
Reference: <author> Pagallo, G. & Haussler, D. </author> <title> "Boolean Feature Discovery in Empirical Learning", </title> <booktitle> Machine Learning 5, </booktitle> <address> p71-99, </address> <year> 1990. </year>
Reference: <author> Perez, E. & Rendell, L. </author> <title> "Using Multidimensional Projection to Find Relations", </title> <booktitle> in Proceeding of the 12th Machine Learning Conference, </booktitle> <address> p447-455, </address> <year> 1995. </year>
Reference-contexts: Besides, LFC constructs new attributes only from a beam of existing attributes and the original attributes. This method is more efficient than naive lookahead search,but it also restricts the construction of new attributes <ref> (Perez & Rendell, 1995) </ref>. Furthermore, LFC is currently a 2-class learner which cannot be applied to multiple-class domains.
Reference: <author> Quinlan, J. R. </author> <title> "Learning efficient classification procedures and their application to chess end games" , in Michalski et. al.'s Machine Learning : An artificial intelligence approach. </title> <editor> (Eds.) </editor> <year> 1983. </year>
Reference: <author> Quinlan, J. R. </author> <title> C4.5 : Programs for Machine Learning, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: <author> Ragavan, H., Rendell, L., Shaw, M., Tessmer, A. </author> <title> "Complex Concept Acquisition through Directed Search and Feature Caching", </title> <booktitle> in Proceeding of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <address> p946-958, </address> <year> 1993. </year>
Reference-contexts: Thus, the experimental results show that the combined heuristic constrain the search space without hurting the resulting accuracy. 5 Related Work FRINGE-like algorithms construct new features from an initial decision tree. Such strategies are insufficient when attributes interact strongly <ref> (Rendell & Ragavan, 1993) </ref>. <p> In contrast, GALA constructs new attributes by iteratively conjoining attributes that have high relative and absolute gains. This directs the algorithm to construct worthwhile and novel features. Another way to discover attribute interaction is by using lookahead <ref> (Ren-dell & Ragavan, 1993) </ref>, but naive lookahead search is expensive. LFC (Raga-van & Rendell, 1993, Ragavan et. al. 1993) uses directed lookahead search to avoid computational explosion. <p> In contrast, GALA constructs new attributes by iteratively conjoining attributes that have high relative and absolute gains. This directs the algorithm to construct worthwhile and novel features. Another way to discover attribute interaction is by using lookahead (Ren-dell & Ragavan, 1993), but naive lookahead search is expensive. LFC <ref> (Raga-van & Rendell, 1993, Ragavan et. al. 1993) </ref> uses directed lookahead search to avoid computational explosion. However, LFC uses a variant of averaged entropy as its quality measure which may also run into the same danger of overlooking promising attributes as mentioned earlier.
Reference: <author> Ragavan, H. & Rendell, L. </author> <title> "Lookahead Feature Construction for Learning Hard Concepts", </title> <booktitle> in Proceeding of the 10th Machine Learning Conference, </booktitle> <address> p252-259, </address> <year> 1993. </year> <note> 17 Rendell L. </note> <author> A. & Ragavan, H. </author> <title> "Improving the Design of Induction Methods by Analyzing Algorithm Functionality and Data-Based Concept Complexity", </title> <booktitle> in Proceeding of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <address> p952-958, </address> <year> 1993. </year>
Reference-contexts: Thus, the experimental results show that the combined heuristic constrain the search space without hurting the resulting accuracy. 5 Related Work FRINGE-like algorithms construct new features from an initial decision tree. Such strategies are insufficient when attributes interact strongly <ref> (Rendell & Ragavan, 1993) </ref>. <p> In contrast, GALA constructs new attributes by iteratively conjoining attributes that have high relative and absolute gains. This directs the algorithm to construct worthwhile and novel features. Another way to discover attribute interaction is by using lookahead <ref> (Ren-dell & Ragavan, 1993) </ref>, but naive lookahead search is expensive. LFC (Raga-van & Rendell, 1993, Ragavan et. al. 1993) uses directed lookahead search to avoid computational explosion. <p> In contrast, GALA constructs new attributes by iteratively conjoining attributes that have high relative and absolute gains. This directs the algorithm to construct worthwhile and novel features. Another way to discover attribute interaction is by using lookahead (Ren-dell & Ragavan, 1993), but naive lookahead search is expensive. LFC <ref> (Raga-van & Rendell, 1993, Ragavan et. al. 1993) </ref> uses directed lookahead search to avoid computational explosion. However, LFC uses a variant of averaged entropy as its quality measure which may also run into the same danger of overlooking promising attributes as mentioned earlier.
Reference: <author> Yang, D-S., Rendell, L. A., Blix, G. </author> <title> "A Scheme for Feature Construction and a Comparison of Empirical Methods", </title> <booktitle> in Proceedingof the 12th International Joint Conference on Artificial Intelligence, </booktitle> <address> p699-704, </address> <year> 1991. </year> <month> 18 </month>
References-found: 18

