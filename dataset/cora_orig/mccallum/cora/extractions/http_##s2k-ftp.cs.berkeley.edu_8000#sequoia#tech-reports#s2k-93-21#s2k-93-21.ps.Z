URL: http://s2k-ftp.cs.berkeley.edu:8000/sequoia/tech-reports/s2k-93-21/s2k-93-21.ps.Z
Refering-URL: http://s2k-ftp.cs.berkeley.edu:8000/sequoia/tech-reports/s2k-93-21/
Root-URL: http://www.cs.berkeley.edu
Email: (jkay@cs.ucsd.edu)  (pasquale@cs.ucsd.edu)  
Title: Measurement, Analysis, and Improvement of UDP/IP Throughput for the DECstation 5000  
Author: Jonathan Kay Joseph Pasquale 
Note: 1.0 Introduction  
Address: La Jolla, CA 92093-0114  
Affiliation: Computer Systems Lab 1  Computer Systems Laboratory Department of Computer Science and Engineering University of California, San Diego  
Abstract: Networking software is a growing bottleneck in modern workstations, particularly for high throughput applications such as networked digital video. We measure various components of the UDP/IP protocol stack in a DECstation 5000/200 running Ultrix 4.2a, and quantify the way in which checksumming and copying dominate the processing time for high throughput applications. This paper describes network software measurements and substantial performance improvements which derive from a faster checksum implementation. Network software of most modern workstation operating systems is not able to take full advantage of hardware speeds. With emerging high-bandwidth network hardware and network-I/O intensive applications, operating system network software is increasingly a bottleneck. The highest-bandwidth network widely supported by workstation vendors is FDDI, which operates at 100 megabits per second or 12.5 megabytes per second (MB/s). Measuring the performance of DECs DEFZA FDDI controller for a DECstation 5000/200 at the level of the device-driver, we find that the send rate is 7-8 MB/s (the receive rate is even higher) using maximum size FDDI packets. However, when sending from user level using UDP/IP over an FDDI network, the maximum sustained throughput measures at only 2.4 MB/s. The network software is reducing throughput from user processes to the device by a factor of three. The goal of this study is to determine how various components of network software contribute to this bottleneck. We instrument the UDP/IP protocol stack since most of the traffic on our departmental networks is comprised of NFS-generated UDP packets. We analyze network software component processing time by layer and by operation. By layer, we measure the individual processing times of the socket, UDP, IP, link, and device driver software. By operation, we measure the processing times for various copying, checksumming, and malloc/free operations. Other studies have shown these operations to be expensive [3-5, 7]. Cabrera et al. discuss a number of network software bottlenecks in the 4.2 release of Berkeley Unix [3]. Clark notes that checksumming and to a lesser extent copying were the dominant costs in the Multics TCP/IP implementation [4]. Clark et al. discuss copy and checksum costs versus other protocol costs in the context of a precursor to the 4.3 Reno release of Berkeley Unix and an experiment that *. An earlier version of this paper appeared in the 1993 Winter USENIX Conference. . This work was supported in part by grants from DEC, IBM, NCR, NSF, TRW, and UC MICRO. 
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> R. T. Braden, </author> <title> Requirements for Internet Hosts -- Communication Layers, Internet Request for Comments 1122, </title> <month> October </month> <year> 1989. </year>
Reference-contexts: However, the Internet checksum exists for a good reason; very simply, packets are occasionally corrupted during transmission, and the checksum is needed to detect corrupted data. Turning off checksumming by default is specifically forbidden within the Internet <ref> [1] </ref> . 4.2.1 Eliminating Checksum Redundancy There is a certain amount of redundant checksumming in the system. Ethernet and FDDI networks implement their own 16-bit cyclic redundancy checksum. Thus, packets sent directly over an Ethernet or FDDI network are already protected from data corruption.
Reference: [2] <editor> R. T. Braden, D. A. Borman, and C. Partridge, </editor> <title> Computing the Internet Checksum, Internet Request for Com ments 1071, </title> <month> September </month> <year> 1988. </year>
Reference-contexts: Since checksumming still consumed a large portion of processing time, we developed a proposal for eliminating checksumming entirely over most messages. 4.1 A RISC Checksum Algorithm The Internet Request for Comments describing the Internet checksum <ref> [2] </ref> includes a generic checksum algorithm written in C and optimized algorithms written in assembly language for three different machine architectures: a CISC microprocessor (the Motorola 68020), a vector supercomputer (the Cray), and a CISC mainframe (the IBM 3090). None of the algorithms described are well suited to RISC processors. <p> We were able to make a number of improvements to that algorithm. The most effective improvement resulted from reading memory in units of 32 bit words rather than in the units of 16 bit words used by the C algorithm described in <ref> [2] </ref>. Reading a 32 bit word results in a single memory access, but requires two additional instructions (shift and mask) to unpack the desired two 16 bit quantities. <p> The next most useful technique is loop unrolling, used by the Motorola and IBM algorithms <ref> [2] </ref>. The inner loop of our checksum algorithm is unrolled sixteen times. We chose sixteen because it is the maximum number of unrolls that is both a power of two, and allows the expanded loop to efficiently operate on a 108-byte small mbuf.
Reference: [3] <author> L.-F. Cabrera, E. Hunter, M. J. Karels, D. A. </author> <title> Mosher, User-Process Communication Performance in Networks of Computers, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14(1), </volume> <pages> 38-53, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: By operation, we measure the processing times for various copying, checksumming, and malloc/free operations. Other studies have shown these operations to be expensive [3-5, 7]. Cabrera et al. discuss a number of network software bottlenecks in the 4.2 release of Berkeley Unix <ref> [3] </ref>. Clark notes that checksumming and to a lesser extent copying were the dominant costs in the Multics TCP/IP implementation [4].
Reference: [4] <author> D. D. Clark, </author> <title> Modularity and Efficiency in Protocol Implementation, Internet RFC, </title> <type> 817, </type> <year> 1982 </year>
Reference-contexts: Other studies have shown these operations to be expensive [3-5, 7]. Cabrera et al. discuss a number of network software bottlenecks in the 4.2 release of Berkeley Unix [3]. Clark notes that checksumming and to a lesser extent copying were the dominant costs in the Multics TCP/IP implementation <ref> [4] </ref>. Clark et al. discuss copy and checksum costs versus other protocol costs in the context of a precursor to the 4.3 Reno release of Berkeley Unix and an experiment that *. An earlier version of this paper appeared in the 1993 Winter USENIX Conference. .
Reference: [5] <author> D. D. Clark, V. Jacobson, J. Romkey, H. Salwen, </author> <title> An Analysis of TCP Processing Overhead, </title> <journal> IEEE Communi cations Magazine, </journal> <pages> 23-29, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: An earlier version of this paper appeared in the 1993 Winter USENIX Conference. . This work was supported in part by grants from DEC, IBM, NCR, NSF, TRW, and UC MICRO. Computer Systems Lab 2 attempted to isolate protocol processing costs <ref> [5] </ref>. Jacobson discusses a number of costs in the 4.3 Tahoe release of Berkeley Unix and their improvements in the Reno precursor [7].
Reference: [6] <author> D. Ferrari, J. Pasquale, and G. Polyzos, </author> <title> Network Issues for Sequoia 2000, </title> <booktitle> Proceedings IEEE COMPCON, </booktitle> <pages> 401-406, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: An important goal of the Sequoia 2000 network <ref> [6] </ref> which we are constructing is to support high throughput for the large volumes of data required for global change applications.
Reference: [7] <author> V. Jacobson, </author> <title> BSD TCP Ethernet Throughput, comp.protocols.tcp-ip, </title> <type> Usenet, </type> <year> 1988. </year>
Reference-contexts: By layer, we measure the individual processing times of the socket, UDP, IP, link, and device driver software. By operation, we measure the processing times for various copying, checksumming, and malloc/free operations. Other studies have shown these operations to be expensive <ref> [3-5, 7] </ref>. Cabrera et al. discuss a number of network software bottlenecks in the 4.2 release of Berkeley Unix [3]. Clark notes that checksumming and to a lesser extent copying were the dominant costs in the Multics TCP/IP implementation [4]. <p> This work was supported in part by grants from DEC, IBM, NCR, NSF, TRW, and UC MICRO. Computer Systems Lab 2 attempted to isolate protocol processing costs [5]. Jacobson discusses a number of costs in the 4.3 Tahoe release of Berkeley Unix and their improvements in the Reno precursor <ref> [7] </ref>. This work is part of Project Sequoia 2000 [9], a project which brings together computer scientists and global change scientists from all over the University of California, including from UC San Diego and UC Berkeley, to improve network, storage, database, and visualization support for global change research.
Reference: [8] <author> J. L. Hennessy and D. A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: The key principle is that a register load should begin right after its previous contents are used, and therefore, multiple registers are used to achieve pipelining <ref> [8] </ref>. We use two registers in our data pipeline which is enough to keep the processor busy. This technique is independent of whatever mechanism is used to wait for memory contents to arrive at the processor (e.g. load delay slots or scoreboarding).
Reference: [9] <author> M. Stonebraker and J. Dozier, </author> <title> Sequoia 2000: Large Capacity Object Servers to Support Global Change Research, </title> <type> Sequoia 2000 Technical Report #1, </type> <institution> U.C. Berkeley, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Computer Systems Lab 2 attempted to isolate protocol processing costs [5]. Jacobson discusses a number of costs in the 4.3 Tahoe release of Berkeley Unix and their improvements in the Reno precursor [7]. This work is part of Project Sequoia 2000 <ref> [9] </ref>, a project which brings together computer scientists and global change scientists from all over the University of California, including from UC San Diego and UC Berkeley, to improve network, storage, database, and visualization support for global change research.
Reference: [10] <author> R. W. Watson, S. A. Mamrak, </author> <title> Gaining Efficiency in Transport Services by Appropriate Design and Imple mentation Choices, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(2), </volume> <pages> 97-120, </pages> <month> May </month> <year> 1987. </year>

References-found: 10

