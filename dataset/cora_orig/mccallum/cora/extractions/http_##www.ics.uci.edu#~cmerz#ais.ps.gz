URL: http://www.ics.uci.edu/~cmerz/ais.ps.gz
Refering-URL: http://www.ics.uci.edu/~cmerz/resume.html
Root-URL: 
Email: cmerz@ics.uci.edu  
Title: Dynamical Selection of Learning Algorithms  
Author: Christopher J. Merz 
Note: 1.1 Introduction  
Date: (714)824-3491  
Address: Irvine, CA 92717  
Affiliation: Information and Computer Science Department University of California, Irvine  
Abstract: Determining the conditions for which a given learning algorithm is appropriate is an open problem in machine learning. Methods for selecting a learning algorithm for a given domain have met with limited success. This paper proposes a new approach to predicting a given example's class by locating it in the "example space" and then choosing the best learner(s) in that region of the example space to make predictions. The regions of the example space are defined by the prediction patterns of the learners being used. The learner(s) chosen for prediction are selected according to their past performance in that region. This dynamic approach to learning algorithm selection is compared to other methods for selecting from multiple learning algorithms. The approach is then extended to weight rather than select the algorithms according to their past performance in a given region. Both approaches are further evaluated on a set of Determining the conditions for which a given learning algorithm is appropriate is an open problem in machine learning. Methods for selecting a learning algorithm for a given domain (e.g. [Aha92, Breiman84]) or for a portion of the domain ([Brodley93, Brodley94]) have met with limited success. This paper proposes a new approach that dynamically selects a learning algorithm for each example by locating it in the "example space" and then choosing the best learner(s) for prediction in that part of the example space. The regions of the example space are formed by the observed prediction patterns of the learners being used. The learner(s) chosen for prediction are selected according to their past performance in that region which is defined by the "cross-validation history." This paper introduces DS, a method for the dynamic selection of a learning algorithm(s). We call it "dynamic" because the learning algorithm(s) used to classify a novel example depends on that example. Preliminary experimentation motivated DW, an extension to DS that dynamically weights the learners predictions according to their regional accuracy. Further experimentation compares DS and DW to a collection of other meta-learning strategies such as cross-validation ([Breiman84]) and various forms of stacking ([Wolpert92]). In this phase of the experiementation, the meta-learners have six constituent learners which are heterogeneous in their search and representation methods (e.g. a rule learner, CN2 [Clark89]; a decision tree learner, C4.5 [Quinlan93]; an oblique decision tree learner, OC1 [Murthy93]; an instance-based learner, PEBLS [Cost93]; a k-nearest neighbor learner, ten domains and compared to several other meta-learning strategies.
Abstract-found: 1
Intro-found: 1
Reference: [Aha92] <author> Aha, D. W. </author> <year> (1992). </year> <title> Generalizing from case studies: A case study. </title> <booktitle> Proceedings of the Ninth International Machine Learning Conference (pp. </booktitle> <pages> 1-10). </pages> <address> San Mateo, CA: 10 Christopher J. </address> <publisher> Merz Morgan Kaufmann. </publisher>
Reference-contexts: 1.1 Introduction Determining the conditions for which a given learning algorithm is appropriate is an open problem in machine learning. Methods for selecting a learning algorithm for a given domain (e.g. <ref> [Aha92, Breiman84] </ref>) or for a portion of the domain ([Brodley93, Brodley94]) have met with limited success. <p> Another approach for selecting the best algorithm for a given domain is given by <ref> [Aha92] </ref> where rules are derived which characterize the conditions under which various learning algorithms do well based on certain high-level properties of a domain (e.g., number of examples, number of attributes, number of classes, types of attributes, class and attribute noise).
Reference: [Breiman84] <author> Breiman, L., Friedman, J.H., Olshen, R.A. & Stone, C.J. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <address> Belmont, CA: </address> <publisher> Wadsworth. </publisher>
Reference-contexts: 1.1 Introduction Determining the conditions for which a given learning algorithm is appropriate is an open problem in machine learning. Methods for selecting a learning algorithm for a given domain (e.g. <ref> [Aha92, Breiman84] </ref>) or for a portion of the domain ([Brodley93, Brodley94]) have met with limited success.
Reference: [Brodley93] <author> Brodley, C. E. </author> <year> (1993). </year> <title> Addressing the Selective Superiority Problem: Automatic Algorithm/Model Class Selection. </title> <booktitle> Proceedings of the Tenth International Machine Learning Conference (pp. </booktitle> <pages> 17-24). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: DS/DW emphasizes the selection of a learning algorithm at the example level rather than at the domain level since it avoids the need for characterization rules by instead considering each learning algorithm's past performance on "similar" examples from that domain. <ref> [Brodley93] </ref> proposes a knowledge-based approach to building hybrid decision structures by using heuristics to select the best algorithm at a given stage of learning.
Reference: [Brodley94] <author> Brodley, C. E. </author> <year> (1994). </year> <title> Recursive Automatic Bias Selection for Classifier Construction. To appear in the special issue of Machine Learning on "Bias Evaluation and Selection." </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference: [Buntine89] <author> Buntine, W. </author> <year> (1989). </year> <title> Decision tree induction systems: a bayesian analysis. </title> <booktitle> Uncertainty in Artificial Intelligence 3 (pp. </booktitle> <pages> 109-127). </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: This avoids the difficult problem of calculating posterior probabilities for rules <ref> [Buntine89] </ref>. The two main drawbacks to this approach are the manual derivation of the models, and the assumption that the majority prediction is always the best one to use.
Reference: [Cheeseman88] <author> Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., & Freeman, D. </author> <year> (1988). </year> <title> AutoClass: A Bayesian classification system. </title> <booktitle> Proceedings of the Fifth International Machine Learning Conference (pp. </booktitle> <pages> 54-64). </pages> <address> Ann Arbor, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [Clark89] <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 Induction Algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-284. </pages>
Reference-contexts: Further experimentation compares DS and DW to a collection of other meta-learning strategies such as cross-validation ([Breiman84]) and various forms of stacking ([Wolpert92]). In this phase of the experiementation, the meta-learners have six constituent learners which are heterogeneous in their search and representation methods (e.g. a rule learner, CN2 <ref> [Clark89] </ref>; a decision tree learner, C4.5 [Quinlan93]; an oblique decision tree learner, OC1 [Murthy93]; an instance-based learner, PEBLS [Cost93]; a k-nearest neighbor learner, 1 AI and Statistics V. Edited by F. Flinstone and B. Bunny. c fl1995 Me-Me-Me Publishers. 2 Christopher J. Merz FIGURE 1. <p> The new constitutent learners were: CN2 <ref> [Clark89] </ref>, a rule learner; C4.5 [Quinlan93], a decision tree learner; PEBLS [Cost93], an instance-based learner; k-nn [Cost93], a nearest neighbor learner, and Bayes [Cost93], a naive bayesian learner. OC1 was also still used, but only with its default configuration, and only on the all-numeric domains.
Reference: [Cost93] <author> Cost, S. & Salzberg, S. </author> <year> (1993). </year> <title> A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features. </title> <journal> Machine Learning, </journal> <volume> 10, </volume> <pages> 57-78 </pages>
Reference-contexts: In this phase of the experiementation, the meta-learners have six constituent learners which are heterogeneous in their search and representation methods (e.g. a rule learner, CN2 [Clark89]; a decision tree learner, C4.5 [Quinlan93]; an oblique decision tree learner, OC1 [Murthy93]; an instance-based learner, PEBLS <ref> [Cost93] </ref>; a k-nearest neighbor learner, 1 AI and Statistics V. Edited by F. Flinstone and B. Bunny. c fl1995 Me-Me-Me Publishers. 2 Christopher J. Merz FIGURE 1. Dividing up the example space by response patterns. k-nn [Cost93], and a naive bayesian learner, Bayes [Cost93]). <p> learner, C4.5 [Quinlan93]; an oblique decision tree learner, OC1 [Murthy93]; an instance-based learner, PEBLS <ref> [Cost93] </ref>; a k-nearest neighbor learner, 1 AI and Statistics V. Edited by F. Flinstone and B. Bunny. c fl1995 Me-Me-Me Publishers. 2 Christopher J. Merz FIGURE 1. Dividing up the example space by response patterns. k-nn [Cost93], and a naive bayesian learner, Bayes [Cost93]). DS and DW demonstrate their ability to consistently be among the top performers for a collection of ten domains. The paper begins by giving motivation for the DS algorithm (Section 2). <p> learner, OC1 [Murthy93]; an instance-based learner, PEBLS <ref> [Cost93] </ref>; a k-nearest neighbor learner, 1 AI and Statistics V. Edited by F. Flinstone and B. Bunny. c fl1995 Me-Me-Me Publishers. 2 Christopher J. Merz FIGURE 1. Dividing up the example space by response patterns. k-nn [Cost93], and a naive bayesian learner, Bayes [Cost93]). DS and DW demonstrate their ability to consistently be among the top performers for a collection of ten domains. The paper begins by giving motivation for the DS algorithm (Section 2). <p> The new constitutent learners were: CN2 [Clark89], a rule learner; C4.5 [Quinlan93], a decision tree learner; PEBLS <ref> [Cost93] </ref>, an instance-based learner; k-nn [Cost93], a nearest neighbor learner, and Bayes [Cost93], a naive bayesian learner. OC1 was also still used, but only with its default configuration, and only on the all-numeric domains. The new domains were also chosen from the UCI data repository. <p> The new constitutent learners were: CN2 [Clark89], a rule learner; C4.5 [Quinlan93], a decision tree learner; PEBLS <ref> [Cost93] </ref>, an instance-based learner; k-nn [Cost93], a nearest neighbor learner, and Bayes [Cost93], a naive bayesian learner. OC1 was also still used, but only with its default configuration, and only on the all-numeric domains. The new domains were also chosen from the UCI data repository. <p> The new constitutent learners were: CN2 [Clark89], a rule learner; C4.5 [Quinlan93], a decision tree learner; PEBLS <ref> [Cost93] </ref>, an instance-based learner; k-nn [Cost93], a nearest neighbor learner, and Bayes [Cost93], a naive bayesian learner. OC1 was also still used, but only with its default configuration, and only on the all-numeric domains. The new domains were also chosen from the UCI data repository. The wave domain consisted of 300 examples with 40 numeric attributes.
Reference: [Kwok90] <author> Kwok, S. W., & Carter, C. </author> <year> (1990). </year> <title> Multiple decision trees. </title> <booktitle> Uncertainty in Artificial Intelligence 4 (pp. </booktitle> <pages> 327-335). </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference-contexts: The development of these heuristics is a difficult ad hoc manual process based on the practitioner's past experience. DS/DW avoids this process by building a collection of models and dynamically choosing which one (s) to use based on past performance in the given region of the domain. <ref> [Kwok90] </ref> select several good models (i.e., rules/trees with high posterior probabilities) manually and average their predictions. This avoids the difficult problem of calculating posterior probabilities for rules [Buntine89].
Reference: [Murthy93] <author> Murthy, S., Kasif, S., Salzberg, S., & Beigel, R. </author> <year> (1993). </year> <title> OC1: Randomized induction of oblique decision trees. </title> <booktitle> In Proceedings of AAAI-93 (pp. </booktitle> <pages> 322-327). </pages> <address> Wash-ington DC: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: In this phase of the experiementation, the meta-learners have six constituent learners which are heterogeneous in their search and representation methods (e.g. a rule learner, CN2 [Clark89]; a decision tree learner, C4.5 [Quinlan93]; an oblique decision tree learner, OC1 <ref> [Murthy93] </ref>; an instance-based learner, PEBLS [Cost93]; a k-nearest neighbor learner, 1 AI and Statistics V. Edited by F. Flinstone and B. Bunny. c fl1995 Me-Me-Me Publishers. 2 Christopher J. Merz FIGURE 1. Dividing up the example space by response patterns. k-nn [Cost93], and a naive bayesian learner, Bayes [Cost93]). <p> The algorithm with the highest local accuracy is then selected in step 4. If a tie occurs, the algorithms having the highest local accuracy vote with equal weighting. 1.5 Experimentation and Analysis For our initial experimentation, DS used 24 variations of the OC1 program <ref> [Murthy93] </ref> as its different learning algorithms. The different entropy measures (6), pruning options (off/on with 20 percent of training data for pruning), and types of splits (univari 2 We use the number of matched responses to measure similarity. Dynamical Selection of Learning Algorithms 5 TABLE 1.1. Glass domain results.
Reference: [Quinlan93] <author> Quinlan, R. </author> <year> (1993). </year> <title> C4.5 Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In this phase of the experiementation, the meta-learners have six constituent learners which are heterogeneous in their search and representation methods (e.g. a rule learner, CN2 [Clark89]; a decision tree learner, C4.5 <ref> [Quinlan93] </ref>; an oblique decision tree learner, OC1 [Murthy93]; an instance-based learner, PEBLS [Cost93]; a k-nearest neighbor learner, 1 AI and Statistics V. Edited by F. Flinstone and B. Bunny. c fl1995 Me-Me-Me Publishers. 2 Christopher J. Merz FIGURE 1. <p> The new constitutent learners were: CN2 [Clark89], a rule learner; C4.5 <ref> [Quinlan93] </ref>, a decision tree learner; PEBLS [Cost93], an instance-based learner; k-nn [Cost93], a nearest neighbor learner, and Bayes [Cost93], a naive bayesian learner. OC1 was also still used, but only with its default configuration, and only on the all-numeric domains.
Reference: [Rumelhart86] <author> Rumelhart, D. E., Hinton, G. E., & Williams, R. J. </author> <year> (1986). </year> <title> Learning Interior Representation by Error Propagation. </title> <booktitle> Parallel Distributed Processing, </booktitle> <pages> 1 318-362. </pages> <address> Cambridge, MASS.: </address> <publisher> MIT Press. </publisher>
Reference: [Wolpert92] <author> Wolpert, D. H. </author> <year> (1992). </year> <title> Stacked Generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5, </volume> <pages> 241-259. </pages>
Reference-contexts: This situation must occur when one or more of the constituents has found a niche in the example space and the meta-learner is capable of exploiting it. 1.8 Related Work The approach taken here is most akin to the approach of stacked generalization as described by <ref> [Wolpert92] </ref> in which learning algorithms at the meta level learn how to classify novel examples by observing the prediction patterns of the constituent learners.
References-found: 13

