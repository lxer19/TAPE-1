URL: ftp://ftp.cs.brown.edu/pub/techreports/95/cs95-32.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-95-32.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Fourer, D. Gay, and B.W. Kernighan. AMPL: </author> <title> A Modeling Language for Mathematical Programming. </title> <publisher> The Scientific Press, </publisher> <address> San Francisco, CA, </address> <year> 1993. </year>
Reference-contexts: Helios statements are compiled into Newton programs, which use advanced logic programming features such as difference-lists. The generated Newton programs are then executed to solve the original applications. It is worth mentioning that Helios shares the same motivation and philosophy as AMPL <ref> [1] </ref>. In fact, Helios intends to be for Newton, and more generally for global optimization, what AMPL is to 1 linear programming and its extensions. The two languages and their implementations are of course fundamentally different because of the nature of their driving application areas. <p> 0.003448/sqrt (40); r8 = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y [5] - y <ref> [1] </ref>*(y [2] + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> = 3*y [5] - y <ref> [1] </ref>*(y [2] + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> 7 n n 2 Compilation Time (ms) Running Time (ms) Growth Factor 5 25 480 1190 10 100 480 8350 2.77 20 400 480 59490 2.86 40 1600 480 535700 3.02 Set: Variable: x : array [idx] in [-10^8..10^8]; Body: minimize 100 * (x [2] - x <ref> [1] </ref>^2)^2 + (x [1] - 1)^2; performance results are given in Figure 6 and indicates that Helios is between linear and quadratic in the size of the constraint system (i.e., between quadratic and cubic in the number of variables). 2.2 Unconstrained Optimization in Helios We now turn to optimization problems and consider first unconstrained <p> On unconstrained optimization problems, Helios returns an interval bounding the value of the global optimum as well as boxes enclosing each of the optima. For instance, in the Rosenbrock problem, Helios returns optimum in [0:00000000; 0:00000001] x <ref> [1] </ref> in [0:99999999; 1:00000001] The compilation and running times of Helios are 0.15 and 0.4 second respectively. It is important to stress that Helios bounds the global optimum value, not a local minimum value. In addition, Helios returns all the global optima. <p> x4 - 819 * x5 + 26000 * x4 * x5 &gt;= b3; - 14000 * x1 * x6 &gt;= b4; Set: Variable: x : array [idx] in [-10..10]; Body: minimize Prod (k in [1..2]) (Sum (i in [1..5]) i * cos ((i+1)*x [k] + i)) with soft constraints x <ref> [1] </ref> &gt;= x [2]; 11 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s <p> (Global) :- constant 0 (Global). constant 0 (Global) :- Global = environment (Constant,Function,Variable,Scope), generateConstant 0 (Global,Local), put (Constant,Offset a ,Local), constant 1 (Global). constant 1 (Global). 19 generateConstant 0 (Global,Result), Local 1 = [ dim (1,2) , dim (1,2)], libBuildArray (Result,Local1), Local2 = [ 1 , 0 ], Local3 = <ref> [ 0 , 1 ] </ref>, Local4 = [ Local2 , Local3 ], libFillArray (Result,Local4), The interesting part is of course predicate generateConstant 0 which constructs a list of the dimensions and then calls the library function libBuildArray to construct the array. <p> Aggregate Operators: It remains to specify how to generate code for the aggregate operators sum and product. The code generation strategy is based on the unfolding of these operators. Consider, for instance, an expression n X x [i] fl j: This expression can be unfolded into x <ref> [1] </ref> fl j + i=2;i6=j 24 if j 6= 1 and into n X x [i] fl j otherwise. This suggests the generation of a recursive predicate that makes a case analysis to filter the value of the index variable. The code pattern for summation is depicted in Figure 23. <p> [10; 20] 6.69 267 Schwefel3 2 [10 7 ; 10 7 ] 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 [0; 10] 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 <ref> [0; 1] </ref> 9.13 2 More1 3 [4; 4] 10.04 5 More2 4 [25; 25] 189.56 32 Table 2: Summary of the Experimental Results on Unconstrained Optimization.
Reference: [2] <author> R. Hammer, M. Hocks, M. Kulisch, and D. Ratz. </author> <title> Numerical Toolbox for Verified Computing I Basic Numerical Problems, Theory, Algorithms, and PASCAL-XSC Programs. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1993. </year>
Reference-contexts: We now consider a simple multivariate problem: the intersection of a circle and a parabola. The problem can be stated as follows: Variable: x : array [1..2]; Body: safe solve system Circle: x [1]^2 + x <ref> [2] </ref>^2 = 1; Parabola: x [1]^2 - x [2] = 0; The variable section declares an array of two variables and the body section specifies the two constraints. <p> s [i]^2 + c [i]^2 = 1; C1 : s <ref> [2] </ref>*c [5]*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c <ref> [2] </ref>*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> [4]*c [5]*s [6] + C2 : c [1]*c <ref> [2] </ref>*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> c [1]*c <ref> [2] </ref>*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c <ref> [2] </ref> + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> s [1]*c [5] = 1.9115; C4 : c [1]*c <ref> [2] </ref> + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. Some more interesting multivariate problems come from the area of robot kinematics, where the goal is to find the angles for the joints of a robot arm so that the robot hand ends up in a specified position. <p> and the running time to obtain the unique 4 Variable: y : array [1..5] in [0..10^8]; Constant: r = 10; r6 = 0.002597/sqrt (40); r7 = 0.003448/sqrt (40); r8 = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y [5] - y [1]*(y <ref> [2] </ref> + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in <p> r = 10; r6 = 0.002597/sqrt (40); r7 = 0.003448/sqrt (40); r8 = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y [5] - y [1]*(y <ref> [2] </ref> + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y [5] - y [1]*(y <ref> [2] </ref> + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> The 7 n n 2 Compilation Time (ms) Running Time (ms) Growth Factor 5 25 480 1190 10 100 480 8350 2.77 20 400 480 59490 2.86 40 1600 480 535700 3.02 Set: Variable: x : array [idx] in [-10^8..10^8]; Body: minimize 100 * (x <ref> [2] </ref> - x [1]^2)^2 + (x [1] - 1)^2; performance results are given in Figure 6 and indicates that Helios is between linear and quadratic in the size of the constraint system (i.e., between quadratic and cubic in the number of variables). 2.2 Unconstrained Optimization in Helios We now turn to <p> * x5 + 26000 * x4 * x5 &gt;= b3; - 14000 * x1 * x6 &gt;= b4; Set: Variable: x : array [idx] in [-10..10]; Body: minimize Prod (k in [1..2]) (Sum (i in [1..5]) i * cos ((i+1)*x [k] + i)) with soft constraints x [1] &gt;= x <ref> [2] </ref>; 11 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 <p> s [i]^2 + c [i]^2 = 1; C1 : s <ref> [2] </ref>*c [5]*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints <p> [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c <ref> [2] </ref>*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to <p> [4]*c [5]*s [6] + C2 : c [1]*c <ref> [2] </ref>*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or badly formulated problems. <p> c [1]*c <ref> [2] </ref>*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or badly formulated problems. <p> + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c <ref> [2] </ref> + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or badly formulated problems. It suffices to examine the size of the intervals associated with the constraints. <p> s [1]*c [5] = 1.9115; C4 : c [1]*c <ref> [2] </ref> + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or badly formulated problems. It suffices to examine the size of the intervals associated with the constraints.
Reference: [3] <author> E. Hansen. </author> <title> Global Optimization Using Interval Analysis. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: [i]^2 = 1; C1 : s [2]*c [5]*s [6] - s <ref> [3] </ref>*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c <ref> [3] </ref>*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> [5] + c [1]*c <ref> [3] </ref>*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c <ref> [3] </ref> + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> Variable: y : array [1..5] in [0..10^8]; Constant: r = 10; r6 = 0.002597/sqrt (40); r7 = 0.003448/sqrt (40); r8 = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y [5] - y [1]*(y [2] + 1); C3: 0 = y <ref> [3] </ref>*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about <p> array [1..5] in [0..10^8]; Constant: r = 10; r6 = 0.002597/sqrt (40); r7 = 0.003448/sqrt (40); r8 = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y [5] - y [1]*(y [2] + 1); C3: 0 = y <ref> [3] </ref>*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> 0.00003846/40; Body: safe solve system C1: 0 = 3*y [5] - y [1]*(y [2] + 1); C3: 0 = y <ref> [3] </ref>*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> [1]*(y [2] + 1); C3: 0 = y <ref> [3] </ref>*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> [i]^2 = 1; C1 : s [2]*c [5]*s [6] - s <ref> [3] </ref>*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information <p> [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c <ref> [3] </ref>*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or <p> [5] + c [1]*c <ref> [3] </ref>*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or badly formulated problems. <p> [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c <ref> [3] </ref> + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or badly formulated problems. It suffices to examine the size of the intervals associated with the constraints.
Reference: [4] <author> E.R. Hansen and R.I. Greenberg. </author> <title> An Interval Newton Method. </title> <journal> Appl. Math. Comput., </journal> <volume> 12 </volume> <pages> 89-98, </pages> <year> 1983. </year>
Reference-contexts: : s [2]*c [5]*s [6] - s [3]*c [5]*s [6] - s <ref> [4] </ref>*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> [1]*c [3]*s [5] + c [1]*c <ref> [4] </ref>*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; x in [+0.78615138,+0.78615137] in about 0.1 second. <p> solve system C1: 0 = 3*y [5] - y [1]*(y [2] + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y <ref> [4] </ref>) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> : s [2]*c [5]*s [6] - s [3]*c [5]*s [6] - s <ref> [4] </ref>*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and <p> [1]*c [3]*s [5] + c [1]*c <ref> [4] </ref>*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; Display: variables: c,s; constraints : C1,C2,C3,C4,C5,C6; constraints provides users with information on numerical accuracy and makes it possible to detect badly conditioned or badly formulated problems. <p> Full details on the benchmarks can be found in [27]. The experimental results once again exhibit a number of interesting facts. Helios is able to 3 Some interval methods such as <ref> [4] </ref> are more sophisticated than HRB but the sophistication aims at speeding up the computation near a solution. <p> true and fails otherwise. */ 26 Benchmarks v d range Helios HRB CONT Broyden 10 3 10 [-1,1] 1.78 18.23 Broyden 20 3 20 [-1,1] 5.36 ? Broyden 160 3 160 [-1,1] 95.09 ? Broyden 160 3 160 [10 8 ; 10 8 ] 105.610 ? More-Cosnard 20 3 20 <ref> [4; 5] </ref> 59.49 968.25 More-Cosnard 40 3 40 [4; 5] 535.70 ? More-Cosnard 40 3 40 [10 8 ; 0] 538.41 ? i1 10 3 10 [-2,2] 0.06 14.28 i3 20 3 20 [-2,2] 0.31 5640.80 i5 10 11 10 [-1,1] 0.08 33.58 kin2 8 256 [10 8 ; 10 8 <p> d range Helios HRB CONT Broyden 10 3 10 [-1,1] 1.78 18.23 Broyden 20 3 20 [-1,1] 5.36 ? Broyden 160 3 160 [-1,1] 95.09 ? Broyden 160 3 160 [10 8 ; 10 8 ] 105.610 ? More-Cosnard 20 3 20 <ref> [4; 5] </ref> 59.49 968.25 More-Cosnard 40 3 40 [4; 5] 535.70 ? More-Cosnard 40 3 40 [10 8 ; 0] 538.41 ? i1 10 3 10 [-2,2] 0.06 14.28 i3 20 3 20 [-2,2] 0.31 5640.80 i5 10 11 10 [-1,1] 0.08 33.58 kin2 8 256 [10 8 ; 10 8 ] 353.06 4730.34 35.61 eco 5 54 [10 <p> [10 7 ; 10 7 ] 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 [0; 10] 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 [0; 1] 9.13 2 More1 3 <ref> [4; 4] </ref> 10.04 5 More2 4 [25; 25] 189.56 32 Table 2: Summary of the Experimental Results on Unconstrained Optimization.
Reference: [5] <author> E.R. Hansen and S. Sengupta. </author> <title> Bounding Solutions of Systems of Equations Using Interval Analysis. </title> <journal> BIT, </journal> <volume> 21 </volume> <pages> 203-211, </pages> <year> 1981. </year>
Reference-contexts: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] <p> [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s <p> in [-10^8..10^8]; Body: safe solve system trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + <p> solve system trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; <p> is about 0.6 second and the running time to obtain the unique 4 Variable: y : array [1..5] in [0..10^8]; Constant: r = 10; r6 = 0.002597/sqrt (40); r7 = 0.003448/sqrt (40); r8 = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y <ref> [5] </ref> - y [1]*(y [2] + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; <p> r6 = 0.002597/sqrt (40); r7 = 0.003448/sqrt (40); r8 = 0.00001799/40; r9 = 0.0002155/sqrt (40); r10 = 0.00003846/40; Body: safe solve system C1: 0 = 3*y <ref> [5] </ref> - y [1]*(y [2] + 1); C3: 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y [5]; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. <p> 0 = y [3]*(2*y [2]*y [3] + 2*r5*y [3] + r6 + r7*y [2]) - 8*y <ref> [5] </ref>; C5: 0 = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y [5] in [0:03695185; 0:03695186] is about 5 seconds. Our next example is the well-known Broyden Banded function problem (e.g., [5]) which amounts to finding the zeros of the system of n equations f i (x 1 ; : : :; x n ) = x i (2 + 5x 2 X <p> = y [2]*(y [1] + r10*y [2] + y [3]^2 + r8 + r7*y [3] + r9*y [4]) + solution y [1] in [0:00311409; 0:00311411] y [3] in [0:06504177; 0:06504178] y <ref> [5] </ref> in [0:03695185; 0:03695186] is about 5 seconds. Our next example is the well-known Broyden Banded function problem (e.g., [5]) which amounts to finding the zeros of the system of n equations f i (x 1 ; : : :; x n ) = x i (2 + 5x 2 X x j (1 + x j ) (1 i n) where J i = fj j max (1; i <p> : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] <p> c : array [idx] in [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s <p> [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + <p> system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c <ref> [5] </ref>*s [6] - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; C6 : s [2] + s [3] + s [4] + s [2] + s [3] + s [2] = 3.9701; <p> Second, the list of indices is used to access the appropriate array. For instance, if [i1,i2] is the list [5,4] and the function foo is defined as previously, i.e., Function: foo (i in [1..n],j in [1..4]) = x [i] + j; this second step fetches the expression x <ref> [5] </ref> + 4 from array Function. This second step is performed by a predicate listDeref/3 defined as follows: listDeref ([],Value,Value). listDeref ([H|T],Array,Value) :- get (Array,H,Element), listDeref (T,Element,Value). The code pattern for complex references is depicted in Figure 22. <p> We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis [19], interval analysis <ref> [5, 7, 18] </ref>, and continuation methods [28, 21, 20, 15]. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching. <p> true and fails otherwise. */ 26 Benchmarks v d range Helios HRB CONT Broyden 10 3 10 [-1,1] 1.78 18.23 Broyden 20 3 20 [-1,1] 5.36 ? Broyden 160 3 160 [-1,1] 95.09 ? Broyden 160 3 160 [10 8 ; 10 8 ] 105.610 ? More-Cosnard 20 3 20 <ref> [4; 5] </ref> 59.49 968.25 More-Cosnard 40 3 40 [4; 5] 535.70 ? More-Cosnard 40 3 40 [10 8 ; 0] 538.41 ? i1 10 3 10 [-2,2] 0.06 14.28 i3 20 3 20 [-2,2] 0.31 5640.80 i5 10 11 10 [-1,1] 0.08 33.58 kin2 8 256 [10 8 ; 10 8 <p> d range Helios HRB CONT Broyden 10 3 10 [-1,1] 1.78 18.23 Broyden 20 3 20 [-1,1] 5.36 ? Broyden 160 3 160 [-1,1] 95.09 ? Broyden 160 3 160 [10 8 ; 10 8 ] 105.610 ? More-Cosnard 20 3 20 <ref> [4; 5] </ref> 59.49 968.25 More-Cosnard 40 3 40 [4; 5] 535.70 ? More-Cosnard 40 3 40 [10 8 ; 0] 538.41 ? i1 10 3 10 [-2,2] 0.06 14.28 i3 20 3 20 [-2,2] 0.31 5640.80 i5 10 11 10 [-1,1] 0.08 33.58 kin2 8 256 [10 8 ; 10 8 ] 353.06 4730.34 35.61 eco 5 54 [10
Reference: [6] <author> W. Hock and K. Schittkowski. </author> <title> Test Examples for Nonlinear Programming Codes. </title> <booktitle> Lecture Notes in Economics and Mathematical Systems. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Helios returns the two boxes (i.e., two tuples of intervals) x in [-0.78615138,-0.78615137] 3 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s <ref> [6] </ref> - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] <p> boxes (i.e., two tuples of intervals) x in [-0.78615138,-0.78615137] 3 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s <ref> [6] </ref> - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + <p> intervals) x in [-0.78615138,-0.78615137] 3 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s <ref> [6] </ref> - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; <p> The Helios statement is shown in minima in about 20 seconds. 2.3 Constrained Optimization in Helios Constrained optimization problems can also be stated in Helios. Figure 11 depicts the Helios statement of a constrained optimization problem taken from <ref> [6] </ref>. The main difference with unconstrained optimization is the keyword subject to which is followed by the description of the constraints to be satisfied. Once again, Helios is guaranteed to return an interval enclosing the value of the global optimum as well as boxes enclosing all the global optima. <p> cos ((i+1)*x [k] + i)) with soft constraints x [1] &gt;= x [2]; 11 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s <ref> [6] </ref> - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] <p> with soft constraints x [1] &gt;= x [2]; 11 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s <ref> [6] </ref> - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + <p> &gt;= x [2]; 11 Set: Variable: s : array [idx] in [-10^8..10^8]; c : array [idx] in [-10^8..10^8]; Body: safe solve system once trigo (i in idx) : s [i]^2 + c [i]^2 = 1; C1 : s [2]*c [5]*s <ref> [6] </ref> - s [3]*c [5]*s [6] - s [4]*c [5]*s [6] + C2 : c [1]*c [2]*s [5] + c [1]*c [3]*s [5] + c [1]*c [4]*s [5] + s [1]*c [5] = 1.9115; C4 : c [1]*c [2] + c [1]*c [3] + c [1]*c [4] + c [1]*c [2] + c [1]*c [3] + c [1]*c [2] = 4.0616; <p> Table 3 summarizes some of our computation results on some of the toughest problems from <ref> [6] </ref>. We give the number of variables in the initial statement (v), the number of constraints (c), the CPU time, and the number of splits.
Reference: [7] <author> H. Hong and V. Stahl. </author> <title> Safe Starting Regions by Fixed Points and Tightening. </title> <booktitle> Computing, </booktitle> <address> 53(3-4):323-335, </address> <year> 1994. </year>
Reference-contexts: Some more interesting multivariate problems come from the area of robot kinematics, where the goal is to find the angles for the joints of a robot arm so that the robot hand ends up in a specified position. The Helios statement to solve a problem given in <ref> [7] </ref> is depicted in Figure 1. There are several novel features in the statement. First, the set section declares a set idx that is used subsequently to define arrays and to specify constraints. Second, the example illustrates how constraints can be stated generically. <p> We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis [19], interval analysis <ref> [5, 7, 18] </ref>, and continuation methods [28, 21, 20, 15]. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching.
Reference: [8] <author> More. J., B. Garbow, and K. Hillstrom. </author> <title> Testing Unconstrained Optimization Software. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 7(1) </volume> <pages> 17-41, </pages> <year> 1981. </year>
Reference-contexts: Note that Helios solves Broyden, More-Cosnard, and interval benchmarks i1, i2, i3 and i5 without backtracking (contrary to most interval methods we know of). 4.2 Unconstrained Optimization Table 2 describes the results of Helios on unconstrained optimization. The benchmarks were taken mainly from <ref> [13, 8, 23, 25] </ref> and, for each of them, we give the number of variables, the range of the variables, the CPU time, and the number of splits. Full details on the benchmarks can be found in [27]. The experimental results once again exhibit a number of interesting facts.
Reference: [9] <author> R.B. Kearfott. </author> <title> Preconditioners for the Interval Gauss-Seidel Method. </title> <journal> SIAM Journal of Numerical Analysis, </journal> <volume> 27, </volume> <year> 1990. </year>
Reference: [10] <author> R.B. Kearfott. </author> <title> A Review of Preconditioners for the Interval Gauss-Seidel Method. Interval Computations 1, </title> <booktitle> 1 </booktitle> <pages> 59-85, </pages> <year> 1991. </year>
Reference-contexts: 29.88 5.87 eco 7 486 [10 8 ; 10 8 ] 127.65 ? 991.45 eco 9 4374 [10 8 ; 10 8 ] 8600.28 ? combustion 10 96 [10 8 ; 10 8 ] 9.94 ? 57.40 chemistry 5 108 [0; 10 8 ] 6.32 ? 56.55 neuro 6 1024 <ref> [10; 10] </ref> 0.91 28.84 5.02 neuro 6 1024 [1000; 1000] 172.71 ? 5.02 Table 1: Summary of the Experimental Results on Equation Solving. 27 Benchmarks v Range Time Splits Hump 2 [10 7 ; 10 8 ] 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <p> 10] 0.91 28.84 5.02 neuro 6 1024 [1000; 1000] 172.71 ? 5.02 Table 1: Summary of the Experimental Results on Equation Solving. 27 Benchmarks v Range Time Splits Hump 2 [10 7 ; 10 8 ] 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 <p> 1024 [1000; 1000] 172.71 ? 5.02 Table 1: Summary of the Experimental Results on Equation Solving. 27 Benchmarks v Range Time Splits Hump 2 [10 7 ; 10 8 ] 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 <p> Table 1: Summary of the Experimental Results on Equation Solving. 27 Benchmarks v Range Time Splits Hump 2 [10 7 ; 10 8 ] 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 <p> Results on Equation Solving. 27 Benchmarks v Range Time Splits Hump 2 [10 7 ; 10 8 ] 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 <p> v Range Time Splits Hump 2 [10 7 ; 10 8 ] 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 <p> [10 7 ; 10 8 ] 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 <p> 0.17 3 Levy1 1 [10 7 ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 <p> ; 10 7 ] 0.09 2 Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 <p> Levy2 1 <ref> [10; 10] </ref> 0.61 4 Levy3 2 [10; 10] 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 3 Beale 2 [10 2 ; <p> Levy3 2 <ref> [10; 10] </ref> 16.14 30 Levy4 2 [10; 10] 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 3 Beale 2 [10 2 ; 10 2 ] 3.31 12 Beale <p> Levy4 2 <ref> [10; 10] </ref> 2.13 7 Levy5 3 [10; 10] 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 3 Beale 2 [10 2 ; 10 2 ] 3.31 12 Beale 2 [10 4 ; 10 4 <p> Levy5 3 <ref> [10; 10] </ref> 0.75 1 Levy5 5 [10; 10] 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 3 Beale 2 [10 2 ; 10 2 ] 3.31 12 Beale 2 [10 4 ; 10 4 ] 5.52 31 Beale 2 [10 <p> Levy5 5 <ref> [10; 10] </ref> 1.04 1 Levy5 10 [10; 10] 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 3 Beale 2 [10 2 ; 10 2 ] 3.31 12 Beale 2 [10 4 ; 10 4 ] 5.52 31 Beale 2 [10 7 ; 10 7 ] 23.29 <p> Levy5 10 <ref> [10; 10] </ref> 3.34 1 Levy5 20 [10; 10] 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 3 Beale 2 [10 2 ; 10 2 ] 3.31 12 Beale 2 [10 4 ; 10 4 ] 5.52 31 Beale 2 [10 7 ; 10 7 ] 23.29 61 Schwefel1 3 [10 7 ; <p> Levy5 20 <ref> [10; 10] </ref> 11.82 1 Levy5 40 [10; 10] 45.89 1 Levy5 80 [10; 10] 235.22 1 Levy6 3 [10; 10] 0.96 1 Levy6 5 [10; 10] 1.57 1 Levy6 10 [10; 10] 4.29 1 Levy6 20 [10; 10] 14.86 1 Levy6 40 [10; 10] 64.11 1 Levy6 80 [10; 10] 372.39 1 Beale 2 [4:5; 4:5] 2.50 3 Beale 2 [10 2 ; 10 2 ] 3.31 12 Beale 2 [10 4 ; 10 4 ] 5.52 31 Beale 2 [10 7 ; 10 7 ] 23.29 61 Schwefel1 3 [10 7 ; 10 7 ] 0.24 0 Booth <p> [10 2 ; 10 2 ] 3.31 12 Beale 2 [10 4 ; 10 4 ] 5.52 31 Beale 2 [10 7 ; 10 7 ] 23.29 61 Schwefel1 3 [10 7 ; 10 7 ] 0.24 0 Booth 2 [10 7 ; 10 7 ] 0.11 0 Powell 4 <ref> [10; 20] </ref> 6.69 267 Schwefel3 2 [10 7 ; 10 7 ] 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 [0; 10] 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 [0; <p> ; 10 7 ] 0.24 0 Booth 2 [10 7 ; 10 7 ] 0.11 0 Powell 4 [10; 20] 6.69 267 Schwefel3 2 [10 7 ; 10 7 ] 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 <ref> [0; 10] </ref> 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 [0; 1] 9.13 2 More1 3 [4; 4] 10.04 5 More2 4 [25; 25] 189.56 32 Table 2: Summary of the Experimental Results on Unconstrained Optimization. <p> Booth 2 [10 7 ; 10 7 ] 0.11 0 Powell 4 [10; 20] 6.69 267 Schwefel3 2 [10 7 ; 10 7 ] 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 <ref> [0; 10] </ref> 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 [0; 1] 9.13 2 More1 3 [4; 4] 10.04 5 More2 4 [25; 25] 189.56 32 Table 2: Summary of the Experimental Results on Unconstrained Optimization. <p> 7 ] 0.11 0 Powell 4 [10; 20] 6.69 267 Schwefel3 2 [10 7 ; 10 7 ] 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 <ref> [0; 10] </ref> 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 [0; 1] 9.13 2 More1 3 [4; 4] 10.04 5 More2 4 [25; 25] 189.56 32 Table 2: Summary of the Experimental Results on Unconstrained Optimization.
Reference: [11] <author> R.B. Kearfott. </author> <title> A Review of Techniques in the Verified Solution of Constrained Global Optimization Problems. </title> <note> (To Appear), </note> <year> 1994. </year>
Reference: [12] <author> R. Krawczyk. </author> <title> Newton-Algorithmen zur Bestimmung von Nullstellen mit Fehlerschranken. </title> <journal> Computing, </journal> <volume> 4 </volume> <pages> 187-201, </pages> <year> 1969. </year>
Reference: [13] <author> A.V. Levy and A. Montalvo. </author> <title> The Tunnelling Algorithm for the Global Minimization of Functions. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 6(1) </volume> <pages> 15-29, </pages> <year> 1985. </year>
Reference-contexts: Our first example is the Rosenbrock function <ref> [13] </ref> which consists of minimizing the function f (x 1 ; x 2 ) = 100 (x 2 x 2 The Helios statement is depicted in Figure 7. <p> It is important to stress that Helios bounds the global optimum value, not a local minimum value. In addition, Helios returns all the global optima. A nice example from <ref> [13] </ref> illustrating this fact is the 8 Input: int n : "Number of variables"; Set: Variable: x : array [idx] in [-10..10]; Function: y (i in idx) = 1 + 0.25 * (x [i]-1); Body: minimize 10 * sin (pi*y (1))^2 + (y (n) - 1)^2 + (y (i) -1)^2 * <p> Note that Helios solves Broyden, More-Cosnard, and interval benchmarks i1, i2, i3 and i5 without backtracking (contrary to most interval methods we know of). 4.2 Unconstrained Optimization Table 2 describes the results of Helios on unconstrained optimization. The benchmarks were taken mainly from <ref> [13, 8, 23, 25] </ref> and, for each of them, we give the number of variables, the range of the variables, the CPU time, and the number of splits. Full details on the benchmarks can be found in [27]. The experimental results once again exhibit a number of interesting facts.
Reference: [14] <author> A.K. Mackworth. </author> <title> Consistency in Networks of Relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8(1) </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference-contexts: Newton [27] is a new constraint logic programming language designed to support this class of applications. It combines interval analysis from numerical analysis [2, 3, 4, 5, 7, 9, 10, 11, 12, 17, 22, 24]) with consistency techniques from artificial intelligence <ref> [14, 16] </ref> to produce one of most efficient constraint solvers in this area [26]. As is traditional with constraint programming languages, Newton allows a short development time of its applications.
Reference: [15] <author> K. Meintjes and A.P. Morgan. </author> <title> Chemical Equilibrium Systems as Numerical test Problems. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 16 </volume> <pages> 143-151, </pages> <year> 1990. </year>
Reference-contexts: Chemistry is the source of many interesting nonlinear problems and our next application of Helios is a chemical equilibrium problem for the propulsion of propane into the air. The problem is taken from <ref> [15] </ref> and the Helios statement is depicted in Figure 2. It illustrates the use of constants in Helios. A constant gives a symbolic name to an expression; the name can then be used in specifying constraints. Constants are assumed to denote real numbers unless specified otherwise by an integer declaration. <p> We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis [19], interval analysis [5, 7, 18], and continuation methods <ref> [28, 21, 20, 15] </ref>. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching.
Reference: [16] <author> U. Montanari. </author> <title> Networks of Constraints : Fundamental Properties and Applications to Picture Processing. </title> <journal> Information Science, </journal> <volume> 7(2) </volume> <pages> 95-132, </pages> <year> 1974. </year>
Reference-contexts: Newton [27] is a new constraint logic programming language designed to support this class of applications. It combines interval analysis from numerical analysis [2, 3, 4, 5, 7, 9, 10, 11, 12, 17, 22, 24]) with consistency techniques from artificial intelligence <ref> [14, 16] </ref> to produce one of most efficient constraint solvers in this area [26]. As is traditional with constraint programming languages, Newton allows a short development time of its applications.
Reference: [17] <author> R.E. Moore. </author> <title> Interval Analysis. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1966. </year>
Reference: [18] <author> R.E. Moore and S.T. Jones. </author> <title> Safe Starting Regions for Iterative Methods. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 14 </volume> <pages> 1051-1065, </pages> <year> 1977. </year>
Reference-contexts: We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis [19], interval analysis <ref> [5, 7, 18] </ref>, and continuation methods [28, 21, 20, 15]. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching.
Reference: [19] <author> J.J. More and M.Y. Cosnard. </author> <title> Numerical Solution of Nonlinear Equations. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 5 </volume> <pages> 64-85, </pages> <year> 1979. </year>
Reference-contexts: Another interesting fact is that Helios is essentially linear in the number of variables on this benchmark. The performance results are given in Figure 4. Our last example of equation solving is another traditional benchmark from numerical analysis: the discretization of a nonlinear integral equation <ref> [19] </ref>. <p> We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis <ref> [19] </ref>, interval analysis [5, 7, 18], and continuation methods [28, 21, 20, 15]. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching.
Reference: [20] <author> A.P. Morgan. </author> <title> Computing All Solutions To Polynomial Systems Using Homotopy Continuation. </title> <journal> Appl. Math. Comput., </journal> <volume> 24 </volume> <pages> 115-138, </pages> <year> 1987. </year>
Reference-contexts: We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis [19], interval analysis [5, 7, 18], and continuation methods <ref> [28, 21, 20, 15] </ref>. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching. <p> [10 2 ; 10 2 ] 3.31 12 Beale 2 [10 4 ; 10 4 ] 5.52 31 Beale 2 [10 7 ; 10 7 ] 23.29 61 Schwefel1 3 [10 7 ; 10 7 ] 0.24 0 Booth 2 [10 7 ; 10 7 ] 0.11 0 Powell 4 <ref> [10; 20] </ref> 6.69 267 Schwefel3 2 [10 7 ; 10 7 ] 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 [0; 10] 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 [0;
Reference: [21] <author> A.P. Morgan. </author> <title> Solving Polynomial Systems Using Continuation for Scientific and Engineering Problems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1987. </year>
Reference-contexts: We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis [19], interval analysis [5, 7, 18], and continuation methods <ref> [28, 21, 20, 15] </ref>. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching.
Reference: [22] <author> A. Neumaier. </author> <title> Interval Methods for Systems of Equations. </title> <booktitle> PHI Series in Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1990. </year> <month> 30 </month>
Reference: [23] <author> D. Ratz. </author> <title> Box-Splitting Strategies for the Interval Gauss-Seidel Step in a Global Optimization Method. </title> <booktitle> Computing, </booktitle> <address> 53(3-4):337-353, </address> <year> 1994. </year>
Reference-contexts: Note that Helios solves Broyden, More-Cosnard, and interval benchmarks i1, i2, i3 and i5 without backtracking (contrary to most interval methods we know of). 4.2 Unconstrained Optimization Table 2 describes the results of Helios on unconstrained optimization. The benchmarks were taken mainly from <ref> [13, 8, 23, 25] </ref> and, for each of them, we give the number of variables, the range of the variables, the CPU time, and the number of splits. Full details on the benchmarks can be found in [27]. The experimental results once again exhibit a number of interesting facts. <p> Helios solves the problems Ratz25, Ratz27, and Ratz210 without splitting. These problems were used in <ref> [23] </ref> to study splitting strategies. Finally, Helios does not exhibit the behaviour of traditional interval methods on problems such as the Rosenbrock function.
Reference: [24] <author> S.M. Rump. </author> <title> Verification Methods for Dense and Sparse Systems of Equations. </title> <editor> In J. (Ed.) Herzberger, editor, </editor> <booktitle> Topics in Validated Computations, </booktitle> <pages> pages 217-231. </pages> <publisher> Elsevier, </publisher> <year> 1988. </year>
Reference: [25] <author> H. Schwefel. </author> <title> Numerical Optimization of Computer Models. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Note that Helios solves Broyden, More-Cosnard, and interval benchmarks i1, i2, i3 and i5 without backtracking (contrary to most interval methods we know of). 4.2 Unconstrained Optimization Table 2 describes the results of Helios on unconstrained optimization. The benchmarks were taken mainly from <ref> [13, 8, 23, 25] </ref> and, for each of them, we give the number of variables, the range of the variables, the CPU time, and the number of splits. Full details on the benchmarks can be found in [27]. The experimental results once again exhibit a number of interesting facts. <p> 0.03 0 Rosenbrock 2 [10 7 ; 10 7 ] 0.33 10 Ratz1 5 [500; 600] 1.19 0 Ratz25 4 [0; 10] 2.86 0 Ratz27 4 [0; 10] 4.44 0 Ratz210 4 [0; 10] 7.42 0 Ratz3 6 [0; 1] 9.13 2 More1 3 [4; 4] 10.04 5 More2 4 <ref> [25; 25] </ref> 189.56 32 Table 2: Summary of the Experimental Results on Unconstrained Optimization.
Reference: [26] <author> P. Van Hentenryck, D. McAllister, and D. Kapur. </author> <title> Solving Polynomial Systems Using a Branch and Prune Approach. </title> <note> SIAM Journal on Numerical Analysis, 1995. (to appear). </note>
Reference-contexts: It combines interval analysis from numerical analysis [2, 3, 4, 5, 7, 9, 10, 11, 12, 17, 22, 24]) with consistency techniques from artificial intelligence [14, 16] to produce one of most efficient constraint solvers in this area <ref> [26] </ref>. As is traditional with constraint programming languages, Newton allows a short development time of its applications. However, Newton programs, although short and generally easy to understand, are still far from the statements traditionally used by scientists and engineers to describe these applications. <p> The benchmarks were taken from papers on numerical analysis [19], interval analysis [5, 7, 18], and continuation methods [28, 21, 20, 15]. Complete details on the benchmarks can be found in <ref> [26, 27] </ref>. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching.
Reference: [27] <author> P. Van Hentenryck and L. Michel. </author> <title> Newton: Constraint Programming over Nonlinear Constraints. </title> <journal> Science of Computer Programming. </journal> <note> To appear, </note> <year> 1996. </year>
Reference-contexts: These problems are difficult due to their inherent computational complexity (i.e., they are NP-hard) and due to the numerical issues involved to guarantee correctness (i.e., finding all solutions or the global optimum) and to ensure termination. Newton <ref> [27] </ref> is a new constraint logic programming language designed to support this class of applications. <p> More precisely, an Helios statement is compiled into a Newton program that can then be executed to solve the initial problem. A complete description of Newton is available in <ref> [27] </ref>. However, for the purpose of this paper, it is almost always sufficient to view Newton as Prolog enhanced with a number of predefined predicates for solving nonlinear constraints and for optimizing an objective function subject to a system of constraints. <p> The benchmarks were taken from papers on numerical analysis [19], interval analysis [5, 7, 18], and continuation methods [28, 21, 20, 15]. Complete details on the benchmarks can be found in <ref> [26, 27] </ref>. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching. <p> The benchmarks were taken mainly from [13, 8, 23, 25] and, for each of them, we give the number of variables, the range of the variables, the CPU time, and the number of splits. Full details on the benchmarks can be found in <ref> [27] </ref>. The experimental results once again exhibit a number of interesting facts. Helios is able to 3 Some interval methods such as [4] are more sophisticated than HRB but the sophistication aims at speeding up the computation near a solution.
Reference: [28] <author> J Verschelde, P. Verlinden, and R. Cools. </author> <title> Homotopies Exploiting Newton Polytopes For Solving Sparse Polynomial Systems. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 31(3) </volume> <pages> 915-930, </pages> <year> 1994. </year> <month> 31 </month>
Reference-contexts: We consider successively equation solving, unconstrained optimization, and constrained optimization. 4.1 Equation Solving We start with experimental results of Helios on a variety of standard benchmarks for equation solving. The benchmarks were taken from papers on numerical analysis [19], interval analysis [5, 7, 18], and continuation methods <ref> [28, 21, 20, 15] </ref>. Complete details on the benchmarks can be found in [26, 27]. We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching. <p> We also compare Helios with a traditional interval method using the Hansen-Segupta's operator, range testing, and branching. This method uses the same implementation technology as Helios and is denoted by HRB in the following. 3 Finally, we compare Helios with a state-of-the-art continuation method <ref> [28] </ref>, denoted by CONT in the following. Note that all results given in this section were obtained by running Helios on a Sun Sparc 10 workstation to obtain all solutions. In addition, the final intervals must have widths smaller than 10 8 . The results are summarized in Table 1.
References-found: 28

