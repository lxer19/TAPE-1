URL: ftp://ftp.dcs.ex.ac.uk/pub/artificial_intelligence/286.ps.gz
Refering-URL: http://www.dcs.ex.ac.uk/reports/reports.html
Root-URL: 
Email: ajit@dcs.exeter.ac.uk  bjorne@his.se  
Title: Converting identification trees into nonmonotonic inheritance structures  
Author: Ajit Narayanan Bjorn Olsson 
Date: January 25, 1994  
Address: Exeter EX4 4PT, UK  Box 408, S-541 28 Skovde, Sweden  
Affiliation: Department of Computer Science University of Exeter  Department of Computer Science, University of Skovde  
Abstract: This paper addresses the issues involved in the automatic generation and upkeep of knowledge derived from datasets. Once identification trees are generated from datasets, algorithms for converting these identification trees into nonmonotonic inheritance structures (i.e. multiple inheritance structures with exceptions) can be applied. This results in a knowledge base which can deal with subsequent, conflicting information directly without requiring a recomputation of a new identification tree which must take the conflicting information into account.
Abstract-found: 1
Intro-found: 1
Reference: <author> Al-Asady, R. and Narayanan, A. </author> <year> (1993). </year> <title> More notes on `A clash of intuitions'. </title> <booktitle> In Proceedings of the 13 International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 682-689. </pages>
Reference: <author> Fahlman, S. </author> <year> (1979). </year> <title> NETL: A system for representing and using real world knowledge. </title> <publisher> MIT Press. </publisher>
Reference-contexts: In cases where there are no redundant links in the nonmonotonic inheritance structure and where cancellation of links is not allowed (as opposed to cancellation of nodes), shortest-path algorithms <ref> (Fahlman, 1979) </ref> based on parallel-marker propagation schemes can replace this two-phased reasoning process. 3 Preliminary analysis One nonmonotonic inheritance structure derivable from the IDT in Figure 1 is provided in Figure 3.
Reference: <author> Horty, J. F., Thomason, R. H., and Touretzky, D. S. </author> <year> (1990). </year> <title> A skeptical theory of inheritance in nonmonotonic semantic networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 311-348. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference: <author> Sandewall, E. </author> <year> (1986). </year> <title> Non-monotonic inference rules for multiple inheritance with exceptions. </title> <booktitle> In Proceedings of IEEE Volume 74, </booktitle> <pages> pages 1345-1353. </pages>
Reference: <author> Schlimmer, J. C. and Fisher, D. </author> <year> (1986). </year> <title> A case study of incremental concept induction. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 496-501. </pages>
Reference-contexts: For instance, `windowing techniques' (Wirth and Catlett, 1988) involve adding exceptions to the original dataset and generating a new tree. ID4 prunes subtrees of the IDT which appear to be incorrect and adds new subtress as new instance appear <ref> (Schlimmer and Fisher, 1986) </ref>. ID5 rearranges test nodes as new information appears, no matter whether the information conflicts with existing information or not (Utgoff, 1988).
Reference: <author> Touretzky, D. </author> <year> (1986). </year> <title> The Mathematics of Inheritance Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Utgoff, P. E. </author> <year> (1988). </year> <title> An incremental ID3. </title> <booktitle> In Proceedings of the Fifth National Conference on Machine Learning. </booktitle>
Reference-contexts: ID4 prunes subtrees of the IDT which appear to be incorrect and adds new subtress as new instance appear (Schlimmer and Fisher, 1986). ID5 rearranges test nodes as new information appears, no matter whether the information conflicts with existing information or not <ref> (Utgoff, 1988) </ref>. The question which this paper addresses is whether a different sort of knowledge structure can be generated from an IDT such that conflicting and exceptional information can be integrated directly into the knowledge structure as they arise, rather than be stored separately for later recompilation.
Reference: <author> Winston, P. H. </author> <year> (1992). </year> <booktitle> Artificial Intelligence. </booktitle> <publisher> Addison Wesley, </publisher> <address> third edition. </address> <note> Chapter 21. </note>
Reference-contexts: Each `path' (sequence of tests) in the IDT is converted into a rule which includes as preconditions the tests to be carried out (from the root node of the IDT) and has as a conclusion the class under which instances fall. The rule-base can be optimized <ref> (Winston, 1992) </ref> by eliminating unnecessary antecedents (by the use of contingency tables, for example) and then whole rules (by subsuming them under a default rule, for example). <p> sunburned Annie blonde short average no sunburned Emily red average heavy no sunburned Pete brown tall heavy no not sunburned John brown average heavy no not sunburned Katie blonde short light yes not sunburned Table 1: Table of data describing who is and who is not sunburned, with attribute values <ref> (Winston, 1992) </ref>. prune. <p> Once such structures are generated, a variety of well-established inheritance mechanisms are applicable for drawing inferences even in the face of conflicting information. 2 Foundations Consider the data-set in Table 1 <ref> (Winston, 1992) </ref>. Applying simple information-theoretic heuristics, the IDT in Figure 1 can be generated. Sunburned and non-sunburned individuals fall neatly into the same class at the leaves. <p> blonde-haired and that person didn't use suntan lotion then that person is sunburned. 2 Katie Dana Annie Sarah yesno lotion used John Pete AlexEmily brownredblonde hair colour use of information-theoretic heuristics results in a structure which shows that only hair-colour and lotion-used values are required to correctly classify all samples <ref> (Winston, 1992) </ref>. 3. If a person is red-haired then that person is sunburned. 4. If a person is brown-haired then that person is not sunburned. This rule set can then be optimized if necessary.
Reference: <author> Wirth, J. and Catlett, J. </author> <year> (1988). </year> <title> Experiments on the cost and benefits of windowing in ID3. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning. </booktitle> <pages> 10 </pages>
Reference-contexts: If the number of exceptions and conflicts grows sufficiently large, they are appended to the original data-set and a new IDT with associated rule-base is generated. For instance, `windowing techniques' <ref> (Wirth and Catlett, 1988) </ref> involve adding exceptions to the original dataset and generating a new tree. ID4 prunes subtrees of the IDT which appear to be incorrect and adds new subtress as new instance appear (Schlimmer and Fisher, 1986).
References-found: 10

