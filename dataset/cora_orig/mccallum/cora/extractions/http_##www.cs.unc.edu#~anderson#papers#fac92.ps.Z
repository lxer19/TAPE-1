URL: http://www.cs.unc.edu/~anderson/papers/fac92.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: A Criterion for Atomicity  
Author: James H. Anderson Mohamed G. Gouda 
Keyword: atomicity, atomic registers, composite registers, history, interleaving semantics, leader election, models of concurrency, shared variable, snapshot, waiting  
Note: CR Categories: D.4.1, D.4.2, D.4.4, F.1.1, F.1.2 Work supported, in part, at the University of Texas at Austin by Office of Naval Research Contract N00014-89 J-1913, and at the University of Maryland by an award from the University of Maryland General Research Board. Work supported, in part, by Office of Naval Research Contract N00014-89-J-1913.  
Date: July 1990 Revised June 1991  
Address: College Park College Park, Maryland 20742-3255  Austin, Texas 78712-1188  
Affiliation: Department of Computer Science The University of Maryland at  Department of Computer Sciences The University of Texas at Austin  
Abstract: Most proof methods for reasoning about concurrent programs are based upon the interleaving semantics of concurrent computation: a concurrent program is executed in a stepwise fashion, with only one enabled action being executed at each step. Interleaving semantics, in effect, requires that a concurrent program be executed as a nondeterministic sequential program. This is clearly an abstraction of the way in which concurrent programs are actually executed. To ensure that this is a reasonable abstraction, interleaving semantics should only be used to reason about programs with "simple" actions; we call such programs "atomic." In this paper, we formally characterize the class of atomic programs. We adopt the criterion that a program is atomic if it can be implemented in a wait-free, serializable manner by a primitive program. A program is primitive if each of its actions has at most one occurrence of a shared bit, and each shared bit is read by at most one process and written by at most one process. It follows from our results that the traditionally accepted atomicity criterion, which allows each action to have at most one occurrence of a shared variable, can be relaxed, allowing programs to have more powerful actions. For example, according to our criterion, an action can read any finite number of shared variables, provided it writes no shared variable. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Afek, H. Attiya, D. Dolev, E. Gafni, M. Merritt, and N. Shavit, </author> <title> "Atomic Snapshots of Shared Memory," </title> <booktitle> Proceedings of the Ninth Annual Symposium on Principles of Distributed Computing , 1990, </booktitle> <pages> pp. 1-14. </pages>
Reference-contexts: pending; y : boolean; c : array [1::2] of Ctype begin do true ! read c := C; reply; pending := c [2]:V W; (c <ref> [1] </ref>:Y Z 6= c [2]:Y Z); if :pending ! consume reply; produce next request; dev; read c := C; y := :c [1]:YZ; write C [1] := (request; dev; y) [] pending ! skip fi end process DEVICE (j : 1::N ) private var request; reply : integer; dev : 1::N ; pending; z : boolean; c : array [1::2] of Ctype begin do true ! read c := C; request; dev; pending := c [1]:V <p> As suggested by Exact-Writing, we partition the five shared variables of this program into two classes fV; X; Y g and fW; Zg. Each of these classes corresponds to one component of C: the class fV; X; Y g corresponds to the first component of C, namely C <ref> [1] </ref>, and the class fW; Zg corresponds to the second component of C, namely C [2]. <p> The notion of a composite register is an extension of an atomic register, and was first introduced by Anderson in [2, 3]. A composite register is equivalent to the atomic snapshot primitive defined by Afek et al. in <ref> [1] </ref>. The notion of an atomic register was first defined by Lamport [19]. An atomic register is a composite register with only one component. We should point out that it may be possible to relax the Exact-Writing and Single-Phase constraints somewhat, despite the necessity results proved in Section 5.
Reference: [2] <author> J. Anderson, </author> <title> "Multiple-Writer Composite Registers," </title> <type> Technical Report TR.89.26, </type> <institution> Department of Computer Sciences, University of Texas at Austin, </institution> <month> September </month> <year> 1989. </year>
Reference-contexts: Thus, both programs are nonatomic. This establishes the following theorem. Theorem 1: There exists a nonatomic program violating Exact-Writing (or Single-Phase), but satisfying the other two constraints. 2 To establish the sufficiency of our atomicity constraints, we consider in Section 6 a shared data object called a composite register <ref> [2, 3] </ref>. A composite register is an array-like variable consisting of a number of components. An operation of the register either writes a value to a single component, or reads the values of all of the components. <p> We prove that any program satisfying the three atomicity constraints is atomic; that is, such a program can be implemented by a primitive program (as described in Section 4). The implementation is facilitated by considering a shared data object, called a composite register <ref> [2, 3] </ref>. A composite register is an array-like variable that consists of a number of components. An operation of a composite register either writes a value to one of the components, or reads the values of all of the components. <p> : array [1::2] of Ctype begin do true ! read c := C; request; dev; pending := c [1]:V W; c [1]:X; (c [1]:Y Z 6= c <ref> [2] </ref>:Y Z); if pending ^ dev = j ! consume request; produce reply; read c := C; z := :c [2]:YZ; write C [2] := (reply; 1; z) [] :pending _ dev 6= j ! skip fi end 17 program with processes that communicate only via a single composite register. The corresponding program is shown in Figure 6. <p> Each of these classes corresponds to one component of C: the class fV; X; Y g corresponds to the first component of C, namely C [1], and the class fW; Zg corresponds to the second component of C, namely C <ref> [2] </ref>. Note that the class fV; X; Y g contains an integer variable, a variable of type 1::N , and a boolean variable, while the class fW; Zg contains an integer variable and a boolean variable. <p> To establish the sufficiency of our atomicity constraints, we considered in Section 6 a shared data object called a composite register. The notion of a composite register is an extension of an atomic register, and was first introduced by Anderson in <ref> [2, 3] </ref>. A composite register is equivalent to the atomic snapshot primitive defined by Afek et al. in [1]. The notion of an atomic register was first defined by Lamport [19]. An atomic register is a composite register with only one component.
Reference: [3] <author> J. Anderson, </author> <title> "Composite Registers," </title> <booktitle> Proceedings of the Ninth Annual Symposium on Principles of Distributed Computing , 1990, </booktitle> <pages> pp. 15-30. </pages>
Reference-contexts: Thus, both programs are nonatomic. This establishes the following theorem. Theorem 1: There exists a nonatomic program violating Exact-Writing (or Single-Phase), but satisfying the other two constraints. 2 To establish the sufficiency of our atomicity constraints, we consider in Section 6 a shared data object called a composite register <ref> [2, 3] </ref>. A composite register is an array-like variable consisting of a number of components. An operation of the register either writes a value to a single component, or reads the values of all of the components. <p> We prove that any program satisfying the three atomicity constraints is atomic; that is, such a program can be implemented by a primitive program (as described in Section 4). The implementation is facilitated by considering a shared data object, called a composite register <ref> [2, 3] </ref>. A composite register is an array-like variable that consists of a number of components. An operation of a composite register either writes a value to one of the components, or reads the values of all of the components. <p> To establish the sufficiency of our atomicity constraints, we considered in Section 6 a shared data object called a composite register. The notion of a composite register is an extension of an atomic register, and was first introduced by Anderson in <ref> [2, 3] </ref>. A composite register is equivalent to the atomic snapshot primitive defined by Afek et al. in [1]. The notion of an atomic register was first defined by Lamport [19]. An atomic register is a composite register with only one component.
Reference: [4] <author> J. Anderson, </author> <title> Atomicity of Concurrent Programs, </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Sciences, University of Texas at Austin, </institution> <year> 1990. </year>
Reference-contexts: The number of different cases that must be taken into account in order to establish this proof obligation can be considerable (see, for example, the proofs given in <ref> [4] </ref>). The main contribution of this paper is to give a simple method for checking whether a given program satisfies the proposed atomicity criterion. <p> In particular, we allow a class to consist of more than one shared variable only if each variable in the class is unsubscripted. In <ref> [4] </ref>, a more permissive version of Exact-Writing is considered in which a class may consist of several subscripted variables. This version of Exact-Writing is considered in Section 9.) The Single-Phase constraint specifies the conditions under which an assignment statement may both read and write shared variables. <p> Constructions for these steps can be found in the Ph.D. dissertation of the first author <ref> [4] </ref>, as well as in the literature. The steps involved in constructing a K=L=M=N composite register from 1=1=1=1 composite registers are illustrated in Figure 7. Each arrow in this figure is labeled by a reference to the paper (s) in which the corresponding register construction (s) appear. <p> An atomic register is a special case of a composite register in which there is only one component. The correctness proof for the Shrinking Lemma is given in <ref> [4] </ref>. The proof is somewhat tedious, but is not hard. The proof strategy is as follows. We first augment the precedence relation on operations in history h by adding pairs of operations. These added pairs of operations are defined based on the five conditions of the lemma. <p> For brevity, we only describe the construction informally here; a formal correctness proof is given in <ref> [4] </ref>. The construction is depicted in Figure 8. (We assume that any arithmetic expression involving L in this figure is replaced by 1 for the case in which L is infinite.) We begin by giving a brief description of how the construction works; a more detailed description is given below. <p> The value of rp is made available to the Writer by writing it to RP . The correctness of this construction follows from the following fact (which is proved in <ref> [4] </ref>): if a Read operation executes its do statement while a Write operation executes its do statement, then rp 6= wp or ralt 6= walt. This implies that no Write operation interferes with a Read operation as it reads from one of the four shared buffers. <p> As mentioned earlier, the version of Exact-Writing considered in this paper is overly restrictive because it allows an assignment statement to write several shared variables only if all such variables are unsubscripted. In <ref> [4] </ref>, a more permissive version of Exact-Writing is considered that allows an assignment statement to write several subscripted variables. This version of Exact-Writing is similar to the one given in this paper, except for the partitioning of shared variables into classes. In [4], a class is allowed to consist of several <p> In <ref> [4] </ref>, a more permissive version of Exact-Writing is considered that allows an assignment statement to write several subscripted variables. This version of Exact-Writing is similar to the one given in this paper, except for the partitioning of shared variables into classes. In [4], a class is allowed to consist of several shared variables in the following cases. * A class may consist of a number of unsubscripted variables. * A class may consist of all elements of a finite array. * If A; B; . . . ; C are single-dimensional arrays whose
Reference: [5] <author> J. Anderson and M. Gouda, </author> <title> "The Virtue of Patience: Concurrent Programming With and Without Waiting," </title> <type> Technical Report TR.90.23, </type> <institution> Department of Computer Sciences, University of Texas at Austin, </institution> <year> 1990. </year>
Reference-contexts: exists a history with a final state in which the value of that process's decision variable is true. * Validity : In the final state of every history, the value of one of the decision variables is true and the value of the other decision variable is false. 2 In <ref> [5] </ref>, we proved that the binary election problem cannot be solved by any program satisfying constraints (4) and (5) in the definition of primitive programs. In particular, we showed that if such a program satisfies both Equity and Validity, then it has an infinite history, violating Wait-Freedom.
Reference: [6] <author> J. Anderson and B. Groselj, </author> <title> "Pseudo Read-Modify-Write Operations: Bounded Wait-Free Implementations," </title> <booktitle> Proceedings of the Fifth International Workshop on Distributed Algorithms, Lecture Notes in Computer Science, </booktitle> <address> Springer Verlag, </address> <note> to appear. </note>
Reference-contexts: The PRMW operation has the form "X := f (X)," and differs from the RMW operation in that the value of X is not returned. It is shown in <ref> [6] </ref> and [7] that any shared 24 data object that can either be read, written, or modified by a commutative PRMW operation can be implemented without waiting from atomic registers.
Reference: [7] <author> J. Aspens and M. Herlihy, </author> <title> "Wait-Free Data Structures in the Asynchronous PRAM Model," </title> <booktitle> Proceedings of the Second Annual ACM Symposium on Parallel Architectures and Algorithms, </booktitle> <month> July, </month> <year> 1990. </year>
Reference-contexts: The PRMW operation has the form "X := f (X)," and differs from the RMW operation in that the value of X is not returned. It is shown in [6] and <ref> [7] </ref> that any shared 24 data object that can either be read, written, or modified by a commutative PRMW operation can be implemented without waiting from atomic registers.
Reference: [8] <author> B. Bloom, </author> <title> "Constructing Two-Writer Atomic Registers," </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 37, No. 12, </volume> <month> December </month> <year> 1988, </year> <pages> pp. 1506-1514. </pages>
Reference-contexts: Our 1=L=1=1 construction is the first that we know of that explicitly addresses the case in which L is allowed to be infinite. In proving that a composite register construction is correct, the principal difficulty that arises is 18 K=L=M=N 1=L=1=N 1=1=1=1 <ref> [8, 22, 27, 30] </ref>[1, 3] [19, 29] that of establishing that all well-formed histories of the construction are serializable. The definition of serializability given in Section 4, while intuitive, is rather difficult to use directly.
Reference: [9] <author> J. Burns and G. Peterson, </author> <title> "Constructing Multi-Reader Atomic Values from Non-Atomic Values," </title> <booktitle> Proceedings of the Sixth Annual Symposium on Principles of Distributed Computing , 1987, </booktitle> <pages> pp. 222-231. </pages>
Reference: [10] <author> J. Burns and G. Peterson, </author> <title> "Pure Buffers for Concurrent Reading While Writing," </title> <type> Techni--cal Report GIT-ICS-87/17, </type> <institution> School of Information and Computer Science, Georgia Institute of Technology, </institution> <month> April </month> <year> 1987. </year>
Reference-contexts: To ensure that the Reader obtains a correct value, the Reader and the Writer are coordinated so that they never access the same buffer at the same time. This technique has been employed in several other similar constructions; see, for example, Burns and Peterson <ref> [10] </ref>, Kirousis et al. [17], and Tromp [29].
Reference: [11] <author> B. Chor, A. Israeli, and M. Li, </author> <title> "On Processor Coordination Using Asynchronous Hardware," </title> <booktitle> Principles of the Sixth Annual Symposium on Principles of Distributed Computing, </booktitle> <year> 1987, </year> <pages> pp. 86-97. </pages>
Reference-contexts: In particular, we showed that if such a program satisfies both Equity and Validity, then it has an infinite history, violating Wait-Freedom. Similar proofs have been obtained independently by Chor, Israeli, and Li <ref> [11] </ref> and by Herlihy [14]. This establishes the following theorem. Theorem 3: The binary election problem cannot be solved by a primitive program. 2 We now show that the binary election problem can be solved if either Exact-Writing or Single-Phase is violated.
Reference: [12] <author> E. Dijkstra, </author> <title> A Discipline of Programming, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1976. </year>
Reference-contexts: The actual justification is given in Sections 4 through 8. Concluding remarks appear in Section 9. 2 Concurrent Programs A concurrent program consists of a set of processes and a set of variables. A process is a sequential program specified using Dijkstra's guarded commands <ref> [12] </ref>. Each variable is either unsubscripted or subscripted. Unsubscripted variables are defined using integer, boolean, and subrange (e.g., 0::K) types. Subscripted variables are defined using an array type; the elements of an array are of type integer, boolean, or subrange.
Reference: [13] <author> M. Gouda, </author> <title> "Serializable Programs, Parallelizable Assertions: A Basis for Interleaving," in Beauty is Our Business, </title> <editor> eds. W.H.J. Feijen, A.J.M. van Gasteren, D. Gries, and J. Misra, </editor> <publisher> Springer-Verlag, </publisher> <year> 1990, </year> <pages> pp. 135-140. </pages>
Reference-contexts: According to our criterion, an action is "sufficiently simple" if it can be implemented in a wait-free, serializable manner in terms of primitive actions. (In <ref> [13] </ref>, Gouda argues that we should also restrict our attention to only certain kinds of assertions when reasoning about the behavior of a program under interleaving semantics.
Reference: [14] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 13, No. 1, </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: The Exact-Writing constraint specifies the conditions under which an assignment statement may write several shared variables; an assignment statement that writes several shared variables is called a multi-register assignment in <ref> [14] </ref>. Intuitively, this constraint implies that we can view the set of shared variables written by a given assignment statement as a single "compound" variable. (For the sake of simplicity, we have made Exact-Writing more restrictive than is necessary. <p> In particular, we showed that if such a program satisfies both Equity and Validity, then it has an infinite history, violating Wait-Freedom. Similar proofs have been obtained independently by Chor, Israeli, and Li [11] and by Herlihy <ref> [14] </ref>. This establishes the following theorem. Theorem 3: The binary election problem cannot be solved by a primitive program. 2 We now show that the binary election problem can be solved if either Exact-Writing or Single-Phase is violated.
Reference: [15] <author> M. Herlihy and J. Wing, </author> <title> "Linearizability: A Correctness Condition for Concurrent Objects," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 12, No. 3, </volume> <year> 1990, </year> <pages> pp. 463-492. </pages>
Reference-contexts: According to this definition, if several operations are executed concurrently, then the net effect should be equivalent to some serial order. Our definition of serializability is similar to the definition of linearizability given by Herlihy and Wing in <ref> [15] </ref>. Definition: Let h be a well-formed history of the implementation. <p> In particular, he considers a restricted notion of parallelism and argues that for interleaving semantics to be a suitable abstraction for this notion of parallelism, we should limit our attention to "parallelizable" assertions.) Our notion of serializability is equivalent to the definition of linearizability given by Herlihy and Wing in <ref> [15] </ref>, for the special case of implementing a program in which shared variables are accessed only by assignment statements. A similar notion has also been proposed by Misra [24].
Reference: [16] <author> C.A.R. Hoare, </author> <title> "Towards a Theory of Parallel Programming," Operating Systems Techniques, </title> <editor> eds. Hoare and Perott, </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: 1 Introduction Most proof methods that have been proposed for reasoning about concurrent programs are based upon the assumption that only one action of a concurrent program is executed at a time <ref> [16, 21, 23, 26] </ref>. This model of program execution is often referred to as interleaving semantics since the actions executed by one process are interleaved with those of other processes. Under interleaving semantics, a concurrent program is executed as a nondeterministic sequential one.
Reference: [17] <author> L. Kirousis, E. Kranakis, and P. Vitanyi, </author> <title> "Atomic Multireader Register," </title> <booktitle> Proceedings of the Second International Workshop on Distributed Computing, Lecture Notes in Computer Science 312, </booktitle> <pages> pp. 278-296, </pages> <publisher> Springer Verlag, </publisher> <year> 1987. </year>
Reference-contexts: To ensure that the Reader obtains a correct value, the Reader and the Writer are coordinated so that they never access the same buffer at the same time. This technique has been employed in several other similar constructions; see, for example, Burns and Peterson [10], Kirousis et al. <ref> [17] </ref>, and Tromp [29].
Reference: [18] <author> C. Kruskal, L. Rudolph, M. Snir, </author> <title> "Efficient Synchronization on Multiprocessors with Shared Memory," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 10, No. 4, </volume> <month> October </month> <year> 1988, </year> <pages> pp. 579-601. </pages>
Reference-contexts: Recent results concerning "pseudo read-modify-write" (PRMW) operations show that Single-Phase can also be relaxed somewhat. The PRMW operation takes its name from the classical read-modify-write (RMW) operation as defined in <ref> [18] </ref>; the RMW operation has the form "temp; X := X; f (X)," where X is a shared variable, temp a private variable, and f a function.
Reference: [19] <author> L. Lamport, </author> <title> "On Interprocess Communication, Parts I and II," </title> <journal> Distributed Computing , Vol. </journal> <volume> 1, </volume> <year> 1986, </year> <pages> pp. 77-101. </pages>
Reference-contexts: Our 1=L=1=1 construction is the first that we know of that explicitly addresses the case in which L is allowed to be infinite. In proving that a composite register construction is correct, the principal difficulty that arises is 18 K=L=M=N 1=L=1=N 1=1=1=1 [8, 22, 27, 30][1, 3] <ref> [19, 29] </ref> that of establishing that all well-formed histories of the construction are serializable. The definition of serializability given in Section 4, while intuitive, is rather difficult to use directly. <p> Note that for K = 1, Write Precedence is a direct consequence of Uniqueness. Conditions similar to Integrity, Proximity, and Read Precedence have been used elsewhere as a correctness condition for atomic register constructions; see, for example, the Integrity, Safety, and Precedence conditions of [28], and Proposition 3 of <ref> [19] </ref>. An atomic register is a special case of a composite register in which there is only one component. The correctness proof for the Shrinking Lemma is given in [4]. The proof is somewhat tedious, but is not hard. The proof strategy is as follows. <p> A composite register is equivalent to the atomic snapshot primitive defined by Afek et al. in [1]. The notion of an atomic register was first defined by Lamport <ref> [19] </ref>. An atomic register is a composite register with only one component. We should point out that it may be possible to relax the Exact-Writing and Single-Phase constraints somewhat, despite the necessity results proved in Section 5.
Reference: [20] <author> L. Lamport, </author> <title> "win and sin: Predicate Transformers for Concurrency," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 12, No. 3, </volume> <year> 1990, </year> <pages> pp. 396-428. </pages>
Reference-contexts: Owicki and Gries attribute the "observation that the memory reference must have `reasonable' properties" to John Reynolds [26]. For this reason, the Owicki-Gries atomicity criterion is sometimes known as Reynolds' Rule <ref> [20] </ref>. This atomicity criterion has gained widespread acceptance since its introduction. Owicki and Gries, in effect, resolve the dilemma noted above "by definition" because they do not defend their atomicity criterion on any formal basis. We are thus led to question their criterion on two grounds. <p> We are thus led to question their criterion on two grounds. First, it is not clear whether this is a viable criterion from an implementation standpoint. In fact, its "reasonableness" in this regard probably qualifies as a folk theorem <ref> [20] </ref>. Second, we question whether this criterion is unnecessarily restrictive. That is, it might be possible to relax the Owicki-Gries atomicity criterion somewhat without making programs any harder to implement. In this paper, we remedy these two shortcomings by providing a formal framework for defining the class of atomic programs.
Reference: [21] <author> L. Lamport and F. Schneider, </author> <title> "The Hoare Logic of CSP, and All That," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 6, No. 2, </volume> <month> April </month> <year> 1984, </year> <pages> pp. 281-296. </pages>
Reference-contexts: 1 Introduction Most proof methods that have been proposed for reasoning about concurrent programs are based upon the assumption that only one action of a concurrent program is executed at a time <ref> [16, 21, 23, 26] </ref>. This model of program execution is often referred to as interleaving semantics since the actions executed by one process are interleaved with those of other processes. Under interleaving semantics, a concurrent program is executed as a nondeterministic sequential one.
Reference: [22] <author> M. Li, J. Tromp, and P. Vitanyi, </author> <title> "How to Construct Wait-Free Variables," </title> <booktitle> Proceedings of International Colloquium on Automata, Languages, and Programming, Lecture Notes in Computer Science 372, </booktitle> <pages> pp. 488-505, </pages> <publisher> Springer Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Our 1=L=1=1 construction is the first that we know of that explicitly addresses the case in which L is allowed to be infinite. In proving that a composite register construction is correct, the principal difficulty that arises is 18 K=L=M=N 1=L=1=N 1=1=1=1 <ref> [8, 22, 27, 30] </ref>[1, 3] [19, 29] that of establishing that all well-formed histories of the construction are serializable. The definition of serializability given in Section 4, while intuitive, is rather difficult to use directly.
Reference: [23] <author> Z. Manna and A. Pnueli, </author> <title> "Adequate Proof Principles for Invariance and Liveness Properities of Concurrent Programs," </title> <booktitle> Science of Computer Programming, </booktitle> <volume> Vol. 4, </volume> <year> 1984, </year> <pages> pp. 257-289. </pages>
Reference-contexts: 1 Introduction Most proof methods that have been proposed for reasoning about concurrent programs are based upon the assumption that only one action of a concurrent program is executed at a time <ref> [16, 21, 23, 26] </ref>. This model of program execution is often referred to as interleaving semantics since the actions executed by one process are interleaved with those of other processes. Under interleaving semantics, a concurrent program is executed as a nondeterministic sequential one.
Reference: [24] <author> J. Misra, </author> <title> "Axioms for Memory Access in Asynchronous Hardware Systems," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 8, No. 1, </volume> <month> January </month> <year> 1986, </year> <pages> pp. 142-153. 27 </pages>
Reference-contexts: A similar notion has also been proposed by Misra <ref> [24] </ref>. In particular, Misra gives a set of axioms for constructing concurrent hardware registers, and shows that if a register satisfies these axioms, then concurrent accesses to the register can be viewed as being interleaved.
Reference: [25] <author> R. Newman-Wolfe, </author> <title> "A Protocol for Wait-Free, Atomic, Multi-Reader Shared Variables, </title> <booktitle> Pro--ceedings of the Sixth Annual Symposium on Principles of Distributed Computing , 1987, </booktitle> <pages> pp. 232-248. </pages>
Reference: [26] <author> S. Owicki and D. Gries, </author> <title> "An Axiomatic Proof Technique for Parallel Programs I," </title> <journal> Acta Infor-matica, </journal> <volume> Vol. 6, </volume> <year> 1976, </year> <pages> pp. 319-340. </pages>
Reference-contexts: 1 Introduction Most proof methods that have been proposed for reasoning about concurrent programs are based upon the assumption that only one action of a concurrent program is executed at a time <ref> [16, 21, 23, 26] </ref>. This model of program execution is often referred to as interleaving semantics since the actions executed by one process are interleaved with those of other processes. Under interleaving semantics, a concurrent program is executed as a nondeterministic sequential one. <p> How can we possibly satisfy both of these seemingly conflicting requirements? The roots of this question can be traced back to the seminal work of Owicki and Gries <ref> [26] </ref>, who were perhaps the first to define a criterion for atomicity. In order to state their atomicity criterion, it is necessary to first distinguish between two classes of program variables, shared and private. <p> The underlying assumption here is that it should be possible to read or write any shared variable in a single action. Owicki and Gries attribute the "observation that the memory reference must have `reasonable' properties" to John Reynolds <ref> [26] </ref>. For this reason, the Owicki-Gries atomicity criterion is sometimes known as Reynolds' Rule [20]. This atomicity criterion has gained widespread acceptance since its introduction. Owicki and Gries, in effect, resolve the dilemma noted above "by definition" because they do not defend their atomicity criterion on any formal basis.
Reference: [27] <author> G. Peterson and J. Burns, </author> <title> "Concurrent Reading While Writing II: The Multi-Writer case," </title> <booktitle> Proceedings of the 28th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1987. </year>
Reference-contexts: Our 1=L=1=1 construction is the first that we know of that explicitly addresses the case in which L is allowed to be infinite. In proving that a composite register construction is correct, the principal difficulty that arises is 18 K=L=M=N 1=L=1=N 1=1=1=1 <ref> [8, 22, 27, 30] </ref>[1, 3] [19, 29] that of establishing that all well-formed histories of the construction are serializable. The definition of serializability given in Section 4, while intuitive, is rather difficult to use directly.
Reference: [28] <author> A. Singh, J. Anderson, and M. Gouda, </author> <title> "The Elusive Atomic Register, Revisited," </title> <booktitle> Proceedings of the Sixth Annual Symposium on Principles of Distributed Computing , 1987, </booktitle> <pages> pp. 206-221. </pages>
Reference-contexts: Note that for K = 1, Write Precedence is a direct consequence of Uniqueness. Conditions similar to Integrity, Proximity, and Read Precedence have been used elsewhere as a correctness condition for atomic register constructions; see, for example, the Integrity, Safety, and Precedence conditions of <ref> [28] </ref>, and Proposition 3 of [19]. An atomic register is a special case of a composite register in which there is only one component. The correctness proof for the Shrinking Lemma is given in [4]. The proof is somewhat tedious, but is not hard. The proof strategy is as follows.
Reference: [29] <author> J. Tromp, </author> <title> "How to Construct an Atomic Variable," </title> <booktitle> Proceedings of the Third International Workshop on Distributed Algorithms, Lecture Notes in Computer Science 392, </booktitle> <pages> pp. 292-302, </pages> <publisher> Springer Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Our 1=L=1=1 construction is the first that we know of that explicitly addresses the case in which L is allowed to be infinite. In proving that a composite register construction is correct, the principal difficulty that arises is 18 K=L=M=N 1=L=1=N 1=1=1=1 [8, 22, 27, 30][1, 3] <ref> [19, 29] </ref> that of establishing that all well-formed histories of the construction are serializable. The definition of serializability given in Section 4, while intuitive, is rather difficult to use directly. <p> This technique has been employed in several other similar constructions; see, for example, Burns and Peterson [10], Kirousis et al. [17], and Tromp <ref> [29] </ref>.
Reference: [30] <author> P. Vitanyi and B. Awerbuch, </author> <title> "Atomic Shared Register Access by Asynchronous Hardware," </title> <booktitle> Proceedings of the 27th IEEE Symposium on the Foundations of Computer Science, </booktitle> <year> 1986, </year> <pages> pp. 233-243. </pages>
Reference-contexts: Our 1=L=1=1 construction is the first that we know of that explicitly addresses the case in which L is allowed to be infinite. In proving that a composite register construction is correct, the principal difficulty that arises is 18 K=L=M=N 1=L=1=N 1=1=1=1 <ref> [8, 22, 27, 30] </ref>[1, 3] [19, 29] that of establishing that all well-formed histories of the construction are serializable. The definition of serializability given in Section 4, while intuitive, is rather difficult to use directly.
References-found: 30

