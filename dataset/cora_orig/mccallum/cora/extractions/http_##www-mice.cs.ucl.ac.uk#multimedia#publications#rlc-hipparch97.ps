URL: http://www-mice.cs.ucl.ac.uk/multimedia/publications/rlc-hipparch97.ps
Refering-URL: http://www-mice.cs.ucl.ac.uk/multimedia/publications/
Root-URL: http://www.cs.ucl.ac.uk
Email: email: fL.Vicisano,J.Crowcroftg@cs.ucl.ac.uk  
Title: One to Many Reliable Bulk-Data Transfer in the MBone  
Author: Lorenzo Vicisano, Jon Crowcroft 
Address: Gower Street, London WC1E 6BT, UK  
Affiliation: Department of Computer Science University College London  
Note: Appeared in Proceedings of the Third International Workshop on High Performance Protocol Architectures HIPPARCH '97 Uppsala, Sweden, June 12-13, 1997. Also UCL-CS Research Note RN/97/49.  
Abstract: In this paper we depict and evaluate the performance of a protocol for reliable bulk-data transfer from one sender to many receivers simultaneously, using the Internet multicast infrastructure (MBone). The protocol, featuring a TCP-friendly congestion control algorithm, has been designed aiming at achieving a complete scalability of the system with the respect to the number of receivers. For this reason both reliability and congestion control are carried out by receivers, avoiding to involve the sender in the congestion control feedback loop and relieving it from the burden of carrying out retransmission for all receivers. The receiver-driven congestion control algorithm presented is based on a redundant layered organisation of data, where redundancy is used to spread the information being sent into a large number of data units, providing receivers with flexibility in accepting some of them rather than others, and still being able to complete the reception. Reliability is based on a probabilistic approach and is achieved using redundancy and continuous transmission, providing graceful degradation of the protocol efficiency when the loss rate increases. Other contributions in this paper include: simulation of the protocol in competition with TCP with drop-tail and RED routers; analysis of the stable operating point; implementation and measurements of the protocol (future). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D-M.Chiu, </author> <title> R.Jain "Analysis of the Increase and Decrease Algorithm hms for Congestion Avoidance in Computer Networks", computer Networks and ISDN Systems, </title> <address> V.17, pp.1-14, </address> <year> 1989. </year>
Reference-contexts: We spread couples of sender/receiver on the two paths with different delay n 0 |n 5 and n 4 |n 3 . Each receiver was started at a random time in the interval <ref> [1, 1 + N=2] </ref>s, N being the number receivers. Table 3 shows some parameters measured using 2, 4, 8, 16 and 32 protocol instances. <p> Each receiver was started at a random time in the interval [1, 1 + N=2]s, N being the number receivers. Table 3 shows some parameters measured using 2, 4, 8, 16 and 32 protocol instances. The first parameter shown is the fairness index <ref> [1] </ref> that is defined as: f i = x=0 T (x) N x=0 T (x) 2 where T (x) is the throughput of the x-th protocol instance. f i always lies between 1=N and 1: when all the instances get a perfectly equal share, f i is equal to 1; when
Reference: [2] <author> K.Fall, S.Floyd, </author> <title> "Simulation Based Comparisons of Thaoe, Reno, and SACK TCP", </title> <address> CCR, Vol.26 N.3, </address> <month> Jul. </month> <year> 1996, </year> <month> pp.5-21. </month>
Reference-contexts: All the simulation has been run using a leave delay time of 1s, and we have set t h 1:1 times the leave delay. In the following, for comparison purposes, we will use the New-Reno variant of TCP described in <ref> [2] </ref> and implemented in ns by the authors of [2] according to suggestions from [5]. <p> All the simulation has been run using a leave delay time of 1s, and we have set t h 1:1 times the leave delay. In the following, for comparison purposes, we will use the New-Reno variant of TCP described in <ref> [2] </ref> and implemented in ns by the authors of [2] according to suggestions from [5].
Reference: [3] <author> W. Fenner, </author> <title> "Internet Group Management Protocol, </title> <type> Version 2", INTERNET-DRAFT (working draft), </type> <month> Jan. 20, </month> <year> 1997, </year> <note> http://ds.internic.net/internet-drafts/- draft-ietf-idmr-igmp-v2-06.txt </note>
Reference: [4] <author> S.Floyd, K.Fall, </author> <title> "Router Mechanisms to Support End-to-End Congestion Control", </title> <type> Technical report, </type> <institution> ftp://ftp.ee.lbl.gov/papers/collapse.ps. </institution>
Reference-contexts: The last parameter to set, P , allows us to tune our protocol in order to make it TCP-friendly (<ref> [4] </ref>). In [4], Floyd and Fall showed that, basing on a simple steady-state model, it is possible to compute an upper bound of the bandwidth a that TCP connection uses, as a function of the loss rate (p) it experiences.
Reference: [5] <author> J.Hoe, </author> <title> "Stat-up Dynamics of TCP's Congestion Control and Avoidance Schemes", </title> <month> Jun. </month> <year> 1995, </year> <type> Master's Thesis, </type> <institution> MIT. </institution> <month> 12 </month>
Reference-contexts: In the following, for comparison purposes, we will use the New-Reno variant of TCP described in [2] and implemented in ns by the authors of [2] according to suggestions from <ref> [5] </ref>. New-Reno TCP is a slightly modified version of Reno-TCP [7] that includes all Reno and Thaoe features (Slow-Start, Congestion Avoidance, Fast Retransmit and Fast Recovery) and fixes some problems of Reno's Fast Recovery preventing from the `pipe' from emptying when multiple packets belonging to the same cwnd are lost.
Reference: [6] <author> V.Jacobson, </author> <title> "Congestion Avoidance and Control", </title> <booktitle> ACM SIGCOMM'88, </booktitle> <month> August </month> <year> 1988, </year> <institution> Stanford, </institution> <address> CA, pp.314-329. </address>
Reference-contexts: This time is proportional to the throughput, as point 2) states. The congestion control performed as above presents, however, a number of differences from that of TCP. First of all TCP congestion control is based on the `conservation of packets' principle <ref> [6] </ref>: a new packet isn't put into the network until an old packet leaves; this allows robustness in the face of short-term load changes, in fact it makes the throughput decrease as the round trip delay increases.
Reference: [7] <author> V.Jacobson, </author> <title> "Modified TCP Congestion Avoidance Algorithm", </title> <type> Tech. report, </type> <month> 30 Apr. </month> <year> 1990. </year> <note> Email to end2end-interest Mailing List, ftp://ftp.ee.lbl.gov/email/- vanj.90apr30.txt. </note>
Reference-contexts: In the following, for comparison purposes, we will use the New-Reno variant of TCP described in [2] and implemented in ns by the authors of [2] according to suggestions from [5]. New-Reno TCP is a slightly modified version of Reno-TCP <ref> [7] </ref> that includes all Reno and Thaoe features (Slow-Start, Congestion Avoidance, Fast Retransmit and Fast Recovery) and fixes some problems of Reno's Fast Recovery preventing from the `pipe' from emptying when multiple packets belonging to the same cwnd are lost.
Reference: [8] <author> S.McCanne, V.Jacobson, M.Vetterli, </author> <title> "Receiver-driven Layered Multicast", </title> <booktitle> ACM SIG-COMM'96, </booktitle> <month> August </month> <year> 1996, </year> <institution> Stanford, </institution> <address> CA, pp.1-14. </address>
Reference-contexts: Receivers can control their receiving rate by choosing their subscription level. This way they establish a tradeoff between bandwidth usage and receiving time, similarly to what is sometimes done with layered multimedia streams <ref> [8] </ref>, where quality can be traded to save bandwidth. In order to allow receivers to fully exploit the bandwidth they use, we must encode data in a flexible way and organise it properly across layers. <p> As this introduce several problems, most communication protocol do not address it. Nevertheless coordinating different instance of a given protocol that share the same bottleneck would apport several benefit, allowing more fairness and a better exploitation of the available bandwidth. McCanne et al. in <ref> [8] </ref> proposed an explicit form of coordination among receivers, belonging to the same protocol instance. In their solution (shared learning) each receiver, before performing a join-experiment (add a layer) to infer the capacity of the links, takes care of informing the other receiver, specifying the current subscription level as well.
Reference: [9] <institution> UCB/LBNL Network Simulator - ns version 2, </institution> <year> 1997, </year> <note> http://www-mash.cs.berkeley.edu/ns/. </note>
Reference-contexts: Performance evaluation, however, has been carried out, for the time being, by means of a simulation. For this purpose we have implemented the protocol in the ns network simulator <ref> [9] </ref>, partly in C++ and partly in otcl [19]. Both the real protocol implementation and the simulation code are available from the authors. For all the experiments presented in this section we have used the simulated network topologies of Figure 2.
Reference: [10] <author> B. Kantor and P. Lapsley, </author> <title> "Network news transfer protocol: A proposed standard for the stream-based transmission of news," Request for Comments (Proposed Standard) RFC 977, </title> <institution> Internet Engineering Task Force, </institution> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: When the application using the protocol is NNTP <ref> [10] </ref> or ICP [18], for News distribution, or web inter-cache protocol traffic, then the organisation of the elected control servers can easily be driven from the hierarchy already present in the news and web server organisation. <p> Our protocols instances have been evenly distributed across the two paths while all the TCP 10 bytes (right). connection have been placed on the path n 0 |n 5 , characterised by 420ms RTT. All the starting time have been determined randomly in the interval <ref> [0, 10] </ref>s. Figure 5 shows the aggregate throughput of TCP connections and that of our protocol instances. The graph on the left refers to TCP with 256 bytes packet size, while the one on the right refers to 1024 bytes packet size.
Reference: [11] <author> T.Ott, J.Kemperman, M.Mhathis, </author> <title> "The stationary distribution of ideal TCP congestion avoidance", </title> <type> Technical Report, </type> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: They found the following relation: T T CP 3=2 fl B T CP p (1) where T is the throughput of the connection and p is the loss rate. A relation identical to 1, with slightly different constant, has been found in <ref> [11] </ref> using a more rigorous model. Using a simplified model of our algorithm, we also found the relation between throughput and loss rate in our protocol. The model assume that receivers oscillate between two adjacent subscription levels.
Reference: [12] <author> L. </author> <title> Rizzo, "Effective erasure codes for reliable computer communication protocols", </title> <address> CCR, V.27 N.2, </address> <month> April </month> <year> 1997, </year> <month> pp.24-36. </month>
Reference-contexts: In order to allow receivers to fully exploit the bandwidth they use, we must encode data in a flexible way and organise it properly across layers. That can be done using a suitable block redundancy code able to recover from erasures (see <ref> [12] </ref>). <p> Some simulations performed in [16] show that the receiving efficiency |defined as the total number of packets received divided by the file length in packets| is always larger than 90% for common loss pattern, such as burst losses or random uncorrelated losses. Concerning the redundant encoding algorithms, <ref> [12] </ref> shows a fast software implementation of such an algorithm, fast enough to allow on-line encoding with a throughput up to 1|2M b=s. The redundant packet encoding is exploited not only to have the flexibility we discussed, but also to cope with packet loss.
Reference: [13] <author> L.Rizzo, L.Vicisano, </author> <title> "A Reliable Multicast data Distribution Protocol based on software FEC techniques", </title> <booktitle> The Fourth IEEE Workshop on the Architecture and Implementation of High Performance Communication Systems (HPCS'97) Sani Beach, </booktitle> <address> Chalkidiki, Greece June 23-25, </address> <note> 1997 (to appear). </note>
Reference-contexts: Another simple protocol to accomplish this task is discussed in <ref> [13] </ref> spread out the original information |e.g. to obtain n data packets from k original source packets| so that what counts is the amount of data received, not the actual information |i.e., dealing with packets, we can rebuild all the original k source packets once k packets are received out of <p> way of providing reliability is a probabilistic approach, that avoids retransmissions altogether, only requiring the sender to keep transmitting for the sufficient amount of time. 34 It also make this protocol suitable in scenarios where reception are started in a uncoordinated fashion at each site, but still statistic overlapping exists. <ref> [13] </ref> discusses further this issue, also showing graphs reporting the reception completion probability versus the transmission extension for various loss rate and patterns. 3 Congestion Control In the receiver-driven congestion control scheme we propose, each receiver is in charge of controlling the data rate flowing toward it, in order to avoid
Reference: [14] <author> H.Schulzrinne, S.Casner, R.Frederick, V.Jacobson, "RTP: </author> <title> A Transport Protocol for Real-Time Applications", Internet Official Protocol Standards, </title> <type> RFC 1889, </type> <month> Jan </month> <year> 1996, </year> <note> http://ds.internic.net/rfc/rfc1889.txt. </note>
Reference-contexts: A redundant encoding could, in principle, allow us to 1 One simple scheme is simply to elect some sample sites, and allot each a reporting time, scattering the report times across some period with a uniform random interval, to avoid implosion, in the manner of RTCP receiver reports <ref> [14] </ref>. When the application using the protocol is NNTP [10] or ICP [18], for News distribution, or web inter-cache protocol traffic, then the organisation of the elected control servers can easily be driven from the hierarchy already present in the news and web server organisation.
Reference: [15] <author> W. Stevens., </author> <title> "TCP Slow Start, Congestion Avoidance, Fast Retransmit, and Fast Recovery Algorithms.", </title> <address> RFC2001, </address> <month> January </month> <year> 1997. </year>
Reference: [16] <author> L.Vicisano, </author> <title> "Notes on a cumulative layered organisation of data packets across multiple streams with variable-rate", </title> <address> http://www.cs.ucl.ac.uk/staff/L.Vicisano/- layers.ps </address> . 
Reference-contexts: That impose the need to use a proper packet organisation across different layers, in order to minimise the number of useless packets received |if we already have k packets of a given block, each additional packet of that block is useless. <ref> [16] </ref> shows two possible packet organisation, that allow to obtain good bandwidth exploitation efficiency, interleaving blocks across layers. Some simulations performed in [16] show that the receiving efficiency |defined as the total number of packets received divided by the file length in packets| is always larger than 90% for common loss <p> in order to minimise the number of useless packets received |if we already have k packets of a given block, each additional packet of that block is useless. <ref> [16] </ref> shows two possible packet organisation, that allow to obtain good bandwidth exploitation efficiency, interleaving blocks across layers. Some simulations performed in [16] show that the receiving efficiency |defined as the total number of packets received divided by the file length in packets| is always larger than 90% for common loss pattern, such as burst losses or random uncorrelated losses.
Reference: [17] <author> L.Vicisano, M.Handley, J.Crowcroft, "B-MART, </author> <title> Bulk-data (non-real-time) Multiparty Adaptive Reliable Transfer Protocol", </title> <publisher> ftp://cs.ucl.ac.uk/darpa/bulk.ps.Z. </publisher>
Reference-contexts: The main problems are associated with a degree of uncertainty about how well one can actually detect loss correlation in the Mbone. Work by Handley (see <ref> [17] </ref>) suggests that it is easy to find some levels of correlated loss for some groups, but that there remains a hard-core of sub-trees of the network for which there is a lot of noise in the loss signal.
Reference: [18] <author> D.Wessels, K.Claffy, </author> <title> "Internet Cache Protocol (ICP), </title> <type> version 2", INTERNET-DRAFT (working draft), </type> <month> May 27 </month> <year> 1997, </year> <note> http://ds.internic.net/internet-drafts/- draft-wessels-icpv2-03.txt. </note>
Reference-contexts: When the application using the protocol is NNTP [10] or ICP <ref> [18] </ref>, for News distribution, or web inter-cache protocol traffic, then the organisation of the elected control servers can easily be driven from the hierarchy already present in the news and web server organisation.
Reference: [19] <author> D.Wetherall and C. Lindblad, </author> <title> "Extending Tcl for Dynamic Object-Oriented Programming", </title> <booktitle> Proceedings of the Tcl/Tk Workshop '95, </booktitle> <address> Toronto, </address> <month> July </month> <year> 1995. </year> <month> 13 </month>
Reference-contexts: Performance evaluation, however, has been carried out, for the time being, by means of a simulation. For this purpose we have implemented the protocol in the ns network simulator [9], partly in C++ and partly in otcl <ref> [19] </ref>. Both the real protocol implementation and the simulation code are available from the authors. For all the experiments presented in this section we have used the simulated network topologies of Figure 2. The simulations have been run using both Drop-Tail routers and RED routers.
References-found: 19

