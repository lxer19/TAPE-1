URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS94-07.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: tyang@cs.ucsb.edu  
Title: An Analysis of Scheduling Coarse-Grain Iterative Task Computation on Message-Passing Architectures  
Author: Tao Yang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: Scheduling task computation and predicting its performance on message-passing architectures are important for program parallelization. In this paper we consider the scheduling of a weighted iterative task graph (ITG) in the presence of communication overhead. An ITG represents a sequence of parallel task computation. Each iteration contains the execution of a set of tasks and there exists task dependence within an iteration and between iterations. We provide a lower bound for optimal scheduling when the weights of iterative task graphs change monotonically in the course of iterations. We devise a valid schedule without searching task instances of all iterations, examine the asymptotic performance of this schedule compared to an optimal solution. Finally, we present case studies and experimental results on nCUBE-2 to verify our solutions. 
Abstract-found: 1
Intro-found: 1
Reference: [AN88] <author> A. Aiken and A. Nicolau, </author> <title> Optimal Loop Parallelization, </title> <booktitle> SIGPLAN 88 Conf. on Programming Language Design and Implementation. </booktitle> <address> pp.308-317. </address>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> This is because processors that execute the tasks T x with a x = a max are overloaded. Loop unrolling is a loop transformation technique to increase the number of tasks within the loop body, which can lead to an optimal solution for software pipelining <ref> [AN88, PM91, CS93] </ref> when there is a sufficient number of processors. We examine how loop unrolling could improve the scheduling performance of ITG on message-passing architectures when a max &gt;> max (a avg ; Q (G)) and more processors are available. <p> We use a similar definition to quantify the granularity of an ITG. The earliest work on software pipelining has been Reiter [REI68]. Lam [LAM88] developed pipelin ing algorithms for compiling on VLIW machines. Aiken and Nicolau <ref> [AN88] </ref> proposed an algorithm that unrolls a loop and finds an optimal schedule. Optimal loop unrolling has also been studied by Parhi and Messerschmitt [PM91] and Chao and Sha [CS93]. Zaky and Sadayappan [ZS89] formulated the scheduling problem using a path algebra to find the optimal solutions.
Reference: [CS93] <author> L. F. Chao and E. H. Sha, </author> <title> Unified static scheduling on various models. </title> <booktitle> Proc. ICPP 1993, </booktitle> <volume> Vol II, </volume> <pages> pp 231-235. </pages>
Reference-contexts: This is because processors that execute the tasks T x with a x = a max are overloaded. Loop unrolling is a loop transformation technique to increase the number of tasks within the loop body, which can lead to an optimal solution for software pipelining <ref> [AN88, PM91, CS93] </ref> when there is a sufficient number of processors. We examine how loop unrolling could improve the scheduling performance of ITG on message-passing architectures when a max &gt;> max (a avg ; Q (G)) and more processors are available. <p> Lam [LAM88] developed pipelin ing algorithms for compiling on VLIW machines. Aiken and Nicolau [AN88] proposed an algorithm that unrolls a loop and finds an optimal schedule. Optimal loop unrolling has also been studied by Parhi and Messerschmitt [PM91] and Chao and Sha <ref> [CS93] </ref>. Zaky and Sadayappan [ZS89] formulated the scheduling problem using a path algebra to find the optimal solutions. Munshi and Simons [MS90] examined the complexity of instruction scheduling and proposed heuristic solutions. Van Dongen, Gao and Ning [VGN92] proposed the scheduling solution on an unbounded number of processors.
Reference: [Ch89] <author> P. Chretienne, </author> <title> Task Scheduling over Distributed Memory Machines, </title> <booktitle> Proc. of Inter. Workshop on Parallel and Distributed Algorithms, </booktitle> <publisher> (North Holland, Ed.), </publisher> <year> 1989. </year>
Reference-contexts: The Gantt chart completely describes the schedule since it defines both the processor assignment and the starting time for each task. The scheduling problem with nonzero communication delay has been shown to be NP-complete for a general task graph, by Chretienne <ref> [Ch89] </ref>, Papadimitriou and Yannakakis [PY90], and Sarkar [S89a]. 1 P Gantt chart n 1 n 3 n 2 n 5 1 2 3 4 5 6 7 Time (a) 2 2 n 1 n 8 n 7 n 5 (b) n 6 n 3 n 2 n 4 (c) Gantt chart
Reference: [Dun91] <author> T. H. Dunigan, </author> <title> Performance of the INTEL iPSC/860 and nCUBE 6400 Hypercube, </title> <institution> ORNL/TM-11790, Oak Ridge National Lab., TN, </institution> <year> 1991. </year>
Reference-contexts: The following table gives the communication and single-precision computation speeds of two machines in microseconds taken from Dunigan <ref> [Dun91] </ref>. startup time (s) trans. speed (t) add or mult iPSC/860 136 s 0.4 s /byte 0.1 s nCUBE-II 160 s 0.6 s /byte 0.8 s The physical distance between processors also affects communication delay, especially in a store-forward routing network; however, in a wormhole routing network the cost is not <p> The communication from T q to S is to send a subvector of B and the cost is approximated as s+tflh where s is the startup time and t is the transmission speed <ref> [Dun91] </ref>. The communication from S to T q is to broadcast X j+1 . The broadcasting communication cost is estimated as log (P + 1)(s + t fl h) on nCUBE-2. The weight function is monotonically decreasing. <p> The sequential time is 21890 milliseconds. Since the number of operations for the sequential algorithm is n 2 w, we estimate w = 0:8756s. For nCUBE-2, s = 160s and t = 0:6s per byte <ref> [Dun91] </ref>. In Fig. 7, we plot the predicted performance by using these parameters in the above formula and compare it to the actual performance in Fig.7. The predicted performance is close to the actual parallel time in nCUBE-2.
Reference: [EL90] <author> H. El-Rewini and T. G. Lewis, </author> <title> Scheduling Parallel Program Tasks onto Arbitrary Target Machines, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 9, </volume> <year> 1990, </year> <pages> pp. 138-153. </pages>
Reference-contexts: A basic representation of parallel computation is a directed acyclic graph (DAG) which represents the dependence between the instances of task computation. DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools <ref> [EL90, WG88, YG92] </ref>. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. [EL90, GY93a, KB88, S89a, WG88, YG92]. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. <p> DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. <ref> [EL90, GY93a, KB88, S89a, WG88, YG92] </ref>. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. An iterative task graph (ITG) represents a sequence of parallel task computation. <p> DAG is the fundamental representation of task computation and the expanded graph in our model is a DAG. Exploring task parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis <ref> [EL90] </ref>, Gerasoulis and Yang [GY93a, YG92], Kim and Browne [KB88], Sarkar [S89a], Shirazi, Wang and Pathak [SWP90], Wolski and Feo [WF93], Wu and Gajski [WG88].
Reference: [GS92] <author> F. Gasperoni and U. </author> <title> Schweigelshoh Scheduling Loops on Parallel Processors: A simple algorithm with close to optimum performance. </title> <booktitle> Proc. of CONPAR 92 , pp. </booktitle> <pages> 613-624. </pages>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> Munshi and Simons [MS90] examined the complexity of instruction scheduling and proposed heuristic solutions. Van Dongen, Gao and Ning [VGN92] proposed the scheduling solution on an unbounded number of processors. Gasperoni and Schweigelshoh <ref> [GS92] </ref> proposed scheduling algorithms for a bounded and unbounded number of processors. We extend the above work to consider the scheduling of coarse-grain task parallelism with nonzero communication.
Reference: [GY93a] <author> A. Gerasoulis and T. Yang, </author> <title> On the Granularity and Clustering of Directed Acyclic Task Graphs, </title> <journal> IEEE Trans. on Parallel and Distributed Systems., </journal> <volume> Vol. 4, no. 6, </volume> <month> June </month> <year> 1993, </year> <pages> pp 686-701. </pages>
Reference-contexts: DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. <ref> [EL90, GY93a, KB88, S89a, WG88, YG92] </ref>. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. An iterative task graph (ITG) represents a sequence of parallel task computation. <p> The performance of scheduling depends on the granularity of task graphs. A definition and analysis on granularity of a DAG is given in <ref> [GY93a] </ref> and we use a slightly different definition to quantify the granularity of an ITG G as: g = min f min T y 2succ (T x ) a x g: Theorem 3 If a max and b max are bounded constants, let Q (G) = max all cycles C A1 <p> Exploring task parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis [EL90], Gerasoulis and Yang <ref> [GY93a, YG92] </ref>, Kim and Browne [KB88], Sarkar [S89a], Shirazi, Wang and Pathak [SWP90], Wolski and Feo [WF93], Wu and Gajski [WG88]. The common model is the macro-dataflow task computation model, the execution of task computation is triggered when the data items are available in the local memory. <p> We use the same model of computation but do not search the entire expanded task graph to produce a schedule, which is suitable when task graphs are 19 executed iteratively. Gerasoulis and Yang <ref> [GY93a] </ref> proposed a definition of granularity to analyze the impact of granularity on DAG scheduling. We use a similar definition to quantify the granularity of an ITG. The earliest work on software pipelining has been Reiter [REI68]. Lam [LAM88] developed pipelin ing algorithms for compiling on VLIW machines.
Reference: [K94] <author> V. Kumar, A. Grama, A. Gupta, G. Karypis, </author> <title> Introduction to Parallel Computing, </title> <publisher> Ben-jamin/Cummings Pub, </publisher> <year> 1994. </year>
Reference-contexts: Kumar et.al. <ref> [K94] </ref> discussed formulas for communication delay in a store-forward or wormhole routing network. In this paper, we assume that the worst-case cost is used in estimating task communication delay. Sarkar [S89a] discussed methods for estimating communication and computation cost.
Reference: [LS81] <author> C. E. Leiserson and J. B. Saxes, </author> <title> Optimizing synchronous systems, </title> <booktitle> IEEE 22nd Annual Symp. Foundations of Computer Science, </booktitle> <month> Oct </month> <year> 1981. </year> <pages> pp. 23-35. </pages>
Reference: [LAM88] <author> M. Lam, </author> <title> Software pipelining: an effective scheduling technique for VLIW machines, </title> <booktitle> Proc. of SIGPLAN 1988 Conf. on Programming Language Design and Implementation, ACM, </booktitle> <month> June </month> <year> 1988, </year> <note> pp.318-328. 21 </note>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> When a avg = 0, the bound is reduced to L crit M C fl B1 C = b N1 D C cB1 C which is a lower bound for any cyclic scheduling <ref> [REI68, LAM88, PM91] </ref>. 4 Scheduling on v processors We present a schedule for an ITG with precise dependence when the number of processors is v (equal to the number of tasks in the loop). We will provide an analysis of its asymptotic performance. <p> Gerasoulis and Yang [GY93a] proposed a definition of granularity to analyze the impact of granularity on DAG scheduling. We use a similar definition to quantify the granularity of an ITG. The earliest work on software pipelining has been Reiter [REI68]. Lam <ref> [LAM88] </ref> developed pipelin ing algorithms for compiling on VLIW machines. Aiken and Nicolau [AN88] proposed an algorithm that unrolls a loop and finds an optimal schedule. Optimal loop unrolling has also been studied by Parhi and Messerschmitt [PM91] and Chao and Sha [CS93].
Reference: [KB88] <author> S.J. Kim and J.C. Browne, </author> <title> A General Approach to Mapping of Parallel Computation upon Multiprocessor Architectures, </title> <booktitle> Proc. of Inter. Conf. on Parallel Processing, </booktitle> <volume> Vol. 3, </volume> <year> 1988, </year> <pages> pp. 1-8. </pages>
Reference-contexts: DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. <ref> [EL90, GY93a, KB88, S89a, WG88, YG92] </ref>. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. An iterative task graph (ITG) represents a sequence of parallel task computation. <p> Exploring task parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis [EL90], Gerasoulis and Yang [GY93a, YG92], Kim and Browne <ref> [KB88] </ref>, Sarkar [S89a], Shirazi, Wang and Pathak [SWP90], Wolski and Feo [WF93], Wu and Gajski [WG88]. The common model is the macro-dataflow task computation model, the execution of task computation is triggered when the data items are available in the local memory.
Reference: [PAM93] <author> S. S. Pande, D. P. Agrawal and J. Mauney, </author> <title> A scalable scheduling scheme for functional parallelism on distributed memory multiprocessor systems, </title> <type> Tech. Report, </type> <institution> North Carolina State Univ. </institution> <year> 1993. </year>
Reference-contexts: 1 Introduction The problem of NP-hard scheduling has been addressed extensively in the literature. A basic representation of parallel computation is a directed acyclic graph (DAG) which represents the dependence between the instances of task computation. DAG scheduling has been used in compiling functional parallelism <ref> [PAM93, S89a, WF93] </ref>, and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. [EL90, GY93a, KB88, S89a, WG88, YG92]. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation.
Reference: [PY90] <author> C. Papadimitriou and M. Yannakakis, </author> <title> Towards on an Architecture-Independent Analysis of Parallel Algorithms, </title> <journal> SIAM J. Comput., </journal> <volume> Vol. 19, </volume> <year> 1990, </year> <pages> pp. 322-328. </pages>
Reference-contexts: The Gantt chart completely describes the schedule since it defines both the processor assignment and the starting time for each task. The scheduling problem with nonzero communication delay has been shown to be NP-complete for a general task graph, by Chretienne [Ch89], Papadimitriou and Yannakakis <ref> [PY90] </ref>, and Sarkar [S89a]. 1 P Gantt chart n 1 n 3 n 2 n 5 1 2 3 4 5 6 7 Time (a) 2 2 n 1 n 8 n 7 n 5 (b) n 6 n 3 n 2 n 4 (c) Gantt chart of a schedule. 3
Reference: [MS90] <author> A. Munshi and B. Simons, </author> <title> Scheduling loops on processors: algorithms and complexity, </title> <journal> SIAM J. of Computing, </journal> <volume> Vol 19, </volume> <year> 1990, </year> <month> pp.728-741. </month>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> Optimal loop unrolling has also been studied by Parhi and Messerschmitt [PM91] and Chao and Sha [CS93]. Zaky and Sadayappan [ZS89] formulated the scheduling problem using a path algebra to find the optimal solutions. Munshi and Simons <ref> [MS90] </ref> examined the complexity of instruction scheduling and proposed heuristic solutions. Van Dongen, Gao and Ning [VGN92] proposed the scheduling solution on an unbounded number of processors. Gasperoni and Schweigelshoh [GS92] proposed scheduling algorithms for a bounded and unbounded number of processors.
Reference: [PM91] <author> K. K. Parhi and D. G. Messerschmitt, </author> <title> Static rate-optimal scheduling of iterative dataflow programs via optimum unfolding, </title> <journal> IEEE Trans. on Computers, </journal> <volume> 40:2, </volume> <year> 1991, </year> <pages> pp. 178-195. </pages>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> When a avg = 0, the bound is reduced to L crit M C fl B1 C = b N1 D C cB1 C which is a lower bound for any cyclic scheduling <ref> [REI68, LAM88, PM91] </ref>. 4 Scheduling on v processors We present a schedule for an ITG with precise dependence when the number of processors is v (equal to the number of tasks in the loop). We will provide an analysis of its asymptotic performance. <p> This is because processors that execute the tasks T x with a x = a max are overloaded. Loop unrolling is a loop transformation technique to increase the number of tasks within the loop body, which can lead to an optimal solution for software pipelining <ref> [AN88, PM91, CS93] </ref> when there is a sufficient number of processors. We examine how loop unrolling could improve the scheduling performance of ITG on message-passing architectures when a max &gt;> max (a avg ; Q (G)) and more processors are available. <p> The earliest work on software pipelining has been Reiter [REI68]. Lam [LAM88] developed pipelin ing algorithms for compiling on VLIW machines. Aiken and Nicolau [AN88] proposed an algorithm that unrolls a loop and finds an optimal schedule. Optimal loop unrolling has also been studied by Parhi and Messerschmitt <ref> [PM91] </ref> and Chao and Sha [CS93]. Zaky and Sadayappan [ZS89] formulated the scheduling problem using a path algebra to find the optimal solutions. Munshi and Simons [MS90] examined the complexity of instruction scheduling and proposed heuristic solutions.
Reference: [REI68] <author> R. Reiter, </author> <title> Scheduling parallel computations, </title> <journal> Journal of ACM, </journal> <month> Oct </month> <year> 1968, </year> <pages> pp. 590-599. </pages>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> When a avg = 0, the bound is reduced to L crit M C fl B1 C = b N1 D C cB1 C which is a lower bound for any cyclic scheduling <ref> [REI68, LAM88, PM91] </ref>. 4 Scheduling on v processors We present a schedule for an ITG with precise dependence when the number of processors is v (equal to the number of tasks in the loop). We will provide an analysis of its asymptotic performance. <p> Gerasoulis and Yang [GY93a] proposed a definition of granularity to analyze the impact of granularity on DAG scheduling. We use a similar definition to quantify the granularity of an ITG. The earliest work on software pipelining has been Reiter <ref> [REI68] </ref>. Lam [LAM88] developed pipelin ing algorithms for compiling on VLIW machines. Aiken and Nicolau [AN88] proposed an algorithm that unrolls a loop and finds an optimal schedule. Optimal loop unrolling has also been studied by Parhi and Messerschmitt [PM91] and Chao and Sha [CS93].
Reference: [S89a] <author> V. Sarkar, </author> <title> Partitioning and Scheduling Parallel Programs for Execution on Multiprocessors, </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction The problem of NP-hard scheduling has been addressed extensively in the literature. A basic representation of parallel computation is a directed acyclic graph (DAG) which represents the dependence between the instances of task computation. DAG scheduling has been used in compiling functional parallelism <ref> [PAM93, S89a, WF93] </ref>, and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. [EL90, GY93a, KB88, S89a, WG88, YG92]. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. <p> DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. <ref> [EL90, GY93a, KB88, S89a, WG88, YG92] </ref>. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. An iterative task graph (ITG) represents a sequence of parallel task computation. <p> We use the macro dataflow model for task computation <ref> [S89a] </ref>: the execution of task T x is triggered by the arrival of all data items that T x needs. At the completion of its execution the data are sent in parallel to successor tasks. <p> Kumar et.al. [K94] discussed formulas for communication delay in a store-forward or wormhole routing network. In this paper, we assume that the worst-case cost is used in estimating task communication delay. Sarkar <ref> [S89a] </ref> discussed methods for estimating communication and computation cost. Given a DAG, a schedule for this DAG is defined by a processor assignment mapping P A (T j ) and a starting time mapping ST (T j ) for all tasks T j . <p> The Gantt chart completely describes the schedule since it defines both the processor assignment and the starting time for each task. The scheduling problem with nonzero communication delay has been shown to be NP-complete for a general task graph, by Chretienne [Ch89], Papadimitriou and Yannakakis [PY90], and Sarkar <ref> [S89a] </ref>. 1 P Gantt chart n 1 n 3 n 2 n 5 1 2 3 4 5 6 7 Time (a) 2 2 n 1 n 8 n 7 n 5 (b) n 6 n 3 n 2 n 4 (c) Gantt chart of a schedule. 3 An iterative task <p> Exploring task parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis [EL90], Gerasoulis and Yang [GY93a, YG92], Kim and Browne [KB88], Sarkar <ref> [S89a] </ref>, Shirazi, Wang and Pathak [SWP90], Wolski and Feo [WF93], Wu and Gajski [WG88]. The common model is the macro-dataflow task computation model, the execution of task computation is triggered when the data items are available in the local memory.
Reference: [S89b] <author> V. Sarkar, </author> <title> Determining average program execution times and their variance, </title> <booktitle> Proc. of 1989 SIGPLAN, ACM, </booktitle> <pages> pp. 298-312. </pages>
Reference: [SWP90] <author> B. Shirazi, M Wang, G. Pathak, </author> <title> Analysis and evaluation of heuristic methods for static task scheduling. </title> <editor> J. </editor> <booktitle> of Parallel and Distributed Computing, </booktitle> <month> Nov. </month> <year> 1990, </year> <note> vol.10, (no.3), pp.222-232. </note>
Reference-contexts: Exploring task parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis [EL90], Gerasoulis and Yang [GY93a, YG92], Kim and Browne [KB88], Sarkar [S89a], Shirazi, Wang and Pathak <ref> [SWP90] </ref>, Wolski and Feo [WF93], Wu and Gajski [WG88]. The common model is the macro-dataflow task computation model, the execution of task computation is triggered when the data items are available in the local memory.
Reference: [VGN92] <author> V. H. Van Dongen, G. R. Gao and Q. </author> <title> Ning A polynomial time method for optimal software pipelining. </title> <booktitle> Proc. of CONPAR 92, </booktitle> <pages> pp. 613-624. </pages>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> Zaky and Sadayappan [ZS89] formulated the scheduling problem using a path algebra to find the optimal solutions. Munshi and Simons [MS90] examined the complexity of instruction scheduling and proposed heuristic solutions. Van Dongen, Gao and Ning <ref> [VGN92] </ref> proposed the scheduling solution on an unbounded number of processors. Gasperoni and Schweigelshoh [GS92] proposed scheduling algorithms for a bounded and unbounded number of processors. We extend the above work to consider the scheduling of coarse-grain task parallelism with nonzero communication.
Reference: [W89] <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers, </title> <publisher> MIT Press, </publisher> <address> Boston, </address> <year> 1989. </year>
Reference-contexts: Using DAG scheduling techniques to obtain a near-optimal mapping solu tion requires a searching of the entire iteration space, which may not be feasible when loop bounds are too large or unknown. Loop parallelism can be explored by various loop transformation methods <ref> [W89] </ref>. An estimation of parallel time or speedup can facilitate the selection and evaluation of transformation techniques. Notice that the parallel time of a transformed program depends on the number of processors and the weight of computation and communication delay. <p> Namely, task instance T k+d i;j j depends on T k i . Some dependence graphs may contain imprecise dependence direction information <ref> [W89] </ref> instead of precise distance values. If d i;j = 0 + 0 , there exists q (q 1) such that task instance T j depends on T k i . <p> For this case, it is not easy to summarize inter-iteration dependence accurately. In fact, current dependence analysis algorithms <ref> [W89] </ref> may overestimate dependence since accurate estimation may be intractable; however, overestimation does not affect the correctness of parallel execution. 4 For j = 0 to N 1 S j : Solve A j+1;j+1 X j+1 = B j+1 . for q= 1 to P q p e fl p +
Reference: [WF93] <author> R. Wolski and J. Feo, </author> <title> Program Partitoning for NUMA Multiprocessor Computer Systems, </title> <type> Tech. Report, </type> <institution> Lawrence Livermore Nat. Lab., </institution> <year> 1992. </year> <editor> J. </editor> <booktitle> of Parallel and Distributed Computing, </booktitle> <year> 1993. </year>
Reference-contexts: 1 Introduction The problem of NP-hard scheduling has been addressed extensively in the literature. A basic representation of parallel computation is a directed acyclic graph (DAG) which represents the dependence between the instances of task computation. DAG scheduling has been used in compiling functional parallelism <ref> [PAM93, S89a, WF93] </ref>, and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. [EL90, GY93a, KB88, S89a, WG88, YG92]. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. <p> Exploring task parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis [EL90], Gerasoulis and Yang [GY93a, YG92], Kim and Browne [KB88], Sarkar [S89a], Shirazi, Wang and Pathak [SWP90], Wolski and Feo <ref> [WF93] </ref>, Wu and Gajski [WG88]. The common model is the macro-dataflow task computation model, the execution of task computation is triggered when the data items are available in the local memory.
Reference: [WG88] <author> M. Y. Wu and D. Gajski, Hypertool: </author> <title> A programming aid for message-passing systems, </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 1, no. 3, pp.330-343, </volume> <year> 1990. </year>
Reference-contexts: A basic representation of parallel computation is a directed acyclic graph (DAG) which represents the dependence between the instances of task computation. DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools <ref> [EL90, WG88, YG92] </ref>. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. [EL90, GY93a, KB88, S89a, WG88, YG92]. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. <p> DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. <ref> [EL90, GY93a, KB88, S89a, WG88, YG92] </ref>. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. An iterative task graph (ITG) represents a sequence of parallel task computation. <p> parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis [EL90], Gerasoulis and Yang [GY93a, YG92], Kim and Browne [KB88], Sarkar [S89a], Shirazi, Wang and Pathak [SWP90], Wolski and Feo [WF93], Wu and Gajski <ref> [WG88] </ref>. The common model is the macro-dataflow task computation model, the execution of task computation is triggered when the data items are available in the local memory.
Reference: [ZS89] <author> A. Zaky and P. Sadayappan, </author> <title> Optimal static scheduling of sequential loops on multiprocessors. </title> <booktitle> Proc. of ICPP 1989, </booktitle> <volume> Vol 3, </volume> <pages> 130-137 </pages>
Reference-contexts: Mapping ITGs on message-passing architectures involves the examination of dependence cycles. Our work has also been motivated by the scheduling of fine grain instruction-level parallelism studied in the context of software pipelining <ref> [AN88, LAM88, MS90, GS92, PM91, REI68, VGN92, ZS89] </ref> in which computation between loop iterations are overlapped. For executing coarse-grain task parallelism on message-passing architectures, pipelined computation can achieve a good performance if computation and communication are properly orchestrated. <p> Lam [LAM88] developed pipelin ing algorithms for compiling on VLIW machines. Aiken and Nicolau [AN88] proposed an algorithm that unrolls a loop and finds an optimal schedule. Optimal loop unrolling has also been studied by Parhi and Messerschmitt [PM91] and Chao and Sha [CS93]. Zaky and Sadayappan <ref> [ZS89] </ref> formulated the scheduling problem using a path algebra to find the optimal solutions. Munshi and Simons [MS90] examined the complexity of instruction scheduling and proposed heuristic solutions. Van Dongen, Gao and Ning [VGN92] proposed the scheduling solution on an unbounded number of processors.
Reference: [YG91] <author> T. Yang and A. Gerasoulis, </author> <title> A fast static scheduling algorithm for DAGs on an unbounded number of processors, </title> <booktitle> Proc. of Supercomputing '91, IEEE, </booktitle> <pages> pp. 633-642. 22 </pages>
Reference: [YG92] <author> T. Yang and A. Gerasoulis, </author> <title> PYRROS: Static Task Scheduling and Code Generation for Message-Passing Multiprocessors, </title> <booktitle> Proc. of 6th ACM Inter. Confer. on Supercomputing, </booktitle> <address> Washington D.C., </address> <year> 1992, </year> <pages> pp. 428-437. </pages>
Reference-contexts: A basic representation of parallel computation is a directed acyclic graph (DAG) which represents the dependence between the instances of task computation. DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools <ref> [EL90, WG88, YG92] </ref>. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. [EL90, GY93a, KB88, S89a, WG88, YG92]. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. <p> DAG scheduling has been used in compiling functional parallelism [PAM93, S89a, WF93], and programming tools [EL90, WG88, YG92]. Many scheduling algorithms for weighted DAGs with the presence of communication have been proposed, e.g. <ref> [EL90, GY93a, KB88, S89a, WG88, YG92] </ref>. The main optimization is to minimize parallel time by balancing load, reducing communication overhead, and overlapping communication with computation. An iterative task graph (ITG) represents a sequence of parallel task computation. <p> The execution of each task follows data-driven computation model. As soon as the data needed by a task is available in the local memory, this task starts computation and then it sends the produced results to its successors assigned in different processors. Such a method has been used in <ref> [YG92] </ref>. We will compare the actual performance with the predicted result using the method of Sections 4 and 5. 6.1 Solving a triangular system In Fig.3, the weight of task S j is r 2 w where w is the time for addition or multiplication. <p> Exploring task parallelism through the asynchronous execution of task computation in message-passing machines has been studied in many DAG scheduling algorithms and systems, for example, El-Rewini and Lewis [EL90], Gerasoulis and Yang <ref> [GY93a, YG92] </ref>, Kim and Browne [KB88], Sarkar [S89a], Shirazi, Wang and Pathak [SWP90], Wolski and Feo [WF93], Wu and Gajski [WG88]. The common model is the macro-dataflow task computation model, the execution of task computation is triggered when the data items are available in the local memory. <p> The performance of such scheduling is affected by the graph granularity and weight variation between tasks in the course of iterations. The scheduling solution is simple since each processor executes instances of one task, it is relatively easy to be implemented using techniques for executing a DAG schedule in <ref> [YG92] </ref>. The analytic result could be used to evaluate the asymptotic performance of parallel execution.
References-found: 26

