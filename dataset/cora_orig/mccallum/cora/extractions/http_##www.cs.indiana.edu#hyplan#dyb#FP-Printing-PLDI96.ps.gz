URL: http://www.cs.indiana.edu/hyplan/dyb/FP-Printing-PLDI96.ps.gz
Refering-URL: http://www.cs.indiana.edu/~dyb/pubs.html
Root-URL: http://www.cs.indiana.edu
Email: fburger,dybg@cs.indiana.edu  
Phone: (812) 855-3608  
Title: Printing Floating-Point Numbers Quickly and Accurately  
Author: Robert G. Burger R. Kent Dybvig 
Keyword: floating-point printing, run-time systems  
Address: Lindley Hall 215 Bloomington, Indiana 47405  
Affiliation: Indiana University Computer Science Department  
Abstract: This paper presents a fast and accurate algorithm for printing floating-point numbers in both free- and fixed-format modes. In freeformat mode, the algorithm generates the shortest, correctly rounded output string that converts to the same number when read back in, accommodating whatever rounding mode the reader uses. In fixed-format mode, the algorithm generates a correctly rounded output string using special # marks to denote insignificant trailing digits. For both modes, the algorithm employs a fast estimator to scale floating-point numbers efficiently. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> William D. Clinger. </author> <title> How to read floating-point numbers accurately. </title> <booktitle> ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <volume> 25(6) </volume> <pages> 92-101, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The algorithm supports two types of output, free format and fixed format. For free-format output the goal is to produce the shortest, correctly rounded output string that converts to the same internal floating-point number when read by an accurate floating-point input routine <ref> [1] </ref>. For example, 3 10 would print as 0.3 instead of 0.2999999. The algorithm accommodates any input rounding mode, including IEEE unbiased rounding, for example. For fixed-format output the goal is to produce correctly rounded output to a given number of places without "garbage digits" beyond the point of significance.
Reference: [2] <author> David M. Gay. </author> <title> Correctly rounded binary-decimal and decimal-binary conversions. Numerical Analysis Manuscript 90-10, </title> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, New Jersey 07974, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: Their algorithm does not distinguish between significant and insignificant trailing zeros, nor does it take into account input rounding modes. In addition, their fixed-format algorithm introduced a slight inaccuracy in the computation of the rounding range. David Gay independently developed an estimator similar to ours <ref> [2] </ref>. It uses the first-degree Taylor series to estimate log 10 v. Although our estimator is less accurate than his, it is less expensive as well, requiring two rather than five floating-point operations.
Reference: [3] <institution> IEEE standard for binary floating-point arithmetic. ANSI/IEEE Std 754-1985, Institute of Electrical and Electronics Engineers, </institution> <address> New York, </address> <year> 1985. </year> <month> 8 </month>
Reference-contexts: Section 4 extends the algorithm to handle fixed format output and introduces # marks. Section 5 summarizes our results and discusses related work. 2 Basic Algorithm In describing the basic algorithm, we first explain how floating-point numbers are represented, using the IEEE double-precision floating-point specification as an example <ref> [3] </ref>. Second, we develop an output algorithm based on a key feature of the representation, the gaps between floating-point numbers. <p> If the input base is two, the mantissa of normalized, nonzero numbers always begins with a one. Consequently, this initial bit is often omitted from the representation and is called the hidden bit . These representations often reserve an exponent bit pattern to signal denormalized numbers. The IEEE specification <ref> [3] </ref> also provides representations for 0:0, positive infinity (+inf), negative infinity (inf), and "not a number" (NaN).
Reference: [4] <author> N. L. Schryer. </author> <title> A test of a computer's floating-point arith-metic unit. </title> <editor> In W. Cowell, editor, </editor> <booktitle> Sources and Development of Mathematical Software. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: This set was generated according to the forms Schryer developed for testing floating-point Scaling Algorithm Relative CPU Time Steele & White 70.0 floating-point log 1.03 log approximation 1.00 Table 2: Relative CPU times for three different scaling algorithms units <ref> [4] </ref>. <p> We have compared an implementation of our free-format algorithm for base-10 output against an implementation of a straightforward fixed-format algorithm on several different systems. For this test, we used a set of 250,680 positive normalized IEEE double-precision floating-point numbers <ref> [4] </ref>. The fixed-format algorithm printed them to 17 significant digits, the minimum number guaranteed to distinguish among IEEE double-precision numbers. In all cases the numbers were printed to /dev/null in order to factor out I/O performance.
Reference: [5] <author> Guy L. Steele Jr. and Jon L. White. </author> <title> How to print floating-point numbers accurately. </title> <booktitle> ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <volume> 25(6) </volume> <pages> 112-126, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: These marks are useful when printing denormalized numbers, which may have only a few digits of precision, or when printing to a large number of digits. Our algorithm is based on an elegant floating-point print ing algorithm developed by Steele and White <ref> [5] </ref>. Their al fl Supported in part by a National Science Foundation Graduate Research Fellowship To appear in Proceedings of the SIGPLAN '96 Conference on Programming Language Design and Implementation. <p> By accommodating unbiased rounding, the algorithm prints this number as 1e23 instead of 9.999999999999999e22. iterative algorithm (scale) similar to the one presented in <ref> [5] </ref> to find k. It assumes the input routine uses IEEE unbiased rounding. In the case of a tie in determining d n , it always rounds up by choosing d n + 1. <p> It modifies the original scale function to take additional arguments f and e, and it uses a table to look up the value of 1 log 2 B for Table 2 gives the relative CPU times for Steele and White's iterative scaling algorithm <ref> [5] </ref> and the floating-point logarithm scaling algorithm with respect to our simple estimate and scaling algorithm. The timings were performed using Chez Scheme on a DEC AXP 8420 running Digital UNIX V3.2C. <p> Our algorithm is based on Steele and White's conversion algorithm <ref> [5] </ref>. Ours is dramatically more efficient, primarily due to our use of a fast estimator for computing scaling factors. Their algorithm does not distinguish between significant and insignificant trailing zeros, nor does it take into account input rounding modes.
References-found: 5

