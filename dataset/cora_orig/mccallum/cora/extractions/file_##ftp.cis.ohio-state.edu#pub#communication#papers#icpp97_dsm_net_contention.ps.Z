URL: file://ftp.cis.ohio-state.edu/pub/communication/papers/icpp97_dsm_net_contention.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/wormhole_pub.html
Root-URL: 
Email: fdai,pandag@cis.ohio-state.edu  
Title: How Much Does Network Contention Affect Distributed Shared Memory Performance?  
Author: Donglai Dai and Dhabaleswar K. Panda 
Address: Columbus, OH 43210-1277  
Affiliation: Dept. of Computer and Information Science The Ohio State University,  
Date: Aug. 1997.  
Note: To be presented in International Conference on Parallel Processing (ICPP'97), Bloomingdale, IL,  
Abstract: Most of recent research on distributed shared memory (DSM) systems have focused on either careful design of node controllers or cache coherence protocols. While evaluating these designs, simplified models of networks (constant latency or average latency based on the network size) are typically used. Such models completely ignore network contention. To help network designers to design better networks for DSM systems, in this paper, we focus on two goals: 1) to isolate and quantify the impact of network link contention and network interface contention on the overall performance of DSM applications and 2) to study the impact of critical architectural parameters on these two categories of network contention. We achieve these goals by evaluating a set of SPLASH2 benchmarks on a DSM simulator using three network models. For an 8 fi 8 wormhole system, our results show that network contention can degrade performance up to 59.8%. Out of this, up to 7.2% is caused by network interface contention alone. The study indicates that network contention becomes dominant for DSM systems using small caches, wide cache line sizes, low degrees of associativity, high processing node speeds, high memory speeds, low network speeds, or small network link widths. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. C. Burger and D. A. Wood. </author> <title> Accuracy vs. Performance in Parallel Simulation of Interconnection Networks. </title> <booktitle> In IPPS'95, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: As mentioned before, these models do not provide useful insights into the effect of network contention on DSM system performance. A set of network simulation models for DSM systems have been proposed in <ref> [1] </ref> to show the tradeoff between accuracy and efficiency of network simulation. However, in this paper, our focus has been to isolate and quantify various types of network contention and study their impact on the overall DSM system performance under a set of design choices.
Reference: [2] <author> D. Dai and D. K. Panda. </author> <title> Reducing Cache Invalidation Overheads in Wormhole DSMs Using Multidestination Message Passing. </title> <booktitle> In ICPP'96, </booktitle> <pages> pp I:138145, </pages> <address> Chicago, IL, </address> <month> Aug </month> <year> 1996. </year>
Reference-contexts: Another research on reducing the invalidation overhead and traffic in DSMs using multidestination message passing mechanism has been presented in <ref> [2] </ref>. 7 Conclusion In this paper, we have studied the impact of network contention on the performance of four representative applications on a CC-NUMA DSM system.
Reference: [3] <author> D. Dai and D. K. Panda. </author> <title> How Can We Design Better Networks for DSM Systems? In PCRCW'97, </title> <address> Atlanta, GA, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Since network contention remains an important factor in designing DSM systems, in a separate paper, we have proposed a set of useful guidelines for designing better networks for DSM systems <ref> [3] </ref>. Another research on reducing the invalidation overhead and traffic in DSMs using multidestination message passing mechanism has been presented in [2]. 7 Conclusion In this paper, we have studied the impact of network contention on the performance of four representative applications on a CC-NUMA DSM system.
Reference: [4] <author> D. Dai and D. K. Panda. </author> <title> How Much Does Network Contention Affect Distributed Shared Memory Performance? Technical Report OSU-CISRC-2/97-TR14, </title> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: The node simulator models the internal structures, the queuing and contention at the node controller, main memory, and cache. The queues for network messages contain eight entries each. So does the incoming queue of the processor/cache. All other queues contain a single entry each <ref> [4] </ref>. Following the assumptions used in [10], the node controller incurs a small fixed occupancy for purely generating/receiving a message. The node controller at the home node of a remote request/response incurs a higher fixed occupancy, because data (in most cases) and directory information must be retrieved and manipulated. <p> Our experimental results show that as the memory bus becomes wider, the network contention barely changes in each application because of the availability of efficient memory pipelining. Due to lack of space, we are not able to include these results here. Interested readers are requested to refer <ref> [4] </ref> for more details. Overall, our study indicates that when the memory module becomes faster in a node, the network contention increases.
Reference: [5] <author> J. Kuskin et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In ISCA'94, </booktitle> <pages> pp 302313, </pages> <year> 1994. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models <ref> [5] </ref>, integrated or decoupled protocol controllers [5, 7, 12]. However, it has been reported [10] that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating several of the above techniques. <p> Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models [5], integrated or decoupled protocol controllers <ref> [5, 7, 12] </ref>. However, it has been reported [10] that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating several of the above techniques. <p> Any difference in the predicted performance between this model and the NIM model is caused by contention occurring inside network alone (excluding the network interfaces). 4 Simulation Environment To apply the above methodology for quantifying the network contention, we have simulated a DSM machine similar to the FLASH <ref> [5] </ref> but with some important differences described later. In this section, we describe the specific DSM implementation used for collecting the results under different network models. <p> The memory bus is 8 bytes wide. On a memory block access, the first word of the block is returned in 30 processor cycles (150 ns). The successive words in the block follow in a pipelined fashion. The machine uses a full-mapped, invalidation-based, three-state directory coherence protocol <ref> [5] </ref>. The node simulator models the internal structures, the queuing and contention at the node controller, main memory, and cache. The queues for network messages contain eight entries each. So does the incoming queue of the processor/cache. All other queues contain a single entry each [4]. <p> commonly used narrow links and slower networks in DSM systems, network contention remains an important factor for designing high-performance machines. 6 Related Work Two most popular network models in DSM research are the constant latency model and the average latency model, as used in the WWT [7] and the FLASH <ref> [5, 8] </ref> projects. As mentioned before, these models do not provide useful insights into the effect of network contention on DSM system performance. A set of network simulation models for DSM systems have been proposed in [1] to show the tradeoff between accuracy and efficiency of network simulation.
Reference: [6] <author> S. C. Woo et al. </author> <title> The SPLASH-2 Programs: Characterization and Methodological Considerations. </title> <booktitle> In ISCA'95, </booktitle> <pages> pp 2436, </pages> <year> 1995. </year>
Reference-contexts: Based on this methodology, we present a comprehensive and in-depth quantitative analysis on network contention using four SPLASH2 <ref> [6] </ref> benchmark applications. For an 8 fi 8 system, the results show that network contention can degrade overall performance of DSM applications by up to 59.8%. <p> This model guarantees the FIFO property of message delivery between each pair of nodes under the dimension order routing scheme. 4.3 Applications We used four SPLASH2 <ref> [6] </ref> benchmark programs presented in Table 2 to drive our simulation environment. These applications were compiled by dlxcc using the optimization level equivalent to O2 of gcc. We used the default mapping and scheduling policies built into these application codes. Table 2: Applications and default problem sizes. Appl. Comm.
Reference: [7] <author> S. K. Reinhardt et al. </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers. </title> <booktitle> In Sigmetrics'93, </booktitle> <pages> pp 4860, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models [5], integrated or decoupled protocol controllers <ref> [5, 7, 12] </ref>. However, it has been reported [10] that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating several of the above techniques. <p> This leaves simulation as the most plausible approach for quantifying contention. Due to the complexity of modeling a network, most research in DSMs has ignored network contention partially or entirely. In the WWT <ref> [7] </ref> and the Typhoon [12] simulators, a constant network latency of 100 processor cycles is assigned for every message independent of the length of the message, the distance traveled, and other traffic in the network. A DSM simulator used in the Stanford FLASH [8] research group models network interfaces. <p> Specifically, we construct a series of three network models as described below. The relations among these models are shown in Fig. 1 (b). No-Contention Network Model (NCM): This model is an enhancement of the network model used in the original WWT simulator <ref> [7] </ref>. It assumes: 1) infinite number of sending buffers, 2) infinite number of injection channels, 3) infinite number of consumption channels, 4) infinite number of receiving buffers, and 5) no traffic interference inside the network. These assumptions guarantee that no network contention can ever occur during any communication. <p> However, considering the commonly used narrow links and slower networks in DSM systems, network contention remains an important factor for designing high-performance machines. 6 Related Work Two most popular network models in DSM research are the constant latency model and the average latency model, as used in the WWT <ref> [7] </ref> and the FLASH [5, 8] projects. As mentioned before, these models do not provide useful insights into the effect of network contention on DSM system performance.
Reference: [8] <author> M. Heinrich et al. </author> <title> The performance impact of flexibility in the Stanford flash multiprocessor. </title> <booktitle> In ASPLOS-VI, </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: In the WWT [7] and the Typhoon [12] simulators, a constant network latency of 100 processor cycles is assigned for every message independent of the length of the message, the distance traveled, and other traffic in the network. A DSM simulator used in the Stanford FLASH <ref> [8] </ref> research group models network interfaces. The network latency of every message is calculated based on the length of the message and half of the diameter of the network. None of these DSM simulators has modeled the channel contention or physical link contention. <p> The network propagation time is a function of both the length and the distance traveled by the message. Interface Only Network Model (NIM): The NIM model is an enhancement of the network model used in the FLASH project <ref> [8] </ref>. The NIM model simulates detailed management of the limited number of sending buffers, receiving buffers, injection channels, and consumption channels. The NIM model still assumes no traffic interference inside the network. Such a model captures the types of contention occurring within a network interface. <p> commonly used narrow links and slower networks in DSM systems, network contention remains an important factor for designing high-performance machines. 6 Related Work Two most popular network models in DSM research are the constant latency model and the average latency model, as used in the WWT [7] and the FLASH <ref> [5, 8] </ref> projects. As mentioned before, these models do not provide useful insights into the effect of network contention on DSM system performance. A set of network simulation models for DSM systems have been proposed in [1] to show the tradeoff between accuracy and efficiency of network simulation.
Reference: [9] <author> J. L. Hennessy and D. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: The cache operates in dual-port mode using write-allocate write-back policies. The instruction latencies, issue rules, and memory interface are modeled based on the DLX design <ref> [9] </ref>. The memory bus is 8 bytes wide. On a memory block access, the first word of the block is returned in 30 processor cycles (150 ns). The successive words in the block follow in a pipelined fashion. The machine uses a full-mapped, invalidation-based, three-state directory coherence protocol [5].
Reference: [10] <author> C. Holt, J. P. Singh, and J. Hennessy. </author> <title> Application and Architectural Bottlenecks in Large Scale Distributed Shared Memory Machines. </title> <booktitle> In ISCA'96, </booktitle> <pages> pp 134145, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models [5], integrated or decoupled protocol controllers [5, 7, 12]. However, it has been reported <ref> [10] </ref> that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating several of the above techniques. <p> The queues for network messages contain eight entries each. So does the incoming queue of the processor/cache. All other queues contain a single entry each [4]. Following the assumptions used in <ref> [10] </ref>, the node controller incurs a small fixed occupancy for purely generating/receiving a message. The node controller at the home node of a remote request/response incurs a higher fixed occupancy, because data (in most cases) and directory information must be retrieved and manipulated.
Reference: [11] <author> L. Ni and P. K. McKinley. </author> <title> A Survey of Wormhole Routing Techniques in Direct Networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pp 6276, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: The former is largely defined by the state of technology in circuit speed and switch design. Contention delays are caused by limited resources related to the network. Current and next generation networks promise to exploit performance aggressively by using different kinds of adaptive routing <ref> [11] </ref> in addition to higher speed. The essence behind these communication innovations is to reduce network contention. However, several fundamental questions about the potential performance gain by employing advanced network communication mechanisms in DSM systems remain unanswered. <p> Sending buffer contention is said to occur when a message is blocked due to the lack of such space. Let us consider a wormhole-routed network <ref> [11] </ref>, as used in current generation CC-NUMA DSM systems like SGI Origin. Once a message has been generated, an injection channel must be obtained to copy the message flit by flit into the associated router. <p> Therefore, at most one outstanding request can be issued by a processor. 4.2 Implementing Network Models We assume the nodes in the machine are connected with a pair of virtual networks sharing a physical 2D 8fi8 wormhole network <ref> [11] </ref>. The physical network is assumed to operate at a frequency of 200 MHz. The rest of this section describes the implementation of each network model in detail. <p> Detailed Network Model (DNM): This model takes into account the internal structures such as data links, channel buffers, signal lines, etc., within and between the routers, in addition to the network interface. It accurately models the mechanisms for wormhole switching <ref> [11] </ref> such as: distributed routing, book-keeping on channel status, and flit-level asynchronous ready/empty handshaking.
Reference: [12] <author> S. K. Reinhardt, J. R. Larus, and D. A. Wood. Tempest and Typhoon: </author> <title> User-Level Shared Memory. </title> <booktitle> In ISCA'94, </booktitle> <pages> pp 325337, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models [5], integrated or decoupled protocol controllers <ref> [5, 7, 12] </ref>. However, it has been reported [10] that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating several of the above techniques. <p> This leaves simulation as the most plausible approach for quantifying contention. Due to the complexity of modeling a network, most research in DSMs has ignored network contention partially or entirely. In the WWT [7] and the Typhoon <ref> [12] </ref> simulators, a constant network latency of 100 processor cycles is assigned for every message independent of the length of the message, the distance traveled, and other traffic in the network. A DSM simulator used in the Stanford FLASH [8] research group models network interfaces.
References-found: 12

