URL: ftp://ftp.research.microsoft.com/pub/TR/TR-95-08.ps
Refering-URL: http://www.research.microsoft.com/~rusa/recent.html
Root-URL: http://www.research.microsoft.com
Title: Points-to analysis in almost linear time  
Author: Bjarne Steensgaard 
Address: One Microsoft Way Redmond, WA 98052  
Affiliation: Microsoft Research Advanced Technology Division Microsoft Corporation  
Date: March, 1995  
Abstract: Technical Report MSR-TR-95-08 
Abstract-found: 1
Intro-found: 1
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. Compilers|Principles, </author> <title> Techniques, and Tools. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Functions are constant values described by the fun (: : : )!(: : : ) expression form. The f variables are formal parameters (sometimes called in parameters), and the r variables are return values (sometimes called out parameters). Function calls have call-by-value semantics <ref> [ASU86] </ref>. Both formal and return parameter variables may be assigned to by the statements in the function body. the source language. We assume that programs are fairly well-behaved.
Reference: [CBC93] <author> Jong-Deok Choi, Michael Burke, and Paul Carini. </author> <title> Efficient flow-sensitive interprocedural computation of pointer-induced aliases and side effects. </title> <booktitle> In Proceedings of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 232-245. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Dependence and interference analyses are fundamental to optimizing compilers. Almost universally used analyses include alias analyses computing pairs of expressions that may be aliased (e.g., <ref> [LR92, LRZ93, CBC93] </ref>) and points-to analyses computing a store model of abstract locations (e.g., [CWZ90, EGH94]). The results of these analyses are used both for optimizing programs and for making program representations sparser in order to speed up other analyses. Existing interprocedural alias and points-to analyses are often slow.
Reference: [CCF94] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> On the efficient engineering of ambitious program analysis. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(2) </volume> <pages> 105-114, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: One sparse program representation is Static Single Assignment (SSA) form [CFR + 91] and its extensions, Factored SSA form (FSSA) form <ref> [CCF94] </ref> and Location Factoried SSA form [Ste95]. All three representations have dependence edges between use and def points (with nodes at control flow merge points). The use and def points are defined in terms of variables (or in terms of abstract locations for non-Fortran programs). <p> Where a points-to analysis build and maintains a model of the store during analysis, an alias analysis builds and maintains a list of access path expressions that may evaluate to the same location (in other words: they are aliased). The most relevant alias analysis algorithms are described in <ref> [CCF94] </ref> and [LR92, LRZ93]. The length of access-paths are k-limited, using a relatively simple truncation mechanism to eliminate extra path elements. Deutsch presents an alias analysis for an imperative subset of ML [Deu92].
Reference: [CFR + 91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The analysis results can be used for making program representations sparser, and possibly also to reduce the domain of abstract values propagated by data flow analyses (including a more precise alias or points-to analysis). One sparse program representation is Static Single Assignment (SSA) form <ref> [CFR + 91] </ref> and its extensions, Factored SSA form (FSSA) form [CCF94] and Location Factoried SSA form [Ste95]. All three representations have dependence edges between use and def points (with nodes at control flow merge points).
Reference: [CWZ90] <author> David R. Chase, Mark Wegman, and F. Kenneth Zadeck. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Dependence and interference analyses are fundamental to optimizing compilers. Almost universally used analyses include alias analyses computing pairs of expressions that may be aliased (e.g., [LR92, LRZ93, CBC93]) and points-to analyses computing a store model of abstract locations (e.g., <ref> [CWZ90, EGH94] </ref>). The results of these analyses are used both for optimizing programs and for making program representations sparser in order to speed up other analyses. Existing interprocedural alias and points-to analyses are often slow. We present a very fast algorithm that performs an interprocedural points-to analysis by type inference. <p> We present a very fast algorithm that performs an interprocedural points-to analysis by type inference. The types used in the algorithm represent sets of abstract locations. The types include relations between sets of abstract locations, in effect representing a model of the store (called a storage shape graph in <ref> [CWZ90] </ref>). The algorithm has time cost complexity of O (N ff (N; N )), where ff is a (very slowly increasing) inverse Ackermann's function [Tar83], and N is the size of the input program. The analysis is performed using the same unification techniques as Henglein's efficient type inference analysis [Hen91]. <p> In this paper, we will not try to distinguish between individual elements of aggregate objects. The types can be viewed as abstract locations. The set of types inferred for a program represents a store model <ref> [CWZ90] </ref> which is valid for all program points. The store model conservatively models all the points-to relations that may hold at runtime. Alias relations may be extracted from the store model [EGH94]. Our goal is a points-to analysis with an almost linear time cost complexity. <p> His algorithm has a time cost complexity that is cubic in the size of the source program, where our algorithm has an almost linear time cost complexity. More precise points-to analysis exist, e.g., <ref> [CWZ90] </ref> and [EGH94]. [CWZ90] is primarily concerned with heap allocated structures, whereas [EGH94] is concerned with stack allocated structures. Both algorithms are flow sensitive data flow analyses. [CWZ90] has polynomial time cost complexity. [EGH94] has polynomial complexity in the size of an unfolded call graph, but exponential complexity in the size <p> His algorithm has a time cost complexity that is cubic in the size of the source program, where our algorithm has an almost linear time cost complexity. More precise points-to analysis exist, e.g., <ref> [CWZ90] </ref> and [EGH94]. [CWZ90] is primarily concerned with heap allocated structures, whereas [EGH94] is concerned with stack allocated structures. Both algorithms are flow sensitive data flow analyses. [CWZ90] has polynomial time cost complexity. [EGH94] has polynomial complexity in the size of an unfolded call graph, but exponential complexity in the size of the program. <p> More precise points-to analysis exist, e.g., <ref> [CWZ90] </ref> and [EGH94]. [CWZ90] is primarily concerned with heap allocated structures, whereas [EGH94] is concerned with stack allocated structures. Both algorithms are flow sensitive data flow analyses. [CWZ90] has polynomial time cost complexity. [EGH94] has polynomial complexity in the size of an unfolded call graph, but exponential complexity in the size of the program. Another type of dependence analysis is alias analysis.
Reference: [Deu92] <author> Alain Deutsch. </author> <title> A storeless model of aliasing and its abstractions using finite representations of right-regular equivalence relations. </title> <booktitle> In International Conference on Computer Languages, </booktitle> <pages> pages 2-13. </pages> <publisher> IEEE, </publisher> <month> April </month> <year> 1992. </year>
Reference-contexts: The most relevant alias analysis algorithms are described in [CCF94] and [LR92, LRZ93]. The length of access-paths are k-limited, using a relatively simple truncation mechanism to eliminate extra path elements. Deutsch presents an alias analysis for an imperative subset of ML <ref> [Deu92] </ref>. Access paths are defined in terms of monomial relations (a kind of polynomial with structure accessors as the variables). The analysis is therefore only relevant for strongly typed languages like ML and strongly typable programs written in weakly typed languages like C (as shown in [Deu94]).
Reference: [Deu94] <author> Alian Deutsch. </author> <title> Interprocedural may-alias analysis for pointers: Beyond k-limiting. </title> <booktitle> In SIG-PLAN'94: Conference on Programming Language Design and Implementation, (PLDI), </booktitle> <pages> pages 230-241, </pages> <address> Orlando, FL, </address> <month> June 20-24 </month> <year> 1994. </year> <note> Proceedings also appear as SIGPLAN Notices 29(6), </note> <year> 1994. </year>
Reference-contexts: Access paths are defined in terms of monomial relations (a kind of polynomial with structure accessors as the variables). The analysis is therefore only relevant for strongly typed languages like ML and strongly typable programs written in weakly typed languages like C (as shown in <ref> [Deu94] </ref>). Access paths are combined by unification. A higher order points-to analysis by type inference has been developed by Tofte and Talpin for the purposes of creating an ML interpreter without a garbage collector [TT94]. The analysis is based on type inference over a polymorphic domain of types.
Reference: [EGH94] <author> Maryam Emami, Rakesh Ghiya, and Laurie J. Hendren. </author> <title> Context-sensitive interprocedural points-to analysis in the presence of function pointers. </title> <booktitle> In SIGPLAN'94: Conference on Programming Language Design and Implementation, (PLDI), </booktitle> <pages> pages 242-256, </pages> <address> Orlando, FL, </address> <month> June 20-24 </month> <year> 1994. </year> <note> Proceedings also appear as SIGPLAN Notices 29(6), </note> <year> 1994. </year>
Reference-contexts: 1 Introduction Dependence and interference analyses are fundamental to optimizing compilers. Almost universally used analyses include alias analyses computing pairs of expressions that may be aliased (e.g., [LR92, LRZ93, CBC93]) and points-to analyses computing a store model of abstract locations (e.g., <ref> [CWZ90, EGH94] </ref>). The results of these analyses are used both for optimizing programs and for making program representations sparser in order to speed up other analyses. Existing interprocedural alias and points-to analyses are often slow. We present a very fast algorithm that performs an interprocedural points-to analysis by type inference. <p> The set of types inferred for a program represents a store model [CWZ90] which is valid for all program points. The store model conservatively models all the points-to relations that may hold at runtime. Alias relations may be extracted from the store model <ref> [EGH94] </ref>. Our goal is a points-to analysis with an almost linear time cost complexity. The size of the store model for a program represented by the types must therefore be linear in the size of the input program. <p> Using type FSSA form, data flow analyses may reduce the size of the domains of abstract values propagated by data flow analyses. An example of such an analysis is Emami, Ghiya, and Hendren's points-to analysis <ref> [EGH94] </ref>. Their algorithm uses a square bit matrix whose dimensions are given by the number of variables in the source program. A set bit in the matrix means that the location/variable corresponding to one coordinate may point to the location/variable corresponding to the other coordinate. <p> His algorithm has a time cost complexity that is cubic in the size of the source program, where our algorithm has an almost linear time cost complexity. More precise points-to analysis exist, e.g., [CWZ90] and <ref> [EGH94] </ref>. [CWZ90] is primarily concerned with heap allocated structures, whereas [EGH94] is concerned with stack allocated structures. Both algorithms are flow sensitive data flow analyses. [CWZ90] has polynomial time cost complexity. [EGH94] has polynomial complexity in the size of an unfolded call graph, but exponential complexity in the size of the <p> His algorithm has a time cost complexity that is cubic in the size of the source program, where our algorithm has an almost linear time cost complexity. More precise points-to analysis exist, e.g., [CWZ90] and <ref> [EGH94] </ref>. [CWZ90] is primarily concerned with heap allocated structures, whereas [EGH94] is concerned with stack allocated structures. Both algorithms are flow sensitive data flow analyses. [CWZ90] has polynomial time cost complexity. [EGH94] has polynomial complexity in the size of an unfolded call graph, but exponential complexity in the size of the program. Another type of dependence analysis is alias analysis. <p> More precise points-to analysis exist, e.g., [CWZ90] and <ref> [EGH94] </ref>. [CWZ90] is primarily concerned with heap allocated structures, whereas [EGH94] is concerned with stack allocated structures. Both algorithms are flow sensitive data flow analyses. [CWZ90] has polynomial time cost complexity. [EGH94] has polynomial complexity in the size of an unfolded call graph, but exponential complexity in the size of the program. Another type of dependence analysis is alias analysis.
Reference: [Hen91] <author> Fritz Henglein. </author> <title> Efficient type inference for higher-order binding-time analysis. </title> <booktitle> In Functional Programming and Computer Architecture, </booktitle> <pages> pages 448-472, </pages> <year> 1991. </year>
Reference-contexts: The algorithm has time cost complexity of O (N ff (N; N )), where ff is a (very slowly increasing) inverse Ackermann's function [Tar83], and N is the size of the input program. The analysis is performed using the same unification techniques as Henglein's efficient type inference analysis <ref> [Hen91] </ref>. It is realistic to assume similar analysis performance in terms of speed, which has been reported to be between 1000 and 10000 lines/second. <p> major technical contributions of this paper include identifying a a domain of types for describing store models that are linear in the size of the source program and showing how type inference over this domain of types can be performed in almost linear time using techniques similar to those of <ref> [Hen91] </ref>. We have used type inference to solve a very practical problem, namely that of performing a points-to analysis. The focus of this paper is therefore more on the practical aspects than on the type theoretical aspects of the algorithm. In Section 2, we present our source language. <p> In addition, instead of propagating the large matrix from statement to statement, the smaller matrices can be propagated along the dependence edges of the type FSSA form, thereby skipping irrelevant statements. 6 Related work Henglein used type inference to perform a binding time analysis in almost linear time <ref> [Hen91] </ref>. He takes a slightly more formal approach than we have done for the points-to analysis. His presentation of the algorithm in terms of constraint systems may be more familiar to people working with type theory. The points-to analysis that closest resembles our analysis is Weihl's [Wei80].
Reference: [Kah87] <author> G. Kahn. </author> <title> Natural semantics. </title> <editor> In F.J. Brandenburg, G. Vidal-Naquet, and M. Wirsing, editors, </editor> <booktitle> STACS 87. 4th Annual Symposium on Theoretical Aspects of Computer Science, Passau, Germany (Lecture Notes in Computer Science, </booktitle> <volume> vol. 247), </volume> <pages> pages 22-39. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference: [KR88] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice Hall, </publisher> <address> second edition, </address> <year> 1988. </year> <month> 11 </month>
Reference-contexts: Since the analysis is flow insensitive, the control structures of the language are irrelevant. The abstract syntax of the relevant statements of the language are shown in Figure 1. The syntax for computing the addresses of variables and for pointer indirection is borrowed from the C programming language <ref> [KR88] </ref>. All variables are assumed to have unique names. The op (: : : ) expression form is used to describe primitive computations like arithmetic operations and computing offsets into aggregate objects. The allocate (y) expression dynamically allocates a block of memory of size y.
Reference: [LR92] <author> William Landi and Barbara G. Ryder. </author> <title> A safe approximate algorithm for interprocedural pointer aliasing. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 235-248. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Dependence and interference analyses are fundamental to optimizing compilers. Almost universally used analyses include alias analyses computing pairs of expressions that may be aliased (e.g., <ref> [LR92, LRZ93, CBC93] </ref>) and points-to analyses computing a store model of abstract locations (e.g., [CWZ90, EGH94]). The results of these analyses are used both for optimizing programs and for making program representations sparser in order to speed up other analyses. Existing interprocedural alias and points-to analyses are often slow. <p> The most relevant alias analysis algorithms are described in [CCF94] and <ref> [LR92, LRZ93] </ref>. The length of access-paths are k-limited, using a relatively simple truncation mechanism to eliminate extra path elements. Deutsch presents an alias analysis for an imperative subset of ML [Deu92]. Access paths are defined in terms of monomial relations (a kind of polynomial with structure accessors as the variables).
Reference: [LRZ93] <author> William A. Landi, Barbara G. Ryder, and Sean Zhang. </author> <title> Interprocedural modification side effect analysis with pointer aliasing. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 56-67. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Dependence and interference analyses are fundamental to optimizing compilers. Almost universally used analyses include alias analyses computing pairs of expressions that may be aliased (e.g., <ref> [LR92, LRZ93, CBC93] </ref>) and points-to analyses computing a store model of abstract locations (e.g., [CWZ90, EGH94]). The results of these analyses are used both for optimizing programs and for making program representations sparser in order to speed up other analyses. Existing interprocedural alias and points-to analyses are often slow. <p> The most relevant alias analysis algorithms are described in [CCF94] and <ref> [LR92, LRZ93] </ref>. The length of access-paths are k-limited, using a relatively simple truncation mechanism to eliminate extra path elements. Deutsch presents an alias analysis for an imperative subset of ML [Deu92]. Access paths are defined in terms of monomial relations (a kind of polynomial with structure accessors as the variables).
Reference: [Ruf95] <author> Erik Ruf. </author> <title> Context-insensitive alias analysis reconsidered. </title> <note> To appear in PLDI'95, </note> <month> June </month> <year> 1995. </year>
Reference-contexts: A restricted (k-limited) degree of polymorphism may also be achieved without sacrificing the time cost complexity of the algorithm. This may prove advantageous, as many functions in real-life programs only perform limited manipulation of locations accessible through argument pointers (although <ref> [Ruf95] </ref> suggests that the advantage may not be very substantial). In the presented type system, the types are monomorphic. The type system may be generalized to an ML-style polymorphic system.
Reference: [Ste95] <author> Bjarne Steensgaard. </author> <title> Sparse functional stores for imperative programs. </title> <booktitle> In ACM SIGPLAN Workshop on Intermediate Representations (IR'95), </booktitle> <pages> pages 62-70, </pages> <address> San Francisco, CA, </address> <month> January 22 </month> <year> 1995. </year> <note> Proceedings to appear as an issue of SIGPLAN Notices. </note>
Reference-contexts: One sparse program representation is Static Single Assignment (SSA) form [CFR + 91] and its extensions, Factored SSA form (FSSA) form [CCF94] and Location Factoried SSA form <ref> [Ste95] </ref>. All three representations have dependence edges between use and def points (with nodes at control flow merge points). The use and def points are defined in terms of variables (or in terms of abstract locations for non-Fortran programs).
Reference: [Tar83] <author> Robert E. Tarjan. </author> <title> Data structures and network flow algorithms. </title> <booktitle> In Regional Conference Series in Applied Mathematics, volume CMBS 44 of Regional Conference Series in Applied Mathematics. </booktitle> <publisher> SIAM, </publisher> <year> 1983. </year>
Reference-contexts: The types include relations between sets of abstract locations, in effect representing a model of the store (called a storage shape graph in [CWZ90]). The algorithm has time cost complexity of O (N ff (N; N )), where ff is a (very slowly increasing) inverse Ackermann's function <ref> [Tar83] </ref>, and N is the size of the input program. The analysis is performed using the same unification techniques as Henglein's efficient type inference analysis [Hen91]. It is realistic to assume similar analysis performance in terms of speed, which has been reported to be between 1000 and 10000 lines/second. <p> The use of fast union/find data structures means that checking for equality of two ECRs has a cost that on average is ff (N; N ), where ff is a (very slowly increasing) inverse of Ackermann's function <ref> [Tar83] </ref>, and N is the size of the source program. Adding the various costs, the worst case time cost complexity of the type inference phase of the algorithm is O (N ff (N; N )). Replacing the ECRs with ordinary type variables after the type inference phase is straightforward.
Reference: [TT94] <author> Mads Tofte and Jean-Pierre Talpin. </author> <title> Implementation of the typed call-by-value -calculus using a stack of regions. </title> <booktitle> In Proceedings 21st SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 188-201, </pages> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: Access paths are combined by unification. A higher order points-to analysis by type inference has been developed by Tofte and Talpin for the purposes of creating an ML interpreter without a garbage collector <ref> [TT94] </ref>. The analysis is based on type inference over a polymorphic domain of types. Variables are allocated from (written to) regions that are passed as extra parameters. Their algorithm does not deal with objects that may be updated after being assigned an initial value (as is normal for imperative programs).
Reference: [WCES94a] <author> Daniel Weise, Roger F. Crew, Michael Ernst, and Bjarne Steensgaard. </author> <title> Value dependence graphs: Representation without taxation. </title> <booktitle> In Proceedings 21st SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 297-310, </pages> <address> Portland, OR, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: We have outlined how the analysis results can be used to make program representations sparser and to reduce the size of abstract domains used for data flow analyses. The presented algorithm has been implemented in the context of the VDG compiler environment at Microsoft Research <ref> [WCES94a, WCES94b] </ref>. Preliminary results show that each type variable on average only describes a small number of abstract locations 1 . Preliminary measurements indicate that the average number of abstract locations described by a single type variable is between 3 and 4.
Reference: [WCES94b] <author> Daniel Weise, Roger F. Crew, Michael Ernst, and Bjarne Steensgaard. </author> <title> Value dependence graphs: Representation without taxation. </title> <type> Technical Report MSR-TR-94-03, </type> <institution> Microsoft Research, Red-mond, WA, </institution> <month> April 13, </month> <year> 1994. </year>
Reference-contexts: We have outlined how the analysis results can be used to make program representations sparser and to reduce the size of abstract domains used for data flow analyses. The presented algorithm has been implemented in the context of the VDG compiler environment at Microsoft Research <ref> [WCES94a, WCES94b] </ref>. Preliminary results show that each type variable on average only describes a small number of abstract locations 1 . Preliminary measurements indicate that the average number of abstract locations described by a single type variable is between 3 and 4.
Reference: [Wei80] <author> William E. Weihl. </author> <title> Interprocedural data flow analysis in the presence of pointers, procedure variables, and label variables. </title> <booktitle> In Conference Record of the Seventh Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 83-94, </pages> <month> January </month> <year> 1980. </year> <month> 12 </month>
Reference-contexts: He takes a slightly more formal approach than we have done for the points-to analysis. His presentation of the algorithm in terms of constraint systems may be more familiar to people working with type theory. The points-to analysis that closest resembles our analysis is Weihl's <ref> [Wei80] </ref>. His analysis is also flow insensitive and deals with pointers to functions. His algorithm does not assume that alias relations are 9 transitive and will therefore in many cases produce better results than our algorithm will.
References-found: 20

