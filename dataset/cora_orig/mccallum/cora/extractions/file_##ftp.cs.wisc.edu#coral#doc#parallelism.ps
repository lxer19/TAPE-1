URL: file://ftp.cs.wisc.edu/coral/doc/parallelism.ps
Refering-URL: http://www.cs.wisc.edu/coral/coral.papers.html
Root-URL: 
Title: Parallelism in Logic Programs  
Author: Raghu Ramakrishnan 
Address: WI 53706, U.S.A.  
Affiliation: Computer Sciences Department University of Wisconsin-Madison,  
Abstract: There is a tension between the objectives of avoiding irrelevant computation and extracting parallelism, in that a computational step used to restrict another must precede the latter. Our thesis, following [BeR87], is that evaluation methods can be viewed as implementing a choice of sideways information propagation graphs, or sips, which determines the set of goals and facts that must be evaluated. Two evaluation methods that implement the same sips can then be compared to see which obtains a greater degree of parallelism, and we provide a formal measure of parallelism to make this comparison. Using this measure, we prove that transforming a program using the Magic Templates algorithm and then evaluating the fixpoint bottom-up provides a "most parallel" implementation for a given choice of sips, without taking resource constraints into account. This result, taken in conjunction with earlier results from [BeR87, Ra88], which show that bottom-up evaluation performs no irrelevant computation and is sound and complete, suggests that a bottom-up approach to parallel evaluation of logic programs is very promising. A more careful analysis of the relative overheads in the top-down and bottom-up evaluation paradigms is needed, however, and we discuss some of the issues. The abstract model allows us to establish several results comparing other proposed parallel evaluation methods in the logic programming and deductive database literature, thereby showing some natural, and sometimes surprising, connections. We consider the limitations of the abstract model and of the proposed bottom-up evaluation method, including the inability of sips to describe certain evaluation methods, and the effect of resource constraints. Our results shed light on the limits of the sip paradigm of computation, which we extend in the process. 
Abstract-found: 1
Intro-found: 1
Reference: [BMSU86] <author> F. Bancilhon, D. Maier, Y. Sagiv and J.D. Ullman, </author> <title> Magic Sets and Other Strange Ways to Implement Logic Programs. </title> <booktitle> In Proc. ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 1-15, </pages> <address> Boston, Massachusetts, </address> <month> March </month> <year> 1986. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc. <p> Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue <ref> [BMSU86, RLK86, BeR87, Ra88, Se89] </ref>.
Reference: [BaR86] <author> F. Bancilhon and R. Ramakrishnan, </author> <title> An Amateur's Introduction to Recursive Query Processing Strategies. </title> <booktitle> In Proc. ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 16-53, </pages> <address> Wash-ington, D.C., </address> <year> 1986. </year> <note> Revised and reprinted in Readings in AI and Databases, </note> <editor> Eds. M. Brodie and J. </editor> <booktitle> Mylopoulos, </booktitle> <pages> pages 376-430, </pages> <year> 1988. </year>
Reference-contexts: We refer the reader to surveys and expositions presented in <ref> [BaR86, Br89, NR89, Ul89a] </ref>. We note that while most of this literature deals with the implementation of Datalog, which is a subset of logic programs without function symbols, and also does not deal with non-ground terms, recent proposals treat full logic programs [Ra88, Se89].
Reference: [BeR87] <author> C. Beeri and R. Ramakrishnan, </author> <title> On the Power of Magic. </title> <booktitle> In Proc. ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 269-283, </pages> <address> San Diego, California, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc. <p> Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue <ref> [BMSU86, RLK86, BeR87, Ra88, Se89] </ref>. <p> may be restricted using only a subset of the bindings made by its predecessors in the sip. (This may be motivated by the overhead of propagating the bindings in some evaluation schemes.) We do not consider such refinements of sips in this paper, and instead we refer the reader to <ref> [BeR87, Ra88] </ref>. Further, it is possible to choose a different sip for the same rule when it is invoked using different goals. For example, we may wish to solve it left-to-right when the first argument of the goal is bound to a ground term, and right-to-left otherwise. <p> The supplementary version of the rewriting algorithm essentially identifies these common sub-expressions and stores them (with some optimizations that allow us to delete some columns from these intermediate, or supplementary, relations). We refer the reader to <ref> [BeR87] </ref> for details, with the remark that the variant is similar to the basic Magic Templates algorithm with respect to parallelism. 5.2 Seminaive Iteration We describe Seminaive iterative fixpoint evaluation, which is a refinement of ordinary bottom-up fixpoint evaluation.
Reference: [Br89] <author> F. Bry, </author> <title> Query Evaluation in Recursive Databases: Bottom-up and Top-Down Reconciled. </title> <type> ECRC TR IR-KB-64, </type> <month> April </month> <year> 1989. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc. <p> We refer the reader to surveys and expositions presented in <ref> [BaR86, Br89, NR89, Ul89a] </ref>. We note that while most of this literature deals with the implementation of Datalog, which is a subset of logic programs without function symbols, and also does not deal with non-ground terms, recent proposals treat full logic programs [Ra88, Se89].
Reference: [CDD85] <author> J.-H. Chang, A.M. Despain and D. </author> <title> DeGroot, AND-Parallelism of Logic Programs Based on A Static Data Dependency Analysis. </title> <booktitle> In Digest of Papers, Compcon 85, IEEE Computer Society, </booktitle> <month> Feb. </month> <year> 1985. </year>
Reference-contexts: Since a variable that is shared between the corresponding literals could be bound to a ground term by a preceding Or-node, detecting such opportunities for solving the children of an And-node in parallel is a difficult problem. Several researchers have addressed this issue, e.g., <ref> [De84, CDD85] </ref>. <p> property that every variable instance in the computation has a unique binding at any time. (With Or-parallelism, recall that an Or-node saves multiple answers; these provide multiple bindings for the variables that appear in it.) This typically results in the loss of much parallelism, but reduces implementation overhead (see e.g., <ref> [De84, CDD85, HR89] </ref>). 3.2 Full Or-Parallelism Full Or-parallelism is best understood in terms of SLD-trees. The SLD-tree for a logic program has the query as the root node. Every node in the tree is a conjunction of goals.
Reference: [CH83] <author> A. Ciepielewski and S. Haridi, </author> <title> A Formal Model for Or-Parallel Execution of Logic Programs. </title> <booktitle> In Information Processing 83, </booktitle> <pages> pages 299-305, </pages> <publisher> North-Holland, </publisher> <month> Sept. </month> <year> 1983. </year>
Reference-contexts: The leaves are empty nodes. The conjunction of substitutions along a path from the root to a leaf, applied to the query, yields an answer. With full Or-parallelism, each branch is explored in parallel, as initially proposed in <ref> [CH83] </ref>. <p> This results in a goal, generated from the i + 1st literal, and one child Or-node is created with this label. The arc from the And-node to this Or-node is labeled with the substitution . This is indeed how the Or-parallel model proposed in <ref> [CH83] </ref> is implemented, as described in [CH84]. In essence, rules are solved left to right, and for each goal, all rules with which it unifies are solved in parallel. <p> We do not see this in the above sequence since its only effect in our model is to affect the hidden state; the set of known facts and goals is unaffected by the re-derivation of a previously known goal. Ciepielewski-Haridi This is a fully Or-parallel method proposed in <ref> [CH83] </ref>.
Reference: [CH84] <editor> A. Ciepielewski and S. Haridi, </editor> <booktitle> Control of Activities in the Or-Parallel Token Machine In Proc. IEEE Symposium on Logic Programming, </booktitle> <address> Atlantic City, </address> <month> Feb. </month> <year> 1984. </year>
Reference-contexts: The arc from the And-node to this Or-node is labeled with the substitution . This is indeed how the Or-parallel model proposed in [CH83] is implemented, as described in <ref> [CH84] </ref>. In essence, rules are solved left to right, and for each goal, all rules with which it unifies are solved in parallel. <p> A token contains enough information to generate tokens for all its successors. (In particular, this includes information about the label of the parent And-node; this is achieved by means of a "continuation", and we refer the reader to <ref> [CH84] </ref> for details.) Note that there is no And-parallelism; a rule is always solved from left to right. <p> Top-down evaluation uses a recursive control strategy. A sequential implementation such as Prolog uses stacks to manage goals. Parallel methods generate a new process each goal, which carries a significant overhead on most systems. (Token based methods, e.g. <ref> [CH84] </ref>, have their own additional overheads such as managing shared environments.) Bottom-up methods do not create a process per goal, but they recover the connections between facts and goals by explicit additional joins.
Reference: [CG86] <author> K.L. Clark and S. Gregory, </author> <title> Parlog: </title> <booktitle> Parallel Programming in Logic. In Transactions on Programming Languages, </booktitle> <pages> pages 1-49, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: All subgoals of these goals must respect the above order. The sip formalism does not allow us to consider the resolvent that is the set of all subgoals and then pick an arbitrary order. This is precisely what committed choice languages such as Parlog <ref> [CG86] </ref> and Concurrent Prolog [Sh86], the f reeze primitive in Nu-Prolog [Na87], and some other proposed methods, e.g. in [Co83], achieve by dynamically suspending and starting goals. <p> The ordering is controlled typically by variable annotations that, for example, suspend a goal until one of its variables is instantiated <ref> [CG86, Sh86, Na87] </ref>; it can also be controlled by a sophisticated run-time scheduler [Co83]. Methods that use annotations typically sacrifice completeness. Completely unrestricted dynamic re-ordering carries a high run-time overhead. Nevertheless, there may be situations where such approaches perform better than any sip-method.
Reference: [CW89] <author> S.R. Cohen and O. Wolfson, </author> <title> Why a Single Parallelization Strategy is Not Enough in Knowledge Bases. </title> <booktitle> In Proc. ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 200-216, </pages> <address> Philadelphia, Penn-sylvania, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: Indeed, it has been remarked that the work on parallel evaluation in the logic programming community, typically top-down methods, are not likely to be useful in the context of bottom-up parallel evaluation <ref> [CW89] </ref>. We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. <p> While considering this work is beyond the scope of this paper, we remark that the interactions of the techniques used in this work and the Magic Templates algorithm remain little understood and suggest an area for further study. We direct the interested reader to <ref> [WS88, CW89, Do89, GST89] </ref>. 8.3 Some Added Advantages of Memoing The remarks in this subsection apply equally to top-down and bottom-up methods that do memoing. As we have already seen, memoing offers gains in terms of avoiding redundant computation and increased parallelism. It also offers other important advantages: 1.
Reference: [Co83] <author> J. Conery, </author> <title> The And-Or Process Model for Parallel Interpretation of Logic Programs. </title> <type> Ph.D. thesis, TR 204, </type> <institution> Univ. of California, Irvine, </institution> <month> June </month> <year> 1983. </year>
Reference-contexts: The unifying substitution is used to label the arc from the parent Or-node to this And-node. An And-node has at most one child Or-node per body literal in its label. The label of a child Or-node is a variant of the corresponding body literal. The And-Or model presented in <ref> [Co83] </ref> builds And-Or trees by generating a process for each node in a top-down order. The query is the root node. The children of an Or-node are generated as described above. <p> intelligent ways to backtrack past predecessor nodes when a node fails (i.e., to recognize that alternative solutions to these predecessors would not enable the given node to succeed, and thus avoid generating further so lutions to them.) Conery also suggested schemes for dynamically re-ordering the nodes in the And-Or tree <ref> [Co83] </ref>; these cannot always be described as sip-methods, and this is discussed further in Section 7. An important restriction of the And-Or model is to simply avoid Or-parallelism by generating the children And-nodes of an Or-node one at a time. <p> )?g ` [fb1 (5); b2 (6)g ` [fb3 (5; 6; Z)?g ` [ fp (5; 9)g ` [fb4 (X; Y )?g ` [fb4 (1; 2)g ` [fp (1; 2)g Conery This is a method that attempts to realize both And- and Or-parallelism, and is one of the methods proposed in <ref> [Co83] </ref>. fp (U; V )?g ` [fb1 (X)?; b2 (Y )?g ` [fb1 (5); b2 (6); b2 (7)g ` [fb3 (5; 6; Z)?g ` [fb4 (X; Y )?g ` [fb4 (1; 2)g ` [fp (1; 2)g Notice that in this method, the two b3 goals are sequentialized. <p> This is precisely what committed choice languages such as Parlog [CG86] and Concurrent Prolog [Sh86], the f reeze primitive in Nu-Prolog [Na87], and some other proposed methods, e.g. in <ref> [Co83] </ref>, achieve by dynamically suspending and starting goals. The ordering is controlled typically by variable annotations that, for example, suspend a goal until one of its variables is instantiated [CG86, Sh86, Na87]; it can also be controlled by a sophisticated run-time scheduler [Co83]. Methods that use annotations typically sacrifice completeness. <p> [Na87], and some other proposed methods, e.g. in <ref> [Co83] </ref>, achieve by dynamically suspending and starting goals. The ordering is controlled typically by variable annotations that, for example, suspend a goal until one of its variables is instantiated [CG86, Sh86, Na87]; it can also be controlled by a sophisticated run-time scheduler [Co83]. Methods that use annotations typically sacrifice completeness. Completely unrestricted dynamic re-ordering carries a high run-time overhead. Nevertheless, there may be situations where such approaches perform better than any sip-method.
Reference: [De84] <author> D. </author> <title> DeGroot, Restricted And-Parallelism. </title> <booktitle> In Proc. Intl. Conf. on Generation Computer Systems, </booktitle> <publisher> ICOT, </publisher> <year> 1984. </year>
Reference-contexts: Since a variable that is shared between the corresponding literals could be bound to a ground term by a preceding Or-node, detecting such opportunities for solving the children of an And-node in parallel is a difficult problem. Several researchers have addressed this issue, e.g., <ref> [De84, CDD85] </ref>. <p> property that every variable instance in the computation has a unique binding at any time. (With Or-parallelism, recall that an Or-node saves multiple answers; these provide multiple bindings for the variables that appear in it.) This typically results in the loss of much parallelism, but reduces implementation overhead (see e.g., <ref> [De84, CDD85, HR89] </ref>). 3.2 Full Or-Parallelism Full Or-parallelism is best understood in terms of SLD-trees. The SLD-tree for a logic program has the query as the root node. Every node in the tree is a conjunction of goals. <p> There is no And-parallelism since in no one transition do we add goals corresponding to different body literals. DeGroot This is an And-parallel method that exploits no Or-parallelism, and was proposed in <ref> [De84] </ref>. fp (U; V )?g ` [fb1 (X)?; b2 (Y )?g ` [fb1 (5); b2 (6)g ` [fb3 (5; 6; Z)?g ` [ fp (5; 9)g ` [fb4 (X; Y )?g ` [fb4 (1; 2)g ` [fp (1; 2)g Conery This is a method that attempts to realize both And- and
Reference: [DW87] <author> S.W. Dietrich and D.S. Warren, </author> <title> Extension Tables: Memo Relations in Logic Programming. </title> <booktitle> In Proc. IEEE Symposium on Logic Programming, </booktitle> <address> San Francisco, </address> <month> Sept. </month> <year> 1987. </year>
Reference-contexts: In general, this requires that all generated goals and facts should be retained and the process repeated iteratively until no new goals and facts are generated. Most of the proposed methods use a top-down control strategy to generate goals, e.g., <ref> [DW87, Lo85, Vi89] </ref>. Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue [BMSU86, RLK86, BeR87, Ra88, Se89].
Reference: [Do89] <author> G. Dong, </author> <title> On Distributed Processing of Datalog Queries by Decomposing Databases. </title> <booktitle> In Proc. ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 26-35, </pages> <address> Portland, </address> <year> 1986. </year>
Reference-contexts: While considering this work is beyond the scope of this paper, we remark that the interactions of the techniques used in this work and the Magic Templates algorithm remain little understood and suggest an area for further study. We direct the interested reader to <ref> [WS88, CW89, Do89, GST89] </ref>. 8.3 Some Added Advantages of Memoing The remarks in this subsection apply equally to top-down and bottom-up methods that do memoing. As we have already seen, memoing offers gains in terms of avoiding redundant computation and increased parallelism. It also offers other important advantages: 1.
Reference: [EKM82] <author> N. Eisinger, S. Kasif, J. Minker, </author> <title> Logic Programming: A Parallel Approach. </title> <booktitle> In Proc. First Logic Programming Conference, </booktitle> <year> 1982. </year>
Reference-contexts: We discuss methods that are not "sip-optimal" in Section 6.1. Several examples of sip-methods were presented in Section 3. There are others that we have not considered; see e.g., <ref> [Po81, EKM82] </ref>. 4.2 A Summary of Our Model of Computation We now present the formal definitions of states, transitions and computations.
Reference: [GST89] <author> S. Ganguly, A. Silberschatz, S. Tsur, </author> <title> A Framework for the Parallel Processing of Datalog Queries. </title> <type> Manuscript. </type>
Reference-contexts: While considering this work is beyond the scope of this paper, we remark that the interactions of the techniques used in this work and the Magic Templates algorithm remain little understood and suggest an area for further study. We direct the interested reader to <ref> [WS88, CW89, Do89, GST89] </ref>. 8.3 Some Added Advantages of Memoing The remarks in this subsection apply equally to top-down and bottom-up methods that do memoing. As we have already seen, memoing offers gains in terms of avoiding redundant computation and increased parallelism. It also offers other important advantages: 1.
Reference: [HR89] <author> M. Hermenegildo and F. Rossi, </author> <title> On the Correctness and Efficiency of Independent And-Parallelism in Logic Programs. </title> <booktitle> In Proc. N. American Conference on Logic Programming, </booktitle> <pages> pages 369-389, </pages> <address> Cleveland, </address> <year> 1989. </year>
Reference-contexts: property that every variable instance in the computation has a unique binding at any time. (With Or-parallelism, recall that an Or-node saves multiple answers; these provide multiple bindings for the variables that appear in it.) This typically results in the loss of much parallelism, but reduces implementation overhead (see e.g., <ref> [De84, CDD85, HR89] </ref>). 3.2 Full Or-Parallelism Full Or-parallelism is best understood in terms of SLD-trees. The SLD-tree for a logic program has the query as the root node. Every node in the tree is a conjunction of goals.
Reference: [Ka87a] <author> L.V. Kale, </author> <title> Parallel Execution of Logic Programs: The Reduce-Or Process Model. </title> <booktitle> In Proc. Intl. Conference on Logic Programming, </booktitle> <pages> pages 616-632, </pages> <address> Melbourne, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Reduce-Or This is also a method that exploits both And- and Or parallelism, and is proposed in <ref> [Ka87a] </ref>. <p> straightforward to show that the Reduce-Or method allows the above subsets of F 1 n1 and G 1 n1 to be used in derivations at Step n. (The details of the proof of this claim follow from the full description of the Reduce-Or method; the reader is asked to consult <ref> [Ka87a] </ref>.) This completes our induction, and the proof of the theorem. 2 Theorem 6.5 Evaluation according to a non-memoing method that exploits only And- or Or- parallelism, but not both, is strictly less parallel than evaluation according to the Reduce-Or process model. <p> However, limiting ourselves to the class of sip-methods (a broad class that includes the methods surveyed in Section 3), we believe that this observation is significant. First, as Kale observes <ref> [Ka87a] </ref>, identifying the available parallelism is a useful first step; it remains to consider efficient realizations. In this, we believe that the Magic Templates method offers considerable flexibility since it frees us from the constraints imposed by maintaining a network of processes and associated binding environments. <p> In fact, this causes Prolog to be incomplete. We note that memoing is not essential for completeness; the Reduce-Or model <ref> [Ka87a] </ref> is complete, although it does not memoing. This is essentially because all paths are explored in parallel, and so even if some paths are non-terminating | and will never produce new solutions | all paths that do produce solutions are considered.
Reference: [Ka87b] <author> L.V. Kale, </author> <title> Completeness and Full Parallelism of Parallel Logic Programming Schemes. </title> <booktitle> In Proc. IEEE Symposium on Logic Programming, </booktitle> <pages> pages 125-133, </pages> <address> San Francisco, </address> <month> Sept. </month> <year> 1987. </year>
Reference-contexts: Most of the methods that we discuss in this section proceed by identifying subgoals and creating processes to solve them. However, there has been some work on achieving similar results through bottom-up fixpoint evaluation, and we discuss this work as well. The discussion in <ref> [Ka87b] </ref> supplements the survey presented in this section, and we suggest that the reader consult it for more details. 3.1 The And-Or Tree Model An And-Or tree for a logic program has the query as the root node, which is an Or-node. <p> Kale discusses the parallelism obtained by several methods in <ref> [Ka87b] </ref>, but without reference to a precise measure of parallelism, and the following theorems may be viewed as formalizations of the discussion in that paper. A method is said to do no memoing if no generated goal or fact is ever saved, except answers to the query.
Reference: [KL86] <author> M. Kifer and E. Lozinskii, </author> <title> A Framework for an Efficient Implementation of Deductive Databases. </title> <booktitle> In Proc. Advanced Database Symposium, </booktitle> <address> Tokyo, </address> <year> 1986. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc. <p> Most of the proposed methods use a top-down control strategy to generate goals, e.g., [DW87, Lo85, Vi89]. Some use a graph structure over the rules of the program for this purpose, e.g., <ref> [KL86, KL88, vG86] </ref>. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue [BMSU86, RLK86, BeR87, Ra88, Se89].
Reference: [KL88] <author> M. Kifer and E. Lozinskii, Sygraf: </author> <title> Implementing Logic Programs in a Database Style. </title> <journal> In Trans. on Software Engineering, </journal> <pages> pages 922-935, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc. <p> Most of the proposed methods use a top-down control strategy to generate goals, e.g., [DW87, Lo85, Vi89]. Some use a graph structure over the rules of the program for this purpose, e.g., <ref> [KL86, KL88, vG86] </ref>. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue [BMSU86, RLK86, BeR87, Ra88, Se89].
Reference: [Lo85] <author> E. Lozinskii, </author> <title> Evaluating Queries in Deductive Databases by Generating. </title> <booktitle> In Proc. Intl. Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 173-177, </pages> <year> 1985. </year>
Reference-contexts: In general, this requires that all generated goals and facts should be retained and the process repeated iteratively until no new goals and facts are generated. Most of the proposed methods use a top-down control strategy to generate goals, e.g., <ref> [DW87, Lo85, Vi89] </ref>. Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue [BMSU86, RLK86, BeR87, Ra88, Se89].
Reference: [MR89] <author> M. Maher and R. Ramakrishnan, </author> <title> Deja Vu in Fixpoints of Logic Programs. </title> <booktitle> In Proc. North American Conference on Logic Programming, </booktitle> <month> pages , </month> <year> 1989. </year>
Reference-contexts: The main difference is that derivations are not repeated in subsequent iterations, through the use of duplicate elimination. We follow the presentation in <ref> [MR89] </ref> in the rest of this section, with some simplification. 1 Let us first define a binary operator W P , whose role is similar to that of the well-known T P operator of [vEK76]: W P (X; Y ) = fh j h : b 1 ; : : : <p> = ffi 0 = ;: S n+1 = set (S n [ ffi n+1 ) S = dup elim (lim n!1 S n ) GC = set (S) The set GC is the set of generated consequences of the program. 1 In particular, the operator W P is defined in <ref> [MR89] </ref> as a multiset constructor. For our purposes here, the cardinality of the elements is not important, and we treat W P as a set constructor.
Reference: [MFPR89] <author> I.S. Mumick, S. Finkelstein, H. Pirahesh and R. Ramakrishnan, </author> <title> Magic Conditions. </title> <note> In preparation. </note>
Reference-contexts: This leads to a notion of "bound" and "free" arguments, similar to "input" and "output" modes, that has been proposed and used by a number of researchers. (More sophisticated compile-time classification has been explored in <ref> [MFPR89] </ref>.) We note that [Ra88] incorporates such an analysis into the Magic Templates algorithm. Recall that the algorithm adds a modified rule and a set of magic rules for each rule in the original program.
Reference: [Na87] <author> L. Naish, </author> <title> Parallelizing Nu-Prolog. </title> <institution> Dept. of Computer Science, Univ. of Melbourne, </institution> <type> TR 17, </type> <year> 1987. </year>
Reference-contexts: The sip formalism does not allow us to consider the resolvent that is the set of all subgoals and then pick an arbitrary order. This is precisely what committed choice languages such as Parlog [CG86] and Concurrent Prolog [Sh86], the f reeze primitive in Nu-Prolog <ref> [Na87] </ref>, and some other proposed methods, e.g. in [Co83], achieve by dynamically suspending and starting goals. <p> The ordering is controlled typically by variable annotations that, for example, suspend a goal until one of its variables is instantiated <ref> [CG86, Sh86, Na87] </ref>; it can also be controlled by a sophisticated run-time scheduler [Co83]. Methods that use annotations typically sacrifice completeness. Completely unrestricted dynamic re-ordering carries a high run-time overhead. Nevertheless, there may be situations where such approaches perform better than any sip-method.
Reference: [NR89] <author> J. Naughton and R. Ramakrishnan, </author> <title> A Unified Approach to Logic Program Evaluation. </title> <type> Technical Report, </type> <institution> University of Wisconsin-Madison, </institution> <year> 1989. </year>
Reference-contexts: While the details of an implementation of a top-down method would differ considerably from that of a bottom-up method, we believe that many ideas, such as schemes for structure-sharing, are likely to work in either approach. (See <ref> [NR89] </ref> for a closer look at this issue.) The parallelism in logic programs is often broadly classified into And, Or- and Stream parallelism. And-parallelism refers to the parallel solution of subgoals generated from literals in the same rule body. <p> We refer the reader to surveys and expositions presented in <ref> [BaR86, Br89, NR89, Ul89a] </ref>. We note that while most of this literature deals with the implementation of Datalog, which is a subset of logic programs without function symbols, and also does not deal with non-ground terms, recent proposals treat full logic programs [Ra88, Se89]. <p> A full discussion of these issues is beyond the scope of this paper. Some of these issues are considered in more detail in <ref> [NR89] </ref>. We note that the results in this paper depend upon the availability of sufficient resources to exploit all available parallelism. In the case that resources are limited, as is likely, the actual parallelism obtained will be curtailed by how efficiently the computation can be mapped onto the resources.
Reference: [Po81] <author> G.H. Pollard, </author> <title> Parallel Execution of Horn Clause Programs. </title> <type> Ph.D. thesis, </type> <institution> Imperial College of Science and Technology, Univ. of London, </institution> <year> 1981. </year>
Reference-contexts: We discuss methods that are not "sip-optimal" in Section 6.1. Several examples of sip-methods were presented in Section 3. There are others that we have not considered; see e.g., <ref> [Po81, EKM82] </ref>. 4.2 A Summary of Our Model of Computation We now present the formal definitions of states, transitions and computations.
Reference: [Ra88] <author> R. Ramakrishnan, </author> <title> Magic Templates: A Spellbinding Approach to Logic Programs. </title> <booktitle> In Proc. Intl. Conference on Logic Programming, </booktitle> <pages> pages 140-159, </pages> <address> Seattle, Washington, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in <ref> [Ra88, Se89] </ref> and also [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88], etc. <p> We note that while most of this literature deals with the implementation of Datalog, which is a subset of logic programs without function symbols, and also does not deal with non-ground terms, recent proposals treat full logic programs <ref> [Ra88, Se89] </ref>. We will examine one of these proposals ([Ra88]) in detail later. The following brief discussion should be supplemented by consulting Section 5. <p> Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue <ref> [BMSU86, RLK86, BeR87, Ra88, Se89] </ref>. <p> may be restricted using only a subset of the bindings made by its predecessors in the sip. (This may be motivated by the overhead of propagating the bindings in some evaluation schemes.) We do not consider such refinements of sips in this paper, and instead we refer the reader to <ref> [BeR87, Ra88] </ref>. Further, it is possible to choose a different sip for the same rule when it is invoked using different goals. For example, we may wish to solve it left-to-right when the first argument of the goal is bound to a ground term, and right-to-left otherwise. <p> The property that we will study in this paper is the effect of the choice of the evaluation method on when goals and facts are identified, and this provides the basis for our measure of parallelism. The reader who is familiar with <ref> [Ra88] </ref> will notice a difference in our definition of a sip-method. In [Ra88], a sip-method was required to generate the facts and goals that it is possible to generate by our definition of complete sip-methods, but it was possible for the method to generate other facts and goals as well. <p> The reader who is familiar with <ref> [Ra88] </ref> will notice a difference in our definition of a sip-method. In [Ra88], a sip-method was required to generate the facts and goals that it is possible to generate by our definition of complete sip-methods, but it was possible for the method to generate other facts and goals as well. <p> Methods that generated precisely the sets of goals and facts that it is possible to generate by our definition of complete subsumption-checking sip-methods were said to be sip-optimal. We have chosen to study this class in order to focus on the issue of parallelism; in <ref> [Ra88] </ref>, the primary concern was the restriction of the computation to relevant facts and goals. We discuss methods that are not "sip-optimal" in Section 6.1. Several examples of sip-methods were presented in Section 3. <p> The reader is referred to <ref> [Ra88] </ref> for a more general algorithm capable of implementing more sophisticated sip choices, and also for a detailed discussion of bottom--up fixpoint computation in the presence of non-ground facts. The idea is to compute a set of auxiliary predicates that contain the goals. <p> U ); sg (U; V ); down (V; Y ). magic sg (U; V ) :- magic sg (X; Y ); up (X; U ). magic sg (john; Z): 2 We have the following results characterizing the transformed program P mg with respect to the original program P , from <ref> [Ra88] </ref>. Theorem 5.1 [Ra88] hP; Qi is equivalent to hP mg ; Qi with respect to the set of answers to the query. Definition 5.2 Let us define the Magic Templates Evaluation Method as follows: 1. <p> (U; V ); down (V; Y ). magic sg (U; V ) :- magic sg (X; Y ); up (X; U ). magic sg (john; Z): 2 We have the following results characterizing the transformed program P mg with respect to the original program P , from <ref> [Ra88] </ref>. Theorem 5.1 [Ra88] hP; Qi is equivalent to hP mg ; Qi with respect to the set of answers to the query. Definition 5.2 Let us define the Magic Templates Evaluation Method as follows: 1. Rewrite the program hP; Qi according to the choice of sips using the Magic Templates algorithm. 2. <p> The second step is presented in more detail in the next subsection. Theorem 5.2 <ref> [Ra88] </ref> The Magic Templates Evaluation Method is a complete sip-method. The careful reader will notice that some joins are repeated in the bodies of rules defining magic predicates and modified rules. <p> Let both methods be more parallel than a sequential method. Then, neither method is more parallel than the other. 6.1 Methods That Sacrifice Restriction for Parallelism We present a result that indicates why we chose a definition of a sip-method that differs from the definition in <ref> [Ra88] </ref>. It also illustrates the trade-off between restricting search and parallelizing the computation. <p> This leads to a notion of "bound" and "free" arguments, similar to "input" and "output" modes, that has been proposed and used by a number of researchers. (More sophisticated compile-time classification has been explored in [MFPR89].) We note that <ref> [Ra88] </ref> incorporates such an analysis into the Magic Templates algorithm. Recall that the algorithm adds a modified rule and a set of magic rules for each rule in the original program.
Reference: [RBK88] <author> R. Ramakrishnan, C. Beeri and R. Krishnamurthy, </author> <title> Optimizing Existential Datalog Queries, </title> <booktitle> In Proc. 7th ACM SIGMOD-SIGACT Symposium on Principles of Database Systems, </booktitle> <year> 1988. </year>
Reference-contexts: The above program can be systematically derived from the following program, using optimizations presented in <ref> [RBK88] </ref>, but we do not pursue this point here. p (X; Z) :- q1 (X; Y; Z); q2 (X; Y ). q2 (X; Y ) :- r q2 (X); b3 (X; Y ). r q1 (Y ) :- q2 (X; Y ). 2 8 Pragmatics We briefly discuss several practical considerations.
Reference: [RLK86] <author> J. Rohmer , R. Lescoeur and J.M. Kerisit, </author> <title> The Alexander Method, a Technique for the Processing of Recursive Axioms in Deductive Databases. </title> <journal> In New Generation Computing, </journal> <volume> 4, 3, </volume> <pages> pages 273-285, </pages> <year> 1986. </year>
Reference-contexts: Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue <ref> [BMSU86, RLK86, BeR87, Ra88, Se89] </ref>.
Reference: [Se89] <author> H. Seki, </author> <title> On the Power of Alexander Templates. </title> <booktitle> In Proc. 8th ACM SIGMOD-SIGACT Symposium on Principles of Database Systems, </booktitle> <pages> pages 150-159, </pages> <year> 1989. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in <ref> [Ra88, Se89] </ref> and also [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88], etc. <p> We note that while most of this literature deals with the implementation of Datalog, which is a subset of logic programs without function symbols, and also does not deal with non-ground terms, recent proposals treat full logic programs <ref> [Ra88, Se89] </ref>. We will examine one of these proposals ([Ra88]) in detail later. The following brief discussion should be supplemented by consulting Section 5. <p> Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue <ref> [BMSU86, RLK86, BeR87, Ra88, Se89] </ref>. <p> First, from Theorem 6.2 it follows that we need only consider memoing methods as candidates. Of these, Alexander Templates <ref> [Se89] </ref> is the only one (other than Magic Templates) that is capable of dealing with non-ground facts. Examples are readily found where dealing with such facts is necessary to restrict search as per the sips we consider.
Reference: [Sh86] <author> E. Shapiro, </author> <title> Concurrent Prolog: A Progress Report. </title> <booktitle> In IEEE Com--puter, </booktitle> <pages> pages 44-58, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: All subgoals of these goals must respect the above order. The sip formalism does not allow us to consider the resolvent that is the set of all subgoals and then pick an arbitrary order. This is precisely what committed choice languages such as Parlog [CG86] and Concurrent Prolog <ref> [Sh86] </ref>, the f reeze primitive in Nu-Prolog [Na87], and some other proposed methods, e.g. in [Co83], achieve by dynamically suspending and starting goals. <p> The ordering is controlled typically by variable annotations that, for example, suspend a goal until one of its variables is instantiated <ref> [CG86, Sh86, Na87] </ref>; it can also be controlled by a sophisticated run-time scheduler [Co83]. Methods that use annotations typically sacrifice completeness. Completely unrestricted dynamic re-ordering carries a high run-time overhead. Nevertheless, there may be situations where such approaches perform better than any sip-method.
Reference: [Ul89a] <author> J.D. Ullman, </author> <title> Principles of Database and Knowledge-Base Systems, Volumes 1 and 2. </title> <publisher> Computer Science Press, </publisher> <year> 1989. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc. <p> We refer the reader to surveys and expositions presented in <ref> [BaR86, Br89, NR89, Ul89a] </ref>. We note that while most of this literature deals with the implementation of Datalog, which is a subset of logic programs without function symbols, and also does not deal with non-ground terms, recent proposals treat full logic programs [Ra88, Se89].
Reference: [Ul89b] <author> J.D. Ullman, </author> <title> Bottom-Up Beats Top-Down for Datalog, </title> <booktitle> In Proc. 8th ACM SIGMOD-SIGACT Symposium on Principles of Database Systems, </booktitle> <pages> pages 140-149, </pages> <year> 1989. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc.
Reference: [vG86] <author> A. van Gelder, </author> <title> A Message Passing Framework for Logical Query Evaluation. </title> <booktitle> In Proc. ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 16-53, </pages> <address> Washington, D.C., </address> <year> 1986. </year>
Reference-contexts: Most of the proposed methods use a top-down control strategy to generate goals, e.g., [DW87, Lo85, Vi89]. Some use a graph structure over the rules of the program for this purpose, e.g., <ref> [KL86, KL88, vG86] </ref>. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue [BMSU86, RLK86, BeR87, Ra88, Se89].
Reference: [vEK76] <author> M. van Emden and R. Kowalski, </author> <title> The Semantics of Predicate Logic as a Programming Language. </title> <journal> In JACM 28, </journal> <volume> no. 4, </volume> <pages> pages 733-742, </pages> <month> Oct. </month> <year> 1976. </year>
Reference-contexts: However, the distinction is artificial, and we may choose to consider (a subset of) facts to be rules if we wish. The meaning of a logic program is given by its least Herbrand model <ref> [vEK76] </ref>. Following the syntax of Edinburgh Prolog, definite clauses (rules) are written as p :- q 1 ; : : : ; q n : read declaratively as q 1 and q 2 and : : : and q n implies p. <p> The following brief discussion should be supplemented by consulting Section 5. The fundamental operation in bottom-up approaches is the application of a rule to a set of facts to generate new facts, which is similar to the use of the T P operator to construct the least fixpoint model <ref> [vEK76] </ref>. An obvious drawback is that all consequences of the program are generated, not just the facts relevant to processing the given query. <p> We follow the presentation in [MR89] in the rest of this section, with some simplification. 1 Let us first define a binary operator W P , whose role is similar to that of the well-known T P operator of <ref> [vEK76] </ref>: W P (X; Y ) = fh j h : b 1 ; : : : ; b k is a rule of P ; is mgu of (b 1 ; : : : ; b k ) and (d 1 ; : : : ; d k ); if <p> Let ground be an operator that takes a set of possibly non-ground facts and returns the set of ground facts that are instances of the input set. the following well-known result shows that Seminaive Iteration is consistent with the usual least Herbrand model semantics of <ref> [vEK76] </ref>. Proposition 5.3 The set of generated consequences GC of a program computed using Seminaive Iteration is such that ground (GC) = M .
Reference: [Vi89] <author> L. Vieille, </author> <title> Recursive Query Processing: </title> <note> The Power of Logic To appear in Theoretical Computer Science, </note> <year> 1989. </year>
Reference-contexts: We think that on the contrary much can be gained by a careful study of the literature of both top-down and bottom-up approaches. There is a strong relationship between the structure of top-down and bottom-up computations, as demonstrated in [Ra88, Se89] and also <ref> [BMSU86, BeR87, Br89, Ul89b, Ul89a, Vi89, KL86, KL88] </ref>, etc. <p> In general, this requires that all generated goals and facts should be retained and the process repeated iteratively until no new goals and facts are generated. Most of the proposed methods use a top-down control strategy to generate goals, e.g., <ref> [DW87, Lo85, Vi89] </ref>. Some use a graph structure over the rules of the program for this purpose, e.g., [KL86, KL88, vG86]. It has been shown however, that this can be achieved through source-to-source program transformations, and this is the approach that we will pursue [BMSU86, RLK86, BeR87, Ra88, Se89]. <p> (X; Z); b (Z; Y ). t (5; Y )? This is a program on which Prolog will not terminate, repeatedly generating the goal t (5,Z)?, but memoing enables us to recognize that the goal has been generated before, and thereby devise modifications to Prolog that do terminate (e.g., see <ref> [Vi89] </ref>). In fact, this causes Prolog to be incomplete. We note that memoing is not essential for completeness; the Reduce-Or model [Ka87a] is complete, although it does not memoing.
Reference: [WS88] <author> O. Wolfson and A. Silberschatz, </author> <title> Sharing the Load of Logic Program Evaluations. </title> <booktitle> In Proc. 7th ACM SIGMOD-SIGACT Symposium on Principles of Database Systems, </booktitle> <year> 1988. </year>
Reference-contexts: While considering this work is beyond the scope of this paper, we remark that the interactions of the techniques used in this work and the Magic Templates algorithm remain little understood and suggest an area for further study. We direct the interested reader to <ref> [WS88, CW89, Do89, GST89] </ref>. 8.3 Some Added Advantages of Memoing The remarks in this subsection apply equally to top-down and bottom-up methods that do memoing. As we have already seen, memoing offers gains in terms of avoiding redundant computation and increased parallelism. It also offers other important advantages: 1.
References-found: 37

