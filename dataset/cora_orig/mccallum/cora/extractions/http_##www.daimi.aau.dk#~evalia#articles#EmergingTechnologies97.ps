URL: http://www.daimi.aau.dk/~evalia/articles/EmergingTechnologies97.ps
Refering-URL: http://www.daimi.aau.dk/~evalia/
Root-URL: http://www.daimi.aau.dk
Title: Genetic Algorithms for Industrial Planning  
Author: Thomas Stidsen 
Keyword: Genetic Algorithms, Simulated Annealing, real world scheduling.  
Address: Aarhus, Ny Munkegade, Bldg. 540, DK-8000 Aarhus C, Denmark  
Affiliation: Dept. of Computer Science, University of  
Abstract: Genetic Algorithms have been an active research area for more than three decades, but the industrial applications of this search technique have been scarce. There may be several reasons for this. The EVALIA 1 project (EVolutionary ALgorithms for Industrial Applications) attempts to test the value of Genetic Algorithms on realistic industrial problems. Further a general framework is developed to ease the implementation of optimisation programs for industrial problems. This article reports on the first results of this project, when testing the framework on a real-world planning problem at Odense Steel Shipyard (OSS). Further this article will report on the possibilities of specialised Genetic Algorithm techniques: Adaptive Operators which are used in what we call the shotgun approach, the Pareto technique for multi-objective op-timisation and Co-evolutionary Constraint Satisfaction. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aarts, E., Korst, J.: </author> <title> Simulated Annealing and Boltzmann Machines. </title> <publisher> John Wiley & Sons 1989 </publisher>
Reference-contexts: The two remaining algorithms are much more serious competitors to the Genetic Algorithm. Simulated Annealing [8] develops solutions to a problem starting from a ran-dom solution by gradually lowering the probability of accepting a worse solution. Simulated Annealing have been throughly reviewed in a number of textbooks, e.g. <ref> [1] </ref>, so I will not describe it in any detail, but only mention where our framework departs from the standard algorithm. The crucial difference in our case is that we use our mutation operators 5 to define the neighbourhood.
Reference: 2. <author> Aarts, E., Lenstra, J. K.: </author> <title> Local Search in Combinatorial Optimization. </title> <publisher> John Wiley & Sons 215-311 1997 </publisher>
Reference-contexts: Until now we have constructed five different genetic operators: - 2-opt revert sub-tour. Move sub-tour. - 3-opt optimise tour. 7 For an excellent review of heuristics for the solution of the TSP problem, from what is probably the leading TSP specialist, see <ref> [2] </ref>. Change machine to perform operation. Move operation to other day. Crossover. The first three operators all focus on the order of the operations for one time-period for one machine. The first two operators simply move a group of operations to some other point during that time-period. <p> The first two operators simply move a group of operations to some other point during that time-period. The third operator, the 3-opt operator, attempts to minimise the length of the tour by performing 3 opt. transitions, see <ref> [2] </ref>. Surprisingly this operator performs very badly. Besides demanding much computation, the operator does not perform very well. This is probably because what may be an optimal order from a distance point of view, is far from that when the specialities of the problem are accounted for.
Reference: 3. <author> Davis, L.: </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold 1991 </publisher>
Reference-contexts: To avoid this we have chosen to make the probability parameters adaptive. This idea is described in <ref> [3] </ref> and [7]. The idea is to change the operator probability if an operator starts to perform well, i.e. produce new good solutions. Some operators may though not produce good solutions directly but solutions which are good platforms for further improvement.
Reference: 4. <author> Glower, F.: </author> <title> Tabu Search Part I. </title> <note> ORSA J. Comput 1 190-206 1989 </note>
Reference-contexts: Further we allow the possibility of using adaptive operators, see section 2.1, which should speedup the algorithm. Simulated Annealing requires less parameters to be tuned and is often faster than Genetic Algorithms, but as mentioned Genetic Algorithms enables the use of crossover operators and some additional possibilities. TABU search <ref> [4] </ref> [5], is another iterative heuristic search algorithm, which starts from a random solution and gradually improves the found solution. Unlike both Genetic Algorithms and Simulated Annealing TABU search is not a model of a real-world phenomenon.
Reference: 5. <author> Glower, F.: </author> <title> Tabu Search Part II. </title> <note> ORSA J. Comput 2 4-32 1990 </note>
Reference-contexts: Simulated Annealing requires less parameters to be tuned and is often faster than Genetic Algorithms, but as mentioned Genetic Algorithms enables the use of crossover operators and some additional possibilities. TABU search [4] <ref> [5] </ref>, is another iterative heuristic search algorithm, which starts from a random solution and gradually improves the found solution. Unlike both Genetic Algorithms and Simulated Annealing TABU search is not a model of a real-world phenomenon.
Reference: 6. <author> Goldberg, D.: </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley 1989 </publisher>
Reference-contexts: Afterwards, I will in section 2.2 briefly describe the two other search heuristics. 2.1 Genetic Algorithms A lot of research has been carried out in the Genetic Algorithm society and the standard Genetic Algorithm has been described in several excellent textbooks, e.g. <ref> [6] </ref> and [11]. I will therefor not describe the standard Genetic Algorithm theory, but concentrate on the more specialised parts. We have implemented a number of Genetic Algorithm features, some standard and others quite specialised: Steady State GA or Generational GA. Single population GA or island GA. Different selection models. <p> The selection algorithm of the Genetic Algorithm usually relies on only one single fitness measure and hence there are two different options: 1. Combine the different factors to one single fitness measure. 2. Use the Pareto optimality measure <ref> [6] </ref> The first option is by far the most applied. The different factors are combined, often linearly, into one measure which is then used in the standard way. The problem is then often to perform this combination in the right way and this may require extensive parameter tuning. <p> The problem is then often to perform this combination in the right way and this may require extensive parameter tuning. The alternative approach is to use the Pareto optimality criteria, described in <ref> [6] </ref>. The simple idea is the following: Given a vector of performance measures, compare the individuals and divide them in two groups, un-dominated individuals and dominated individuals. <p> Genetic Algorithms are quite complicated, with lots of parameters which are each connected in non-trivial ways. Too many applications have attempted the bit-string representation, as rec ommended in <ref> [6] </ref>. Genetic Algorithms have not matured to a productive age. It was to test whether the last point is true, that the EVALIA project was initiated. We do not claim to be able to answer that question, at least not outside the limited use at the OSS.
Reference: 7. <author> Julstrom, B. A.: </author> <title> What Have You Done for Me Lately? Adapting Operator Proba--bilities in a Steady-State Genetic Algorithm. </title> <note> ICGA 81 1995 </note>
Reference-contexts: To avoid this we have chosen to make the probability parameters adaptive. This idea is described in [3] and <ref> [7] </ref>. The idea is to change the operator probability if an operator starts to perform well, i.e. produce new good solutions. Some operators may though not produce good solutions directly but solutions which are good platforms for further improvement. <p> Therefor it is necessary, not only to reward operators that produce the new individuals, the children, but also the operators that produced the parents and the operators which produced the grand parents and so forth. We have chosen the solution described in <ref> [7] </ref> where each individual is tagged with information about which operator produced it. Whenever a new individual is created from one or two existing individuals, the reward algorithm trace backwards through the family tree and rewards the responsible operators with an amount 4 .
Reference: 8. <author> Kirckpatrick, S., Gelatt Jr., C. D., Vecchi, M. P.: </author> <title> Optimization by Simulated Annealing. </title> <note> Science 220 671-680 1983 </note>
Reference-contexts: The Random Search algorithm is only used for comparison and the hill climber algorithm can essentially be thought of as a Simulated Annealing algorithm with start temperature zero. The two remaining algorithms are much more serious competitors to the Genetic Algorithm. Simulated Annealing <ref> [8] </ref> develops solutions to a problem starting from a ran-dom solution by gradually lowering the probability of accepting a worse solution.
Reference: 9. <author> Kragelund, L. V.: </author> <title> Solving a Timetabling Problem using Hybrid Genetic Algorithms. </title> <journal> Software-Practice and Experience, </journal> <volume> Vol. 27(10), </volume> <pages> 1121-1134, </pages> <month> Oct. </month> <year> 1997 </year>
Reference-contexts: A practical application of this technique when applied to a real-world planning problem is described in <ref> [9] </ref>. Like the Pareto option this option is only possible for the Genetic Algorithm. 2.2 Other Search Heuristics The focus of the EVALIA project is mainly Genetic Algorithms, but we are not fundamentalistic so we have designed our framework to include a number of other heuristics: Simulated Annealing.
Reference: 10. <author> Michalewicz, Z.: </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer Verlag 1992 </publisher>
Reference-contexts: The third level is the level of the fitness function. This level is completely problem dependent and has to be reprogrammed for every application. Together the three levels constitutes the application. This approach to the use of genetic algorithms very precisely follows the suggestions in <ref> [10] </ref>. The framework is implemented in object-oriented C++. This makes it easy to isolate the levels from each other. Each of the levels are then implemented as classes: Level 1 is implemented as a number of connected objects to which the two other levels are added.
Reference: 11. <author> Mitchell, M.: </author> <title> An Introduction to Genetic Algorithms. </title> <publisher> The MIT press 1996 </publisher>
Reference-contexts: Afterwards, I will in section 2.2 briefly describe the two other search heuristics. 2.1 Genetic Algorithms A lot of research has been carried out in the Genetic Algorithm society and the standard Genetic Algorithm has been described in several excellent textbooks, e.g. [6] and <ref> [11] </ref>. I will therefor not describe the standard Genetic Algorithm theory, but concentrate on the more specialised parts. We have implemented a number of Genetic Algorithm features, some standard and others quite specialised: Steady State GA or Generational GA. Single population GA or island GA. Different selection models.
Reference: 12. <author> Paredis, J.: </author> <title> Co-evolutionary Constraint Satisfaction. </title> <booktitle> PPSN 1994, Lecture Notes in Computer Science vol. </booktitle> <pages> 866. </pages>
Reference-contexts: In some practical problems a huge number of constraints constitutes the problem. The combined effect of these constraints then defines the fitness of each individual. The standard solution is then to calculate the fitness as the combination of all the constraints. An alternative solution is suggested in <ref> [12] </ref>. Here the biological arms race between a population of individuals and a population of parasites drives the evolution towards better individuals. The individuals are then the solutions to the problem and the constraints are the parasites.
Reference: 13. <author> Stidsen, T., Kragelund L. V., Mateescu, O.: </author> <title> Jobshop Scheduling in a Shipyard. </title> <note> ECAI 1996, obtainable through WWW: http://www.daimi.aau.dk/evalia </note>
Reference-contexts: The plate storage problem is though not the first problem at the shipyard to which we have applied Genetic Algorithms, see also <ref> [13] </ref> In order to create this application it is now necessary to construct three things: Construct a representation, see subsection 5.1. Construct a set of genetic operators, see subsection 5.2.
Reference: 14. <author> Vaessens, R. J. M., Aarts, E. H. L., Lenstra, J. K.: </author> <title> Job Shop Scheduling by Local Search. </title> <note> Memorandum COSCOR 94-05 1994 </note>
Reference-contexts: There are several other tricks involved which I will not review here. The algorithm has not been implemented in our framework yet, but I mention it because it is fairly easy to incoperate in the framework and because is has shown remarkable results on a scheduling problem, see <ref> [14] </ref> where it is compared to Genetic Algorithms and Simulated Annealing. 2.3 The Representation issues In the EVALIA project we have made the questionable choice to expel the representation issue and hence the operators from the general framework.
Reference: 15. <author> Wolpert, D. H., Macready, W. G.: </author> <title> No Free Lunch Theorems For Search. </title> <institution> Technical report from The Santa Fe Institute, </institution> <note> SFI-TR-95-02-010, obtainable through WWW: http://www.santafe.edu/wgm/papers.html 1996 </note>
Reference-contexts: From this perspective, the only thing which is needed to make a search algorithm, is to construct a fitness function for the problem at hand, and then you are in business. The No Free Lunch theorem (NFL-theorem) <ref> [15] </ref>, however seriously challenges this point of view. Here it is proved that averaged over all 2 possible optimisation problems all search algorithms perform equally well or equally badly !.
References-found: 15

