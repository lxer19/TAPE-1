URL: http://www.cc.gatech.edu/faculty/ashwin/papers/er-93-04.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Email: E-mail: ashwin@cc.gatech.edu  
Title: Creative Conceptual Change  
Author: Ashwin Ram 
Affiliation: College of Computing Georgia Institute of Technology  
Date: June 1993.  
Address: Boulder, CO,  Atlanta, Georgia 30332-0280  
Note: Fifteenth Annual Conference of the Cognitive Science Society, pp. 17-26,  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: <author> Alexander, J. </author> <year> (1992). </year> <note> Metacognition and Giftedness. Paper presented at The SouthEast Cognitive Science Conference, abstracted in Technical Report #1, </note> <institution> Cognitive Science Program, Georgia Institute of Technology, </institution> <address> Atlanta, GA. </address>
Reference: <author> Anderson, J.R. </author> <year> (1983). </year> <title> The Architecture of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Anderson, J.R. </author> <year> (1989). </year> <title> A Theory of the Origins of Human Knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 30 </volume> <pages> 313-351. </pages>
Reference-contexts: The model is based on observations of human troubleshooting operators and protocol analysis of the data gathered in the test area of an operational electronics assembly manufacturing plant. In Meta-TS, multiple learning methods for knowledge compilation <ref> (Anderson, 1989) </ref>, interactive transfer of expertise (Davis, 1979), postponement (Ram, 1991, 1993), and forgetting are integrated through metacognitive analysis. Experimental results in metacogni-tion also suggest that such analysis can facilitate reasoning and learning (e.g., Alexander, 1992; Carr, 1992; Schneider, 1985; Weinert, 1987).
Reference: <author> Arkin, R.C. </author> <year> (1989). </year> <title> Motor Schema-Based Mobile Robot Navigation. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 8(4) </volume> <pages> 92-112. </pages>
Reference-contexts: These representations model the environment and the effects of the agent's actions in that environment, and provide a basis for selecting appropriate actions in a possibly unfamiliar environment. SINS uses schema-based reactive control for fast performance <ref> (Arkin, 1989) </ref>, augmented with multistrategy learning methods that allow the system to adapt to novel environments and to learn from its experiences (see figure 1).
Reference: <author> Birnbaum, L. </author> <year> (1986). </year> <title> Integrated Processing in Planning and Understanding. </title> <type> Ph.D. thesis, Research Report #489, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT. </address>
Reference: <author> Black, J.B. & Seifert, </author> <title> C.M. (1981). The Psychological Study of Story Understanding. </title> <type> Technical Report #18, </type> <institution> Yale University, </institution> <address> New Haven, CT. </address>
Reference: <author> Brooks, R. </author> <year> (1986). </year> <title> A Robust Layered Control System for a Mobile Robot. </title> <journal> IEEE Journal of Robotics and Automation, RA-2(1):14-23. </journal>
Reference: <author> Bloch, A. </author> <year> (1963). </year> <title> Men Are Different. </title> <editor> In I. Asimov & G. Conklin, editors, </editor> <title> 50 Short Science Fiction Tales, </title> <publisher> Macmillan Publishing Company, </publisher> <address> New York. </address>
Reference: <author> Carbonell, J.G. </author> <year> (1986). </year> <title> Derivational Analogy: A Theory of Reconstructive Problem Solving and Expertise Acquisition. In R.S. </title> <editor> Michalski, J.G. Carbonell, & T.M. Mitchell, editors, </editor> <booktitle> Machine Learning II: An Artificial Intelligence Approach, </booktitle> <publisher> Morgam Kaufman Publishers, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Carbonell, J.G., Knoblock, C.A., & Minton, S. </author> <year> (1991). </year> <title> PRODIGY: An Integrated Architecture for Planning and Learning. </title> <editor> In K. Van Lehn, editor, </editor> <booktitle> Architectures for Intelligence, </booktitle> <pages> pages 241-278, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Carr, M. </author> <year> (1992). </year> <title> Metacognitive Knowledge as a Predictor of Decomposition Strategy Use. </title> <note> Paper presented at The SouthEast Cognitive Science Conference, abstracted in Technical Report #1, </note> <institution> Cognitive Science Program, Georgia Institute of Technology, </institution> <address> Atlanta, GA. </address>
Reference: <author> Corrigan, R.W. </author> <year> (1979). </year> <title> The World of the Theatre. Scott, </title> <publisher> Fores-man and Company, </publisher> <address> Glenview, IL. </address>
Reference-contexts: The process of understanding the un-understandable involves the extrapolative type of creative conceptual change. A central requirement is the willingness of the reader to suspend his or her disbelief of the material being presented or the assumptions being made about the fictional world <ref> (Corrigan, 1979) </ref>. Consider the ambiguous title of a Larry Niven (1973) story, Flight of the Horse. This phrase could refer to a fleeing horse, a horse on an airplane flight, or to a flying horse.
Reference: <author> Davis, R. </author> <year> (1979). </year> <title> Interactive Transfer of Expertise: Acquisition of New Inference Rules. </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 121-157. </pages>
Reference-contexts: The model is based on observations of human troubleshooting operators and protocol analysis of the data gathered in the test area of an operational electronics assembly manufacturing plant. In Meta-TS, multiple learning methods for knowledge compilation (Anderson, 1989), interactive transfer of expertise <ref> (Davis, 1979) </ref>, postponement (Ram, 1991, 1993), and forgetting are integrated through metacognitive analysis. Experimental results in metacogni-tion also suggest that such analysis can facilitate reasoning and learning (e.g., Alexander, 1992; Carr, 1992; Schneider, 1985; Weinert, 1987).
Reference: <author> Dennett, D. </author> <year> (1987). </year> <title> The Intentional Stance. </title> <publisher> Bradford Books/ MIT Press, </publisher> <address> Boston, </address> <publisher> MA. </publisher> <editor> desJardins, M. </editor> <year> (1992). </year> <title> Goal-Directed Learning: A Decision-Theoretic Model for Deciding What to Learn Next. </title> <booktitle> In Proceedings of the ML-92 Workshop on Machine Discovery, </booktitle> <pages> pages 147-151, </pages> <booktitle> Ninth International Machine Learning Conference, </booktitle> <institution> University of Aberdeen, </institution> <address> Scotland. </address>
Reference-contexts: Although I do not want to suggest that humans have perfect or conscious metacognitive knowledge of, and control over, their learning processes, such a model could be used to take an intentional stance <ref> (Dennett, 1987) </ref> towards a computational theory of multistrategy reasoning, both as a description of human reasoning processes and as a basis for the design of creative AI systems. Meta-TS, for example, implements a computational model of human operators learning to troubleshoot physical devices (Narayanan & Ram, 1992).
Reference: <author> Domeshek, E.A. </author> <year> (1992). </year> <title> Do the Right Thing: A Component Theory for Indexing Stories as Social Advice. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT. </address>
Reference-contexts: For example, a transfer is a generic action. Different types of transfers can be represented as physical (e.g., the PTRANS primitive of Schank, 1972), mental (e.g., MTRANS), and social (e.g., ATRANS). The grid also allows the system to represent emotional and temporal transfers <ref> (see also Domeshek, 1992) </ref>. Concept extrapolation is accomplished by moving around the grid, leading to creative and metaphorical interpretations of known concepts. Each type of movement incurs a cost to the system, depending on the degree to which the concept has been altered.
Reference: <author> Falkenhainer, B. </author> <year> (1987). </year> <title> Scientific Theory Formation through Analogical Inference. </title> <booktitle> In Proceedings of the Fourth Inter national Workshop on Machine Learning, </booktitle> <publisher> Morgan Kaufman Publishers, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Fikes, R.E., Hart, P.E., & Nilsson, N.J. </author> <year> (1972). </year> <title> Learning and Executing Generalized Robot Plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 251-288. </pages>
Reference: <author> Gavelek, J.R. & Raphael, R.E. </author> <year> (1985). </year> <title> Metacognition, Instruction and the Role of Questioning Activities. </title> <editor> In D.L. Forrest-Pressley, G.E. MacKinnon, & T.G. Waller, editors, Metacogni-tion, </editor> <booktitle> Cognition, and Human Performance, </booktitle> <volume> Volume 2 (Instructional Practices), </volume> <pages> pages 103-136, </pages> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Gentner, D. </author> <year> (1989). </year> <title> Mechanisms of Analogical Learning. </title> <editor> In S. Vosniadou & A. Ortony, editors, </editor> <title> Similarity and Analogical Reasoning, </title> <publisher> Cambridge University Press, London. </publisher>
Reference: <author> Goodman, M., Waterman, S., & Alterman, R. </author> <year> (1991). </year> <title> Interactive Reasoning about Spatial Concepts. </title> <booktitle> Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 734-738, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Graesser, A., Golding, J.M., & Long, D.L. </author> <year> (1991). </year> <title> Narrative Representation and Comprehension. </title> <editor> In R. Barr, M.L. Kamil, P. Mosenthal & P.D. Pearson, editors, </editor> <booktitle> Handbook of Reading Research, </booktitle> <volume> volume 2, chapter 8, </volume> <publisher> Longman Publishing Group, </publisher> <address> White Plains, NY. </address>
Reference: <author> Gruber, H.E. </author> <year> (1989). </year> <title> The Evolving Systems Approach to Creative Work. In D.B. </title> <editor> Wallace & H.E. Gruber, editors, </editor> <booktitle> Creative People at Work, </booktitle> <pages> pages 3-24, </pages> <publisher> Oxford University Press, </publisher> <address> New York. </address>
Reference-contexts: Such conceptual change is qualitative; not only do children learn new concepts, the nature of the concepts themselves changes through development. The study of scientific conceptual change is concerned with how new conceptual structures come to replace existing conceptual structures through scientific revolutions (Kuhn, 1962) or through longer-term enterprise <ref> (Gruber, 1989) </ref>. Nersessian (1991) argues that the problem-solving strategies scientists have invented and the representational practices they have developed over the course of the history of science are very sophisticated and refined outgrowths of ordinary reasoning and representational processes. <p> The mechanisms of conceptual change discussed here are an integral part of ordinary reasoning. Creative understanding in ISAAC is not implemented through a separate creativity process, but rather through normal pro cesses of reasoning and learning <ref> (Gruber, 1989) </ref>. Similarly, conceptual change in SINS also occurs through the normal processes of perception and control of action. Everyday reasoning is robust, adaptive, and creative; no special process need be postulated to model or explain these capabilities.
Reference: <author> Hammond, K.J. </author> <year> (1989). </year> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <publisher> Academic Press, </publisher> <address> Boston, MA. </address>
Reference-contexts: The learning methods are based on a combination of ideas from case-based reasoning and learning, which deals with the issue of using past experiences to deal with and learn from novel situations <ref> (e.g., Hammond, 1989) </ref>, and from reinforcement learning, which deals with the issue of updating the content of system's knowledge based on feedback from the environment (e.g., Sutton, 1992).
Reference: <author> Holbrook, J.K., Eiselt, K.P., & Mahesh, K. </author> <year> (1992). </year> <title> A Unified Process Model of Syntactic and Semantic Error Recovery in Sentence Understanding. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 195-200, </pages> <publisher> Lawrence Erlbaum Publishers, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Hunter, L.E. </author> <year> (1990). </year> <title> Planning to Learn. </title> <booktitle> In Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 261-276, </pages> <address> Boston, MA. </address>
Reference-contexts: Other learning goals may be selected based on a higher-level analysis of utility of knowledge and relevance to the system's tasks, such as in ISAAC, Meta-AQUA, IVY <ref> (Hunter, 1990) </ref>, and PAGODA (desJardins, 1992). These systems are better described as goal directed since goals are explicitly represented and used to drive the selection and execution of reasoning and learning strategies (Leake & Ram, 1993; Ram & Cox, 1993; Ram & Hunter, 1992).
Reference: <author> Johnson-Laird, P.N. </author> <year> (1983). </year> <title> Mental Models: Towards a Cognitive Science of Language, Inference, and Consciousness. </title> <publisher> Har-vard University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <editor> Just, </editor> <address> M.A. & Carpenter, P.A. </address> <year> (1992). </year> <title> A Capacity Theory of Comprehension: Individual Differences in Working Memory. </title> <journal> Psychological Review, </journal> <volume> 99(1) </volume> <pages> 122-149. </pages>
Reference-contexts: The reader's environment (the story), knowledge (existing concepts), goals and tasks (e.g., Ram & Hunter, 1992), and cognitive resources available to the processing machinery <ref> (e.g., Just & Carpenter, 1992) </ref> interact to constrain the possible extrapolation to a more manageable level. The story understanding processes in ISAAC are not unique to science fiction stories, of course. Understanding any fictional story requires similar kinds of processing.
Reference: <author> Kaelbling, L. </author> <year> (1986). </year> <title> An Architecture for Intelligent Reactive Systems. </title> <type> Technical Note #400, </type> <institution> SRI International. </institution>
Reference: <author> Keil, F.C. </author> <year> (1989). </year> <title> Concepts, Kinds, and Cognitive Development. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Quine (1977) suggests that early concepts may be more perceptual, being defined inductively using an innate similarity notion or spacing of qualities, and later concepts may become more scientifically sophisticated, conceptual, and theory-embedded <ref> (see also Keil, 1989) </ref>. Quine was interested in the issue of development of natural kinds, but perhaps a similar idea could be used to integrate perceptual and conceptual change in an adult reasoning system. To facilitate integration, it is useful to look at commonalities between the models.
Reference: <author> Koestler, A. </author> <year> (1964). </year> <title> The Act of Creation. </title> <publisher> MacMillan Publishers, </publisher> <address> New York. </address>
Reference-contexts: In addition to aiding in the story comprehension process, the new concepts and theories can also provide a basis for future problem solving in the real world <ref> (e.g., Koestler, 1964) </ref>. For example, reading about a fictitious device may prompt the reader to develop a similar device in the real world, or may help the reader understand a similar device when it is actually encountered at some later point.
Reference: <author> Kolodner, J.L. </author> <year> (1984). </year> <title> Retrieval and Organizational Strategies in Conceptual Memory: A Computer Model. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Kuhn, T.S. </author> <year> (1962). </year> <title> The Structure of Scientific Revolutions, </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, IL. </address>
Reference-contexts: Such conceptual change is qualitative; not only do children learn new concepts, the nature of the concepts themselves changes through development. The study of scientific conceptual change is concerned with how new conceptual structures come to replace existing conceptual structures through scientific revolutions <ref> (Kuhn, 1962) </ref> or through longer-term enterprise (Gruber, 1989). Nersessian (1991) argues that the problem-solving strategies scientists have invented and the representational practices they have developed over the course of the history of science are very sophisticated and refined outgrowths of ordinary reasoning and representational processes.
Reference: <author> Kuipers, B.J. & Byun, Y.-T. </author> <year> (1991). </year> <title> A Robot Exploration and Mapping Strategy Based on a Semantic Hierarchy of Spatial Representations. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <address> 8(1-2):47-63. </address>
Reference: <author> Lakoff, G. & Johnson, M. </author> <year> (1980). </year> <title> Metaphors We Live By. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, IL. </address>
Reference-contexts: For example, many temporal metaphors can be represented as analogies between the physical and temporal columns of the grid <ref> (Lakoff & Johnson, 1980) </ref>. In a sentence such as Time has passed her by, for example, a temporal event is described in physical terms, and an abstract object (time) is described as the agent of the physical action.
Reference: <author> Leake, D. & Ram, A. </author> <year> (1993). </year> <title> Goal-Driven Learning: Fundamental Issues and Symposium Report, </title> <type> Technical Report #85, </type> <institution> Indiana University, Cognitive Science Program, Bloomington, </institution> <note> IN. </note>
Reference-contexts: ISAAC integrates its processes using explicit arbitration and control; thus, conceptual change in ISAAC is guided by the particular needs and goals of the program. SINS, in contrast, learns automatically through its task performance, and thus is better characterized as having an implicit orientation or goal to learn <ref> (Barsalou, discussed in Leake & Ram, 1993) </ref>. The two systems are discussed in more detail below. Constructive conceptual change Many machine learning and conceptual change systems have traditionally been used in problem domains that can be adequately described using discrete, symbolic representations. <p> Some learning goals may be low-level and always active, such as in SINS and NX. These systems can be described as performing goal relevant learning, in that learning is relevant to the overall goals of the system (Thagard) but the system only has an implicit goal to learn <ref> (Barsalou, both discussed in Leake & Ram, 1993) </ref>. Other learning goals may be selected based on a higher-level analysis of utility of knowledge and relevance to the system's tasks, such as in ISAAC, Meta-AQUA, IVY (Hunter, 1990), and PAGODA (desJardins, 1992).
Reference: <author> Lynch, K. </author> <year> (1960). </year> <title> The Image of the City. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <editor> Michalski, R.S. & Tecuci, G. </editor> <year> (1993), </year> <title> editors. Machine Learning: A Multistrategy Approach, </title> <booktitle> Volume IV, </booktitle> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, CA. </address> <note> (In press.) </note> <author> Moorman, K. & Ram, A. </author> <year> (1993). </year> <title> A New Perspective on Story Understanding. </title> <booktitle> In Proceedings of the Thirty-First Southeast ACM Conference, </booktitle> <institution> Birmingham, AL. </institution>
Reference-contexts: Multi-strategy approaches provide the flexibility and power required in practical, real-world domains. There are several methods of integrating multiple learning algorithms into a single system <ref> (see Michalski & Tecuci, 1993) </ref>. One such framework is that used in the Meta-AQUA and Meta-TS systems (Ram & Cox, 1993; Ram, Cox & Narayanan, 1992).
Reference: <author> Murphy, G.L. & Medin, D.L. </author> <year> (1985). </year> <title> The Role of Theories in Conceptual Coherence. </title> <journal> Psychological Review, </journal> <volume> 92 </volume> <pages> 289-316. </pages>
Reference: <author> Narayanan, S. & Ram, A. </author> <year> (1992). </year> <title> Learning to Troubleshoot in Electronics Assembly Manufacturing. </title> <booktitle> In Proceedings of the ML-92 Workshop on Integrated Learning in Real-World Domains, Ninth International Machine Learning Conference, </booktitle> <institution> University of Aberdeen, </institution> <address> Scotland. </address>
Reference-contexts: Meta-TS, for example, implements a computational model of human operators learning to troubleshoot physical devices <ref> (Narayanan & Ram, 1992) </ref>. The model is based on observations of human troubleshooting operators and protocol analysis of the data gathered in the test area of an operational electronics assembly manufacturing plant.
Reference: <author> Neisser, U. </author> <year> (1987), </year> <title> editor. Concepts and Conceptual Development: Ecological and Intellectual Factors in Categorization. </title> <publisher> Cambridge University Press, </publisher> <year> 1987. </year>
Reference-contexts: Keil (1989) argues that systematic belief systems, or theories, are important in developmental conceptual change, and that causal relations are essential and more useful in such theories than other sorts of relations <ref> (see also Neisser, 1987) </ref>. Causal belief systems are critical in extrapolative conceptual change as well since they guide and constrain the creative adaptations performed by the reasoner.
Reference: <author> Nersessian, N.J. </author> <year> (1991). </year> <title> How Do Scientists Think? Capturing the Dynamics of Conceptual Change in Science. </title> <editor> In R.N. Giere, editor, </editor> <booktitle> Minnesota Studies in the Philosophy of Science, Volume XV (Cognitive Models of Science), </booktitle> <publisher> University of Minnesota Press, </publisher> <address> Minneapolis, MN. </address>
Reference-contexts: Similarly, the representations constructed through extrapolative and constructive conceptual change also embody such explanations (albeit not always correct ones). Analogy and mental modelling play a crucial role in theories of scientific conceptual change <ref> (e.g., Nersessian, 1991) </ref>, and in extrapolative conceptual change as well. All these types of con-ceptual change rely both on inductive and analytical reasoning processes, though sometimes to different extents.
Reference: <author> Nisbett, R.E. & Wilson, T.D. </author> <year> (1977). </year> <title> Telling More Than We Can Know: Verbal Reports on Mental Processes. </title> <journal> Psychological Review, </journal> <volume> 84(3). </volume>
Reference-contexts: Metacontrol is responsible for integration of the other su-pertasks, and for focus of attention, time management, and suspension of disbelief. Since it is unreasonable to assume that the system would have complete metacognitive access to all its internal processes <ref> (Nisbett & Wilson, 1977) </ref>, metacontrol and metareasoning operate on supertasks and do not access the individual tasks directly. The supertasks in turn control the individual tasks that they are responsible for.
Reference: <author> Niven, L. </author> <year> (1973). </year> <title> The Flight of the Horse. </title> <publisher> Ballantine Books, </publisher> <address> New York. </address>
Reference: <author> Payton, D. </author> <year> (1986). </year> <title> An Architecture for Reflexive Autonomous Vehicle Control. </title> <booktitle> In Proceedings of the 1986 IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 1838-1845, </pages> <publisher> IEEE. </publisher>
Reference: <author> Piaget, J. & Inhelder, B. </author> <year> (1967). </year> <title> The Child's Conception of Space. </title> <publisher> Norton Publishers, </publisher> <address> New York. </address>
Reference: <author> Pinto, J., Shrager, J. & Berthenthal, B.I. </author> <year> (1992). </year> <title> Developmental Changes in Infants' Perceptual Processing of Biomechanical Motions. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 60-65, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Pratchett, T. </author> <year> (1983). </year> <title> The Colour of Magic. </title> <publisher> Penguin Books, </publisher> <address> New York. </address>
Reference: <author> Quine, W.V.O. </author> <year> (1977). </year> <title> Natural Kinds. In S.P. Schwarts, editor, Naming, Necessity, and Natural Kinds, </title> <publisher> Cornell University Press, </publisher> <address> Ithaca, NY. </address>
Reference: <author> Ram, A. </author> <year> (1990). </year> <title> Knowledge Goals: A Theory of Interestingness. </title> <booktitle> In Proceedings of the Twelvth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 206-214, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Ram, A. </author> <year> (1991). </year> <title> A Theory of Questions and Question Asking. </title> <journal> The Journal of the Learning Sciences, </journal> 1(3&4):273-318. 
Reference-contexts: The model is based on observations of human troubleshooting operators and protocol analysis of the data gathered in the test area of an operational electronics assembly manufacturing plant. In Meta-TS, multiple learning methods for knowledge compilation (Anderson, 1989), interactive transfer of expertise (Davis, 1979), postponement <ref> (Ram, 1991, 1993) </ref>, and forgetting are integrated through metacognitive analysis. Experimental results in metacogni-tion also suggest that such analysis can facilitate reasoning and learning (e.g., Alexander, 1992; Carr, 1992; Schneider, 1985; Weinert, 1987).
Reference: <author> Ram, A. </author> <year> (1993). </year> <title> Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases. </title> <journal> Machine Learning, </journal> <volume> 10 </volume> <pages> 201-248. </pages> <note> (In press.) </note> <author> Ram, A. & Cox, </author> <title> M.T. (1993). Introspective Reasoning using Meta-Explanations for Multistrategy Learning. In R.S. </title> <editor> Michal-ski & G. Tecuci, editors, </editor> <title> Machine Learning: A Multistrategy Approach, </title> <booktitle> Volume IV, </booktitle> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Ma-teo, CA. </address> <note> (In press.) </note> <author> Ram, A., Cox, M.T., & Narayanan, S. </author> <year> (1992). </year> <title> An Architecture for Integrated Introspective Learning. </title> <booktitle> In Proceedings of the ML-92 Workshop on Computational Architectures for Supporting Machine Learning and Knowledge Acquisition, Ninth Interna--tional Machine Learning Conference, </booktitle> <institution> University of Aberdeen, </institution> <address> Scotland. </address>
Reference-contexts: Case studies in creative conceptual change The computer programs presented here serve as case studies of constructive and extrapolative processes in conceptual change. The first program, called SINS (Self-Improving Navigation System) is an autonomous robotic navigation system that learns to navigate in an obstacle-ridden world <ref> (Ram & Santamaria, 1993) </ref>. Autonomous robotic navigation is the task of finding a path along which a robot can physically move through a given environment and then executing the actions to carry out the movement in a real or simulated world. <p> The second case study is based on a computer program called ISAAC (Integrated Story Analysis And Comprehension), which is a natural language understanding system that reads short stories from the science fiction genre <ref> (Moorman & Ram, 1993) </ref>. Such stories require creative understanding, in which the reader must learn enough about an alien world in a short text in order to accept it as the background for the story, and simultaneously must understand the story itself. <p> ISAAC integrates its processes using explicit arbitration and control; thus, conceptual change in ISAAC is guided by the particular needs and goals of the program. SINS, in contrast, learns automatically through its task performance, and thus is better characterized as having an implicit orientation or goal to learn <ref> (Barsalou, discussed in Leake & Ram, 1993) </ref>. The two systems are discussed in more detail below. Constructive conceptual change Many machine learning and conceptual change systems have traditionally been used in problem domains that can be adequately described using discrete, symbolic representations. <p> The system is very robust and can perform successfully in (and learn from) novel environments without any user intervention or supervisory input, yet it compares favorably with traditional reactive methods in terms of speed and performance <ref> (Ram & Santamaria, 1993) </ref>. Furthermore, the system designers do not need to foresee and represent all the possibilities that might occur since the system develops its own understanding of the world and its actions. <p> As I argued earlier, these considerations are not unique to science fiction stories; even factual stories (such as newspaper stories) in domains that are not completely understood may require the system to consider the possibility that its current understanding of the domain is incomplete or incorrect <ref> (e.g., Ram, 1993) </ref>. To understand concepts which do not fit into a standard world view, the system attempts to modify existing concepts (Schank, 1986). This usually involves extending or adapting not just a single concept, but systems of conceptsthat is, theories. This modification can occur in several ways. <p> Some learning goals may be low-level and always active, such as in SINS and NX. These systems can be described as performing goal relevant learning, in that learning is relevant to the overall goals of the system (Thagard) but the system only has an implicit goal to learn <ref> (Barsalou, both discussed in Leake & Ram, 1993) </ref>. Other learning goals may be selected based on a higher-level analysis of utility of knowledge and relevance to the system's tasks, such as in ISAAC, Meta-AQUA, IVY (Hunter, 1990), and PAGODA (desJardins, 1992).
Reference: <author> Ram, A. & Hunter, L. </author> <year> (1992). </year> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning. </title> <journal> Applied Intelligence, </journal> <volume> 2(1) </volume> <pages> 47-73. </pages>
Reference-contexts: No reader, machine or human, could have the time, memory, and other resources to read every single word in a story in-depth and to consider all the ramifications of each word. The reader's environment (the story), knowledge (existing concepts), goals and tasks <ref> (e.g., Ram & Hunter, 1992) </ref>, and cognitive resources available to the processing machinery (e.g., Just & Carpenter, 1992) interact to constrain the possible extrapolation to a more manageable level. The story understanding processes in ISAAC are not unique to science fiction stories, of course. <p> Meta-TS, for example, implements a computational model of human operators learning to troubleshoot physical devices <ref> (Narayanan & Ram, 1992) </ref>. The model is based on observations of human troubleshooting operators and protocol analysis of the data gathered in the test area of an operational electronics assembly manufacturing plant.
Reference: <author> Ram, A. & Santamaria, J.C. </author> <year> (1993). </year> <title> A Multistrategy Case-Based and Reinforcement Learning Approach to Self-Improving Reactive Control Systems for Autonomous Robotic Navigation. </title> <booktitle> In Proceedings of the Second International Workshop on Mul-tistrategy Learning, Center for Artificial Intelligence, </booktitle> <institution> George Mason University, Fairfax, VA. </institution> <note> (To appear.) </note> <author> Rumelhart, D.E. </author> <year> (1977). </year> <title> Understanding and Summarizing Brief Stories. </title> <editor> In D.L. Berge and J. Samuels, editors, </editor> <title> Basic Processes in Reading and Comprehension, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference-contexts: Case studies in creative conceptual change The computer programs presented here serve as case studies of constructive and extrapolative processes in conceptual change. The first program, called SINS (Self-Improving Navigation System) is an autonomous robotic navigation system that learns to navigate in an obstacle-ridden world <ref> (Ram & Santamaria, 1993) </ref>. Autonomous robotic navigation is the task of finding a path along which a robot can physically move through a given environment and then executing the actions to carry out the movement in a real or simulated world. <p> The second case study is based on a computer program called ISAAC (Integrated Story Analysis And Comprehension), which is a natural language understanding system that reads short stories from the science fiction genre <ref> (Moorman & Ram, 1993) </ref>. Such stories require creative understanding, in which the reader must learn enough about an alien world in a short text in order to accept it as the background for the story, and simultaneously must understand the story itself. <p> ISAAC integrates its processes using explicit arbitration and control; thus, conceptual change in ISAAC is guided by the particular needs and goals of the program. SINS, in contrast, learns automatically through its task performance, and thus is better characterized as having an implicit orientation or goal to learn <ref> (Barsalou, discussed in Leake & Ram, 1993) </ref>. The two systems are discussed in more detail below. Constructive conceptual change Many machine learning and conceptual change systems have traditionally been used in problem domains that can be adequately described using discrete, symbolic representations. <p> The system is very robust and can perform successfully in (and learn from) novel environments without any user intervention or supervisory input, yet it compares favorably with traditional reactive methods in terms of speed and performance <ref> (Ram & Santamaria, 1993) </ref>. Furthermore, the system designers do not need to foresee and represent all the possibilities that might occur since the system develops its own understanding of the world and its actions. <p> As I argued earlier, these considerations are not unique to science fiction stories; even factual stories (such as newspaper stories) in domains that are not completely understood may require the system to consider the possibility that its current understanding of the domain is incomplete or incorrect <ref> (e.g., Ram, 1993) </ref>. To understand concepts which do not fit into a standard world view, the system attempts to modify existing concepts (Schank, 1986). This usually involves extending or adapting not just a single concept, but systems of conceptsthat is, theories. This modification can occur in several ways. <p> Some learning goals may be low-level and always active, such as in SINS and NX. These systems can be described as performing goal relevant learning, in that learning is relevant to the overall goals of the system (Thagard) but the system only has an implicit goal to learn <ref> (Barsalou, both discussed in Leake & Ram, 1993) </ref>. Other learning goals may be selected based on a higher-level analysis of utility of knowledge and relevance to the system's tasks, such as in ISAAC, Meta-AQUA, IVY (Hunter, 1990), and PAGODA (desJardins, 1992).
Reference: <author> Sacerdoti, E.D. </author> <year> (1975). </year> <title> A Structure for Plans and Behavior. </title> <note> Technical Note #109, SRI International. Summarized in P.R. </note>
Reference: <editor> Cohen & E.A. Feigenbaum, </editor> <booktitle> Handbook of AI, Volume III, </booktitle> <pages> pages 541-550. </pages>
Reference: <author> Schank, R.C. </author> <year> (1972). </year> <title> Conceptual Dependency: A Theory of Natural Language Understanding. </title> <journal> Cognitive Psychology, </journal> <volume> 3(4) </volume> <pages> 552-631. </pages>
Reference-contexts: The columns of the grid represent conceptual domains, such as physical, mental, social, emotional, and temporal. For example, a transfer is a generic action. Different types of transfers can be represented as physical <ref> (e.g., the PTRANS primitive of Schank, 1972) </ref>, mental (e.g., MTRANS), and social (e.g., ATRANS). The grid also allows the system to represent emotional and temporal transfers (see also Domeshek, 1992). Concept extrapolation is accomplished by moving around the grid, leading to creative and metaphorical interpretations of known concepts.
Reference: <author> Schank, R.C. </author> <year> (1982). </year> <title> Dynamic Memory: A Theory of Learning in Computers and People. </title> <publisher> Cambridge University Press, </publisher> <address> New York. </address>
Reference: <author> Schank, R.C. </author> <year> (1986). </year> <title> Explanation Patterns: Understanding Mechanically and Creatively. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference-contexts: To understand concepts which do not fit into a standard world view, the system attempts to modify existing concepts <ref> (Schank, 1986) </ref>. This usually involves extending or adapting not just a single concept, but systems of conceptsthat is, theories. This modification can occur in several ways. Definitional constraints may be relaxed to produce concepts with alternative constraints.
Reference: <author> Schank, </author> <title> R.C. & Leake, D.B. (1990). Creativity and Learning in a Case-Based Explainer. </title> <editor> In J.G. Carbonell, editor, </editor> <title> Machine Learning: Paradigms and Methods, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Schneider, W. </author> <year> (1985). </year> <title> Developmental Trends in the Metamemory-Memory Behavior Relationship: An Integrative Review. </title> <editor> In D.L. Forrest-Pressley, G.E. MacKinnon, & T.G. Waller, editors, Metacognition, </editor> <booktitle> Cognition, and Human Performance, </booktitle> <volume> Volume 1, </volume> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Siegel, A.W. & White, S.H. </author> <year> (1975). </year> <title> The Development of Spatial Representations of Large-Scale Environments. In H.W. Reese, editor, Advances in Child Development and Behavior, </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Sutton, R.S. </author> <year> (1992), </year> <title> editor. </title> <journal> Machine Learning, </journal> <note> 8(3/4), special issue on Reinforcement Learning. </note>
Reference-contexts: combination of ideas from case-based reasoning and learning, which deals with the issue of using past experiences to deal with and learn from novel situations (e.g., Hammond, 1989), and from reinforcement learning, which deals with the issue of updating the content of system's knowledge based on feedback from the environment <ref> (e.g., Sutton, 1992) </ref>. Each case in SINS represents an observed regularity between a particular environmental configuration and the effects of different actions, and prescribes the values of the control parameters that are most appropriate (as far as the system can determine based on its previous experience) for that environment.
Reference: <author> Turner, S.R. </author> <year> (1991). </year> <title> A Case-Based Model of Creativity. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 933-937, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address> <publisher> van Dijk, T.A. & Kintsch, W. </publisher> <year> (1983). </year> <title> Strategies of Discourse Comprehension. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Weinert, F.E. </author> <year> (1987). </year> <title> Introduction and Overview: Metacog-nition and Motivation as Determinants of Effective Learning and Understanding. In F.E. Weinert & R.H. </title> <editor> Kluwe, editors, Metacognition, </editor> <title> Motivation, and Understanding, </title> <publisher> Lawrence Erl-baum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Wellman, H.M. </author> <year> (1985). </year> <note> The Origins of Metacognition. In D.L. </note>
Reference: <author> Forrest-Pressley, G.E. MacKinnon, & T.G. Waller, </author> <title> editors, </title> <journal> Metacognition, Cognition, and Human Performance, </journal> <volume> Volume 1, </volume> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Wisniewski, E.J. & Medin, D.L. </author> <year> (1991). </year> <title> Harpoons and Long Sticks: The Interaction of Theory and Similarity in Rule Induction. </title> <editor> In D. Fisher & M.J. Pazzani, editors, </editor> <title> Concept Formation: Knowledge and Experience in Unsupervised Learning, </title> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, CA. </address>
References-found: 67

