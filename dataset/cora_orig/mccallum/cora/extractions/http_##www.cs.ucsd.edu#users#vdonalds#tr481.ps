URL: http://www.cs.ucsd.edu/users/vdonalds/tr481.ps
Refering-URL: http://www.cs.ucsd.edu/users/vdonalds/
Root-URL: http://www.cs.ucsd.edu
Email: fvdonalds,ferranteg@cs.ucsd.edu  
Title: Determining Asynchronous Pipeline Execution Times  
Author: Val Donaldson and Jeanne Ferrante 
Address: La Jolla, California 92093-0114  
Affiliation: Computer Science and Engineering Department University of California, San Diego  
Abstract: Technical Report CS96-481, CSE Dept., UCSD, April 1996 Abstract Asynchronous pipelining is a form of parallelism in which processors execute different loop tasks (loop statements) as opposed to different loop iterations. An asynchronous pipeline schedule for a loop is an assignment of loop tasks to processors, plus an order on instances of tasks assigned to the same processor. This variant of pipelining is particularly relevant in distributed memory systems (since pipeline control may be distributed across processors), but may also be used in shared memory systems. Accurate estimation of the execution time of a pipeline schedule is needed to determine if pipelining is appropriate for a loop, and to compare alternative schedules. Pipeline execution of n iterations of a loop requires time at most a + bn, for some constants a and b. The coefficient b is the iteration interval of the pipeline schedule, and is the primary measure of the performance of a schedule. The startup time a is a secondary performance measure. We generalize previous work on determining if a pipeline schedule will deadlock, and generalize Reiter's well-known formula [21] for determining the iteration interval b of a deadlock-free schedule, to account for nonzero communication times (easy) and the assignment of multiple tasks to processors (nontrivial). Two key components of our generalization are the use of pipeline scheduling edges, and the notion of negative data dependence distances (in a single unnested loop). We also discuss implementation of an asynchronous pipeline schedule at runtime; show how to efficiently simulate pipeline execution on a sequential processor; derive bounds on the startup time a; and discuss evaluation of the iteration interval formula, including development of a new algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alexander Aiken and Alexandru Nicolau. </author> <title> Optimal loop parallelization. </title> <booktitle> Proc. SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> pp. 308-317. </pages>
Reference-contexts: Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. Examples include instruction and vector pipelining in hardware [14], and software pipelining <ref> [1, 16] </ref>, where assembly language instructions from multiple loop iterations are scheduled to reduce the number of hardware pipeline delays, or to increase instruction level parallelism. These forms of pipelining are fine-grained, with pipeline tasks executing in a small number of discrete time units. <p> We use this sequence specification to add scheduling edges to G as follows. For each i 2 <ref> [1; k 1] </ref>, create a scheduling edge (X i ; X i+1 ), with (X i ; X i+1 ):dist = s i s i+1 . <p> Proof (a) For i 2 <ref> [1; k 1] </ref>, let (X i ; X i+1 ) be an edge in c. By definition, (X i ; X i+1 ):dist = s i s i+1 . <p> Working "backwards" from c to a sequence specification, we can arbitrarily choose task X i as the first task in the task order, for any i 2 <ref> [1; k] </ref>, as well as any arbitrary stage assignment X i :stage for this first task. An arbitrary value for X:stage can be specified as X i :stage = s i + d, for some integer d = X i :stage s i . <p> For j 2 <ref> [1; p] </ref>, let hX j;1 : X j;1 :sdist; X j;2 : X j;2 :sdist; : : : ; X j;k j : X j;k j :sdisti be the sequence specification obtained from the sequential sequence specification by deleting all tasks which are not contained in the jth scheduling cycle.
Reference: [2] <author> Sati Banerjee, Takeo Hamada, Paul M. Chau, and Ronald D. Fellman. </author> <title> Macro pipelining based scheduling on high performance heterogeneous multiprocessor systems. </title> <journal> IEEE Transactions on Signal Processing 43:8 (June 1995), </journal> <pages> pp. 1468-1484. </pages>
Reference-contexts: Application program loops may also be pipelined on multiprocessors or multicomputers. This form of pipelining is sometimes referred to as macropipelining, and has been studied particularly in the context of digital signal processing algorithms <ref> [2, 12] </ref>, although it has been considered in other contexts as well [3, 23]. <p> The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems <ref> [2, 12, 23] </ref> use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula [21]. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. <p> Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph [15, 16], dependence graph [10], flow graph [12], signal flow graph <ref> [2] </ref>, iterative task graph [23], collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. <p> Borrowing and expanding on terminology from <ref> [2] </ref>, when a processor has multiple tasks assigned to it, we say it is a shared processor, and any task assigned to a shared processor is a sharing task. <p> There need not necessarily be any direct relationship between the stage values or execution times of tasks on different processors. Pipeline scheduling algorithms from the literature specify schedules in terms specific to a particular algorithm. In our terminology, the pipeline scheduling algorithms in <ref> [2, 12] </ref> assign all tasks sharing the same processor to the same stage, which can therefore be assigned any arbitrary value (either zero or the "current" stage number are logical choices). The order in which tasks are assigned to a processor is the corresponding task order. <p> For this example, we use "processor A" to denote the processor executing task A, and similarly for task B. 9 (a) A :1 ! B :1 <ref> [2] </ref> (c) A :1 ! B :1 [-2] dependence distances. <p> Theorem 10 (deadlock characterization) may be applied to show that a pipeline scheduling algorithm produces schedules which are free of deadlock. Theorem 11 (iteration interval determination) may be applied to precisely determine the iteration interval of schedules derived from existing scheduling algorithms <ref> [2, 12, 23] </ref>.
Reference: [3] <author> Adam Beguelin, Jack J. Dongarra, G. A. Geist, Robert Manchek, and V. S. Sunderam. </author> <title> Graphical development tools for network-based concurrent supercomputing. </title> <booktitle> Proc. Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991, </year> <pages> pp. 435-444. </pages>
Reference-contexts: Application program loops may also be pipelined on multiprocessors or multicomputers. This form of pipelining is sometimes referred to as macropipelining, and has been studied particularly in the context of digital signal processing algorithms [2, 12], although it has been considered in other contexts as well <ref> [3, 23] </ref>. Tasks may be of arbitrary size, from simple statements to complex compound statements or subroutine calls. 1 Task execution times may vary from iteration to iteration, although we assume that there is an expected execution time for each task.
Reference: [4] <author> Steven M. Burns. </author> <title> Performance analysis and optimization of asynchronous circuits. </title> <type> Ph.D. Thesis, </type> <institution> Cali-fornia Institute of Technology, Pasadena, California, </institution> <year> 1991. </year>
Reference-contexts: be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph [15, 16], dependence graph [10], flow graph [12], signal flow graph [2], iterative task graph [23], collapsed-constraint graph <ref> [4] </ref>, and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. <p> Dantzig et al. [7] formulated an equivalent problem as a linear programming problem, and derived the first known algorithm for the problem using the simplex method. Burns <ref> [4] </ref> used a linear programming formulation to design a primal-dual algorithm, which in practice appears to run in O (ev) time.
Reference: [5] <author> F. Commoner, A. W. Holt, S. Even, and A. Pnueli. </author> <title> Marked directed graphs. </title> <journal> Journal of Computer and System Sciences 5:5 (October 1971), </journal> <pages> pp. 511-523. </pages>
Reference-contexts: We summarize our conclusions in Section 10. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph <ref> [5] </ref>, dataflow graph [15, 16], dependence graph [10], flow graph [12], signal flow graph [2], iterative task graph [23], collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. <p> Some authors implicitly assume the following theorem on deadlock; explicit discussion and a proof can be found in <ref> [5] </ref> (see also [15]). <p> Therefore, the maximum such ratio over all cycles is a lower bound on b. Further, this lower bound can be achieved, except when G:vmax is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [5, 12, 15, 20] </ref>. Our statement of the result borrows from the discussion in several of these papers. <p> The retiming process has an operational interpretation of "executing a few initial instances of specified DDG tasks," and is similar to the movement of tokens in dataflow graphs <ref> [5, 15] </ref>. For our purposes, the basic step in retiming a DDG G is leading a task X by one iteration.
Reference: [6] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: To solve this problem, we can borrow the notion of retiming from the literature on systolic networks [18, Section 1.4] (see also the discussion of reweighting in <ref> [6, Section 26.3] </ref>), to transform a DDG G with edges with negative dependence distances into a nonnegative DDG G 0 with an equivalent iteration interval. <p> The null path from X to itself puts an upper bound on this value, so X:sdist 0 (and G:min sdist 0 as well). X:sdist values can be found in O (ev) time by solving a single-source shortest paths problem <ref> [6] </ref>. Specifically, a new source vertex X s may be created, with edges from X s to all original tasks with dependence distances of zero. X:sdist is then the shortest path from X s to X, using dependence distances as edge weights. <p> All jCj simple cycles in a graph can be enumerated in O (jCj (e + v)) time [13], but there are v1 X v i + 1 (v i)! simple cycles in a complete directed graph (not a multigraph) with v vertices [13]. Since v! = !(2 v ) <ref> [6] </ref>, evaluation of the maximum cycle ratio by explicit enumeration of all cycles is only feasible if it is known that the DDG has only a few cycles. 9.2 Binary Search Algorithm Lawler [17, Section 3.13] describes a technique for computing the maximum cycle ratio of a DDG G by looking <p> Longest paths between vertices in a graph are not well-defined if the graph contains a positive weight cycle, so general single-source longest path algorithms such as the O (ev) Bellman-Ford algorithm <ref> [6] </ref>, detect the existence of positive cycles as a necessary precondition or side-effect of the search for longest paths. (Bellman-Ford and other similar algorithms are usually referred to as shortest path algorithms, but are equally applicable as longest path algorithms.) Therefore, any given value of b fl can be compared to <p> If G b fl has one or more positive cycles, an augmented version of the Bellman-Ford algorithm can be used to find one. When longest paths are well-defined, the Bellman-Ford algorithm can explicitly enumerate the vertices in a longest path by constructing a predecessor subgraph <ref> [6] </ref>. The same technique can be used to explicitly identify a positive cycle, by following predecessor links until a cycle is found in O (v) time. <p> The ratio for this cycle can then be calculated in O (v) time, and this value can be used as the next value of b fl . As a heuristic, we can start the search for a positive cycle at the task which has the largest "relaxation delta" <ref> [6] </ref> in the cycle checking pass. The primary question with this approach is: How many b fl trial values must be checked before b is found? To address this question, we implemented the monotonic search algorithm using the O (ev) Bellman-Ford algorithm as the longest path subalgorithm.
Reference: [7] <author> G.B. Dantzig, W.O. Blattner, and M.R. Rao. </author> <title> Finding a cycle in a graph with minimum cost to time ratio with application to a ship routing problem. </title> <editor> In P. Rosenstiehl (Ed.), </editor> <booktitle> Theory of Graphs, </booktitle> <address> Dunod, Paris, </address> <publisher> and Gordon and Breach, </publisher> <address> New York, NY, </address> <year> 1967, </year> <pages> pp. 77-83. </pages>
Reference-contexts: Further, if a DDG is generated by pipeline scheduling algorithms such as those in [10, 23], it may be possible to implicitly perform the retiming step without incurring the graph transformation cost. Dantzig et al. <ref> [7] </ref> formulated an equivalent problem as a linear programming problem, and derived the first known algorithm for the problem using the simplex method. Burns [4] used a linear programming formulation to design a primal-dual algorithm, which in practice appears to run in O (ev) time.
Reference: [8] <author> Val Donaldson and Jeanne Ferrante. </author> <title> Determining asynchronous acyclic pipeline execution times. </title> <booktitle> Proc. 10th International Parallel Processing Symposium, </booktitle> <address> Honolulu, HI, </address> <month> April </month> <year> 1996, </year> <pages> pp. 568-572. </pages>
Reference-contexts: The algorithm in <ref> [8] </ref> assumes that the DDG is a task graph, which is a DDG in which all dependence distances are uniformly zero, and also assumes that processors are not shared. <p> With the exception of <ref> [8] </ref>, which restricts the form of a DDG and does not allow processor sharing, previous work has not addressed the issue of determining a value for a, in part because the iteration interval b was not known. <p> DDG's for which a fl overestimated a by a larger multiple of b were all small granularity DDG's, with large communication to computation ratios, and the time required to produce the first pipeline result was much larger than b. It might be possible to borrow techniques from <ref> [8] </ref> to get a more accurate value for a fl . a fl + bn is an upper bound on G:time n , the execution time of n iterations of a DDG G.
Reference: [9] <author> Harold N. Gabow and Robert E. Tarjan. </author> <title> Faster scaling algorithms for network problems. </title> <journal> SIAM Journal on Computing 18:5 (October 1989), </journal> <pages> pp. 1013-1036. </pages>
Reference-contexts: This same general approach is also used in [23], but with the accuracy specified by a parameter *, such that b is approximated as *d b * e (0:5 is used as an example value for *). Additionally, since b is only approximated, the longest path algorithm in <ref> [9] </ref> can be used, which uses scaling to find approximate longest paths. The approximation of b is then found in O (e p v log 2 vG:vmax * ) time. 9.3 Monotonic Search Algorithm There are two drawbacks to the binary search algorithm.
Reference: [10] <author> Franco Gasperoni and Uwe Schwiegelshohn. </author> <title> Scheduling loops on parallel processors: a simple algorithm with close to optimum performance. </title> <booktitle> Second Joint International Conference on Vector and Parallel Processing (Parallel Processing: CONPAR 92-VAPP V), </booktitle> <address> Lyon, France, </address> <month> September </month> <year> 1992, </year> <pages> pp. 625-636. </pages>
Reference-contexts: in Section 10. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph [15, 16], dependence graph <ref> [10] </ref>, flow graph [12], signal flow graph [2], iterative task graph [23], collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. <p> The order in which tasks are assigned to a processor is the corresponding task order. The scheduling algorithm of <ref> [10] </ref> generates a noniterative task graph schedule " a " which provides a processor assignment and a task order for each processor. Stage assignments are given by the "" function. The algorithm in [23] is a generalization of the algorithm in [10]. <p> The scheduling algorithm of <ref> [10] </ref> generates a noniterative task graph schedule " a " which provides a processor assignment and a task order for each processor. Stage assignments are given by the "" function. The algorithm in [23] is a generalization of the algorithm in [10]. <p> The second question concerns search termination: How can it be determined that the current smallest b fl value such that G b fl has no positive cycles is the actual value of b? One solution is to settle for a conservative approximation of b. In <ref> [10] </ref>, the search is confined to integral values, and b is approximated as dbe. Using the Bellman-Ford algorithm as a subroutine, the resulting binary search algorithm runs in O (ev log G:vtime) time. <p> When this is the case, Lemma 5 can be used transform a general DDG into a nonnegative DDG with an equivalent maximum cycle ratio, in O (ev) time. Further, if a DDG is generated by pipeline scheduling algorithms such as those in <ref> [10, 23] </ref>, it may be possible to implicitly perform the retiming step without incurring the graph transformation cost. Dantzig et al. [7] formulated an equivalent problem as a linear programming problem, and derived the first known algorithm for the problem using the simplex method.
Reference: [11] <author> Mark Hartmann and James B. Orlin. </author> <title> Finding minimum cost to time ratio cycles with small integral transit times. </title> <booktitle> Networks 23:6 (September 1993), </booktitle> <pages> pp. 567-74. </pages>
Reference-contexts: If X:max dist is the largest dependence distance of any edge directed out of a task X in a DDG G, and G:max dist = P X X:max dist, the algorithm of Hartmann and Orlin <ref> [11] </ref> will find the maximum cycle ratio of G in O (eG:max dist) time. (G:max dist is an upper bound on the sum of dependence distances in any simple cycle.) Hartmann and Orlin also provide references for several additional algorithms.
Reference: [12] <author> Phu D. Hoang and Jan M. Rabaey. </author> <title> Scheduling of DSP programs onto multiprocessors for maximum throughput. </title> <journal> IEEE Transactions on Signal Processing 41:6 (June 1993), </journal> <pages> pp. 2225-2235. </pages>
Reference-contexts: Application program loops may also be pipelined on multiprocessors or multicomputers. This form of pipelining is sometimes referred to as macropipelining, and has been studied particularly in the context of digital signal processing algorithms <ref> [2, 12] </ref>, although it has been considered in other contexts as well [3, 23]. <p> The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems <ref> [2, 12, 23] </ref> use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula [21]. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. <p> 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph [15, 16], dependence graph [10], flow graph <ref> [12] </ref>, signal flow graph [2], iterative task graph [23], collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. <p> Therefore, the maximum such ratio over all cycles is a lower bound on b. Further, this lower bound can be achieved, except when G:vmax is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [5, 12, 15, 20] </ref>. Our statement of the result borrows from the discussion in several of these papers. <p> There need not necessarily be any direct relationship between the stage values or execution times of tasks on different processors. Pipeline scheduling algorithms from the literature specify schedules in terms specific to a particular algorithm. In our terminology, the pipeline scheduling algorithms in <ref> [2, 12] </ref> assign all tasks sharing the same processor to the same stage, which can therefore be assigned any arbitrary value (either zero or the "current" stage number are logical choices). The order in which tasks are assigned to a processor is the corresponding task order. <p> A natural question to ask is: If a DDG contains cycles, can the maximum cycle ratio be computed efficiently? 9.1 Cycle Enumeration Algorithm A straightforward approach, used in <ref> [12] </ref>, is to enumerate all simple cycles, and explicitly calculate the value of the maximum cycle ratio. <p> Theorem 10 (deadlock characterization) may be applied to show that a pipeline scheduling algorithm produces schedules which are free of deadlock. Theorem 11 (iteration interval determination) may be applied to precisely determine the iteration interval of schedules derived from existing scheduling algorithms <ref> [2, 12, 23] </ref>.
Reference: [13] <author> Donald B. Johnson. </author> <title> Finding all the elementary circuits of a directed graph. </title> <journal> SIAM Journal on Computing 4:1 (March 1975), </journal> <pages> pp. 77-84. </pages>
Reference-contexts: All jCj simple cycles in a graph can be enumerated in O (jCj (e + v)) time <ref> [13] </ref>, but there are v1 X v i + 1 (v i)! simple cycles in a complete directed graph (not a multigraph) with v vertices [13]. <p> All jCj simple cycles in a graph can be enumerated in O (jCj (e + v)) time <ref> [13] </ref>, but there are v1 X v i + 1 (v i)! simple cycles in a complete directed graph (not a multigraph) with v vertices [13].
Reference: [14] <author> Peter M. Kogge. </author> <title> The Architecture of Pipelined Computers. </title> <publisher> Hemisphere Publishing, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. Examples include instruction and vector pipelining in hardware <ref> [14] </ref>, and software pipelining [1, 16], where assembly language instructions from multiple loop iterations are scheduled to reduce the number of hardware pipeline delays, or to increase instruction level parallelism. These forms of pipelining are fine-grained, with pipeline tasks executing in a small number of discrete time units.
Reference: [15] <author> S. Y. Kung, P. S. Lewis, and S. C. Lo. </author> <title> Performance analysis and optimization of VLSI dataflow arrays. </title> <journal> Journal of Parallel and Distributed Computing 4:6 (December 1987), </journal> <pages> pp. 592-618. 22 </pages>
Reference-contexts: We summarize our conclusions in Section 10. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph <ref> [15, 16] </ref>, dependence graph [10], flow graph [12], signal flow graph [2], iterative task graph [23], collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. <p> Some authors implicitly assume the following theorem on deadlock; explicit discussion and a proof can be found in [5] (see also <ref> [15] </ref>). Theorem 1 Pipeline execution of a nonnegative DDG G with zero communication times and without processor sharing is free of deadlock iff G satisfies the positive cycle constraint. 2 4 (a) in the Gantt charts represents execution of instances of a task on a processor dedicated to that task. <p> Therefore, the maximum such ratio over all cycles is a lower bound on b. Further, this lower bound can be achieved, except when G:vmax is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [5, 12, 15, 20] </ref>. Our statement of the result borrows from the discussion in several of these papers. <p> Our statement of the result borrows from the discussion in several of these papers. Theorem 2 could be stated in terms of arbitrary cycles rather than simple cycles, but this is unnecessary since evaluation of the formula for simple cycles is equivalent to evaluation for arbitrary cycles <ref> [15] </ref>. For any cycle c in a DDG, V c is the set of tasks in c, and E c is the set of edges in c. <p> The retiming process has an operational interpretation of "executing a few initial instances of specified DDG tasks," and is similar to the movement of tokens in dataflow graphs <ref> [5, 15] </ref>. For our purposes, the basic step in retiming a DDG G is leading a task X by one iteration.
Reference: [16] <author> Monica Lam. </author> <title> Software pipelining: an effective scheduling technique for VLIW machines. </title> <booktitle> Proc. SIG--PLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> pp. 318-328. </pages>
Reference-contexts: Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. Examples include instruction and vector pipelining in hardware [14], and software pipelining <ref> [1, 16] </ref>, where assembly language instructions from multiple loop iterations are scheduled to reduce the number of hardware pipeline delays, or to increase instruction level parallelism. These forms of pipelining are fine-grained, with pipeline tasks executing in a small number of discrete time units. <p> We summarize our conclusions in Section 10. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph <ref> [15, 16] </ref>, dependence graph [10], flow graph [12], signal flow graph [2], iterative task graph [23], collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed.
Reference: [17] <author> Eugene L. Lawler. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Holt, Rinehart, and Winston, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: Since v! = !(2 v ) [6], evaluation of the maximum cycle ratio by explicit enumeration of all cycles is only feasible if it is known that the DDG has only a few cycles. 9.2 Binary Search Algorithm Lawler <ref> [17, Section 3.13] </ref> describes a technique for computing the maximum cycle ratio of a DDG G by looking for positive cycles in a family of derivative graphs with edge weights.
Reference: [18] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph [15, 16], dependence graph [10], flow graph [12], signal flow graph [2], iterative task graph [23], collapsed-constraint graph [4], and semisystolic network <ref> [18] </ref>, among others. Alternative models such as variations of Petri nets [20] have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. <p> The use of negative dependence distances violates the assumption in Lemma 3 (deadlock characterization) and Lemma 4 (iteration interval determination), that the DDG is a nonnegative DDG. To solve this problem, we can borrow the notion of retiming from the literature on systolic networks <ref> [18, Section 1.4] </ref> (see also the discussion of reweighting in [6, Section 26.3]), to transform a DDG G with edges with negative dependence distances into a nonnegative DDG G 0 with an equivalent iteration interval.
Reference: [19] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM 29:12 (December 1986), </journal> <pages> pp. 1184-1201. </pages>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism <ref> [19] </ref>, which assigns different loop iterations to different processors, or noniterative task (or DAG) parallelism [22, 24], may permit pipeline parallelization. Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. <p> Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. Variants of this data structure have been extensively studied in the optimizing compiler literature under the name data dependence graph <ref> [19] </ref>, which is the name we will use. 2 for i := 1 to n do B [i] := f2 (A [i],E [i-2]); D [i] := f4 (C [i],B [i-1]); endfor defined. Unbracketed numbers in the DDG are execution times, and bracketed numbers are dependence distances.
Reference: [20] <author> C. V. Ramamoorthy and Gary S. Ho. </author> <title> Performance evaluation of asynchronous concurrent systems using Petri nets. </title> <journal> IEEE Transactions on Software Engineering SE-6:5 (September 1980), </journal> <pages> pp. 440-449. </pages>
Reference-contexts: Alternative models such as variations of Petri nets <ref> [20] </ref> have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. <p> Then the iteration interval b and startup time a for pipeline execution of G are b = lim G:time n n a = maxfG:time n bnjn 1g 2 This definition of the iteration interval b, and a proof of the existence of the limit can be found in <ref> [20] </ref> (see also [21]). The iteration interval is the average time between completion of successive iterations of the DDG, and is the primary measure of the performance of a pipeline schedule. We will show how to find b for any pipeline schedule which does not deadlock. <p> Therefore, the maximum such ratio over all cycles is a lower bound on b. Further, this lower bound can be achieved, except when G:vmax is greater than this bound. This result (Theorem 2 below) has been analyzed by a number of authors in addition to Reiter, including <ref> [5, 12, 15, 20] </ref>. Our statement of the result borrows from the discussion in several of these papers.
Reference: [21] <author> Raymond Reiter. </author> <title> Scheduling parallel computations. </title> <journal> Journal of the ACM 15:4 (October 1968), </journal> <pages> pp. 590-599. </pages>
Reference-contexts: The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems [2, 12, 23] use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula <ref> [21] </ref>. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. The primary contributions of this paper are a generalization of previous work on determining if a pipeline schedule will deadlock, and generalization of Reiter's formula for determining the iteration interval b. <p> We summarize our conclusions in Section 10. 2 Loop and Pipeline Execution Models Pipeline scheduling and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph <ref> [21] </ref>, marked directed graph [5], dataflow graph [15, 16], dependence graph [10], flow graph [12], signal flow graph [2], iterative task graph [23], collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. <p> the iteration interval b and startup time a for pipeline execution of G are b = lim G:time n n a = maxfG:time n bnjn 1g 2 This definition of the iteration interval b, and a proof of the existence of the limit can be found in [20] (see also <ref> [21] </ref>). The iteration interval is the average time between completion of successive iterations of the DDG, and is the primary measure of the performance of a pipeline schedule. We will show how to find b for any pipeline schedule which does not deadlock. <p> We will show how to find b for any pipeline schedule which does not deadlock. Our definition of the startup time a, which is a secondary measure of the performance of a pipeline schedule, is based in part on results from <ref> [21] </ref>. In Section 9.5 we will show that the set in this definition is finite and therefore has a maximum, so a is well-defined. <p> We will generalize this result to remove the restrictions on G, and to allow processor sharing. Beyond deadlock considerations, the primary result in determining the pipeline execution time of a DDG is Reiter's formula <ref> [21] </ref> for determining the iteration interval b of a nonnegative DDG, when all data communication times are zero, and processors are not shared. To motivate this formula, consider the two examples in Figure 2. <p> These values are automatically found for all tasks as a side-effect of using a longest path algorithm to determine b (or given b, may be found in O (ev) time with a single longest path calculation). Reiter <ref> [21] </ref> showed that with reference to a global clock, the ith iteration of task X could legally start at time X:est + b (i 1). With asynchronous execution, this value is an upper bound on when the ith iteration of X will begin execution.
Reference: [22] <author> Vivek Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Multiprocessors. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1989. </year>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism [19], which assigns different loop iterations to different processors, or noniterative task (or DAG) parallelism <ref> [22, 24] </ref>, may permit pipeline parallelization. Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. <p> Dependence distances are discussed in more detail in Section 6. Definition 2 A nonnegative DDG is a DDG in which all edges have nonnegative dependence distances. 2 Asynchronous pipeline execution is a form of macro-dataflow execution <ref> [22] </ref>. Task execution is atomic. An instance of a task may not begin execution until all input data is available. Once a task instance begins execution, it executes without interruption to completion, and any output data becomes available for communication to other tasks only when task execution is complete.
Reference: [23] <author> Tao Yang, Cong Fu, Apostolos Gerasoulis, and Vivek Sarkar. </author> <title> Mapping iterative task graphs on distributed memory machines. </title> <booktitle> Proc. 24th International Conference on Parallel Processing, </booktitle> <address> Oconomowoc, WI, </address> <month> August </month> <year> 1995, </year> <booktitle> Vol II, </booktitle> <pages> pp. 151-158. </pages>
Reference-contexts: Application program loops may also be pipelined on multiprocessors or multicomputers. This form of pipelining is sometimes referred to as macropipelining, and has been studied particularly in the context of digital signal processing algorithms [2, 12], although it has been considered in other contexts as well <ref> [3, 23] </ref>. Tasks may be of arbitrary size, from simple statements to complex compound statements or subroutine calls. 1 Task execution times may vary from iteration to iteration, although we assume that there is an expected execution time for each task. <p> The term a is the startup time of the schedule, and is a secondary performance measure. Previous asynchronous pipeline scheduling algorithms targeting distributed memory systems <ref> [2, 12, 23] </ref> use conservative estimates of the pipeline iteration interval as their performance measure, derived in part from Reiter's well-known iteration interval formula [21]. Reiter's formula assumes that intertask communication times are zero, and each task is assigned to a distinct processor. <p> and analysis may be performed on a multiply weighted directed multigraph, variations of which have been given a wide variety of names in the literature, including computation graph [21], marked directed graph [5], dataflow graph [15, 16], dependence graph [10], flow graph [12], signal flow graph [2], iterative task graph <ref> [23] </ref>, collapsed-constraint graph [4], and semisystolic network [18], among others. Alternative models such as variations of Petri nets [20] have also been analyzed. Although the large choice of names and model variations is perhaps confusing, it also illustrates that pipelining is useful in a variety of contexts. <p> We require task execution and data communication times to be fixed, invariant times, but we expect variances in component execution times to typically translate to similar magnitude variances in pipeline execution times <ref> [23] </ref>. Much of the literature on pipeline scheduling, particularly outside compiler research, uses the term "delay" as a synonym for what we refer to as dependence distance. <p> The scheduling algorithm of [10] generates a noniterative task graph schedule " a " which provides a processor assignment and a task order for each processor. Stage assignments are given by the "" function. The algorithm in <ref> [23] </ref> is a generalization of the algorithm in [10]. <p> Theorem 11 may be applied to obtain exact iteration interval values for examples from the literature. For example, the iteration interval of the schedule in <ref> [23, Figure 1d] </ref> is 80, rather than the reported conservative estimate of 90. 9 Iteration Interval Formula Evaluation Theorem 11 states that the iteration interval of a scheduled DDG is equal to the maximum cycle ratio of the DDG. <p> In [10], the search is confined to integral values, and b is approximated as dbe. Using the Bellman-Ford algorithm as a subroutine, the resulting binary search algorithm runs in O (ev log G:vtime) time. This same general approach is also used in <ref> [23] </ref>, but with the accuracy specified by a parameter *, such that b is approximated as *d b * e (0:5 is used as an example value for *). <p> When this is the case, Lemma 5 can be used transform a general DDG into a nonnegative DDG with an equivalent maximum cycle ratio, in O (ev) time. Further, if a DDG is generated by pipeline scheduling algorithms such as those in <ref> [10, 23] </ref>, it may be possible to implicitly perform the retiming step without incurring the graph transformation cost. Dantzig et al. [7] formulated an equivalent problem as a linear programming problem, and derived the first known algorithm for the problem using the simplex method. <p> Theorem 10 (deadlock characterization) may be applied to show that a pipeline scheduling algorithm produces schedules which are free of deadlock. Theorem 11 (iteration interval determination) may be applied to precisely determine the iteration interval of schedules derived from existing scheduling algorithms <ref> [2, 12, 23] </ref>.
Reference: [24] <author> Tao Yang and Apostolos Gerasoulis. </author> <title> DSC: scheduling parallel tasks on an unbounded number of processors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems 5:9 (September 1994), </journal> <pages> pp. 951-967. 23 </pages>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism [19], which assigns different loop iterations to different processors, or noniterative task (or DAG) parallelism <ref> [22, 24] </ref>, may permit pipeline parallelization. Under the broad umbrella of pipeline parallelism, there are a number of variants which make different assumptions, or focus on different aspects of the computation which is being pipelined. <p> A key component of our approach is the use of scheduling edges with potentially negative data dependence distances, which generalizes the use of scheduling edges in noniterative task graphs <ref> [24] </ref>. <p> Scheduling edges allow the problem of analyzing pipeline execution of a graph when processors are shared to be reduced to a problem where processors are not shared. This is a generalization of the use of scheduling edges in noniterative task graph scheduling <ref> [24] </ref>. From Section 5, a regular asynchronous pipeline schedule for a DDG G has three components: a processor assignment, and for each processor, a task order and stage assignment.
References-found: 24

