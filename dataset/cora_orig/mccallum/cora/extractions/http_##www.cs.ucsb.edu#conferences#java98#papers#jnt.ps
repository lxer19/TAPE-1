URL: http://www.cs.ucsb.edu/conferences/java98/papers/jnt.ps
Refering-URL: http://math.nist.gov/javanumerics/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (email: fboisvert,pozo,karing@nist.gov)  (email: dongarra@cs.utk.edu)  (email: stewart@cs.umd.edu)  
Phone: 2  3  
Title: Developing numerical libraries in Java  
Author: RONALD F. BOISVERT JACK J. DONGARRA ROLDAN POZO KARIN A. REMINGTON AND G.W. STEWART ; 
Date: SUMMARY  
Address: Gaithersburg, MD 20899 USA  Knoxville, Knoxville, TN 37996, and Oak Ridge  Oak Ridge, TN  College Park, MD 20742 USA  
Affiliation: 1 Mathematical and Computational Sciences Division, Information Technology Laboratory, National Institute of Standards and Technology,  Computer Science Department, University of Tennessee at  National Laboratory,  Department of Computer Science, University of Maryland,  
Abstract: The rapid and widespread adoption of Java has created a demand for reliable and reusable mathematical software components to support the growing number of compute-intensive applications now under development, particularly in science and engineering. In this paper we address practical issues of the Java language and environment which have an effect on numerical library design and development. Benchmarks which illustrate the current levels of performance of key numerical kernels on a variety of Java platforms are presented. Finally, a strategy for the development of a fundamental numerical toolkit for Java is proposed and its current status is described. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. D. Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LAPACK Users' Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: Numerical software designers typically take information about the physical layout of data in memory into account when designing algorithms to achieve high performance. For example, LINPACK [7] used column-oriented algorithms and the Level 1 BLAS in order to localize memory references for efficiency in paged virtual memory environments. LAPACK <ref> [1] </ref> used block-oriented algorithms and the Level 2 and 3 BLAS to localize references for efficiency in modern cache-based systems. The ability to do this hinged on the fact that Fortran requires two-dimensional arrays be stored contiguously by columns. 2 Many of these are listed at http://grunge.cs.tu-berlin.de/~tolk/vmlanguages.html.
Reference: [2] <author> R. Barrett, M. Berry, T. F. Chan, J. Demmel, J. Donato, J. Dongarra, V. Eijkhout, R. Pozo, C. Romine, and H. van der Vorst. </author> <title> Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1994. </year>
Reference-contexts: As expected, however, kernels based on dot products may be preferable in Java, and strategies such as unrolling and one-dimensional indexing may also help. 3.4. Sparse matrix-vector multiply Finally, we consider sparse matrix-vector multiplication based on a sparse coordinate storage format <ref> [2] </ref>. In particular, we compare an implementation in Java with those based upon the NIST Sparse BLAS Toolkit reference implementation [14] in C on a 266 MHz Pentium II running Windows 95.
Reference: [3] <author> A. J. C. Bik and D. B. Gannon. </author> <title> A note on native level 1 BLAS in Java. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1091-1099, </pages> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: Early experience with Java interpreters has led to the common perception that applications written in Java are slow. One can get good performance in Java by using native methods, i.e. calls to optimized code written in other languages <ref> [3] </ref>. However, this comes at the expense of portability, which is a key feature of the language. Advances in just-in-time (JIT) compilers, and improvements in Java run-time systems have changed the landscape in recent months, suggesting that Java itself may indeed be suitable for many types of numerical computations.
Reference: [4] <author> R. F. Boisvert, S. Browne, J. Dongarra, and E. Grosse. </author> <title> Digital software and data repositories for support of scientific computing. </title> <editor> In N. Adam, B. K. Bhargava, and M. Halem, editors, </editor> <booktitle> Advances in Digital Libraries, number 1082 in Lecture Notes in Computer Science, </booktitle> <pages> pages 61-72. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: Many successful libraries have since been developed, resulting in a variety of commercial products, as well as public repositories of reusable components such as netlib and the Guide to Available Mathematical Software <ref> [4] </ref>. Library users want components which run fast, are easily moved among computing platforms, invariably produce the right answer, and are easy to understand and integrate with their applications. Thus, efficiency, portability, reliability and usability are of primary concern to library developers.
Reference: [5] <author> R. F. Boisvert, R. Pozo, K. Remington, R. Barrett, and J. J. Dongarra. </author> <title> The Matrix Market: A web resource for test matrix collections. </title> <editor> In R. F. Boisvert, editor, </editor> <booktitle> The Quality of Numerical Software: Assessment and Enhancement, </booktitle> <pages> pages 125-137, </pages> <address> London, 1997. </address> <publisher> Chapman & Hall. </publisher>
Reference-contexts: In particular, we compare an implementation in Java with those based upon the NIST Sparse BLAS Toolkit reference implementation [14] in C on a 266 MHz Pentium II running Windows 95. The test cases, taken from the Harwell-Boeing collection <ref> [5, 8] </ref>, represent fairly small sparse matrices, but may provide an indication of the relative performance of these languages on kernels which contain indirect index computations. The results are presented in Table 4.
Reference: [6] <author> H. Casanova, J. Dongarra, and D. M. Doolin. </author> <title> Java access to numerical libraries. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1279-1291, </pages> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: This is, of course, labor-intensive, and could lead to less than optimal code due to inefficiencies in the language. Nevertheless, several groups have begun to undertake such projects [15, 16, 17]. A second option is to develop tools to translate existing Fortran libraries into Java <ref> [6, 10] </ref>. While this provides easy access to a wealth of existing software, the severe mismatch between Fortran and Java semantics is likely to lead to converted library source which is unnatural and inefficient.
Reference: [7] <author> J. J. Dongarra, C. B. Moler, J. R. Bunch, and G. W. Stewart. </author> <title> LINPACK Users' Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference-contexts: Memory model Perhaps the biggest difference in developing numerical code in Java rather than in Fortran or C results from Java's memory model. Numerical software designers typically take information about the physical layout of data in memory into account when designing algorithms to achieve high performance. For example, LINPACK <ref> [7] </ref> used column-oriented algorithms and the Level 1 BLAS in order to localize memory references for efficiency in paged virtual memory environments. LAPACK [1] used block-oriented algorithms and the Level 2 and 3 BLAS to localize references for efficiency in modern cache-based systems.
Reference: [8] <author> I. S. Duff, R. G. Grimes, and J. G. Lewis. </author> <title> Sparse matrix test problems. </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 15(1) </volume> <pages> 1-14, </pages> <month> Mar. </month> <year> 1989. </year>
Reference-contexts: In particular, we compare an implementation in Java with those based upon the NIST Sparse BLAS Toolkit reference implementation [14] in C on a 266 MHz Pentium II running Windows 95. The test cases, taken from the Harwell-Boeing collection <ref> [5, 8] </ref>, represent fairly small sparse matrices, but may provide an indication of the relative performance of these languages on kernels which contain indirect index computations. The results are presented in Table 4.
Reference: [9] <author> M. B. Dwyer and V. </author> <title> Wallentine. A framework for parallel adaptive grid simulations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1293-1310, </pages> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: A toolkit provides a low-level interface to numerical algorithms similar to what one finds in C and Fortran. Toolkits provide a source of basic numerical kernels and computational algorithms which can be used in the construction of more facile object-oriented frameworks for particular applications <ref> [9] </ref>. 4.2.
Reference: [10] <author> G. Fox, X. Li, Z. Qiang, and W. Zhigang. </author> <title> A prototype Fortran-to-Java converter. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1047-1061, </pages> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: To use a vector of double, for example, one needs to use Java's wrapper Double class and perform explicit coercions. Consider the difference between using native Java arrays, double x [] = new double <ref> [10] </ref>; // using native Java arrays double a [] = new double [10]; ... and Java's Vector class, Vector x = new Vector (10); // using Java's Vector class Vector a = new Vector (10); ... a.setElement (i, new Double ((((Double) x.ElementAt (i+1)).doubleValue () - ((Double) x.ElementAt (i-1)).doubleValue ()) / 2.0); <p> To use a vector of double, for example, one needs to use Java's wrapper Double class and perform explicit coercions. Consider the difference between using native Java arrays, double x [] = new double <ref> [10] </ref>; // using native Java arrays double a [] = new double [10]; ... and Java's Vector class, Vector x = new Vector (10); // using Java's Vector class Vector a = new Vector (10); ... a.setElement (i, new Double ((((Double) x.ElementAt (i+1)).doubleValue () - ((Double) x.ElementAt (i-1)).doubleValue ()) / 2.0); Deriving a VectorDouble class from Vector which performed these coercions automatically would <p> This is, of course, labor-intensive, and could lead to less than optimal code due to inefficiencies in the language. Nevertheless, several groups have begun to undertake such projects [15, 16, 17]. A second option is to develop tools to translate existing Fortran libraries into Java <ref> [6, 10] </ref>. While this provides easy access to a wealth of existing software, the severe mismatch between Fortran and Java semantics is likely to lead to converted library source which is unnatural and inefficient.
Reference: [11] <author> J. Gosling, B. Joy, and G. Steele. </author> <title> The Java Language Specification. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1996. </year>
Reference-contexts: Unfortunately, these properties are often competing, portability and reliability often taking a toll on performance, for example. Hence, the development of high quality portable mathematical software libraries for widely differing computing environments continues to be a challenging task. Java technology <ref> [11, 12] </ref> is leading to a revolution in network-based computing. One of the main reasons for this is the promise of new levels of portability across a very wide range of platforms. Java is only beginning to affect the scientific computing world. <p> NUMERICAL COMPUTING IN JAVA Java is both a computer language and a run-time environment. The Java language <ref> [11] </ref> is an object-oriented language similar to, but much simpler than, C++. Compilers translate Java programs into bytecodes for execution the Java Virtual Machine (JVM) [12]. The JVM presents a fixed computational environment which can be provided on any computer platform. <p> If such tools achieve a high enough level of maturity and support, they too can provide the basis for a Java-based development environments for scientific computing. 2.1. Arithmetic The idea that results produced on every JVM should be bitwise identical <ref> [11] </ref> on all platforms threatens the usability of Java for high performance scientific computing. While there may be some scientific applications where such certainty would be useful, its strict implementation could severely degrade performance on many platforms.
Reference: [12] <author> T. Lindholm and F. Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1996. </year>
Reference-contexts: Unfortunately, these properties are often competing, portability and reliability often taking a toll on performance, for example. Hence, the development of high quality portable mathematical software libraries for widely differing computing environments continues to be a challenging task. Java technology <ref> [11, 12] </ref> is leading to a revolution in network-based computing. One of the main reasons for this is the promise of new levels of portability across a very wide range of platforms. Java is only beginning to affect the scientific computing world. <p> NUMERICAL COMPUTING IN JAVA Java is both a computer language and a run-time environment. The Java language [11] is an object-oriented language similar to, but much simpler than, C++. Compilers translate Java programs into bytecodes for execution the Java Virtual Machine (JVM) <ref> [12] </ref>. The JVM presents a fixed computational environment which can be provided on any computer platform.
Reference: [13] <author> R. Pozo. </author> <title> Template Numerical Toolkit for linear algebra: High performance programming with C++ and the Standard Template Library. </title> <journal> International Journal of High Performance Computing Applications, </journal> <volume> 11(3), </volume> <year> 1997. </year> <note> Further information about TNT may be found at http://math.nist.gov/tnt/. </note>
Reference-contexts: Fortunately, this does not necessarily imply significant performance degradation in practice. Modern processors have the ability to overlap index checks with other computation, allowing them to cost very little. Experiments performed in C++ using the NIST Template Numerical Toolkit <ref> [13] </ref> on a Pentium Pro with the Watcom C++ compiler (version 10.6) show that array bounds checking can add as little as 20% overhead. 3.2. Elementary kernels Timings for several BLAS 1 kernels with various unrolling strategies in several environments are presented in Table 1.
Reference: [14] <author> K. Remington and R. Pozo. </author> <title> Sparse blas. Working document of the Basic Linear Algebra Subprograms Technical (BLAST) Forum. </title> <note> Available at http://www.netlib.org/utk/papers/blast-forum.html. </note>
Reference-contexts: Sparse matrix-vector multiply Finally, we consider sparse matrix-vector multiplication based on a sparse coordinate storage format [2]. In particular, we compare an implementation in Java with those based upon the NIST Sparse BLAS Toolkit reference implementation <ref> [14] </ref> in C on a 266 MHz Pentium II running Windows 95. The test cases, taken from the Harwell-Boeing collection [5, 8], represent fairly small sparse matrices, but may provide an indication of the relative performance of these languages on kernels which contain indirect index computations.
Reference: [15] <author> S. Russell, L. Stiller, and O. Hansson. PNPACK: </author> <title> Computing with probabilities in Java. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1333-1339, </pages> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: First, numerical classes can be coded directly in the language. This is, of course, labor-intensive, and could lead to less than optimal code due to inefficiencies in the language. Nevertheless, several groups have begun to undertake such projects <ref> [15, 16, 17] </ref>. A second option is to develop tools to translate existing Fortran libraries into Java [6, 10].
Reference: [16] <author> T. H. Smith, A. E. Gower, and D. S. Boning. </author> <title> A matrix math library for Java. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1127-1137, </pages> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: First, numerical classes can be coded directly in the language. This is, of course, labor-intensive, and could lead to less than optimal code due to inefficiencies in the language. Nevertheless, several groups have begun to undertake such projects <ref> [15, 16, 17] </ref>. A second option is to develop tools to translate existing Fortran libraries into Java [6, 10].
Reference: [17] <institution> Java language proposal. Visual Numerics, Inc., </institution> <address> 9990 Richmond Ave., Ste. 400, Houston, TX 77042-4548. </address> <note> Available at http://www.vni.com/products/wpd/jnl/JNL/docs/intro.html, 1997. </note>
Reference-contexts: This is because compilers, as well as the JVM, will be unable to perform conventional optimizations on complex arithmetic because they are unaware of the semantics of the class. Since complex arithmetic is so pervasive it is necessary to establish community consensus on a Java interface for complex classes <ref> [17] </ref>. 2.3. Memory model Perhaps the biggest difference in developing numerical code in Java rather than in Fortran or C results from Java's memory model. Numerical software designers typically take information about the physical layout of data in memory into account when designing algorithms to achieve high performance. <p> First, numerical classes can be coded directly in the language. This is, of course, labor-intensive, and could lead to less than optimal code due to inefficiencies in the language. Nevertheless, several groups have begun to undertake such projects <ref> [15, 16, 17] </ref>. A second option is to develop tools to translate existing Fortran libraries into Java [6, 10].
References-found: 17

