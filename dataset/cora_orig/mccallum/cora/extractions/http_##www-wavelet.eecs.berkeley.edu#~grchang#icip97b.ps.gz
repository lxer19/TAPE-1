URL: http://www-wavelet.eecs.berkeley.edu/~grchang/icip97b.ps.gz
Refering-URL: http://www-wavelet.eecs.berkeley.edu/~grchang/publications.html
Root-URL: 
Email: grchang@eecs.berkeley.edu, binyu@stat.berkeley.edu, vetterli@de.epfl.ch  
Phone: 2  3  
Title: IMAGE DENOISING VIA LOSSY COMPRESSION AND WAVELET THRESHOLDING  
Author: S. Grace Chang Bin Yu Martin Vetterli ; 
Address: Berkeley, CA 94720, USA  Berkeley, CA 94720, USA  CH-1015 Lausanne, Switzerland  
Affiliation: 1 Department of Electrical Engineering and Computer Sciences University of California,  Department of Statistics University of California,  Departement d'Electricite Ecole Polytechnique Federale de Lausanne,  
Abstract: Some past work has proposed to use lossy compression to remove noise, based on the rationale that a reasonable compression method retains the dominant signal features more than the randomness of the noise. Building on this theme, we explain why compression (via coefficient quantization) is appropriate for filtering noise from signal by making the connection that quantization of transform coefficients approximates the operation of wavelet thresholding for de-noising. That is, denoising is mainly due to the zero-zone and that the full precision of the thresholded coefficients is of secondary importance. The method of quantization is facilitated by a criterion similar to Rissanen's minimum description length principle. An important issue is the threshold value of the zero-zone (and of wavelet thresholding). For a natural image, it has been observed that its subband coefficients can be well modeled by a Laplacian distribution. With this assumption, we derive a threshold which is easy to compute and is intuitive. Experiments show that the proposed threshold performs close to optimal thresholding. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Daubechies, </author> <title> Ten Lectures on Wavelets, </title> <booktitle> vol. 61 of CBMS-NSF Regional Conference Series in Applied Mathematics, </booktitle> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: EXPERIMENTAL RESULTS The images "goldhill" and "lena", with various noise strength = 10; 15; 20, are used as test data. The chosen wavelet is Daubechies' least asymmetric compactly-supported wavelet with 8 vanishing moments <ref> [1] </ref>, and 4 levels of decomposition is used. Table 1 compares the SNRs of the soft-thresholding denoised results using the oracle threshold, orc , and ~ ( ^ff) (adaptive in each sub band).
Reference: [2] <author> D.L. Donoho and I.M. Johnstone, </author> <title> "Ideal spatial adaptation via wavelet shrinkage," </title> <journal> Biometrika, </journal> <volume> vol 81, </volume> <pages> pp. 425-455, </pages> <year> 1994. </year>
Reference-contexts: More specifically, we wish to show that quantization (a common step in compression) of transform coefficients achieves denoising by posing quantization as an approximation to an effective denoising method called wavelet thresholding <ref> [2] </ref>. The theoretical formalization of thresholding in the context of removing noise via thresholding wavelet coefficients was pioneered by Donoho and Johnstone [2]. <p> to show that quantization (a common step in compression) of transform coefficients achieves denoising by posing quantization as an approximation to an effective denoising method called wavelet thresholding <ref> [2] </ref>. The theoretical formalization of thresholding in the context of removing noise via thresholding wavelet coefficients was pioneered by Donoho and Johnstone [2]. Both the soft (shrink or kill) and the hard- (keep or kill) thresholding methods compare the input to a given threshold and set it to zero if its magnitude is less than the threshold. <p> One of the most important and frequently asked questions in using wavelet thresholding is "What is the threshold?", or in the compression scenario, "how to choose the zero-zone?" While Donoho and Johnstone <ref> [2] </ref> have pro posed several thresholds such as the universal ( p SURE, and hybrid thresholds, and have demonstrated their asymptotic optimality conditions, these thresholds do not work well in practice. <p> The noise variance is estimated by the robust median estimator in the highest subband, ^ = Median (jY i j)=:6745; Y i 2 subband HH 1 ; also used in <ref> [2] </ref>. Since the signal and noise are assumed to be independent, Var (Y ) = 1=ff + 2 , thus ^ff = SampleVariance (Y) ^ 2 .
Reference: [3] <author> S. Mallat, </author> <title> "A theory for multiresolution signal decomposition: The wavelet representation," </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> vol. 11, no. 7, </volume> <pages> pp. 674-693, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: A large class of natural images has decaying spectrums, which means that the subband energy also follows a certain decay across scales. Within each subband, the coefficients can be well modeled by a generalized Laplacian distribution <ref> [3] </ref>. Assuming a Laplacian distribution, the proposed threshold is an approximation to the optimal threshold which minimizes the expected squared error among soft-threshold estimators. A different threshold is computed for each subband to adapt to the changing subband characteristics. 2. <p> Let Y = Wy denote the vector of wavelet coefficients of y, where W is the orthogonal wavelet transform operator, and similarly with X and V. The readers are referred to <ref> [3] </ref> for details on wavelet subband decomposition. Since the transform is orthogonal, V i is also iid Gaussian N (0; 2 ). The idea of wavelet thresholding suggests filtering noise from y by thresholding its wavelet coefficients (except the coarsest scale coefficients). <p> to derive a threshold which mini mizes the averaged squared error, 1=N P For a large class of natural images, it has been observed that the coefficients in each subband of its wavelet transform (with the exception of the lowest scale) can be well described by a generalized Laplacian distribution <ref> [3] </ref>. For this work, we assume the Laplacian pdf for simplicity. Consider now only coefficients from one subband. Let X ~ LAP ( 2ff) = 1 p p 2ffjXj .
Reference: [4] <author> B.K. Natarajan, </author> <title> "Filtering random noise from deterministic signals via data compression," </title> <journal> IEEE Trans. on Signal Processing, </journal> <volume> vol. 43, no. 11, </volume> <pages> pp. 2595-2605, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Suppose an image has been corrupted by additive noise, and the goal is to remove the noise. The idea of using a lossy compression algorithm to denoise the signal has been proposed in several works <ref> [4, 7] </ref>. Continuing on this theme, one main purpose of this paper is to explain why lossy compression can be appropriate for noise filtering.
Reference: [5] <author> J. Rissanen, </author> <title> Stochastic Complexity in Statistical Inquiry, </title> <publisher> World Scientific, </publisher> <year> 1989. </year>
Reference-contexts: Thus, a comparable level of denoising performance can be achieved by quantizing the coefficients with a zero-zone and a few number of quantization levels outside of the zero-zone. The manner of quantization will be facilitated by a criterion similar to Rissanen's minimum description length (MDL) <ref> [5] </ref>. <p> We propose to use an MDL-like criterion to facilitate this decision. For a given set of observations, the MDL criterion is useful for choosing a reasonable statistical model which yields the shortest description length <ref> [5] </ref>. It does this by choosing the model which minimizes the total code-length of a two-part encoding consisting of the data (based on the chosen model) and of the model parameters.
Reference: [6] <author> F. Ruggeri and B. Vidakovic, </author> <title> "A Bayesian decision theoretic approach to wavelet thresholding," </title> <type> preprint, </type> <institution> Duke University, Durham, NC. (ftp://ftp.isds.duke. edu/pub/Users/brani/papers/Decision.ps). </institution>
Reference-contexts: Now for a general value of , the above discussion holds by replacing , ff, and x by =, 2 ff, and x =, respectively, and our proposed threshold is ~ (ff) = ff: (1) A similar threshold to (1) is found independently in <ref> [6] </ref> for using the same priors with the hard-thresholding function. Soft-thresholding is used here because it is more suitable for images. Furthermore, with these priors, the expected squared error of optimal soft-thresholding is smaller than that of optimal hard-thresholding.
Reference: [7] <author> N. Saito, </author> <title> "Simultaneous noise suppression and signal compression using a library of orthonormal bases and the minimum description length criterion," in Wavelets in Geophysics, </title> <editor> Eds. E. Foufoula-Georgiou and P. </editor> <booktitle> Ku-mar, </booktitle> <pages> pp. 299-324, </pages> <publisher> Academic Press, </publisher> <year> 1994. </year> <title> (a) (c) thresholding. (c) Threshold with ~ ( ^ff). (d) Our method of thresholding followed by quantization. </title>
Reference-contexts: 1. INTRODUCTION Suppose an image has been corrupted by additive noise, and the goal is to remove the noise. The idea of using a lossy compression algorithm to denoise the signal has been proposed in several works <ref> [4, 7] </ref>. Continuing on this theme, one main purpose of this paper is to explain why lossy compression can be appropriate for noise filtering. <p> In Saito's simultaneous compression and denoising method <ref> [7] </ref> of combining MDL with thresholding, the hard-thresholding function was used and the term L (X) was taken to be (3=2)k log 2 n, where k is the number of nonzero coefficients: log 2 n bits to indicate the location of each nonzero coefficient (assuming an uniform indexing) and (1=2) log
References-found: 7

