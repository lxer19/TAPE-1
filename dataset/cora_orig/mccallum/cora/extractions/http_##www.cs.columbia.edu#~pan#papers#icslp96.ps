URL: http://www.cs.columbia.edu/~pan/papers/icslp96.ps
Refering-URL: http://www.cs.columbia.edu/~pan/publication.html
Root-URL: http://www.cs.columbia.edu
Email: fpan, mckeowng@cs.columbia.edu  
Title: SPOKEN LANGUAGE GENERATION IN A MULTIMEDIA SYSTEM  
Author: Shimei Pan, Kathleen McKeown 
Address: New York, NY 10027  
Affiliation: Columbia University Department of Computer Science  
Abstract: In this paper we address two important issues in generating spoken language within a multimedia system: the design of a speech generator to facilitate coordination between media, and extensions to the functionality of a written language generation system to produce natural speech output. We demonstrate how a speech generator can produce information that allows for temporal coordination between multiple media. We describe how our speech generator takes advantage of rich and accurate syntactic and semantic information during text planning and speech realization. This enables the system to accurately predict, generate, and utilize prosodic features to facilitate coordination of speech with graphical actions such as highlighting. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. Allen, S. Hunnicutt, and D. Klatt. </author> <title> From text to speech: the MITalk system. </title> <publisher> Cambridge University Press, </publisher> <address> Cam-bridge, </address> <year> 1987. </year>
Reference-contexts: We used Lucent Bell Laboratories' Text-To-Speech (TTS) system for speech synthesis. For a general speech generation system, a major task is generating appropriate prosody for speech output. Most research in this area is related to TTS synthesis <ref> [1, 8, 10] </ref>, which uses stored text as input. A major problem for TTS systems is that they must analyze the underlying linguistic structure from the text during the text-to-speech conversion and then assign prosody based on the results [3].
Reference: 2. <author> J. Bachenko and E. Fitzpatrick. </author> <title> A computational grammar of discourse-neutral prosodic phrasing in English. </title> <journal> Computational Linguistics, </journal> <volume> 16(3) </volume> <pages> 155-170, </pages> <year> 1990. </year>
Reference-contexts: This can be done either by predicting where pauses can be added to the speech without comprising intelligibility and naturalness or by overlapping highlighting with spoken material between references. For the purpose of predicting possible additional pause locations, we employ a variant of the algorithm proposed in <ref> [2] </ref>. Briefly, in their algorithm, a phonological phrase is defined as all the material up to and including the head of a syntactic phrase, following Gee and Grosjean [7]. Two kinds of rules are used to determine pause location and relative strength respectively.
Reference: 3. <author> K. Church. </author> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Proceedings of the Second Conference on Applied Natural Language Processing, </booktitle> <pages> pages 136-143, </pages> <address> Morristown, New Jersey, </address> <year> 1988. </year>
Reference-contexts: Most research in this area is related to TTS synthesis [1, 8, 10], which uses stored text as input. A major problem for TTS systems is that they must analyze the underlying linguistic structure from the text during the text-to-speech conversion and then assign prosody based on the results <ref> [3] </ref>. However, the results of this analysis are usually not accurate enough to predict prosody fully. In order to avoid such limitations, a smaller amount of research has been done in generating speech from concepts, termed Meaning-To-Speech or MTS [5, 12, 14].
Reference: 4. <author> M. Dalal, S. Feiner, K. McKewon, S. Pan, M. Zhou, T. Hollerer, J. Shaw, Y. Feng, and J. Fromer. </author> <title> Negotiation for automated generation of temporal multimedia presentations. </title> <note> Submitted, </note> <year> 1996. </year>
Reference-contexts: Since multiple items may be displayed graphically at any one time, Magic uses synchronized speech and highlighting to help the user focus on the current topic and find the illustrated information referred to by speech. In order to achieve a coordinated presentation, our work uses negotiation <ref> [4] </ref> to arrive at an ordering of spoken references that is compatible with the order of highlighting. We want to use a highlighting order that is regular and does not jump around the screen; at the same time, speech should be natural. <p> In this section, we describe how the speech generator produces different orderings to make the task of media coordination easier. Input to the speech generator is represented in a hierarchical presentation plan produced by Magic's high level content planner <ref> [4] </ref>. The task for the speech generator is to determine how to order the basic information units of the plan in speech, where a basic information unit corresponds to the lowest-level goal, or smallest unit, within the plan. <p> Since there is considerable flexibility in ordering due to paraphrasing, the speech generator produces a representation of possible orderings, ranked according to preference. These orderings are then passed to the media coordinator for negotiation with graphics as described in <ref> [4] </ref>. For example, three possible orderings of a patient's demographics information can be produced: 1. Ms. Walker is a 50 year old anorexic, hypokalemic fe male patient of doctor Longman undergoing CABG. 2. Ms. Walker is a 50 year old female patient of doctor Longman undergoing CABG.
Reference: 5. <author> J. Davis and J. Hirschberg. </author> <title> Assigning intonational features in synthesized spoken discourse. </title> <booktitle> In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 187-193, </pages> <address> Buffalo, New York, </address> <year> 1988. </year>
Reference-contexts: However, the results of this analysis are usually not accurate enough to predict prosody fully. In order to avoid such limitations, a smaller amount of research has been done in generating speech from concepts, termed Meaning-To-Speech or MTS <ref> [5, 12, 14] </ref>. Like other MTS systems, Magic builds a full semantic and syntactic representation for the text as part of the generation process. <p> This kind of information has been used to produce better prosodic structures in several MTS systems, such as the given/new distinction or contrast has been used to determine accentual patterns and intonational contours <ref> [5, 12] </ref>. Our work differs from other MTS systems both in the use of a large-scale language generation subsystem, as well as in our focus on generating speech that is compatible with requirements from other media.
Reference: 6. <author> M. Elhadad. </author> <title> Using Argumentation to Control Lexical Choice: A Functional Unification Implementation. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1993. </year>
Reference-contexts: RELATED WORK Our research builds on techniques developed for language generation [9], incorporating components that handle the tasks of content planning, lexical selection, and syntactic sentence generation. Our speech generator uses the Fuf/Surge package <ref> [6] </ref>, a sentence generation system containing a robust English grammar. Unlike previous work in language generation, our work focuses on the development of techniques for producing spoken language. We used Lucent Bell Laboratories' Text-To-Speech (TTS) system for speech synthesis.
Reference: 7. <author> J. P. Gee and F. Grosjean. </author> <title> Performance structure: A psycholinguistic and linguistic appraisal. </title> <journal> Cognitive Psychology, </journal> <volume> 15 </volume> <pages> 411-458, </pages> <year> 1983. </year>
Reference-contexts: For the purpose of predicting possible additional pause locations, we employ a variant of the algorithm proposed in [2]. Briefly, in their algorithm, a phonological phrase is defined as all the material up to and including the head of a syntactic phrase, following Gee and Grosjean <ref> [7] </ref>. Two kinds of rules are used to determine pause location and relative strength respectively. Location rules effectively derive phonological words and phrases. Boundary salience rules are used to group phonological phrases into prosodic phrases with pause strength index.
Reference: 8. <author> M. Liberman and A.L. Buchsbaum. </author> <title> Structure and usage of current Bell Labs Text-To-Speech programs. </title> <type> Technical Memorandum 11225-850731-11, </type> <institution> AT&T Bell laboratories, </institution> <year> 1985. </year>
Reference-contexts: We used Lucent Bell Laboratories' Text-To-Speech (TTS) system for speech synthesis. For a general speech generation system, a major task is generating appropriate prosody for speech output. Most research in this area is related to TTS synthesis <ref> [1, 8, 10] </ref>, which uses stored text as input. A major problem for TTS systems is that they must analyze the underlying linguistic structure from the text during the text-to-speech conversion and then assign prosody based on the results [3].
Reference: 9. <author> K. McKeown. </author> <title> Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1985. </year>
Reference-contexts: Predicting the location and relative strength of pauses to facilitate temporal synchronization between media. 3. Augmenting the functionality of the language generation system for the generation of speech as opposed to written language. 2. RELATED WORK Our research builds on techniques developed for language generation <ref> [9] </ref>, incorporating components that handle the tasks of content planning, lexical selection, and syntactic sentence generation. Our speech generator uses the Fuf/Surge package [6], a sentence generation system containing a robust English grammar.
Reference: 10. <author> A. Monaghan. </author> <title> Intonation in a Text-To-Speech conversion system. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1991. </year>
Reference-contexts: We used Lucent Bell Laboratories' Text-To-Speech (TTS) system for speech synthesis. For a general speech generation system, a major task is generating appropriate prosody for speech output. Most research in this area is related to TTS synthesis <ref> [1, 8, 10] </ref>, which uses stored text as input. A major problem for TTS systems is that they must analyze the underlying linguistic structure from the text during the text-to-speech conversion and then assign prosody based on the results [3].
Reference: 11. <author> J. Neal, C. Thielman, Z. Dobes, S. Haller, and S. Shapiro. </author> <title> Natural language with integrated deictic and graphics gestures. </title> <booktitle> In Proceedings of Speech and Natural Language Workshop, </booktitle> <pages> pages 410-423, </pages> <address> Cape Cod, Mas-sachusetts, </address> <year> 1989. </year>
Reference-contexts: Of the few systems that also coordinate speech with graphics, either a unified generator is used to produce speech and graphics simultaneously and thus, no specific negotiation between speech and graphics is necessary <ref> [11] </ref>, or speech controls the process of synchronization, thereby simplifying the language generation task [12]. In both of these systems, the flexibility in coordination is more limited than in Magic. 3. COORDINATING SPEECH WITH GRAPHICS In Magic, the communicative goal is to convey a patient's status to caregivers.
Reference: 12. <author> S. Prevost. </author> <title> A Semantics of Contrast and Informaiton Structure for Specifying Intonation in Spoken Language Generation. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1995. </year>
Reference-contexts: However, the results of this analysis are usually not accurate enough to predict prosody fully. In order to avoid such limitations, a smaller amount of research has been done in generating speech from concepts, termed Meaning-To-Speech or MTS <ref> [5, 12, 14] </ref>. Like other MTS systems, Magic builds a full semantic and syntactic representation for the text as part of the generation process. <p> This kind of information has been used to produce better prosodic structures in several MTS systems, such as the given/new distinction or contrast has been used to determine accentual patterns and intonational contours <ref> [5, 12] </ref>. Our work differs from other MTS systems both in the use of a large-scale language generation subsystem, as well as in our focus on generating speech that is compatible with requirements from other media. <p> Of the few systems that also coordinate speech with graphics, either a unified generator is used to produce speech and graphics simultaneously and thus, no specific negotiation between speech and graphics is necessary [11], or speech controls the process of synchronization, thereby simplifying the language generation task <ref> [12] </ref>. In both of these systems, the flexibility in coordination is more limited than in Magic. 3. COORDINATING SPEECH WITH GRAPHICS In Magic, the communicative goal is to convey a patient's status to caregivers. Text, animated graphics and speech are used simultaneously to achieve this goal.
Reference: 13. <author> J. Shaw. </author> <title> Conciseness through aggregation in text generation. </title> <booktitle> In Proceedings of 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 329-331, </pages> <address> Cambridge, Massachusetts, </address> <year> 1995. </year>
Reference-contexts: First, the speech content planner distributes information units among sentences. It attempts to place as many information units into a single sentence as possible, using modifiers (e.g., adjectives) since this will result in fewer words in the output (see <ref> [13] </ref> for aggregation techniques). After this, the lexical chooser selects appropriate words for each information unit.
Reference: 14. <author> S. Young and F. Fallside. </author> <title> Speech synthesis from concept: a method for speech output from information systems. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 66 </volume> <pages> 685-695, </pages> <year> 1979. </year>
Reference-contexts: However, the results of this analysis are usually not accurate enough to predict prosody fully. In order to avoid such limitations, a smaller amount of research has been done in generating speech from concepts, termed Meaning-To-Speech or MTS <ref> [5, 12, 14] </ref>. Like other MTS systems, Magic builds a full semantic and syntactic representation for the text as part of the generation process.
Reference: 15. <author> M. Zhou and S. Feiner. </author> <title> Data characterization for automatically visualizing heterogeneous information. </title> <note> Submitted, </note> <year> 1996. </year>
Reference-contexts: Three media generators are involved: a 3D graphics generator <ref> [15] </ref>, a speech generator, and a text generator. The speech, graphics, and text are all generated on the fly.
References-found: 15

