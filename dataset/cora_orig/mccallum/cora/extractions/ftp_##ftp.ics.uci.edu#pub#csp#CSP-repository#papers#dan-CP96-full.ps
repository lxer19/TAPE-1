URL: ftp://ftp.ics.uci.edu/pub/csp/CSP-repository/papers/dan-CP96-full.ps
Refering-URL: http://www.ics.uci.edu/~mlearn/MLPapers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fdfrost, dechterg@ics.uci.edu  
Phone: Frost: (714) 824-1084 Dechter: (714) 824-6556 Fax: (714) 824-4056  
Title: Looking at Full Looking Ahead  
Author: Daniel Frost and Rina Dechter 
Keyword: Constraint Satisfaction, Algorithms, Forward Checking, Experimental Analysis  
Note: This work was partially supported by NSF grant IRI-9157636, by the Electrical Power Research Institute (EPRI), and by grants from Toshiba of America, Xerox Northrop and Rockwell.  
Address: Irvine, CA 92717-3425 U.S.A.  
Affiliation: Dept. of Information and Computer Science University of California,  
Abstract: Haralick and Elliott's full looking ahead algorithm [4] was presented in the same article as forward checking, but is not as commonly used. We give experimental results which indicate that on some types of constraint satisfaction problems, full looking ahead outperforms forward checking. We also present three new looking ahead algorithms, all variations on full looking ahead, which were designed with the goal of achieving performance equal to the better of forward checking and full looking ahead on a variety of constraint satisfaction problems. One of these new algorithms, called smart looking ahead, comes close to achieving our goal. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter Cheeseman, Bob Kanefsky, and William M. Taylor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 331-337, </pages> <year> 1991. </year>
Reference-contexts: The specific constraints are chosen randomly from a uniform distribution. Certain combinations of parameters generate problems of which about 50% are satisfiable; such problems are on average much more difficult than those which almost all have solutions (under-constrained) or which almost never have solutions (over-constrained) <ref> [1, 6] </ref>. Such a set of parameters is sometimes called a cross-over point.
Reference: [2] <author> Rina Dechter and Judea Pearl. </author> <title> Network-based heuristics for constraint-satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 1-38, </pages> <year> 1987. </year>
Reference-contexts: It would be remiss not to mention one of the original variants of looking ahead, called partial looking ahead [4]. This scheme checks each future variable only with other future variables later than it, thus performing directional arc consistency at each step <ref> [2] </ref>. As noted in [4], partial looking ahead makes about half the consistency checks of full looking ahead. Partial looking ahead is described in Fig. 9. A comparison of all algorithms discussed in the paper is shown in Fig. 10.
Reference: [3] <author> M. J. Dent and R. E. Mercer. </author> <title> Minimal forward checking. </title> <type> Technical Report 374, </type> <institution> The University of Western Ontario, Dept. of Computer Science, </institution> <year> 1993. </year>
Reference-contexts: On such problems the look-ahead that forward checking does is too time-consuming, and the benefits too small, as future dead-ends are rarely uncovered. It may be better do perform minimal forward checking as suggested in <ref> [3] </ref>, or backtracking or backjumping with no look-ahead component.
Reference: [4] <author> R. M. Haralick and G. L. Elliott. </author> <title> Increasing Tree Search Efficiency for Constraint Satisfaction Problems. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 263-313, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction In 1980, Haralick and Elliott <ref> [4] </ref> introduced the forward checking algorithm, as well as two variants which they called partial looking ahead and full looking ahead. All three algorithms can be used to solve constraint satisfaction problems, that is, to find one or more consistent solutions, or to prove that no consistent solution exists. <p> Over the last 15 years, forward checking has become one of the primary algorithms in the CSP-solver's arsenal, while partial and full looking ahead have received little attention. This neglect is due, no doubt, in large part to the conclusions reached in <ref> [4] </ref>: "The checks of future with future units do not discover inconsistencies often enough to justify the large number of tests required." In this paper we have three goals. <p> A constraint satisfaction problem can be represented by a constraint graph which has a node for each variable and an arc connecting each pair of variables that are contained in a constraint. 2.2 Forward Checking The essential idea of forward checking <ref> [4] </ref> is that when a variable X is instantiated with a value x from its domain, the domain of each future (uninstantiated) variable Y is examined, and if a value y is found such that X = x conflicts with Y = y, then the value y is temporarily removed from <p> It is called with an argument Alg which determines whether full looking ahead ("FLA") or any of the variants we present later is to be run. Our forward checking and full looking ahead algorithms are essentially the same as the ones presented in <ref> [4] </ref>, with several differences worth noting. Most immediately apparent, we do not present the algorithms recursively, primarily because this follows our implementation in C. Another significant difference has to do with our reliance on a dynamic variable ordering heuristic embodied in the SelectNextVar () function. <p> This function always selects a variable with an empty current domain, if one is available. Therefore, when our version of the algorithm detects that selecting a certain value x will lead to an empty domain in the future, it does not immediately reject x (as does the procedure in <ref> [4] </ref>). Instead, the tree-depth variable d is incremented, and on the next level of the search the empty-domain variable is encountered. This variable is a dead-end, and d is then decremented. <p> This variable is a dead-end, and d is then decremented. There is no difference between the two approaches in terms of consistency checks, and a negligible difference in CPU time. Another small difference is that our algorithm does not call full-looking-ahead () (called "look-future" in <ref> [4] </ref>) if an empty domain has been detected. In addition to SelectNextVar, our pseudo-code refers to two other functions which are not explicitly defined. ConstraintBetween returns a boolean value which is true if there exists a constraint which includes the two variables specified in the function's arguments, and false otherwise. <p> This function can be implemented with a static table created before processing begins. Its use can significantly speed up processing. The Relation (X,x,Y,y) function is based on one with the same name in <ref> [4] </ref>. <p> In a dynamic variable ordering, the order of variables is determined as the search progresses, and can vary from one branch of the search tree to another. We use a dynamic variable ordering scheme proposed in <ref> [4] </ref> and widely adopted today: always select next the variable with the smallest remaining current domain (i.e. D 0 ). If D 0 d;i is empty for some uninstantiated variable X i , then X i is moved to be the next variable, and a dead-end occurs immediately. <p> The goal is to do enough looking ahead to effectively guide the variable ordering heuristic. It would be remiss not to mention one of the original variants of looking ahead, called partial looking ahead <ref> [4] </ref>. This scheme checks each future variable only with other future variables later than it, thus performing directional arc consistency at each step [2]. As noted in [4], partial looking ahead makes about half the consistency checks of full looking ahead. Partial looking ahead is described in Fig. 9. <p> It would be remiss not to mention one of the original variants of looking ahead, called partial looking ahead <ref> [4] </ref>. This scheme checks each future variable only with other future variables later than it, thus performing directional arc consistency at each step [2]. As noted in [4], partial looking ahead makes about half the consistency checks of full looking ahead. Partial looking ahead is described in Fig. 9. A comparison of all algorithms discussed in the paper is shown in Fig. 10. <p> paper, the ideal might be an algorithm always does the "right" amount of looking ahead, from as little as backtracking, through forward checking and full looking 13 ahead, to full arc consistency at each instantiation. 6 Conclusion We have presented experimental evidence that the full looking ahead algorithm developed in <ref> [4] </ref> is often preferable to forward checking, at least in conjunction with dynamic variable ordering and on hard problems with tight constraints. Three new looking ahead algorithms, truncated looking ahead, self-adjusting looking ahead, and smart looking ahead, were shown experimentally to have some desirable characteristics.
Reference: [5] <author> A. K. Mackworth. </author> <title> Consistency in networks of relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8(1) </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference-contexts: The additional processing done by full looking ahead is a limited form of arc-consistency, in effect performing a single iteration of the "revise" procedure described in <ref> [5] </ref>. Suppose there are three future variables, X with current domain fa; bg, Y with current domain fa; bg and Z with current domain fbg. There is an inequality constraint (as in graph coloring) between X and Y and between Y and Z.
Reference: [6] <author> David Mitchell, Bart Selman, and Hector Levesque. </author> <title> Hard and Easy Distributions of SAT Problems. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 459-465, </pages> <year> 1992. </year> <month> 14 </month>
Reference-contexts: The specific constraints are chosen randomly from a uniform distribution. Certain combinations of parameters generate problems of which about 50% are satisfiable; such problems are on average much more difficult than those which almost all have solutions (under-constrained) or which almost never have solutions (over-constrained) <ref> [1, 6] </ref>. Such a set of parameters is sometimes called a cross-over point.
References-found: 6

