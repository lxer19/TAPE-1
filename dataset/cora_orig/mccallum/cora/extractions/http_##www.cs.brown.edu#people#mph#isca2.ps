URL: http://www.cs.brown.edu/people/mph/isca2.ps
Refering-URL: http://www.cs.brown.edu/people/mph/isca93.html
Root-URL: http://www.cs.brown.edu/
Email: herlihy@crl.dec.com  moss@cs.umass.edu  
Title: Transactional Memory: Architectural Support for Lock-Free Data Structures  
Author: Maurice Herlihy J. Eliot B. Moss 
Address: Cambridge MA 02139  Amherst, MA 01003  
Affiliation: Digital Equipment Corporation Cambridge Research Laboratory  Dept. of Computer Science University of Massachusetts  
Abstract: A shared data structure is lock-free if its operations do not require mutual exclusion. If one process is interrupted in the middle of an operation, other processes will not be prevented from operating on that object. In highly concurrent systems, lock-free data structures avoid common problems associated with conventional locking techniques, including priority inversion, convoying, and difficulty of avoiding deadlock. This paper introduces transactional memory, a new multiprocessor architecture intended to make lock-free synchronization as efficient (and easy to use) as conventional techniques based on mutual exclusion. Transactional memory allows programmers to define customized read-modify-write operations that apply to multiple, independently-chosen words of memory. It is implemented by straightforward extensions to any multiprocessor cache-coherence protocol. Simulation results show that transactional memory matches or outperforms the best known locking techniques for simple benchmarks, even in the absence of priority inversion, convoying, and deadlock. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal et al. </author> <title> The MIT Alewife machine: A large-scale distributed-memory multiprocessor. </title> <type> Technical Report TM-454, </type> <institution> MIT Lab for Computer Science, 545 Technology Square, </institution> <address> Cambridge MA 02139, </address> <month> March </month> <year> 1991. </year> <note> Extended version submitted for publication. </note>
Reference-contexts: Proteus does not capture the effects of instruction caches or local caches. We implemented two versions of transactional memory, one based on Goodman's snoopy protocol for a bus-based architecture, and one based on the Chaiken directory protocol for a (simulated) Alewife machine <ref> [1] </ref>. Our motive in choosing these particular protocols was simply ease of implementation: the Proteus release includes implementations of both. As noted below, a more complex snoopy protocol could make spin locks more efficient. Both simulated architectures use 32 processors.
Reference: [2] <author> J. Allemany and E.W. Felton. </author> <title> Performance issues in non-blocking synchronization on shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 11th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 125-134. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1992. </year>
Reference-contexts: Deadlock avoidance can be awkward if processes must lock multiple data objects, particularly if the set of objects is not known in advance. A number of researchers have investigated techniques for implementing lock-free concurrent data structures using software techniques <ref> [2, 4, 19, 25, 26, 32] </ref>. Experimental evidence suggests that in the absence of inversion, convoying, or deadlock, software implementations of lock-free data structures often do not perform as well as their locking-based counterparts.
Reference: [3] <author> T.E. Anderson. </author> <title> The performance of spin lock alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Page 2 A more complex transaction, such as one that chains down a linked list (see Figure 3), would alternate LT and VALIDATE instructions. When contention is high, programmers are advised to apply adaptive backoff <ref> [3, 28] </ref> before retrying. The VALIDATE instruction is motivated by considerations of software engineering. A set of values in memory is inconsistent if it could not have been produced by any serial execution of transactions. <p> (&new-&gt;prev, old_tail); if (old_tail == NULL) - ST (&Head, new); else ST (&old_tail-&gt;next, new); - ST (&Tail, new); if (COMMIT ()) return; - wait = random () % (01 &lt;< backoff); while (wait--); if (backoff &lt; BACKOFF_MAX) backoff++; - mechanisms were (1) test-and-test-and-set (TTS) [30] spin locks with exponential backoff <ref> [3, 28] </ref>, and (2) software queueing [3, 17, 27]. The hardware mechanisms were (1) LOAD LINKED/STORE COND (LL/SC) with exponential backoff, and (2) hardware queueing [16]. <p> - ST (&Head, new); else ST (&old_tail-&gt;next, new); - ST (&Tail, new); if (COMMIT ()) return; - wait = random () % (01 &lt;< backoff); while (wait--); if (backoff &lt; BACKOFF_MAX) backoff++; - mechanisms were (1) test-and-test-and-set (TTS) [30] spin locks with exponential backoff [3, 28], and (2) software queueing <ref> [3, 17, 27] </ref>. The hardware mechanisms were (1) LOAD LINKED/STORE COND (LL/SC) with exponential backoff, and (2) hardware queueing [16]. For a single-word counter benchmark, we ran the LL/SC implementation directly on the shared variable, while on the others we used LL/SC to implement a spin lock. <p> We now give a brief review of these techniques. A spin lock is perhaps the simplest way to implement mutual exclusion. Each processor repeatedly applies a test-and-set operation until it succeeds in acquiring the lock. As discussed in more detail by Anderson <ref> [3] </ref>, this nave technique performs poorly because it consumes excessive amounts of processor-to-memory bandwidth. <p> Even better performance is achieved by introducing an exponential delay after each unsuccessful attempt to acquire a lock <ref> [3, 27] </ref>. Because Anderson and Mellor-Crummey et al. have shown that TTS locks with exponential backoff substantially outperform conventional TTS locks on small-scale machines, it is a natural choice for our experiments. The LL operation copies the value of a shared variable to a local variable. <p> In software queuing, a process that is unable to acquire a lock places itself on a software queue, thus eliminating the need to poll the lock. Variations of queue locks have been proposed by Anderson <ref> [3] </ref>, by Mellor-Crummey and Scott [27], and by Graunke and Thakkar [17]. Our simulations use the algorithm of Mellor-Crummey and Scott. In hardware queuing, queue maintenance is incorporated into the cache coherence protocol itself. <p> Note that despite superficial similarities in terminology, the synchronization mechanisms provided by transactional memory and by the 801 are intended for entirely different purposes, and use entirely different techniques. Our approach to performance issues has been heavily influenced by recent work on locking in multiprocessors, including work of Anderson <ref> [3] </ref>, Bershad [4], Graunke and Thakkar [17], and Mellor-Crummey and Scott [27]. 7 Conclusions The primary goal of transactional memory is to make it easier to perform general atomic updates of multiple independent memory words, avoiding the problems of locks (priority inversion, convoying, and deadlock).
Reference: [4] <author> B.N. Bershad. </author> <title> Practical considerations for lock-free concurrent objects. </title> <type> Technical Report CMU-CS-91-183, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: Deadlock avoidance can be awkward if processes must lock multiple data objects, particularly if the set of objects is not known in advance. A number of researchers have investigated techniques for implementing lock-free concurrent data structures using software techniques <ref> [2, 4, 19, 25, 26, 32] </ref>. Experimental evidence suggests that in the absence of inversion, convoying, or deadlock, software implementations of lock-free data structures often do not perform as well as their locking-based counterparts. <p> Our approach to performance issues has been heavily influenced by recent work on locking in multiprocessors, including work of Anderson [3], Bershad <ref> [4] </ref>, Graunke and Thakkar [17], and Mellor-Crummey and Scott [27]. 7 Conclusions The primary goal of transactional memory is to make it easier to perform general atomic updates of multiple independent memory words, avoiding the problems of locks (priority inversion, convoying, and deadlock).
Reference: [5] <author> E. A. Brewer, C. N. Dellarocas, A. Colbrook, and W. E. Weihl. PROTEUS: </author> <title> A high-performance parallel architecture simulator. </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: Because transactional memory has no such locks, it typically requires fewer memory accesses. We modified a copy of the Proteus simulator <ref> [5] </ref> to support transactional memory. Proteus is an execution-driven simulator system for multiprocessors developed by Eric Brewer and Chris Dellarocas of MIT. The program to be simulated is written in a superset of C.
Reference: [6] <author> D. Chaiken, J. Kubiatowicz, and A. Agarwal. </author> <title> LimitLESS directories: a scalable cache coherence scheme. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Langauges and Operating Systems, </booktitle> <pages> pages 224-234. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: For programs to be portable, the instruction set architecture must guarantee a minimum transaction size, thus establishing a lower bound for the transactional cache size. An alternative approach is suggested by the LimitLESS directory-based cache coherence scheme of Chaiken, Ku-biatowicz, and Agarwal <ref> [6] </ref>. This scheme uses a fast, fixed-size hardware implementation for directories. If a directory overflows, the protocol traps into software, and the software emulates a larger directory. A similar approach might be used to respond to transactional cache overflow.
Reference: [7] <author> A. Chang and M.F. Mergen. </author> <title> 801 storage: Architecture and programming. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 28-50, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Other researchers who have investigated architectural support for multi-word synchronization include Knight [23], who suggests using cache coherence protocols to add parallelism to mostly functional LISP programs, and the IBM 801 <ref> [7] </ref>, which provides support for database-style locking in hardware. Note that despite superficial similarities in terminology, the synchronization mechanisms provided by transactional memory and by the 801 are intended for entirely different purposes, and use entirely different techniques.
Reference: [8] <author> Michel Dubois and Christoph Scheurich. </author> <title> Memory access dependencies in shared-memory multiprocessors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(6) </volume> <pages> 660-673, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Some kind of hardware queueing mechanism [16] might alleviate this limitation. The cache coherence protocols used in our simulations provide a sequentially consistent memory [24]. A number of researchers have proposed weaker notions of correctness that permit more efficient implementations. These alternatives include processor consistency [14], weak consistency <ref> [9, 8] </ref>, release consistency [13], and others 5 .
Reference: [9] <author> Michel Dubois, Christoph Scheurich, and Faye Briggs. </author> <title> Memory access buffering in multiprocessors. </title> <booktitle> In Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 434-442, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: Some kind of hardware queueing mechanism [16] might alleviate this limitation. The cache coherence protocols used in our simulations provide a sequentially consistent memory [24]. A number of researchers have proposed weaker notions of correctness that permit more efficient implementations. These alternatives include processor consistency [14], weak consistency <ref> [9, 8] </ref>, release consistency [13], and others 5 .
Reference: [10] <author> M. Franklin and G. S. Sohi. </author> <title> The expandable split window paradigm for exploiting fine-grain parallelism. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 58-67. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: Other work that uses after-the-fact conflict detection to recognize violations of desired correctness conditions include Gharachorloo and Gibbons [11], who propose an implementation of release consistency that exploits an underlying invalidation-based cache protocol to detect violations of sequential consistency, and Franklin and Sohi <ref> [10] </ref>, who propose a hardware architecture that optimistically parallelizes sequential code at runtime.
Reference: [11] <author> K. Gharachorloo and P. Gibbons. </author> <title> Detecting violations of sequential consistency. </title> <booktitle> In Proceedings Page 11 of the 2nd Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 316-326, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Massalin and Pu [25] use this instruction for lock-free list manipulation in an operating system kernel. Transactional memory provides more powerful support for this lock-free style of programming. Other work that uses after-the-fact conflict detection to recognize violations of desired correctness conditions include Gharachorloo and Gibbons <ref> [11] </ref>, who propose an implementation of release consistency that exploits an underlying invalidation-based cache protocol to detect violations of sequential consistency, and Franklin and Sohi [10], who propose a hardware architecture that optimistically parallelizes sequential code at runtime.
Reference: [12] <author> Kourosh Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> Performance evaluation of memory consistency models for shared-memory multiprocessors. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 245-257, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: A number of researchers have proposed weaker notions of correctness that permit more efficient implementations. These alternatives include processor consistency [14], weak consistency [9, 8], release consistency [13], and others 5 . Most of these models guarantee that memory will appear to be 5 See Gharachorloo et al. <ref> [12] </ref> for concise descriptions of these models as well as performance comparisons. sequentially consistent as long as the programmer executes a barrier (or fence) instruction at the start and finish of each critical section.
Reference: [13] <author> Kourosh Gharachorloo, Dan Lenoski, James Laudon, Phillip Gibbons, Anoop Gupta, and John Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The cache coherence protocols used in our simulations provide a sequentially consistent memory [24]. A number of researchers have proposed weaker notions of correctness that permit more efficient implementations. These alternatives include processor consistency [14], weak consistency [9, 8], release consistency <ref> [13] </ref>, and others 5 .
Reference: [14] <author> James R. Goodman. </author> <title> Cache consistency and sequential consistency. </title> <type> Technical Report 61, </type> <institution> SCI Committee, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: Some kind of hardware queueing mechanism [16] might alleviate this limitation. The cache coherence protocols used in our simulations provide a sequentially consistent memory [24]. A number of researchers have proposed weaker notions of correctness that permit more efficient implementations. These alternatives include processor consistency <ref> [14] </ref>, weak consistency [9, 8], release consistency [13], and others 5 .
Reference: [15] <author> J.R. Goodman. </author> <title> Using cache memory to reduce processor-memory traffic. </title> <booktitle> In Proceedings of the 12th International Symposium on Computer Architecture, </booktitle> <pages> pages 124-131. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1983. </year>
Reference-contexts: Alternative strategies are discussed in [20]. 3.1 Example implementation We describe here how to extend Goodman's snoopy protocol for a shared bus <ref> [15] </ref> to support transactional memory. (See [20] for similar extensions to a directory-based protocol.) We first describe the general implementation strategy, the various cache line states, and possible bus cycles. <p> In the bus architecture, the TTS spin lock suffers because of an artifact of the particular snoopy cache protocol we adapted <ref> [15] </ref>: the first time a location is modified, it is marked reserved and written back.
Reference: [16] <author> J.R. Goodman, M.K. Vernon, and P.J. Woest. </author> <title> Efficient synchronization primitives for large-scale cache-coherent multiprocessors. </title> <booktitle> In Proceedings of the 3rd International Conference on Architectural Support for Programming Languates and Operating Systems, </booktitle> <pages> pages 64-75, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: The hardware mechanisms were (1) LOAD LINKED/STORE COND (LL/SC) with exponential backoff, and (2) hardware queueing <ref> [16] </ref>. For a single-word counter benchmark, we ran the LL/SC implementation directly on the shared variable, while on the others we used LL/SC to implement a spin lock. Both software mechanisms perform synchronization in-line, and all schemes that use exponential backoff use the same fixed minimum and maximum backoff durations. <p> The queue's head is kept in memory, and unused cache lines are used to hold the queue elements. The directory-based scheme must also keep the queue tail in memory. Our simulations use a Page 7 queuing scheme roughly based on the QOSB mechanism of Goodman et al. <ref> [16] </ref>. 5.1 Counting Benchmark In our first benchmark (code in Figure 1), each of n processes increments a shared counter 2 16 =n times, where n ranges from 1 to 32. In this benchmark, transactions and critical sections are very short (two shared memory accesses) and contention is correspondingly high. <p> Our simulations suggest that adaptive backoff works reasonably well when conflicting transactions have approximately the same duration. If durations differ, however, then longer transactions will be more likely to abort. Some kind of hardware queueing mechanism <ref> [16] </ref> might alleviate this limitation. The cache coherence protocols used in our simulations provide a sequentially consistent memory [24]. A number of researchers have proposed weaker notions of correctness that permit more efficient implementations.
Reference: [17] <author> G. Graunke and S. Thakkar. </author> <title> Synchronization algorithms for shared-memory multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 23(6) </volume> <pages> 60-70, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: - ST (&Head, new); else ST (&old_tail-&gt;next, new); - ST (&Tail, new); if (COMMIT ()) return; - wait = random () % (01 &lt;< backoff); while (wait--); if (backoff &lt; BACKOFF_MAX) backoff++; - mechanisms were (1) test-and-test-and-set (TTS) [30] spin locks with exponential backoff [3, 28], and (2) software queueing <ref> [3, 17, 27] </ref>. The hardware mechanisms were (1) LOAD LINKED/STORE COND (LL/SC) with exponential backoff, and (2) hardware queueing [16]. For a single-word counter benchmark, we ran the LL/SC implementation directly on the shared variable, while on the others we used LL/SC to implement a spin lock. <p> In software queuing, a process that is unable to acquire a lock places itself on a software queue, thus eliminating the need to poll the lock. Variations of queue locks have been proposed by Anderson [3], by Mellor-Crummey and Scott [27], and by Graunke and Thakkar <ref> [17] </ref>. Our simulations use the algorithm of Mellor-Crummey and Scott. In hardware queuing, queue maintenance is incorporated into the cache coherence protocol itself. The queue's head is kept in memory, and unused cache lines are used to hold the queue elements. <p> Our approach to performance issues has been heavily influenced by recent work on locking in multiprocessors, including work of Anderson [3], Bershad [4], Graunke and Thakkar <ref> [17] </ref>, and Mellor-Crummey and Scott [27]. 7 Conclusions The primary goal of transactional memory is to make it easier to perform general atomic updates of multiple independent memory words, avoiding the problems of locks (priority inversion, convoying, and deadlock).
Reference: [18] <editor> J.N. Gray. </editor> <booktitle> Notes on Database Operating Systems, </booktitle> <pages> pages 393-481. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1978. </year>
Reference-contexts: Of course, VALIDATE is not always needed, but it simplifies the writing of correct transactions and improves performance by eliminating the need for ad-hoc checks. Our transactions satisfy the same formal serializability and atomicity properties as database-style transactions (viz. <ref> [18] </ref>), but they are intended to be used very differently. Unlike database transactions, our transactions are short-lived activities that access a relatively small number of memory locations in primary memory.
Reference: [19] <author> M.P. Herlihy. </author> <title> A methodology for implementing highly concurrent data structures. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 197-206, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Deadlock avoidance can be awkward if processes must lock multiple data objects, particularly if the set of objects is not known in advance. A number of researchers have investigated techniques for implementing lock-free concurrent data structures using software techniques <ref> [2, 4, 19, 25, 26, 32] </ref>. Experimental evidence suggests that in the absence of inversion, convoying, or deadlock, software implementations of lock-free data structures often do not perform as well as their locking-based counterparts.
Reference: [20] <author> M.P. Herlihy and J.E.B. Moss. </author> <title> Transactional memory: Architectural support for lock-free data structures. </title> <type> Technical Report 92/07, </type> <institution> Digital Cambridge Research Lab, One Kendall Square, </institution> <address> Cambridge MA 02139, </address> <month> December </month> <year> 1992. </year>
Reference-contexts: An associated technical report <ref> [20] </ref> gives detailed protocols for both bus-based (snoopy cache) and network-based (directory) architectures. <p> This strategy is attractive if one assumes (as we do) that timer (or other) interrupts will abort a stalled transaction after a fixed duration, so there is no danger of a transaction holding resources for too long. Alternative strategies are discussed in <ref> [20] </ref>. 3.1 Example implementation We describe here how to extend Goodman's snoopy protocol for a shared bus [15] to support transactional memory. (See [20] for similar extensions to a directory-based protocol.) We first describe the general implementation strategy, the various cache line states, and possible bus cycles. <p> Alternative strategies are discussed in <ref> [20] </ref>. 3.1 Example implementation We describe here how to extend Goodman's snoopy protocol for a shared bus [15] to support transactional memory. (See [20] for similar extensions to a directory-based protocol.) We first describe the general implementation strategy, the various cache line states, and possible bus cycles.
Reference: [21] <author> E.H. Jensen, G.W. Hagensen, and J.M. Broughton. </author> <title> A new approach to exclusive data access in shared memory multiprocessors. </title> <type> Technical Report UCRL-97663, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: Such frequent barriers would limit performance. We believe our implementation can be extended to require barriers only at transaction start, finish, and validate instructions. 6 Related Work Transactional memory is a direct generalization of the LOAD LINKED and STORE COND instructions originally proposed by Jensen et al. <ref> [21] </ref>, and since incorporated into the MIPS II architecture [29] and Digital's Alpha [31]. The LOAD LINKED instruction is essentially the same as LTX, and STORE COND is a combination of ST and COMMIT.
Reference: [22] <author> N. Jouppi. </author> <title> Improving direct mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In 17th Annual Internationall Symposium on Computer Architecture, </booktitle> <pages> page 364. </pages> <institution> ACM SIGARCH, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: The overall hardware organization is similar to that used by Jouppi for the victim cache <ref> [22] </ref>, and indeed one can readily extend the transactional cache to act as a victim cache as well. The idea is that the transactional cache holds all the tentative writes, without propagating them to other processors or to main memory unless the transaction commits.
Reference: [23] <author> T. Knight. </author> <title> An achitecture for mostly functional languages. </title> <booktitle> In Conference on Lisp and Functional Programming, </booktitle> <pages> pages 105-112, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Other researchers who have investigated architectural support for multi-word synchronization include Knight <ref> [23] </ref>, who suggests using cache coherence protocols to add parallelism to mostly functional LISP programs, and the IBM 801 [7], which provides support for database-style locking in hardware.
Reference: [24] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):241-248, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: If durations differ, however, then longer transactions will be more likely to abort. Some kind of hardware queueing mechanism [16] might alleviate this limitation. The cache coherence protocols used in our simulations provide a sequentially consistent memory <ref> [24] </ref>. A number of researchers have proposed weaker notions of correctness that permit more efficient implementations. These alternatives include processor consistency [14], weak consistency [9, 8], release consistency [13], and others 5 .
Reference: [25] <author> H. Massalin and C. Pu. </author> <title> A lock-free multiprocessor OS kernel. </title> <type> Technical Report CUCS-005-91, </type> <institution> Columbia University Computer Science Dept., </institution> <year> 1991. </year>
Reference-contexts: Deadlock avoidance can be awkward if processes must lock multiple data objects, particularly if the set of objects is not known in advance. A number of researchers have investigated techniques for implementing lock-free concurrent data structures using software techniques <ref> [2, 4, 19, 25, 26, 32] </ref>. Experimental evidence suggests that in the absence of inversion, convoying, or deadlock, software implementations of lock-free data structures often do not perform as well as their locking-based counterparts. <p> Transactional memory has the same flexibility, but can operate on multiple, independently-chosen words. We are not the first to observe the utility of performing Page 9 atomic operations on multiple locations. For example, the Motorola 68000 provides a COMPARE&SWAP2 that operates on two independent locations. Massalin and Pu <ref> [25] </ref> use this instruction for lock-free list manipulation in an operating system kernel. Transactional memory provides more powerful support for this lock-free style of programming.
Reference: [26] <author> J.M. Mellor-Crummey. </author> <title> Practical fetch-and-phi algorithms. </title> <type> Technical Report Technical Report 229, </type> <institution> Computer Science Dept., University of Rochester, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: Deadlock avoidance can be awkward if processes must lock multiple data objects, particularly if the set of objects is not known in advance. A number of researchers have investigated techniques for implementing lock-free concurrent data structures using software techniques <ref> [2, 4, 19, 25, 26, 32] </ref>. Experimental evidence suggests that in the absence of inversion, convoying, or deadlock, software implementations of lock-free data structures often do not perform as well as their locking-based counterparts.
Reference: [27] <author> John M. Mellor-Crummey and Michael L. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: - ST (&Head, new); else ST (&old_tail-&gt;next, new); - ST (&Tail, new); if (COMMIT ()) return; - wait = random () % (01 &lt;< backoff); while (wait--); if (backoff &lt; BACKOFF_MAX) backoff++; - mechanisms were (1) test-and-test-and-set (TTS) [30] spin locks with exponential backoff [3, 28], and (2) software queueing <ref> [3, 17, 27] </ref>. The hardware mechanisms were (1) LOAD LINKED/STORE COND (LL/SC) with exponential backoff, and (2) hardware queueing [16]. For a single-word counter benchmark, we ran the LL/SC implementation directly on the shared variable, while on the others we used LL/SC to implement a spin lock. <p> Even better performance is achieved by introducing an exponential delay after each unsuccessful attempt to acquire a lock <ref> [3, 27] </ref>. Because Anderson and Mellor-Crummey et al. have shown that TTS locks with exponential backoff substantially outperform conventional TTS locks on small-scale machines, it is a natural choice for our experiments. The LL operation copies the value of a shared variable to a local variable. <p> In software queuing, a process that is unable to acquire a lock places itself on a software queue, thus eliminating the need to poll the lock. Variations of queue locks have been proposed by Anderson [3], by Mellor-Crummey and Scott <ref> [27] </ref>, and by Graunke and Thakkar [17]. Our simulations use the algorithm of Mellor-Crummey and Scott. In hardware queuing, queue maintenance is incorporated into the cache coherence protocol itself. The queue's head is kept in memory, and unused cache lines are used to hold the queue elements. <p> Our approach to performance issues has been heavily influenced by recent work on locking in multiprocessors, including work of Anderson [3], Bershad [4], Graunke and Thakkar [17], and Mellor-Crummey and Scott <ref> [27] </ref>. 7 Conclusions The primary goal of transactional memory is to make it easier to perform general atomic updates of multiple independent memory words, avoiding the problems of locks (priority inversion, convoying, and deadlock).
Reference: [28] <author> R. Metcalfe and D. Boggs. </author> <title> Ethernet: distributed packet switching for local computer networks. </title> <journal> Communications of the ACM, </journal> <volume> 19(7) </volume> <pages> 395-404, </pages> <month> July </month> <year> 1976. </year>
Reference-contexts: Page 2 A more complex transaction, such as one that chains down a linked list (see Figure 3), would alternate LT and VALIDATE instructions. When contention is high, programmers are advised to apply adaptive backoff <ref> [3, 28] </ref> before retrying. The VALIDATE instruction is motivated by considerations of software engineering. A set of values in memory is inconsistent if it could not have been produced by any serial execution of transactions. <p> (&new-&gt;prev, old_tail); if (old_tail == NULL) - ST (&Head, new); else ST (&old_tail-&gt;next, new); - ST (&Tail, new); if (COMMIT ()) return; - wait = random () % (01 &lt;< backoff); while (wait--); if (backoff &lt; BACKOFF_MAX) backoff++; - mechanisms were (1) test-and-test-and-set (TTS) [30] spin locks with exponential backoff <ref> [3, 28] </ref>, and (2) software queueing [3, 17, 27]. The hardware mechanisms were (1) LOAD LINKED/STORE COND (LL/SC) with exponential backoff, and (2) hardware queueing [16].
Reference: [29] <institution> MIPS Computer Company. The MIPS RISC architecture. </institution>
Reference-contexts: If the operation does not succeed, it leaves the shared variable unchanged. The LL/SC operations are the principal synchronization primitives provided by the MIPS II architecture <ref> [29] </ref> and Digital's Alpha [31]. On a cache-coherent architecture, these operations are implemented as single-word transactions a SC succeeds if the processor retains exclusive access to the entry read by the LL. <p> We believe our implementation can be extended to require barriers only at transaction start, finish, and validate instructions. 6 Related Work Transactional memory is a direct generalization of the LOAD LINKED and STORE COND instructions originally proposed by Jensen et al. [21], and since incorporated into the MIPS II architecture <ref> [29] </ref> and Digital's Alpha [31]. The LOAD LINKED instruction is essentially the same as LTX, and STORE COND is a combination of ST and COMMIT. The LOAD LINKED/STORE COND combination can implement any read-modify-write operation, but it is restricted to a single word.
Reference: [30] <author> L. Rudolph and Z. Segall. </author> <title> Dynamic decentralized cache schemes for MIMD parallel processors. </title> <booktitle> In 11th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 340-347, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: (&Tail); if (VALIDATE ()) - ST (&new-&gt;prev, old_tail); if (old_tail == NULL) - ST (&Head, new); else ST (&old_tail-&gt;next, new); - ST (&Tail, new); if (COMMIT ()) return; - wait = random () % (01 &lt;< backoff); while (wait--); if (backoff &lt; BACKOFF_MAX) backoff++; - mechanisms were (1) test-and-test-and-set (TTS) <ref> [30] </ref> spin locks with exponential backoff [3, 28], and (2) software queueing [3, 17, 27]. The hardware mechanisms were (1) LOAD LINKED/STORE COND (LL/SC) with exponential backoff, and (2) hardware queueing [16]. <p> Each processor repeatedly applies a test-and-set operation until it succeeds in acquiring the lock. As discussed in more detail by Anderson [3], this nave technique performs poorly because it consumes excessive amounts of processor-to-memory bandwidth. On a cache-coherent architecture, the test-and-test-and-set <ref> [30] </ref> protocol achieves somewhat better performance by repeatedly rereading the cached value of the lock (generating no memory traffic), until it observes the lock is free, and then applying the test-and-set operation directly to the lock in memory.
Reference: [31] <author> R.L. </author> <title> Sites. Alpha Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <address> Maynard, MA, </address> <year> 1992. </year>
Reference-contexts: If the operation does not succeed, it leaves the shared variable unchanged. The LL/SC operations are the principal synchronization primitives provided by the MIPS II architecture [29] and Digital's Alpha <ref> [31] </ref>. On a cache-coherent architecture, these operations are implemented as single-word transactions a SC succeeds if the processor retains exclusive access to the entry read by the LL. <p> The larger the data set, the larger the transactional cache needed, and (perhaps) the more likely a synchronization conflict will occur. 4 The identical concerns apply to current implementations of the LOAD LINKED and STORE COND instructions <ref> [31, Appendix A] </ref>. Page 8 Such size and length restrictions are reasonable for applications that would otherwise have used short critical sections, but not for applications that would otherwise lock large objects for a long time (such as navigating a B-link tree with a large node size). <p> can be extended to require barriers only at transaction start, finish, and validate instructions. 6 Related Work Transactional memory is a direct generalization of the LOAD LINKED and STORE COND instructions originally proposed by Jensen et al. [21], and since incorporated into the MIPS II architecture [29] and Digital's Alpha <ref> [31] </ref>. The LOAD LINKED instruction is essentially the same as LTX, and STORE COND is a combination of ST and COMMIT. The LOAD LINKED/STORE COND combination can implement any read-modify-write operation, but it is restricted to a single word.
Reference: [32] <author> J. Wing and C. Gong. </author> <title> Testing and verifying concurrent objects. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 17(2), </volume> <month> February </month> <year> 1993. </year> <pages> Page 12 </pages>
Reference-contexts: Deadlock avoidance can be awkward if processes must lock multiple data objects, particularly if the set of objects is not known in advance. A number of researchers have investigated techniques for implementing lock-free concurrent data structures using software techniques <ref> [2, 4, 19, 25, 26, 32] </ref>. Experimental evidence suggests that in the absence of inversion, convoying, or deadlock, software implementations of lock-free data structures often do not perform as well as their locking-based counterparts.
References-found: 32

