URL: http://www.cs.yale.edu/users/toyama/papers/iros95short.ps.gz
Refering-URL: http://www.cs.yale.edu/users/toyama/toyama.html
Root-URL: http://www.cs.yale.edu
Title: Keeping Your Eye on the Ball: Tracking Occluding Contours of Unfamiliar Objects without Distraction  
Author: Kentaro Toyama and Gregory D. Hager 
Address: P.O. Box 208285 New Haven, CT 06520  
Affiliation: Department of Computer Science Yale University,  
Abstract: Visual tracking is prone to distractions, where features similar to the target features guide the tracker away from its intended object. Global shape models and dynamic models are necessary for completely distraction-free contour tracking, but there are cases when component feature trackers alone can be expected to avoid distraction. We define the tracking problem in general and devise a method for local, window-based, feature trackers to track accurately in spite of background distractions. The algorithm is applied to a generic line tracker and a snake-like contour tracker which are then analyzed with respect to previous contour-trackers. We discuss the advantages and disadvantages of our approach and suggest that existing model-based trackers can be improved by incorporating similar techniques at the local level. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> Affine-invariant contour tracking with automatic control of of strong edges in background. spatiotemporal scale. </title> <booktitle> Proc., Int'l Conf. on Comp. Vision, </booktitle> <year> 1993, </year> <pages> pp. 421-430. </pages>
Reference-contexts: A state space for a feature x is denoted F x : The notation F n stands for Q n i=1 F i where F i ; 1 i n, are arbitrary feature state spaces. The variable t 2 <ref> [0; 1] </ref> represents time. Thus, f i (t) denotes the state of feature i at time t. Systems evolve continuously but are sampled at unit-spaced time instances. Local feature detectors minimize objective functions, which may be temporally dependent or independent. <p> Tracking based on correlative methods works well for matching specific patterns, yet it becomes unreliable in many situations when the pattern is occluded or altered. At the other end of the spectrum lie simple edge detection methods <ref> [1, 2, 4] </ref>. These methods are temporally independent in that they make decisions about a feature's state by observing only the current window. <p> When information about the object motion is available, dynamic models can be used to predict feature location [2, 3, 9]. In constraint-based tracking, no explicit model is used, but feature states are forced to respect one or more constraints C : F m ! &lt; (see <ref> [1] </ref>, for example). Models and constraints allow distractions to be detected and also help to position windows. <p> Distraction occurs because individual components are just high-gradient edge finders and depend upon high-level models to correct them in the case that they stray. While many model- or template-based contour trackers, such as those described in <ref> [1] </ref>, might not be distracted by large deviations from a model, they would still fail in cases where the change in the shape of the contour is small or gradual. maintaining some information about the kind of edges that are tracked, tracking improves significantly.
Reference: [2] <author> E. D. Dickmanns, and V. Graefe. </author> <title> Dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1 </volume> <pages> 223-240, </pages> <year> 1988. </year>
Reference-contexts: Tracking based on correlative methods works well for matching specific patterns, yet it becomes unreliable in many situations when the pattern is occluded or altered. At the other end of the spectrum lie simple edge detection methods <ref> [1, 2, 4] </ref>. These methods are temporally independent in that they make decisions about a feature's state by observing only the current window. <p> In model-based tracking, information about the geometry of features is supplied [7]. When information about the object motion is available, dynamic models can be used to predict feature location <ref> [2, 3, 9] </ref>. In constraint-based tracking, no explicit model is used, but feature states are forced to respect one or more constraints C : F m ! &lt; (see [1], for example). Models and constraints allow distractions to be detected and also help to position windows.
Reference: [3] <author> O. D. Faugeras. </author> <title> Three-Dimensional Computer Vision. </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In model-based tracking, information about the geometry of features is supplied [7]. When information about the object motion is available, dynamic models can be used to predict feature location <ref> [2, 3, 9] </ref>. In constraint-based tracking, no explicit model is used, but feature states are forced to respect one or more constraints C : F m ! &lt; (see [1], for example). Models and constraints allow distractions to be detected and also help to position windows.
Reference: [4] <author> G. Hager, S. Puri, and K. Toyama. </author> <title> A framework for real-time window-based tracking using off-the-shelf hardware. </title> <type> Yale TR: </type> <institution> DCS-RR-988, </institution> <year> 1993. </year>
Reference-contexts: Tracking based on correlative methods works well for matching specific patterns, yet it becomes unreliable in many situations when the pattern is occluded or altered. At the other end of the spectrum lie simple edge detection methods <ref> [1, 2, 4] </ref>. These methods are temporally independent in that they make decisions about a feature's state by observing only the current window. <p> Edges are found by convolving a 1-dimensional discrete derivative mask with the line of pixels in a window and looking for points with gray-scale gradient above a threshold (See <ref> [4] </ref>). Regions between edges and window boundaries are identified by computing the mode of gray-scale values for each region.
Reference: [5] <author> J. Huang and G. D. Hager. </author> <title> Tracking tools for vision-based navigation. </title> <type> Yale TR: </type> <institution> DCS-RR-1060, </institution> <year> 1994. </year>
Reference-contexts: Small changes, for example, in the local brightness can easily ruin a match. We use visual tracking in a variety of applications where specific geometric and dynamic information is not available <ref> [5] </ref>. Without models, our tracking algorithms must rely on local feature detection to perform properly. In this article, we address the question of what can be tracked locally without distraction. We first delineate a set of situations where local tracking can be performed robustly.
Reference: [6] <author> M. Kass, A. Witkin, and D. Terzopoulos. Snakes: </author> <title> active contour models. </title> <journal> Int'l J. of Comp. Vision, </journal> <volume> 1 </volume> <pages> 321-331, </pages> <year> 1987. </year>
Reference-contexts: We note also that SSD-based trackers cannot track constant-valued foregrounds at all. Contours: Our contour tracker is slightly more complex. The only geometric constraint is that the contour is a simple, closed loop. Elements of previous contour trackers are used <ref> [6, 10, 13] </ref>.
Reference: [7] <author> D. G. Lowe. </author> <title> Robust model-based motion tracking through the integration of search and estimation. </title> <journal> Int'l J. of Comp. Vision, </journal> <volume> 8(2) </volume> <pages> 113-122, </pages> <year> 1992. </year>
Reference-contexts: In model-based tracking, information about the geometry of features is supplied <ref> [7] </ref>. When information about the object motion is available, dynamic models can be used to predict feature location [2, 3, 9]. In constraint-based tracking, no explicit model is used, but feature states are forced to respect one or more constraints C : F m ! &lt; (see [1], for example).
Reference: [8] <author> N. P. Papanikolopoulos, P. K. Khosla, T. Kanade. </author> <title> Visual tracking of a moving target by a camera mounted on a robot: a combination of control and vision. </title> <journal> IEEE Trans. on Rob. Automat., </journal> <volume> 9(1) </volume> <pages> 14-35, </pages> <month> Feb, </month> <year> 1993. </year>
Reference-contexts: Temporally dependent objective functions are usually variations of auto-correlation methods, such as sum-of-squared-difference (SSD) matching <ref> [8, 11] </ref>. Tracking based on correlative methods works well for matching specific patterns, yet it becomes unreliable in many situations when the pattern is occluded or altered. At the other end of the spectrum lie simple edge detection methods [1, 2, 4].
Reference: [9] <author> A. A. Rizzi and D. E. Koditschek. </author> <title> An active visual estimator for dexterous manipulation. </title> <booktitle> IEEE Int'l Conf. on Rob. </booktitle> <address> Automat., </address> <year> 1994. </year>
Reference-contexts: In model-based tracking, information about the geometry of features is supplied [7]. When information about the object motion is available, dynamic models can be used to predict feature location <ref> [2, 3, 9] </ref>. In constraint-based tracking, no explicit model is used, but feature states are forced to respect one or more constraints C : F m ! &lt; (see [1], for example). Models and constraints allow distractions to be detected and also help to position windows.
Reference: [10] <author> D. Terzopoulos and Szeliski. </author> <title> Tracking with Kalman snakes Active Vision, </title> <editor> ed. A. Blake and A. Yuille. </editor> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: We note also that SSD-based trackers cannot track constant-valued foregrounds at all. Contours: Our contour tracker is slightly more complex. The only geometric constraint is that the contour is a simple, closed loop. Elements of previous contour trackers are used <ref> [6, 10, 13] </ref>.
Reference: [11] <author> C. Tomasi and T. Kanade. </author> <title> Detection and tracking of point features. </title> <type> Carnegie-Mellon TR, </type> <institution> CMU-CS-91-132, </institution> <month> April, </month> <year> 1991. </year>
Reference-contexts: Temporally dependent objective functions are usually variations of auto-correlation methods, such as sum-of-squared-difference (SSD) matching <ref> [8, 11] </ref>. Tracking based on correlative methods works well for matching specific patterns, yet it becomes unreliable in many situations when the pattern is occluded or altered. At the other end of the spectrum lie simple edge detection methods [1, 2, 4].
Reference: [12] <author> K. Toyama and G. D. Hager. </author> <title> Distraction-Proof Tracking: Keeping One's Eye on the Ball. </title> <type> Yale TR: </type> <institution> DCS-RR-1059, </institution> <year> 1995. </year>
Reference-contexts: The interested reader may wish to refer to a longer version of this article for more results and discussion <ref> [12] </ref>. 2 Background In order to formalize window-based tracking, we define trackers as state-based observers with minimal dynamics. We also explain how model-based tracking fits into our paradigm. 2.1 Tracking formalism We view tracking as a state-based control system.
Reference: [13] <author> D. J. Williams and M. Shah. </author> <title> A fast algorithm for active contours and curvature estimation. </title> <journal> CVGIP: IU, </journal> <volume> 55(1) </volume> <pages> 14-26, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: We note also that SSD-based trackers cannot track constant-valued foregrounds at all. Contours: Our contour tracker is slightly more complex. The only geometric constraint is that the contour is a simple, closed loop. Elements of previous contour trackers are used <ref> [6, 10, 13] </ref>.
References-found: 13

