URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1997/TR25.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: email: sheta@cis.ohio-state.edu, singhal@cis.ohio-state.edu  
Phone: Phone: 614-292-5839 Fax: 614-292-2991  
Title: Scheduling Fork-Join Computations on Distributed-Memory Multiprocessor Systems  
Author: Khalid H. Sheta, Mukesh Singhal Dr. Phillip E. Krueger 
Keyword: Key words: distributed-memory multiprocessors, job scheduling, fork-join computations, performance analysis.  
Address: Columbus, OH 43210  15450 SW Koll Parkway Beaverton, OR 97006  
Affiliation: Department of Computer and Information Science The Ohio State University  Sequent Computer Systems  
Abstract: In this paper, we develop two analytic models for scheduling fork-join computations on distributed-memory multiprocessor system. The first model allows for arriving tasks to multiplex processors with existing tasks, while the other model does not allow multiplexing. Both models assume that tasks block for I/O and that the overhead of rescheduling a task to another processor is prohibitive. We compare the performance of both models in terms of the overall job completion time. We show that multiplexing have a performance advantage over non-multiplexing over a wide range of conditions. We point out how the results can be used in the design of an adaptive multiprocessor scheduler. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D., Dewitt, et. al. </author> <title> "GAMMA A high performance Dataflow Database Machine". </title> <booktitle> In Proc. 12th International Conf. on Very Large Databases, </booktitle> <year> 1986. </year>
Reference: [2] <author> D.Towsley, C.Rommel and J.Stankovic. </author> <title> "Analysis of fork-join program response times on multiprocessors". </title> <journal> In Trans. Parallel and Dist. Systems., volume Vol.1, No.3. IEEE, </journal> <month> July </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Over the past several years, multiprocessor systems have become increasingly important. Many studies have dealt with scheduling concurrent computations on shared-memory multiprocessor systems <ref> [2, 7, 6] </ref> where a task execution can be transferred between processors with relatively little overhead. Due to their scalability, multiprocessors having distributed-memory architectures are particularly promising for large multiprocessors.
Reference: [3] <author> G. Z. Qadah. </author> <title> "The Equi-Join Operation on a Multiprocessor Database Machine: Algorithms and the Evaluation of their Performance". </title> <booktitle> In Fourth International Workshop Grand bahamas Island. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: In particular we focus on fork-join jobs having tasks that block for I/O. Examples of such jobs include parallelized relational database operations, such as those proposed by Dewitt, et al.[1] and Qadah <ref> [3] </ref>. In the remainder of this paper we will use the word job to refer to a fork-join job of the type described above. When a task blocks for I/O, it may become advantageous to multiprogram, or `multiplex' the processor, by running a task from another job on that processor.
Reference: [4] <author> L. Kleinrock. </author> <title> "Queueuing Systems, Volume I: Theory". </title> <publisher> Wiley, </publisher> <year> 1975. </year>
Reference-contexts: We assume that when two tasks are scheduled on the same processor, they share it using the Processor Sharing <ref> [4] </ref> discipline (PS). 2 Because our goal is to determine whether multiplexing can be advantageous under any circumstances, we consider the simplest case in which an arriving job finds a single job already executing. We assume that neither job has more tasks than there are processors in the system.
Reference: [5] <author> R.Nelson,D.Towsley, A.Tantawi. </author> <title> "Peformance Analysis of Parallel Processing Systems". </title> <journal> In Trans. Software Eng., </journal> <volume> volume Vol. 14, </volume> <publisher> No.4. IEEE, </publisher> <month> April </month> <year> 1988. </year>
Reference-contexts: First we find the expected job completion time of the arriving job, and then that of the existing job. Here a processor has at most one task running at any time. Our NONMUX is quite similar to the model described in <ref> [5] </ref>, but we extend the model to 1 If we assume that the probability of having i jobs initially running on i of n processors is binomial, Prfi jobs initially scheduledg = i =2 n , then (1) will have a closed form solution F Y (n) = 1=2 n (F
Reference: [6] <author> S. Majumdar, D.L.Eager and R.B.Bunt. </author> <title> "Scheduling in Multiprogrammed Parallel Systems". </title> <booktitle> In Proceedings of SIGMETRICS Conf. on Meas.& Modeling of Comp. Sys. ACM, </booktitle> <month> May </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Over the past several years, multiprocessor systems have become increasingly important. Many studies have dealt with scheduling concurrent computations on shared-memory multiprocessor systems <ref> [2, 7, 6] </ref> where a task execution can be transferred between processors with relatively little overhead. Due to their scalability, multiprocessors having distributed-memory architectures are particularly promising for large multiprocessors.
Reference: [7] <author> S.T. Leutenegeger and M.K. Vernon. </author> <title> "The performance of Multiprogrammed Multiprocessor Scheduling Policies". </title> <booktitle> In Proceedings of SIGMETRICS Conf. on Meas. & Modeling of Comp. Sys. ACM, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Over the past several years, multiprocessor systems have become increasingly important. Many studies have dealt with scheduling concurrent computations on shared-memory multiprocessor systems <ref> [2, 7, 6] </ref> where a task execution can be transferred between processors with relatively little overhead. Due to their scalability, multiprocessors having distributed-memory architectures are particularly promising for large multiprocessors.
Reference: [8] <author> W.Mendenhall and R.Scheaffer. </author> <title> "Mathematical Statistics with Applications". </title> <publisher> Duxbury Press, </publisher> <year> 1981. </year> <month> 14 </month>
Reference-contexts: We denote that as E (Y (n) ; i). Y (n) is the n th order statistics <ref> [8] </ref> of n distributions where the j th distribution j = 1; 2; :::; n represents the completion time of the j th task of the arriving job.
References-found: 8

