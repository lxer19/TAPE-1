URL: ftp://ftp.cse.unsw.edu.au/pub/doc/papers/UNSW/9402.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/research/tr.html
Root-URL: http://www.cse.unsw.edu.au
Title: A New Transport Protocol for High-speed Networks  
Author: Toong Shoon Chan and Ian Gorton 
Affiliation: SCHOOL OF COMPUTER SCIENCE AND ENGINEERING THE UNIVERSITY OF NEW SOUTH WALES  
Note: HTPNET:  
Abstract: SCS&E Report 9402 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> W. Doeringer, D. Dykeman, M. Kaiserswerth, B. Meiser, H. Rudin and R. Williamson, </author> <title> "A Survey of Lightweight Transport Protocols for Highspeed Networks," </title> <journal> IEEE Trans. Commn., </journal> <volume> vol 38, </volume> <pages> pp. 2057-2071, </pages> <month> Nov </month> <year> 1991. </year>
Reference-contexts: This mismatch in speed reduces data transfer rates between hosts and degrades the overall performance of the underlying network <ref> [1] </ref>. In addition, the evolution of lightwave networks has altered network characteristics, bringing about a higher bandwidth-delay-product and lower error rates. These changed characteristics will have a major impact on the design of future transport protocols. <p> Furthermore, the processing speed at host systems was sufficient to match the transmission speed of the underlying network. This gave rise to 3 protocols that use in-band signalling <ref> [1] </ref> for the exchange of information between peer transport entities. With in-band signalling, the control and data functions are combined together as a single entity. Thus, the actual body of data is encapsulated with all the control information necessary for the reliable transport of data. <p> Therefore, at the receiving end, a simple hardware circuit can be built to identify different packets, which can then be routed to the corresponding processing units. The major advantage of out-of-band signalling is the ability to support parallel architectures efficiently <ref> [1] </ref>. In addition, out-of-band signalling is adaptable to changing needs. New services can be added without incurring any impact on the data transport mechanism.
Reference: 2. <author> W. S. Lai, </author> <title> "Protocols for High Speed Networking," </title> <booktitle> Proc. of INFOCOMM '90, Panel Discussion (June 1990), </booktitle> <pages> pp 1268-1269. </pages>
Reference-contexts: Consequently, the protocol architecture of an X.25 WAN is designed to have error recovery and flow control functions in multiple protocol layers, introducing overlap in the functions <ref> [2] </ref>. However, given the wider application mix and highspeed communication environment of future highspeed broadband networks, duplication of functionality is highly undesirable. In broadband networks like B-ISDN, protocol functions inside the network have been streamlined and are limited only to switching, routing and relaying functions.
Reference: 3. <author> W. R. Bryne, </author> <title> "Broadband ISDN Technology and Architecture," </title> <journal> IEEE Network, </journal> <month> Jan </month> <year> 1989, </year> <pages> pp 7-13. </pages>
Reference-contexts: In broadband networks like B-ISDN, protocol functions inside the network have been streamlined and are limited only to switching, routing and relaying functions. Streamlining of protocols facilitates high speed relaying of data, and is amenable to a custom-built hardware implementation <ref> [3] </ref>. As a consequence, critical functions for providing reliable data transport have been shifted to the host systems. For existing protocols such as TCP/IP, the high overheads associated with protocol processing creates a massive imbalance between the processing capacity of the protocols and the transmission speed of the underlying network.
Reference: 4. <author> M. Zitterbart, </author> <title> "High-Speed Transport Components," </title> <journal> IEEE Network Magazine, </journal> <month> Jan </month> <year> 1991, </year> <pages> pp 54-63. </pages>
Reference-contexts: Another approach that meets cost constraints and yet remains adaptable to changing requirements is the application of parallel processing techniques using commercially available microprocessors such as transputers <ref> [4] </ref>. A network of transputers can be constructed to distribute the protocol processing workload.
Reference: 5. <author> G. Chesson, </author> <title> "The Protocol Engine Project," Unix Review, </title> <month> Sept </month> <year> 1990. </year>
Reference-contexts: Although it is possible to design dedicated hardware for a specific protocol, as demonstrated in XTP <ref> [5] </ref>, the drawback is the difficulty in adapting to changing requirements. Another approach that meets cost constraints and yet remains adaptable to changing requirements is the application of parallel processing techniques using commercially available microprocessors such as transputers [4].
Reference: 6. <author> David D. Clark, Van Jacobson, John Romkey, Howard Salwen, </author> <title> "An Analysis of TCP Processing Overhead," </title> <journal> IEEE Commn. Magazine, </journal> <pages> pp. 23-29, </pages> <month> June </month> <year> 1989. </year> <month> 23 </month>
Reference-contexts: For a highspeed network operating at 1Gb/s, with a packet size of 1 Kbytes, a processing time of 8 microseconds for each packet is required. Given that a typical protocol packet would require approximately 250 instructions <ref> [6] </ref>, then the processing speed required merely to support network traffic is about 30 MIPS (Million Instructions Per Second). Therefore, in order to meet the high speed requirements of protocol processing, we believe additional processor support must be provided to offload much of the network overheads from the host system. <p> For a network operating at 100 Mb/s, with packet size of 1K bytes and a RTD of 30 milliseconds, the transmitter will need to manage about 1000 timers at a particular instance of time. This considerable amount of computational overheads would place unacceptable overheads on the transmitter processor <ref> [6] </ref>. In HTPNET, a new mechanism for detecting loss of packets has been incorporated. This mechanism has the advantage of requiring only a coarse estimate of RTD, with low computational overheads of managing a single timer.
Reference: 7. <author> H. Kanakia and D.R. Cheriton, </author> <title> "The VMP Network Adapter Board, High-Performance Network Communication for Multiprocessors," </title> <booktitle> Proc. ACM SIGCOMM Symp.: Communications, Architecture and Protocols, </booktitle> <year> 1988. </year>
Reference-contexts: This approach of separating protocol processing from the main host operating system has been used in the design of VMTP network adapter board <ref> [7] </ref>. Their analysis has shown that 6% of the delay in packet processing is due to network delay, 12% is due to processing on the network adapter board and 88% is due to host processing.
Reference: 8. <author> L. Zhang, </author> <title> "Why TCP Timers Don't Work Well," </title> <booktitle> Proc. ACM SIGCOMM Symp. on Commn., Architectures, and Protocols, </booktitle> <address> Stowe, VT, </address> <year> 1986, </year> <pages> pp 397-405. </pages>
Reference-contexts: Experience with the TCP retransmission timer has clearly shown that timers have limitations in offering optimal performance <ref> [8] </ref>, particularly for highspeed communications. One of the major problems with using timers is the difficulty in obtaining an accurate estimate of the round-trip-delay (RTD) due to lack of information about network topology and dynamics. <p> This is necessary to take into consideration the possibility of excess delay due to congestion in the underlying network. Such RTD estimation often results in nonoptimal timeout value being selected <ref> [8] </ref>, thus affecting the overall throughput performance. In TCP, the implementation of the delta-list [15] for efficient management of timers requires the list to be scanned whenever a timer is inserted or deleted [16].
Reference: 9. <author> Van Jacobsen, </author> <title> "Congestion Avoidance and Control", </title> <booktitle> Proceedings of the ACM SIGCOMM'88, </booktitle> <address> Aug. 1988, Standford CA, pp.314-329. </address>
Reference-contexts: Such continuous over-admission of packets results in buffer overflow at the nodes, thus causing data loss. Consequently, severe congestion may occur due to excessive retransmission by host systems affected by the overrun node (s). If the situation persists, this will eventually lead to a congestion collapse <ref> [9] </ref>. To avoid such congestion, HTPNET is designed with a rate control mechanism which dynamically adapts the rate at which packets are transmitted, based on the situation of the underlying network. 3.
Reference: 10. <author> D. E. Comer, </author> <title> "Internetworking with TCP/IP: </title> <booktitle> Principles, Protocols and Architecture", </booktitle> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1988. </year>
Reference-contexts: To setup a connection, a three-way handshake protocol is used to establish a connection between two end points similar to that of TCP <ref> [10] </ref>. This setup allows the endpoints to negotiate communication parameters and options, including protocol class, available buffer (flow control) and inter-packet gap (rate control). HTPNET is designed with eight variations of protocol classes to provide different quality of services (QOS). Table 1 defines the functions available for different protocol classes. <p> In addition, the implementation of TCP protocol is optimised as much as possible to avoid unnecessary overhead in protocol processing. For example, instead of using explicit timers for each transmitted packet, a delta-list [15] is employed for efficient implementation of timers. An adaptive retransmission algorithm <ref> [10] </ref> is used to compute the timeout for the retransmission timers using the following formulae: RTT = ( a * Old RTT) + ((1-a )*New RTT Sample) Timeout = b * RTT where a is set to 0.9 and b is set to 2.0.
Reference: 11. <author> R. A. Donnann, </author> <title> "Method and System for Retransmitting Incorrectly Received Numbered Frames in a Data Transmission System," </title> <type> U.S. Pat. 439859, </type> <month> Mar. </month> <year> 1984. </year>
Reference-contexts: A unique feature of HTPNET is the transmitter paced periodic exchange of state information between the end systems. The idea of periodic state exchange was first introduced by a data-link protocol known as Checkpoint Mode Protocol (CMP) <ref> [11] </ref>. CMP uses periodic transmission of complete state information via acknowledgments from the receiver to the transmitter for the error control mechanism. More recently, the SNR protocol [12] has employed a similar idea in the exchange of state information in both directions between end systems.
Reference: 12. <author> A. N. Netravali, W. D. Roome, and K. Sabnani, </author> <title> "Design and Implementation of a High Speed Transport Protocol", </title> <journal> IEEE Trans. on Commn., </journal> <volume> vol. 38, no. 11, </volume> <pages> pp 2010-24, </pages> <month> Nov </month> <year> 1990. </year>
Reference-contexts: The idea of periodic state exchange was first introduced by a data-link protocol known as Checkpoint Mode Protocol (CMP) [11]. CMP uses periodic transmission of complete state information via acknowledgments from the receiver to the transmitter for the error control mechanism. More recently, the SNR protocol <ref> [12] </ref> has employed a similar idea in the exchange of state information in both directions between end systems. Importantly, in contrast to SNR which exchanges state information independently between end systems, HTPNET utilises the transmitter node to control the periodical exchange of state information. <p> This example clearly 11 demonstrates how additional services can be added to exploit the parallel architecture of HTPNET, without having any impact on the fundamental data transport mechanism. 4. DISCUSSION The design of HTPNET has been greatly motivated by several protocols, most significantly by SNR <ref> [12] </ref>. SNR is a lightweight transport protocol designed for data communications over high-speed networks. The protocol uses independent periodic state exchange between the transmitter and receiver in both directions for end-to-end state synchronisation.
Reference: 13. <author> Doshi B.T., H.Q. Nguyen, </author> <title> "Congestion Control in ISDN FrameRelay Networks," </title> <journal> AT&T Technical Journal, </journal> <volume> Vol. 67, </volume> <month> Nov-Dec, </month> <year> 1988, </year> <pages> pp. 36-46. </pages>
Reference-contexts: It must be stressed that we view congestion control as a two-level strategy operating on short and medium timescales <ref> [13] </ref>. In contrast to short term control which employs an open-loop strategy, PTIF employs medium term control which uses a close-loop strategy by incorporating feedback signals that convey the status of the network to dynamically adapt the source load.
Reference: 14. <author> D. C. Feldmeier, E. W. Bierack, </author> " <title> Comparison of Error Control Protocols for High-Bandwidth-Delay Product Networks", Protocols for HighSpeed Networks, II, </title> <publisher> IFIP, North-Holland Publisher, </publisher> <year> 1991, </year> <pages> pp 271-295. </pages>
Reference-contexts: Each time a ACK is received, the "timers" associated with the transmitted packets are decremented by k (value k is embedded in the ACK packet), where k is the interval between two consecutive ACK packets. As pointed in <ref> [14] </ref>, SNR exhibits a behaviour known as timeslipping. The retransmission time of the blocks at the transmitter relies heavily on the arrival of ACKs. However, if an ACK is lost along the way, then timeslips will occur.
Reference: 15. <author> D. E. Comer, D. L. Stevens, </author> <title> "Internetworking with TCP/IP Vol 2: Design, Implementation, and Internals", </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1991. </year>
Reference-contexts: This is necessary to take into consideration the possibility of excess delay due to congestion in the underlying network. Such RTD estimation often results in nonoptimal timeout value being selected [8], thus affecting the overall throughput performance. In TCP, the implementation of the delta-list <ref> [15] </ref> for efficient management of timers requires the list to be scanned whenever a timer is inserted or deleted [16]. In a highspeed network, with large bandwidth-delay product, this would incur considerable computational overheads in managing the list. <p> In addition, the implementation of TCP protocol is optimised as much as possible to avoid unnecessary overhead in protocol processing. For example, instead of using explicit timers for each transmitted packet, a delta-list <ref> [15] </ref> is employed for efficient implementation of timers.
Reference: 16. <author> D. C. Feldmeier, </author> <title> "A Survey of High Performance Protocol Implementation Techniques", in High Performance Networks - Technology and Protocols, Chapter 2, </title> <editor> Ahmed Tantawy editor, </editor> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year> <title> 17. "Occam 2 Reference Manual," </title> <publisher> Prentice Hall, INMOS Limited, </publisher> <year> 1988. </year>
Reference-contexts: Such RTD estimation often results in nonoptimal timeout value being selected [8], thus affecting the overall throughput performance. In TCP, the implementation of the delta-list [15] for efficient management of timers requires the list to be scanned whenever a timer is inserted or deleted <ref> [16] </ref>. In a highspeed network, with large bandwidth-delay product, this would incur considerable computational overheads in managing the list. Similarly, in SNR, for each state packet received at the transmitter, each entry in the timer list needs to be processed by decrementing the retransmission count for all unacknowledged blocks.
Reference: 18. <author> B. S. Davie, </author> <title> "The Architecture and Implementation of a HighSpeed Host Interface", </title> <journal> IEEE Journal on Selected Areas of Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp 228-239, </pages> <month> Feb </month> <year> 1993. </year>
Reference: 19. <author> K. K. Ramakrishnan, </author> <title> "Perfromance Considerations in Designing Network Interfaces", </title> <journal> IEEE Journal on Selected Areas of Communication, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp 203-219, </pages> <month> Feb </month> <year> 1993. </year> <month> 24 </month>
Reference: 20. <author> P. Karn and C. Partridge, </author> <title> "Improving Round-Trip Time Estimates in Reliable Transport Protocols", </title> <booktitle> Proceedings of ACM SIGCOMM '87, </booktitle> <pages> pp 2-7, </pages> <month> Aug </month> <year> 1987. </year>
Reference: 21. <author> SGS-THOMSON, </author> <title> "The T9000 Transputer Products Overview Manual", </title> <note> first edition 1991. </note>
Reference-contexts: It should further be noted that advances in microprocessors designed for parallel systems offer even greater performance potential for protocol processing systems. For example, the release of the 50 MHz T9000 transputer with 100 Mb/s links should give a tenfold increase in speed over the T800 <ref> [21] </ref>. We believe that this development could further enhance the throughput of HTPNET, with potential to deliver over the gigabits range.
References-found: 20

