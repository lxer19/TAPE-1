URL: file://ftp.it.kth.se/Reports/paradis/ParaDigme.ps.Z
Refering-URL: http://www.it.kth.se/~lisper/
Root-URL: http://www.it.kth.se
Title: Data Parallelism and Functional Programming  
Author: Bjorn Lisper 
Address: 204, S-164 40 Kista, SWEDEN  
Affiliation: Department of Teleinformatics, Royal Institute of Technology, Electrum  
Abstract: Data parallelism is often seen as a form of explicit parallelism for SIMD and vector machines, and data parallel programming as an explicit programming paradigm for these architectures. Data parallel languages possess certain software qualities as well, which justifies their use in higher level programming and specification closer to the algorithm domain. Thus, it is interesting to study how the data parallel paradigm can be best realized in a declarative setting, since declarative languages offer a pure view of computation which is good for these purposes. For numerical computing the functional programming paradigm is especially attractive, since numerical algorithms often are specified by recursion equations and thus can be translated more or less directly into recursive functional programs. Merging the data parallel and functional paradigms then yields languages and formalisms where many algorithms can be expressed in a very succinct fashion. In this paper we review data parallelism, functional programming, and existing approaches to the integration of the two paradigms. We then proceed to describe a formalism for data parallel functional programming, allowing very simple languages, where the view of aggregate data is particularly abstract. We explain how various data parallel operations can be expressed in this formalism. Finally, we conclude with a discussion of issues for languages based directly on the formalism. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Anderson and P. Hudak. </author> <title> Compilation of Haskell array comprehensions for scientific computing. </title> <booktitle> In Proceedings of the ACM SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 137-149. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: It is possible to leave out certain indices within the bounds: the corresponding array elements are then undefined. Haskell array comprehensions are not primarily intended for parallel implementation, but there is nothing that prevents it <ref> [1] </ref>. Data Parallel Haskell (or DPHaskell) [31] is a version of Haskell extended with "Parallel Objects of Arbitrary Dimensions" (pods). These are essentially nonstrict arrays, possibly without bounds, supporting parallel operations. Unbounded, infinite pods are possible thanks to the nonstrictness.
Reference: 2. <author> J. Backus. </author> <title> Can programming be liberated from the von Neumann style? A functional style and its algebra of programs. </title> <journal> Comm. ACM, </journal> <volume> 21(8) </volume> <pages> 613-641, </pages> <month> August </month> <year> 1978. </year>
Reference-contexts: Some of these formalisms are executable and have been implemented, while others can be used only as an abstract notation. An early example is Backus' FP <ref> [2] </ref>. FP is a formalism entirely based on functions and operations on functions, most prominently function composition. These operations are called functional (or combining ) forms. FP supports a "combinatory style" of specification, i.e., functions are defined just by combining other functions, without using formal parameters.
Reference: 3. <author> J. Backus, J. H. Williams, and E. L. Wimmers. </author> <title> An introduction to the programming language FL. </title> <editor> In D. A. Turner, editor, </editor> <booktitle> Research Topics in Functional Programming, The UT Year of Programming Series, chapter 9, </booktitle> <pages> pages 219-247. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: For instance, FP has a Map operation that serves as elementwise application, and Right Insert and Left Insert which can be used for reduction over sequences. FL <ref> [3] </ref> is an implementation of FP. Similar to FP in spirit is the Bird-Meertens formalism. Here an algebra with unary and binary functions forms a base for a set of theories for different data types [5, 6]. In particular, there is a theory for functions over lists.
Reference: 4. <author> H. P. Barendregt. </author> <title> The Lambda Calculus Its Syntax and Semantics, </title> <booktitle> volume 103 of Studies in Logic and the Foundations of Mathematics. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1981. </year>
Reference-contexts: A natural step is to allow ff and fi to be function types themselves. We then obtain a higher order functional language, where functions are considered values and can be passed around just like any other data. Lambda abstractions, from the formal -calculus <ref> [4] </ref>, define nameless expressions of function type, and they constitute "function typed values". They have the form x:e, where x, a variable, is "formal parameter" and e, an expression, is the "function body". <p> But what do we mean? Actually, we are talking about a different evaluation mechanism for functions. The conventional evaluation mechanism for functions which is used in traditional functional languages is based on the fi-reduction of the -calculus <ref> [4] </ref>, which means that a function is not evaluated until it is applied to an argument. So a function can only be computed "pointwise", for one argument at a time. The 1 The exception is Corollary 10, which holds in a weaker form for "reasonably" consistently extended strict operations.
Reference: 5. <author> R. S. Bird. </author> <title> A calculus of functions for program derivation. </title> <editor> In D. A. Turner, editor, </editor> <booktitle> Research Topics in Functional Programming, The UT Year of Programming Series, chapter 11, </booktitle> <pages> pages 287-307. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: FL [3] is an implementation of FP. Similar to FP in spirit is the Bird-Meertens formalism. Here an algebra with unary and binary functions forms a base for a set of theories for different data types <ref> [5, 6] </ref>. In particular, there is a theory for functions over lists. The lists can be seen as carriers of parallel data; then, the formalism gives a framework to specify and reason about data parallel algorithms.
Reference: 6. <author> R. S. Bird. </author> <title> Constructive functional programming. </title> <editor> In M. Broy, editor, </editor> <booktitle> Marktober-dorf International Summer school on Constructive Methods in Computer Science, NATO Advanced Science Institute Series. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1989. </year>
Reference-contexts: FL [3] is an implementation of FP. Similar to FP in spirit is the Bird-Meertens formalism. Here an algebra with unary and binary functions forms a base for a set of theories for different data types <ref> [5, 6] </ref>. In particular, there is a theory for functions over lists. The lists can be seen as carriers of parallel data; then, the formalism gives a framework to specify and reason about data parallel algorithms.
Reference: 7. <author> G. E. Blelloch. NESL: </author> <title> A nested data-parallel language. </title> <type> Technical Report CMU-CS-95-170, </type> <institution> School of Computer Science, Carnegie-Mellon University, </institution> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: These are essentially nonstrict arrays, possibly without bounds, supporting parallel operations. Unbounded, infinite pods are possible thanks to the nonstrictness. Another feature is the use of guards: boolean expressions that filter out certain elements of pods. This makes it possible to express sparse pods. NESL <ref> [7, 8] </ref>, a successor to Paralation Lisp [9] with a similar parallel data type, is a strongly typed, first order functional language that uses nested sequences as parallel data. A sequence in the sense of NESL is essentially a one-dimensional array indexed from zero and up.
Reference: 8. <author> G. E. Blelloch, S. Chatterjee, J. C. Hardwick, J. Sipelstein, and M. Zagha. </author> <title> Implementation of a portable nested data-parallel language. </title> <booktitle> In Proceedings 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 102-111, </pages> <address> San Diego, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: These are essentially nonstrict arrays, possibly without bounds, supporting parallel operations. Unbounded, infinite pods are possible thanks to the nonstrictness. Another feature is the use of guards: boolean expressions that filter out certain elements of pods. This makes it possible to express sparse pods. NESL <ref> [7, 8] </ref>, a successor to Paralation Lisp [9] with a similar parallel data type, is a strongly typed, first order functional language that uses nested sequences as parallel data. A sequence in the sense of NESL is essentially a one-dimensional array indexed from zero and up.
Reference: 9. <author> G. E. Blelloch and G. W. Sabot. </author> <title> Compiling collection-oriented languages onto massively parallel computers. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 8(2) </volume> <pages> 119-134, </pages> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: Unbounded, infinite pods are possible thanks to the nonstrictness. Another feature is the use of guards: boolean expressions that filter out certain elements of pods. This makes it possible to express sparse pods. NESL [7, 8], a successor to Paralation Lisp <ref> [9] </ref> with a similar parallel data type, is a strongly typed, first order functional language that uses nested sequences as parallel data. A sequence in the sense of NESL is essentially a one-dimensional array indexed from zero and up.
Reference: 10. <author> L. Bouge. </author> <title> The data-parallel programming model: A semantic perspective. This Volume. </title>
Reference-contexts: We will treat all these three aspects in this paper. But let us first give some background: 2 Data Parallelism Data parallelism usually refers to the kind of parallelism where operations are carried out in parallel over collections of data: see also <ref> [10] </ref> for a similar discussion of the topic.
Reference: 11. <author> W. S. Brainerd, C. H. Goldberg, and J. C. Adams. </author> <title> Programmer's Guide to FORTRAN 90. Programming Languages. </title> <publisher> McGraw-Hill, </publisher> <year> 1990. </year>
Reference-contexts: This kind of operation is used in *Lisp [55] for the Connection Machine, where elementwise addition is denoted "+!!". It is often more convenient to overload the scalar operation, viz.: C := A + B Array languages like Fortran 90 <ref> [11] </ref> provide this kind of overloading. This as-sumes some kind of typing of A and B, such that the overloading really can be resolved. This kind of overloaded syntax is also common in mathematical texts on, e.g., linear algebra, and should thus be familiar to many programmers.
Reference: 12. <author> D. Cann. </author> <title> Retire Fortran? A debate rekindled. </title> <journal> Comm. ACM, </journal> <volume> 35(3) </volume> <pages> 81-89, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Thus, it is somewhat like a side-effect free version of the FORALL construct of HPF. There is a rich set of array operations. The design of Sisal is made to enhance the generation of efficient code, and Sisal has efficient implementations on a number of vector- and parallel architectures <ref> [12] </ref>. Equational Programming Language [43, 53] has recursive array definitions with strong syntactic restrictions ensuring that they can be interpreted as recurrent equations. This enables the use of powerful program analysis methods and optimizing compilation.
Reference: 13. <author> B. Carpentieri and Z. G. Mou. </author> <title> A formal approach to Divide-and-Conquer parallel computation and its applications on the Connection Machine. </title> <booktitle> In Proceedings of the First Italian Conference: Algorithms and Complexity, </booktitle> <pages> pages 13-44. </pages> <publisher> World Scientific Publ., </publisher> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: A different approach is Carpentieri's and Mou's algebraic model for Divide-and-Conquer algorithms [14]. Here, Divide-and-Conquer is expressed as a certain form of recursion. The parallel functional programming language Divacon <ref> [13] </ref> is based on this model: it is targeted towards efficient implementation of Divide-and-Conquer algorithms on hypercube SIMD architectures. The Pei (Parallel Equations Interpreter) formalism [57, 58] is intended to specify recurrent equations.
Reference: 14. <author> B. Carpentieri and Z. G. Mou. </author> <title> Compile-time transformations and optimization of parallel Divide-and-Conquer algorithms. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 26(10) </volume> <pages> 19-28, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: A different approach is Carpentieri's and Mou's algebraic model for Divide-and-Conquer algorithms <ref> [14] </ref>. Here, Divide-and-Conquer is expressed as a certain form of recursion. The parallel functional programming language Divacon [13] is based on this model: it is targeted towards efficient implementation of Divide-and-Conquer algorithms on hypercube SIMD architectures. The Pei (Parallel Equations Interpreter) formalism [57, 58] is intended to specify recurrent equations.
Reference: 15. <author> S. Chatterjee. </author> <title> Compiling nested data-parallel programs for shared-memory multiprocessors. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(3) </volume> <pages> 400-462, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: A sequence in the sense of NESL is essentially a one-dimensional array indexed from zero and up. Thus, the nested sequences of NESL are quite close to the nested arrays of Sisal. NESL is implemented on several parallel architectures on top of the intermediate format VCODE <ref> [15] </ref>. The language Crystal [17] adds another level of abstraction: parallel data are considered as functions ranging over finite index domains. These domains are constructed from a number of base domains (integer intervals, hypercube coordinates, trees) which can be combined using constructors for product, direct sum and function space.
Reference: 16. <author> M. C. Chen. </author> <title> A design methodology for synthesizing parallel algorithms and architectures. </title> <journal> J. Parallel Distrib. Comput., </journal> <pages> pages 461-491, </pages> <year> 1986. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 17. <author> M. C. Chen, Y.-I. Choo, and J. Li. </author> <title> Crystal: Theory and pragmatics of generating efficient parallel code. </title> <editor> In B. K. Szymanski, editor, </editor> <booktitle> Parallel Functional Languages and Compilers, chapter 7, </booktitle> <pages> pages 255-308. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: From now on, in analogy with the terminology in physics, we will refer to these indexed collections as data fields (as in the language Crystal <ref> [17] </ref>). The index set of a data field is the set of locations where it is defined. What about program notation for elementwise applied operations? There are several possibilities. <p> Thus, the nested sequences of NESL are quite close to the nested arrays of Sisal. NESL is implemented on several parallel architectures on top of the intermediate format VCODE [15]. The language Crystal <ref> [17] </ref> adds another level of abstraction: parallel data are considered as functions ranging over finite index domains. These domains are constructed from a number of base domains (integer intervals, hypercube coordinates, trees) which can be combined using constructors for product, direct sum and function space. The definitions can be recursive.
Reference: 18. <author> P. Cousot and R. Cousot. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> In Proc. 4th ACM Symposium on Principles of Programming Languages, </booktitle> <address> Los Angeles, </address> <month> Jan. </month> <year> 1977. </year>
Reference-contexts: This is particularly valuable in order to avoid the runtime overheads associated with advanced evaluation mechanisms, like elaborate request operators. Extent analysis [41] refers to two static analyses, formulated as abstract interpretations <ref> [18] </ref>, which are applicable to data field expressions. "Extent" stands for index sets or needed parts thereof: in these analyses the extent of a function [[oe]] ! [[o ]] is represented by a predicate [[oe]] ! [[bool]].
Reference: 19. <author> J. Darlington, A. Field, P. Harrison, P. Kelly, D. Sharp, Q. Wu, and R. </author> <title> While. Parallel programming using skeleton functions. </title> <booktitle> In Proc. PARLE'93, Volume 694 of Lecture Notes in Comput. Sci., </booktitle> <pages> pages 146-160, </pages> <address> Athens, June 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Reductions Reductions and related operations can be defined as higher order operations through recursion. (They can be seen as algorithmic skeletons <ref> [19] </ref>.) Below, we define a general reduction which can reduce any data field f : o ! oe with respect to any binary operation g: oe fi oe ! oe.
Reference: 20. <author> J.-M. Delosme and I. Ipsen. </author> <title> Efficient systolic arrays for the solution of Toeplitz systems: an illustration of a methodology for the construction of systolic architectures in VLSI. </title> <editor> In W. Moore, A. McCabe, and R. Urquhart, editors, </editor> <booktitle> Systolic Arrays, </booktitle> <pages> pages 37-46, </pages> <address> Bristol, UK, </address> <year> 1987. </year> <note> Adam Hilger. </note>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 21. <author> E. W. Dijkstra. </author> <title> A Discipline of Programming. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1976. </year>
Reference-contexts: Input-output analysis propagates constraints from input data fields to results, whereas output-input analysis propagates constraints on outputs (requested parts of data fields) to inputs. Thus, they are related to the Floyd-Hoare semantics of imperative languages, in particular the strongest postcondition and weakest precondition predicate transformers <ref> [21] </ref>. Directly related are methods to analyze constraints on integer typed variables, e.g., for the purpose of analyzing array references statically. In particular, the polyhedral abstract interpretation of Halbwachs [26] seems relevant. 6.5 Non-Consistent Extensions There is at least one non-consistent extension that seems useful.
Reference: 22. <author> K. Ekanadham. </author> <title> A perspective on Id. </title> <editor> In B. K. Szymanski, editor, </editor> <booktitle> Parallel Func--tional Languages and Compilers, chapter 6, </booktitle> <pages> pages 197-253. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: Equational Programming Language [43, 53] has recursive array definitions with strong syntactic restrictions ensuring that they can be interpreted as recurrent equations. This enables the use of powerful program analysis methods and optimizing compilation. The Id Language <ref> [22] </ref> has array comprehensions, which serve the same purpose as the For construct of Sisal. They are, however, more general in that they are non-strict, which means that only the part of an array that is actually used is computed.
Reference: 23. <author> P. Feautrier. </author> <title> Automatic parallelization in the polytope model. This Volume. </title>
Reference-contexts: But for certain classes of predicates it is decidable. An important case is systems of linear inequalities, where the finiteness is equivalent to emptiness of an associated system of linear inequalities. This can be decided by polyhedral methods: for an introduction, see <ref> [23] </ref>. It is sometimes convenient to define a "scalar" version of the restriction operator, viz. x n y = if (y; x; ?). <p> See Fig. 11. Other formats are certainly also possible to recognize. An immediate generalization is to allow b to be a general system of linear inequalities: the problem to enumerate the integral points in polyhedra defined by linear inequalities is exactly the loop scanning problem <ref> [23, 38] </ref>. As mentioned in Section 5.3, there are also methods to decide the finiteness of polyhedra. Fig. 11. An array-like restriction. It is also possible to envisage request operators which perform a more elaborate search for a "narrower" S.
Reference: 24. <author> J. T. Feo, D. C. Cann, and R. R. Oldehoeft. </author> <title> A report on the Sisal language project. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 10 </volume> <pages> 349-366, </pages> <year> 1990. </year>
Reference-contexts: For instance, the functional array language Sisal <ref> [24] </ref> has an operation array_fill that creates an array where each element is a copy of a given scalar. <p> Many functional languages, for instance, lack support for anything except basic array operations. (A notable exception is Sisal <ref> [24] </ref>.) 4 Data Parallel Functional Languages Despite the dominance of functional languages tuned for symbolic computing applications, there have been attempts to incorporate array and data parallel operations in functional languages. In particular, there are a number of languages emanating from the efforts in data flow computing in the eighties. <p> The traditional way to add data parallelism is to designate a certain aggregate data type for this purpose, and to provide (1) a way to define entities of this type, and (2) a number of primitives operating on these. Arrays are a common carrier of data parallelism. Sisal <ref> [24, 50] </ref> is a strongly typed, call-by-value functional language intended for scientific computing. It has one-dimensional arrays (multi-dimensional arrays are thus expressed as arrays of arrays).
Reference: 25. <author> D. Goldberg. </author> <title> What every computer scientist should know about floating-point arithmetic. </title> <journal> ACM Computing Surveys, </journal> <volume> 23(1) </volume> <pages> 5-48, </pages> <month> Mar. </month> <year> 1991. </year>
Reference-contexts: With this kind of implementation, fl will behave very much like "failure" in Prolog. For details, see [29]. For floating point computations according to the IEEE standard the "NaN" (Not a Number) entities can represent fl, since they have the correct algebraic properties <ref> [25] </ref>. When operating on data fields, it can be advantageous, for a data field f, to have a "aggregated tagged" representation as a bit mask b paralleling the data structure with the "real" values of f, such that b (x) = false encodes f (x) = fl.
Reference: 26. <author> N. Halbwachs. </author> <title> Determination automatique de relations lineaires verifiees par les variables d'un programme. </title> <institution> These de 3eme cycle, Univ. de Grenoble, </institution> <month> Mar. </month> <year> 1979. </year>
Reference-contexts: Directly related are methods to analyze constraints on integer typed variables, e.g., for the purpose of analyzing array references statically. In particular, the polyhedral abstract interpretation of Halbwachs <ref> [26] </ref> seems relevant. 6.5 Non-Consistent Extensions There is at least one non-consistent extension that seems useful. Sometimes it makes sense to have a special equality predicate "= 0 " where fl = 0 fl returns true and otherwise false is returned.
Reference: 27. <author> J. Halen, P. Hammarlund, and B. Lisper. </author> <title> An experimental implementation of a highly abstract model of data parallel programming. </title> <note> In preparation, </note> <year> 1996. </year>
Reference-contexts: Certain classes of predicates, e.g., the "array predicates" exemplified above and also the more general systems of linear inequalities, define classes of sets which are closed under intersection. A prototype implementation of a simple functional language with a request operator performing a search of this kind exists <ref> [27] </ref>. 6.3 Loosely Specified Reductions For binary operations which are both associative and commutative, the order of operations and operands is not significant. <p> Furthermore, a mathematical formalism like ours can guide the design of the data parallel primitives in new production languages. We are currently experimenting with functional languages based directly on the formalism. A first experiment has been carried out, where a simple interpreter was implemented <ref> [27] </ref>.
Reference: 28. <author> P. Hammarlund and B. Lisper. </author> <title> On the relation between functional and data parallel programming languages. </title> <booktitle> In Proc. Sixth Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 210-222. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction This paper gives a review of a novel abstract programming formalism <ref> [28, 29] </ref>. The source of inspiration is the data parallel paradigm and its view of aggregate data, which often makes it possible to write very clear and succinct data parallel programs for certain applications. <p> Send communication, as specified in Section 2.2, has side effect and is thus not as straightforward to model in our framework. It is, however, possible to define a side-effect-free version of combining send as the segmented reduction in <ref> [28, 29] </ref>. Replication Replication is easily specified through -abstraction. If y has type oe, then we can create a "constant valued" data field x:y of any function type o ! oe by abstracting with respect to a fresh variable x of type o . <p> Finding these will in general require operations which are able to distinguish between "divergent ?" and "out of range?", see Section 6.5. Other reduction operations, like scan and the segmented variants of reduction and scan, can be defined similarly to Definition 5. See <ref> [28, 29] </ref>. 5.5 Algebraic Laws We will now present a number of algebraic laws for the explicit restriction. They can be seen as constraint propagation rules, and they are clearly of use for, e.g., program optimization. <p> Viewing a 3-D scenery means requesting a 2-D plane of pixels from some viewpoint, computed according to the projected 3-D scenery of data fields. Exploring these applications are additional research topics of great interest. 8 Acknowledgements Most of this text is based on joint work with Per Hammarlund <ref> [28, 29] </ref>. Extent analysis is joint work with Jean-Francois Collard [41]. I would also like to thank Karl-Filip Faxen, Joacim Halen, Olof Johansson and Claes Thornberg, who have all contributed in one way or another.
Reference: 29. <author> P. Hammarlund and B. Lisper. </author> <title> Purely functional data parallel programming. </title> <note> Submitted, </note> <year> 1995. </year>
Reference-contexts: 1 Introduction This paper gives a review of a novel abstract programming formalism <ref> [28, 29] </ref>. The source of inspiration is the data parallel paradigm and its view of aggregate data, which often makes it possible to write very clear and succinct data parallel programs for certain applications. <p> Send communication, as specified in Section 2.2, has side effect and is thus not as straightforward to model in our framework. It is, however, possible to define a side-effect-free version of combining send as the segmented reduction in <ref> [28, 29] </ref>. Replication Replication is easily specified through -abstraction. If y has type oe, then we can create a "constant valued" data field x:y of any function type o ! oe by abstracting with respect to a fresh variable x of type o . <p> Finding these will in general require operations which are able to distinguish between "divergent ?" and "out of range?", see Section 6.5. Other reduction operations, like scan and the segmented variants of reduction and scan, can be defined similarly to Definition 5. See <ref> [28, 29] </ref>. 5.5 Algebraic Laws We will now present a number of algebraic laws for the explicit restriction. They can be seen as constraint propagation rules, and they are clearly of use for, e.g., program optimization. <p> Such languages can be based on higher-order strongly typed languages: using functions as data fields in the way suggested by our formalism will then require a very small extension of the language. A more detailed account of the material presented here is found in <ref> [29] </ref>. 6.1 C.p.o.'s with Explicitly Undefined Values In our formalism the abstract value ? is really used for two different purposes: to denote nontermination, and to represent a failing lookup. The second situation can be detected in finite time and is thus in some respect a "soft" failure. <p> function f fl : [[o ]] fl ! [[o ]] fl is a consistent extension of f : [[o ]] ! [[o ]] if it, roughly speaking, obeys the same algebraic identities with respect to fl as the ones f obeys with respect to ? (for an exact definition, see <ref> [29] </ref>). Being a consistent extension is not a fundamental property, and indeed there are useful functions over [[o ]] fl which are not (see Section 6.5), but the consistent extensions have certain nice properties. <p> These can be consistently extended in various ways, differing in how they treat the cases where some strict arguments are fl and others are ?. Some of these extensions will require expensive implementations, those which do not will obey weaker forms of Corollary 10. See <ref> [29] </ref>. "data field reading" of a function is different: it implies an attempt to evaluate all the possibly defined values of the (partial) function in order to tabulate it. This is a (conceptually) parallel evaluation mechanism, and it is different from the conventional one. <p> This is correct for consistently extended operations since these should return fl whenever a strict argument is fl. With this kind of implementation, fl will behave very much like "failure" in Prolog. For details, see <ref> [29] </ref>. For floating point computations according to the IEEE standard the "NaN" (Not a Number) entities can represent fl, since they have the correct algebraic properties [25]. <p> Viewing a 3-D scenery means requesting a 2-D plane of pixels from some viewpoint, computed according to the projected 3-D scenery of data fields. Exploring these applications are additional research topics of great interest. 8 Acknowledgements Most of this text is based on joint work with Per Hammarlund <ref> [28, 29] </ref>. Extent analysis is joint work with Jean-Francois Collard [41]. I would also like to thank Karl-Filip Faxen, Joacim Halen, Olof Johansson and Claes Thornberg, who have all contributed in one way or another.
Reference: 30. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <note> version 1.0. Technical report CRC-TR-92225, Center for Research on Parallel Computation, </note> <institution> Rice University, Houston, TX, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: It is common that i is given an explicit range, e.g., if the locations are integers, "Forall i in 1::N . . .". High Performance Fortran (HPF) <ref> [30] </ref> provides FORALL statements with range. 2.2 Communication Operations The second main group of data parallel operations concern communication. Get communication, or parallel (concurrent) read, lets each location i concurrently read an element of some data field A at location source (i).
Reference: 31. <author> J. M. Hill. </author> <title> The AIM is laziness in a data-parallel language. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: It is possible to leave out certain indices within the bounds: the corresponding array elements are then undefined. Haskell array comprehensions are not primarily intended for parallel implementation, but there is nothing that prevents it [1]. Data Parallel Haskell (or DPHaskell) <ref> [31] </ref> is a version of Haskell extended with "Parallel Objects of Arbitrary Dimensions" (pods). These are essentially nonstrict arrays, possibly without bounds, supporting parallel operations. Unbounded, infinite pods are possible thanks to the nonstrictness. Another feature is the use of guards: boolean expressions that filter out certain elements of pods.
Reference: 32. <author> W. D. Hillis and G. L. Steele, Jr. </author> <title> Data parallel algorithms. </title> <journal> Comm. ACM, </journal> <volume> 29(12) </volume> <pages> 1170-1183, </pages> <month> Dec. </month> <year> 1986. </year>
Reference-contexts: The former case is by far the most frequent. Very related are the scan (or parallel prefix ) operations <ref> [32] </ref>. They compute all partial reductions over a data field with respect to some binary operation. The result is a data field over the same index set as the original field.
Reference: 33. <author> C.-H. Huang and C. Lengauer. </author> <title> The derivation of systolic implementations of programs. </title> <journal> Acta Inform., </journal> <volume> 24 </volume> <pages> 595-632, </pages> <year> 1987. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 34. <author> P. Hudak. </author> <title> Conception, evolution, </title> <booktitle> and application of functional programming languages. </booktitle> <volume> 21(3) </volume> <pages> 359-411, </pages> <year> 1989. </year>
Reference-contexts: This led to the abstract model of data fields presented in Section 5. 3 Functional Languages Functional languages <ref> [34] </ref> are a class of declarative languages usually considered to have the following properties: No side effects, no destructive updates. Program control is only through nonstrict operators (see below) and recur sion. A program is a function definition (possibly recursive).
Reference: 35. <author> P. Hudak, S. P. Jones, P. Wadler, B. Boutel, J. Fairbairn, J. Fasel, M. M. Guzman, K. Hammond, J. Hughes, T. Johnsson, D. Kieburtz, R. Nikhil, W. Partain, and J. Peterson. </author> <title> Report on the programming language Haskell: A non-strict, purely functional language. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: This is essentially lazy evaluation applied to arrays, and allows array definitions with nonterminating elements. Id array comprehensions can furthermore be recursive, i.e., an array can be defined in terms of itself. Array comprehensions are also found in the lazy language Haskell <ref> [35] </ref>. The array elements are defined by a list of associations, i.e., pairs of indices and element values. This list is often given as a list comprehension (i.e., a convenient syntax for lists which allows enumerations over integer intervals, akin to loop ranges). <p> :(l 1 i 1 u 1 ^ ^ l n i n u n ), where the l j and u j are integers: this kind of predicate specifies array-like data fields and a request operation accepting such predicates will act very much like the array comprehensions of, e.g., Haskell <ref> [35] </ref>. See Fig. 11. Other formats are certainly also possible to recognize. An immediate generalization is to allow b to be a general system of linear inequalities: the problem to enumerate the integral points in polyhedra defined by linear inequalities is exactly the loop scanning problem [23, 38].
Reference: 36. <author> K. E. Iverson. </author> <title> A Programming Language. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1962. </year>
Reference-contexts: Pei also includes a refinement calculus, which makes it possible to perform formal derivations of parallel algorithms for the recurrences from looser specifications. Finally, APL <ref> [36] </ref> must be mentioned since it probably is the first example of a formalism (and programming language) where the typical data parallel constructs appear. 5 An Abstract Formalism for Aggregate Data All the languages and formalisms in the previous section have in common that they use a single carrier of parallel
Reference: 37. <author> S. Y. Kung. </author> <title> VLSI array processors. </title> <editor> In W. Moore, A. McCabe, and R. Urquhart, editors, </editor> <booktitle> Systolic Arrays, </booktitle> <pages> pages 7-24, </pages> <address> Bristol, UK, </address> <year> 1987. </year> <note> Adam Hilger. </note>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 38. <author> H. Le Verge, V. Van Dongen, and D. K. Wilde. </author> <title> Loop nest synthesis using the polyhedral library. </title> <type> Research Report 840, </type> <institution> IRISA, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: See Fig. 11. Other formats are certainly also possible to recognize. An immediate generalization is to allow b to be a general system of linear inequalities: the problem to enumerate the integral points in polyhedra defined by linear inequalities is exactly the loop scanning problem <ref> [23, 38] </ref>. As mentioned in Section 5.3, there are also methods to decide the finiteness of polyhedra. Fig. 11. An array-like restriction. It is also possible to envisage request operators which perform a more elaborate search for a "narrower" S.
Reference: 39. <author> B. Lisper. </author> <title> Synthesis of Synchronous Systems by Static Scheduling in Space-Time, </title> <booktitle> volume 362 of Lecture Notes in Comput. </booktitle> <publisher> Sci. Springer-Verlag, </publisher> <address> Berlin, </address> <month> May </month> <year> 1989. </year> <editor> (Ph. D. </editor> <booktitle> thesis). </booktitle>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 40. <author> B. Lisper. </author> <title> Synthesis of time-optimal systolic arrays with cells with inner structure. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 10(2) </volume> <pages> 182-187, </pages> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 41. <author> B. Lisper and J.-F. Collard. </author> <title> Extent analysis of data fields. </title> <editor> In B. Le Charlier, editor, </editor> <booktitle> Proc. International Symposium on Static Analysis, Vol. 864 of Lecture Notes in Comput. Sci., </booktitle> <pages> pages 208-222, </pages> <address> Namur, Belgium, Sept. 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This is particularly valuable in order to avoid the runtime overheads associated with advanced evaluation mechanisms, like elaborate request operators. Extent analysis <ref> [41] </ref> refers to two static analyses, formulated as abstract interpretations [18], which are applicable to data field expressions. "Extent" stands for index sets or needed parts thereof: in these analyses the extent of a function [[oe]] ! [[o ]] is represented by a predicate [[oe]] ! [[bool]]. <p> the "input" data fields, an approximation f # to the index set of the resulting data field f. f # has the property that f (x) 6= ? =) f # (x): thus, it provides a safe approximation to the index set of f . (This analysis, as given in <ref> [41] </ref>, is formulated with respect to the simpler semantical c.p.o.'s where fl is identified with ?: it is straightforward to reformulate it to c.p.o.'s with fl and prove f (x) 6= fl =) f # (x).) Input-output analysis can be used to perform the analysis phase of request at compile time, <p> Exploring these applications are additional research topics of great interest. 8 Acknowledgements Most of this text is based on joint work with Per Hammarlund [28, 29]. Extent analysis is joint work with Jean-Francois Collard <ref> [41] </ref>. I would also like to thank Karl-Filip Faxen, Joacim Halen, Olof Johansson and Claes Thornberg, who have all contributed in one way or another. Support has been given by The Swedish Research Council for Engineering Sciences (TFR), grants 91-333 and 94-109.
Reference: 42. <author> Z. Manna. </author> <title> Mathematical Theory of Computation. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: An expression e of type ff ! fi can be given a meaning [[e]] as a mathematical function [[ff]] ! [[fi]], where [[ff]] and [[fi]] are interpretations of the types ff, fi as complete partial orders (c.p.o.'s, see, for instance, <ref> [42] </ref>). A c.p.o. contains a least element, which is not a computable value but rather represents divergence or "complete lack of information".
Reference: 43. <author> B. McKenney and B. Szymanski. </author> <title> Generating parallel code for SIMD machines. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 59-73, </pages> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: There is a rich set of array operations. The design of Sisal is made to enhance the generation of efficient code, and Sisal has efficient implementations on a number of vector- and parallel architectures [12]. Equational Programming Language <ref> [43, 53] </ref> has recursive array definitions with strong syntactic restrictions ensuring that they can be interpreted as recurrent equations. This enables the use of powerful program analysis methods and optimizing compilation. The Id Language [22] has array comprehensions, which serve the same purpose as the For construct of Sisal.
Reference: 44. <author> D. I. Moldovan. </author> <title> On the analysis and synthesis of VLSI algorithms. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-31:1121-1126, </volume> <month> Oct. </month> <year> 1982. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 45. <author> P. </author> <title> Quinton. Automatic synthesis of systolic arrays from uniform recurrent equa-tions. </title> <booktitle> In Proc. 11th Annual Int. Symp. on Comput. Arch., </booktitle> <pages> pages 208-214, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 46. <author> P. Quinton, S. Rajopadhye, and D. Wilde. </author> <title> Derivation of data parallel code from a functional program. </title> <booktitle> In 9th International Parallel Processing Symposium, </booktitle> <pages> pages 1-15, </pages> <year> 1995. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed <ref> [46, 47] </ref>. These methods are based on space-time mappings [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 47. <author> P. Quinton, S. Rajopadhye, and D. Wilde. </author> <title> Deriving imperative code from functional programs. </title> <booktitle> In 7th Conference on Functional Programming Languages and Computer Architecture, </booktitle> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed <ref> [46, 47] </ref>. These methods are based on space-time mappings [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 48. <author> S. V. Rajopadye and R. M. Fujimoto. </author> <title> Synthesizing systolic arrays from recurrence equations. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 163-189, </pages> <year> 1990. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 49. <author> S. K. Rao and T. Kailath. </author> <title> Regular iterative algorithms and their implementation on processor arrays. </title> <journal> Proc. IEEE, </journal> <volume> 76(3) </volume> <pages> 259-269, </pages> <month> Mar. </month> <year> 1988. </year>
Reference-contexts: The definitions can be recursive. In [59], a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47]. These methods are based on space-time mappings <ref> [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] </ref> of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp [52].
Reference: 50. <author> S. K. Skedzielewski. </author> <title> Sisal. </title> <editor> In B. K. Szymanski, editor, </editor> <booktitle> Parallel Functional Languages and Compilers, chapter 4, </booktitle> <pages> pages 105-157. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: The traditional way to add data parallelism is to designate a certain aggregate data type for this purpose, and to provide (1) a way to define entities of this type, and (2) a number of primitives operating on these. Arrays are a common carrier of data parallelism. Sisal <ref> [24, 50] </ref> is a strongly typed, call-by-value functional language intended for scientific computing. It has one-dimensional arrays (multi-dimensional arrays are thus expressed as arrays of arrays).
Reference: 51. <author> D. B. Skillicorn. </author> <title> Architecture-independent parallel computation. </title> <journal> Computer, </journal> <volume> 23(12) </volume> <pages> 38-50, </pages> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: The Bird-Meertens formalism has Map and Reduce operations which can be directly interpreted as data parallel operations, as well as a Filter operation which forms a "compressed" list of the elements for which some predicate is true. Skillicorn <ref> [51] </ref> has shown that the Bird-Meertens formalism provides a model of data parallelism that is universal over a broad class of parallel architectures, i.e., that there is a cost model which gives the correct order of magnitude for the cost of executing the primitives in the formalism on these architectures.
Reference: 52. <author> G. L. Steele and W. D. Hillis. </author> <title> Connection Machine LISP: Fine grained parallel symbolic programming. </title> <booktitle> In Proc. 1986 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 279-297, </pages> <address> Cambridge, MA, 1986. </address> <publisher> ACM. </publisher>
Reference-contexts: These methods are based on space-time mappings [16, 20, 33, 37, 39, 40, 44, 45, 48, 49] of certain recurrent equations, which statically specify where and when each step in the recurrence will be computed. A similar view of parallel data appears in Connection Machine Lisp <ref> [52] </ref>. Here, the parallel data type is the xapping, which is a set of pairs of Lisp objects where the first component of a pair cannot occur in another pair.
Reference: 53. <author> B. K. Szymanski. </author> <title> EPL-parallel programming with recurrent equations. </title> <editor> In B. K. Szymanski, editor, </editor> <booktitle> Parallel Functional Languages and Compilers, chapter 3, </booktitle> <pages> pages 51-104. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: There is a rich set of array operations. The design of Sisal is made to enhance the generation of efficient code, and Sisal has efficient implementations on a number of vector- and parallel architectures [12]. Equational Programming Language <ref> [43, 53] </ref> has recursive array definitions with strong syntactic restrictions ensuring that they can be interpreted as recurrent equations. This enables the use of powerful program analysis methods and optimizing compilation. The Id Language [22] has array comprehensions, which serve the same purpose as the For construct of Sisal.
Reference: 54. <institution> Thinking Machines Corporation. </institution> <note> Connection Machine: Programming in C*, 6.1 edition, </note> <year> 1991. </year>
Reference-contexts: Some data parallel production languages for SIMD machines, e.g., C* and *Lisp for the Connection Machine <ref> [54, 55] </ref>, reflect the underlying architecture quite closely. It was, however, soon discovered that data parallelism also possesses certain software qualities: the use of operations on aggregate data can often yield very succinct programs for applications where such data are extensively handled.
Reference: 55. <author> Thinking Machines Corporation. </author> <title> Connection Machine: </title> <booktitle> Programming in *Lisp, </booktitle> <address> 6.1 edition, </address> <year> 1991. </year>
Reference-contexts: Some data parallel production languages for SIMD machines, e.g., C* and *Lisp for the Connection Machine <ref> [54, 55] </ref>, reflect the underlying architecture quite closely. It was, however, soon discovered that data parallelism also possesses certain software qualities: the use of operations on aggregate data can often yield very succinct programs for applications where such data are extensively handled. <p> For instance, if p add adds two data fields elementwise, then C := p add (A; B) assigns the elementwise sum of the data fields A and B to C. This kind of operation is used in *Lisp <ref> [55] </ref> for the Connection Machine, where elementwise addition is denoted "+!!". It is often more convenient to overload the scalar operation, viz.: C := A + B Array languages like Fortran 90 [11] provide this kind of overloading.
Reference: 56. <author> D. Turner. </author> <title> Functional programming and communicating processes. </title> <booktitle> In Proc. </booktitle> <volume> PARLE'87 vol. 2, </volume> <booktitle> Volume 259 of Lecture Notes in Comput. Sci., </booktitle> <pages> pages 54-74, </pages> <address> Berlin, 1987. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Also note that request (f ) will fail to terminate if f (x) = ? for any total x, that is: request is hyperstrict <ref> [56] </ref>. The situation is akin to the evaluation of a list-valued expression at the top level in a lazy functional language.
Reference: 57. <author> E. Violard. </author> <title> Data-parallelism versus functional programming: The contribution of PEI. </title> <type> Technical report, </type> <institution> ICPS, Universite Luis Pasteur, Strasbourg, </institution> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: Here, Divide-and-Conquer is expressed as a certain form of recursion. The parallel functional programming language Divacon [13] is based on this model: it is targeted towards efficient implementation of Divide-and-Conquer algorithms on hypercube SIMD architectures. The Pei (Parallel Equations Interpreter) formalism <ref> [57, 58] </ref> is intended to specify recurrent equations.
Reference: 58. <author> E. Violard and G.-R. Perrin. PEI: </author> <title> A language and its refinement calculus for parallel programming. </title> <journal> Parallel Computing, </journal> <volume> 18 </volume> <pages> 1167-1184, </pages> <year> 1992. </year>
Reference-contexts: Here, Divide-and-Conquer is expressed as a certain form of recursion. The parallel functional programming language Divacon [13] is based on this model: it is targeted towards efficient implementation of Divide-and-Conquer algorithms on hypercube SIMD architectures. The Pei (Parallel Equations Interpreter) formalism <ref> [57, 58] </ref> is intended to specify recurrent equations.
Reference: 59. <author> J. A. Yang and Y. Choo. </author> <title> Data fields as parallel programs. </title> <booktitle> In Proceedings of the Second International Workshop on Array Structures, </booktitle> <address> Montreal, Canada, </address> <month> June/July </month> <year> 1992. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: These domains are constructed from a number of base domains (integer intervals, hypercube coordinates, trees) which can be combined using constructors for product, direct sum and function space. The definitions can be recursive. In <ref> [59] </ref>, a restriction operation on index domains is described that is similar to DPHaskell's guards. A similar but more restricted language is Alpha, for which efficient compilation techniques have been developed [46, 47].
References-found: 59

