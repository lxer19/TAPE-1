URL: http://www.cs.nmsu.edu/lldap/download/jicslp/lao.ps.gz
Refering-URL: http://www.cs.nmsu.edu/lldap/jicslp/lao.html
Root-URL: http://www.cs.nmsu.edu
Email: fgupta,epontellg@cs.nmsu.edu  
Title: Last Alternative Optimization  
Author: Gopal Gupta Enrico Pontelli 
Address: Las Cruces, NM 88003  
Affiliation: Laboratory for Logic, Databases, and Advanced Programming New Mexico State University  
Abstract: Astract We present a new optimization for or-parallel logic programming (Prolog) systems, called Last Alternative Optimization (LAO). The LAO follows from the Flattening Principle and the Principle of Duality of or-parallelism and and-parallelism. Originally LAO was conceived as the dual of the Last Parallel Call Optimization [4] an optimization developed by us for and-parallel systems. LAO enables Prolog programs that have data-or parallelism to execute more efficiently. It also enables more efficient (parallel) execution of Constraint Logic Programs over finite domains. LAO is a fairly general optimization and can be readily applied to virtually any parallel system that exploits non-determinism (e.g., parallel search based artificial intelligence systems). The Last Alternative Optimization has been implemented in the ACE parallel Prolog system. The performance results presented in this paper indeed prove the effectiveness of LAO. We present a second optimization based on the flattening principle, called the Balanced Nesting Optimization (BNO), that is related to LAO, and that also leads to reduction of parallel overhead. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Ali and R. Karlsson. </author> <title> The Muse Or-parallel Prolog Model and its Performance. </title> <booktitle> In 1990 N. American Conf. on Logic Prog. </booktitle> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Or-parallelism is thus a way of efficiently searching for solution (s) to the top-level query, by exploring in parallel the branches of the solutions space tree. Or-parallelism has been efficiently implemented in the Aurora [10] and MUSE <ref> [1] </ref> systems. fl This work is supported by NSF Grants CCR 92-11732, CCR 96-25358, INT 94-15256, and HRD 93-53271, and by NATO Grant CRG 921318. 1 2 1996 Compulog Net Meeting on Parallelism and Implementation Technology * And-parallelism arises when more than one goal is present in the query or in <p> In this section we describe the changes that had to be made to the ACE system in order to implement LAO. The ACE system uses the stack copying environment representation technique (originally developed for the MUSE or-parallel system <ref> [1] </ref>) for representing multiple environments that arise during or-parallelism.
Reference: [2] <author> S. Debray and M. Jain. </author> <title> A Simple Program Transformation for Parallelism. </title> <booktitle> In Proc. of the 1994 Symposium on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Balanced Nesting Optimization The LAO is the dual of LPCO. The dual of other optimizations devised for and-parallelism can similarly be conceived of. It is well known that certain linearly recursive programs can be transformed into a doubly recursive divide-and-conquer programs that are more amenable to and-parallel execution <ref> [9, 2] </ref>. This transformation relies on the associativity and commutativity of operators used in the program. The same idea can be applied to or-parallel systems, and linearly recursive structured programs. Let's consider the member predicate again.
Reference: [3] <author> S. M. e. a. E. Lusk. </author> <title> Applications of the Aurora Parallel Prolog System to Computational Molecular Biology. </title> <booktitle> In International Logic Programming Symposium. </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: It is our conjecture that LAO will considerably benefit or-parallel systems such as Aurora [10] (at present we have only tried it on Muse). The find match predicate used in the DNA application in <ref> [3] </ref> will also benefit from LAO. LAO will also improve the performance of programs that use failure driven loops based on Prolog's repeat builtin. 3.
Reference: [4] <author> E.Pontelli and G. Gupta. </author> <title> Data And-parallel Logic Programming in &ACE. </title> <booktitle> In Proc. of 7th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1995. </year>
Reference-contexts: The results of implementing these optimizations in the ACE system, a high performance parallel Prolog system are also presented. 2. Last Alternative Optimization The last alternative optimization is based on the principle of flattening. After we developed the LPCO <ref> [4] </ref>, an optimization for and-parallel systems, the principle of duality led us to believe that the dual of LPCO should work for or-parallel systems. That is how the idea of LAO was born. We illustrate the Last Alternative Optimization with an example.
Reference: [5] <author> G. Gupta, M. Hermenegildo, and E. Pontelli. </author> <title> &ACE: A High-performance Parallel Prolog System. </title> <booktitle> In IPPS 95. IEEE Computer Society, </booktitle> <address> Santa Barbara, CA, </address> <month> April </month> <year> 1995. </year> <title> 4 Aurora is an or-parallel system based on a different environment representation scheme. </title> <booktitle> 8 1996 Compulog Net Meeting on Parallelism and Implementation Technology </booktitle>
Reference-contexts: The find match predicate used in the DNA application in [3] will also benefit from LAO. LAO will also improve the performance of programs that use failure driven loops based on Prolog's repeat builtin. 3. Implementation of LAO ACE <ref> [6, 5] </ref> is a high performance implementation of parallel Prolog based on the SICStus WAM engine that exploits both and- and or-parallelism. We have incorporated the LAO in the ACE system and results are reported in section 3.1..
Reference: [6] <author> G. Gupta, M. Hermenegildo, E. Pontelli, and V. S. Costa. </author> <title> ACE: And/Or-parallel Copying-based Execution of Logic Programs. </title> <booktitle> In Proc. ICLP'94, </booktitle> <pages> pages 93-109. </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The find match predicate used in the DNA application in [3] will also benefit from LAO. LAO will also improve the performance of programs that use failure driven loops based on Prolog's repeat builtin. 3. Implementation of LAO ACE <ref> [6, 5] </ref> is a high performance implementation of parallel Prolog based on the SICStus WAM engine that exploits both and- and or-parallelism. We have incorporated the LAO in the ACE system and results are reported in section 3.1..
Reference: [7] <author> G. Gupta and E. Pontelli. </author> <title> Last Alternative Optimization and Parallel Implementation of CLP(FD). </title> <type> Technical Report NMSU-CSTR-9606, </type> <institution> New Mexico State University, </institution> <year> 1995. </year>
Reference-contexts: the two choice points merged (B 1 and B 2 above) correspond to the same predicate, in the general case, they may correspond to different predicates (however, in such a case special action will be needed if predicates corresponding to the two choice points have different number of arguments; see <ref> [7] </ref> for details). <p> Some additional changes to the design of the data structures are required to accommodate the new features of LAO and its implementation in its most general form. Details are omitted due to lack of space and can be found elsewhere <ref> [7] </ref>. Table 1 describes the results obtained by running some benchmarks on the ACE systems with and without LAO. Each entry in the table indicates the unoptimized execution time (in milliseconds), the time obtained using LAO, and the corresponding percentage of improvement.
Reference: [8] <author> P. V. Hentenryck. </author> <title> Constraint Handling in Prolog. </title> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: We also show how LAO and BNO can be applied for: (i) exploiting data or-parallelism more efficiently, and (ii) exploiting parallelism from constraint logic programming (CLP) systems based on finite domains <ref> [8] </ref>. The results of implementing these optimizations in the ACE system, a high performance parallel Prolog system are also presented. 2. Last Alternative Optimization The last alternative optimization is based on the principle of flattening. <p> No special machinery for data-parallelism needs to be built in. LAO will be specially useful in parallel constraint logic programming systems, based on finite domains, such as CHIP <ref> [8] </ref>. CLP programs make extensive use of the indomain and labeling predicates that are very similar to the member predicate, and are thus amenable to LAO and data-parallelism. 5. Balanced Nesting Optimization The LAO is the dual of LPCO.
Reference: [9] <author> M. Hermenegildo and M. Carro. </author> <title> Relating Data-Parallelism and (And-)Parallelism in Logic Programs. In EuroPar'95. </title> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Balanced Nesting Optimization The LAO is the dual of LPCO. The dual of other optimizations devised for and-parallelism can similarly be conceived of. It is well known that certain linearly recursive programs can be transformed into a doubly recursive divide-and-conquer programs that are more amenable to and-parallel execution <ref> [9, 2] </ref>. This transformation relies on the associativity and commutativity of operators used in the program. The same idea can be applied to or-parallel systems, and linearly recursive structured programs. Let's consider the member predicate again.
Reference: [10] <author> E. Lusk and al. </author> <title> The Aurora Or-parallel Prolog System. </title> <journal> New Generation Computing, 7(2,3), </journal> <volume> '90. </volume>
Reference-contexts: Or-parallelism is thus a way of efficiently searching for solution (s) to the top-level query, by exploring in parallel the branches of the solutions space tree. Or-parallelism has been efficiently implemented in the Aurora <ref> [10] </ref> and MUSE [1] systems. fl This work is supported by NSF Grants CCR 92-11732, CCR 96-25358, INT 94-15256, and HRD 93-53271, and by NATO Grant CRG 921318. 1 2 1996 Compulog Net Meeting on Parallelism and Implementation Technology * And-parallelism arises when more than one goal is present in the <p> It is our conjecture that LAO will considerably benefit or-parallel systems such as Aurora <ref> [10] </ref> (at present we have only tried it on Muse). The find match predicate used in the DNA application in [3] will also benefit from LAO. LAO will also improve the performance of programs that use failure driven loops based on Prolog's repeat builtin. 3.
Reference: [11] <author> M. Meier. </author> <title> Recursion vs. Iteration in Prolog. </title> <booktitle> In International Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Note that LAO doesn't bring much benefit to sequential implementations of Prolog <ref> [11] </ref>, Unlike a sequential system, in an or-parallel implementation when the last alternative from a choice point is picked, that choice point cannot be deallocated as alternatives before the last one may still be active (i.e., they are still being explored by other processors).
Reference: [12] <author> D. Smith. Multilog: </author> <title> Data or-parallel logic programming. </title> <booktitle> In International Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The same discussion applies to the select predicate that, like the member predicate, is also traditionally used to spawn or-parallelism: select (X,[X|T],T). select (X,[Y|T],[Y|R]) :- select (X,T,R). Several researchers have proposed ways for making the work distribution operation more efficient. For example, Smith, in his Multilog system <ref> [13, 12] </ref>, has proposed the addition of a disj primitive to Prolog, that the programmer should place before call to member. Thus, the query is of the form: ?- disj member (X,[1,2,3,4]), compute (X,R).
Reference: [13] <author> D. Smith. </author> <title> Why Multi-SLD beats SLD (even on a uniprocessor). </title> <booktitle> In LPAR. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1994. </year>
Reference-contexts: The same discussion applies to the select predicate that, like the member predicate, is also traditionally used to spawn or-parallelism: select (X,[X|T],T). select (X,[Y|T],[Y|R]) :- select (X,T,R). Several researchers have proposed ways for making the work distribution operation more efficient. For example, Smith, in his Multilog system <ref> [13, 12] </ref>, has proposed the addition of a disj primitive to Prolog, that the programmer should place before call to member. Thus, the query is of the form: ?- disj member (X,[1,2,3,4]), compute (X,R).
References-found: 13

