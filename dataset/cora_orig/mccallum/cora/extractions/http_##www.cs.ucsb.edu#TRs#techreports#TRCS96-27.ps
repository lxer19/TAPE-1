URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS96-27.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fdandrese, tyangg@cs.ucsb.edu  
Title: Adaptive Scheduling with Client Resources to Improve WWW Server Scalability  
Author: Daniel Andresen and Tao Yang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: WWW-based Internet information service has grown enormously during last few years, and major performance bottlenecks have been caused by WWW server and Internet bandwidth inadequacies. Augmenting the server with multi-processor support and shifting computation to client-site machines can substantially improve the system response time and for some applications, it may also reduce network bandwidth requirement. In this paper, we model client-server partitionable WWW applications and propose adaptive scheduling techniques that optimize the use of client-server resource by predicting the aggregate impact of I/O, CPU and network capabilities. We present a software system called SWEB++ which implements and supports the use of our scheduling strategies when programming WWW applications. We also provide a performance-analysis framework based on homogeneous client-server assumptions to identify the impact of system loads and network bandwidth and demonstrate the effectiveness of our scheduling strategies. Finally we present several experimental results to examine the system performance and verify the usefulness of the analytic model.
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> The AltaVista: Main Page, </institution> <note> http://altavista.digital.com/. </note>
Reference-contexts: The emergence of gigabit information superhighways further enhances the vision of accessible world-wide global computing resources. The major performance bottlenecks for the advent of WWW technology are server computing capabilities and Internet bandwidth. Popular WWW sites such as Alta Vista <ref> [1] </ref> receive over twenty million accesses a day, where the computational demand for each request is often less than that in many sophisticated WWW systems (e.g. DLs). In [4], we have addressed issues of developing multi-processor Web servers in dealing with this bottleneck using networked workstations connected with inexpensive disks. <p> transfer the required data from the server disk drive, or from the remote disk if the file is not local. t server 8 #sample task chain definition for wavelets TASK wav_extract_subtree &lt; SERVER_BINARY = "wavelet.subtree_extract" CLIENT_BINARY = "wavelet.subtree_extract.clnt" ARGUMENT_KEY = "sub_extract" EXECUTION_LOCATION = EITHER FILE_IN_SIZE = FUNC return dbm_lookup_filesize (ARGUMENT_KEY <ref> [1] </ref>); FUNC_END LOCALITY = ARGUMENT_KEY [1] #use our path in the first argument for locality OUTPUT_SIZE = FUNC return subregion_size (FILE_IN_SIZE); FUNC_END OUTPUT_TYPE = "x-wav/compressed_coeff" COMPUTATION = FUNC: return 100*OUTPUT_SIZE; FUNC_END &gt; TASK wav_recreate_coefficients &lt; SERVER_BINARY = "wavelet.recreate_coeff" CLIENT_BINARY = "wavelet.recreate_coeff.clnt" ARGUMENT_KEY = "rec_coeff" EXECUTION_LOCATION = EITHER OUTPUT_SIZE = FUNC return <p> the server disk drive, or from the remote disk if the file is not local. t server 8 #sample task chain definition for wavelets TASK wav_extract_subtree &lt; SERVER_BINARY = "wavelet.subtree_extract" CLIENT_BINARY = "wavelet.subtree_extract.clnt" ARGUMENT_KEY = "sub_extract" EXECUTION_LOCATION = EITHER FILE_IN_SIZE = FUNC return dbm_lookup_filesize (ARGUMENT_KEY <ref> [1] </ref>); FUNC_END LOCALITY = ARGUMENT_KEY [1] #use our path in the first argument for locality OUTPUT_SIZE = FUNC return subregion_size (FILE_IN_SIZE); FUNC_END OUTPUT_TYPE = "x-wav/compressed_coeff" COMPUTATION = FUNC: return 100*OUTPUT_SIZE; FUNC_END &gt; TASK wav_recreate_coefficients &lt; SERVER_BINARY = "wavelet.recreate_coeff" CLIENT_BINARY = "wavelet.recreate_coeff.clnt" ARGUMENT_KEY = "rec_coeff" EXECUTION_LOCATION = EITHER OUTPUT_SIZE = FUNC return 8*INPUT_SIZE; FUNC_END OUTPUT_TYPE = "x-wav/uncompressed_coeff" <p> coefficients for transfer return 20*OUTPUT_SIZE; FUNC_END SPLIT_CLIENT_COMPUTATION = FUNC #decompress the coefficients after transfer return 20*OUTPUT_SIZE; FUNC_END SPLIT_OUTPUT_SIZE = INPUT_SIZE COMPUTATION = FUNC: return 100*OUTPUT_SIZE; FUNC_END &gt; TASK wav_create_ppm &lt; SERVER_BINARY = "wavelet.recreate_ppm" CLIENT_BINARY = "wavelet.recreate_ppm.clnt" ARGUMENT_KEY = "rec_ppm" EXECUTION_LOCATION = EITHER FILE_INPUT_SIZE= FUNC if (ON_SERVER) - return dbm_lookup_filesize (ARGUMENT_KEY <ref> [1] </ref>); else- return 0;- FUNC_END LOCALITY = ARGUMENT_KEY [1] OUTPUT_SIZE = FUNC return image_size (ARGUMENT_KEY [2]); FUNC_END OUTPUT_TYPE = "image/ppm" COMPUTATION = FUNC return 100*OUTPUT_SIZE; FUNC_END &gt; TASK view &lt; EXECUTION_LOCATION = CLIENT_ONLY COMPUTATION = 0 &gt; CHAIN wavelets IS wav_extract_subtree, wav_recreate_coefficients, wav_create_ppm, view &lt; REQUEST_KEY = "wavelet" &gt; 9 is <p> FUNC #decompress the coefficients after transfer return 20*OUTPUT_SIZE; FUNC_END SPLIT_OUTPUT_SIZE = INPUT_SIZE COMPUTATION = FUNC: return 100*OUTPUT_SIZE; FUNC_END &gt; TASK wav_create_ppm &lt; SERVER_BINARY = "wavelet.recreate_ppm" CLIENT_BINARY = "wavelet.recreate_ppm.clnt" ARGUMENT_KEY = "rec_ppm" EXECUTION_LOCATION = EITHER FILE_INPUT_SIZE= FUNC if (ON_SERVER) - return dbm_lookup_filesize (ARGUMENT_KEY <ref> [1] </ref>); else- return 0;- FUNC_END LOCALITY = ARGUMENT_KEY [1] OUTPUT_SIZE = FUNC return image_size (ARGUMENT_KEY [2]); FUNC_END OUTPUT_TYPE = "image/ppm" COMPUTATION = FUNC return 100*OUTPUT_SIZE; FUNC_END &gt; TASK view &lt; EXECUTION_LOCATION = CLIENT_ONLY COMPUTATION = 0 &gt; CHAIN wavelets IS wav_extract_subtree, wav_recreate_coefficients, wav_create_ppm, view &lt; REQUEST_KEY = "wavelet" &gt; 9 is the time for server computation required. t net
Reference: [2] <author> E. Anderson, D. Patterson, E. Brewer, </author> <title> "The Magicrouter, an Application of Fast Packet Interposing", </title> <booktitle> submitted to the Second Symposium on Operating System Design and Implementation (OSDI96), </booktitle> <year> 1996. </year>
Reference-contexts: Load re-balancing is effective under the assumption that our targeted WWW applications (e.g. DLs) involve intensive I/O and computation in the server. Another approach for implementing re-assignment is socket forwarding, which avoids the overhead of re-connection, but requires significant changes in the OS kernel or network interface drivers <ref> [2] </ref>. We have not used it for compatibility reasons. 4.1 A cost model for processing task chains For each request, we predict the processing time and assign this request to an appropriate processor. <p> 20*OUTPUT_SIZE; FUNC_END SPLIT_OUTPUT_SIZE = INPUT_SIZE COMPUTATION = FUNC: return 100*OUTPUT_SIZE; FUNC_END &gt; TASK wav_create_ppm &lt; SERVER_BINARY = "wavelet.recreate_ppm" CLIENT_BINARY = "wavelet.recreate_ppm.clnt" ARGUMENT_KEY = "rec_ppm" EXECUTION_LOCATION = EITHER FILE_INPUT_SIZE= FUNC if (ON_SERVER) - return dbm_lookup_filesize (ARGUMENT_KEY [1]); else- return 0;- FUNC_END LOCALITY = ARGUMENT_KEY [1] OUTPUT_SIZE = FUNC return image_size (ARGUMENT_KEY <ref> [2] </ref>); FUNC_END OUTPUT_TYPE = "image/ppm" COMPUTATION = FUNC return 100*OUTPUT_SIZE; FUNC_END &gt; TASK view &lt; EXECUTION_LOCATION = CLIENT_ONLY COMPUTATION = 0 &gt; CHAIN wavelets IS wav_extract_subtree, wav_recreate_coefficients, wav_create_ppm, view &lt; REQUEST_KEY = "wavelet" &gt; 9 is the time for server computation required. t net is the cost for transferring the processing
Reference: [3] <author> D.Andresen, L.Carver, R.Dolin, C.Fischer, J.Frew, M.Goodchild, O.Ibarra, R.Kothuri, M.Larsgaard, B.Manjunath, D.Nebert, J.Simpson, T.Smith, T.Yang, Q.Zheng, </author> <title> "The WWW Prototype of the Alexandria Digital Library", </title> <booktitle> Proceedings of ISDL'95: International Symposium on Digital Libraries, </booktitle> <address> Japan August 22 - 25, </address> <year> 1995. </year>
Reference-contexts: assume that local communication between tasks within the same partition (client or server) is zero while client-server communication delay is determined by the current available bandwidth between them. 2.2 An example: multi-resolution image browsing We briefly demonstrate the above model for an application in the Alexandria Digital Library system (ADL) <ref> [3] </ref>. The current collections of ADL involve geographically-referenced materials, such as maps, satellite images, digitized aerial photographs, and associated metadata. The images can range in size from 10-100MB, with larger files expected in the near future as the scanning resolution increases.
Reference: [4] <author> D.Andresen, T.Yang, V.Holmedahl, O.Ibarra, "SWEB: </author> <title> Towards a Scalable World Wide Web Server on Multi-computers", </title> <booktitle> Proc. of 10th IEEE International Symp. on Parallel Processing (IPPS'96), </booktitle> <pages> pp. 850-856. </pages> <month> April, </month> <year> 1996. </year>
Reference-contexts: Popular WWW sites such as Alta Vista [1] receive over twenty million accesses a day, where the computational demand for each request is often less than that in many sophisticated WWW systems (e.g. DLs). In <ref> [4] </ref>, we have addressed issues of developing multi-processor Web servers in dealing with this bottleneck using networked workstations connected with inexpensive disks. As the WWW develops and Web browsers achieve the ability to download executable content (e.g. <p> Our WWW server model consists of a set of nodes connected with a fast network as shown in Figure 1 and presented as a single logical server to the Internet <ref> [4] </ref>. The user requests are first evenly routed to processors via DNS rotation [22]. Each server node may have its local disk, which is accessible to other nodes via remote file service in the OS. Each task chain can be scheduled onto one of the server nodes. <p> Local network traffic congestion could dramatically slow the request processing. We first present the cost model for predicting the response time in processing a request, then we discuss a strategy to select a server node and decide a good split point. Notice that in <ref> [4] </ref>, we have proposed using URL redirection to implement the request re-assignment. The HTTP protocol allows for a response called "URL Redirection". <p> The overhead of our scheduling and load monitoring is quite small for all experiments. Analyzing a request takes about 2-4ms, and load monitoring takes about 0.1% of CPU resources. These results are very similar to those reported in <ref> [4] </ref>. 6.1 The impact of adding multiple servers (a) (b) Wavelet subimage retrieval. The period is 30 seconds. We examine the scalability of the multi-processor server with client resources. We run a test for a period of 30 seconds, at each second R requests are launched from clients. <p> Compared to the previous SWEB work <ref> [4] </ref>, the main contributions of SWEB++ are an adaptive scheduling model for processing requests by utilizing both client and WWW server resources, a software tool prototype for WWW programmers to incorporate this adaptive scheduling model in developing their applications, and an analytic framework for identifying the performance impact of various system
Reference: [5] <author> D. Andresen, T. Yang, O. Egecioglu, O.H. Ibarra, T.R. Smith, </author> <title> "Scalability Issues for High Performance Digital Libraries on the World Wide Web", </title> <booktitle> Proc. of the 3rd Forum on Research and Tech. Advances in Digital Libraries (ADL96), </booktitle> <pages> pp. 139-148, </pages> <month> May, </month> <year> 1996. </year>
Reference-contexts: It is infeasible to simultaneously transfer many large data files for browsing over the current slow Internet links. The 3 ADL has adopted progressive multi-resolution and subregion browsing strategies to reduce Internet traffic in accessing map images <ref> [5] </ref>. This approach is based on the idea that users often browse large images via a thumbnail (at coarse resolution), and desire to rapidly view higher-resolution versions and subregions of those images already being viewed.
Reference: [6] <author> M. Arlitt, C. Williamson, </author> <title> Web Server Workload Characterization: The Search for Invariants, </title> <booktitle> Proc. SIGMETRICS Conference, </booktitle> <address> Philadelphia, PA, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: We denote this as model (r; L). Two instances of this model are considered. * (r; 1). This reflects the system performance in responding to a burst in user requests, which occurs frequently in many WWW sites <ref> [6, 12] </ref>. All requests are assumed completed in the same length of time and each server processor is dealing with the same number of requests until all finish. All task chains are partitioned uniformly on the same edge. * (r; 1).
Reference: [7] <author> T. Bemers-Lee and D. Connolly, </author> <title> Hypertext Markup Language - 2.0, </title> <address> http://www.w3.org/hypertext/WWW/MarkUp/html-spec/html-spec toc.html, </address> <month> June 16, </month> <year> 1995. </year>
Reference-contexts: The URL defines which resource the user wishes to access, the HTML language allows the information to be presented in a platform-independent but still well-formatted manner, and the HTTP protocol is the application-level mechanism for achieving the transfer of information <ref> [7, 8, 21] </ref>. An HTTP request would typically activate the following sequence of events from initiation to completion. First, the client determines the host name from the URL, and uses the local Domain Name System (DNS) server to determine its IP address.
Reference: [8] <author> T. Bemers-Lee, </author> <title> Uniform Resource Locators, </title> <note> http://www.w3.org/hypertext/WWW/Addressing/URL/, 1996. </note>
Reference-contexts: The URL defines which resource the user wishes to access, the HTML language allows the information to be presented in a platform-independent but still well-formatted manner, and the HTTP protocol is the application-level mechanism for achieving the transfer of information <ref> [7, 8, 21] </ref>. An HTTP request would typically activate the following sequence of events from initiation to completion. First, the client determines the host name from the URL, and uses the local Domain Name System (DNS) server to determine its IP address.
Reference: [9] <author> F. Berman, R. Wolski, S. Figueira, J. Schopf, G. Shao, </author> <title> "Application-Level Scheduling on Distributed Heterogeneous Networks", </title> <note> Submitted to Supercomputing '96. </note>
Reference-contexts: There are other projects [11, 18, 26] also working on global computing software infrastructures. Our current project focuses on the optimization for single server/client pair and the nodes in the WWW server are relatively tightly coupled. The AppLeS project <ref> [9] </ref> addresses the scheduling issues in heterogeneous computing and also uses network bandwidth and load information. Their work deals with an integration of different machines as one server and does not have the division of client and server.
Reference: [10] <author> E.C.K. Chui, </author> <title> Wavelets: A Tutorial in Theory and Applications, </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: To support these features, the ADL system is using a wavelet-based hierarchical data representation for multi-resolution decomposition of images. This process of multi-resolution browsing is summarized as follows. An image is decomposed hierarchically using the wavelet transform <ref> [10] </ref>. When a client requests an image, the system searches through a database catalog engine and then delivers a thumbnail of this image.
Reference: [11] <author> H. Casanova, J. Dongarra, NetSolve: </author> <title> A network server for solving computation science problems, </title> <note> To Appear in Supercomputing'96, ACM/IEEE, Nov 196. </note>
Reference-contexts: Several projects are related to our work. The WWWVM project [13] is aimed at providing meta-computing services by integrating resources of several WWW servers. There are other projects <ref> [11, 18, 26] </ref> also working on global computing software infrastructures. Our current project focuses on the optimization for single server/client pair and the nodes in the WWW server are relatively tightly coupled.
Reference: [12] <author> M. Crovella, A. Bestavros, </author> <title> "Self-Similarity in World Wide Web Traffic Evidence and Possible Causes", </title> <booktitle> Proc. </booktitle> <address> SIGMETRICS96, Philadelphia, PA, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: We denote this as model (r; L). Two instances of this model are considered. * (r; 1). This reflects the system performance in responding to a burst in user requests, which occurs frequently in many WWW sites <ref> [6, 12] </ref>. All requests are assumed completed in the same length of time and each server processor is dealing with the same number of requests until all finish. All task chains are partitioned uniformly on the same edge. * (r; 1).
Reference: [13] <author> K. Dincer, and G. C. Fox, </author> <title> Bulding a world-wide virtual machine based on Web and HPCC technologies. </title> <note> To Appear in Supercomputing'96, ACM/IEEE, Nov 196. </note>
Reference-contexts: For example, most digital library (DL) systems [16] will be based on the WWW. Research efforts are being made to build a virtual global computing service through WWW servers, e.g. <ref> [13] </ref>. An important feature of such services is that information can be obtained and processed transparently, independent of its location. The emergence of gigabit information superhighways further enhances the vision of accessible world-wide global computing resources. <p> The experimental results with SWEB++ show that proper monitoring and utilizing of server and client resources significantly enhance the scalability of WWW-based services. Several projects are related to our work. The WWWVM project <ref> [13] </ref> is aimed at providing meta-computing services by integrating resources of several WWW servers. There are other projects [11, 18, 26] also working on global computing software infrastructures. Our current project focuses on the optimization for single server/client pair and the nodes in the WWW server are relatively tightly coupled.
Reference: [14] <author> D. L. Eager, E. D. Lazowska, and J. Zahojan, </author> <title> Adaptive load sharing in homogeneous distributed systems, </title> <journal> IEEE Trans on Software Engineering, </journal> <volume> 12(5) </volume> <pages> 662-675. </pages> <year> 1986. </year>
Reference-contexts: Addressing client configuration variation is discussed in [15] for filtering multi-media data in order to reduce network bandwidth requirements but does not consider the use of client resources for integrated computing. The classical work on load balancing for distributed systems <ref> [14, 28, 29] </ref> usually assumes that task resource requirements are unknown, and the criteria for task migration are usually based on a single system parameter, i.e., the CPU load.
Reference: [15] <author> A. Fox, E. Brewer, </author> <title> "Reducing WWW Latency and Bandwidth Requirements by Real-Time Distillation", </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> Volume 28, issues 711, </volume> <editor> p. </editor> <volume> 1445. </volume> <month> May, </month> <year> 1996. </year>
Reference-contexts: The AppLeS project [9] addresses the scheduling issues in heterogeneous computing and also uses network bandwidth and load information. Their work deals with an integration of different machines as one server and does not have the division of client and server. Addressing client configuration variation is discussed in <ref> [15] </ref> for filtering multi-media data in order to reduce network bandwidth requirements but does not consider the use of client resources for integrated computing.
Reference: [16] <author> E. Fox, Akscyn, R., Furuta, R. and Leggett, J. </author> <title> (Eds), </title> <journal> Special issue on digital libraries, CACM, </journal> <month> April </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Recently WWW-based computer technology has had an explosive growth in providing on-line access for images, files, and computing services over Internet. For example, most digital library (DL) systems <ref> [16] </ref> will be based on the WWW. Research efforts are being made to build a virtual global computing service through WWW servers, e.g. [13]. An important feature of such services is that information can be obtained and processed transparently, independent of its location.
Reference: [17] <author> K. Goswami, M. Devarakonda, R. Iyer, </author> <title> Prediction-based Dynamic Load-sharing Heuristics, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 638-648, </pages> <month> June, </month> <year> 1993. </year>
Reference-contexts: In WWW applications, we need to consider multiple parameters that affect the system performance, including CPU loads, interconnection network performance and disk channel usages. In <ref> [17] </ref>, multiple resource requirements are predicted and suggested to guide the load sharing, our work provides a more comprehensive scheme focusing on client-server computing environments. Several issues still remain to be explored.
Reference: [18] <author> A. S. Grimshaw, A. N. Tuong, W. A. Wulf, </author> <title> Campus-Wide Computing: Results Using Legion at the University of Virginia, </title> <type> UVa CS Technical Report CS-95-19, </type> <month> March 27, </month> <year> 1995. </year>
Reference-contexts: Several projects are related to our work. The WWWVM project [13] is aimed at providing meta-computing services by integrating resources of several WWW servers. There are other projects <ref> [11, 18, 26] </ref> also working on global computing software infrastructures. Our current project focuses on the optimization for single server/client pair and the nodes in the WWW server are relatively tightly coupled.
Reference: [19] <author> M. Hamilton, </author> <title> "Java and the Shift to Net-Centric Computing", </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 31-39, </pages> <month> August, </month> <year> 1996. </year>
Reference-contexts: As the WWW develops and Web browsers achieve the ability to download executable content (e.g. Java), it becomes logical to think of transferring part of the server's workload to clients <ref> [19] </ref>. Changing the computation distribution between a client and a server may also alter communication patterns between them, possibly reducing network bandwidth requirements. Such a global computing style scatters the workload around the world and can lead to significantly improved user interfaces and response times.
Reference: [20] <author> R. Hof, </author> <title> "These may really be the PCs for the rest of us", </title> <booktitle> Business Week, </booktitle> <pages> pp. 76-78, </pages> <month> June 24, </month> <year> 1996. </year>
Reference-contexts: Also a number of commercial corporations are developing so-called "network computers", with little or no hard drive, and a minimal processor, but with Java and the Internet networking built in. A careful design of the scheduling strategy is needed to avoid imposing too much burden on these Net PCs <ref> [20] </ref>. At the server site, information on the current system load and the disk I/O bandwidth also affects the selection of a server node for processing a request. In addition to this, the impact of available bandwidth between the server and client needs to be incorporated. <p> For example, if the server nodes are heavily burdened and the client is rather powerful, it might be sensible to shift everything possible to the client. If the client happens to be a 16Mhz 386sx sitting in a high school laboratory or under-powered NetPC <ref> [20] </ref>, then keeping things on the server could be more optimal in terms of request response time. In addition to balancing between client and server machine load and capability, the network bandwidth between client and server also affects the partitioning point.
Reference: [21] <author> Hypertext Transfer Protocol(HTTP): </author> <title> A protocol for networked information, </title> <address> http://www.w3.org/hypertext/WWW/Protocols/HTTP/HTTP2.html, June 26, </address> <year> 1995. </year>
Reference-contexts: The URL defines which resource the user wishes to access, the HTML language allows the information to be presented in a platform-independent but still well-formatted manner, and the HTTP protocol is the application-level mechanism for achieving the transfer of information <ref> [7, 8, 21] </ref>. An HTTP request would typically activate the following sequence of events from initiation to completion. First, the client determines the host name from the URL, and uses the local Domain Name System (DNS) server to determine its IP address. <p> This response code could indicate the request service can be performed, or might redirect the request to another server. After the contents of the response are sent to the client, the connection is closed by either the client or the server <ref> [21] </ref>. The results of the request are normally described in HTML for client display.
Reference: [22] <author> E.D. Katz, M. Butler, R. McGrath, </author> <title> A Scalable HTTP Server: the NCSA Prototype, </title> <journal> Computer Networks and ISDN Systems. </journal> <volume> vol. 27, </volume> <year> 1994, </year> <pages> pp. 155-164. </pages>
Reference-contexts: Our WWW server model consists of a set of nodes connected with a fast network as shown in Figure 1 and presented as a single logical server to the Internet [4]. The user requests are first evenly routed to processors via DNS rotation <ref> [22] </ref>. Each server node may have its local disk, which is accessible to other nodes via remote file service in the OS. Each task chain can be scheduled onto one of the server nodes. <p> Various authors have noted that DNS rotation seems to inevitably lead to load imbalances <ref> [22, 24] </ref>. We examine how our system deals with hot-spots by sending a fixed number of requests to a subset of nodes in our server cluster, giving a wide range of load disparities. Without our scheduler, the selected nodes would have to process all of those requests.
Reference: [23] <author> Meiko Corp., </author> <title> Computing Surface CS-2 Product Description, Meiko, </title> <address> Waltham, MA, </address> <year> 1994. </year> <month> 24 </month>
Reference-contexts: The Meiko CS-2 can be viewed as a workstation cluster connected by the Elan fast network. Each node has a scalar processing unit (a 40Mhz SuperSparc chip) with 32MB of RAM running SUN Solaris 2.3 <ref> [23] </ref>. The theoretical peak performance of Elan network is 40MBytes/sec; however, the TCP/IP layer communication on the Meiko can achieve approximately 3-15% of the peak performance.
Reference: [24] <author> D. Mosedale, W. Foss, R. McCool, </author> <title> "Administering Very High Volume Internet Services", </title> <booktitle> 1995 LISA IX, </booktitle> <address> Mon--terey, CA, </address> <month> September, </month> <year> 1995. </year>
Reference-contexts: Various authors have noted that DNS rotation seems to inevitably lead to load imbalances <ref> [22, 24] </ref>. We examine how our system deals with hot-spots by sending a fixed number of requests to a subset of nodes in our server cluster, giving a wide range of load disparities. Without our scheduler, the selected nodes would have to process all of those requests.
Reference: [25] <author> NCSA development team, </author> <title> The Common Gateway Interface, </title> <address> http://hoohoo.ncsa.uiuc.edu/cgi/, June, </address> <year> 1995. </year>
Reference-contexts: and the request results can be a platform-independent program (called applet) runnable at the client machine to produce the results for display. 2 2.1 The Model We model the interaction between client and server as a task chain that is partially executed at the server node (possibly as a CGI <ref> [25] </ref> program) and partially executed at the client site (as a Java applet if applicable). A task consists of a segment of the request fulfillment, with its associated computation and communication.
Reference: [26] <author> Ninf, </author> <title> A network based information library for global world-wide computing infrastructure, </title> <note> http://hpc.etl.go.jp/NinfDemo.html, 1996. </note>
Reference-contexts: an active role in contributing its resources and send back with its requests estimated information on the bandwidth to the server, latency for a server connection, and the client's processing capabilities. 6 3.2 The Task Definition Language The Task Definition Language (TDL) is similar to the Durra language used by <ref> [26] </ref>, with several extensions to meet our needs. The syntax is straightforward, and many simple tasks can be defined within the language itself. For complex tasks, TDL allows a user to embed a complete C++ function where necessary. <p> Several projects are related to our work. The WWWVM project [13] is aimed at providing meta-computing services by integrating resources of several WWW servers. There are other projects <ref> [11, 18, 26] </ref> also working on global computing software infrastructures. Our current project focuses on the optimization for single server/client pair and the nodes in the WWW server are relatively tightly coupled.
Reference: [27] <author> A. Poulakidas, A. Srinivasan, O. Egecioglu, O. Ibarra, and T. Yang, </author> <title> Experimental Studies on a Compact Storage Scheme for Wavelet-based Multiresolution Subregion Retrieval, </title> <booktitle> Proceedings of NASA 1996 Combined Industry, Space and Earth Science Data Compression Workshop, </booktitle> <address> Utah, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: In this case the system needs to find the appropriate subregion image wavelet data, sending the client site only the data necessary for the subregion. computation partitioning between client and server. resolution, based on an implementation in <ref> [27] </ref>. The chain has four tasks, which are summarized as follows: * Fetching and extracting the subtree. The wavelet image data is stored in a combined quad-tree/Huffman encoded form on a disk. These compressed files must be fetched. <p> To avoid 18 Internet bandwidth fluctuations, clients are located within the campus network to assist in experimental stability over multiple runs. We primarily examine the SWEB++ performance of wavelet subimage retrieval and file fetches. The wavelet code used for our experiments was developed in <ref> [27] </ref>. The wavelet operation we choose is to extract a 512 fi 512 subregion at full resolution from a 2K fi 2K map image, representing the user zooming in on a point of interest at a higher resolution after examining at an image thumbnail.
Reference: [28] <author> B. A. Shirazi, A. R. Hurson, and K. M. Kavi (Eds), </author> <title> Scheduling and Load Balancing in Parallel and Distributed Systems, </title> <publisher> IEEE CS Press, </publisher> <year> 1995. </year>
Reference-contexts: To avoid this unsynchronized overloading, we conservatively increase the CPU load of p x by . This strategy is found to be effective in <ref> [28, 29] </ref>. We typically use = 30%. * t client = No. of client operations required CP U client speed : The number of client operations required depends on how the subtask chain is partitioned. <p> Addressing client configuration variation is discussed in [15] for filtering multi-media data in order to reduce network bandwidth requirements but does not consider the use of client resources for integrated computing. The classical work on load balancing for distributed systems <ref> [14, 28, 29] </ref> usually assumes that task resource requirements are unknown, and the criteria for task migration are usually based on a single system parameter, i.e., the CPU load.
Reference: [29] <author> M. Willebeek-LeMair and A. Reeves, </author> <title> Strategies for Dynamic Load Balancing on Highly Parallel Computers, </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 4, no. 9, </volume> <month> September, </month> <year> 1993, </year> <pages> pp. 979-993. 25 </pages>
Reference-contexts: To avoid this unsynchronized overloading, we conservatively increase the CPU load of p x by . This strategy is found to be effective in <ref> [28, 29] </ref>. We typically use = 30%. * t client = No. of client operations required CP U client speed : The number of client operations required depends on how the subtask chain is partitioned. <p> Addressing client configuration variation is discussed in [15] for filtering multi-media data in order to reduce network bandwidth requirements but does not consider the use of client resources for integrated computing. The classical work on load balancing for distributed systems <ref> [14, 28, 29] </ref> usually assumes that task resource requirements are unknown, and the criteria for task migration are usually based on a single system parameter, i.e., the CPU load.
References-found: 29

