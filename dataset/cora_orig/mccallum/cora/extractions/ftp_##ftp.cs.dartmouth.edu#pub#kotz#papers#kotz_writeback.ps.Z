URL: ftp://ftp.cs.dartmouth.edu/pub/kotz/papers/kotz:writeback.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~dfk/papers/writeback.html
Root-URL: http://www.cs.dartmouth.edu
Email: David.Kotz@Dartmouth.edu carla@cs.duke.edu  
Title: Caching and Writeback Policies in Parallel File Systems  
Author: David Kotz Carla Schlatter Ellis 
Address: Hanover, NH 03755-3551 Durham, NC 27706  
Affiliation: Dept. of Math and Computer Science Dept. of Computer Science Dartmouth College Duke University  
Web: URL ftp://ftp.cs.dartmouth.edu/pub/CS-papers/Kotz/kotz:writeback.ps.Z  
Note: Copyright 1991 by IEEE. Appeared in Symp. on Parallel and Distributed Processing, pages 60-67. Available at  
Abstract: Improvements in the processing speed of multiprocessors are outpacing improvements in the speed of disk hardware. Parallel disk I/O subsystems have been proposed as one way to close the gap between processor and disk speeds. Such parallel disk systems require parallel file system software to avoid performance-limiting bottlenecks. We discuss cache management techniques that can be used in a parallel file system implementation. We examine several writeback policies, and give results of experiments that test their performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> BBN Advanced Computers. Butterfly Products Overview, </institution> <year> 1987. </year>
Reference-contexts: We implemented a file system testbed called RAPID-Transit ("Read-Ahead for Parallel Independent Disks") on a BBN GP1000 Butterfly parallel processor <ref> [1] </ref>, an MIMD machine. Since the multiprocessor does not have parallel disks, they are simulated. The testbed is a heavily parameterized parallel program, incorporating the synthetic workload (the application), the file system (interface and manager), and the set of simulated disks.
Reference: [2] <author> Thomas W. Crockett. </author> <title> File concepts for parallel I/O. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <pages> pages 574-579, </pages> <year> 1989. </year>
Reference-contexts: These studies found that sequential access, usually of the entire file, is the major form of access. Supercomputer file access patterns (a scientific workload) involve huge files (tens to thousands of megabytes) accessed primarily sequentially, sometimes repeatedly [11]. Parallel file access has been discussed by Crockett <ref> [2] </ref>, but he did not study an actual workload. 3 Models and Methods 3.1 Architectural Models Our architectural model is a multiple instruction stream, multiple data stream (MIMD) multiprocessor.
Reference: [3] <author> Peter Dibble, Michael Scott, and Carla Ellis. </author> <title> Bridge: A high-performance file system for parallel processors. </title> <booktitle> In Proceedings of the Eighth International Conference on Distributed Computer Systems, </booktitle> <pages> pages 154-161, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The files may be interleaved over the disks, but the multiple controllers and independent access to the disks make this technique different from disk striping. Examples of this architecture include the Concurrent File System [14, 6] for the Intel iPSC/2 multiprocessor, and the Bridge <ref> [4, 3] </ref> file system for the BBN Butterfly parallel computer. File caching is a technique used in most modern file systems. Caching has not been studied for parallel file systems, but Alan Smith has extensively studied disk caching in uniprocessors with general-purpose work-loads.
Reference: [4] <author> Peter C. Dibble. </author> <title> A Parallel Interleaved File System. </title> <type> PhD thesis, </type> <institution> University of Rochester, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: The files may be interleaved over the disks, but the multiple controllers and independent access to the disks make this technique different from disk striping. Examples of this architecture include the Concurrent File System [14, 6] for the Intel iPSC/2 multiprocessor, and the Bridge <ref> [4, 3] </ref> file system for the BBN Butterfly parallel computer. File caching is a technique used in most modern file systems. Caching has not been studied for parallel file systems, but Alan Smith has extensively studied disk caching in uniprocessors with general-purpose work-loads.
Reference: [5] <author> Rick Floyd. </author> <title> Short-term file reference patterns in a UNIX environment. </title> <type> Technical Report 177, </type> <institution> Dept. of Computer Science, Univ. of Rochester, </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: This paper concentrates on multiprocessor file systems intended for scientific applications. These applications typically push the leading edge of computing technology, such as multiprocessors, placing tremendous demands on both CPU and I/O systems. Most file caching studies have examined general-purpose workloads (e.g., [16]), where files are much smaller <ref> [12, 5] </ref>. The parallel environment and workload raise a number of questions: Are caches useful for parallel scientific applications using parallel file systems? If so, in what way? What are the appropriate management policies? Different workload characteristics, including a new form of locality, lead us to new policies. <p> File access patterns have never been studied for parallel computers, but have been studied extensively for uniprocessors <ref> [5, 12] </ref>. These studies found that sequential access, usually of the entire file, is the major form of access. Supercomputer file access patterns (a scientific workload) involve huge files (tens to thousands of megabytes) accessed primarily sequentially, sometimes repeatedly [11]. <p> The file system internals, which are responsible for caching, see only the block access pattern. In our research we do not investigate read/write file access patterns, because most files are opened for either reading or writing, with few files updated <ref> [5, 12] </ref>. We expect this to be especially true for the large files used in scientific applications. Thus we consider read-only patterns, used to demonstrate the benefits of caching, and write-only patterns, used to investigate delayed-write policies. All sequential patterns consist of a sequence of accesses to sequential portions.
Reference: [6] <author> James C. French, Terrence W. Pratt, and Mri-ganka Das. </author> <title> Performance measurement of a parallel input/output system for the Intel iPSC/2 hypercube. </title> <booktitle> Proceedings of the 1991 ACM Sigmet-rics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 178-187, </pages> <year> 1991. </year>
Reference-contexts: The files may be interleaved over the disks, but the multiple controllers and independent access to the disks make this technique different from disk striping. Examples of this architecture include the Concurrent File System <ref> [14, 6] </ref> for the Intel iPSC/2 multiprocessor, and the Bridge [4, 3] file system for the BBN Butterfly parallel computer. File caching is a technique used in most modern file systems.
Reference: [7] <author> Michelle Y. Kim. </author> <title> Synchronized disk interleaving. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(11):978-988, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: In Section 4 we present the experiments, performance measures, and results. Section 5 concludes. 2 Background Much of the previous work in I/O hardware parallelism involves disk striping. In this technique, data of a file are interleaved across numerous disks and accessed synchronously in parallel <ref> [15, 7, 13] </ref>. These schemes rely on a single controller to manage all of the disks. For multiprocessors, one form of parallel disk architecture is based on the notion of parallel, independent disks, using multiple conventional disk devices 1 addressed independently and attached to separate pro-cessors.
Reference: [8] <author> David Kotz. </author> <title> Prefetching and Caching Techniques in File Systems for MIMD Multiprocessors. </title> <type> PhD thesis, </type> <institution> Duke University, </institution> <month> April </month> <year> 1991. </year> <note> Available as technical report CS-1991-016. </note>
Reference-contexts: The sequential access patterns in the workload suggest prefetching and write-behind. Prefetching is the focus of <ref> [9, 10, 8] </ref>, and write-behind is the focus of this paper. What policies are most appropriate for buffering writes for these parallel scientific-application workloads? Do write-behind and delayed writeback help? In what way? This paper examines these issues, defines some new policies, and reports results from experiments with these policies. <p> This method allows us to evaluate whether practical caching policies can be implemented. See <ref> [8] </ref> for more details. In this section we describe one simple replacement policy, which determines the blocks to replace when a free buffer is needed, and several write policies, which determine when new data are written back to disk. <p> Prefetch-ing can avoid this underutilization; see <ref> [9, 8, 10] </ref> for further study of read-only patterns and prefetching.
Reference: [9] <author> David Kotz and Carla Schlatter Ellis. </author> <title> Prefetch-ing in file systems for MIMD multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(2) </volume> <pages> 218-230, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: The sequential access patterns in the workload suggest prefetching and write-behind. Prefetching is the focus of <ref> [9, 10, 8] </ref>, and write-behind is the focus of this paper. What policies are most appropriate for buffering writes for these parallel scientific-application workloads? Do write-behind and delayed writeback help? In what way? This paper examines these issues, defines some new policies, and reports results from experiments with these policies. <p> Prefetch-ing can avoid this underutilization; see <ref> [9, 8, 10] </ref> for further study of read-only patterns and prefetching.
Reference: [10] <author> David Kotz and Carla Schlatter Ellis. </author> <title> Practical prefetching techniques for parallel file systems. </title> <booktitle> In First International Conference on Parallel and Distributed Information Systems, </booktitle> <month> Decem-ber </month> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: The sequential access patterns in the workload suggest prefetching and write-behind. Prefetching is the focus of <ref> [9, 10, 8] </ref>, and write-behind is the focus of this paper. What policies are most appropriate for buffering writes for these parallel scientific-application workloads? Do write-behind and delayed writeback help? In what way? This paper examines these issues, defines some new policies, and reports results from experiments with these policies. <p> Prefetch-ing can avoid this underutilization; see <ref> [9, 8, 10] </ref> for further study of read-only patterns and prefetching.
Reference: [11] <author> Ethan Miller. </author> <title> Input/Output behavior of supercomputing applications. </title> <type> Technical Report UCB/CSD 91/616, </type> <institution> University of California, Berkeley, </institution> <year> 1991. </year> <note> Submitted to Supercomputing '91. </note>
Reference-contexts: These studies found that sequential access, usually of the entire file, is the major form of access. Supercomputer file access patterns (a scientific workload) involve huge files (tens to thousands of megabytes) accessed primarily sequentially, sometimes repeatedly <ref> [11] </ref>. Parallel file access has been discussed by Crockett [2], but he did not study an actual workload. 3 Models and Methods 3.1 Architectural Models Our architectural model is a multiple instruction stream, multiple data stream (MIMD) multiprocessor. <p> This is a shared cache concurrently servicing the requests of all processes within a parallel application. The workload plays a significant role in determining the appropriate cache policies. Scientific applications often read and write several megabytes or gigabytes of data, generally sequentially <ref> [11] </ref>. For a cache to succeed, the workload must exhibit some locality. Temporal locality, where recently used data will be used again soon, is not present when large files (much larger than the cache size) are accessed sequentially, even if the files are accessed repeatedly.
Reference: [12] <author> John Ousterhout, Herve Da Costa, David Har-rison, John Kunze, Mike Kupfer, and James Thompson. </author> <title> A trace driven analysis of the UNIX 4.2 BSD file system. </title> <booktitle> In Proceedings of the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 15-24, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: This paper concentrates on multiprocessor file systems intended for scientific applications. These applications typically push the leading edge of computing technology, such as multiprocessors, placing tremendous demands on both CPU and I/O systems. Most file caching studies have examined general-purpose workloads (e.g., [16]), where files are much smaller <ref> [12, 5] </ref>. The parallel environment and workload raise a number of questions: Are caches useful for parallel scientific applications using parallel file systems? If so, in what way? What are the appropriate management policies? Different workload characteristics, including a new form of locality, lead us to new policies. <p> File access patterns have never been studied for parallel computers, but have been studied extensively for uniprocessors <ref> [5, 12] </ref>. These studies found that sequential access, usually of the entire file, is the major form of access. Supercomputer file access patterns (a scientific workload) involve huge files (tens to thousands of megabytes) accessed primarily sequentially, sometimes repeatedly [11]. <p> The file system internals, which are responsible for caching, see only the block access pattern. In our research we do not investigate read/write file access patterns, because most files are opened for either reading or writing, with few files updated <ref> [5, 12] </ref>. We expect this to be especially true for the large files used in scientific applications. Thus we consider read-only patterns, used to demonstrate the benefits of caching, and write-only patterns, used to investigate delayed-write policies. All sequential patterns consist of a sequence of accesses to sequential portions.
Reference: [13] <author> David Patterson, Garth Gibson, and Randy Katz. </author> <title> A case for redundant arrays of inexpensive disks (RAID). </title> <booktitle> In ACM SIGMOD Conference, </booktitle> <pages> pages 109-116, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Disk I/O has always been slower than processing speed, and recent trends have shown that improvements in the speed of disk hardware are not keeping up with the increasing raw speed of processors. This widening access-time gap is known as the I/O crisis <ref> [13, 16] </ref>. The problem is compounded in typical parallel architectures that multiply the processing and memory capacity without balancing the I/O capabilities. The most promising solution to the I/O crisis is to extend parallelism into the I/O subsystem. <p> In Section 4 we present the experiments, performance measures, and results. Section 5 concludes. 2 Background Much of the previous work in I/O hardware parallelism involves disk striping. In this technique, data of a file are interleaved across numerous disks and accessed synchronously in parallel <ref> [15, 7, 13] </ref>. These schemes rely on a single controller to manage all of the disks. For multiprocessors, one form of parallel disk architecture is based on the notion of parallel, independent disks, using multiple conventional disk devices 1 addressed independently and attached to separate pro-cessors.
Reference: [14] <author> Paul Pierce. </author> <title> A concurrent file system for a highly parallel mass storage system. </title> <booktitle> In Fourth Conference on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pages 155-160, </pages> <year> 1989. </year>
Reference-contexts: The files may be interleaved over the disks, but the multiple controllers and independent access to the disks make this technique different from disk striping. Examples of this architecture include the Concurrent File System <ref> [14, 6] </ref> for the Intel iPSC/2 multiprocessor, and the Bridge [4, 3] file system for the BBN Butterfly parallel computer. File caching is a technique used in most modern file systems.
Reference: [15] <author> Kenneth Salem and Hector Garcia-Molina. </author> <title> Disk striping. </title> <booktitle> In IEEE 1986 Conference on Data Engineering, </booktitle> <pages> pages 336-342, </pages> <year> 1986. </year>
Reference-contexts: In Section 4 we present the experiments, performance measures, and results. Section 5 concludes. 2 Background Much of the previous work in I/O hardware parallelism involves disk striping. In this technique, data of a file are interleaved across numerous disks and accessed synchronously in parallel <ref> [15, 7, 13] </ref>. These schemes rely on a single controller to manage all of the disks. For multiprocessors, one form of parallel disk architecture is based on the notion of parallel, independent disks, using multiple conventional disk devices 1 addressed independently and attached to separate pro-cessors.
Reference: [16] <author> Alan Jay Smith. </author> <title> Disk cache-miss ratio analysis and design considerations. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 161-203, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Disk I/O has always been slower than processing speed, and recent trends have shown that improvements in the speed of disk hardware are not keeping up with the increasing raw speed of processors. This widening access-time gap is known as the I/O crisis <ref> [13, 16] </ref>. The problem is compounded in typical parallel architectures that multiply the processing and memory capacity without balancing the I/O capabilities. The most promising solution to the I/O crisis is to extend parallelism into the I/O subsystem. <p> This paper concentrates on multiprocessor file systems intended for scientific applications. These applications typically push the leading edge of computing technology, such as multiprocessors, placing tremendous demands on both CPU and I/O systems. Most file caching studies have examined general-purpose workloads (e.g., <ref> [16] </ref>), where files are much smaller [12, 5]. <p> File caching is a technique used in most modern file systems. Caching has not been studied for parallel file systems, but Alan Smith has extensively studied disk caching in uniprocessors with general-purpose work-loads. In <ref> [16] </ref>, his simulations show that disk caching is an effective way to boost the performance (as measured by the cache miss ratio) of the I/O subsystem (e.g., an 8 MByte cache can service 80-90% of I/O requests).
Reference: [17] <author> Michael Stonebraker. </author> <title> Operating system support for database management. </title> <journal> Communications of the ACM, </journal> <volume> 24(7) </volume> <pages> 412-418, </pages> <month> July </month> <year> 1981. </year> <month> 8 </month>
Reference-contexts: The combination of these observations leads to a "toss-immediately" replacement policy, where only the most recently used (MRU) block remains in the cache. This is more appropriate than the traditional LRU policy <ref> [17] </ref> (although of course it is identical to LRU with a stack size of one). In the access patterns we expect to see in parallel scientific applications, another form of locality occurs.
References-found: 17

