URL: ftp://borneo.gmd.de/pub/as/ga/gmd_as_ga-93_05.ps
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: zhang@gmd.de, muehlen@gmd.de  
Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Author: Byoung-Tak Zhang Heinz Muhlenbein 
Address: Schloss Birlinghoven, D-53757 Sankt Augustin, Germany  
Affiliation: Artificial Intelligence Research Division German National Research Center for Computer Science (GMD)  
Abstract: Genetic algorithms have been used for neural networks in two main ways: to optimize the network architecture and to train the weights of a fixed architecture. While most previous work focuses on only one of these two options, this paper investigates an alternative evolutionary approach called Breeder Genetic Programming (BGP) in which the architecture and the weights are optimized simultaneously. The genotype of each network is represented as a tree whose depth and width are dynamically adapted to the particular application by specifically defined genetic operators. The weights are trained by a next-ascent hillclimbing search. A new fitness function is proposed that quantifies the principle of Occam's razor. It makes an optimal trade-off between the error fitting ability and the parsimony of the network. Simulation results on two benchmark problems of differing complexity suggest that the method finds minimal size networks on clean data. The experiments on noisy data show that using Occam's razor not only improves the generalization performance, it also accel erates the convergence speed of evolution. fl Published in Complex Systems, 7(3): 199-220, 1993
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. S. Abu-Mostafa, </author> <title> "The Vapnik-Chervonenkis Dimension: Information versus Complexity in Learning," </title> <booktitle> Neural Computation, </booktitle> <month> 1 </month> <year> (1989) </year> <month> 312-317. </month>
Reference-contexts: On the other hand, a small network will achieve a good generalization if it converges, it needs, however, generally a large amount of training time <ref> [1, 32] </ref>. Therefore, the size of the network should be as small as possible, but sufficiently large to ensure an accurate fitting of the training set. A general way of evolving genetic neural networks was suggested by Muhlenbein and Kindermann in [24].
Reference: [2] <author> T. Back and H.-P. Schwefel, </author> <title> "An Overview of Evolutionary Algorithms for Parameter Optimization," </title> <booktitle> Evolutionary Computation, </booktitle> <month> 1 </month> <year> (1993) </year> <month> 1-23. </month>
Reference-contexts: Evolving Optimal Neural Networks 16 purposes. No general learning methods are yet known to find such a solution (architecture plus weight values). Most existing search methods, including iterated hillclimbing methods [4, 18, 31], simulated annealing [10], Backpropagation [29] and even other genetic algorithms <ref> [2] </ref>, work on a search space of fixed size, while our search space is of variable size. This difference of ability combined with different parameters used in each algorithm make the comparison of learning speed difficult.
Reference: [3] <author> S. Kauffman and S. Levin, </author> <title> "Towards a General Theory of Adaptive Walks on Rugged Landscapes," </title> <journal> Journal of Theoretical Biology, </journal> <month> 128 </month> <year> (1987) </year> <month> 11-45. </month>
Reference-contexts: In order to assess the complexity of an optimization problem and to speed up the genetic search further, an investigation of its fitness landscapes is necessary. 6 Analysis of fitness landscapes Fitness landscapes have been analyzed for Boolean N -K networks by Kauff-man <ref> [3] </ref>, for random traveling salesman (tsp) problems by Kirkpatrick et al. [10], and for Euclidean tsp problems by Muhlenbein [21]. The general characterization of a fitness landscape is very difficult.
Reference: [4] <author> I. P. Gent and T. Walsh, </author> <title> "Towards an Understanding of Hill-climbing Procedures for SAT," </title> <booktitle> in Proceedings of the 11th National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> 28-33, </pages> <publisher> (MIT Press, </publisher> <year> 1993). </year>
Reference-contexts: In terms of binary-valued connections, b, the discovered solution has two more connections than the minimal solution. Evolving Optimal Neural Networks 16 purposes. No general learning methods are yet known to find such a solution (architecture plus weight values). Most existing search methods, including iterated hillclimbing methods <ref> [4, 18, 31] </ref>, simulated annealing [10], Backpropagation [29] and even other genetic algorithms [2], work on a search space of fixed size, while our search space is of variable size. This difference of ability combined with different parameters used in each algorithm make the comparison of learning speed difficult. <p> While we have used a simple next-ascent hillclimbing for adjustment of discrete weights, other traditional search methods might as well have been used for this purpose. Examples include iterated hillclimbing procedures developed in symbolic artificial intelligence <ref> [4, 18, 31] </ref>. The discrete-valued weights may be extended to more general real-valued weights. In this extension, it will be necessary to modify or replace the discrete hillclimbing search by a continuous parameter optimization method which may be again genetic algorithms [25, 30] or conventional gradient-based search methods [29].
Reference: [5] <author> D. E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization & Machine Learning (Addison Wesley, </title> <year> 1989). </year>
Reference-contexts: 1 Introduction Constructing multilayer neural networks involves difficult optimization problems, i.e. finding a network architecture appropriate for the application at hand and finding an optimal set of weight values for the network to solve the problem. Genetic algorithms <ref> [8, 5, 20] </ref> have been used for solving both optimization problems [36]. In weight optimization, the set of weights is represented as a chromosome and a genetic search is applied on the encoded representation to find a set of weights that best fits the training data. <p> While the usual genetic algorithms model a natural evolution, the BGA models a rational selection performed by human breeders. The BGA can be considered as a recombination between evolution strategies (ES) [27, 30] and genetic algorithms (GA) <ref> [8, 5] </ref>. The BGA uses truncation selection as performed by breeders. This selection scheme is similar to the (; )-strategy in ES [30]. The search process of the BGA is mainly driven by recombination, making the BGA a genetic algorithm.
Reference: [6] <author> F. Gruau, </author> <title> "Genetic Synthesis of Boolean Neural Networks with a Cell Rewriting Developmental Process," </title> <type> Tech. Rep., </type> <institution> Laboratoire de l'Infor-matique du Parallelisme (1992). </institution> <note> Evolving Optimal Neural Networks 25 </note>
Reference-contexts: Harp et al. [7] and Miller [15] have described representation schemes in which the anatomical properties of the network structure are encoded as bit-strings. Similar representation has also been used by Whitley et al. [36] to prune unnecessary connections. Ki-tano [11] and Gruau <ref> [6] </ref> have suggested encoding schemes in which a network configuration is indirectly specified by a graph generation grammar which is evolved by genetic algorithms. All these methods use the backpropagation algorithm [29], a gradient-descent method, to train the weights of the network.
Reference: [7] <author> S. A. Harp, T. Samad, and A. Guha, </author> <title> "Towards the Genetic Synthesis of Neural Networks," </title> <booktitle> in Proceedings of the Third International Conference on Genetic Algorithms (ICGA-89), </booktitle> <pages> 360-369, </pages> <publisher> (Morgan Kaufmann, </publisher> <year> 1989). </year>
Reference-contexts: A general way of evolving genetic neural networks was suggested by Muhlenbein and Kindermann in [24]. Recent works, however, have focused on using genetic algorithms separately in each optimization problem, mainly in optimizing the network topology. Harp et al. <ref> [7] </ref> and Miller [15] have described representation schemes in which the anatomical properties of the network structure are encoded as bit-strings. Similar representation has also been used by Whitley et al. [36] to prune unnecessary connections.
Reference: [8] <author> J. H. Holland, </author> <title> Adaptation in Natural and Artificial Systems, </title> <publisher> (University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975). </year>
Reference-contexts: 1 Introduction Constructing multilayer neural networks involves difficult optimization problems, i.e. finding a network architecture appropriate for the application at hand and finding an optimal set of weight values for the network to solve the problem. Genetic algorithms <ref> [8, 5, 20] </ref> have been used for solving both optimization problems [36]. In weight optimization, the set of weights is represented as a chromosome and a genetic search is applied on the encoded representation to find a set of weights that best fits the training data. <p> While the usual genetic algorithms model a natural evolution, the BGA models a rational selection performed by human breeders. The BGA can be considered as a recombination between evolution strategies (ES) [27, 30] and genetic algorithms (GA) <ref> [8, 5] </ref>. The BGA uses truncation selection as performed by breeders. This selection scheme is similar to the (; )-strategy in ES [30]. The search process of the BGA is mainly driven by recombination, making the BGA a genetic algorithm.
Reference: [9] <author> A. G. Ivakhnenko, </author> <title> "Polynomial Theory of Complex Systems," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <month> SMC-1 </month> <year> (1971) </year> <month> 364-378. </month>
Reference-contexts: It is interesting to notice that the global behavior of this optimization method is comparable with the group method of data handling (GMDH) in which additional terms are incrementally added to the existing polynomial approximator to achieve a minimal description length model of a complex system <ref> [9, 34] </ref>. The performance of the BGP method on noisy data was tested with the majority problem of 9 inputs. Unlike in the previous experiments where all possible examples are used without noise insertion, we used in each run a training set of 256 examples with 5% noise.
Reference: [10] <author> S. Kirkpatrick, C. D. Gelett, and M. P. Vecchi, </author> <title> "Optimization by Simulated Annealing," </title> <booktitle> Science, </booktitle> <month> 220 </month> <year> (1985) </year> <month> 621-630. </month>
Reference-contexts: Evolving Optimal Neural Networks 16 purposes. No general learning methods are yet known to find such a solution (architecture plus weight values). Most existing search methods, including iterated hillclimbing methods [4, 18, 31], simulated annealing <ref> [10] </ref>, Backpropagation [29] and even other genetic algorithms [2], work on a search space of fixed size, while our search space is of variable size. This difference of ability combined with different parameters used in each algorithm make the comparison of learning speed difficult. <p> the complexity of an optimization problem and to speed up the genetic search further, an investigation of its fitness landscapes is necessary. 6 Analysis of fitness landscapes Fitness landscapes have been analyzed for Boolean N -K networks by Kauff-man [3], for random traveling salesman (tsp) problems by Kirkpatrick et al. <ref> [10] </ref>, and for Euclidean tsp problems by Muhlenbein [21]. The general characterization of a fitness landscape is very difficult. The number of local optima, their distribution and the basins of attraction are some of the important parameters which describe a fitness landscape.
Reference: [11] <author> H. Kitano, </author> <title> "Designing Neural Networks Using Genetic Algorithms with Graph Generation System," </title> <journal> Complex Systems, </journal> <month> 4 </month> <year> (1990) </year> <month> 461-476. </month>
Reference-contexts: Harp et al. [7] and Miller [15] have described representation schemes in which the anatomical properties of the network structure are encoded as bit-strings. Similar representation has also been used by Whitley et al. [36] to prune unnecessary connections. Ki-tano <ref> [11] </ref> and Gruau [6] have suggested encoding schemes in which a network configuration is indirectly specified by a graph generation grammar which is evolved by genetic algorithms. All these methods use the backpropagation algorithm [29], a gradient-descent method, to train the weights of the network.
Reference: [12] <author> J. R. Koza, </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection (MIT Press, </title> <year> 1992). </year>
Reference-contexts: Ki-tano [11] and Gruau [6] have suggested encoding schemes in which a network configuration is indirectly specified by a graph generation grammar which is evolved by genetic algorithms. All these methods use the backpropagation algorithm [29], a gradient-descent method, to train the weights of the network. Koza <ref> [12] </ref> provides an alternative approach to representing neural networks, under the framework of so-called genetic programming, which en Evolving Optimal Neural Networks 3 ables modification not only of the weights but also of the architecture for a neural network. <p> This selection scheme is similar to the (; )-strategy in ES [30]. The search process of the BGA is mainly driven by recombination, making the BGA a genetic algorithm. Our approach differs from the BGA in that we use variable size of chromosomes, a characteristic of genetic programming (GP) <ref> [12] </ref>. Thus we call the method Breeder Genetic Programming (BGP). BGP also differs from usual GP. While GP uses proportional selection combined with crossover as main operator, BGP uses truncation selection combined with crossover plus local hillclimbing.
Reference: [13] <author> D. J. C. MacKay, </author> <title> "Bayesian Methods for Adaptive Models," </title> <type> Ph.D. thesis, </type> <institution> Caltech, Pasadena, </institution> <address> CA. </address> <year> (1992). </year>
Reference-contexts: of arguments of each operator plays no role because the syntactically correct subtree under the node c i and c j is completely replaced by another syntactically correct subtree. 4 Fitness function with an Occam's razor Occam's razor states that unnecessarily complex models should not be preferred to simpler ones <ref> [13, 33] </ref>. This section gives a quantitative Occam's razor for constructing minimal complexity neural networks by genetic algorithms. In defining minimality, it is important that the network be able to approximate at least the training set to a specified performance level. <p> Additionally, large weights should in general be penalized in the hope of achieving a smoother or simpler mapping. This technique is called regularization <ref> [26, 13] </ref>. We define the complexity, C, of a network as C (W jA) = k=1 k (7) where K is the number of free parameters. Notice that K can be arbitrarily large, because we fit the architectures too.
Reference: [14] <author> W. S. McCulloch and W. Pitts, </author> <title> "A Logical Calculus of the Ideas Immanent in Nervous Activity," </title> <journal> Bull. Math. Biophysics, </journal> <month> 5 </month> <year> (1943) </year> <month> 115-133. </month>
Reference-contexts: Figure 1 compares an usual multilayer perceptron and a more general architecture adopted in this work. There are also many options in the type of neural units. We will confine ourselves to McCulloch-Pitts neurons <ref> [14] </ref>, although the method described below can be easily extended to employ other types of neurons. Evolving Optimal Neural Networks 4 architecture adopts a full connectivity between neighboring layers only (left), the architecture used in this work allows local receptive fields and direct connections between non-neighboring layers (right). <p> The i is usually considered as a weight w i0 in (1) connected to an extra unit whose activation value is always 1. Despite their simplicity, McCulloch-Pitts neurons are very powerful. In fact, it can be shown that any finite logical expression can be realized by them <ref> [14] </ref>.
Reference: [15] <author> G. F. Miller, P. M. Todd, and S. U. Hegde, </author> <title> "Designing Neural Networks Using Genetic Algorithms," </title> <booktitle> in Proceedings of the Third International Conference on Genetic Algorithms (ICGA-89), </booktitle> <address> 379-384 (Morgan Kauf-mann, </address> <year> 1989). </year>
Reference-contexts: A general way of evolving genetic neural networks was suggested by Muhlenbein and Kindermann in [24]. Recent works, however, have focused on using genetic algorithms separately in each optimization problem, mainly in optimizing the network topology. Harp et al. [7] and Miller <ref> [15] </ref> have described representation schemes in which the anatomical properties of the network structure are encoded as bit-strings. Similar representation has also been used by Whitley et al. [36] to prune unnecessary connections.
Reference: [16] <author> M. Minsky and S. Papert, </author> <title> Perceptrons: An Introduction to Computational Geometry (MIT Press, </title> <year> 1969, 1988). </year>
Reference-contexts: The experimental results are given in Section 5, which is followed by an analysis of fitness landscapes in Section 6, and discussions in Section 7. 2 Representing neural networks as trees Multilayer feedforward neural networks or multilayer perceptrons <ref> [28, 16, 29] </ref> are networks of simple processing elements, called neurons or units, organized in layers. The external inputs are presented to the input layer and are fed forward via one or more layers of hidden units to the output layer.
Reference: [17] <author> D. Montana and L. Davis, </author> <title> "Training Feedforward Neural Networks Using Genetic Algorithms,", </title> <booktitle> in Proceedings of the International Joint Conference on Artificial Intelligence (1989). </booktitle>
Reference-contexts: In weight optimization, the set of weights is represented as a chromosome and a genetic search is applied on the encoded representation to find a set of weights that best fits the training data. Some encouraging results have been reported which are comparable with conventional learning algorithms <ref> [17] </ref>. In architecture optimization, the topology of the networks is encoded as a chromosome and some genetic operators are applied to find an architecture which fits best the specified task according to some explicit design criteria.
Reference: [18] <author> P. Morris, </author> <title> "The Breakout Method for Escaping from Local Minima," </title> <booktitle> in Proceedings of the 11th National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> 40-45, </pages> <publisher> (MIT Press, </publisher> <year> 1993). </year> <title> Evolving Optimal Neural Networks 26 </title>
Reference-contexts: In terms of binary-valued connections, b, the discovered solution has two more connections than the minimal solution. Evolving Optimal Neural Networks 16 purposes. No general learning methods are yet known to find such a solution (architecture plus weight values). Most existing search methods, including iterated hillclimbing methods <ref> [4, 18, 31] </ref>, simulated annealing [10], Backpropagation [29] and even other genetic algorithms [2], work on a search space of fixed size, while our search space is of variable size. This difference of ability combined with different parameters used in each algorithm make the comparison of learning speed difficult. <p> While we have used a simple next-ascent hillclimbing for adjustment of discrete weights, other traditional search methods might as well have been used for this purpose. Examples include iterated hillclimbing procedures developed in symbolic artificial intelligence <ref> [4, 18, 31] </ref>. The discrete-valued weights may be extended to more general real-valued weights. In this extension, it will be necessary to modify or replace the discrete hillclimbing search by a continuous parameter optimization method which may be again genetic algorithms [25, 30] or conventional gradient-based search methods [29].
Reference: [19] <author> H. Muhlenbein, </author> <title> "Darwin's Continental Cycle and Its Simulation by the Prisoner's Dilemma," </title> <journal> Complex Systems, </journal> <month> 5 </month> <year> (1991) </year> <month> 459-478. </month>
Reference: [20] <author> H. Muhlenbein, </author> <title> "Evolution in Time and Space|The Parallel Genetic Algorithm," </title> <booktitle> in Foundations of Genetic Algorithms, </booktitle> <pages> 316-338, </pages> <publisher> edited by G. Rawlins (Morgan Kaufmann, </publisher> <year> 1991). </year>
Reference-contexts: 1 Introduction Constructing multilayer neural networks involves difficult optimization problems, i.e. finding a network architecture appropriate for the application at hand and finding an optimal set of weight values for the network to solve the problem. Genetic algorithms <ref> [8, 5, 20] </ref> have been used for solving both optimization problems [36]. In weight optimization, the set of weights is represented as a chromosome and a genetic search is applied on the encoded representation to find a set of weights that best fits the training data.
Reference: [21] <author> H. Muhlenbein, </author> <title> "Parallel Genetic Algorithms in Combinatorial Optimization," </title> <booktitle> in Computer Science and Operations Research, </booktitle> <pages> 441-456, </pages> <editor> edited by G. Balci, R. Sharda, and S. A. </editor> <publisher> Zenios (Pergamon, Oxford, </publisher> <year> 1992). </year>
Reference-contexts: speed up the genetic search further, an investigation of its fitness landscapes is necessary. 6 Analysis of fitness landscapes Fitness landscapes have been analyzed for Boolean N -K networks by Kauff-man [3], for random traveling salesman (tsp) problems by Kirkpatrick et al. [10], and for Euclidean tsp problems by Muhlenbein <ref> [21] </ref>. The general characterization of a fitness landscape is very difficult. The number of local optima, their distribution and the basins of attraction are some of the important parameters which describe a fitness landscape.
Reference: [22] <author> H. Muhlenbein, </author> <title> "Evolutionary Algorithms: Theory and Applications," in Local Search in Combinatorial Optimization, edited by E. </title> <editor> H. L. Aarts and J. K. </editor> <publisher> Lenstra (Wiley, </publisher> <year> 1993). </year>
Reference-contexts: A simple optimization method does not exist which performs better than any other optimization method for a reasonable large class of binary functions of size n. To be effective, every sophisticated optimization method has to be tuned to the application <ref> [22] </ref>.
Reference: [23] <author> H. Muhlenbein, M. Gorges-Schleuter, and O. Kramer, </author> <title> "New Solutions to the Mapping Problem of Parallel Systems|The Evolution Approach," </title> <booktitle> Parallel Computing, </booktitle> <month> 4 </month> <year> (1987) </year> <month> 269-279. </month>
Reference: [24] <author> H. Muhlenbein and J. Kindermann, </author> <title> "The Dynamics of Evolution and Learning|Towards Genetic Neural Networks," </title> <booktitle> in Connectionism in Perspective, </booktitle> <pages> 173-197, </pages> <editor> edited by R. Pfeifer et al., </editor> <publisher> (Elsevier, </publisher> <year> 1989). </year>
Reference-contexts: Therefore, the size of the network should be as small as possible, but sufficiently large to ensure an accurate fitting of the training set. A general way of evolving genetic neural networks was suggested by Muhlenbein and Kindermann in <ref> [24] </ref>. Recent works, however, have focused on using genetic algorithms separately in each optimization problem, mainly in optimizing the network topology. Harp et al. [7] and Miller [15] have described representation schemes in which the anatomical properties of the network structure are encoded as bit-strings.
Reference: [25] <author> H. Muhlenbein and D. Schlierkamp-Voosen, </author> <title> "Predictive Models for the Breeder Genetic Algorithm I: Continuous Parameter Optimization," </title> <booktitle> Evolutionary Computation, </booktitle> <month> 1 </month> <year> (1993) </year> <month> 25-49. </month>
Reference-contexts: Evolving Optimal Neural Networks 7 3 Genetic breeding of neural networks 3.1 Breeder genetic programming (BGP) For the evolution of optimal neural networks we use the concepts based on the breeder genetic algorithm, BGA, of Muhlenbein et al. <ref> [25] </ref>. While the usual genetic algorithms model a natural evolution, the BGA models a rational selection performed by human breeders. The BGA can be considered as a recombination between evolution strategies (ES) [27, 30] and genetic algorithms (GA) [8, 5]. The BGA uses truncation selection as performed by breeders. <p> The discrete-valued weights may be extended to more general real-valued weights. In this extension, it will be necessary to modify or replace the discrete hillclimbing search by a continuous parameter optimization method which may be again genetic algorithms <ref> [25, 30] </ref> or conventional gradient-based search methods [29]. Notice that this adaptation does not change the top-level structure of the breeder genetic programming method described in Figure 4. As opposed to conventional learning algorithms for neural networks, the genetic programming method makes relatively few assumptions about the network types.
Reference: [26] <author> T. Poggio and F. Girosi, </author> <title> "Networks for Approximation and Learning," </title> <booktitle> Proceedings of the IEEE, </booktitle> <month> 78 </month> <year> (1990) </year> <month> 1481-1497. </month>
Reference-contexts: Additionally, large weights should in general be penalized in the hope of achieving a smoother or simpler mapping. This technique is called regularization <ref> [26, 13] </ref>. We define the complexity, C, of a network as C (W jA) = k=1 k (7) where K is the number of free parameters. Notice that K can be arbitrarily large, because we fit the architectures too.
Reference: [27] <author> I. Rechenberg, </author> <title> Evolutionsstrategie: Optimierung Technischer Systeme nach Prinzipien der Biologischen Evolution (Stuttgart, </title> <address> Frommann-Holzboog, </address> <year> 1973). </year>
Reference-contexts: While the usual genetic algorithms model a natural evolution, the BGA models a rational selection performed by human breeders. The BGA can be considered as a recombination between evolution strategies (ES) <ref> [27, 30] </ref> and genetic algorithms (GA) [8, 5]. The BGA uses truncation selection as performed by breeders. This selection scheme is similar to the (; )-strategy in ES [30]. The search process of the BGA is mainly driven by recombination, making the BGA a genetic algorithm.
Reference: [28] <author> F. Rosenblatt, </author> <title> Principles of Neurodynamics (Spartan Books, </title> <address> Washing-ton D.C., </address> <year> 1962). </year> <title> Evolving Optimal Neural Networks 27 </title>
Reference-contexts: The experimental results are given in Section 5, which is followed by an analysis of fitness landscapes in Section 6, and discussions in Section 7. 2 Representing neural networks as trees Multilayer feedforward neural networks or multilayer perceptrons <ref> [28, 16, 29] </ref> are networks of simple processing elements, called neurons or units, organized in layers. The external inputs are presented to the input layer and are fed forward via one or more layers of hidden units to the output layer.
Reference: [29] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams, </author> <title> "Learning Internal Representations by Error-Propagation," </title> <booktitle> in Parallel Distributed Processing, </booktitle> <volume> Vol. I, </volume> <pages> 318-362, </pages> <editor> edited by D. E. Rumelhart and J. L. </editor> <publisher> McClelland (MIT Press, </publisher> <year> 1986). </year>
Reference-contexts: Ki-tano [11] and Gruau [6] have suggested encoding schemes in which a network configuration is indirectly specified by a graph generation grammar which is evolved by genetic algorithms. All these methods use the backpropagation algorithm <ref> [29] </ref>, a gradient-descent method, to train the weights of the network. <p> The experimental results are given in Section 5, which is followed by an analysis of fitness landscapes in Section 6, and discussions in Section 7. 2 Representing neural networks as trees Multilayer feedforward neural networks or multilayer perceptrons <ref> [28, 16, 29] </ref> are networks of simple processing elements, called neurons or units, organized in layers. The external inputs are presented to the input layer and are fed forward via one or more layers of hidden units to the output layer. <p> Evolving Optimal Neural Networks 16 purposes. No general learning methods are yet known to find such a solution (architecture plus weight values). Most existing search methods, including iterated hillclimbing methods [4, 18, 31], simulated annealing [10], Backpropagation <ref> [29] </ref> and even other genetic algorithms [2], work on a search space of fixed size, while our search space is of variable size. This difference of ability combined with different parameters used in each algorithm make the comparison of learning speed difficult. <p> The discrete-valued weights may be extended to more general real-valued weights. In this extension, it will be necessary to modify or replace the discrete hillclimbing search by a continuous parameter optimization method which may be again genetic algorithms [25, 30] or conventional gradient-based search methods <ref> [29] </ref>. Notice that this adaptation does not change the top-level structure of the breeder genetic programming method described in Figure 4. As opposed to conventional learning algorithms for neural networks, the genetic programming method makes relatively few assumptions about the network types.
Reference: [30] <author> H.-P. Schwefel, </author> <title> Numerical Optimization of Computer Models (Chich-ester, </title> <publisher> Wiley, </publisher> <year> 1981). </year>
Reference-contexts: While the usual genetic algorithms model a natural evolution, the BGA models a rational selection performed by human breeders. The BGA can be considered as a recombination between evolution strategies (ES) <ref> [27, 30] </ref> and genetic algorithms (GA) [8, 5]. The BGA uses truncation selection as performed by breeders. This selection scheme is similar to the (; )-strategy in ES [30]. The search process of the BGA is mainly driven by recombination, making the BGA a genetic algorithm. <p> The BGA can be considered as a recombination between evolution strategies (ES) [27, 30] and genetic algorithms (GA) [8, 5]. The BGA uses truncation selection as performed by breeders. This selection scheme is similar to the (; )-strategy in ES <ref> [30] </ref>. The search process of the BGA is mainly driven by recombination, making the BGA a genetic algorithm. Our approach differs from the BGA in that we use variable size of chromosomes, a characteristic of genetic programming (GP) [12]. Thus we call the method Breeder Genetic Programming (BGP). <p> The discrete-valued weights may be extended to more general real-valued weights. In this extension, it will be necessary to modify or replace the discrete hillclimbing search by a continuous parameter optimization method which may be again genetic algorithms <ref> [25, 30] </ref> or conventional gradient-based search methods [29]. Notice that this adaptation does not change the top-level structure of the breeder genetic programming method described in Figure 4. As opposed to conventional learning algorithms for neural networks, the genetic programming method makes relatively few assumptions about the network types.
Reference: [31] <author> B. Selman and H. A. Kautz, </author> <title> "An Empirical Study of Greedy Local Search for Satisfiability Testing," </title> <booktitle> in Proceedings of the 11th National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> 46-51, </pages> <publisher> (MIT Press, </publisher> <year> 1993). </year>
Reference-contexts: In terms of binary-valued connections, b, the discovered solution has two more connections than the minimal solution. Evolving Optimal Neural Networks 16 purposes. No general learning methods are yet known to find such a solution (architecture plus weight values). Most existing search methods, including iterated hillclimbing methods <ref> [4, 18, 31] </ref>, simulated annealing [10], Backpropagation [29] and even other genetic algorithms [2], work on a search space of fixed size, while our search space is of variable size. This difference of ability combined with different parameters used in each algorithm make the comparison of learning speed difficult. <p> While we have used a simple next-ascent hillclimbing for adjustment of discrete weights, other traditional search methods might as well have been used for this purpose. Examples include iterated hillclimbing procedures developed in symbolic artificial intelligence <ref> [4, 18, 31] </ref>. The discrete-valued weights may be extended to more general real-valued weights. In this extension, it will be necessary to modify or replace the discrete hillclimbing search by a continuous parameter optimization method which may be again genetic algorithms [25, 30] or conventional gradient-based search methods [29].
Reference: [32] <author> F. Smieja, </author> <title> "Neural Network Constructive Algorithms: Trading Generalization for Learning Efficiency?", Circuits, </title> <booktitle> Systems, and Signal Processing, </booktitle> <month> 12 </month> <year> (1993) </year> <month> 331-374. </month>
Reference-contexts: On the other hand, a small network will achieve a good generalization if it converges, it needs, however, generally a large amount of training time <ref> [1, 32] </ref>. Therefore, the size of the network should be as small as possible, but sufficiently large to ensure an accurate fitting of the training set. A general way of evolving genetic neural networks was suggested by Muhlenbein and Kindermann in [24].
Reference: [33] <author> R. Sorkin, </author> <title> "A Quantitative Occam's Razor," </title> <journal> International Journal of Theoretical Physics, </journal> <month> 22 </month> <year> (1983) </year> <month> 1091-1104. </month>
Reference-contexts: of arguments of each operator plays no role because the syntactically correct subtree under the node c i and c j is completely replaced by another syntactically correct subtree. 4 Fitness function with an Occam's razor Occam's razor states that unnecessarily complex models should not be preferred to simpler ones <ref> [13, 33] </ref>. This section gives a quantitative Occam's razor for constructing minimal complexity neural networks by genetic algorithms. In defining minimality, it is important that the network be able to approximate at least the training set to a specified performance level.
Reference: [34] <author> M. F. Tenorio and W. -T. Lee, </author> <title> "Self-Organizing Network for Optimum Supervised Learning," </title> <journal> IEEE Transactions on Neural Networks, </journal> <month> 1 </month> <year> (1990) </year> <month> 100-110. </month>
Reference-contexts: It is interesting to notice that the global behavior of this optimization method is comparable with the group method of data handling (GMDH) in which additional terms are incrementally added to the existing polynomial approximator to achieve a minimal description length model of a complex system <ref> [9, 34] </ref>. The performance of the BGP method on noisy data was tested with the majority problem of 9 inputs. Unlike in the previous experiments where all possible examples are used without noise insertion, we used in each run a training set of 256 examples with 5% noise.
Reference: [35] <author> N. Tishby, E. Levin, and S. A. Solla, </author> <title> "Consistent Inference of Probabilities in Layered Networks: Predictions and Generalization," </title> <booktitle> in Proceedings of the International Joint Conference on Neural Networks (IJCNN-89), </booktitle> <volume> Vol. II, </volume> <pages> 403-409 (IEEE, </pages> <year> 1989). </year>
Reference-contexts: That is, a network with specified architecture A and weights W is viewed as a model M = fA; W g predicting the outputs y as a function of input x in accordance with the probability distribution <ref> [35] </ref>: P (yjx; W; A) = Z (fi) Evolving Optimal Neural Networks 12 where fi is a positive constant which determines the sensitivity of the probability to the error value and Z (fi) = exp (fiE (yjx; W; A))dy (11) is a normalizing constant.
Reference: [36] <author> D. Whitley, T. Starkweather, and C. Bogart, </author> <title> "Genetic Algorithms and Neural Networks: Optimizing Connections and Connectivity," </title> <booktitle> Parallel Computing, </booktitle> <month> 14 </month> <year> (1990) </year> <month> 347-361. </month>
Reference-contexts: 1 Introduction Constructing multilayer neural networks involves difficult optimization problems, i.e. finding a network architecture appropriate for the application at hand and finding an optimal set of weight values for the network to solve the problem. Genetic algorithms [8, 5, 20] have been used for solving both optimization problems <ref> [36] </ref>. In weight optimization, the set of weights is represented as a chromosome and a genetic search is applied on the encoded representation to find a set of weights that best fits the training data. Some encouraging results have been reported which are comparable with conventional learning algorithms [17]. <p> Harp et al. [7] and Miller [15] have described representation schemes in which the anatomical properties of the network structure are encoded as bit-strings. Similar representation has also been used by Whitley et al. <ref> [36] </ref> to prune unnecessary connections. Ki-tano [11] and Gruau [6] have suggested encoding schemes in which a network configuration is indirectly specified by a graph generation grammar which is evolved by genetic algorithms.
Reference: [37] <author> B. T. Zhang, </author> <title> Learning by Genetic Neural Evolution, </title> <note> (in German), ISBN 3-929037-16-5, Infix-Verlag, Sankt Augustin (1992). Also available as Informatik Berichte No. 93, </note> <institution> Institut fur Informatik I, </institution> <address> Universitat Bonn (July 1992). </address>
Reference-contexts: The genetic programming involves a time-consuming process of evaluating training examples. The fitness evaluation time can be saved enormously, if we have an efficient method for selecting examples critical to specific tasks <ref> [38, 37, 40] </ref>. The integration of active data selection to the genetic programming should improve the efficiency and scaling property of the method described above.
Reference: [38] <author> B. T. Zhang, </author> <title> "Accelerated Learning by Active Example Selection," to appear in International Journal of Neural Systems (1993). Evolving Optimal Neural Networks 28 </title>
Reference-contexts: The genetic programming involves a time-consuming process of evaluating training examples. The fitness evaluation time can be saved enormously, if we have an efficient method for selecting examples critical to specific tasks <ref> [38, 37, 40] </ref>. The integration of active data selection to the genetic programming should improve the efficiency and scaling property of the method described above.
Reference: [39] <author> B. T. Zhang and H. Muhlenbein, </author> <title> "Genetic Programming of Minimal Neural Nets Using Occam's Razor," </title> <booktitle> in Proceedings of the Fifth International Conference on Genetic Algorithms (ICGA-93), </booktitle> <pages> 342-349, </pages> <editor> edited by S. </editor> <publisher> Forrest (Morgan Kaufmann, </publisher> <year> 1993). </year>
Reference: [40] <author> B. T. Zhang and G. Veenker, </author> <title> "Focused Incremental Learning for Improved Generalization with Reduced Training Sets," </title> <booktitle> in Artificial Neural Networks: Proceedings of the International Conference on Artificial Neural Networks (ICANN-91), </booktitle> <volume> Vol. I, </volume> <pages> 227-232, </pages> <editor> edited by T. Kohonen et al. </editor> <publisher> (Elsevier, </publisher> <year> 1991). </year>
Reference-contexts: The genetic programming involves a time-consuming process of evaluating training examples. The fitness evaluation time can be saved enormously, if we have an efficient method for selecting examples critical to specific tasks <ref> [38, 37, 40] </ref>. The integration of active data selection to the genetic programming should improve the efficiency and scaling property of the method described above.
Reference: [41] <author> B. T. Zhang and G. Veenker, </author> <title> "Neural Networks That Teach Themselves through Genetic Discovery of Novel Examples," </title> <booktitle> in Proceedings of the International Joint Conference on Neural Networks (IJCNN-91), </booktitle> <volume> Vol. I, </volume> <pages> 690-695 (IEEE, </pages> <year> 1991). </year>
References-found: 41

