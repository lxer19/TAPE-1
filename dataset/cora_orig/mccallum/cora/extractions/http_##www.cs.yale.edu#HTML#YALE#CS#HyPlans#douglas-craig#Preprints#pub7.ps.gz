URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/Preprints/pub7.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/ccd-preprints.html
Root-URL: http://www.cs.yale.edu
Title: AN EFFICIENT IMPLEMENTATION FOR SSOR AND INCOMPLETE FACTORIZATION PRECONDITIONINGS  
Author: RANDOLPH E. BANK AND CRAIG C. DOUGLAS 
Abstract: We investigate methods for efficiently implementing a class of incomplete factorization preconditioners which includes Symmetric Gauss Seidel [9], SSOR [9], generalized SSOR [1], Dupont Kendall Rachford [4], ICCG(0) [7], and MICCG(0) [6]. Our techniques can be extended to similar methods for nonsymmetric matrices. 1. Symmetric Matrices. We consider the solution of the linear system 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Axelsson, </author> <title> A generalized SSOR, </title> <journal> BIT, </journal> <volume> 13 (1972), </volume> <pages> pp. 443-467. </pages>
Reference-contexts: Such linear systems are often solved by iterative methods, for example, Symmetric Gauss Seidel [9], SSOR [9], generalized SSOR <ref> [1] </ref>, Dupont Kendall Rachford [4], ICCG (0) [7], and MICCG (0) [6].
Reference: [2] <author> R. E. Bank, </author> <title> Pltmg user's guide, </title> <type> tech. rep., </type> <institution> Univeristy of California at San Diego, </institution> <address> San Diego, </address> <year> 1981. </year>
Reference-contexts: The column in Table 1 corresponding to the special case of F = 0I is important since it corresponds to the Symmetric Gauss Seidel preconditioner. In practice, variants of the Gauss Seidel iteration are among the most popular smoothing iterations used in multigrid codes <ref> [2] </ref>, [3]. Since the cost of smoothing is usually a major expense in a multigrid code, reducing the number of matrix multiplies can significantly reduce the overall computational cost.
Reference: [3] <author> C. C. Douglas, </author> <title> A multigrid optimal order solver for elliptic boundary value problems: the finite difference case, in Advances in Computer Methods for Partial Differential Equations - V, </title> <editor> R. Vichnevetsky and R. S. Stepleman, eds., </editor> <address> New Brunswick, NJ, </address> <year> 1984, </year> <booktitle> IMACS, </booktitle> <pages> pp. 369-374. </pages>
Reference-contexts: The column in Table 1 corresponding to the special case of F = 0I is important since it corresponds to the Symmetric Gauss Seidel preconditioner. In practice, variants of the Gauss Seidel iteration are among the most popular smoothing iterations used in multigrid codes [2], <ref> [3] </ref>. Since the cost of smoothing is usually a major expense in a multigrid code, reducing the number of matrix multiplies can significantly reduce the overall computational cost.
Reference: [4] <author> T. Dupont, R. P. Kendall, and J. H. H. Rachford, </author> <title> An approximate factorization procedure for solving self-adjoint elliptic difference equations, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 5 (1968), </volume> <pages> pp. 559-573. </pages>
Reference-contexts: Such linear systems are often solved by iterative methods, for example, Symmetric Gauss Seidel [9], SSOR [9], generalized SSOR [1], Dupont Kendall Rachford <ref> [4] </ref>, ICCG (0) [7], and MICCG (0) [6].
Reference: [5] <author> S. C. Eisenstat, </author> <title> Efficient implementation of a class of conjugate gradient methods, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 2 (1981), </volume> <pages> pp. 1-4. </pages>
Reference-contexts: The obvious approach to implementing the basic iterative step (2) apparently requires 2M + O (N ) multiplies. Our goal is to reduce this to M + O (N ). See Eisenstat <ref> [5] </ref> for a different solution to the same problem. We note that the case F = 0I (unaccelerated Symmetric Gauss-Seidel) is of particular interest since we can reduce the number of multiplies per iteration to M + N .
Reference: [6] <author> I. Gustafsson, </author> <title> A class of first order factorization methods, </title> <journal> BIT, </journal> <volume> 18 (1978), </volume> <pages> pp. 142-156. </pages>
Reference-contexts: Such linear systems are often solved by iterative methods, for example, Symmetric Gauss Seidel [9], SSOR [9], generalized SSOR [1], Dupont Kendall Rachford [4], ICCG (0) [7], and MICCG (0) <ref> [6] </ref>.
Reference: [7] <author> J. A. Meijerink and H. A. Vorst, </author> <title> An iterative solution method for linear systems of which the the coefficient matrix is a symmetric m-matrix, </title> <journal> Math. Comp., </journal> <volume> 31 (1977), </volume> <pages> pp. 148-162. </pages>
Reference-contexts: Such linear systems are often solved by iterative methods, for example, Symmetric Gauss Seidel [9], SSOR [9], generalized SSOR [1], Dupont Kendall Rachford [4], ICCG (0) <ref> [7] </ref>, and MICCG (0) [6].
Reference: [8] <author> P. K. W. Vinsome, Orthomin, </author> <title> an iterative method for solving sparse sets of simultaneous linear equations, </title> <booktitle> in Proceedings of the Fourth Symposium on Reservoir Simulation, Society of Petroleum Engineers of AIME, </booktitle> <year> 1976, </year> <pages> pp. 149-159. </pages>
Reference-contexts: Given the linear system (5), we replace (6)-(8) by T w = ffr + L (ffv + w);(10) (D U )z = q;(12) The generalization of Algorithm 2 requires M + O (N ) multiplies. Unfortunately, some adaptive schemes, like Orthomin (1) <ref> [8] </ref> or Orthodir (1) [10], appear to require 1:5M + O (N ) multiplies (assuming the cost of multiplying by L and U are the same).
Reference: [9] <author> D. M. Young, </author> <title> Iterative Solution of Large Linear Systems, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Such linear systems are often solved by iterative methods, for example, Symmetric Gauss Seidel <ref> [9] </ref>, SSOR [9], generalized SSOR [1], Dupont Kendall Rachford [4], ICCG (0) [7], and MICCG (0) [6]. <p> Such linear systems are often solved by iterative methods, for example, Symmetric Gauss Seidel <ref> [9] </ref>, SSOR [9], generalized SSOR [1], Dupont Kendall Rachford [4], ICCG (0) [7], and MICCG (0) [6].
Reference: [10] <author> D. M. Young and K. C. Jea, </author> <title> Generalized conjugate gradient acceleration of nonsymmetrizable iterative methods, Linear Algebra and Its Applications, </title> <booktitle> 24 (1980), </booktitle> <pages> pp. 159-194. 4 </pages>
Reference-contexts: Given the linear system (5), we replace (6)-(8) by T w = ffr + L (ffv + w);(10) (D U )z = q;(12) The generalization of Algorithm 2 requires M + O (N ) multiplies. Unfortunately, some adaptive schemes, like Orthomin (1) [8] or Orthodir (1) <ref> [10] </ref>, appear to require 1:5M + O (N ) multiplies (assuming the cost of multiplying by L and U are the same).
References-found: 10

