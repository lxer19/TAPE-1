URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-96-28.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Email: fberna,manig@cs.caltech.edu  
Title: Parallel Program Archetypes  
Author: Berna L. Massingill and K. Mani Chandy 
Date: January 30, 1997  
Address: Pasadena, California 91125  
Affiliation: California Institute of Technology 256-80  
Abstract: A parallel program archetype is an abstraction that captures the common features of a class of problems with similar computational structure and combines them with a parallelization strategy to produce a pattern of dataflow and communication. Such abstractions are useful in application development, both as a conceptual framework and as a basis for tools and techniques. This paper describes an approach to parallel application development based on archetypes and presents two example archetypes with applications.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Atlas, S. Banerjee, J. C. Cummings, P. J. Hinker, M. Srikant, J. V. W. Reynders, and M. Tholburn. POOMA: </author> <title> A high performance distributed simulation environment for scientific applications. </title> <note> h http:/ /www.acl.lanl.gov/PoomaFramework/papers/SCPaper-95.html i, </note> <year> 1995. </year>
Reference-contexts: Examples of specific algorithms include one-deep mergesort [20] and one-deep quicksort [13, 35]. Distributed objects. The mesh-spectral archetype is based to some extent on the idea of distributed objects, as discussed for example in work on pC++ [5] and POOMA <ref> [1] </ref>. We differ from this work in that we focus more on the pattern of computation and on identifying and exploiting patterns of computation and communication. Communication libraries. Many researchers have investigated and developed reusable general libraries of communication routines; MPI [29] is a notable example.
Reference: [2] <author> C. F. Baillie, O. Broker, O. A. McBryan, and J. P. Wilson. MPI-RGL: </author> <title> a regular grid library for MPI. h http://www.cs.colorado.edu/ broker/ mpi rgl/mpi rgl.ps i, </title> <year> 1995. </year>
Reference-contexts: Communication libraries. Many researchers have investigated and developed reusable general libraries of communication routines; MPI [29] is a notable example. Others have developed more specialized libraries, for example MPI-RGL <ref> [2] </ref> for regular grids. We differ from this work, again, in that our focus is on identifying and exploiting patterns. Automatic parallelizing compilers. Much effort has gone into development of compilers that automatically recognize potential concurrency and emit parallel code; HPF [25] is a notable example.
Reference: [3] <author> R. A. Ballance, A. J. Giancola, G. F. Luger, and T. J. Ross. </author> <title> A framework-based environment for object-oriented scientific codes. </title> <journal> Scientific Programming, </journal> <volume> 2(4) </volume> <pages> 111-121, </pages> <year> 1993. </year> <month> 38 </month>
Reference-contexts: Program development strategies. Fang [22] describes a programming strategy similar to ours, but with less focus on the identification and exploitation of patterns. The Basel approach [9] is more concerned with developing and exploiting a general approach for classifying and dealing with parallel programs. Ballance et al. <ref> [3] </ref> are more explicitly concerned with the development of tools for application support; while our work can be exploited to create such tools, it is not our primary focus.
Reference: [4] <author> R. Barrett, M. Berry, T. Chan, J. Demmel, J. Donato, J. Dongarra, V. Ei--jkhout, R. Pozo, C. Romine, and H. van der Vorst. </author> <title> Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods. </title> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference-contexts: Libraries of program skeletons for functional and other programs have been developed [7, 14, 18]. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines <ref> [4] </ref>. Parallel structures have been investigated by many other researchers [8, 22]. Structuring parallel programs by means of examining dataflow patterns has also been investigated [21]. <p> Brinch Hansen's work on parallel structures [8] is similar in motivation to our work, but his model programs are generally more narrowly defined than our archetypes. Other work addresses lower-level patterns, as for example the use of templates to develop algorithms for linear algebra in <ref> [4] </ref>. Program skeletons. Much work has also been done on structuring programs by means of program skeletons, including that of Cole [14], Botorog and Kuchen [6, 7], and Darlington et al. [18].
Reference: [5] <author> F. Bodin, P. Beckman, D. Gannon, S. Narayana, and S. X. Yang. </author> <title> Distributed pC++: Basic ideas for an object parallel language. </title> <journal> Scientific Programming, </journal> <volume> 2(3) </volume> <pages> 7-22, </pages> <year> 1993. </year>
Reference-contexts: Examples of specific algorithms include one-deep mergesort [20] and one-deep quicksort [13, 35]. Distributed objects. The mesh-spectral archetype is based to some extent on the idea of distributed objects, as discussed for example in work on pC++ <ref> [5] </ref> and POOMA [1]. We differ from this work in that we focus more on the pattern of computation and on identifying and exploiting patterns of computation and communication. Communication libraries. Many researchers have investigated and developed reusable general libraries of communication routines; MPI [29] is a notable example.
Reference: [6] <author> G. H. Botorog and H. Kuchen. </author> <title> Efficient parallel programming with algorithmic skeletons. </title> <editor> In L. Bouge, editor, </editor> <booktitle> Proceedings of EuroPar '96, volume 1123-1124 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Other work addresses lower-level patterns, as for example the use of templates to develop algorithms for linear algebra in [4]. Program skeletons. Much work has also been done on structuring programs by means of program skeletons, including that of Cole [14], Botorog and Kuchen <ref> [6, 7] </ref>, and Darlington et al. [18]. This work is more oriented toward functional programming than ours, although [14] mentions the possibility of expressing the idea of program skeletons in imperative languages, and [7] combines functional skeletons with sequential imperative code.
Reference: [7] <author> G. H. Botorog and H. Kuchen. Skil: </author> <title> An imperative language with algorithmic skeletons for efficient distributed programming. </title> <booktitle> In Proceedings of the Fifth IEEE International Symposium on High Performance Distributed Computing, </booktitle> <year> 1996. </year>
Reference-contexts: Libraries of program skeletons for functional and other programs have been developed <ref> [7, 14, 18] </ref>. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers [8, 22]. Structuring parallel programs by means of examining dataflow patterns has also been investigated [21]. <p> Other work addresses lower-level patterns, as for example the use of templates to develop algorithms for linear algebra in [4]. Program skeletons. Much work has also been done on structuring programs by means of program skeletons, including that of Cole [14], Botorog and Kuchen <ref> [6, 7] </ref>, and Darlington et al. [18]. This work is more oriented toward functional programming than ours, although [14] mentions the possibility of expressing the idea of program skeletons in imperative languages, and [7] combines functional skeletons with sequential imperative code. <p> This work is more oriented toward functional programming than ours, although [14] mentions the possibility of expressing the idea of program skeletons in imperative languages, and <ref> [7] </ref> combines functional skeletons with sequential imperative code. This work, like that of Brinch Hansen, describes a program development strategy that consists of filling in the "blanks" of a parallel structure with sequential code.
Reference: [8] <author> P. Brinch Hansen. </author> <title> Model programs for computational science: A programming methodology for multicomputers. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 5(5) </volume> <pages> 407-423, </pages> <year> 1993. </year>
Reference-contexts: Libraries of program skeletons for functional and other programs have been developed [7, 14, 18]. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers <ref> [8, 22] </ref>. Structuring parallel programs by means of examining dataflow patterns has also been investigated [21]. <p> Schmidt [33] focuses more on parallel structure, but in a different context from our work and with less emphasis on code reuse. Shaw [34] examines higher-level patterns in the context of software architectures. Brinch Hansen's work on parallel structures <ref> [8] </ref> is similar in motivation to our work, but his model programs are generally more narrowly defined than our archetypes. Other work addresses lower-level patterns, as for example the use of templates to develop algorithms for linear algebra in [4]. Program skeletons.
Reference: [9] <author> H. Burkhart, R. Frank, and G. Hachler. </author> <title> Structured parallel programming: How informatics can help overcome the software dilemma. </title> <journal> Scientific Programming, </journal> <volume> 5(1) </volume> <pages> 33-45, </pages> <year> 1996. </year>
Reference-contexts: Our approach is similar, but we allow the sequential code to reference the containing parallel structure, as in the mesh-spectral archetype examples. Program development strategies. Fang [22] describes a programming strategy similar to ours, but with less focus on the identification and exploitation of patterns. The Basel approach <ref> [9] </ref> is more concerned with developing and exploiting a general approach for classifying and dealing with parallel programs. Ballance et al. [3] are more explicitly concerned with the development of tools for application support; while our work can be exploited to create such tools, it is not our primary focus.
Reference: [10] <author> K. M. Chandy. </author> <title> Concurrent program archetypes. </title> <booktitle> In Proceedings of the Scalable Parallel Library Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Many researchers have investigated the use of patterns in developing algorithms and applications. Previous work by the authors and others <ref> [10, 12] </ref> explores a more general notion of archetypes and their role in developing both sequential and parallel programs. Gamma et al. [24] address primarily the issue of patterns of computation, in the context of object-oriented design.
Reference: [11] <author> K. M. Chandy and C. Kesselman. </author> <title> CC++: A declarative concurrent object-oriented programming notation. In Research Directions in Concurrent Object-Oriented Programming. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: It is then straightforward to write down this algorithm; figure 4 shows C-like pseudocode, using the CC++ <ref> [11] </ref> parfor construct to express exploitable 10 concurrency. Observe that the iterations of each parfor loop are independent (this is part of the computational pattern captured by the archetype), so this algorithm can be executed (and debugged, if necessary) sequentially by replacing the parfor loops with for loops.
Reference: [12] <author> K. M. Chandy, R. Manohar, B. L. Massingill, and D. I. Meiron. </author> <title> Integrating task and data parallelism with the group communication archetype. </title> <booktitle> In Proceedings of the 9th International Parallel Processing Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: the dataflow pattern is information that can be exploited by a compiler. * Archetypes may also be helpful in developing performance models for classes of programs with common structure, as discussed in [32]. * Archetypes can be useful in structuring programs that combine task and data parallelism, as described in <ref> [12] </ref>. 1.2 An archetype-based program development strategy Our general strategy for writing programs using archetypes is as follows: 1. Start with a sequential algorithm (or possibly a problem description). 2. Identify an appropriate archetype. 3. Develop an initial archetype-based version of the algorithm. <p> Many researchers have investigated the use of patterns in developing algorithms and applications. Previous work by the authors and others <ref> [10, 12] </ref> explores a more general notion of archetypes and their role in developing both sequential and parallel programs. Gamma et al. [24] address primarily the issue of patterns of computation, in the context of object-oriented design.
Reference: [13] <author> M. J. Clement and M. J. Quinn. </author> <title> Overlapping computations, communications and I/O in parallel sorting. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 28(2) </volume> <pages> 162-172, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: One-deep divide and conquer algorithms. Several researchers have developed algorithms that fit the one-deep divide-and-conquer pattern. A treatment of the overall pattern, focusing on shared-memory architectures, appears in [36]. Examples of specific algorithms include one-deep mergesort [20] and one-deep quicksort <ref> [13, 35] </ref>. Distributed objects. The mesh-spectral archetype is based to some extent on the idea of distributed objects, as discussed for example in work on pC++ [5] and POOMA [1].
Reference: [14] <author> M. I. Cole. </author> <title> Algorithmic Skeletons: Structured Management of Parallel Computation. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Libraries of program skeletons for functional and other programs have been developed <ref> [7, 14, 18] </ref>. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers [8, 22]. Structuring parallel programs by means of examining dataflow patterns has also been investigated [21]. <p> Other work addresses lower-level patterns, as for example the use of templates to develop algorithms for linear algebra in [4]. Program skeletons. Much work has also been done on structuring programs by means of program skeletons, including that of Cole <ref> [14] </ref>, Botorog and Kuchen [6, 7], and Darlington et al. [18]. This work is more oriented toward functional programming than ours, although [14] mentions the possibility of expressing the idea of program skeletons in imperative languages, and [7] combines functional skeletons with sequential imperative code. <p> Program skeletons. Much work has also been done on structuring programs by means of program skeletons, including that of Cole <ref> [14] </ref>, Botorog and Kuchen [6, 7], and Darlington et al. [18]. This work is more oriented toward functional programming than ours, although [14] mentions the possibility of expressing the idea of program skeletons in imperative languages, and [7] combines functional skeletons with sequential imperative code. This work, like that of Brinch Hansen, describes a program development strategy that consists of filling in the "blanks" of a parallel structure with sequential code.
Reference: [15] <author> D. Dabdub and R. Manohar. </author> <title> Parallel computation in atmospheric chemical modeling. </title> <booktitle> Parallel Computing, </booktitle> <year> 1997. </year> <note> To appear in special issue on regional weather models. 39 </note>
Reference-contexts: Figure 18 shows speedups for the parallel code relative to single-processor execution on the IBM SP. Figure 21 shows sample output. 3.7.4 Smog model This code, known as the CIT airshed model <ref> [15, 16, 17] </ref> models smog in the Los Angeles basin. <p> It is conceptually based on the mesh-spectral archetype, although it does not use the mesh-spectral implementation, and has been implemented on a number of platforms, including the Intel Delta, the Intel Paragon, the Cray T3D, and the IBM SP2, as described in <ref> [15] </ref>. 29 150 by 100 grid, 600 steps, on the Intel Delta. 30 code for 66 by 66 by 66 grid, 512 steps, on the IBM SP.
Reference: [16] <author> D. Dabdub and J. H. Seinfeld. </author> <title> Air quality modeling on massively parallel computers. </title> <journal> Atmospheric Environment, </journal> <volume> 28(9) </volume> <pages> 1679-1687, </pages> <year> 1994. </year>
Reference-contexts: Figure 18 shows speedups for the parallel code relative to single-processor execution on the IBM SP. Figure 21 shows sample output. 3.7.4 Smog model This code, known as the CIT airshed model <ref> [15, 16, 17] </ref> models smog in the Los Angeles basin.
Reference: [17] <author> D. Dabdub and J. H. Seinfeld. </author> <title> Parallel computation in atmospheric chemical modeling. </title> <journal> Parallel Computing, </journal> <volume> 22 </volume> <pages> 111-130, </pages> <year> 1996. </year>
Reference-contexts: Figure 18 shows speedups for the parallel code relative to single-processor execution on the IBM SP. Figure 21 shows sample output. 3.7.4 Smog model This code, known as the CIT airshed model <ref> [15, 16, 17] </ref> models smog in the Los Angeles basin.
Reference: [18] <author> J. Darlington, A. J. Field, P. O. Harrison, P. H. J. Kelly, D. W. N. Sharp, Q. Wu, and R. L. White. </author> <title> Parallel programming using skeleton functions. </title> <editor> In A. Bode, editor, </editor> <booktitle> Proceedings of PARLE 1993, volume 694 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Libraries of program skeletons for functional and other programs have been developed <ref> [7, 14, 18] </ref>. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers [8, 22]. Structuring parallel programs by means of examining dataflow patterns has also been investigated [21]. <p> Program skeletons. Much work has also been done on structuring programs by means of program skeletons, including that of Cole [14], Botorog and Kuchen [6, 7], and Darlington et al. <ref> [18] </ref>. This work is more oriented toward functional programming than ours, although [14] mentions the possibility of expressing the idea of program skeletons in imperative languages, and [7] combines functional skeletons with sequential imperative code.
Reference: [19] <author> G. Davis and B. Massingill. </author> <title> The mesh-spectral archetype. </title> <type> Technical Report CS-TR-96-26, </type> <institution> California Institute of Technology, </institution> <year> 1996. </year> <note> Also available via h http://www.etext.caltech.edu/Implementations/ i. </note>
Reference-contexts: A key element of this archetype is support for ensuring that these requirements are met. This support can take the form of guidelines for manually transforming programs, as in our archetype-implementation user guides <ref> [19, 28] </ref>, or it could be expressed in terms of more formal transformations with proofs of their correctness (currently in work). 3.3 Communication patterns The above dataflow patterns give rise to the need for the following communication operations: Grid redistribution.
Reference: [20] <author> D. J. DeWitt, J. F. Naughton, and D. A. Schneider. </author> <title> Parallel sorting on a shared-nothing architecture using probabilistic splitting. </title> <booktitle> In International Conference of Parallel and Distributed Information Systems, </booktitle> <pages> pages 280-291, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: One-deep divide and conquer algorithms. Several researchers have developed algorithms that fit the one-deep divide-and-conquer pattern. A treatment of the overall pattern, focusing on shared-memory architectures, appears in [36]. Examples of specific algorithms include one-deep mergesort <ref> [20] </ref> and one-deep quicksort [13, 35]. Distributed objects. The mesh-spectral archetype is based to some extent on the idea of distributed objects, as discussed for example in work on pC++ [5] and POOMA [1].
Reference: [21] <author> D. C. Dinucci and R. G. Babb II. </author> <title> Development of portable parallel programs with Large-Grain Data Flow 2. </title> <editor> In G. Goos and J. Hartmanis, editors, </editor> <booktitle> CONPAR 90 | VAPP IV, volume 457 of Lecture Notes in Computer Science, </booktitle> <pages> pages 253-264. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers [8, 22]. Structuring parallel programs by means of examining dataflow patterns has also been investigated <ref> [21] </ref>. <p> Previous work on software reuse, e.g., Krueger [26] and Vol--pano and Kieburtz [38], tends to focus on code reuse, while our approach includes reuse of designs as well as code. Dataflow patterns. Other work, e.g., Dinucci and Babb <ref> [21] </ref>, has addressed the question of structuring parallel programs in terms of dataflow; our work differs in that it addresses patterns of both dataflow and computation. One-deep divide and conquer algorithms. Several researchers have developed algorithms that fit the one-deep divide-and-conquer pattern.
Reference: [22] <author> N. Fang. </author> <title> Engineering parallel algorithms. </title> <booktitle> In Proceedings of the Fifth IEEE International Symposium on High Performance Distributed Computing, </booktitle> <year> 1996. </year>
Reference-contexts: Libraries of program skeletons for functional and other programs have been developed [7, 14, 18]. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers <ref> [8, 22] </ref>. Structuring parallel programs by means of examining dataflow patterns has also been investigated [21]. <p> Our approach is similar, but we allow the sequential code to reference the containing parallel structure, as in the mesh-spectral archetype examples. Program development strategies. Fang <ref> [22] </ref> describes a programming strategy similar to ours, but with less focus on the identification and exploitation of patterns. The Basel approach [9] is more concerned with developing and exploiting a general approach for classifying and dealing with parallel programs.
Reference: [23] <author> I. T. Foster and K. M. Chandy. </author> <title> FORTRAN M: A language for modular parallel programming. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 26(1) </volume> <pages> 24-35, </pages> <year> 1995. </year>
Reference-contexts: This algorithm has been implemented on top of a general mesh-spectral archetype implementation (consisting of a code skeleton and an archetype-specific library of communication routines). The archetype in turn has been implemented in both Fortran M <ref> [23] </ref> and Fortran with MPI [29]. The Fortran M version has been used to run applications on the IBM SP and on networks of Sun workstations; the MPI version has been used to run applications on the IBM SP and on networks of Sun and Pentium-based workstations.
Reference: [24] <author> E. Gamma, R. Helm, R. Johnson, and J. Vlissides. </author> <title> Design Patterns: Elements of Reusable Object-Oriented Software. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: CCR-9120008. The government has certain rights in this material. 1 Much previous work also addresses the identification and exploitation of patterns: The idea of design patterns, especially for object-oriented design, has received a great deal of attention (e.g., <ref> [24, 33] </ref>). Libraries of program skeletons for functional and other programs have been developed [7, 14, 18]. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers [8, 22]. <p> Many researchers have investigated the use of patterns in developing algorithms and applications. Previous work by the authors and others [10, 12] explores a more general notion of archetypes and their role in developing both sequential and parallel programs. Gamma et al. <ref> [24] </ref> address primarily the issue of patterns of computation, in the context of object-oriented design. Our notion of a parallel program archetype, in contrast, includes patterns of dataflow and communication.
Reference: [25] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification, version 1.0. </title> <booktitle> Scientific Programming, </booktitle> <address> 2(1-2):1-170, </address> <year> 1993. </year>
Reference-contexts: We differ from this work, again, in that our focus is on identifying and exploiting patterns. Automatic parallelizing compilers. Much effort has gone into development of compilers that automatically recognize potential concurrency and emit parallel code; HPF <ref> [25] </ref> is a notable example.
Reference: [26] <author> C. W. Krueger. </author> <title> Software reuse. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(2) </volume> <pages> 131-273, </pages> <year> 1992. </year>
Reference-contexts: Kumaran and Quinn [27] focus more on automated conversion of template based applications into efficient programs for different architectures. 35 Software reuse. Previous work on software reuse, e.g., Krueger <ref> [26] </ref> and Vol--pano and Kieburtz [38], tends to focus on code reuse, while our approach includes reuse of designs as well as code. Dataflow patterns.
Reference: [27] <author> S. Kumaran and M. J. Quinn. </author> <title> An architecture-adaptable problem solving environment for scientific computing, </title> <note> 1996. Submitted to Journal of Parallel and Distributed Computing. </note>
Reference-contexts: Ballance et al. [3] are more explicitly concerned with the development of tools for application support; while our work can be exploited to create such tools, it is not our primary focus. Kumaran and Quinn <ref> [27] </ref> focus more on automated conversion of template based applications into efficient programs for different architectures. 35 Software reuse. Previous work on software reuse, e.g., Krueger [26] and Vol--pano and Kieburtz [38], tends to focus on code reuse, while our approach includes reuse of designs as well as code.
Reference: [28] <author> B. Massingill. </author> <title> The mesh archetype. </title> <type> Technical Report CS-TR-96-25, </type> <institution> California Institute of Technology, </institution> <year> 1996. </year> <note> Also available via h http:// www.etext.caltech.edu/Implementations/ i. 40 </note>
Reference-contexts: A key element of this archetype is support for ensuring that these requirements are met. This support can take the form of guidelines for manually transforming programs, as in our archetype-implementation user guides <ref> [19, 28] </ref>, or it could be expressed in terms of more formal transformations with proofs of their correctness (currently in work). 3.3 Communication patterns The above dataflow patterns give rise to the need for the following communication operations: Grid redistribution.
Reference: [29] <author> Message Passing Interface Forum. </author> <title> MPI: A message-passing interface stan-dard. </title> <journal> International Journal of Supercomputer Applications and High Performance Computing, </journal> <pages> 8(3-4), </pages> <year> 1994. </year>
Reference-contexts: This algorithm has been implemented on top of a general mesh-spectral archetype implementation (consisting of a code skeleton and an archetype-specific library of communication routines). The archetype in turn has been implemented in both Fortran M [23] and Fortran with MPI <ref> [29] </ref>. The Fortran M version has been used to run applications on the IBM SP and on networks of Sun workstations; the MPI version has been used to run applications on the IBM SP and on networks of Sun and Pentium-based workstations. <p> We differ from this work in that we focus more on the pattern of computation and on identifying and exploiting patterns of computation and communication. Communication libraries. Many researchers have investigated and developed reusable general libraries of communication routines; MPI <ref> [29] </ref> is a notable example. Others have developed more specialized libraries, for example MPI-RGL [2] for regular grids. We differ from this work, again, in that our focus is on identifying and exploiting patterns. Automatic parallelizing compilers.
Reference: [30] <author> M. E. Moret and H. D. Shapiro. </author> <title> Algorithms from P to NP | Volume I: Design and Efficiency. </title> <publisher> The Benjamin/Cummings Publishing Company, </publisher> <year> 1991. </year>
Reference-contexts: Other problems amenable to one-deep solutions include the convex hull problem and the problem of finding the two nearest neighbors in a set of points in a plane. 13 2.6.1 The skyline problem The skyline problem, as described in <ref> [30] </ref>, consists of merging a collection of rectangularly-shaped buildings into a single skyline. In the sequential divide-and-conquer algorithm, the base-case solution takes a single building and returns it as a skyline, and the merge operation merges two skylines into one by considering their overlap.
Reference: [31] <author> W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. </author> <title> Numerical Recipes. </title> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: This example illustrates how the archetype guides the process of transforming a sequential algorithm into a program for a distributed-memory message-passing architecture. 3.5.1 Problem description The problem is to perform a two-dimensional discrete Fourier transform (using the FFT algorithm) in place. This can be done (as described in <ref> [31] </ref>) by performing a one-dimensional FFT on each row of the two-dimensional array and then performing a one-dimensional FFT on each column of the resulting two-dimensional array. 3.5.2 Archetype-based algorithm, version 1 It is clear that the sequential algorithm described fits the pattern of the mesh-spectral archetype: The data (the two-dimensional
Reference: [32] <author> A. Rifkin and B. L. Massingill. </author> <title> Performance analysis for mesh and mesh-spectral archetype applications. </title> <type> Technical Report CS-TR-96-27, </type> <institution> California Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: of this paper is on active stepwise refinement by programmers and not on compilation tools, we postulate that the dataflow pattern is information that can be exploited by a compiler. * Archetypes may also be helpful in developing performance models for classes of programs with common structure, as discussed in <ref> [32] </ref>. * Archetypes can be useful in structuring programs that combine task and data parallelism, as described in [12]. 1.2 An archetype-based program development strategy Our general strategy for writing programs using archetypes is as follows: 1. Start with a sequential algorithm (or possibly a problem description). 2. <p> Within these constraints, programmers may choose any data distribution; choosing the data distribution that gives the best performance is important but orthogonal to the concerns of this paper. However, an archetype-based performance model, such as that described in <ref> [32] </ref>, may help with this choice. 16 Observe that after completion of a reduction operation all processes have access to its result; this must be guaranteed by the implementation. File input/output operations. Exploitable concurrency and appropriate data distribution depend on considerations of file structure and (perhaps) system-dependent I/O considerations.
Reference: [33] <author> D. C. Schmidt. </author> <title> Using design patterns to develop reusable object-oriented communication software. </title> <journal> Communications of the ACM, </journal> <volume> 38(10) </volume> <pages> 65-74, </pages> <year> 1995. </year>
Reference-contexts: CCR-9120008. The government has certain rights in this material. 1 Much previous work also addresses the identification and exploitation of patterns: The idea of design patterns, especially for object-oriented design, has received a great deal of attention (e.g., <ref> [24, 33] </ref>). Libraries of program skeletons for functional and other programs have been developed [7, 14, 18]. Algorithm templates of the more common linear algebra programs have been developed and then used in designing programs for parallel machines [4]. Parallel structures have been investigated by many other researchers [8, 22]. <p> Gamma et al. [24] address primarily the issue of patterns of computation, in the context of object-oriented design. Our notion of a parallel program archetype, in contrast, includes patterns of dataflow and communication. Schmidt <ref> [33] </ref> focuses more on parallel structure, but in a different context from our work and with less emphasis on code reuse. Shaw [34] examines higher-level patterns in the context of software architectures.
Reference: [34] <author> M. Shaw. </author> <title> Patterns for software architectures. </title> <editor> In J. O. Coplien and D. C. Schmidt, editors, </editor> <booktitle> Pattern Languages of Program Design, </booktitle> <pages> pages 453-462. </pages> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: Our notion of a parallel program archetype, in contrast, includes patterns of dataflow and communication. Schmidt [33] focuses more on parallel structure, but in a different context from our work and with less emphasis on code reuse. Shaw <ref> [34] </ref> examines higher-level patterns in the context of software architectures. Brinch Hansen's work on parallel structures [8] is similar in motivation to our work, but his model programs are generally more narrowly defined than our archetypes.
Reference: [35] <author> H. Shi and J. Schaeffer. </author> <title> Parallel sorting by regular sampling. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 14(4) </volume> <pages> 361-372, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: One-deep divide and conquer algorithms. Several researchers have developed algorithms that fit the one-deep divide-and-conquer pattern. A treatment of the overall pattern, focusing on shared-memory architectures, appears in [36]. Examples of specific algorithms include one-deep mergesort [20] and one-deep quicksort <ref> [13, 35] </ref>. Distributed objects. The mesh-spectral archetype is based to some extent on the idea of distributed objects, as discussed for example in work on pC++ [5] and POOMA [1].
Reference: [36] <author> J. Thornley. </author> <title> Performance of a class of highly-parallel divide-and-conquer algorithms. </title> <type> Technical Report CS-TR-95-10, </type> <institution> California Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: N of processes actually used, which can lead to inefficiency if N is large and the tree shown in figure 1 is deep. 2.1.2 "One-deep" divide and conquer Both of these sources of inefficiency can be addressed by a modification of the original divide-and-conquer paradigm called "one-deep divide and conquer" <ref> [36] </ref>. 5 First, we assume that the input data is originally distributed among pro-cesses, and that after execution the output data is to be distributed among processes as well. <p> In the figure "perfect" speedup represents the best speedup obtainable without superlinear effects and is simply the number of processors. As anticipated, the one-deep version performs significantly better. An analogous comparison for a shared-memory architecture can be found in <ref> [36] </ref>. 2.6 Other application examples The above discussion of mergesort illustrates that the key difficulty in applying the one-deep archetype to a divide-and-conquer problem is algorithmic | determining an effective N -way split and/or merge. <p> One-deep divide and conquer algorithms. Several researchers have developed algorithms that fit the one-deep divide-and-conquer pattern. A treatment of the overall pattern, focusing on shared-memory architectures, appears in <ref> [36] </ref>. Examples of specific algorithms include one-deep mergesort [20] and one-deep quicksort [13, 35]. Distributed objects. The mesh-spectral archetype is based to some extent on the idea of distributed objects, as discussed for example in work on pC++ [5] and POOMA [1].
Reference: [37] <author> E. F. Van de Velde. </author> <title> Concurrent Scientific Computing. </title> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: = 1, M/P call colfft (Data_cols (:,j)) end do !-------redistribute to restore original distribution call redistribute (Data_cols, Data_rows) end subroutine twoDfft_process again illustrates how the archetype guides the process of transforming a sequential algorithm into a program for a distributed-memory, message-passing architecture. 3.6.1 Problem description The problem (as described in <ref> [37] </ref>) is to find a numerical solution to the Poisson problem: @x 2 @y 2 = f (x; y) with Dirichlet boundary condition u (x; y) = g (x; y) using discretization and Jacobi iteration; i.e., by discretizing the problem domain and applying the following operation to all interior points until
Reference: [38] <author> D. M. Volpano and R. B. Kieburtz. </author> <title> The templates approach to software reuse. </title> <editor> In T. J. Biggerstaff and A. J. Perlis, editors, </editor> <booktitle> Software Reusability, chapter 9, </booktitle> <pages> pages 247-255. </pages> <publisher> ACM Press, Addison Wesley, </publisher> <year> 1989. </year> <month> 41 </month>
Reference-contexts: Kumaran and Quinn [27] focus more on automated conversion of template based applications into efficient programs for different architectures. 35 Software reuse. Previous work on software reuse, e.g., Krueger [26] and Vol--pano and Kieburtz <ref> [38] </ref>, tends to focus on code reuse, while our approach includes reuse of designs as well as code. Dataflow patterns.
References-found: 38

