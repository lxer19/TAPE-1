URL: http://www.prism.uvsq.fr/public/paf/sainmal2.ps
Refering-URL: http://wwwipd.ira.uka.de/~hopp/seminar97.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Array Expansion  
Author: Paul Feautrier 
Date: July 1988  
Address: Versailles St-Quentin 45 Avenue des Etats-Unis 78035 VERSAILLES CEDEX FRANCE  
Affiliation: Laboratoire PRiSM, Universite de  
Abstract: A common problem in restructuring programs for vector or parallel execution is the suppression of false dependencies which originate in the reuse of the same memory cell for unrelated values. The method is simple and well understood in the case of scalars. This paper gives the general solution for the case of arrays. The expansion is done in two steps: first, modify all definitions of the offending array in order to obtain the single assignment property. Then, reconstruct the original data flow by adapting all uses of the array. This is done with the help of a new algorithm for solving parametric integer programs. The technique is quite general and may be used for other purposes, including program checking, collecting array predicates, etc...
Abstract-found: 1
Intro-found: 1
Reference: [AK84] <author> J.R. Allen and Ken Kennedy. </author> <title> Automatic loop interchange. </title> <booktitle> In Proc. of the 1984 ACM SIGPLAN Compiler Conference, </booktitle> <pages> pages 233-246, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: Most often, the dependence relation is summarized by a dependency graph. There are several algorithms to extract a parallel or vector program from this graph, the most comprehensive being probably the one of <ref> [AK84] </ref>. Whatever the algorithm, it is clear that edges in the dependency graph are obstacles to paral-lelization. <p> The last term is simply a set of linear inequalities. The second term may be computed with the help of (3). According to the definition of the lexicographic order, it is a disjunction of N st + 1 terms. The term at depth p (according to <ref> [AK84] </ref> definition of depth) is: u [1::p] = b [1::p] ^ u [p + 1] &lt; b [p + 1]; while the last one is: u [1::N st ] = b [1::N st ]: This term must be omitted if T st is false.
Reference: [ASU86] <author> A.V. Aho, R. Sethi, and J.D. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass, </address> <year> 1986. </year>
Reference-contexts: A closely related technique is node splitting, in which a subexpression is equated to a temporary, which is then expanded into an array. In this case, neither initialisation nor restoration is necessary. 1.3.2 Use Def Chains The computation of use-def chains, (see <ref> [ASU86] </ref>, chapter 11), is a technique which is used in optimizing compilers to summarize the flow of data in a program. Before executing an optimizing transformation (such as code motion or dead code elimination), the information is used to verify that the proposed transformation is valid.
Reference: [Bak77] <author> Brenda S. Baker. </author> <title> An algorithm for structuring programs. </title> <journal> Journal of the ACM, </journal> <volume> 24 </volume> <pages> 98-120, </pages> <year> 1977. </year>
Reference-contexts: Furthermore, in the interest of simplicity, the step will always be 1. It is quite easy to implement a preprocessor to reduce all for loops to the above format. It is also possible to eliminate goto's (see for instance <ref> [Bak77] </ref>), to detect induction variables ([ASU86]) and to detect while loops which are for loops in disguise. Linear indices All indices will be restricted to affine functions of the loops inductions variables and of other integer variables.
Reference: [CH78] <author> Patrick Cousot and N. Halbwach. </author> <title> Automatic discovery of linear restraints among variables of a program. </title> <booktitle> In ACM POPL, </booktitle> <year> 1978. </year>
Reference-contexts: Similarly, all loops upper bounds will be affine functions of the surrounding loops induction variables and of other integer variables. These auxilliary variables will be treated as constants throughout this paper. This restriction may sometime be lifted by semantic analysis (see <ref> [CH78] </ref> or [Jou87]). The source program is correct! We will use the fact that in a correct program, array indices are always within the array bounds.
Reference: [Dij68] <author> Edger W. Dijkstra. </author> <title> Goto statements considered harmfull. </title> <journal> Communications of the ACM, </journal> <volume> 11 </volume> <pages> 147-148, </pages> <year> 1968. </year>
Reference-contexts: Extending the notation to unstructured programs is apparently impossible, especially since there is no longer a uniform method for specifying a particular instruction instance. This is the gist of the classical arguments of <ref> [Dij68] </ref> against the use of goto's.
Reference: [Fea88a] <author> Paul Feautrier. </author> <title> Array expansion. </title> <booktitle> In ACM Int. Conf. on Supercomputing, </booktitle> <address> St Malo, </address> <year> 1988. </year>
Reference-contexts: Q s0 is the set: Q s0 (i; j) = fy; zji + j = y + z; 0 y m; 0 z n; y &lt; ig in the context 0 i m; 0 j n. In order to apply <ref> [Fea88a] </ref> algorithm, we must first convert all constraints to the form f 0, and transform the problem to a search for a lexicographic minimum.
Reference: [Fea88b] <author> Paul Feautrier. </author> <title> Parametric integer programming. </title> <journal> RAIRO Recherche Operationnelle, </journal> <volume> 22 </volume> <pages> 243-268, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Finding its lexical maximum is a parametric integer problem, for which the author has devised an efficient algorithm in <ref> [Fea88b] </ref>. The parameters are the components of b and other integer variables (e.g. the variables which occurs in the array bounds). In the sequel, in the interest of legibility, we will not note explicitly these supplementary variables. <p> In the sequel, in the interest of legibility, we will not note explicitly these supplementary variables. Note also that the components of b are not arbitrary; they must satisfy various constraints, among which is: L t b + h t 0: In <ref> [Fea88b] </ref> terminology, these inequalities form the context of the parametric integer problem. To express the solution, we need the concept of a quasi-linear form. A quasi-linear form is constructed from the parameters and integer constants by the operations of addition, multiplication by an integer, and euclidean division by an integer. <p> K may sometime be simplified by detecting non-compatible predicates in the path from the root to a leaf. A set of quasi-linear predicates is non-compatible if the corresponding set of linear inequalities is not feasible. This is easily tested 12 by the methods of <ref> [Fea88b] </ref>. If a non-compatible path is detected, simply delete the leaf and the last test. We now put together all partial results to obtain the correct expression for A [g (b)]. <p> non negative integers, and the solution is found by zeroing the independent variables: y 0 = m i + 1; z 0 = n j 1; y = i 1; (In more complicated cases, the parametric terms may be fractional; one may have to introduce cuts to restore integrity, see <ref> [Fea88b] </ref> for details). Suppose now that i 1 is negative. Inspection of the c row shows that the coefficients of the independent variables are null or negative. Hence bringing the row to a non-negative value is impossible, and the problem has no solution. <p> This technique involves solving small parametric integer problems. The algorithm of <ref> [Fea88b] </ref> has been implemented and found to work reliably on examples such as programs fAg and fCg. The method will work under any expansion strategy: one simply has to modify accordingly rules (17) to (19). The overall complexity of the method depends on several size parameters.
Reference: [Jou87] <author> Pierre Jouvelot. </author> <title> Semantic parallelization, a practical exercise in abstract interpretation. </title> <booktitle> In ACM POPL, </booktitle> <year> 1987. </year>
Reference-contexts: Similarly, all loops upper bounds will be affine functions of the surrounding loops induction variables and of other integer variables. These auxilliary variables will be treated as constants throughout this paper. This restriction may sometime be lifted by semantic analysis (see [CH78] or <ref> [Jou87] </ref>). The source program is correct! We will use the fact that in a correct program, array indices are always within the array bounds. Hence, two array references address the same memory location if and only if they are references to the same array and if their indices are equal. <p> We have noted that they give a method for testing that no array element is used before being defined. Similarly, the method may be used to build assertions on arrays, in the manner of <ref> [Jou87] </ref>. It may even be possible in some cases to solve recurrence equations on array, as for instance to transform: x [0] := 0; x [i] := x [i-1]; into for i := 0 to n do with the attendant increase in parallelism.
Reference: [Kuc78] <author> David J. Kuck. </author> <title> The Structure of Computers and Computations. </title> <editor> J. </editor> <publisher> Wiley and sons, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: In our source language, the only repetitive construct is the for loop. Hence, an instruction instance is uniquely defined by the name of the instruction and the values of the surrounding loop induction variables (the iteration vector of <ref> [Kuc78] </ref>). A pair whose components are an instruction name and an integer list will be called an instruction coordinate.
Reference: [PW86] <author> D. A. Padua and Michael J. Wolfe. </author> <title> Advanced compiler optimization for supercomputers. </title> <journal> CACM, </journal> <volume> 29 </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: To make efficient use of a super-computer, one must retrieve these features from the sequential program text or (worse !) from one's sequential thinking. Many attempts have been made to automate this process by constructing optimizing and restructuring compilers; see <ref> [PW86] </ref> for an up-to-date review. Broadly speaking, all such compilers start by detecting dependencies in the source code. <p> In paragraph 4, we will return to the simpler problem of scalar expansion, and show that classical techniques are particular cases of our general solution. In the conclusion, we will 2 review our results and point to some unsolved problems. 1.3 Related work 1.3.1 Scalar expansion Scalar expansion (see <ref> [PW86] </ref> or [Wol78]), is mainly used by vectorizing compilers; the transformation is restricted to innermost loops in which a scalar is assigned to.
Reference: [Wol78] <author> Michael J. Wolfe. </author> <title> Techniques for improving the inherent parallelism in programs. </title> <type> Master's thesis, </type> <institution> Univ. of Illinois at Urbana-Champlain, </institution> <year> 1978. </year> <month> 20 </month>
Reference-contexts: Replacing the scalar by an array whose index is the loop counter will cut the PP edge and may (in favorable cases) allow parallel execution. This is the well-known scalar expansion technique <ref> [Wol78] </ref>. <p> In the conclusion, we will 2 review our results and point to some unsolved problems. 1.3 Related work 1.3.1 Scalar expansion Scalar expansion (see [PW86] or <ref> [Wol78] </ref>), is mainly used by vectorizing compilers; the transformation is restricted to innermost loops in which a scalar is assigned to.
References-found: 11

