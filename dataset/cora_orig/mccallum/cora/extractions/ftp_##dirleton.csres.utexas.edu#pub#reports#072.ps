URL: ftp://dirleton.csres.utexas.edu/pub/reports/072.ps
Refering-URL: http://www.cli.com/reports/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Interface Logics?  
Phone: (512) 322-9951  
Author: Matt Kaufmann J Strother Moore 
Note: This work was supported in part at Computational Logic, Inc., by the Defense Advanced Research Projects Agency, ARPA Order 7406. The views and conclusions contained in this document are those of the author(s) and should not be interpreted as representing the official policies, either expressed or implied, of Computational Logic, Inc., the Defense Advanced Research Projects Agency or the U.S. Government. POSITION PAPER: for  
Address: 1717 W. 6th St. Suite 290 Austin, Texas 78703  
Affiliation: Computational Logic Inc.  
Abstract: Technical Report 72 January, 1992 Should We Begin a Standardization Process
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Donald I. Good, Matt Kaufmann, J Strother Moore, </author> <title> ``The Role of Automated Reasoning in Integrated System Verification Environments'', </title> <type> Technical Report 73, </type> <institution> Computational Logic, Inc., </institution> <month> January </month> <year> 1992. </year> <title> 2. ``&lt;Informal electronic discussion among members of the deftpi@itd.nrl.navy.mil mailing list&gt;''. </title>
Reference-contexts: 1. Introduction This paper is a companion paper to <ref> [1] </ref>. In that paper we argue against so-called interface logics for the verification of systems, and present an alternative approach that has already enjoyed considerable success. <p> In fact, except for that interpretation we have not understood to our own satisfaction just how interface logics would be usefully applied to nontrivial verification problems. In the system verification realm we actually argue quite directly against interface logics in <ref> [1] </ref>. However, even outside that realm we have a number of concerns about interface logics. Let us also acknowledge that standardization can in general be made difficult by waiting too long, since various divergent interests could by then be entrenched. <p> In fact, we argue in <ref> [1] </ref> that the truly important constraint on writers of formula generators is that they choose a well-defined logic, not necessarily a theorem prover, as their target. However, we think the benefit of using an interface logic may be fairly minimal.
Reference: 3. <author> Joshua D. Guttman, </author> <title> ``A Proposed Interface Logic for Verification Environments'', </title> <type> Tech. report M91-19, </type> <institution> The MITRE Corporation, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: There has recently been some considerable discussion of ``interface logics'' in the verification community <ref> [2, 3] </ref>. Our impression is that there could be pressure forthcoming at some point to standardize one or more interface logics. We have chosen to air our concerns here at this time in order to head off such pressure. <p> Rather, we suggest that proponents of this ``narrow interpretation'' of interface logics 2 demonstrate the idea's viability by providing an example based on connecting a nucleus of existing systems. Guttman's paper <ref> [3] </ref> is a step in this direction, though it does not provide several existing systems that isomorphically map precisely to one of the logics provided there. We do not think it particularly useful to have community-wide discussion of such a task. <p> However, defining semantics for logics isn't generally difficult anyhow. In those cases where it is difficult, we wonder if well-understood interface logics would be rich enough to ``absorb'' the prover logic. An exception could be the treatment of partial functions by Lutins (see <ref> [3] </ref>) that could make it a useful interface logic for other logics with partial functions. <p> Conclusion A solution to the concern raised in the paragraph immediately above, and perhaps to all the concerns raised in this paper, is simply to let people propose and publish interface logics (e.g. see <ref> [3] </ref>) and demonstrate that they map to existing logics by implementing the mappings. If there is a natural demand for interface logics and they are found to be useful, then standardization can be considered.
Reference: 4. <author> Kaufmann, Matthew J. and David Basin, </author> <title> ``The Boyer-Moore Prover and Nuprl: An Experimental Comparison'', </title> <booktitle> Proceedings of Workshop for Basic Research Action, Logical Frameworks, Antibes, </booktitle> <address> France. </address> <note> Also published as CLI Technical Report 58 </note>
Reference-contexts: However, our experience is that comparison of different theorem proving systems is an expensive and difficult enterprise. Quoting from one such comparison <ref> [4] </ref>: Perhaps though it would be responsible of us to point out that it took much more effort to write this paper than to carry out the proofs. Some potential pitfalls in comparing theorem provers are as follows. Most of these come essentially from [4]. <p> Quoting from one such comparison <ref> [4] </ref>: Perhaps though it would be responsible of us to point out that it took much more effort to write this paper than to carry out the proofs. Some potential pitfalls in comparing theorem provers are as follows. Most of these come essentially from [4]. <p> For example, the Nqthm proof from <ref> [4] </ref> used two lemmas that were created with the emacs editor from existing text, using very few keystrokes; yet these consisted of 116 tokens. It isn't always clear just what constitutes a ``token.'' Replay time is a dangerous metric.
Reference: 5. <author> R. S. Boyer and J S. Moore, </author> <title> ``A Verification Condition Generator for FORTRAN'', in The Correctness Problem in Computer Science, </title> <editor> R. S. Boyer and J S. Moore, eds., </editor> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: For a concrete example, consider the Fortran VCG work described in <ref> [5] </ref>. There, the loop invariants were formulated as rewrite rules. Thus, knowledge of the target prover was important.
Reference: 6. <author> Robert S. Boyer and J Strother Moore, </author> <title> ``Integrating Decision Procedures into Heuristic Theorem Provers: A Case Study of Linear Arithmetic'', </title> <type> Tech. report ICSCA-CMP-44, </type> <institution> University of Texas at Austin, </institution> <year> 1985. </year>
Reference-contexts: Perhaps more significantly, it can be difficult to write stand-alone modules even for a single theorem prover. The linear arithmetic procedure in Nqthm is a good example of this phenomenon <ref> [6] </ref>: it was discovered that the particular decision procedure was much less important than the way it was tightly integrated into the rewriting process.
Reference: 7. <author> Randal E. Bryant, </author> <title> ``Graph-Based Algorithms for Boolean Function Manipulation'', </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-35, No. 8, </volume> <month> August </month> <year> 1986, </year> <pages> pp. </pages> <month> 677--691. </month> <title> i Table of Contents </title>
Reference-contexts: Some recent preliminary work by Kaufmann in incorporating binary decision diagram (BDD) technology <ref> [7] </ref> into Nqthm seemed to significantly slow down the prover, in spite of its apparent superiority for tautologies to the prover's clausification method. The problem appears to be that we need to consider more carefully the interaction of Nqthm's clausification process with the BDD algorithm we used.


Reference: 3. <institution> Allow incremental improvements in systems by allowing replacement of modules (?) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 </institution>
Reference-contexts: There has recently been some considerable discussion of ``interface logics'' in the verification community <ref> [2, 3] </ref>. Our impression is that there could be pressure forthcoming at some point to standardize one or more interface logics. We have chosen to air our concerns here at this time in order to head off such pressure. <p> Rather, we suggest that proponents of this ``narrow interpretation'' of interface logics 2 demonstrate the idea's viability by providing an example based on connecting a nucleus of existing systems. Guttman's paper <ref> [3] </ref> is a step in this direction, though it does not provide several existing systems that isomorphically map precisely to one of the logics provided there. We do not think it particularly useful to have community-wide discussion of such a task. <p> However, defining semantics for logics isn't generally difficult anyhow. In those cases where it is difficult, we wonder if well-understood interface logics would be rich enough to ``absorb'' the prover logic. An exception could be the treatment of partial functions by Lutins (see <ref> [3] </ref>) that could make it a useful interface logic for other logics with partial functions. <p> Conclusion A solution to the concern raised in the paragraph immediately above, and perhaps to all the concerns raised in this paper, is simply to let people propose and publish interface logics (e.g. see <ref> [3] </ref>) and demonstrate that they map to existing logics by implementing the mappings. If there is a natural demand for interface logics and they are found to be useful, then standardization can be considered.
Reference: 4. <editor> Allow for clear presentation of what's been proved, </editor> <title> in a uniform language, so that others can understand it (?) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 </title>
Reference-contexts: However, our experience is that comparison of different theorem proving systems is an expensive and difficult enterprise. Quoting from one such comparison <ref> [4] </ref>: Perhaps though it would be responsible of us to point out that it took much more effort to write this paper than to carry out the proofs. Some potential pitfalls in comparing theorem provers are as follows. Most of these come essentially from [4]. <p> Quoting from one such comparison <ref> [4] </ref>: Perhaps though it would be responsible of us to point out that it took much more effort to write this paper than to carry out the proofs. Some potential pitfalls in comparing theorem provers are as follows. Most of these come essentially from [4]. <p> For example, the Nqthm proof from <ref> [4] </ref> used two lemmas that were created with the emacs editor from existing text, using very few keystrokes; yet these consisted of 116 tokens. It isn't always clear just what constitutes a ``token.'' Replay time is a dangerous metric.
Reference: 5. <institution> Assist with the definition of the semantics of new prover logics (?) . . . . . . . . . . . . 8 </institution>
Reference-contexts: For a concrete example, consider the Fortran VCG work described in <ref> [5] </ref>. There, the loop invariants were formulated as rewrite rules. Thus, knowledge of the target prover was important.
Reference: 6. <institution> Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 </institution>
Reference-contexts: Perhaps more significantly, it can be difficult to write stand-alone modules even for a single theorem prover. The linear arithmetic procedure in Nqthm is a good example of this phenomenon <ref> [6] </ref>: it was discovered that the particular decision procedure was much less important than the way it was tightly integrated into the rewriting process.
References-found: 10

