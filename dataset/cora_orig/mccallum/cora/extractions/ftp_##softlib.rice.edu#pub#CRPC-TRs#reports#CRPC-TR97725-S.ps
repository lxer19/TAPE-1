URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR97725-S.ps
Refering-URL: http://www.cs.rice.edu:80/~roth/papers.html
Root-URL: 
Email: frothjjohnmcjkeng@cs:rice:edu  rgb@lanl:gov  
Title: Compiling Stencils in High Performance Fortran  
Author: Gerald Roth John Mellor-Crummey Ken Kennedy R. Gregg Brickner 
Keyword: stencil compilation, shift optimization, communication unioning, state ment partitioning, High Performance Fortran  
Note: From the Proceedings of SC'97: High Performance Networking and Computing  
Address: Houston, TX 77005-1892  Los Alamos, NM 87545  
Affiliation: Department of Computer Science Rice University  Scientific Computing Group Los Alamos National Laboratory  
Abstract: For many Fortran90 and HPF programs performing dense matrix computations, the main computational portion of the program belongs to a class of kernels known as stencils. Stencil computations are commonly used in solving partial differential equations, image processing, and geometric modeling. The efficient handling of such stencils is critical for achieving high performance on distributed-memory machines. Compiling stencils into efficient code is viewed as so important that some companies have built special-purpose compilers for handling them and others have added stencil-recognizers to existing compilers. In this paper we present a general compilation strategy for stencils written using Fortran90 array constructs. Our strategy is capable of optimizing single or multi-statement stencils and is applicable to stencils specified with shift intrinsics or with array-syntax all equally well. The strategy eliminates the need for pattern-recognition algorithms by orchestrating a set of optimizations that address the overhead of both intraprocessor and interprocessor data movement that results from the translation of Fortran90 array constructs. Our experimental results show that code produced by this strategy beats or matches the best code produced by the special-purpose compilers or pattern-recognition schemes that are known to us. In addition, our strategy produces highly optimized code in situations where the others fail, producing several orders of magnitude performance improvement, and thus provides a stencil compilation strategy that is more robust than its predecessors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Z. Bozkus, L. Meadows, D. Miles, S. Nakamoto, V. Schuster, and M. Young. </author> <title> Techniques for compiling and executing HPF programs on shared-memory and distributed-memory parallel systems. </title> <booktitle> In Proceedings of the First International Workshop on Parallel Processing, </booktitle> <address> Bangalore, India, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: Compiling stencils into efficient code is viewed as so important that some companies have built special-purpose compilers for handling them [4, 5, 6] and others have added stencil-recognizers to existing HPF compilers <ref> [1, 2] </ref>. Each of these previous approaches to stencil compilation had significant limitations that restricted the types of stencils that they could handle. In this paper, we focus on the problem of optimizing stencil computations, no matter how they are instantiated by the programmer, for execution on distributed-memory architectures. <p> However, they do not describe their algorithm for accomplishing this, and it is unknown whether they would be able to eliminate the redundant communication that arises from shifts over the same dimension and direction but of different distances. The Portland Group's pghpf compiler, as described by Bozkus, et al. <ref> [1, 2] </ref>, performs stencil recognition and optimizes the computation by using overlap shift communication. They also perform a subset of our communication unioning optimization. However, they are limited to single-statement expressions in both cases. In general, there have been several different methods for handling specific forms of stencil computations.
Reference: [2] <author> Z. Bozkus, L. Meadows, S. Nakamoto, V. Schuster, and M. Young. </author> <title> PGHPF an optimizing High Performance Fortran compiler for distributed memory machines. </title> <journal> Scientific Programming, </journal> <volume> 6(1) </volume> <pages> 29-40, </pages> <year> 1997. </year>
Reference-contexts: Compiling stencils into efficient code is viewed as so important that some companies have built special-purpose compilers for handling them [4, 5, 6] and others have added stencil-recognizers to existing HPF compilers <ref> [1, 2] </ref>. Each of these previous approaches to stencil compilation had significant limitations that restricted the types of stencils that they could handle. In this paper, we focus on the problem of optimizing stencil computations, no matter how they are instantiated by the programmer, for execution on distributed-memory architectures. <p> However, they do not describe their algorithm for accomplishing this, and it is unknown whether they would be able to eliminate the redundant communication that arises from shifts over the same dimension and direction but of different distances. The Portland Group's pghpf compiler, as described by Bozkus, et al. <ref> [1, 2] </ref>, performs stencil recognition and optimizes the computation by using overlap shift communication. They also perform a subset of our communication unioning optimization. However, they are limited to single-statement expressions in both cases. In general, there have been several different methods for handling specific forms of stencil computations.
Reference: [3] <author> T. Brandes. </author> <title> Compiling data parallel programs to message passing programs for massively parallel MIMD systems. </title> <booktitle> In Working Conference on Massively Parallel Programming Models, </booktitle> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: For this reason, we have designed our optimizer to target the most general, normalized input form. All stencil and stencil-like computations can be translated into this normal form by factoring expressions and introducing temporary arrays. In fact, this is the intermediate form used by several distributed-memory compilers <ref> [18, 23, 3] </ref>.
Reference: [4] <author> R. G. Brickner, W. George, S. L. Johnsson, and A. Ruttenberg. </author> <title> A stencil compiler for the Connection Machine models CM-2/200. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: For HPF to gain acceptance as a vehicle for parallel scientific programming, it must achieve high performance on this important class of problems. Compiling stencils into efficient code is viewed as so important that some companies have built special-purpose compilers for handling them <ref> [4, 5, 6] </ref> and others have added stencil-recognizers to existing HPF compilers [1, 2]. Each of these previous approaches to stencil compilation had significant limitations that restricted the types of stencils that they could handle. <p> handle the lowest common denominator a form into which our compiler can transform all stencil computations. 6 Related Work One of the first major efforts to specifically address the compilation of stencil computations for a distributed-memory machine was the stencil compiler for the CM-2, also known as the convolution compiler <ref> [4, 5, 6] </ref>. The compiler eliminated intraprocessor data movement and optimized the interprocessor data movement by exploiting the CM-2's polyshift communication [10]. The final computation was performed by hand-optimized library microcode that took advantage of several loop transformations and a specialized register allocation scheme.
Reference: [5] <author> R. G. Brickner, K. Holian, B. Thiagarajan, and S. L. Johnsson. </author> <title> A stencil compiler for the Connection Machine model CM-5. </title> <type> Technical Report CRPC-TR94457, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: For HPF to gain acceptance as a vehicle for parallel scientific programming, it must achieve high performance on this important class of problems. Compiling stencils into efficient code is viewed as so important that some companies have built special-purpose compilers for handling them <ref> [4, 5, 6] </ref> and others have added stencil-recognizers to existing HPF compilers [1, 2]. Each of these previous approaches to stencil compilation had significant limitations that restricted the types of stencils that they could handle. <p> handle the lowest common denominator a form into which our compiler can transform all stencil computations. 6 Related Work One of the first major efforts to specifically address the compilation of stencil computations for a distributed-memory machine was the stencil compiler for the CM-2, also known as the convolution compiler <ref> [4, 5, 6] </ref>. The compiler eliminated intraprocessor data movement and optimized the interprocessor data movement by exploiting the CM-2's polyshift communication [10]. The final computation was performed by hand-optimized library microcode that took advantage of several loop transformations and a specialized register allocation scheme.
Reference: [6] <author> M. Bromley, S. Heller, T. McNerney, and G. Steele, Jr. </author> <title> Fortran at ten gigaflops: The Connection Machine convolution compiler. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: For HPF to gain acceptance as a vehicle for parallel scientific programming, it must achieve high performance on this important class of problems. Compiling stencils into efficient code is viewed as so important that some companies have built special-purpose compilers for handling them <ref> [4, 5, 6] </ref> and others have added stencil-recognizers to existing HPF compilers [1, 2]. Each of these previous approaches to stencil compilation had significant limitations that restricted the types of stencils that they could handle. <p> handle the lowest common denominator a form into which our compiler can transform all stencil computations. 6 Related Work One of the first major efforts to specifically address the compilation of stencil computations for a distributed-memory machine was the stencil compiler for the CM-2, also known as the convolution compiler <ref> [4, 5, 6] </ref>. The compiler eliminated intraprocessor data movement and optimized the interprocessor data movement by exploiting the CM-2's polyshift communication [10]. The final computation was performed by hand-optimized library microcode that took advantage of several loop transformations and a specialized register allocation scheme. <p> Our compilation scheme handles a strict superset of patterns handled by the CM-2 stencil compiler. In their own words, they "avoid the general problem by restricting the domain of applicability." <ref> [6] </ref> We have placed no such restrictions upon our work. Our strategy optimizes single-statement stencils, multi-statement stencils, cshift intrinsic stencils, and array-syntax stencils all equally well. And since our optimizations were designed to be incorporated into an HPF compiler, they benefit those computations that only slightly resemble stencils.
Reference: [7] <author> S. Carr, K. S. M c Kinley, and C.-W. Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: These transformations include unroll-and-jam, which addresses memory references, and loop permutation, which addresses cache references. Each of these optimize the program by exploiting reuse of data values. These optimizations are described in detail elsewhere <ref> [7, 19] </ref> and are not addressed in this paper. 4 An Extended Example In this section, we trace our compilation strategy through an extended example. This detailed examination shows how our strategy is able to produce code that matches or beats hand-optimized code.
Reference: [8] <author> A. Choudhary, G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, S. Ranka, and C.-W. Tseng. </author> <title> Compiling Fortran 77D and 90D for MIMD distributed-memory machines. </title> <booktitle> In Frontiers '92: The 4th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The loop nest for a stencil computation is 4 constructed during compilation in two steps. First the compiler applies scalarization [24] to replace Fortran 90 array operations with a serial loop nest that operates on individual data elements. Next, the compiler transforms this loop nest into SPMD code <ref> [8] </ref>. The SPMD code is synthesized by reducing the loop bounds so that each PE computes values only for the data it owns. A copy of this transformed loop nest, known as the subgrid loop nest, executes on each PE of the parallel machine.
Reference: [9] <author> R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and K. Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year> <month> 18 </month>
Reference-contexts: The algorithm that we have devised for verifying the criteria and for performing the above transformations is based upon the static single assignment (SSA) intermediate representation <ref> [9] </ref>. The algorithm, after validating the use of an offset array at a shift operation, transforms the program and propagates that information in an optimistic manner. The propagation continues until there are no more references to transform or one of the criteria has been violated.
Reference: [10] <author> W. George, R. Brickner, and S. L. Johnsson. </author> <title> Polyshift communications software for the Connection Machine systems CM-2 and CM-200. </title> <booktitle> Scientific Programming, </booktitle> <address> 3(1):83, </address> <month> Spring </month> <year> 1994. </year>
Reference-contexts: The compiler eliminated intraprocessor data movement and optimized the interprocessor data movement by exploiting the CM-2's polyshift communication <ref> [10] </ref>. The final computation was performed by hand-optimized library microcode that took advantage of several loop transformations and a specialized register allocation scheme. Our general compilation methodology produces the same style code as this specialized compiler. We both eliminate intraprocessor data movement and minimize interprocessor 15 data movement.
Reference: [11] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: This optimization determines when the source array (src) and the destination array (dst) of the cshift can share the same memory locations. If this is the case only the interprocessor data movement needs to occur. We exploit overlap areas <ref> [11] </ref> to receive the data that is copied between processors. After this has been accomplished, appropriate references to the destination array can be rewritten to refer to the source array with indices offset by the shift amount.
Reference: [12] <author> M. Gupta, S. Midkiff, E. Schonberg, V. Seshadri, D. Shields, K. Wang, W. Ching, and T. Ngo. </author> <title> An HPF compiler for the IBM SP2. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <address> San Diego, CA, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: However, the compiler still performs all the data movement for single-statement stencils written using shift intrinsics. This strategy is shared by many Fortran90/HPF compilers that focus 16 on handling scalarized code. As with the CM-2 stencil compiler, our methodology is a strict superset of this strategy. Gupta, et al. <ref> [12] </ref>, in describing IBM's xlhpf compiler, state that they are able to reduce the number of messages for multi-dimensional shifts by exploiting methods similar to ours.
Reference: [13] <author> T. Haupt, S. Reddy, and G. Vengurlekar. </author> <title> Low level HPF compiler benchmark suite. </title> <type> Technical Report SCCS-735, </type> <institution> Northeast Parallel Architectures Center, Syracuse University, Syracuse, </institution> <address> NY, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: It also demonstrates how we are able to handle stencil computations that cause other methods to fail. For this exercise, we have chosen to use Problem 9 of the Purdue Set [21], as adapted for Fortran D benchmarking by Thomas Haupt of NPAC <ref> [20, 13] </ref>. The program kernel is shown in Figure 3. The arrays T, U, RIP, and RIN are all two-dimensional and have been distributed in a (block,block) fashion. This kernel computes a standard 9-point stencil, identical to that computed by the single-statement stencil shown in Figure 2.
Reference: [14] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification. </title> <booktitle> Scientific Programming, </booktitle> <address> 2(1-2):1-170, </address> <year> 1993. </year>
Reference: [15] <author> K. Kennedy, J. Mellor-Crummey, and G. Roth. </author> <title> Optimizing Fortran 90 shift operations on distributed-memory multicomputers. </title> <booktitle> In Languages and Compilers for Parallel Computing, Eighth International Workshop, </booktitle> <address> Columbus, OH, </address> <month> August </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: Finally, loop-level transformations are applied to optimize the computation. 3.1 Optimizing Intraprocessor Data Movement Intraprocessor data movement associated with shift intrinsics is completely eliminated when possible. This is accomplished by an optimization we call offset arrays <ref> [15] </ref>. This optimization determines when the source array (src) and the destination array (dst) of the cshift can share the same memory locations. If this is the case only the interprocessor data movement needs to occur. We exploit overlap areas [11] to receive the data that is copied between processors. <p> We have established a set of criteria to determine when it is safe and profitable to create an offset array. These criteria, and an algorithm used to verify them are described in detail elsewhere <ref> [15, 22] </ref>. In general, our approach allows the source and destination arrays of a shift operation to share storage between destructive updates to either array when the shift offset is a small constant.
Reference: [16] <author> K. Kennedy and K. S. M c Kinley. </author> <title> Typed fusion with applications to parallel and sequential code generation. </title> <type> Technical Report TR93-208, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: Second, by grouping together communication operations, we simplify the task of reducing the amount of interprocessor data movement, which we discuss in the next subsection. To accomplish context partitioning, we use an algorithm proposed by Kennedy and M c Kinley <ref> [16] </ref>. While this algorithm was developed to partition parallel and serial loops into fusible groups, we use it to partition Fortran90 statements into congruence classes. The algorithm works on the data dependence graph (ddg)which must be acyclic.
Reference: [17] <author> K. Kennedy and G. Roth. </author> <title> Context optimization for SIMD execution. </title> <booktitle> In Proceedings of the 1994 Scalable High Performance Computing Conference, </booktitle> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: This allows our stencil compilation strategy to eliminate intraprocessor data movement in situations where other strategies fail. 6 3.2 Statement Reordering We follow the offset array optimization with our context partitioning optimization <ref> [17] </ref>. This optimization partitions a set of Fortran90 statements into groups of congruent array statements 2 , scalar expressions, and communication operations. This assists the compilation of stencils in the following two ways: 1. <p> The algorithm works on the data dependence graph (ddg)which must be acyclic. Since we apply it to a set of statements within a basic block, our dependence graph contains only loop-independent dependences and thus is acyclic. A complete description of our context partitioning algorithm is available elsewhere <ref> [17, 22] </ref>, along with a discussion of its advantages for both SIMD and MIMD machines. Context partitioning is key to our ability to optimize multi-statement stencils as fully as single-statement stencils.
Reference: [18] <author> K. Knobe, J. Lukas, and M. Weiss. </author> <title> Optimization techniques for SIMD Fortran compilers. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 5(7) </volume> <pages> 527-552, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: For this reason, we have designed our optimizer to target the most general, normalized input form. All stencil and stencil-like computations can be translated into this normal form by factoring expressions and introducing temporary arrays. In fact, this is the intermediate form used by several distributed-memory compilers <ref> [18, 23, 3] </ref>.
Reference: [19] <author> K. S. McKinley, S. Carr, and C.-W. Tseng. </author> <title> Improving data locality with loop transformations. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 18(4) </volume> <pages> 424-453, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: These transformations include unroll-and-jam, which addresses memory references, and loop permutation, which addresses cache references. Each of these optimize the program by exploiting reuse of data values. These optimizations are described in detail elsewhere <ref> [7, 19] </ref> and are not addressed in this paper. 4 An Extended Example In this section, we trace our compilation strategy through an extended example. This detailed examination shows how our strategy is able to produce code that matches or beats hand-optimized code.
Reference: [20] <author> A. Mohamed, G. Fox, G. v. Laszewski, M. Parashar, T. Haupt, K. Mills, Y. Lu, N. Lin, and N. Yeh. </author> <title> Applications benchmark set for Fortran-D and High Performance Fortran. </title> <type> Technical Report SCCS-327, </type> <institution> Northeast Parallel Architectures Center, Syracuse University, Syracuse, </institution> <address> NY, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: It also demonstrates how we are able to handle stencil computations that cause other methods to fail. For this exercise, we have chosen to use Problem 9 of the Purdue Set [21], as adapted for Fortran D benchmarking by Thomas Haupt of NPAC <ref> [20, 13] </ref>. The program kernel is shown in Figure 3. The arrays T, U, RIP, and RIN are all two-dimensional and have been distributed in a (block,block) fashion. This kernel computes a standard 9-point stencil, identical to that computed by the single-statement stencil shown in Figure 2.
Reference: [21] <author> J. R. Rice and J. Jing. </author> <title> Problems to test parallel and vector languages. </title> <type> Technical Report CSD-TR-1016, </type> <institution> Dept. of Computer Science, Purdue University, </institution> <year> 1990. </year>
Reference-contexts: The normal form has several distinguishing characteristics: * cshift intrinsics and temporary arrays have been inserted to perform data movement needed for operations on array sections that have different processor mappings. 1 This example was taken from Problem 9 of the Purdue Set <ref> [21] </ref> as adapted for Fortran D benchmarking by Thomas Haupt of NPAC. 3 ALLOCATE TMP1, TMP2, TMP3, TMP4 TMP1 = CSHIFT (SRC,SHIFT=-1,DIM=1) TMP2 = CSHIFT (SRC,SHIFT=-1,DIM=2) TMP3 = CSHIFT (SRC,SHIFT=+1,DIM=1) TMP4 = CSHIFT (SRC,SHIFT=+1,DIM=2) DST (2:N-1,2:N-1) = C1 * TMP1 (2:N-1,2:N-1) & + C3 * SRC (2:N-1,2:N-1) & + C5 * <p> This detailed examination shows how our strategy is able to produce code that matches or beats hand-optimized code. It also demonstrates how we are able to handle stencil computations that cause other methods to fail. For this exercise, we have chosen to use Problem 9 of the Purdue Set <ref> [21] </ref>, as adapted for Fortran D benchmarking by Thomas Haupt of NPAC [20, 13]. The program kernel is shown in Figure 3. The arrays T, U, RIP, and RIN are all two-dimensional and have been distributed in a (block,block) fashion.
Reference: [22] <author> G. Roth. </author> <title> Optimizing Fortran90D/HPF for Distributed-Memory Computers. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: We have established a set of criteria to determine when it is safe and profitable to create an offset array. These criteria, and an algorithm used to verify them are described in detail elsewhere <ref> [15, 22] </ref>. In general, our approach allows the source and destination arrays of a shift operation to share storage between destructive updates to either array when the shift offset is a small constant. <p> This assists the compilation of stencils in the following two ways: 1. First, by grouping congruent array statements together, we ensure that as subgrid loops are generated, via scalarization and loop fusion, as much computation as possible is placed within each loop without causing the loops to be over-fused <ref> [22] </ref>. Loops are over-fused when the code produced for the resulting parallel loops exhibits worse performance than the code for the separate parallel loops. Also, the structure of the subgrid loops produced is very regular. <p> The algorithm works on the data dependence graph (ddg)which must be acyclic. Since we apply it to a set of statements within a basic block, our dependence graph contains only loop-independent dependences and thus is acyclic. A complete description of our context partitioning algorithm is available elsewhere <ref> [17, 22] </ref>, along with a discussion of its advantages for both SIMD and MIMD machines. Context partitioning is key to our ability to optimize multi-statement stencils as fully as single-statement stencils. <p> Due to the nature of offset arrays, we are presented with many opportunities to eliminate redundant and partially redundant data movement. We call this optimization communication unioning <ref> [22] </ref>, since it combines a set of communication operations to produce a smaller set of operations. There are two key observations that allow us to find and eliminate redundant inter-processor data movement.
Reference: [23] <author> G. Sabot. </author> <title> A compiler for a massively parallel distributed memory MIMD computer. </title> <booktitle> In Frontiers '92: The 4th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> October </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: For this reason, we have designed our optimizer to target the most general, normalized input form. All stencil and stencil-like computations can be translated into this normal form by factoring expressions and introducing temporary arrays. In fact, this is the intermediate form used by several distributed-memory compilers <ref> [18, 23, 3] </ref>.
Reference: [24] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cam--bridge, MA, </address> <year> 1989. </year> <month> 20 </month>
Reference-contexts: The solid lines in Following data movement, the second phase of a stencil computation is the execution of a loop nest to calculate a sum of products. The loop nest for a stencil computation is 4 constructed during compilation in two steps. First the compiler applies scalarization <ref> [24] </ref> to replace Fortran 90 array operations with a serial loop nest that operates on individual data elements. Next, the compiler transforms this loop nest into SPMD code [8].
References-found: 24

