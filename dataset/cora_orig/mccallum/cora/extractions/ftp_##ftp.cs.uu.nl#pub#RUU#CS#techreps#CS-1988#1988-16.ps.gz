URL: ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1988/1988-16.ps.gz
Refering-URL: http://www.cs.ruu.nl/docs/research/publication/TechList1.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: gerard@cs.ruu.nl  
Title: Total Algorithms  
Author: Gerard Tel 
Keyword: [Tel91, Sec. 4.1]. Key Words: Distrubuted Algorithms, Design methods, Broadcast, Mutual Exclusion, Election, Termination Detection.  
Date: April 1988 Revised November 1989 and February 1993  
Address: P.O. Box 80.089, 3508 TB Utrecht, The Netherlands.  
Affiliation: Department of Computer Science, University of Utrecht,  
Abstract: We define the notion of total algorithms for networks of processes. A total algorithm enforces that a "decision" is taken by a subset of the processes, and that participation of all processes is required to reach this decision. Total algorithms are an important building block in the design of distributed algorithms. For some important network control problems it can be shown that an algorithm solving it is necessarily total, and that any total algorithm can solve the problem. We study some total algorithms for a variety of network topologies. Constructions are shown to derive algorithms for Mutual Exclusion, Election, and Distributed Infimum Approximation from arbitrary total algorithms. The paper puts many results and paradigms about designing distributed algorithms in a general framework. This report outlines several other works of the author. Total algorithms, their properties, and some additional examples, as well as traversal algorithms and the time complexity of distributed algorithms are studied in [Tel94, Chap. 6]. The construction of algorithms for distributed infimum approximation is treated in [CBT94, Tel86] and 
Abstract-found: 1
Intro-found: 1
Reference: [Att87] <author> Attiya, H. </author> <title> Constructing efficient election algorithms from efficient traversal algorithms. </title> <booktitle> In Proc. 2nd Int. Workshop on Distributed Algorithms (Amsterdam, </booktitle> <year> 1987), </year> <editor> J. van Leeuwen (ed.), </editor> <volume> vol. </volume> <booktitle> 312 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 377-344. </pages>
Reference-contexts: Construction 2: (Korach et al., [KKM90]) Starting from a traversal algorithm with message complexity f (N ), Korach et al. construct an Election algorithm with message complexity O ((f (N ) + N ) log s). Construction 3: (Attiya, <ref> [Att87] </ref>) Starting from a traversal algorithm with message complexity f (N ), Attiya constructs an Election algorithm for bidirectional networks with a message complexity of P N k ).
Reference: [Awe85] <author> Awerbuch, B. </author> <title> A new distributed depth first search algorithm. </title> <journal> Inf. Proc. Lett. </journal> <volume> 20 (1985), </volume> <pages> 147-150. </pages>
Reference-contexts: It is sequential, i.e., DDFS is a Traversal algorithm in the sense of [KKM90]. Both its message and time complexity are 2E. The processes need not have distinct identities. Intricate variants with an O (N ) time complexity exist (see e.g. Awerbuch <ref> [Awe85] </ref> or [Tel94]), but these variants are no longer sequential. A version for directed networks exists [GA84]. 4 Mutual Exclusion and Election Mutual Exclusion is a fundamental problem in the design and implementation of parallel and distributed systems.
Reference: [BYKWZ87] <author> Bar-Yehuda, R., Kutten, S., Wolfstahl, Y., and Zaks, S. </author> <title> Making distributed spanning tree algorithms fault-resilient. </title> <booktitle> In Proc. Symp. on Theoretical Aspects of Computer Science (1987), </booktitle> <editor> F. J. Brandenburg et al. (eds.), </editor> <volume> vol. </volume> <booktitle> 247 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 432-444. 24 </pages>
Reference-contexts: For rings and trees similar constructions can be given. fl Many known Election algorithms are total, but non-total ones are also known, for example Peterson's algorithm for grid networks [Pet85] or Bar-Yehuda's alorithm for networks of known size <ref> [BYKWZ87] </ref>. See also section 4.4. 2.5 Traversal The purpose of a traversal algorithm is to pass a token, initiated by a single starter, through every node in the network and return it to the starter. A traversal algorithm is total and centralized by definition. <p> The starter floods a request through the network and decides when it has received replies from bN=2c processes. The message complexity is of the same order as of the REPLY algorithm, but this algorithm is highly fault-tolerant. It is the basis of an Election algorithm by Kutten <ref> [BYKWZ87] </ref>. Algorithm 2: For networks with a designated process L. L replies to received messages by sending a message back. The algorithm for a starter p consists of sending a message to L, and awaiting the reply. Algorithm 2 implements centralized control of the network.
Reference: [CBT94] <author> Charron-Bost, B. and Tel, G. </author> <title> Approximation d'une borne inferieure repartie. </title> <institution> Rapport de Recherche LIX/RR/94/06, Ecole Polytechnique, </institution> <year> 1994. </year> <note> Submitted to RAIRO. </note>
Reference: [Cha82] <author> Chang, E. J.-H. </author> <title> Echo algorithms: Depth parallel operations on general graphs. </title> <journal> IEEE Trans. Softw. Eng. </journal> <volume> SE-8 (1982), </volume> <pages> 391-401. </pages>
Reference-contexts: This number of messages must be added to the message complexity N of the given version of the TREE algorithm. 3.3 ECHO Algorithm A centralized total algorithm for general bidirectional networks. This algorithm is usually referred to as Chang's Echo algorithm <ref> [Cha82] </ref>. The starter sends a message over all links. Followers store the link over which they first received a message as their f ather. Upon receiving their first message followers send a message to all neighbors except their father.
Reference: [Che83] <author> Cheung, T.-Y. </author> <title> Graph traversal techniques and the maximum flow problem in distributed computation. </title> <journal> IEEE Trans. Softw. Eng. </journal> <month> SE-9 </month> <year> (1983), </year> <pages> 504-512. </pages>
Reference-contexts: Their complexity is typically O (N log N ). Peterson's algorithm [Pet82] is noteworthy because it runs on unidirectional rings and has a message complexity of O (N log s), where s is the number of starters. Distributed Depth First Search (DDFS) [Tel94, Sec. 6.4]. The classical DDFS algorithm <ref> [Che83] </ref> is a centralized algorithm for general bidirectional networks. It is sequential, i.e., DDFS is a Traversal algorithm in the sense of [KKM90]. Both its message and time complexity are 2E. The processes need not have distinct identities. Intricate variants with an O (N ) time complexity exist (see e.g.
Reference: [CM88] <author> Chandy, K. M. and Misra, J. </author> <title> Parallel Program Design: A Foundation. </title> <publisher> Addison-Wesley, </publisher> <year> 1988 </year> <month> (516 pp.). </month>
Reference-contexts: Reasoning in this paper was based on considering complete executions and a partial order on the events. This can be seen as an alternative for reasoning about system states only, as advocated for example in <ref> [CM88] </ref>. The partial order allows us to express relations necessary for example in the proof of theorem 2.7. Thus, although it is generally felt to be less error-prone to reason about system states only, it is doubtfull whether all our results could be obtained by it.
Reference: [CR79] <author> Chang, E. J.-H. and Roberts, R. </author> <title> An improved algorithm for decentralized extrema finding in circular arrangements of processes. Commun. </title> <booktitle> ACM 22 (1979), </booktitle> <pages> 281-283. </pages>
Reference-contexts: Let M and T be as before, and s be the number of starters. Then the message and time complexity of the constructed algorithm are now O (sM ) and O (sT ), respectively. The algorithms of Chang and Roberts <ref> [CR79] </ref> is obtained by applying Extinction to the RING algorithm. The algorithm by Hirschberg [Hir80] is obtained by applying Extinction to the ECHO algorithm.
Reference: [Fin79] <author> Finn, S. G. </author> <title> Resynch procedures and a fail-safe network protocol. </title> <journal> IEEE Trans. Commun. </journal> <month> COM-27 </month> <year> (1979), </year> <pages> 840-845. </pages>
Reference-contexts: A formal definition will follow later in this section. We study the relation between total algorithms and a number of network control problems, namely Distributed Infimum computation, Resynchronization <ref> [Fin79] </ref>, Propagation of Information with Feedback [Seg83], Extrema Finding, and Connectivity. For all these problems it will turn out that (1) any solution to these problems is necessarily total, and (2) any total algorithm can be used to solve these problems. <p> decision event correctly signals the completion of the broadcast. fl To decrease the number of bits to be transmitted, we remark that it suffices to append M to the first message that is sent over every link. 2.2 Resynchronization The Resynchronization (or, shortly, Resynch) problem was first described by Finn <ref> [Fin79] </ref>. It asks to bring all processes of P in a special state synch and then bring processes in a state normal. <p> In the Resynch problem we regard the state change to normal as a "decision". (We drop the requirement of <ref> [Fin79] </ref> that all processes decide.) Theorem 2.4 Every Resynch algorithm is total. Proof. Assume R is a Resynch algorithm. By definition it is required that in every execution of R at least one event takes place in every process and in at least one process a decision takes place. <p> The TREE algorithm below is symmetric, but not decentralized. In some algorithms all processes decide, in others only one or few. In the original statement of some problems, e.g., Resynchronization <ref> [Fin79] </ref>, it is explicitly required that all processes decide. If, in some total algorithm, not all processes decide, the deciding process (es) can flood a signal over the network to make other processes decide also. <p> Thus an execution does not come to a halt before all processes have decided. Because only 2N E send, 2N E receive, N addition, and N decision events are possible, it follows that all processes will decide. fl The GOSSIP algorithm is in fact Finn's Resynch algorithm <ref> [Fin79] </ref>. To see this, first observe that always OK HO for all processes and messages. Thus, the two sets can be represented by a vector as follows. In this vector there is an entry for each potential member of P. The entry can be 0, 1, or 2. <p> A second difference is that Finn's algorithm also provides a mechanism to restart the algorithm after a topological change. This mechanism was described separately by Segall [Seg83]. A consequence of the material in this section is that the Resynch problem <ref> [Fin79] </ref> can be solved by an algorithm using fewer messages. In Finn's work bidirectional channels are assumed, so the GOSSIP algorithm can be replaced by e.g. the GHS algorithm. For the resynchronization of unidirectional networks the algorithm of Gafni and Afek [GA84] can be used instead. <p> The concept of total algorithms allows us to abstract away from the network topology when designing an algorithm. The underlying total algorithm is designed separately. Until now, independency of the topology was always achieved by using an algorithm for general networks <ref> [SE85, Fin79, HPR88] </ref>. Our approach combines separation of concerns with the possibility to use more efficient total algorithms whenever a particular topology allows to do so. Reasoning in this paper was based on considering complete executions and a partial order on the events.
Reference: [GA84] <author> Gafni, E. and Afek, Y. </author> <title> Election and traversal in unidirectional networks. </title> <booktitle> In Proc. Symp. on Principles of Distributed Computing (1984), </booktitle> <pages> pp. 190-198. </pages>
Reference-contexts: In Finn's work bidirectional channels are assumed, so the GOSSIP algorithm can be replaced by e.g. the GHS algorithm. For the resynchronization of unidirectional networks the algorithm of Gafni and Afek <ref> [GA84] </ref> can be used instead. An advantage of the GOSSIP algorithm over the others is its low time complexity. The GOSSIP algorithm is decentralized and works on any (directed) network. Processes must have distinct identities. <p> This is a decentralized algorithm for general bidirectional networks. Distinct identities are required. The message complexity is O (N log N + E), which is provably optimal, and its time complexity is O (N log N ). Noteworthy is the adaptation by Gafni and Afek to directed networks <ref> [GA84] </ref>. Many algorithms have been given for Election on (unidirectional) rings. Their complexity is typically O (N log N ). Peterson's algorithm [Pet82] is noteworthy because it runs on unidirectional rings and has a message complexity of O (N log s), where s is the number of starters. <p> Both its message and time complexity are 2E. The processes need not have distinct identities. Intricate variants with an O (N ) time complexity exist (see e.g. Awerbuch [Awe85] or [Tel94]), but these variants are no longer sequential. A version for directed networks exists <ref> [GA84] </ref>. 4 Mutual Exclusion and Election Mutual Exclusion is a fundamental problem in the design and implementation of parallel and distributed systems.
Reference: [Gaf86] <author> Gafni, E. </author> <title> Perspectives on distributed network protocols: A case for building blocks. </title> <booktitle> In Proc. </booktitle> <address> MILCOM (Monterey, California, </address> <year> 1986), </year> <pages> pp. 1-5. </pages>
Reference-contexts: 1 Introduction Modular techniques have been advocated recently to facilitate the design and verification of distributed algorithms. Noteworthy examples are Gafni <ref> [Gaf86] </ref>, Segall [Seg83], and Korach et al. [KKM90]. Modular design techniques not only facilitate the design and ver ification of distributed algorithms, they also show that distributed algorithms for different tasks may share some common aspects.
Reference: [GHS83] <author> Gallager, R. G., Humblet, P. A., and Spira, P. M. </author> <title> A distributed algorithm for minimum weight spanning trees. </title> <journal> ACM Trans. Program. Lang. Syst. </journal> <volume> 5 (1983), </volume> <pages> 67-77. </pages>
Reference-contexts: A centralized total algorithm for complete networks. The starter sends a message to every other process. A follower acknowledges the receipt of a message. The starter decides when it has received enough acknowledgements. The GHS algorithm. Gallager, Humblet, and Spira's algorithm for distributed Minimum Spanning Tree construction <ref> [GHS83] </ref>. This is a decentralized algorithm for general bidirectional networks. Distinct identities are required. The message complexity is O (N log N + E), which is provably optimal, and its time complexity is O (N log N ). Noteworthy is the adaptation by Gafni and Afek to directed networks [GA84].
Reference: [GLT + 85] <author> Gafni, E., Loui, M. C., Tiwari, P., West, D. B., and Zaks, S. </author> <title> Lower bounds on common knowledge in distributed systems. </title> <booktitle> In Proc. Distributed Algorithms on Graphs (1985), </booktitle> <editor> E. Gafni and N. Santoro (eds.), </editor> <publisher> Carleton University Press, </publisher> <pages> pp. 49-67. </pages>
Reference-contexts: To this end it is necessary to make a (technical) restriction on the algorithms considered, namely that they are comparison algorithms. A comparison algorithm is an algorithm that allows comparison as the only operation on identities. For a more precise definition, see Gafni et al. <ref> [GLT + 85] </ref>. Theorem 2.10 Comparison Election algorithms for rings, trees, or general networks of unknown size are total. Proof. We prove the result for general networks.
Reference: [Hir80] <author> Hirschberg, D. S. </author> <title> Election processes in distributed systems. </title> <type> Tech. rep., </type> <institution> Dept Computer Science, Rice University, Houston, Texas, </institution> <year> 1980. </year>
Reference-contexts: Then the message and time complexity of the constructed algorithm are now O (sM ) and O (sT ), respectively. The algorithms of Chang and Roberts [CR79] is obtained by applying Extinction to the RING algorithm. The algorithm by Hirschberg <ref> [Hir80] </ref> is obtained by applying Extinction to the ECHO algorithm. Construction 2: (Korach et al., [KKM90]) Starting from a traversal algorithm with message complexity f (N ), Korach et al. construct an Election algorithm with message complexity O ((f (N ) + N ) log s).
Reference: [HPR88] <author> H elary, J.-M., Plouzeau, N., and Raynal, M. </author> <title> A distributed algorithm for mutual exclusion in an arbitrary network. </title> <journal> Computer J. </journal> <volume> 31 (1988), </volume> <pages> 289-295. </pages>
Reference-contexts: Their algorithm is obtained by applying the superimposition to the REPLY algorithm of section 3. Application of the superimposition to the ECHO algorithm yields an algorithm, very similar to that of Helary et al. <ref> [HPR88] </ref>. The idea of the algorithm is very simple and ressembles the bakery principle. Each request to enter the critical section is assigned a unique identification label v. <p> The concept of total algorithms allows us to abstract away from the network topology when designing an algorithm. The underlying total algorithm is designed separately. Until now, independency of the topology was always achieved by using an algorithm for general networks <ref> [SE85, Fin79, HPR88] </ref>. Our approach combines separation of concerns with the possibility to use more efficient total algorithms whenever a particular topology allows to do so. Reasoning in this paper was based on considering complete executions and a partial order on the events.
Reference: [HR88] <author> H elary, J.-M. and Raynal, M. </author> <title> Un schema (abstrait) d'iteration repartie. </title> <institution> Rapport de Recherche 417, IRISA, Rennes, </institution> <year> 1988. </year>
Reference-contexts: Repeated execution is also required in other applications, such as the algorithm for distributed selection of Santoro et al. [SSS88]. Iteration schemes based on repeated executions of total algorithms were studied also by Helary and Raynal <ref> [HR88] </ref>. In all these applications it is required that subsequent executions of the algorithm are disjoint.
Reference: [KKM90] <author> Korach, E., Kutten, S., and Moran, S. </author> <title> A modular technique for the design of efficient leader finding algorithms. </title> <journal> ACM Trans. Program. Lang. Syst. </journal> <volume> 12 (1990), </volume> <pages> 84-101. </pages>
Reference-contexts: 1 Introduction Modular techniques have been advocated recently to facilitate the design and verification of distributed algorithms. Noteworthy examples are Gafni [Gaf86], Segall [Seg83], and Korach et al. <ref> [KKM90] </ref>. Modular design techniques not only facilitate the design and ver ification of distributed algorithms, they also show that distributed algorithms for different tasks may share some common aspects. <p> A traversal algorithm is total and centralized by definition. For the application of Traversal algorithms in <ref> [KKM90] </ref> it is required that the algorithm is sequential. That is, the starter sends out exactly one message in the beginning, and thereafter a process can only send (at most) one message after receiving a message. <p> Distributed Depth First Search (DDFS) [Tel94, Sec. 6.4]. The classical DDFS algorithm [Che83] is a centralized algorithm for general bidirectional networks. It is sequential, i.e., DDFS is a Traversal algorithm in the sense of <ref> [KKM90] </ref>. Both its message and time complexity are 2E. The processes need not have distinct identities. Intricate variants with an O (N ) time complexity exist (see e.g. Awerbuch [Awe85] or [Tel94]), but these variants are no longer sequential. <p> The algorithms of Chang and Roberts [CR79] is obtained by applying Extinction to the RING algorithm. The algorithm by Hirschberg [Hir80] is obtained by applying Extinction to the ECHO algorithm. Construction 2: (Korach et al., <ref> [KKM90] </ref>) Starting from a traversal algorithm with message complexity f (N ), Korach et al. construct an Election algorithm with message complexity O ((f (N ) + N ) log s).
Reference: [Lam78] <author> Lamport, L. </author> <title> Time, clocks, and the ordering of events in a distributed system. Commun. </title> <booktitle> ACM 21 (1978), </booktitle> <pages> 558-564. </pages>
Reference-contexts: We assume the network is strongly connected and channels are fault free. We consider an execution of an algorithm as a sequence a 1 ; : : : ; a k ; : : : of events (cf. Lamport <ref> [Lam78] </ref>). The occurrence of these events is according to the program that the processes are running: an event takes place in a process only when the program of the process specifies the event and it is enabled. We roughly divide the events in three classes: send, receive and internal events. <p> If this is the case, event a must occur earlier in the sequence of events than event b, because a message can be received only after it is sent. We define a partial order "precedes" on the events in a particular execution as in <ref> [Lam78] </ref>.
Reference: [Mae85] <author> Maekawa, M. </author> <title> A p N algorithm for mutual exclusion in decentralized systems. </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 3 (1985), </volume> <pages> 145-159. </pages>
Reference-contexts: A similar approach can be used in networks whose topology is a projective plane. The message complexity can be O ( p N ). This algorithm underlies the Election algorithm of Peterson [Pet85] (torus) and the Mutual Exclusion algorithm of Maekawa <ref> [Mae85] </ref> (projective plane). 21 5 Distributed Infimum Approximation Distributed Infimum Approximation was defined in [Tel86] as an abstraction of several control problems in distributed systems, including Termination detection and evaluation of Global Virtual Time. Several constructions of algorithms for the problem were given in [Tel86].
Reference: [Pet82] <author> Peterson, G. L. </author> <title> An O(n log n) unidirectional algorithm for the circular extrema problem. </title> <journal> ACM Trans. Program. Lang. Syst. </journal> <volume> 4 (1982), </volume> <pages> 758-762. </pages>
Reference-contexts: Noteworthy is the adaptation by Gafni and Afek to directed networks [GA84]. Many algorithms have been given for Election on (unidirectional) rings. Their complexity is typically O (N log N ). Peterson's algorithm <ref> [Pet82] </ref> is noteworthy because it runs on unidirectional rings and has a message complexity of O (N log s), where s is the number of starters. Distributed Depth First Search (DDFS) [Tel94, Sec. 6.4]. The classical DDFS algorithm [Che83] is a centralized algorithm for general bidirectional networks.
Reference: [Pet85] <author> Peterson, G. L. </author> <title> Efficient algorithms for elections in meshes and complete networks. </title> <type> Tech. Rep. TR 140, </type> <institution> Dept Computer Science, University of Rochester, </institution> <address> Rochester NY 14627, </address> <year> 1985. </year>
Reference-contexts: For rings and trees similar constructions can be given. fl Many known Election algorithms are total, but non-total ones are also known, for example Peterson's algorithm for grid networks <ref> [Pet85] </ref> or Bar-Yehuda's alorithm for networks of known size [BYKWZ87]. See also section 4.4. 2.5 Traversal The purpose of a traversal algorithm is to pass a token, initiated by a single starter, through every node in the network and return it to the starter. <p> This algorithm is dominating because each row crosses each column. A similar approach can be used in networks whose topology is a projective plane. The message complexity can be O ( p N ). This algorithm underlies the Election algorithm of Peterson <ref> [Pet85] </ref> (torus) and the Mutual Exclusion algorithm of Maekawa [Mae85] (projective plane). 21 5 Distributed Infimum Approximation Distributed Infimum Approximation was defined in [Tel86] as an abstraction of several control problems in distributed systems, including Termination detection and evaluation of Global Virtual Time.
Reference: [RA81] <author> Ricart, G. and Agrawala, A. K. </author> <title> An optimal algorithm for mutual exclusion in computer networks. </title> <journal> Commun. ACM 24, </journal> <volume> 1 (1981), </volume> <pages> 9-17. 25 </pages>
Reference-contexts: In this section we will show that a Mutual Exclusion protocol can be obtained by a superimposition on a suitable total algorithm. In fact, the superimposition is a generalization of the Mutual Exclusion algorithm of Ricart and Agrawala <ref> [RA81] </ref>. Their algorithm is obtained by applying the superimposition to the REPLY algorithm of section 3. Application of the superimposition to the ECHO algorithm yields an algorithm, very similar to that of Helary et al. [HPR88]. The idea of the algorithm is very simple and ressembles the bakery principle.
Reference: [SE85] <author> Skyum, S. and Erikson, O. </author> <title> Symmetric distributed termination. In The Book of L, </title> <editor> G. Rozenberg and A. Salomaa (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: The concept of total algorithms allows us to abstract away from the network topology when designing an algorithm. The underlying total algorithm is designed separately. Until now, independency of the topology was always achieved by using an algorithm for general networks <ref> [SE85, Fin79, HPR88] </ref>. Our approach combines separation of concerns with the possibility to use more efficient total algorithms whenever a particular topology allows to do so. Reasoning in this paper was based on considering complete executions and a partial order on the events.
Reference: [Seg83] <author> Segall, A. </author> <title> Distributed network protocols. </title> <journal> IEEE Trans. Inform. Theory IT-29 (1983), </journal> <pages> 23-35. </pages>
Reference-contexts: 1 Introduction Modular techniques have been advocated recently to facilitate the design and verification of distributed algorithms. Noteworthy examples are Gafni [Gaf86], Segall <ref> [Seg83] </ref>, and Korach et al. [KKM90]. Modular design techniques not only facilitate the design and ver ification of distributed algorithms, they also show that distributed algorithms for different tasks may share some common aspects. <p> A formal definition will follow later in this section. We study the relation between total algorithms and a number of network control problems, namely Distributed Infimum computation, Resynchronization [Fin79], Propagation of Information with Feedback <ref> [Seg83] </ref>, Extrema Finding, and Connectivity. For all these problems it will turn out that (1) any solution to these problems is necessarily total, and (2) any total algorithm can be used to solve these problems. <p> Informally, this theorem says that any reordering of the events in an execution that is consistent with the partial ordering , is also a possible execution. 2.1 Propagation of Information with Feedback The problem of Propagation of Information with Feedback (PIF) is explained as follows <ref> [Seg83] </ref>. Starters of a PIF algorithm have a message M . All starters (if there are more 3 than one) have the same message. This message must be broadcast, i.e., all processes must receive and accept M . <p> The following correctness proof is found in <ref> [Seg83] </ref>. Consider a (completed) execution S of the ECHO algorithm and observe that the f ather fields, once given a value 6= nil, are never changed thereafter. <p> Finn uses the algorithm to determine the nodes in one component and synchronize this component only. A second difference is that Finn's algorithm also provides a mechanism to restart the algorithm after a topological change. This mechanism was described separately by Segall <ref> [Seg83] </ref>. A consequence of the material in this section is that the Resynch problem [Fin79] can be solved by an algorithm using fewer messages. In Finn's work bidirectional channels are assumed, so the GOSSIP algorithm can be replaced by e.g. the GHS algorithm.
Reference: [SSS88] <author> Santoro, N., Scheutzow, M., and Sidney, J. B. </author> <title> On the expected complexity of distributed selection. </title> <editor> J. </editor> <booktitle> Parallel and Distributed Computing 5 (1988), </booktitle> <pages> 194-203. </pages>
Reference-contexts: In this case F (S) = inf (fx (S) To compute successive approximations f the execution of a total algorithm, say A, is repeated many times. Repeated execution is also required in other applications, such as the algorithm for distributed selection of Santoro et al. <ref> [SSS88] </ref>. Iteration schemes based on repeated executions of total algorithms were studied also by Helary and Raynal [HR88]. In all these applications it is required that subsequent executions of the algorithm are disjoint.
Reference: [Tel86] <author> Tel, G. </author> <title> Distributed infimum approximation. </title> <type> Tech. Rep. </type> <institution> RUU-CS-86-12, Dept Computer Science, Utrecht University, </institution> <address> The Netherlands, </address> <year> 1986. </year>
Reference-contexts: We will also see that algorithms for Mutual Exclusion and for Distributed Infimum Approximation can be constructed in a generic way, based on arbitrary total algorithms. The problem of Distributed Infimum Approximation (defined in <ref> [Tel86] </ref>) includes both the Termination Detection problem and approximation of Global Virtual Time. Thus the total algorithms are a key concept in the design of network control algorithms. We present a number of total algorithms and some constructions of other algorithms based upon them. This paper is organized as follows. <p> It is easily seen that for all events a i (a) J . It follows that i (d) = J , and the constructed algorithm is correct. fl The problem of Distributed Infimum computation as described here is different from the problem of Distributed Infimum Approximation as described in <ref> [Tel86] </ref>. Here we consider fixed values r p . In the Distributed Infimum Approximation problem changing values x p are considered. The problem of Distributed Infimum Approximation is briefly addressed in section 5. <p> The message complexity can be O ( p N ). This algorithm underlies the Election algorithm of Peterson [Pet85] (torus) and the Mutual Exclusion algorithm of Maekawa [Mae85] (projective plane). 21 5 Distributed Infimum Approximation Distributed Infimum Approximation was defined in <ref> [Tel86] </ref> as an abstraction of several control problems in distributed systems, including Termination detection and evaluation of Global Virtual Time. Several constructions of algorithms for the problem were given in [Tel86]. <p> the Mutual Exclusion algorithm of Maekawa [Mae85] (projective plane). 21 5 Distributed Infimum Approximation Distributed Infimum Approximation was defined in <ref> [Tel86] </ref> as an abstraction of several control problems in distributed systems, including Termination detection and evaluation of Global Virtual Time. Several constructions of algorithms for the problem were given in [Tel86]. This section contains a brief overview of the material contained in that paper. 5.1 Definition of the Problem Each process p is equipped with a variable x p with values in a partially ordered domain X. <p> Proof. Let i be the number of the first execution of A that starts after F k. Now for all p r (i+1) p k so after completion of the (i + 1) th execution f k. fl Examples of these constructions are found in <ref> [Tel86] </ref> and [Tel91]. 23 6 Conclusions Total algorithms are an important building block in the design of distributed algorithms for a wide range of network problems.
Reference: [Tel91] <author> Tel, G. </author> <booktitle> Topics in Distributed Algorithms, vol. 1 of Cambridge Int. Series on Parallel Computation. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1991 </year> <month> (240 pp.). </month>
Reference-contexts: Thus there is always an event enabled until all processes have decided. Furthermore, only a finite number of events can take place, namely DE send, DE receive, and N decide events. It follows that all processes will decide. fl The PHASE algorithm is studied further in <ref> [Tel91, Sec 4.2.3] </ref>. The algorithm is decentralized and works on any (directed) network. It is required that (an upper bound for) the network diameter is known. The processes need not have distinct identities. The message complexity is DE, the time complexity of the PHASE algorithm is D. <p> Proof. Let i be the number of the first execution of A that starts after F k. Now for all p r (i+1) p k so after completion of the (i + 1) th execution f k. fl Examples of these constructions are found in [Tel86] and <ref> [Tel91] </ref>. 23 6 Conclusions Total algorithms are an important building block in the design of distributed algorithms for a wide range of network problems.
Reference: [Tel94] <author> Tel, G. </author> <title> Introduction to Distributed Algorithms. </title> <publisher> Cambridge University Press, </publisher> <year> 1994. </year>
Reference-contexts: We use the following well-known fact about asynchronous systems (which can be seen as the characterizing property of asynchronous systems) to show that algorithms for some problems are necessarily total. A proof is found in <ref> [Tel94, Sec. 2.3] </ref>. Fact 2.1 Let a 1 ; : : : ; a k be a (finite) execution of some algorithm A and let a (1) ; : : : ; a (k) be a permutation of the events such that a (i) a (j) implies i j. <p> Their complexity is typically O (N log N ). Peterson's algorithm [Pet82] is noteworthy because it runs on unidirectional rings and has a message complexity of O (N log s), where s is the number of starters. Distributed Depth First Search (DDFS) <ref> [Tel94, Sec. 6.4] </ref>. The classical DDFS algorithm [Che83] is a centralized algorithm for general bidirectional networks. It is sequential, i.e., DDFS is a Traversal algorithm in the sense of [KKM90]. Both its message and time complexity are 2E. The processes need not have distinct identities. <p> It is sequential, i.e., DDFS is a Traversal algorithm in the sense of [KKM90]. Both its message and time complexity are 2E. The processes need not have distinct identities. Intricate variants with an O (N ) time complexity exist (see e.g. Awerbuch [Awe85] or <ref> [Tel94] </ref>), but these variants are no longer sequential. A version for directed networks exists [GA84]. 4 Mutual Exclusion and Election Mutual Exclusion is a fundamental problem in the design and implementation of parallel and distributed systems.
References-found: 28

