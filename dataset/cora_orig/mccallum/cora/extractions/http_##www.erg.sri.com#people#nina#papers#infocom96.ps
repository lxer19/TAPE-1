URL: http://www.erg.sri.com/people/nina/papers/infocom96.ps
Refering-URL: http://www.erg.sri.com/people/nina/papers/
Root-URL: 
Title: Neural Network Methods with Traffic Descriptor Compression for Call Admission Control  
Author: Richard Ogier and Nina T. Plotkin Irfan Khan 
Address: Menlo Park, CA 94025 San Diego, CA  
Affiliation: SRI International Qualcomm Inc.  
Abstract: We present and evaluate new techniques for call admission control based on neural networks. The methods are applicable to very general models that allow heterogeneous traffic sources and finite buffers. A feedforward neural network (NN) is used to predict whether or not accepting a requested new call would result in a feasible aggregate stream, i.e., one that satisfies the QOS requirements. The NN input vector is a traffic descriptor for the aggregate stream that has the following beneficial properties: its dimension is independent of the number of traffic classes; and it is additive, allowing it to be updated efficiently by simply adding the traffic descriptor of the new call. A novel asymmetric error function for the NN helps achieve our asymmetric objective in which rejecting an infeasible stream is more important than accepting a feasible one. We present an NN design that provides an optimal linear compression of the NN inputs to a smaller number of traffic parameters. The special case of one compressed parameter corresponds to an NN version of equivalent bandwidth. Experiments show our methods to be better than methods based on equivalent bandwidth, with respect to call blocking probability, throughput, and the percentage of feasible streams that are correctly classified. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Elwalid and D. Mitra. </author> <title> Effective Bandwidth of General Markovian Traffic Sources and Admission Control of High Speed Networks. </title> <booktitle> IEEE In-focom Proceedings, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: For example, Elwalid and Mitra <ref> [1] </ref> present a solution in which the traffic descriptor is a single parameter called "equivalent bandwidth." Their method assumes heterogeneous Markov-modulated fluid sources or Markov-modulated Poisson sources, which are fed into a single buffer served by a constant-rate channel. <p> Section 2 states our model assumptions and objectives. Section 3 develops our basic NN design, and Section 4 presents the NN method that performs linear compression to reduce the number of traffic parameters. In Section 5 we discuss equivalent bandwidth techniques <ref> [1] </ref>. Here we introduce our modified version of equivalent bandwidth, in which the decision threshold is selected based on the traffic data in the training set. In Section 6 we provide the results of experiments that compare our different neural network designs and investigate how many compressed parameters are required. <p> We call a measure of EB exact if it never under-allocates or overallocates bandwidth. The method in <ref> [1] </ref> is exact only asymptotically, for buffer sizes that approach infinity and CLRs that approach zero. For finite buffer sizes, this method always overallocates bandwidth, and will therefore never accept an infeasible stream. <p> Recall that the decision threshold for our NN methods is chosen based on the training set: It is chosen as small as possible while ensuring that no infeasible streams in the training set are accepted. This motivates us to define a modified equivalent bandwidth (MEB) method, based on <ref> [1] </ref>, except that the decision threshold (which is normally the channel capacity) is increased as much as possible while still ensuring that no infeasible streams in the training set are accepted. As a result, the MEB method accepts more feasible streams than the EB method. <p> For the target CLR we used 10 3 . For 1000 of the 2000 training vectors, the number N of calls per stream was selected at random from a uniform probability distribution over the interval <ref> [1; 64] </ref>. For the other 1000 training vectors, N was selected from a binomial distribution with mean E (N ) = 32. This last step was done in order to generate more streams close to the boundary of the feasible region. <p> This way each individual stream, on average, contributes an equal amount to the total aggregate stream. This results in an average cell rate of 0.075 cells/slot for a single source. The average burst size is chosen from a uniform distribution over the interval <ref> [1; 2B 1] </ref> where B denotes the average burst size. An average burst size of 500 cells was chosen because this is close to the average number of bytes/frame in the coded video from the Star Wars movie as reported in [2].
Reference: [2] <author> M. Garrett and W. Willinger. </author> <title> Analysis, Modeling and Generation of Self-Similar VBR Video Traffic. </title> <booktitle> ACM SigComm Proceedings, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: An average burst size of 500 cells was chosen because this is close to the average number of bytes/frame in the coded video from the Star Wars movie as reported in <ref> [2] </ref>. We considered buffer sizes that range from 2000 to 5000 cells.
Reference: [3] <author> R. Guerin, H. Ahmadi, and M. Naghshineh. </author> <title> Equivalent Capacity and Its Application to Band-with Allocation in High-Speed Networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> September </month> <year> 1991. </year>
Reference-contexts: This method is exact only asymptotically, as the buffer size approaches infinity and the CLR approaches zero. Other CAC methods based on the concept of equivalent bandwidth also exist, e.g., <ref> [3] </ref>. Neural networks have previously been applied to ATM networks. Using NNs for the call admission control problem was studied in [9, 8].
Reference: [4] <author> S. Haykin. </author> <title> Neural Networks, A Comprehensive Foundation. </title> <publisher> Macmillan Publishing Company, </publisher> <year> 1994. </year>
Reference-contexts: Based on these inputs, the output of the NN classifies each aggregate stream as being Appeared in: IEEE Infocom Proceedings, March 1996 2 feasible (accept) or infeasible (reject). Because of an NN's ability to approximate any piecewise-continuous function with arbitrary accuracy, given enough hidden neurons <ref> [4] </ref>, the NN can be trained to accurately classify the streams using a representative set of observed input-output pairs. Since the neural network is trained on observed data, no assumptions need to be made for the traffic model or the network model. <p> Let Y denote the actual output for input (u and let e = D Y denote the output error. The neural network is trained using a variation of the backpropagation algorithm (e.g., <ref> [4] </ref>), which involves adjusting the NN weights and biases in an attempt to minimize some function of the output errors, most commonly the mean squared error. The training pairs can be obtained either from simulations or from actual network measurements. <p> The training pairs can be obtained either from simulations or from actual network measurements. It has been proven that, if the number of hidden neurons is sufficiently large, then a feedforward NN with a single hidden layer can approximate any piecewise-continuous function to arbitrary accuracy (e.g., see <ref> [4] </ref>). Therefore, in theory, the NN method should be able to solve the general CAC problem with arbitrary accuracy. However, the NN input vector must be defined so that the desired output is determinable from the input; otherwise, the training input-output pairs may not even correspond to a function. <p> A linear compression of the NN inputs can be obtained using principal components analysis <ref> [4] </ref>. This method provides a linear compression to a given number of parameters such that the original inputs can be approximated from the compressed parameters with minimimum mean squared error. However, this method does not attempt to minimize the error in the NN output. <p> This method was motivated by the well-known technique of using a hidden layer of linear neurons for image or data compression <ref> [4, 7] </ref>. Assuming that NN weights (including the ff ki ) are found that minimize the output error function, the compressed parameters v i are optimal by definition. Once this NN is trained and thus the linear transformation is found, the original input layer is no longer required.
Reference: [5] <author> H. Heffes and D. Lucantoni. </author> <title> A Markov Modulated Characterization of Packetized Voice and Data Traffic and Related Statistical Multiplexer Performance. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> September </month> <year> 1986. </year>
Reference-contexts: An aggregate stream is defined to be feasible if the network can satisfy the QoS constraint for all the calls that compose the stream, and infeasible otherwise. For the general model we consider, which includes highly heterogeneous traffic and finite buffers, this problem is analytically intractable <ref> [5, 6] </ref>, and so we can only hope to obtain approximate solutions. <p> The VOC traffic descriptor is an unnormalized IDC as described by Heffes and Lucantoni in <ref> [5] </ref>, that is, V OC S (m) = IDC S (m) S . <p> We use the VOCs because they characterize all second-order statistics of the stream, because they are additive, and because moments of interval counts have been shown to accurately predict queuing delay for some models <ref> [5] </ref>. One could also use third central moments of interval counts as NN inputs, which may improve the performance of the method. To limit the number of NN inputs while considering a representative set of VOCs, we use VOCs over intervals of exponentially increasing length. It is known [5] that IDC <p> some models <ref> [5] </ref>. One could also use third central moments of interval counts as NN inputs, which may improve the performance of the method. To limit the number of NN inputs while considering a representative set of VOCs, we use VOCs over intervals of exponentially increasing length. It is known [5] that IDC S (m) converges to var (X)=E 2 (X), the squared coefficient of variation of the interarrival time X, and so V OC S (m) also converges to a constant if the interarrival time has finite variance.
Reference: [6] <author> J. Hyman, A. Lazar, and G. Pacifici. </author> <title> A Separation Principle Between Scheduling and Admission Control for Broadband Switching. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> May </month> <year> 1993. </year>
Reference-contexts: An aggregate stream is defined to be feasible if the network can satisfy the QoS constraint for all the calls that compose the stream, and infeasible otherwise. For the general model we consider, which includes highly heterogeneous traffic and finite buffers, this problem is analytically intractable <ref> [5, 6] </ref>, and so we can only hope to obtain approximate solutions. <p> This choice of inputs has been used by other researchers <ref> [9, 6, 8] </ref>. This choice of inputs should work well if the number of traffic classes is small. However, in actual networks there could be hundreds of such classes, which would require a very complex NN, and would also require a large number of variables to characterize each stream. <p> In our experiments we use R = 1 for all sources; thus, each traffic class i is specified by the pair ( i ; ff i ). Since we choose both i and ff i randomly from preselected distributions, the number of traffic classes is unrestricted. In <ref> [6] </ref> it was observed that the feasible region is highly dependent upon the traffic mix. It is thus reasonable to assume that, as the amount of heterogeneity among traffic sources increases, the feasible region becomes increasingly more difficult to estimate.
Reference: [7] <author> T. </author> <title> Masters. Practical Neural Network Recipes in C++. </title> <publisher> Academic Press, </publisher> <year> 1993. </year>
Reference-contexts: This method was motivated by the well-known technique of using a hidden layer of linear neurons for image or data compression <ref> [4, 7] </ref>. Assuming that NN weights (including the ff ki ) are found that minimize the output error function, the compressed parameters v i are optimal by definition. Once this NN is trained and thus the linear transformation is found, the original input layer is no longer required.
Reference: [8] <author> J. Neves, L. de Almeida, and M. Leitao. </author> <title> B-ISDN Connection Admission Control and Routing Strategy with Traffic Prediction by Neural Networks. </title> <booktitle> ICC Proceedings, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Other CAC methods based on the concept of equivalent bandwidth also exist, e.g., [3]. Neural networks have previously been applied to ATM networks. Using NNs for the call admission control problem was studied in <ref> [9, 8] </ref>. These methods assume a small number of traffic classes, where all calls belonging to the same class have exactly the same statistical characteristics (including peak rate and mean rate). <p> The input to the NN is the vector that gives the number of calls of each class contained in the aggregate stream (or as in <ref> [8] </ref> the amount of bandwidth allocated to each class), and the output of the NN predicts the average delay. Experiment results are presented for examples with two or three classes. <p> This choice of inputs has been used by other researchers <ref> [9, 6, 8] </ref>. This choice of inputs should work well if the number of traffic classes is small. However, in actual networks there could be hundreds of such classes, which would require a very complex NN, and would also require a large number of variables to characterize each stream.
Reference: [9] <author> R. Morris and B. Samadi. </author> <title> Neural Networks in Communications: Admission Control and Switch Control. </title> <booktitle> ICC Proceedings, </booktitle> <year> 1991. </year>
Reference-contexts: Other CAC methods based on the concept of equivalent bandwidth also exist, e.g., [3]. Neural networks have previously been applied to ATM networks. Using NNs for the call admission control problem was studied in <ref> [9, 8] </ref>. These methods assume a small number of traffic classes, where all calls belonging to the same class have exactly the same statistical characteristics (including peak rate and mean rate). <p> This choice of inputs has been used by other researchers <ref> [9, 6, 8] </ref>. This choice of inputs should work well if the number of traffic classes is small. However, in actual networks there could be hundreds of such classes, which would require a very complex NN, and would also require a large number of variables to characterize each stream.
Reference: [10] <author> A. Tarraf, I. Habib, and T. Saadawi. </author> <title> A Novel Neural Network Traffic Enforcement Mechanism for ATM Networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> August </month> <year> 1994. </year> <note> Appeared in: IEEE Infocom Proceedings, </note> <month> March </month> <year> 1996 </year>
Reference-contexts: Experiment results are presented for examples with two or three classes. In <ref> [10] </ref> they use NNs for traffic policing by training an NN to learn the entire distribution of each source's traffic process. These methods do not scale well as the number of traffic classes grows.
References-found: 10

