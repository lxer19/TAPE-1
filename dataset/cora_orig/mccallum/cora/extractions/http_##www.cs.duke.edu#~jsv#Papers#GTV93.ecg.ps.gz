URL: http://www.cs.duke.edu/~jsv/Papers/GTV93.ecg.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node10.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: External-Memory Computational Geometry (Preliminary Version)  
Author: Michael T. Goodrich Jyh-Jong Tsay Darren Erik Vengroff Jeffrey Scott Vitter 
Address: Baltimore, MD 21218  Providence, RI 02912-1910 Durham, NC 27708-0129 Chiayi 621, Taiwan, ROC  
Affiliation: Dept. of Computer Science Dept. of Computer Science Dept. of Computer Science Dept. of Computer Science The Johns Hopkins University and Information Engineering Brown University Duke University  National Chung Cheng University  
Abstract: In this paper we give new techniques for designing efficient algorithms for computational geometry problems that are too large to be solved in internal memory. We use these techniques to develop optimal and practical algorithms for a number of important large-scale problems. We discuss our algorithms primarily in the context of single processor/single disk machines, a domain in which they are not only the first known optimal results but also of tremendous practical value. Our methods also produce the first known optimal algorithms for a wide range of two-level and hierarchical multilevel memory models, including parallel models. The algorithms are optimal both in terms of I/O cost and internal computation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, B. Alpern, A. K. Chandra, and M. Snir, </author> <title> "A Model for Hierarchical Memory," </title> <booktitle> Proc. 19th ACM STOC (1987), </booktitle> <pages> 305-314. </pages>
Reference-contexts: More significantly, the paradigms described in this paper continue to work even when parallelism is added and D and P increase. Furthermore, they can be made to work optimally on hierarchical models having more than two levels; these include the well known HMM <ref> [1] </ref>, BT [2], and UMH [4] (pictured in Figure 2), and their parallelizations [27,38] (pictured in Details of the algorithms for these models are discussed in the full version of this paper.
Reference: [2] <author> A. Aggarwal, A. Chandra, and M. Snir, </author> <title> "Hierarchical Memory with Block Transfer," </title> <booktitle> Proc. 28th IEEE FOCS (1987), </booktitle> <pages> 204-216. </pages>
Reference-contexts: More significantly, the paradigms described in this paper continue to work even when parallelism is added and D and P increase. Furthermore, they can be made to work optimally on hierarchical models having more than two levels; these include the well known HMM [1], BT <ref> [2] </ref>, and UMH [4] (pictured in Figure 2), and their parallelizations [27,38] (pictured in Details of the algorithms for these models are discussed in the full version of this paper.
Reference: [3] <author> A. Aggarwal and J. S. Vitter, </author> <title> "The Input/Output Complexity of Sorting and Related Problems," </title> <booktitle> Comm. ACM 31 (1988), </booktitle> <pages> 1116-1127. </pages>
Reference: [4] <author> B. Alpern, L. Carter, E. Feig, and T. Selker, </author> <title> "The Uniform Memory Hierarchy Model of Computation," </title> <note> Proc. 31st IEEE FOCS (1990), To appear in Algo-rithmica. </note>
Reference-contexts: More significantly, the paradigms described in this paper continue to work even when parallelism is added and D and P increase. Furthermore, they can be made to work optimally on hierarchical models having more than two levels; these include the well known HMM [1], BT [2], and UMH <ref> [4] </ref> (pictured in Figure 2), and their parallelizations [27,38] (pictured in Details of the algorithms for these models are discussed in the full version of this paper.
Reference: [5] <author> M. J. Atallah and J. -J. Tsay,, </author> <title> "On the Parallel-Decomposability of Geometric Problems," </title> <booktitle> Algorith-mica 8 (1992), </booktitle> <pages> 209-231. </pages>
Reference-contexts: A i is the set of points in fl i for which we do not yet have either a certificate or a definite answer as to the identity of FN b (p). The following lemma, due to Atallah and Tsay <ref> [5] </ref> bounds the size of A i . Lemma 2.1 [5]: At all times during the sweep, jA i j 4 for all fl i . <p> The following lemma, due to Atallah and Tsay <ref> [5] </ref> bounds the size of A i . Lemma 2.1 [5]: At all times during the sweep, jA i j 4 for all fl i . <p> To a large extent they are based on modified versions of two of the main paradigms discussed above, namely distribution sweeping and batch filtering. We can also rely on the many-way divide-and-conquer approach of Atallah and Tsay <ref> [5] </ref>, which can be extended to the I/O model. To implement distribution sweeping in these models we take advantage of the practical and optimal deterministic distribution techniques recently developed by Nodine and Vitter [27] for sorting.
Reference: [6] <author> R. Bayer and E. McCreight, </author> <title> "Organization of Large Ordered Indexes," </title> <journal> Acta Inform. </journal> <volume> 1 (1972), </volume> <pages> 173-189. </pages>
Reference: [7] <author> B. Chazelle and L. J. Guibas, "Fractional Cascading: I. </author> <title> A Data Structuring Technique," </title> <booktitle> Algorithmica 1 (1986), </booktitle> <pages> 133-162. </pages>
Reference: [8] <author> B. Chazelle and L. J. Guibas, </author> <title> "Fractional Cascading: II. </title> <booktitle> Applications," Algorithmica 1 (1986), </booktitle> <pages> 163-191. </pages>
Reference: [9] <author> D. Comer, </author> <title> "The Ubiquitous B-tree," </title> <journal> Comput. Surveys 11 (1979), </journal> <pages> 121-137. </pages>
Reference: [10] <author> R. F. Cromp, </author> <title> "An Intellegent Information Fusion System for Handling the Archiving and Querying of Terabyte-sized Spatial Databases," in Report on the Workshop on Data and Image Compression Needs and Uses in the Scientific Community, </title> <editor> S. R. Tate, ed., </editor> <booktitle> CESDIS Technical Report Series #TR-93-99, CESDIS, </booktitle> <year> 1993, </year> <pages> 75-84. </pages>
Reference-contexts: As an example, NASA's soon-to-be petabyte-sized databases are expected to facilitate a variety of complex geometric queries <ref> [10] </ref>. Important operations on geometric data include range queries, constructing convex hulls, nearest neighbor calculations, finding intersections, and ray tracing, to name but a few. 1.1 Our I/O model In I/O systems, data are usually transferred in units of blocks, which may consist of several kilobytes.
Reference: [11] <author> J. R. Driscoll, N. Sarnak, D. D. Sleator, and R. E. Tarjan, </author> <title> "Making Data Structures Persistent," </title> <journal> J. Comput. System Sci. </journal> <volume> 38 (1989), </volume> <pages> 86-124. </pages>
Reference-contexts: For batched problems this gives a factor of B improvement over the generic persis tence techniques of Driscoll et al. <ref> [11] </ref>; * batch filtering: a general method for performing K simultaneous external-memory searches in data structures that can be modeled as planar layered dags and in certain fractional cascaded data struc tures; * on-line filtering : A technique based on the work of Tamassia and Vitter [35] that allows I/O optimal <p> In some cases, however, it may be advantageous to be able to access previous versions of the data structure. Being able to access such previous versions is known as persistence, and there exist very general techniques for making most data structures persistent <ref> [11] </ref>. Persistence can be implemented either in an on-line fashion (i.e., where the tree updates are coming on-line) or in an off-line fashion (i.e., where one is given the sequence of tree updates in advance). For the on-line case, the method of Driscoll et al. Lspace [11] can be applied to <p> most data structures persistent <ref> [11] </ref>. Persistence can be implemented either in an on-line fashion (i.e., where the tree updates are coming on-line) or in an off-line fashion (i.e., where one is given the sequence of tree updates in advance). For the on-line case, the method of Driscoll et al. Lspace [11] can be applied to hysterical B-trees as described by Maier and Salveter [26]. Since it is on-line, this structure requires O (N log -) I/Os to construct, which is optimal in an on-line setting.
Reference: [12] <author> G. Gibson, L. Hellerstein, R. M. Karp, R. H. Katz, and D. A. Patterson, </author> <title> "Coding Techniques for Handling Failures in Large Disk Arrays," </title> <editor> U. C. </editor> <address> Berkeley, UCB/CSD 88/477, </address> <month> December </month> <year> 1988. </year>
Reference: [13] <author> D. Gifford and A. Spector, </author> <title> "The TWA Reservation System," </title> <journal> Comm. </journal> <note> ACM 27 (July 1984), 650-665. </note>
Reference: [14] <author> M. H. Goodrich, </author> <title> "Geometric Partioning Made Easier, Even in Parallel," </title> <booktitle> Proc. 9th ACM Comp. </booktitle> <address> Geo. </address> <year> (1993). </year>
Reference-contexts: If desired, the randomization in our algorithm can be removed by an external memory implementation of the technique in <ref> [14] </ref>. Details are omitted for brevity. In the full version of this paper we demonstrate how, for problems of any reasonable practical size, we can improve upon this algorithm by using samples of size instead of N " .
Reference: [15] <author> M. T. Goodrich, </author> <title> "Constructing the Convex Hull of a Partially Sorted Set of Points," Computational Geometry: </title> <booktitle> Theory and Applications 2 (1993), </booktitle> <pages> 267-278. </pages>
Reference-contexts: We use the techniques of [3,37] to divide the set of input points into s = d p e buckets divided by vertical lines. We then use an external-memory implementation of a method of Goodrich <ref> [15] </ref> for combining prune-and-search bridge finding [22] with the Graham scan technique [16] to find all the upper hull edges intersecting our given vertical lines. Our implementation uses O (-) I/Os.
Reference: [16] <author> R. L. Graham, </author> <title> "An Efficient Algorithm for Determining the Convex Hull of a Finite Planar Set," </title> <journal> Inform. Process. Lett. </journal> <volume> 1 (1972), </volume> <pages> 132-133. </pages>
Reference-contexts: A simple way to solve the problem optimally in external memory is to modify one of the main memory approaches, namely Graham's scan <ref> [16] </ref>. Graham's scan requires that we sort the points, which can be done in O (- log -) I/O operations, and then scan linearly through them, at times backtracking, but only over each input point at most once. <p> We use the techniques of [3,37] to divide the set of input points into s = d p e buckets divided by vertical lines. We then use an external-memory implementation of a method of Goodrich [15] for combining prune-and-search bridge finding [22] with the Graham scan technique <ref> [16] </ref> to find all the upper hull edges intersecting our given vertical lines. Our implementation uses O (-) I/Os. Given these hull edges we may then re-curse on any buckets that are not completely spanned by the hull edges we just discovered.
Reference: [17] <author> L. J. Guibas and J. Stolfi, </author> <title> "Primitives for the Manipulation of General Subdivisions and the Computation of Voronoi Diagrams," </title> <journal> ACM Trans. Graphics 4 (1985), </journal> <pages> 74-123 </pages> . 
Reference-contexts: In this section we will examine the problem in external memory for two and three dimensions. The three-dimensional case is particularly interesting because of the number of two-dimensional geometric structures closely related to it, such as Voronoi diagrams and Delaunay triangulations. In fact, by well-known reductions <ref> [17] </ref>, our 3-d convex hull algorithm immediately gives external-memory algorithms for planar Voronoi diagrams and Delaunay triangulations with the same I/O performance.
Reference: [18] <author> W. Jilke, </author> <title> "Disk Array Mass Storage Systems: The New Opportunity," </title> <publisher> Amperif Corporation, </publisher> <month> Septem-ber </month> <year> 1986. </year>
Reference: [19] <author> P. C. Kanellakis, G. M. Kuper, and P. Z. Revesz, </author> <title> "Constraint Query Languages," </title> <booktitle> Proc. 9th ACM PODS (1990), </booktitle> <pages> 299-313. </pages>
Reference: [20] <author> P. C. Kanellakis, S. Ramaswamy, D. E. Vengroff, and J. S. Vitter, </author> <title> "Indexing for Data Models with Constraints and Classes," </title> <booktitle> Proc. 12th ACM PODS (1993), </booktitle> <pages> 233-243. </pages>
Reference-contexts: structure for 2-d on-line range queries that achieves O (log B - + t ) I/Os for updates and range queries using O (-) blocks of space? (The off-line version of the problem is solved optimally in this paper.) Updates and three-sided range queries can be handled by metablock trees <ref> [20] </ref> in O (log B - + log B + t ) I/Os using O (-) space. <p> Two-sided range queries anchored on the diagonal can be done in O (log B - + t ) I/Os per query and O (log B - + (log B -) 2 =B) I/Os per (semidynamic) insertion <ref> [20] </ref>. * Can an N -vertex polygon be triangulated using O (N=B) I/Os? Under what conditions? * Can we find all intersecting pairs of N non orthogonal segments using O (- log - + t ) I/Os? Acknowledgments Figures 1, 2, and 3 were borrowed from [27] with our appreciation.
Reference: [21] <author> R. M. Karp, </author> <title> "Probabilistic Recurrence Relations," </title> <booktitle> Proc. 23rd ACM STOC (1991), </booktitle> <pages> 190-197. </pages>
Reference-contexts: In the recurrence the jS i j terms are actually random variables. It suffices to use Karp's method for solving probabilistic recurrence relations <ref> [21] </ref> to get the optimal solution T (n) = O (- log -) with high probability.
Reference: [22] <author> D. G. Kirkpatrick and R. Seidel, </author> <title> "The Ultimate Planar Convex Hull Algorithm?," </title> <journal> SIAM J. Comput. </journal> <volume> 15 (1986), </volume> <pages> 287-299. </pages>
Reference-contexts: cascaded data struc tures; * on-line filtering : A technique based on the work of Tamassia and Vitter [35] that allows I/O optimal on-line queries in fractional cascaded data struc tures based on balanced binary trees. * external marriage-before-conquest: an external-memory analog to the well-known technique of Kirkpatrick and Seidel <ref> [22] </ref> for performing output sensitive hull constructions. <p> We develop an output-sensitive algorithm based upon an external-memory version of the marriage-before-conquest paradigm of Kirkpatrick and Seidel <ref> [22] </ref>. <p> We use the techniques of [3,37] to divide the set of input points into s = d p e buckets divided by vertical lines. We then use an external-memory implementation of a method of Goodrich [15] for combining prune-and-search bridge finding <ref> [22] </ref> with the Graham scan technique [16] to find all the upper hull edges intersecting our given vertical lines. Our implementation uses O (-) I/Os. Given these hull edges we may then re-curse on any buckets that are not completely spanned by the hull edges we just discovered.
Reference: [23] <author> D. E. Knuth, </author> <booktitle> The Art of Computer Programming, Volume 2: Seminumerical Algorithms, </booktitle> <publisher> Addison Wes-ley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: Step 1 can be completed with O (- log -) I/Os by making a linear pass through S for each sample, as suggested by Knuth <ref> [23] </ref>. Step 2 consists of recursive calls that will be considered later. In Step 3 we decompose each S j into cones using a plane sweep. This takes O ((jS j j=B) log (jS j j=B)) I/Os.
Reference: [24] <author> R. Laurini and D. Thompson, </author> <title> Fundamentals of Spatial Information Systems, A.P.I.C. Series, </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference: [25] <author> N. B. Maginnis, </author> <title> "Store More, Spend Less: MidRange Options Around," </title> <type> Computerworld (November 16, </type> <year> 1987), </year> <pages> 71-82. </pages>
Reference: [26] <author> D. Maier and S. C. Salveter, </author> <title> "Hysterical B-trees," </title> <journal> Inform. Process. Lett. </journal> <volume> 12 (1981), </volume> <pages> 199-202. </pages>
Reference-contexts: For the on-line case, the method of Driscoll et al. Lspace [11] can be applied to hysterical B-trees as described by Maier and Salveter <ref> [26] </ref>. Since it is on-line, this structure requires O (N log -) I/Os to construct, which is optimal in an on-line setting. Unfortunately, this is a factor of B away from optimal for the sort of batch geometric problems we would like to consider.
Reference: [27] <author> M. H. Nodine and J. S. Vitter, </author> <title> "Deterministic Distribution Sort in Shared and Distributed Memory Multiprocessors," </title> <booktitle> Proc. 5th ACM SPAA (1993), </booktitle> <pages> 120-129. </pages>
Reference-contexts: We can also rely on the many-way divide-and-conquer approach of Atallah and Tsay [5], which can be extended to the I/O model. To implement distribution sweeping in these models we take advantage of the practical and optimal deterministic distribution techniques recently developed by Nodine and Vitter <ref> [27] </ref> for sorting. To implement batch filtering, we can use disk striping [28]. 8 Conclusion We have given a number of paradigms for external-memory computational geometry that yield the first known I/O optimal algorithms for several interesting large-scale problems in computational geometry. <p> I/Os per (semidynamic) insertion [20]. * Can an N -vertex polygon be triangulated using O (N=B) I/Os? Under what conditions? * Can we find all intersecting pairs of N non orthogonal segments using O (- log - + t ) I/Os? Acknowledgments Figures 1, 2, and 3 were borrowed from <ref> [27] </ref> with our appreciation.
Reference: [28] <author> D. A. Patterson, G. Gibson, and R. H. Katz, </author> <title> "A Case for Redundant Arrays of Inexpensive Disks (RAID)," </title> <booktitle> Proc. 1988 ACM SIGMOD (1988), </booktitle> <pages> 109-116. </pages>
Reference-contexts: To implement distribution sweeping in these models we take advantage of the practical and optimal deterministic distribution techniques recently developed by Nodine and Vitter [27] for sorting. To implement batch filtering, we can use disk striping <ref> [28] </ref>. 8 Conclusion We have given a number of paradigms for external-memory computational geometry that yield the first known I/O optimal algorithms for several interesting large-scale problems in computational geometry.
Reference: [29] <author> F. P. Preparata and S. J. Hong, </author> <title> "Convex Hulls of Finite Sets of Points in Two and Three Dimensions," </title> <booktitle> Comm. ACM 20 (1977), </booktitle> <pages> 87-93. </pages>
Reference-contexts: the total number of I/Os is O (- log t ), which is optimal for any value of T . 6.3 Three-dimensional convex hulls Even in main memory, space sweeping algorithms fail to solve the 3-d convex hull problem, and we must resort to more advanced divide and conquer approaches <ref> [29] </ref>. One idea is to use a plane to partition the points into equally sized sets, recursively construct the convex hull for each set, and then merge the recursive solutions together in linear time.
Reference: [30] <author> F. P. Preparata and M. I. Shamos, </author> <title> Computational Geometry: An Introduction, </title> <publisher> Springer-Verlag, </publisher> <address> New York-Heidelberg-Berlin, </address> <year> 1985. </year>
Reference-contexts: problems in which there are no queries as part of the problem instance, we use K = 0 (and thus = 0); if the output (solution) size is fixed, we use T = 1 (and thus t = 1=B = o (1)). 2 Distribution sweeping The well-known plane sweep paradigm <ref> [30] </ref> is a powerful approach for developing computational geometry algorithms that are efficient in terms of internal computation. <p> For problems to which this technique is typically applied, this performance is optimal. An example of this is the standard plane sweep algorithm for orthogonal segment intersection, where the dynamic data structure is an interval tree <ref> [30] </ref>. An obvious way of implementing algorithms of this type in secondary memory is to replace the dynamic search tree with a dynamic B-tree [6,9]. <p> In main memory the lower bound for computing the convex hull of N points in dimension d = 2 and d = 3 is (N log N ) <ref> [30] </ref>. In secondary memory, this bound becomes (- log -). In this section we give optimal algorithms that match this lower bound. <p> that, although not optimal asymptotically, is simpler to implement and is faster for the vast majority of practical cases. 6.1 A worst-case optimal two-dimen sional convex hull algorithm For the two-dimensional case, a number of main memory algorithms are known that operate in optimal time O (N log N ) <ref> [30] </ref>. A simple way to solve the problem optimally in external memory is to modify one of the main memory approaches, namely Graham's scan [16]. <p> In order to get around the problems associated with a merging approach, we use a novel formulation of the distribution method. We consider the dual of the convex hull problem, namely that of computing the intersection of N half spaces all of which contain the origin <ref> [30] </ref>. Once we are dealing with the dual problem, we can use a distribution based approach along the lines of that proposed by Reif and Sen for computing 3-d convex hulls in parallel [31]. Let S be a set of N halfspaces all of which contain the origin.
Reference: [31] <author> J. R. Reif and S. Sen, </author> <title> "Optimal Parallel Randomized Algorithms for Three-Dimensional Convex Hulls and Related Problems," </title> <journal> SIAM J. Comput. </journal> <volume> 21 (1992), </volume> <pages> 466-485. </pages>
Reference-contexts: Once we are dealing with the dual problem, we can use a distribution based approach along the lines of that proposed by Reif and Sen for computing 3-d convex hulls in parallel <ref> [31] </ref>. Let S be a set of N halfspaces all of which contain the origin. Let the boundary of halfspace h i 2 S be denoted P i . Suppose we have a subset S 0 S such that jS 0 j = N " . <p> Luckily, using a form of random sampling called polling and eliminating redundant planes from within a cone prior to recursion <ref> [31] </ref>, we can with high probability get around this problem. (In this discus sion, the phrase "with high probability" means with probability 1 N ff , for some constant ff.) Algorithm 6.1 is the resulting distribution algorithm for computing the intersection of all h i 2 S. <p> Both require O ( r B log B ) I/O operations. Finally, Step 6 recursively solves the subprob-lems. By methods analogous to the approach of Reif and Sen <ref> [31] </ref> for the parallel case, we can develop the following recurrence for the running time of our algorithm: T (N ) = O (- log -) + T (N " ) log - + i The first term on the right-hand side is the I/O cost for sampling and partitioning, the <p> The main reason for the increase in performance is that to do polling efficiently the algorithm requires " &lt; 1=8 (see <ref> [31] </ref>) and thus in most practical situations &lt; N " . 7 Parallel and multi-level extensions Up to this point our discussion has centered on the special case where D = 1 and P = 1.
Reference: [32] <author> H. Samet, </author> <title> Applications of Spatial Data Structures: Computer Graphics, Image Processing, and GIS, </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: was supported in part by National Science Foundation grant CCR-9007851 and by Army Research Office grant DAAL03-91-G-0035, email: jsv@cs.duke.edu Large-scale problems involving geometric data are ubiquitous in spatial databases [24,32,33], geographic information systems (GIS) [10,24,32], constraint logic programming [19,20], object oriented databases [39], statistics, virtual reality systems, and computer graphics <ref> [32] </ref>. As an example, NASA's soon-to-be petabyte-sized databases are expected to facilitate a variety of complex geometric queries [10].
Reference: [33] <author> H. Samet, </author> <title> The Design and Analysis of Spatial Data Structures, </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference: [34] <author> R. Tamassia and J. S. Vitter, </author> <note> mentioned in invited paper by J. </note> <author> S. Vitter, </author> <title> "Efficient Memory Access in Large-Scale Computation," </title> <note> STACS '93. </note>
Reference-contexts: Unfortunately, this requires fi ((N + K) log -) = fi (B (- + ) log -) I/O operations in the worst case, which is prohibitive. Previous work using lazy batched updates on the B-tree yielded algorithms with O ((- +) log 2 -) I/Os <ref> [34] </ref>. Our new method uses an off-line top-down implementation of the sweep, which is based upon a novel application of the subdivision technique used in the "distribution sort" algorithms of [3,27,37].
Reference: [35] <author> R. Tamassia and J. S. Vitter, </author> <title> "Optimal Cooperative Search in Fractional Cascaded Data Structures," </title> <booktitle> Proc. 2nd ACM SPAA (1990), </booktitle> <pages> 307-316. </pages>
Reference-contexts: of Driscoll et al. [11]; * batch filtering: a general method for performing K simultaneous external-memory searches in data structures that can be modeled as planar layered dags and in certain fractional cascaded data struc tures; * on-line filtering : A technique based on the work of Tamassia and Vitter <ref> [35] </ref> that allows I/O optimal on-line queries in fractional cascaded data struc tures based on balanced binary trees. * external marriage-before-conquest: an external-memory analog to the well-known technique of Kirkpatrick and Seidel [22] for performing output sensitive hull constructions. <p> In this section we briefly describe how this can be done with a modified version of a parallel fractional cascading technique of Tamas-sia and Vitter <ref> [35] </ref>. The method of Tamassia and Vitter [35] works with data structures whose underlying graphs are balanced binary trees. Preprocessing takes O (N ) work. Once this is done, individual queries can be answered on a p processor CREW PRAM in O (log p N ) time. <p> In this section we briefly describe how this can be done with a modified version of a parallel fractional cascading technique of Tamas-sia and Vitter <ref> [35] </ref>. The method of Tamassia and Vitter [35] works with data structures whose underlying graphs are balanced binary trees. Preprocessing takes O (N ) work. Once this is done, individual queries can be answered on a p processor CREW PRAM in O (log p N ) time.
Reference: [36] <institution> University of California at Berkeley, "Massive Information Storage, Management, and Use (NSF Institutional Infrastructure Proposal)," </institution> <note> Technical Report No. UCB/CSD 89/493, </note> <month> January </month> <year> 1989. </year>
Reference: [37] <author> J. S. Vitter and E. A. M. Shriver, </author> <title> "Algorithms for Parallel Memory I: Two-Level Memories," to appear in a special issue of Algorithmica on Large-Scale Memories, summary appears in "Optimal Disk I/O with Parallel Block Transfer" Proc. </title> <booktitle> 22nd ACM STOC (1990), </booktitle> <pages> 159-169. </pages>
Reference: [38] <author> J. S. Vitter and E. A. M. Shriver, </author> <title> "Algorithms for Parallel Memory II: Hierarchical Multilevel Memories," to appear in a special issue of Algorithmica on Large-Scale Memories, summary appears in "Optimal Disk I/O with Parallel Block Transfer" Proc. </title> <booktitle> 22nd ACM STOC (1990), </booktitle> <pages> 159-169. </pages>
Reference: [39] <editor> S. B. Zdonik and D. Maier, eds., </editor> <booktitle> Readings in Object-Oriented Database Systems, </booktitle> <publisher> Morgan Kauff-man, </publisher> <year> 1990. </year>
Reference-contexts: visiting Duke University, email: dev@cs.duke.edu x This research was supported in part by National Science Foundation grant CCR-9007851 and by Army Research Office grant DAAL03-91-G-0035, email: jsv@cs.duke.edu Large-scale problems involving geometric data are ubiquitous in spatial databases [24,32,33], geographic information systems (GIS) [10,24,32], constraint logic programming [19,20], object oriented databases <ref> [39] </ref>, statistics, virtual reality systems, and computer graphics [32]. As an example, NASA's soon-to-be petabyte-sized databases are expected to facilitate a variety of complex geometric queries [10].
References-found: 39

