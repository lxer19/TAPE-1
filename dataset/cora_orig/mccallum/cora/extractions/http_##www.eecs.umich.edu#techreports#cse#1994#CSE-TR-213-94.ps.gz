URL: http://www.eecs.umich.edu/techreports/cse/1994/CSE-TR-213-94.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse94.html
Root-URL: http://www.eecs.umich.edu
Title: An Active Visual Estimator for Dexterous Manipulation  
Author: A. A. Rizzi and D. E. Koditschek 
Note: Prepared for presentation at the 1994 IEEE International Conference on Robotics and Automation Workshop on Visual Servoing  
Abstract: Artificial Intelligence Laboratory, University of Michigan, Department of Electrical Engineering and Computer Science Technical Report CSE-TR-213-94 Abstract We present a working implementation of a dynamics based architecture for visual sensing. This architecture provides field rate estimates of the positions and velocities of two independent falling balls in the face of repeated visual occlusions and departures from field of view. The practical success of this system can be attributed to the feedback interconnection between two strongly nonlinear dynamical systems: a novel "triangulating" state estimator; and an image plane window controller. We detail the architecture of this active sensor, provide data documenting its performance, and offer an initial analysis of its soundness in the form of a convergence proof for (a simpler version of) the estimator and a boundedness proof for (a somewhat idealized version of) the manager. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter K. Allen, Aleksandra Timcenko, Billibon Yoshimi, and Paul Michelman. </author> <title> Trajectory filtering and prediction for automated tracking and grasping of a moving object. </title> <booktitle> In IEEE Int. Conf. Robt. Aut., </booktitle> <pages> pages 1850-1856, </pages> <year> 1992. </year>
Reference-contexts: One may attempt to control or mearly estimate the world state variables. Either class of problem may in turn take form with or without prior knowledge of the exact parameters. Several of these four logical variations have been well studied in the literature <ref> [16, 1, 11, 6] </ref>. The work presented here focuses on what may be arguably be the simplest: the problem of estimating the state of the world given explicit prior knowledge of the relevant parameters. <p> For some ff 2 <ref> [0; 1] </ref> this impact model can be expressed as ( _ b 0 n v 0 n ) = ff ( _ b n v n ); where _ b 0 n and v 0 denote the normal components of the ball and paddle velocities immediately after impact, while _ b <p> In fact this class of system has formed the central focus for a majority of the current visual servoing research <ref> [1, 12] </ref>. An observer for this class of system takes the form _ ^ b = A ^ b + u KC T ( ^ b) (^v v) (29) with K 2 IR 3fi4 .
Reference: [2] <author> P. Anandan. </author> <title> Measuring visual motion from image sequences. </title> <type> Technical Report COINS-TR-87-21, </type> <institution> COINS Department, University of Massachusetts, </institution> <year> 1987. </year>
Reference-contexts: Clearly the choice of "confidence" measures chosen here is simplistic and merely adequate to the task at hand. More sophisticated approaches have been proposed in the literature <ref> [2, 16] </ref>. The important idea to note is that when the sensing system controls how measurements are acquired, it must be capable of determining if a measurement was successful.
Reference: [3] <author> R. L. Andersson. </author> <title> A Robot Ping-Pong Player: Experiment in Real-Time Intelligent Control. </title> <publisher> MIT, </publisher> <address> Cambridge,MA, </address> <year> 1988. </year>
Reference-contexts: However, little thought was given to their interconnection. Consequently, the associated sensor control module connecting them was correspondingly trivial. Figure 3 depicts the architecture of this initial version of the system: Data Processing Following Andersson's experience in real-time visual servoing <ref> [3] </ref> we chose to employ a first order moment computation applied to a small window of a threshold-sampled (thus, binary valued) image of each field. Thresholding, of course, presumes a visually structured environment.
Reference: [4] <author> D. J. Bennett, J. M. Hollerbach, and D. Geiger. </author> <title> Autonomous robot calibration for hand-eye coordination. </title> <booktitle> In International Symposium of Robotics Research, </booktitle> <year> 1989. </year>
Reference-contexts: the problem of integrating sparse data from a large number of sensors, or "sensor fusion" problem. 27 A Vision System Calibration In the course of developing the sensing system discussed in this paper, we have been led to re-formulate a very attractive coordinated camera-arm calibration scheme originally proposed by Hollerbach <ref> [4] </ref>. <p> A Modified Procedure Hollerbach's proposed procedure tested in simulation of a planar arm, <ref> [4] </ref>, calls for recording some number of joint-space/camera-image pairs, D = f (q l ; c l )g n and then performing a Newton-like numerical descent algorithm on the cost function n X kc y (c l ) g k (q l )k 2 : When we attempted to implement this
Reference: [5] <author> M. Buhler, D. E. Koditschek, and P.J. Kindlmann. </author> <title> A family of robot control strategies for intermittent dynamical environments. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 10 </volume> <pages> 16-22, </pages> <month> Feb </month> <year> 1990. </year>
Reference-contexts: We seek a description of how the ball's phase, (b; _ b), is changed by the robot's phase, (q; _q), at an impact. 3 As in <ref> [5, 13, 19] </ref> we will assume that the components of the ball's velocity tangent to the paddle at the instant of contact are unchanged by impact, while the change in the normal component is governed by the simplistic (but standard [23]) coefficient of restitution law. <p> motions of the ball in four ways: (i) q d1 = OE b causes the paddle to track under the ball at all times. (ii) The paddle "mirrors" the vertical motion of the ball through the action of b on q d2 as expressed by the original planar mirror law <ref> [5] </ref>. 4 (iii) Radial motion of the ball causes the paddle to raise and lower, resulting in the normal being adjusted to correct for radial deviation in the ball position. (iv) Lateral motion of the ball causes the paddle to roll, again adjusting the normal so as to correct for lateral
Reference: [6] <author> P. I. Corke. </author> <title> Video-rate robot visual servoing. </title> <editor> In Koichi Hashimoto, editor, </editor> <title> Visual Servoing | Real-Time Control of Robot Manipulators Based on Visual Sensory Feedback. </title> <publisher> World Scientific, </publisher> <year> 1993. </year>
Reference-contexts: One may attempt to control or mearly estimate the world state variables. Either class of problem may in turn take form with or without prior knowledge of the exact parameters. Several of these four logical variations have been well studied in the literature <ref> [16, 1, 11, 6] </ref>. The work presented here focuses on what may be arguably be the simplest: the problem of estimating the state of the world given explicit prior knowledge of the relevant parameters. <p> processing subsystem allows for a more rational and localized search of the available data when attempting to extract meaningful features. 3.2.2 Sensor Control: Feedback for Active Vision The idea of centering an image, whether in a sub-window or by moving a camera, is referred to as the "visual tracking" problem <ref> [6, 14] </ref>. As discussed above, the active control of the sensor is motivated by the need to provide suitable clues to the data processing subsystem so as to assure continued acquisition of useful measurements. What follows below are our intuitive ideas about the design and implementation of such a system.
Reference: [7] <author> Ernst Dieter Dickmanns and Volker Graefe. </author> <title> Applications of dynamic monocular machine vision. </title> <booktitle> Machine Vision and Applications, </booktitle> <pages> pages 241-261, </pages> <year> 1988. </year>
Reference-contexts: The sensor control block in Figure 2 presumes a fundamental need and/or advantage to constructing "active" sensing systems. Our experimental experience and that of others <ref> [8, 7, 15] </ref> suggests that such an advantage both exists and can be practically exploited. Clearly, an active sensing system can be used to minimize the total incoming data by "focusing the attention" of the machine only where meaningful data is likely to be found.
Reference: [8] <author> Ernst Dieter Dickmanns and Volker Graefe. </author> <title> Dynamic monocular machine vision. </title> <booktitle> Machine Vision and Applications, </booktitle> <pages> pages 223-240, </pages> <year> 1988. </year>
Reference-contexts: The sensor control block in Figure 2 presumes a fundamental need and/or advantage to constructing "active" sensing systems. Our experimental experience and that of others <ref> [8, 7, 15] </ref> suggests that such an advantage both exists and can be practically exploited. Clearly, an active sensing system can be used to minimize the total incoming data by "focusing the attention" of the machine only where meaningful data is likely to be found.
Reference: [9] <author> Armando Fox and Seth Hutchenson. </author> <title> Exploiting visual constraints in teh synthesis of uncertainty-tolerant motion plans i: The directional backprojection. </title> <booktitle> In IEEE Int. Conf. Robt. Aut., </booktitle> <pages> pages 1 305-310, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Traditionally <ref> [11, 15, 9, 10] </ref> researchers working in this are have had static goals for environments they can manipulate (i.e. move the robot until the the scene looks like "this").
Reference: [10] <author> Armando Fox and Seth Hutchenson. </author> <title> Exploiting visual constraints in teh synthesis of uncertainty-tolerant motion plans ii: </title> <booktitle> The nondirectional backprojection. In IEEE Int. Conf. Robt. Aut., </booktitle> <pages> pages 1 311-316, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Traditionally <ref> [11, 15, 9, 10] </ref> researchers working in this are have had static goals for environments they can manipulate (i.e. move the robot until the the scene looks like "this").
Reference: [11] <author> Gregory D. Hager, Wen-Chung Chang, and A. S. Morse. </author> <title> Robot feedback control based on stereo vision: Towards calibration-free hand-eye coordination. </title> <booktitle> In IEEE Int. Conf. </booktitle> <address> Robt. </address> <note> and Aut., page (to appear), </note> <institution> San Diego California, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: One may attempt to control or mearly estimate the world state variables. Either class of problem may in turn take form with or without prior knowledge of the exact parameters. Several of these four logical variations have been well studied in the literature <ref> [16, 1, 11, 6] </ref>. The work presented here focuses on what may be arguably be the simplest: the problem of estimating the state of the world given explicit prior knowledge of the relevant parameters. <p> Related research, often categorized as visual servoing, normally focuses on the direct control of the world state given similar parametric information [15]. Recently there has emerged a body of work focused on this same control problem, but without the presumption of complete prior calibration <ref> [11] </ref>. We will offer more comments below on the relationship between these problems. Given the desire to perform tasks in the physical world the natural sensor choice would provide cartesian measurements. However cartesian sensors are expensive and often complex. <p> Traditionally <ref> [11, 15, 9, 10] </ref> researchers working in this are have had static goals for environments they can manipulate (i.e. move the robot until the the scene looks like "this").
Reference: [12] <author> Bijoy k. Ghosh, Mrdjan Jankovic, and Y. T. Wu. </author> <title> Some problems in perspective system theory and its application to machine vision. </title> <booktitle> In Int. Conf. on Intelligent Robots and Systems, </booktitle> <pages> pages 139-146, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In fact this class of system has formed the central focus for a majority of the current visual servoing research <ref> [1, 12] </ref>. An observer for this class of system takes the form _ ^ b = A ^ b + u KC T ( ^ b) (^v v) (29) with K 2 IR 3fi4 .
Reference: [13] <author> D. E. Koditschek and M. Buhler. </author> <title> Analysis of a simplified hopping robot. </title> <journal> International Journal of Robotics Research, </journal> <volume> 10(6), </volume> <month> Dec </month> <year> 1991 </year> . 
Reference-contexts: We seek a description of how the ball's phase, (b; _ b), is changed by the robot's phase, (q; _q), at an impact. 3 As in <ref> [5, 13, 19] </ref> we will assume that the components of the ball's velocity tangent to the paddle at the instant of contact are unchanged by impact, while the change in the normal component is governed by the simplistic (but standard [23]) coefficient of restitution law.
Reference: [14] <author> Brad Nelson and Pradeep K. Khosla. </author> <title> Integrating sensor placement and visual tracking strategies. </title> <booktitle> In Third Int. Symp. on Experimental Robotics, </booktitle> <year> 1993. </year> <month> 31 </month>
Reference-contexts: processing subsystem allows for a more rational and localized search of the available data when attempting to extract meaningful features. 3.2.2 Sensor Control: Feedback for Active Vision The idea of centering an image, whether in a sub-window or by moving a camera, is referred to as the "visual tracking" problem <ref> [6, 14] </ref>. As discussed above, the active control of the sensor is motivated by the need to provide suitable clues to the data processing subsystem so as to assure continued acquisition of useful measurements. What follows below are our intuitive ideas about the design and implementation of such a system.
Reference: [15] <author> Brad Nelson, N. P. Papanikolopolos, and P. K. Khosla. </author> <title> Visual servoing for robotic assembly. </title> <editor> In Koichi Hashimoto, editor, </editor> <title> Visual Servoing | Real-Time Control of Robot Manipulators Based on Visual Sensory Feedback. </title> <publisher> World Scientific, </publisher> <year> 1993. </year>
Reference-contexts: Related research, often categorized as visual servoing, normally focuses on the direct control of the world state given similar parametric information <ref> [15] </ref>. Recently there has emerged a body of work focused on this same control problem, but without the presumption of complete prior calibration [11]. We will offer more comments below on the relationship between these problems. <p> The sensor control block in Figure 2 presumes a fundamental need and/or advantage to constructing "active" sensing systems. Our experimental experience and that of others <ref> [8, 7, 15] </ref> suggests that such an advantage both exists and can be practically exploited. Clearly, an active sensing system can be used to minimize the total incoming data by "focusing the attention" of the machine only where meaningful data is likely to be found. <p> Traditionally <ref> [11, 15, 9, 10] </ref> researchers working in this are have had static goals for environments they can manipulate (i.e. move the robot until the the scene looks like "this").
Reference: [16] <author> N. P. Papanikolopolos and P. K. Khosla. </author> <title> Adaptive robotic visual tracking: Theory and experiments. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 38(3) </volume> <pages> 429-445, </pages> <year> 1993. </year>
Reference-contexts: One may attempt to control or mearly estimate the world state variables. Either class of problem may in turn take form with or without prior knowledge of the exact parameters. Several of these four logical variations have been well studied in the literature <ref> [16, 1, 11, 6] </ref>. The work presented here focuses on what may be arguably be the simplest: the problem of estimating the state of the world given explicit prior knowledge of the relevant parameters. <p> Clearly the choice of "confidence" measures chosen here is simplistic and merely adequate to the task at hand. More sophisticated approaches have been proposed in the literature <ref> [2, 16] </ref>. The important idea to note is that when the sensing system controls how measurements are acquired, it must be capable of determining if a measurement was successful.
Reference: [17] <author> A. A. Rizzi and D. E. Koditschek. </author> <title> Further progress in robot juggling: The spatial two-juggle. </title> <booktitle> In IEEE Int. Conf. Robt. Aut., </booktitle> <pages> pages 3 919-924, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: denotes the unit normal vector to the paddle. 2.2 Behavioral Model: The Robot's Strategy X 0 Y 0 Y 1 X 2 Z 2 Y 3 n g n g q 1 q 1 s 2 d 2 A detailed development of our juggling control strategy can be found in <ref> [17] </ref>. Briefly, the "mirror law," is a map (m) from the phase space of a ball into the configuration space of the robot. Thus the robot's reference trajectory is specified by q d (t) = m (w (t)); where w (t) denotes the state of the ball. <p> Prior to attempting two-juggle experiments, we ignored this "detail" and happily ran with the open loop sensory management procedures used to obtain data (8) <ref> [17] </ref>. It soon became clear that these procedures could not be similarly transparent in the more demanding domain of the two-juggle task. The practical limitations of our robot arm necessitated considerable enhancements to the vision subsystem, and getting these management issues right became one of the chief sources of difficulty. <p> 3.40 Time (seconds) 0.6 0.8 Z (meters) (b) Predicted Measured sequence (a), and an expanded view of a single recovery event (b). 3.3 Effect of the Modifications We are convinced that the sensing enhancements discussed above have significantly contributed to our success at the two juggle task, as discussed in <ref> [17] </ref>. This Section documents the performance of the sensing system for the previously unmanageable situations discussed above.
Reference: [18] <author> A. A. Rizzi and D. E. Koditschek. </author> <title> Toward the control of attention in a dynamically dexterous robot. </title> <editor> In Koichi Hashimoto, editor, </editor> <title> Visual Servoing | Real-Time Control of Robot Manipulators Based on Visual Sensory Feedback. </title> <publisher> World Scientific, </publisher> <year> 1993. </year>
Reference-contexts: The practical limitations of our robot arm necessitated considerable enhancements to the vision subsystem, and getting these management issues right became one of the chief sources of difficulty. For reasons detailed in <ref> [18] </ref> the considerable torque generating capabilities of our Buhgler arm did not prove sufficient to permit easily tracked ball trajectories in the two-juggle setting.
Reference: [19] <author> Alfred Rizzi and Daniel E. Koditschek. </author> <title> Preliminary experiments in robot juggling. </title> <booktitle> In Proc. Int. Symp. on Experimental Robotics, </booktitle> <address> Toulouse, France, June 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: We seek a description of how the ball's phase, (b; _ b), is changed by the robot's phase, (q; _q), at an impact. 3 As in <ref> [5, 13, 19] </ref> we will assume that the components of the ball's velocity tangent to the paddle at the instant of contact are unchanged by impact, while the change in the normal component is governed by the simplistic (but standard [23]) coefficient of restitution law. <p> We have discussed our choice of pseudo-inverse at length in previous publications [21], and details of the calibration scheme can be found in Appendix A and <ref> [19] </ref>.
Reference: [20] <author> Alfred A. Rizzi and D. E. Koditschek. </author> <title> Progress in spatial robot juggling. </title> <booktitle> In IEEE Int. Conf. Robt. Aut., </booktitle> <pages> pages 775-780, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction We have built a three degree of freedom robot that bats two balls into simultaneous stable periodic vertical trajectories that commonly persist for the better part of an hour <ref> [20] </ref>. The juggling algorithm underlying this behavior relies on a continuous stream of ball position and velocity estimates delivered by a stereo camera system that views brightly illuminated white balls against a dark background.
Reference: [21] <author> Alfred A. Rizzi and D. E. Koditschek. </author> <title> Progress in spatial robot juggling. </title> <booktitle> In IEEE Int. Conf. Robt. Aut., </booktitle> <pages> pages 775-780, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Thus the robot's reference trajectory is specified by q d (t) = m (w (t)); where w (t) denotes the state of the ball. The function, m is defined as follows. Using (6) from <ref> [21] </ref>, define the joint space position of the ball 2 6 OE b b 3 7 4 where g 1 is the inverse kinematic map (including the paddle's length s that provides an effec tive fourth degree of freedom) for our machine, which is shown in Figure 1. <p> We have discussed our choice of pseudo-inverse at length in previous publications <ref> [21] </ref>, and details of the calibration scheme can be found in Appendix A and [19].
Reference: [22] <author> Alfred A. Rizzi, Louis L. Whitcomb, and D. E. Koditschek. </author> <title> Distributed real-time control of a spatial robot juggler. </title> <journal> IEEE Computer, </journal> <volume> 25(5), </volume> <month> May </month> <year> 1992. </year>
Reference: [23] <author> J. L. Synge and B. A. Griffith. </author> <title> Principles of Mechanics. </title> <publisher> McGraw Hill, </publisher> <address> London, </address> <year> 1959. </year> <month> 32 </month>
Reference-contexts: robot's phase, (q; _q), at an impact. 3 As in [5, 13, 19] we will assume that the components of the ball's velocity tangent to the paddle at the instant of contact are unchanged by impact, while the change in the normal component is governed by the simplistic (but standard <ref> [23] </ref>) coefficient of restitution law.
References-found: 23

