URL: file://ftp.cis.ohio-state.edu/pub/communication/techreports/tr46-97-effec-vchan-dsm.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~dai/
Root-URL: 
Title: Effective Use of Virtual Channels in Wormhole Routed Distributed Shared Memory Systems  
Abstract: Donglai Dai and Dhabaleswar K. Panda Technical Report OSU-CISRC-10/97-TR46 October 1997 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. V. Anjan and T. M. Pinkston. </author> <title> An Efficient Fully Adaptive Deadlock Recovery Scheme: </title> <booktitle> DISHA. In International Symposium on Computer Architecture, </booktitle> <pages> pages 201-210, </pages> <year> 1995. </year>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency [19, 27, 5, 22]. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks <ref> [1, 8] </ref>, provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9]. Most of these studies on using virtual channels mechanism in wormhole networks have focused on synthetic traffic (uniform/non-uniform/hot-spot), arbitrary message lengths, and message generation intervals following some probabilistic distributions.
Reference: [2] <author> K. Aoyama and A. A. Chien. </author> <title> The Cost of Adaptivity and Virtual Lanes in a Wormhole Router. </title> <journal> Journal of VLSI Design, </journal> <volume> 2(4) </volume> <pages> 315-333, </pages> <year> 1995. </year>
Reference-contexts: Such an approach prevents the directory controller of the destination node from processing these messages in a timely fashion. This results in an increase in effective message latency and nullifies the latency reduction gained by the virtual channel mechanism. * A performance degradation model <ref> [2] </ref> for implementing the virtual channel mechanism has been used in the evaluation. However, new techniques [17] are available today to design routers with a moderate number of virtual channels (up to 4 or 5) without increasing the routing decision delay for the header flit. <p> Some researchers believe that the network speed can not remain unchanged as more number of virtual channels are supported. In an earlier study <ref> [2] </ref>, a performance model of 30% slowdown in network cycle time for adding each virtual channel has been proposed. However, a more careful analysis on the problem reveals that the slowdown is mainly caused by the routing delay of the header flit at a router.
Reference: [3] <author> D. Basak and D. K. Panda. </author> <title> Alleviating Consumption Channel Bottleneck in WormholeRouted k-ary n-cube Systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <note> 1997. To appear. </note>
Reference-contexts: But it aggravates contention at the NI. An example of such contention is illustrated in Fig. 5. Such contention at the NI has also been identified in the context of distributed memory systems in a separate research <ref> [3] </ref>. 3.3 FIFO Restriction As the VLSI technology advances, implementing a coherence protocol with moderate complexity is no longer a concern. New automatic or semi-automatic tools are available to help checking the correctness of the protocol. <p> A set of guidelines have been proposed in [5] for designing better networks for DSM systems with two virtual networks (with one virtual channel each) and one injection and consumption channel at the network interface. Impact of multiple physical injection/consumption channels has been the focus of study <ref> [3] </ref>. However, this study has been done with respect to uniform traffic distribution in distributed memory systems. Traffic non-uniformities in the forward and reverse multistage networks in the Cedar system have been investigated in [26].
Reference: [4] <author> R. V. Boppana and S. Chalasani. </author> <title> A Comparison of Adaptive Wormhole Routing Algorithms. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 351-360, </pages> <year> 1993. </year>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency [19, 27, 5, 22]. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity <ref> [4] </ref>, increase throughput [9], and reduce latency in wormhole routed networks [9]. Most of these studies on using virtual channels mechanism in wormhole networks have focused on synthetic traffic (uniform/non-uniform/hot-spot), arbitrary message lengths, and message generation intervals following some probabilistic distributions.
Reference: [5] <author> D. Dai and D. K. Panda. </author> <title> How Can We Design Better Networks for DSM Systems? In Proceedings of the 1997 Parallel Computing, Routing, </title> <booktitle> and Communication Workshop (PCRCW'97), </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency <ref> [19, 27, 5, 22] </ref>. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9]. <p> This indicates that the performance of DSM systems is not so sensitive to reasonably increased routing delay. How- ever, the performance is quite sensitive to the overall network cycle time (or link cycle time) increase as reported in <ref> [5, 6, 27] </ref>. 5.2.5 Impact of Topology Finally, we studied the impact of network topology. We focused on the k-ary n-cube topologies. Recently, there are some renewed interests of using higher dimensional k-ary n-cube topologies in DSM systems because of many different reasons [10, 20]. <p> The performance impact of network contention under various designs of cache and memory module, processor speed, and different network components has been reported in [6]. A set of guidelines have been proposed in <ref> [5] </ref> for designing better networks for DSM systems with two virtual networks (with one virtual channel each) and one injection and consumption channel at the network interface. Impact of multiple physical injection/consumption channels has been the focus of study [3].
Reference: [6] <author> D. Dai and D. K. Panda. </author> <title> How Much Does Network Contention Affect Distributed Shared Memory Performance? In Proceedings of the International Conference on Parallel Processing, </title> <address> Chicago, IL, </address> <month> Aug </month> <year> 1997. </year>
Reference-contexts: However, the current generation DSM systems using wormhole interconnection network do not deliver very good performance due to the high latency associated with shared memory accesses. A significant portion of this latency is incurred by messages in the interconnection network <ref> [6] </ref>, and a lot of research is currently taking place to reduce this latency [19, 27, 5, 22]. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9]. <p> According to a study done in <ref> [6] </ref>, the execution time of a DSM application shows a bathtub behavior as the cache line size changes with a pollution point around 64 bytes. <p> This indicates that the performance of DSM systems is not so sensitive to reasonably increased routing delay. How- ever, the performance is quite sensitive to the overall network cycle time (or link cycle time) increase as reported in <ref> [5, 6, 27] </ref>. 5.2.5 Impact of Topology Finally, we studied the impact of network topology. We focused on the k-ary n-cube topologies. Recently, there are some renewed interests of using higher dimensional k-ary n-cube topologies in DSM systems because of many different reasons [10, 20]. <p> But, as we have shown in this study, incorporating virtual channel mechanism into DSM systems in an efficient manner can provide a significant performance improvement. The performance impact of network contention under various designs of cache and memory module, processor speed, and different network components has been reported in <ref> [6] </ref>. A set of guidelines have been proposed in [5] for designing better networks for DSM systems with two virtual networks (with one virtual channel each) and one injection and consumption channel at the network interface. Impact of multiple physical injection/consumption channels has been the focus of study [3].
Reference: [7] <author> W. J. Dally. </author> <title> Virtual Channel Flow Control. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <pages> pages 194-205, </pages> <month> Mar </month> <year> 1992. </year>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency [19, 27, 5, 22]. Virtual channels <ref> [7] </ref> have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9]. <p> are made in Section 7. 5 2 Current Generation DSM Networks and Coherence Protocols In this section we provide a brief overview of the current generation DSM systems and focus on the important issues related to the networks and cache coherence protocols. 2.1 Virtual Channels and Virtual Lanes Virtual channels <ref> [7] </ref> over a physical channel have been proposed and implemented [17, 24] as a mechanism to avoid deadlocks and improve throughput in wormhole routed networks. These channels divide the buffering storage at a router and compete (on demand) for the bandwidth of the physical channel.
Reference: [8] <author> J. Duato. </author> <title> A New Theory of Deadlock-Free Adaptive Routing in Wormhole Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(12) </volume> <pages> 1320-1331, </pages> <year> 1993. </year>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency [19, 27, 5, 22]. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks <ref> [1, 8] </ref>, provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9]. Most of these studies on using virtual channels mechanism in wormhole networks have focused on synthetic traffic (uniform/non-uniform/hot-spot), arbitrary message lengths, and message generation intervals following some probabilistic distributions.
Reference: [9] <author> J. Duato, S. Yalamanchili, and L. Ni. </author> <title> Interconnection Networks: An Engineering Approach. </title> <publisher> The IEEE Computer Society Press, </publisher> <year> 1997. </year>
Reference-contexts: Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput <ref> [9] </ref>, and reduce latency in wormhole routed networks [9]. Most of these studies on using virtual channels mechanism in wormhole networks have focused on synthetic traffic (uniform/non-uniform/hot-spot), arbitrary message lengths, and message generation intervals following some probabilistic distributions. <p> Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput <ref> [9] </ref>, and reduce latency in wormhole routed networks [9]. Most of these studies on using virtual channels mechanism in wormhole networks have focused on synthetic traffic (uniform/non-uniform/hot-spot), arbitrary message lengths, and message generation intervals following some probabilistic distributions. <p> These channels divide the buffering storage at a router and compete (on demand) for the bandwidth of the physical channel. A group of such virtual channels are called virtual lanes if any member of this group can be used for transferring a message <ref> [9] </ref>. A message (or worm) consists of a set of flits and uses one virtual channel at each hop of the network while propagating towards its destination. Thus, the flits of a worm form a pipeline across routers of a network. <p> The average message latencies in these two networks can be illustrated as shown in Fig. 4 according to the theoretical performance model of wormhole network with contention <ref> [9] </ref>. It indicates that the reply network typically operates at a higher load due to heavier traffic and leads to increased latency for reply messages.
Reference: [10] <author> Jose Duato and M. P. Malumbres. </author> <title> Optimal Topology for Distributed Shared Memory Multiprocessors: Hypercubes Again? In Proceedings of the Euro-Par96, </title> <note> page to appear, </note> <year> 1996. </year>
Reference-contexts: We focused on the k-ary n-cube topologies. Recently, there are some renewed interests of using higher dimensional k-ary n-cube topologies in DSM systems because of many different reasons <ref> [10, 20] </ref>. Thus, we selected three configurations (1,1,2,2), (1,2,3,3), and (1,3,4,4) and performed simulations by varying dimensionality from 2 to 3 to 6 and keeping the total number of processing nodes fixed at 64.
Reference: [11] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: Architecture and Performance. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 2-13, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Distributed Shared Memory (DSM) multiprocessors are emerging as the trend in building parallel systems because they provide much desired programmability <ref> [12, 11, 15, 13, 20] </ref>. However, the current generation DSM systems using wormhole interconnection network do not deliver very good performance due to the high latency associated with shared memory accesses.
Reference: [12] <author> D. Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <month> March </month> <year> 1992. </year> <month> 25 </month>
Reference-contexts: 1 Introduction Distributed Shared Memory (DSM) multiprocessors are emerging as the trend in building parallel systems because they provide much desired programmability <ref> [12, 11, 15, 13, 20] </ref>. However, the current generation DSM systems using wormhole interconnection network do not deliver very good performance due to the high latency associated with shared memory accesses. <p> The request and reply messages travel in separate (virtual) networks to avoid deadlocks <ref> [12] </ref>. <p> For instance, a dependency exists between a read request message and the subsequent reply message containing the desired data. To avoid deadlocks caused by such dependencies, two logically separate networks are commonly used in practice <ref> [12, 13] </ref>. One of the two networks, known as the request network, is used to transfer all types of request messages. The other, known as the reply network, is used to transfer all types of reply messages. <p> the injection/consumption channel must be reserved exclusively for the time period when an entire message is injected or consumed. within the adapter contains a single physical injection channel and a single physical consumption channel. 2.4 Cache Coherence Protocols Traditionally, directory-based write-invalidate cache coherence protocols have been used in DSM systems <ref> [12, 13] </ref>. Most of these protocols are designed by assuming the property of in-order 7 message delivery. Such coherence protocols are commonly identified as FIFO coherence pro-tocols. <p> The justification for these motivations can be illustrated by an example as shown in Fig. 3. Consider a node N 1 issuing a write-miss request (Rxq (1)) to a memory block B 1 whose home node is N 2 and whose directory state is dirty-remote <ref> [12, 13] </ref>. Once the request Rxq arrives at node N 2 , a flush request (F sh (2)) is issued by N 2 to the current owner node N 3 . <p> The machine is assumed to be using a non-FIFO coherence protocol as discussed in section 4.3 and supporting the release consistency memory model [13, 20]. The synchronization protocol assumed in the system is the QOLB protocol, which is similar to the one used in DASH <ref> [12] </ref>. The node simulator models the internal structures and the queuing and contention at the node controller, the main memory, and the cache [23]. Table 2 shows the default memory hierarchy parameters, node controller occupancy delays, network parameters, and network interface parameters used in our simulations.
Reference: [13] <author> J. Kuskin et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Distributed Shared Memory (DSM) multiprocessors are emerging as the trend in building parallel systems because they provide much desired programmability <ref> [12, 11, 15, 13, 20] </ref>. However, the current generation DSM systems using wormhole interconnection network do not deliver very good performance due to the high latency associated with shared memory accesses. <p> For instance, a dependency exists between a read request message and the subsequent reply message containing the desired data. To avoid deadlocks caused by such dependencies, two logically separate networks are commonly used in practice <ref> [12, 13] </ref>. One of the two networks, known as the request network, is used to transfer all types of request messages. The other, known as the reply network, is used to transfer all types of reply messages. <p> Earlier research has indicated that the request and reply networks that are physically separated (duplicated links and routers) operate far below their saturation point most of the time during the execution of typical applications <ref> [13, 20] </ref>. To be cost-effective, the current generation DSM systems tend to employ dual virtual networks. A virtual network refers to a network in which the logical links are implemented using the virtual channel mechanism. <p> the injection/consumption channel must be reserved exclusively for the time period when an entire message is injected or consumed. within the adapter contains a single physical injection channel and a single physical consumption channel. 2.4 Cache Coherence Protocols Traditionally, directory-based write-invalidate cache coherence protocols have been used in DSM systems <ref> [12, 13] </ref>. Most of these protocols are designed by assuming the property of in-order 7 message delivery. Such coherence protocols are commonly identified as FIFO coherence pro-tocols. <p> The justification for these motivations can be illustrated by an example as shown in Fig. 3. Consider a node N 1 issuing a write-miss request (Rxq (1)) to a memory block B 1 whose home node is N 2 and whose directory state is dirty-remote <ref> [12, 13] </ref>. Once the request Rxq arrives at node N 2 , a flush request (F sh (2)) is issued by N 2 to the current owner node N 3 . <p> configurations are based on our solutions proposed in the previous section. 13 5.1 Simulation Experiments This section describes our basic methodology and the default system and application parameters used in simulation experiments. 5.1.1 Simulation Environment The hardware cache coherent multiprocessor we simulated has an architecture similar to the FLASH machine <ref> [13] </ref>. The system consists of 64 processing nodes interconnected in a topology of K-ary N-cube (2D mesh as default except when we study the impact of topology). Each node contains one processor. <p> Each buffer can hold one cache line and merge multiple writes into the line. The machine is assumed to be using a non-FIFO coherence protocol as discussed in section 4.3 and supporting the release consistency memory model <ref> [13, 20] </ref>. The synchronization protocol assumed in the system is the QOLB protocol, which is similar to the one used in DASH [12]. The node simulator models the internal structures and the queuing and contention at the node controller, the main memory, and the cache [23].
Reference: [14] <author> S. C. Woo et al. </author> <title> The SPLASH-2 Programs: Characterization and Methodological Considerations. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <year> 1995. </year>
Reference-contexts: All are real applications or challenging computational kernels ported from the Stanford SPLASH2 <ref> [25, 14] </ref> benchmark suite. Table 3 shows the basic communication patterns and problem sizes for the applications. These applications were compiled by dlxcc using the optimization level equivalent to O2 of gcc. Table 3: Applications and the used input sizes.
Reference: [15] <author> S. K. Reinhardt et al. </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers. </title> <booktitle> In ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 48-60, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Distributed Shared Memory (DSM) multiprocessors are emerging as the trend in building parallel systems because they provide much desired programmability <ref> [12, 11, 15, 13, 20] </ref>. However, the current generation DSM systems using wormhole interconnection network do not deliver very good performance due to the high latency associated with shared memory accesses.
Reference: [16] <editor> W.-D. Webber et al. </editor> <title> The mercury interconnect architecture: A cost-effective infrastructure for high-performance servers. </title> <booktitle> In Proceedings of International Symposium on Computer Architecture (ISCA-24), </booktitle> <pages> pages 98-107, </pages> <year> 1997. </year>
Reference-contexts: Under such an assumption, no bandwidth bottleneck can ever occur between processing nodes and the network. Thus, the current studies on virtual channels do not provide any concrete guideline about using virtual channels in DSM systems. In recent years, several commercial network switching products <ref> [17, 24, 16] </ref> have incorporated virtual channel mechanism as a major feature for improving network performance. Out of these products, the SGI Spider interconnect [17] is directly geared towards cache-coherent DSM systems. However, this study [17] does not clearly outline the performance benefit of virtual channels in DSM systems.
Reference: [17] <author> Mike Galles. Spider: </author> <title> A High-Speed Network Interconnect. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 34-39, </pages> <month> January/February </month> <year> 1997. </year>
Reference-contexts: Under such an assumption, no bandwidth bottleneck can ever occur between processing nodes and the network. Thus, the current studies on virtual channels do not provide any concrete guideline about using virtual channels in DSM systems. In recent years, several commercial network switching products <ref> [17, 24, 16] </ref> have incorporated virtual channel mechanism as a major feature for improving network performance. Out of these products, the SGI Spider interconnect [17] is directly geared towards cache-coherent DSM systems. However, this study [17] does not clearly outline the performance benefit of virtual channels in DSM systems. <p> In recent years, several commercial network switching products [17, 24, 16] have incorporated virtual channel mechanism as a major feature for improving network performance. Out of these products, the SGI Spider interconnect <ref> [17] </ref> is directly geared towards cache-coherent DSM systems. However, this study [17] does not clearly outline the performance benefit of virtual channels in DSM systems. Recently, an application-driven study [27] has shown that only a negligible performance benefit exists in using virtual channels and adaptive routing in a DSM system. <p> In recent years, several commercial network switching products [17, 24, 16] have incorporated virtual channel mechanism as a major feature for improving network performance. Out of these products, the SGI Spider interconnect <ref> [17] </ref> is directly geared towards cache-coherent DSM systems. However, this study [17] does not clearly outline the performance benefit of virtual channels in DSM systems. Recently, an application-driven study [27] has shown that only a negligible performance benefit exists in using virtual channels and adaptive routing in a DSM system. <p> This results in an increase in effective message latency and nullifies the latency reduction gained by the virtual channel mechanism. * A performance degradation model [2] for implementing the virtual channel mechanism has been used in the evaluation. However, new techniques <ref> [17] </ref> are available today to design routers with a moderate number of virtual channels (up to 4 or 5) without increasing the routing decision delay for the header flit. <p> Networks and Coherence Protocols In this section we provide a brief overview of the current generation DSM systems and focus on the important issues related to the networks and cache coherence protocols. 2.1 Virtual Channels and Virtual Lanes Virtual channels [7] over a physical channel have been proposed and implemented <ref> [17, 24] </ref> as a mechanism to avoid deadlocks and improve throughput in wormhole routed networks. These channels divide the buffering storage at a router and compete (on demand) for the bandwidth of the physical channel. <p> However, a more careful analysis on the problem reveals that the slowdown is mainly caused by the routing delay of the header flit at a router. As the network technology advances and better pipelining techniques are developed, several commercial routers <ref> [17, 24] </ref> supporting a moderate number of virtual channels have been designed successfully without noticeably increasing the network cycle time and routing delay.
Reference: [18] <author> J. L. Hennessy and D. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> 2nd edition, </address> <year> 1996. </year>
Reference-contexts: The cache is assumed to operate in dual-port mode using write-back and write- allocate policies. The instruction latencies, issue rules, and memory interface are modeled based on the DLX design <ref> [18] </ref>. The memory bus is assumed to be 8 bytes wide. On a memory block access, the first word of the block is returned in 30 processor cycles (100 ns). The successive words in the block follow in a pipelined fashion.
Reference: [19] <author> Akhilesh Kumar and Laxmi N. Bhuyan. </author> <title> Evaluating Virtual Channels for Cache-Coherent Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the 10th ACM International Conference on Supercomputing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency <ref> [19, 27, 5, 22] </ref>. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9]. <p> This is confirmed in Fig. 15 which shows that the reductions in average message latencies decrease significantly from 2D to 3D to 6D in all the applications. 23 6 Related Work Using multiple virtual channels with various buffer sizes in DSM systems was first studied in <ref> [19] </ref>. However, with more realistic assumptions on existing technology, study [27] has suggested that it may be unjustified to use virtual channel mechanism in DSM systems with respect to cost- performance viewpoint.
Reference: [20] <author> J. Laudon and D. Lenoski. </author> <title> The SGI Origin: A ccNUMA highly Scalable Server. </title> <booktitle> In Proceedings of the 24th IEEE/ACM Annual International Symposium on Computer Architecture (ISCA-24), </booktitle> <pages> pages 241-251, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Distributed Shared Memory (DSM) multiprocessors are emerging as the trend in building parallel systems because they provide much desired programmability <ref> [12, 11, 15, 13, 20] </ref>. However, the current generation DSM systems using wormhole interconnection network do not deliver very good performance due to the high latency associated with shared memory accesses. <p> Earlier research has indicated that the request and reply networks that are physically separated (duplicated links and routers) operate far below their saturation point most of the time during the execution of typical applications <ref> [13, 20] </ref>. To be cost-effective, the current generation DSM systems tend to employ dual virtual networks. A virtual network refers to a network in which the logical links are implemented using the virtual channel mechanism. <p> The non-FIFO coherence protocol used in this study is somewhat similar to the one used in SGI Origin <ref> [20] </ref>. The most noticeable difference is that a normal four-node scheme is employed in our coherence protocol instead of the three-node forwarding scheme. <p> Each buffer can hold one cache line and merge multiple writes into the line. The machine is assumed to be using a non-FIFO coherence protocol as discussed in section 4.3 and supporting the release consistency memory model <ref> [13, 20] </ref>. The synchronization protocol assumed in the system is the QOLB protocol, which is similar to the one used in DASH [12]. The node simulator models the internal structures and the queuing and contention at the node controller, the main memory, and the cache [23]. <p> We focused on the k-ary n-cube topologies. Recently, there are some renewed interests of using higher dimensional k-ary n-cube topologies in DSM systems because of many different reasons <ref> [10, 20] </ref>. Thus, we selected three configurations (1,1,2,2), (1,2,3,3), and (1,3,4,4) and performed simulations by varying dimensionality from 2 to 3 to 6 and keeping the total number of processing nodes fixed at 64.
Reference: [21] <author> L. Ni and P. K. McKinley. </author> <title> A Survey of Wormhole Routing Techniques in Direct Networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 62-76, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: Thus, the flits of a worm form a pipeline across routers of a network. The routing algorithm associated with the routers decides which virtual channel to be used by the worm at each hop based on its destination. In this paper, we concentrate on the popular dimensional order routing <ref> [21] </ref>. 2.2 Dual Request-Reply Networks As mentioned earlier, the request and reply messages in a DSM system form strong cycle dependencies with one another. For instance, a dependency exists between a read request message and the subsequent reply message containing the desired data.
Reference: [22] <author> S. Pakin, M. Lauria, and A. Chien. </author> <title> High Performance Messaging on Workstations: Illinois Fast Messages (FM). </title> <booktitle> In Proceedings of the Supercomputing, </booktitle> <year> 1995. </year>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency <ref> [19, 27, 5, 22] </ref>. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9].
Reference: [23] <author> D. K. Panda, D. Basak, D. Dai, R. Kesavan, R. Sivaram, M. Banikazemi, and V. Moorthy. </author> <title> Simulation of Modern Parallel Systems: A CSIM-based approach. </title> <booktitle> In Proceedings of the 1997 Winter Simulation Conference (WSC'97), </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: The synchronization protocol assumed in the system is the QOLB protocol, which is similar to the one used in DASH [12]. The node simulator models the internal structures and the queuing and contention at the node controller, the main memory, and the cache <ref> [23] </ref>. Table 2 shows the default memory hierarchy parameters, node controller occupancy delays, network parameters, and network interface parameters used in our simulations. Table 2: Default system parameters used in simulation.
Reference: [24] <author> S. L. Scott and G. M. Thorson. </author> <title> The Cray T3E Network: Adaptive Routing in a High Performance 3D Torus. </title> <booktitle> In Proceedings of the Symposium on High Performance Interconnects (Hot Interconnects 4), </booktitle> <pages> pages 147-156, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: Under such an assumption, no bandwidth bottleneck can ever occur between processing nodes and the network. Thus, the current studies on virtual channels do not provide any concrete guideline about using virtual channels in DSM systems. In recent years, several commercial network switching products <ref> [17, 24, 16] </ref> have incorporated virtual channel mechanism as a major feature for improving network performance. Out of these products, the SGI Spider interconnect [17] is directly geared towards cache-coherent DSM systems. However, this study [17] does not clearly outline the performance benefit of virtual channels in DSM systems. <p> Networks and Coherence Protocols In this section we provide a brief overview of the current generation DSM systems and focus on the important issues related to the networks and cache coherence protocols. 2.1 Virtual Channels and Virtual Lanes Virtual channels [7] over a physical channel have been proposed and implemented <ref> [17, 24] </ref> as a mechanism to avoid deadlocks and improve throughput in wormhole routed networks. These channels divide the buffering storage at a router and compete (on demand) for the bandwidth of the physical channel. <p> However, a more careful analysis on the problem reveals that the slowdown is mainly caused by the routing delay of the header flit at a router. As the network technology advances and better pipelining techniques are developed, several commercial routers <ref> [17, 24] </ref> supporting a moderate number of virtual channels have been designed successfully without noticeably increasing the network cycle time and routing delay.
Reference: [25] <author> J. P. Singh, W. Weber, and A. Gupta. </author> <title> SPLASH: Stanford Parallel Applications for SharedMemory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 5-44, </pages> <year> 1992. </year>
Reference-contexts: All are real applications or challenging computational kernels ported from the Stanford SPLASH2 <ref> [25, 14] </ref> benchmark suite. Table 3 shows the basic communication patterns and problem sizes for the applications. These applications were compiled by dlxcc using the optimization level equivalent to O2 of gcc. Table 3: Applications and the used input sizes.
Reference: [26] <author> J. Torrellas and Z. Zhang. </author> <title> The Performance of the Cedar Multistage Switching Network. </title> <booktitle> IEEE Transaction on Parallel and Distributed Systems, </booktitle> <pages> pages 321-336, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Impact of multiple physical injection/consumption channels has been the focus of study [3]. However, this study has been done with respect to uniform traffic distribution in distributed memory systems. Traffic non-uniformities in the forward and reverse multistage networks in the Cedar system have been investigated in <ref> [26] </ref>. Strategies for improving the performance of dance-hall vector multiprocessors using MIN networks have been proposed in this study. 7 Conclusion In this paper we have presented two simple techniques for exploiting the promising performance benefit of the virtual channel mechanism in distributed shared memory systems.
Reference: [27] <author> A. S. Vaidya, A. Sivasubramaniam, and C. R. Das. </author> <title> Performance benefits of virtual channels and adaptive routing: An application-driven study. </title> <booktitle> In Proceedings of ACM International Conference on Supercomputing (ISC'97), </booktitle> <month> July </month> <year> 1997. </year> <month> 26 </month>
Reference-contexts: A significant portion of this latency is incurred by messages in the interconnection network [6], and a lot of research is currently taking place to reduce this latency <ref> [19, 27, 5, 22] </ref>. Virtual channels [7] have been proposed as an attractive mechanism to avoid deadlocks [1, 8], provide adaptivity [4], increase throughput [9], and reduce latency in wormhole routed networks [9]. <p> Out of these products, the SGI Spider interconnect [17] is directly geared towards cache-coherent DSM systems. However, this study [17] does not clearly outline the performance benefit of virtual channels in DSM systems. Recently, an application-driven study <ref> [27] </ref> has shown that only a negligible performance benefit exists in using virtual channels and adaptive routing in a DSM system. According to this study, the enhancements due to virtual channels and adaptive routing might not be justified considering the associated increase in router complexity. <p> This indicates that the performance of DSM systems is not so sensitive to reasonably increased routing delay. How- ever, the performance is quite sensitive to the overall network cycle time (or link cycle time) increase as reported in <ref> [5, 6, 27] </ref>. 5.2.5 Impact of Topology Finally, we studied the impact of network topology. We focused on the k-ary n-cube topologies. Recently, there are some renewed interests of using higher dimensional k-ary n-cube topologies in DSM systems because of many different reasons [10, 20]. <p> However, with more realistic assumptions on existing technology, study <ref> [27] </ref> has suggested that it may be unjustified to use virtual channel mechanism in DSM systems with respect to cost- performance viewpoint. But, as we have shown in this study, incorporating virtual channel mechanism into DSM systems in an efficient manner can provide a significant performance improvement.
References-found: 27

