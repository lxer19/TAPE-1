URL: ftp://ftp.cs.helsinki.fi/pub/Reports/by_Project/Cosco/Mapping_Bayesian_Networks_to_Boltzmann_Machines.ps.gz
Refering-URL: 
Root-URL: 
Email: Email: Petri.Myllymaki@cs.Helsinki.FI  
Title: Mapping Bayesian Networks to Boltzmann Machines  
Author: Petri Myllymki 
Date: April 1995).  
Note: Pp. 269280 in Proceedings of Applied Decision Technologies 1995 (London,  
Address: P.O.Box 26, FIN-00014 University of Helsinki, Finland  
Affiliation: Department of Computer Science  
Abstract: We study the task of tnding a maximal a posteriori (MAP) instantiation of Bayesian network variables, given a partial value assignment as an initial constraint. This problem is known to be NP-hard, so we concentrate on a stochastic approximation algorithm, simulated annealing. This stochastic algorithm can be realized as a sequential process on the set of Bayesian network variables, where only one variable is allowed to change at a time. Consequently, the method can become impractically slow as the number of variables increases. We present a method for mapping a given Bayesian network to a massively parallel Bolztmann machine neural network architecture, in the sense that instead of using the normal sequential simulated annealing algorithm, we can use a massively parallel stochastic process on the Boltzmann machine architecture. The neural network updating process provably converges to a state which solves a given MAP task.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Cooper, </author> <title> G.F., The computational complexity of probabilistic inference using Bayesian belief networks. </title> <booktitle> Artitcial Intelligence 42 (1990) 23 (March), </booktitle> <pages> 393405. </pages>
Reference-contexts: It has been shown that the MAP problem for Bayesian networks belongs to the class of NP-hard problems with respect to the size of the corresponding network <ref> [1, 28] </ref>, and hence the MAP problem is probably intractable (in the worst case sense) for Bayesian networks in general.
Reference: [2] <author> Aarts, E. and Korst, J., </author> <title> Simulated Annealing and Boltzmann Machines: A Stochastic Approach to Combinatorial Optimization and Neural Computing. </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester, </address> <year> 1989. </year>
Reference-contexts: In both cases it can be shown that the resulting stochastic process will converge to a MAP solution with probability p, where p approaches one as the number of iterations approaches intnity <ref> [2] </ref>. Moreover, it can be shown that if the temperature T (t) decreases towards zero slowly enough, the convergence is almost certain even with a tnite time process [6]. Unfortunately, for a theoretically guaranteed convergence, a computationally infeasible exponential number of iterations is needed. <p> Using this kind of clustered BM models we can maintain some parallelism and update all the nodes in one cluster at the same time, while a convergence theorem can be proved <ref> [2, p. 139] </ref>. Obviously, the degree of parallelism depends on the number of clusters in the network. Unfortunately, the problem of tnding a minimal set of clusters in a given network is NP-complete [2, p. 141]. <p> Obviously, the degree of parallelism depends on the number of clusters in the network. Unfortunately, the problem of tnding a minimal set of clusters in a given network is NP-complete <ref> [2, p. 141] </ref>. <p> After each iteration, the temperature was lowered by multiplying it with the annealing factor F, F &lt; 1:0. Although simple, this type of cooling schedule is very common, and has proven successful in many applications <ref> [2] </ref>. It is also empirically observed that more sophisticated annealing methods do not necessarily produce any better results than this simple method [14]. We use the term trial for denoting one simulation run, where the temperature goes from its initial value to zero.
Reference: [3] <author> Barker, A.A., </author> <title> Monte Carlo calculations of the radial distribution functions for a proton-electron plasma. Aust. </title> <journal> J. Phys. </journal> <volume> 18 (1965), </volume> <pages> 119133. </pages>
Reference-contexts: In Metropolis-Hastings version [17, 9] of simulated annealing the acceptance probability is detned as A ij (T ) = 1 ; if exp ( T ) 1; V (~u j )V (~u i ) T ) ; otherwise, whereas Barker <ref> [3] </ref> has introduced an alternative method with acceptance probabilities of the form A ij (t) = 1 + exp ( T (t) ) where T (t), the computational temperature, is a monotonely decreasing function converging to zero as t approaches intnity.
Reference: [4] <author> Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W. , and Freeman, D., </author> <title> AutoClass: A Bayesian Classitcation System. Pp. </title> <booktitle> 5464 in Proceedings of the Fifth International Conference on Machine Learning (Ann Arbor, </booktitle> <month> June </month> <year> 1988). </year>
Reference-contexts: Alternatively, clustering can also be done by introducing new latent variables 269 which represent separate clusters of original variables <ref> [4, 22] </ref>. The latent variable model oers an interesting opportunity for constructing Bayesian networks from data using unsupervised learning algorithms.
Reference: [5] <author> Freund, Y., and Haussler, D., </author> <title> Unsupervised learning of distributions on binary vectors using two layer networks. Pp. </title> <booktitle> 912919 in Neural Information Processing Systems 4, edited by J.Moody, S.J.Hanson and R.P.Lippmann. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: Moreover, the resulting neural network could also be used as a good initial state for existing learning algorithms <ref> [11, 5] </ref>, which would probably 278 result in speeding up of the learning process. On the other hand, after having learned the neural network parameters, the network could be mapped back to a Bayesian network representation, thus allowing an interesting scheme for knowledge extraction from neural networks.
Reference: [6] <author> Geman, S. and Geman, D., </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence 6 (1984), </journal> <note> 721741. [7] de Gloria, </note> <author> A., Faraboschi, P., and Olivieri, M., </author> <title> Clustered Boltzmann Machines: Massively parallel architectures for constrained optimization problems. </title> <booktitle> Parallel Computing 19 (1993), </booktitle> <pages> 163175. </pages>
Reference-contexts: Moreover, it can be shown that if the temperature T (t) decreases towards zero slowly enough, the convergence is almost certain even with a tnite time process <ref> [6] </ref>. Unfortunately, for a theoretically guaranteed convergence, a computationally infeasible exponential number of iterations is needed. Although in practice good results are sometimes obtained with a relatively small number of iterations, the method can be excruciatingly slow.
Reference: [8] <author> Greening, D., </author> <title> Parallel Simulated Annealing Techniques. </title> <journal> Physica D 42 (1990), </journal> <volume> 293306. </volume>
Reference-contexts: It should also be noted that the method developed here apply only for massively parallel neural network implementations parallelization of simulated annealing using more conventional computing architectures is discussed in <ref> [8] </ref>. From the neural network point of view, the proposed mapping from a Bayesian network to a Boltzmann machine oers an interesting opportunity for constructing neural networks from expert knowledge, instead of learning them from raw data.
Reference: [9] <author> Hastings, </author> <title> W.K., Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrika 57 (1970), </journal> <volume> 97109. </volume>
Reference-contexts: For generating a new candidate state ~u j , most versions of simulated annealing use a simple scheme called Gibbs sampling where only one randomly chosen variable is allowed to change its value to a new randomly chosen value. In Metropolis-Hastings version <ref> [17, 9] </ref> of simulated annealing the acceptance probability is detned as A ij (T ) = 1 ; if exp ( T ) 1; V (~u j )V (~u i ) T ) ; otherwise, whereas Barker [3] has introduced an alternative method with acceptance probabilities of the form A ij
Reference: [10] <editor> Henrion, M., Shachter, R.D., Kanal, L.N., and Lemmer, J.F. (eds.), </editor> <booktitle> Uncertainty in Artitcial Intelligence 5. </booktitle> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <address> Amsterdam 1990. </address>
Reference: [11] <author> Hinton, G.E., and Sejnowski, T.J., </author> <title> Learning and relearning in Boltzmann machines. </title> <note> Pp. 282 317 in [25]. </note>
Reference-contexts: In the following, we show how to create a massively parallel implementation of simulated annealing by using the Boltzmann machine architecture. 272 4 Boltzmann machines A Boltzmann machine (BM) <ref> [11] </ref> is a neural network consisting of a set of binary nodes fS 1 ; : : : ; S n g, where the state s i of a node S i is either 1 (on), or 0 (o). <p> Moreover, the resulting neural network could also be used as a good initial state for existing learning algorithms <ref> [11, 5] </ref>, which would probably 278 result in speeding up of the learning process. On the other hand, after having learned the neural network parameters, the network could be mapped back to a Bayesian network representation, thus allowing an interesting scheme for knowledge extraction from neural networks.
Reference: [12] <author> Howard, R.A., and Matheson, </author> <title> J.E., Inuence diagrams. Pp. 763771 in Readings in Decision Analysis, edited by R.A.Howard and J.E.Matheson. Strategic Decisions Group, </title> <address> Menlo Park, CA, </address> <year> 1984. </year>
Reference-contexts: In the teld of decision theory, a model similar to Bayesian networks is known as inuence diagrams <ref> [12] </ref>. Rigorous introductions to the Bayesian network theory can be found in [24, 23].
Reference: [13] <author> Hrycej, T., </author> <title> Gibbs sampling in Bayesian networks. </title> <booktitle> Artitcial Intelligence 46 (1990), </booktitle> <pages> 351363. </pages>
Reference-contexts: As has been noted in several occasions <ref> [13, 15, 16, 30, 21, 18] </ref>, these cliques can be used to con struct an undirected graphical Markov random teld model of the probability distribution P, which 271 means that the joint probability distribution (1) for a Bayesian network representation can also be expressed as a Gibbs distribution Pf~ug = Z
Reference: [14] <author> Johnson, D.S., Aragon, C.R., McGeoch, L.A., and Schevon, C., </author> <title> Optimization by simulated annealing: an experimental evaluation; Part I, graph partitioning. </title> <journal> Operations Research, </journal> <volume> 37 (1989) 6 (November-December), </volume> <pages> 865892. </pages>
Reference-contexts: Although simple, this type of cooling schedule is very common, and has proven successful in many applications [2]. It is also empirically observed that more sophisticated annealing methods do not necessarily produce any better results than this simple method <ref> [14] </ref>. We use the term trial for denoting one simulation run, where the temperature goes from its initial value to zero. If the tnal state after a trial was not the MAP state, we started new trials until the MAP solution was found.
Reference: [15] <author> Laskey, </author> <title> K.B., Adapting connectionist learning to Bayesian networks. </title> <journal> International Journal of Approximate Reasoning 4 (1990), </journal> <volume> 261282. </volume> <pages> 279 </pages>
Reference-contexts: As has been noted in several occasions <ref> [13, 15, 16, 30, 21, 18] </ref>, these cliques can be used to con struct an undirected graphical Markov random teld model of the probability distribution P, which 271 means that the joint probability distribution (1) for a Bayesian network representation can also be expressed as a Gibbs distribution Pf~ug = Z
Reference: [16] <author> Lauritzen, S.L. and Spiegelhalter, </author> <title> D.J., Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Royal Stat. Soc., Ser. </journal> <volume> B 50 (1988) 2, </volume> <pages> 157224. </pages> <note> Reprinted as pp. 415448 in Readings in Uncertain Reasoning, </note> <editor> edited by G.Shafer and J.Pearl. </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: Consequently, most existing systems for Bayesian reasoning transform trst a given multi-connected BN structure to a singly-connected network, and use then the existing polynomial-time algorithms. This transformation can be done either explicitly by clustering several nodes together as in <ref> [16, 26] </ref> or [24, Ch.4.4.1], or implicitly by blocking multiply connected paths by conditioning a set of variables as in [24, Ch.4.4.2] (for a discussion of dierent transformation techniques, see [27]). <p> As has been noted in several occasions <ref> [13, 15, 16, 30, 21, 18] </ref>, these cliques can be used to con struct an undirected graphical Markov random teld model of the probability distribution P, which 271 means that the joint probability distribution (1) for a Bayesian network representation can also be expressed as a Gibbs distribution Pf~ug = Z
Reference: [17] <author> Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, M.N. and Teller, E., </author> <title> Equations of state calculations by fast computing machines. </title> <journal> Journal of Chem. Phys. </journal> <volume> 21 (1953), </volume> <pages> 10871092. </pages>
Reference-contexts: For generating a new candidate state ~u j , most versions of simulated annealing use a simple scheme called Gibbs sampling where only one randomly chosen variable is allowed to change its value to a new randomly chosen value. In Metropolis-Hastings version <ref> [17, 9] </ref> of simulated annealing the acceptance probability is detned as A ij (T ) = 1 ; if exp ( T ) 1; V (~u j )V (~u i ) T ) ; otherwise, whereas Barker [3] has introduced an alternative method with acceptance probabilities of the form A ij
Reference: [18] <author> Myllymki, P., </author> <title> Bayesian reasoning by stochastic neural networks. Ph.Lic. </title> <type> Thesis, Report C-1993-67, </type> <institution> Department of Computer Science, University of Helsinki, </institution> <year> 1993. </year>
Reference-contexts: As has been noted in several occasions <ref> [13, 15, 16, 30, 21, 18] </ref>, these cliques can be used to con struct an undirected graphical Markov random teld model of the probability distribution P, which 271 means that the joint probability distribution (1) for a Bayesian network representation can also be expressed as a Gibbs distribution Pf~ug = Z
Reference: [19] <author> Myllymki, P., </author> <title> Using Bayesian networks for incorporating probabilistic a priori knowledge into Boltzmann machines. </title> <booktitle> Pp.97-102 in Proceedings of SOUTHCON'94 (Orlando, </booktitle> <month> March </month> <year> 1994). </year>
Reference-contexts: The NN architecture proposed here is a Boltzmann machine with two layers of stochastic units, where all the units on one layer are updated at the same time. Compared to the models suggested in <ref> [21, 19] </ref>, the mapping proposed here is more general as it allows multivalued attributes, whereas the earlier models assumed the variables to be binary. The resulting NN updating process provably converges to a state which can be projected to a MAP solution on the original BN structure.
Reference: [20] <author> Myllymki, P., </author> <title> Finding MAP Instantiations of Bayesian Networks by Stochastic Neural Networks. </title> <type> Ph.D. Thesis, </type> <institution> University of Helsinki, Department of Computer Science (in preparation). </institution>
Reference-contexts: Let us consider a state ~s, and let ~s 0 be a new state which is produced by changing the state of node S i . It is now relatively easy too see <ref> [20] </ref> that the dierence in consensus between the two states is exactly the net input in (6): V (~s 0 ) V (~s) = j it follows that the BM updating process can be regarded as a Gibbs sampling process with accep tance probabilities identical to those given in (4), with <p> For a more detailed description of the test results, we refer to <ref> [20] </ref>. 7 Conclusion and future work We presented a method for solving a given Bayesian network MAP problem by a massively parallel neural network computer. From the Bayesian network point of view, the mapping oers a possibility to speed up a simulated annealing process for solving MAP problems.
Reference: [21] <author> Myllymki, P., and Orponen,P., </author> <booktitle> Programming the Harmonium. </booktitle> <pages> Pp. </pages> <booktitle> 671677 in Proceedings of the International Joint Conference on Neural Networks (Singapore, November 1991), </booktitle> <volume> Vol. 1. </volume> <publisher> IEEE, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: The NN architecture proposed here is a Boltzmann machine with two layers of stochastic units, where all the units on one layer are updated at the same time. Compared to the models suggested in <ref> [21, 19] </ref>, the mapping proposed here is more general as it allows multivalued attributes, whereas the earlier models assumed the variables to be binary. The resulting NN updating process provably converges to a state which can be projected to a MAP solution on the original BN structure. <p> As has been noted in several occasions <ref> [13, 15, 16, 30, 21, 18] </ref>, these cliques can be used to con struct an undirected graphical Markov random teld model of the probability distribution P, which 271 means that the joint probability distribution (1) for a Bayesian network representation can also be expressed as a Gibbs distribution Pf~ug = Z
Reference: [22] <author> Myllymki, P., and Tirri, H., </author> <title> Constructing computationally ecient Bayesian models via unsupervised clustering. Pp. 237248 in Probabilistic Reasoning and Bayesian Belief Networks, edited by A.Gammerman. </title> <publisher> Alfred Waller Publishers, </publisher> <month> Suolk </month> <year> 1995. </year>
Reference-contexts: Alternatively, clustering can also be done by introducing new latent variables 269 which represent separate clusters of original variables <ref> [4, 22] </ref>. The latent variable model oers an interesting opportunity for constructing Bayesian networks from data using unsupervised learning algorithms.
Reference: [23] <author> Neapolitan, R.E., </author> <title> Probabilistic Reasoning in Expert Systems. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: As in diagnostic applications this kind of a system would provide the user the best explanation for a given set of symptoms, the solution is sometimes called the most probable explanation [24], and the task of obtaining the MAP solution is sometimes referred to as abductive inference <ref> [23] </ref>. It has been shown that the MAP problem for Bayesian networks belongs to the class of NP-hard problems with respect to the size of the corresponding network [1, 28], and hence the MAP problem is probably intractable (in the worst case sense) for Bayesian networks in general. <p> However, for singly-connected Bayesian network structures (networks with at most one path between any two variables, disregarding the direction of the connecting arc), the MAP problem can be solved in polynomial time <ref> [24, 23] </ref>. Consequently, most existing systems for Bayesian reasoning transform trst a given multi-connected BN structure to a singly-connected network, and use then the existing polynomial-time algorithms. <p> In the teld of decision theory, a model similar to Bayesian networks is known as inuence diagrams [12]. Rigorous introductions to the Bayesian network theory can be found in <ref> [24, 23] </ref>.
Reference: [24] <author> Pearl, J., </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: As in diagnostic applications this kind of a system would provide the user the best explanation for a given set of symptoms, the solution is sometimes called the most probable explanation <ref> [24] </ref>, and the task of obtaining the MAP solution is sometimes referred to as abductive inference [23]. <p> However, for singly-connected Bayesian network structures (networks with at most one path between any two variables, disregarding the direction of the connecting arc), the MAP problem can be solved in polynomial time <ref> [24, 23] </ref>. Consequently, most existing systems for Bayesian reasoning transform trst a given multi-connected BN structure to a singly-connected network, and use then the existing polynomial-time algorithms. <p> Consequently, most existing systems for Bayesian reasoning transform trst a given multi-connected BN structure to a singly-connected network, and use then the existing polynomial-time algorithms. This transformation can be done either explicitly by clustering several nodes together as in [16, 26] or <ref> [24, Ch.4.4.1] </ref>, or implicitly by blocking multiply connected paths by conditioning a set of variables as in [24, Ch.4.4.2] (for a discussion of dierent transformation techniques, see [27]). Alternatively, clustering can also be done by introducing new latent variables 269 which represent separate clusters of original variables [4, 22]. <p> This transformation can be done either explicitly by clustering several nodes together as in [16, 26] or [24, Ch.4.4.1], or implicitly by blocking multiply connected paths by conditioning a set of variables as in <ref> [24, Ch.4.4.2] </ref> (for a discussion of dierent transformation techniques, see [27]). Alternatively, clustering can also be done by introducing new latent variables 269 which represent separate clusters of original variables [4, 22]. The latent variable model oers an interesting opportunity for constructing Bayesian networks from data using unsupervised learning algorithms. <p> In the teld of decision theory, a model similar to Bayesian networks is known as inuence diagrams [12]. Rigorous introductions to the Bayesian network theory can be found in <ref> [24, 23] </ref>.
Reference: [25] <editor> Rumelhart, D.E. and McClelland, J.L., </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> Vol. 1. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference: [26] <author> Shachter, R.D., </author> <title> Probabilistic Inference and Inuence Diagrams. </title> <journal> Operations Research, </journal> <volume> 36 (1988) 4 (July-August), </volume> <pages> 589604. </pages>
Reference-contexts: Consequently, most existing systems for Bayesian reasoning transform trst a given multi-connected BN structure to a singly-connected network, and use then the existing polynomial-time algorithms. This transformation can be done either explicitly by clustering several nodes together as in <ref> [16, 26] </ref> or [24, Ch.4.4.1], or implicitly by blocking multiply connected paths by conditioning a set of variables as in [24, Ch.4.4.2] (for a discussion of dierent transformation techniques, see [27]).
Reference: [27] <author> Shachter, R.D., </author> <title> Evidence absorption and propagation through evidence reversals. </title> <journal> Pp. </journal> <volume> 173190 [10]. </volume>
Reference-contexts: This transformation can be done either explicitly by clustering several nodes together as in [16, 26] or [24, Ch.4.4.1], or implicitly by blocking multiply connected paths by conditioning a set of variables as in [24, Ch.4.4.2] (for a discussion of dierent transformation techniques, see <ref> [27] </ref>). Alternatively, clustering can also be done by introducing new latent variables 269 which represent separate clusters of original variables [4, 22]. The latent variable model oers an interesting opportunity for constructing Bayesian networks from data using unsupervised learning algorithms.
Reference: [28] <author> Shimony, </author> <title> S.E., Finding MAPs for belief networks is NP-hard. </title> <booktitle> Artitcial Intelligence 68 (1994), </booktitle> <pages> 399-410. </pages>
Reference-contexts: It has been shown that the MAP problem for Bayesian networks belongs to the class of NP-hard problems with respect to the size of the corresponding network <ref> [1, 28] </ref>, and hence the MAP problem is probably intractable (in the worst case sense) for Bayesian networks in general.
Reference: [29] <author> Smolensky, P., </author> <booktitle> Information processing in dynamical systems: Foundations of Harmony Theory. </booktitle> <pages> Pp. </pages> <note> 194-281 in [25]. </note>
Reference: [30] <author> Spiegelhalter, </author> <title> D.J., Probabilistic reasoning in predictive expert systems. Pp. </title> <booktitle> 4767 in Uncertainty in Artitcial Intelligence edited by L.N.Kanal and J.F.Lemmer. </booktitle> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1986. </year> <month> 280 </month>
Reference-contexts: As has been noted in several occasions <ref> [13, 15, 16, 30, 21, 18] </ref>, these cliques can be used to con struct an undirected graphical Markov random teld model of the probability distribution P, which 271 means that the joint probability distribution (1) for a Bayesian network representation can also be expressed as a Gibbs distribution Pf~ug = Z
References-found: 29

