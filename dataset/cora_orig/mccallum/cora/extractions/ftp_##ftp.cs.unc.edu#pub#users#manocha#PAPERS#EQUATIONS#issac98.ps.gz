URL: ftp://ftp.cs.unc.edu/pub/users/manocha/PAPERS/EQUATIONS/issac98.ps.gz
Refering-URL: http://www.cs.unc.edu/~geom/chron.html
Root-URL: http://www.cs.unc.edu
Email: awallack@cognex.com  emiris@sophia.inria.fr,  dm@cs.unc.edu,  
Author: Ioannis Z. Emiris Dinesh Manocha 
Web: http://www.inria.fr/safir/emiris  http://www.cs.unc.edu/~dm  
Address: Drive, Natick MA 01760, USA.  B.P. 93, Sophia-Antipolis 06902, France.  UNC, Chapel Hill NC 27599-3175, USA.  
Affiliation: Vision  INRIA,  Department of Computer Science,  
Note: Aaron Wallack Cognex Corporation, 1  
Abstract: MARS: A Maple/Matlab/C Resultant-based Solver Abstract The problem of computing zeros of a system of polynomial equations has been well studied in the computational literature. A number of algorithms have been proposed and many computer algebra and public domain packages provide the capability of computing the roots of polynomial equations. Most of these implementations are based on Grobner bases which can be slow for even small problems. In this paper, we present a new system, MARS, to compute the roots of a zero dimensional polynomial system. It is based on computing the resultant of a system of polynomial equations followed by eigendecompo-sition of a generalized companion matrix. MARS includes a robust library of Maple functions for constructing resultant matrices, an efficient library of Matlab routines for numerically solving the eigenproblem, and C code generation routines and a C library for incorporating the numerical solver into applications. We illustrate the usage of MARS on various examples and utilize different resultant formulations. 
Abstract-found: 1
Intro-found: 1
Reference: [AS88] <author> W. Auzinger and H.J. Stetter, </author> <title> An elimination algorithm for the computation of all zeros of a system of multivariate polynomial equations, </title> <booktitle> In Proc. Intern. Conf. on Numerical Math., Intern. Series of Numerical Math., </booktitle> <volume> 86, </volume> <pages> pages 12-30, </pages> <address> 1988. </address> <publisher> Birkhauser, Basel. </publisher>
Reference-contexts: This resultant is known as the multipolynomial resultant the given system of polynomial equations <ref> [AS88, Man94, MC94] </ref>. The multipolynomial resultant of the system of polynomial equations can be used for eliminating the variables and computing the numeric solutions of a given system of polynomial equations. The same approach is also valid in the non-homogeneous context, as illustrated later.
Reference: [CE93] <author> J. Canny and I. Emiris. </author> <title> An efficient algorithm for the sparse mixed resultant. </title> <editor> In G. Cohen, T. Mora, and O. Moreno, editors, </editor> <booktitle> Proc. Intern. Symp. on Applied Algebra, Algebraic Algor. and Error-Corr. Codes, Lect. Notes in Comp. Science 263, </booktitle> <pages> pages 89-104, </pages> <address> Puerto Rico, 1993. </address> <publisher> Springer. </publisher>
Reference-contexts: Sparse elimination defines the sparse, or toric, resultant, whose degree depends on these convex polytopes instead of the total degrees. Canny et al. described a construction based on a mixed subdivision of the Newton polytopes of the input polynomial system <ref> [CE93, CP93] </ref>. A direct incremental method yields smaller matrices [EC95, Emi97]. 3.1.3 Bezout matrices The second branch of resultant matrix constructions stems from Bezout's method for the resultant of two univariate polynomials. <p> Current work is con centrating on numeric methods for transforming the matrix problem in a numerically stable way so that multiple roots are identified and degeneracies are avoided. Another approach is based on perturbation techniques. For more information see <ref> [KL92, CE93, Man94, MD95, Mou97] </ref> and the references thereof. 4 MARS description In this section, we present an overview of the MARS package. Then, we discuss the design goals. 4.1 MARS Architecture The MARS package is implemented in Maple, Matlab, and C.
Reference: [CGT97] <author> R.M. Corless, P.M. Gianni, and B.M. Trager. </author> <title> A reordered Schur factorization method for zero-dimensional polynomial systems with multiple roots. </title> <booktitle> In Proc. ACM Intern. Symp. on Symbolic and Algebraic Computation, </booktitle> <pages> pages 133-140, </pages> <year> 1997. </year>
Reference-contexts: Some use of resultants can also be found in other systems, such as CASA, developed at RISC-Linz. Different specialized modules based on resultant matrices exist for solving systems of polynomial equations, e.g. <ref> [CGT97, CP93, Emi97, KM95, KS96, MP97, Reg95] </ref>. Typically, these programs would rely on Linpack, Eispack, Lapack, or Mat-lab for their numerical calculations. All of these programs implement one or, exceptionally, two kinds of matrices, and are not designed for wide distribution, so they lack in user-friendliness.
Reference: [CM96] <author> J.-P. Cardinal and B. Mourrain. </author> <title> Algebraic approach of residues and applications. </title> <editor> In J. Renegar, M. Shub, and S. Smale, editors, </editor> <booktitle> The Mathematics of Numerical Analysis, volume 32 of Lectures in Applied Math., </booktitle> <pages> pages 189-210. </pages> <publisher> AMS, </publisher> <year> 1996. </year>
Reference-contexts: Bezout's matrix has been generalized to arbitrary systems. Although the above method does not always yield a square matrix, it is always possible to define a square maximal sub-matrix whose determinant is a nontrivial multiple of the resultant <ref> [CM96, EM97] </ref>. There is a rich algebraic theory behind these matrices, based on algebraic residues, which shows that Bezout matrices behave better for several degenerate input systems. Moreover, Bezout's matrix has smaller size than Macaulay's and the sparse resultant matrix.
Reference: [CP93] <author> J. Canny and P. Pedersen. </author> <title> An algorithm for the Newton resultant. </title> <type> Technical Report 1394, </type> <institution> Comp. Science Dept., Cornell University, </institution> <year> 1993. </year>
Reference-contexts: Some use of resultants can also be found in other systems, such as CASA, developed at RISC-Linz. Different specialized modules based on resultant matrices exist for solving systems of polynomial equations, e.g. <ref> [CGT97, CP93, Emi97, KM95, KS96, MP97, Reg95] </ref>. Typically, these programs would rely on Linpack, Eispack, Lapack, or Mat-lab for their numerical calculations. All of these programs implement one or, exceptionally, two kinds of matrices, and are not designed for wide distribution, so they lack in user-friendliness. <p> Sparse elimination defines the sparse, or toric, resultant, whose degree depends on these convex polytopes instead of the total degrees. Canny et al. described a construction based on a mixed subdivision of the Newton polytopes of the input polynomial system <ref> [CE93, CP93] </ref>. A direct incremental method yields smaller matrices [EC95, Emi97]. 3.1.3 Bezout matrices The second branch of resultant matrix constructions stems from Bezout's method for the resultant of two univariate polynomials.
Reference: [EC95] <author> I.Z. Emiris and J.F. Canny. </author> <title> Efficient incremental algorithms for the sparse resultant and the mixed volume. </title> <journal> J. Symbolic Computation, </journal> <volume> 20(2) </volume> <pages> 117-149, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Sparse elimination defines the sparse, or toric, resultant, whose degree depends on these convex polytopes instead of the total degrees. Canny et al. described a construction based on a mixed subdivision of the Newton polytopes of the input polynomial system [CE93, CP93]. A direct incremental method yields smaller matrices <ref> [EC95, Emi97] </ref>. 3.1.3 Bezout matrices The second branch of resultant matrix constructions stems from Bezout's method for the resultant of two univariate polynomials. Let these polynomials be f 1 (x); f 2 (x), of degrees d 1 d 2 respectively, and let y be a new variable.
Reference: [EM96] <author> I.Z. Emiris and B. Mourrain. </author> <title> Polynomial system solving: The case of a 6-atom molecule. </title> <type> Technical Report 3075, </type> <institution> INRIA Sophia-Antipolis, France, </institution> <year> 1996. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics [MC94, RR95, WC97], computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy <ref> [EM96] </ref>. The main operations in these applications can be classified into two types. First, the simultaneous elimination of one or more variables from a given set of polynomial equations to obtain a "symbolically smaller" system.
Reference: [EM97] <author> I.Z. Emiris and B. Mourrain. </author> <title> Matrices in elimination theory. </title> <journal> J. Symbolic Computation, </journal> <note> Special Issue on Elimination, 1997. Submitted. </note>
Reference-contexts: In addition, for solving polynomial systems these matrices are sufficient, since they reduce the given nonlinear problem to a question in linear algebra. For details see <ref> [KL92, EM97] </ref>. Resultant matrices can be classified into two large families. The first type includes Sylvester matrices and their classic generalization by Macaulay. In the context of sparse elimination theory, there are matrices that generalize Sylvester's and Macaulay's formulations and known as sparse, or toric, resultant matrices. <p> Bezout's matrix has been generalized to arbitrary systems. Although the above method does not always yield a square matrix, it is always possible to define a square maximal sub-matrix whose determinant is a nontrivial multiple of the resultant <ref> [CM96, EM97] </ref>. There is a rich algebraic theory behind these matrices, based on algebraic residues, which shows that Bezout matrices behave better for several degenerate input systems. Moreover, Bezout's matrix has smaller size than Macaulay's and the sparse resultant matrix.
Reference: [Emi97] <author> I.Z. Emiris. </author> <title> A general solver based on sparse resultants: Numerical issues and kinematic applications. </title> <type> Technical Report 3110, </type> <institution> INRIA Sophia-Antipolis, France, </institution> <year> 1997. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics [MC94, RR95, WC97], computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision <ref> [Emi97, WM98] </ref>, economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types. First, the simultaneous elimination of one or more variables from a given set of polynomial equations to obtain a "symbolically smaller" system. <p> Some use of resultants can also be found in other systems, such as CASA, developed at RISC-Linz. Different specialized modules based on resultant matrices exist for solving systems of polynomial equations, e.g. <ref> [CGT97, CP93, Emi97, KM95, KS96, MP97, Reg95] </ref>. Typically, these programs would rely on Linpack, Eispack, Lapack, or Mat-lab for their numerical calculations. All of these programs implement one or, exceptionally, two kinds of matrices, and are not designed for wide distribution, so they lack in user-friendliness. <p> Sparse elimination defines the sparse, or toric, resultant, whose degree depends on these convex polytopes instead of the total degrees. Canny et al. described a construction based on a mixed subdivision of the Newton polytopes of the input polynomial system [CE93, CP93]. A direct incremental method yields smaller matrices <ref> [EC95, Emi97] </ref>. 3.1.3 Bezout matrices The second branch of resultant matrix constructions stems from Bezout's method for the resultant of two univariate polynomials. Let these polynomials be f 1 (x); f 2 (x), of degrees d 1 d 2 respectively, and let y be a new variable. <p> Our method reduces solving a zero-dimensional system to either a regular or a generalized eigenproblem, thus transforming the nonlinear question to a problem in linear algebra. This is a classical technique that enables us to approximate all solutions; see e.g. <ref> [Man94, Emi97] </ref> and the references thereof. Several extensions to positive-dimensional systems have been explored [KM95] or are currently under investigation.
Reference: [Fau95] <author> J.-C. Faugere. </author> <title> State of GB and tutorial. </title> <booktitle> In Proc. PoSSo (Polynomial System Solving) Workshop on Software, </booktitle> <pages> pages 55-71, </pages> <address> Paris, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Grobner bases have been studied for a longer time and offer an array of general implementations to efficiently handle zero-dimensional systems. For the purposes of illustration, we mention only very few representatives, namely GB <ref> [Fau95] </ref> and the PoSSo/FRISCO library [FRI97]. Most computer algebra systems, like Axiom, Mathematica, Maple and Reduce have a package for computing the Grobner bases of an ideal. One of the main drawbacks of using Grobner bases is that the method may be slow for even small problems.
Reference: [FRI97] <editor> FRISCO. </editor> <booktitle> First year report, </booktitle> <month> February </month> <year> 1997. </year> <note> http://extweb.nag.co.uk/projects/ FRISCO.html. </note>
Reference-contexts: Grobner bases have been studied for a longer time and offer an array of general implementations to efficiently handle zero-dimensional systems. For the purposes of illustration, we mention only very few representatives, namely GB [Fau95] and the PoSSo/FRISCO library <ref> [FRI97] </ref>. Most computer algebra systems, like Axiom, Mathematica, Maple and Reduce have a package for computing the Grobner bases of an ideal. One of the main drawbacks of using Grobner bases is that the method may be slow for even small problems.
Reference: [Gon91] <author> L. Gonzalez-Vega. </author> <title> Determinantal formulae for the solution set of zero-dimensional ideals, </title> <journal> J. Pure Applied Algebra, </journal> <volume> 76 </volume> <pages> 57-80, </pages> <year> 1991. </year>
Reference-contexts: Directions of further algorithmic work include the use of matrix structure for reducing the time as well as space complexity of our methods, and the study of genericity conditions, as in e.g. <ref> [Gon91] </ref>. Acknowledgments I.E. was partially supported by European ESPRIT project FRISCO (LTR 21.024) and acknowledges enlightening car commutes with Bernard Mourrain. D.M. has been supported by an Alfred P. Sloan Foundation Fellowship, ARO Contract DAAH04-96-1-0257, NSF Grant CCR-9319957, NSF Career Award CCR-9625217, ONR Young Investigator Award (N00014-97-1-0631) and Intel.
Reference: [Hof89] <author> C.M. Hoffmann, </author> <title> Geometric and Solid Modeling, </title> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, California, </address> <year> 1989. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics [MC94, RR95, WC97], computer graphics [Man94], geometric and solid modeling <ref> [Hof89, MD95] </ref>, computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types. First, the simultaneous elimination of one or more variables from a given set of polynomial equations to obtain a "symbolically smaller" system.
Reference: [KL92] <author> D. Kapur and Y.N. Lakshman. </author> <title> Elimination methods: An introduction. </title> <editor> In B. Donald, D. Kapur, and J. Mundy, editors, </editor> <booktitle> Symbolic and Numerical Computation for Artificial Intelligence, </booktitle> <pages> pages 45-88. </pages> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: In addition, for solving polynomial systems these matrices are sufficient, since they reduce the given nonlinear problem to a question in linear algebra. For details see <ref> [KL92, EM97] </ref>. Resultant matrices can be classified into two large families. The first type includes Sylvester matrices and their classic generalization by Macaulay. In the context of sparse elimination theory, there are matrices that generalize Sylvester's and Macaulay's formulations and known as sparse, or toric, resultant matrices. <p> Current work is con centrating on numeric methods for transforming the matrix problem in a numerically stable way so that multiple roots are identified and degeneracies are avoided. Another approach is based on perturbation techniques. For more information see <ref> [KL92, CE93, Man94, MD95, Mou97] </ref> and the references thereof. 4 MARS description In this section, we present an overview of the MARS package. Then, we discuss the design goals. 4.1 MARS Architecture The MARS package is implemented in Maple, Matlab, and C.
Reference: [KM95] <author> S. Krishnan and D. Manocha. </author> <title> Numeric-symbolic algorithms for evaluating one-dimensional algebraic sets. </title> <booktitle> In Proc. ACM Intern. Symp. on Symbolic and Algebraic Computation, </booktitle> <pages> pages 59-67, </pages> <year> 1995. </year>
Reference-contexts: Some use of resultants can also be found in other systems, such as CASA, developed at RISC-Linz. Different specialized modules based on resultant matrices exist for solving systems of polynomial equations, e.g. <ref> [CGT97, CP93, Emi97, KM95, KS96, MP97, Reg95] </ref>. Typically, these programs would rely on Linpack, Eispack, Lapack, or Mat-lab for their numerical calculations. All of these programs implement one or, exceptionally, two kinds of matrices, and are not designed for wide distribution, so they lack in user-friendliness. <p> This is a classical technique that enables us to approximate all solutions; see e.g. [Man94, Emi97] and the references thereof. Several extensions to positive-dimensional systems have been explored <ref> [KM95] </ref> or are currently under investigation. An overconstrained system is obtained by adding extra polynomial f n+1 (x; u) to the given system f 1 (x); : : : ; f n (x), where x = (x 1 ; : : : ; x n ).
Reference: [KS96] <author> D. Kapur and T. Saxena. </author> <title> Sparsity considerations in Dixon resultants. </title> <booktitle> In Proc. ACM Symp. Theory of Computing, </booktitle> <pages> pages 184-191, </pages> <year> 1996. </year>
Reference-contexts: Some use of resultants can also be found in other systems, such as CASA, developed at RISC-Linz. Different specialized modules based on resultant matrices exist for solving systems of polynomial equations, e.g. <ref> [CGT97, CP93, Emi97, KM95, KS96, MP97, Reg95] </ref>. Typically, these programs would rely on Linpack, Eispack, Lapack, or Mat-lab for their numerical calculations. All of these programs implement one or, exceptionally, two kinds of matrices, and are not designed for wide distribution, so they lack in user-friendliness.
Reference: [Mac02] <editor> F.S. </editor> <booktitle> Macaulay On Some Formula in Elimination Proceedings of London Mathematical Society, </booktitle> <pages> pages 3-27, </pages> <month> May </month> <year> 1902. </year>
Reference-contexts: Then Sylvester's construction is applied repeatedly, albeit with a high overhead, because this technique introduces many superfluous solutions. Macaulay devised a method that generalizes Sylvester's construction to systems of an arbitrary number of polynomials, under the hypothesis that these polynomials are completely dense <ref> [Mac02] </ref>.
Reference: [Man92] <author> D. Manocha. </author> <title> Algebraic and Numeric Techniques for Modeling and Robotics. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, University of California, Berkeley, </institution> <year> 1992. </year>
Reference: [Man94] <author> D. Manocha. </author> <title> Solving systems of polynomial equations. </title> <journal> IEEE Comp. Graphics and Appl., Special Issue on Solid Modeling, </journal> <pages> pages 46-55, </pages> <year> 1994. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics [MC94, RR95, WC97], computer graphics <ref> [Man94] </ref>, geometric and solid modeling [Hof89, MD95], computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types. <p> This resultant is known as the multipolynomial resultant the given system of polynomial equations <ref> [AS88, Man94, MC94] </ref>. The multipolynomial resultant of the system of polynomial equations can be used for eliminating the variables and computing the numeric solutions of a given system of polynomial equations. The same approach is also valid in the non-homogeneous context, as illustrated later. <p> Our method reduces solving a zero-dimensional system to either a regular or a generalized eigenproblem, thus transforming the nonlinear question to a problem in linear algebra. This is a classical technique that enables us to approximate all solutions; see e.g. <ref> [Man94, Emi97] </ref> and the references thereof. Several extensions to positive-dimensional systems have been explored [KM95] or are currently under investigation. <p> Current work is con centrating on numeric methods for transforming the matrix problem in a numerically stable way so that multiple roots are identified and degeneracies are avoided. Another approach is based on perturbation techniques. For more information see <ref> [KL92, CE93, Man94, MD95, Mou97] </ref> and the references thereof. 4 MARS description In this section, we present an overview of the MARS package. Then, we discuss the design goals. 4.1 MARS Architecture The MARS package is implemented in Maple, Matlab, and C.
Reference: [MC94] <author> D. Manocha and J.F. Canny. </author> <title> Efficient inverse kinematics for general 6R manipulators. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 10(5) </volume> <pages> 648-657, </pages> <year> 1994. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics <ref> [MC94, RR95, WC97] </ref>, computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types. <p> This resultant is known as the multipolynomial resultant the given system of polynomial equations <ref> [AS88, Man94, MC94] </ref>. The multipolynomial resultant of the system of polynomial equations can be used for eliminating the variables and computing the numeric solutions of a given system of polynomial equations. The same approach is also valid in the non-homogeneous context, as illustrated later.
Reference: [MD95] <author> D. Manocha and J. Demmel. </author> <title> Algorithms for intersecting parametric and algebraic curves II: Multiple intersections. </title> <booktitle> Graphical Models and Image Proc., </booktitle> <volume> 57(2) </volume> <pages> 81-100, </pages> <year> 1995. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics [MC94, RR95, WC97], computer graphics [Man94], geometric and solid modeling <ref> [Hof89, MD95] </ref>, computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types. First, the simultaneous elimination of one or more variables from a given set of polynomial equations to obtain a "symbolically smaller" system. <p> Current work is con centrating on numeric methods for transforming the matrix problem in a numerically stable way so that multiple roots are identified and degeneracies are avoided. Another approach is based on perturbation techniques. For more information see <ref> [KL92, CE93, Man94, MD95, Mou97] </ref> and the references thereof. 4 MARS description In this section, we present an overview of the MARS package. Then, we discuss the design goals. 4.1 MARS Architecture The MARS package is implemented in Maple, Matlab, and C.
Reference: [MM94] <author> R.D. McKelvey and A. McLennan. </author> <title> The maximal number of regular totally mixed Nash equilibria. </title> <type> Technical Report 865, </type> <institution> Div. of the Humanities and Social Sciences, California Institute of Technology, Pasadena, Calif., </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics [MC94, RR95, WC97], computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision [Emi97, WM98], economics and optimization <ref> [MM94] </ref>, and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types. First, the simultaneous elimination of one or more variables from a given set of polynomial equations to obtain a "symbolically smaller" system.
Reference: [Mou97] <author> B. Mourrain. </author> <title> Solving polynomial systems by matrix computations. </title> <type> Manuscript. </type> <institution> INRIA Sophia-Antipolis, France. </institution> <note> Submitted for publication, </note> <year> 1997. </year>
Reference-contexts: Current work is con centrating on numeric methods for transforming the matrix problem in a numerically stable way so that multiple roots are identified and degeneracies are avoided. Another approach is based on perturbation techniques. For more information see <ref> [KL92, CE93, Man94, MD95, Mou97] </ref> and the references thereof. 4 MARS description In this section, we present an overview of the MARS package. Then, we discuss the design goals. 4.1 MARS Architecture The MARS package is implemented in Maple, Matlab, and C.
Reference: [MP97] <author> B. Mourrain and V.Y. Pan. </author> <title> Solving special polynomial systems by using structured matrices and algebraic residues. </title> <editor> In F. Cucker and M. Shub, editors, </editor> <booktitle> Proc. Workshop on Foundations of Computational Mathematics, </booktitle> <pages> pages 287-304, </pages> <address> Berlin, 1997. </address> <publisher> Springer. </publisher>
Reference-contexts: Some use of resultants can also be found in other systems, such as CASA, developed at RISC-Linz. Different specialized modules based on resultant matrices exist for solving systems of polynomial equations, e.g. <ref> [CGT97, CP93, Emi97, KM95, KS96, MP97, Reg95] </ref>. Typically, these programs would rely on Linpack, Eispack, Lapack, or Mat-lab for their numerical calculations. All of these programs implement one or, exceptionally, two kinds of matrices, and are not designed for wide distribution, so they lack in user-friendliness.
Reference: [MSW94] <author> A.P. Morgan, A.J. Sommese, and C.W. Wampler. </author> <title> A product-decomposition bound for Bezout numbers. </title> <journal> SIAM J. Numerical Analysis, </journal> <volume> 32(4), </volume> <year> 1994. </year>
Reference-contexts: This is a rather difficult prerequisite for most applications. Homotopy methods have a good theoretical background and proceed by following paths in the complex space. In theory, each path converges to a geometrically isolated solution. They have been implemented and tried on a variety of applications. e.g. <ref> [MSW94, VVC94] </ref>. In practice, however, current homotopy implementations and algorithms suffer from many problems. The different paths being followed may not be geometrically isolated. As a result, each path has to be at times followed with impractically tight tolerances, which slows down the overall algorithm.
Reference: [Reg95] <author> A. </author> <title> Rege. A complete and practical algorithm for geometric theorem proving. </title> <booktitle> In Proc. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 277-286, </pages> <address> Vancouver, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Some use of resultants can also be found in other systems, such as CASA, developed at RISC-Linz. Different specialized modules based on resultant matrices exist for solving systems of polynomial equations, e.g. <ref> [CGT97, CP93, Emi97, KM95, KS96, MP97, Reg95] </ref>. Typically, these programs would rely on Linpack, Eispack, Lapack, or Mat-lab for their numerical calculations. All of these programs implement one or, exceptionally, two kinds of matrices, and are not designed for wide distribution, so they lack in user-friendliness.
Reference: [Ren92] <author> J. Renegar. </author> <title> On the computational complexity of the first-order theory of the reals. </title> <journal> J. Symbolic Computation, </journal> <volume> 13(3) </volume> <pages> 255-352, </pages> <year> 1992. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra <ref> [Ren92] </ref>, robotics [MC94, RR95, WC97], computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types.
Reference: [RR95] <author> M. Raghavan and B. Roth. </author> <title> Solving polynomial systems for the kinematics analysis and synthesis of mechanisms and robot manipulators. </title> <journal> Trans. ASME, Special 50th Annivers. Design Issue, </journal> <volume> 117 </volume> <pages> 71-79, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics <ref> [MC94, RR95, WC97] </ref>, computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types.
Reference: [VVC94] <author> J. Verschelde, P. Verlinden, and R. Cools. </author> <title> Homotopies exploiting Newton polytopes for solving sparse polynomial systems. </title> <journal> SIAM J. Numerical Analysis, </journal> <volume> 31(3) </volume> <pages> 915-930, </pages> <year> 1994. </year>
Reference-contexts: This is a rather difficult prerequisite for most applications. Homotopy methods have a good theoretical background and proceed by following paths in the complex space. In theory, each path converges to a geometrically isolated solution. They have been implemented and tried on a variety of applications. e.g. <ref> [MSW94, VVC94] </ref>. In practice, however, current homotopy implementations and algorithms suffer from many problems. The different paths being followed may not be geometrically isolated. As a result, each path has to be at times followed with impractically tight tolerances, which slows down the overall algorithm.
Reference: [WC97] <author> A. Wallack and J. Canny. </author> <title> Planning for modular and hybrid fixtures. </title> <journal> Algorithmica, </journal> <volume> 19 </volume> <pages> 40-60, </pages> <year> 1997. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics <ref> [MC94, RR95, WC97] </ref>, computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision [Emi97, WM98], economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types.
Reference: [WEM98] <author> A. Wallack and I. Emiris and D. Manocha MARS: </author> <note> A Maple/Matlab/C Resultant-based Solver Technical Report TR98-020, </note> <institution> Dept. of Computer Science, University of North Car-olina, Chapel Hill, </institution> <month> April </month> <year> 1998. </year>
Reference-contexts: Main Contributions: The main contribution of our work is a software package consisting of Maple, Matlab and C libraries for solving zero-dimensional systems (a more thorough review can be found in <ref> [WEM98] </ref>). Given a system, MARS computes the resultant as a matrix polynomial and numerically solving the resultant matrices. MARS simplifies the task of incorporating a numerical multipolynomial solver into a user's application.
Reference: [WM98] <author> A. Wallack and D. Manocha. </author> <title> Robust algorithms for object localization. </title> <journal> Intern. J. Comp. Vision, </journal> <volume> 27(3) </volume> <pages> 243-262, </pages> <year> 1998. </year>
Reference-contexts: Recently, a great deal of interest in solving nonlinear polynomial systems has come from different applications. It includes computer algebra [Ren92], robotics [MC94, RR95, WC97], computer graphics [Man94], geometric and solid modeling [Hof89, MD95], computer vision <ref> [Emi97, WM98] </ref>, economics and optimization [MM94], and molecular biol ogy [EM96]. The main operations in these applications can be classified into two types. First, the simultaneous elimination of one or more variables from a given set of polynomial equations to obtain a "symbolically smaller" system.
References-found: 32

