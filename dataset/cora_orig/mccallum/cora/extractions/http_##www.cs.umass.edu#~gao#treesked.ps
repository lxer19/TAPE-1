URL: http://www.cs.umass.edu/~gao/treesked.ps
Refering-URL: http://eksl-www.cs.umass.edu/~gregory/summaries/SPDP.html
Root-URL: 
Email: Email: fgao, rsnbrg, rameshg@cs.umass.edu  
Title: Optimal Architecture-Independent Scheduling of Fine-Grain Tree-Sweep Computations  
Author: Lixin Gao Arnold L. Rosenberg Ramesh K. Sitaraman 
Address: Amherst, Mass. 01003, USA  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: We present algorithms for optimally scheduling computations that comprise a sequence of complete up- and/or down-sweeps on a complete binary tree, on a parallel architecture in which the communication delay between any two processors is uniform. Such computations include, for instance, those that implement broadcast, accumulation, and the parallel-prefix operator; such architectures include, for instance, networks of workstations. Our schedules are optimal in the sense of having the actual minimum time-to-completion|not just an approximation thereof| considering the time for both computation and communication. We concentrate on schedules for fine-grain tree-sweep computations|wherein communication costs are rather large relative to per-task computation cost. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Afrati, C.H. Papadimitriou, G. </author> <title> Papageorgiou (1988): Scheduling dags to minimize time and communication. </title> <booktitle> VLSI Algorithms and Architectures (Aegean Wkshp. on Computing) Lecture Notes in Computer Science 319, </booktitle> <publisher> Springer-Verlag, Berlin, </publisher> <pages> 134-138. </pages>
Reference-contexts: Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in <ref> [1, 7] </ref>. For coarse-grain computations, one finds in [2] an o*ine polynomial-time algorithm to construct optimal schedules for tree-structured computation-dags.
Reference: [2] <author> P. </author> <month> Chretienne </month> <year> (1989): </year> <title> A polynomial algorithm to optimally schedule tasks on a virtual distributed system under tree-like precedence constraints. </title> <journal> European J. Operations Research 43, </journal> <pages> 225-230. </pages>
Reference-contexts: Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in [1, 7]. For coarse-grain computations, one finds in <ref> [2] </ref> an o*ine polynomial-time algorithm to construct optimal schedules for tree-structured computation-dags. Along the same general lines, [3, 4, 5] study optimal linear-clustering schedules for general dags (such schedules seek to assign nodes that lie on the same path in the computation-dag to the same processor).
Reference: [3] <author> A. Gerasoulis and T. </author> <title> Yang (1990): On the granularity and clustering of directed acyclic task graphs. </title> <type> Tech. </type> <institution> Rpt. LCSR-TR-153, Rutgers Univ. </institution>
Reference-contexts: Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in [1, 7]. For coarse-grain computations, one finds in [2] an o*ine polynomial-time algorithm to construct optimal schedules for tree-structured computation-dags. Along the same general lines, <ref> [3, 4, 5] </ref> study optimal linear-clustering schedules for general dags (such schedules seek to assign nodes that lie on the same path in the computation-dag to the same processor). It is proved in [3] that there is always an optimal schedule using linear clustering for coarse-grain computations. <p> Along the same general lines, [3, 4, 5] study optimal linear-clustering schedules for general dags (such schedules seek to assign nodes that lie on the same path in the computation-dag to the same processor). It is proved in <ref> [3] </ref> that there is always an optimal schedule using linear clustering for coarse-grain computations. Leaving the topic of optimal schedules, [8] shows that for general dags, there is an approximation algorithm that allows recomputation of tasks, which produces schedules whose times-to-completion are within a factor of 2 of optimum.
Reference: [4] <author> A. Gerasoulis and T. </author> <title> Yang (1992): A comparison of clustering heuristics for scheduling dags on multiprocessors. </title> <journal> J. Parallel Distr. Comput. </journal> <volume> 16, </volume> <pages> 276-291. </pages>
Reference-contexts: Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in [1, 7]. For coarse-grain computations, one finds in [2] an o*ine polynomial-time algorithm to construct optimal schedules for tree-structured computation-dags. Along the same general lines, <ref> [3, 4, 5] </ref> study optimal linear-clustering schedules for general dags (such schedules seek to assign nodes that lie on the same path in the computation-dag to the same processor). It is proved in [3] that there is always an optimal schedule using linear clustering for coarse-grain computations.
Reference: [5] <author> A. Gerasoulis and T. </author> <title> Yang (1992): Static scheduling of parallel programs for message passing architectures. </title> <booktitle> Parallel Processing: CONPAR 92 - VAPP V. Lecture Notes in Computer Science 634, </booktitle> <publisher> Springer-Verlag, Berlin, </publisher> <pages> 601-612. </pages>
Reference-contexts: Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in [1, 7]. For coarse-grain computations, one finds in [2] an o*ine polynomial-time algorithm to construct optimal schedules for tree-structured computation-dags. Along the same general lines, <ref> [3, 4, 5] </ref> study optimal linear-clustering schedules for general dags (such schedules seek to assign nodes that lie on the same path in the computation-dag to the same processor). It is proved in [3] that there is always an optimal schedule using linear clustering for coarse-grain computations.
Reference: [6] <author> H. Jung, L. Kirousis, P. </author> <title> Spirakis (1989): Lower bounds and efficient algorithms for multiprocessor scheduling of dags with communication delays. </title> <booktitle> 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> 254-264. </pages>
Reference-contexts: In general, the problem of finding an "architecture-independent" schedule that minimizes the time-to-completion for a given computation-dag and a given communication-overhead parameter t (that characterizes the architecture) is NP-hard [8]; in <ref> [6] </ref> one finds an algorithm for constructing such a schedule for an N - node dag in time O (N t ). Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in [1, 7].
Reference: [7] <author> J.K. Lenstra, M. Veldhorst, B. </author> <month> Veltman </month> <year> (1993): </year> <title> The complexity of scheduling trees with communication delays. </title> <booktitle> 1st European Symp. on Algorithms, Bad Honnef, </booktitle> <editor> Germany (T. Lengauer, ed.) </editor> <booktitle> Lecture Notes in Computer Science 726, </booktitle> <publisher> Springer-Verlag, Berlin, </publisher> <pages> 284-294. </pages>
Reference-contexts: Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in <ref> [1, 7] </ref>. For coarse-grain computations, one finds in [2] an o*ine polynomial-time algorithm to construct optimal schedules for tree-structured computation-dags.
Reference: [8] <author> C.H. Papadimitriou and M. </author> <title> Yannakakis (1990): Towards an architecture-independent analysis of parallel algorithms. </title> <journal> SIAM J. Comput. </journal> <volume> 19, </volume> <pages> 322-328. </pages>
Reference-contexts: Following sources such as <ref> [8] </ref>, we schedule our computations in an "architecture-independent" fashion, assuming only that the architectures consist of an adequate number of identical processors that have uniform computation costs| which we arbitrarily set at unit cost per task (= tree-node)|and uniform communication delay between any two processors|which we denote by the parameter t <p> In general, the problem of finding an "architecture-independent" schedule that minimizes the time-to-completion for a given computation-dag and a given communication-overhead parameter t (that characterizes the architecture) is NP-hard <ref> [8] </ref>; in [6] one finds an algorithm for constructing such a schedule for an N - node dag in time O (N t ). Polynomial-time algorithms for constructing optimal o*ine schedules for special classes of computation-dags are presented in [1, 7]. <p> It is proved in [3] that there is always an optimal schedule using linear clustering for coarse-grain computations. Leaving the topic of optimal schedules, <ref> [8] </ref> shows that for general dags, there is an approximation algorithm that allows recomputation of tasks, which produces schedules whose times-to-completion are within a factor of 2 of optimum. Using the approximation algorithm, [8] presents a schedule for 1-sweep N -node TS computations, with time-to-completion 2 (t = log t ) <p> Leaving the topic of optimal schedules, <ref> [8] </ref> shows that for general dags, there is an approximation algorithm that allows recomputation of tasks, which produces schedules whose times-to-completion are within a factor of 2 of optimum. Using the approximation algorithm, [8] presents a schedule for 1-sweep N -node TS computations, with time-to-completion 2 (t = log t ) log N ; no recomputation of tasks is needed in this case, because of the tree structure of the computation-dag.
References-found: 8

