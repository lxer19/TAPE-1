URL: ftp://ftp.cs.washington.edu/tr/1997/11/UW-CSE-97-11-03.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Scheduling Policies to Support Distributed 3D Multimedia Applications  
Author: Thu D. Nguyen and John Zahorjan 
Date: November 3, 1997  
Note: (submitted for publication)  This work was supported in part by the National Science Foundation (Grants CCR-9704503 and CCR-9200832), Microsoft Corporation, and Intel Corporation.  
Address: Box 352350  Seattle, WA 98195-2350  
Affiliation: Department of Computer Science and Engineering,  University of Washington,  
Pubnum: Technical Report UW-CSE-97-11-03  
Abstract: We consider the problem of scheduling tasks with unpredictable service times on distinct processing nodes so as to meet a real-time deadline, given that all communication among nodes entails some (possibly large) overhead. This work is motivated by our effort to build a distributed rendering system that uses a cluster of commodity workstations to improve the performance of multimedia applications that require real-time 3D rendering. In this context, the tasks correspond to sets of scene objects that must be rendered to create a single image while the deadline corresponds to the fixed amount of time available to render each frame. The abstract problem then corresponds to the problem of intra-frame scheduling, that is, how to maximize the likelihood that all rendering tasks will be completed on time for the current frame. In this work, we assume the existence of an inter-frame load-balancing agent; that is, we assume that the overall work is periodically partitioned into a number of tasks with similar expected rendering times. Despite this longer-term load balancing, however, load imbalances during a particular frame can still be significant: it's difficult to accurately estimate tasks' rendering times and repartitioning is too expensive to be performed for every frame. Thus, while the initial assignment of tasks at the beginning of a frame may have equal expected processing times, the system must recover from imbalances discovered during the processing of each frame. We consider two distinct classes of scheduling policies, static, in which task reassignments can only occur at specific times, and dynamic, in which reassignments are triggered by some node going idle. For both classes, we further examine global reassignment, in which all nodes are rescheduled at a rescheduling moment, and local reassignment, in which only a subset of the nodes engage in rescheduling at any one time. We show that, over a range of parameterizations appropriate to clusters of commodity workstations, global dynamic policies work best. We introduce a new policy, Dynamic with Shadowing, that places each of a small number of tasks in the schedules of multiple nodes to reduce the amount of communication required for load-balancing. This policy dominates all other alternatives considered over most of the parameter space. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bestavros. </author> <title> Load Profiling in Distributed Real-Time Systems. </title> <journal> Information Sciences, </journal> <volume> 101(12):127, </volume> <month> Sept. </month> <year> 1997. </year>
Reference-contexts: Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., [15, 30, 4, 11, 6]), especially those that dealt with real-time tasks (e.g., <ref> [12, 1] </ref>). However, the former had as a goal minimizing response time, rather than meeting real-time deadlines, while the latter addressed workloads in which each task had its own deadline, rather than our situation in which there is a single deadline for the ensemble of tasks.
Reference: [2] <author> C.-I. H. Chen and V. Cherkassky. </author> <title> Task Reallocation for Fault Tolerance in Multiprocessor Systems. </title> <booktitle> In Proceedings of the IEEE 1990 National Aerospace and Electronics Conference, </booktitle> <pages> pages 495500, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., [13, 23, 8, 25]) as well as scheduling of fault-tolerance real-time systems (e.g., <ref> [10, 2, 19] </ref>), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [3] <author> T. W. Crockett. </author> <title> An Introduction to Parallel Rendering. </title> <booktitle> Parallel Computing, </booktitle> <address> 23(7):819843, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Additionally, all of the policies we examine accommodate partial replication, although at some performance degradation relative to full replication. 1.1 Related Work Although our work is motivated by the parallel rendering problem, unlike much of the previous work on parallel ren 1 http://www.ocnus.com/models/Misc/aztec-city.wrl.gz dering <ref> [3] </ref>, we are as concerned with minimizing the inter-frame variance as we are with maximizing the mean frame rate.
Reference: [4] <author> D. Eager, E. Lazowska, and J. Zahorjan. </author> <title> Adaptive Load Sharing in Homogeneous Distributed Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12(5):662675, </volume> <month> May </month> <year> 1986. </year>
Reference-contexts: Lastly, we evaluate the policies based on the probability that a deadline is met, rather than on the average time to complete all the work. Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., <ref> [15, 30, 4, 11, 6] </ref>), especially those that dealt with real-time tasks (e.g., [12, 1]).
Reference: [5] <author> D. A. Ellsworth. </author> <title> A New Algorithm for Interactive Graphics on Multicomputers. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 14(4):3340, </volume> <month> July </month> <year> 1994. </year>
Reference-contexts: The single class assumption is reasonable in our application because a higher level component of the scheduler, not addressed here, uses information about object rendering times obtained over a sequence of frames to occasionally regroup scene objects into roughly equal sized tasks. (Examples of such schemes have been described in <ref> [5, 17] </ref>.) * The cost of communicating for the purposes of schedul ing is relatively large, on the order of a few percent of the deadline time.
Reference: [6] <author> M. Harchol-Balter and A. B. Downey. </author> <title> Exploiting Process Lifetime Distributions for Dynamic Load Balancing. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference, </booktitle> <pages> pages 13 24, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Lastly, we evaluate the policies based on the probability that a deadline is met, rather than on the average time to complete all the work. Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., <ref> [15, 30, 4, 11, 6] </ref>), especially those that dealt with real-time tasks (e.g., [12, 1]).
Reference: [7] <author> S. F. Hummel, E. Schonberg, and L. E. Flynn. </author> <title> Factoring: A Method for Scheduling Parallel Loops. </title> <journal> Communications of the ACM, </journal> <volume> 35(8):90101, </volume> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [22, 7, 26, 14, 16, 20, 29] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when there is work left to be done against the overhead of finding that work.
Reference: [8] <author> K. Jeffay, D. F. Stanat, and C. U. Martel. </author> <title> On Non-Preemptive Scheduling of Period and Sporadic Tasks. </title> <booktitle> In Proceedings of the 12th Real-Time Systems Symposium, </booktitle> <pages> pages 129139, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: While Shekhar et al. consider some similar policies, however, they are not concerned with meeting a real-time deadline. Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., <ref> [13, 23, 8, 25] </ref>) as well as scheduling of fault-tolerance real-time systems (e.g., [10, 2, 19]), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [9] <author> D. D. Kouvatsos. </author> <title> Entropy Maximisation and Queueing Network Models. </title> <journal> Annals of Operations Research, </journal> <volume> 48(14):63 126, </volume> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: More specifically, we assume that task execution times are exponentially distributed. A major advantage of the exponential over other potential distributions is that it allows us to find an optimal schedule for the static policy we propose. Additionally, it is the maximum entropy distribution <ref> [9] </ref>, and so is motivated by the absence of information available at this time on actual task time distributions (which is highly data dependent in any case).
Reference: [10] <author> C. M. Krishna and K. G. Shin. </author> <title> On Scheduling Tasks with a Quick Recovery from Failure. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-35(5):448455, </volume> <month> May </month> <year> 1986. </year>
Reference-contexts: Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., [13, 23, 8, 25]) as well as scheduling of fault-tolerance real-time systems (e.g., <ref> [10, 2, 19] </ref>), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [11] <author> P. Krueger and M. Livny. </author> <title> A Comparison of Preemptive and Non-Preemptive Load Distributing. </title> <booktitle> In Proceedings of the 8th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 123130, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Lastly, we evaluate the policies based on the probability that a deadline is met, rather than on the average time to complete all the work. Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., <ref> [15, 30, 4, 11, 6] </ref>), especially those that dealt with real-time tasks (e.g., [12, 1]).
Reference: [12] <author> J. F. Kurose and R. Chipalkatti. </author> <title> Load Sharing in Soft Real-Time Distributed Computer Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-36(8):9931000, </volume> <month> Aug. </month> <year> 1987. </year>
Reference-contexts: Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., [15, 30, 4, 11, 6]), especially those that dealt with real-time tasks (e.g., <ref> [12, 1] </ref>). However, the former had as a goal minimizing response time, rather than meeting real-time deadlines, while the latter addressed workloads in which each task had its own deadline, rather than our situation in which there is a single deadline for the ensemble of tasks.
Reference: [13] <author> C. Liu and J. Layland. </author> <title> Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment. </title> <journal> Journal of the ACM, </journal> <volume> 20(1):4661, </volume> <month> Jan. </month> <year> 1973. </year>
Reference-contexts: While Shekhar et al. consider some similar policies, however, they are not concerned with meeting a real-time deadline. Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., <ref> [13, 23, 8, 25] </ref>) as well as scheduling of fault-tolerance real-time systems (e.g., [10, 2, 19]), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [14] <author> J. Liu and V. A. Saletore. </author> <title> Self-Scheduling on Distributed-Memory Machines. </title> <booktitle> In Supercomputing '93, </booktitle> <pages> pages 814823, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [22, 7, 26, 14, 16, 20, 29] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when there is work left to be done against the overhead of finding that work. <p> Broadcasting a single message to all processors and then waiting until a message is received from each (using UDP) con 3 This policy is very similar to a number of loop scheduling policies that have been proposed for NUMA systems <ref> [14, 16, 20, 29] </ref>, and shares with nearly all loop scheduling strategies the essential property that chunk sizes decrease as the size of the work pool decreases. sumes about 0.3 ms of CPU on both the sender (the one performing the original broadcast and collecting the return messages) and the receivers,
Reference: [15] <author> M. Livny and M. Melman. </author> <title> Load Balancing in Homogeneous Broadcast Distributed Systems. </title> <booktitle> In Proceedings of the ACM Computer Network Performance Symposium, </booktitle> <pages> pages 4755, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Lastly, we evaluate the policies based on the probability that a deadline is met, rather than on the average time to complete all the work. Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., <ref> [15, 30, 4, 11, 6] </ref>), especially those that dealt with real-time tasks (e.g., [12, 1]).
Reference: [16] <author> E. P. Markatos and T. J. LeBlanc. </author> <title> Using Processor Affinity in Loop Scheduling on Shared-Memory Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(4):379 400, </volume> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [22, 7, 26, 14, 16, 20, 29] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when there is work left to be done against the overhead of finding that work. <p> Broadcasting a single message to all processors and then waiting until a message is received from each (using UDP) con 3 This policy is very similar to a number of loop scheduling policies that have been proposed for NUMA systems <ref> [14, 16, 20, 29] </ref>, and shares with nearly all loop scheduling strategies the essential property that chunk sizes decrease as the size of the work pool decreases. sumes about 0.3 ms of CPU on both the sender (the one performing the original broadcast and collecting the return messages) and the receivers,
Reference: [17] <author> C. Mueller. </author> <title> Sort-First Rendering Architecture for High-Performance Graphics. </title> <booktitle> In Proceedings of the 1995 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 7584, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: The single class assumption is reasonable in our application because a higher level component of the scheduler, not addressed here, uses information about object rendering times obtained over a sequence of frames to occasionally regroup scene objects into roughly equal sized tasks. (Examples of such schemes have been described in <ref> [5, 17] </ref>.) * The cost of communicating for the purposes of schedul ing is relatively large, on the order of a few percent of the deadline time.
Reference: [18] <author> R. S. Nickerson. </author> <title> Man-Computer Interaction: A Challenge for Human Factors Research. </title> <journal> IEEE Transactions on Man-Machine Systems, </journal> <volume> 10:164180, </volume> <month> Dec. </month> <year> 1969. </year>
Reference-contexts: Although our system is not a hard real-time system, i.e., it is acceptable to miss a small number of deadlines, maintaining a constant frame rate is an important concern. Users are often willing to trade (some) performance for lower variance <ref> [18] </ref>. Smooth motion requires at least 10 frames per second (fps), implying a real-time period of at most 100 ms. At the current TV rate of 30 fps, the period is reduced to 33 ms. * All tasks are available at the beginning of the compu tation.
Reference: [19] <author> Y. Oh and S. Son. </author> <title> Fault-Tolerant Real-Time Multiprocessor Scheduling. </title> <type> Technical Report TR-92-09, </type> <institution> University of Virginia, </institution> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., [13, 23, 8, 25]) as well as scheduling of fault-tolerance real-time systems (e.g., <ref> [10, 2, 19] </ref>), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [20] <author> S. Orlando and R. Perego. </author> <title> Exploiting Partial Replication in Unbalanced Parallel Loop Scheduling on Multicomputers. </title> <journal> Microprocessing and Microprogramming, </journal> <volume> 41(89):645658, </volume> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [22, 7, 26, 14, 16, 20, 29] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when there is work left to be done against the overhead of finding that work. <p> Broadcasting a single message to all processors and then waiting until a message is received from each (using UDP) con 3 This policy is very similar to a number of loop scheduling policies that have been proposed for NUMA systems <ref> [14, 16, 20, 29] </ref>, and shares with nearly all loop scheduling strategies the essential property that chunk sizes decrease as the size of the work pool decreases. sumes about 0.3 ms of CPU on both the sender (the one performing the original broadcast and collecting the return messages) and the receivers,
Reference: [21] <author> S. Pakin, V. Karamcheti, and A. Chien. </author> <title> Fast Messages: Efficient, Portable Communication for Workstation Clusters and MPPs. </title> <journal> IEEE Concurrency, </journal> <volume> 5(2):6072, </volume> <month> Apr. </month> <year> 1997. </year>
Reference-contexts: observations, which we divide into two groups, one appropriate when full replication of the scene description is possible (the global policies), and the other when only partial replication is available (the local policies). 4 Unfortunately, current production operating systems impose overheads that are considerably larger than those achievable experimentally (e.g., <ref> [21, 27] </ref>). 5.2.1 Policy Comparison Under Full Replication (Global Policies) Figures 8 and 9 show twelve representative graphs comparing the performance of the global variants of SMR, DSR, PDR, and DDR, and of ILS, for communication overheads of 1% and 3%, respectively. These results lead us to the following conclusions.
Reference: [22] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided Self-Scheduling: </title>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [22, 7, 26, 14, 16, 20, 29] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when there is work left to be done against the overhead of finding that work.
References-found: 22

