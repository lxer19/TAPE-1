URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3110/3110.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: vadik@cs.umd.edu  
Title: Lazy Array Data-Flow Dependence Analysis  
Author: Vadim Maslov 
Note: Appeared in the Proceedings of the 21st Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, January 1994, pp. 311-325. This work is supported by an NSF PYI grant CCR-9157384 and by a Packard Fellowship.  
Address: College Park, MD 20742  
Affiliation: Dept. of Computer Science Univ. of Maryland,  
Date: July, 1993  
Pubnum: UMIACS-TR-93-69.1  CS-TR-3110.1  
Abstract: Automatic parallelization of real FORTRAN programs does not live up to users expectations yet, and dependence analysis algorithms which either produce too many false dependences or are too slow contribute significantly to this. In this paper we introduce data-flow dependence analysis algorithm which exactly computes value-based dependence relations for program fragments in which all subscripts, loop bounds and IF conditions are affine. Our algorithm also computes good affine approximations of dependence relations for non-affine program fragments. Actually, we do not know about any other algorithm which can compute better approximations. And our algorithm is efficient too, because it is lazy. When searching for write statements that supply values used by a given read statement, it starts with statements which are lexicographically close to the read statement in iteration space. Then if some of the read statement instances are not "satisfied" with these close writes, the algorithm broadens its search scope by looking into more distant writes. The search scope keeps broadening until all read instances are satisfied or no write candidates are left. We timed our algorithm on several benchmark programs and the timing results suggest that our algorithm is fast enough to be used in commercial compilers | it usually takes 5 to 15 percent of f77 -O2 compilation time to analyze a program. Most programs in the 100-line range take less than 1 second to analyze on a SUN SparcStation IPX. 
Abstract-found: 1
Intro-found: 1
Reference: [AK87] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: All other measurements were performed on SUN SparcStation IPX (SPECint89 rating of 21.7). 10 7 Related work We would like to compare our techniques to several other approaches to dependence analysis. Memory-based dependence computation. Until recently only techniques for computing memory-based dependences were considered by most researchers <ref> [AK87, Wol82, MHL91] </ref>. The problem SameCell (w; r; s) defined at line 17 of Figure 7 essentially describes a memory-based dependence. Since we compute this problem only once for each pair of statements, we don't take more time to compute memory-based dependences than existing techniques do. <p> In [PW93b] the authors propose to compute upper and lower bounds on dependences. However, their techniques can not prove that dependence from statement S 1 to S 2 is not carried by loop i in Figure 3 (a). A number of papers <ref> [AK87, HP91, LT88] </ref> suggest using symbolically enhanced versions of GCD test and Banerjee's inequalities.
Reference: [AL93] <author> Saman P. Amarasinghe and Monica S. Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <booktitle> In ACM '93 Conf. on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Direction vectors represent a relationship between statement instances involved in dependence inexactly, and dependence distances are limited to representing only fixed differences between write and read variables. The exact relationship should be provided, if we want to use advanced loop transformation and code generation techniques such as <ref> [Fea92a, Fea92b, AL93, KP93] </ref>. Some array expansion and privatization algorithms also require exact dependence information [Fea88b]. Recently researchers started to use source functions to represent value-based dependences.
Reference: [B + 89] <author> M. Berry et al. </author> <title> The PERFECT Club benchmarks: Effective performance evaluation of supercomputers. </title> <journal> International Journal of Supercomputing Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: END DO (b) Fragment of subroutine INTERF from MDG Let's consider a program in Figure 1 (a) which is slightly simplified fragment of the subroutine OLDA from the Perfect Club benchmark suite <ref> [B + 89] </ref>.
Reference: [Blu92] <author> William Joseph Blume. </author> <title> Success and limitations in automatic parallelization of the Perfect benchmarks T M programs. </title> <type> Master's thesis, </type> <institution> Dept. of Computer Science, U. of Illinois at Urbana-Champaign, </institution> <year> 1992. </year>
Reference-contexts: 1 Introduction Currently automatic parallelization of real-life FORTRAN programs is not as perfect as users desire. As recent studies <ref> [EHLP91, Blu92, May92] </ref> indicate, in many cases false dependences between statements introduced by inexact dependence analysis algorithms prevent loops from being parallelized. In the introduction we analyze the basic reasons for false dependences and show how the algorithm introduced in this paper avoids introducing false dependences without loosing efficiency.
Reference: [EHLP91] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the automatic paral-lelization of 4 Perfect benchmark programs. </title> <booktitle> In Proc. of the 4th Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Currently automatic parallelization of real-life FORTRAN programs is not as perfect as users desire. As recent studies <ref> [EHLP91, Blu92, May92] </ref> indicate, in many cases false dependences between statements introduced by inexact dependence analysis algorithms prevent loops from being parallelized. In the introduction we analyze the basic reasons for false dependences and show how the algorithm introduced in this paper avoids introducing false dependences without loosing efficiency.
Reference: [Fea88a] <author> P. Feautrier. </author> <title> Parametric integer programming. </title> <journal> Operationnelle/Operations Research, </journal> <volume> 22(3) </volume> <pages> 243-268, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . q 76543210 4 2 S2 [p,q] at (p+1/2,q+1/2) * Integer division is used in quasts <ref> [Fea88a] </ref> to represent complicated dependence patterns (see example in Figure 6). It means that quast may contain non-affine functions. <p> Since source functions may involve integer division by constant <ref> [Fea88a] </ref> and we want to keep conjuncts DepRel i affine, we use wild-card variables to represent the integer division. That is, we replace constraint i = bk=cc with affine constraint ci + ff = k ^ 0 ff c 1. Let's consider a program in Figure 6 [Fea88a] as an example <p> division by constant <ref> [Fea88a] </ref> and we want to keep conjuncts DepRel i affine, we use wild-card variables to represent the integer division. That is, we replace constraint i = bk=cc with affine constraint ci + ff = k ^ 0 ff c 1. Let's consider a program in Figure 6 [Fea88a] as an example of representing relatively complex dependence with dependence relations. <p> Feautrier developed the PIP algorithm (an integer version of simplex algorithm) <ref> [Fea88a] </ref> to compute an equivalent of ProblemMax t . We are not aware of any performance figures for the PIP, and Figure 8 suggests that it is slow. His analogue of RelMax2 t does not simplify the resulting quasts, so they may become very big.
Reference: [Fea88b] <author> Paul Feautrier. </author> <title> Array expansion. </title> <booktitle> In ACM Int. Conf. on Supercomputing, St Malo, </booktitle> <pages> pages 429-441, </pages> <year> 1988. </year>
Reference-contexts: Value-based dependences, introduced by Feautrier in <ref> [Fea88b] </ref>, reflect true flow of values in a program unobscured by details of storing data in memory. <p> The exact relationship should be provided, if we want to use advanced loop transformation and code generation techniques such as [Fea92a, Fea92b, AL93, KP93]. Some array expansion and privatization algorithms also require exact dependence information <ref> [Fea88b] </ref>. Recently researchers started to use source functions to represent value-based dependences. For a given statement instance S 2 [r] the source function produces coordinates of the statement instance S 1 [w] such that S 1 [w] supplies the value used in S 2 [r].
Reference: [Fea91] <author> Paul Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1), </volume> <month> February </month> <year> 1991. </year>
Reference-contexts: For a given statement instance S 2 [r] the source function produces coordinates of the statement instance S 1 [w] such that S 1 [w] supplies the value used in S 2 [r]. The version of source function computed in <ref> [Fea91] </ref> is called Quasi-Affine Selection Tree (quast). In [MAL93] a different term is used for the same object | Last Write Tree (LWT). <p> After we expanded the iteration space, we have to expand the set of dependences to make them affine too. That is, when dependence relation becomes non-affine as more loops are unfixed, we replace newly 9 Our % of f77 -O2 Times faster Times faster Program Lines f77 -O2 <ref> [Fea91] </ref> [PW93a] algorithm compile time than [Fea91] than [PW93a] across 15 200 600 9 7.8 4 62 1.15 burg 29 600 5,600 91 82 14 56 1.10 relax 13 400 1,700 24 25 6 57 .96 gosser 22 700 2,800 62 50 8 43 1.24 choles 25 600 2,600 32 32 <p> That is, when dependence relation becomes non-affine as more loops are unfixed, we replace newly 9 Our % of f77 -O2 Times faster Times faster Program Lines f77 -O2 <ref> [Fea91] </ref> [PW93a] algorithm compile time than [Fea91] than [PW93a] across 15 200 600 9 7.8 4 62 1.15 burg 29 600 5,600 91 82 14 56 1.10 relax 13 400 1,700 24 25 6 57 .96 gosser 22 700 2,800 62 50 8 43 1.24 choles 25 600 2,600 32 32 6 63 1.00 lanczos 69 1,700 <p> So non-affine fragments do not necessarily lead to inexact dependence relations. 6 How fast is our algorithm We measured time taken by our dependence analysis algorithm to analyze Feautrier's benchmarks <ref> [Fea91] </ref> and some NASA NAS codes. In Figure 8 we compare our timing results with time taken by: * Regular Fortran-77 compiler to compile the pro gram [PW93a]. * Feautrier's algorithm to compute source functions for the program [Fea91]. * Pugh and Wonnacott techniques to compute memory-based direction vectors and value-based <p> measured time taken by our dependence analysis algorithm to analyze Feautrier's benchmarks <ref> [Fea91] </ref> and some NASA NAS codes. In Figure 8 we compare our timing results with time taken by: * Regular Fortran-77 compiler to compile the pro gram [PW93a]. * Feautrier's algorithm to compute source functions for the program [Fea91]. * Pugh and Wonnacott techniques to compute memory-based direction vectors and value-based dependence relations for the program [PW93a]. Feautrier times were obtained on SUN Sparc ELC (SPECint89 rating of 18.0). <p> So no time is spent disproving this dependence. Feautrier work. Feautrier <ref> [Fea91] </ref> computes value-based dependences exactly for what we call affine program fragments, but his techniques are slow, because while computing dependences using definition (4), he does not keep track of what read instances were covered.
Reference: [Fea92a] <author> Paul Feautrier. </author> <title> Some efficient solutions to the affine scheduling problem, Part I, One-dimensional time. </title> <journal> Int. J. of Parallel Programming, </journal> <volume> 21(5), </volume> <month> Oct </month> <year> 1992. </year>
Reference-contexts: Direction vectors represent a relationship between statement instances involved in dependence inexactly, and dependence distances are limited to representing only fixed differences between write and read variables. The exact relationship should be provided, if we want to use advanced loop transformation and code generation techniques such as <ref> [Fea92a, Fea92b, AL93, KP93] </ref>. Some array expansion and privatization algorithms also require exact dependence information [Fea88b]. Recently researchers started to use source functions to represent value-based dependences.
Reference: [Fea92b] <author> Paul Feautrier. </author> <title> Some efficient solutions to the affine scheduling problem, Part II, Multidimensional time. </title> <journal> Int. J. of Parallel Programming, </journal> <volume> 21(6), </volume> <month> Dec </month> <year> 1992. </year>
Reference-contexts: Direction vectors represent a relationship between statement instances involved in dependence inexactly, and dependence distances are limited to representing only fixed differences between write and read variables. The exact relationship should be provided, if we want to use advanced loop transformation and code generation techniques such as <ref> [Fea92a, Fea92b, AL93, KP93] </ref>. Some array expansion and privatization algorithms also require exact dependence information [Fea88b]. Recently researchers started to use source functions to represent value-based dependences.
Reference: [HP91] <author> M. Haghighat and C. Polychronopoulos. </author> <title> Symbolic dependence analysis for high-performance parallelizing compilers. </title> <booktitle> In Advances In Languages And Compilers for Parallel Processing, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: In [PW93b] the authors propose to compute upper and lower bounds on dependences. However, their techniques can not prove that dependence from statement S 1 to S 2 is not carried by loop i in Figure 3 (a). A number of papers <ref> [AK87, HP91, LT88] </ref> suggest using symbolically enhanced versions of GCD test and Banerjee's inequalities.
Reference: [KP93] <author> Wayne Kelly and William Pugh. </author> <title> A framework for unifying reordering transformations. </title> <type> Technical Report CS-TR-3193, </type> <institution> Dept. of Computer Science, University of Maryland, College Park, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Direction vectors represent a relationship between statement instances involved in dependence inexactly, and dependence distances are limited to representing only fixed differences between write and read variables. The exact relationship should be provided, if we want to use advanced loop transformation and code generation techniques such as <ref> [Fea92a, Fea92b, AL93, KP93] </ref>. Some array expansion and privatization algorithms also require exact dependence information [Fea88b]. Recently researchers started to use source functions to represent value-based dependences.
Reference: [LT88] <author> A. Lichnewsky and F. Thomasset. </author> <title> Introducing symbolic problem solving techniques in the dependence testing phases of a vectorizer. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: In [PW93b] the authors propose to compute upper and lower bounds on dependences. However, their techniques can not prove that dependence from statement S 1 to S 2 is not carried by loop i in Figure 3 (a). A number of papers <ref> [AK87, HP91, LT88] </ref> suggest using symbolically enhanced versions of GCD test and Banerjee's inequalities.
Reference: [MAL93] <author> Dror E. Maydan, Saman P. Amarasinghe, and Monica S. Lam. </author> <title> Array data-flow analysis and its use in array privatization. </title> <booktitle> In ACM '93 Conf. on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: For a given statement instance S 2 [r] the source function produces coordinates of the statement instance S 1 [w] such that S 1 [w] supplies the value used in S 2 [r]. The version of source function computed in [Fea91] is called Quasi-Affine Selection Tree (quast). In <ref> [MAL93] </ref> a different term is used for the same object | Last Write Tree (LWT). <p> Unfortunately, they do not describe their algorithm in detail and they do not provide timing results, so it is difficult to compare their algorithm to ours. Maydan, Amarasinghe and Lam work. Their algorithm <ref> [MAL93, May92] </ref> does not apply to the general case of affine program fragment, so they use Feautrier's algorithm for backup. Their algorithm applies only to writes that do not self-interfere (that is, there is no output dependence from the write to itself) when unused loop indices are removed.
Reference: [May92] <author> Dror Eliezer Maydan. </author> <title> Accurate Analysis of Array References. </title> <type> PhD thesis, </type> <institution> Computer Systems Laboratory, Stanford U., </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Currently automatic parallelization of real-life FORTRAN programs is not as perfect as users desire. As recent studies <ref> [EHLP91, Blu92, May92] </ref> indicate, in many cases false dependences between statements introduced by inexact dependence analysis algorithms prevent loops from being parallelized. In the introduction we analyze the basic reasons for false dependences and show how the algorithm introduced in this paper avoids introducing false dependences without loosing efficiency. <p> Unfortunately, they do not describe their algorithm in detail and they do not provide timing results, so it is difficult to compare their algorithm to ours. Maydan, Amarasinghe and Lam work. Their algorithm <ref> [MAL93, May92] </ref> does not apply to the general case of affine program fragment, so they use Feautrier's algorithm for backup. Their algorithm applies only to writes that do not self-interfere (that is, there is no output dependence from the write to itself) when unused loop indices are removed.
Reference: [MHL91] <author> D. E. Maydan, J. L. Hennessy, and M. S. Lam. </author> <title> Efficient and exact data dependence analysis. </title> <booktitle> In ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1-14, </pages> <month> June </month> <year> 1991. </year> <month> 12 </month>
Reference-contexts: All other measurements were performed on SUN SparcStation IPX (SPECint89 rating of 21.7). 10 7 Related work We would like to compare our techniques to several other approaches to dependence analysis. Memory-based dependence computation. Until recently only techniques for computing memory-based dependences were considered by most researchers <ref> [AK87, Wol82, MHL91] </ref>. The problem SameCell (w; r; s) defined at line 17 of Figure 7 essentially describes a memory-based dependence. Since we compute this problem only once for each pair of statements, we don't take more time to compute memory-based dependences than existing techniques do.
Reference: [Mur71] <author> Y. Muraoka. </author> <title> Parallelism Exposure and Exploita--tion in Programs. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> February </month> <year> 1971. </year>
Reference-contexts: Dependence Representation. Traditionally dependences were represented by direction vectors [Wol82] and dependence distances <ref> [Mur71] </ref>. Direction vectors represent a relationship between statement instances involved in dependence inexactly, and dependence distances are limited to representing only fixed differences between write and read variables.
Reference: [Pug91] <author> William Pugh. </author> <title> Uniform techniques for loop optimization. </title> <booktitle> In 1991 International Conference on Supercomputing, </booktitle> <pages> pages 341-352, </pages> <address> Cologne, Ger-many, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: We found that LWTs/quasts have several drawbacks as a method of dependence representation (see below), and we decided to use dependence relations introduced in <ref> [Pug91] </ref> to represent value-based dependences. If a pair consisting of the given instance of write statement S 1 [w] and read statement S 2 [r] belongs to the dependence relation then there is a value-based dependence from S 1 [w] to S 2 [r].
Reference: [Pug92] <author> William Pugh. </author> <title> The Omega test: a fast and practical integer programming algorithm for dependence analysis. </title> <journal> Communications of the ACM, </journal> <volume> 8 </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: We use the following basic operations on DNFs: ^ , _ , :, , RelMax1 t , RelMax2 t . They can be broken into 3 classes. Conjunct to conjunct: ^ , . We use the Omega test <ref> [Pug92] </ref> to simplify conjunctions of constraints and to prove that they have no solutions. The Omega test always performs the exact simplification. Another useful operation performed by the Omega test that we use is projection.
Reference: [PW92] <author> William Pugh and David Wonnacott. </author> <title> Going beyond integer programming with the Omega test to eliminate false data dependences. </title> <type> Technical Report CS-TR-3191, </type> <institution> Dept. of Computer Science, University of Maryland, College Park, </institution> <month> December </month> <year> 1992. </year> <note> An earlier version of this paper appeared at the SIGPLAN PLDI'92 conference. </note>
Reference-contexts: Also their algorithm does not seem to handle non-affine program fragments. Pugh and Wonnacott work. Pugh and Wonnacott use kill analysis to compute exact dependence information, that is, they first compute memory-based dependences and then kill or refine them by techniques originally described in <ref> [PW92] </ref> and [PW93b]. Since their kill analysis in the worst case considers all write-killer-read triples, while we in the worst case consider only all write-read pairs, the kill analysis can be expensive. <p> They also use memory-based dependences to perform some quick kills as it was suggested in the earlier paper <ref> [PW92] </ref>, while we do not need them at all. However, if need be, we can compute the memory-based dependences with ease.
Reference: [PW93a] <author> William Pugh and David Wonnacott. </author> <title> An evaluation of exact methods for analysis of value-based array data dependences. </title> <booktitle> In Sixth Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: In it we always maintain the disjunctive normal form of the formula using distributive properties of operations ^ and _ . To avoid combinatorial explosion when computing negation we used gist operation in a way proposed in <ref> [PW93a] </ref>. Lexicographical maximum: RelMax t . The function RelMax1 t (see Appendix A.1) computes the lexicographical maximum of the set of vectors w which is described by DNF p (w; r), where r is a vector of parameter variables. <p> His analogue of RelMax2 t does not simplify the resulting quasts, so they may become very big. To simplify quasts one needs to perform negation and it is not mentioned in Feautrier's papers as far as we know. Pugh and Wonnacott in <ref> [PW93a] </ref> advocate the use of the Presburger arithmetic subclass for dependence testing. <p> After we expanded the iteration space, we have to expand the set of dependences to make them affine too. That is, when dependence relation becomes non-affine as more loops are unfixed, we replace newly 9 Our % of f77 -O2 Times faster Times faster Program Lines f77 -O2 [Fea91] <ref> [PW93a] </ref> algorithm compile time than [Fea91] than [PW93a] across 15 200 600 9 7.8 4 62 1.15 burg 29 600 5,600 91 82 14 56 1.10 relax 13 400 1,700 24 25 6 57 .96 gosser 22 700 2,800 62 50 8 43 1.24 choles 25 600 2,600 32 32 6 <p> That is, when dependence relation becomes non-affine as more loops are unfixed, we replace newly 9 Our % of f77 -O2 Times faster Times faster Program Lines f77 -O2 [Fea91] <ref> [PW93a] </ref> algorithm compile time than [Fea91] than [PW93a] across 15 200 600 9 7.8 4 62 1.15 burg 29 600 5,600 91 82 14 56 1.10 relax 13 400 1,700 24 25 6 57 .96 gosser 22 700 2,800 62 50 8 43 1.24 choles 25 600 2,600 32 32 6 63 1.00 lanczos 69 1,700 12,600 119 <p> In Figure 8 we compare our timing results with time taken by: * Regular Fortran-77 compiler to compile the pro gram <ref> [PW93a] </ref>. * Feautrier's algorithm to compute source functions for the program [Fea91]. * Pugh and Wonnacott techniques to compute memory-based direction vectors and value-based dependence relations for the program [PW93a]. Feautrier times were obtained on SUN Sparc ELC (SPECint89 rating of 18.0). <p> In Figure 8 we compare our timing results with time taken by: * Regular Fortran-77 compiler to compile the pro gram <ref> [PW93a] </ref>. * Feautrier's algorithm to compute source functions for the program [Fea91]. * Pugh and Wonnacott techniques to compute memory-based direction vectors and value-based dependence relations for the program [PW93a]. Feautrier times were obtained on SUN Sparc ELC (SPECint89 rating of 18.0). All other measurements were performed on SUN SparcStation IPX (SPECint89 rating of 21.7). 10 7 Related work We would like to compare our techniques to several other approaches to dependence analysis. Memory-based dependence computation. <p> So they have incorporated our idea of keeping track of the read instances that were already covered by another dependence under the name of "partial covers". They combine the partial cover computation with their traditional kill analysis as described in <ref> [PW93a] </ref>.
Reference: [PW93b] <author> William Pugh and David Wonnacott. </author> <title> Static analysis of upper and lower bounds on dependences and parallelism. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <note> 1993. accepted for publication. </note>
Reference-contexts: Following <ref> [PW93b] </ref>, we compute lower and upper bound for each dependence relation: * Lower bound on dependence is computed by replacing non-affine variables with False in the positive context (in disjunctions and conjunctions) and with True in the negative context (in negations). <p> Also their algorithm does not seem to handle non-affine program fragments. Pugh and Wonnacott work. Pugh and Wonnacott use kill analysis to compute exact dependence information, that is, they first compute memory-based dependences and then kill or refine them by techniques originally described in [PW92] and <ref> [PW93b] </ref>. Since their kill analysis in the worst case considers all write-killer-read triples, while we in the worst case consider only all write-read pairs, the kill analysis can be expensive. <p> Both approaches are implemented in the Tiny tool, originally developed by Michael Wolfe and then considerably enhanced in the University of Maryland, College Park, so it is possible to compare the timing results (see Handling non-affine constraints. In [Voe92b] and <ref> [PW93b] </ref> the authors describe their techniques for computing value-based dependences for non-affine program fragments. Voevodin [Voe92b] suggests that the algorithm graph (that is, iteration space plus dependences) for non-affine fragment should be extended to become affine, but he does not describe how this is achieved. In [PW93b] the authors propose to <p> In [Voe92b] and <ref> [PW93b] </ref> the authors describe their techniques for computing value-based dependences for non-affine program fragments. Voevodin [Voe92b] suggests that the algorithm graph (that is, iteration space plus dependences) for non-affine fragment should be extended to become affine, but he does not describe how this is achieved. In [PW93b] the authors propose to compute upper and lower bounds on dependences. However, their techniques can not prove that dependence from statement S 1 to S 2 is not carried by loop i in Figure 3 (a).
Reference: [Voe92a] <author> Valentin V. Voevodin. </author> <booktitle> Mathematical Foundations of Parallel Computing. </booktitle> <publisher> World Scientific Publishers, </publisher> <year> 1992. </year> <booktitle> World Scientific Series in Computer Science, </booktitle> <volume> vol. </volume> <pages> 33. </pages>
Reference-contexts: Also Feautrier's algorithm does not handle IF statements and non-affine program fragments. Voevodins work. Voevodin & Voevodin <ref> [Voe92a, Voe92b] </ref> also compute exact value-based dependences for affine program fragments and they handle non-affine program fragments. They use methods that are close to that of Feautrier's. So we believe that our algorithm should work faster than theirs for the same reasons as above.
Reference: [Voe92b] <author> Vladimir V. Voevodin. </author> <title> Theory and practice of parallelism detection in sequential programs. </title> <journal> Programming and Computer Software (Programmirovaniye), </journal> <volume> 18(3), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: Computing the upper bound on iteration space. So we expand the actual iteration space to get rid of non-affine constraints, as it was suggested in <ref> [Voe92b] </ref>. For each non-affine expression in IF condition we assume that it can be both True and False, that is, we replace non-affine boolean terms with True in the positive context (that is, in the conjunction or disjunction), and with False in the negative context (that is, in the negation). <p> Also Feautrier's algorithm does not handle IF statements and non-affine program fragments. Voevodins work. Voevodin & Voevodin <ref> [Voe92a, Voe92b] </ref> also compute exact value-based dependences for affine program fragments and they handle non-affine program fragments. They use methods that are close to that of Feautrier's. So we believe that our algorithm should work faster than theirs for the same reasons as above. <p> Both approaches are implemented in the Tiny tool, originally developed by Michael Wolfe and then considerably enhanced in the University of Maryland, College Park, so it is possible to compare the timing results (see Handling non-affine constraints. In <ref> [Voe92b] </ref> and [PW93b] the authors describe their techniques for computing value-based dependences for non-affine program fragments. Voevodin [Voe92b] suggests that the algorithm graph (that is, iteration space plus dependences) for non-affine fragment should be extended to become affine, but he does not describe how this is achieved. <p> In <ref> [Voe92b] </ref> and [PW93b] the authors describe their techniques for computing value-based dependences for non-affine program fragments. Voevodin [Voe92b] suggests that the algorithm graph (that is, iteration space plus dependences) for non-affine fragment should be extended to become affine, but he does not describe how this is achieved. In [PW93b] the authors propose to compute upper and lower bounds on dependences.
Reference: [Wol82] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1982. </year>
Reference-contexts: Dependence Representation. Traditionally dependences were represented by direction vectors <ref> [Wol82] </ref> and dependence distances [Mur71]. Direction vectors represent a relationship between statement instances involved in dependence inexactly, and dependence distances are limited to representing only fixed differences between write and read variables. <p> All other measurements were performed on SUN SparcStation IPX (SPECint89 rating of 21.7). 10 7 Related work We would like to compare our techniques to several other approaches to dependence analysis. Memory-based dependence computation. Until recently only techniques for computing memory-based dependences were considered by most researchers <ref> [AK87, Wol82, MHL91] </ref>. The problem SameCell (w; r; s) defined at line 17 of Figure 7 essentially describes a memory-based dependence. Since we compute this problem only once for each pair of statements, we don't take more time to compute memory-based dependences than existing techniques do.
Reference: [Wol92] <author> Michael Wolfe. </author> <title> Beyond induction variables. </title> <booktitle> In SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <address> San Fran-cisco, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: To find the definition for the particular read of scalar variable and to distinguish between different definitions of the same variable we use the Static Single Assignment (SSA) graph of the program <ref> [Wol92] </ref>. This dynamic definition of symbolic constant is used in our dependence analysis algorithm in the following way. When computing the execution condition for the write statement in line 17 all the variables v such that v 2 SymConst (S; FixLoops) are considered to be symbolic constants. Example: non-affine conditions.
References-found: 26

