URL: ftp://ftp.cs.toronto.edu/pub/jepson/papers/eccv98.ps.gz
Refering-URL: http://www.cs.toronto.edu/~jepson/papers-available.html
Root-URL: http://www.cs.toronto.edu
Email: black@parc.xerox.com  jepson@vis.toronto.edu  
Phone: 2  
Title: A Probabilistic Framework for Matching Temporal Trajectories: Condensation-Based Recognition of Gestures and Expressions  
Author: Michael J. Black and Allan D. Jepson 
Address: 3333 Coyote Hill Road, Palo Alto, CA 94304 USA.  Toronto, Ontario M5S 1A4 Canada.  
Affiliation: 1 Xerox Palo Alto Research Center,  Department of Computer Science, University of Toronto,  
Abstract: The recognition of human gestures and facial expressions in image sequences is an important and challenging problem that enables a host of human-computer interaction applications. This paper describes a framework for incremental recognition of human motion that extends the "Condensation" algorithm proposed by Isard and Blake (ECCV'96). Human motions are modeled as temporal trajectories of some estimated parameters over time. The Condensation algorithm uses random sampling techniques to incrementally match the trajectory models to the multi-variate input data. The recognition framework is demonstrated with two examples. The first example involves an augmented office whiteboard with which a user can make simple hand gestures to grab regions of the board, print them, save them, etc. The second example illustrates the recognition of human facial expressions using the estimated parameters of a learned model of mouth motion. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Baumberg and D. Hogg. </author> <title> Learning flexible models from image sequences. </title> <booktitle> ECCV-94, </booktitle> <pages> pp. 299-308, </pages> <address> Stockholm, </address> <year> 1994. </year>
Reference-contexts: The oe i are estimates of the standard deviation for Probability Cumulative Probability 1 0 States States r Selected state 0 Fig. 2. We sample from the distribution over the states by constructing a cumulative probability distribution and sampling it uniformly. Choosing r from a uniform distribution over <ref> [0; 1] </ref> gives us a corresponding state. curve i. Also, ffm () (OEaej);i is simply the value of the i th coefficient in the model interpolated at time OE aej and scaled by ff. <p> Given a definition for p (z t js t ), we can construct a discrete representation of the entire probability distribution over the possible states. Initially, we sample uniformly for the state parameters 2 [0; max ] 1 y y ; where y 2 <ref> [0; 1] </ref> ff 2 [ff min ; ff max ] Note that the prediction for the initial phase OE is biased towards small values. We then compute the probability of the state p (z t js t ). <p> The evolution of these parameters over time can be used for motion-based recognition of facial expressions [3]. While here we consider optical flow, other authors have explored related approaches using deformable contours <ref> [1, 5, 12, 13, 15] </ref>.
Reference: 2. <author> M. J. Black and P. Anandan. </author> <title> The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields. </title> <journal> CVIU, </journal> <volume> 63(1) </volume> <pages> 75-104, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: Top: Example frames from the 600 image training set. Bottom: Basis flows for non-rigid mouth motion. 5 Facial Expressions Parameterized models of optical flow provide a concise description of the image motion within a region in terms of a small number of parameters <ref> [2] </ref>. The evolution of these parameters over time can be used for motion-based recognition of facial expressions [3]. While here we consider optical flow, other authors have explored related approaches using deformable contours [1, 5, 12, 13, 15].
Reference: 3. <author> M. J. Black and Y. Yacoob. </author> <title> Recognizing facial expressions in image sequences using local parameterized models of image motion. </title> <journal> IJCV, </journal> <volume> 25(1) </volume> <pages> 23-48, </pages> <year> 1997. </year>
Reference-contexts: For each pair of frames in a video sequence we compute a set of parameters that describe the motion. These might be simply horizontal and vertical velocity or the parameters of a more sophisticated pa-rameterized model of optical flow <ref> [3] </ref>. Over time the estimated parameter vectors form temporal trajectories that characterize the gesture or expression. Given a number of examples of a gesture we construct a model of the temporal trajectory that encodes the mean trajectory and the expected variance along the trajectory. <p> The evolution of these parameters over time can be used for motion-based recognition of facial expressions <ref> [3] </ref>. While here we consider optical flow, other authors have explored related approaches using deformable contours [1, 5, 12, 13, 15]. <p> The utterances of the test word were manually aligned and averaged to produce the trajectory models in Figure 10. Similarly, the single training smile was used to construct a compound model of a smile that is composed of primitive "onset," "apex," and "ending" models (cf. <ref> [3] </ref>). The apex is modeled as zero motion (all parameters zero) and may be of a prespecified or arbitrary duration. Given the small training set, we manually set oe to 20:0. sequence. Figure 11 (middle) shows the probability of the composite parent models (Smile and Utterance).
Reference: 4. <author> M. J. Black, Y. Yacoob, A. D. Jepson, and D. J. </author> <title> Fleet. Learning parameterized models of image motion. </title> <booktitle> CVPR-97, </booktitle> <pages> pp. 561-567, </pages> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Consider the example mouth images in Figure 8. To represent non-rigid motion of mouths we learn a parameterized model from example flow fields using principal component analysis. (see <ref> [4] </ref>). Such a learned flow basis set is shown in Figure 8 for a training set that contained a variety of speech, a single smile, and four utterances of a test word. <p> The motion coefficients are estimated between frames using a standard regression-based optical flow algorithm <ref> [4] </ref>. The learned model is used to estimate the motion in a 150-image test sequence in which the subject smiles and speaks a word that occured in the training set. A sample of the images from the sequence are shown in Fig. 9.
Reference: 5. <author> A. Blake, M. Isard, and D. Reynard. </author> <title> Learning to track the visual motions of contours. </title> <journal> Artificial Intelligence, </journal> <volume> 78 </volume> <pages> 101-134, </pages> <year> 1995. </year>
Reference-contexts: The evolution of these parameters over time can be used for motion-based recognition of facial expressions [3]. While here we consider optical flow, other authors have explored related approaches using deformable contours <ref> [1, 5, 12, 13, 15] </ref>.
Reference: 6. <author> C. Bregler. </author> <title> Learning and recognizing human dynamics in video sequences. </title> <booktitle> CVPR-97, </booktitle> <pages> pp. 568-574, </pages> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: The two most common methods for recognizing temporal trajectories are Hidden Markov Models (HMM's) [14] and Dynamic Time Warping (DTW) [16]. There have been many applications of these basic techniques to the problem of gesture recognition in computer vision (e.g. <ref> [6, 18, 20] </ref>). The proposed method can be seen as a generalization of HMM's in that it allows a discrete set of states with probabilistic transitions between states.
Reference: 7. <author> J. L. Crowley and F. Berard, </author> <title> Multi-Modal Tracking of Faces for Video Communications, </title> <booktitle> CVPR'97, </booktitle> <pages> pp. 640-645, </pages> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: In our scenario, when the user wants to perform a command, they pick up a gesture "phicon" (or physical icon) [10] that has a distinctive color that makes it easy to locate and track. The motion of the phicon is tracked using a color histogram tracker <ref> [7] </ref> in real time. Tracking is performed at roughly 30Hz. Since the tracking rate varies slightly, we resample the phicon locations at fixed time instants using linear interpolation. The horizontal and vertical velocity of the phicon are used for gesture recognition.
Reference: 8. <author> M. Isard and A. Blake. </author> <title> Contour tracking by sotchastic propagation of conditional density. </title> <booktitle> ECCV-96, </booktitle> <pages> pp. 343-356, </pages> <address> Cambridge, UK, </address> <year> 1996. </year>
Reference-contexts: In this paper we focus on the problem of recognizing human motion using a probabilistic framework that is based on random sampling techniques. We represent human motions as temporal trajectories and we match these to estimated trajectories in an on-line fashion. This framework applies the Condensation algorithm <ref> [8, 9] </ref> in a novel way to recognize complex human motions. We illustrate the method with examples of human gestures and human facial expressions. Our focus here will be on recognition of gestures given some estimated representation of the human motion. <p> Our approach applies the Condensation algorithm to the problem of recognizing temporal trajectories. The Condensation (CONDitional dENSity propagATION) algorithm uses random sampling techniques to simply and elegantly search a multi-variate parameter space that is changing over time. The algorithm was proposed by Isard and Blake <ref> [8] </ref> for tracking objects in clutter and has recently been extended [9] to simple gesture-recognition tasks. Here we extend the method further to recognize more complex temporal activities. See also [11] for a related random sampling techinque used in dynamic probabilistic belief networks. <p> The advantages over the method of Yacoob and Black would include on-line recognition, automatic segmentation, and local curve deformations. The most significant advantage of the CTR approach is that it allows the formulation of recognition and motion estimation or tracking in the same probabilistic framework. Isard and Blake <ref> [8] </ref> initially developed the Condensation algorithm to deal with the difficult problem of tracking an object in a cluttered environment. In this case the algorithm is able to maintain a probability distribution over multiple tracking hypotheses which provides robustness while achieving near real-time performance. <p> We can do this for S samples where we take S on the order of 1000. This gives us a set fs (n) samples. We normalize these probabilities so that they sum to one, producing weights (n) t = (n) P S (i) (2) The Condensation algorithm <ref> [8, 9] </ref> uses this information (the sample states and their weights) to predict the entire probability distribution at the next time instant. Unlike traditional tracking methods (e.g. Kalman filtering) this approach can deal well with ambiguous data since multiple matches are propagated in time. <p> In particular, we developed an augmented whiteboard application that allows users to interact with a whiteboard "scanner." Note that in previous work <ref> [8, 9] </ref>, the Condensation algorithm has been used to track objects with learned spatial and temporal dynamics. In this paper the tracking, or motion estimation, problem was solved separately and the Condensation algorithm was used only to perform recognition given the temporal trajectories. <p> In future research we will explore the integration of the motion estimation and recognition problems by using the probability distribution over states to help constrain the estimation problem. Note that for optical flow estimation this may prove more difficult than for the tracking applications in <ref> [8, 9] </ref>. In the experiments presented here we took 1000 samples and the resulting experiments run significantly slower than real time. Blake and Isard have demonstrated real-time versions of a similar algorithm which suggests that our method might be suitable for real-time recognition (with appropriate optimizations).
Reference: 9. <author> M. Isard and A. Blake. </author> <title> A mixed-state Condensation tracker with automatic model-switching. </title> <booktitle> ICCV'98, </booktitle> <pages> pp. 107-112, </pages> <address> Mumbai, India, </address> <month> Jan. </month> <year> 1998. </year>
Reference-contexts: In this paper we focus on the problem of recognizing human motion using a probabilistic framework that is based on random sampling techniques. We represent human motions as temporal trajectories and we match these to estimated trajectories in an on-line fashion. This framework applies the Condensation algorithm <ref> [8, 9] </ref> in a novel way to recognize complex human motions. We illustrate the method with examples of human gestures and human facial expressions. Our focus here will be on recognition of gestures given some estimated representation of the human motion. <p> The Condensation (CONDitional dENSity propagATION) algorithm uses random sampling techniques to simply and elegantly search a multi-variate parameter space that is changing over time. The algorithm was proposed by Isard and Blake [8] for tracking objects in clutter and has recently been extended <ref> [9] </ref> to simple gesture-recognition tasks. Here we extend the method further to recognize more complex temporal activities. See also [11] for a related random sampling techinque used in dynamic probabilistic belief networks. <p> Isard and Blake [8] initially developed the Condensation algorithm to deal with the difficult problem of tracking an object in a cluttered environment. In this case the algorithm is able to maintain a probability distribution over multiple tracking hypotheses which provides robustness while achieving near real-time performance. In <ref> [9] </ref> they also show how this tracking ability can be combined with simple dynamical models of gestures to simultaneously perform tracking and recognition. They define a "mixed-state" representation that adds a discrete model parameter to the definition of a state. <p> They define a "mixed-state" representation that adds a discrete model parameter to the definition of a state. This allows the tracker to use multiple motion models corresponding to different gestures. The recognition in <ref> [9] </ref> is limited to fairly simple "gestures" (e.g. "scribbling" motion versus "smooth" motion). In this paper we focus only the recognition part of the problem and by incorporating explicit, learned, temporal trajectories we extend the Condensation method to more complex gestures. <p> We can do this for S samples where we take S on the order of 1000. This gives us a set fs (n) samples. We normalize these probabilities so that they sum to one, producing weights (n) t = (n) P S (i) (2) The Condensation algorithm <ref> [8, 9] </ref> uses this information (the sample states and their weights) to predict the entire probability distribution at the next time instant. Unlike traditional tracking methods (e.g. Kalman filtering) this approach can deal well with ambiguous data since multiple matches are propagated in time. <p> Note that prediction can be viewed as sampling from the probability distribution p (s (n) (n) t1 ) <ref> [9] </ref>. For the time being, the model type does not change over time; we will extend the method below to allow transition probabilities to take to a new state. <p> A number of authors have looked at problem of scanning white-boards at high resolution using mosaicing [19] and interacting with the board by making hand-drawn marks [17]. Here we look at the problem of recognizing dynamic gestures. Isard and Blake <ref> [9] </ref> used the Condensation algorithm to recognize simple drawing gestures. Our extension to temporal trajectories allows more complex gestures to be recognized. <p> In particular, we developed an augmented whiteboard application that allows users to interact with a whiteboard "scanner." Note that in previous work <ref> [8, 9] </ref>, the Condensation algorithm has been used to track objects with learned spatial and temporal dynamics. In this paper the tracking, or motion estimation, problem was solved separately and the Condensation algorithm was used only to perform recognition given the temporal trajectories. <p> In future research we will explore the integration of the motion estimation and recognition problems by using the probability distribution over states to help constrain the estimation problem. Note that for optical flow estimation this may prove more difficult than for the tracking applications in <ref> [8, 9] </ref>. In the experiments presented here we took 1000 samples and the resulting experiments run significantly slower than real time. Blake and Isard have demonstrated real-time versions of a similar algorithm which suggests that our method might be suitable for real-time recognition (with appropriate optimizations).
Reference: 10. <author> H. Ishii and B. Ullmer. </author> <title> Tangible bits: Towards seamless interfaces between people, bits and atoms. </title> <booktitle> Proc. of CHI'97, </booktitle> <year> 1997. </year>
Reference-contexts: Isard and Blake [9] used the Condensation algorithm to recognize simple drawing gestures. Our extension to temporal trajectories allows more complex gestures to be recognized. In our scenario, when the user wants to perform a command, they pick up a gesture "phicon" (or physical icon) <ref> [10] </ref> that has a distinctive color that makes it easy to locate and track. The motion of the phicon is tracked using a color histogram tracker [7] in real time. Tracking is performed at roughly 30Hz.
Reference: 11. <author> K. Kanazawa, D. Koller, and S. Russell. </author> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <booktitle> Proc. of the Eleventh Conf. on Uncertainty in AI, </booktitle> <address> Montreal, </address> <year> 1995. </year>
Reference-contexts: The algorithm was proposed by Isard and Blake [8] for tracking objects in clutter and has recently been extended [9] to simple gesture-recognition tasks. Here we extend the method further to recognize more complex temporal activities. See also <ref> [11] </ref> for a related random sampling techinque used in dynamic probabilistic belief networks. We define a "state" to be a set of parameters that align a trajectory model with the input data.
Reference: 12. <author> R. Kaucic, B. Dalton, and A. Blake. </author> <title> Real-time lip tracking for audio-visual speech recognition applications. </title> <booktitle> ECCV-96, </booktitle> <pages> pp. 376-387, </pages> <address> Cambridge, UK, </address> <year> 1996. </year>
Reference-contexts: The evolution of these parameters over time can be used for motion-based recognition of facial expressions [3]. While here we consider optical flow, other authors have explored related approaches using deformable contours <ref> [1, 5, 12, 13, 15] </ref>.
Reference: 13. <author> A. Lanitis, C. J. Taylor, T. F. Cootes, and T. Ahmed. </author> <title> Automatic interpretation of human faces and hand gestures using flexible models. </title> <booktitle> Int. Conf. on Automatic Face and Gesture Recognition, </booktitle> <pages> pp. 98-103, </pages> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: The evolution of these parameters over time can be used for motion-based recognition of facial expressions [3]. While here we consider optical flow, other authors have explored related approaches using deformable contours <ref> [1, 5, 12, 13, 15] </ref>.
Reference: 14. <author> L. R. Rabiner. </author> <title> A tutorial on Hidden Markov Models and selected applications in speech recognition. </title> <booktitle> Readings in Speech Recognition, </booktitle> <year> 1989. </year>
Reference-contexts: We do not attempt an exhaustive review here but rather highlight the relationships between the proposed framework and the most relevant related approaches. The two most common methods for recognizing temporal trajectories are Hidden Markov Models (HMM's) <ref> [14] </ref> and Dynamic Time Warping (DTW) [16]. There have been many applications of these basic techniques to the problem of gesture recognition in computer vision (e.g. [6, 18, 20]).
Reference: 15. <author> D. Reynard, A. Wildenberg, A. Blake, and J. Marchant. </author> <title> Learning dynamics of complex motion from image sequences. </title> <booktitle> ECCV-96, </booktitle> <pages> pp. 357-368, </pages> <address> Cambridge, UK, </address> <year> 1996. </year>
Reference-contexts: The evolution of these parameters over time can be used for motion-based recognition of facial expressions [3]. While here we consider optical flow, other authors have explored related approaches using deformable contours <ref> [1, 5, 12, 13, 15] </ref>.
Reference: 16. <author> D. Sankoff and Eds. J. B. Kruskal. </author> <title> Time warps, string edits, and macromolecules: The theory and practice of sequence compression. </title> <publisher> Addison-Wesley Pub., </publisher> <address> Reading, Mass., </address> <year> 1983. </year>
Reference-contexts: We do not attempt an exhaustive review here but rather highlight the relationships between the proposed framework and the most relevant related approaches. The two most common methods for recognizing temporal trajectories are Hidden Markov Models (HMM's) [14] and Dynamic Time Warping (DTW) <ref> [16] </ref>. There have been many applications of these basic techniques to the problem of gesture recognition in computer vision (e.g. [6, 18, 20]). The proposed method can be seen as a generalization of HMM's in that it allows a discrete set of states with probabilistic transitions between states.
Reference: 17. <author> Q. Stafford-Fraser. Brightboard: </author> <title> A video-augmented environment. </title> <booktitle> Proc. of CHI'96, </booktitle> <year> 1996. </year>
Reference-contexts: A number of authors have looked at problem of scanning white-boards at high resolution using mosaicing [19] and interacting with the board by making hand-drawn marks <ref> [17] </ref>. Here we look at the problem of recognizing dynamic gestures. Isard and Blake [9] used the Condensation algorithm to recognize simple drawing gestures. Our extension to temporal trajectories allows more complex gestures to be recognized.
Reference: 18. <author> T. Starner and A. Pentland. </author> <title> Visual recognition of American Sign Language using Hidden Markov Models. </title> <booktitle> Int. Conf. on Automatic Face and Gesture Recognition, </booktitle> <pages> pp. 189-194, </pages> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: The two most common methods for recognizing temporal trajectories are Hidden Markov Models (HMM's) [14] and Dynamic Time Warping (DTW) [16]. There have been many applications of these basic techniques to the problem of gesture recognition in computer vision (e.g. <ref> [6, 18, 20] </ref>). The proposed method can be seen as a generalization of HMM's in that it allows a discrete set of states with probabilistic transitions between states.
Reference: 19. <author> R. Szeliski. </author> <title> Image mosaicing for tele-reality applications. </title> <booktitle> Second IEEE Workshop on Applications of Computer Vision, </booktitle> <pages> pp. 44-53, </pages> <address> Sarasota, Florida, </address> <year> 1994. </year>
Reference-contexts: A number of authors have looked at problem of scanning white-boards at high resolution using mosaicing <ref> [19] </ref> and interacting with the board by making hand-drawn marks [17]. Here we look at the problem of recognizing dynamic gestures. Isard and Blake [9] used the Condensation algorithm to recognize simple drawing gestures. Our extension to temporal trajectories allows more complex gestures to be recognized.
Reference: 20. <author> A. D. Wilson, A. F. Bobick, and J. Cassell. </author> <title> Temporal classification of natural gesture and application to video coding. </title> <booktitle> CVPR-97, </booktitle> <pages> pp. 948-954, </pages> <address> Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: The two most common methods for recognizing temporal trajectories are Hidden Markov Models (HMM's) [14] and Dynamic Time Warping (DTW) [16]. There have been many applications of these basic techniques to the problem of gesture recognition in computer vision (e.g. <ref> [6, 18, 20] </ref>). The proposed method can be seen as a generalization of HMM's in that it allows a discrete set of states with probabilistic transitions between states.
Reference: 21. <author> Y. Yacoob and M. J. Black. </author> <title> Parameterized modeling and recognition of activities. </title> <booktitle> ICCV'98, </booktitle> <pages> pp. 120-127, </pages> <address> Mumbai, India, </address> <month> Jan. </month> <year> 1998. </year>
Reference-contexts: The temporal trajectories may be discrete or continuous and the method allows parameterized deformations of the trajectories. Computational resources are automatically applied to more fully explore the most probable models. The "EigenCurve" representation <ref> [21] </ref> has been proposed as an alternative to HMM's and DTW. The approach matches an input trajectory to an basis-set representation of stored curves while allowing various global deformations. The CTR framework could be extended to represent temporal trajectories using this "eigen" basis representation. <p> A standard deviation from the mean trajectory was also computed for each curve. The trajectory models for each gesture are shown in Figure 4. The initial alignment of the curves could be performed using DTW. In addition to computing just the mean curve, we could compute "EigenCurves" as in <ref> [21] </ref>. In our experiments we take max = 9 (there are nine primitive models), ff max = 1:3, ff min = 0:7 (we allow a 30% scaling), ae max = 1:3, ae min = 0:7 (a 30% temporal scaling).
References-found: 21

