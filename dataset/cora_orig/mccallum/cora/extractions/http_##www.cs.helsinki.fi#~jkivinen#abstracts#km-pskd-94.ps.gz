URL: http://www.cs.helsinki.fi/~jkivinen/abstracts/km-pskd-94.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~jkivinen/abstracts/km-pskd-94.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The power of sampling in knowledge discovery  
Author: Jyrki Kivinen and Heikki Mannila P. O. Box (Teollisuuskatu ) 
Address: Helsinki, Finland  
Date: Helsinki, December 1993  
Note: Series of Publications C, No. C-1993-66  The papers in the series are intended for internal use and are distributed by the author. Copies may be ordered from the library  
Affiliation: University of Helsinki Department of Computer Science  Department of Computer Science  University of  of Department of Computer Science.  
Pubnum: FIN-00014  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> William W. Cohen. </author> <title> Pac-learning a restricted class of recursive logic programs. </title> <booktitle> In AAAI '93, </booktitle> <pages> pages 86-92, </pages> <year> 1993. </year>
Reference-contexts: Therefore, we consider the following approximate verification problem. We first define an error measure g that for each database M assigns to each sentence in some class fi of sentences a value g (; M ) 2 <ref> [0; 1] </ref>. Intuitively, g (; M ) 0 means that almost holds in M , while g (; M ) 1 means that clearly does not hold in M . Defining a natural error measure g is not straightforward, and we return to this problem shortly. <p> We suggest two measures that are suitable for quantifying the degree of truth of a universal sentence in a structure. These measures can to some extent be generalized for universal-existential sentences, as we see in Section 5. 5 The measures give a value in the range <ref> [0; 1] </ref> for the error of a statement, value 0 meaning that the sentence is true in the structure, and values close to 1 meaning that the sentence is in some sense clearly false. Consider first a formula = 8t ((t)) for some quantifier-free formula (t). <p> Another open problem is looking at whether smaller bounds for sample size could be obtained for simpler classes or sentences. Also looking at some small extensions of first-order formulas could be interesting. Such work could have connections to inductive logic programming <ref> [8, 1] </ref>. Our goal has been to detect clearly erroneous sentences, without concern for sentences that are nearly but not quite true. Often one would also wish to be certain that sentences that are almost true in the whole database remain almost true in the sample.
Reference: [2] <author> Ronald Fagin. </author> <title> Horn clauses and database dependencies. </title> <journal> J. ACM, </journal> <volume> 29(4) </volume> <pages> 952-985, </pages> <year> 1982. </year>
Reference-contexts: The modified definition gives a natural interpretation to, e.g., the truth of inclusion dependencies in a sample. Note also that all sentences in a very large class of database dependencies, extended embedded implicational dependencies (XEIDs) <ref> [2] </ref> are universal-existential. Naturally, universal-existential sentences include a lot of sentences that are not XEIDs. In tuple relational calculus one can freely use predicates and functions of the domain in expressing the sentences.
Reference: [3] <author> Adam J. Grove, Joseph Y. Halpern and Daphne Koller. </author> <title> Asymptotic conditional probabilities for first-order logic. </title> <booktitle> In STOC '92, </booktitle> <pages> pages 294-305, </pages> <year> 1992. </year>
Reference-contexts: Somewhat similar in spirit to our approach is the work [15] that considers the estimation accuracy of a whole class of queries using the Vapnik-Chervonenkis dimension and results from machine learning. The work <ref> [3] </ref> on asymptotic conditional probabilities for first-order logic has influenced us, although the formal setting is completely different. Sampling also has applications to more traditional database problems.
Reference: [4] <author> P.J. </author> <title> Haas and A.N. Swami. Sequential sampling procedures for query size optimization. </title> <booktitle> In SIGMOD '92, </booktitle> <pages> pages 341-350, </pages> <year> 1992. </year>
Reference-contexts: The work [3] on asymptotic conditional probabilities for first-order logic has influenced us, although the formal setting is completely different. Sampling also has applications to more traditional database problems. The results on using sampling for estimation of query size <ref> [7, 9, 4] </ref> can be considered to show something about how regularities concerning the size of answers to simple relational algebra (or tuple calculus) queries can be verified using samples. Our results give as an immediate corollary the earlier sample size results for verifying functional dependencies [5].
Reference: [5] <author> Jyrki Kivinen and Heikki Mannila. </author> <title> Approximate dependency inference from relations. </title> <editor> In Joachim Biskup and Richard Hull, editors, </editor> <booktitle> Proc. 4th International Conference on Database Theory, </booktitle> <pages> pages 86-98, </pages> <year> 1992. </year>
Reference-contexts: Hence, the natural generalization of 1 The names g 1 and g 3 have been used to maintain consistency with <ref> [5] </ref>. 2 g 3 makes all existential sentences almost true or identically false. <p> Our results give as an immediate corollary the earlier sample size results for verifying functional dependencies <ref> [5] </ref>. Also other integrity constraints can checked from samples using the current framework. The rest of this paper is organized as follows. In Section 2 we briefly describe the logical formalism we use. Section 3 considers how the degree of truth of a sentence can be defined. <p> This special case was discussed in detail in the earlier paper <ref> [5] </ref>. 2 10 5 Universal-existential sentences In the introduction we pointed out that existential sentences cannot, in general, be discovered using small samples. This is due to the basic assumption that when using the sample, one looks only inside it, not to the whole structure.
Reference: [6] <author> Ravi Krishnamurthy and Tomasz Imielinski. </author> <title> Research directions in knowledge discovery. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 20(3) </volume> <pages> 76-78, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Knowledge discovery, or database mining, has recently been recognized as an important subfield of database research <ref> [14, 6] </ref>. The goal of knowledge discovery can be vaguely characterized as locating interesting regularities from large databases.
Reference: [7] <author> R.J. Lipton, J.F. Naughton and D.A. Schneider. </author> <title> Practical selectivity estimation through adaptive sampling. </title> <booktitle> In SIGMOD'90, </booktitle> <pages> pages 1-11, </pages> <year> 1990. </year>
Reference-contexts: The work [3] on asymptotic conditional probabilities for first-order logic has influenced us, although the formal setting is completely different. Sampling also has applications to more traditional database problems. The results on using sampling for estimation of query size <ref> [7, 9, 4] </ref> can be considered to show something about how regularities concerning the size of answers to simple relational algebra (or tuple calculus) queries can be verified using samples. Our results give as an immediate corollary the earlier sample size results for verifying functional dependencies [5].
Reference: [8] <editor> Steven Muggleton, editor. </editor> <booktitle> Inductive Logic Programming. </booktitle> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: Another open problem is looking at whether smaller bounds for sample size could be obtained for simpler classes or sentences. Also looking at some small extensions of first-order formulas could be interesting. Such work could have connections to inductive logic programming <ref> [8, 1] </ref>. Our goal has been to detect clearly erroneous sentences, without concern for sentences that are nearly but not quite true. Often one would also wish to be certain that sentences that are almost true in the whole database remain almost true in the sample.
Reference: [9] <author> J.F. Naughton and S. Seshadri. </author> <title> On estimating the size of projections. </title> <booktitle> In Proc. International Conference on Database Theory, </booktitle> <pages> pages 499-513, </pages> <year> 1990. </year>
Reference-contexts: The work [3] on asymptotic conditional probabilities for first-order logic has influenced us, although the formal setting is completely different. Sampling also has applications to more traditional database problems. The results on using sampling for estimation of query size <ref> [7, 9, 4] </ref> can be considered to show something about how regularities concerning the size of answers to simple relational algebra (or tuple calculus) queries can be verified using samples. Our results give as an immediate corollary the earlier sample size results for verifying functional dependencies [5].
Reference: [10] <editor> Ilkka Niiniluoto. Truthlikeness. D. </editor> <publisher> Reidel Publishing Company, Dordrecht, Holland, </publisher> <year> 1987. </year>
Reference-contexts: As the sample may contain repetitions, we have 1 jN j m for this N . 3 Measures of truth for universal sentences Defining the degree of truth of a sentence has received a lot of attention in the philosophy of science; see <ref> [10, 11] </ref> for detailed expositions. These treatises, however, concentrate on finding out how close the set of models of one sentence is to the set of models of another, and they do not consider quantifying the truth of a sentence within a model.
Reference: [11] <author> Graham Oddie. </author> <title> Likeness to Truth. </title> <address> D. </address> <publisher> Reidel Publishing Company, Dordrecht, Holland, </publisher> <year> 1986. </year>
Reference-contexts: As the sample may contain repetitions, we have 1 jN j m for this N . 3 Measures of truth for universal sentences Defining the degree of truth of a sentence has received a lot of attention in the philosophy of science; see <ref> [10, 11] </ref> for detailed expositions. These treatises, however, concentrate on finding out how close the set of models of one sentence is to the set of models of another, and they do not consider quantifying the truth of a sentence within a model.
Reference: [12] <author> Daniel N. Osherson, Michael Stob and Scott Weinstein. </author> <title> On approximate truth. </title> <booktitle> In Proc. 2nd Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 88-101, </pages> <year> 1989. </year>
Reference-contexts: The problem of how closely a structure approximates another is considered in <ref> [12] </ref>. We suggest two measures that are suitable for quantifying the degree of truth of a universal sentence in a structure.
Reference: [13] <author> Gregory Piatetsky-Shapiro. </author> <title> Discovery, analysis, and presentation of strong rules. </title> <editor> In Gregory Piatetsky-Shapiro and William J. Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <year> 1991. </year> <month> 13 </month>
Reference-contexts: However, our emphasis on looking at the logical form of sentences and on defining the error measures based on the idea of approximate truth in logical structures is different from what is usually done in statistics. Piatetsky-Shapiro <ref> [13] </ref> analyzes the accuracy of sample-derived equality and range rules. These correspond to universally quantified implicational statements where the right-hand side is either of the form t [B] = b or of the form (b 1 &lt; t [B]) ^ (t [B] &lt; b 2 ).
Reference: [14] <editor> Gregory Piatetsky-Shapiro and William J. Frawley, editors. </editor> <booktitle> Knowledge Dis--covery in Databases. </booktitle> <publisher> AAAI Press / The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction Knowledge discovery, or database mining, has recently been recognized as an important subfield of database research <ref> [14, 6] </ref>. The goal of knowledge discovery can be vaguely characterized as locating interesting regularities from large databases.
Reference: [15] <author> Shaibal Roy. </author> <title> Semantic complexity of classes of relational queries and query independent data partitioning. </title> <booktitle> In PODS '91, </booktitle> <pages> pages 259-267, </pages> <year> 1991. </year>
Reference-contexts: These correspond to universally quantified implicational statements where the right-hand side is either of the form t [B] = b or of the form (b 1 &lt; t [B]) ^ (t [B] &lt; b 2 ). Somewhat similar in spirit to our approach is the work <ref> [15] </ref> that considers the estimation accuracy of a whole class of queries using the Vapnik-Chervonenkis dimension and results from machine learning. The work [3] on asymptotic conditional probabilities for first-order logic has influenced us, although the formal setting is completely different. Sampling also has applications to more traditional database problems.
Reference: [16] <author> Jeffrey D. Ullman. </author> <title> Principles of Database and Knowledge-Base Systems, Volume I. </title> <publisher> Computer Science Press, </publisher> <year> 1988. </year>
Reference-contexts: In Section 5 we discuss how a combination of sampling and query evaluation makes it possible to discover existential and universal-existential sentences from small samples. The Appendix gives some proofs omitted in the main text. 2 Tuple relational calculus and structures We use the tuple relational calculus (see, e.g., <ref> [16, p. 156] </ref>) as our logical formalism.
Reference: [17] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Comm. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: The proba-bility with which we allow at least one sentence with error higher than " to remain undetected is called the confidence parameter and denoted by ffi. This approach to approximate verification is closely related to the machine learning model advanced by Valiant <ref> [17] </ref>. Note that the algorithmic problem of generating the true sentences is different from testing the truth of the sentences. As explained above, we are particularly interested in universal sentences.
Reference: [18] <author> Vladimir Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <year> 1982. </year>
Reference-contexts: This is particularly important if the attribute values contain, e.g., numerical errors [19], and exactly true sentences are unlikely to exist. In machine learning setting, uniform convergence results <ref> [18] </ref> show that a slight increase in sample size enables one to not only rule out bad hypotheses but accurately estimate the errors of all hypotheses. Similar results for our setting would be interesting. In a more database oriented direction, one could consider aggregate terms in the sentences.
Reference: [19] <author> Robert Zembowicz and Jan M. _ Zytkov. </author> <title> Testing the existence of functional relationship in data. </title> <booktitle> In Proc. AAAI-93 Workshop on Knowledge Discovery in Databases, </booktitle> <year> 1993. </year> <month> 14 </month>
Reference-contexts: Often one would also wish to be certain that sentences that are almost true in the whole database remain almost true in the sample. This is particularly important if the attribute values contain, e.g., numerical errors <ref> [19] </ref>, and exactly true sentences are unlikely to exist. In machine learning setting, uniform convergence results [18] show that a slight increase in sample size enables one to not only rule out bad hypotheses but accurately estimate the errors of all hypotheses. Similar results for our setting would be interesting.
References-found: 19

