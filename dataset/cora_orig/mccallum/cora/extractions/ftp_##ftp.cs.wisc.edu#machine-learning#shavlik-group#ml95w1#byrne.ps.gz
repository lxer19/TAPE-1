URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/ml95w1/byrne.ps.gz
Refering-URL: http://www.cs.wisc.edu/~shavlik/ml95w1/procs.html
Root-URL: 
Email: byrne@csd.abdn.ac.uk  pedwards@csd.abdn.ac.uk  
Title: Collaborating to Refine Knowledge  
Author: Ciara Byrne Peter Edwards 
Address: King's College,  Scotland AB9 2UE  King's College,  Scotland AB9 2UE  
Affiliation: Department of Computing Science,  University of Aberdeen,  Department of Computing Science,  University of Aberdeen,  
Abstract: 1 Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Alan H. Bond and Les Gasser, editors. </editor> <booktitle> An Analysis of Problems and Research in DAI, </booktitle> <pages> pages 3-35. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: The performance of a community of intelligent agents may be evaluated by its coherence or by the success of individual agents in achieving their goals. "Coherence will refer to how well the system behaves as a unit." <ref> [1] </ref>. Cohesion may be measured along several dimensions. Among these are the quality of the solutions which the system produces, the efficiency with which solutions are produced and how gracefully performance degrades in the presence of failure or uncertainty.
Reference: [2] <author> P.R. Cohen, M.L. Greenberg, D.M. Hart, and A.E. Howe. </author> <title> Trial by Fire: Requirements for Agents in Complex Environments. </title> <journal> AI Magazine, </journal> <pages> pages 33-48, 10(3), </pages> <year> 1989. </year>
Reference-contexts: For example, a useful behaviour may be the avoidance of conflicts with other agents and an agent may learn to predict when a conflict is likely to occur. Fig.1 shows a behavioural ecology triangle <ref> [2] </ref>. If the agent designer knows what behaviours are required and the characteristics of the agent's environment (two vertices are fixed) she can solve for an agent design.
Reference: [3] <author> R. Fikes, M. Cutkosky, T. Gruber, and J. V. Baalen. </author> <title> Knowledge Sharing Technology Project Overview. </title> <type> Technical Report KSL-91-71, </type> <institution> Knowledge Systems Laboratory, Stanford University, </institution> <year> 1991. </year>
Reference-contexts: Agents must use the same knowledge representation or be able to use some translation mechanism if the information exchanged is to be understandable to them. For example, KIF (Knowledge Interchange Format) <ref> [3] </ref> is an interlingua which has been proposed as a means of sharing knowledge between agents. A Distributed Refinement System: The aim of our refinement system [4] is the production of coordinated and effective behaviour in an agent group.
Reference: [4] <author> C. Byrne and P. Edwards. </author> <title> Refinement in Agent Groups. </title> <booktitle> In Proceedings of the IJCAI-95 Workshop on Learning and Adaptation in Multiagent Systems, </booktitle> <year> 1995. </year>
Reference-contexts: For example, KIF (Knowledge Interchange Format) [3] is an interlingua which has been proposed as a means of sharing knowledge between agents. A Distributed Refinement System: The aim of our refinement system <ref> [4] </ref> is the production of coordinated and effective behaviour in an agent group. This can be achieved by resolving incompleteness and inconsistency in the agents' knowledge bases. We would hope that the performance of the agent group in achieving common goals would be improved as a result.
Reference: [5] <author> D. Ourston and R.J. Mooney. </author> <title> Changing the Rules: A Comprehensive Approach to Theory Refinement. </title> <booktitle> In Proceedings of the Eighth International Conference on Machine Learning, </booktitle> <pages> pages 485-489, </pages> <year> 1991. </year>
Reference-contexts: We would hope that the performance of the agent group in achieving common goals would be improved as a result. Extensive investigation of techniques for refining the knowledge held in a single knowledge base has already been carried out <ref> [5] </ref> [6] [7]. The process of refining multiple related knowledge bases, such as those of a group of agents, presents new challenges. The refinement of one agent's knowledge may affect other agents in the system.
Reference: [6] <author> B.L. Richards and R.J. Mooney. </author> <title> Learning Relations by Pathfinding. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 723-738, </pages> <year> 1992. </year>
Reference-contexts: We would hope that the performance of the agent group in achieving common goals would be improved as a result. Extensive investigation of techniques for refining the knowledge held in a single knowledge base has already been carried out [5] <ref> [6] </ref> [7]. The process of refining multiple related knowledge bases, such as those of a group of agents, presents new challenges. The refinement of one agent's knowledge may affect other agents in the system.
Reference: [7] <author> S. Craw and D. Sleeman. </author> <title> The Flexibility of Speculative Refinement. </title> <editor> In L. A. Birnbaum and G. C. Collins, editors, </editor> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop, </booktitle> <pages> pages 28-32, </pages> <year> 1991. </year>
Reference-contexts: We would hope that the performance of the agent group in achieving common goals would be improved as a result. Extensive investigation of techniques for refining the knowledge held in a single knowledge base has already been carried out [5] [6] <ref> [7] </ref>. The process of refining multiple related knowledge bases, such as those of a group of agents, presents new challenges. The refinement of one agent's knowledge may affect other agents in the system.
Reference: [8] <author> W. Davies and P. Edwards. Agent-K: </author> <title> An Integration of AOP and KQML. </title> <editor> In Y. Labrou and T. Finin, editors, </editor> <booktitle> CIKM Workshop on Intelligent Information Agents. </booktitle> <institution> National Institute of Standards and Technology, Gaithersburg, Maryland, </institution> <year> 1994. </year>
Reference-contexts: What is Learnt: Agents in our system are written in an Agent-Oriented Programming Language, AgentK* <ref> [8] </ref> which is based on Agent-0 [9]. The state of an agent consists of its current commitments, beliefs and capabilities. A belief is a statement which the agent considers to be currently true or false, e.g. "it is raining". Beliefs may change over time.
Reference: [9] <author> Y. Shoham. </author> <title> Agent-Oriented Programming. </title> <type> Technical Report STAN-CS-1335-90, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1990. </year>
Reference-contexts: What is Learnt: Agents in our system are written in an Agent-Oriented Programming Language, AgentK* [8] which is based on Agent-0 <ref> [9] </ref>. The state of an agent consists of its current commitments, beliefs and capabilities. A belief is a statement which the agent considers to be currently true or false, e.g. "it is raining". Beliefs may change over time. An agent's capabilities are the actions which it can perform.
Reference: [10] <author> T. Finin, R. Fritzson, and D. McKay et al. </author> <title> An Overview of KQML: A Knowledge Query and Manipulation Language. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Maryland, </institution> <year> 1992. </year>
Reference-contexts: To allow agents to effectively refine their collective knowledge, we have introduced a new type of agent termed a refinement facilitator. A facilitator coordinates interaction between agents. For example, KQML <ref> [10] </ref> communication facilitators are used to manage message traffic among other agents by routing messages to appropriate agents, providing buffering and translation facilities, etc. There are several stages in the refinement process: 1. One of the agents participating in cooperation, usually the initiator, recognises that a failure has occurred.
References-found: 10

