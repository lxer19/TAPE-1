URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-202.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Representation of Image Velocity  
Author: Eero P. Simoncelli 
Keyword: motion, optical flow, representation, distributions, sampling, interpola tion, occlusion, transparency, multiple motions.  
Date: October 1992  
Address: Cambridge, Massachusetts 02139  
Affiliation: The Media Laboratory Massachusetts Institute of Technology  
Note: Distributed  
Abstract: MIT Media Laboratory Vision and Modeling Technical Report #202. Abstract We describe a new form of representation of image velocities, which does not rely on vector fields. For each local spatio-temporal region of the input image, we desire a function over the space of velocities describing the presence of a given velocity in that region. This function may be interpreted as a probability distribution over velocity, although it is not necessary to do so. A primary advantage of this representation is that it is capable of representing more than one velocity at a given image location. A multi-modal distribution indicates the presence of multiple motions. Such situations occur frequently in natural scenes near occlusion boundaries, and in situations of transparency. We develop an example of this type of representation through a series of modifications of current differential approaches to motion estimation. We define an angular version of the standard gradient constraint equation, and then extend this to represent multiple motions. The derivation is first done for one-dimensional signals and then extended to two dimensions. We implement an efficient version of this distributed representation, in which the entire distribution may be interpolated from a sparse set of samples. We then demonstrate its use on simple synthetic examples containing occlusion boundaries and transparent surfaces. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Anandan. </author> <title> A computational framework and an algorithm for the measurement of visual motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2 </volume> <pages> 283-310, </pages> <year> 1989. </year>
Reference-contexts: In light of the first problem, many authors have suggested that optical flow computations should be augmented by the computation of "confidence" measures <ref> [1, 18, 9, 2] </ref>. More recently, some authors have developed estimation-theoretic approaches that compute covariance matrices [25, 24, 26], which serve as a two-dimensional confidence measure. In this paper, we will re-examine the measurement and representation of motion in 1 the image plane.
Reference: [2] <author> J. L. Barron, D. J. Fleet, and S. S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <type> Technical Report RPL-TR-9107, </type> <institution> Robotics and Perception Laboratory Technical Report, Queen's University, Kingston, </institution> <address> Ontario, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: In light of the first problem, many authors have suggested that optical flow computations should be augmented by the computation of "confidence" measures <ref> [1, 18, 9, 2] </ref>. More recently, some authors have developed estimation-theoretic approaches that compute covariance matrices [25, 24, 26], which serve as a two-dimensional confidence measure. In this paper, we will re-examine the measurement and representation of motion in 1 the image plane.
Reference: [3] <author> J. R. Bergen, P. J. Burt, K. Hanna, R. Hingorani, P. Jeanne, and S. Peleg. </author> <title> Dynamic multiple-motion computation. </title> <editor> In Y. A. Feldman and A. Bruckstein, editors, </editor> <booktitle> Artificial Intelligence and Computer Vision, </booktitle> <pages> pages 147-156. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1991. </year>
Reference-contexts: Some authors have tried to handle this by using higher-order expansions of the motion field (e.g., affine models [4, 7]). Shizawa and Mase [20, 21], and Bergen et. al. <ref> [3] </ref> have described algorithms for explicitly computing two motion vectors at each point in the scene. We take a different approach here. In the previous section, we described the computation of a unimodal distribution function over the space of all velocities, v, for each point in space and time.
Reference: [4] <author> R. W. Brockett. Gramians, </author> <title> generalized inverses, and the least-squares approximation of optical flow. </title> <journal> J. Vis. Comm. and Image Rep., </journal> <volume> 1(1) </volume> <pages> 3-11, </pages> <month> Septemeber </month> <year> 1990. </year>
Reference-contexts: Some authors have tried to handle this by using higher-order expansions of the motion field (e.g., affine models <ref> [4, 7] </ref>). Shizawa and Mase [20, 21], and Bergen et. al. [3] have described algorithms for explicitly computing two motion vectors at each point in the scene. We take a different approach here.
Reference: [5] <author> C. Cafforio and F. Rocca. </author> <title> Methods for measuring small displacements of television images. </title> <journal> IEEE Trans. Info. Theory, </journal> <volume> IT-22:573-579, </volume> <month> September </month> <year> 1976. </year>
Reference-contexts: Since velocity is a differential quantity, it is not surprising that one approach to its computation is through derivative measurements. Many authors have used this approach or variants of this approach <ref> [15, 5, 8, 13, 16, 27] </ref>. For simplicity we will introduce the problem using one-dimensional signals, extending to two dimensions in the next section. 2 Depicted on the left is the original temporal sequence of images.
Reference: [6] <author> T. Darrell and A. P. Pentland. </author> <title> Robust estimation of a multi-layer motion representation. </title> <booktitle> In Proceedings IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Simple flow-based algorithms would perform poorly at this task in the presence of multiple motions. We expect that the distributed representation should also prove useful for segmenting or grouping scenes according to coherency of motion <ref> [6] </ref>. 21
Reference: [7] <author> R. Eagleson. </author> <title> Measurement of the 2D affine lie group parameters for visual motion analysis. J. Spatial Vision, </title> <year> 1992. </year>
Reference-contexts: Some authors have tried to handle this by using higher-order expansions of the motion field (e.g., affine models <ref> [4, 7] </ref>). Shizawa and Mase [20, 21], and Bergen et. al. [3] have described algorithms for explicitly computing two motion vectors at each point in the scene. We take a different approach here.
Reference: [8] <author> C. L. Fennema and W. Thompson. </author> <title> Velocity determination in scenes containing several moving objects. </title> <booktitle> In CGIP-9, </booktitle> <pages> pages 301-315, </pages> <year> 1979. </year>
Reference-contexts: Since velocity is a differential quantity, it is not surprising that one approach to its computation is through derivative measurements. Many authors have used this approach or variants of this approach <ref> [15, 5, 8, 13, 16, 27] </ref>. For simplicity we will introduce the problem using one-dimensional signals, extending to two dimensions in the next section. 2 Depicted on the left is the original temporal sequence of images.
Reference: [9] <author> D. Fleet and A. Jepson. </author> <title> Computation of component image velocity from local phase information. </title> <journal> Intl. J. Comp. Vis., </journal> <volume> 5(1) </volume> <pages> 77-104, </pages> <year> 1990. </year>
Reference-contexts: In light of the first problem, many authors have suggested that optical flow computations should be augmented by the computation of "confidence" measures <ref> [1, 18, 9, 2] </ref>. More recently, some authors have developed estimation-theoretic approaches that compute covariance matrices [25, 24, 26], which serve as a two-dimensional confidence measure. In this paper, we will re-examine the measurement and representation of motion in 1 the image plane. <p> He made local measurements of the power spectrum using a set of Gabor functions tuned for different spatio-temporal frequencies, and then computed a least-squares regression estimate to find the best-fitting plane to account for the measurements. Watson and Ahumada [28], Fleet and Jepson <ref> [9] </ref>, and Gryzwacz and Yuille [11] have also used spatiotemporal filters to compute optical flow velocities. A fundamental problem with each of these previous filtering approaches is that the velocity estimates depend on the local spatial content of the signal.
Reference: [10] <author> W. T. Freeman and E. H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: Also, for a fixed set of directional cosine measurements, the distribution P (v) has the form of a squared cosine function. It is therefore always unimodal. This is illustrated in figure 3. Freeman and Adelson have developed a theory of such functions, which they call "steerable" <ref> [10] </ref>. They describe a sampling theorem in orientation and derive the interpolation functions that are used to synthesize the response of a filter at a desired orientation from the responses at some fixed set of orientations.
Reference: [11] <author> N. M. Grzywacz and A. L. Yuille. </author> <title> A model for the estimate of local image velocity by cells in the visual cortex. </title> <journal> Proc. R. Soc. Lond. A, </journal> <volume> 239 </volume> <pages> 129-161, </pages> <year> 1990. </year> <month> 22 </month>
Reference-contexts: He made local measurements of the power spectrum using a set of Gabor functions tuned for different spatio-temporal frequencies, and then computed a least-squares regression estimate to find the best-fitting plane to account for the measurements. Watson and Ahumada [28], Fleet and Jepson [9], and Gryzwacz and Yuille <ref> [11] </ref> have also used spatiotemporal filters to compute optical flow velocities. A fundamental problem with each of these previous filtering approaches is that the velocity estimates depend on the local spatial content of the signal.
Reference: [12] <author> D. J. Heeger. </author> <title> Model for the extraction of image flow. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 4(8):1455--1471, </volume> <month> August </month> <year> 1987. </year>
Reference-contexts: On the right, its power spectrum, plotted over the ranges ! x ; ! t 2 [; ]. practice, the entire image is seldom translating. One is therefore interested in a measure of the local power spectrum. This concept was used by Heeger <ref> [12] </ref> to develop a regression algorithm for the computation optical flow. He made local measurements of the power spectrum using a set of Gabor functions tuned for different spatio-temporal frequencies, and then computed a least-squares regression estimate to find the best-fitting plane to account for the measurements.
Reference: [13] <author> B. K. P. Horn and B. G. Schunk. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: Since velocity is a differential quantity, it is not surprising that one approach to its computation is through derivative measurements. Many authors have used this approach or variants of this approach <ref> [15, 5, 8, 13, 16, 27] </ref>. For simplicity we will introduce the problem using one-dimensional signals, extending to two dimensions in the next section. 2 Depicted on the left is the original temporal sequence of images.
Reference: [14] <author> H. Knutsson and G. H. Granlund. </author> <title> Texture analysis using two-dimensional quadrature filters. </title> <booktitle> In IEEE Computer Society Workshop on Computer Architecture for Pattern Analysis and Image Database Management, </booktitle> <pages> pages 206-213, </pages> <year> 1983. </year>
Reference-contexts: They describe a sampling theorem in orientation and derive the interpolation functions that are used to synthesize the response of a filter at a desired orientation from the responses at some fixed set of orientations. Others have also worked on the analysis of orientation using rotationally-invariant operators (eg., <ref> [14, 19] </ref>). We can take the interpolation in equation (9) one step further, and compute the value of the distribution P (v) at any v from three precomputed measurements.
Reference: [15] <author> J. O. Limb and J. A. Murphy. </author> <title> Estimating the velocity of moving images in television signals. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 4 </volume> <pages> 311-327, </pages> <month> December </month> <year> 1975. </year>
Reference-contexts: Since velocity is a differential quantity, it is not surprising that one approach to its computation is through derivative measurements. Many authors have used this approach or variants of this approach <ref> [15, 5, 8, 13, 16, 27] </ref>. For simplicity we will introduce the problem using one-dimensional signals, extending to two dimensions in the next section. 2 Depicted on the left is the original temporal sequence of images.
Reference: [16] <author> B. D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> In Proceedings of the 7th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 674-679, </pages> <address> Vancouver, </address> <year> 1981. </year>
Reference-contexts: Since velocity is a differential quantity, it is not surprising that one approach to its computation is through derivative measurements. Many authors have used this approach or variants of this approach <ref> [15, 5, 8, 13, 16, 27] </ref>. For simplicity we will introduce the problem using one-dimensional signals, extending to two dimensions in the next section. 2 Depicted on the left is the original temporal sequence of images. <p> Equation (1) can only be solved for v at positions where the spatial derivative, f x , is non-zero. Following the solution of Lucas and Kanade <ref> [16] </ref>, we can avoid these singular-ities by writing a least-squares error function based on the combination of constraints 3 from a small spatial patch: E (v) = i h i 2 In practice, the signal f (x; t) is typically discretized, and thus the computation of derivatives involves (at least implicitly)
Reference: [17] <author> D. Marr. </author> <title> Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> San Fransisco, </address> <year> 1982. </year>
Reference-contexts: We argue that it is the vector-field representation that is the source of the difficulty. Given that scene motion at a point is often not adequately described by a single motion, the vector representation is a violation of what Marr referred to as the "principle of least commitment" <ref> [17] </ref>. As an alternative, we advocate distributed representations of motion, in which the encoding of image plane velocity is implicit. The reader should have in mind the computation of a probability distribution (over the space of velocities) for each patch of the image, although this interpretation is not necessary.
Reference: [18] <author> H. H. Nagel. </author> <title> Displacement vectors derived from second order intensity variations in image sequences. Computer Vision, </title> <journal> Pattern Recognition, and Image Processing, </journal> <volume> 21 </volume> <pages> 85-117, </pages> <year> 1983. </year>
Reference-contexts: In light of the first problem, many authors have suggested that optical flow computations should be augmented by the computation of "confidence" measures <ref> [1, 18, 9, 2] </ref>. More recently, some authors have developed estimation-theoretic approaches that compute covariance matrices [25, 24, 26], which serve as a two-dimensional confidence measure. In this paper, we will re-examine the measurement and representation of motion in 1 the image plane.
Reference: [19] <author> P. Perona. </author> <title> Deformable kernels for early vision. </title> <booktitle> In IEEE Comp. Soc. Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 222-227, </pages> <address> Maui, </address> <year> 1991. </year>
Reference-contexts: They describe a sampling theorem in orientation and derive the interpolation functions that are used to synthesize the response of a filter at a desired orientation from the responses at some fixed set of orientations. Others have also worked on the analysis of orientation using rotationally-invariant operators (eg., <ref> [14, 19] </ref>). We can take the interpolation in equation (9) one step further, and compute the value of the distribution P (v) at any v from three precomputed measurements.
Reference: [20] <author> M. Shizawa and K. Mase. </author> <title> Simultaneous multiple optical flow estimation. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Atlantic City, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: First, we extract the angular portion of the velocity dependence: E (~v) = v 2 + 1 ~! 2 = v 2 + 1 ~! 2 1 Other regression error measures are also possible. For example, Shizawa and Mase <ref> [20] </ref> use the perpendicular distance to the line. 6 where ^v is the normalized angular velocity vector defined by ^v = (v; 1) T = p D ^v (~!) = ^v ~! is (the Fourier transform of) the directional derivative in the ^v direction. ^v is sometimes called a "steering" vector. <p> Some authors have tried to handle this by using higher-order expansions of the motion field (e.g., affine models [4, 7]). Shizawa and Mase <ref> [20, 21] </ref>, and Bergen et. al. [3] have described algorithms for explicitly computing two motion vectors at each point in the scene. We take a different approach here.
Reference: [21] <author> M. Shizawa and K. Mase. </author> <title> A unified computational theory for motion transparency and motion boundaries based on eigenenergy analysis. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Maui, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Some authors have tried to handle this by using higher-order expansions of the motion field (e.g., affine models [4, 7]). Shizawa and Mase <ref> [20, 21] </ref>, and Bergen et. al. [3] have described algorithms for explicitly computing two motion vectors at each point in the scene. We take a different approach here.
Reference: [22] <author> E. P. Simoncelli and E. H. Adelson. </author> <title> Computation of optical flow: Relationship between several standard techniques. Vision and Modeling Technical Report 165, </title> <publisher> MIT Media Laboratory, </publisher> <month> November </month> <year> 1990. </year> <month> 23 </month>
Reference-contexts: Specifically, a set of filters that produce an unbiased estimate are the derivative filters discussed previously. In previous work, we have shown that the gradient approach may be viewed as a spatio-temporal regression analysis much like that described above <ref> [23, 22] </ref>.
Reference: [23] <author> E. P. Simoncelli and E. H. Adelson. </author> <title> Optical flow distributions: gradient, energy and regression methods. </title> <booktitle> In Optical Society of America, Annual Meeting, </booktitle> <address> Boston, MA, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: In this paper, we will develop distributed representations that are no longer restricted to unimodality, thus allowing us to robustly represent multiple motions that occur near occlusion boundaries, in regions of strong divergence or curl, and in transparently moving imagery. This work is an extension of <ref> [23] </ref>, in which we proposed a mechanism for computing multimodal velocity distributions for one-dimensional imagery. This generalized computational algorithm operates by first applying a set of spatio-temporally oriented linear filters, and squaring their outputs. These responses correspond to a sampled representation of local image spatio-temporal energy. <p> Specifically, a set of filters that produce an unbiased estimate are the derivative filters discussed previously. In previous work, we have shown that the gradient approach may be viewed as a spatio-temporal regression analysis much like that described above <ref> [23, 22] </ref>.
Reference: [24] <author> E. P. Simoncelli and E. H. Adelson. </author> <title> Probability distributions of optical flow. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, Mauii, Hawaii, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: In light of the first problem, many authors have suggested that optical flow computations should be augmented by the computation of "confidence" measures [1, 18, 9, 2]. More recently, some authors have developed estimation-theoretic approaches that compute covariance matrices <ref> [25, 24, 26] </ref>, which serve as a two-dimensional confidence measure. In this paper, we will re-examine the measurement and representation of motion in 1 the image plane. We argue that it is the vector-field representation that is the source of the difficulty. <p> In previous work, we derived Gaussian probability distributions of optical flow based on the standard gradient constraint and a simple model of measurement and state noise <ref> [24] </ref>. These distributions are unimodal, and thus have a fundamental assumption of unique velocity description. <p> For example, one could negate and exponentiate the expression to produce a Gaussian distribution as in <ref> [24] </ref>. 8 Distribution Sampling and Interpolation The previous equation gives a functional form for the distributed representation of velocity. In practice, one does not wish to compute and store the value of this function for at a large number of v values and for each point in space-time.
Reference: [25] <author> E. P. Simoncelli, D. J. Heeger, and E. H. Adelson. </author> <title> Perception of 3D motion in the presence of uncertainty. </title> <booktitle> In Investigative Opthalmology and Visual Science Supplement (ARVO), </booktitle> <volume> volume 31, </volume> <year> 1990. </year>
Reference-contexts: In light of the first problem, many authors have suggested that optical flow computations should be augmented by the computation of "confidence" measures [1, 18, 9, 2]. More recently, some authors have developed estimation-theoretic approaches that compute covariance matrices <ref> [25, 24, 26] </ref>, which serve as a two-dimensional confidence measure. In this paper, we will re-examine the measurement and representation of motion in 1 the image plane. We argue that it is the vector-field representation that is the source of the difficulty.
Reference: [26] <author> A. Singh. </author> <title> Incremental estimation of image-flow using a kalman filter. </title> <booktitle> In Proceedings IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: In light of the first problem, many authors have suggested that optical flow computations should be augmented by the computation of "confidence" measures [1, 18, 9, 2]. More recently, some authors have developed estimation-theoretic approaches that compute covariance matrices <ref> [25, 24, 26] </ref>, which serve as a two-dimensional confidence measure. In this paper, we will re-examine the measurement and representation of motion in 1 the image plane. We argue that it is the vector-field representation that is the source of the difficulty.
Reference: [27] <author> A. Verri, F. Girosi, and V. Torre. </author> <title> Differential techniques for optical flow. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 7 </volume> <pages> 912-922, </pages> <year> 1990. </year>
Reference-contexts: Since velocity is a differential quantity, it is not surprising that one approach to its computation is through derivative measurements. Many authors have used this approach or variants of this approach <ref> [15, 5, 8, 13, 16, 27] </ref>. For simplicity we will introduce the problem using one-dimensional signals, extending to two dimensions in the next section. 2 Depicted on the left is the original temporal sequence of images.
Reference: [28] <author> A. B. Watson and A. J. Ahumada. </author> <title> Model of human visual-motion sensing. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 2 </volume> <pages> 322-342, </pages> <year> 1985. </year> <month> 24 </month>
Reference-contexts: He made local measurements of the power spectrum using a set of Gabor functions tuned for different spatio-temporal frequencies, and then computed a least-squares regression estimate to find the best-fitting plane to account for the measurements. Watson and Ahumada <ref> [28] </ref>, Fleet and Jepson [9], and Gryzwacz and Yuille [11] have also used spatiotemporal filters to compute optical flow velocities. A fundamental problem with each of these previous filtering approaches is that the velocity estimates depend on the local spatial content of the signal.
References-found: 28

