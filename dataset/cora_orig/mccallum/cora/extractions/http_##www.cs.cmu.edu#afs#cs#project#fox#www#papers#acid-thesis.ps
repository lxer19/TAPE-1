URL: http://www.cs.cmu.edu/afs/cs/project/fox/www/papers/acid-thesis.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs/Web/groups/pop/pop.html
Root-URL: 
Title: Semantics-based Program Analysis via Symbolic Composition of Transfer Relations  
Author: Christopher Colby Patrick Cousot, 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy. Thesis Committee: Peter Lee, Chair Robert Harper John Reynolds  
Note: Copyright c 1996 Christopher Colby This research was sponsored in part by the Advanced Research Projects Agency CSTO under the title "The Fox Project: Advanced Languages for Systems Software," ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of the Advanced Research Projects Agency or the U.S. Government.  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  Ecole Normale Superieure  
Date: August 16, 1996  
Pubnum: CMU-CS-96-162  
Abstract-found: 0
Intro-found: 1
Reference: [AH87] <editor> S Abramsky and C Hankin, editors. </editor> <title> Abstract Interpretation of Declarative Languages. </title> <publisher> Ellis-Horwood, </publisher> <year> 1987. </year> <title> (p 68) </title>
Reference-contexts: Almost as soon as abstract interpretation arrived on the scene, to make a connection between program analyses and the semantics of programming languages, a great amount of effort was spent in adapting it to denotational semantics. For some examples, see [Myc81], [Nie84], [Nie86], and <ref> [AH87] </ref>. As one would expect, this body of work offers some of the most esthetically pleasing formulations of program analyses, but it also has found little use beyond a narrow range of applications such as strictness analysis [BHA86].
Reference: [App92] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1992. </year> <title> (p 100) </title>
Reference-contexts: The first major practical use of CPS was in the Scheme Rabbit compiler [Ste78], which translated source programs into a restricted syntax much like ours. This was later done in the Orbit Scheme compiler [Kra88] and then in the SML/NJ compiler <ref> [App92] </ref>. All translations are based on a universal calling convention in which all source functions take a continuation argument and all source applications must thus pass a continuation function 6.4 Semantics 101 describing the remainder of the computation.
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers principles, techniques, and tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year> <pages> (pp 3, 42, 52, 136) </pages>
Reference-contexts: Therefore, the compiler must invoke a program analysis to uncover this run-time behavior. For instance, most compilers use data-flow analysis (e.g., [KU76], [MJ81]) and alias analysis (e.g., [CWZ90], [Lan91], [Deu94]) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations <ref> [ASU86] </ref>. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., [JM79], [Shi91]) to construct a conservative control graph. Compiler support is far and away the most common application of program analysis. * Program verification. <p> This is called "constant folding" in the compiler literature <ref> [ASU86] </ref>. <p> For instance, dependency analysis <ref> [ASU86] </ref> is concerned with such properties. In Chapter 9 we will see some example applications of E. Here, we will give some examples of how E works. The L algorithm is just an application of E, so we will not demonstrate it separately. <p> Such paths roughly correspond to so-called extended basic blocks <ref> [ASU86] </ref>. Note that such a strategy would automatically compose the sequence of three assignment statements that posed a problem in the example at the beginning of this chapter.
Reference: [AWL94] <author> Alexander Aiken, Edward L. Wimmers, and T. K. Lakshman. </author> <title> Soft typing with conditional types. </title> <booktitle> In Conference Record of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 163-173, </pages> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year> <title> (p 12) </title>
Reference-contexts: Almost every kind of program analysis is based on a similar notion of fixed-point calculation over an abstraction of the properties of interest. This is not always apparent, because many analysis frameworks, such as data-flow analysis [MJ81], type inference [KMP84], and constraint-based analysis <ref> [Hei92, AWL94] </ref>, are phrased in terms of systems of equations or inference rules. But most of these frameworks reduce to a fixed-point calculation whose iterations correspond in some sense to abstract execution steps of the program. Abstract interpretation is a fixed-point-based theory that unifies these seemingly disparate approaches.
Reference: [Bar81] <author> D. W. Barron. </author> <title> Pascal the language and its implementation. </title> <publisher> John Wiley & Sons Ltd, </publisher> <address> Chichester, England, </address> <year> 1981. </year> <title> (p 97) </title>
Reference-contexts: For instance, they may be assigned to variables, placed in data structures, and passed to other functions. The functions in most advanced languages, such as Scheme [ReC86] or Standard ML (SML) [MTH90], are first class. In contrast, the functions in C [KR78], Fortran [Knu71], and Pascal <ref> [Bar81] </ref> are not first class. In some ways, our methodology must be rather stretched to handle first-class functions. We will see this below and in Chapter 7, and we will give a summary at the end of Chapter 7. 98 First-Class Functions: The Language Pure 6.1 Substitution vs.
Reference: [Bar84] <author> H. P. Barendregt. </author> <title> The Lambda Calculus. </title> <address> North Holland, </address> <note> revised edition, </note> <year> 1984. </year> <pages> (pp 67, 98, 112) </pages>
Reference-contexts: This turns out to be difficult; Dana Scott solved the underlying problems [Sco70, Sco76, Sco82]. On the other hand, Jean-Yves Girard in [GLT89] makes the following philosophical observation about the ff, fi, and equations of -calculus <ref> [Bar84] </ref>: In fact, these equations may be read in two different ways, which re-iterate the dichotomy [in logic] between sense and denotation: 68 Semantics via Transfer Relations * as the equations which define the equality of terms, in other words the equality of denotations (the static viewpoint). * as rewrite rules <p> We will see this below and in Chapter 7, and we will give a summary at the end of Chapter 7. 98 First-Class Functions: The Language Pure 6.1 Substitution vs. Closures Consider the syntax of -calculus terms <ref> [Bar84] </ref>: e ::= x j x: e j e e 0 Now consider the following term: (x: y: x) (z: z) Via the reduction rules of the -calculus, this term reduces in a single step to the (unique up to renaming) normal form: y: z: z This term represents a function <p> Note that the rule does not have the syntactic non-interference condition x 0 62 FV (t) because it is covered by the semantic non-interference condition that x 0 = undef. The notion of variable renaming is based on ff-conversion of the -calculus <ref> [Bar84] </ref>. We can get away without variable renaming, however. First we describe how we achieve this and compare this choice with a semantics based upon variable renaming, and then we explain why it is desirable for our purposes of program analysis to avoid the need for variable renaming.
Reference: [BHA86] <author> G L Burn, C L Hankin, and S Abramsky. </author> <title> Strictness analysis for higher-order functions. </title> <journal> Sci. Comp. Prog., </journal> <volume> 7 </volume> <pages> 249-278, </pages> <year> 1986. </year> <pages> (pp 68, 102) </pages>
Reference-contexts: For some examples, see [Myc81], [Nie84], [Nie86], and [AH87]. As one would expect, this body of work offers some of the most esthetically pleasing formulations of program analyses, but it also has found little use beyond a narrow range of applications such as strictness analysis <ref> [BHA86] </ref>. In general, however, one would like a program analysis to produce some information about a dynamic interpretation of a program rather than this static denotation. <p> The other circularity arises from first-class functions, and again it is no coincidence that analysis designers have traditionally encountered trouble with first-class functions. The usual ad hoc approaches are to be found in the work on denotational-based abstract interpretations, usually applied to strictness analysis <ref> [BHA86] </ref>, the work on finite approximations of closures [Shi91], or the work on augmenting higher-order type systems with "effects" [TJ92]. None of this work seems satisfactory.
Reference: [Bou93a] <author> F. Bourdoncle. </author> <title> Abstract debugging of higher-order imperative languages. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation: </booktitle> <address> Albuquerque, New Mexico, </address> <month> June 23-25, </month> <year> 1993, </year> <journal> volume 28-6 of SIGPLAN notices; ISSN: </journal> <volume> 0362-1340; v. 28, no. </volume> <month> 6 (June </month> <year> 1993), </year> <pages> pages 46-55, </pages> <address> New York, NY, USA, June 1993. </address> <publisher> ACM Press. </publisher> <pages> (pp 3, 11) </pages>
Reference-contexts: Furthermore, static type-checking reveals at compile time a remarkable percentage of programmer errors. * Program comprehension. A subject that has been gaining interest in recent years is the use of program analysis to aid the human understanding of code. For instance, the work in static debugging <ref> [Bou93a, Bou93b] </ref> allows the user to specify various kinds of pre- and post-conditions at different points in the program, and then calculates the 4 Some Topics in Program Analysis corresponding information about the ranges of numeric variables. <p> We do note, however, that the use of coinduction for program analysis is powerful technique, especially for the analysis of errors, that is currently not well appreciated. For examples, see <ref> [Bou93a] </ref>. 12 Some Topics in Program Analysis table ^ , describes the set of all execution sequences whose states satisfy the properties given in ^ . The function ff abstracts a set of execution sequences by a table giving the strongest sign properties of the states in those sequences.
Reference: [Bou93b] <author> F. Bourdoncle. </author> <title> Assertion-based debugging of imperative programs by abstract interpretation. </title> <booktitle> Lecture Notes in Computer Science, 717:501-??, 1993. (p 3) </booktitle>
Reference-contexts: Furthermore, static type-checking reveals at compile time a remarkable percentage of programmer errors. * Program comprehension. A subject that has been gaining interest in recent years is the use of program analysis to aid the human understanding of code. For instance, the work in static debugging <ref> [Bou93a, Bou93b] </ref> allows the user to specify various kinds of pre- and post-conditions at different points in the program, and then calculates the 4 Some Topics in Program Analysis corresponding information about the ranges of numeric variables.
Reference: [CC77] <author> P. Cousot and R. Cousot. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction of approximation of fixed points. </title> <booktitle> In Proceedings of the 4th ACM Symposium on Principles of Programming Languages, </booktitle> <address> Los Angeles, </address> <pages> pages 238-252, </pages> <address> New York, NY, </address> <year> 1977. </year> <journal> ACM. (pp 4, </journal> <volume> 42, 126, 127) 164 BIBLIOGRAPHY </volume>
Reference-contexts: To put our goals into perspective, we compare them to the goals of abstract interpretation. Abstract interpretation <ref> [CC77] </ref> is a general theory of semantics-based program analysis|so general and wide-ranging that the theory itself intentionally does not provide explicit support for particular language features, such as data structures and functions, or particular applications, such as alias or data-shape analysis. <p> The framework constructed in this section is for us what the notion of the Galois connection and associated fixed-point theorem is for abstract interpretation <ref> [CC77] </ref>. In abstract interpretation, one first designs a fixed-point-based semantics for the language to be analyzed and then designs an abstraction of the semantic domain. <p> In order to explain why this is not already a part of program-analysis methodology, we must take a step back and examine the foundations of semantics-based program analysis. 8.1 A Review of Abstract Interpretation Abstract interpretation <ref> [CC77] </ref> is a general framework for expressing semantics-based program analyses.
Reference: [CC79] <author> Patrick Cousot and Radhia Cousot. </author> <title> Systematic design of program analysis frameworks. </title> <booktitle> In Conference Record of the Sixth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 269-282. </pages> <publisher> ACM, ACM, </publisher> <month> January </month> <year> 1979. </year> <pages> (pp 4, 127) </pages>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b]. <p> Then from <ref> [CC79] </ref>, the function ^ S 2 Prog ! d SemObj ! d SemObj defined as ^ S [[P ]] = ff ffi S [[P ]] ffi fl corresponds to S in such a way that the fixed point fix ( ^ S [[P ]]) is an abstraction of the semantics M <p> In other words, ff (M [[P ]]) implies the property fix ( ^ S [[P ]]). We omit the formal details of this correspondence and refer the reader to <ref> [CC79] </ref>. Intuitively, an abstract semantic object is like a semantic object, but with some information missing, and ^ S [[P ]] first applies S [[P ]] to the information still present and then abstracts the result. We give an example below.
Reference: [CC92a] <author> P. Cousot and R. Cousot. </author> <title> Comparing the Galois connection and widening/narrowing approaches to abstract interpretation. </title> <editor> In M. Bruynooghe and M. Wirsing, editors, </editor> <booktitle> Proceedings of the Fourth International Symposium on Programming Language Implementation and Logic Programming, </booktitle> <pages> pages 269-295, </pages> <address> Leuven, Belgium, 1992. </address> <publisher> LNCS 631, Springer-Verlag. (p 4) </publisher>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b].
Reference: [CC92b] <author> P. Cousot and R. Cousot. </author> <title> Inductive definitions, semantics and abstract interpretation. </title> <booktitle> In Conference record of the Nineteenth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages: papers presented at the symposium, </booktitle> <address> Albu-querque, New Mexico, </address> <month> January 19-22, </month> <year> 1992, </year> <pages> pages 83-94, </pages> <address> New York, NY, USA, 1992. </address> <publisher> ACM Press. ACM order number 54990. </publisher> <pages> (pp 4, 11, 69) </pages>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b]. <p> The function fl, given such a 2 There are similar ways to express the infinite executions of a program via coinduction, but for the sake of simplicity we leave the reader to <ref> [CC92b] </ref> for a discussion. We do note, however, that the use of coinduction for program analysis is powerful technique, especially for the analysis of errors, that is currently not well appreciated. <p> This is also perhaps why the field of program analysis continues to struggle for acceptance in programming-language theory. As Girard says, operational semantics tend to be "uncivilised", and despite the frameworks of structural operational semantics [Plo81] (generalized to infinite behaviors in <ref> [CC92b] </ref>) and natural semantics [Kah87], operational semantics does not have nearly the developed and refined theory of denotational semantics.
Reference: [CC92c] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation and application to logic programs. </title> <journal> Journal of Logic Programming, </journal> <volume> 13(2-3):103-179, </volume> <month> July </month> <year> 1992. </year> <title> (p 4) </title>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b].
Reference: [CC92d] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation frameworks. </title> <journal> Journal of Logic and Computation, </journal> <volume> 2(4) </volume> <pages> 511-547, </pages> <month> August </month> <year> 1992. </year> <pages> (pp 4, 131) </pages>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b]. <p> Thus, ff ffi S [[P ]] ffi S [[P ]] ffi S [[P ]] ffi fl: performs three steps before abstracting, and consequently may yield more accurate results than applying ^ S [[P ]] three times. (The formal justification of this is in <ref> [CC92d] </ref>.) As we explained above and in Section 1.1, this increase in accuracy can be striking.
Reference: [CC94] <author> Patrick Cousot and Radhia Cousot. </author> <title> Higher-order abstract interpretation (and application to comportment analysis generalizing strictness, termination, projection and PER analysis of functional languages). </title> <booktitle> In Proceedings of the 1994 International Conference on Computer Languages, ICCL'94, </booktitle> <pages> pages 95-112, </pages> <address> Toulouse, France, May 1994. </address> <publisher> IEEE Computer Society Press. (p 4) </publisher>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b].
Reference: [CC95] <author> Patrick Cousot and Radhia Cousot. </author> <title> Formal language, grammar and set-constraint-based program analysis by abstract interpretation. </title> <booktitle> In Proceedings of the Seventh International Conference on Functional Programming Languages and Computer Architecture (FPCA'95), </booktitle> <pages> pages 170-181, </pages> <address> La Jolla, California, June 25-28, 1995. </address> <publisher> ACM SIGPLAN/SIGARCH and IFIP WG2.8, ACM Press. (p 4) </publisher>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b].
Reference: [CH78] <author> Patrick Cousot and Nicholas Halbwachs. </author> <title> Automatic discovery of linear restraints among variables of a program. </title> <booktitle> In Conference Record of the Fifth annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 84-96. </pages> <publisher> ACM, ACM, </publisher> <month> January </month> <year> 1978. </year> <title> (p 4) </title>
Reference-contexts: A powerful methodology has been constructed around this theory [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95], including a wide range of techniques for designing numeric lattices <ref> [Kar76, CH78, Gra89, Gra91a, Gra91b] </ref>. But when faced with a specific analysis task for a specific programming language, the analysis designer is left largely on his own to cope with the overwhelming generality of the framework.
Reference: [Cou78] <author> P. Cousot. </author> <title> Methodes iteratives de construction et d'approximation de point fixes d'operateurs monotone sur un treillis analyse semantique des programmes. </title> <type> PhD thesis, </type> <institution> Grenoble, </institution> <year> 1978. </year> <title> (p 127) </title>
Reference: [Cou81] <author> P. Cousot. </author> <title> Semantic foundations of program analysis. </title> <editor> In S. S. Muchnick and N. D. Jones, editors, </editor> <title> Program Flow Analysis: Theory and Applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year> <title> (p 4) BIBLIOGRAPHY 165 </title>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b].
Reference: [Cou90] <author> Patrick Cousot. </author> <title> Methods and logics for proving programs. </title> <editor> In J. van Leewen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B: Formal Models and Semantics, chapter 15, </booktitle> <pages> pages 841-993. </pages> <publisher> The MIT Press, </publisher> <address> New York, N.Y., </address> <year> 1990. </year> <title> (p 4) </title>
Reference-contexts: A powerful methodology has been constructed around this theory <ref> [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95] </ref>, including a wide range of techniques for designing numeric lattices [Kar76, CH78, Gra89, Gra91a, Gra91b].
Reference: [CWZ90] <author> D.R. Chase, M. Wegman, and F.K. Zadeck. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <month> June </month> <year> 1990. </year> <title> (p 3) </title>
Reference-contexts: Therefore, the compiler must invoke a program analysis to uncover this run-time behavior. For instance, most compilers use data-flow analysis (e.g., [KU76], [MJ81]) and alias analysis (e.g., <ref> [CWZ90] </ref>, [Lan91], [Deu94]) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations [ASU86]. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., [JM79], [Shi91]) to construct a conservative control graph.
Reference: [dB72] <author> Nicolas G. de Bruijn. </author> <title> Lambda-calculus notation with nameless dummies: a tool for automatic formula manipulation with application to the Church-Rosser theorem. </title> <journal> Indag. Math., </journal> <volume> 34(5) </volume> <pages> 381-392, </pages> <year> 1972. </year> <title> (p 115) </title>
Reference-contexts: It is possible, however, that there is a different semantic approach, based on a different treatment of Pure variables in the transfer relations, that would not suffer the above factors. For instance, perhaps the environment could be represented as a list, accessed by de Bruijn indices <ref> [dB72] </ref> instead of variables. 116 First-Class Functions: The Language Pure Chapter 7 Extending Pure with Mutable Records and Arrays Imperative features are crucial components of almost all languages, even "functional" languages such as Scheme and Standard ML.
Reference: [Deu92] <author> Alain Deutsch. </author> <title> Modeles operationnels de langages de programmation et representations de relations sur des langages rationnels avec application a la determination statique de proprietes de partages dynamiques de donnees. </title> <institution> These de doctorat d'universite, Universite Pierre et Marie Curie (Paris 6), Paris (France), </institution> <month> April </month> <year> 1992. </year> <pages> (pp 4, 102) </pages>
Reference-contexts: With a deep understanding and skillful use of the methodology, the results can be spectacular, such as the storeless alias analysis of Deutsch <ref> [Deu92, Deu94] </ref>. But after 20 years, much of the staggering potential of abstract interpretation still remains largely untapped. In contrast, our methodology is designed around real language features, such as pointers, heap-allocated data structures, arrays, assignment, and to a lesser extent first-class functions. <p> The circularity in the equation for Val arises from immutable tuples, and indeed most static analyses of even immutable structured values|not to mention mutable data structures|are quite crude (e.g., [Wad87], [Hei92]). One of the few satisfactory analyses of structured values is <ref> [Deu92] </ref>, but it is still somewhat ad hoc and also quite complicated. The other circularity arises from first-class functions, and again it is no coincidence that analysis designers have traditionally encountered trouble with first-class functions.
Reference: [Deu94] <author> Alain Deutsch. </author> <title> Interprocedural May-Alias analysis for pointers: Beyond k-limiting. </title> <journal> SIGPLAN Notices, </journal> <volume> 29(6) </volume> <pages> 230-241, </pages> <month> June </month> <year> 1994. </year> <booktitle> Proceedings of the ACM SIGPLAN '94 Conference on Programming Language Design and Implementation. </booktitle> <pages> (pp 3, 4) </pages>
Reference-contexts: Therefore, the compiler must invoke a program analysis to uncover this run-time behavior. For instance, most compilers use data-flow analysis (e.g., [KU76], [MJ81]) and alias analysis (e.g., [CWZ90], [Lan91], <ref> [Deu94] </ref>) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations [ASU86]. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., [JM79], [Shi91]) to construct a conservative control graph. <p> With a deep understanding and skillful use of the methodology, the results can be spectacular, such as the storeless alias analysis of Deutsch <ref> [Deu92, Deu94] </ref>. But after 20 years, much of the staggering potential of abstract interpretation still remains largely untapped. In contrast, our methodology is designed around real language features, such as pointers, heap-allocated data structures, arrays, assignment, and to a lesser extent first-class functions.
Reference: [Dij76] <author> E W Dijkstra. </author> <title> A Discipline of programming. </title> <publisher> Prentice-Hall, </publisher> <year> 1976. </year> <title> (p 22) </title>
Reference-contexts: This is similar to the situation with loops; a potentially unbounded number of trace intervals share a common net effect between their initial and final stores. Related to this idea is the use of weakest preconditions to describe the semantics of loops <ref> [Dij76, Wan77] </ref>. * As a practical matter, even if the initial store is fixed and the program terminates, isolating the patterns in the trace provides a hope of making the analysis feasible in practice.
Reference: [FF86] <author> M. Felleisen and D.P. Friedman. </author> <title> Control operators, the secd-machine, and the lambda-calculus. </title> <booktitle> In 3rd Working Conference on the Formal Description of Programming Concepts, </booktitle> <month> August </month> <year> 1986. </year> <title> (p 69) </title>
Reference-contexts: For instance, the control might be modeled by a label describing the position in the code that is scheduled to be executed next. In some operational semantics, the control state and the data state are intertwined. For instance, in context semantics <ref> [FF86] </ref>, a state of execution is simply a syntactic term; the control state is encoded in as the next redex to be reduced, and the data state is modeled with syntactic constructs (such as substitution or the heap variables in [MFH95]) and folded into the term itself.
Reference: [FRT95] <author> John Field, G. Ramalingam, and Frank Tip. </author> <title> Parametric program slicing. </title> <booktitle> In Conference Record of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 379-392, </pages> <address> San Francisco, California, </address> <month> January </month> <year> 1995. </year> <title> (p 4) </title>
Reference-contexts: For instance, the work in static debugging [Bou93a, Bou93b] allows the user to specify various kinds of pre- and post-conditions at different points in the program, and then calculates the 4 Some Topics in Program Analysis corresponding information about the ranges of numeric variables. Also, program slicing (e.g., [HRB90], <ref> [FRT95] </ref>) isolates the parts of a program that contribute to or depend on a particular variable in the program chosen by the user. This dissertation presents some new developments in the theory of program analysis.
Reference: [GH96] <author> Rakesh Ghiya and Laurie J. Hendren. </author> <title> Is it a tree, a DAG, or a cyclic graph? A shape analysis for heap-directed pointers in C. </title> <booktitle> In Conference Record of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'96), </booktitle> <pages> pages 1-15, </pages> <address> St. Petersburg, Florida, </address> <month> January 21-24, </month> <title> 1996. </title> <publisher> ACM Press. </publisher> <pages> (pp 9, 136) </pages>
Reference-contexts: The above is of course merely a toy example. But it is not hard to find examples in real program analyses that suffer from this same phenomenon of abstracting after every step. For instance, Ghiya and Hendren describe in <ref> [GH96] </ref> a shape analysis that attempts to determine whether data structures in a C program are trees, dags, or graphs. <p> Note that such a strategy would automatically compose the sequence of three assignment statements that posed a problem in the example at the beginning of this chapter. All that remains to solve that example, for instance, is to adapt an existing store analysis such as <ref> [GH96] </ref>. 8.7 Value Analysis In this section, we isolate a subcase of our our methodology for value analyses. The sign analysis of Section 1.1 and Section 8.4 is a simple kind of value analysis. Recall that a store is a function from l-value to value.
Reference: [GLT89] <author> Jean-Yves Girard, Yves Lafont, and Paul Taylor. </author> <title> Proofs and Types, </title> <booktitle> volume 7 of Cambridge Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1989. </year> <pages> (pp 67, 98) </pages>
Reference-contexts: The spirit of denotational semantics is to model function terms in the source language with actual functions. This turns out to be difficult; Dana Scott solved the underlying problems [Sco70, Sco76, Sco82]. On the other hand, Jean-Yves Girard in <ref> [GLT89] </ref> makes the following philosophical observation about the ff, fi, and equations of -calculus [Bar84]: In fact, these equations may be read in two different ways, which re-iterate the dichotomy [in logic] between sense and denotation: 68 Semantics via Transfer Relations * as the equations which define the equality of terms, <p> Much of programming-language theory and practice is based on the notion that reduction of -calculus terms is a kind of computation. Even further, the Curry-Howard isomor-phism [How80] introduces the connection between proof theory and computation, and consequently between logical systems and programming languages. (We refer the curious reader to <ref> [GLT89] </ref>.) Let us consider how the above -calculus term might correspond to a SML program (chosen rather arbitrarily, simply as an example of a "real" language), and how its reduction might correspond to the execution of the program.
Reference: [Gra89] <author> Philippe Granger. </author> <title> Static analysis of arithmetical congruences. </title> <journal> International Journal of Computer Mathematics, </journal> <pages> pages 165-199, </pages> <year> 1989. </year> <title> (p 4) 166 BIBLIOGRAPHY </title>
Reference-contexts: A powerful methodology has been constructed around this theory [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95], including a wide range of techniques for designing numeric lattices <ref> [Kar76, CH78, Gra89, Gra91a, Gra91b] </ref>. But when faced with a specific analysis task for a specific programming language, the analysis designer is left largely on his own to cope with the overwhelming generality of the framework.
Reference: [Gra91a] <author> P. Granger. </author> <title> Analyses Semantiques de Congruence. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, Palaiseau, France, </institution> <month> July </month> <year> 1991. </year> <title> (p 4) </title>
Reference-contexts: A powerful methodology has been constructed around this theory [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95], including a wide range of techniques for designing numeric lattices <ref> [Kar76, CH78, Gra89, Gra91a, Gra91b] </ref>. But when faced with a specific analysis task for a specific programming language, the analysis designer is left largely on his own to cope with the overwhelming generality of the framework.
Reference: [Gra91b] <author> P. Granger. </author> <title> Static analysis on linear congruence equalities among variables of a program. </title> <booktitle> In TAPSOFT'91, volume 493 of Lecture Notes in Computer Science, </booktitle> <pages> pages 169-192. </pages> <publisher> Springer Verlag, </publisher> <year> 1991. </year> <title> (p 4) </title>
Reference-contexts: A powerful methodology has been constructed around this theory [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95], including a wide range of techniques for designing numeric lattices <ref> [Kar76, CH78, Gra89, Gra91a, Gra91b] </ref>. But when faced with a specific analysis task for a specific programming language, the analysis designer is left largely on his own to cope with the overwhelming generality of the framework.
Reference: [H + 92] <editor> P. Hudak et al. </editor> <title> Report on the programming language Haskell. </title> <journal> SIGPLAN Notices, 27(5):Section R, 1992. </journal> <volume> (p 97) </volume>
Reference-contexts: Real programming languages have some mechanism for defining functions. A function accepts some input data (parameters) from its caller and returns a result value to the caller. In some languages, such as Haskell <ref> [H + 92] </ref>, functions have the same input-output behavior in any context. This is sometimes known as referential transparency [SS90]. We call this kind of function "pure". The vast majority of programming languages, however, provide impure functions.
Reference: [Hei92] <author> Nevin Heintze. </author> <title> Set Based Program Analysis. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania, </institution> <year> 1992. </year> <pages> (pp 12, 102) </pages>
Reference-contexts: Almost every kind of program analysis is based on a similar notion of fixed-point calculation over an abstraction of the properties of interest. This is not always apparent, because many analysis frameworks, such as data-flow analysis [MJ81], type inference [KMP84], and constraint-based analysis <ref> [Hei92, AWL94] </ref>, are phrased in terms of systems of equations or inference rules. But most of these frameworks reduce to a fixed-point calculation whose iterations correspond in some sense to abstract execution steps of the program. Abstract interpretation is a fixed-point-based theory that unifies these seemingly disparate approaches. <p> The circularity in the equation for Val arises from immutable tuples, and indeed most static analyses of even immutable structured values|not to mention mutable data structures|are quite crude (e.g., [Wad87], <ref> [Hei92] </ref>). One of the few satisfactory analyses of structured values is [Deu92], but it is still somewhat ad hoc and also quite complicated. The other circularity arises from first-class functions, and again it is no coincidence that analysis designers have traditionally encountered trouble with first-class functions.
Reference: [How80] <author> W. Howard. </author> <title> The formulas-as-types notion of construction. In To H.B. </title> <booktitle> Curry: Essays on Combinatory Logic, Lambda-Calculus and Formalism, </booktitle> <pages> pages 479-490. </pages> <publisher> Academic Press, </publisher> <year> 1980. </year> <title> (p 98) </title>
Reference-contexts: Much of programming-language theory and practice is based on the notion that reduction of -calculus terms is a kind of computation. Even further, the Curry-Howard isomor-phism <ref> [How80] </ref> introduces the connection between proof theory and computation, and consequently between logical systems and programming languages. (We refer the curious reader to [GLT89].) Let us consider how the above -calculus term might correspond to a SML program (chosen rather arbitrarily, simply as an example of a "real" language), and how
Reference: [HP79] <author> M. Hennessy and G. D. Plotkin. </author> <title> Full abstraction for a simple programming language. </title> <editor> In J. Becvar, editor, </editor> <booktitle> 8 th Symposium on Mathematical Foundations of Computer Science, volume 74 of Lecture Notes in Computer Science, </booktitle> <pages> pages 108-120. </pages> <publisher> Springer-Verlag, </publisher> <year> 1979. </year> <title> (p 39) </title>
Reference-contexts: For instance, true? 0 ; but true? 0 6= : In this sense, the language TR is not fully abstract <ref> [HP79, Mul87] </ref>. If it were fully abstract, then we would have a decidable way of testing semantic equality of transfer relations, but this will not be so important for the applications of our analysis framework.
Reference: [HRB90] <author> Susan Horwitz, Thomas Reps, and David Binkley. </author> <title> Interprocedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year> <title> (p 4) </title>
Reference-contexts: For instance, the work in static debugging [Bou93a, Bou93b] allows the user to specify various kinds of pre- and post-conditions at different points in the program, and then calculates the 4 Some Topics in Program Analysis corresponding information about the ranges of numeric variables. Also, program slicing (e.g., <ref> [HRB90] </ref>, [FRT95]) isolates the parts of a program that contribute to or depend on a particular variable in the program chosen by the user. This dissertation presents some new developments in the theory of program analysis.
Reference: [JM79] <author> Neil D. Jones and Steven S. Muchnick. </author> <title> Flow analysis and optimization of Lisp-like structures. </title> <booktitle> In Conference Record of the 8th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 244-256, </pages> <month> January </month> <year> 1979. </year> <title> (p 3) </title>
Reference-contexts: For instance, most compilers use data-flow analysis (e.g., [KU76], [MJ81]) and alias analysis (e.g., [CWZ90], [Lan91], [Deu94]) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations [ASU86]. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., <ref> [JM79] </ref>, [Shi91]) to construct a conservative control graph. Compiler support is far and away the most common application of program analysis. * Program verification. One would like to check statically that a program will behave properly at run time.
Reference: [Kah87] <author> Gilles Kahn. </author> <title> Natural semantics. </title> <booktitle> In Proceedings of the Symposium on Theoretical Aspects of Computer Science, </booktitle> <address> Passau, Germany, </address> <month> February </month> <year> 1987. </year> <note> Proceedings published as Springer-Verlag Lecture Notes in Computer Science 247. The paper is also available as INRIA Report 601, February, 1987. (p 69) </note>
Reference-contexts: This is also perhaps why the field of program analysis continues to struggle for acceptance in programming-language theory. As Girard says, operational semantics tend to be "uncivilised", and despite the frameworks of structural operational semantics [Plo81] (generalized to infinite behaviors in [CC92b]) and natural semantics <ref> [Kah87] </ref>, operational semantics does not have nearly the developed and refined theory of denotational semantics.
Reference: [Kar76] <author> M. Karr. </author> <title> Affine relationships among variables of a program. </title> <journal> Acta Informatica, </journal> <volume> 6 </volume> <pages> 133-151, </pages> <year> 1976. </year> <title> (p 4) </title>
Reference-contexts: A powerful methodology has been constructed around this theory [CC79, Cou81, Cou90, CC92a, CC92b, CC92d, CC92c, CC94, CC95], including a wide range of techniques for designing numeric lattices <ref> [Kar76, CH78, Gra89, Gra91a, Gra91b] </ref>. But when faced with a specific analysis task for a specific programming language, the analysis designer is left largely on his own to cope with the overwhelming generality of the framework.
Reference: [KMP84] <author> G. Kahn, D. B. MacQueen, and G. Plotkin. </author> <title> Semantics of Data Types. </title> <publisher> Springer Verlag (Heidelberg, </publisher> <address> FRG and NewYork NY, USA), Internat.Symp.Proc., </address> ; <note> ACM CR 8504-0266, 1984. (p 12) </note>
Reference-contexts: Almost every kind of program analysis is based on a similar notion of fixed-point calculation over an abstraction of the properties of interest. This is not always apparent, because many analysis frameworks, such as data-flow analysis [MJ81], type inference <ref> [KMP84] </ref>, and constraint-based analysis [Hei92, AWL94], are phrased in terms of systems of equations or inference rules. But most of these frameworks reduce to a fixed-point calculation whose iterations correspond in some sense to abstract execution steps of the program.
Reference: [Knu71] <author> D. E. Knuth. </author> <title> An empirical study of FORTRAN programs. </title> <journal> Software Practice and Experience, </journal> <volume> 1(12) </volume> <pages> 105-134, </pages> <year> 1971. </year> <title> Motivation for optimization. (p 97) </title>
Reference-contexts: For instance, they may be assigned to variables, placed in data structures, and passed to other functions. The functions in most advanced languages, such as Scheme [ReC86] or Standard ML (SML) [MTH90], are first class. In contrast, the functions in C [KR78], Fortran <ref> [Knu71] </ref>, and Pascal [Bar81] are not first class. In some ways, our methodology must be rather stretched to handle first-class functions.
Reference: [KR78] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Progamming Language. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, 1 edition, </address> <year> 1978. </year> <title> (p 97) BIBLIOGRAPHY 167 </title>
Reference-contexts: For instance, they may be assigned to variables, placed in data structures, and passed to other functions. The functions in most advanced languages, such as Scheme [ReC86] or Standard ML (SML) [MTH90], are first class. In contrast, the functions in C <ref> [KR78] </ref>, Fortran [Knu71], and Pascal [Bar81] are not first class. In some ways, our methodology must be rather stretched to handle first-class functions.
Reference: [Kra88] <author> David Kranz. </author> <title> Orbit: An optimizing compiler for scheme. </title> <type> Computer science technical report #632 (ph.d. dissertation), </type> <institution> Yale University, </institution> <year> 1988. </year> <title> (p 100) </title>
Reference-contexts: The first major practical use of CPS was in the Scheme Rabbit compiler [Ste78], which translated source programs into a restricted syntax much like ours. This was later done in the Orbit Scheme compiler <ref> [Kra88] </ref> and then in the SML/NJ compiler [App92]. All translations are based on a universal calling convention in which all source functions take a continuation argument and all source applications must thus pass a continuation function 6.4 Semantics 101 describing the remainder of the computation.
Reference: [KU76] <author> J. B. Kam and Jeffrey D. Ullman. </author> <title> Global data flow analysis and iterative algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 158-171, </pages> <year> 1976. </year> <title> (p 3) </title>
Reference-contexts: Therefore, the compiler must invoke a program analysis to uncover this run-time behavior. For instance, most compilers use data-flow analysis (e.g., <ref> [KU76] </ref>, [MJ81]) and alias analysis (e.g., [CWZ90], [Lan91], [Deu94]) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations [ASU86]. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., [JM79], [Shi91]) to construct a conservative control graph.
Reference: [Lan91] <author> W. Landi. </author> <title> Interprocedural aliasing in the presence of pointers. </title> <type> Phd thesis, </type> <institution> Rutgers University, </institution> <year> 1991. </year> <title> (p 3) </title>
Reference-contexts: Therefore, the compiler must invoke a program analysis to uncover this run-time behavior. For instance, most compilers use data-flow analysis (e.g., [KU76], [MJ81]) and alias analysis (e.g., [CWZ90], <ref> [Lan91] </ref>, [Deu94]) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations [ASU86]. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., [JM79], [Shi91]) to construct a conservative control graph.
Reference: [LD93] <author> Julia L. Lawall and Olivier Danvy. </author> <title> Separating stages in the continuation-passing style transformation. </title> <booktitle> In Conference Record of the 20th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 124-136, </pages> <address> Charleston, South Carolina, </address> <month> January </month> <year> 1993. </year> <title> (p 99) </title>
Reference-contexts: Therefore, because real implementations typically use closures to model first-class functions, we will model functions with closures in our semantics. 6.2 Syntax We now present the purely functional language called Pure. A program is a member of the set Term of terms, written in a brand of continuation-passing style <ref> [LD93] </ref>. t ::= let x = e in t local binding j rec g in t recursive function binding j e (~e) function application j if e then t else t 0 conditional j e simple term (Exp) g ::= x (~y) = t 0 n-ary function definitions 100 First-Class Functions:
Reference: [MFH95] <author> Greg Morrisett, Matthias Felleisen, and Robert Harper. </author> <title> Abstract models of memory management. </title> <booktitle> In International Conference on Functional Programming and Computer Architecture, </booktitle> <month> June </month> <year> 1995. </year> <pages> (pp 24, 69) </pages>
Reference-contexts: The above example illustrates that for some programming languages, the set Val of values might include, in addition to the base values of the language, a set of pointers to represent mutable data structures. In some operational semantics, these are called "locations" or "heap values" <ref> [MFH95] </ref> and are just taken from an arbitrary infinite set. Again, we stress that a store is a total function. <p> For instance, in context semantics [FF86], a state of execution is simply a syntactic term; the control state is encoded in as the next redex to be reduced, and the data state is modeled with syntactic constructs (such as substitution or the heap variables in <ref> [MFH95] </ref>) and folded into the term itself. But much of program analysis is concerned with analyzing the patterns of data access during execution, and so we wish to keep control and data explicitly separated. This inspires a semantic methodology in which a program is modeled by a transition system.
Reference: [MJ81] <author> S. S Muchnick and N. D. Jones. </author> <title> Program flow analysis: theory and applications. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year> <pages> (pp 3, 12) </pages>
Reference-contexts: Therefore, the compiler must invoke a program analysis to uncover this run-time behavior. For instance, most compilers use data-flow analysis (e.g., [KU76], <ref> [MJ81] </ref>) and alias analysis (e.g., [CWZ90], [Lan91], [Deu94]) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations [ASU86]. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., [JM79], [Shi91]) to construct a conservative control graph. <p> Almost every kind of program analysis is based on a similar notion of fixed-point calculation over an abstraction of the properties of interest. This is not always apparent, because many analysis frameworks, such as data-flow analysis <ref> [MJ81] </ref>, type inference [KMP84], and constraint-based analysis [Hei92, AWL94], are phrased in terms of systems of equations or inference rules. But most of these frameworks reduce to a fixed-point calculation whose iterations correspond in some sense to abstract execution steps of the program.
Reference: [MTH90] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year> <pages> (pp 3, 24, 97) </pages>
Reference-contexts: For instance, an analysis might verify that a C program never attempts to dereference a dangling pointer; or if it cannot verify a property that strong, it might at least isolate a small number of potential trouble spots in the code. Also, strongly typed languages such as Standard ML <ref> [MTH90] </ref> verify at compile time that a program is well-typed and thus completely eliminate any possibility of a type error at run time. Furthermore, static type-checking reveals at compile time a remarkable percentage of programmer errors. * Program comprehension. <p> We stress again the crucial concept that l-values represent the mutable memory locations. Some programming languages include data structures that are not mutable|for instance, the 24 Stores and Transfer Relations tuples, records, and vectors in Standard ML <ref> [MTH90] </ref>. One would probably model these objects simply as compound values rather than breaking them up into their components and indexing those components by separate l-values in the store. Example 1 Consider the C programming language. <p> For instance, they may be assigned to variables, placed in data structures, and passed to other functions. The functions in most advanced languages, such as Scheme [ReC86] or Standard ML (SML) <ref> [MTH90] </ref>, are first class. In contrast, the functions in C [KR78], Fortran [Knu71], and Pascal [Bar81] are not first class. In some ways, our methodology must be rather stretched to handle first-class functions.
Reference: [Mul87] <author> Ketan Mulmuley. </author> <title> Full Abstraction and Semantic Equivalence. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, 1987. </address> <publisher> Ph. </publisher> <address> D. </address> <institution> Dissertation, Carnegie Mellon University, </institution> <month> August </month> <year> 1985. </year> <pages> (pp 39, 127) </pages>
Reference-contexts: For instance, true? 0 ; but true? 0 6= : In this sense, the language TR is not fully abstract <ref> [HP79, Mul87] </ref>. If it were fully abstract, then we would have a decidable way of testing semantic equality of transfer relations, but this will not be so important for the applications of our analysis framework. <p> For instance, much of the study of pure semantics is concerned with finding semantic objects that are as abstract as possible while still adequate as a semantic definition; the ultimate goal here is full abstraction <ref> [Mul87] </ref>. But for the purpose of program analysis, it is necessary to abstract away crucial information for the sake of computability. The choice of what to abstract away defines the program analysis.
Reference: [Myc81] <author> Alan Mycroft. </author> <title> Abstract Interpretation and Optimising Transformations for Applicative Programs. </title> <type> Ph.D. Thesis, </type> <institution> Univ. of Edinburgh, </institution> <month> December </month> <year> 1981. </year> <title> (p 68) </title>
Reference-contexts: Almost as soon as abstract interpretation arrived on the scene, to make a connection between program analyses and the semantics of programming languages, a great amount of effort was spent in adapting it to denotational semantics. For some examples, see <ref> [Myc81] </ref>, [Nie84], [Nie86], and [AH87]. As one would expect, this body of work offers some of the most esthetically pleasing formulations of program analyses, but it also has found little use beyond a narrow range of applications such as strictness analysis [BHA86].
Reference: [Nie84] <author> Flemming Nielson. </author> <title> Abstract Interpretation using Domain Theory. </title> <type> Ph.D. Thesis, </type> <institution> Univ. of Edinburgh, </institution> <month> October </month> <year> 1984. </year> <title> (p 68) </title>
Reference-contexts: Almost as soon as abstract interpretation arrived on the scene, to make a connection between program analyses and the semantics of programming languages, a great amount of effort was spent in adapting it to denotational semantics. For some examples, see [Myc81], <ref> [Nie84] </ref>, [Nie86], and [AH87]. As one would expect, this body of work offers some of the most esthetically pleasing formulations of program analyses, but it also has found little use beyond a narrow range of applications such as strictness analysis [BHA86].
Reference: [Nie86] <author> F Nielson. </author> <title> Abstract Interpretation of Denotational Definitions. </title> <booktitle> In STACS'86, volume 210 of LNCS, </booktitle> <pages> pages 1-20. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year> <title> (p 68) </title>
Reference-contexts: Almost as soon as abstract interpretation arrived on the scene, to make a connection between program analyses and the semantics of programming languages, a great amount of effort was spent in adapting it to denotational semantics. For some examples, see [Myc81], [Nie84], <ref> [Nie86] </ref>, and [AH87]. As one would expect, this body of work offers some of the most esthetically pleasing formulations of program analyses, but it also has found little use beyond a narrow range of applications such as strictness analysis [BHA86].
Reference: [OT95] <author> P. W. O'Hearn and R. D. Tennent. </author> <title> Parametricity and local variables. </title> <journal> Journal of the ACM, </journal> <volume> 42(3) </volume> <pages> 658-709, </pages> <month> May </month> <year> 1995. </year> <title> (p 120) </title>
Reference-contexts: This is a simple case of the well studied problem with full abstraction for languages that combine assignment and procedures <ref> [OT95, Sie94] </ref>. At this point, we have simplified the new imperative constructs into a set of primitive operations and a generic assignment term.
Reference: [Plo75] <author> Gordon Plotkin. </author> <title> Call-by-name, call-by-value, and the -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 125-159, </pages> <year> 1975. </year> <pages> (pp 100, 101) </pages>
Reference-contexts: CPS was studied early as the subset of -calculus terms for which call-by-name and call-by-value reduction strategies are equivalent <ref> [Plo75] </ref>. The first major practical use of CPS was in the Scheme Rabbit compiler [Ste78], which translated source programs into a restricted syntax much like ours. This was later done in the Orbit Scheme compiler [Kra88] and then in the SML/NJ compiler [App92]. <p> So, for instance, an automatic CPS converter might produce rec f (x; k) = (rec g (y; k) = k (x + y) in k (g)) for the program above. These translations are well studied, both in theory and practice <ref> [Plo75] </ref> (see also other references cited above), and so we will not go any further into CPS here.
Reference: [Plo81] <author> Gordon D. Plotkin. </author> <title> A structural approach to operational semantics. </title> <type> Technical Report DAIMI FN-19, </type> <institution> Computer Science Department, Aarhus University, Aarhus, Denmark, </institution> <year> 1981. </year> <title> (p 69) 168 BIBLIOGRAPHY </title>
Reference-contexts: This is also perhaps why the field of program analysis continues to struggle for acceptance in programming-language theory. As Girard says, operational semantics tend to be "uncivilised", and despite the frameworks of structural operational semantics <ref> [Plo81] </ref> (generalized to infinite behaviors in [CC92b]) and natural semantics [Kah87], operational semantics does not have nearly the developed and refined theory of denotational semantics.
Reference: [ReC86] <editor> Jonathan A. Rees and eds. Clinger, William C. </editor> <title> Revised 3 report on the algorithmic language scheme. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(12) </volume> <pages> 37-79, </pages> <month> December </month> <year> 1986. </year> <pages> (pp 23, 97) </pages>
Reference-contexts: In the latter case, however, the compound object must be immutable because it represents the contents of a single mutable memory location. So, for instance, one should not model a (mutable) Scheme <ref> [ReC86] </ref> cons cell (1 : 2) with a single value, but rather use three values: one for the cons cell itself, one for 1, and one for 2. A store is then a function from l-values to values that describes the contents of the memory. <p> This means that the functions are semantic values, and as such can be manipulated by a program like any other value. For instance, they may be assigned to variables, placed in data structures, and passed to other functions. The functions in most advanced languages, such as Scheme <ref> [ReC86] </ref> or Standard ML (SML) [MTH90], are first class. In contrast, the functions in C [KR78], Fortran [Knu71], and Pascal [Bar81] are not first class. In some ways, our methodology must be rather stretched to handle first-class functions.
Reference: [Sch95] <author> D. A. Schmidt. </author> <title> Natural-semantics-based abstract interpretation. </title> <booktitle> Lecture Notes in Computer Science, 983:1-??, 1995. (p 69) </booktitle>
Reference-contexts: Even worse, despite an effort by Schmidt in <ref> [Sch95] </ref> to begin to develop a sub-framework of abstract interpretation for natural semantics, most program analyses use what Girard calls the "ad hoc semantics that crudely paraphrase the steps toward normalisation".
Reference: [Sco70] <author> Dana Scott. </author> <title> Outline of a mathematical theory of computation. </title> <booktitle> In Proceedings, Fourth Annual Princeton Conference on Information Sciences and Systems, </booktitle> <pages> pages 169-176. </pages> <institution> Princeton University, </institution> <year> 1970. </year> <note> Also, </note> <institution> Programming Research Group Technical Monograph PRG-2, Oxford University. (p 67) </institution>
Reference-contexts: The spirit of denotational semantics is to model function terms in the source language with actual functions. This turns out to be difficult; Dana Scott solved the underlying problems <ref> [Sco70, Sco76, Sco82] </ref>.
Reference: [Sco76] <author> Dana S. Scott. </author> <title> Data types as lattices. </title> <journal> SIAM Journal on Computing, </journal> <volume> 5 </volume> <pages> 522-587, </pages> <year> 1976. </year> <title> (p 67) </title>
Reference-contexts: The spirit of denotational semantics is to model function terms in the source language with actual functions. This turns out to be difficult; Dana Scott solved the underlying problems <ref> [Sco70, Sco76, Sco82] </ref>.
Reference: [Sco82] <author> Dana S. Scott. </author> <title> Domains for denotational semantics. </title> <booktitle> In Proceedings International Colloquium on Automata, Languages, and Programming '82, 1982. (p 67) </booktitle>
Reference-contexts: The spirit of denotational semantics is to model function terms in the source language with actual functions. This turns out to be difficult; Dana Scott solved the underlying problems <ref> [Sco70, Sco76, Sco82] </ref>.
Reference: [Shi91] <author> Olin Grigsby Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages or Taming Lambda. </title> <type> PhD thesis, </type> <institution> Carnige-Mellon Univeristy, </institution> <month> May </month> <year> 1991. </year> <note> Also available as CMU-CS-91-145. (pp 3, 102) </note>
Reference-contexts: For instance, most compilers use data-flow analysis (e.g., [KU76], [MJ81]) and alias analysis (e.g., [CWZ90], [Lan91], [Deu94]) to enable classic optimizations such as common-subexpression elimination, copy propagation, and hoisting of loop-invariant computations [ASU86]. Similarly, some compilers for languages with first-class functions use a control-flow analysis (e.g., [JM79], <ref> [Shi91] </ref>) to construct a conservative control graph. Compiler support is far and away the most common application of program analysis. * Program verification. One would like to check statically that a program will behave properly at run time. <p> The usual ad hoc approaches are to be found in the work on denotational-based abstract interpretations, usually applied to strictness analysis [BHA86], the work on finite approximations of closures <ref> [Shi91] </ref>, or the work on augmenting higher-order type systems with "effects" [TJ92]. None of this work seems satisfactory. What lies at the root of these problems is the ubiquitous analysis methodology that begins with the design of a (hopefully clever) approximation of an infinite domain.
Reference: [Sie94] <author> Kurt Sieber. </author> <title> Full abstraction for the second order subset of an algol-like language. </title> <editor> In Igor Prvara, Branislav Rovan, and Peter Ruzicka, editors, </editor> <booktitle> Mathematical Foundations of Computer Science 1994 19th International Symposium, volume 841 of LNCS, </booktitle> <pages> pages 608-617, </pages> <address> Kosice, Slovakia, </address> <month> 22-26 August </month> <year> 1994. </year> <title> Springer. (p 120) </title>
Reference-contexts: This is a simple case of the well studied problem with full abstraction for languages that combine assignment and procedures <ref> [OT95, Sie94] </ref>. At this point, we have simplified the new imperative constructs into a set of primitive operations and a generic assignment term.
Reference: [SRW96] <author> Mooly Sagiv, Thomas Reps, and Reinhard Wilhelm. </author> <title> Solving shape-analysis problems in languages with destructive updating. </title> <booktitle> In Conference Record of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'96), </booktitle> <pages> pages 16-31, </pages> <address> St. Petersburg, Florida, </address> <month> January 21-24, </month> <title> 1996. </title> <publisher> ACM Press. </publisher> <pages> (pp 9, 125, 126) </pages>
Reference-contexts: This is a problem not just with Ghiya and Hendren's shape analysis. At the same conference, Sagiv, Reps, and Wilhelm presented a shape analysis that attempts to address these issues <ref> [SRW96] </ref>. <p> Most shape analyses cannot determine this information. To our knowledge, only <ref> [SRW96] </ref> can achieve this result, but it is highly specialized for this and similar cases and requires quite restrictive conditions, as explained in Section 1.1. But for now we wish to point out why this program is so difficult to analyze. <p> An analysis would need to have the ability to describe the special property at 8 with sufficient detail to infer that the assignment at 8 changes x back to a tree. In fact, that is what <ref> [SRW96] </ref> does to solve this particular problem. But there is a much more general solution, and that is to avoid the necessity to infer a property at every step, and instead allow multiple steps of execution before abstracting.
Reference: [SS90] <author> Harald Stndergaard and Peter Sestoft. </author> <title> Referential transparency, definiteness and unfoldability. </title> <journal> Acta Informatica, </journal> <volume> 27 </volume> <pages> 505-517, </pages> <year> 1990. </year> <title> (p 97) </title>
Reference-contexts: A function accepts some input data (parameters) from its caller and returns a result value to the caller. In some languages, such as Haskell [H + 92], functions have the same input-output behavior in any context. This is sometimes known as referential transparency <ref> [SS90] </ref>. We call this kind of function "pure". The vast majority of programming languages, however, provide impure functions. In this chapter we model a programming language with pure functions, and in the next chapter we will extend this language with imperative features and impure functions.
Reference: [Ste78] <author> Guy L. Steele. Rabbit: </author> <title> A compiler for Scheme. </title> <type> Technical Report 474, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1978. </year> <title> (p 100) </title>
Reference-contexts: CPS was studied early as the subset of -calculus terms for which call-by-name and call-by-value reduction strategies are equivalent [Plo75]. The first major practical use of CPS was in the Scheme Rabbit compiler <ref> [Ste78] </ref>, which translated source programs into a restricted syntax much like ours. This was later done in the Orbit Scheme compiler [Kra88] and then in the SML/NJ compiler [App92].
Reference: [Sto77] <author> J. Stoy. </author> <title> Denotational Semantics. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mass, </address> <year> 1977. </year> <pages> (pp 67, 99) </pages>
Reference-contexts: A denotational semantics <ref> [Sto77] </ref> uses structural induction to assign each term in the source language an object in some abstract model. The spirit of denotational semantics is to model function terms in the source language with actual functions. This turns out to be difficult; Dana Scott solved the underlying problems [Sco70, Sco76, Sco82]. <p> This deeply ingrained notion that a variable "has a value" is partially an artifact of this implementation issue, and is supported by the standard denotational model of the -calculus which models a term x: e as a continuous function <ref> [Sto77] </ref>. In the reduction of -terms, one must consider variables in a different light; they are placeholders that during reduction (execution) are replaced with terms and disappear entirely.
Reference: [TJ92] <author> J.-P. Talpin and P. Jouvelot. </author> <title> The type and effects discipline. </title> <booktitle> In Proc. IEEE Symp. on Logic in Computer Science, </booktitle> <pages> pages 162-173, </pages> <year> 1992. </year> <title> (p 102) </title>
Reference-contexts: The usual ad hoc approaches are to be found in the work on denotational-based abstract interpretations, usually applied to strictness analysis [BHA86], the work on finite approximations of closures [Shi91], or the work on augmenting higher-order type systems with "effects" <ref> [TJ92] </ref>. None of this work seems satisfactory. What lies at the root of these problems is the ubiquitous analysis methodology that begins with the design of a (hopefully clever) approximation of an infinite domain.
Reference: [Wad87] <author> Phil Wadler. </author> <title> Strictness analysis on non-flat domains (by abstract interpretation). </title> <editor> In S Abramsky and C Hankin, editors, </editor> <booktitle> Abstract Interpretation of Declarative Languages, chapter 12, </booktitle> <pages> pages 266-275. </pages> <publisher> Ellis-Horwood, </publisher> <year> 1987. </year> <title> (p 102) BIBLIOGRAPHY 169 </title>
Reference-contexts: The circularity in the equation for Val arises from immutable tuples, and indeed most static analyses of even immutable structured values|not to mention mutable data structures|are quite crude (e.g., <ref> [Wad87] </ref>, [Hei92]). One of the few satisfactory analyses of structured values is [Deu92], but it is still somewhat ad hoc and also quite complicated. The other circularity arises from first-class functions, and again it is no coincidence that analysis designers have traditionally encountered trouble with first-class functions.
Reference: [Wan77] <author> Mitchell Wand. </author> <title> A characterization of weakest preconditions. </title> <journal> Journal of Computer and Systems Science, </journal> <volume> 15 </volume> <pages> 209-212, </pages> <year> 1977. </year> <title> (p 22) </title>
Reference-contexts: This is similar to the situation with loops; a potentially unbounded number of trace intervals share a common net effect between their initial and final stores. Related to this idea is the use of weakest preconditions to describe the semantics of loops <ref> [Dij76, Wan77] </ref>. * As a practical matter, even if the initial store is fixed and the program terminates, isolating the patterns in the trace provides a hope of making the analysis feasible in practice.
References-found: 72

