URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/miikkulainen.inference.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: 
Email: risto@cs.utexas.edu  
Title: Script-Based Inference and Memory Retrieval in Subsymbolic Story Processing  
Author: Risto Miikkulainen 
Address: Austin, Austin, TX 78712  
Affiliation: Department of Computer Sciences The University of Texas at  
Abstract: DISCERN is an integrated natural language processing system built entirely from distributed neural networks. It reads short narratives about stereotypical event sequences, stores them in episodic memory, generates fully expanded paraphrases of the narratives, and answers questions about them. Processing in DISCERN is based on hierarchically-organized backpropagation modules, communicating through a central lexicon of word representations. The lexicon is a double feature map system that transforms each orthographic word symbol into its semantic representation and vice versa. The episodic memory is a hierarchy of feature maps, where memories are stored "one-shot" at different locations. Several high-level phenomena emerge automatically from the special properties of distributed neural networks in this model. DISCERN learns to infer unmentioned events and unspecified role fillers, generates expectations and defaults, and exhibits plausible lexical access errors and memory interference behavior. Word semantics, memory organization, and appropriate script inferences are automatically extracted from examples. DISCERN shows that high-level natural language processing is feasible through integrated subsymbolic systems. Subsymbolic control of high-level behavior and representing and learning abstractions are the two main challenges in scaling up the approach to more open-ended tasks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Alvarado, M. G. Dyer, and M. Flowers. </author> <title> Argument representation for editorial text. </title> <journal> Knowledge-Based Systems, </journal> <volume> 3 </volume> <pages> 87-107, </pages> <year> 1990. </year>
Reference-contexts: The error signal is propagated to the input layer, and the current input representations are modified as if they were an extra layer of weights (but constrained within the interval <ref> [0; 1] </ref>): r ci (t+1) = max (0; min (1; r ci (t) +ffi 1i )); ; (1) where r ci (t) is the value of the representation component i of word c at time t, ffi 1i is the error signal of the corresponding input layer unit, and is the <p> For example in story understanding, symbolic systems have been developed that analyze realistic stories in-depth, based on higher-level knowledge structures such as goals, plans, themes, affects, beliefs, argument structures, plots, and morals <ref> [1; 11; 41; 46] </ref>. Subsymbolic systems cannot yet model cognitive processes at this level.
Reference: [2] <author> A. D. Baddeley. </author> <title> The Psychology of Memory. </title> <publisher> Basic Books: </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: If the memory capacity is exceeded, older traces will be selectively replaced by newer ones. Traces that are unique, that is, located in a sparse area of the map, are not affected, no matter how old they are. Similar effects are common in human long-term memory <ref> [2; 39] </ref>. 2.3.3 Storage and retrieval A story is represented in the episodic memory by the maximally responding units at the script, track, and role-binding levels. However, each unit on a role-binding map stands for a unique story, and a trace needs to be created only at the bottom level.
Reference: [3] <author> G. H. Bower, J. B. Black, and T. J. Turner. </author> <title> Scripts in memory for text. </title> <journal> Cognitive Psychology, </journal> <volume> 11 </volume> <pages> 177-220, </pages> <year> 1979. </year>
Reference-contexts: What details are produced in the paraphrase and question answering depends on the training of the output networks. This result is consistent with psychological data on how people remember stories of familiar event sequences <ref> [3; 17; 18] </ref>. The distinction of what was actually mentioned and what was inferred becomes blurred. Questions or references to events that were not mentioned are often answered as if they were part of the original story. 4.2 Paraphrasing The generator subsystem reverses the parsing process. <p> They may appear slightly out of order without much problem. The story parser is still able to generate the correct slot-filler representation for the story, and in the paraphrase, the events appear in normal order. This behavior matches human performance in recalling script-based stories <ref> [3] </ref>. However, the hidden layer pattern does undergo a subtle change as more events are input. If an event appears very far from its correct place, the network will have trouble interpreting it. <p> In this case, a representation that is a combination of the stored traces is retrieved. In other words, DISCERN remembers several distinct features of similar stories, but cannot keep the stories separate. Similar behavior has been observed experimentally in human memory <ref> [3; 56] </ref>. 5 Discussion DISCERN serves to illustrate and focus several important issues in subsymbolic natural language processing, including the nature of schema representations and intuitive inference, the need for type/token information, and problems in generalizing into novel situations.
Reference: [4] <author> A. Caramazza. </author> <title> Some aspects of language processing revealed through the analysis of acquired aphasia: The lexical system. </title> <journal> Annual Review of Neuroscience, </journal> <volume> 11 </volume> <pages> 395-421, </pages> <year> 1988. </year>
Reference-contexts: Both maps and the associative connections between them are organized simultaneously, based on examples of co-occurring symbols and meanings. The lexicon architecture facilitates interesting behavior. Localized damage to the semantic map results in category-specific lexical deficits similar to human aphasia <ref> [4; 30] </ref>. For example, the system selectively loses access to restaurant names, or animate words, when that part of the map is damaged. Dyslexic performance errors can also be modeled.
Reference: [5] <author> M. Coltheart, K. Patterson, and J. C. Marshall, </author> <title> editors. Deep Dyslexia. </title> <publisher> Routledge and Kegan Paul: </publisher> <address> London, Boston, Henley, </address> <note> second edition, 1988. 27 </note>
Reference-contexts: Dyslexic performance errors can also be modeled. If the performance is degraded, for example, by adding noise to the connections, parsing and generation errors occur quite similarly to those observed in human deep dyslexia <ref> [5] </ref>. For example, the system may confuse Leone's with MaMaison, or LINE with LIKE, because they are nearby in the map and share similar associative connections. 2.2 FGREP processing modules Processing in DISCERN is carried out by hierarchically organized FGREP modules.
Reference: [6] <author> W. A. Cook. </author> <title> Case Grammar Theory. </title> <publisher> Georgetown University Press: </publisher> <address> Washington, DC, </address> <year> 1989. </year>
Reference-contexts: The answer producer receives the question and the story and generates an answer representation, which is output word by word by the sentence generator. The sentence representation is loosely based on the theory of thematic case roles <ref> [15; 6] </ref>. The slots in the representation correspond to the shallow semantic cases such as agent, patient, recipient, and location. The story representation follows the standard representation for scripts in symbolic systems. A script is seen as a causal chain of events with a number of open roles.
Reference: [7] <author> R. E. Cullingford. </author> <title> Script Application: Computer Understanding of Newspaper Stories. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <year> 1978. </year> <type> Technical Report 116. </type>
Reference-contexts: Understanding and retrieving stories about stereotypical event sequences is not a new task. Script theory [46] was developed to explain how knowledge about familiar everyday routines is used in story understanding. At the same time, symbolic computer models such as SAM <ref> [7] </ref> and FRUMP [8] were built that implemented the theory at various levels. The IPP [27] and CYRUS [26] systems showed how episodic memory can be organized based on a few fundamental schemas and a number of specific examples. <p> The goal is to demonstrate understanding of multisentential connected text. In this sense, DISCERN aims at natural language processing at a different level than previous subsymbolic models. 5.2 Symbolic and subsymbolic schemas There is an important distinction between scripts (or more generally, schemas) in symbolic systems <ref> [7; 11; 46] </ref>, and scripts in subsymbolic systems such as DISCERN and the above models. In the symbolic approach, a script is stored in memory as a separate, exact knowledge structure, coded by the knowledge engineer.
Reference: [8] <author> G. F. DeJong. </author> <title> Skimming Stories in Real Time: An Experiment in Integrated Understanding. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <year> 1979. </year> <type> Technical Report 158. </type>
Reference-contexts: Understanding and retrieving stories about stereotypical event sequences is not a new task. Script theory [46] was developed to explain how knowledge about familiar everyday routines is used in story understanding. At the same time, symbolic computer models such as SAM [7] and FRUMP <ref> [8] </ref> were built that implemented the theory at various levels. The IPP [27] and CYRUS [26] systems showed how episodic memory can be organized based on a few fundamental schemas and a number of specific examples.
Reference: [9] <author> C. P. Dolan and M. G. Dyer. </author> <title> Symbolic schemata, role binding, and the evolution of structure in connectionist memories. </title> <booktitle> In Proceedings of the IEEE First International Conference on Neural Networks (San Diego, CA), </booktitle> <volume> volume II, </volume> <pages> pp. 287-298, </pages> <publisher> IEEE: </publisher> <address> Piscataway, NJ, </address> <year> 1987. </year>
Reference-contexts: There are a few models that address issues in script-based understanding. They typically take some part of the task and apply subsymbolic mechanisms to it. For example, mechanisms for processing causal sequences [16], role binding <ref> [10; 9] </ref>, sequential activation and deactivation of multiple scripts [48], and learning the script taxonomy from examples [32] have been developed.
Reference: [10] <author> C. P. Dolan. </author> <title> Tensor Manipulation Networks: Connectionist and Symbolic Approaches to Comprehension, Learning and Planning. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of California, </institution> <address> Los Angeles, </address> <year> 1989. </year> <note> Technical Report UCLA-AI-89-06. </note>
Reference-contexts: There are a few models that address issues in script-based understanding. They typically take some part of the task and apply subsymbolic mechanisms to it. For example, mechanisms for processing causal sequences [16], role binding <ref> [10; 9] </ref>, sequential activation and deactivation of multiple scripts [48], and learning the script taxonomy from examples [32] have been developed. <p> The strongest, most probable correlations will dominate, depending on how well they match the input, but all of them are simultaneously active at all times (see also [45]). The correlations vary in scope from cooccurring case-role fillers to long sequences of events, even to regularities at the goal/plan level <ref> [10; 28; 47] </ref>. Regularities that make up scripts can be particularly well captured by such correlations, making script-based inference a good domain for the subsymbolic approach. Generalization and graceful degradation give rise to inferencing that is intuitive, immediate, and occurs without conscious control, similar to script-based inference in humans. <p> Units cannot be created or moved around in the network, they can only function in the same exact configuration they were trained in. It is very difficult to represent multiple fillers (e.g. the man and the boy), additional constituents, and recursive structures (see <ref> [10; 22; 38; 49] </ref> for possible approaches). Second, processing knowledge in subsymbolic models is based on statistical regularities, and they cannot handle deviations from the regularities very well [35; 51]. Exceptions are simply overridden.
Reference: [11] <author> M. G. Dyer. </author> <title> In-Depth Understanding: A Computer Model of Integrated Processing for Narrative Comprehension. </title> <publisher> MIT Press: </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: Inferences are based on handcrafted rules and representations of the scripts. Such systems cannot utilize the statistical properties of the data to enhance processing; they can only do what their creator explicitly programmed them to do. For example, symbolic expectations must be implemented as specific rules for specific situations <ref> [11; 46] </ref>. Generalization to previously unencountered inputs is possible only if there exists a rule that specifies how this is done. Representations of these rules and their application is often very complex. <p> DISCERN treats the new information provided by the question simply as a mistake, and corrects it. Of course, DISCERN could be right. However, in situations like this it would be more plausible to incorporate the new information into the memory trace <ref> [11; 29] </ref>. If the question assumes a fact that was originally left unspecified, it is plausible to incorporate the fact into the memory. Currently DISCERN has no mechanism for doing this. After the trace has been created, it cannot be modified. <p> The goal is to demonstrate understanding of multisentential connected text. In this sense, DISCERN aims at natural language processing at a different level than previous subsymbolic models. 5.2 Symbolic and subsymbolic schemas There is an important distinction between scripts (or more generally, schemas) in symbolic systems <ref> [7; 11; 46] </ref>, and scripts in subsymbolic systems such as DISCERN and the above models. In the symbolic approach, a script is stored in memory as a separate, exact knowledge structure, coded by the knowledge engineer. <p> For example in story understanding, symbolic systems have been developed that analyze realistic stories in-depth, based on higher-level knowledge structures such as goals, plans, themes, affects, beliefs, argument structures, plots, and morals <ref> [1; 11; 41; 46] </ref>. Subsymbolic systems cannot yet model cognitive processes at this level.
Reference: [12] <author> M. G. Dyer. </author> <title> Symbolic neuroengineering for natural language processing: A multilevel research approach. </title> <editor> In J. A. Barnden and J. B. Pollack, editors, </editor> <title> High-Level Connectionist Models, </title> <booktitle> volume 1 of Advances in Connectionist and Neural Computation Theory, </booktitle> <editor> J. A. Barnden, </editor> <booktitle> series editor, </booktitle> <pages> pp. 32-86. </pages> <publisher> Ablex: </publisher> <address> Norwood, NJ, </address> <year> 1991. </year>
Reference-contexts: Thus, DISCERN performs plausible role bindings: an essential task in high-level inferencing and postulated as very difficult for parallel distributed processing systems to achieve <ref> [12] </ref>. 4.9 Forgetting and Memory Confusions Memory errors occur when the episodic memory becomes overloaded with similar stories.
Reference: [13] <author> J. L. Elman. </author> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 179-211, </pages> <year> 1990. </year>
Reference-contexts: In the recurrent modules the previous hidden layer serves as sequence memory, remembering where in the sequence the system currently is and what has occurred before (figure 3). These networks have the same structure as Elman's Simple Recurrent Networks <ref> [13] </ref>, but they are used differently. In a sequential input network, the input changes at each time step, while the teaching pattern stays the same. The network learns to form a stationary representation of the sequence.
Reference: [14] <author> T. D. Erickson and M. E. Mattson. </author> <title> From words to meaning: A semantic illusion. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 20 </volume> <pages> 540-551, </pages> <year> 1981. </year>
Reference-contexts: What appears as a binding emerges from the statistical correlations between all constituents in parallel, encoded in the connections between layers. The network automatically interpolates between examples, and therefore generalizes well into familiar situations. The system can naturally model semantic illusions <ref> [14] </ref>, where the actual content of the text is overridden by semantically more likely content. But truly novel role bindings would require extrapolation, which does not automatically result from correlations. Extrapolation is only possible by applying a symbolic-like higher-level rule, which is beyond the scope of current subsymbolic models.
Reference: [15] <author> C. J. Fillmore. </author> <title> The case for case. </title> <editor> In E. Bach and R. T. Harms, editors, </editor> <booktitle> Universals in Linguistic Theory, </booktitle> <pages> pp. 0-88. </pages> <publisher> Holt, Rinehart and Winston: </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: The answer producer receives the question and the story and generates an answer representation, which is output word by word by the sentence generator. The sentence representation is loosely based on the theory of thematic case roles <ref> [15; 6] </ref>. The slots in the representation correspond to the shallow semantic cases such as agent, patient, recipient, and location. The story representation follows the standard representation for scripts in symbolic systems. A script is seen as a causal chain of events with a number of open roles.
Reference: [16] <author> R. M. Golden. </author> <title> Representing causal schemata in connectionist systems. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 13-21. </pages> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: There are a few models that address issues in script-based understanding. They typically take some part of the task and apply subsymbolic mechanisms to it. For example, mechanisms for processing causal sequences <ref> [16] </ref>, role binding [10; 9], sequential activation and deactivation of multiple scripts [48], and learning the script taxonomy from examples [32] have been developed.
Reference: [17] <author> A. C. Graesser, S. E. Gordon, and J. D. Sawyer. </author> <title> Recognition memory for typical and atypical actions in scripted activities: Tests for the script pointer+tag hypothesis. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 18 </volume> <pages> 319-332, </pages> <year> 1979. </year>
Reference-contexts: What details are produced in the paraphrase and question answering depends on the training of the output networks. This result is consistent with psychological data on how people remember stories of familiar event sequences <ref> [3; 17; 18] </ref>. The distinction of what was actually mentioned and what was inferred becomes blurred. Questions or references to events that were not mentioned are often answered as if they were part of the original story. 4.2 Paraphrasing The generator subsystem reverses the parsing process.
Reference: [18] <author> A. C. Graesser, S. B. Woll, D. J. Kowalski, and D. A. Smith. </author> <title> Memory for typical and atypical actions in scripted activities. Journal of Experimental Psychology: </title> <booktitle> Human Learning and Memory, </booktitle> <volume> 6 </volume> <pages> 503-515, </pages> <year> 1980. </year>
Reference-contexts: What details are produced in the paraphrase and question answering depends on the training of the output networks. This result is consistent with psychological data on how people remember stories of familiar event sequences <ref> [3; 17; 18] </ref>. The distinction of what was actually mentioned and what was inferred becomes blurred. Questions or references to events that were not mentioned are often answered as if they were part of the original story. 4.2 Paraphrasing The generator subsystem reverses the parsing process.
Reference: [19] <author> J. F. Hall. </author> <title> Learning as a function of word-frequency. </title> <journal> American Journal of Psychology, </journal> <volume> 67 </volume> <pages> 138-140, </pages> <year> 1954. </year>
Reference-contexts: The cue pattern is closest to the most common story representation, and if an infrequent story is to be recalled, more details need to be specified in the question. Similar frequency effect has been observed in human free recall <ref> [19; 23; 52] </ref>. The cue pattern is given to the episodic memory, which classifies it as an instance of the restaurant 14 script (0,0) and fancy-restaurant track (0,0).
Reference: [20] <author> S. Harnad. </author> <title> The symbol grounding problem. </title> <journal> Physica D, </journal> <volume> 42 </volume> <pages> 335-346, </pages> <year> 1990. </year>
Reference-contexts: system needs to be able to deal with two kinds of information: (1) semantics of symbols, defined as knowledge about the properties of symbols and the relationships between them; and (2) identities of symbols, based on some unique surface-level tag such as a sensory perception of the referent (see also <ref> [20] </ref>). The semantic knowledge is necessary for guiding the processing in a meaningful way, and the identities are necessary for logical reasoning and manipulation.
Reference: [21] <author> C. L. Harris and J. L. Elman. </author> <title> Representing variable information with simple recurrent networks. </title> <booktitle> In Proceedings of the 11th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 435-642. </pages> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1989. </year>
Reference-contexts: They typically take some part of the task and apply subsymbolic mechanisms to it. For example, mechanisms for processing causal sequences [16], role binding [10; 9], sequential activation and deactivation of multiple scripts [48], and learning the script taxonomy from examples [32] have been developed. Harris and Elman <ref> [21] </ref> trained a simple recurrent network to predict the next word 22 in a script-based story, and showed that role bindings take place not between two different occurrences of a variable, but between the variable and a global state. St.
Reference: [22] <author> G. E. Hinton. </author> <title> Mapping part-whole hierarchies into connectionist networks. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 47-75, </pages> <year> 1990. </year>
Reference-contexts: Large amounts of information, which may be incomplete or even conflicting, are simultaneously brought together to produce the most likely answer. Neural network systems fit well into modeling intuitive inference (see also <ref> [22; 57] </ref>). The network extracts statistical knowledge from the input data, and these statistics are brought together to generate the inference. For example, the quality of food in the restaurant story is inferred from the whole story, not just by looking at some part and applying a specific rule. <p> Units cannot be created or moved around in the network, they can only function in the same exact configuration they were trained in. It is very difficult to represent multiple fillers (e.g. the man and the boy), additional constituents, and recursive structures (see <ref> [10; 22; 38; 49] </ref> for possible approaches). Second, processing knowledge in subsymbolic models is based on statistical regularities, and they cannot handle deviations from the regularities very well [35; 51]. Exceptions are simply overridden.
Reference: [23] <author> W. Kintsch. </author> <title> Memory and Cognition. </title> <publisher> Wiley, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1977. </year>
Reference-contexts: The cue pattern is closest to the most common story representation, and if an infrequent story is to be recalled, more details need to be specified in the question. Similar frequency effect has been observed in human free recall <ref> [19; 23; 52] </ref>. The cue pattern is given to the episodic memory, which classifies it as an instance of the restaurant 14 script (0,0) and fancy-restaurant track (0,0).
Reference: [24] <author> T. Kohonen. </author> <title> Self-Organization and Associative Memory. </title> <publisher> Springer: </publisher> <address> Berlin, Heidelberg, New York, third edition, </address> <year> 1989. </year>
Reference-contexts: The lines indicate pathways carrying distributed word, sentence, and story representations during the performance phase of the system. The modules are trained separately with compatible I/O data. The lexicon [31] stores the lexical and semantic representations and translates between them (figure 2). It is implemented as two feature maps <ref> [24; 25] </ref>, lexical and semantic. Words whose lexical forms are similar, such as LINE and LIKE, are represented by nearby units in the lexical map. In the semantic map, words with similar semantic content, such as John and Mary or Leone's and MaMaison are mapped near each other.
Reference: [25] <author> T. Kohonen. </author> <title> The self-organizing map. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78 </volume> <pages> 1464-1480, </pages> <year> 1990. </year>
Reference-contexts: The lines indicate pathways carrying distributed word, sentence, and story representations during the performance phase of the system. The modules are trained separately with compatible I/O data. The lexicon [31] stores the lexical and semantic representations and translates between them (figure 2). It is implemented as two feature maps <ref> [24; 25] </ref>, lexical and semantic. Words whose lexical forms are similar, such as LINE and LIKE, are represented by nearby units in the lexical map. In the semantic map, words with similar semantic content, such as John and Mary or Leone's and MaMaison are mapped near each other.
Reference: [26] <author> J. L. Kolodner. </author> <title> Retrieval and Organizational Strategies in Conceptual Memory: A Computer Model. </title> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1984. </year>
Reference-contexts: Script theory [46] was developed to explain how knowledge about familiar everyday routines is used in story understanding. At the same time, symbolic computer models such as SAM [7] and FRUMP [8] were built that implemented the theory at various levels. The IPP [27] and CYRUS <ref> [26] </ref> systems showed how episodic memory can be organized based on a few fundamental schemas and a number of specific examples. These models demonstrated the power of scripts and schemas in processing texts about everyday events, and were capable of quite impressive behavior in their domains. <p> Such sequential reasoning would require intervention of a high-level "conscious" monitor (section 6.1). The hierarchical feature map system can be seen as a general model of schema-based episodic memory, similar in spirit to the symbolic CYRUS and IPP models <ref> [26; 27] </ref>. In all these models, memory is organized according to similarities in the stories, and these similarities are more abstract than simple fillers. The memory builds schemas (by abstracting individual stories), and organization proceeds by specializing existing schemas.
Reference: [27] <author> M. Lebowitz. </author> <title> Generalization and Memory in an Integrated Understanding System. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <year> 1980. </year> <note> Research Report 186. 28 </note>
Reference-contexts: Script theory [46] was developed to explain how knowledge about familiar everyday routines is used in story understanding. At the same time, symbolic computer models such as SAM [7] and FRUMP [8] were built that implemented the theory at various levels. The IPP <ref> [27] </ref> and CYRUS [26] systems showed how episodic memory can be organized based on a few fundamental schemas and a number of specific examples. These models demonstrated the power of scripts and schemas in processing texts about everyday events, and were capable of quite impressive behavior in their domains. <p> Such sequential reasoning would require intervention of a high-level "conscious" monitor (section 6.1). The hierarchical feature map system can be seen as a general model of schema-based episodic memory, similar in spirit to the symbolic CYRUS and IPP models <ref> [26; 27] </ref>. In all these models, memory is organized according to similarities in the stories, and these similarities are more abstract than simple fillers. The memory builds schemas (by abstracting individual stories), and organization proceeds by specializing existing schemas.
Reference: [28] <author> G. Lee. </author> <title> Distributed Semantic Representations for Goal/Plan Analysis of Narratives in a Connectionist Architecture. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of California, </institution> <address> Los Angeles, </address> <year> 1991. </year> <note> Technical Report UCLA-AI-91-03. </note>
Reference-contexts: The strongest, most probable correlations will dominate, depending on how well they match the input, but all of them are simultaneously active at all times (see also [45]). The correlations vary in scope from cooccurring case-role fillers to long sequences of events, even to regularities at the goal/plan level <ref> [10; 28; 47] </ref>. Regularities that make up scripts can be particularly well captured by such correlations, making script-based inference a good domain for the subsymbolic approach. Generalization and graceful degradation give rise to inferencing that is intuitive, immediate, and occurs without conscious control, similar to script-based inference in humans.
Reference: [29] <author> W. G. Lehnert. </author> <title> The Process of Question Answering. </title> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1978. </year>
Reference-contexts: DISCERN treats the new information provided by the question simply as a mistake, and corrects it. Of course, DISCERN could be right. However, in situations like this it would be more plausible to incorporate the new information into the memory trace <ref> [11; 29] </ref>. If the question assumes a fact that was originally left unspecified, it is plausible to incorporate the fact into the memory. Currently DISCERN has no mechanism for doing this. After the trace has been created, it cannot be modified.
Reference: [30] <author> R. A. McCarthy and E. K. Warrington. </author> <title> Cognitive Neuropsychology: A Clinical Introduction. </title> <publisher> Academic Press: </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Both maps and the associative connections between them are organized simultaneously, based on examples of co-occurring symbols and meanings. The lexicon architecture facilitates interesting behavior. Localized damage to the semantic map results in category-specific lexical deficits similar to human aphasia <ref> [4; 30] </ref>. For example, the system selectively loses access to restaurant names, or animate words, when that part of the map is damaged. Dyslexic performance errors can also be modeled.
Reference: [31] <author> R. Miikkulainen. </author> <title> A distributed feature map model of the lexicon. </title> <booktitle> In Proceedings of the 12th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 447-454. </pages> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1990. </year>
Reference-contexts: The lines indicate pathways carrying distributed word, sentence, and story representations during the performance phase of the system. The modules are trained separately with compatible I/O data. The lexicon <ref> [31] </ref> stores the lexical and semantic representations and translates between them (figure 2). It is implemented as two feature maps [24; 25], lexical and semantic. Words whose lexical forms are similar, such as LINE and LIKE, are represented by nearby units in the lexical map.
Reference: [32] <author> R. Miikkulainen. </author> <title> Script recognition with hierarchical feature maps. </title> <journal> Connection Science, </journal> <volume> 2 </volume> <pages> 83-101, </pages> <year> 1990. </year>
Reference-contexts: The ID part has no intrinsic meaning in the system and can be assigned e.g. randomly; its task is only to distinguish the representation from all other instances of the same word prototype. 2.3 Episodic memory 2.3.1 Map hierarchy The episodic memory in DISCERN is a hierarchical feature map system <ref> [32] </ref> combined with the trace feature map mechanism [33]. The map hierarchy provides the organization for the memory, and the trace feature map technique implements the storage and retrieval of memory traces. The feature map hierarchy is a pyramid organized according to the hierarchical taxonomy of script-based stories (figure 5). <p> They typically take some part of the task and apply subsymbolic mechanisms to it. For example, mechanisms for processing causal sequences [16], role binding [10; 9], sequential activation and deactivation of multiple scripts [48], and learning the script taxonomy from examples <ref> [32] </ref> have been developed. Harris and Elman [21] trained a simple recurrent network to predict the next word 22 in a script-based story, and showed that role bindings take place not between two different occurrences of a variable, but between the variable and a global state. St.
Reference: [33] <author> R. Miikkulainen. </author> <title> Trace feature map: A model of episodic associative memory. </title> <journal> Biological Cybernetics, </journal> <volume> 66 </volume> <pages> 273-282, </pages> <year> 1992. </year>
Reference-contexts: the system and can be assigned e.g. randomly; its task is only to distinguish the representation from all other instances of the same word prototype. 2.3 Episodic memory 2.3.1 Map hierarchy The episodic memory in DISCERN is a hierarchical feature map system [32] combined with the trace feature map mechanism <ref> [33] </ref>. The map hierarchy provides the organization for the memory, and the trace feature map technique implements the storage and retrieval of memory traces. The feature map hierarchy is a pyramid organized according to the hierarchical taxonomy of script-based stories (figure 5).
Reference: [34] <author> R. Miikkulainen. </author> <title> Subsymbolic Natural Language Processing: An Integrated Model of Scripts, Lexicon, and Memory. </title> <publisher> MIT Press: </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: This paper concentrates on the types of reasoning that DISCERN performs in processing script-based stories. A brief introduction to the DISCERN model is first given (for a more detailed description see <ref> [34] </ref>), followed by a description of the training and testing methodology. Several specific examples of reasoning in DISCERN are then presented, including script-based inference in parsing, paraphrasing, and question answering, dealing with ambiguous, incomplete, and erroneous input, and memory confusions and forgetting. <p> DISCERN can provide a framework for future research in large modular neural network systems, and for research in connectionist language processing, episodic memory, lexicon, and semantic representation. Many issues related to these tasks have been finessed in DISCERN, and they call for further research (see <ref> [34] </ref> for a detailed discussion). For example, methods could be developed for processing more complex sentences. It might be possible to devise mechanisms and representations for sequential activation and deactivation of scripts, or even multiple simultaneously active scripts.
Reference: [35] <author> R. Miikkulainen and M. G. Dyer. </author> <title> A modular neural network architecture for sequential paraphrasing of script-based stories. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks (Washington, DC), </booktitle> <volume> volume II, </volume> <pages> pp. 49-56. </pages> <publisher> IEEE: </publisher> <address> Piscataway, NJ, </address> <year> 1989. </year>
Reference-contexts: It is very difficult to represent multiple fillers (e.g. the man and the boy), additional constituents, and recursive structures (see [10; 22; 38; 49] for possible approaches). Second, processing knowledge in subsymbolic models is based on statistical regularities, and they cannot handle deviations from the regularities very well <ref> [35; 51] </ref>. Exceptions are simply overridden. The network has no representation for all-or-none role bindings, and as a result it cannot process truly novel inputs according to a symbolic-like higher-level rule. The third problem, dynamic inferencing [57], is evident in trying to process questions in a new context.
Reference: [36] <author> R. Miikkulainen and M. G. Dyer. </author> <title> Natural language processing with modular neural networks and distributed lexicon. </title> <journal> Cognitive Science, </journal> <volume> 15 </volume> <pages> 343-399, </pages> <year> 1991. </year>
Reference-contexts: Each module performs a specific subtask, such as parsing a sentence or generating an answer to a question. All these modules have the same basic architecture. The FGREP mechanism (Forming Global Representations with Extended backPropagation, <ref> [36] </ref>) is based on a basic three-layer backward error propagation network, with the I/O representation patterns stored in an external lexicon (figure 3). The input and output layers of the network are divided into assemblies (i.e. 4 John.
Reference: [37] <author> J. B. Pollack. </author> <title> Cascaded back-propagation on dynamic connectionist networks. </title> <booktitle> In Proceedings of the Ninth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 391-404. </pages> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1987. </year>
Reference-contexts: It might be possible to implement the necessary monitoring, modulation, and decision-making tasks with trainable control networks. These modules would receive input from several pathways in the system, monitoring its state, and their output would gate the system pathways through multiplicative connections (such as those of <ref> [37; 42] </ref>).
Reference: [38] <author> J. B. Pollack. </author> <title> Recursive distributed representations. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 77-105, </pages> <year> 1990. </year>
Reference-contexts: Units cannot be created or moved around in the network, they can only function in the same exact configuration they were trained in. It is very difficult to represent multiple fillers (e.g. the man and the boy), additional constituents, and recursive structures (see <ref> [10; 22; 38; 49] </ref> for possible approaches). Second, processing knowledge in subsymbolic models is based on statistical regularities, and they cannot handle deviations from the regularities very well [35; 51]. Exceptions are simply overridden.
Reference: [39] <author> L. Postman. </author> <title> Transfer, interference and forgetting. </title> <editor> In J. W. Kling and L. A. Riggs, editors, </editor> <booktitle> Woodworth and Schlosberg's Experimental Psychology, </booktitle> <pages> pp. 1019-1132. </pages> <publisher> Holt, Rinehart and Winston: </publisher> <address> New York, third edition, </address> <year> 1971. </year>
Reference-contexts: If the memory capacity is exceeded, older traces will be selectively replaced by newer ones. Traces that are unique, that is, located in a sparse area of the map, are not affected, no matter how old they are. Similar effects are common in human long-term memory <ref> [2; 39] </ref>. 2.3.3 Storage and retrieval A story is represented in the episodic memory by the maximally responding units at the script, track, and role-binding levels. However, each unit on a role-binding map stands for a unique story, and a trace needs to be created only at the bottom level.
Reference: [40] <author> M. R. Quillian. </author> <title> Word concepts: A theory and simulation of some basic semantic capabilities. </title> <booktitle> Behavioral Science, </booktitle> <volume> 12 </volume> <pages> 410-430, </pages> <year> 1967. </year>
Reference-contexts: The types form semantic hierarchies, the instances inherit the properties of parent types and also accumulate specific properties of their own during processing. Whether implemented in a symbolic semantic network <ref> [40] </ref> or in a semantic network/subsymbolic neural network hybrid [53; 54; 55], in effect, there are two separate systems with a very complex interaction. One system performs reasoning based on semantic relations and the other one propagates the bindings.
Reference: [41] <author> J. F. Reeves. </author> <title> Computational Morality: A Process Model of Belief Conflict and Resolution for Story Understanding. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of California, </institution> <address> Los Angeles, </address> <year> 1991. </year> <note> Technical Report UCLA-AI-91-05. </note>
Reference-contexts: For example in story understanding, symbolic systems have been developed that analyze realistic stories in-depth, based on higher-level knowledge structures such as goals, plans, themes, affects, beliefs, argument structures, plots, and morals <ref> [1; 11; 41; 46] </ref>. Subsymbolic systems cannot yet model cognitive processes at this level.
Reference: [42] <author> D. E. Rumelhart, G. E. Hinton, and J. L. McClelland. </author> <title> A general framework for parallel distributed processing. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations, </booktitle> <pages> pp. 45-76. </pages> <publisher> MIT Press: </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: It might be possible to implement the necessary monitoring, modulation, and decision-making tasks with trainable control networks. These modules would receive input from several pathways in the system, monitoring its state, and their output would gate the system pathways through multiplicative connections (such as those of <ref> [37; 42] </ref>).
Reference: [43] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations, </booktitle> <pages> pp. 318-362. </pages> <publisher> MIT Press: </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The network learns the processing task by adapting the connection weights according to the standard on-line backpropagation procedure <ref> [43, pages 327-329] </ref>.
Reference: [44] <author> D. E. Rumelhart and D. A. Norman. Accretion, </author> <title> tuning and restructuring. </title> <editor> In J. W. Cotton and R. L. Klatzky, editors, </editor> <booktitle> Semantic Factors in Cognition, </booktitle> <pages> pp. 37-53. </pages> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1978. </year>
Reference-contexts: Specifically, this contradicts the intuitive notion of scripts. They should not be preset, fixed, 2 all-or-none representations, but instead should emerge automatically from the statistical regularities in the experience <ref> [44; 45] </ref>. A major motivation for DISCERN is to give a better account of these high-level cognitive phenomena in terms of the special properties of subsymbolic systems, such as learning from examples, automatic generalization and graceful degradation. The approach taken in DISCERN is that of integrated subsymbolic modeling.
Reference: [45] <author> D. E. Rumelhart, P. Smolensky, J. L. McClelland, and G. E. Hinton. </author> <title> Schemata and sequential thought processes in PDP models. </title> <editor> In J. L. McClelland and D. E. Rumelhart, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 2: Psychological and Biological Models, </booktitle> <pages> pp. 7-57. </pages> <publisher> MIT Press: </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Specifically, this contradicts the intuitive notion of scripts. They should not be preset, fixed, 2 all-or-none representations, but instead should emerge automatically from the statistical regularities in the experience <ref> [44; 45] </ref>. A major motivation for DISCERN is to give a better account of these high-level cognitive phenomena in terms of the special properties of subsymbolic systems, such as learning from examples, automatic generalization and graceful degradation. The approach taken in DISCERN is that of integrated subsymbolic modeling. <p> Every input is automatically matched to every correlation in parallel. There is no all-or-none instantiation of a particular knowledge structure. The strongest, most probable correlations will dominate, depending on how well they match the input, but all of them are simultaneously active at all times (see also <ref> [45] </ref>). The correlations vary in scope from cooccurring case-role fillers to long sequences of events, even to regularities at the goal/plan level [10; 28; 47]. Regularities that make up scripts can be particularly well captured by such correlations, making script-based inference a good domain for the subsymbolic approach.
Reference: [46] <author> R. C. Schank and R. P. Abelson. </author> <title> Scripts, Plans, Goals, and Understanding: An Inquiry into Human Knowledge Structures. </title> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1977. </year>
Reference-contexts: And of course, it is possible to recognize a situation where there is nothing appropriate in the memory. Understanding and retrieving stories about stereotypical event sequences is not a new task. Script theory <ref> [46] </ref> was developed to explain how knowledge about familiar everyday routines is used in story understanding. At the same time, symbolic computer models such as SAM [7] and FRUMP [8] were built that implemented the theory at various levels. <p> Inferences are based on handcrafted rules and representations of the scripts. Such systems cannot utilize the statistical properties of the data to enhance processing; they can only do what their creator explicitly programmed them to do. For example, symbolic expectations must be implemented as specific rules for specific situations <ref> [11; 46] </ref>. Generalization to previously unencountered inputs is possible only if there exists a rule that specifies how this is done. Representations of these rules and their application is often very complex. <p> The goal is to demonstrate understanding of multisentential connected text. In this sense, DISCERN aims at natural language processing at a different level than previous subsymbolic models. 5.2 Symbolic and subsymbolic schemas There is an important distinction between scripts (or more generally, schemas) in symbolic systems <ref> [7; 11; 46] </ref>, and scripts in subsymbolic systems such as DISCERN and the above models. In the symbolic approach, a script is stored in memory as a separate, exact knowledge structure, coded by the knowledge engineer. <p> For example in story understanding, symbolic systems have been developed that analyze realistic stories in-depth, based on higher-level knowledge structures such as goals, plans, themes, affects, beliefs, argument structures, plots, and morals <ref> [1; 11; 41; 46] </ref>. Subsymbolic systems cannot yet model cognitive processes at this level.
Reference: [47] <author> N. E. Sharkey. </author> <title> A PDP system for goal-plan decisions. </title> <editor> In R. Trappl, editor, </editor> <booktitle> Cybernetics and Systems '88: Proceedings of the Ninth European Meeting on Cybernetics and Systems Research, </booktitle> <pages> pp. 1031-1038. </pages> <publisher> Kluwer: </publisher> <address> Dordrecht, Boston, </address> <year> 1988. </year> <month> 29 </month>
Reference-contexts: The strongest, most probable correlations will dominate, depending on how well they match the input, but all of them are simultaneously active at all times (see also [45]). The correlations vary in scope from cooccurring case-role fillers to long sequences of events, even to regularities at the goal/plan level <ref> [10; 28; 47] </ref>. Regularities that make up scripts can be particularly well captured by such correlations, making script-based inference a good domain for the subsymbolic approach. Generalization and graceful degradation give rise to inferencing that is intuitive, immediate, and occurs without conscious control, similar to script-based inference in humans.
Reference: [48] <author> N. E. Sharkey. </author> <title> A PDP learning approach to natural language understanding. </title> <editor> In I. Alexander, editor, </editor> <booktitle> Neural Computing Architectures: The Design of Brainlike Machines, </booktitle> <pages> pp. 92-116. </pages> <publisher> MIT Press: </publisher> <address> Cam-bridge, MA, </address> <year> 1989. </year>
Reference-contexts: There are a few models that address issues in script-based understanding. They typically take some part of the task and apply subsymbolic mechanisms to it. For example, mechanisms for processing causal sequences [16], role binding [10; 9], sequential activation and deactivation of multiple scripts <ref> [48] </ref>, and learning the script taxonomy from examples [32] have been developed.
Reference: [49] <author> P. Smolensky. </author> <title> Tensor product variable binding and the representation of symbolic structures in connectionist systems. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 159-216, </pages> <year> 1990. </year>
Reference-contexts: Units cannot be created or moved around in the network, they can only function in the same exact configuration they were trained in. It is very difficult to represent multiple fillers (e.g. the man and the boy), additional constituents, and recursive structures (see <ref> [10; 22; 38; 49] </ref> for possible approaches). Second, processing knowledge in subsymbolic models is based on statistical regularities, and they cannot handle deviations from the regularities very well [35; 51]. Exceptions are simply overridden.
Reference: [50] <author> M. F. St. John. </author> <title> The Story Gestalt: Text Comprehension by Cue-Based Constraint Satisfaction. </title> <type> PhD thesis, </type> <institution> Department of Psychology, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1990. </year>
Reference-contexts: Harris and Elman [21] trained a simple recurrent network to predict the next word 22 in a script-based story, and showed that role bindings take place not between two different occurrences of a variable, but between the variable and a global state. St. John's <ref> [50; 51] </ref> story gestalt model demonstrated how script-based regularities in the input data implement soft constraints that are brought together to form an interpretation of the text. Such models illustrate various aspects of learning, representing, and applying schematic knowledge, but they are not self-contained story-processing systems.
Reference: [51] <author> M. F. St. John. </author> <title> The story gestalt: A model of knowledge-intensive processes in text comprehension. </title> <journal> Cognitive Science, </journal> <volume> 16 </volume> <pages> 271-306, </pages> <year> 1992. </year>
Reference-contexts: Harris and Elman [21] trained a simple recurrent network to predict the next word 22 in a script-based story, and showed that role bindings take place not between two different occurrences of a variable, but between the variable and a global state. St. John's <ref> [50; 51] </ref> story gestalt model demonstrated how script-based regularities in the input data implement soft constraints that are brought together to form an interpretation of the text. Such models illustrate various aspects of learning, representing, and applying schematic knowledge, but they are not self-contained story-processing systems. <p> It is very difficult to represent multiple fillers (e.g. the man and the boy), additional constituents, and recursive structures (see [10; 22; 38; 49] for possible approaches). Second, processing knowledge in subsymbolic models is based on statistical regularities, and they cannot handle deviations from the regularities very well <ref> [35; 51] </ref>. Exceptions are simply overridden. The network has no representation for all-or-none role bindings, and as a result it cannot process truly novel inputs according to a symbolic-like higher-level rule. The third problem, dynamic inferencing [57], is evident in trying to process questions in a new context.
Reference: [52] <author> W. H. Sumby. </author> <title> Word frequency and serial position effects. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 1 </volume> <pages> 443-450, </pages> <year> 1963. </year>
Reference-contexts: The cue pattern is closest to the most common story representation, and if an infrequent story is to be recalled, more details need to be specified in the question. Similar frequency effect has been observed in human free recall <ref> [19; 23; 52] </ref>. The cue pattern is given to the episodic memory, which classifies it as an instance of the restaurant 14 script (0,0) and fancy-restaurant track (0,0).
Reference: [53] <author> R. A. Sumida. </author> <title> Dynamic inferencing in parallel distributed semantic networks. </title> <booktitle> In Proceedings of the 13th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 913-917. </pages> <publisher> Erlbaum: </publisher> <address> Hillsdale, NJ, </address> <year> 1991. </year>
Reference-contexts: The types form semantic hierarchies, the instances inherit the properties of parent types and also accumulate specific properties of their own during processing. Whether implemented in a symbolic semantic network [40] or in a semantic network/subsymbolic neural network hybrid <ref> [53; 54; 55] </ref>, in effect, there are two separate systems with a very complex interaction. One system performs reasoning based on semantic relations and the other one propagates the bindings.
Reference: [54] <author> R. A. Sumida and M. G. Dyer. </author> <title> Storing and generalizing multiple instances while maintaining knowledge-level parallelism. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1426-1431. </pages> <publisher> Morgan Kaufmann: </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: The types form semantic hierarchies, the instances inherit the properties of parent types and also accumulate specific properties of their own during processing. Whether implemented in a symbolic semantic network [40] or in a semantic network/subsymbolic neural network hybrid <ref> [53; 54; 55] </ref>, in effect, there are two separate systems with a very complex interaction. One system performs reasoning based on semantic relations and the other one propagates the bindings.
Reference: [55] <author> R. A. Sumida and M. G. Dyer. </author> <title> Propagation filters in PDS networks for sequencing and ambiguity resolution. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pp. 233-240. </pages> <publisher> Morgan Kaufmann: </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: The types form semantic hierarchies, the instances inherit the properties of parent types and also accumulate specific properties of their own during processing. Whether implemented in a symbolic semantic network [40] or in a semantic network/subsymbolic neural network hybrid <ref> [53; 54; 55] </ref>, in effect, there are two separate systems with a very complex interaction. One system performs reasoning based on semantic relations and the other one propagates the bindings.
Reference: [56] <author> P. W. Thorndyke and B. Hayes-Roth. </author> <title> The use of schemata in the acquisition and transfer of knowledge. </title> <journal> Cognitive Psychology, </journal> <volume> 11 </volume> <pages> 82-106, </pages> <year> 1979. </year>
Reference-contexts: In this case, a representation that is a combination of the stored traces is retrieved. In other words, DISCERN remembers several distinct features of similar stories, but cannot keep the stories separate. Similar behavior has been observed experimentally in human memory <ref> [3; 56] </ref>. 5 Discussion DISCERN serves to illustrate and focus several important issues in subsymbolic natural language processing, including the nature of schema representations and intuitive inference, the need for type/token information, and problems in generalizing into novel situations.
Reference: [57] <author> D. S. Touretzky. </author> <title> Connectionism and compositional semantics. </title> <editor> In J. A. Barnden and J. B. Pollack, editors, </editor> <title> High-Level Connectionist Models, volume 1 of Advances in Connectionist and Neural Computation Theory, Barnden, </title> <editor> J. A., </editor> <booktitle> series editor, </booktitle> <pages> pp. 17-31. </pages> <publisher> Ablex: </publisher> <address> Norwood, NJ, </address> <year> 1991. </year> <month> 30 </month>
Reference-contexts: Large amounts of information, which may be incomplete or even conflicting, are simultaneously brought together to produce the most likely answer. Neural network systems fit well into modeling intuitive inference (see also <ref> [22; 57] </ref>). The network extracts statistical knowledge from the input data, and these statistics are brought together to generate the inference. For example, the quality of food in the restaurant story is inferred from the whole story, not just by looking at some part and applying a specific rule. <p> Exceptions are simply overridden. The network has no representation for all-or-none role bindings, and as a result it cannot process truly novel inputs according to a symbolic-like higher-level rule. The third problem, dynamic inferencing <ref> [57] </ref>, is evident in trying to process questions in a new context. If the cue former and answer producer have seen, for example, a who question only in the context of restaurant stories, they would not be able to make sense out it in a shopping context.
References-found: 57

