URL: http://www.csc.calpoly.edu/~tpederse/tr-text-mining.ps.gz
Refering-URL: http://www.csc.calpoly.edu/~tpederse/pubs.html
Root-URL: http://www.csc.calpoly.edu
Email: fpedersen,rbruceg@seas.smu.edu  
Title: Unsupervised Text Mining  
Author: Ted Pedersen Rebecca Bruce 
Date: June 1997  
Address: Dallas, TX 75275-0122 USA  
Affiliation: Department of Computer Science and Engineering Southern Methodist University  
Abstract: TECHNICAL REPORT 97-CSE-9 Abstract We describe the results of performing text mining on a challenging problem in natural language processing, word sense disambiguation. We compare two methods of unsupervised learning, Ward's minimum-variance clustering and the EM algorithm, that distinguish the meaning of an ambiguous word based only on features that can be automatically identified in text. This is a significant advantage over most previous approaches which require a training sample where the meanings of ambiguous words have been manually disambiguated. The creation of sense tagged text sufficient to serve as a training sample is expensive and time consuming and is yet another example of the knowledge acquisition bottleneck. We present experimental results showing the application of each of these algorithms to the disambiguation of three nouns using five different feature sets. We find that these methods can distinguish two senses of bill with accuracy of up to 82 percent, three senses of interest with accuracy up to 69 percent, and three senses of line with accuracy up to 43 percent. These are improvments of 32, 36, and 10 percent over the lower bounds, respectively. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Baum. </author> <title> An inequality and associated maximization technique in statistical estimation for probabilistic functions of a Markov process. </title> <editor> In O. Shisha, editor, Inequalities, </editor> <volume> volume 3, </volume> <pages> pages 1-8. </pages> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1972. </year>
Reference-contexts: The results presented are preliminary but show an accuracy percentage in the mid-nineties when applied to Dixon, a name found to be quite ambiguous. It should be noted that the EM algorithm relates to a large body of work in speech processing. The forward-backward (also known as Baum-Welch) algorithm <ref> [1] </ref> is a specialized form of the EM algorithm that assumes the underlying parametric model is a hidden Markov model. The forward-backward algorithm has been used extensively in speech recognition (e.g. [17], [15]), [13]). 7 7 Conclusions These experiments provide evidence that text can be disambiguated using unsupervised techniques.
Reference: [2] <author> E. Black. </author> <title> An experiment in computational discrimination of English word senses. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 32(2) </volume> <pages> 185-194, </pages> <year> 1988. </year>
Reference-contexts: The ability to automatically annotate text with sense information can improve document classification (e.g., [33], [32]) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., <ref> [2] </ref>, [35], [36], [16], [3], [21], [22], [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create.
Reference: [3] <author> R. Bruce and J. Wiebe. </author> <title> Word-sense disambiguation using decomposable models. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 139-146, </pages> <year> 1994. </year>
Reference-contexts: The ability to automatically annotate text with sense information can improve document classification (e.g., [33], [32]) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], [16], <ref> [3] </ref>, [21], [22], [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create. <p> Each sentence containing the ambiguous word is reduced to a vector of features (i.e., an observation) and the corpus of text under study is reduced to a matrix of observations. 2.1.1 Feature Sets A and B Feature set A has been used in a variety of supervised learning experiments (e.g., <ref> [3] </ref>, [22], [23]). A sentence with an ambiguous word is represented by a feature set composed of three types of contextual features: one morphological feature, four part-of-speech (POS) features, and three collocation features. The morphological feature indicates if the ambiguous noun is plural or not.
Reference: [4] <author> R. Bruce, J. Wiebe, and T. Pedersen. </author> <title> The measure of a model. </title> <booktitle> In Proceedings of the Conference on Empirical Methods in Natural Language Processing, </booktitle> <pages> pages 101-112, </pages> <year> 1996. </year>
Reference-contexts: Each extracted sentence is tagged with a single sense defined in the Longman Dictionary of Contemporary English (LDOCE) [26]. This data is described in more detail in <ref> [4] </ref>. The line data comes from both the ACL/DCI WSJ corpus and the American Printing House for the Blind corpus. Each extracted sentence is tagged with a single sense of line defined in WordNet [20]. This data is described in more detail in [16].
Reference: [5] <author> Y. Choueka and S. Lusignan. </author> <title> Disambiguation by short contexts. </title> <journal> Computers and the Humanities, </journal> <volume> 19 </volume> <pages> 147-157, </pages> <year> 1985. </year>
Reference-contexts: fi 2 3 fi 2 fi 2 = 15; 000 possible values. 2.1.2 Feature Sets C, D, and E It has been reported that human beings disambiguate word senses based on the words that occur two words to the left and two words to the right of the ambiguous word <ref> [5] </ref>. Feature sets C, D and E are based on this finding in that they consist only of four positional collocation features. The values of these features are the words that occur one and two positions to the right and left of the ambiguous word.
Reference: [6] <author> A. Dempster, N. Laird, and D. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 39 </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: Rather than assuming the availability of sense-tagged text, it seems more reasonable to develop unsupervised approaches that do not have such costly requirements. We discuss two unsupervised learning algorithms, Ward's minimum-variance method [34] and the EM algorithm <ref> [6] </ref>, that can distinguish among the known senses of an ambiguous word without the aid of disambiguated examples. The EM algorithm produces maximum likelihood estimates of the parameters of a parametric probabilistic model. <p> Also, the relative success of Ward's method indicates that the mixture of normals assumption holds. However, further experiments will be carried out to verify this assumption. 4 EM Algorithm The expectation maximization algorithm <ref> [6] </ref>, commonly known as the EM algorithm, estimates the values of model parameters when data is missing or unknown. In this work, the sense of the ambiguous word is represented by a feature whose values are missing from the data. <p> The EM algorithm is an iterative estimation procedure in which the problem is recast to make use of complete data estimation techniques (i.e., techniques that can be used when there are no missing values). At the heart of the EM Algorithm lies the Q-function, defined in <ref> [6] </ref>.
Reference: [7] <author> R. Duda and P. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1973. </year>
Reference-contexts: We also assume that we know the parametric form of the model that best represents the data. For these experiments we assume that the model form is the Naive Bayes <ref> [7] </ref>. This is a model in which all contextual features are conditionally independent given the value of the classification feature (i.e., the sense of the ambiguous word, represented as S).
Reference: [8] <author> O. Etzioni. </author> <title> The World-Wide Web: </title> <journal> Quagmire or gold mine? Communications of the ACM, </journal> <volume> 39(11) </volume> <pages> 65-68, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: However, a text mining system searching for knowledge about bird anatomy might erroneously select this sentence unless bill is disambiguated. The ability to automatically annotate text with sense information can improve document classification (e.g., [33], [32]) and smooth the path for Web mining applications such as those described in <ref> [8] </ref>. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], [16], [3], [21], [22], [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm.
Reference: [9] <author> W. Gale, K. Church, and D. Yarowsky. </author> <title> A method for disambiguating word senses in a large corpus. </title> <journal> Computers and the Humanities, </journal> <volume> 26 </volume> <pages> 415-439, </pages> <year> 1992. </year>
Reference-contexts: We make this assumption because a number of researchers have reported high accuracy when applying the Naive Bayes model to supervised word-sense disambiguation (e.g. <ref> [9] </ref>, [16], [21],[23]). The EM algorithm is an iterative estimation procedure in which the problem is recast to make use of complete data estimation techniques (i.e., techniques that can be used when there are no missing values). At the heart of the EM Algorithm lies the Q-function, defined in [6].
Reference: [10] <author> W. Gale, K. Church, and D. Yarowsky. </author> <title> Discrimination decisions for 100,000 dimensional spaces. </title> <journal> Journal of Operations Research, </journal> <volume> 55 </volume> <pages> 323-344, </pages> <year> 1995. </year>
Reference-contexts: The only previous application of the EM algorithm to word-sense disambiguation is described in <ref> [10] </ref>. There the EM algorithm is used as part of a supervised learning algorithm to distinguish city names from people's names. A narrow window of context, one or two words to either side, was found to perform better than wider windows.
Reference: [11] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference-contexts: If the likelihood function is very irregular the EM algorithm may converge to a local maximum and not find the true maximum of the likelihood function. In this case the alternative is to use the more computationally expensive method of Gibbs Sampling <ref> [11] </ref> to find the complete distribution of either the likelihood or posterior probability function.
Reference: [12] <author> M. Hearst. </author> <title> Noun homograph disambiguation using local context in large text corpora. </title> <booktitle> In Proceedings of the 7th Annual Conference of the UW Centre for the New OED and Text Research: Using Corpora, </booktitle> <address> Oxford, </address> <year> 1991. </year> <month> 8 </month>
Reference-contexts: An early example of such an approach is described in <ref> [12] </ref>. A supervised learning algorithm is trained with a small amount of manually sense-tagged text and applied to a held out test set. Those examples in the test set that are most confidently disambiguated are added to the training sample. A more recent bootstrapping approach is described in [37].
Reference: [13] <author> F. Jelinek. </author> <title> Self-organized language modeling for speech recognition. </title> <editor> In Waibel and Lee, editors, </editor> <booktitle> Readings in Speech Recognition. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: The forward-backward (also known as Baum-Welch) algorithm [1] is a specialized form of the EM algorithm that assumes the underlying parametric model is a hidden Markov model. The forward-backward algorithm has been used extensively in speech recognition (e.g. [17], [15]), <ref> [13] </ref>). 7 7 Conclusions These experiments provide evidence that text can be disambiguated using unsupervised techniques. We also find that the relative success of Ward's minimum variance method as compared to the EM algorithm varies with the feature set.
Reference: [14] <author> G Kiss. </author> <title> Grammatical word classes: A learning process and its simulation. </title> <journal> Psychology of Learning and Motivation, </journal> <volume> 7 </volume> <pages> 1-41, </pages> <year> 1973. </year>
Reference-contexts: To take an example from our data, the collocations telephone line and production line make such a distinction. Clustering has previously been applied in natural language processing as an exploratory method for inducing syntactic or semantically related groupings of words (e.g., [30], <ref> [14] </ref>, [29], [25], [27]). An early application of clustering to word-sense disambiguation is described in [31]. There words are represented in terms of the co-occurrence statistics of four letter sequences.
Reference: [15] <author> J. Kupiec. </author> <title> Robust part-of-speech tagging using a hidden Markov model. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 6 </volume> <pages> 225-243, </pages> <year> 1992. </year>
Reference-contexts: The forward-backward (also known as Baum-Welch) algorithm [1] is a specialized form of the EM algorithm that assumes the underlying parametric model is a hidden Markov model. The forward-backward algorithm has been used extensively in speech recognition (e.g. [17], <ref> [15] </ref>), [13]). 7 7 Conclusions These experiments provide evidence that text can be disambiguated using unsupervised techniques. We also find that the relative success of Ward's minimum variance method as compared to the EM algorithm varies with the feature set.
Reference: [16] <author> C. Leacock, G. Towell, and E. Voorhees. </author> <title> Corpus-based statistical sense resolution. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology, </booktitle> <year> 1993. </year>
Reference-contexts: The ability to automatically annotate text with sense information can improve document classification (e.g., [33], [32]) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], <ref> [16] </ref>, [3], [21], [22], [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create. <p> The line data comes from both the ACL/DCI WSJ corpus and the American Printing House for the Blind corpus. Each extracted sentence is tagged with a single sense of line defined in WordNet [20]. This data is described in more detail in <ref> [16] </ref>. In these experiments we distinguish among three senses of interest and line and between two senses of bill. Those senses are shown in Figure 1 along with an example and the number of instances of each sense in the corpus. For each word, we create three test sets. <p> We make this assumption because a number of researchers have reported high accuracy when applying the Naive Bayes model to supervised word-sense disambiguation (e.g. [9], <ref> [16] </ref>, [21],[23]). The EM algorithm is an iterative estimation procedure in which the problem is recast to make use of complete data estimation techniques (i.e., techniques that can be used when there are no missing values). At the heart of the EM Algorithm lies the Q-function, defined in [6]. <p> The average accuracy for line is somewhat disappointing. The improvement over the lower bound is at most 10 percent and there is no clear advantage associated with any particular combination of learning method and feature set. The complexity of disambiguating line is discussed in <ref> [16] </ref>. They point out that the text sense of line is very difficult to distinguish because it is not tightly defined and it is not associated with a particular topic, a line of text can be about anything.
Reference: [17] <author> S. Levinson, L. Rabiner, and M. Sondhi. </author> <title> An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition. </title> <journal> Bell System Technical Journal, </journal> <volume> 62 </volume> <pages> 1035-1074, </pages> <year> 1983. </year>
Reference-contexts: The forward-backward (also known as Baum-Welch) algorithm [1] is a specialized form of the EM algorithm that assumes the underlying parametric model is a hidden Markov model. The forward-backward algorithm has been used extensively in speech recognition (e.g. <ref> [17] </ref>, [15]), [13]). 7 7 Conclusions These experiments provide evidence that text can be disambiguated using unsupervised techniques. We also find that the relative success of Ward's minimum variance method as compared to the EM algorithm varies with the feature set.
Reference: [18] <author> X. Li, S. Szpakowicz, and S. Matwin. </author> <title> A WordNet-based algorithm for word sense disambiguation. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Other clustering approaches to word-sense disambiguation have been based on measures of semantic distance defined with respect to a semantic network such as WordNet. Measures of semantic distance are based on the path length between concepts in a network and are used to group semantically similar concepts (e.g. <ref> [18] </ref>). [28] provides an information theoretic definition of semantic distance based on WordNet. The only previous application of the EM algorithm to word-sense disambiguation is described in [10]. There the EM algorithm is used as part of a supervised learning algorithm to distinguish city names from people's names.
Reference: [19] <author> M. Marcus, B. Santorini, and M. Marcinkiewicz. </author> <title> Building a large annotated corpus of English: The Penn Treebank. </title> <journal> Computational Linguistics, </journal> <volume> 19(2) </volume> <pages> 313-330, </pages> <year> 1993. </year>
Reference-contexts: The morphological feature indicates if the ambiguous noun is plural or not. The POS features have one of 25 possible POS tags, derived from the first letter of the tags in the ACL/DCI Wall Street Journal corpus <ref> [19] </ref>. There are four features representing the part-of-speech of the two words immediately preceding and following the ambiguous word. The three binary collocation-specific features indicate the presence or 1 absence of a particular word in the same sentence as the ambiguous word.
Reference: [20] <author> G. Miller. </author> <title> WordNet: A lexical database. </title> <journal> Communications of the ACM, </journal> <volume> 38(11) </volume> <pages> 39-41, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: This data is described in more detail in [4]. The line data comes from both the ACL/DCI WSJ corpus and the American Printing House for the Blind corpus. Each extracted sentence is tagged with a single sense of line defined in WordNet <ref> [20] </ref>. This data is described in more detail in [16]. In these experiments we distinguish among three senses of interest and line and between two senses of bill. Those senses are shown in Figure 1 along with an example and the number of instances of each sense in the corpus.
Reference: [21] <author> R. Mooney. </author> <title> Comparative experiments on disambiguating word senses: An illustration of the role of bias in machine learning. </title> <booktitle> In Proceedings of the Conference on Empirical Methods in Natural Language Processing, </booktitle> <year> 1996. </year>
Reference-contexts: The ability to automatically annotate text with sense information can improve document classification (e.g., [33], [32]) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], [16], [3], <ref> [21] </ref>, [22], [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create.
Reference: [22] <author> H.T. Ng and H.B. Lee. </author> <title> Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Society for Computational Linguistics, </booktitle> <pages> pages 40-47, </pages> <year> 1996. </year>
Reference-contexts: Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], [16], [3], [21], <ref> [22] </ref>, [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create. <p> sentence containing the ambiguous word is reduced to a vector of features (i.e., an observation) and the corpus of text under study is reduced to a matrix of observations. 2.1.1 Feature Sets A and B Feature set A has been used in a variety of supervised learning experiments (e.g., [3], <ref> [22] </ref>, [23]). A sentence with an ambiguous word is represented by a feature set composed of three types of contextual features: one morphological feature, four part-of-speech (POS) features, and three collocation features. The morphological feature indicates if the ambiguous noun is plural or not.
Reference: [23] <author> T. Pedersen, R. Bruce, and J. Wiebe. </author> <title> Sequential model selection for word sense disambiguation. </title> <booktitle> In Proceedings of the Fifth Conference on Applied Natural Language Processing, </booktitle> <address> Washington, DC, </address> <year> 1997. </year>
Reference-contexts: Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], [16], [3], [21], [22], <ref> [23] </ref>). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create. <p> containing the ambiguous word is reduced to a vector of features (i.e., an observation) and the corpus of text under study is reduced to a matrix of observations. 2.1.1 Feature Sets A and B Feature set A has been used in a variety of supervised learning experiments (e.g., [3], [22], <ref> [23] </ref>). A sentence with an ambiguous word is represented by a feature set composed of three types of contextual features: one morphological feature, four part-of-speech (POS) features, and three collocation features. The morphological feature indicates if the ambiguous noun is plural or not.
Reference: [24] <author> T. Pedersen, M. Kayaalp, and R. Bruce. </author> <title> Significant lexical relationships. </title> <booktitle> In Proceedings of the 13th National Conference on Artificial Intelligence, </booktitle> <pages> pages 455-460, </pages> <year> 1996. </year>
Reference-contexts: An assumption that is implicit in Ward's method is that the data comes from a mixture of normal distributions. While NLP data is typically not well characterized by a normal distribution (see, e.g. [38], <ref> [24] </ref>), our findings indicate that when the data is represented in terms of Hamming distances, it can be adequately characterized by the normal distribution. Also, the relative success of Ward's method indicates that the mixture of normals assumption holds.
Reference: [25] <author> F. Pereira, N. Tishby, and L. Lee. </author> <title> Distributional clustering of English words. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 183-190, </pages> <address> Columbus, OH, </address> <year> 1993. </year>
Reference-contexts: To take an example from our data, the collocations telephone line and production line make such a distinction. Clustering has previously been applied in natural language processing as an exploratory method for inducing syntactic or semantically related groupings of words (e.g., [30], [14], [29], <ref> [25] </ref>, [27]). An early application of clustering to word-sense disambiguation is described in [31]. There words are represented in terms of the co-occurrence statistics of four letter sequences.
Reference: [26] <author> P. Procter, </author> <title> editor. Longman Dictionary of Contemporary English. </title> <publisher> Longman Group Ltd., Essex, </publisher> <address> UK, </address> <year> 1978. </year>
Reference-contexts: Each extracted sentence is tagged with a single sense defined in the Longman Dictionary of Contemporary English (LDOCE) <ref> [26] </ref>. This data is described in more detail in [4]. The line data comes from both the ACL/DCI WSJ corpus and the American Printing House for the Blind corpus. Each extracted sentence is tagged with a single sense of line defined in WordNet [20].
Reference: [27] <author> P. </author> <title> Resnik. Disambiguating noun groupings with respect to WordNet senses. </title> <booktitle> In Proceedings of the Third Workshop on Very Large Corpora, </booktitle> <publisher> MIT, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: To take an example from our data, the collocations telephone line and production line make such a distinction. Clustering has previously been applied in natural language processing as an exploratory method for inducing syntactic or semantically related groupings of words (e.g., [30], [14], [29], [25], <ref> [27] </ref>). An early application of clustering to word-sense disambiguation is described in [31]. There words are represented in terms of the co-occurrence statistics of four letter sequences.
Reference: [28] <author> P. </author> <title> Resnik. Using information content to evaluate semantic similarity in a taxonomy. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Other clustering approaches to word-sense disambiguation have been based on measures of semantic distance defined with respect to a semantic network such as WordNet. Measures of semantic distance are based on the path length between concepts in a network and are used to group semantically similar concepts (e.g. [18]). <ref> [28] </ref> provides an information theoretic definition of semantic distance based on WordNet. The only previous application of the EM algorithm to word-sense disambiguation is described in [10]. There the EM algorithm is used as part of a supervised learning algorithm to distinguish city names from people's names.
Reference: [29] <author> H. Ritter and T. Kohonen. </author> <title> Self-organizing semantic maps. </title> <journal> Biological Cybernetics, </journal> <volume> 62 </volume> <pages> 241-254, </pages> <year> 1989. </year> <month> 9 </month>
Reference-contexts: To take an example from our data, the collocations telephone line and production line make such a distinction. Clustering has previously been applied in natural language processing as an exploratory method for inducing syntactic or semantically related groupings of words (e.g., [30], [14], <ref> [29] </ref>, [25], [27]). An early application of clustering to word-sense disambiguation is described in [31]. There words are represented in terms of the co-occurrence statistics of four letter sequences.
Reference: [30] <author> A. Rosenfeld, H. Huang, and V. Schneider. </author> <title> An application of cluster detection to text and picture processing. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 15 </volume> <pages> 672-681, </pages> <year> 1969. </year>
Reference-contexts: To take an example from our data, the collocations telephone line and production line make such a distinction. Clustering has previously been applied in natural language processing as an exploratory method for inducing syntactic or semantically related groupings of words (e.g., <ref> [30] </ref>, [14], [29], [25], [27]). An early application of clustering to word-sense disambiguation is described in [31]. There words are represented in terms of the co-occurrence statistics of four letter sequences.
Reference: [31] <author> H. Schutze. </author> <title> Dimensions of meaning. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pages 787-796, </pages> <address> Minneapo-lis, MN, </address> <year> 1992. </year>
Reference-contexts: Clustering has previously been applied in natural language processing as an exploratory method for inducing syntactic or semantically related groupings of words (e.g., [30], [14], [29], [25], [27]). An early application of clustering to word-sense disambiguation is described in <ref> [31] </ref>. There words are represented in terms of the co-occurrence statistics of four letter sequences. <p> The set of context vectors for the word to be disambiguated are then clustered, and the clusters are manually sense-tagged. The features used in <ref> [31] </ref> are complex and difficult to interpret and it isn't clear that this complexity is required. [37] compares his method to [31] and shows that for four words the former performs significantly better in distinguishing between two senses. <p> The set of context vectors for the word to be disambiguated are then clustered, and the clusters are manually sense-tagged. The features used in <ref> [31] </ref> are complex and difficult to interpret and it isn't clear that this complexity is required. [37] compares his method to [31] and shows that for four words the former performs significantly better in distinguishing between two senses. Other clustering approaches to word-sense disambiguation have been based on measures of semantic distance defined with respect to a semantic network such as WordNet.
Reference: [32] <author> H. Schutze and J. Pedersen. </author> <title> Information retrieval based on word senses. </title> <booktitle> In Proceedings of the 4th Annual Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pages 161-175, </pages> <address> Las Vegas, NV, </address> <year> 1995. </year>
Reference-contexts: However, a text mining system searching for knowledge about bird anatomy might erroneously select this sentence unless bill is disambiguated. The ability to automatically annotate text with sense information can improve document classification (e.g., [33], <ref> [32] </ref>) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], [16], [3], [21], [22], [23]).
Reference: [33] <author> E. Voorhees. </author> <title> Using WordNet to disambiguate word senses for text retrieval. </title> <booktitle> In Proceedings of SIGIR '93, </booktitle> <pages> pages 171-180, </pages> <address> Pittsburgh, PA, </address> <year> 1993. </year>
Reference-contexts: However, a text mining system searching for knowledge about bird anatomy might erroneously select this sentence unless bill is disambiguated. The ability to automatically annotate text with sense information can improve document classification (e.g., <ref> [33] </ref>, [32]) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], [36], [16], [3], [21], [22], [23]).
Reference: [34] <author> J. Ward. </author> <title> Hierarchical grouping to optimize an objective function. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58 </volume> <pages> 236-244, </pages> <year> 1963. </year>
Reference-contexts: Such data exists only in very small quantities and is very expensive to create. Rather than assuming the availability of sense-tagged text, it seems more reasonable to develop unsupervised approaches that do not have such costly requirements. We discuss two unsupervised learning algorithms, Ward's minimum-variance method <ref> [34] </ref> and the EM algorithm [6], that can distinguish among the known senses of an ambiguous word without the aid of disambiguated examples. The EM algorithm produces maximum likelihood estimates of the parameters of a parametric probabilistic model.
Reference: [35] <author> D. Yarowsky. </author> <title> Word-sense disambiguation using statistical models of Roget's categories trained on large corpora. </title> <booktitle> In Proceedings of the 14th International Conference on Computational Linguistics (COLING-92), </booktitle> <pages> pages 454-460, </pages> <address> Nantes, France, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The ability to automatically annotate text with sense information can improve document classification (e.g., [33], [32]) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], <ref> [35] </ref>, [36], [16], [3], [21], [22], [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create.
Reference: [36] <author> D. Yarowsky. </author> <title> One sense per collocation. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology, </booktitle> <pages> pages 266-271, </pages> <year> 1993. </year>
Reference-contexts: The ability to automatically annotate text with sense information can improve document classification (e.g., [33], [32]) and smooth the path for Web mining applications such as those described in [8]. Word sense disambiguation has commonly been cast as a problem in supervised learning (e.g., [2], [35], <ref> [36] </ref>, [16], [3], [21], [22], [23]). However, these methods require text where ambiguous words have been manually tagged with sense information to train the learning algorithm. Such data exists only in very small quantities and is very expensive to create.
Reference: [37] <author> D. Yarowsky. </author> <title> Unsupervised word sense disambiguation rivaling supervised methods. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 189-196, </pages> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: A supervised learning algorithm is trained with a small amount of manually sense-tagged text and applied to a held out test set. Those examples in the test set that are most confidently disambiguated are added to the training sample. A more recent bootstrapping approach is described in <ref> [37] </ref>. This algorithm requires a small number of training examples to serve as a seed. This approach relies upon the identification of collocations that uniquely distinguish between senses. To take an example from our data, the collocations telephone line and production line make such a distinction. <p> The set of context vectors for the word to be disambiguated are then clustered, and the clusters are manually sense-tagged. The features used in [31] are complex and difficult to interpret and it isn't clear that this complexity is required. <ref> [37] </ref> compares his method to [31] and shows that for four words the former performs significantly better in distinguishing between two senses. Other clustering approaches to word-sense disambiguation have been based on measures of semantic distance defined with respect to a semantic network such as WordNet.
Reference: [38] <author> G. Zipf. </author> <title> The Psycho-Biology of Language. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, MA, </address> <year> 1935. </year> <month> 10 </month>
Reference-contexts: An assumption that is implicit in Ward's method is that the data comes from a mixture of normal distributions. While NLP data is typically not well characterized by a normal distribution (see, e.g. <ref> [38] </ref>, [24]), our findings indicate that when the data is represented in terms of Hamming distances, it can be adequately characterized by the normal distribution. Also, the relative success of Ward's method indicates that the mixture of normals assumption holds.
References-found: 38

