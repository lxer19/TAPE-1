URL: http://robotics.eecs.berkeley.edu/~janka/eccv98.ps.gz
Refering-URL: http://robotics.eecs.berkeley.edu/~janka/vision_control_publ.html
Root-URL: 
Title: Motion Recovery From Image Sequences: Discrete Viewpoint vs. Differential Viewpoint unifying theory of the motion
Author: Yi Ma Jana Kosecka Shankar Sastry 
Keyword: optical flow, epipolar constraint, motion estimation.  
Note: The presented  cameras.  Research is supported by ARO under the MURI grant DAAH04-96-1-0341, "An Integrated Approach to  
Address: Berkeley, CA 94720-1774  Address: 211-109 Cory Hall, EECS, UC Berkeley, Berkeley, CA 94720-1772, USA. Tel: (USA) 510-643-2383. Address: 211- 98 Cory Hall, EECS, UC Berkeley, Berkeley, CA 94720-1772, USA. Tel: (USA) 510-643-5806. Address: 269M Cory Hall, EECS, UC Berkeley, Berkeley, CA 94720-1772, USA. Tel: (USA) 510-642-1857.  
Affiliation: Electronics Research Laboratory University of California at Berkeley  Intelligent Systems".  
Email: fmayi, janka, sastryg@robotics.eecs.berkeley.edu  
Date: November 3, 1997  
Abstract: The aim of this paper is to explore intrinsic geometric methods of recovering the three dimensional motion of a moving camera from a sequence of images. Generic similarities between the discrete approach and the differential approach are revealed through a parallel development of their analogous motion estimation theories. We begin with a brief review of the (discrete) essential matrix approach, showing how to recover the 3D displacement from image correspondences. The space of normalized essential matrices is characterized geometrically: the unit tangent bundle of the rotation group is a double covering of the space of normalized essential matrices. This characterization naturally explains the geometry of the possible number of 3D displacements which can be obtained from the essential matrix. Second, a differential version of the essential matrix constraint previously explored by [19, 20] is introduced. We then present the precise characterization of the space of differential essential matrices, which gives rise to a novel eigenvector-decomposition-based 3D velocity estimation algorithm from the optical flow measurements. This algorithm gives a unique solution to the motion estimation problem and serves as a differential counterpart of the SVD-based 3D displacement estimation algorithm from the discrete case. Finally, simulation results are presented evaluating the performance of our algorithm in terms of bias and sensitivity of the estimates with respect to the noise in optical flow measurements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Michael J. Brooks, Wojciech Chojnacki, and Luis Baumela. </author> <title> Determining the ego-motion of an uncalibrated camera from instantaneous optical flow. </title> <publisher> in press, </publisher> <year> 1997. </year>
Reference-contexts: In this paper, we have assumed that the camera is ideal. This approach can be extended to uncalibrated camera case, where the motion estimation and camera self-calibration problem can be solved simultaneously, using the differential essential constraint <ref> [19, 1] </ref>. In this case, the essential matrix is replaced by the fundamental matrix which captures both motion information and camera intrinsic parameters. It is shown in [1], that the space of such fundamental matrices is a 7-dimensional algebraic variety in R 3fi3 . <p> In this case, the essential matrix is replaced by the fundamental matrix which captures both motion information and camera intrinsic parameters. It is shown in <ref> [1] </ref>, that the space of such fundamental matrices is a 7-dimensional algebraic variety in R 3fi3 . Thus, besides five motion parameters, only two extra intrinsic parameters can be recovered.
Reference: [2] <author> A. R. Bruss and B. K. Horn. </author> <title> Passive navigation. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 21 </volume> <pages> 3-20, </pages> <year> 1983. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn <ref> [2] </ref>) or linear subspace methods (Heeger and Jepson [3, 4]). Kanatani [5] proposed 1 a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow. However, in these algorithms, the similarities between the discrete case and the differential case are not fully revealed and exploited.
Reference: [3] <author> D. J. Heeger and A. D. Jepson. </author> <title> Subspace methods for recovering rigid motion I: Algorithm and implementation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(2) </volume> <pages> 95-117, </pages> <year> 1992. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [2]) or linear subspace methods (Heeger and Jepson <ref> [3, 4] </ref>). Kanatani [5] proposed 1 a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow. However, in these algorithms, the similarities between the discrete case and the differential case are not fully revealed and exploited. <p> However, one can discard the ambiguous solution by adding the "positive depth constraint". Remark 3 By the way of comparison to the Heeger and Jepson's algorithm <ref> [3] </ref>, note that the equation (43) may be rewritten to highlight the dependence on optical flow as: [A 1 (u) j A 2 ] e = 0 (53) where A 1 (u) 2 R mfi3 is a linear function of the measured optical flow and A 2 2 R mfi6 is
Reference: [4] <author> A. D. Jepson and D. J. Heeger. </author> <title> Linear subspace methods for recovering translation direction. Spatial Vision in Humans and Robots, </title> <publisher> Cambridge Univ. Press, </publisher> <pages> pages 39-62, </pages> <year> 1993. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [2]) or linear subspace methods (Heeger and Jepson <ref> [3, 4] </ref>). Kanatani [5] proposed 1 a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow. However, in these algorithms, the similarities between the discrete case and the differential case are not fully revealed and exploited.
Reference: [5] <author> K. Kanatani. </author> <title> 3d interpretation of optical flow by renormalization. </title> <journal> International Journal of Computer Vision, </journal> <volume> 11(3) </volume> <pages> 267-282, </pages> <year> 1993. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [2]) or linear subspace methods (Heeger and Jepson [3, 4]). Kanatani <ref> [5] </ref> proposed 1 a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow. However, in these algorithms, the similarities between the discrete case and the differential case are not fully revealed and exploited. <p> Another potential way to improve this algorithm is to study the systematic bias introduced by the least square method in step 1. A similar problem has been studied by Kanatani <ref> [5] </ref> and an algorithm was proposed to remove such bias from Zhuang's algorithm [20]. Remark 2 Since both E; E 2 E 0 1 satisfy the same set of differential Longuet-Higgins constraints, both (!; v) are possible solutions for the given set of optical flows.
Reference: [6] <author> H. C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year> <month> 14 </month>
Reference-contexts: Among the efforts to solve this problem, one of the more appealing approaches is the essential matrix approach, proposed by Longuet-Higgins, Huang and Faugeras et al in 1980s <ref> [6] </ref>. It shows that the relative 3D displacement of a camera can be recovered from an intrinsic geometric constraint between two images of the same scene, the so-called Longuet-Higgins constraint (also called the epipolar or essential constraint). <p> The two corresponding image points q o and q c have to satisfy an intrinsic geometric constraint, the so-called Longuet-Higgins or epipolar constraint <ref> [6] </ref>: q T Consequently, the matrices which have the form E = R T ^p with R 2 SO (3) and ^p 2 so (3) play an important role in recovering the displacement (p; R).
Reference: [7] <author> Waxman A. M., Kamgar-Parsi B., and Subbarao M. </author> <title> Closed form solutions to image flow equations for 3d structure and motion. </title> <journal> International Journal of Computer Vision 1, </journal> <pages> pages 239-258, </pages> <year> 1987. </year>
Reference-contexts: This problem has also been explored by many researchers: an algorithm was proposed in 1984 by Zhuang et al [20] with a simplified version given in 1986 [21]; and a first order algorithm was given by Waxman et al <ref> [7] </ref> in 1987. Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [2]) or linear subspace methods (Heeger and Jepson [3, 4]).
Reference: [8] <author> Yi Ma, Jana Kosecka, and Shankar Sastry. </author> <title> Motion recovery from image sequences: Discrete viewpoint vs. differential viewpoint. </title> <institution> Electronic Research Laboratory Memorandum, UC Berke-ley, UCB/ERL, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: T 1 (SO (3)), is a double covering of the space of normalized essential matrices (full proof are given in <ref> [8] </ref>). However, the essential matrix approach based on the Longuet-Higgins constraint only recovers discrete 3D displacement. The velocity information can only be approximately obtained from the inverse of the exponential map, as Soatto et al did in [14]. <p> However, in these algorithms, the similarities between the discrete case and the differential case are not fully revealed and exploited. In this paper, we develop in parallel to the discrete essential matrix approach developed in the literature, as a review see Ma et al <ref> [8] </ref> or Maybank [10], a differential essential matrix approach for recovering 3D velocity from optical flow. Based on the differential version of the Longuet-Higgins constraint, so called differential essential matrices are defined. <p> The condition U; V 2 SO (3) was not in the original theorem given by Huang or Faugeras, but it is convenient for the following theorem which shows how to explicitly recover the displacement from an essential matrix. One may refer to the full paper <ref> [8] </ref> for the proof of this extra condition. Theorem 2 (Uniqueness of the Displacement Recovery from the Essential Matrix) There exist exactly two 3D displacements g = (p; R) 2 SE (3) corresponding to a non-zero essential matrix E 2 E. <p> then the two displacements (p; R) that solve E = R T ^p are given by: (R T Z (+ 2 )V T ) 2 ; ^p 2 ) = (U R T )V T ; V R Z ( 2 A rigorous proof for this theorem is given in <ref> [8] </ref>. A natural consequence of these two theorems is the three-step SVD-based displacement estimation algorithm proposed by Toscani and Faugeras [17], which is summarized in [8] or [10]. 3 Motivated by recent interests in dynamic (or recursive) motion estimation schemes [14], differ-ential geometric properties of the essential space E have been <p> ; ^p 2 ) = (U R T )V T ; V R Z ( 2 A rigorous proof for this theorem is given in <ref> [8] </ref>. A natural consequence of these two theorems is the three-step SVD-based displacement estimation algorithm proposed by Toscani and Faugeras [17], which is summarized in [8] or [10]. 3 Motivated by recent interests in dynamic (or recursive) motion estimation schemes [14], differ-ential geometric properties of the essential space E have been explored. Since the Longuet-Higgins condition is an homogeneous constraint, the essential matrix E can only be recovered up to a scale factor. <p> The proof of this theorem, as well as a more detailed differential geometric characterization of the normalized essential space is given in <ref> [8] </ref>. As a consequence of this theorem, the normalized essential space E 1 is a 5-dimensional connected compact manifold embedded in R 3fi3 . <p> To reveal the similarities between these two cases, we now develop the differential essential matrix approach for estimating 3D velocity from optical flow in a parallel way as developed in the literature for the discrete essential matrix approach for estimating 3D displacement from image correspondences <ref> [8, 10] </ref>. <p> The formula (44) for 1 ; 2 ; 3 are directly obtained from solving this minimization problem. An important property of this projection is that it is statistically unbiased <ref> [8] </ref>. That is, if components of the essential vector e are corrupted by identically independent (symmetric) zero-mean noise, this projection gives an unbiased estimate of the true special symmetric matrix. <p> This will be implemented in future. Note this algorithm is not optimal in the sense that the recovered velocity does not necessarily minimize the originally picked error function kAe (!; v)k 2 on E 0 1 (same for the three-step SVD based algorithm in the discrete case <ref> [8] </ref>). However, this algorithm only uses linear algebra techniques and is thus simpler than a one which tries to optimize on the submanifold E 0 1 . 4 Experimental Results We carried out initial simulations in order to study the performance of our algorithm. <p> In applications to robotics, a big advantage of the differential approach over the discrete one is that it can make use of nonholonomic constraints (i.e. constraints that confine the infinitesimal motion of the mobile base but not the global motion) and simplify the motion estimation algorithms <ref> [8] </ref>. An example study of vision guided nonholonomic system can be found in [9]. In this paper, we have assumed that the camera is ideal.
Reference: [9] <author> Yi Ma, Jana Kosecka, and Shankar Sastry. </author> <title> Vision guided navigation for a nonholonomic mobile robot. </title> <institution> Electronic Research Laboratory Memorandum, UC Berkeley, UCB/ERL(M97/42), </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: An example study of vision guided nonholonomic system can be found in <ref> [9] </ref>. In this paper, we have assumed that the camera is ideal. This approach can be extended to uncalibrated camera case, where the motion estimation and camera self-calibration problem can be solved simultaneously, using the differential essential constraint [19, 1].
Reference: [10] <author> Stephen Maybank. </author> <title> Theory of Reconstruction from Image Motion. </title> <booktitle> Springer Series in Information Sciences. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The study of the essential matrix then led to a three-step SVD-based algorithm for recovering the 3D displacement from noisy image correspondences, proposed in 1986 by Toscani and Faugeras [17] and later summarized in Maybank <ref> [10] </ref>. Motivated by recent interests in dynamical motion estimation schemes (Soatto, Frezza and Perona [14]) which usually require smoothness and regularity of the parameter space, the geometric property of the essential matrix space is further explored: the unit tangent bundle of the rotation group, i.e. <p> However, in these algorithms, the similarities between the discrete case and the differential case are not fully revealed and exploited. In this paper, we develop in parallel to the discrete essential matrix approach developed in the literature, as a review see Ma et al [8] or Maybank <ref> [10] </ref>, a differential essential matrix approach for recovering 3D velocity from optical flow. Based on the differential version of the Longuet-Higgins constraint, so called differential essential matrices are defined. <p> A natural consequence of these two theorems is the three-step SVD-based displacement estimation algorithm proposed by Toscani and Faugeras [17], which is summarized in [8] or <ref> [10] </ref>. 3 Motivated by recent interests in dynamic (or recursive) motion estimation schemes [14], differ-ential geometric properties of the essential space E have been explored. Since the Longuet-Higgins condition is an homogeneous constraint, the essential matrix E can only be recovered up to a scale factor. <p> To reveal the similarities between these two cases, we now develop the differential essential matrix approach for estimating 3D velocity from optical flow in a parallel way as developed in the literature for the discrete essential matrix approach for estimating 3D displacement from image correspondences <ref> [8, 10] </ref>. <p> version of the Longuet-Higgins constraint, the concept of differential essential matrix is defined; we then give a thorough characterization for such matrices and show that there exists exactly one 3D velocity corresponding to a non-zero differential essential matrix; as a differential version of the three-step SVD-based 3D displacement estimation algorithm <ref> [10] </ref>, a four-step eigenvector-decomposition-based 3D velocity estimation algorithm is proposed. 3.1 Differential Longuet-Higgins Constraint Suppose the motion of the camera is described by a smooth curve g (t) = (p (t); R (t)) 2 SE (3). <p> However, the velocity corresponding to a differential essential matrix is unique. This is because, in the differential case, the twist-pair ambiguity (see Maybank <ref> [10] </ref>), which is caused by a 180 ffi rotation of the camera around the translation direction, is avoided. It is clear that the normalized differential essential space E 0 1 is a 5-dimensional differentiable submanifold embedded in R 6fi3 . <p> Thus, for this algorithm, in general, the optical flow vectors of at least eight points are needed to recover the 3D velocity, i.e. m 8, although the minimum number of optical flows needed is 5 (see Maybank <ref> [10] </ref>). 1 For perspective projection, z = 1 and u 3 = 0 thus the expression for a can be simplified. 9 When the measurements are noisy, there might be no solution of e for Ae = 0. <p> As in the discrete case, we choose the solution which minimizes the error function kAek 2 . This can be mechanized using the following lemma. It is straight forward to see that (Theorem 6.1 of Maybank <ref> [10] </ref>): Lemma 2 If a matrix A 2 R nfin has the singular value decomposition A = U V T and c n (V ) is the n th column vector of V (the singular vector associated to the smallest singular value n ), then e = c n (V )
Reference: [11] <author> Philip F. McLauchlan and David W. Murray. </author> <title> A unifying framework for structure and motion recovery from image sequences. </title> <booktitle> In Proceeding of Fifth International Conference on Computer Vision, </booktitle> <pages> pages 314-320, </pages> <address> Cambridge, MA, USA, 1995. </address> <publisher> IEEE Comput. Soc. Press. </publisher>
Reference-contexts: So the two are usually viewed as separate problems. In spite of the fact that the robustness of existing algorithms has been studied quite extensively, it has been suggested that the fact that the structure and motion estimation are decoupled typically hinders their performance <ref> [11] </ref>. Some algorithms address the problem of motion and structure (shape) recovery simultaneously either in batch [16] or recursive fashion [11]. <p> that the robustness of existing algorithms has been studied quite extensively, it has been suggested that the fact that the structure and motion estimation are decoupled typically hinders their performance <ref> [11] </ref>. Some algorithms address the problem of motion and structure (shape) recovery simultaneously either in batch [16] or recursive fashion [11]. The approaches to the motion estimation only, can be partitioned into the discrete and differential methods depending on whether they use as an input set of point correspondences or image velocities.
Reference: [12] <author> Richard M. Murray, Zexiang Li, and Shankar S. Sastry. </author> <title> A Mathematical Introduction to Robotic Manipulation. </title> <publisher> CRC press Inc., </publisher> <year> 1994. </year>
Reference-contexts: camera frame satisfy: q o = R (t)q c (t) + p (t): (9) Differentiating this equation yields: _q c = R T _ Rq c R T _p: (10) Since R T _ R 2 so (3) and R T _p 2 R 3 (see Murray, Li and Sastry <ref> [12] </ref>), we may define ! = (! 1 ; ! 2 ; ! 3 ) T 2 R 3 and v = (v 1 ; v 2 ; v 3 ) T 2 R 3 to be: 4 The interpretation of these velocities is: ! is the angular velocity of the
Reference: [13] <author> Andrew Kelly Packard. </author> <title> What's new with : structured uncertainty in multivariable control. </title> <type> PhD thesis, </type> <institution> EECS, UC Berkeley, </institution> <year> 1988. </year>
Reference: [14] <author> S. Soatto, R. Frezza, and P. Perona. </author> <title> Motion estimation via dynamic vision. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 41(3) </volume> <pages> 393-413, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: The study of the essential matrix then led to a three-step SVD-based algorithm for recovering the 3D displacement from noisy image correspondences, proposed in 1986 by Toscani and Faugeras [17] and later summarized in Maybank [10]. Motivated by recent interests in dynamical motion estimation schemes (Soatto, Frezza and Perona <ref> [14] </ref>) which usually require smoothness and regularity of the parameter space, the geometric property of the essential matrix space is further explored: the unit tangent bundle of the rotation group, i.e. <p> However, the essential matrix approach based on the Longuet-Higgins constraint only recovers discrete 3D displacement. The velocity information can only be approximately obtained from the inverse of the exponential map, as Soatto et al did in <ref> [14] </ref>. In principle, the displacement estimation algorithms obtained by using epipolar constraints work well when the displacement (especially the translation) between the two images is relatively large. <p> A natural consequence of these two theorems is the three-step SVD-based displacement estimation algorithm proposed by Toscani and Faugeras [17], which is summarized in [8] or [10]. 3 Motivated by recent interests in dynamic (or recursive) motion estimation schemes <ref> [14] </ref>, differ-ential geometric properties of the essential space E have been explored. Since the Longuet-Higgins condition is an homogeneous constraint, the essential matrix E can only be recovered up to a scale factor. It is then customary to set the norm of the translation vector p to be 1. <p> This property is useful when using estimation schemes which require some regularity on the parameter space (for example, the dynamic estimation scheme proposed by Soatto et al <ref> [14] </ref>). 3.4 Algorithm Based on the previous study of the differential essential matrix, in this section, we propose an algorithm which recovers the 3D velocity of the camera from a set of (possibly noisy) optical flows. <p> In order to exploit temporal coherence of motion and improve algorithm's robustness, a dynamic (recursive) motion estimation scheme, which uses implicit extended Kalman filter for estimating the essential parameters, has been proposed by Soatto et al <ref> [14] </ref> for the discrete case. The same ideas certainly apply to our algorithm.
Reference: [15] <author> T. Y. Tian, C. Tomasi, and D. J. Heeger. </author> <title> Comparison of approaches to egomotion computation. </title> <booktitle> In Proceedings of 1996 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 315-20, </pages> <address> Los Alamitos, CA, USA, 1996. </address> <publisher> IEEE Comput. Soc. Press. </publisher>
Reference-contexts: The image size was considered to be 512x512 pixels. Our algorithm has been implemented in Matlab and the simulations have been performed using example sets proposed by <ref> [15] </ref> in their paper on comparison of the egomotion estimation from 12 optical flow 3 . The motion estimation was performed by observing the motion of a random cloud of points placed in front of the camera. <p> The presented results demonstrate the performance of the algorithm while translating along X-axis and rotating around Z-axis with rate of 23 o per frame. The analysis of the obtained results of the motion estimation algorithm was performed using benchmarks proposed by <ref> [15] </ref>. The bias is expressed as an angle between the average estimate out of all trails (for a given setting of parameters) and the true direction of translation and/or rotation. <p> The translational estimates are very similar. Increasing the ratio between magnitudes of translational and angular velocities improves the bias and sensitivity of both algorithms. The evaluation of the results and more extensive simulations are currently underway. We believe 3 We would like to thank the authors in <ref> [15] </ref> for making the code for simulations of various algorithms and evaluation of their results available on the web. 13 that through thorough understanding of the source of translational bias we can obtain even better performance by utilizing additional information about linear velocity, which is embedded in the symmetric part of
Reference: [16] <author> Carlo Tomasi and Takeo Kanade. </author> <title> Shape and motion from image streams under orthography. </title> <journal> Intl. Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: Some algorithms address the problem of motion and structure (shape) recovery simultaneously either in batch <ref> [16] </ref> or recursive fashion [11]. The approaches to the motion estimation only, can be partitioned into the discrete and differential methods depending on whether they use as an input set of point correspondences or image velocities.
Reference: [17] <author> G. Toscani and O. D. Faugeras. </author> <title> Structure and motion from two noisy perspective images. </title> <booktitle> Proceedings of IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 221-227, </pages> <year> 1986. </year>
Reference-contexts: The study of the essential matrix then led to a three-step SVD-based algorithm for recovering the 3D displacement from noisy image correspondences, proposed in 1986 by Toscani and Faugeras <ref> [17] </ref> and later summarized in Maybank [10]. <p> A natural consequence of these two theorems is the three-step SVD-based displacement estimation algorithm proposed by Toscani and Faugeras <ref> [17] </ref>, which is summarized in [8] or [10]. 3 Motivated by recent interests in dynamic (or recursive) motion estimation schemes [14], differ-ential geometric properties of the essential space E have been explored. <p> In addition, in the differential case understanding of the space of differential essential matrices leads to a new egomotion estimation algorithm, which is a natural counterpart of the three-step SVD based algorithm in developed for the discrete case by <ref> [17] </ref>. In order to exploit temporal coherence of motion and improve algorithm's robustness, a dynamic (recursive) motion estimation scheme, which uses implicit extended Kalman filter for estimating the essential parameters, has been proposed by Soatto et al [14] for the discrete case. The same ideas certainly apply to our algorithm.
Reference: [18] <author> Roger Y. Tsai and Thomas S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects with curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-6(1):13-27, </volume> <month> January </month> <year> 1984. </year>
Reference-contexts: This endows the resulting motion estimation algorithms with some advantageous features: they do not need to assume any a priori knowledge of the scene; and are computationally simpler (comparing to most non-intrinsic motion estimation algorithms), using mostly linear algebraic techniques. Tsai and Huang <ref> [18] </ref> then proved that, given an essential matrix associated with the Longuet-Higgins constraint, there are only two possible 3D displacements.
Reference: [19] <author> T. Vieville and O. D. Faugeras. </author> <title> Motion analysis with a camera with unknown, and possibly varying intrinsic parameters. </title> <booktitle> Proceedings of Fifth International Conference on Computer Vision, </booktitle> <pages> pages 750-756, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: In this paper, we have assumed that the camera is ideal. This approach can be extended to uncalibrated camera case, where the motion estimation and camera self-calibration problem can be solved simultaneously, using the differential essential constraint <ref> [19, 1] </ref>. In this case, the essential matrix is replaced by the fundamental matrix which captures both motion information and camera intrinsic parameters. It is shown in [1], that the space of such fundamental matrices is a 7-dimensional algebraic variety in R 3fi3 .
Reference: [20] <author> Xinhua Zhuang and R. M. Haralick. </author> <title> Rigid body motion and optical flow image. </title> <booktitle> Proceedings of the First International Conference on Artificial Intelligence Applications, </booktitle> <pages> pages 366-375, </pages> <year> 1984. </year>
Reference-contexts: A differential (or continuous) version of the 3D motion estimation problem is to recover the 3D velocity of the camera from optical flow. This problem has also been explored by many researchers: an algorithm was proposed in 1984 by Zhuang et al <ref> [20] </ref> with a simplified version given in 1986 [21]; and a first order algorithm was given by Waxman et al [7] in 1987. <p> Thus one can not directly use the previously derived results for special symmetric matrices to recover the 3D velocity. In the algorithms proposed in Zhuang <ref> [20, 21] </ref>, such s, with the linear velocity v obtained from the skew-symmetric part, is directly used to calculate the angular velocity !. <p> Another potential way to improve this algorithm is to study the systematic bias introduced by the least square method in step 1. A similar problem has been studied by Kanatani [5] and an algorithm was proposed to remove such bias from Zhuang's algorithm <ref> [20] </ref>. Remark 2 Since both E; E 2 E 0 1 satisfy the same set of differential Longuet-Higgins constraints, both (!; v) are possible solutions for the given set of optical flows. However, one can discard the ambiguous solution by adding the "positive depth constraint".
Reference: [21] <author> Xinhua Zhuang, Thomas S. Huang, and Narendra Ahuja. </author> <title> A simplified linear optic flow-motion algorithm. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 42 </volume> <pages> 334-344, </pages> <year> 1988. </year> <month> 15 </month>
Reference-contexts: This problem has also been explored by many researchers: an algorithm was proposed in 1984 by Zhuang et al [20] with a simplified version given in 1986 <ref> [21] </ref>; and a first order algorithm was given by Waxman et al [7] in 1987. <p> Thus one can not directly use the previously derived results for special symmetric matrices to recover the 3D velocity. In the algorithms proposed in Zhuang <ref> [20, 21] </ref>, such s, with the linear velocity v obtained from the skew-symmetric part, is directly used to calculate the angular velocity !.
References-found: 21

