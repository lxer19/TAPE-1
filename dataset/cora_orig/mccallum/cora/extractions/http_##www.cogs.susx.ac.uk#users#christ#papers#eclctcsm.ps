URL: http://www.cogs.susx.ac.uk/users/christ/papers/eclctcsm.ps
Refering-URL: http://www.cogs.susx.ac.uk/users/christ/index-noframes.html
Root-URL: 
Email: Email christ@cogs.susx.ac.uk  
Title: Representational Eclecticism A Foundation Stone for the New AI?  
Author: Chris Thornton 
Date: January 27, 1993  
Address: Brighton BN1 9QN  
Affiliation: School of Cognitive and Computing Sciences University of Sussex  
Abstract: In this paper I support the view that neural networks and connectionism constitute a `new AI' but argue that the new field incorporates both the reactive systems movement and work on genetic algorithms. The common theme in these approaches is, I propose, the idea that cognitive agents may use representations in an eclectic and opportunistic fashion rather than in the neatly structured manner proposed by classical AI. The way in which this idea is being developed (in connectionism) is considered and the outstanding problems are illustrated using a simulation.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sloman, A. </author> <year> (1991). </year> <title> AI, neural networks, neurobiology, architectures and design space. </title> <journal> AISB Quarterly, </journal> <volume> No. </volume> <pages> 78 (pp. 10-13). </pages>
Reference-contexts: There are obviously methodological differences between connectionism and classical AI. Connectionism concerns itself with network architectures and training algorithms whereas classical AI concerns itself with algorithmic methods and knowledge representation. But are these differences deep-set or merely superficial? Some researchers (eg. <ref> [1] </ref>) have suggested that there is a strong continuity from classical AI to connectionism noting that even though the latter paradigm is concerned with a new type of computational architecture it remains concerned with the problems that were central to classical AI (e.g. representation). 1 My own view is that a
Reference: [2] <author> Brooks, R. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, RA-2, </journal> <volume> No. </volume> <pages> 1 (pp. 14-23). </pages>
Reference-contexts: Brooks for example has done experimental work with situated `creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. With these creatures there is essentially no representational structure but rather a fabric of reactive tendencies which, in combination, produce seemingly purposeful behaviour.
Reference: [3] <author> Brooks, R. </author> <year> (1986). </year> <title> Achieving artificial intelligence through building robots. MIT A.I. </title> <type> Memo 899, </type> <institution> Masachusetts Institute of Technology. </institution>
Reference-contexts: Brooks for example has done experimental work with situated `creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. With these creatures there is essentially no representational structure but rather a fabric of reactive tendencies which, in combination, produce seemingly purposeful behaviour.
Reference: [4] <author> Brooks, R. </author> <year> (1991). </year> <title> Intelligence without reason. </title> <booktitle> Proceedings of the Twelth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 569-595). </pages> <address> San Mateo, California: </address> <publisher> Morgan Kaufman. </publisher> <pages> 8 </pages>
Reference-contexts: Brooks for example has done experimental work with situated `creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. With these creatures there is essentially no representational structure but rather a fabric of reactive tendencies which, in combination, produce seemingly purposeful behaviour. <p> This is certainly the case in connectionism where a vast amount of work has been devoted to the investigation of simple architectures such as 2-layer back-propagation networks. It also seems that reactivist work on mobile robots has been concentrated on a limited subset of the envisaged system. <ref> [4] </ref> However, some recent work in connectionism has made some real progress on the question of how a more realistic form of RE might be achieved in practice.
Reference: [5] <author> Brooks, R. </author> <year> (1991). </year> <title> Intelligence without representation. </title> <booktitle> Artificial Intelli-gence, </booktitle> <pages> 47 (pp. 139-159). </pages>
Reference-contexts: Brooks for example has done experimental work with situated `creatures' | simple, insect-like robots which rely primarily on reactive behaviour to negotiate and interact with genuine (ie. non-simulated), physical environments <ref> [2, 3, 4, 5] </ref>. With these creatures there is essentially no representational structure but rather a fabric of reactive tendencies which, in combination, produce seemingly purposeful behaviour.
Reference: [6] <author> Goldberg, D. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: With these creatures there is essentially no representational structure but rather a fabric of reactive tendencies which, in combination, produce seemingly purposeful behaviour. In geneticism the emphasis is on developing computational systems which mimic Darwinian processes of evolution. <ref> [6] </ref> Evolutionary pressure is used to steer the system towards desired behaviours. But once again, the finished product has no neat, representational structure which carves up the relevant domain into nicely separated layers of description.
Reference: [7] <author> Sejnowski, T. and Rosenberg, C. </author> <year> (1987). </year> <title> Parallel networks that learn to pronounce english text. </title> <journal> Complex Systems, </journal> <pages> 1 (pp. 145-68). </pages>
Reference-contexts: This is a central problem in connectionism and to a lesser extent in geneticism and has led to the development of a whole set of analytic techniques (eg. hidden-vector analysis using clustering, cf. <ref> [7] </ref>.) 2 Eclecticism in theory and in practice The general plausibility of representational eclecticism (RE) seems fairly clear; but does it have any cash value? When embodied in a suitable reactivist or connectionist system does RE actually produce a tangible improvement in performance? It is, of course, very early days yet.
Reference: [8] <author> Fahlman, S. and Lebiere, C. </author> <year> (1990). </year> <title> The Cascade-Correlation Learning Architecture. </title> <institution> CMU-CS-90-100, School of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA 15213. </address>
Reference-contexts: In practice, carrying out trial and error experiments to determine an appropriate architecture is extremely costly in time. One of the leading constructive algorithms at the present time has been described by Fahlman and Lebiere <ref> [8] </ref>. This is called cascade-correlation. This algorithm dynamically constructs new internal units and connects them into an existing network while learning is taking place. <p> such as the Upstart algorithm [9] and the Tiling algorithm [10] work in a similar way. 1 In fact the algorithm can be applied to networks involving more than one output unit but the description is more complex in this case. 4 4 Problems with incremental schemes Fahlman and Lebiere <ref> [8] </ref> note that in standard back-propagation each hidden unit is attempting to learn a correct set of weights at the same time as all the other hidden units.
Reference: [9] <author> Frean, M. </author> <year> (1989). </year> <title> The Upstart Algorithm: A Method for Constructing and Training Feed-Forward Neural Networks. </title> <type> Edinburgh Physics Preprint 89/479, </type> <institution> Dept. of Physics, University of Edinburgh. </institution>
Reference-contexts: If the correlation is large but negative, the weight will be positive for the same reason. Other methods such as the Upstart algorithm <ref> [9] </ref> and the Tiling algorithm [10] work in a similar way. 1 In fact the algorithm can be applied to networks involving more than one output unit but the description is more complex in this case. 4 4 Problems with incremental schemes Fahlman and Lebiere [8] note that in standard back-propagation
Reference: [10] <author> Mezard, M. and Nadal, J. </author> <year> (1989). </year> <title> Learning in feedforward layered networks: the tiling algorithm. </title> <journal> J. Phys. A: Math. Gen., </journal> <pages> 22 (pp. 2191-2203). </pages>
Reference-contexts: If the correlation is large but negative, the weight will be positive for the same reason. Other methods such as the Upstart algorithm [9] and the Tiling algorithm <ref> [10] </ref> work in a similar way. 1 In fact the algorithm can be applied to networks involving more than one output unit but the description is more complex in this case. 4 4 Problems with incremental schemes Fahlman and Lebiere [8] note that in standard back-propagation each hidden unit is attempting
Reference: [11] <author> Hinton, G., Sejnowski, T. and Ackley, D. </author> <year> (1984). </year> <title> Boltzmann Machines: Constraint Satisfaction Networks that Learn. </title> <type> Technical Report CMU-CS84-119, </type> <institution> Carnegie-Mellon University. </institution>
Reference-contexts: In particular they assume that the desired representation will decompose on a unit-by-unit basis with each unit fulfilling an independent, error-affecting task. 5 Example 1 The problems that beset simple incremental schemes such as cascade-correlation can be illustrated using the example of the 8-unit encoder problem. <ref> [11] </ref> In this problem there are 8 input units and 8 output units. The task is to reproduce the pattern of input activation at the output units given the constraint that only one input unit is turned on at a time.
Reference: [12] <author> Rumelhart, D., Hinton, G. and Williams, R. </author> <year> (1986). </year> <title> Learning internal rep-resentations by error propagation. </title> <editor> In D. Rumelhart, J. McClelland and T.P.R. Group (Eds.), </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructures of Cognition. Vols I and II (pp. </booktitle> <pages> 318-362). </pages> <address> Cambridge, Mass.: </address> <publisher> MIT Press. </publisher> <pages> 9 10 </pages>
Reference-contexts: a lower-level network which is comprised of N `equality detectors' 4 (one for each pair of inputs) and a higher-level which simply takes the OR of the equality detector outputs. 4 Feedforward nets implementing equality detection can be constructed in a variety of ways; cf. the XOR network described in <ref> [12] </ref>. 7 7 Concluding comments The paper has put forward the view that a `new AI' has emerged in the last ten years or so and that it involves a variety of new approaches including reactivism and geneticism as well as connectionism.
References-found: 12

