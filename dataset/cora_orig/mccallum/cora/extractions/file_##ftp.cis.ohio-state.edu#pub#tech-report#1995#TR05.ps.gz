URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1995/TR05.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Title: TEMPORAL ANALYSIS OF LOAD IMBALANCE IN DISTRIBUTED COMPUTING SYSTEMS  
Author: M.G. Sriram and Mukesh Singhal. 
Keyword: Key Words: Queues, Load Imbalance, Load Sharing Window, Transfer Pair, Quantiles, Bulk Job Transfer.  
Date: January 20, 1995  
Address: Columbus, Ohio 43210  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: Distributed computing systems consist of computers interconnected by communications links. In such systems, statistical fluctuations in job arrival and service patterns cause episodes of load imbalance during which some computers are lightly loaded while others are simultaneously overloaded. Load sharing is the process of transferring jobs from overloaded to underloaded computers to improve overall system performance. Load sharing is implemented by means of load sharing algorithms . However, since little has been known about the temporal characteristics of load imbalance, various pitfalls arise in the operation of load sharing algorithms which prevent full realization of the potential benefits of load sharing. In this paper, we present a stochastic analysis of time durations of load imbalance. The notions of Transfer Pair , and Load Sharing Window are introduced. Using first passage times, a general expression for the probability distribution function of the Load Sharing Window is derived. A class of rules, called quantile rules, is introduced. Their role in avoiding unproductive job redistribution as well as to make bulk job transfers, is explained. The general technique is applied to the specific case of a distributed computing system consisting of M/M/1 queues. For this case, an expression for the mean of the Load Sharing Window is derived. Numerical computations, in the form of graphs, are presented, and their significance discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. </author> <title> Abramowitz and I.A. Stegun. </title> <publisher> Handbook of Mathematical Functions . Dover Publications Inc., </publisher> <address> New York, </address> <year> 1965. </year>
Reference-contexts: to state 0 in an M/M/1 queue is : f (t ; k, 0) = k * exp [- l + m ( ) t] * I k 2t lm ( ) * l ( ) t 16 where I k () is the Modified Bessel function of order k <ref> [1] </ref>. <p> Lemma 4: The probability distribution function of the first passage time from state k to state 0 in an M/M/1 queue is : F (x; k, 0) = 1.0 - km n 2n+k Here, G () is the incomplete Gamma Function. Proof: From <ref> [1] </ref> we have the following identity satisfied by Modified Bessel Functions: 17 x k x 4 ( ) n! n + k ( ) ! n=0 (4) Identity (4) is valid for complex x. In our case we are concerned only with real x 0. <p> integral in (6) to yield: F (x ; k, 0) = 1 - k * m * n k+2n-1 n=0 (7) Finally, Lemma 4 follows upon observing that, after a change of variable from t to ( l + m)t , the integral in (7) is the incomplete Gamma Function <ref> [1] </ref> defined as: G (a, x) = e t x dt Approximations to F (x; k, 0) can be obtained as partial sums of the infinite series in Lemma 4.
Reference: [2] <author> Y. Artsy and R. Finkel. </author> <title> "Designing A Process Migration Facility: The Charlotte Experience". </title> <journal> IEEE Computer, </journal> <volume> 22(9), </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: Eager, Lazowska, and Zahorjan [7] report communication cost to be from 1% - 10% of job processing cost. In the Charlotte distributed system, the communication overhead was reported to be 11.5 milliseconds in <ref> [2] </ref>. Theimer et al. report concerns with task transfer delays in [19].
Reference: [3] <author> D.R. Cheriton, </author> <title> The V kernel Distributed Operating System, </title> <journal> Commun. ACM, </journal> <volume> vol 1, </volume> <pages> pp. 105-115, </pages> <month> Feb </month> <year> 1985. </year>
Reference-contexts: Load sharing is an important technique for performance enhancement in the design of high-performance distributed computing systems, and has been implemented in several experimental systems such as V <ref> [3] </ref>, CONDOR [12] etc. 1.1 Existing Research in Load Sharing Most existing research in load sharing can be divided into two categories. The first deals with design and development of load sharing algorithms, Ni [15].
Reference: [4] <author> T.S. Chihara, </author> <title> An Introduction to Orthogonal Polynomials . Gordon and Breach, </title> <address> New York, </address> <year> 1978. </year>
Reference-contexts: Using this fact and equation (16) it follows easily by induction that D (0, j) = l , for j 1. (20) Since 0 &lt; l we see from (20) that 0 cannot be a root of D (s,j), j 1. Now, applying Favards Theorem <ref> [4] </ref>, it turns out that the polynomials D (s, j), j 1, defined recursively by equations (15) and (16) comprise a sequence of orthogonal polynomials with respect to some linear moment functional. For such polynomials it is well known [4] that the roots of D (s, j) are all real and <p> Now, applying Favards Theorem <ref> [4] </ref>, it turns out that the polynomials D (s, j), j 1, defined recursively by equations (15) and (16) comprise a sequence of orthogonal polynomials with respect to some linear moment functional. For such polynomials it is well known [4] that the roots of D (s, j) are all real and simple. In other words, for j 1, the polynomial D (s, j), which has degree j, has j distinct real roots. Denote these as -a 1 , -a 2 , ..., -a j .
Reference: [5] <author> T.C.K. Chow and J.A. </author> <title> Abraham,Load Balancing in Distributed Systems, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. SE-8, no. 4, </volume> <pages> pp 401-412, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: With respect to the former category, Shivaratri, Krueger, and Singhal [17] provide a survey and taxonomy of load sharing algorithms. Examples of research falling in the second category are found in <ref> [5] </ref>, [6], [7]. In a distributed computing system, the state space of the corresponding Markov Chain consists of all possible combinations of queue sizes across the nodes of the system.
Reference: [6] <author> D. Eager, E. Lazowska, and J. Zahorjan. </author> <title> "Adaptive load sharing in homogeneous distributed systems," </title> <journal> IEEE Trans. Software Eng. </journal> , <volume> vol. SE-12, no. 5, </volume> <pages> pp. 662-675, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: With respect to the former category, Shivaratri, Krueger, and Singhal [17] provide a survey and taxonomy of load sharing algorithms. Examples of research falling in the second category are found in [5], <ref> [6] </ref>, [7]. In a distributed computing system, the state space of the corresponding Markov Chain consists of all possible combinations of queue sizes across the nodes of the system. <p> Lin 2 and Raghavendra [11] use the state space aggregation method in which all system states with the same number of jobs are aggregated into one state and the time taken to transfer jobs across the distributed system is assumed to be negligible. Eager et al. <ref> [6] </ref> use the system decomposition technique to evaluate three types of load sharing algorithms. In system decomposition, the distributed system is divided into several subsystems, each consisting of a single node. <p> System performance suffers even more in this situation. Job transfer turned out to be unnecessary, and did not alleviate load imbalance while incurring processor and communications costs. Some load sharing algorithms recognize that pitfall (a) can occur. For example, in the Threshold algorithm <ref> [6] </ref>, a potential receiving node, R, is probed to determine if R is eligible to receive a transferred job, J. If so, then J is transferred to R. The receiving site, R, must process J regardless of its state, i.e., underloaded or otherwise, when J actually arrives at R. <p> If so, then J is transferred to R. The receiving site, R, must process J regardless of its state, i.e., underloaded or otherwise, when J actually arrives at R. Another load sharing algorithm described in <ref> [6] </ref> is called Random . In the Random algorithm, a transferred job, J, is transferred to a destination site, say R, picked at random. J is processed at R if R is underloaded when J arrives. Else, another node is selected at random and J is sent there.
Reference: [7] <author> D. Eager, E. Lazowska, and J. Zahorjan. </author> <title> "Adaptive load sharing in homogeneous distributed systems," </title> <journal> IEEE Trans. Software Eng. </journal> , <volume> vol. SE-12, no. 5, </volume> <pages> pp. 662-675, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: With respect to the former category, Shivaratri, Krueger, and Singhal [17] provide a survey and taxonomy of load sharing algorithms. Examples of research falling in the second category are found in [5], [6], <ref> [7] </ref>. In a distributed computing system, the state space of the corresponding Markov Chain consists of all possible combinations of queue sizes across the nodes of the system. <p> This topic was studied in detail in [18]. Another aspect of the potential for load sharing is the timedependent behavior of load imbalance in a distributed computing system. Since communication and job transfer are not instantaneous in most real-world distributed computing systems <ref> [7] </ref>, [10], [16], [17], [21], it is reasonable to speculate that the potential for load sharing is greatly affected by the temporal behavior of load imbalance. <p> Krueger and Shivaratri [10] report that the mean CPU overhead for job transfer amounts to 2% of the mean processing time. The communications overhead was reported by Zhou [21] to be between 4.5 - 20 milliseconds when the mean job processing time was 1.5 seconds. Eager, Lazowska, and Zahorjan <ref> [7] </ref> report communication cost to be from 1% - 10% of job processing cost. In the Charlotte distributed system, the communication overhead was reported to be 11.5 milliseconds in [2]. Theimer et al. report concerns with task transfer delays in [19].
Reference: [8] <author> D.P. Heyman and M.J.Sobel. </author> <title> Stochastic Models in Operations Research , vol 1, </title> <publisher> McGraw - Hill, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: For the purpose of temporal analysis, we are especially concerned with the time durations involved in such transitions. This leads us to a consideration of first passage times , in continuous time stochastic processes with state space consisting of the non-negative integers. From <ref> [8] </ref> we note the following definition. Definition 7: Let -X (t), t 0- be a stationary stochastic process with state space consisting of the non-negative integers. Let m and n be two distinct non-negative integers. <p> Let F (t; i, j) be the probability distribution function of the passage time T (i,j) and let its Laplace Transform be denoted as F ~ (s; i, j). Due to the memoryless property of inter-event times in Poisson processes, we have the following result <ref> [8] </ref>. 15 Lemma 2: F (s; i, j) = ~ k=i for i &lt; j (1) ~ k= j for i &gt; j (2) Further, F ~ (s; k + 1, k) is independent of k, for all k 1. <p> Proof: From <ref> [8] </ref> we obtain the Laplace Transform of f (t; 1, 0): f (s; 1, 0) = 2 2l From Lemma 2, it follows that for k 1 the Laplace transform of f (t; k, 0) is f (s; k, 0) = 2 2l (3) The inverse of this Laplace transform can <p> Of course, the approximation improves as we sum a greater number of terms . 18 4.2 Probability Distribution Function of Upward Jumps For upward jumps to the next higher state the probability density of first passage times depends upon the starting state. From <ref> [8] </ref> we have the following two results. Lemma 5: Let g (t; 0, 1) be the probability density function of the first passage time of the M/M/1 queue from state 0 to state 1.
Reference: [9] <author> N. Kleinrock, </author> <title> Queuing Systems, </title> <booktitle> vol. </booktitle> <address> 1 New York: </address> <publisher> Wiley, </publisher> <year> 1976. </year> <month> 39 </month>
Reference-contexts: In an M/M/1 queue <ref> [9] </ref>, jobs arrive according to a Poisson process with mean arrival rate l, and are processed by a memoryless server with exponential service time. The mean service rate is denoted as m. <p> By definition, G (x; i, j) = g (t; i, j)dt x Next, let LT [f](s) denote the Laplace transform of the function f (x). A well-known identity is <ref> [9] </ref>: LT f (x).dx t LT f [ ] s ( ) (19) Applying (19) to the Laplace Transform g ~ (s; i, j) in (18) we obtain the following expression for the Laplace transform of the probability distribution function G (t; i, j). 21 ~ l D (s, i) , <p> Thus, G ~ (s; i, j) is a rational function in which the numerator polynomial has degree i while the denominator polynomial has degree (j+1). Since i &lt; j in equation (20) it follows that the RHS of equation (20) can expanded into a finite sum of partial fractions <ref> [9] </ref>, as described in the following. To perform the partial fraction expansion we need to study the roots of the polynomial D (s,j) for j 1. First, we observe from equations (15) and (16) that D (0, 1) = l. <p> Denote these as -a 1 , -a 2 , ..., -a j . Thus, D (s, j) = s + a 1 ( ) s + a 2 ( ) .... s + a j ( ) (21) From <ref> [9] </ref>, and the fact, proved in equation (20), that 0 cannot be a root of D (s, j), we obtain the following partial fraction expansion for G ~ 22 j-i C 0 + s + a k ( ) k=1 In equation (22), for 1 j k, the coefficients are given <p> Each term on the right hand side of (25) is of the form A / (s + B) for some constants A and B,. The inverse of such a Laplace transform is well known <ref> [9] </ref> to be A exp (-Bt) . Applying this inversion formula to each term in (25) and simplifying, we obtain Lemma 7. <p> - F t; m, 0 ( ) [ ] n k=1 exp (-a k t) i.e., EW (m,n) = - l C k L 0 1 - F t; m, 0 ( ) [ ] dt (27) Now, for any non-negative function p (), we have the following two identities <ref> [9] </ref>. Let LT [p](s) denote the Laplace transform of the function p (t). Then, p (t) dt Let be a non-negative real number.
Reference: [9] <author> P. Krueger and N. G. Shivaratri. </author> <title> "Adaptive Location Policies for Global Scheduling". </title> <journal> IEEE Trans. on Software Engineering , pp 432-444, </journal> <month> June </month> <year> 1994. </year>
Reference-contexts: In an M/M/1 queue <ref> [9] </ref>, jobs arrive according to a Poisson process with mean arrival rate l, and are processed by a memoryless server with exponential service time. The mean service rate is denoted as m. <p> By definition, G (x; i, j) = g (t; i, j)dt x Next, let LT [f](s) denote the Laplace transform of the function f (x). A well-known identity is <ref> [9] </ref>: LT f (x).dx t LT f [ ] s ( ) (19) Applying (19) to the Laplace Transform g ~ (s; i, j) in (18) we obtain the following expression for the Laplace transform of the probability distribution function G (t; i, j). 21 ~ l D (s, i) , <p> Thus, G ~ (s; i, j) is a rational function in which the numerator polynomial has degree i while the denominator polynomial has degree (j+1). Since i &lt; j in equation (20) it follows that the RHS of equation (20) can expanded into a finite sum of partial fractions <ref> [9] </ref>, as described in the following. To perform the partial fraction expansion we need to study the roots of the polynomial D (s,j) for j 1. First, we observe from equations (15) and (16) that D (0, 1) = l. <p> Denote these as -a 1 , -a 2 , ..., -a j . Thus, D (s, j) = s + a 1 ( ) s + a 2 ( ) .... s + a j ( ) (21) From <ref> [9] </ref>, and the fact, proved in equation (20), that 0 cannot be a root of D (s, j), we obtain the following partial fraction expansion for G ~ 22 j-i C 0 + s + a k ( ) k=1 In equation (22), for 1 j k, the coefficients are given <p> Each term on the right hand side of (25) is of the form A / (s + B) for some constants A and B,. The inverse of such a Laplace transform is well known <ref> [9] </ref> to be A exp (-Bt) . Applying this inversion formula to each term in (25) and simplifying, we obtain Lemma 7. <p> - F t; m, 0 ( ) [ ] n k=1 exp (-a k t) i.e., EW (m,n) = - l C k L 0 1 - F t; m, 0 ( ) [ ] dt (27) Now, for any non-negative function p (), we have the following two identities <ref> [9] </ref>. Let LT [p](s) denote the Laplace transform of the function p (t). Then, p (t) dt Let be a non-negative real number.
Reference: [11] <author> H-C Lin, and C.S. Raghavendra. </author> <title> "A State-Aggregation Method for Analyzing Dynamic Load-Balancing Policies", </title> <booktitle> Proc. Int. Conf. Dist. Comput. Sys., </booktitle> <pages> pp 482-489, </pages> <year> 1993. </year>
Reference-contexts: Homogeneity of nodes with respect to job arrival and service rates is a common assumption. Lin 2 and Raghavendra <ref> [11] </ref> use the state space aggregation method in which all system states with the same number of jobs are aggregated into one state and the time taken to transfer jobs across the distributed system is assumed to be negligible.
Reference: [12] <author> M.J.Litzkow, M.Livny, </author> <title> and M.Melman,Condor - A Hunter of Idle Workstations, </title> <booktitle> in Proc. 8th Int. Conf. Distr. </booktitle> <institution> Comput. Syst., </institution> <month> June </month> <year> 1988, </year> <pages> pp 104-111. </pages>
Reference-contexts: Load sharing is an important technique for performance enhancement in the design of high-performance distributed computing systems, and has been implemented in several experimental systems such as V [3], CONDOR <ref> [12] </ref> etc. 1.1 Existing Research in Load Sharing Most existing research in load sharing can be divided into two categories. The first deals with design and development of load sharing algorithms, Ni [15].
Reference: [13] <author> M. Livny and M. Melman. </author> <title> "Load Balancing in homogeneous broadcast distributed systems", </title> <journal> pp. </journal> <pages> 47-55, </pages> <booktitle> Proc. Computer Network Perform. Symp. </booktitle> , <year> 1982. </year>
Reference-contexts: 1.0 Introduction A distributed computing system is a collection of computing sites, also called nodes, connected by a communication network. Each node receives work in the form of jobs from external sources. These jobs are then processed, and the outputs are returned to the external world. It has been shown <ref> [13] </ref> that even in systems with homogeneous nodes, statistical fluctuations in arrival and service patterns cause situations in which jobs are waiting for service at some nodes while others are simultaneously idle. Such occurrences are termed as load imbalances. <p> Analysis of load imbalance yields insight which can be used to accurately estimate potential benefits of load sharing and to construct better load sharing algorithms. In this vein, Livny and Melman <ref> [13] </ref> studied the probability that in a homogeneous distributed computing system, a customer waits for service at one node while at least one node is idle. It was shown that for a wide range of system traffic intensity, this probability was close to one. Rommel [16] extended the results of [13] <p> <ref> [13] </ref> studied the probability that in a homogeneous distributed computing system, a customer waits for service at one node while at least one node is idle. It was shown that for a wide range of system traffic intensity, this probability was close to one. Rommel [16] extended the results of [13] by using a generalized definition of underload and overload and studying the Probability of Load Balancing Success (PLBS) in homogeneous distributed computing systems. <p> Load imbalance in distributed computing systems is a multifaceted phenomenon, possessing frequency, magnitude and temporal aspects. Existing research in the nature of load imbalance has concentrated upon frequency and magnitude aspects <ref> [13] </ref>, [16], [18]. In this paper we presented a stochastic analysis of temporal aspects of load imbalance in distributed computing systems. Since probe and job transfer times can be significant in such systems, load sharing algorithms are subject to a number of pitfalls resulting in unproductive and/or unnecessary job redistribution.
Reference: [14] <author> G.E. Roberts and H. Kaufman, </author> <title> Table of Laplace Transforms. </title> <publisher> W.B. Saunders Co., </publisher> <address> Philadelphia, </address> <year> 1966. </year>
Reference-contexts: of f (t; 1, 0): f (s; 1, 0) = 2 2l From Lemma 2, it follows that for k 1 the Laplace transform of f (t; k, 0) is f (s; k, 0) = 2 2l (3) The inverse of this Laplace transform can be obtained from tables in <ref> [14] </ref> as f (t ; k, 0) = k * exp [- l + m ( ) t] * I k 2t lm ( ) * l ( ) t Next, let F (x ; k, 0) denote the distribution function of the above density function, i.e., F (x; k, 0)
Reference: [15] <author> L. Ni, W Xu, </author> <title> T.B. Gendreau, A Distributed Drafting Algorithm for Load Balancing, </title> <journal> IEEE Transactions Software Engineering, </journal> <volume> vol SE-10, No. 10, </volume> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: The first deals with design and development of load sharing algorithms, Ni <ref> [15] </ref>. The second is concerned with stability and performance issues of load sharing algorithms, often with a view to comparing different types of load sharing algorithms. With respect to the former category, Shivaratri, Krueger, and Singhal [17] provide a survey and taxonomy of load sharing algorithms.
Reference: [16] <author> C.G. Rommel, </author> <title> "The Probability of load balancing success in a homogeneous network", </title> <journal> IEEE Trans. Software Engineering , vol. </journal> <volume> 17, </volume> <pages> pp. 922 - 933, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: It was shown that for a wide range of system traffic intensity, this probability was close to one. Rommel <ref> [16] </ref> extended the results of [13] by using a generalized definition of underload and overload and studying the Probability of Load Balancing Success (PLBS) in homogeneous distributed computing systems. <p> This topic was studied in detail in [18]. Another aspect of the potential for load sharing is the timedependent behavior of load imbalance in a distributed computing system. Since communication and job transfer are not instantaneous in most real-world distributed computing systems [7], [10], <ref> [16] </ref>, [17], [21], it is reasonable to speculate that the potential for load sharing is greatly affected by the temporal behavior of load imbalance. <p> Eager, Lazowska, and Zahorjan [7] report communication cost to be from 1% - 10% of job processing cost. In the Charlotte distributed system, the communication overhead was reported to be 11.5 milliseconds in [2]. Theimer et al. report concerns with task transfer delays in [19]. In <ref> [16] </ref> Rommel observes that large subnet delays may result in performance degradation. 8 Since time and processor overhead costs associated with job redistribution can be significant, load sharing algorithms are subject to the following pitfalls. a) By the time a job transferred from an overloaded node arrives at a receiving node, <p> As explained in Section 4.8, bulk job transfer can yield considerable savings of system overhead. 34 5.3 Comparison with Previous Work It is interesting to contrast the detailed information obtained from analysis of LSW versus a global measure such as the Probability of Load Balancing Success (PLBS) <ref> [16] </ref>, which does not account for temporal factors. The case l = 4.0 and m = 5.0 corresponds to system traffic intensity r = 0.8. Suppose also that the lower and upper thresholds on queue size, L and H, are 3 and 5, respectively. <p> Suppose also that the lower and upper thresholds on queue size, L and H, are 3 and 5, respectively. When the number of sites in the distributed system, is 25, we see from Figure 2 (c) of <ref> [16] </ref> that the PLBS is 1.0. This indicates that load transfer is certain to be successful. However, from our detailed analysis of LSW we note that for this case, unless PRJT is less than 0.1452 msec, the probability that job redistribution will be successful is less than 0.90. <p> Load imbalance in distributed computing systems is a multifaceted phenomenon, possessing frequency, magnitude and temporal aspects. Existing research in the nature of load imbalance has concentrated upon frequency and magnitude aspects [13], <ref> [16] </ref>, [18]. In this paper we presented a stochastic analysis of temporal aspects of load imbalance in distributed computing systems. Since probe and job transfer times can be significant in such systems, load sharing algorithms are subject to a number of pitfalls resulting in unproductive and/or unnecessary job redistribution.
Reference: [17] <author> N. G. Shivaratri, P. Krueger, and M. Singhal. </author> <title> Load Distributing in Locally Distributed Systems, </title> <journal> IEEE Computer, </journal> <volume> vol. 25, </volume> <pages> pp. 33 - 44, </pages> <month> Dec </month> <year> 1992. </year>
Reference-contexts: The first deals with design and development of load sharing algorithms, Ni [15]. The second is concerned with stability and performance issues of load sharing algorithms, often with a view to comparing different types of load sharing algorithms. With respect to the former category, Shivaratri, Krueger, and Singhal <ref> [17] </ref> provide a survey and taxonomy of load sharing algorithms. Examples of research falling in the second category are found in [5], [6], [7]. <p> This topic was studied in detail in [18]. Another aspect of the potential for load sharing is the timedependent behavior of load imbalance in a distributed computing system. Since communication and job transfer are not instantaneous in most real-world distributed computing systems [7], [10], [16], <ref> [17] </ref>, [21], it is reasonable to speculate that the potential for load sharing is greatly affected by the temporal behavior of load imbalance. <p> The location policy can be either sender-initiated , in which an overloaded site initiates a search for underloaded sites, or receiver-initiated, in which an underloaded site starts a search for overloaded ones, or symmetric, a combination of the previous two. Details of such algorithms can be found in <ref> [17] </ref>. In general, all load sharing algorithms work by sending out special messages called probes whose objectives are to locate suitable sites for the purpose of load redistribution. <p> The benefits of bulk job transfer include decreased system overhead and faster load balancing. We note that existing load sharing algorithms do not appear to deal with redistribution of more than one job at a time <ref> [17] </ref>. Thus, the entire procedure of broadcasting probes, waiting for their return, and selecting a suitable site for job redistribution, must be repeated for each job which needs to be transferred. <p> The time savings and peformance improvement resulting from redistributing more than one job at a time without reprobing can be considerable. To illustrate, suppose that in a given distributed computing system, the load sharing algorithm is of the sender-initiated type <ref> [17] </ref>, and that it transfers only one job at a time. At time t, let S be an overloaded site with overload equal to 3.
Reference: [18] <author> M.G. Sriram and M. Singhal. </author> <title> "Measures of Load Sharing Potential in Distributed Computer Systems", </title> <note> To appear in IEEE Transactions Software Engineering. </note>
Reference-contexts: This aspect is important because during load imbalance, underloaded sites of the distributed system may not have sufficient capacity to absorb all of the excess load in overloaded sites. This topic was studied in detail in <ref> [18] </ref>. Another aspect of the potential for load sharing is the timedependent behavior of load imbalance in a distributed computing system. <p> The magnitudes of overload and underload at these sites. 3. The time duration of load imbalance. In other words, the length of time that the load imbalance persists among nodes. In previous work, <ref> [18] </ref>, the first two factors have been studied in detail. In this paper we investigate the third factor, i.e., the time duration of load imbalance. <p> The total number of jobs which can be redistributed in the system is upper-bounded by a random variable called the Number of Sharable Jobs. A detailed analysis of this quantity is presented in <ref> [18] </ref>. 3.0 Temporal Analysis of Load Imbalance. In a transfer pair the time needed to transfer a job can be a significant factor. Job transfer involves processor overhead as well as communications overhead. The latter cost is directly proportional to the size of the transferred job and communications network topology. <p> Load imbalance in distributed computing systems is a multifaceted phenomenon, possessing frequency, magnitude and temporal aspects. Existing research in the nature of load imbalance has concentrated upon frequency and magnitude aspects [13], [16], <ref> [18] </ref>. In this paper we presented a stochastic analysis of temporal aspects of load imbalance in distributed computing systems. Since probe and job transfer times can be significant in such systems, load sharing algorithms are subject to a number of pitfalls resulting in unproductive and/or unnecessary job redistribution.
Reference: [19] <author> M. Theimer, K. Lantz, and D. Cheriton. </author> <title> "Preemptable remote execution facilities for the V-System.," </title> <booktitle> in Proc. 10th Symp. Oper. Syst. Principles, </booktitle> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: Eager, Lazowska, and Zahorjan [7] report communication cost to be from 1% - 10% of job processing cost. In the Charlotte distributed system, the communication overhead was reported to be 11.5 milliseconds in [2]. Theimer et al. report concerns with task transfer delays in <ref> [19] </ref>. <p> Hence from <ref> [19] </ref>, we can interchange the infinite summation and the integral in (6) to yield: F (x ; k, 0) = 1 - k * m * n k+2n-1 n=0 (7) Finally, Lemma 4 follows upon observing that, after a change of variable from t to ( l + m)t , the
Reference: [20] <author> S. Wolfram. </author> <title> Mathematica , 2d ed, </title> <publisher> Addison Wesley, </publisher> <address> Menlo Park, Ca, </address> <year> 1991 </year>
Reference-contexts: Remark 2 To apply Lemma 7 the roots of D (s, j), j 0 need to be computed. This can be done numerically, using standard interpolation methods, or by using symbolic mathematical software such as Mathematica <ref> [20] </ref>. The latter is preferable because the entire computation of G (t; i, j), can be most easily performed using such software. 23 Remark 3.

References-found: 20

