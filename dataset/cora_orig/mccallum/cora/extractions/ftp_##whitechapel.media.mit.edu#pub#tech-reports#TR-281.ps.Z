URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-281.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Segmentation of Rigidly Moving Objects using Multiple Kalman Filters  
Author: Trevor Darrell, Ali Azarbayejani, and Alex P. Pentland 
Address: 20 Ames Street Cambridge MA, 02139  
Affiliation: Perceptual Computing Group The Media Laboratory Massachusetts Institute of Technology  
Abstract: M.I.T. Media Laboratory Vision and Modeling Group Technical Report No. 281 Appeared, Proc. Wkshp. Performance vs. Methodology in C.V., CVPR-94 ABSTRACT In this paper we describe a method for structure-from-motion recovery when there are multiple objects in the scene. We use our recently developed recursive estimation technique to recover shape and motion parameters given a set of features being tracked in the image. Support maps defined for these features limit the integration of information across space when there are multiple objects in a scene, due to occlusions or interleaved regions. Multiple hypothetical models are run concurrently, based on random initial groupings of the data. A minimum description length selection mechanism determines which 3-D structure/motion models and which groups of features constitute the best match to the data. We show results segmenting a synthetic sequence containing features on two rotating spheres, where there are no static cues available for segmentation, and on a real image sequence containing both camera and object motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. J. Azarbayejani, B. Horowitz, A. P. Pentland, </author> <title> Recursive Estimation of Structure and Motion using the Relative Orientation Constraint In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </title> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]). <p> Given that the rigid-body assumption is correct, after the selection stage each real object in the scene will have a separate structure from motion computation modeling shape and motion for that object. The motion model we use is based on the recursive estimation approach of Azarbayejani and Pentland <ref> [1] </ref>. This method formulates the estimation problem as an instance of an Extended Kalman Filter (EKF) which solves for the optimal estimate of the relative orientation and pointwise structure of an object at each time step. <p> This work provides for the optimal integration of information over time, under the assumption that a set of features constituting a coherent object is provided as input. 2 Recursive Structure From Motion First we briefly review the recursive structure from motion model presented in <ref> [1] </ref>. This formulation embeds the constraints of the well-known relative orientation approach to structure from motion [8, 9] directly into an EKF measurement relationship. Here we are only considering the case of structure from motion based on explicitly tracked features. <p> The two hypotheses correspond to the two original motions used to synthetically create the sequence; their support maps are shown in Figure 8. 3.4 Example with real imagery Features were tracked on this sequence using the (human assisted) method desribed in <ref> [1] </ref>. Hypotheses were constructed by taking 500 random selections of 4 points, and setting the intial support map for each hypothesis to be the randomly selected points. Motion estimates were computed for each of these hypotheses, based only on the supported points. <p> Appendix A. Extended Kalman Filter The following presentation of the EKF is adapted from <ref> [1] </ref>. <p> The observation at each time step is a set of N 2D measurements which is a nonlinear function of the state vector: y (t) = B y 1 (t) y N (t) C The imaging geometry outlined in Section 2 (see <ref> [1] </ref> for details) define the nonlinear function h (x (t)), with an uncertainty term (t), modeled as Gaussian distributed white noise.
Reference: [2] <author> T. E. Boult and L. G. Brown, </author> <title> Factorization-Based Segmentation of Motions Proc. </title> <booktitle> IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, <ref> [2] </ref>). If there is only a single rigid motion in the scene, such as in the case of ego-motion and a static scene, or a single moving object with a uniform background, then all features can be integrated together.
Reference: [3] <author> Ted J. Broida, S. Chandrashekhar, and Rama Chellappa. </author> <title> Recursive estimation of 3-d motion from a monocular image sequence. </title> <journal> IEEE Trans. Aerosp. Electron. Syst., </journal> <volume> 26(4) </volume> <pages> 639-656, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [4] <author> T. Darrell and A. P. Pentland. </author> <title> Segmentation by minimal description. </title> <booktitle> In Proceedings Thrid Intl. Conference on Computer Vision, </booktitle> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Figure 4 shows an overview of the model we propose. This work is an extension of the segmentation framework we developed based on minimal length description and robust estimation techniques <ref> [13, 4] </ref>. We have previously applied this formulation to the motion domain, developing a model for the perception of multiple motions in the case of structured optical flow fields with occlusion [5] or transparency [6].
Reference: [5] <author> T. Darrell and A. P. Pentland. </author> <title> Robust estimation of a multi-layer motion representation. </title> <booktitle> In Proceedings IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: We have previously applied this formulation to the motion domain, developing a model for the perception of multiple motions in the case of structured optical flow fields with occlusion <ref> [5] </ref> or transparency [6]. For the task addressed in this paper the computation of rigid-body structure from motion using tracked features we generate hypotheses by taking random samples of sets of features, and using those to compute a motion estimate.
Reference: [6] <author> T. Darrell and E.P. </author> <title> Simoncelli Separation of Transparent Motion into Layers using Velocity-tuned Mechanisms. </title> <booktitle> Vision and Modeling Group TR-244, </booktitle> <year> 1993. </year>
Reference-contexts: We have previously applied this formulation to the motion domain, developing a model for the perception of multiple motions in the case of structured optical flow fields with occlusion [5] or transparency <ref> [6] </ref>. For the task addressed in this paper the computation of rigid-body structure from motion using tracked features we generate hypotheses by taking random samples of sets of features, and using those to compute a motion estimate. <p> We follow the presentation adopted in <ref> [6] </ref> simplified to the case of pure occlusion (e.g., no transparent combination of two hypotheses at a single point).
Reference: [7] <author> Ernst Dieter Dickmanns and Volker Graefe. </author> <title> Dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1 </volume> <pages> 223-240, </pages> <year> 1988. </year>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [8] <author> B. K. P. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: This formulation embeds the constraints of the well-known relative orientation approach to structure from motion <ref> [8, 9] </ref> directly into an EKF measurement relationship. Here we are only considering the case of structure from motion based on explicitly tracked features. In our system features are selected and tracked as in reference [17]. For a single object, the formulation is as follows.
Reference: [9] <author> B. K. P. Horn. </author> <title> Relative orientation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4(1) </volume> <pages> 59-78, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: This formulation embeds the constraints of the well-known relative orientation approach to structure from motion <ref> [8, 9] </ref> directly into an EKF measurement relationship. Here we are only considering the case of structure from motion based on explicitly tracked features. In our system features are selected and tracked as in reference [17]. For a single object, the formulation is as follows.
Reference: [10] <author> J. J. Hopfield, and D. W. Tank, </author> <title> Neural computation of decisions in Optimization Problems. </title> <journal> Biological Cybernetics, </journal> <volume> Vol. 52, </volume> <pages> pp. 141-152. </pages> <year> 1985. </year>
Reference-contexts: Since T is symmetric, the network will converge to a stable solution which is a local maxima of E (a) <ref> [10] </ref>. are 200 hypotheses, and thus a selection vector a with 200 elements. Initially they are set to zero, and after 60 time steps they have converged to select two hypotheses which best account for all the data.
Reference: [11] <author> Ratnam V. Raja Kumar, Arun Tirumalai, and Ramesh C. Jain. </author> <title> A non-linear optimization algorithm for the estimation of structure and motion parameters. </title> <booktitle> In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 136-143, </pages> <address> June 1989. (San Diego, CA.). </address>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [12] <author> J. Oliensis and J. Inigo Thomas. </author> <title> Incorporating motion error in multi-frame structure from motion. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 8-13, </pages> <address> Los Alamitos, CA, </address> <month> October </month> <year> 1991. </year> <booktitle> IEEE Computer Society, </booktitle> <publisher> IEEE Computer Society Press. </publisher> <address> (Nassau Inn, Princeton, NJ.). </address>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [13] <author> A. P. Pentland. </author> <title> Part Segmentation for Object Recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 82-91, </pages> <year> 1989. </year>
Reference-contexts: Figure 4 shows an overview of the model we propose. This work is an extension of the segmentation framework we developed based on minimal length description and robust estimation techniques <ref> [13, 4] </ref>. We have previously applied this formulation to the motion domain, developing a model for the perception of multiple motions in the case of structured optical flow fields with occlusion [5] or transparency [6].
Reference: [14] <author> S. Soatto, P. Perona, R. Fraezza, and G. Picci. </author> <title> Recursive motion and structure estimation with complete error characterization. </title> <booktitle> In 1993 IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 428-433, </pages> <address> Los Alamitos, CA, June 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher> <address> (New York). </address>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [15] <author> Minas Spetsakis and Yiannis Aloimonos. </author> <title> A multi-frame approach to visual motion perception. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6(3) </volume> <pages> 245-255, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [16] <author> Richard Szeliski and Sing Bing Kang. </author> <title> Recovering 3d shape and motion from image streams using non-linear least squares. </title> <booktitle> In 1993 IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 752-753, </pages> <address> Los Alamitos, CA, June 1993. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher> <address> (New York). </address>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [17] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]). <p> Here we are only considering the case of structure from motion based on explicitly tracked features. In our system features are selected and tracked as in reference <ref> [17] </ref>. For a single object, the formulation is as follows. Motion is defined as the 3-D translation and rotation of the camera (or object) with respect to the first frame in the sequence. Similarly, structure is represented as the 3-D locations of points seen in the first camera frame.
Reference: [18] <author> Juyang Weng, Narendra Ahuja, and Thomas S. Huang. </author> <title> Optimal motion and structure estimation. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15(9) </volume> <pages> 864-884, </pages> <month> September </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
Reference: [19] <author> G-S. Young and Rama Chellappa. </author> <title> 3-d motion estimation using a sequence of noisy stereo im-ages: Models, estimation and uniqueness. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 12(8) </volume> <pages> 735-759, </pages> <month> January </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: Many methods have been proposed for recovering the structure and motion parameters of a single rigidly moving object given a set of tracked features or reliable optical flow information <ref> [1, 3, 7, 11, 12, 14, 15, 16, 17, 18, 19] </ref>. In general these methods do not address the question of how to segment the motion information when there are multiple motions in the sequence (but see, for instance, [2]).
References-found: 19

