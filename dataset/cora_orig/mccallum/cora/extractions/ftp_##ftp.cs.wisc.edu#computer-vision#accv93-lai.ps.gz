URL: ftp://ftp.cs.wisc.edu/computer-vision/accv93-lai.ps.gz
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Title: On Regularization, Formulation and Initialization of the Active Contour Models (Snakes)  
Author: Kok F. Lai Roland T. Chin yx 
Address: Madison WI 53706  Hong Kong  
Affiliation: Electrical Computer Engineering University of Wisconsin  Computer Science Hong Kong University of Science Technology Clear Water Bay,  
Abstract: In snake formulation, large regularization enhances the robustness against noise and incomplete data, while small values increase the accuracy in capturing boundary variations. We present a local minimax criterion which automatically determines the optimal regularization at every locations along the boundary with no added computation cost. We also modify existing energy formulations to repair deficiencies in internal energy and improve performance in external energy. This yields snakes that contain Hough transform as a special case. We can therefore initialize the snake efficiently and reliably using Hough transform. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kass, A. Witkin & D. Terzopoulos, "Snakes: </author> <title> Active Contour Models," </title> <booktitle> Proc. 1st Int. Conf. on Comp. Vision, </booktitle> <year> 1987, </year> <pages> pp. 259-269. </pages>
Reference-contexts: 1 Introduction The active contour models (snakes) <ref> [1] </ref> turn boundary detection into an optimization problem. <p> Setting (1) emphasizes regularization, yielding strongly model-driven solutions which are robust to noise. In contrast, small values of enable the snakes to effectively capture boundary discontinuities, but they also make the solutions very noise sensitive. Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored <ref> [1, 2, 3, 4] </ref>, or based on empirical observations [5, 6] and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. <p> Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored [1, 2, 3, 4], or based on empirical observations [5, 6] and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation <ref> [1] </ref> causes a snake to shrink around strong edge points. Ballooning force [6] and hard constraint on snaxel proximity [5] have been suggested, but these require fl This research was supported in part by the National Computer Board, Republic of Singapore. prior information in setting the weighing factor or constraint. <p> Snaxel initialization is the next factor with significant impact. For satisfactory results, most existing methods <ref> [1, 5, 7] </ref> require human to judiciously place the initial snaxels near desired boundaries. Alternatively, short snakes are initialized at locations of high intensity gradient and they either overlap [2] or extend in length [3] to cover a longer boundary. <p> For each 2 <ref> [0; 1] </ref>, let v be the optimum snake that minimizes equation (2) corresponding to the chosen , and let U () = e (v ; ). Note that since v are optimum, U () is the minimum possible energy for . <p> Consequently only an optimum snake can be the minimax solution for this figure. Moreover, by examination of Figure 2 (b), we see that the mini max solution is an optimum snake v fl for a parameter fl that maximizes U () over 2 <ref> [0; 1] </ref>: min max e (v; ) = max min e (v; ) (4) Since fl maximizes the minimum snake energy U (), a minimax snake is the optimum snake that minimizes the worst case energy. <p> Let 1 = <ref> [1; 1; :::; 1] </ref> T . <p> We define E cont to measure the normalized deviation of the inter-snaxel distance from the averaged distance: E cont (i) = (d 1 kv i v i1 k 1 ) 2 =d 2 1 (9) E cont encourages snaxels to be evenly spaced and eliminates the tendency of shrinkage <ref> [1] </ref> and expansion [7] in other formulations. Normalizing the deviations with d 1 , the averaged inter-snaxel distance, makes E cont scale invariant. <p> For external energy, we use both the magnitude and direction of intensity gradient to yield E ext (i) = 1 jrI (v i )j (1 j cos (' i )j) (11) where jrI (v i )j is the magnitude of the intensity gradient normalized to <ref> [0; 1] </ref> and ' i is the angle between the intensity gradient vector and the unit tangent vector at v i .
Reference: [2] <author> S. Zucker, C. David, A. Dobbins & L. Iverson, </author> <title> "The Organization of Curve Detection: Coarse Tangent Fields and Fine Spline Coverings, </title> " <booktitle> Proc. 2nd Int. Conf. on Comp. Vision, </booktitle> <year> 1988, </year> <pages> pp. 568-577. </pages>
Reference-contexts: Setting (1) emphasizes regularization, yielding strongly model-driven solutions which are robust to noise. In contrast, small values of enable the snakes to effectively capture boundary discontinuities, but they also make the solutions very noise sensitive. Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored <ref> [1, 2, 3, 4] </ref>, or based on empirical observations [5, 6] and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. <p> Snaxel initialization is the next factor with significant impact. For satisfactory results, most existing methods [1, 5, 7] require human to judiciously place the initial snaxels near desired boundaries. Alternatively, short snakes are initialized at locations of high intensity gradient and they either overlap <ref> [2] </ref> or extend in length [3] to cover a longer boundary. However, the latter strategies cause the snake to lose the globalities that enable it to interpolate subjective contours across boundary gaps and noisy segments.
Reference: [3] <author> M. Berger & R. Mohr, </author> <title> "Towards Autonomy in Active Contour Models," </title> <booktitle> IEEE 10th Int. Conf. on Pat. </booktitle> <address> Recog., </address> <year> 1990, </year> <month> pp.847-851. </month>
Reference-contexts: Setting (1) emphasizes regularization, yielding strongly model-driven solutions which are robust to noise. In contrast, small values of enable the snakes to effectively capture boundary discontinuities, but they also make the solutions very noise sensitive. Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored <ref> [1, 2, 3, 4] </ref>, or based on empirical observations [5, 6] and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. <p> Snaxel initialization is the next factor with significant impact. For satisfactory results, most existing methods [1, 5, 7] require human to judiciously place the initial snaxels near desired boundaries. Alternatively, short snakes are initialized at locations of high intensity gradient and they either overlap [2] or extend in length <ref> [3] </ref> to cover a longer boundary. However, the latter strategies cause the snake to lose the globalities that enable it to interpolate subjective contours across boundary gaps and noisy segments. This paper tackles the fundamental issues on regularization, formulation and initialization of the active contour models. <p> Unlike methods <ref> [3] </ref> which use gradient direction to discard spurious edge points, we use the factor 1 j cos (' i )j to continuously weigh the gradient magnitude against any orientation inconsistency.
Reference: [4] <author> F. Leymarie & M. Levine, </author> <title> "Simulating the Grassfire Transform Using an Active Contour Model," </title> <journal> PAMI-14, </journal> <volume> no. 1, </volume> <year> 1992, </year> <pages> pp. 56-75. </pages>
Reference-contexts: Setting (1) emphasizes regularization, yielding strongly model-driven solutions which are robust to noise. In contrast, small values of enable the snakes to effectively capture boundary discontinuities, but they also make the solutions very noise sensitive. Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored <ref> [1, 2, 3, 4] </ref>, or based on empirical observations [5, 6] and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points.
Reference: [5] <author> A. A. Amini, T.E. Weymouth & R. C. Jain, </author> <title> "Using Dynamic Programming for Solving Variational Problems in Vision," </title> <journal> PAMI-12, </journal> <volume> no. 9, </volume> <year> 1990, </year> <pages> pp. 855-867. </pages>
Reference-contexts: In contrast, small values of enable the snakes to effectively capture boundary discontinuities, but they also make the solutions very noise sensitive. Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored [1, 2, 3, 4], or based on empirical observations <ref> [5, 6] </ref> and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. <p> Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. Ballooning force [6] and hard constraint on snaxel proximity <ref> [5] </ref> have been suggested, but these require fl This research was supported in part by the National Computer Board, Republic of Singapore. prior information in setting the weighing factor or constraint. <p> Snaxel initialization is the next factor with significant impact. For satisfactory results, most existing methods <ref> [1, 5, 7] </ref> require human to judiciously place the initial snaxels near desired boundaries. Alternatively, short snakes are initialized at locations of high intensity gradient and they either overlap [2] or extend in length [3] to cover a longer boundary. <p> Note from (6) that this criterion completely bypasses the explicit selection of the nuisance parameters fl fl . It can therefore be incorporated into discrete energy minimization algorithms <ref> [5, 7] </ref> with no added computational cost. <p> Hence the reformulated E ext is able to discriminate against phantom lines while allowing legitimate corners to develop. We compute the intensity gradient vectors by fitting planes in 2x2 windows using the method of least squares. Unlike methods <ref> [5, 6] </ref> that use complex edge detectors (e.g. Canny's), we do not accept or discard edges at this stage. We contend that these decisions are premature and thus defeat the purpose of regularization. <p> The minimax criterion exhibits good compromise (see also Figure 1), providing the capability to capture boundary discontinuities but only suffer moderate degradation with noise. Energy minimization using dynamic programming <ref> [5] </ref> guarantees convergence, but suffers dramatic speed degradation as one increases the size of search windows. Point-wise method [7] improves speed performance but does not guarantee convergence. For practicality, we use a modified greedy algorithm which also considers the energy of the two neighboring snaxels.
Reference: [6] <author> L. D. Cohen, </author> <title> "On Active Contour Models and Balloons," </title> <journal> CVGIP-53, </journal> <volume> no. 2, </volume> <year> 1991, </year> <pages> pp. 211-218. </pages>
Reference-contexts: In contrast, small values of enable the snakes to effectively capture boundary discontinuities, but they also make the solutions very noise sensitive. Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored [1, 2, 3, 4], or based on empirical observations <ref> [5, 6] </ref> and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. <p> Despite its significance, regularization selection were either ignored [1, 2, 3, 4], or based on empirical observations [5, 6] and heuristics [7]. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. Ballooning force <ref> [6] </ref> and hard constraint on snaxel proximity [5] have been suggested, but these require fl This research was supported in part by the National Computer Board, Republic of Singapore. prior information in setting the weighing factor or constraint. <p> Hence the reformulated E ext is able to discriminate against phantom lines while allowing legitimate corners to develop. We compute the intensity gradient vectors by fitting planes in 2x2 windows using the method of least squares. Unlike methods <ref> [5, 6] </ref> that use complex edge detectors (e.g. Canny's), we do not accept or discard edges at this stage. We contend that these decisions are premature and thus defeat the purpose of regularization.
Reference: [7] <author> D. J. Williams & M. Shah, </author> <title> "A Fast Algorithm for Active Contours and Curvature Estimation," </title> <address> CVGIP-55, </address> <year> 1992, </year> <pages> pp. 14-26. </pages>
Reference-contexts: In contrast, small values of enable the snakes to effectively capture boundary discontinuities, but they also make the solutions very noise sensitive. Figure 1 illustrates these conflicting goals. Despite its significance, regularization selection were either ignored [1, 2, 3, 4], or based on empirical observations [5, 6] and heuristics <ref> [7] </ref>. Another factor which directly affects the solutions is energy formulation. The original E int formulation [1] causes a snake to shrink around strong edge points. <p> Snaxel initialization is the next factor with significant impact. For satisfactory results, most existing methods <ref> [1, 5, 7] </ref> require human to judiciously place the initial snaxels near desired boundaries. Alternatively, short snakes are initialized at locations of high intensity gradient and they either overlap [2] or extend in length [3] to cover a longer boundary. <p> Note from (6) that this criterion completely bypasses the explicit selection of the nuisance parameters fl fl . It can therefore be incorporated into discrete energy minimization algorithms <ref> [5, 7] </ref> with no added computational cost. <p> E cont to measure the normalized deviation of the inter-snaxel distance from the averaged distance: E cont (i) = (d 1 kv i v i1 k 1 ) 2 =d 2 1 (9) E cont encourages snaxels to be evenly spaced and eliminates the tendency of shrinkage [1] and expansion <ref> [7] </ref> in other formulations. Normalizing the deviations with d 1 , the averaged inter-snaxel distance, makes E cont scale invariant. <p> The minimax criterion exhibits good compromise (see also Figure 1), providing the capability to capture boundary discontinuities but only suffer moderate degradation with noise. Energy minimization using dynamic programming [5] guarantees convergence, but suffers dramatic speed degradation as one increases the size of search windows. Point-wise method <ref> [7] </ref> improves speed performance but does not guarantee convergence. For practicality, we use a modified greedy algorithm which also considers the energy of the two neighboring snaxels. <p> For practicality, we use a modified greedy algorithm which also considers the energy of the two neighboring snaxels. This algorithm moves a snaxel v i to a location that minimizes the sum e (i 1) + e (i) + e (i + 1), rather than e (i) as in <ref> [7] </ref>. This yields monotonically decreasing energy that ensures convergence. 6 Conclusions We treated the fundamental issues on regularization, formulation and initialization of the active contour models. The experimental results confirmed the validity of our theoretical analysis.
Reference: [8] <author> R. O. Duda & P. E. Hart, </author> <title> "Use of the Hough Transformation to Detect Lines and Curves in Pictures," </title> <journal> Comm. Ass. Comp. Mach., </journal> <volume> v15, </volume> <year> 1972, </year> <pages> pp. 11-15. </pages>
Reference-contexts: Section 2 proposes modifications in energy formulation to repair existing deficiencies in E int and enhance performance in E ext . Section 3 shows that Hough transform <ref> [8] </ref> is a special case of a snake and use it to initialize the snake efficiently from a global perspective.
Reference: [9] <author> M. A. Gennert & A. L. </author> <title> Yuille,"Determining the Optimal Weights in Multiple Objective Function Optimization," </title> <booktitle> Proc. 2nd Int. Conf. on Comp. Vision, </booktitle> <year> 1988, </year> <pages> pp. 87-89. </pages>
Reference-contexts: Since values chosen a priori are unlikely to be satisfactory for all cases, it becomes necessary to define a criterion to determine . A viable criterion is to seek a v that minimizes, over all , the maximum of e (v; ). This yields the minimax <ref> [9] </ref> criterion : e (v fl ; fl ) = min max E int (v) + (1 )E ext (v) (3) where v fl and fl are, respectively, the minimax snake and regularization parameter.
References-found: 9

