URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/bedk/icassp97_rasta.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/bedk/
Root-URL: http://www.icsi.berkeley.edu
Email: fbedk,morgang@icsi.berkeley.edu  
Title: RECOGNIZING REVERBERANT SPEECH WITH RASTA-PLP  
Author: Brian E. D. Kingsbury and Nelson Morgan 
Address: 1947 Center Street, Suite 600, Berkeley, CA 94704, USA  Berkeley, Berkeley, CA 94704, USA  
Affiliation: International Computer Science Institute,  Dept. of Electrical Engineering and Computer Sciences, University of California at  
Abstract: The performance of the PLP, log-RASTA-PLP, and J-RASTA-PLP front ends for recognition of highly reverberant speech is measured and compared with the performance of humans and the performance of an experimental RASTA-like front end on reverberant speech, and with the performance of a PLP-based recognizer trained on reverberant speech. While humans are able to reliably recognize the reverberant test set, achieving a 6.1% word error rate, the best RASTA-PLP-based recognizer has a word error rate of 68.7% on the same test set, and the PLP-based recognizer trained on reverberant speech has a 50.3% word error rate. Our experimental variant on RASTA processing provides a statistically significant improvement in performance on the reverberant speech, with a best word error rate of 64.1%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sumeet Sandhu and Oded Ghitza. </author> <title> A comparative study of mel cepstra and EIH for phone classification under adverse conditions. </title> <booktitle> In ICASSP-95. The 1995 International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 409-412. </pages> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: In a spec-trographic display such as Figure 1, reverberation appears as a form of temporal smearing. While humans are relatively tolerant of reverberation in speech, it appears that ASR systems are not. In <ref> [1] </ref>, Sandhu and Ghitza reported that the phone error rate on TIMIT sentences increased from 27.1% on a clean test set to 81.3% on a reverberant test set for a recognizer that used a mel-cepstral front end.
Reference: [2] <author> Stanley A. Gelfand and Shlomo Silman. </author> <title> Effects of small room reverberation upon the recognition of some consonant features. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 66(1) </volume> <pages> 22-29, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: presentations of Modified Rhyme Test (MRT) words in a carrier phrase, the error rate increased from 1.2% on a clean test set to 6.6% on a reverberant test set for word-initial consonants, and from 5.6% on a clean test set to 15.5% on a reverberant test set for word-final consonants <ref> [2] </ref>. In that study, the reverberant test set was produced by playing the clean test set in a room with an average reverberation time of 800 ms.
Reference: [3] <author> H. G. Hirsch. </author> <title> Automatic speech recognition in rooms. </title> <editor> In J. L. Lacoume, A. Chehikian, N. Martin, and J. Mal-bos, editors, </editor> <booktitle> Signal Processing IV: Theories and Applications. Proceedings of EUSIPCO-88. Fourth European Signal Processing Conference., </booktitle> <volume> volume 3, </volume> <pages> pages 1177-1180, </pages> <address> Amsterdam, 1988. </address> <publisher> Elsevier Science Publishers B.V. </publisher>
Reference-contexts: A RASTA-like algorithm for the dereverberation of speech was previously used to improve the performance of a speaker-dependent, isolated-word dynamic-time-warp recognizer on reverberant speech <ref> [3] </ref>. Our goal is not to enhance speech, but rather to extract reverberation-robust features for use in speaker-independent, continuous speech recognition systems.
Reference: [4] <author> Hynek Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: To provide a baseline reference for a study of these algorithms, we have tested PLP <ref> [4] </ref>, log-RASTA-PLP, and J-RASTA-PLP [5] front ends, both singly and in combination, on a highly reverberant test set. We have included a simple example of the class of algorithms we are now studying in these tests, and the initial results are promising.
Reference: [5] <author> Hynek Hermansky and Nelson Morgan. </author> <title> RASTA processing of speech. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> 2(4) </volume> <pages> 578-589, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: To provide a baseline reference for a study of these algorithms, we have tested PLP [4], log-RASTA-PLP, and J-RASTA-PLP <ref> [5] </ref> front ends, both singly and in combination, on a highly reverberant test set. We have included a simple example of the class of algorithms we are now studying in these tests, and the initial results are promising.
Reference: [6] <institution> Center for Spoken Language Understanding, Department of Computer Science and Engineering, Oregon Graduate Institute. Numbers corpus, release 1.0, </institution> <year> 1995. </year>
Reference-contexts: EXPERIMENTAL CONDITIONS 2.1. Speech Material Both the machine recognition and human recognition tests were performed using material from the Numbers93 corpus, a subset of the Numbers corpus <ref> [6] </ref> collected by the Center for Speech and Language Understanding at the Oregon Graduate Institute. The Numbers93 corpus is a collection of spontaneous utterances from many speakers, collected over the telephone and sampled at 8 kHz with a 16-bit A/D converter.
Reference: [7] <author> J. B. Allen and D. A. Berkley. </author> <title> Image method for efficiently simulating small-room acoustics. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 65(4) </volume> <pages> 943-950, </pages> <month> April </month> <year> 1979. </year>
Reference-contexts: The modulated noise bands were then added together to produce the reverberant tail of the impulse response. The sparse, early reflections were estimated using a simple time-domain point image expansion simulation <ref> [7] </ref>. The ratio of direct to reverberant sound was adjusted by ear to match the original recording conditions, in which the microphone was located approximately 2.5 m from the speaker. The ratio of direct to reverberant sound energy is -16 dB. 2.3.
Reference: [8] <author> Herve Bourlard and Nelson Morgan. </author> <title> Connectionist Speech Recognition: A Hybrid Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: The ratio of direct to reverberant sound energy is -16 dB. 2.3. Machine Recognition Experiments Machine recognition tests were run using a hybrid hidden Markov model/multilayer perceptron (HMM/MLP) recog-nizer <ref> [8] </ref> in which phone probabilities are estimated using an MLP and speech decoding is done with a Viterbi search. Four front ends were tested: PLP, log-RASTA-PLP, J-RASTA-PLP, and an experimental RASTA-like front end we call the modulation spectrogram.
Reference: [9] <author> Steven Greenberg and Brian E. D. Kingsbury. </author> <title> The modulation spectrogram: In pursuit of an invariant representation of speech. </title> <booktitle> In ICASSP-97. 1997 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, </booktitle> <year> 1997. </year>
Reference-contexts: Further details on the modulation spectrogram are provided in <ref> [9] </ref>. The PLP, log-RASTA-PLP, and J-RASTA-PLP front ends used a 25 ms analysis window, an 80 Hz frame rate, and produced nine cepstral coefficients (including the energy term) per frame. The MLP phonetic probability estimators used with these front ends had 120 inputs (the Freq. Band Reverb. <p> Also, we have observed that the modulation spec-trographic features tend to highlight the high-energy portions of the speech signal associated with syllabic nuclei. A variant on the modulation spectrographic features that does not perform any global thresholding <ref> [9] </ref> gives nearly the same performance on the clean speech as PLP, without any probability combination, and performance on the reverberant speech that is essentially the same as that provided by the modulation spectrographic features reported in this paper.
Reference: [10] <author> R. Gary Leonard. </author> <title> A database for speaker-independent digit recognition. </title> <booktitle> In ICASSP-84. 1984 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 3, </volume> <pages> pages 42.11.1-42.11.4. </pages> <publisher> IEEE, </publisher> <year> 1984. </year>
Reference-contexts: Although we do not have measurements for human subjects listening to the clean test set, we note that the word error rate for humans listening to connected digit strings from the TI DIGITS corpus was 0.105% <ref> [10] </ref>. The error rate for humans on the reverberant test set is still lower than the best recognizer's error rate on the clean test set. 4. CONCLUSIONS Recognition of highly reverberant speech is a difficult task.
References-found: 10

