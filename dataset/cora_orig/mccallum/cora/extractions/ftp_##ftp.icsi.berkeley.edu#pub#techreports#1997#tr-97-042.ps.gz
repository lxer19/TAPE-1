URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1997/tr-97-042.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1997.html
Root-URL: http://www.icsi.berkeley.edu
Title: Analysis of Random Processes via And-Or Tree Evaluation  
Author: Michael G. Luby Michael Mitzenmacher M. Amin Shokrollahi 
Note: Parts of this research were done while still at the Digital Equipment Corporation Systems Research Center, Palo Alto, CA. Research partially supported by NSF operating grant NCR-9416101. Digital Equipment Corporation, Systems Research  Research supported by a Habilitationsstipendium of the Deutsche Forschungsgemeinschaft, Grant Sh 57/1-1.  
Address: Berkeley, CA.  Palo Alto, CA.  Bonn, Germany.  
Affiliation: International Computer Science Institute,  Center,  International Computer Science Institute Berkeley, and Institut fur Informatik der Universitat  
Pubnum: TR-97-042  
Abstract: We introduce a new set of probabilistic analysis tools based on the analysis of And-Or trees with random inputs. These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes, including random loss-resilient codes, solving random k-SAT formulae using the pure literal rule, the greedy algorithm for matchings in random graphs. In addition, these tools allow generalizations of these problems not previously analyzed to be analyzed in a straightforward manner. We illustrate our methodology on the three problems listed above. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, J. Edmonds, M. Luby, </author> <title> "Linear Time Erasure Codes With Nearly Optimal Recovery", </title> <booktitle> Proc. of the 36 th Annual Symp. on Foundations of Computer Science, </booktitle> <year> 1995, </year> <pages> pp. 512-519. </pages>
Reference: [2] <author> N. Alon, M. Luby, </author> <title> "A Linear Time Erasure-Resilient Code With Nearly Optimal Recovery", </title> <journal> IEEE Transactions on Information Theory (special issue devoted to coding theory), </journal> <volume> Vol. 42, No. 6, </volume> <month> November </month> <year> 1996, </year> <pages> pp. 1732-1736. </pages>
Reference: [3] <author> J. Aronson, A. Frieze, B. G. Pittel, </author> <title> "Maximum Matchings in Sparse Random Graphs: Karp-Sipser revisited", </title> <type> preprint. </type>
Reference-contexts: Finally, the simplicity and generality 2 of the new analysis will undoubtably lead to a number of other applications. We do note, however, that the differential equations approach can lead to a much more sophisticated analysis of the underlying processes (see, for example, [16] or <ref> [3] </ref>). Hence we believe our analysis tools will prove most useful in conjunction with differential equations. <p> the limiting behavior of y ` behaves properly, this methodology finds the correct threshold. 4 Greedy Matching Analysis In the paper [9], the analysis of a simple and fast heuristic for finding matchings was described and analyzed with respect to randomly chosen graphs. (This analysis has since been extended in <ref> [3] </ref>.) The tree approach provides an analysis of what they call "Phase 1"; in fact, Karp and Sipser provide an argument based on a similar tree argument. The details are similar to, but somewhat different than, those presented above to analyze the loss-resilient codes. <p> Thus, the expected size of the matching produced by the greedy algorithm is equal to the expected number of directed edges in the graph times L X ff k =k y 2 =2: 5 Acknowledgements The second author thanks Alan Frieze for the references to [16] and <ref> [3] </ref>, and thanks Alan Frieze and Andrei Broder for several useful discussions. 14
Reference: [4] <author> R. Boppana, </author> <title> "Amplification of probabilistic Boolean formulas", </title> <booktitle> Advances in Computer Research, </booktitle> <volume> Vol. 5: </volume> <booktitle> Randomness and Computation, </booktitle> <publisher> JAI Press, </publisher> <address> Greenwich, CI, </address> <year> 1989, </year> <pages> pp. 27-45. </pages>
Reference-contexts: the fact that a (2; 2)-regular And-Or tree has a critical value of = (3 p and that if y `1 = + * then y ` &gt; + c* for a constant c &gt; 1. (Analogously, if y `1 = *, then y ` &lt; c*.) In further work, <ref> [4] </ref> and [6] provide beautiful proofs that the construction size of [17] is optimal, this time using amplification analysis to prove a lower bound.
Reference: [5] <author> A. Broder, A. Frieze, E. Upfal, </author> <title> "On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas", </title> <booktitle> Proc. of the 4 th ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <year> 1993, </year> <pages> pp. 322-330. </pages>
Reference-contexts: tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes, including the random loss-resilient codes introduced in [11], the greedy algorithm for matchings in random graphs studied in [9], the threshold for solving random k-SAT formulae using the pure literal rule <ref> [5] </ref>, the emergence of a giant k-core [16], and error-correcting codes introduced in [8, 12]. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. <p> to randomly chosen k-SAT formulae ([5, 14]). (See also [7] for related results using more sophisticated heuristics.) Here, we show how the tree analysis gives a direct explanation of the behavior of the pure literal rule for a randomly chosen k-SAT formula with respect to the same distributions considered in <ref> [5] </ref> and [14]. With this new analysis, it is also straightforward to analyze distributions that were not previously considered and which would be much harder to analyze using previous techniques applied to this problem. <p> For a specific k we can easily determine the threshold value c for which (3.5) is satisfied. In particular, for k = 3 we obtain the value c ~ 1:63. This result has been found previously by <ref> [5] </ref> and [14] using a different approach. The advantage of the tree analysis approach employed in this paper is that, with little additional difficulty, it is easily possible to analyze substantially different distributions for choosing the formula, merely by establishing the proper functions (x) and (x). <p> It requires some additional technical work, as in Section 2.3, to prove that if (3.5) is satisfied then the pure literal rule finds a solution with high probability. Specifically, we need an expansion based argument like that given in <ref> [5, Lemma 4.4] </ref> to show that once all but a constant fraction of the literals are assigned values, the process must complete with high probability. Also, technically we have only proven one direction, namely that the pure literal rule finds a solution is (3.5) is satisfied.
Reference: [6] <author> M. Dubiner, U. Zwick, </author> <title> "Amplification by Read-Once Formulas", </title> <journal> Siam J. on Computing, </journal> <volume> Vol. 26, No. 1, </volume> <month> Feb. </month> <year> 1997, </year> <pages> pp. 15-38. </pages>
Reference-contexts: 1 Introduction We introduce a new set of probabilistic analysis tools related to the amplification method introduced by [15] and further developed and used in <ref> [17, 6] </ref>. <p> We say the tree is (d or ,d and )-regular if each "OR" node has d or children and each "AND" node has d and children. Our analysis is related to the study of amplification, initiated by Moore and Shannon [15], and continued in several works <ref> [17, 6] </ref>. Consider the probability that the root of T ` evaluates to 0 when the value of each leaf is independently chosen to be 0 with probability p. Let us denote this probability as y ` . <p> that a (2; 2)-regular And-Or tree has a critical value of = (3 p and that if y `1 = + * then y ` &gt; + c* for a constant c &gt; 1. (Analogously, if y `1 = *, then y ` &lt; c*.) In further work, [4] and <ref> [6] </ref> provide beautiful proofs that the construction size of [17] is optimal, this time using amplification analysis to prove a lower bound. <p> Starting at the root and working down the tree, each "OR" node chooses to have i children with probability ff i independent of any other node, and similarly each "AND" node choose to have j children with probability fi j independent of any other node. (Some previous research, e.g., <ref> [6] </ref>, introduced a variant of this form and used it in a limited way in their construction.) A further generalization is to allow two positive values a and b such that each "OR" node is independently short circuited to produce the value 1 with probability a, and each "AND" node is
Reference: [7] <author> A. Frieze, S. Suen, </author> <title> "Analysis of Two Simple Heuristics on a Random Instance of k-SAT", </title> <journal> J. of Algorithms, </journal> <volume> Vol. 20, </volume> <year> 1996, </year> <pages> pp. 312-355. </pages>
Reference-contexts: The behavior of the pure literal rule has been studied previously with respect to randomly chosen k-SAT formulae ([5, 14]). (See also <ref> [7] </ref> for related results using more sophisticated heuristics.) Here, we show how the tree analysis gives a direct explanation of the behavior of the pure literal rule for a randomly chosen k-SAT formula with respect to the same distributions considered in [5] and [14].
Reference: [8] <author> R. G. Gallager, </author> <title> Low-Density Parity-Check Codes, </title> <publisher> MIT Press, </publisher> <year> 1963. </year>
Reference-contexts: of several previously studied random processes, including the random loss-resilient codes introduced in [11], the greedy algorithm for matchings in random graphs studied in [9], the threshold for solving random k-SAT formulae using the pure literal rule [5], the emergence of a giant k-core [16], and error-correcting codes introduced in <ref> [8, 12] </ref>. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. For example, we can analyze generalizations of the loss-resilient codes considered in [11] where the goal is to recover a certain fraction of the message packets.
Reference: [9] <author> R. Karp, M. Sipser, </author> <title> "Maximum Matchings in Sparse Random Graphs", </title> <booktitle> FOCS, </booktitle> <year> 1981, </year> <pages> pp. 364-375. </pages>
Reference-contexts: These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes, including the random loss-resilient codes introduced in [11], the greedy algorithm for matchings in random graphs studied in <ref> [9] </ref>, the threshold for solving random k-SAT formulae using the pure literal rule [5], the emergence of a giant k-core [16], and error-correcting codes introduced in [8, 12]. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. <p> This type of analysis has also been noted as a possible attack for specific random graph problems, including the greedy matching algorithm of <ref> [9] </ref> and the emergence of the k-core [16]. Our work has a similar spirit to this previous work, but it differs in several ways. We generalize to allow the number of children of each node to vary in the following 1 way. <p> One common technique involved modeling the random process using differential equations. This type of approach was pioneered in the analysis of algorithms domain in by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in <ref> [9] </ref>. <p> Unfortunately, doing so appears to require using the differential equations based approach, as our tree-based approach only shows that there is a witness for the satisfiability of a random formula with high probability. (See, for example, the discussion in [16], or the proof of <ref> [9, Theorem 9] </ref>.) Intuitively, however, it is clear that as long as the limiting behavior of y ` behaves properly, this methodology finds the correct threshold. 4 Greedy Matching Analysis In the paper [9], the analysis of a simple and fast heuristic for finding matchings was described and analyzed with respect <p> a random formula with high probability. (See, for example, the discussion in [16], or the proof of [9, Theorem 9].) Intuitively, however, it is clear that as long as the limiting behavior of y ` behaves properly, this methodology finds the correct threshold. 4 Greedy Matching Analysis In the paper <ref> [9] </ref>, the analysis of a simple and fast heuristic for finding matchings was described and analyzed with respect to randomly chosen graphs. (This analysis has since been extended in [3].) The tree approach provides an analysis of what they call "Phase 1"; in fact, Karp and Sipser provide an argument based <p> The details are similar to, but somewhat different than, those presented above to analyze the loss-resilient codes. As mentioned above, the advantage of the tree analysis is that it can be adopted to analyze a variety of distributions on the graph with little additional effort. The first phase of <ref> [9] </ref> is a greedy matching algorithm in a random graph. The basic step of the first phase of their algorithm is the following. <p> This matching step is applied iteratively until there are no degree one nodes in the graph. The basic quantity of interest is the expected number of edges in the matching produced by this phase in a random graph. In the work of <ref> [9] </ref>, this basic quantity is analyzed with respect to a random graph with n nodes chosen as follows: each edge is chosen to exist with probability =(n 1) independently of all other edges. Using the tree approach, we can easily generalize this to the following. <p> Using the tree approach, we can easily generalize this to the following. Let (p 0 ; p 1 ; : : : ; p L ) be a probability vector. Each node is chosen 11 to have degree i with probability p i . The distribution analyzed by <ref> [9] </ref> is the special case where p i = exp ()() i =i!. Once the graph is fixed, the edges in the matching produced by repeated application of the greedy matching step described above depend on the order in which the nodes are chosen. <p> It is clear that z y ` for all `. We claim that y ` approaches z as ` grows; however, the only justification we currently know for this relies on the differential equation approach. (See Theorem 9 of <ref> [9] </ref>.) We assume that this is the case hereafter. Let us analyze the probability y ` that a uniformly chosen directed edge hv; wi is labeled with 1 in the tree labeling of G ` hv; wi.
Reference: [10] <author> T.G. Kurtz, </author> <title> Approximation of Population Processes, </title> <booktitle> CBMS-NSF Regional Conf. Series in Applied Math, </booktitle> <publisher> SIAM, </publisher> <year> 1981. </year>
Reference-contexts: literal on random k-SAT formulae [14]. (See also [13, 14, 16] for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [11] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem <ref> [10] </ref> to make the connection between the behavior of the random process and that of the polynomial. One of the ingredients lacking in the previous analysis of these codes was a simple intuitive connection between the polynomial solution and the original process.
Reference: [11] <author> M. Luby, M. Mitzenmacher, M. A. Shokrollahi, D. Spielman, V. Stemann, </author> <title> "Practical Loss-Resilient Codes", </title> <booktitle> Proc. 29 th Symp. on Theory of Computing, </booktitle> <year> 1997, </year> <pages> pp. 150-159. </pages>
Reference-contexts: These tools provide a unifying, intuitive, and powerful framework for carrying out the analysis of several previously studied random processes, including the random loss-resilient codes introduced in <ref> [11] </ref>, the greedy algorithm for matchings in random graphs studied in [9], the threshold for solving random k-SAT formulae using the pure literal rule [5], the emergence of a giant k-core [16], and error-correcting codes introduced in [8, 12]. <p> In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. For example, we can analyze generalizations of the loss-resilient codes considered in <ref> [11] </ref> where the goal is to recover a certain fraction of the message packets. As another example, we can analyze the behavior of the pure literal rule on random SAT formulae chosen from distributions not considered by previous analyses. <p> It has also been used to analyze the pure literal on random k-SAT formulae [14]. (See also [13, 14, 16] for references to other uses.) Similarly, the analysis of the loss-resilient codes described in <ref> [11] </ref> was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [10] to make the connection between the behavior of the random process and that of the polynomial. <p> In the next three sections, we apply Lemma 1 to the analysis of loss-resilient codes, the pure literal rule for random k-CNF formula, and the greedy matching algorithm for random graphs. 2 Loss-Resilient Code Analysis 2.1 Essentials of the Codes The codes described in <ref> [11] </ref> consist of a cascading sequence of random bipartite graphs. Because the code requires the same properties from all of these bipartite graphs, it is enough to consider one generic bipartite graph in the sequence when describing the encoding and decoding process and its analysis. <p> The decoding process terminates successfully with all message bits recovered if and only if the graph substitution recovery rule ends with no remaining left nodes with label 0. 3 2.2 New Analysis of the Original Process The paper <ref> [11] </ref> gave an analysis of the decoding process described in the previous subsection using differential equations to model the process, and then solving these equations as polynomials. In this subsection, we obtain the same result using Lemma 1. <p> Let (p 0 ; p 1 ; : : : ; p L ) and (q 0 ; q 1 ; : : : ; q R ) be probability vectors. As in <ref> [11] </ref>, consider choosing a random bipartite graph with n left nodes and m right nodes as follows: each node on the left is chosen to have degree i with probability p i , and each node on the right is chosen to have degree j with probability p j , where <p> if ffi (1 (1 x)) &lt; x (2.1) for all x 2 (0; ffi]. (Becaue and are continuous and the y ` are decreasing, the limit of the y ` is easily shown to be 0 if this condition holds.) This turns out to equivalent to the condition given in <ref> [11] </ref> for this process to end successfully. 2.3 The Overall Analysis It is not hard to argue that the process terminates with all message values successfully recovered with high probability if the probability that a message bit is not directly received is ffi and if Condition (2.1) is fulfilled. <p> Hence the number of message bits not recovered at the end of the decoding process is greater than fl 0 n with probability exponentially small in n, for fl 0 fl. Then using the expansion properties of the random graph, which follows from standard combinatorial arguments as outlined in <ref> [11] </ref>, it is not hard to argue that if 5 at most fl 0 n message bits are left recovered then the decoding process fails to recover more than O (n fl 00 ) message bits with probability at most inverse polynomial in n, for some constant fl 00 &lt; 1. <p> From this it follows that, with high probability, when the decoding process terminates all message bits have been successfully recovered. 2.4 The Dual Inequality In <ref> [11] </ref> a procedure is described for finding (close to) optimal right probabilities 1 ; : : : ; R for a given set of left probabilities 1 ; : : : ; L using a linear programming approach. However, [11] did not describe how to find the optimal left probabilities for <p> message bits have been successfully recovered. 2.4 The Dual Inequality In <ref> [11] </ref> a procedure is described for finding (close to) optimal right probabilities 1 ; : : : ; R for a given set of left probabilities 1 ; : : : ; L using a linear programming approach. However, [11] did not describe how to find the optimal left probabilities for a given set of right probabilities. Using Condition (2.1), it is easy to see how to use the methodology described in [11] to do exactly this. <p> However, <ref> [11] </ref> did not describe how to find the optimal left probabilities for a given set of right probabilities. Using Condition (2.1), it is easy to see how to use the methodology described in [11] to do exactly this. In fact, Condition (2.1) is in some sense the dual of the corresponding condition described in [11], which was (1 ffi (1 x)) &gt; x (2.2) for all x 2 (0; 1]. It is from Condition (2.2) that [11] shows how to find the optimal right <p> Using Condition (2.1), it is easy to see how to use the methodology described in <ref> [11] </ref> to do exactly this. In fact, Condition (2.1) is in some sense the dual of the corresponding condition described in [11], which was (1 ffi (1 x)) &gt; x (2.2) for all x 2 (0; 1]. It is from Condition (2.2) that [11] shows how to find the optimal right probabilities for a given set of left probabilities. <p> how to use the methodology described in <ref> [11] </ref> to do exactly this. In fact, Condition (2.1) is in some sense the dual of the corresponding condition described in [11], which was (1 ffi (1 x)) &gt; x (2.2) for all x 2 (0; 1]. It is from Condition (2.2) that [11] shows how to find the optimal right probabilities for a given set of left probabilities. We leave it as an exercise how to use the And-Or tree analysis to easily derive Condition (2.2).
Reference: [12] <author> M. Luby, M. Mitzenmacher, M. A. Shokrollahi, D. Spielman, </author> <title> "Analysis of Low Density Codes and Improved Designs using Irregular Graphs", </title> <note> submitted to STOC 1998. </note>
Reference-contexts: of several previously studied random processes, including the random loss-resilient codes introduced in [11], the greedy algorithm for matchings in random graphs studied in [9], the threshold for solving random k-SAT formulae using the pure literal rule [5], the emergence of a giant k-core [16], and error-correcting codes introduced in <ref> [8, 12] </ref>. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. For example, we can analyze generalizations of the loss-resilient codes considered in [11] where the goal is to recover a certain fraction of the message packets.
Reference: [13] <author> M. </author> <title> Mitzenmacher, </title> <type> Ph.D. thesis. </type> <institution> University of California, Berkeley, </institution> <year> 1996. </year>
Reference-contexts: This type of approach was pioneered in the analysis of algorithms domain in by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in [9]. It has also been used to analyze the pure literal on random k-SAT formulae [14]. (See also <ref> [13, 14, 16] </ref> for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [11] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [10] to make the connection between the behavior of
Reference: [14] <author> M. Mitzenmacher, </author> <title> "Tight Thresholds for the Pure Literal Rule", </title> <type> DEC/SRC Technical Note 1997-011, </type> <month> June </month> <year> 1997. </year>
Reference-contexts: This type of approach was pioneered in the analysis of algorithms domain in by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in [9]. It has also been used to analyze the pure literal on random k-SAT formulae <ref> [14] </ref>. (See also [13, 14, 16] for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [11] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [10] to make the connection between <p> This type of approach was pioneered in the analysis of algorithms domain in by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in [9]. It has also been used to analyze the pure literal on random k-SAT formulae [14]. (See also <ref> [13, 14, 16] </ref> for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [11] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [10] to make the connection between the behavior of <p> chosen k-SAT formulae ([5, 14]). (See also [7] for related results using more sophisticated heuristics.) Here, we show how the tree analysis gives a direct explanation of the behavior of the pure literal rule for a randomly chosen k-SAT formula with respect to the same distributions considered in [5] and <ref> [14] </ref>. With this new analysis, it is also straightforward to analyze distributions that were not previously considered and which would be much harder to analyze using previous techniques applied to this problem. <p> For a specific k we can easily determine the threshold value c for which (3.5) is satisfied. In particular, for k = 3 we obtain the value c ~ 1:63. This result has been found previously by [5] and <ref> [14] </ref> using a different approach. The advantage of the tree analysis approach employed in this paper is that, with little additional difficulty, it is easily possible to analyze substantially different distributions for choosing the formula, merely by establishing the proper functions (x) and (x).
Reference: [15] <author> E. Moore, C. Shannon, </author> <title> "Reliable Circuits Using Less Reliable Relays", </title> <journal> J. Franklin Inst., </journal> <volume> 262, </volume> <year> 1956, </year> <pages> pp. 191-208 and 281-297. </pages>
Reference-contexts: 1 Introduction We introduce a new set of probabilistic analysis tools related to the amplification method introduced by <ref> [15] </ref> and further developed and used in [17, 6]. <p> We say the tree is (d or ,d and )-regular if each "OR" node has d or children and each "AND" node has d and children. Our analysis is related to the study of amplification, initiated by Moore and Shannon <ref> [15] </ref>, and continued in several works [17, 6]. Consider the probability that the root of T ` evaluates to 0 when the value of each leaf is independently chosen to be 0 with probability p. Let us denote this probability as y ` .
Reference: [16] <author> B. Pittel, J. Spencer, N. Wormald, </author> <title> "Sudden Emergence of a Giant k-Core in a Random Graph", </title> <journal> J. of Combinatorial Theory, Series B, </journal> <volume> 67, </volume> <year> 1996, </year> <pages> pp. 111-151. </pages>
Reference-contexts: framework for carrying out the analysis of several previously studied random processes, including the random loss-resilient codes introduced in [11], the greedy algorithm for matchings in random graphs studied in [9], the threshold for solving random k-SAT formulae using the pure literal rule [5], the emergence of a giant k-core <ref> [16] </ref>, and error-correcting codes introduced in [8, 12]. In addition, generalizations of these problems not previously analyzed can now be analyzed in a straightforward manner. <p> This type of analysis has also been noted as a possible attack for specific random graph problems, including the greedy matching algorithm of [9] and the emergence of the k-core <ref> [16] </ref>. Our work has a similar spirit to this previous work, but it differs in several ways. We generalize to allow the number of children of each node to vary in the following 1 way. <p> This type of approach was pioneered in the analysis of algorithms domain in by Karp and Sipser, who used it to analyze a greedy algorithm for matchings in [9]. It has also been used to analyze the pure literal on random k-SAT formulae [14]. (See also <ref> [13, 14, 16] </ref> for references to other uses.) Similarly, the analysis of the loss-resilient codes described in [11] was done by modeling the random process using differential equations, solving the equations to obtain a polynomial, and using a version of Kurtz's theorem [10] to make the connection between the behavior of <p> Finally, the simplicity and generality 2 of the new analysis will undoubtably lead to a number of other applications. We do note, however, that the differential equations approach can lead to a much more sophisticated analysis of the underlying processes (see, for example, <ref> [16] </ref> or [3]). Hence we believe our analysis tools will prove most useful in conjunction with differential equations. <p> Unfortunately, doing so appears to require using the differential equations based approach, as our tree-based approach only shows that there is a witness for the satisfiability of a random formula with high probability. (See, for example, the discussion in <ref> [16] </ref>, or the proof of [9, Theorem 9].) Intuitively, however, it is clear that as long as the limiting behavior of y ` behaves properly, this methodology finds the correct threshold. 4 Greedy Matching Analysis In the paper [9], the analysis of a simple and fast heuristic for finding matchings was <p> Thus, the expected size of the matching produced by the greedy algorithm is equal to the expected number of directed edges in the graph times L X ff k =k y 2 =2: 5 Acknowledgements The second author thanks Alan Frieze for the references to <ref> [16] </ref> and [3], and thanks Alan Frieze and Andrei Broder for several useful discussions. 14
Reference: [17] <author> L. G. Valiant, </author> <title> "Short Monotone Formulae for the Majority Function", </title> <journal> J. of Algorithms, </journal> <volume> Vol. 5, </volume> <year> 1984, </year> <pages> pp. 363-366. </pages>
Reference-contexts: 1 Introduction We introduce a new set of probabilistic analysis tools related to the amplification method introduced by [15] and further developed and used in <ref> [17, 6] </ref>. <p> We say the tree is (d or ,d and )-regular if each "OR" node has d or children and each "AND" node has d and children. Our analysis is related to the study of amplification, initiated by Moore and Shannon [15], and continued in several works <ref> [17, 6] </ref>. Consider the probability that the root of T ` evaluates to 0 when the value of each leaf is independently chosen to be 0 with probability p. Let us denote this probability as y ` . <p> Of primary interest in these studies is the rate of amplification, i.e., the rate at which y ` goes to either 0 or 1 as a function of `. One work that uses exactly this type of analysis is the elegant randomized construction, given in <ref> [17] </ref>, of a polynomial size monotone boolean formula that computes the majority function. <p> value of = (3 p and that if y `1 = + * then y ` &gt; + c* for a constant c &gt; 1. (Analogously, if y `1 = *, then y ` &lt; c*.) In further work, [4] and [6] provide beautiful proofs that the construction size of <ref> [17] </ref> is optimal, this time using amplification analysis to prove a lower bound. This type of analysis has also been noted as a possible attack for specific random graph problems, including the greedy matching algorithm of [9] and the emergence of the k-core [16].
References-found: 17

