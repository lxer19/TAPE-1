URL: http://www-cad.eecs.berkeley.edu/HomePages/aloka/papers/wset.ps
Refering-URL: http://www-cad.eecs.berkeley.edu/HomePages/aloka/courses.html
Root-URL: http://www.cs.berkeley.edu
Email: aloka@cs.berkeley.edu alok@cs.berkeley.edu  
Title: Measurement of Working Set on a Cluster of Workstations  
Author: Alok Agrawal Alok Mittal 
Date: December 9, 1994  
Abstract: The idea of using a cluster of workstations to get supercomputing power is not a new one. One such attempt is being made by the NOW group here at Berkeley. One of the basic tenets of the NOW group is that a lot of workstations are idle at any time and by using them for running non-interactive jobs a huge amounts of unused computing power can be utilized. This requires that the workstations not only support normal interactive users but also large parallel jobs. However, when a parallel job runs on some idle machine, it may evict the cached pages of the idle interactive user and consequently when the user returns he may experience a high initial response time when his pages are cached back into the local memory One possible solution to this problem is to pin the working set of the user in the memory even when the parallel job is running. In this paper we have made an attempt to characterize the working set of an average user in an academic setting in order to evaluate the feasibility of this method. We present results on the average size of the file system cache and virtual memory cache which contribute to the working set of a user. We also suggest some solutions to the problem when we cannot retain the working set in the memory. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Anderson, D. Culler, D. Patterson, </author> <title> "A Case for NOW (Network of Workstations)," </title> <booktitle> IEEE Micro, </booktitle> <year> 1995 </year>
Reference-contexts: These include normal interactive users as well as parallel applications which need much more computing power than present in any single machine on the network. The basic idea is to use idle resources to run non-interactive applications, while allowing the interactive user to obtain full performance of his machine <ref> [1] </ref>. According to the Berkeley NOW group , 80% of the RAM in a NOW is free at any time [3]. Thus it may seem that RAM is not an issue. <p> Recent technological trends have lead systems' researchers to investigate the viability of a network of workstations (NOW) as a solution to different computing needs of a user <ref> [1] </ref>. One of the key issues of Berkeley NOW project is to use network RAM as a system wide resource. The idea is to use idle memory on other clients in the cluster for paging and swapping [11].
Reference: [2] <author> R. Arpaci, A. Vahdat, T. Anderson, D. Patterson, </author> <title> "Combining Parallel and Sequential Workloads on a Network of Workstations," </title> <type> Technical Report, </type> <institution> Computer Science Division, University of California at Berkeley, </institution> <year> 1994 </year>
Reference-contexts: Hence, the interactive user will get a slow initial response when he returns. In another study, it has been shown that both parallel and sequential programmers want good response time and that a parallel workload can significantly impact the interactive users <ref> [2] </ref>. The paper observes that fast context switching is important for both interactive and parallel users.
Reference: [3] <author> S. Asami, </author> <title> "NOW Retreat Presentation Evaluating Network RAM via Paging," </title> <type> UC Berkeley CS internal report, </type> <month> June </month> <year> 1994 </year>
Reference-contexts: The basic idea is to use idle resources to run non-interactive applications, while allowing the interactive user to obtain full performance of his machine [1]. According to the Berkeley NOW group , 80% of the RAM in a NOW is free at any time <ref> [3] </ref>. Thus it may seem that RAM is not an issue. However, it is not clear whether this would hold when parallel 1 job load is superimposed on top of current workstation load. <p> The currently proposed solution is to use Network RAM, i.e. use other clients' free RAM for paging and swapping. Since networks are expected to get faster and faster, NRAM is expected to be about 10 times faster than disk <ref> [3] </ref>. While this may be useful when a cache miss is being serviced, this might not give acceptable performance in case of idle users because they expect a dedicated workstation which already has their blocks cached and thus would not tolerate the latency in refetching their blocks from another client. <p> The currently proposed solution advocates use of NRAM for paging out the local RAM. However, even if a killer network is available, the NRAM is still expected to be 2-10 times slower than local RAM <ref> [3] </ref>. Hence, the interactive user will get a slow initial response when he returns. In another study, it has been shown that both parallel and sequential programmers want good response time and that a parallel workload can significantly impact the interactive users [2].
Reference: [4] <author> M. Baker, J. Hartman, M. Kupfer, K. Shirriff, J. Ousterhout, </author> <title> "Measurements of a Distributed File System," </title> <booktitle> Proceedings of the 13th Symposium on Operating Systems Principles, </booktitle> <pages> pp 198-212, </pages> <month> October </month> <year> 1991 </year>
Reference-contexts: The system had four file servers during each of the trace intervals. The main file server, "allspice", contained most of the files in the system. The workload comprised of OS researchers, architecture researchers, students and faculty working on VLSI design and parallel processing, and other miscellaneous people <ref> [4] </ref>. There are eight traces of day long interval each. We used the following four traces collected at allspice : 1. Jan 25 - 07:01 to 20:46 3. May 15 - 07:07 to 20:52 Each of the trace interval is 14 hrs. <p> With the process sizes having increased considerably <ref> [4] </ref> the virtual memory cache is a major contributor to the working set of the user. 3.3.1 Strategy for Measuring VM We had originally planned to modify the kernel of some of the workstations in order to trace the VM usage at the kernel level, however, due the unavailability of a <p> Except for trace 1, all other traces gradually drop in their memory usage. For upto 15 minutes of time-slot, we need less than 1.6 MB of memory. Trace 1 has anomolous behavior. We suspect that this is because trace 1 has a more small files <ref> [4] </ref> which are sequentially accessed than other traces and hence, trace 1 does not demonstrate good temporal locality. Also notice that the effect of the two users using large files has been filtered out by using the percentile (instead of average) as a statistical measure. <p> The file system cache measurement uses traces from the file system traces for the sprite file system taken by Baker et al. <ref> [4] </ref>. These traces were taken about three years ago. In such a long time it is plausible that the usage pattern of users would have changed. In fact Baker et. al. observed many changes in the file system usage since the BSD study made about five years eralier.
Reference: [5] <author> M. Dahlin, C. Mather, R. Wang, T. Anderson, D. Patterson, </author> <title> "A Quantitative Analysis of Cache Policies for Scalable Network File Systems," </title> <booktitle> Proceedings of 1994 SIGMETRICS, </booktitle> <pages> p 150-160, </pages> <month> May </month> <year> 1994 </year>
Reference-contexts: An analysis by Dahlin et al for network file systems shows that using client-to-client data transfer gives performance gains upto 40% as compared to using the disk. Using a hierarchy based on clusters can yield a further 50% gain <ref> [5] </ref>. Based on these ideas, a new file system called xFS has been designed for use in NOW [12].
Reference: [6] <author> M. Dahlin, R. Wang, T. Anderson, D. Patterson, </author> <title> "Cooperative Caching: Using Remote Client Memory to Improve File System Performance," </title> <booktitle> Proc. of the First Conference on Operating Systems Design and Implementation, </booktitle> <month> November </month> <year> 1994 </year>
Reference-contexts: The second choice was the Auspex traces which measure the requests on an NFS network. However, these traces do not include local accesses and we would have to make adjustments to our results to account for the missing accesses, as done in <ref> [6] </ref>. Thus, these results could be used for supporting some other measurements but it was not advisable to use them in isolation. The third option was to get traces ourselves. Since it was not possible for us to get permission to effectively do this, we had to drop this option.
Reference: [7] <author> P. Denning, </author> <title> "The Working Set Model for Program Behavior," </title> <journal> Communications of the ACM, </journal> <pages> pp 323-333, </pages> <month> May </month> <year> 1968 </year>
Reference-contexts: In 1968, Peter Denning defined the notion of working set as the set of pages recently referenced by a program <ref> [7] </ref>. Denning further examined some properties of working sets and suggested a mechanism for its implementation. In his later work, Denning refines the notion of a working set into a generalized working set using the concept of retention cost of a page calculated by its space-time product [8].
Reference: [8] <author> P. Denning, </author> <title> "Working Sets Past and Present," </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pp 64-84, </pages> <month> January </month> <year> 1980 </year> <month> 19 </month>
Reference-contexts: Denning further examined some properties of working sets and suggested a mechanism for its implementation. In his later work, Denning refines the notion of a working set into a generalized working set using the concept of retention cost of a page calculated by its space-time product <ref> [8] </ref>. In all these works a working set is defined in relation to a program.We use the notion of working set of a user as the set of pages recently referenced by a user.
Reference: [9] <author> J. Hartman, </author> <title> "Using the Sprite File System Traces," UC Berkeley CS internal report May 1993 </title>
Reference-contexts: Recall from the Sprite study that trace 2 corresponds to the case where two users were continuously accessing very large files. The trace file is organized as a file header followed by a sequence of records. A library is provided to use these trace files <ref> [9] </ref>. 5 3.2.2 Postprocessing The trace files were postprocessed as follows to get the desired measurements. In the first step, we isolated the open, lseek and close records from the traces files.
Reference: [10] <author> E. Johnson, </author> <title> "Working Set Prefetching for Cache Memories," </title> <booktitle> Computer Architecture News, </booktitle> <pages> pp 137-141, </pages> <month> December </month> <year> 1989 </year>
Reference-contexts: Implementations of memory management based on working set principle are typically based on providing enough memory to accommodate the working set of a program and using a suitable page-replacement algorithm like LRU, FIFO, etc. Another school of thought advocates compiler based working set calculations <ref> [10] </ref>. It should be noted that these mechanisms are ways of implementing the working set concept. The classical definition of a working set is independent of the implementation and we use 2 the classical definition to determine working sets of interactive users on workstations.
Reference: [11] <author> A. Mainwaring, C. Yoshikawa, K. Wright, </author> <title> "NOW White Paper: Network RAM Prototype," </title> <type> UC Berkeley CS internal report, </type> <month> November </month> <year> 1994 </year>
Reference-contexts: One of the key issues of Berkeley NOW project is to use network RAM as a system wide resource. The idea is to use idle memory on other clients in the cluster for paging and swapping <ref> [11] </ref>. The idea of using idle memory as another level in virtual memory hierarchy has been explored earlier. An analysis by Dahlin et al for network file systems shows that using client-to-client data transfer gives performance gains upto 40% as compared to using the disk.
Reference: [12] <author> R.Y. Wang, T. Anderson, "xFS: </author> <title> A Wide Area Mass Storage File System," </title> <booktitle> Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> p 71-78, </pages> <month> October </month> <year> 1993 </year> <month> 20 </month>
Reference-contexts: Using a hierarchy based on clusters can yield a further 50% gain [5]. Based on these ideas, a new file system called xFS has been designed for use in NOW <ref> [12] </ref>. In contrast to the problem addressed above is what to do with the contents of the local memory of an idle interactive user when a new non-interactive application is migrated to the idle workstation. The currently proposed solution advocates use of NRAM for paging out the local RAM.
References-found: 12

