URL: http://www.aic.nrl.navy.mil/papers/1996/AIC-96-024.ps
Refering-URL: http://www.aic.nrl.navy.mil/~aha/pub-details.html
Root-URL: 
Email: aha@aic.nrl.navy.mil  bankert@nrlmry.navy.mil  
Title: Cloud Classification Using Error-Correcting Output Codes  
Author: David W. Aha Richard L. Bankert 
Note: Submission to AI Applications: Natural Resources, Agriculture, and Environmental Science. Corresponding author: The first author is the corresponding author for this submission. David's phone number is (202) 767-9006 and FAX number is (202) 767-3172. Suggested running head: "Cloud Classification Using Error-Correcting Output Codes" Available as NCARAI Technical Note AIC-96-024  
Date: October 30, 1996  
Address: Washington, DC 20375  Monterey, CA 93943  
Affiliation: Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory  Marine Meteorology Division Naval Research Laboratory  
Abstract-found: 0
Intro-found: 1
Reference: <author> Aha, D. W. </author> <year> 1989. </year> <title> Incremental, instance-based learning of independent and graded concept descriptions. </title> <booktitle> Pages 387-391 in: Proceedings, Sixth International Workshop on Machine Learning, </booktitle> <address> Ithaca, New York, July 1989. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: For example, this corresponds to using the bit string "100" for cases in the Earthling class in the first entry of Table 2. For many learning algorithms, such as those that induce decision tree (Quinlan 1993a) or k-nearest neighbor classifiers <ref> (Aha 1989) </ref>, one-per-class encoding is done by generating one concept description per class.
Reference: <author> Aha, D. W., and R. L. Bankert. </author> <year> 1994. </year> <title> Feature selection for case-based classification of cloud types: An empirical comparison. Pages 106-112 in: Case-Based Reasoning: </title> <note> Papers from the 1994 Workshop (Technical Report WS-94-01), </note> <editor> D. W. Aha, editor. </editor> <publisher> AAAI Press, </publisher> <address> Menlo Park, California. </address>
Reference-contexts: Although this FSA dramatically reduced the number of features used, reduced processing times correspondingly, and increased classification accuracy by 4.5% (i.e., compared with using all 204 features), it is not obvious whether enhanced performance can be obtained by using more sophisticated FSAs. Thus, we evaluated <ref> (Aha and Bankert 1994, 1996) </ref> a novel beam-search extension for sequential selection on this cloud classification task, coupled with a different evaluation function for feature subsets.
Reference: <author> Aha, D. W., and R. L. Bankert. </author> <year> 1996. </year> <title> A comparative evaluation of sequential feature selection algorithms. To appear in: </title> <booktitle> Artificial Intelligence and Statistics V, </booktitle> <editor> D. Fisher and J.-H. Lenz, editors. </editor> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: 1 Introduction Several types of algorithms have been evaluated for their utility on various cloud classification tasks, including neural networks (Welch et al. 1992), Bayesian approaches (Bankert 1994), and k-nearest neighbor algorithms <ref> (Aha and Bankert 1996) </ref>. A frequent goal of classification algorithms in the context of environmental science applications is to maximize accuracy when predicting classifications for previously unseen query samples. Thus, several innovative methods have been evaluated for their ability to enhance accuracy (e.g., clustering hierarchical neural networks (Welch 1996)). <p> IB1's 10-fold accuracy using all 204 features is 72.6%, which is similar to PNN's accuracy. BEAM, using FSS to select feature subsets, located a subset of only eleven features that increase IB1's accuracy to 87.0%. This accuracy was the highest we found while working with this data set <ref> (Bankert and Aha 1996) </ref>. 4 An analysis of the remaining errors lead us to question whether further improvements were possible. We found that three of the 45 pairs of classes were responsible for 42.3% of the (remaining) classification errors. <p> We introduce and describe how to use ECOCs in classification tasks in Section 3. 4 We reported similar results for a cloud system (e.g., fronts, tropical cyclones) classification task <ref> (Aha and Bankert 1996) </ref>, where a variant of BEAM located a feature subset that increased LOOCV from 62.3% to 95.7% while reducing the set of features from 98 to 16. 6 Table 2: Output representations for a hypothetical set of three classes Class Output Representation Name Monolithic Distributed One-Per-Class Error-Correcting (ECOC)
Reference: <author> Aha, D. W., D. Kibler, and M. K. Albert. </author> <year> 1991. </year> <title> Instance-based learning algorithms. </title> <booktitle> Machine Learning 6: </booktitle> <pages> 37-66. </pages>
Reference-contexts: By using the same algorithm for both tasks, we avoid this conflict. We used a variant of the nearest neighbor classifier, named IB1 <ref> (Aha et al. 1991) </ref>, rather than PNN to evaluate feature subsets because, unlike PNN (which has a user-defined parameter) or backpropagation (which has many tunable parameters), IB1 does not require users or automated strategies to set parameter values.
Reference: <author> Bankert, R. L. </author> <year> 1994. </year> <title> Cloud classification of AVHRR imagery in maritime regions using a probabilistic neural network. </title> <journal> Journal of Applied Meteorology 33: </journal> <pages> 909-918. </pages>
Reference-contexts: 1 Introduction Several types of algorithms have been evaluated for their utility on various cloud classification tasks, including neural networks (Welch et al. 1992), Bayesian approaches <ref> (Bankert 1994) </ref>, and k-nearest neighbor algorithms (Aha and Bankert 1996). A frequent goal of classification algorithms in the context of environmental science applications is to maximize accuracy when predicting classifications for previously unseen query samples. <p> prediction (Peak and Tag 1989)), SIAMES (a satellite image analysis meteorological expert system (Fett et al. 1997)), ExperCAT (a clear air turbulence expert system (Ellrod et al. 1993)), and MEDEX (an expert system for forecasting Mediterranean gale force winds (Kuciauskus et al. 1996)), as well as classifiers of cloud types <ref> (Bankert 1994) </ref> and cloud systems (Bankert and Tag 1996) in satellite imagery. With satellite imagery being a primary (and sometimes only) source of observational data for remote maritime regions, automated identification of cloud types within those images would be a useful tool for the operational forecaster. <p> Although this FSA dramatically reduced the number of features used, reduced processing times correspondingly, and increased classification accuracy by 4.5% (i.e., compared with using all 204 features), it is not obvious whether enhanced performance can be obtained by using more sophisticated FSAs. Thus, we evaluated <ref> (Aha and Bankert 1994, 1996) </ref> a novel beam-search extension for sequential selection on this cloud classification task, coupled with a different evaluation function for feature subsets. <p> However, this would greatly complicate the training and testing processes. Moreover, our preliminary attempts at using a cascading approach have not been promising <ref> (Bankert 1994) </ref>. While ECOCs can increase classification accuracy, they have two primary drawbacks. First, unlike the one-per-class approach, the output node functions no longer correspond to unique classes. Instead, output bits are functions that partition classes into (almost) arbitrary groupings. Thus, this limitation causes a loss of comprehensibility.
Reference: <author> Bankert, R. L., and D. W. Aha. </author> <year> 1996. </year> <title> Improvement to a neural network cloud classifier. </title> <booktitle> Applied Meteorology 35: </booktitle> <pages> 2036-2039. </pages> <note> 21 Bankert, </note> <author> R. L. and P. M. Tag. </author> <year> 1996. </year> <title> Automated extraction and identification of cloud systems in satellite imagery. </title> <booktitle> Pages 373-376 in: Proceedings, Eighth Conference on Satellite Meteorology and Oceanography. </booktitle> <publisher> American Meteorological Society, </publisher> <address> Atlanta, Georgia. </address>
Reference-contexts: 1 Introduction Several types of algorithms have been evaluated for their utility on various cloud classification tasks, including neural networks (Welch et al. 1992), Bayesian approaches (Bankert 1994), and k-nearest neighbor algorithms <ref> (Aha and Bankert 1996) </ref>. A frequent goal of classification algorithms in the context of environmental science applications is to maximize accuracy when predicting classifications for previously unseen query samples. Thus, several innovative methods have been evaluated for their ability to enhance accuracy (e.g., clustering hierarchical neural networks (Welch 1996)). <p> SIAMES (a satellite image analysis meteorological expert system (Fett et al. 1997)), ExperCAT (a clear air turbulence expert system (Ellrod et al. 1993)), and MEDEX (an expert system for forecasting Mediterranean gale force winds (Kuciauskus et al. 1996)), as well as classifiers of cloud types (Bankert 1994) and cloud systems <ref> (Bankert and Tag 1996) </ref> in satellite imagery. With satellite imagery being a primary (and sometimes only) source of observational data for remote maritime regions, automated identification of cloud types within those images would be a useful tool for the operational forecaster. <p> IB1's 10-fold accuracy using all 204 features is 72.6%, which is similar to PNN's accuracy. BEAM, using FSS to select feature subsets, located a subset of only eleven features that increase IB1's accuracy to 87.0%. This accuracy was the highest we found while working with this data set <ref> (Bankert and Aha 1996) </ref>. 4 An analysis of the remaining errors lead us to question whether further improvements were possible. We found that three of the 45 pairs of classes were responsible for 42.3% of the (remaining) classification errors. <p> We introduce and describe how to use ECOCs in classification tasks in Section 3. 4 We reported similar results for a cloud system (e.g., fronts, tropical cyclones) classification task <ref> (Aha and Bankert 1996) </ref>, where a variant of BEAM located a feature subset that increased LOOCV from 62.3% to 95.7% while reducing the set of features from 98 to 16. 6 Table 2: Output representations for a hypothetical set of three classes Class Output Representation Name Monolithic Distributed One-Per-Class Error-Correcting (ECOC)
Reference: <author> Bankman, I. N., and D. W. Aha. </author> <year> 1992. </year> <title> Fast learning in feedforward neural networks by migrating hidden unit outputs. </title> <booktitle> Pages 179-184 in: Intelligent Engineering Systems Through Artificial Neural Networks, </booktitle> <volume> Volume II, </volume> <editor> C. H. Dagli, editor. </editor> <publisher> ASME Press, </publisher> <address> St. Louis, Missouri. </address>
Reference-contexts: This can be expensive for some algorithms. For example, backpropagation's training complexity is O (mn 2 ), where m is the number of training samples and n is the maximum number of nodes at any layer <ref> (Bankman and Aha 1992) </ref>. Thus, increases in the number of output nodes 19 can cause greater than linear increases in the training time.
Reference: <editor> Birnbaum, L. A., and G. C. Collins, editors. </editor> <booktitle> 1991. Proceedings, Eighth International Workshop on Machine Learning, </booktitle> <address> Evanston, Illinois, June 1991. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: Several similar methods, for use with either numeric or symbolic features, have been developed to automatically modify the representations of samples (e.g., Mohri and Tanaka 1994, Rendell and Seshu 1990) with the intent of increasing accuracy. This topic is often referred to as constructive induction by machine learning researchers <ref> (Birnbaum and Collins 1991) </ref>. Although these methods re-represent samples, they do not re-represent the class labels associated with them. Recently, Dietterich and Bakiri (1991, 1995) introduced a technique that re-represents samples' class labels using error-correcting output codes (ECOCs).
Reference: <author> Breiman, L. </author> <year> 1994. </year> <type> Bagging predictors (Technical Report 421). </type> <institution> University of California, Department of Statistics, Berkeley, California. </institution>
Reference-contexts: As Kong and Dietterich (1995) explain, several algorithms reduce only errors caused by variance. These algorithms generate multiple hypotheses (e.g., by using different initial random weights in a neural network or different training sets to induce multiple decision trees or rule sets) and then vote among these hypotheses <ref> (Perrone 1994, Breiman 1994) </ref>. They cannot reduce bias errors because the predictions among the multiple hypotheses are correlated.
Reference: <author> Clemen, R. T. </author> <year> 1989. </year> <title> Combining forecasts: A review and annotated bibliography. </title> <journal> International Journal of Forecasting 5: </journal> <pages> 559-583. </pages>
Reference-contexts: They cannot reduce bias errors because the predictions among the multiple hypotheses are correlated. However, both variance and bias errors can be reduced by voting among multiple hypotheses produced by different learning algorithms applied to the same problem, assuming the bias errors differ among the different algorithms <ref> (Clemen 1989, Makridakis and Winkler 1983, Quinlan 1993b) </ref>. Error correcting output codes also reduce variance and bias errors, but with a different form of voting (i.e., computing Hamming distance between the prediction and the codewords of each class).
Reference: <author> Crosiar, C. L. </author> <year> 1993. </year> <title> An AVHRR cloud classification database typed by experts (Technical Report NRL/MR/7531-93-7207). </title> <institution> Naval Research Laboratory, Prediction Systems Branch, Marine Meteorology Division, Monterey, California. </institution>
Reference-contexts: Images were taken from various maritime regions throughout the Northern Hemisphere during a one-year period beginning in October, 1988. Adding to an initial collection of 610 samples labeled by experts at the Naval Postgraduate School, four experts independently labeled samples <ref> (Crosiar 1993) </ref> as one of nine cloud types, "clear" (see Table 1), or mixed clouds using image-displaying software. 2 Bankert then selected the subset of these 3625 cloud type samples for which there was a majority agreement (i.e., at least three of the four experts labelled it with the same class),
Reference: <author> Devijver, P. A., and J. Kittler. </author> <year> 1982. </year> <title> Pattern recognition: A statistical approach. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey. </address>
Reference-contexts: Since the space of feature subsets (i.e., the power set of all features) for this task is huge (2 204 2:6 fi 10 61 ), Bankert (1994) selected a computationally inexpensive FSA named forward sequential selection (FSS) <ref> (Devijver and Kittler 1982) </ref> to search for feature subsets. It starts by locating the singleton subset of features that has highest accuracy and then adds the feature that maximizes accuracy. This process iterates with additional features until no accuracy improvements occur during an iteration.
Reference: <author> Dietterich, T. G., and G. Bakiri. </author> <year> 1991. </year> <title> Error-correcting output codes: A general method for improving multiclass inductive learning programs. </title> <booktitle> Pages 572-577 in: Proceedings, Ninth National Conference on Artificial Intelligence, </booktitle> <address> Anaheim, California, August 1991. </address> <publisher> AAAI Press, </publisher> <address> Menlo Park, California. </address>
Reference: <author> Dietterich, T. G., and G. Bakiri. </author> <year> 1995. </year> <title> Solving multiclass learning problems via error-correcting output codes. </title> <journal> Journal of Artificial Intelligence Research 2: </journal> <pages> 263-286. </pages>
Reference-contexts: This causes a conflict: ECOCs usually do not work well in conjunction with local classifiers because local learning algorithms cannot correct errors caused by learning biases (i.e., their classification errors are correlated) <ref> (Kong and Dietterich 1995) </ref>.
Reference: <author> Ellrod, G. P., J. M. Peak, and R. L. Bankert. </author> <year> 1993. </year> <title> An expert system for the analysis of high altitude turbulence. </title> <booktitle> Pages 617-620 in: Proceedings, Thirteenth Conference on Weather Analysis and Forecasting. </booktitle> <publisher> American Meteorological Society, </publisher> <address> Vienna, Virginia. </address>
Reference-contexts: Tools developed or being developed at MMD that use AI include AESOP (an expert system for shipboard obscuration prediction (Peak and Tag 1989)), SIAMES (a satellite image analysis meteorological expert system (Fett et al. 1997)), ExperCAT (a clear air turbulence expert system <ref> (Ellrod et al. 1993) </ref>), and MEDEX (an expert system for forecasting Mediterranean gale force winds (Kuciauskus et al. 1996)), as well as classifiers of cloud types (Bankert 1994) and cloud systems (Bankert and Tag 1996) in satellite imagery.
Reference: <author> Fett, R. W., M. E. White, J. E. Peak, S. Brand, and P. M. Tag. </author> <year> 1997. </year> <title> Application of hypermedia and expert system technology to navy environmental satellite image analysis. </title> <journal> Accepted for publication in Bulletin of the American Meteorological Society. </journal>
Reference-contexts: Tools developed or being developed at MMD that use AI include AESOP (an expert system for shipboard obscuration prediction (Peak and Tag 1989)), SIAMES (a satellite image analysis meteorological expert system <ref> (Fett et al. 1997) </ref>), ExperCAT (a clear air turbulence expert system (Ellrod et al. 1993)), and MEDEX (an expert system for forecasting Mediterranean gale force winds (Kuciauskus et al. 1996)), as well as classifiers of cloud types (Bankert 1994) and cloud systems (Bankert and Tag 1996) in satellite imagery.
Reference: <author> Fu, K. S. </author> <year> 1968. </year> <title> Sequential methods in pattern recognition and machine learning. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: Towards this goal, he used a feature selection algorithm (FSA) to preprocess the training data. Given a (usually large) set of features, an FSA searches for subsets that improve performance (e.g., classification accuracy) on a given task <ref> (Fu 1968) </ref>. Since the space of feature subsets (i.e., the power set of all features) for this task is huge (2 204 2:6 fi 10 61 ), Bankert (1994) selected a computationally inexpensive FSA named forward sequential selection (FSS) (Devijver and Kittler 1982) to search for feature subsets.
Reference: <author> John, G., R. Kohavi, and K. Pfleger. </author> <year> 1994. </year> <title> Irrelevant features and the subset selection problem. </title> <booktitle> Pages 121-129 in: Proceedings, Eleventh International Machine Learning Conference, </booktitle> <address> New Brunswick, New Jersey, August 1994. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: The subset with the highest classification accuracy is chosen. We also changed the way in which feature subsets were evaluated. Rather than use a clustering algorithm (e.g., the Bhattacharya index measure), we instead used the classifier itself to evaluate feature subsets <ref> (John et al. 1994) </ref>. In this way, the classifier can provide feedback to the feature subset evaluation routine, and this practice can prevent a mismatch in the preference rankings between the subset evaluator and the classifier.
Reference: <author> Kong, E. B., and T. G. Dietterich. </author> <year> 1995. </year> <title> Error-correcting output coding corrects bias and variance. </title> <booktitle> Pages 313-321 in: Proceedings, Twelfth International Conference on Machine Learning, </booktitle> <address> Tahoe City, California, July 1995. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address> <note> 22 Kuciauskas, </note> <author> A. P., L. R. Brody, R. L. Bankert, P. M. Tag, and M. Hadjimichael. </author> <year> 1996. </year> <title> Automated forecasting of gale force winds in the mediterranean region. </title> <booktitle> Pages 385-361 in: Proceedings, Fifteenth Conference on Weather Analysis and Forecasting. </booktitle> <publisher> American Meteorological Society, </publisher> <address> Norfolk, Virginia. </address>
Reference-contexts: This causes a conflict: ECOCs usually do not work well in conjunction with local classifiers because local learning algorithms cannot correct errors caused by learning biases (i.e., their classification errors are correlated) <ref> (Kong and Dietterich 1995) </ref>.
Reference: <author> Makridakis, S., and R. L. Winkler. </author> <year> 1983. </year> <title> Averages of forecasts: Some empirical results. </title> <booktitle> Management Science 29(9): </booktitle> <pages> 987-996. </pages>
Reference: <author> Mohri, T., and H. Tanaka. </author> <year> 1994. </year> <title> An optimal weighting criterion of case indexing for both numeric and symbolic attributes. Pages 123-127 in: Case-Based Reasoning: </title> <note> Papers from the 1994 Workshop (Technical Report WS-94-01), </note> <editor> D. W. Aha, editor. </editor> <publisher> AAAI Press, </publisher> <address> Menlo Park, California. </address>
Reference-contexts: Several similar methods, for use with either numeric or symbolic features, have been developed to automatically modify the representations of samples <ref> (e.g., Mohri and Tanaka 1994, Rendell and Seshu 1990) </ref> with the intent of increasing accuracy. This topic is often referred to as constructive induction by machine learning researchers (Birnbaum and Collins 1991). Although these methods re-represent samples, they do not re-represent the class labels associated with them.
Reference: <author> Peak, J. E., and P. M. Tag. </author> <year> 1989. </year> <title> An expert system approach for prediction of maritime visibility obscuration. </title> <journal> Monthly Weather Review 117: </journal> <pages> 2641-2653. </pages>
Reference-contexts: One of their objectives is to create shipboard decision aid tools for assisting US Navy personnel in various meteorological analysis and prediction tasks. Tools developed or being developed at MMD that use AI include AESOP (an expert system for shipboard obscuration prediction <ref> (Peak and Tag 1989) </ref>), SIAMES (a satellite image analysis meteorological expert system (Fett et al. 1997)), ExperCAT (a clear air turbulence expert system (Ellrod et al. 1993)), and MEDEX (an expert system for forecasting Mediterranean gale force winds (Kuciauskus et al. 1996)), as well as classifiers of cloud types (Bankert 1994)
Reference: <author> Perrone, M. P. </author> <year> 1994. </year> <title> Putting it all together: Methods for combining neural networks. </title> <booktitle> Pages 1188-1190 in: Advances in Neural Information Processing Systems, </booktitle> <volume> 6, </volume> <editor> J. D. Cowan, G. Tesauro, and J. Alspector, editors. </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: As Kong and Dietterich (1995) explain, several algorithms reduce only errors caused by variance. These algorithms generate multiple hypotheses (e.g., by using different initial random weights in a neural network or different training sets to induce multiple decision trees or rule sets) and then vote among these hypotheses <ref> (Perrone 1994, Breiman 1994) </ref>. They cannot reduce bias errors because the predictions among the multiple hypotheses are correlated.
Reference: <author> Perrone, M. P., and L. N. Cooper. </author> <year> 1993. </year> <title> When networks disagree: Ensemble methods for hybrid neural networks. In Neural Networks for Speech and Image Processing, </title> <editor> R. J. Mammone, editor. </editor> <publisher> Chapman and Hall, </publisher> <address> Philadelphia, Pennsylvania. </address>
Reference-contexts: These errors can be reduced by averaging the contributions of multiple predictions during a single prediction task, such as by voting among multiple runs of the same algorithm <ref> (Perrone and Cooper 1993, Breiman 1994) </ref>. This also occurs when using ECOCs because a vote (among predictions for the different output bits) takes place when selecting the nearest codeword, as computed by predicting the class whose codeword has the smallest Hamming distance.
Reference: <author> Quinlan, J. R. </author> <year> 1993a. </year> <title> C4.5: Programs for machine learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: Learning algorithms that use this approach induce a single concept description that distinguishes all class boundaries. For example, C4.5 <ref> (Quinlan 1993a) </ref> uses this approach; given a training set, C4.5 induces a decision tree where classification judgements are made at the leaves. <p> That is, it involves learning a separate binary function for each class. For example, this corresponds to using the bit string "100" for cases in the Earthling class in the first entry of Table 2. For many learning algorithms, such as those that induce decision tree <ref> (Quinlan 1993a) </ref> or k-nearest neighbor classifiers (Aha 1989), one-per-class encoding is done by generating one concept description per class. <p> Dietterich and Bakiri (1991, 1995) introduced the use of ECOCs for multiclass classification tasks. They detailed experiments showing that, versus other multiclass approaches, ECOCs can improve the classification accuracy of C4.5 <ref> (Quinlan 1993a) </ref> and a multilayer connectionist network trained by backpropagation (Rumelhart et al. 1986) on a set of multiclass tasks, although ECOCs are slower because they involve learning a function for each output bit (i.e., as opposed to learning a single, albeit multiclass, function).
Reference: <author> Quinlan, J. R. </author> <year> 1993b. </year> <title> Combining instance-based learning and model-based learning. </title> <booktitle> Pages 236-243 in: Proceedings, Tenth International Conference on Machine Learning, </booktitle> <address> Amherst, Massachusetts, July 1993. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference: <author> Rendell, L., and R. Seshu. </author> <year> 1990. </year> <title> Learning hard concepts through constructive induction: Framework and rationale. </title> <booktitle> Computational Intelligence 6: </booktitle> <pages> 247-270. </pages>
Reference: <author> Rumelhart, D. E., G. E. Hinton, and R. J. Williams. </author> <year> 1986. </year> <title> Learning internal representations by error propagation. Pages 318-362 in: Parallel Distributed Processing: Explorations in the Microstructures of Cognition, </title> <editor> D. E. Rumelhart and J. L. McClelland, editors. </editor> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: Dietterich and Bakiri showed that, for some multiclass (i.e., more than two classes) classification tasks, ECOCs can significantly increase classification accuracy for both decision tree induction algorithms and neural networks trained using the error backpropagation algorithm <ref> (Rumelhart et al. 1986) </ref>, although with substantially greater computational costs. These two algorithms both generate nonlocal classifiers, which generate class predictions using all information in the set of training samples rather than only information local to the query sample. <p> This strategy classifies a new sample according to the class of the tree with the highest confidence. For backpropagation-trained networks <ref> (Rumelhart et al. 1986) </ref>, this representation instead uses n output nodes (i.e., one per class), and the classifier predicts the class corresponding to the output node with highest activation (i.e., a winner-take-all network). <p> Dietterich and Bakiri (1991, 1995) introduced the use of ECOCs for multiclass classification tasks. They detailed experiments showing that, versus other multiclass approaches, ECOCs can improve the classification accuracy of C4.5 (Quinlan 1993a) and a multilayer connectionist network trained by backpropagation <ref> (Rumelhart et al. 1986) </ref> on a set of multiclass tasks, although ECOCs are slower because they involve learning a function for each output bit (i.e., as opposed to learning a single, albeit multiclass, function).
Reference: <author> Sejnowski, T. J., and C. R. Rosenberg. </author> <year> 1987. </year> <title> Parallel networks that learn to pronounce English text. </title> <booktitle> Complex Systems 1: </booktitle> <pages> 145-168. </pages>
Reference-contexts: For example, they can instead assign a set of log n nodes to represent the n classes, or use some other pre-determined number of bits to define codeword length <ref> (Sejnowski and Rosenberg 1987) </ref>. Class encodings can be carefully designed with specific distinguishing properties. ECOCs are examples of this approach: they are not restricted to having exactly n output bits and their codewords can have multiple output bits that are "on" (corresponding to values of 1).
Reference: <author> Specht, D. F. </author> <year> 1990. </year> <title> Probabilistic neural networks. </title> <booktitle> Neural Networks 3: </booktitle> <pages> 109-118. </pages>
Reference-contexts: It ranks subsets based on their ability to cluster samples by their class. FSS, a deterministic algorithm in this context, selected only 15 of the 204 features. Bankert tested both the entire feature set and the selected subset on this data set using a probabilistic neural network (PNN) classifier <ref> (Specht 1990) </ref>. PNN was chosen because it performed well on similar tasks (Welch et al. 1992). It uses a standard three-layer network of nodes and a Bayesian classification strategy to select the class with the highest value of the a posteriori class probability density function.
Reference: <author> Welch, R. M. </author> <year> 1996. </year> <title> Hierarchical neural networks with don't care nodes. </title> <booktitle> Presentation at the Artificial Intelligence esearch in Environmental Sciences Workshop, </booktitle> <address> Wakefield, assachusetts, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: A frequent goal of classification algorithms in the context of environmental science applications is to maximize accuracy when predicting classifications for previously unseen query samples. Thus, several innovative methods have been evaluated for their ability to enhance accuracy (e.g., clustering hierarchical neural networks <ref> (Welch 1996) </ref>). One general way to increase accuracy involves re-representing samples so that their classes can be more easily distinguished.
Reference: <author> Welch, R. M., S. K. Sengupta, A. K. Goroch, P. Rabindra, N. Rangaraj, and M. S. Navar. </author> <year> 1992. </year> <title> Polar cloud and surface classification using AVHRR imagery: An intercomparison of methods. </title> <journal> Journal of Applied Meteorology 31: </journal> <pages> 405-420. </pages> <note> 23 Wettschereck, </note> <author> D., and T. G. Dietterich. </author> <year> 1992. </year> <title> Improving the performance of radial basis function networks by learning center locations. </title> <booktitle> Pages 1133-1140 in: Neural Information Processing Systems 4, </booktitle> <editor> J. Moody, S. Hanson, and R. Lippmann, editors. </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: 1 Introduction Several types of algorithms have been evaluated for their utility on various cloud classification tasks, including neural networks <ref> (Welch et al. 1992) </ref>, Bayesian approaches (Bankert 1994), and k-nearest neighbor algorithms (Aha and Bankert 1996). A frequent goal of classification algorithms in the context of environmental science applications is to maximize accuracy when predicting classifications for previously unseen query samples. <p> FSS, a deterministic algorithm in this context, selected only 15 of the 204 features. Bankert tested both the entire feature set and the selected subset on this data set using a probabilistic neural network (PNN) classifier (Specht 1990). PNN was chosen because it performed well on similar tasks <ref> (Welch et al. 1992) </ref>. It uses a standard three-layer network of nodes and a Bayesian classification strategy to select the class with the highest value of the a posteriori class probability density function.

Reference: <author> Richard L. </author> <title> Bankert (Penn State, 1988) joined the Marine Meteorology Division of the Naval Research Laboratory in 1990 (then called the Naval Oceanographic and Atmospheric Research Laboratory). His research interests include the application of a variety of artificial intelligence techniques to meteorological and other environmental science problems. He has previously served on the AIRIES committee (1992) and is currently on the American Meteorological Society's Science and Technological Activities Committee on AI Applications to Environmental Science. </title> <type> 24 </type>
References-found: 33

