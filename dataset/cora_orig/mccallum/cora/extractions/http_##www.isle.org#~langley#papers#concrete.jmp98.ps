URL: http://www.isle.org/~langley/papers/concrete.jmp98.ps
Refering-URL: http://www.isle.org/~langley/psych.html
Root-URL: 
Email: (langley@isle.org)  
Title: Computational Learning in Humans and Machines  
Author: Pat Langley and 
Address: 2164 Staunton Court, Palo Alto, CA 94306  1510 Page Mill Rd., Palo Alto, CA 94304  
Affiliation: Institute for the Study of Learning and Expertise  Daimler-Benz Research and Technology Center  
Abstract: In this paper we review research on machine learning and its relation to computational models of human learning. We focus initially on concept induction, examining five main approaches to this problem, then consider the more complex issue of learning sequential behaviors. After this, we compare the rhetoric that sometimes appears in the machine learning and psychological literature with the growing evidence that different theoretical paradigms typically produce similar results. In response, we suggest that concrete computational models, which currently dominate the field, may be less useful than simulations that operate at a more abstract level. We illustrate this point with an abstract simulation that explains a challenging phenomenon in the area of category learning, and we conclude with some general observations about such abstract models. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., Kibler, D., & Albert, M. K. </author> <year> (1991). </year> <title> Instance-based learning algorithms. </title> <booktitle> Machine Learning, </booktitle> <pages> 6 , 37-66. </pages>
Reference: <author> Anderson, J. R., & Kline, P. J. </author> <year> (1979). </year> <title> A learning system and its psychological implications. </title> <booktitle> Proceedings of the Sixth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 16-21). </pages> <address> Tokyo, Japan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Learning in Humans and Machines 2 classes in the remaining data. Clark and Niblett (1989) describe two such separate-and-conquer methods, which are also known as covering algorithms. These techniques bear a close relation to production-system models of human category learning <ref> (e.g., Anderson & Kline, 1979) </ref>. A second framework represents category knowledge as a decision tree or concept hierarchy. Each node in a decision tree specifies some attribute or test, with branches corresponding to alternative outcomes, except for terminal nodes, which indicate category or class labels.
Reference: <author> Anderson, J. R. </author> <year> (1991). </year> <title> The adaptive character of thought. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Atkeson, C. G., Moore, A. W., & Schaal, S. </author> <year> (1997). </year> <title> Locally weighted learning for control. </title> <journal> Artificial Intelligence Review , 11 , 75-113. </journal>
Reference-contexts: Research on reinforcement learning often invokes neural network methods to induce mappings from state-action pairs onto expected values (Sutton & Barto, 1998), but nearest neighbor techniques have also been used to this end <ref> (e.g., Atkeson, Moore, & Schaal, 1997) </ref>. Research on analogical reasoning typically draws on case-based methods, adapted to first-order representations, that use structures akin to macro-operators in a flexible way for solving new problems (e.g., Veloso & Carbonell, 1993).
Reference: <author> Billman, D., & Davila, D. </author> <year> (1995). </year> <title> Consistency is the hobgoblin of human minds: People care but concept learning models do not. </title> <booktitle> Proceedings of the Seventeenth Conference of the Cognitive Science Society (pp. </booktitle> <pages> 188-193). </pages> <institution> Pittsburgh: Lawrence Erlbaum. </institution> <note> Learning in Humans and Machines 12 Chapman, </note> <author> D., & Kaelbling, L. P. </author> <year> (1991). </year> <title> Input generalization in delayed reinforcement learning: An algorithm and performance comparisons. </title> <booktitle> Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 726-731). </pages> <address> Sydney, Australia: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <booktitle> Machine Learning, </booktitle> <pages> 3 , 261-284. </pages>
Reference: <author> Fisher, D. H. </author> <year> (1987). </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <booktitle> Machine Learning, </booktitle> <pages> 2 , 139-172. </pages>
Reference-contexts: Learning involves the simple process of using training cases to update class and conditional probabilities. More sophisticated variants store information about correlations among the predictive variables (Suppes & Liang, 1996), organize naive classifiers into a concept hierarchy <ref> (Fisher, 1987) </ref>, or induce Bayesian networks that specify violations of conditional independence. Methods for inducing probabilistic descriptions have also been proposed as models of human category formation (e.g., Anderson, 1991; Fisher & Langley, 1990). Machine Learning of Sequential Behaviors Certainly, cognition involves much more than assigning stimuli to categories.
Reference: <author> Fisher, D. H., & Langley, P. </author> <year> (1990). </year> <title> The structure and formation of natural categories. </title> <editor> In G. H. Bower (Ed.), </editor> <booktitle> The psychology of learning and motivation: Advances in research and theory (Vol. 26). </booktitle> <address> Cambridge, MA: </address> <publisher> Academic Press. </publisher>
Reference: <author> Fisher, D., & McKusick, K. B. </author> <year> (1989). </year> <title> An empirical comparison of ID3 and back-propagation. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 788-793). </pages> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Iba, G. A. </author> <year> (1989). </year> <title> A heuristic approach to the discovery of macro-operators. </title> <booktitle> Machine Learning, </booktitle> <pages> 3 , 285-317. </pages>
Reference-contexts: A third generic approach to sequential learning relies on the creation of larger-scale knowledge structures from smaller components. Within the problem-space framework, this often involves constructing macro-operators that take many steps in the problem space rather than one step at a time <ref> (e.g., Iba, 1989) </ref>. Researchers often implement this idea as a logical composition of production rules in a manner that guarantees the composite rule has the same effect as applying the component rules in sequence, based on traces of these rules that achieved some goal (e.g., Neves & Anderson, 1981). <p> The key idea in their model is that humans acquire chunks that let them link complex perceptual configurations to complex actions, thus reducing the need to carry out multiple reasoning steps at the cognitive level. The chunking process is related to techniques for constructing macro-operators <ref> (e.g., Iba, 1989) </ref> in machine learning.
Reference: <author> Jones, R., & Langley, P. </author> <year> (1995). </year> <title> Retrieval and learning in analogical problem solving. </title> <booktitle> Proceedings of the Seventeenth Conference of the Cognitive Science Society (pp. </booktitle> <pages> 466-471). </pages> <address> Pittsburgh: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Jones, R. M., & VanLehn, K. </author> <year> (1994). </year> <title> Acquisition of children's addition strategies: A model of impasse-free, knowledge-level learning. </title> <booktitle> Machine Learning, </booktitle> <pages> 16 , 11-36. </pages>
Reference: <author> Kruschke, J. K. </author> <year> (1992). </year> <title> Alcove: An exemplar-based connectionist model of category learning. </title> <type> Psychological Review , 99 , 22-44. </type>
Reference: <author> Langley, P. </author> <year> (1996). </year> <title> An abstract computational model of learning selective sensing skills. </title> <booktitle> Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 385-390). </pages> <address> San Diego: </address> <publisher> Lawrence Erlbaum Publishers. </publisher>
Reference: <author> Langley, P., Iba, W., & Thompson, K. </author> <year> (1992). </year> <title> An analysis of Bayesian classifiers. </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 223-228). </pages> <address> San Jose, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Langley, P., Provan, G. M., & Smyth, P. </author> <year> (1997). </year> <title> Learning with probabilistic representations. </title> <booktitle> Machine Learning, </booktitle> <pages> 29 , 91-101. </pages>
Reference-contexts: Aha, Kibler, and Albert (1991) report a number of approaches to instance-based learning, which are typically referred to as exemplar models (Smith & Medin, 1981) in the psychological literature. A final paradigm encodes knowledge as probabilistic descriptions of categories <ref> (Langley, Provan, & Smyth, 1997) </ref>. The simplest version of this approach, known as the naive Bayesian classifier , stores the probability of each class and the conditional probability of each attribute-value pair given Learning in Humans and Machines 3 the class.
Reference: <author> Langley, P., & Simon, H. A. </author> <year> (1995). </year> <title> Applications of machine learning and rule induction. </title> <journal> Communications of the ACM , 38 , November, </journal> <pages> 55-64. </pages>
Reference: <author> Martin, J., & Billman, D. </author> <year> (1991). </year> <title> Variability bias and category learning. </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 90-94). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Mooney, R., Shavlik, S., Towell, G., & Gove, A. </author> <year> (1989). </year> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 775-780). </pages> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Newell, A. </author> <year> (1990). </year> <title> Unified theories of cognition. </title> <address> Cambridge, MA: </address> <institution> Harvard University Press. </institution> <note> Learning in Humans and Machines 13 Neves, </note> <author> D. M., & Anderson, J. R. </author> <year> (1981). </year> <title> Knowledge compilation: Mechanisms for the automatization of cognitive skills. </title> <editor> In J. R. Anderson (Ed.), </editor> <title> Cognitive skills and their acquisition. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Ohlsson, S., & Jewett, J. J. </author> <year> (1995). </year> <title> Abstract computer models: Towards a new method for theorizing about adaptive agents. </title> <booktitle> Proceedings of the Eighth European Conference on Machine Learning (pp. </booktitle> <pages> 33-52). </pages> <address> Heraclion, Crete: </address> <publisher> Springer Verlag. </publisher>
Reference: <author> Ohlsson, S., & Jewett, J. J. </author> <year> (1997). </year> <title> Simulation models and the power law of learning. </title> <booktitle> Proceedings of the Nineteenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 584-589). </pages> <address> Mahwah, NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <booktitle> Machine Learning, </booktitle> <pages> 1 , 81-106. </pages>
Reference: <author> Rendell, L. A. </author> <year> (1986). </year> <title> A new basis for state-space learning systems and a successful implementation. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 20 , 369-392. </pages>
Reference: <author> Richman, H. B., & Simon, H. A. </author> <year> (1989). </year> <title> Context effects in letter perception: Comparison of two models. </title> <type> Psychological Review , 96 , 417-432. </type>
Reference-contexts: Some variants incorporate more complex, multivariate tests at each node or organize memory using directed acyclic graphs rather than trees. Methods for decision-tree induction bear a close relation to psychological models of learning that construct discrimination networks <ref> (e.g., Richman & Simon, 1989) </ref>. A third paradigm represents knowledge as a multilayer neural network . These consist of input nodes (which correspond to attributes of the stimulus), output nodes (which correspond to categories), and intermediate nodes.
Reference: <author> Rosenbloom, P. S., & Newell, A. </author> <year> (1987). </year> <title> Learning by chunking: A production system model of practice. </title> <editor> In D. Klahr, P. Langley, & R. Neches (Eds.), </editor> <title> Production system models of learning and development. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Rumelhart, D. E., Hinton, G., & Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart & J. L. McClelland (Eds.), </editor> <booktitle> Parallel distributed processing: Explorations in the microstructure of cognition (Vol. 1). </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Shrager, J., Hogg, T., & Huberman, B. A. </author> <year> (1988). </year> <title> A graph-dynamic model of the power law of practice and the problem-solving fan effect. </title> <booktitle> Science, </booktitle> <pages> 242 , 414-416. </pages>
Reference: <author> Sleeman, D., Langley, P., & Mitchell, T. </author> <month> (Spring, </month> <year> 1982). </year> <title> Learning from solution paths: An approach to the credit assignment problem. </title> <journal> AI Magazine, </journal> <pages> 48-52. </pages>
Reference-contexts: For the latter, a typical response views each rule as an operator used in problem-space search and assigns credit only after finding the solution to some problem <ref> (Sleeman, Langley, & Mitchell, 1982) </ref>. This approach labels actions along the solution path as positive instances of the responsible rule, labels actions one step off the path as negative instances, and passes the resulting training data to some algorithm for rule induction.
Reference: <author> Sutton, R. S., & Barto, A. G. </author> <year> (1998). </year> <title> Reinforcement learning: An introduction. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Research on reinforcement learning often invokes neural network methods to induce mappings from state-action pairs onto expected values <ref> (Sutton & Barto, 1998) </ref>, but nearest neighbor techniques have also been used to this end (e.g., Atkeson, Moore, & Schaal, 1997).
Reference: <author> Veloso, M. M., & Carbonell, J. G. </author> <year> (1993). </year> <title> Derivational analogy in Prodigy: Automating case acquisition, storage, and utilization. </title> <booktitle> Machine Learning, </booktitle> <pages> 10 , 249-278. </pages>
Reference-contexts: Research on analogical reasoning typically draws on case-based methods, adapted to first-order representations, that use structures akin to macro-operators in a flexible way for solving new problems <ref> (e.g., Veloso & Carbonell, 1993) </ref>. The mixture of basic induction methods (usually borrowed from work on category learning) with sequential behaviors makes this a challenging literature. But this is hardly surprising, given the inherent complexity of planning, reasoning, and natural language.
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1993). </year> <title> Learning semantic grammars with constructive inductive logic programming. </title> <booktitle> Proceedings of the Eleventh National Conference on Artificial Intelligence (pp. </booktitle> <pages> 817-822). </pages> <address> Washington, DC: </address> <publisher> AAAI. </publisher>
Reference-contexts: Although such `learning from solution paths' has been most widely used in problem-solving domains, one can use the same idea with reasoning and natural language tasks <ref> (e.g., Zelle & Mooney, 1993) </ref>. A somewhat different approach focuses not on learning to select operators or actions, but rather to predict the value of the resulting state.
References-found: 32

