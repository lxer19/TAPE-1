URL: ftp://ftp.mad-scientist.com/pub/genetic-programming/papers/stgp2.ps.Z
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Strongly Typed Genetic Programming  
Author: David J. Montana 
Date: March 25, 1994  
Address: 10 Moulton Street Cambridge, MA 02138  
Affiliation: Bolt Beranek and Newman, Inc.  
Abstract: BBN Technical Report #7866: Abstract Genetic programming is a powerful method for automatically generating computer programs via the process of natural selection [Koza 92]. However, it has the limitation known as "closure", i.e. that all the variables, constants, arguments for functions, and values returned from functions must be of the same data type. To correct this deficiency, we introduce a variation of genetic programming called "strongly typed" genetic programming (STGP). In STGP, variables, constants, arguments, and returned values can be of any data type with the provision that the data type for each such value be specified beforehand. This allows the initialization process and the genetic operators to only generate syntactically correct parse trees. Key concepts for STGP are generic functions, which are not true strongly typed functions but rather templates for classes of such functions, and generic data types, which are analogous. To illustrate STGP, we present four examples involving vector/matrix manipulation and list manipulation: (1) the multi-dimensional least-squares regression problem, (2) the multi-dimensional Kalman filter, (3) the list manipulation function NTH, and (4) the list manipulation function MAPCAR.
Abstract-found: 1
Intro-found: 1
Reference: [Barnes 82] <author> Barnes, J. </author> <year> 1982. </year> <title> Programming in Ada. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: This language is a cross between Ada and Lisp. The essential ingredient it takes from Ada is the concept of strong typing and the concept of generics as a way of making strongly typed data and functions practical to use <ref> [Barnes 82] </ref>. The essential ingredient it takes from Lisp is the concept of having programs basically be their parse trees [Steele 84]. The resulting language might best be considered a strongly typed Lisp. [Note that it is important here to distinguish between a language and its parser.
Reference: [Campbell and Meyer 1979] <author> Campbell, S.L. and Meyer, Jr., C.D. </author> <year> 1979. </year> <title> Generalised Inverses of Linear Transformations. </title> <publisher> Pittman. </publisher>
Reference-contexts: This problem is known to have the solution X = (A T A) 1 A T B (1) where (A T A) 1 A T is called the "pseudo-inverse" of A <ref> [Campbell and Meyer 1979] </ref>. Note that this is a generalization of the linear regression problem, given m pairs of data (x i ; y i ), find m and b such that the line y = mx + b gives the best least-squares fit to the data.
Reference: [Cox, Davis and Qiu 91] <author> Cox, Jr., A.L., Davis, L. and Qiu, Y. </author> <year> 1991. </year> <title> "Dynamic Anticipatory Routing in Circuit-Switched Telecommunications Networks," </title> <booktitle> in [Davis 91], </booktitle> <pages> pp. 124-143. </pages>
Reference-contexts: Comparisons of results between different genetic algorithms should be made in units of number of evaluations. (Since steady-state genetic algorithms can be parallelized [Montana 91], such a comparison is fair.) A second important features of this code is the use of exponential fitness normalization <ref> [Cox, Davis and Qiu 91] </ref>.
Reference: [Cramer 85] <author> Cramer, N.L. </author> <year> 1985. </year> <title> A Representation for the Adaptive Generation of Simple Sequential Programs. </title> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 183-187. </pages>
Reference-contexts: It uses a genetic algorithm to search through a space of possible computer programs for one which is nearly optimal in its ability to perform a particular task. While it was not the first method of automatic programming using genetic algorithms (one earlier approach is detailed in <ref> [Cramer 85] </ref>), it is so far the most successful. In Section 1.1 we give a very brief overview of genetic algorithms (the unindoctrinated reader is referred to [Goldberg 89] as an introduction).
Reference: [Davis 87] <author> Davis, L. </author> <year> 1987. </year> <title> Genetic Algorithms and Simulated Annealing. </title> <publisher> Pittman. </publisher> <pages> 30 </pages>
Reference-contexts: They have been shown to be capable of finding nearly global optima in large and complex spaces 1 in a relatively short time. Acccording to <ref> [Davis 87] </ref>, a genetic algorithm has five basic components: 1. A representation scheme provides a way to code possible solutions to a problem in a form that is readily manipulable by the genetic operators.
Reference: [Davis 91] <author> Davis, L. </author> <year> 1991. </year> <title> Handbook of Genetic Algorithms, </title> <publisher> Von Nostrand Reinhold. </publisher>
Reference-contexts: We now describe these differences so that readers can best analyze and (if desired) reproduce the results. The code used for this genetic algorithm is a C++ translation of an early version of OOGA <ref> [Davis 91] </ref>. One important distinction of this genetic algorithm is its use of steady-state replacement [Syswerda 89] rather than generational replacement for performing population updates.
Reference: [Goldberg 89] <author> Goldberg, D.E. </author> <year> 1989. </year> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: While it was not the first method of automatic programming using genetic algorithms (one earlier approach is detailed in [Cramer 85]), it is so far the most successful. In Section 1.1 we give a very brief overview of genetic algorithms (the unindoctrinated reader is referred to <ref> [Goldberg 89] </ref> as an introduction). In Section 1.2 we discuss genetic programming and how it differs from a standard genetic algorithm. 1.1 Genetic Algorithms Genetic algorithms are a class of algorithms for optimization and learning based on the principles of natural evolution.
Reference: [Kalman 60] <author> Kalman, R.E. </author> <year> 1960. </year> <title> A New Approach to Linear Filtering and Prediction Problems. </title> <journal> Trans. ASME: J. Basic Eng., </journal> <volume> vol. 82, </volume> <pages> pp. 35-45. </pages>
Reference-contexts: method of generating only legal parse trees is clearly a superior approach and is what makes a dauntingly difficult problem into an easy one. 3.3 The Kalman Filter Problem Description: The Kalman filter is a popular method for tracking the state of a system with stochastic behavior using noisy measurements <ref> [Kalman 60] </ref>. A standard formulation of a Kalman filter is the following.
Reference: [Kernighan and Ritchie 78] <author> Kernighan, B. and Ritchie, D. </author> <year> 1978. </year> <title> The C Programming Language. </title> <publisher> Prentice-Hall. </publisher>
Reference-contexts: We call this data type "VOID" to be consistent with C and C++, which use this same special data type for the same purpose <ref> [Kernighan and Ritchie 78] </ref>. Such procedures act only via their side effects, i.e. by changing some internal state. Some examples of functions that have arguments and/or returned values of type VOID are shown in certain angle. EXECUTE-TWO executes two subtrees in sequence and returns the value from the second one.
Reference: [Koza 92] <author> Koza, J.R. </author> <year> 1992. </year> <title> Genetic Programming. </title> <publisher> The MIT Press. </publisher>
Reference-contexts: 1 Introduction Genetic programming is a method of automatically generating computer programs to perform specified tasks <ref> [Koza 92] </ref>. It uses a genetic algorithm to search through a space of possible computer programs for one which is nearly optimal in its ability to perform a particular task. <p> Although computational limitations kept us from moving out further along the evaluations versus problem complexity curve for random search, these results yield the same conclusion as those of <ref> [Koza 92] </ref>: that genetic search of parse tree space is superior to random search for sufficiently complex searches, and the reason is the better scaling properties of genetic algorithms. The NTH-3 problem is more difficult than NTH-2 for a few reasons.
Reference: [Montana 91] <author> Montana, D. </author> <year> 1991. </year> <title> "Automated Parameter Tuning for Interpretation of Synthetic Images," </title> <booktitle> in [Davis 91], </booktitle> <pages> pp. 282-311. </pages>
Reference-contexts: Comparisons of results between different genetic algorithms should be made in units of number of evaluations. (Since steady-state genetic algorithms can be parallelized <ref> [Montana 91] </ref>, such a comparison is fair.) A second important features of this code is the use of exponential fitness normalization [Cox, Davis and Qiu 91].
Reference: [Montana 94] <author> Montana, D. </author> <year> 1994. </year> <title> "Genetic Search of a Generalized Hough Transform Space," </title> <note> in preparation. </note>
Reference-contexts: Controlling the convergence rate is important to avoid both excessively long runs and runs which converge prematurely to a non-global optimum. The effect of the population size and the parent scalar on convergence rate is detailed in <ref> [Montana 94] </ref>. For the purposes of this paper, it is enough to note that increasing the population size and increasing the parent scalar each slow down the convergence rate. 3.2 Multi-Dimensional Least Squares Regression Problem Description: The multi-dimensional least squares regression problem can be stated as follows.
Reference: [Perkis 93] <author> Perkis, T. </author> <year> 1993. </year> <title> "Stack-Based Genetic Programming," </title>
Reference-contexts: Finally, Section 2.7 discusses how our work on STGP has started laying the foundations for a new computer language which is particularly suited for automatic programming. Note that a different approach to extending genetic programming to allow for different data types is the stack-based approach described in <ref> [Perkis 93] </ref>.
Reference: [Steele 84] <author> Steele, G. </author> <year> 1984. </year> <title> Common Lisp. </title> <institution> Digital Equipment Corporation. </institution>
Reference-contexts: Figure 5 shows a variety of strongly typed functions with their argument types and returns types. For those readers not familiar with Lisp, CAR is a function which takes a list and returns the first element <ref> [Steele 84] </ref>. <p> The essential ingredient it takes from Lisp is the concept of having programs basically be their parse trees <ref> [Steele 84] </ref>. The resulting language might best be considered a strongly typed Lisp. [Note that it is important here to distinguish between a language and its parser. <p> The standard definition of NTH <ref> [Steele 84] </ref> specifies that it actually returns the (N + 1) st element of the list; e.g., for N = 1, NTH will return the second element of the list.
Reference: [Syswerda 89] <author> Syswerda, G. </author> <year> 1989. </year> <title> "Uniform Crossover in Genetic Algorithms," </title> <booktitle> Proc. Third International Conference on Genetic Algorithms, </booktitle> <pages> pp. 2-9. 31 </pages>
Reference-contexts: We now describe these differences so that readers can best analyze and (if desired) reproduce the results. The code used for this genetic algorithm is a C++ translation of an early version of OOGA [Davis 91]. One important distinction of this genetic algorithm is its use of steady-state replacement <ref> [Syswerda 89] </ref> rather than generational replacement for performing population updates. This means that for each generation only one individual (or a small number of individuals) is generated and placed in the population rather than generating a whole new population.
References-found: 15

