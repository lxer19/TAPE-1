URL: http://www.cs.ucsb.edu/~schauser/courses/cs595i/papers/Charm++_OOPSLA93.ps
Refering-URL: http://www.cs.ucsb.edu/~schauser/courses/cs595i/
Root-URL: http://www.cs.ucsb.edu
Email: email kale@cs.uiuc.edu  email sanjeev@cs.uiuc.edu  
Title: CHARM++ A Portable Concurrent Object Oriented System Based On C++*  
Author: Laxmikant V. Kale Sanjeev Krishnan 
Affiliation: Department of Computer Science University of Illinois, Urbana-Champaign  Department of Computer Science University of Illinois, Urbana-Champaign  
Abstract: We describe Charm++, an object oriented portable parallel programming language based on C++. Its design philosophy, implementation, sample applications and their performance on various parallel machines are described. Charm++ is an explicitly parallel language consisting of C++ with a few extensions. It provides a clear separation between sequential and parallel objects. The execution model of Charm++ is message driven, thus helping one write programs that are latency-tolerant. The language supports multiple inheritance, dynamic binding, overloading, strong typing, and reuse for parallel objects. Charm++ provides specific modes for sharing information between parallel objects. Extensive dynamic load balancing strategies are provided. It is based on the Charm parallel programming system, and its runtime system implementation reuses most of the runtime system for Charm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: The notion of "actors" was described by Hewitt [17] and further developed by Agha <ref> [1] </ref>. One of the first implementations of Actors on commercial parallel machines was carried out recently using Charm [18]. Actors, which are concurrent objects, communicate with each other solely via messages, and allow concurrency even within a single actor.
Reference: [2] <author> P. </author> <title> America. Issues in the design of a parallel object oriented language. </title> <journal> Formal Aspects of Computing, </journal> <volume> 1(4) </volume> <pages> 366-411, </pages> <year> 1989. </year>
Reference-contexts: Both ESP and Amber do not seem to have been ported to commercial massively parallel computers. There are several other efforts in this area. CC++ [6] provides various parallel constructs while using C++ for the sequential portions of the codes. POOL-T <ref> [2] </ref> has parallel objects that can be dynamically created, with a blocking model of communication between objects. Parallel-C++ [19] provides a restricted "co-begin, co-end" model of process creation. Only sequential objects are allowed, which can be "migrated" to other processors.
Reference: [3] <author> W. Athas and N. Boden. </author> <title> Cantor : An actor programming system for scientific computing. </title> <booktitle> In Proceedings of the ACM SIGPLAN Workshop on Object Based Concurrent Programming, ACM SIGPLAN Notices, </booktitle> <pages> pages 66-68, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Moreover, using messages as the sole mechanism for information exchange diminishes the expressiveness of the language as well as its efficiency. Charm++ supports specific kinds of "shared objects" in addition to messages for this reason (Section 4.3). Other Actor like languages include Cantor <ref> [3] </ref>. ABCL/1 [29] also has concurrent, message driven objects. An object processes one message at a time, and can selectively receive messages. Communication between objects can be blocking, non-blocking or future based. An express mode of messaging allows high priority messages to be processed quickly. ABCL/1 also supports delegation.
Reference: [4] <author> B. Bershad, E. Lazowska, and H. Levy. </author> <title> Presto: A system for object oriented parallel programming. </title> <journal> Software: Practice and Experience, </journal> <volume> 18(8), </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: ESP-C++ [25] has concurrent objects, transparent remote method invocation, and blocking as well as non-blocking, future based messaging. Amber [7], and its predecessor Presto <ref> [4] </ref>, are designed for a network of shared-memory multiprocessors. They provide a uniform network-wide object space. Amber objects are passive entities, and thread objects invoke operations on them. The programmer can control object location by migration primitives.
Reference: [5] <author> F. Bodin, P. Beckman, D. Gan-non, S. Narayana, and S. Yang. </author> <title> Distributed pC++: Basic ideas for an object parallel language, </title> <year> 1992. </year>
Reference-contexts: CA offers concurrency within objects, which can be distributed across more than one processor, allowing hierarchies of parallel abstractions. CA also supports delegation, first class messages and continuations. pC++ <ref> [14, 5] </ref> is a parallel C++ language largely oriented toward data-parallel and SPMD programs, and is based on CA and High Performance Fortran (HPF) ideas. It has a single thread of control, which can be forked into parallel threads (one on each processor) via a concurrent call.
Reference: [6] <author> K. Mani Chandy and Carl Kesselman. </author> <title> Compositional C++: Compositional parallel programming. </title> <type> Technical Report Caltech-CS-TR-92-13, </type> <institution> Department of Computer Science, Cal-ifornia Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: Amber objects are passive entities, and thread objects invoke operations on them. The programmer can control object location by migration primitives. Both ESP and Amber do not seem to have been ported to commercial massively parallel computers. There are several other efforts in this area. CC++ <ref> [6] </ref> provides various parallel constructs while using C++ for the sequential portions of the codes. POOL-T [2] has parallel objects that can be dynamically created, with a blocking model of communication between objects. Parallel-C++ [19] provides a restricted "co-begin, co-end" model of process creation.
Reference: [7] <author> J. Chase, F. Amador, E. Lazowska, H. Levy, and R. Littlefield. </author> <title> The Amber system : Parallel programming on a network of multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating System Principles, in ACM SIGOPS Operating Systems Review, </booktitle> <month> Decem-ber </month> <year> 1989. </year>
Reference-contexts: Objects are localized to a cluster, and can have multiple concurrent threads, with synchronization provided by a monitor construct. pSather has data-parallel constructs for distribution and alignment. ESP-C++ [25] has concurrent objects, transparent remote method invocation, and blocking as well as non-blocking, future based messaging. Amber <ref> [7] </ref>, and its predecessor Presto [4], are designed for a network of shared-memory multiprocessors. They provide a uniform network-wide object space. Amber objects are passive entities, and thread objects invoke operations on them. The programmer can control object location by migration primitives.
Reference: [8] <author> A. Chien. </author> <title> Concurrent Aggregates. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: ABCL/1 also supports delegation. A low-latency implementation of ABCL was recently done [28] on the Fujitsu AP1000. Concurrent Smalltalk (CST) [11] is an experimental language designed to run on (fine grained) message-driven processors. The CA (Concurrent Aggregates) language <ref> [8, 9] </ref> supports a fine-grained model of parallelism, originally intended for the J-machine. An aggregate is a collection of objects that has a single name a call to an aggregate may be sent to any one of its members.
Reference: [9] <author> A. Chien and W. J. Dally. </author> <title> Concurrent aggregates. </title> <booktitle> In Proceedings of the Second ACM Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 187-196, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: ABCL/1 also supports delegation. A low-latency implementation of ABCL was recently done [28] on the Fujitsu AP1000. Concurrent Smalltalk (CST) [11] is an experimental language designed to run on (fine grained) message-driven processors. The CA (Concurrent Aggregates) language <ref> [8, 9] </ref> supports a fine-grained model of parallelism, originally intended for the J-machine. An aggregate is a collection of objects that has a single name a call to an aggregate may be sent to any one of its members.
Reference: [10] <author> T. W. Christopher. </author> <title> Early experience with object-oriented message driven computing. </title> <booktitle> In Proceedings of the 3rd Symposium on Frontiers of Massively Parallel Computing, </booktitle> <month> Octo-ber </month> <year> 1990. </year>
Reference-contexts: POOL-T [2] has parallel objects that can be dynamically created, with a blocking model of communication between objects. Parallel-C++ [19] provides a restricted "co-begin, co-end" model of process creation. Only sequential objects are allowed, which can be "migrated" to other processors. OOMDC/C <ref> [10] </ref> has a message driven computing model built on C, and does not appear to fully support object oriented features like inheritance and dynamic binding.
Reference: [11] <author> W. Dally and A. Chien. </author> <title> Object oriented concurrent programming in CST. </title> <booktitle> In Proceedings of the Third Conference on Hypercube Computers, </booktitle> <pages> pages 434-439. </pages> <publisher> SIAM, </publisher> <year> 1988. </year>
Reference-contexts: Communication between objects can be blocking, non-blocking or future based. An express mode of messaging allows high priority messages to be processed quickly. ABCL/1 also supports delegation. A low-latency implementation of ABCL was recently done [28] on the Fujitsu AP1000. Concurrent Smalltalk (CST) <ref> [11] </ref> is an experimental language designed to run on (fine grained) message-driven processors. The CA (Concurrent Aggregates) language [8, 9] supports a fine-grained model of parallelism, originally intended for the J-machine.
Reference: [12] <author> J. Feldman, C-C. Lim, and T. Rauber. </author> <title> The shared-memory language pSather on a distributed-memory multiprocessor. </title> <booktitle> In Proceedings of the Second Workshop on Languages, Compilers and Runtime Environments for Distributed Memory Multiprocessors, </booktitle> <month> Oc-tober </month> <year> 1992. </year>
Reference-contexts: Mentat supports futures, and manages object location, and synchronization and forwarding of communication automatically based on compiler analysis of dependences. Mentat does not appear to provide any special constructs for programming regular, data-parallel computations. pSather <ref> [12] </ref> is based on the Eiffel object oriented language. It supports a shared-memory model, based on clusters of shared-memory processors. Objects are localized to a cluster, and can have multiple concurrent threads, with synchronization provided by a monitor construct. pSather has data-parallel constructs for distribution and alignment.
Reference: [13] <author> W. Fenton, B. Ramkumar, V.A. Saletore, A.B. Sinha, and L.V. Kale. </author> <title> Supporting machine independent programming on diverse parallel architectures. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: It is also one of the few systems that has been implemented on many commercial shared as well as large distributed memory machines. 3 Design Philosophy We will first describe the parallel programming concepts developed in the Charm parallel programming system <ref> [21, 13, 20] </ref>, and then discuss issues involved in synthesizing them with object oriented notions. 3.1 The Charm Parallel Programming Philosophy The rationale used in the design of Charm can be summarized as follows. Portability is an essential catalyst for large scale development of parallel software. <p> The runtime system of Charm is reused with modifications to support C++ interfaces. Currently, a prototype transla tor with complete functionality but restricted error checking has been implemented. Several test and application programs have been successfully exe cuted on various parallel machines. The Charm runtime system <ref> [13] </ref> is written in C. It's lowest layer consists of a machine dependent set of routines which use the calls provided by the par ticular machine.
Reference: [14] <author> D. Gannon and J. K. Lee. </author> <title> Object oriented parallelism: pC++ ideas and experiments. </title> <booktitle> In Proceedings of 1991 Japan Society for Parallel Processing, </booktitle> <pages> pages 13-23, </pages> <year> 1993. </year>
Reference-contexts: CA offers concurrency within objects, which can be distributed across more than one processor, allowing hierarchies of parallel abstractions. CA also supports delegation, first class messages and continuations. pC++ <ref> [14, 5] </ref> is a parallel C++ language largely oriented toward data-parallel and SPMD programs, and is based on CA and High Performance Fortran (HPF) ideas. It has a single thread of control, which can be forked into parallel threads (one on each processor) via a concurrent call.
Reference: [15] <author> A. S. Grimshaw. </author> <title> Easy-to-use object oriented parallel programming with Mentat. </title> <institution> Techni cal Report CS-92-32, Department of Com--puter Science, University of Virginia, Char-lottesville, </institution> <year> 1992. </year>
Reference-contexts: The concurrent objects share arrays which are distributed using HPF-like constructs such as alignments and distribution-templates. Originally designed for shared memory machines, pC++ has recently been implemented on the CM-5. C** [24] is another data-parallel C++ language. Mentat is a noteworthy portable C++ based language <ref> [15] </ref>. Concurrent objects are specified separately from sequential objects, which is a desirable feature, because it gives the programmer control over parallelism. Mentat, however, overloads constructs for method invocation and message sending, which makes the cost of a call unclear to the programmer. <p> Also, futures do not adapt to the runtime variation of remote response time: a programmer must decide how much computation to do before blocking on a future. Finally, transparent implementation of futures <ref> [15] </ref> hides the true cost of remote invocation from the programmer, because all invocations appear to have the same blocking syntax and semantics. 3.2 Synthesizing Parallelism with Ob ject Orientation For completeness, we briefly restate some of the essential properties of object oriented programs.
Reference: [16] <author> A. Gursoy and L. V. Kale. Dagger: </author> <title> Combining the benefits of synchronous and asynchronous communication styles. </title> <type> Technical Report 93-3, </type> <institution> Parallel Programming Laboratory, Department of Computer Science , University of Illinois, Urbana-Champaign, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: We also expect Charm++ modules to co-exist with Charm as well as DP [23] ( an HPF based data-parallel language being developed on top of Charm) modules, in a single application. Dagger <ref> [16] </ref> is a notation (and a visual editor) for expressing synchronization constraints (dependences between messages and computations) within a chare. It will be extended to provide the same facilities in Charm++. Our future agenda for Charm++ consists of work in implementation, language design, and applications.
Reference: [17] <author> C. Hewitt, P. Bishop, and R. Steiger. </author> <title> A universal ACTOR formalism for artificial intelligence. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 235-245. </pages> <publisher> SIAM, </publisher> <year> 1973. </year>
Reference-contexts: An example which uses dynamically created concurrent objects and shared objects is illustrated in Appendix A. 2 Previous Work In this section we briefly discuss work done previously by other researchers in object oriented concurrent programming. The notion of "actors" was described by Hewitt <ref> [17] </ref> and further developed by Agha [1]. One of the first implementations of Actors on commercial parallel machines was carried out recently using Charm [18]. Actors, which are concurrent objects, communicate with each other solely via messages, and allow concurrency even within a single actor.
Reference: [18] <author> C. Houck and G. Agha. Hal: </author> <title> A high level actor language and its distributed implementation. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: The notion of "actors" was described by Hewitt [17] and further developed by Agha [1]. One of the first implementations of Actors on commercial parallel machines was carried out recently using Charm <ref> [18] </ref>. Actors, which are concurrent objects, communicate with each other solely via messages, and allow concurrency even within a single actor. The execution model for actors is message driven, which is helpful for latency tolerance (see Section 3).
Reference: [19] <author> C-H. Jo, K. M. George, and K. A. Teague. </author> <title> Parallelizing translator for an object-oriented parallel programming language. </title> <booktitle> In Proceedings of Tenth Annual Phoenix Conference on Computers and Communications. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> March </month> <year> 1991. </year>
Reference-contexts: There are several other efforts in this area. CC++ [6] provides various parallel constructs while using C++ for the sequential portions of the codes. POOL-T [2] has parallel objects that can be dynamically created, with a blocking model of communication between objects. Parallel-C++ <ref> [19] </ref> provides a restricted "co-begin, co-end" model of process creation. Only sequential objects are allowed, which can be "migrated" to other processors. OOMDC/C [10] has a message driven computing model built on C, and does not appear to fully support object oriented features like inheritance and dynamic binding.
Reference: [20] <author> L. V. Kale. </author> <title> A tutorial introduction to CHARM, </title> <month> December </month> <year> 1992. </year>
Reference-contexts: It is also one of the few systems that has been implemented on many commercial shared as well as large distributed memory machines. 3 Design Philosophy We will first describe the parallel programming concepts developed in the Charm parallel programming system <ref> [21, 13, 20] </ref>, and then discuss issues involved in synthesizing them with object oriented notions. 3.1 The Charm Parallel Programming Philosophy The rationale used in the design of Charm can be summarized as follows. Portability is an essential catalyst for large scale development of parallel software.
Reference: [21] <author> L.V. Kale. </author> <title> The Chare Kernel parallel programming language and system. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: This idea has some similarities with the idea of "branch offices" (see Section 4.1) of chares, implemented in Charm around the same time that CA was defined <ref> [21] </ref>. CA offers concurrency within objects, which can be distributed across more than one processor, allowing hierarchies of parallel abstractions. <p> It is also one of the few systems that has been implemented on many commercial shared as well as large distributed memory machines. 3 Design Philosophy We will first describe the parallel programming concepts developed in the Charm parallel programming system <ref> [21, 13, 20] </ref>, and then discuss issues involved in synthesizing them with object oriented notions. 3.1 The Charm Parallel Programming Philosophy The rationale used in the design of Charm can be summarized as follows. Portability is an essential catalyst for large scale development of parallel software.
Reference: [22] <author> L.V. Kale and A. B. Sinha. </author> <title> Projections: A scalable performance tool. In Parallel Systems Fair, </title> <booktitle> International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Charm++ makes a significant step in this direction. Charm++ is the latest component of the broader family of Charm parallel programming tools. Since Charm++ shares the runtime system with Charm, it can be used with Projections <ref> [22] </ref> and future performance feedback tools developed for Charm. We also expect Charm++ modules to co-exist with Charm as well as DP [23] ( an HPF based data-parallel language being developed on top of Charm) modules, in a single application.
Reference: [23] <author> E. Kornkven and L. V. Kale. </author> <title> Dynamic adaptive scheduling in an implementation of a data parallel language. </title> <type> Technical Report 92-10, </type> <institution> Parallel Programming Laboratory, Department of Computer Science , University of Illinois, Urbana-Champaign, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Since Charm++ shares the runtime system with Charm, it can be used with Projections [22] and future performance feedback tools developed for Charm. We also expect Charm++ modules to co-exist with Charm as well as DP <ref> [23] </ref> ( an HPF based data-parallel language being developed on top of Charm) modules, in a single application. Dagger [16] is a notation (and a visual editor) for expressing synchronization constraints (dependences between messages and computations) within a chare. It will be extended to provide the same facilities in Charm++.
Reference: [24] <author> J. Larus, B. Richards, and G. Viswanathan. </author> <title> C** : A large-grain, object-oriented, data-parallel programming language. </title> <type> Technical Report 1126, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <year> 1992. </year>
Reference-contexts: The concurrent objects share arrays which are distributed using HPF-like constructs such as alignments and distribution-templates. Originally designed for shared memory machines, pC++ has recently been implemented on the CM-5. C** <ref> [24] </ref> is another data-parallel C++ language. Mentat is a noteworthy portable C++ based language [15]. Concurrent objects are specified separately from sequential objects, which is a desirable feature, because it gives the programmer control over parallelism.
Reference: [25] <author> W. Lau and V. Singh. </author> <title> An object-oriented class library for scalable parallel heuristic search. </title> <booktitle> In Proceedings of the European Conference on Object Oriented Programming, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: It supports a shared-memory model, based on clusters of shared-memory processors. Objects are localized to a cluster, and can have multiple concurrent threads, with synchronization provided by a monitor construct. pSather has data-parallel constructs for distribution and alignment. ESP-C++ <ref> [25] </ref> has concurrent objects, transparent remote method invocation, and blocking as well as non-blocking, future based messaging. Amber [7], and its predecessor Presto [4], are designed for a network of shared-memory multiprocessors. They provide a uniform network-wide object space.
Reference: [26] <author> A. B. Sinha and L.V. Kale. </author> <title> A load balancing strategy for prioritized execution of tasks. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: The strategies are implemented as modules on top of the basic runtime system. Some of the load balancing strategies supported include <ref> [26] </ref> 1. Random : new chares are sent to random pro cessors 2. Adaptive Contracting Within Neighborhood : new chares are balanced within a neighbor hood, leading to a global balance. 3. Central manager : All new chares are sent to a central manager which redistributes them among processors. <p> The implementation uses integer message priorities (equal to the lower bound on cost of a branch and bound node) to guide search through the branch and bound tree. The cost of the best solution is maintained using a monotonic variable. The token based load balancing strategy <ref> [26] </ref> was used to distribute chares.
Reference: [27] <author> B. Stroustrup. </author> <title> The C++ Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> second edition, </address> <year> 1991. </year>
Reference: [28] <author> K. Taura, S. Matsuoka, and A. Yonezawa. </author> <title> An efficient implementation scheme of concurrent object-oriented languages on stock multicom-puters. </title> <booktitle> In Proceedings of the 5th ACM SIG-PLAN Symposium on Principles and Practice of Parallel Programming, ACM SIGPLAN Notices, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: An object processes one message at a time, and can selectively receive messages. Communication between objects can be blocking, non-blocking or future based. An express mode of messaging allows high priority messages to be processed quickly. ABCL/1 also supports delegation. A low-latency implementation of ABCL was recently done <ref> [28] </ref> on the Fujitsu AP1000. Concurrent Smalltalk (CST) [11] is an experimental language designed to run on (fine grained) message-driven processors. The CA (Concurrent Aggregates) language [8, 9] supports a fine-grained model of parallelism, originally intended for the J-machine.
Reference: [29] <author> A. Yonezawa. </author> <title> ABCL: An Object Oriented Concurrent System. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Moreover, using messages as the sole mechanism for information exchange diminishes the expressiveness of the language as well as its efficiency. Charm++ supports specific kinds of "shared objects" in addition to messages for this reason (Section 4.3). Other Actor like languages include Cantor [3]. ABCL/1 <ref> [29] </ref> also has concurrent, message driven objects. An object processes one message at a time, and can selectively receive messages. Communication between objects can be blocking, non-blocking or future based. An express mode of messaging allows high priority messages to be processed quickly. ABCL/1 also supports delegation.
References-found: 29

