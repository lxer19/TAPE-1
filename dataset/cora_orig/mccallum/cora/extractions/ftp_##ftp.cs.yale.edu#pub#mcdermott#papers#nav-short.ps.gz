URL: ftp://ftp.cs.yale.edu/pub/mcdermott/papers/nav-short.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/mcdermott.html
Root-URL: http://www.cs.yale.edu
Email: mcdermott,xiaog@cs.yale.edu  
Title: Visual Place Recognition for Autonomous Robots  
Author: Hemant D. Tagare Drew McDermott Hong Xiao 
Address: ftagare,  
Affiliation: Department of Diagnostic Radiology and Department of Electrical Engineering  Department of Computer Science Yale University  
Abstract: The problem of place recognition is central to robot map learning. A robot needs to be able to recognize when it has returned to a previously visited place, or at least to be able to estimate the likelihood that it has been at a place before. Our approach is to compare images taken at two places, using a stochastic model of changes due to shift, zoom, and occlusion to predict the probability that one of them could be a perturbation of the other. We have performed experiments to gather the value of a 2 statistic applied to image matches from a variety of indoor locations. Image pairs gathered from nearby locations generate low 2 values, and images gathered from different locations generate high values. The rate of false positive and false negative matches is low. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew Blake and Andrew Zisserman. </author> <title> Visual Reconstruction. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: During the search for the maximum likelihood, the maximizing values of and m are found by an iterative coordinate ascent procedure. This procedure alternately maxi mizes and m. For a given interpolated image and m, the correspondence domain which maximizes the log likelihood is easily found using standard methods <ref> [1] </ref>: fl = (e; l) j 2 2 (e; l) Similarly, for a given , we pick m (the aperture factor) as the least-square estimate 5 e;l2 I (e; l)(e; l) : At the end of the MAP procedure outlined above, we have the MAP estimates fl ; fl ; m
Reference: [2] <author> Joachim Buhmann, Wolfram Burgard, Armin B. Cremers, Dieter Fox, Thomas Hofmann, Frank E. Schneider, Jiannis Strikos, and Sebastian Thrun. </author> <title> The mobile robot Rhino. </title> <journal> AI Magazine , 16(2) </journal> <pages> 31-38, </pages> <year> 1995. </year>
Reference-contexts: the two points approximately coinciding in position and orientation, which is the case we are really interested in. is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [14], [3], <ref> [2] </ref>. Data from stereo vision can be used in a similar way [15]. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. [7] describe a system for taking a one-dimensional panorama for use in robot localization. <p> We use the simplest plausible priors. For p (), we use an exponential distribution that makes high levels of occlusion less likely. Because we know nothing about E, we assume all E's are equally likely. The aperture factor m has a uniform distribution over the range <ref> [0:5; 2] </ref>. The rotation prior p () is uniformly distributed over the range [; ].
Reference: [3] <author> Alberto Elfes. </author> <title> Using occupancy grids for mobile robot perception and navigation. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 46-58, </pages> <year> 1989. </year> <note> special issue on Autonomous Intelligent Machines, </note> <month> June. </month>
Reference-contexts: drew the two points approximately coinciding in position and orientation, which is the case we are really interested in. is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [14], <ref> [3] </ref>, [2]. Data from stereo vision can be used in a similar way [15]. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. [7] describe a system for taking a one-dimensional panorama for use in robot localization.
Reference: [4] <author> Sean Engelson. </author> <title> Passive Map Learning and Visual Place Recognition. </title> <type> Technical Report 1032, </type> <institution> Yale Computer Science Department, </institution> <year> 1994. </year>
Reference-contexts: In [19], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9], [8] and especially [16], [19], <ref> [4] </ref>, [5], [6].
Reference: [5] <author> Sean P. Engelson and Drew V. McDermott. </author> <title> Image signatures for place recognition and map construction. </title> <booktitle> In Proceedings of SPIE Symposium on Intelligent Robotic Systems, Sensor Fusion IV, </booktitle> <year> 1991. </year>
Reference-contexts: In [19], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9], [8] and especially [16], [19], [4], <ref> [5] </ref>, [6].
Reference: [6] <author> Sean P. Engelson and Drew V. McDermott. </author> <title> Error correction in mobile robot map learning. </title> <booktitle> In Proc. IEEE Conf. on Robotics and Automation, </booktitle> <pages> pages 2555-2560, </pages> <year> 1992. </year>
Reference-contexts: In [19], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9], [8] and especially [16], [19], [4], [5], <ref> [6] </ref>.
Reference: [7] <author> Jiawei Hong, Xianan Tan, Brian Pinette, Richard Weiss, and Edward M. Riseman. </author> <title> Image-based homing. </title> <booktitle> In Proc. IEEE Conf. on Robotics and Automation, </booktitle> <pages> pages 620-625, </pages> <year> 1991. </year>
Reference-contexts: Data from stereo vision can be used in a similar way [15]. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. <ref> [7] </ref> describe a system for taking a one-dimensional panorama for use in robot localization. It uses a spherical mirror to produce a 360-degree image of a location. One slice through this image remains at the same height as the robot moves around.
Reference: [8] <author> Ian Horswill. </author> <title> Specialization of Perceptual Processes. </title> <type> PhD thesis, </type> <year> 1993. </year>
Reference-contexts: This implies that the amount of change in gray levels at corresponding pixels is small. The exact nature of the relation is the third issue in image comparison. The simplest image-based algorithms use correlation to compare the two images <ref> [8] </ref>, which makes sense only if the correspondence is the identity function. More sophisticated approaches attempt to estimate the correspondence during image comparison. <p> In [19], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9], <ref> [8] </ref> and especially [16], [19], [4], [5], [6].
Reference: [9] <author> David Kortenkamp, L. Douglas Baker, and Terry Weymouth. </author> <title> Using gateways to build a route map. </title> <booktitle> In Proc. IEEE/RSJ Int'l. Workshop on Intelligent Robots and Systems, </booktitle> <year> 1992. </year>
Reference-contexts: In [19], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including <ref> [9] </ref>, [8] and especially [16], [19], [4], [5], [6].
Reference: [10] <author> Benjamin Kuipers and Yung tai Byun. </author> <title> A robust, qualitative method for robot spatial reasoning. </title> <booktitle> In Proc. AAAI 7, </booktitle> <pages> pages 774-779, </pages> <year> 1988. </year>
Reference-contexts: The class of geometries is specified as non-informatively as possible (analogous to models for white noise). Finally, we pose the recognition problem in the framework of statistical decision theory. II. Related Work The basic idea of treating maps as networks of places is from <ref> [10] </ref>, [11]. A recent program uses this approach to learn office-building layouts very effectively [12].
Reference: [11] <author> Benjamin Kuipers and Yung tai Byun. </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <booktitle> Robotis and Autonomous Systems , 8 </booktitle> <pages> 47-63, </pages> <year> 1991. </year>
Reference-contexts: The class of geometries is specified as non-informatively as possible (analogous to models for white noise). Finally, we pose the recognition problem in the framework of statistical decision theory. II. Related Work The basic idea of treating maps as networks of places is from [10], <ref> [11] </ref>. A recent program uses this approach to learn office-building layouts very effectively [12].
Reference: [12] <author> Clayton Kunz, Thomas Willeke, and Illah R. Nourbakhsh. </author> <title> Automatic mapping of dynamic office environments. </title> <booktitle> In Proc. IEEE Conf. on Robotics and Automation, </booktitle> <pages> pages 1681-1687, </pages> <year> 1997. </year>
Reference-contexts: Finally, we pose the recognition problem in the framework of statistical decision theory. II. Related Work The basic idea of treating maps as networks of places is from [10], [11]. A recent program uses this approach to learn office-building layouts very effectively <ref> [12] </ref>. It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions [18], [17]. [13] investigates a map representation in which nodes were regions (more generally, behaviors), and the edges indicated transitions among them. In [19], nodes are obstacle boundaries from which landmarks are visible.
Reference: [13] <editor> Maja J. Mataric. </editor> <title> Environment learning using a distributed representation. </title> <booktitle> In Proc. IEEE Int'l. Conf. on Robotics and Automation, </booktitle> <pages> pages 402-406, </pages> <year> 1990. </year>
Reference-contexts: II. Related Work The basic idea of treating maps as networks of places is from [10], [11]. A recent program uses this approach to learn office-building layouts very effectively [12]. It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions [18], [17]. <ref> [13] </ref> investigates a map representation in which nodes were regions (more generally, behaviors), and the edges indicated transitions among them. In [19], nodes are obstacle boundaries from which landmarks are visible.
Reference: [14] <author> Hans P. Moravec and Alberto Elfes. </author> <title> High-resolution maps from wide-angle sonar. </title> <booktitle> In Proc. IEEE Int'l Conf. on Robotics and Automation, </booktitle> <year> 1985. </year>
Reference-contexts: we drew the two points approximately coinciding in position and orientation, which is the case we are really interested in. is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square <ref> [14] </ref>, [3], [2]. Data from stereo vision can be used in a similar way [15]. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. [7] describe a system for taking a one-dimensional panorama for use in robot localization.
Reference: [15] <author> Don Murray and Cullen Jennings. </author> <title> Stereo vision based mapping and navigation for mobile robots. </title> <booktitle> In Proc. IEE Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 1694-1699, </pages> <year> 1997. </year>
Reference-contexts: Data from stereo vision can be used in a similar way <ref> [15] </ref>. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. [7] describe a system for taking a one-dimensional panorama for use in robot localization. It uses a spherical mirror to produce a 360-degree image of a location.
Reference: [16] <author> Randall Nelson. </author> <title> Visual Navigation. </title> <type> PhD thesis, </type> <year> 1989. </year>
Reference-contexts: In [19], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9], [8] and especially <ref> [16] </ref>, [19], [4], [5], [6].
Reference: [17] <author> Illah Nourbakhsh, Rob Powers, and Stan Birchfield. Dervish, </author> <title> An Office-navigating Robot. </title> <journal> AI Magazine , 16(2) </journal> <pages> 53-60, </pages> <year> 1995. </year>
Reference-contexts: II. Related Work The basic idea of treating maps as networks of places is from [10], [11]. A recent program uses this approach to learn office-building layouts very effectively [12]. It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions [18], <ref> [17] </ref>. [13] investigates a map representation in which nodes were regions (more generally, behaviors), and the edges indicated transitions among them. In [19], nodes are obstacle boundaries from which landmarks are visible.
Reference: [18] <author> Reid Simmons and Sven Koenig. </author> <title> Probabilistic navigation in partially observable environments. </title> <booktitle> In Proc. Ijcai, </booktitle> <year> 1995. </year>
Reference-contexts: II. Related Work The basic idea of treating maps as networks of places is from [10], [11]. A recent program uses this approach to learn office-building layouts very effectively [12]. It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions <ref> [18] </ref>, [17]. [13] investigates a map representation in which nodes were regions (more generally, behaviors), and the edges indicated transitions among them. In [19], nodes are obstacle boundaries from which landmarks are visible.
Reference: [19] <author> Camillo J. Taylor and David J. Kriegman. </author> <title> Exploration strategies for mobile robots. </title> <booktitle> In Proc. IEEE Int'l. Conf. on Robots and Automation, </booktitle> <year> 1993. </year>
Reference-contexts: It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions [18], [17]. [13] investigates a map representation in which nodes were regions (more generally, behaviors), and the edges indicated transitions among them. In <ref> [19] </ref>, nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9], [8] and especially [16], [19], [4], [5], [6]. <p> In <ref> [19] </ref>, nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9], [8] and especially [16], [19], [4], [5], [6].
Reference: [20] <author> Jian YuZheng, Matthew Barth, and Saburo Tsuji. </author> <title> Autonomous landmark selection for route recognition by a mobile robot. </title> <booktitle> In Proc. IEEE Conf. on Robotics and Automation, </booktitle> <pages> pages 2004-2009, </pages> <year> 1991. </year> <title> 7 Fig. 7. Image matching panorama </title>
Reference-contexts: One slice through this image remains at the same height as the robot moves around. This slice is used to produce a one-dimensional list of features used as landmarks. Our approach uses a full two-dimensional panorama. In <ref> [20] </ref> there is described a scheme for taking a panorama of what the robot sees to its side, and looking for features to use to retrace the same route.
References-found: 20

