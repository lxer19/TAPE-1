URL: http://www.cs.clemson.edu/~johnmc/papers/TESTING/HIT/hit.ps
Refering-URL: http://www.cs.clemson.edu/~johnmc/testing.html
Root-URL: http://www.cs.clemson.edu
Title: Incremental Testing of Object-Oriented Class Structures  
Author: Mary Jean Harrold and John D. McGregor 
Keyword: compiler Categories and Subject Descriptors: D.1.5[Programming Techniques]: Object-oriented Programming, D.2.5[Software Engineering]: Testing and Debugging General Terms: Class, Incremental, Object-oriented, Testing Additional Key Words and Phrases: Class Libraries, Class Testing, Object-oriented Testing  
Affiliation: Clemson University  
Abstract: Although there is much interest in creating libraries of well-designed, thoroughly-tested classes that can be confidently reused for many applications, few class testing techniques have been developed. In this paper, we present a class testing technique that exploits the hierarchical nature of the inheritance relation to test related groups of classes by reusing the testing information for a parent class to guide the testing of a subclass. We initially test base classes having no parents by designing a test suite that tests each member function individually and also tests the interactions among member functions. To design a test suite for a subclass, our algorithm incrementally updates the history of its parent to reect both the modified, inherited attributes and the subclass's newly defined attributes. Only those new attributes or affected, inherited attributes are tested and the parent class's test suites are reused, if possible, for the testing. Inherited attributes are retested in their new context in a subclass by testing their interactions with the subclass's newly defined attributes. We have incorporated our class testing technique into Free Software Foundation, Inc's C ++ and have used it in conjunction with a data ow tester for our experimentation. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> B. Beizer, </author> <title> in Software Testing Techniques, </title> <publisher> Van Nostrand Reinhold Company, Inc., </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: For integration testing, the interface between units is the focus of the testing. Interface problems include errors in input/output format, incorrect sequencing of subroutine calls, and misunderstood entry or exit parameter values <ref> [1] </ref>. Although many integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed [7, 12].
Reference: 2. <author> T. J. Cheatham and L. Mellinger, </author> <title> ``Testing object-oriented software systems,'' </title> <booktitle> Proceedings of the 1990 Computer Science Conference, </booktitle> <pages> pp. 161-165, </pages> <year> 1990. </year>
Reference-contexts: Part of his test design phase is an analysis of the effects of inheritance on the subclass. He suggests that only minimal testing may be required for inherited member functions whose functionality has not changed. Cheatham and Mellinger <ref> [2] </ref> also discuss the problem of subclass testing and present a more extensive analysis of the retesting required for a subclass. However, both of these subclass testing techniques require that the analysis be performed by hand, which prohibits automating the design phase of testing.
Reference: 3. <author> R-K. Doong and P. G. Frankl, </author> <title> ``Case studies on testing object-oriented programs,'' </title> <booktitle> Proceedings of the Fourth Symposium on Testing, Analysis and Verification (TAV4), </booktitle> <pages> pp. 165-177, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Thus, we individually test each member function in a class using a test suite that contains both specification-based and program-based test cases. The specification-based test cases can be constructed using existing approaches such as the one proposed by Doong and Frankl <ref> [3] </ref>. The program-based test cases are constructed using existing techniques such as branch testing or data ow testing. The testing history for a class contains associations between each member function in the class and both a specification-based and a program-based test suite.
Reference: 4. <author> S. P. Fielder, </author> ` <title> `Object-oriented unit testing,'' </title> <journal> Hewlett-Packard Journal, </journal> <pages> pp. 69-74, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: However, Perry and Kaiser [16] have shown that many inherited attributes in subclasses of well designed and thoroughly tested classes must be retested in the context of the subclasses. Thus, any subclass testing technique must ensure that this interaction of new attributes and inherited attributes is thoroughly tested. Fielder <ref> [4] </ref> presented a technique to test subclasses whose parent classes are thoroughly tested. Part of his test design phase is an analysis of the effects of inheritance on the subclass. He suggests that only minimal testing may be required for inherited member functions whose functionality has not changed.
Reference: 5. <author> P. G. Frankl and E. J. Weyuker, </author> <title> ``An applicable family of data ow testing criteria,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-14, no. 10, </volume> <pages> pp. 1483-1498, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: The History Generator inputs the parent class, the history for the parent class and the definition of the subclass and outputs the history for the subclass. Although, our hierarchical incremental algorithm is independent of the testing methodology, we used a type of program-based testing known as data ow testing <ref> [5, 11, 15] </ref> to demonstrate the feasibility of our technique. We modified the intraprocedural data ow analysis performed by the g++ compiler [8] to gather the definition-use pairs for the testing. Another technique [6, 7] uses this intraprocedural data ow information to compute the interproce-dural definition-use pairs.
Reference: 6. <author> M. J. Harrold and M. L. Soffa, </author> <title> ``Interprocedural data ow testing,'' </title> <booktitle> Proceedings of the Third Testing, Analysis, and Verification Symposium (TAV3 - SIGSOFT89), </booktitle> <pages> pp. </pages> <address> 158-167 , Key West, FL , December 1989. </address>
Reference-contexts: We modified the intraprocedural data ow analysis performed by the g++ compiler [8] to gather the definition-use pairs for the testing. Another technique <ref> [6, 7] </ref> uses this intraprocedural data ow information to compute the interproce-dural definition-use pairs. Thus, we perform intraprocedural data ow testing on individual member functions and interprocedural data ow testing on interacting member functions. 5.
Reference: 7. <author> M. J. Harrold and M. L. Soffa, </author> <title> ``Selecting Data for Integration Testing,'' </title> <journal> IEEE Software, special issue on testing and debugging, </journal> <pages> pp. 58-65, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: For integration testing, the interface between units is the focus of the testing. Interface problems include errors in input/output format, incorrect sequencing of subroutine calls, and misunderstood entry or exit parameter values [1]. Although many integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed <ref> [7, 12] </ref>. A test set is adequate for a selected criterion if it covers the program according to that criterion [19] and a program is deemed to be adequately tested if it has been tested with an adequate test set. <p> We modified the intraprocedural data ow analysis performed by the g++ compiler [8] to gather the definition-use pairs for the testing. Another technique <ref> [6, 7] </ref> uses this intraprocedural data ow information to compute the interproce-dural definition-use pairs. Thus, we perform intraprocedural data ow testing on individual member functions and interprocedural data ow testing on interacting member functions. 5.
Reference: 8. <author> M. J. Harrold and P. Kolte, </author> <title> ``Combat: A compiler based data ow testing system,'' </title> <booktitle> Proceedings of Pacific Northwest Quality Assurance, </booktitle> <pages> pp. 311-323, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Although, our hierarchical incremental algorithm is independent of the testing methodology, we used a type of program-based testing known as data ow testing [5, 11, 15] to demonstrate the feasibility of our technique. We modified the intraprocedural data ow analysis performed by the g++ compiler <ref> [8] </ref> to gather the definition-use pairs for the testing. Another technique [6, 7] uses this intraprocedural data ow information to compute the interproce-dural definition-use pairs. Thus, we perform intraprocedural data ow testing on individual member functions and interprocedural data ow testing on interacting member functions. 5.
Reference: 9. <author> W. E. Howden, </author> <title> in Software Engineering and Technology: Functional Program Testing and Analysis, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Thus, systematic testing techniques generate a representative set of test cases to provide coverage of the program according to some selected criteria. There are two general forms of test case coverage: specification-based and program-based <ref> [9] </ref>. In specification-based or `black-box' testing, test cases are generated to show that a program satisfies its rrrrrrrrrrrrrrrrrr Copyright (C) 1987, 1989 Free Software Foundation, Inc, 675 Mass Avenue, Cambridge, MA 02139. - 4 - functional and performance specifications.
Reference: 10. <author> M. Killian, </author> <title> ``Trellis: Turning designs into programs,'' </title> <journal> CACM, </journal> <volume> vol. 33, no. 9, </volume> <pages> pp. 65-67, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Our testing technique assumes a language model that is a generalization of the C++[17] model but is sufficiently exible to support other languages with similar features such as Trellis <ref> [10] </ref>.
Reference: 11. <author> B. Korel and J. Laski, </author> <title> ``A tool for data ow oriented program testing,'' </title> <booktitle> ACM Softfair Proceedings, </booktitle> <pages> pp. 35-37, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: The History Generator inputs the parent class, the history for the parent class and the definition of the subclass and outputs the history for the subclass. Although, our hierarchical incremental algorithm is independent of the testing methodology, we used a type of program-based testing known as data ow testing <ref> [5, 11, 15] </ref> to demonstrate the feasibility of our technique. We modified the intraprocedural data ow analysis performed by the g++ compiler [8] to gather the definition-use pairs for the testing. Another technique [6, 7] uses this intraprocedural data ow information to compute the interproce-dural definition-use pairs.
Reference: 12. <author> U. Linnenkugel and M. Mullerburg, </author> <title> ``Test data selection criteria for integration testing,'' </title> <booktitle> Proceedings of the 1990 Conference on Systems Integration, </booktitle> <pages> pp. 45-58, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: For integration testing, the interface between units is the focus of the testing. Interface problems include errors in input/output format, incorrect sequencing of subroutine calls, and misunderstood entry or exit parameter values [1]. Although many integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed <ref> [7, 12] </ref>. A test set is adequate for a selected criterion if it covers the program according to that criterion [19] and a program is deemed to be adequately tested if it has been tested with an adequate test set.
Reference: 13. <author> M. A. Linton and P. R. Calder, </author> <booktitle> ``The design and implementation of InterViews,'' Proceedings of USNIX C++ Workship, </booktitle> <pages> pp. 256-267, </pages> <year> 1987. </year>
Reference-contexts: Experimentation We are using a variety of existing C++ class hierarchies for our experimentation to determine the savings in testing gained using our technique. We have tested the class hierarchies in InterViews 3.0.1 <ref> [13] </ref>, which is a library of graphics interface classes. A representative class hierarchy in the InterViews class library, shown in Figure 8, has class Resource as its base class. Here, we report the results for the hierarchy with base class Resource and subclasses, Glyph, Interactor, Scene, MonoScene and Dialog.
Reference: 14. <author> S. B. Lippman, </author> <title> in C++ Primer, Second Edition, </title> <editor> p. </editor> <volume> 121, </volume> <publisher> Addison-Wesley Publishing Company , New York, </publisher> <year> 1991. </year>
Reference-contexts: Data member oat i is a new attribute in R since it rrrrrrrrrrrrrrrrrr The argument list is referred to as the signature of a function because the argument list is often used to distinguish one instance of a function from another <ref> [14] </ref>. - 7 - class P class R : public P - R's attributes after the mapping private: private: private: int i; oat i; oat i; //new public: public: public: P ( )- R ( )- R ( ) -- //new void A (int a,int b) void A (int a, int
Reference: 15. <author> S. C. Ntafos, </author> <title> ``An evaluation of required element testing strategies,'' </title> <booktitle> Proceedings of 7th International Conference on Software Engineering, </booktitle> <pages> pp. 250-256, </pages> <month> March </month> <year> 1984. </year>
Reference-contexts: The History Generator inputs the parent class, the history for the parent class and the definition of the subclass and outputs the history for the subclass. Although, our hierarchical incremental algorithm is independent of the testing methodology, we used a type of program-based testing known as data ow testing <ref> [5, 11, 15] </ref> to demonstrate the feasibility of our technique. We modified the intraprocedural data ow analysis performed by the g++ compiler [8] to gather the definition-use pairs for the testing. Another technique [6, 7] uses this intraprocedural data ow information to compute the interproce-dural definition-use pairs.
Reference: 16. <author> D. E. Perry and G. E. Kaiser, </author> <title> ``Adequate testing and object-oriented programming,'' </title> <journal> Journal of Object-Oriented Programming, </journal> <volume> vol. 2, </volume> <pages> pp. 13-19, </pages> <month> January/February </month> <year> 1990. </year>
Reference-contexts: Additionally, completely retesting each class does not exploit opportunities to reuse and share design, construction and execution of test suites. Another approach to class testing is to utilize the hierarchical nature of classes related by inheritance to reduce the overhead of retesting each subclass. However, Perry and Kaiser <ref> [16] </ref> have shown that many inherited attributes in subclasses of well designed and thoroughly tested classes must be retested in the context of the subclasses. Thus, any subclass testing technique must ensure that this interaction of new attributes and inherited attributes is thoroughly tested. <p> Base Class Testing We first test base classes using traditional unit testing techniques to test individual member functions in the class. Our incremental testing technique addresses the test data adequacy concerns expressed by Perry and Kaiser <ref> [16] </ref>. The antidecomposition axiom tells us that adequate testing of the class does not guarantee adequate testing of each member function. Adequately testing each member function is particularly important since member functions may be inherited by the subclasses and expected to operate in a new context.
Reference: 17. <author> B. Stroustrup, </author> <title> in The C++ Programming Language, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Conclusion We have presented an incremental technique to assist in testing classes that exploits the hierarchical structure of groups of classes related by inheritance. Our language model is a generalization of the C++ <ref> [17] </ref> language. Base classes are initially tested using both specification-based and program-based test cases, and a history of the testing information is saved. A subclass is then tested by incrementally updating the history of the parent class to reect the - 22 - differences from the parent.
Reference: 18. <author> P. Wegner and S. B. Zdonik, </author> <title> ``Inheritance as an incremental modification mechanism or what like is and isn't like,'' </title> <booktitle> Proceedings of ECOOP'88, </booktitle> <pages> pp. 55-77, </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: The class designer controls the specification of the modifier while the inheritance relation controls the combination of the modifier and the parent class to get the subclass. Wegner and Zdonik <ref> [18] </ref> described inheritance as an incremental modification technique that combines a parent class P with modifier M to get a resulting class R. <p> The subclass designer specifies the modifier, which may contain various types of attributes that alter the parent class to get the resulting subclass. We include the redefined, virtual and inherited attributes presented by Wegner and Zdonik <ref> [18] </ref> and define an additional type of attribute, the new attribute. We further classify the virtual attribute as virtual-new, virtual-inherited and virtual-redefined to enable the identification of the required subclass (re)testing. <p> In the following list, we reference Figure 1, define the attributes and identify the scope to which they are bound. rrrrrrrrrrrrrrrrrr In their paper <ref> [18] </ref>, Wegner and Zdonik use recursive instead of inherited to describe this type of attribute.
Reference: 19. <author> E. J. Weyuker, </author> <title> ``Axiomatizing software test data adequacy,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-12, no. 12, </volume> <pages> pp. 1128-1138, </pages> <month> December </month> <year> 1986. </year> <month> - 23 </month> - 
Reference-contexts: Although many integration testing techniques are specification-based, some interprocedural program-based testing techniques have recently been developed [7, 12]. A test set is adequate for a selected criterion if it covers the program according to that criterion <ref> [19] </ref> and a program is deemed to be adequately tested if it has been tested with an adequate test set. Weyuker [19] developed a set of axioms for test data adequacy that expose insufficiencies in program-based adequacy criteria. Several of these axioms are specifically related to unit and integration testing. <p> A test set is adequate for a selected criterion if it covers the program according to that criterion <ref> [19] </ref> and a program is deemed to be adequately tested if it has been tested with an adequate test set. Weyuker [19] developed a set of axioms for test data adequacy that expose insufficiencies in program-based adequacy criteria. Several of these axioms are specifically related to unit and integration testing. The antiextensionality axiom reminds us that two programs that compute the same function may have entirely different implementations.
References-found: 19

