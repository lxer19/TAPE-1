URL: http://www.icsi.berkeley.edu/ftp/global/pub/ai/lzero/first_five_years.ps.Z
Refering-URL: 
Root-URL: 
Email: Email: fjfeldman,lakoff,dbailey,snarayan, regier,stolckeg@icsi.berkeley.edu.  
Title: AI REVIEW SPECIAL VOLUME ON INTEGRATION OF VISION AND LANGUAGE L 0 |The First Five
Author: Jerome Feldman George Lakoff David Bailey Srini Narayanan Terry Regier Andreas Stolcke 
Keyword: language learning, structured connectionism,  
Note: embodied cognition  
Address: 1947 Center St. Suite 600 Berkeley CA 94704  
Affiliation: International Computer Science Institute  
Abstract: The L 0 project at ICSI and UC Berkeley attempts to combine not only vision and natural language modelling, but also learning. The original task was put forward in (Feldman et al. 1990a) as a touchstone task for AI and cognitive science. The task is to build a system that can learn the appropriate fragment of any natural language from sentence-picture pairs. We have not succeeded in building such a system, but we have made considerable progress on component subtasks and this has led in a number of productive and surprising directions. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Berlin, Brent, & Paul Kay, </author> <year> 1969. </year> <title> Basic color terms: Their universality and evolution. </title> <institution> University of California Press, Berkeley. </institution>
Reference-contexts: In this respect it resembles the domain of color, another objectively measurable domain which has attracted work in semantics <ref> (Berlin & Kay 1969) </ref>. In addition, space (along with time) has a privileged position as a fundamental conceptual structuring device in language, a position which most other domains, color included, do not share. <p> Decades of work by people from a wide range of disciplines has produced an understanding of this (admittedly very narrow) aspect of cognition that seems as solid and incontestable as any in the sciences <ref> (Berlin & Kay 1969) </ref>. Our belief is that this paradigm can be extended, albeit with enormous effort, to yield a cognitive science that will establish a continually growing body of established scientific truth.
Reference: <author> Brugman, Claudia, </author> <year> 1983. </year> <title> The use of body-part terms as locatives in chalcatongo mixtec. in Report No. </title> <booktitle> 4 of the Survey of California and other Indian Languages, </booktitle> <pages> pp. 235-90. </pages> <institution> University of California, Berkeley. </institution>
Reference-contexts: Such differences in spatial systems are sometimes quite dramatic, but more often than not they are rather subtle, particularly when one compares closely related languages. provides examples of non-English spatial structuring, from Mixtec <ref> (Brugman 1983) </ref>, a Mexican Indian language, and from German. In Figure 2 (a) we see two spatial configurations which would both be categorized as above in English, but which receive distinct categorizations in Mixtec, which is sensitive to the major axis orientation of objects.

Reference: <author> Guyon, I., P. Albrecht, Y. LeCun, J. Denker, & W. Hubbard. </author> <year> 1991. </year> <title> Design of a neural network character recognizer for a touch terminal. </title> <journal> Pattern Recognition 24.105-119. </journal>
Reference: <author> Horning, James Jay. </author> <year> 1969. </year> <title> A study of grammatical inference. </title> <type> Technical Report CS 139, </type> <institution> Computer Science Department, Stanford University, Stanford, </institution> <address> Ca. </address>
Reference: <author> Jurafsky, Daniel, </author> <year> 1992. </year> <title> An On-line Computational Model Of Human Sentence Interpretation. </title> <institution> Berkeley, CA: Dept. of Computer Science, University Of California dissertation. </institution> <note> Available as Technical Report UCB/CSD 92/767. </note>
Reference-contexts: Input/Output * Input. Input sentences are parsed using a probabilistic version of the Construction Grammar Interpreter SAL developed by Jurafsky <ref> (Jurafsky 1992) </ref>. We are in the process of enhancing the evidential access and selection of constructions in SAL to include metaphoric knowledge. Our hypothesis is that metaphors are structures that can potentially increase the information that a linguistic utterance provides about the agent's world model.
Reference: <author> Keeler, James, David Rumelhart, & Wee-Kheng Leow. </author> <year> 1991. </year> <title> Integrated segmentation and recognition of hand-printed numerals. </title> <type> Technical Report ACT-NN-010-91, </type> <institution> Microelectronics and Computer Technology Corporation. </institution>
Reference: <author> Lakoff, George. </author> <year> 1987. </year> <title> Women, Fire, and Dangerous Things: What Categories Reveal about the Mind . University of Chicago Press. ||. 1992. What is metaphor? In Advances In Connectionist and Neural Computational Theory, Vol. 2: Analogical Connections, </title> <editor> ed. by K. J. Holyoak & J. A. Barnden. </editor> <publisher> Ablex. </publisher> <address> LeCun, Yann. </address> <year> 1989. </year> <title> Generalization and network design strategies. </title> <type> Technical Report CRG-TR-89-4, </type> <institution> Connectionist Research Group, University of Toronto. </institution>
Reference-contexts: We postulate therefore, that an adequate representation of the concrete domain is an essential component of modeling the semantics of these narratives. Recent work in Cognitive Semantics provides good evidence for this view. In particular, there are proposals for schema-based semantics, as in the case of Image Schemas <ref> (Lakoff 1987) </ref>. The work in Cognitive Semantics, however, lacks a computational model for such theories. 19 Second, we note that the deep semantics of the causal narratives are dynamic and arise from a continuous interaction between input and memory.
Reference: <author> Mozer, Michael, Richard Zemel, & Marlene Behrmann. </author> <year> 1991. </year> <title> Learning to segment images using dynamic feature binding. </title> <type> Technical Report CU-CS-540-91, </type> <institution> Dept. of Computer Science, University of Colorado at Boulder. </institution>
Reference: <author> Nenov, Valeriy I., & Michael G. Dyer. </author> <year> 1993. </year> <title> Perceptually grounded language learning: Part 1 | a neural network architecture for robust sequence association. </title> <booktitle> Connection Science 5. </booktitle> ||, & ||. <year> 1994. </year> <title> Perceptually grounded language learning: Part 2 | DETE: A neural/procedural model. </title> <booktitle> Connection Science 6. </booktitle>
Reference: <author> Nielsen, M., G. Plotkin, & G. Winskel. </author> <year> 1981. </year> <title> Petri nets, event structures, and domains, Part I. </title> <booktitle> Theoretical Computer Science 13. </booktitle>
Reference-contexts: Any representation of the semantics should therefore be of a fine granularity, be flexible and adaptive in the way context affects interpretation, and be able to support concurrent activities in the memory storage, retrieval, and indexing process. Our observations suggest the use of process semantics <ref> (Nielsen et al. 1981) </ref> to characterize the deep semantics of causal narratives. Of special interest to us is the possibility of modeling such processes in structured connectionist models (Feldman 1989). <p> The requirements outlined above suggest a net based model of process semantics. The requirements of learnability and connectionist implementation require us to define special modifications to standard concurrency models (such as Petri Nets and Event Logics <ref> (Nielsen et al. 1981) </ref>). We have done some preliminary investigation of such a model by using variant of Petri Nets to model aspectual distinctions made by different languages. * Mapping the abstract social domain structures into the relevant concrete spatial and experiential domain structures.
Reference: <author> Omohundro, Stephen M. </author> <year> 1992. </year> <title> Best-first model merging for dynamic learning and recognition. </title> <booktitle> In Advances in Neural Information Processing Systems 4 , ed. </booktitle> <publisher> by John E. </publisher>
Reference: <editor> Moody, Steve J. Hanson, & Richard P. Lippman, </editor> <address> 958-965. San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Regier, Terry, </author> <year> 1992. </year> <title> The Acquisition of Lexical Semantics for Spatial Terms: A Connectionist Model of Perceptual Categorization. </title> <institution> Computer Science Division, EECS Department, University of California at Berkeley dissertation. </institution> <note> available as Technical Report TR-92-062, </note> <institution> International Computer Science Institute, Berkeley. </institution> <month> 25 ||. </month> <year> 1993. </year> <title> Two predicted universals in the semantics of space. </title> <booktitle> In Proceedings of the Nineteenth Annual Meeting of the Berkeley Linguistics Society. </booktitle> <institution> University of California, Berkeley. </institution>
Reference: <author> Rissanen, Jorma. </author> <year> 1983. </year> <title> A universal prior for integers and estimation by minimum description length. </title> <journal> The Annals of Statistics 11.416-431. </journal>
Reference: <author> Rumelhart, David E., Geoffrey E. Hinton, & Ronald J. Williams. </author> <year> 1986. </year> <title> Learning internal representations by error propagation. In Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </title> <editor> ed. by James L. </editor> <publisher> McClelland & David E. </publisher>
Reference: <editor> Rumelhart, </editor> <address> 318-362. </address> <publisher> MIT Press. </publisher>
Reference: <author> Shieber, Stuart M. </author> <year> 1986. </year> <title> An Introduction to Unification-Based Approaches to Grammar . Number 4 in CSLI Lecture Note Series. Stanford, Ca.: Center for the Study of Language and Information. </title>
Reference-contexts: The rules that propagate the feature values through the syntactic structure are extensions of context-free rules, and similar to those found in many feature-based grammar theories <ref> (Shieber 1986) </ref>.
Reference: <author> Siskind, Jeffrey Mark, </author> <year> 1992. </year> <title> Naive Physics, Event Perception, Lexical Semantics, and Language Acquisition. </title> <address> Cambridge, Mass.: </address> <institution> Massachussetts Institute of Technology dissertation. </institution>

Reference: <author> Suppes, Patrick, Lin Liang, & Michael B ottner. </author> <year> 1991. </year> <title> Complexity issues in robotic machine learning of natural language. In Modeling Complex Phenomena, </title> <editor> ed. by L. Lam & V. Naroditsky. </editor> <address> New York, N.Y.: </address> <publisher> Springer Verlag. </publisher>
Reference: <author> Wallace, C. S., & P. R. Freeman. </author> <year> 1987. </year> <title> Estimation and inference by compact coding. </title> <journal> Journal of the Royal Statistical Society, Series B 49.240-265. </journal>
Reference: <author> Weber, Susan Hollbach, & Andreas Stolcke. </author> <year> 1990. </year> <title> L 0 : A testbed for miniature language acquisition. </title> <type> Technical Report TR-90-010, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA. </address>
Reference: <author> Whorf, Benjamin Lee. </author> <year> 1956. </year> <title> Language, </title> <booktitle> Thought, and Reality. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <editor> (ed. John B. </editor> <title> Carroll). </title> <type> 26 Wooters, Chuck, & Andreas Stolcke. </type> <year> 1994. </year> <title> Multiple-pronunciation lexical modeling in a speaker-independent speech understanding system. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing, </booktitle> <volume> volume 3, </volume> <pages> 1363-1366, </pages> <address> Yokohama. </address> <booktitle> 27 AI REVIEW SPECIAL VOLUME ON INTEGRATION OF VISION AND LANGUAGE L 0 |The First Five Years of an Automated Language Acquisition Project Jerome Feldman is director of the International Computer Science Institute and Professor of Electrical Engineering and Computer Science at U.C. </booktitle> <address> Berkeley. </address>
Reference: <institution> George Lakoff is Professor of Linguistics at U.C. Berkeley. The other four coauthors have all been graduate students of Computer Science at U.C.Berkeley, working at the International Computer Science Institute. </institution> <note> Terry Regier is now Assistant Professor of Psychology at U. Chicago and Andreas Stolcke is on the scientific staff of SRI International. David Bailey and Srini Narayanan will complete their dissertations in 1996. </note>
References-found: 23

