URL: ftp://ftp.research.microsoft.com/users/lomet/pub/opkey.ps
Refering-URL: http://www.research.microsoft.com/users/lomet/pub/default.htm
Root-URL: http://www.research.microsoft.com
Title: Order Preserving String Compression  
Author: Gennady Antoshenkov David Lomet James Murray 
Address: Maynard, MA  
Affiliation: Digital Equipment Corporation  
Abstract: Order preserving compression can improve sorting and searching performance, and hence the performance of database systems. We describe a new parsing (tokenization) technique that can be applied to variable length "keys", producing substantial compression. It can both compress and decompress data, permitting variable length for dictionary entries and compressed forms. The key notion is to partition the space of strings into ranges, encoding the common prefix of each range. We illustrate our method with padding character compression for multi-field keys, demonstrating the dramatic gains possible. A specific version of the method has been implemented in Digital's Rdb relational database system to enable effective multi-field compression. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bayer, R. and McCreight, E. </author> <title> Organization and maintenance of large ordered indices. </title> <journal> Acta Informatica 1,3(1972), </journal> <pages> 173-189. </pages>
Reference-contexts: AlphaSort [9], the world's fastest sort, uses tag sort. Comparisons can be very fast when a conditioned key is used. B-tree Searching: Index terms in a B-tree <ref> [1] </ref>, can be conditioned keys stored as byte strings within an index page. Index oriented compression techniques such as those in prefix B-trees [2] can be used to shorten the keys, while continuing to permit binary search. Such an approach results in very fast node search and high node fanout.
Reference: [2] <author> Bayer, R. and Unterrauer, K. </author> <title> Prefix B-trees. </title> <journal> ACM Trans. on Database Systems 2,1 (Mar. </journal> <year> 1977) </year> <month> 11-26. </month>
Reference-contexts: Comparisons can be very fast when a conditioned key is used. B-tree Searching: Index terms in a B-tree [1], can be conditioned keys stored as byte strings within an index page. Index oriented compression techniques such as those in prefix B-trees <ref> [2] </ref> can be used to shorten the keys, while continuing to permit binary search. Such an approach results in very fast node search and high node fanout. Order preserving compression can further enhance sort and search performance by shortening the lengths of the conditioned keys.
Reference: [3] <author> Bell, T.C., Cleary, J.G., and Witten, I.H. </author> <title> Text Compression. </title> <publisher> Prentice Hall (1990) London, </publisher> <address> UK </address>
Reference-contexts: 1 Introduction 1.1 Order Preserving Compression Most powerful compression techniques, e.g. Huff-man coding [6] and Ziv-Lempel [11] , do not preserve order <ref> [3] </ref>. Indeed, for most applications, whether order is preserved by compression is irrelevant. Only the resulting storage savings is important. Hence, the data compression community pays very little attention to order preservation (OP). But for databases, the collation order of data is an important property. <p> These are fundamental limitations of most dictionary based methods. They make it hard for dictionary methods to be as effective at compression as arithmetic coding, the next technique we describe. Arithmetic compression <ref> [3] </ref> can also preserve order. It is based on knowing the probabilities of the entries to be compressed. It works by adding cumulative probabilities to the results of prior encodings that have already been calculated. <p> There is no requirement that a given token be mapped in only one way. There are usually two additional requirements that must be satisfied if OP translation is to be used for compression. * all input strings must be encodable. This is called dictionary completeness in <ref> [3] </ref>. * encoded strings must be decodable so as to pro duce the original input string. To perform this context dependent parsing and translation, we decompose the entire string space into disjoint ranges. Each range must have a unique prefix that is one of the tokens on our list.
Reference: [4] <author> Blasgen, M., Casey, R., and Eswaran, K. </author> <title> An Encoding Method for Multi-field Sorting and Indexing. IBM Research Report RJ 1753 (March, 1976), </title> <institution> Almaden Research Center, </institution> <address> San Jose, CA. </address>
Reference-contexts: It is particularly important to compress multi-field keys. Multi-field keys are common in both sorting and searching. And the result of compressing individual fields and then concatenating the resultant variable length strings does not work <ref> [4] </ref>, as we describe subsequently. Without some different approach, each compressed field would need to be padded to a size fixed for the field. A multi-field key with extensive padding can destroy both index node fanout and the performance of compares. <p> Multi-field comparison was recognized as a problem in the System R project. In <ref> [4] </ref>, it was shown that order cannot be preserved when multi-field keys are compressed by simply concatenating the variable length strings resulting from the compression of the individual fields, no matter what information is appended onto the end of each compressed field. <p> The problem is that any end markers may also occur within the strings. Their conclusion was that "an encoder must mutilate the strings in some way" to correctly preserve order. 2.2.1 Prior Work The System R solution is described in <ref> [4] </ref>. Briefly, they propose that padding characters can be truncated if one inserts control characters at intervals of N characters, where N is a fixed parameter, into the resulting concatenated character string. The control characters indicate whether the next field begins or the current field continues. <p> In <ref> [4] </ref>, an example of the representation of a key consisting of the two fields with values "ABCDEF" and "XYZ" is the following, with N = 4: For this method, continuing fields always compare high to fields that are terminating. Further, if both fields are terminating, the longer one compares high.
Reference: [5] <author> ISO. ISO/IEC 9075:1992, </author> <title> Information Technology-Database Language SQL July, </title> <year> 1992. </year>
Reference-contexts: Typically, and surely in this case, the average size of an employee's name is much shorter. It is not unusual to have a maximum length for a NAME field of 50 to 100 bytes while the typical employee name is perhaps 15 to 20 bytes. The SQL standard <ref> [5] </ref> is precise as to what is required when comparing different length character strings. One extends the shorter field with blanks until the shorter field is of the same length as the longer field and then one does the comparison as between two fields of the same length.
Reference: [6] <author> Knuth, D. </author> <title> The Art of Computing Programming. vol. 1 Fundamental Algorithms, vol.3 Sorting and Searching. </title> <publisher> Addison Wesley (1973) Reading, </publisher> <address> MA </address>
Reference-contexts: 1 Introduction 1.1 Order Preserving Compression Most powerful compression techniques, e.g. Huff-man coding <ref> [6] </ref> and Ziv-Lempel [11] , do not preserve order [3]. Indeed, for most applications, whether order is preserved by compression is irrelevant. Only the resulting storage savings is important. Hence, the data compression community pays very little attention to order preservation (OP). <p> The prefix property for a dictionary requires that no dictionary entry be a prefix of any other entry. An "optimal" dictionary method of performing OP compression is the Hu-Tucker algorithm <ref> [6] </ref>. Like Huff-man coding, it builds an optimal weighted binary tree, the weights based on the frequency of the entries to be encoded.
Reference: [7] <author> Lorin, H. </author> <title> Sorting and Sort Systems Addison Wesley (1975) Reading, </title> <address> MA </address>
Reference-contexts: To see how this works, consider specific sorting and searching techniques. Tag Sorting: Instead of moving entire records when sorting, one extracts the sort key (the tag) of each record and stores it with a record pointer <ref> [7] </ref> and sorts this pair, thus greatly reducing data movement and improving cache locality. AlphaSort [9], the world's fastest sort, uses tag sort. Comparisons can be very fast when a conditioned key is used.
Reference: [8] <author> Moffat, A. and Zobel, J. </author> <title> Coding for Compression in Full-text Retrieval Systems. </title> <booktitle> Data Compression Conference (1992) Snowbird, UT, </booktitle> <pages> 72-81. </pages>
Reference-contexts: Dictionary approaches, especially those that can deal with units of multiple symbols, are much faster than arithmetic methods. 1 * Arithmetic compression pretty much requires 1 In <ref> [8] </ref>, arithmetic coding was reported as being a factor of 40 slower than their dictionary approach. that all of the input string be compressed (en-coded). A dictionary approach has much more flexibility. For example, one might compress some entries without compressing others. Indeed, we illustrate this in our running example.
Reference: [9] <author> Nyberg, C., Barclay, T., Cvetanopvic. Z., Gray, J., and Lomet, D. AlphaSort: </author> <title> a RISC Machine Sort Proc. </title> <booktitle> ACM SIGMOD Conf.(May 1994) Minneapolis, </booktitle> <address> MN 233-242. </address>
Reference-contexts: Tag Sorting: Instead of moving entire records when sorting, one extracts the sort key (the tag) of each record and stores it with a record pointer [7] and sorts this pair, thus greatly reducing data movement and improving cache locality. AlphaSort <ref> [9] </ref>, the world's fastest sort, uses tag sort. Comparisons can be very fast when a conditioned key is used. B-tree Searching: Index terms in a B-tree [1], can be conditioned keys stored as byte strings within an index page.
Reference: [10] <author> Zandi, A., Iyer, B. and Langdon, G. </author> <title> Sort Order Preserving Data compression for Extended Alphabets. </title> <booktitle> Data Compression Conference (1993) Snowbird, UT, </booktitle> <pages> 330-339. </pages>
Reference-contexts: Ordering of entries parsed from a longer input string may, however, require information about the substrings that follow the entries. ALM's parsing method permits a much more flexible choice of which entries are to be encoded compared with its only real competitor, the ZIL method <ref> [10] </ref>, which we learned of during the writing of this paper. This permits us, if we wish, to reduce the dictionary size compared with ZIL. ALM's very flexible parsing also permits more choice of compressed forms, leading to potentially higher compression than the ZIL method. <p> While not all interior nodes of a binary tree can be used as ALM encodings, some are acceptable. Figure 2 displays the trees produced by Hu-Tucker and ALM for our example. 5.2 Improving on ZIL Our padding compression example shows the ALM generalization with respect to ZIL <ref> [10] </ref>. Very few byte encodings precede a blank which is used as the padding character. With ALM we can choose to provide better encodings for the blank strings that are followed by characters that compare high to blanks. <p> As we have seen in comparing ALM with Huffman and Hu-Tucker methods, ALM uses the same parsing strategy to decode as it does to encode. Thus, it provides very flexible encodings as well. The encodings need not have the prefix property. This is not discussed with the ZIL method <ref> [10] </ref>. 6 Discussion 6.1 Framework ALM encoding is a framework for performing variable length order preserving translations. It gives you a new trailing context method for uniquely tokenizing strings.
Reference: [11] <author> Ziv, J., Lempel, A. </author> <title> Compression of individual se quences via variable-rate coding. </title> <journal> IEEE Trans. Infor mation Theory IT-24, </journal> <month> 5 (Sept. </month> <year> 1978) </year> <month> 530-536. </month>
Reference-contexts: 1 Introduction 1.1 Order Preserving Compression Most powerful compression techniques, e.g. Huff-man coding [6] and Ziv-Lempel <ref> [11] </ref> , do not preserve order [3]. Indeed, for most applications, whether order is preserved by compression is irrelevant. Only the resulting storage savings is important. Hence, the data compression community pays very little attention to order preservation (OP).
References-found: 11

