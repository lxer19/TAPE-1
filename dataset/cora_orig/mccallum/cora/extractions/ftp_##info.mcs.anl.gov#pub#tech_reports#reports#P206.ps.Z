URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P206.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts91.htm
Root-URL: http://www.mcs.anl.gov
Title: AN IMPROVED INCOMPLETE CHOLESKY FACTORIZATION  
Phone: 60439-4801  
Author: Mark T. Jones and Paul E. Plassmann 
Note: This work was supported by the Applied Mathematical Sciences subprogram of the Office of Energy Research, U.S. Department of Energy, under Contract W-31-109-Eng-38.  
Date: January 1991 (Revised July 1992)  
Address: 9700 South Cass Avenue Argonne, Illinois  Preprint MCS-P206-0191  
Affiliation: ARGONNE NATIONAL LABORATORY  Mathematics and Computer Science Division  
Abstract: Incomplete factorization has been shown to be a good preconditioner for the conjugate gradient method on a wide variety of problems. It is well known that allowing some fill-in during the incomplete factorization can significantly reduce the number of iterations needed for convergence. Allowing fill-in, however, increases the time for the factorization and for the triangular system solves. In addition, it is difficult to predict a priori how much fill-in to allow and how to allow it. The unpredictability of the required storage/work and the unknown benefits of the additional fill-in make such strategies impractical to use in many situations. In this paper we motivate, and then present, two "black-box" strategies that significantly increase the effectiveness of incomplete Cholesky factorization as a preconditioner. These strategies require no parameters from the user and do not increase the cost of the triangular system solves. Efficient implementations for these algorithms are described. These algorithms are shown to be successful for a variety of problems from the Harwell-Boeing sparse matrix collection. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Axelsson and N. Munksgaard, </author> <title> Analysis of incomplete factorizations with fixed storage allocation, in Preconditioning Methods Theory and Applications, </title> <editor> D. Evans, ed., Gordon and Breach, </editor> <year> 1983, </year> <pages> pp. 219-241. </pages>
Reference-contexts: More complex strategies where the tolerance varies during the factorization according to the amount of fill-in included at each stage of the factorization have been proposed <ref> [1, 14] </ref>. These more complex strategies keep the storage required by the incomplete factor within the fixed amount of storage allocated by the user. The number of nonzeros in the factor at step k is compared with the amount of space that the user has allocated for the incomplete factor.
Reference: [2] <author> I. S. Duff, R. Grimes, J. Lewis, and B. Poole, </author> <title> Sparse matrix test problems, </title> <note> SIGNUM Newsletter, 17 (1982), p. 22. </note>
Reference-contexts: The matrices used for the comparisons are described in Table 2. The first five problems were generated from finite element models from the Computational Structural Mechanics Branch at NASA Langley Research Center. The last five problems are from the Harwell-Boeing Sparse Matrix Collection <ref> [2] </ref>. A first set of experiments was run using the environment provided by the CLAM package [5]. A second set of experiments were run using a Fortran program on a Sun Sparcstation.
Reference: [3] <author> I. S. Duff and G. A. Meurant, </author> <title> The effect of ordering on preconditioned conjugate gradients, </title> <journal> BIT, </journal> <volume> 29 (1989), </volume> <pages> pp. 635-657. </pages>
Reference-contexts: The only parameters that must be chosen, aside from the initial c, are the formula for altering c and the amount of storage to allocate for the incomplete factor. Fixed fill-in and drop-tolerance strategies were evaluated on grid problems with with five-point and nine-point stencils by Duff and Meurant <ref> [3] </ref>. They compared a level 1 fill-in algorithm to a no-fill incomplete Cholesky factorization and found that the extra work in the factorization and forward/back substitutions was greater than the work saved by the reduced number (if any) of iterations. <p> Given the symmetric positive definite matrix A, let A = LL T be the complete Cholesky factorization and A = ^ L ^ L T R be an incomplete factorization. The size and structure of R have typically been examined for insights into the goodness of the preconditioner <ref> [3] </ref>. Ultimately, however, the goal is to reduce the condition number of the matrix B = ^ L 1 A ^ L T [9].
Reference: [4] <author> R. W. Freund and N. M. Nachtigal, </author> <title> An implementation of the look-ahead Lanczos algorithm for non-Hermitian matrices: Part II, </title> <type> Technical report, </type> <institution> RIACS, </institution> <year> 1990. </year>
Reference-contexts: A drop-tolerance strategy was also evaluated and was found to be cost-effective if the right drop-tolerance was selected, but was found to be more difficult from an implementation standpoint. Freund and Nachtigal <ref> [4] </ref> have independently developed an algorithm that is similar to our proposed algorithm. Their algorithm combines drop-tolerances with a cap on the number of nonzeros that can be kept per row.
Reference: [5] <author> W. D. Gropp, D. E. Foulser, and S. Chang, </author> <title> CLAM User's Guide, </title> <publisher> Scientific Computing Associates, </publisher> <year> 1989. </year>
Reference-contexts: The first five problems were generated from finite element models from the Computational Structural Mechanics Branch at NASA Langley Research Center. The last five problems are from the Harwell-Boeing Sparse Matrix Collection [2]. A first set of experiments was run using the environment provided by the CLAM package <ref> [5] </ref>. A second set of experiments were run using a Fortran program on a Sun Sparcstation. For these experiments, each matrix was scaled so that its diagonal was the identity and the right-hand side was chosen to be the normalized vector of ones.
Reference: [6] <author> I. Gustafsson, </author> <title> A class of first order factorization methods, </title> <journal> BIT, </journal> <volume> 18 (1978), </volume> <pages> pp. 142-156. </pages>
Reference-contexts: For example, fixed fill-in strategies for naturally-ordered matrices arising from finite-difference stencils have been proposed that allow extra diagonals of fill-in [12, 13]. Gustafs-son has proposed modifications to the methods in [12] for which has he proved have better convergence than the standard incomplete factorizations <ref> [6] </ref>. This concept of extra diagonals is only useful within the context of naturally-ordered matrices arising from finite-difference stencils. For general sparse matrices, the extra diagonal concept can be generalized to the concept of "levels" of fill-in.
Reference: [7] <author> M. R. Hestenes and E. </author> <title> Stiefel, Methods of conjugate gradients for solving linear systems, </title> <journal> Journal of Research of the National Bureau of Standards, </journal> <volume> 49 (1952), </volume> <pages> pp. 409-436. </pages>
Reference-contexts: 1. Introduction. One of the most successful iterative methods for solving large sparse symmetric positive definite linear systems is the preconditioned conjugate gradient method <ref> [7] </ref>. The incomplete Cholesky factorization, proposed by Meijerink and van der Vorst [12] for use on symmetric M-matrices, has been shown to be a very effective preconditioner for a wide variety of problems. However, the incomplete Cholesky factorization can fail for symmetric positive definite matrices [10].
Reference: [8] <author> M. T. Jones and P. E. Plassmann, </author> <title> Scalable iterative solution of sparse linear systems, </title> <type> Preprint MCS-P277-1191, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1991. </year>
Reference-contexts: In other recent work, we have shown that coloring heuristics can be used to provide orderings for positive definite matrices arising in practical problems <ref> [8] </ref>. These orderings provide a large amount of exploitable parallelism for incomplete factorization and the accompanying triangular system solves. A possible drawback to the two strategies presented in this paper is that, if implemented in a straightforward fashion, they will destroy the parallelism inherent in a given ordering.
Reference: [9] <author> S. Kaniel, </author> <title> Estimates for some computational techniques in linear algebra, </title> <journal> Mathematics of Computation, </journal> <volume> 20 (1966), </volume> <pages> pp. 369-378. </pages>
Reference-contexts: The size and structure of R have typically been examined for insights into the goodness of the preconditioner [3]. Ultimately, however, the goal is to reduce the condition number of the matrix B = ^ L 1 A ^ L T <ref> [9] </ref>.
Reference: [10] <author> D. S. Kershaw, </author> <title> The incomplete Cholesky-conjugate gradient method for the iterative solution of systems of linear equations, </title> <journal> Journal of Computational Physics, </journal> <volume> 26 (1978), </volume> <pages> pp. 43-65. </pages>
Reference-contexts: The incomplete Cholesky factorization, proposed by Meijerink and van der Vorst [12] for use on symmetric M-matrices, has been shown to be a very effective preconditioner for a wide variety of problems. However, the incomplete Cholesky factorization can fail for symmetric positive definite matrices <ref> [10] </ref>. To alleviate this problem, Manteuffel [11] introduced the shifted incomplete factorization algorithm. No-fill incomplete Cholesky factorization computes incomplete factors, ^ L ^ L T , of the original matrix A, where ^ L has nonzeros only in those positions that correspond to nonzero positions in A [12].
Reference: [11] <author> T. A. Manteuffel, </author> <title> An incomplete factorization technique for positive definite linear systems, </title> <journal> Mathematics of Computation, </journal> <volume> 34 (1980), </volume> <pages> pp. 473-497. </pages>
Reference-contexts: However, the incomplete Cholesky factorization can fail for symmetric positive definite matrices [10]. To alleviate this problem, Manteuffel <ref> [11] </ref> introduced the shifted incomplete factorization algorithm. No-fill incomplete Cholesky factorization computes incomplete factors, ^ L ^ L T , of the original matrix A, where ^ L has nonzeros only in those positions that correspond to nonzero positions in A [12]. <p> This strategy was sometimes much better, but not consistently or dramatically better than incomplete factorization with no fill-in. Aside from being better preconditioners, these two strategies often allow for a more stable incomplete factorization. If we use shifted incomplete factorization <ref> [11] </ref> to form a positive definite preconditioner, the shift required to make the factorization positive definite is often smaller for our two strategies than it is for incomplete factorization without fill-in. <p> The search for the optimal ff is halted when the number of iterations begins to increase; the reasoning for this search pattern is based on the results presented in <ref> [11] </ref>. When the optimal ff differs from the first acceptable ff, the results for the optimal value are reported in parentheses. Again, the concern was whether the superiority of the column and row algorithms was independent of whether the "critical" or "optimal" ff was found.
Reference: [12] <author> J. Meijerink and H. A. van der Vorst, </author> <title> An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix, </title> <journal> Mathematics of Computation, </journal> <volume> 31 (1977), </volume> <pages> pp. </pages> <month> 148-162. </month> <title> [13] , Guidelines for the usage of incomplete decompositions in solving sets of linear equations as they occur in practical problems, </title> <journal> Journal of Computational Physics, </journal> <volume> 44 (1981), </volume> <pages> pp. 134-155. </pages>
Reference-contexts: 1. Introduction. One of the most successful iterative methods for solving large sparse symmetric positive definite linear systems is the preconditioned conjugate gradient method [7]. The incomplete Cholesky factorization, proposed by Meijerink and van der Vorst <ref> [12] </ref> for use on symmetric M-matrices, has been shown to be a very effective preconditioner for a wide variety of problems. However, the incomplete Cholesky factorization can fail for symmetric positive definite matrices [10]. To alleviate this problem, Manteuffel [11] introduced the shifted incomplete factorization algorithm. <p> To alleviate this problem, Manteuffel [11] introduced the shifted incomplete factorization algorithm. No-fill incomplete Cholesky factorization computes incomplete factors, ^ L ^ L T , of the original matrix A, where ^ L has nonzeros only in those positions that correspond to nonzero positions in A <ref> [12] </ref>. To improve the quality of the preconditioner, many strategies for altering the pattern of the nonzeros in the incomplete factor have been proposed. For the purposes of this paper, we classify these strategies as either fixed fill-in or drop-tolerance strategies. <p> The pattern may be determined by a symbolic factorization step or may be known a priori if the matrix has a very regular structure. For example, fixed fill-in strategies for naturally-ordered matrices arising from finite-difference stencils have been proposed that allow extra diagonals of fill-in <ref> [12, 13] </ref>. Gustafs-son has proposed modifications to the methods in [12] for which has he proved have better convergence than the standard incomplete factorizations [6]. This concept of extra diagonals is only useful within the context of naturally-ordered matrices arising from finite-difference stencils. <p> For example, fixed fill-in strategies for naturally-ordered matrices arising from finite-difference stencils have been proposed that allow extra diagonals of fill-in [12, 13]. Gustafs-son has proposed modifications to the methods in <ref> [12] </ref> for which has he proved have better convergence than the standard incomplete factorizations [6]. This concept of extra diagonals is only useful within the context of naturally-ordered matrices arising from finite-difference stencils.
Reference: [14] <author> N. Munksgaard, </author> <title> Solving sparse symmetric sets of linear equations by preconditioned conjugate gradients, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 6 (1980), </volume> <pages> pp. 206-219. </pages>
Reference-contexts: In these strategies nonzeros are included in the incomplete factor if they are larger than some threshold tolerance. A simple drop-tolerance strategy is to set the tolerance for element a ij to be c p a ii a jj , where c is a constant <ref> [14] </ref>. Neither the pattern or number of nonzeros in the incomplete factor can be determined a priori for such a strategy; they are determined during the factorization. <p> More complex strategies where the tolerance varies during the factorization according to the amount of fill-in included at each stage of the factorization have been proposed <ref> [1, 14] </ref>. These more complex strategies keep the storage required by the incomplete factor within the fixed amount of storage allocated by the user. The number of nonzeros in the factor at step k is compared with the amount of space that the user has allocated for the incomplete factor.
References-found: 13

