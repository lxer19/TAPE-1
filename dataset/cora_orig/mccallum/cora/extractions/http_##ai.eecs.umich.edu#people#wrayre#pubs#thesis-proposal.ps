URL: http://ai.eecs.umich.edu/people/wrayre/pubs/thesis-proposal.ps
Refering-URL: http://ai.eecs.umich.edu/people/wrayre/pubs.html
Root-URL: http://www.cs.umich.edu
Email: robert.wray@umich.edu  
Title: Learning While Doing: A Knowledge Compilation Approach to Learning in External Environments  
Author: Robert E. Wray, III 
Address: 1101 Beal Avenue  Ann Arbor, MI 48109  
Affiliation: Artificial Intelligence Laboratory  University of Michigan  
Abstract: Integrated, intelligent agents must be able to adapt their behavior in dynamic environments. A number of systems that interact in the world use knowledge organized hierarchically. For these systems, an obvious approach to learning is to compile the steps leading to a particular action, allowing an agent to become increasingly responsive to the environment with experience. This work presents an analysis of the requirements for such knowledge compilation in external domains. These requirements underspecify the exact nature of compilation, and a diverse group of architectures are considered for the addition of knowledge compilation. Although an architecture can meet the general requirements, its functional constraints can also present additional problems for realizing compilation. Analyzing these problems and the contributing functional constraints leads to the identification of solution alternatives. A methodology for exploring the characteristics of different alternatives is introduced, including qualitative and quantitative evaluation criteria. These will guide both implementation decisions and the empirical comparison of implemented alternatives. Preliminary results suggest that several of the presented approaches are able to compile knowledge robustly for at least a simple task. Further, the developing methodology appears to facilitate meaningful comparison of the approaches. The proposed future work involves extending the approaches to more complex tasks and more relevant domains, in order to assess the generality of the different alternatives. Finally, evaluation and the possible contributions of the overall work are outlined by considering the versatility, efficiency, scalability and generality of the individual approaches to knowledge compilation to be developed and compared in the proposed thesis. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agre, P. E. and D. Chapman (1987, </author> <month> August). </month> <title> Pengi: An implementation of a theory of activity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Seattle, Washington, </address> <pages> pp. 196-201. </pages>
Reference: <author> Bresina, J., M. Drummond, and S. </author> <month> Kedar </month> <year> (1993). </year> <title> Reactive, integrated systems pose new problems for machine learning. </title> <editor> In S. Minton (Ed.), </editor> <title> Machine Learning Methods for Planning, </title> <booktitle> Chapter 6, </booktitle> <pages> pp. 159-195. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The architecture supports several different types of learning, including the operationalization of certain kinds of its knowledge. 3.7 The Entropy Reduction Engine The Entropy Reduction Engine (ERE) <ref> (Bresina, Drummond, and Kedar 1993) </ref> integrates real-time planning, scheduling and control. It consists of three modules. The Reductor identifies problem solving strategies. One such strategy could be a hierarchical decomposition of a task, represented as problem reduction rules.
Reference: <author> Brooks, R. A. </author> <year> (1986, </year> <month> March). </month> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal on Robotics and Automation RA-2 (1), </journal> <pages> 14-22. </pages>
Reference-contexts: This rule would fire twice (once to move the gripper to column 1, then to column 2) and move the gripper 1 I am making an assumption that the agent has internal goals. In many reactive systems (e.g., sub-sumption <ref> (Brooks 1986) </ref>), no internal symbols are supported. For these systems, the goal conditions in the rule would be external or hard-wired into the agent. I use this particular representation to readily compare it to the hierarchical example that follows. 7 over the current tower.
Reference: <author> Carbonell, J. G., C. A. Knoblock, and S. </author> <title> Minton (1991). PRODIGY: An integrated architecture for planning and learning. </title> <editor> In K. VanLehn (Ed.), </editor> <booktitle> Architectures for Intelligence, Chapter 9, </booktitle> <pages> pp. 241-278. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Explanation-based learning (EBL) approaches have been successfully used to make problem solving knowledge operational for a number of different types of problem solving including concept formation (Mitchell, Kellar, and Kedar-Cabelli 1986), planning (Fikes, Hart, and Nilsson 1972; Minton 1988) and scheduling <ref> (Carbonell, Knoblock, and Minton 1991) </ref>. EBL uses a domain theory to generate an explanation of why some training instance is an example of a goal concept according to some operationality criterion (DeJong and Mooney 1986). <p> The only difficulty that Theo-Agent presents in terms of the general requirements is that is lacks any notion of persistence. All active drives and beliefs are completely dependent upon sensor input. Therefore, Theo-Agent can not reason about anything not directly sensed in its local environment. 3.5 Prodigy Prodigy <ref> (Carbonell, Knoblock, and Minton 1991) </ref> is not an execution system but rather a deliberate planning and problem solving system. It is discussed here because it meets most of the general requirements other than real-time execution. <p> The agent's knowledge of a primitive action is thus separate from the actual implementation of the action. This is in contrast to many planning systems (e.g., STRIPS (Fikes, Hart, and Nilsson 1972) and Prodigy <ref> (Carbonell, Knoblock, and Minton 1991) </ref>) where the agent's knowledge of an action is also used to represent the execution of the action. Second, this domain is also truly dynamic.
Reference: <author> Chapman, D. </author> <year> (1987). </year> <title> Planning for conjunctive goals. </title> <booktitle> Artificial Intelligence 32 (3), </booktitle> <pages> 333-377. </pages>
Reference-contexts: I illustrate the contrast between purely reactive and hierarchical execution systems with a simple example which will be used throughout the rest of this proposal. This example is based on the blocks world domain familiar from planning <ref> (Chapman 1987) </ref> but, rather than planning about the movement of blocks, in this example an agent must actually move blocks to build towers, walls, etc. <p> The test bed developed for this work, the dynamic blocks world, facilitates controlled experimentation while posing tasks that distill the important properties of dynamic domains. Tasks in the test bed are similar to blocks world problems familiar in planning <ref> (Chapman 1987) </ref>. However, there are two key differences. First, actions are not internal. An agent generates primitive commands (such as "open the gripper" or "move-up 2 steps"), which are then executed by a simulator independent of the architecture.
Reference: <author> Chien, S. A., M. T. Gervasio, and G. F. DeJong (1991, </author> <month> June). </month> <title> On becoming decreasingly reactive: Learning to deliberate minimally. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <address> Evanston, </address> <publisher> Illinois, </publisher> <pages> pp. 288-292. </pages>
Reference: <author> DeJong, G. and S. Bennett (1995, </author> <month> Aug). </month> <title> Extending classical planning to real-world execution with machine learning. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada, </address> <pages> pp. 1153-1159. </pages>
Reference: <author> DeJong, G. and R. </author> <title> Mooney (1986). Explantion-based learning: An alternative view. </title> <booktitle> Machine Learning 1 (2), </booktitle> <pages> 145-176. </pages>
Reference-contexts: EBL uses a domain theory to generate an explanation of why some training instance is an example of a goal concept according to some operationality criterion <ref> (DeJong and Mooney 1986) </ref>. In external domains, the goal concept for EBL is the conditions for which a primitive operation should be generated in the current state, where the current state is defined by the available percepts and task goals.
Reference: <author> Doorenbos, R. </author> <year> (1994, </year> <month> August). </month> <title> Combining left and right unlinking for matching a large number of learned rules. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <address> Seattle, WA. </address>
Reference-contexts: This approach has the advantage of nearly immediate use; S-R rules can be applied as quickly as their conditions are matched. This assumes that the match process takes place faster than the world changes, a reasonable assumption given the current technology for matching rules <ref> (Doorenbos 1994) </ref>. However, stimulus-response rules alone are often problematic because they are difficult to write for complex systems. <p> For instance, for a rule-based system, the match time for a rule set should be no more than linear in the number of rules and preferably sub-linear or independent of the number of rules. Examples such as the RETE algorithm <ref> (Doorenbos 1994) </ref> suggest that current matching technology can support such a requirement. 7. Incremental Knowledge Bases: Knowledge compilation will add new knowledge incrementally to the agent's knowledge base. <p> Experiments with production systems have demonstrated that productions and the underlying match tech 19 nology can support a very large number of productions (10 6 ) without serious impact on match time <ref> (Doorenbos 1994) </ref>. (a) Homogeneous Knowledge Base (b) Impenetrable Knowledge Base 4. Attribute/Value Representation is the Medium for All Things: Soar is a fully symbolic system, representing all features in terms of attribute-value pairs. This requires that all input to the system be represented in this form.
Reference: <author> Erol, K., J. Hendler, and D. S. </author> <title> Nau (1994). HTN planning: Complexity and ex-pressivity. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, Washington, </address> <pages> pp. 1123-1128. </pages>
Reference-contexts: Such hierarchical decomposition <ref> (Erol, Hendler, and Nau 1994) </ref> has been used extensively in plan generation systems. Additionally, a number of different AI systems (Firby 1987; Georgeff and Lansky 1987; Laird, Newell, and Rosenbloom 1987; Musliner, Durfee, and Shin 1993) have used this approach to execute tasks in complex, dynamic environments. <p> Such decomposition has been influential in both planning <ref> (Erol, Hendler, and Nau 1994) </ref> and previous execution systems (Firby 1987; Georgeff and Lansky 1987; Laird, Newell, and Rosenbloom 1987). Decomposition allows a performance system to react within the context of intermediate goals.
Reference: <author> Fikes, R. E., P. E. Hart, and N. J. </author> <title> Nilsson (1972). Learning and executing generalized robot plans. </title> <booktitle> Artificial Intelligence 3, </booktitle> <pages> 251-288. </pages>
Reference-contexts: Knowledge compilation has been used successfully in static domains and in dynamic domains in which the learning occurs "off-line" from the execution. For example, STRIPS <ref> (Fikes, Hart, and Nilsson 1972) </ref> compiled macro-operators over a static planning space even though these operators were then used to direct a robot in the external world. <p> The agent's knowledge of a primitive action is thus separate from the actual implementation of the action. This is in contrast to many planning systems (e.g., STRIPS <ref> (Fikes, Hart, and Nilsson 1972) </ref> and Prodigy (Carbonell, Knoblock, and Minton 1991)) where the agent's knowledge of an action is also used to represent the execution of the action. Second, this domain is also truly dynamic.
Reference: <author> Firby, R. J. </author> <year> (1987, </year> <month> August). </month> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Seattle, Washington, </address> <pages> pp. 202-206. </pages>
Reference-contexts: Similarly, if an architecture meets the requirements then knowledge compilation should be fairly straightforward, although there may be some complication due to additional constraints imposed by that particular architecture. 3.1 The RAP Planner The RAP Planner <ref> (Firby 1987) </ref> executes autonomous processes called reactive action packages, or RAPs. A RAP is a unit of knowledge invoked to pursue some goal and many different RAPs can be active simultaneously. An interpreter chooses which among all active RAPs to execute for each execution cycle.
Reference: <author> Gat, E. </author> <year> (1991). </year> <title> Integrating planning and reacting in a heterogeneous asynchronous architecture for mobile robots. </title> <journal> SIGART BULLETIN 2 , 71-74. </journal>
Reference-contexts: For instance, the selection among these items on the execution queue could become increasingly problematic because conflict resolution between competing RAPS is architectural and not open to knowledge-based deliberation. 3.2 ATLANTIS The ATLANTIS architecture <ref> (Gat 1991) </ref> explicitly addresses the need for both reactive and deliberate behavior in an execution system. It is organized into three layers. 13 The control layer consists of modules that behave like a purely reactive controller, connecting inputs directly to actuators with no internal state.
Reference: <author> Georgeff, M. and A. L. </author> <title> Lansky (1987, August). Reactive reasoning and planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Seattle, Washington, </address> <pages> pp. 677-682. </pages>
Reference-contexts: The sequencing layer can elaborate previously activated primitive activities with additional parameters as execution proceeds. Thus, there is not a clear distinction between a primitive activity and the sequencing layer processing that initiates and modifies it. 3.3 The Procedural Reasoning System The Procedural Reasoning System <ref> (Georgeff and Lansky 1987) </ref>, or PRS, is specifically designed to be an embedded, real-time agent. It is based around an interpreter that chooses procedures (knowledge areas or KAs) to execute based on the current state and goals (called, within PRS, beliefs and desires, respectively).
Reference: <author> Hanks, S., M. Pollack, and P. R. Cohen (1993, Winter). </author> <title> Benchmarks, test beds, controlled experimentation and the design of agent architectures. </title> <journal> AI Magazine 14, </journal> <pages> 17-42. </pages>
Reference-contexts: This allows results from the test bed comparisons to identify alternatives to pursue in the real domains while the results from real domains can feed back into the test bed, suggesting new capabilities to examine and additional evaluation criteria. 5.1 Empirical Comparison Using Test Beds A test bed <ref> (Hanks, Pollack, and Cohen 1993) </ref> is simply some virtual environment in which to perform experiments. For the purposes of this work, a test bed strategy will have two significant benefits: 1. <p> One could argue that building towers is only a small part of the whole capability. This problem is inherent with the use of test beds <ref> (Hanks, Pollack, and Cohen 1993) </ref> but claiming any general result from experience in a specific task environment faces the same problem (McDermott 1976). I will address this issue later, in the evaluation of the generality of the alternatives.
Reference: <author> Hayes-Roth, B. </author> <year> (1985, </year> <month> July). </month> <title> A blackboard architecture for control. </title> <booktitle> Artificial Intelligence 26 (3), </booktitle> <pages> 251-321. </pages> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> Alan H. Bond and Les Gasser, editors, </editor> <address> pages 503-540, </address> <publisher> Morgan Kaufmann, 1988.). </publisher>
Reference: <author> Hayes-Roth, B. </author> <year> (1991). </year> <title> Making intelligent systems adapative. </title> <editor> In K. VanLehn (Ed.), </editor> <booktitle> Architectures for Intelligence, Chapter 11, </booktitle> <pages> pp. 301-321. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Laird, J. E. </author> <year> (1993). </year> <title> Extending problem spaces to external environments. </title> <editor> In P. Rosembloom, J. Laird, and A. Newell (Eds.), </editor> <booktitle> The Soar Papers: Research on 47 Integrated Intelligence, Chapter 63, </booktitle> <pages> pp. 1295-1308. </pages> <institution> Massachusetts Institute of Technology. </institution>
Reference-contexts: However, this hierarchical representation captures the flexibility necessary for agents behaving in complex environments. Furthermore, the approach has been used for both stick-level control of an aircraft in simulation <ref> (Pearson, Huffman, Willis, Laird, and Jones 1993) </ref> and higher level tactical flight (Tambe, Johnson, Jones, Koss, Laird, Rosenbloom, and Schwamb 1995) for medium sized (400-3000 rule) real time expert systems, indicating the feasibility of such an approach. 2.2 Addressing Problems with Hierarchical Knowledge Hierarchical knowledge is economical and flexible, but it
Reference: <author> Laird, J. E., A. Newell, and P. S. </author> <title> Rosenbloom (1987). Soar: An architecture for general intelligence. </title> <booktitle> Artificial Intelligence 33, </booktitle> <pages> 1-64. </pages>
Reference-contexts: While this approach is subject to local extrema just like any hill-climbing approach (the starting point may dictate what space is actually explored), a careful choice of a very general architecture should reduce the influence of this decision on the overall results. Soar <ref> (Laird, Newell, and Rosenbloom 1987) </ref> is the specific choice of architecture, based on the requirements developed in the following section and a survey of related work in the third section. 2 Compiling Over Hierarchical Knowledge Autonomous agents must be able to respond in real time to the demands of complex, dynamic, <p> Thus, ERE has a decomposition mechanism in the Projector, a reactive component in the Reactor, and compiles SCRs correctly and in real-time, adding them incrementally to the system's knowledge base. Effects due to the size of the knowledge base are unknown. 3.8 Soar The Soar architecture <ref> (Laird, Newell, and Rosenbloom 1987) </ref> has been used in both real-time execution domains, like PRS and RAPs, and planning domains like Prodigy. Soar's behavior is driven by the decision cycle. This cycle consists of a number of knowledge retrievals, corresponding to the firing of (possibly many) productions.
Reference: <author> Laird, J. E. and P. S. </author> <month> Rosenbloom </month> <year> (1990, </year> <month> Aug). </month> <title> Integrating execution, planning, and learning in Soar for external environments. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, Massachusetts, </address> <pages> pp. 1022-1029. </pages>
Reference: <author> Laird, J. E., P. S. Rosenbloom, and A. </author> <title> Newell (1986a). Chunking in Soar: The anatomy of a general learning mechanism. </title> <booktitle> Machine Learning 1 (1), </booktitle> <pages> 11-46. </pages>
Reference-contexts: Therefore, the object of EBL in execution environments is to operationalize appropriately the generation of a primitive output command. EBL algorithms such as EBG (Mitchell, Kellar, and Kedar-Cabelli 1986) and chunking <ref> (Laird, Rosenbloom, and Newell 1986a) </ref> also use generalization schemes that would allow the compiled rule to be more general than the over-specific Rule 6. The level at which knowledge should be made operational is an open question. <p> This leaves the second part of the algorithm, generalization, to consider. While some EBL system's "re-prove" the explanation to create a generalized explanation, several systems use architecture dependent techniques to improve efficiency. Examples include Prodigy's EBS algorithm (Minton 1988) and Soar's chunking mechanism <ref> (Laird, Rosenbloom, and Newell 1986a) </ref>. 2. Symbolic Knowledge: Knowledge compilation is dependent upon an explicit, symbolic domain theory and is an analytic technique in that the knowledge to execute the required action is available but not fully operational. <p> Because task goals are represented as architectural goals, this then implies that the architecture supports the persistence of task goals in the execution hierarchy. (a) Architecture Supports Persistence of Goals in the Hierarchy (b) Task Goal = Architectural Goal 7. Chunking of All Goal Results: Chunking <ref> (Laird, Rosenbloom, and Newell 1986a) </ref> is an explanation-based learning algorithm which converts decision steps 20 under an impasse into a production (or series of productions). It occurs continuously (each time there is a result passed to higher state) and requires only a fraction of the decision cycle to execute.
Reference: <author> Laird, J. E., P. S. Rosenbloom, and A. </author> <title> Newell (1986b). Overgeneralization during knowledge compilation in soar. </title> <editor> In T. G. Dietterich (Ed.), </editor> <booktitle> Proceedings of the Workshop on Knowledge Compilation. </booktitle>
Reference-contexts: For example, each time a similar experience is encountered, all the knowledge in the decomposition must be brought to bear, taking time. Learning from this experience could be used to speed up performance by "compiling" the decomposition into a more operational form. Knowledge compilation <ref> (Laird, Rosenbloom, and Newell 1986b) </ref> is analytic rather than inductive. In contrast, reinforcement learning techniques (Sutton 1988) have been used to empirically determine appropriate actions in similar domains. <p> Although this is more of a requirement for the compilation algorithm, it does also make demands on the execution system. For instance, the target language of compilation must be sufficient for describing the necessary subgoal computations <ref> (Laird, Rosenbloom, and Newell 1986b) </ref>. 9. Architecture Can Recognize When a Primitive is Generated: A final requirement is that the architecture must "know" when a primitive command is generated because this is necessary to trigger the compilation mechanism.
Reference: <author> McDermott, D. </author> <year> (1976). </year> <booktitle> Artificial intelligence meets natural stupidity. SIGART Newsletter 57, </booktitle> <pages> 144-160. </pages>
Reference-contexts: One could argue that building towers is only a small part of the whole capability. This problem is inherent with the use of test beds (Hanks, Pollack, and Cohen 1993) but claiming any general result from experience in a specific task environment faces the same problem <ref> (McDermott 1976) </ref>. I will address this issue later, in the evaluation of the generality of the alternatives. For now, the tasks will necessarily be seen as limited instantiations of some capability for the dynamic blocks world. Individual tasks for some of the capabilities presented previously have been developed.
Reference: <author> Minton, S. </author> <year> (1988). </year> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: IF Goal (Put-On-Table (x)) Clear (x) Left-Of (Gripper, x) Higher (Gripper, x) THEN Execute (Step (right, Gripper)) A commitment to a particular level of operationality may be viewed as a way to address the utility problem <ref> (Minton 1988) </ref>. If the utility problem may be ignored (due to the nature of the environment or the characteristics or the problem solver), then the "best" level of operationality may be determined through performance, rather than making an arbitrary assumption a priori. <p> Thus, this component of EBL impacts actual performance minimally. This leaves the second part of the algorithm, generalization, to consider. While some EBL system's "re-prove" the explanation to create a generalized explanation, several systems use architecture dependent techniques to improve efficiency. Examples include Prodigy's EBS algorithm <ref> (Minton 1988) </ref> and Soar's chunking mechanism (Laird, Rosenbloom, and Newell 1986a). 2. Symbolic Knowledge: Knowledge compilation is dependent upon an explicit, symbolic domain theory and is an analytic technique in that the knowledge to execute the required action is available but not fully operational.
Reference: <author> Mitchell, T. M. </author> <year> (1990, </year> <month> Aug). </month> <title> Becoming increasingly reactive. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, Massachusetts, </address> <pages> pp. 1051-1058. </pages>
Reference-contexts: However, PRS supports multiple systems running asynchronously with data channels connecting separate agents. Thus, in a learning PRS, an approach to combating any slowdown might be to distribute an agent's knowledge across multiple PRSs. 3.4 Theo-Agent Theo-Agent <ref> (Mitchell 1990) </ref> integrates planning, reacting and knowledge compilation. The architecture reacts whenever possible, deferring to decomposition only when necessary. Results of decomposition are compiled into reactive stimulus-response (S-R) rules which are added incrementally to the agent's knowledge base. <p> Previous uses of attention mechanisms in Soar (Nelson, Lehman, and John 1994; Wiesmeyer and Laird 1991) have been used primarily for cognitive simulation and have been tightly bound to the task and domain. There have been other attempts to use symbolic attention mechanisms in intelligent agent architectures. Theo-Agent <ref> (Mitchell 1990) </ref> uses a sensor policy to determine if features should be sensed "lazily" or "eagerly." The AIS architecture also includes an explicit (declarative) representation of the system's current state and control decisions in order to allow the I/O subsystem to use its knowledge to selectively filter and transform incoming data.
Reference: <author> Mitchell, T. M., R. M. Kellar, and S. T. </author> <month> Kedar-Cabelli </month> <year> (1986). </year> <title> Explantion-based generalization: A unifying view. </title> <booktitle> Machine Learning 1 (1), </booktitle> <pages> 47-80. </pages>
Reference-contexts: Another way of expressing the compilation problem is that the knowledge required for performing the task is present but is not fully operational. Explanation-based learning (EBL) approaches have been successfully used to make problem solving knowledge operational for a number of different types of problem solving including concept formation <ref> (Mitchell, Kellar, and Kedar-Cabelli 1986) </ref>, planning (Fikes, Hart, and Nilsson 1972; Minton 1988) and scheduling (Carbonell, Knoblock, and Minton 1991). EBL uses a domain theory to generate an explanation of why some training instance is an example of a goal concept according to some operationality criterion (DeJong and Mooney 1986). <p> The training example is the decomposition over the different problem spaces that led to the generation of the output primitive. Therefore, the object of EBL in execution environments is to operationalize appropriately the generation of a primitive output command. EBL algorithms such as EBG <ref> (Mitchell, Kellar, and Kedar-Cabelli 1986) </ref> and chunking (Laird, Rosenbloom, and Newell 1986a) also use generalization schemes that would allow the compiled rule to be more general than the over-specific Rule 6. The level at which knowledge should be made operational is an open question.
Reference: <author> Musliner, D. J., E. H. Durfee, and K. G. </author> <title> Shin (1993). CIRCA: A cooperative intelligent real-time control architecture. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 23 (6), </journal> <pages> 1561-1574. </pages>
Reference: <author> Nelson, G., J. F. Lehman, and B. E. </author> <title> John (1994). Integrating cognitive capabilities in a real-time task. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society. </booktitle>
Reference: <author> Newell, A. </author> <year> (1990). </year> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press. </publisher>
Reference-contexts: However, the architecture's particular functional constraints handicap learning in external environments with a number of problems. In order to better understand the difficulty in realizing knowledge compilation, I describe how the functional constraints of the architecture (enumerated in previous work <ref> (Newell 1990) </ref>) relate to hierarchical execution and knowledge compilation. In particular, derived entailments of the functional constraints may relate specifically to these capabilities. These entailments are not exhaustive but are meant to demonstrate how the architecture's functional constraints result in elaboration of the general requirements for knowledge compilation introduced previously.
Reference: <author> Newell, A. and H. A. </author> <title> Simon (1972). Human Problem Solving. </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: However, the bodies of knowledge are really about two different things. This notion of "levels" is really the same as a problem space <ref> (Newell and Simon 1972) </ref> in a hierarchical system. The elevator failure might trigger the selection of a problem space with operators that initiate path planning. On the other hand, operators for obstacle avoidance are probably closer to the primitive actions, including commands to start and stop movement.
Reference: <author> Ogasawara, G. H. </author> <year> (1991). </year> <title> A distributed decision-theoretic control system for a mobile robot. </title> <journal> SIGART BULLETIN 2 , 140-145. </journal>
Reference: <author> Pearson, D. J., S. B. Huffman, M. B. Willis, J. E. Laird, and R. M. </author> <title> Jones (1993). A symbolic solution to intelligent real-time control. </title> <booktitle> Robotics and Autonomous Systems 11, </booktitle> <pages> 279-291. </pages>
Reference-contexts: However, this hierarchical representation captures the flexibility necessary for agents behaving in complex environments. Furthermore, the approach has been used for both stick-level control of an aircraft in simulation <ref> (Pearson, Huffman, Willis, Laird, and Jones 1993) </ref> and higher level tactical flight (Tambe, Johnson, Jones, Koss, Laird, Rosenbloom, and Schwamb 1995) for medium sized (400-3000 rule) real time expert systems, indicating the feasibility of such an approach. 2.2 Addressing Problems with Hierarchical Knowledge Hierarchical knowledge is economical and flexible, but it
Reference: <author> Rosenbloom, P. and J. </author> <title> Laird (1986). Mapping explanation-based generalization onto Soar. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, Pennsylvania, </address> <pages> pp. 561-567. </pages>
Reference: <author> Rumelhart, D. E., G. E. Hinton, and R. J. </author> <title> Williams (1986). Learning internal representation by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland (Eds.), </editor> <booktitle> Parallel Distributed Processing, </booktitle> <pages> pp. 318-362. </pages> <publisher> MIT Press. </publisher>
Reference: <author> Sutton, R. S. </author> <year> (1988). </year> <title> Learning to predict by the method of temporal differences. </title> <booktitle> Machine Learning 3 (1), </booktitle> <pages> 9-44. </pages>
Reference-contexts: Learning from this experience could be used to speed up performance by "compiling" the decomposition into a more operational form. Knowledge compilation (Laird, Rosenbloom, and Newell 1986b) is analytic rather than inductive. In contrast, reinforcement learning techniques <ref> (Sutton 1988) </ref> have been used to empirically determine appropriate actions in similar domains. The difference in this approach is that the knowledge of "what to do" is already known; it is just not in an immediately accessible form.
Reference: <author> Tambe, M., W. L. Johnson, R. M. Jones, F. Koss, J. E. Laird, P. S. Rosenbloom, and K. </author> <month> Schwamb </month> <year> (1995). </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine 16 (1), </journal> <pages> 15-39. </pages>
Reference-contexts: However, this hierarchical representation captures the flexibility necessary for agents behaving in complex environments. Furthermore, the approach has been used for both stick-level control of an aircraft in simulation (Pearson, Huffman, Willis, Laird, and Jones 1993) and higher level tactical flight <ref> (Tambe, Johnson, Jones, Koss, Laird, Rosenbloom, and Schwamb 1995) </ref> for medium sized (400-3000 rule) real time expert systems, indicating the feasibility of such an approach. 2.2 Addressing Problems with Hierarchical Knowledge Hierarchical knowledge is economical and flexible, but it is not without drawbacks. <p> Because A-5 is the most promising approach at present, an immediate priority is to investigate it in a dynamic domain. The domain currently being considered for this step is a scaled-down version of the TacAir-Soar <ref> (Tambe, Johnson, Jones, Koss, Laird, Rosenbloom, and Schwamb 1995) </ref> domain. TacAir-Soar uses a hierarchical knowledge representation to control aircraft in a real-time simulation at the tactical level. Because of problems such as non-contemporaneous constraints and knowledge contention, TacAir-Soar is currently used without learning.
Reference: <author> Wiesmeyer, M. and J. E. </author> <title> Laird (1991). Attentional modeling of object identification and search. </title> <type> Technical Report CSE-TR-108-91, </type> <institution> University of Michigan. </institution>
Reference: <author> Wray, R., J. Laird, and R. Jones (1996, </author> <month> August). </month> <title> Compilation of non-contemporaneous constraints. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <address> Portland, OR. </address> <month> 48 </month>
Reference-contexts: These constraints are important because they provide a framework for identifying plausible avenues of approach for realizing the learning capability. However, the functional constraints may also present unique problems. Following the presentation of Soar's functional constraints, the non-contemporaneous constraints <ref> (Wray, Laird, and Jones 1996) </ref> problem is described. I show that this problem derives directly from some of the architecture's particular constraints. This problem, and others introduced later, may be addressed by relaxing some constraint and adding others. <p> The alternatives are only briefly introduced here. A more complete discussion may be found in <ref> (Wray, Laird, and Jones 1996) </ref>.
References-found: 38

