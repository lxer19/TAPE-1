URL: ftp://crl.ucsd.edu/pub/neuralnets/dynamics.ps.Z
Refering-URL: http://crl.ucsd.edu/~elman/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Language as a dynamical system  
Author: Jeffrey L. Elman 
Affiliation: University of California, San Diego  
Abstract-found: 0
Intro-found: 1
Reference: <author> Agre, P.E., & Chapman, D. </author> <year> (1987). </year> <title> Pengi: An implementation of a theory of activity. </title> <booktitle> In Proceedings of the AAAI-87. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Altmann, G.T.M. & Steedman, M.J. </author> <year> (1988). </year> <title> Interaction with context during human sentence processing. </title> <journal> Cognition, </journal> <volume> 30, </volume> <pages> 191-238. </pages>
Reference: <author> Bever, T. </author> <year> (1970a). </year> <title> The cognitive basis for linguistic structure. </title> <editor> In J.R. Hayes (Ed.), </editor> <booktitle> Cognition and the development of language. </booktitle> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Blaubergs, M.S. & Braine, M.D.S. </author> <year> (1974). </year> <title> Short-term memory limitations on decoding self-embedded sentences. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 102, No.4, </volume> <pages> 745-748. </pages>
Reference: <author> Brooks, R.A. </author> <year> (1989). </year> <title> A robot that walks: Emergent behaviors from a carefully evolved network. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 253-262. </pages>
Reference: <author> Browman, C.P., & Goldstein, L. </author> <year> (1985). </year> <title> Dynamic modeling of phonetic structure. </title>
Reference: <editor> In V. Fromken (Ed.), </editor> <booktitle> Phonetic linguistics. </booktitle> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Chomsky, N. </author> <year> (1975). </year> <booktitle> Reections on Language. </booktitle> <address> New York: Pantheon. </address>
Reference-contexts: This consensus extends to the very basic question about what counts as a cognitive process. So although many cognitive scientists are fond of referring to the brain as a mental organ <ref> (e.g., Chomsky, 1975) </ref>implying a similarity to other organs such as the liver or kidneysit is also assumed that the brain is an organ with special properties which set it apart. Brains carry out computation (it is argued); they entertain propositions; and they support representations.
Reference: <author> Churchland, P.S., & Sejnowski, T.J. </author> <year> (1992). </year> <title> The computational brain. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: indeed quite remarkable, and does some things which are very similar to human-made symbol processors; but there are also profound differences between the brain and digital symbol processors, and attempts to ignore these on grounds of simplification or abstraction run the risk of fundamentally misunderstanding the nature of neural computation <ref> (Churchland & Sejnowski, 1992) </ref>. In a larger sense, I raise the more general Elman Page 2 warning that (as Ed Hutchins has suggested) cognition may not be what we think it is. <p> be interested in another theory? One reason is that this view of our mental life which I have just described, that is, a view which relies on discrete, static, passive, and context-free representations, appears to be sharply at variance with what is known about the computational properties of the brain <ref> (Churchland & Sejnowski, 1992) </ref>. It must also be acknowledged that while the theories of language which subscribe to the assumptions listed above do provide a great deal of coverage of data, that coverage is often awed, internally inconsistent and ad hoc, and highly controversial.
Reference: <author> Elman, J.L. </author> <year> (1990). </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14, </volume> <pages> 179-211. </pages>
Reference-contexts: The basic approach is illustrated in Figure 1. The temporal order of input events (first-to-last) is represented by the spatial order (left-to-right) of the input vector. There are a number of problems with this approach <ref> (see Elman, 1990, for discussion) </ref>. One of the most serious is that the left-to-right spatial ordering has no intrinsic significance at the level of computation which is meaningful for the network. All input dimensions are orthogonal to each other in the input vector space. <p> A small lexicon of 29 nouns and verbs was used to form simple sentences <ref> (see Elman, 1990, for details) </ref>. Each word was represented as a localist vector in which a single randomly assigned bit was turned on.
Reference: <author> Elman, J.L., </author> <year> (1991a). </year> <title> Representation and structure in connectionist models. </title> <editor> In Gerald Altmann (Ed.), </editor> <booktitle> Computational and psycholinguistic approaches to speech processing. </booktitle> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Elman, J.L. </author> <year> (1991b). </year> <title> Distributed representations, simple recurrent networks, and grammatical structure. </title> <journal> Machine Learning, </journal> <volume> 7, </volume> <pages> 195-225. </pages>
Reference-contexts: They therefore impose a difficult set of demands on a recurrent network. However, after training a network on such stimuli <ref> (Elman, 1991b) </ref> it appeared the network was able to make correct predictions (mean cosine between outputs and empirically derived conditional probability distributions: 0.852; perfect performance would have been 1.0). These predictions honored the grammatical constraints which were present in the training data.
Reference: <author> Ferreira, F. & Henderson, J.M. </author> <year> (1990). </year> <title> The use of verb information in syntactic parsing: A comparison of evidence from eye movements and word-by-word Elman Page 35 self-paced reading. </title> <journal> Journal of Experimental Psychology: Learning, Memory and Cognition, </journal> <volume> 16, </volume> <pages> 555-568. </pages>
Reference: <author> Fodor, J. </author> <year> (1976). </year> <booktitle> The language of thought. </booktitle> <address> Sussex: </address> <publisher> Harvester Press. </publisher>
Reference: <author> Fodor, J., & Pylyshyn, Z. </author> <year> (1988). </year> <title> Connectionism and cognitive architecture: A critical analysis. </title> <editor> In S. Pinker & J. Mueller (Eds.) </editor> <title> Connections and symbols. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: It is not obvious how complex grammatical relations might be expressed using distributed representations. Indeed, it has been argued that distributed representations (of the sort exemplified by the hidden unit activation patterns in the previous simulation) cannot have constituent structure in any systematic fashion <ref> (Fodor & Pylyshyn, 1988) </ref>. (As a backup, Fodor and Pylyshyn suggest that if distributed representations do have a systematic constituent structure, then they are merely implementations of what they call the classical theory, in this case, the Language of Thought, Fodor, 1976.) The fact that the grammar of the first simulation
Reference: <author> Forster, K. </author> <year> (1976). </year> <title> Accessing the mental lexicon. </title> <editor> In R.J. Wales & E. Walker (Eds.), </editor> <title> New approaches to language mechanisms. </title> <publisher> Amsterdam: North-Holland. </publisher>
Reference-contexts: As described, this scenario may seem simple, straightforward, and not likely to be controversial. But in fact, there is considerable debate about a number of important details. For instance: Is the lexicon passive or active? In some models, the lexicon is a passive data structure <ref> (Forster, 1976) </ref>. In other models, lexical items are active (Marslen-Wilson, 1980; McClelland & Elman, 1986; Morton, 1979) in the style of Selfridges demons (Selfridge, 1958). <p> The lexicon may be organized along dimensions which reflect phonological, or orthographic, or syntactic, or syntactic properties; or it may be organized along usage parameters, such as frequency <ref> (Forster, 1976) </ref>.
Reference: <author> Fowler, C. </author> <year> (1977). </year> <title> Timing and control in speech production. </title> <address> Bloomington, </address> <note> IN: Indiana University Linguistics Club. </note>
Reference: <author> Fowler, C. </author> <year> (1980). </year> <title> Coarticulation and theories of extrinsic timing control. </title> <journal> Journal of Phonetics, </journal> <volume> 8, </volume> <pages> 113-133. </pages>
Reference: <author> Frazier, L. </author> <year> (1987). </year> <title> Sentence processing: A tutorial review. </title> <editor> In M. Coltheart (Ed.), </editor> <title> Attention and Performance XII: The psychology of reading. </title> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Frazier, L., & Rayner, K. </author> <year> (1982). </year> <title> Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences. </title> <journal> Cognitive Psychology, </journal> <volume> 14, </volume> <pages> 178-210. </pages>
Reference-contexts: One proposal is that there is a first-pass parse during which only category-general syntactic information is available <ref> (Frazier & Rayner, 1982) </ref>. The other major position is that considerably more information, including lexically-specific constraints on argument structure, is available and used in processing (Taraban & McClelland, 1990).
Reference: <author> Harris, C. & Elman, J.L. </author> <year> (1989). </year> <title> Representing variable information with simple recurrent networks. </title> <booktitle> In Proceedings of the Tenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Jordan, M. I. </author> <year> (1986). </year> <title> Serial order: A parallel distributed processing approach. </title> <institution> Institute for Cognitive Science Report 8604. University of California, </institution> <address> San Diego. </address>
Reference: <author> Jordan, M.I., & Rosenbaum, D.A. </author> <year> (1988). </year> <title> Action. </title> <type> Technical Report 88-26. </type>
Reference: <institution> Elman Page 36 Department of Computer Science, University of Massachusetts at Amherst. </institution>
Reference: <author> Kelso, J.A.S., Saltzman, E., & Tuller, B. </author> <year> (1986). </year> <title> The dynamical theory of speech production: </title> <journal> Data and theory. Journal of Phonetics, </journal> <volume> 14, </volume> <pages> 29-60. </pages>
Reference: <author> King, </author> <title> J & Just, </title> <address> M.A. </address> <year> (1991). </year> <title> Individual differences in syntactic processing: the role of working memory. </title> <journal> Journal of Memory and Language, </journal> <volume> 30, </volume> <pages> 580-602. </pages>
Reference: <author> Langacker, R.W. </author> <year> (1987). </year> <booktitle> Foundations of cognitive grammar: Theoretical perspectives. </booktitle> <volume> Volume 1. </volume> <publisher> Stanford: Stanford University Press. </publisher>
Reference-contexts: The tokens location in state space is thus at least functionally compositional (in the sense described by van Gelder, 1990). 5.3 Polysemy and accommodation Polysemy refers to the case where a word has multiple senses. Accommodation is used to describe the phenomenon in which word meanings are contextually altered <ref> (Langacker, 1987) </ref>. The network approach to language processing provides an Elman Page 26 account for both phenomena, and shows how they may be related. Although there are clear instances where the same phonological form has entirely different meanings (bank, for instance), in many cases polysemy is a matter of degree.
Reference: <author> MacNeilage, P.F. </author> <year> (1970). </year> <title> Motor control of serial ordering of speech. </title> <journal> Psychological Review, </journal> <volume> 77, </volume> <pages> 182-196. </pages>
Reference: <author> Marslen-Wilson, W.D. </author> <year> (1980). </year> <title> Speech understanding as a psychological process. </title>
Reference: <editor> In J.C. Simon (Ed.), </editor> <title> Spoken language understanding and generation. </title> <publisher> Dordrecht: </publisher> <editor> Reidel.g McClelland, J.L., & Elman, J.L. </editor> <year> (1986). </year> <title> The TRACE model of speech perception. </title> <journal> Cognitive Psychology, </journal> <volume> 18, </volume> <pages> 1-86. </pages>
Reference: <author> McClelland, J.L., & Rumelhart, D.E. </author> <year> (1981). </year> <title> An interactive activation model of contexts effects in letter perception: Part 1. An account of basic findings. </title> <journal> Psychological Review, </journal> <volume> 88, </volume> <pages> 365-407. </pages>
Reference-contexts: Time has been a challenge for connectionist models as well. Early models, perhaps reecting the initial emphasis on the parallel aspects of these models, typically adopted a spatial representation of time <ref> (e.g., McClelland & Rumelhart, 1981) </ref>. The basic approach is illustrated in Figure 1. The temporal order of input events (first-to-last) is represented by the spatial order (left-to-right) of the input vector. There are a number of problems with this approach (see Elman, 1990, for discussion).
Reference: <author> Miller, G.A., & Chomsky, N. </author> <year> (1963). </year> <title> Finitary models of language users. </title> <booktitle> In R.D. </booktitle>
Reference: <author> Luce, </author> <title> R.R. Bush, </title> & <editor> E. Galanter (Eds.), </editor> <booktitle> Handbook of mathematical psychology (Vol. II). </booktitle> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Miller, G. & Isard, S. </author> <year> (1964). </year> <title> Free recall of self-embedded English sentences. </title> <journal> Information and Control, </journal> <volume> 7, </volume> <pages> 292-303. </pages>
Reference-contexts: It has been known for many years that sentences of the first sort are processed in humans more easily and accurately than sentences of the second kind, and a number of reasons have been suggested <ref> (e.g., Miller & Isard, 1964) </ref>. In the case of the network, such an asymmetry arises because right-branching structures do not require that information be carried forward over embedded material, whereas in center-embedded sentences information from the matrix sentence must be saved over intervening embedded clauses.
Reference: <author> Morton, J. </author> <year> (1979). </year> <title> Word recognition. </title> <editor> In J. Morton & J.C. Marshall (Eds.), </editor> <booktitle> Psycholinguistics 2: Structures and processes. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Mozer, M.C. </author> <year> (1989). </year> <title> A focused back-propagation algorithm for temporal pattern Elman Page 37 recognition. </title> <journal> Complex Systems, </journal> <volume> 3, </volume> <pages> 49-81. </pages>
Reference: <author> Nolfi, S., Elman, J.L., & Parisi, D. </author> <title> (in press). Learning and evolution in neural networks. Adaptive Behavior. </title>
Reference: <author> Pearlmutter, B.A. </author> <year> (1989). </year> <title> Learning state space trajectories in recurrent neural networks. </title> <booktitle> Proceedings of the International Joint Conference on Neural Networks, </booktitle> <address> Washington, D.C., II-365. </address>
Reference: <author> Pierrehumbert, J.B., & Pierrehumbert, R.T. </author> <year> (1990). </year> <title> On attributing grammars to dynamical systems. </title> <journal> Journal of Phonetics, </journal> <volume> 18, </volume> <pages> 465-477. </pages>
Reference: <author> Pollack, J.B. </author> <year> (1990). </year> <title> The induction of dynamical recognizers. </title> <journal> Machine Learning, </journal> <volume> 7, </volume> <pages> 227-252. </pages>
Reference-contexts: It also seems reasonable that the conceptual notions which are associated with discrete automata theory and symbolic computation may offer less insight into their functioning than the concepts from dynamical systems theory <ref> (e.g., Pollack, 1990) </ref>. How might such networks be applied to problems relevant to language processing, and how might they suggest a different view of the underlying mechanisms of language? One way to approach this is to consider the problem of how the elements of language may be ordered.
Reference: <author> Rumelhart, D.E., Hinton, G.E., & Williams, R.J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In D.E. Rumelhart & J.L. McClelland (Eds.), </editor> <booktitle> Parallel distributed processing: Explorations in the microstructure of cognition (Vol. 1). </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Selfridge, O.G. </author> <year> (1958). </year> <title> Pandemonium: A paradigm for learning. </title> <booktitle> Mechanisation of thought processes: Proceedings of a symposium held at the National Physical Laboratory, </booktitle> <month> November </month> <year> 1958. </year> <institution> London: HMSO. </institution>
Reference-contexts: For instance: Is the lexicon passive or active? In some models, the lexicon is a passive data structure (Forster, 1976). In other models, lexical items are active (Marslen-Wilson, 1980; McClelland & Elman, 1986; Morton, 1979) in the style of Selfridges demons <ref> (Selfridge, 1958) </ref>.
Reference: <author> Siegelmann, H.T., & Sontag, E.D. </author> <year> (1992). </year> <title> Neural networks with real weights: Analog computational complexity. </title> <type> Report SYCON-92-05. </type> <institution> Rutgers Center for Systems and Control, Rutgers University. </institution>
Reference-contexts: The computational properties of such networks are not yet fully known, but it is clear that they are considerable <ref> (Siegelmann & Sontag, 1992) </ref>. It also seems reasonable that the conceptual notions which are associated with discrete automata theory and symbolic computation may offer less insight into their functioning than the concepts from dynamical systems theory (e.g., Pollack, 1990).
Reference: <author> Simon, H. </author> <year> (1980). </year> <title> Physical symbol systems. </title> <journal> Cognitive Science, </journal> <volume> 4, </volume> <pages> 135-183. </pages>
Reference-contexts: In the traditional view, the act of constructing mental representations is similar to the act of constructing a physical edifice. Indeed, this is precisely what is claimed in the Physical Symbol System Hypothesis <ref> (Simon, 1980) </ref>. In this view, words and more abstract constituents are like the bricks in a building; rules are the mortar which binds them together. As processing proceeds, the representation grows much as does a building under construction.
Reference: <author> St. John, M. F. </author> <year> (1992). </year> <title> The story gestalt: A model of knowledge-intensive processes in text comprehension. </title> <journal> Cognitive Science, </journal> <volume> 16, </volume> <pages> 271-306. </pages>
Reference: <author> St. John, M., & McClelland, J.L. </author> <year> (1990). </year> <title> Learning and applying contextual constraints in sentence comprehension. </title> <journal> Artificial Intelligence, </journal> <volume> 46, </volume> <pages> 217-457. </pages>
Reference: <author> Taraban, R., & McClelland, J.L. </author> <year> (1988). </year> <title> Constituent attachment and thematic role Elman Page 38 expectations. </title> <journal> Journal of Memory and Language, </journal> <volume> 27, </volume> <pages> 597-632. </pages>
Reference: <editor> Trueswell, J.C., Tanenhaus, M.K., & Kello, C. (in press). </editor> <title> Verb-specific constraints in sentence processing: Separating effects of lexical preference from garden-paths. </title> <journal> Journal of Experimental Psychology: Learning, Memory and Cognition. </journal>
Reference: <author> Van Gelder, T. </author> <year> (1990). </year> <title> A connectionist variation on a classical theme. </title> <journal> Cognitive Sciece, </journal> <volume> 14, </volume> <pages> 355-384. </pages>
Reference-contexts: Note that the tokenization process does not involve creation of new syntactic or semantic atoms. It is, instead, a systematic process. The state space dimensions along which token variation occurs may be interpreted meaningfully. The tokens location in state space is thus at least functionally compositional <ref> (in the sense described by van Gelder, 1990) </ref>. 5.3 Polysemy and accommodation Polysemy refers to the case where a word has multiple senses. Accommodation is used to describe the phenomenon in which word meanings are contextually altered (Langacker, 1987).
Reference: <author> Weckerly, J., & Elman, J.L. </author> <year> (1992). </year> <title> A PDP approach to processing center-embedded sentences. </title> <booktitle> Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>


Reference: <institution> Elman Page 41 and 2) as the network processes the sentences -john, mary, </institution> <note> lion, </note> <author> tiger, boy, girl burns house, </author> <title> as well as -museum, house burns (the final word of each sentences is terminated with ]S). The internal representations of the word burns varies slightly as a function of the verbs subject. </title>
Reference: <institution> Elman Page 42 t t t t output units input units hidden units TIME Elman Page 43 OUTPUT UNIT(S) HIDDEN UNITS INPUT UNIT(S) CONTEXT UNITS (linear) (hidden units at t-1) fixed connections, one-to-one, </institution> <note> at 1.0 Elman Page 44 smell move see think exist sleep break smash like chase eat mouse cat monster lion dragon woman girl man boy car book rock sandwich cookie bread plate glass VERBS NOUNS ANIMATES INANIMATES humans animals food breakables transitive (sometimes) intransitive (always) transitive (always) 0.0 1.01.52.0 dog Distance Elman Page 45 Elman Page 46 Elman Page 47 Elman Page 48 Elman Page 49 </note>
References-found: 52

