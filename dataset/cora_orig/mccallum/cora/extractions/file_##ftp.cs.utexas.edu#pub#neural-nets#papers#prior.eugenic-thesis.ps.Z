URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/prior.eugenic-thesis.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: http://www.cs.utexas.edu
Address: Austin, TX 78712  
Affiliation: Artificial Intelligence Laboratory The University of Texas at Austin  
Web: http://www.cs.utexas.edu/users/jprior/  
Note: jprior@cs.utexas.edu  
Abstract: Eugenic Evolution for Combinatorial Optimization John William Prior Report AI98-268 May 1998 
Abstract-found: 1
Intro-found: 1
Reference: <author> Back, T. </author> <year> (1992). </year> <title> A user's guide to genesys 1.0. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Dortmund. </institution>
Reference: <author> Back, T., Rudolph, G., and Schwefel, H.-P. </author> <year> (1993). </year> <title> Evolutionary programming and evolution strategies: Similarities and differences. </title> <editor> In Fogel, D. B., and Atmar, J. W., editors, </editor> <booktitle> Proceedings of the 2nd Annual Conference on Evolutionary Programming, </booktitle> <pages> 11-22. </pages> <booktitle> Evolutionary Programming Society, </booktitle> <address> La Jolla, CA. </address>
Reference-contexts: This allows for "stochastic backtracking", where algorithm can extract itself from dead-ends. The probability of accepting a lower fitness individual over a higher fitness individual (the "acceptance probability") can be made to decrease over time. Other mutation-based algorithms, including the "two-membered evolution strategy" (1+1)-ES <ref> (Back et al., 1993) </ref> and the roughly equivalent MBSH algorithm (Baluja, 1995), utilize deterministic competitions that are always won by the competitor of higher fitness. A secondary characteristic of mutation-based methods are their mutation "temperatures"| the average size of modifications made to competition winners to create new individuals.
Reference: <author> Baluja, S. </author> <year> (1994). </year> <title> Population-based incremental learning. </title> <type> Technical Report CMU-CS-94-163, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania 15213. </institution>
Reference-contexts: At least two algorithms, "Binary Simulated Crossover" (BSC) (Syswerda, 1993) and "Population-Based Iterative Learning" (PBIL) <ref> (Baluja, 1994) </ref>, have attempted to proactively and explicitly identify and exploit correlations between fitness and genetic parts or complete genotypes. Both are pattern-based methods, but PBIL also can be considered to be a mutation-based method, even though it makes use of a population of samples. <p> Population-Based Iterative Learning (PBIL) <ref> (Baluja, 1994) </ref> uses a probability vector as an explicit "fuzzy" representation of a "good" o (l) schema from which similar o (l) schemata are constructed. What is missing from both these algorithms is the explicit analysis and processing of intermediate order schemata|o (2) to o (l 1).
Reference: <author> Baluja, S. </author> <year> (1995). </year> <title> An empirical comparison of seven iterative and evolutionary function optimization heuristics. </title> <type> Technical Report CMU-CS-95-193, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania 15213. </institution>
Reference-contexts: The probability of accepting a lower fitness individual over a higher fitness individual (the "acceptance probability") can be made to decrease over time. Other mutation-based algorithms, including the "two-membered evolution strategy" (1+1)-ES (Back et al., 1993) and the roughly equivalent MBSH algorithm <ref> (Baluja, 1995) </ref>, utilize deterministic competitions that are always won by the competitor of higher fitness. A secondary characteristic of mutation-based methods are their mutation "temperatures"| the average size of modifications made to competition winners to create new individuals. <p> In contrast, PBIL learns explicitly from negative examples. In PBIL, only the alleles that differ between the very worst and best individuals are selected against, while alleles that are shared remain unaffected by the information gained from the low fit individual <ref> (Baluja and Caruana, 1995) </ref>. In order to identify low fitness alleles, it is 106 not necessary to explicitly search for alleles shared among the best and worst individuals. In fact, it is not necessary to depart from the standard statistical basis of the EuA at all.
Reference: <author> Baluja, S., and Caruana, R. </author> <year> (1995). </year> <title> Removing the genetics from the standard genetic algorithm. </title> <type> Technical Report CMU-CS-95-141, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania 15213. </institution>
Reference-contexts: The probability of accepting a lower fitness individual over a higher fitness individual (the "acceptance probability") can be made to decrease over time. Other mutation-based algorithms, including the "two-membered evolution strategy" (1+1)-ES (Back et al., 1993) and the roughly equivalent MBSH algorithm <ref> (Baluja, 1995) </ref>, utilize deterministic competitions that are always won by the competitor of higher fitness. A secondary characteristic of mutation-based methods are their mutation "temperatures"| the average size of modifications made to competition winners to create new individuals. <p> In contrast, PBIL learns explicitly from negative examples. In PBIL, only the alleles that differ between the very worst and best individuals are selected against, while alleles that are shared remain unaffected by the information gained from the low fit individual <ref> (Baluja and Caruana, 1995) </ref>. In order to identify low fitness alleles, it is 106 not necessary to explicitly search for alleles shared among the best and worst individuals. In fact, it is not necessary to depart from the standard statistical basis of the EuA at all.
Reference: <author> Darwin, C. </author> <title> (1859). On the origin of species by means of natural selection or the preservation of favored races in the struggle for life. </title> <address> London: Murray. </address>
Reference: <author> De Jong, K. A. </author> <year> (1993). </year> <title> Foundations of Genetic Algorithms 2, chapter Genetic Algorithms are NOT Functions Optimizers, </title> <address> 5-17. San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Therefore the total number of random samples taken for an l-bit problem was l 500. 5.3.1 F02: The Two-Dimensional Rosenbrock Function Problem Description The two-dimensional Rosenbrock function has one global optimum and one major local optimum, when encoded in 2-dimensional real space <ref> (De Jong, 1993) </ref>. It is an artificial problem that was intentionally created to have a local optimum with a basin of attraction much larger than the global optimum's basin of attraction. It is therefore very deceptive in real space. The two dependent variables can vary in the region [5:12; 5:12].
Reference: <author> Eiben, A. E., Raue, P.-E., and Ruttkay, Z. </author> <year> (1994). </year> <title> Parallel Problem Solving from Nature - PPSN III, chapter Genetic algorithms with multi-parent recombination, </title> <address> 78-87. Berlin: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Therefore each gene is a section, and every section is probabilistically interchanged between the two parents. Other recombination operators take many shapes and forms, including crossover operators that use more than two parents to generate a single offspring <ref> (Eiben et al., 1994) </ref>. However, these operators typically give no consideration to the functional interdependence of alleles ("epistasis") when deciding how to section the parents.
Reference: <author> Eshelman, L. J. </author> <year> (1991). </year> <title> Foundations of Genetic Algorithms, chapter The CHC Adaptive Search Algorithm: How to Have Safe Search When Engaging in Nontraditional Genetic Recombination, </title> <address> 265-283. San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher> <editor> 111 Eshelman, L. J., and Schaffer, J. D. </editor> <year> (1991). </year> <title> Preventing premature convergence in genetic algorithms by preventing incest. </title> <editor> In Belew, R. K., and Booker, L. B., editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> 115-122. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The experiments to follow will demonstrate this empirically, illustrating that very genotypical different individuals coexist peacefully, yet competitively, in EuA populations. It should be pointed out that the restriction operator performs exactly the opposite of what has been recommended by previous researchers|"incest prevention" <ref> (Eshelman 50 and Schaffer, 1991) </ref>. Since the problem of premature convergence is very significant in the performance of GAs, some method such as incest prevention must be used to maintain high levels of diversity, without introducing random mutation.
Reference: <author> Forrest, S., and Mitchell, M. </author> <year> (1993). </year> <title> Foundations of Genetic Algorithms 2, chapter Relative Building-Block Fitness and the Building-Block Hypothesis, </title> <address> 109-126. San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, in practice, even toy problems that have been designed specifically to be building block constructive are not that easily optimized by pattern-based algorithms. However,it has been demonstrated that GAs can perform relatively poorly on problems that are specifically designed to be building-block constructive (the "Royal-Road" functions described in <ref> (Forrest and Mitchell, 1993) </ref>). In particular, far simpler approaches such as random bit-climbing algorithms have been shown to easily outperform GAs on several of these problems. It is now clear that there are many other factors involved in GA performance, and that building-block constructivity cannot be so easily measured. <p> The mutation-based algorithms are "Increasing Mutation Hill Climbing" (IMHC), "Decreasing Mutation Hill Climbing" (DMHC), and simulated annealing (SA) (Kirkpatrick and Sherrington, 1988). Both IMHC and DMHC were derived from "Random Mutation Hill Climbing" (RMHC) <ref> (Forrest and Mitchell, 1993) </ref> especially for this thesis. The mutation based-algorithms can be broken down into two classes|heating algorithms (IMHC) and cooling algorithms (DMHC and SA). Heating algorithms start with a random individual and slowly increase the "heat" (the size of mutations) using an arbitrary schedule.
Reference: <author> Garey, M. R., and Johnson, D. S. </author> <year> (1979). </year> <title> Computers and Intractability. </title> <address> New York, NY: </address> <publisher> W. H. Freeman and Company. </publisher>
Reference-contexts: Because most of these algorithms guide their quest for better solutions by making small modifications to existing solutions, they rely on the heuristic of "neighborhood search" <ref> (Garey and Johnson, 1979) </ref>. Both genetic algorithms ("GA"s) (Goldberg, 1989; Holland, 1975) and simulated annealing ("SA") (Kirkpatrick and Sherrington, 1988) are examples of neighborhood search algorithms. In past years, both GAs and SA have received increasing recognition for their ability to efficiently approximate arbitrary functions. <p> Approaches to solving NP-complete problems can be roughly divided into two categories <ref> (Garey and Johnson, 1979) </ref>. The first category includes more "traditional" techniques, while the second consists of more modern (and radical) algorithms. The traditional techniques focus mainly on reducing the size of the search by eliminating as many potential solutions as possible. <p> These algorithms do not attempt to guarantee the finding of an optimal solution, but instead just try to find good solutions as quickly as possible. They are approximation algorithms. This thesis focuses on this class of algorithms. <ref> (Garey and Johnson, 1979) </ref> provides a concise discussion of combinatorial optimization. <p> A heuristic common among many combinatorial approximation algorithms is "neighborhood search", in which the search proceeds by making small modifications to existing solutions <ref> (Garey and Johnson, 1979) </ref>. This closely parallels the random genotypic mutations that occur during biological reproduction. Some algorithms even go so far as to mimic sexual reproduction in order to share information among solutions.
Reference: <author> Garfinkel, R. S., and Nemhauser, G. L. </author> <year> (1972). </year> <title> Integer Programming. </title> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: The first category includes more "traditional" techniques, while the second consists of more modern (and radical) algorithms. The traditional techniques focus mainly on reducing the size of the search by eliminating as many potential solutions as possible. For example, "branch-and-bound" and "implicit-enumeration" <ref> (Garfinkel and Nemhauser, 1972) </ref> utilize a tree-structured search that generates "partial" solutions, subsequentally identifying partial solutions that could not possibly be part of a true solution and then eliminating those solutions containing these partial solutions. Other traditional techniques include "dynamic programming" and "cutting-plane" techniques (Garfinkel and Nemhauser, 3 1972). <p> For example, "branch-and-bound" and "implicit-enumeration" (Garfinkel and Nemhauser, 1972) utilize a tree-structured search that generates "partial" solutions, subsequentally identifying partial solutions that could not possibly be part of a true solution and then eliminating those solutions containing these partial solutions. Other traditional techniques include "dynamic programming" and "cutting-plane" techniques <ref> (Garfinkel and Nemhauser, 3 1972) </ref>. The second major category of algorithms used for attacking NP-complete problems pertain soley to combinatorial optimization. These algorithms do not attempt to guarantee the finding of an optimal solution, but instead just try to find good solutions as quickly as possible. They are approximation algorithms.
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Genetic algorithms rely upon fitness-biased simulated sexual reproduction and random mutation of offspring to generate variation. The fitness-biased reproduction ensures that lower fitness solutions have a smaller chance of contributing their genetic material to the next generation <ref> (Goldberg, 1989) </ref>. This process is very similar to that used of Darwinian evolution. Darwinian evolution relies upon random variation to expand its search into unexplored regions of the genotypic search space, and natural selection to discourage exploration into lower fitness regions. <p> If offspring replace individuals in the current population, the algorithm is called a "steady state" genetic algorithm (SSGA) (Syswerda, 1991). There are a great many variations of the crossover operator, but two forms of recombination| "M-point crossover" and "uniform crossover" are probably the most common <ref> (Goldberg, 1989) </ref>. In M-point crossover, each parent is divided at M locations into M+1 contiguous sections, numbered 1 through M+1. Each parent is divided at the same M locations. Two offspring are created by exchanging every odd section between the two parents. <p> In the remaining parts of this thesis, the "fitness" of a schema will refer its observed average fitness. The greater the amount of knowledge an evolutionary algorithm has about the search space, the greater its chances of success. <ref> (Goldberg, 1989) </ref> estimated that a random population of size will sample on the order of 3 schemata. Consequently, the computational burden of explicitly recording statistics about each schema encountered quickly becomes prohibitive as population size is increased. <p> While allocating trials on the basis of observed schema fitness probably is a good heuristic for locating this individual, it is quite possible that the highest fitness schemata do not contain the highest fitness individuals. This phenomena is called "deception" <ref> (Goldberg, 1989) </ref>. When deception is present, the blanket assumption that above-average fitness schemata should be utilized more often than below-average schemata is incorrect. In such situations, an algorithm must take action to avoid converging permanently to the deceptive local optima. <p> Later in this thesis, a specific mutation-based hill-climbing algorithm will be developed to determine the MBHC of any problem. Pattern-based hill-climbability (PBHC), better known as "building block construc-tivity", has been discussed extensively in GA literature <ref> (Goldberg, 1989) </ref>. In theory, a PBHC problem could easily be solved by exploiting alleles and allele sets that have superior observed fitness averages. <p> schemata that can never be recombined to form the optimum. 3.5 Epistasis In general, the degree to which a problem exhibits epistasis is the degree to which the "best" setting of an allele is dependent on the settings of other alleles|it is the amount of interdependence among a genotype's alleles <ref> (Goldberg, 1989) </ref>. However, little attention has been given to the interaction between attractors and epistasis. <p> An example of this phenomena will be demonstrated later in this thesis (see the discussion of F31 in the "Experiments" chapter). Various methods (such as "fitness scaling" <ref> (Goldberg, 1989) </ref>) have been proposed that alleviate some of the problems associated with mismatches in fitness distributions and specific algorithms.
Reference: <author> H-L. Fang, P. Ross, D. C. </author> <year> (1993). </year> <title> A promising genetic algorithm approach to job-shop scheduling, rescheduling, and open-shop scheduling problems. </title> <editor> In Forrest, S., editor, </editor> <booktitle> Proceedings of the Fifth Annual Conference on Genetic Algorithms, </booktitle> <pages> 375-382. </pages> <address> San Ma-teo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Haykin, S. </author> <year> (1994). </year> <title> Neural Networks, A comprehensive foundation. </title> <address> New York: </address> <publisher> Macmillan College Publishing Company. </publisher>
Reference-contexts: Information-theoretic analysis may lead to a more disciplined approach of generating and analyzing algorithm heuristics and bias, not only for the EuA but for other algorithms as well. For a more complete discussion of information-theoretic measures and machine learning, see <ref> (Haykin, 1994) </ref>. The mention of information-theoretic measures brings to light a different view of the EuA's restriction operator. The restriction operator causes the EuA to probabilistically traverse paths of decision-tree separating high fitness individuals from low fitness individuals. <p> The determination of gene significance would have to be modified to more efficiently gauge a gene's effect on fitness. Gene significance could be based upon cluster distinctness, simple linear correlations, or more complex measures such as factor analysis <ref> (Haykin, 1994) </ref>. Modifications would also have to be made to the restriction operator. Currently, the restriction operator simply searches for individuals containing a particular allele to include in the restricted population.
Reference: <author> Holland, J. H. </author> <year> (1975). </year> <title> Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <address> Ann Arbor, MI: </address> <publisher> University of Michigan Press. </publisher>
Reference-contexts: Schemata The concepts of "schemata" and "schemata processing" have been used to quantify the structure of binary combinatorial problems, explain how evolutionary algorithms process the information contained in their populations, and how the evolutionary algorithms should exploit this information <ref> (Holland, 1975) </ref>. Schemata are generalized descriptors of properties 12 found in an individual's genotype; several individuals may share the same property, and it is hoped that an evolutionary algorithm will promote the spread of beneficial properties and curtail the propagation of detrimental properties. <p> The heuristics an algorithm uses to guide its search may have to change, depending on the specific task to be accomplished. Sometimes the goal of evolutionary search is not approximation, but the maximization of the cumulative fitness of all function evaluations. <ref> (Holland, 1975) </ref> proved that allocating exponentially increasing trials to schemata of above-average observed fitness is a minimum-loss strategy. It must be recognized that this strategy is only a heuristic for guiding evolutionary search. <p> A different example could easily be generated in which these effects were reversed. One of the main reasons -fitness has been so widely used in the past is because it has been shown to be the best strategy for maximizing the cumulative "payoff" of repeated trails <ref> (Holland, 1975) </ref>|-fitness is the best choice, on average, to select "good" alleles. Since the goal in this thesis is to design an algorithm to optimize a fitness function, instead of finding "good" solutions on average, X n -fitness may be a better choice than -fitness.
Reference: <author> Ingber, L. </author> <year> (1993). </year> <title> Simulated annealing: Practice versus theory. </title> <journal> Journal of Mathematical Computer Modelling, </journal> <volume> 18(11) </volume> <pages> 29-57. </pages>
Reference-contexts: Simulated quenching 3 The methods could also be termed "asexual" and "sexual" methods, respectively. 9 does not have the same ergodic search property as simulated annealing, and therefore can not guarantee an optimal solution. However, it has been demonstrated previously <ref> (Ingber, 1993) </ref> and will be shown in this thesis that simulated quenching can compare favorably in efficiency to genetic algorithms (and even the EuA) on some practical combinatorial optimization problems, but suffer from the same premature convergence problems that GAs encounter as a consequence of too rapid a cooling schedule. <p> Five of these problems are drawn from the genesys-2.0 test suite 1 , and the sixth has been studied in simulated annealing literature comparing the performance of simulated annealing to that of genetic algorithms <ref> (Ingber, 1993) </ref>. These problems are considered to be very hard, as even customized methods (such as direction set, branch and bound, etc.) have great trouble finding the global optima. At least four are NP-complete. <p> The relative performance of the EuAs tested in this experiment demonstrated that the EuA can be an extremely reliable and more successful alternative to mutation-based algorithms. 5.3.6 F38: Simulated Annealing Test Function Problem Description F38 was a test function in <ref> (Ingber, 1993) </ref>. The real-space encoding of this problem has an extremely large amount of local minima, for which small changes in the real parameters only decrease fitness values.
Reference: <author> Khuri, S., Back, T., and Heitkotter, J. </author> <year> (1993). </year> <title> An evolutionary approach to combinatorial optimization problems. </title> <booktitle> In Proceedings of the CSC'94. </booktitle>
Reference-contexts: If this sum does not exceed M , then the solution is "feasible". If the sum exceeds M , then the solution is "infeasible". The representation chosen for this problem is described in <ref> (Khuri et al., 1993) </ref>. This problem is included in the genesys-2.0 package. Each bit in the genotype represents the presence or absence of a particular integer from the set I. The problem tested had 50 integers in the set I, and so the genotype was 50 bits long. <p> Complete details on this problem can be found in <ref> (Khuri et al., 1993) </ref>. 50; 000 samples were generated for the random sampling conducted for estimating epistasis and fitness variance. The measured epistasis was 0.50 and the fitness variation was 0.10.
Reference: <author> Kirkpatrick, S., and Sherrington, D. </author> <year> (1988). </year> <title> Infinite range models of spin-glasses. </title> <journal> Physical Review B, </journal> <volume> 17 </volume> <pages> 4384-4403. </pages>
Reference-contexts: Because most of these algorithms guide their quest for better solutions by making small modifications to existing solutions, they rely on the heuristic of "neighborhood search" (Garey and Johnson, 1979). Both genetic algorithms ("GA"s) (Goldberg, 1989; Holland, 1975) and simulated annealing ("SA") <ref> (Kirkpatrick and Sherrington, 1988) </ref> are examples of neighborhood search algorithms. In past years, both GAs and SA have received increasing recognition for their ability to efficiently approximate arbitrary functions. <p> The loser of each competition is discarded, and a new solution is then created by modifying the winner. The winner and the new solution then compete in a new tournament, and the process is repeated. In simulated annealing <ref> (Kirkpatrick and Sherrington, 1988) </ref>, the tournaments are stochastic| i.e. the winner of each tournament is not necessarily the highest fitness individual. This allows for "stochastic backtracking", where algorithm can extract itself from dead-ends. <p> Then, each experiment and its results will be discussed in depth. 5.2 The Algorithms Three mutation-based and two pattern-based algorithms are evaluated in this section. The mutation-based algorithms are "Increasing Mutation Hill Climbing" (IMHC), "Decreasing Mutation Hill Climbing" (DMHC), and simulated annealing (SA) <ref> (Kirkpatrick and Sherrington, 1988) </ref>. Both IMHC and DMHC were derived from "Random Mutation Hill Climbing" (RMHC) (Forrest and Mitchell, 1993) especially for this thesis. The mutation based-algorithms can be broken down into two classes|heating algorithms (IMHC) and cooling algorithms (DMHC and SA).
Reference: <author> Lamarck, J. B. </author> <year> (1914). </year> <title> Zoological Philosophy. </title> <publisher> London. </publisher>
Reference-contexts: Darwinian evolution is the form of evolution prevalent in such well-known evolutionary approximation algorithms as genetic algorithms and simulated annealing, which both rely on random modifications of existing individuals to create new individuals. 6 2.2.2 Lamarckian Evolution In Lamarckian evolution <ref> (Lamarck, 1914) </ref>, adaptation occurs in not only the genotypic frequencies of the population, but also in the genotypes themselves. In Lamarckian evolution, it is possible for the phenotypic state of an individual to directly modify its current genotypic state.
Reference: <author> Luria, S. E., Gould, S. J., and Singer, S. </author> <year> (1981). </year> <title> A View Of Life. </title> <address> Menlo Park, CA: </address> <publisher> The Benjamin/Cummings Publishing Company, </publisher> <address> Inc. </address> <note> 112 Radcliffe, </note> <author> N. J., and Surry, P. D. </author> <year> (1995). </year> <title> Fundamental limitations on search algorithms: </title> <booktitle> Evolutionary computing in perspective. Lecture Notes in Computer Science, </booktitle> <editor> 1000:275 ?? Syswerda, G. </editor> <year> (1991). </year> <title> Foundations of Genetic Algorithms, chapter A Study of Reproduction in Generational and Steady State Genetic Algorithms, </title> <address> 94-101. San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Syswerda, G. </author> <year> (1993). </year> <title> Foundations of Genetic Algorithms 2, chapter Simulated Crossover in Genetic Algorithms, </title> <address> 239-255. San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The population plays a fundamental role in the search strategy, by biasing the selection probabilities of new samples. As discussed by Syswerda <ref> (Syswerda, 1993) </ref>, it is not easily possible to eliminate the population completely and substitute a simply-updated set of allele statistics, as this strategy would lead to repeatedly generating the same alleles with the same probabilities. <p> This allows pattern-based algorithms to be more "conservatively explorative" than mutation-based algorithms, since recombination of previously tested genotypic parts is a more cautious strategy than randomly mutating existing parts into completely new forms <ref> (Syswerda, 1993) </ref>. But how do pattern-based algorithms choose the "best" parts to recombine? Somehow, the "fitness" of schemata must be gauged. The next section will describe how this can be accomplished. <p> Eugenic evolution hopefully reduces some of the need for many trials by performing reasonable amounts of analysis of the information gathered in previous trials and pro-actively exploiting this information to guide the choices made for choosing and combining genetic material. At least two algorithms, "Binary Simulated Crossover" (BSC) <ref> (Syswerda, 1993) </ref> and "Population-Based Iterative Learning" (PBIL) (Baluja, 1994), have attempted to proactively and explicitly identify and exploit correlations between fitness and genetic parts or complete genotypes. <p> be presented in the next chapter that accomplishes this goal through the use of an operator (the "restriction" operator) that causes conditional allele-fitness distributions to be measured and therefore determines what combinations of alleles lead to extremes in fitness. 33 Chapter 4 The Eugenic Algorithm The Binary Simulated Crossover (BSC) <ref> (Syswerda, 1993) </ref> algorithm explicitly analyzes and recombines o (1) schemata to form new individuals. Population-Based Iterative Learning (PBIL) (Baluja, 1994) uses a probability vector as an explicit "fuzzy" representation of a "good" o (l) schema from which similar o (l) schemata are constructed. <p> The EuA will be the only eugenic algorithm studied, although tests will be conducted with EuAs that do not use the restriction operator, and are therefore effectively equivalent to BSC <ref> (Syswerda, 1993) </ref>. Different parameter settings for these algorithms were tested in the experiments. For SA and DMHC, two settings of the "cooling rate" parameter are studied. For the GA, two recombination methods are tested.
Reference: <author> Whitley, D., Gordon, V. S., and Mathias, K. </author> <year> (1994). </year> <title> Lamarckian evolution, the baldwin effect and function optimization. </title> <editor> In Davidor, Y., Schwefel, H.-P., and Maenner, R., editors, </editor> <booktitle> Proceedings of the International Conference on Evolutionary Computation, </booktitle> <volume> vol. </volume> <pages> 866. </pages> <address> Jerusalem, Israel. </address> <month> 113 </month>
References-found: 23

