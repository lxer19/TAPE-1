URL: ftp://psyche.mit.edu/pub/tommi/varqmr.ps
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00280.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: ftommi,jordang@psyche.mit.edu  
Title: database  
Author: Tommi S. Jaakkola and Michael I. Jordan 
Keyword: Variational methods  
Address: Cambridge, MA 02139  
Affiliation: Department of Brain and Cognitive Sciences Massachusetts Institute of Technology  
Note: and the QMR-DT  
Abstract: MIT Computational Cognitive Science Technical Report 9701 Abstract We describe variational approximation methods for efficient probabilistic reasoning, applying these methods to the problem of diagnostic inference in the QMR-DT database. The QMR-DT database is a large-scale belief network based on statistical and expert knowledge in internal medicine. The size and complexity of this network render exact probabilistic diagnosis infeasible for all but a small set of cases. This has hindered the development of the QMR-DT network as a practical diagnostic tool and has hindered researchers from exploring and critiquing the diagnostic behavior of QMR. In this paper we describe how variational approximation methods can be applied to the QMR network, resulting in fast diagnostic inference. We evaluate the accuracy of our methods on a set of standard diagnostic cases and compare to stochastic sampling methods. 
Abstract-found: 1
Intro-found: 1
Reference: <author> B. </author> <month> D'Ambrosio </month> <year> (1994). </year> <title> Symbolic probabilistic inference in large BN20 networks. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> G. </author> <title> Cooper (1990). The computational complexity of probabilistic inference using Bayesian belief networks. </title> <booktitle> Artificial Intelligence 42 </booktitle> <pages> 393-405. </pages>
Reference: <author> A. Gelfand and A. </author> <title> Smith (1990). Sampling-based approaches to calculating marginal Densities. </title> <journal> Journal of the American Statistical Association 85(410) </journal> <pages> 398-409. </pages>
Reference-contexts: These dependencies are infeasible to handle exactly; indeed, for the more difficult diagnosis problems that we consider below we estimate that exact algorithms would require approximately 50 years to run on current computers. An alternative to exact methods is provided by stochastic sampling methods <ref> (see, e.g., Gelfand & Smith 1990) </ref>. These methods are readily implemented for general belief networks and provide theoretical assurance of convergence to exact answers. It can be difficult in practice, however, to diagnose convergence and to assess the reliability of results obtained over finite sampling intervals.
Reference: <author> T. Jaakkola and M. </author> <title> Jordan (1996a). Computing upper and lower bounds on likelihoods in intractable networks. </title> <booktitle> In Proceedings of the twelfth Conference on Uncertainty in Artificial Intelligence. </booktitle>
Reference-contexts: To obtain upper bounds on the latter quantities would require that we also obtain lower bounds on the likelihood. Although variational machinery naturally provides lower bounds as well as upper bounds on the likelihood <ref> (cf. Jaakkola & Jordan 1996a) </ref>, in our preliminary work on the QMR-DT database, however, the bounds that we have obtained are not sufficiently tight. We are currently exploring alternative variational transformations for the node probabilities in order to tighten these bounds.
Reference: <author> T. Jaakkola and M. </author> <title> Jordan (1996b). Recursive algorithms for approximating probabilities in graphical models. </title> <booktitle> In Advances of Neural Information Processing Systems 9. </booktitle>
Reference-contexts: Finally, note that we have utilized only the simplest variational transformations in the current paper, in particular those based on linear convexity bounds. It is worth exploring the speed/accuracy tradeoffs obtained by using more sophisticated bounds <ref> (cf. Jaakkola & Jordan 1996b) </ref>. Our results are nonetheless quite promising. We have presented an algorithm which runs in real time on a large-scale belief network for which exact algorithms are entirely infeasible.
Reference: <author> F. </author> <title> Jensen (1996). Introduction to Bayesian networks. </title> <publisher> Springer, </publisher> <address> New York. </address>
Reference: <author> B. Middleton, M. Shwe, D. Heckerman, M. Henrion, E. Horvitz, H. Lehmann, </author> <title> and G. </title>
Reference: <author> Cooper (1990). </author> <title> Probabilistic Diagnosis Using a Reformulation of the INTERNIST-1/QMR Knowledge Base II. Evaluation of Diagnostic Performance. </title> <institution> Section on Medical Informatics Technical report SMI-90-0329. Stanford University. </institution>
Reference: <author> R. </author> <title> Neal (1993). Probabilistic inference using Markov chain Monte Carlo methods. </title> <type> Technical report CRG-TR-93-1, </type> <institution> University of Toronto. </institution>
Reference: <author> J. </author> <title> Pearl (1988). Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1 Introduction Bayesian belief networks provide an elegant unifying formalism for probabilistic modeling <ref> (see, e.g., Pearl 1988, Jensen 1996) </ref>. Given a set of random variables represented as nodes in a directed acyclic graph, and given a conditional probability distribution for each node, the formalism defines the joint probability distribution of the variables as the product of the node probabilities. <p> The diseases and findings occupy the nodes on the two levels of the network, respectively, and the conditional probabilities specifying the dependencies between the levels are assumed to be noisy-OR gates <ref> (cf. Pearl 1988) </ref>. The bi-partite network structure encodes the assumption that, in the absence of findings, the diseases appear independently from each other with their respective prior probabilities (i.e. marginal independence). (Note that diseases are not assumed to be mutually exclusive; a patient can have multiple diseases).
Reference: <author> R. </author> <month> Rockafellar </month> <year> (1972). </year> <title> Convex Analysis. </title> <publisher> Princeton Univ. Press. </publisher>
Reference: <author> M. Shwe and G. </author> <title> Cooper (1991). An empirical analysis of likelihood weighting simulation on a large, multiply connected medical belief network. </title> <booktitle> Computers and Biomedical Research 24 </booktitle> <pages> 453-475. </pages> <note> 19 M. </note> <author> Shwe, B. Middleton, D. Heckerman, M. Henrion, E. Horvitz, H. Lehmann, </author> <title> and G. </title>
Reference-contexts: The noisy-OR probability model encodes the causal independence assumption <ref> (Shwe et al. 1991) </ref>; that is, the diseases act independently to cause the outcome of the findings.
Reference: <author> Cooper (1991). </author> <title> Probabilistic Diagnosis Using a Reformulation of the INTERNIST-1/QMR Knowledge Base I. The Probabilistic Model and Inference Algorithms. </title> <booktitle> Methods of Information in Medicine 30 </booktitle> <pages> 241-255, </pages> <year> 1991. </year>
References-found: 13

