URL: ftp://ftp.cs.brown.edu/pub/techreports/96/cs96-14.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-96-14.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> N. Ayache, I. Cohen, and I. Herlin. </author> <title> Medical image tracking. </title> <editor> In A. Blake and A. Yuille, editor, </editor> <booktitle> Active Vision, </booktitle> <pages> pp. 285-301. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Medical ultrasound images play an important diagnostic role for physicians, and enjoy a number of advantages over other imaging techniques <ref> [1] </ref>. The advantages can be summed up with the remark that the acquisition of ultrasound images is fast, cheap, and safe. In particular, ultrasound image sequences can be acquired at video rates, allowing dynamic analysis of moving structures (such as heart walls). The equipment required is relatively inexpensive and portable. <p> What's more, locating and tracking features in noisy images such as these is recognized as a difficult problem in computer vision <ref> [1] </ref>. <p> In spite of these potential problems, Ayache et al <ref> [1] </ref> and Herlin and Ayache [14] describe a semi-automatic snake-based method for tracking features in echocardiograms. <p> Many previous attempts to detect and track features in ultrasound image sequences have been based on detecting edges <ref> [1, 2, 14, 17, 19] </ref>. This may be due to specific objectives (precise measurement of tissue structure dimensions), or simply because much of the computer vision literature focuses on detecting edges (in photographic and video image data).
Reference: [2] <author> C.H. Chu, E.J. Delp, and A.J. Buda. </author> <title> Detecting left ventricular endocardial and epi-cardial boundaries by digital two-dimensional echocardiography. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 7(2) </volume> <pages> 81-90, </pages> <year> 1988. </year> <month> 11 </month>
Reference-contexts: On the other hand, the quality of the images is relatively poor. The images are plagued by low image intensity contrast, dropouts in the image (in which structures exhibit apparent gaps, or disappear temporarily in some frames of a sequence), and "speckle" <ref> [2] </ref>. (See Figure 1). Ultrasound images are formed by sending a pulse into the body from a transducer placed against the skin. The pulse is reflected by interfaces within the body between tissues with different properties. <p> This assumption is not always valid [4], and again the method has limited applicability. 2 Temporal filtering is an alternative approach which shares characteristics with both methods based on compounding and those based on image filtering <ref> [2, 8] </ref>. The method requires a time sequence of images as input. As in direct image filtering methods, pixels are averaged with their neighbors, but in this case the "neighbors" are chosen in the temporal dimension - from preceding or subsequent frames. <p> Applying this straightforward approach in the presence of motion (e.g. in echocardiograms) results in motion blur and loss of resolution. An alternative approach in that case (echocardiogram sequences) is to average frames taken from the same point in the cardiac cycle <ref> [2] </ref>. <p> As yet, efforts to apply this strategy in echocardiogram sequences have not been successful, mainly because of the difficulty of accurately estimating image motion in the presence of noise, signal dropout, and rapid motion of the heart combined with temporal undersampling <ref> [2] </ref>. 3 A new approach In this research I propose a new method for automatically locating and tracking features in echocardiogram image sequences. The key idea is to locate and track features at multiple scales in the image. <p> A number of optical flow algorithms have been developed in the computer vision community. As a class, these algorithms are not suitable for applications such as ultrasound imaging which produce particularly noisy image sequences. Chu et al. <ref> [2] </ref> note that these algorithms are based on a number of assumptions, including the following: * the image intensity at a fixed point on a structure does not vary with time or viewpoint. * locally, all motion can be modelled as rigid body translation. * velocities vary smoothly across the image <p> Many previous attempts to detect and track features in ultrasound image sequences have been based on detecting edges <ref> [1, 2, 14, 17, 19] </ref>. This may be due to specific objectives (precise measurement of tissue structure dimensions), or simply because much of the computer vision literature focuses on detecting edges (in photographic and video image data).
Reference: [3] <author> A.N. Evans and M.S. Nixon. </author> <title> Temporal speckle reduction for feature extraction in ultra-sound images. </title> <booktitle> Computer analysis of images and patterns : 5th international conference, </booktitle> <address> CAIP '93. </address>
Reference-contexts: acquired and viewed [4], an additional goal of this work is to achieve real-time speeds for an implementation of the algorithm running on a standard scientific workstation. 2 Previous work on speckle reduction Previous attempts to reduce speckle in ultrasound images fall into two main categories: image filtering and compounding <ref> [3, 5] </ref>. Image filtering methods, also called post-formation methods, involve the application of image processing techniques to already acquired images. A straightforward approach would be to smooth the image with a low-pass filter, which would reduce speckle. <p> Further, these methods tend to trade off speckle suppression for edge preservation. Methods based on compounding involve the acquisition of multiple images which are averaged to produce an output with increased signal to noise ratio <ref> [3] </ref>. Spatial compounding involves the use of multiple images of the target structure, taken from slightly different viewpoints. This approach is fully applicable only to relatively few sites of clinical interest [4].
Reference: [4] <author> F. Forsberg, A.J. Healy, S. Leeman and J.A. Jensen. </author> <title> Assessment of hybrid speckle reduction algorithms. </title> <journal> Phys. Med. Biol. </journal> <volume> 36(11) </volume> <pages> 1539-1549. </pages> <year> 1991. </year>
Reference-contexts: What's more, locating and tracking features in noisy images such as these is recognized as a difficult problem in computer vision [1]. Since any effective filtering technique would be far more useful if it could be applied in real time as the images are acquired and viewed <ref> [4] </ref>, an additional goal of this work is to achieve real-time speeds for an implementation of the algorithm running on a standard scientific workstation. 2 Previous work on speckle reduction Previous attempts to reduce speckle in ultrasound images fall into two main categories: image filtering and compounding [3, 5]. <p> Spatial compounding involves the use of multiple images of the target structure, taken from slightly different viewpoints. This approach is fully applicable only to relatively few sites of clinical interest <ref> [4] </ref>. Another form of compounding is frequency compounding, which is based on the assumption that speckle produced at one imaging frequency is not correlated with that produced at other frequencies. This assumption is not always valid [4], and again the method has limited applicability. 2 Temporal filtering is an alternative approach <p> This approach is fully applicable only to relatively few sites of clinical interest <ref> [4] </ref>. Another form of compounding is frequency compounding, which is based on the assumption that speckle produced at one imaging frequency is not correlated with that produced at other frequencies. This assumption is not always valid [4], and again the method has limited applicability. 2 Temporal filtering is an alternative approach which shares characteristics with both methods based on compounding and those based on image filtering [2, 8]. The method requires a time sequence of images as input.
Reference: [5] <author> J.I. Koo and S.B. Park. </author> <title> Speckle reduction with edge preservation in medical ultrasonic images using a homogeneous region growing mean filter (HRGMF). </title> <booktitle> Ultrasonic Imaging 13 </booktitle> <pages> 211-237. </pages> <year> 1991. </year>
Reference-contexts: acquired and viewed [4], an additional goal of this work is to achieve real-time speeds for an implementation of the algorithm running on a standard scientific workstation. 2 Previous work on speckle reduction Previous attempts to reduce speckle in ultrasound images fall into two main categories: image filtering and compounding <ref> [3, 5] </ref>. Image filtering methods, also called post-formation methods, involve the application of image processing techniques to already acquired images. A straightforward approach would be to smooth the image with a low-pass filter, which would reduce speckle. <p> In this way it is hoped that edges will be preserved while speckle is still suppressed. Loupas et. al. [7] proposed a similar adaptive approach based on a median filter. Koo and Park <ref> [5] </ref> note that adaptive approaches based on local image statistics suffer from a sensitive dependence on the choice of statistical parameters to be used, which vary from one data set to the next.
Reference: [6] <author> J.C. Bamber and C. Daft. </author> <title> Adaptive filtering for reduction of speckle in ultrasonic pulse-echo images. </title> <booktitle> Ultrasonics 24 </booktitle> <pages> 41-44. </pages> <year> 1986. </year>
Reference-contexts: A straightforward approach would be to smooth the image with a low-pass filter, which would reduce speckle. Unfortunately, this would also have the side-effect of blurring the actual information content of the image. Bamber and Daft <ref> [6] </ref> proposed an adaptive mean-based (low pass) filter in which the filter is applied to each pixel in the image based on local image statistics near that pixel. <p> As motion increases, or in cases where the tracking fails, the filtering should operate at reduced levels or not at all. In this respect the filtering algorithm resembles adaptive algorithms such as <ref> [6] </ref> and [7]. 4 Previous work on optical flow and feature tracking Before proceeding to describe the implementation of my algorithm for estimating global image motion from tracked features, I will address existing methods for calculating image motion ("optical flow") and for tracking features in images.
Reference: [7] <author> T. Loupas, W.N. McDicken and P.L. Allan. </author> <title> An adaptive weighted median filter for speckle suppression in medical ultrasound images. </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <volume> 36(1) </volume> <pages> 129-135. </pages> <year> 1989. </year>
Reference-contexts: Basically, the filter is not applied near object boundaries in the image, but is applied fully in areas with uniform background gray level. In this way it is hoped that edges will be preserved while speckle is still suppressed. Loupas et. al. <ref> [7] </ref> proposed a similar adaptive approach based on a median filter. Koo and Park [5] note that adaptive approaches based on local image statistics suffer from a sensitive dependence on the choice of statistical parameters to be used, which vary from one data set to the next. <p> As motion increases, or in cases where the tracking fails, the filtering should operate at reduced levels or not at all. In this respect the filtering algorithm resembles adaptive algorithms such as [6] and <ref> [7] </ref>. 4 Previous work on optical flow and feature tracking Before proceeding to describe the implementation of my algorithm for estimating global image motion from tracked features, I will address existing methods for calculating image motion ("optical flow") and for tracking features in images.
Reference: [8] <author> S. Geman, D.E. McClure and D. Geman. </author> <title> A nonlinear filter for film restoration and other problems in image processing. CVGIP: </title> <booktitle> Graphicsl Models and Image Processing 54(4) </booktitle> <pages> 281-289. </pages> <year> 1992. </year>
Reference-contexts: This assumption is not always valid [4], and again the method has limited applicability. 2 Temporal filtering is an alternative approach which shares characteristics with both methods based on compounding and those based on image filtering <ref> [2, 8] </ref>. The method requires a time sequence of images as input. As in direct image filtering methods, pixels are averaged with their neighbors, but in this case the "neighbors" are chosen in the temporal dimension - from preceding or subsequent frames. <p> This strategy is the basic ingredient of most algorithms for restoration and enhancement of image sequences <ref> [8] </ref>. Shinya [9] applied this idea to the problem of antialiasing in computer-generated animations. MPEG video encoding uses a similar idea for image compression.
Reference: [9] <author> M. Shinya. </author> <title> Spatial anti-aliasing for animation sequences with spatio-temporal filtering. </title> <booktitle> Proceedings of SIGGRAPH, </booktitle> <address> '93 (Anaheim, California, </address> <month> August 1-6). </month>
Reference-contexts: This strategy is the basic ingredient of most algorithms for restoration and enhancement of image sequences [8]. Shinya <ref> [9] </ref> applied this idea to the problem of antialiasing in computer-generated animations. MPEG video encoding uses a similar idea for image compression.
Reference: [10] <author> T. Camus. </author> <title> Real-time optical flow. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1994. </year>
Reference-contexts: Camus <ref> [10] </ref> writes, "The current trend in optical flow research is to stress accuracy under ideal conditions and not to consider computational resource requirements or resistance to noise." In informal tests I conducted using implementations of a number of standard optical flow algorithms made available on the internet by ICCV '94, I
Reference: [11] <author> M. Kass, A. Witken and D. Terzopolous. Snakes: </author> <title> active contour models. </title> <booktitle> Proceedings of First International Conference on Computer Vision, </booktitle> <address> London, </address> <year> 1987, </year> <pages> pp. 259-269. </pages>
Reference-contexts: Approaches which I considered for automatic feature tracking fall into two related categories: active contours, or "snakes," and deformable templates. Snakes were first proposed by Kass et al in 1987 <ref> [11] </ref>. In their formulation, a snake is a deformable contour which lies in an image and is subject both to image forces and to internal forces.
Reference: [12] <author> A.A. Amini, S. Tehrani and T.E. Weymouth. </author> <title> Using dynamic programming for minimizing the energy of active contours in the presence of hard constraints. </title> <booktitle> Proceedings, Second International Conference on Computer Vision, </booktitle> <year> 1988, </year> <pages> pp. 95-99. </pages>
Reference-contexts: Kass et al claim that snakes are somewhat resistant to noise and local tracking errors, and so are suitable for edge detection and feature tracking in real applications. Amini et al <ref> [12] </ref> and Williams and Shah [13] discuss a number of disadvantages of snakes (and propose improvements).
Reference: [13] <author> D.J. Williams and M. Shah. </author> <title> A fast algorithm for active contours and curvature estimation. CVGIP: </title> <booktitle> Image Understanding 55(1) </booktitle> <pages> 14-26. </pages> <year> 1992. </year>
Reference-contexts: Kass et al claim that snakes are somewhat resistant to noise and local tracking errors, and so are suitable for edge detection and feature tracking in real applications. Amini et al [12] and Williams and Shah <ref> [13] </ref> discuss a number of disadvantages of snakes (and propose improvements).
Reference: [14] <author> I.L. Herlin and N. Ayache. </author> <title> Features extraction and analysis methods for sequences of ultrasound images. </title> <booktitle> Computer vision-ECCV '92 : Second European Conference on Computer Vision, </booktitle> <month> May </month> <year> 1992. </year> <pages> pp. 43-57. </pages>
Reference-contexts: In spite of these potential problems, Ayache et al [1] and Herlin and Ayache <ref> [14] </ref> describe a semi-automatic snake-based method for tracking features in echocardiograms. Their method is based on a pre-procesing edge detection step followed by a tracking phase in which a user positions the snake initially, then intervenes occasionally to guide the snake when it loses the feature. <p> Many previous attempts to detect and track features in ultrasound image sequences have been based on detecting edges <ref> [1, 2, 14, 17, 19] </ref>. This may be due to specific objectives (precise measurement of tissue structure dimensions), or simply because much of the computer vision literature focuses on detecting edges (in photographic and video image data).
Reference: [15] <author> P. Lispon, A.L. Yuille, D. O'Keefe, J. Cavanaugh, J. Taaffe and D. Rosenthal. </author> <title> De-formable templates for feature extraction from medical images. </title> <booktitle> Computer vision-ECCV 90 : First European Conference on Computer Vision, </booktitle> <month> April 23-27, </month> <year> 1990. </year> <pages> pp. 413-417. </pages>
Reference-contexts: In effect, it would attempt to bridge a gap which should not be bridged. Deformable templates have been proposed as an alternative method for detecting and tracking features in image sequences <ref> [15, 18] </ref>. A deformable template is a parametric representation (with a small number of parameters) of an idealized feature of the particular type one expects to track. Example applications include detecting or tracking a pedestrian [18], a hand [16], a vertebral trabecular bone [15], or a left ventricle [17]. <p> A deformable template is a parametric representation (with a small number of parameters) of an idealized feature of the particular type one expects to track. Example applications include detecting or tracking a pedestrian [18], a hand [16], a vertebral trabecular bone <ref> [15] </ref>, or a left ventricle [17]. With this approach, detecting the feature corresponds to searching the parameter space of the parameterized template to find the best match with the image data. <p> With this approach, detecting the feature corresponds to searching the parameter space of the parameterized template to find the best match with the image data. Methods for conducting this search include simulated annealing [16] and iterative schemes based on Kalman filters [18] or energy minimization techniques (like snakes) <ref> [15] </ref>. At first, the idea of detecting and tracking features in echocardiogram image sequences seemed plausible, particularly since there are only a small number of "views" typically used by diagnosticians.
Reference: [16] <author> A. Bennett and I. Craw. </author> <title> Finding image features using deformable templates and detailed prior statistical knowledge. </title> <booktitle> BMVC 91 : proceedings of the British Machine Vision Conference, </booktitle> <month> September 24-26, </month> <year> 1991. </year> <pages> pp. 233-239. 12 </pages>
Reference-contexts: A deformable template is a parametric representation (with a small number of parameters) of an idealized feature of the particular type one expects to track. Example applications include detecting or tracking a pedestrian [18], a hand <ref> [16] </ref>, a vertebral trabecular bone [15], or a left ventricle [17]. With this approach, detecting the feature corresponds to searching the parameter space of the parameterized template to find the best match with the image data. Methods for conducting this search include simulated annealing [16] and iterative schemes based on Kalman <p> tracking a pedestrian [18], a hand <ref> [16] </ref>, a vertebral trabecular bone [15], or a left ventricle [17]. With this approach, detecting the feature corresponds to searching the parameter space of the parameterized template to find the best match with the image data. Methods for conducting this search include simulated annealing [16] and iterative schemes based on Kalman filters [18] or energy minimization techniques (like snakes) [15]. At first, the idea of detecting and tracking features in echocardiogram image sequences seemed plausible, particularly since there are only a small number of "views" typically used by diagnosticians.
Reference: [17] <author> J.C. McEachen II, F.G. Meyer, R.T. Constable, A. Nehorai and J.S. Duncan. </author> <title> A recursive filter for phase velocity assisted shape-based tracking of cardiac non-rigid motion. </title> <note> Online publication: http://noodle.med.yale.edu/mceachen/iccv/iccv.ps.gz </note>
Reference-contexts: A deformable template is a parametric representation (with a small number of parameters) of an idealized feature of the particular type one expects to track. Example applications include detecting or tracking a pedestrian [18], a hand [16], a vertebral trabecular bone [15], or a left ventricle <ref> [17] </ref>. With this approach, detecting the feature corresponds to searching the parameter space of the parameterized template to find the best match with the image data. Methods for conducting this search include simulated annealing [16] and iterative schemes based on Kalman filters [18] or energy minimization techniques (like snakes) [15]. <p> It might be possible to tailor the tracking algorithm to "look for" a 5 particular set of features in a particular configuration in the data. This might be achieved using a deformable template. What's more, prior knowledge of the expected motion could be built into the model, as in <ref> [17] </ref>. After seeing actual echocardiogram data sets, though, I reconsidered. Even within image sequences taken with the same view, there is a great deal of variability (see Figure 2 and Figure 3). <p> Many previous attempts to detect and track features in ultrasound image sequences have been based on detecting edges <ref> [1, 2, 14, 17, 19] </ref>. This may be due to specific objectives (precise measurement of tissue structure dimensions), or simply because much of the computer vision literature focuses on detecting edges (in photographic and video image data).
Reference: [18] <author> A.M. Baumberg and D.C. Hogg. </author> <title> An efficient method for contour tracking using active shape models. </title> <institution> University of Leeds, School of Computer Studies, Tech Report 94.11. </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: In effect, it would attempt to bridge a gap which should not be bridged. Deformable templates have been proposed as an alternative method for detecting and tracking features in image sequences <ref> [15, 18] </ref>. A deformable template is a parametric representation (with a small number of parameters) of an idealized feature of the particular type one expects to track. Example applications include detecting or tracking a pedestrian [18], a hand [16], a vertebral trabecular bone [15], or a left ventricle [17]. <p> A deformable template is a parametric representation (with a small number of parameters) of an idealized feature of the particular type one expects to track. Example applications include detecting or tracking a pedestrian <ref> [18] </ref>, a hand [16], a vertebral trabecular bone [15], or a left ventricle [17]. With this approach, detecting the feature corresponds to searching the parameter space of the parameterized template to find the best match with the image data. <p> With this approach, detecting the feature corresponds to searching the parameter space of the parameterized template to find the best match with the image data. Methods for conducting this search include simulated annealing [16] and iterative schemes based on Kalman filters <ref> [18] </ref> or energy minimization techniques (like snakes) [15]. At first, the idea of detecting and tracking features in echocardiogram image sequences seemed plausible, particularly since there are only a small number of "views" typically used by diagnosticians.
Reference: [19] <author> L.D. Cohen. </author> <title> Note on active contour models and balloons. CVGIP: </title> <booktitle> Image Understanding 53(2) </booktitle> <pages> 211-218. </pages> <year> 1991. </year>
Reference-contexts: Many previous attempts to detect and track features in ultrasound image sequences have been based on detecting edges <ref> [1, 2, 14, 17, 19] </ref>. This may be due to specific objectives (precise measurement of tissue structure dimensions), or simply because much of the computer vision literature focuses on detecting edges (in photographic and video image data).
Reference: [20] <author> N. Selmaoui, C. Leschi and H. Emptoz. </author> <title> Crest lines detection in grey level images: studies of different approaches and proposition of a new one. </title> <booktitle> Computer analysis of images and patterns : 5th international conference, </booktitle> <address> CAIP '93. </address>
Reference-contexts: Also, faint local maxima stand more chance of corresponding to noise and should not be tracked as persistently as strong local maxima. Other authors have proposed methods for characterizing the shape of a gray-scale image at a local maximum <ref> [20, 22] </ref>. Selmaoui et al [20] propose a scheme based on classifying a pixel according to rules applied to the 3x3 window surrounding it. Gauch and Pizer [21] and Eberly et al [22] use concepts from differential geometry. <p> Also, faint local maxima stand more chance of corresponding to noise and should not be tracked as persistently as strong local maxima. Other authors have proposed methods for characterizing the shape of a gray-scale image at a local maximum [20, 22]. Selmaoui et al <ref> [20] </ref> propose a scheme based on classifying a pixel according to rules applied to the 3x3 window surrounding it. Gauch and Pizer [21] and Eberly et al [22] use concepts from differential geometry. In their approaches, the image intensity values can be thought of as describing a surface in 3D.
Reference: [21] <author> J.M. Gauch and S.M. Pizer. </author> <title> Multiresolution analysis of ridges and valleys in grey-scale images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 15(6) </journal> <pages> 635-646. </pages> <year> 1993. </year>
Reference-contexts: Other authors have proposed methods for characterizing the shape of a gray-scale image at a local maximum [20, 22]. Selmaoui et al [20] propose a scheme based on classifying a pixel according to rules applied to the 3x3 window surrounding it. Gauch and Pizer <ref> [21] </ref> and Eberly et al [22] use concepts from differential geometry. In their approaches, the image intensity values can be thought of as describing a surface in 3D. Each local maximum can then be characterized by the principal curvatures and directions at that point.
Reference: [22] <author> D. Eberly, R. Gardner, B. Morse, S. Pizer and C. Scharlach. </author> <title> Ridges for image analysis. </title> <institution> University of North Carolina, Department of Computer Science, </institution> <type> Tech Report 93-055. </type> <year> 1993. </year>
Reference-contexts: Also, faint local maxima stand more chance of corresponding to noise and should not be tracked as persistently as strong local maxima. Other authors have proposed methods for characterizing the shape of a gray-scale image at a local maximum <ref> [20, 22] </ref>. Selmaoui et al [20] propose a scheme based on classifying a pixel according to rules applied to the 3x3 window surrounding it. Gauch and Pizer [21] and Eberly et al [22] use concepts from differential geometry. <p> Other authors have proposed methods for characterizing the shape of a gray-scale image at a local maximum [20, 22]. Selmaoui et al [20] propose a scheme based on classifying a pixel according to rules applied to the 3x3 window surrounding it. Gauch and Pizer [21] and Eberly et al <ref> [22] </ref> use concepts from differential geometry. In their approaches, the image intensity values can be thought of as describing a surface in 3D. Each local maximum can then be characterized by the principal curvatures and directions at that point.
Reference: [23] <author> M.P. </author> <title> do Carmo. Differential geometry of curves and surfaces. </title> <publisher> Prentice-Hall, Inc. </publisher> <year> 1976. </year>
Reference-contexts: The principal directions give the orientation of the ridge. At a round peak, both principal curvatures are are nearly equal (and negative). Methods exist from differential geometry for calculating curvature information at a point, given first and second order derivatives. See, for example, <ref> [23] </ref>. Gauch and Pizer estimate derivative information by first fitting a spline surface to the image data. Derivatives of the spline surface can be readily calculated. They apply this method to images with realively little noise, such as medical MRI images and fingerprints.
Reference: [24] <author> P. Foerster. </author> <title> Pre-calculus with trigonometry. </title> <publisher> Addison-Wesley. </publisher> <year> 1991. </year>
Reference-contexts: I mean, is efficient. (It involves the multiplication of a 3x24 matrix and a 24x1 vector). Given the degree 2 polynomial approximating the surface locally at p, the principal curvatures and and directions can be found without resort to explicit derivatives, using techniques from analytic geometry <ref> [24] </ref>. The basic idea is that the iso-lines of the degree 2 polynomial surface around p form concentric ellipses (since p is a local maximum).
Reference: [25] <author> G. Turk. </author> <title> Interactive collision detection for molecular graphics. M.Sc. </title> <type> thesis, </type> <institution> Department of Computer Science, </institution> <address> University of North Carolina. </address> <booktitle> 1989. </booktitle> <volume> 13 11 Figures 14 15 16 17 18 19 20 21 22 23 24 25 26 27 </volume>
Reference-contexts: Secondly, in order to make the first step efficient, the operation of finding nearby feature 9 points at a given pixel must be fast. I used a scheme based on uniform spatial subdivision <ref> [25] </ref>, in which feature points record their id's in "buckets" of dimension 4x4 pixels in a radius R around the feature point. When two feature points from the same feature record their id's in the same bucket, the one closest to the bucket overwrites the other one.
References-found: 25

