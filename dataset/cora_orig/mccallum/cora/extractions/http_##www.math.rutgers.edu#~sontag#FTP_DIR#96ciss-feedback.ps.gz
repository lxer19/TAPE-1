URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/96ciss-feedback.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Email: clarke@crm.umontreal.ca  ledyaev@mian.su  sontag@control.rutgers.edu  sai@subb.intec.ru  
Title: ASYMPTOTIC CONTROLLABILITY AND FEEDBACK STABILIZATION  
Author: F. H. Clarke Yu. S.Ledyaev Eduardo Sontag A. I. Subbotin 
Address: Montreal, Quebec, Canada, H3C 3J7  Moscow 117966 Russia  New Brunswick, NJ 08903, USA  Ekaterinburg 620219 Russia  
Affiliation: Centre de Recherches Mathematiques Universite de Montreal  Steklov Institute of Mathematics  Dept. of Mathematics Rutgers University  Inst. of Mathematics Mechanics  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Artstein, Z., </author> <title> "Stabilization with relaxed controls," </title> <journal> Nonl. Anal., </journal> <volume> TMA 7(1983): </volume> <pages> 1163-1173. </pages>
Reference-contexts: In other words, there is no analogue of the classical theorems due to Massera and Kurzweil. This issue is intimately related to that of existence of continuous feedback, via what is known as Artstein's Theorem (cf. <ref> [1, 10, 11, 15] </ref>), which asserts that existence of a differentiable V is equivalent, for systems affine in controls, to there being a stabilizing regular feedback.
Reference: [2] <author> Brockett, R.W., </author> <title> "Asymptotic stability and feedback stabilization," in Differential Geometric Control theory (R.W. </title> <editor> Brockett, R.S. Millman, and H.J. Sussmann, eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1983, </year> <pages> pp. 181-191. </pages>
Reference-contexts: General results regarding the nonexistence of continuous feedback were presented in the paper <ref> [2] </ref>, where techniques from topological degree theory were used (an exposition is given in the textbook [16]). These negative results led to the search for feedback laws which are not necessarily of the form u = k (x), k a continuous function.
Reference: [3] <author> Clarke, F.H., </author> <title> Methods of Dynamic and Nonsmooth Optimization. </title> <booktitle> Volume 57 of CBMS-NSF Regional Conference Series in Applied Mathematics, </booktitle> <publisher> S.I.A.M., </publisher> <address> Philadelphia, </address> <year> 1989. </year>
Reference-contexts: The use of proximal subgradients as substitutes for the gradient for a nondifferentiable function plays a central role in our contruction of feedback. The concept was originally developed in nonsmooth analysis for the study of optimization problems, see <ref> [3] </ref>. Finally, we rely on methods developed in the theory of positional differential games in [12].
Reference: [4] <author> Clarke, F.H., Yu.S. Ledyaev, and P. Wolenski, </author> <title> "Proximal analysis and minimization principles," </title> <journal> J. Math. Anal. Appl. </journal> <volume> 196 (1995): </volume> <pages> 722-735 </pages>
Reference-contexts: In the case of a lower semi-continuous V which is bounded below (for instance, for a clf V , which is continuous and nonnegative), the function V ff is locally Lipschitz and is an approximation of V in the sense that lim ff#0 V ff (x) = V (x); cf. <ref> [4] </ref>. In this case, the set of minimizing points y in (9) is nonempty.
Reference: [5] <author> Clarke, F.H., Yu.S. Ledyaev, and A.I. Subbotin, </author> <title> "Universal feedback strategies for differential games of pursuit," </title> <note> SIAM J. Control , (in press). </note>
Reference-contexts: Finally, we rely on methods developed in the theory of positional differential games in [12]. These techniques were used together with nonsmooth analysis tools in the construction of discontinuous feedback for differ ential games of pursuit in <ref> [5] </ref> and games of fixed duration in [6], and these results are relevant to the construction of stabilizing feedback in our main result. 3. Proximal Subgradients and Inf-Convolutions We recall the concept of proximal subgradient, one of the basic building blocks of nonsmooth analysis.
Reference: [6] <author> Clarke, F.H., Yu.S. Ledyaev, and A.I. Subbotin, </author> <title> "Universal feedback via proximal aiming in problems of control and differential games," </title> <type> preprint, </type> <institution> U. de Montreal. </institution>
Reference-contexts: Finally, we rely on methods developed in the theory of positional differential games in [12]. These techniques were used together with nonsmooth analysis tools in the construction of discontinuous feedback for differ ential games of pursuit in [5] and games of fixed duration in <ref> [6] </ref>, and these results are relevant to the construction of stabilizing feedback in our main result. 3. Proximal Subgradients and Inf-Convolutions We recall the concept of proximal subgradient, one of the basic building blocks of nonsmooth analysis.
Reference: [7] <author> Coron, J-M., </author> <title> "Global asymptotic stabilization for controllable systems without drift," Math of Control, Signals, </title> <booktitle> and Systems 5(1992): </booktitle> <pages> 295-312. </pages>
Reference-contexts: Such time-varying laws were shown in [18] to be always possible in the case of one-dimensional systems, and in the major work <ref> [7] </ref> it was shown that they are also always possible when the original system is completely controllable and has "no drift", meaning essentially that f (x; 0) = 0 for all states (see also [17] for numerical algorithms and an alternative proof of the time-varying result for analytic systems).
Reference: [8] <author> Coron, J.-M., and L. Rosier, </author> <title> "A relation between continuous time-varying and discontinuous feedback stabilization," J.Math. Systems, Estimation, </title> <booktitle> and Control 4(1994): </booktitle> <pages> 67-84. </pages>
Reference-contexts: However, it follows from the results in <ref> [13, 8] </ref> that the existence of a discontinuous stabilizing feedback in the Filippov sense implies the same Brockett necessary conditions as the existence of a continuous stabilizing feedback does. <p> However, it follows from the results in [13, 8] that the existence of a discontinuous stabilizing feedback in the Filippov sense implies the same Brockett necessary conditions as the existence of a continuous stabilizing feedback does. Moreover, it is shown in <ref> [8] </ref> that the existence of a stabilizing feedback in the Filippov sense is equivalent to the existence of a continuous stabilizing one, in the case of systems affine in controls. In conclusion, there is no hope of obtaining general results if one insists on the use of Filippov solutions.
Reference: [9] <author> Filippov, </author> <title> A.F., "Differential equations with discontinuous right-hand side," </title> <journal> Matem. Sbornik 5(1960): 99-127. English trans. in Amer. Math. </journal> <volume> Translations 42(1964): </volume> <pages> 199-231. </pages>
Reference-contexts: Unfortunately, allowing nonreg-ular feedback leads to an immediate difficulty: how should one define the meaning of solution x () of the differential equation (2) with discontinuous right-hand side? One of the best-known candidates for the concept of solution of (2) is that of a Filippov solution (cf. <ref> [9] </ref>), which is defined as the solution of a certain differential inclusion with multivalued right-hand side which is built from f (x; k (x)).
Reference: [10] <author> Isidori, A., </author> <title> Nonlinear Control Systems, Third Edition, </title> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: Finally, the Lyapunov stability property holds by construction. The interesting implication is the converse, namely the construction of the feedback law. The main ingredients in this construction are: (a) the notion of control-Lyapunov function (called just "Lyapunov function" for a control system in [16]; see also <ref> [10, 11] </ref>), (b) methods of nons-mooth analysis, and (c) techniques from positional differential games. We review these ingredients in the next section, and then develop further technical results; the last section contains the proof. 2. <p> In other words, there is no analogue of the classical theorems due to Massera and Kurzweil. This issue is intimately related to that of existence of continuous feedback, via what is known as Artstein's Theorem (cf. <ref> [1, 10, 11, 15] </ref>), which asserts that existence of a differentiable V is equivalent, for systems affine in controls, to there being a stabilizing regular feedback.
Reference: [11] <author> Krstic, M., I. Kanellakopoulos, and P. Kokotovic, </author> <title> Nonlinear and adaptive control design, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Finally, the Lyapunov stability property holds by construction. The interesting implication is the converse, namely the construction of the feedback law. The main ingredients in this construction are: (a) the notion of control-Lyapunov function (called just "Lyapunov function" for a control system in [16]; see also <ref> [10, 11] </ref>), (b) methods of nons-mooth analysis, and (c) techniques from positional differential games. We review these ingredients in the next section, and then develop further technical results; the last section contains the proof. 2. <p> In other words, there is no analogue of the classical theorems due to Massera and Kurzweil. This issue is intimately related to that of existence of continuous feedback, via what is known as Artstein's Theorem (cf. <ref> [1, 10, 11, 15] </ref>), which asserts that existence of a differentiable V is equivalent, for systems affine in controls, to there being a stabilizing regular feedback.
Reference: [12] <author> Krasovskii, N.N., and A.I. Subbotin, </author> <title> Positional differential games, </title> <publisher> Nauka, </publisher> <address> Moscow, </address> <note> 1974 [in Russian]. French translation Jeux differentiels, Editions Mir, Moscou, </note> <year> 1979. </year> <title> Revised English translation Game-Theoretical Control Problems, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Our notion is borrowed from the theory of positional differential games, and it was systematically studied in that context by Krasovskii and Subbotin in <ref> [12] </ref>. 1.1. <p> The concept was originally developed in nonsmooth analysis for the study of optimization problems, see [3]. Finally, we rely on methods developed in the theory of positional differential games in <ref> [12] </ref>. These techniques were used together with nonsmooth analysis tools in the construction of discontinuous feedback for differ ential games of pursuit in [5] and games of fixed duration in [6], and these results are relevant to the construction of stabilizing feedback in our main result. 3.
Reference: [13] <author> Ryan, </author> <title> E.P., "On Brockett's condition for smooth stabiliz-ability and its necessity in a context of nonsmooth feedback," </title> <journal> SIAM J. Control Optim. </journal> <volume> 32(1994): </volume> <pages> 1597-1604. </pages>
Reference-contexts: However, it follows from the results in <ref> [13, 8] </ref> that the existence of a discontinuous stabilizing feedback in the Filippov sense implies the same Brockett necessary conditions as the existence of a continuous stabilizing feedback does.
Reference: [14] <author> Sontag E.D., </author> <title> "A Lyapunov-like characterization of asymptotic controllability," </title> <journal> SIAM J. Control and Opt. </journal> <volume> 21(1983): </volume> <pages> 462-471. </pages>
Reference-contexts: If V is part of a control-Lyapunov pair (V; W ), it is a control-Lyapunov function (clf ). It was shown in <ref> [14] </ref> that asymptotic controllability is equivalent to the existence of a pair of functions (V; W ) which satisfy the properties given above, except that property 3 is expressed in an apparently weaker fashion, namely, by means of derivatives along trajectories (corresponding to relaxed controls).
Reference: [15] <author> Sontag, E.D., </author> <title> "A `universal' construction of Artstein's theorem on nonlinear stabilization," </title> <journal> Systems and Control Letters, </journal> <volume> 13(1989): </volume> <pages> 117-123. </pages>
Reference-contexts: In other words, there is no analogue of the classical theorems due to Massera and Kurzweil. This issue is intimately related to that of existence of continuous feedback, via what is known as Artstein's Theorem (cf. <ref> [1, 10, 11, 15] </ref>), which asserts that existence of a differentiable V is equivalent, for systems affine in controls, to there being a stabilizing regular feedback.
Reference: [16] <author> Sontag E.D., </author> <title> Mathematical Control Theory, Deterministic Finite Dimensional Systems, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: General results regarding the nonexistence of continuous feedback were presented in the paper [2], where techniques from topological degree theory were used (an exposition is given in the textbook <ref> [16] </ref>). These negative results led to the search for feedback laws which are not necessarily of the form u = k (x), k a continuous function. <p> This is a natural generalization to control systems of the concept of uniform asymptotic stability of solutions of differential equations. The last property which is not part of the standard definition of asymptotic controllability given in textbooks, e.g. <ref> [16] </ref> is introduced here for technical reasons, and it has the effect of ruling out the case in which the only way to control to zero is by using controls that must "go to infinity" as the state approaches the origin. Our main result is as follows. <p> Finally, the Lyapunov stability property holds by construction. The interesting implication is the converse, namely the construction of the feedback law. The main ingredients in this construction are: (a) the notion of control-Lyapunov function (called just "Lyapunov function" for a control system in <ref> [16] </ref>; see also [10, 11]), (b) methods of nons-mooth analysis, and (c) techniques from positional differential games. We review these ingredients in the next section, and then develop further technical results; the last section contains the proof. 2.
Reference: [17] <author> Sontag E.D., </author> <title> "Control of systems without drift via generic loops," </title> <journal> IEEE Trans. Autom. Control 40(1995): </journal> <pages> 1210-1219. </pages>
Reference-contexts: [18] to be always possible in the case of one-dimensional systems, and in the major work [7] it was shown that they are also always possible when the original system is completely controllable and has "no drift", meaning essentially that f (x; 0) = 0 for all states (see also <ref> [17] </ref> for numerical algorithms and an alternative proof of the time-varying result for analytic systems). However, for the general case of asymptotically controllable systems with drift, no dynamic or time-varying solutions are known. Thus it is natural to ask about the existence of discontinuous feedback laws u = k (x).
Reference: [18] <author> Sontag, E.D., and H.J. Sussmann, </author> <title> "Remarks on continuous feedback," </title> <booktitle> in Proc. IEEE Conf. Decision and Control, </booktitle> <address> Albuquerque, Dec. 1980, </address> <publisher> IEEE Publications, Piscat-away, </publisher> <pages> pp. 457-458. </pages>
Reference-contexts: But it is well-known that continuous feedback laws may fail to exist even for simple asymptotically controllable nonlinear systems. This is especially easy to see, as discussed in <ref> [18] </ref>, for one-dimensional (U = R, n = 1) systems (1): in that case asymptotic controllability is equivalent to the property "for each x 6= 0 there is some value u so that xf (x; u) &lt; 0", but it is easy to construct examples of functions f, even analytic, for <p> One possible approach consists of looking for dynamical feedback laws, where additional "memory" variables are introduced into a controller, and as a very special case, time-varying (even periodic) continuous feedback u = k (t; x). Such time-varying laws were shown in <ref> [18] </ref> to be always possible in the case of one-dimensional systems, and in the major work [7] it was shown that they are also always possible when the original system is completely controllable and has "no drift", meaning essentially that f (x; 0) = 0 for all states (see also [17]
Reference: [19] <author> Sontag, E.D., and H.J. Sussmann, </author> <title> "Nonsmooth control-Lyapunov functions," </title> <booktitle> Proc. IEEE Conf. Decision and Control, </booktitle> <address> New Orleans, Dec. 1995, </address> <publisher> IEEE Publications, </publisher> <year> 1995, </year> <pages> pp. 2799-2805. </pages>
Reference-contexts: In <ref> [19] </ref> it was observed that in fact one can reformulate the definition in the above terms, so we obtain as follows. Theorem 2 The system (1) is asymptotically control lable if and only if it admits a control-Lyapunov function.
References-found: 19

