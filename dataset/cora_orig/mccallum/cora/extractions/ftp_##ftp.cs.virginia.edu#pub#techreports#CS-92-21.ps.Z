URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-92-21.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Note: This research was supported in part by NSF Grant #CCR-9108448 and JPL Contract #957721.  
Abstract: Making Parallel Simulations Go Fast Paul F. Reynolds, Jr.,Carmen M. Pancerella,Sudhir Srinivasan Computer Science Report No. CS-92-21 June 17, 1992 
Abstract-found: 1
Intro-found: 1
Reference: [AbRi91] <author> Abrams, M. and Richardson, D., </author> <title> "Implementing a Global Termination Condition and Collecting Output Measures in Parallel Simulation", </title> <booktitle> Proceedings of the SCS Multiconference on Advances in Parallel and Distributed Simulation, </booktitle> <address> Anaheim, California, </address> <pages> pp. 86-91, </pages> <month> (January </month> <year> 1991). </year>
Reference-contexts: For example, a window may be enlarged by including this additional knowledge. Finally, the challenge of global termination detection and the calculation of output measures in a PDES <ref> [AbRi91] </ref> can be realized easily within our framework. Many global termination conditions for example, sums and boolean operations can be calculated and disseminated efficiently in a reduction network.
Reference: [Bell90] <author> Bellenot, S., </author> <title> "Global Virtual Time Algorithms", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 122-127, </pages> <month> (January </month> <year> 1990). </year>
Reference-contexts: GVT computation and dissemination in this hardware-based framework is a significant improvement in algorithm complexity and implementation efficiency over previously proposed GVT maintenance schemes ([Jeff85], [JeSo85], [Sama85], [LiLa89], <ref> [Bell90] </ref>, [CoKe91]). Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], [Fuji88], [ReMM88], and [FeKl92].). A hardware-based framework can be used to calculate and disseminate the smallest future time that an LP can send event messages.
Reference: [ChLa85] <author> Chandy, K. M. and Lamport, L., </author> <title> "Distributed Snapshots: Determining Global States of Distributed Systems", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 3, No. 1, </volume> <pages> pp. 63-75, </pages> <month> (February </month> <year> 1985). </year>
Reference-contexts: Many global termination conditions for example, sums and boolean operations can be calculated and disseminated efficiently in a reduction network. Unlike Chandy and Lamport's distributed snapshot algorithm <ref> [ChLa85] </ref>, a framework consisting of synchronization values and related algorithms can be used to evaluate termination conditions even when there are outstanding messages in the parallel simulation.
Reference: [CoKe91] <author> Concepcion, A. I. and Kelly, S. G., </author> <title> "Computing Global Virtual Time Using the Multi-Level Token Passing Algorithm", </title> <booktitle> Proceedings of the SCS Multiconference on Advances in Parallel and Distributed Simulation, </booktitle> <address> Anaheim, California, </address> <pages> pp. 63-68, </pages> <month> (January </month> <year> 1991). </year>
Reference-contexts: GVT computation and dissemination in this hardware-based framework is a significant improvement in algorithm complexity and implementation efficiency over previously proposed GVT maintenance schemes ([Jeff85], [JeSo85], [Sama85], [LiLa89], [Bell90], <ref> [CoKe91] </ref>). Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], [Fuji88], [ReMM88], and [FeKl92].). A hardware-based framework can be used to calculate and disseminate the smallest future time that an LP can send event messages.
Reference: [CrKn85] <author> Crockett, T. W. and Knott, J. D., </author> <title> "System Software for the Finite Element Machine", </title> <type> NASA Contractor Report 3870, </type> <institution> NASA Langley, Hampton, Virginia, </institution> <month> February </month> <year> 1985. </year>
Reference-contexts: Lubachevsky [Luba88] suggests using a binary tree implemented in hardware in order to support synchronization barriers and to compute and broadcast a minimum next event time in a bounded lag PDES. His control synchronization network is presented strictly in support of this PDES protocol. The Finite Element Machine <ref> [CrKn85, JoSc79] </ref>, a NASA prototype, utilizes a binary tree-structured max/summation network to perform the global sum and maximum calculations necessary to support structural analysis algorithms. Like the hardware we propose, the sum and max calculations in the FEM are calculated alternately without processor synchronization.
Reference: [DiRe92] <author> Dickens, P. M. and Reynolds Jr., P. F., </author> <title> "State Saving and Rollback Costs for an Aggressive Global Windowing Algorithm ", Computer Science Report No. </title> <type> Technical Report-92-18, </type> <institution> Department of Computer Science, University of Virginia, Charlottesville, Virginia, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: We have a hardware-based framework for disseminating this information easily. Iterative PDES algorithms, such as Bounded Lag [Luba88], Moving Time Window [SoBW88], and the aggressive Global Windowing Algorithm discussed in <ref> [DiRe92] </ref>, require the rapid computation and dissemination of ceiling values or fault values. Lubachevsky has recognized that a special-purpose network can be used to broadcast a minimum event time in his bounded lag protocol [Luba88]; a reduction network can efficiently support this PDES algorithm and other PDES windowing algorithms.
Reference: [FeKl90] <author> Felderman, R. E. and Kleinrock, L., </author> <title> "Two Processor Time Warp Analysis: Capturing the Effects of Message Queueing and Rollback/State Saving Costs ", submitted to ACM Transactions on Modeling and Computer Simulation, </title> <month> (November </month> <year> 1990). </year>
Reference-contexts: If each LP submits a current estimate of its rate of simulation, the fastest (or slowest) LP (with respect to logical time) can be identified. In <ref> [FeKl90] </ref> the authors show analytically that a Time Warp simulation can be more efficient if a faster LP is slowed down; they do not propose how the information might be propagated. We have a hardware-based framework for disseminating this information easily.
Reference: [FeKl92] <author> Felderman, R. E. and Kleinrock, L., </author> <title> "Two Processor Conservative Simulation Analysis", </title> <booktitle> Proceedings of the 1992 Western Simulation MultiConference on Parallel and Distributed Simulation, </booktitle> <address> Newport Beach, California, </address> <pages> pp. 169-177, </pages> <month> (January </month> <year> 1992). </year>
Reference-contexts: Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], [Fuji88], [ReMM88], and <ref> [FeKl92] </ref>.). A hardware-based framework can be used to calculate and disseminate the smallest future time that an LP can send event messages. Each LP computes the value it submits to this reduction based on its current local clock and its minimum processing time.
Reference: [FiGP91] <author> Filoque, J. M., Gautrin, E. and Pottier, B., </author> <title> "Efficient Global Computations on a Processors Network with Programmable Logic", </title> <type> Report 1374, </type> <institution> Institut National de Recherche en Informatique et en Anutomatique, France, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Exceptions include Fujimoto's rollback chip [FuTG92] and virtual computer [Fuji89] efforts, Filoque's global virtual time (GVT) network <ref> [FiGP91] </ref> and our own framework [Reyn92]. Recent simulation results [Srin92] show beyond a doubt that specialized hardware such as the framework we describe here can yield significant benefits to parallel simulations. We describe the details of a hardware realization of the framework described in [Reyn92]. <p> Our hardware design, however, employs a set of input and output registers which are treated as a single state vector, whereas the FEM uses a single input and a single output register. At about the same time that we introduced our framework, Filoque, et.al., <ref> [FiGP91] </ref> proposed the use of a processor network with programmable logic for efficient global computations, such as the computation of GVT in a Time Warp simulation. This hardware is not a single network like the PRN; it is, however, a distributed system of sockets, one per processor. <p> When the token returns to the controller, the global computation is complete. Therefore, their proposed hardware performs global computations in O (n) time whereas the PRN performs the same computations in O (logn) time. Furthermore, the proposed synchronization algorithms for computing GVT in <ref> [FiGP91] </ref> rely on the host communication network for message acknowledgements and our framework uses the framework hardware for this purpose. The goals of both approaches are similar, but our framework is more efficient, more flexible, and more scalable. Several researchers have proposed the use of hardware to implement barrier synchronization.
Reference: [Fuji87] <author> Fujimoto, R. M., </author> <title> "Performance Measurements of Distributed Simulation Strategies", </title> <type> Technical Report No. </type> <institution> UUCS-87-026a, Computer Science Department, University of Utah, </institution> <address> Salt Lake City, Utah, </address> <month> November </month> <year> 1987. </year> <month> 15 </month>
Reference-contexts: Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See <ref> [Fuji87] </ref>, [Fuji88], [ReMM88], and [FeKl92].). A hardware-based framework can be used to calculate and disseminate the smallest future time that an LP can send event messages. Each LP computes the value it submits to this reduction based on its current local clock and its minimum processing time.
Reference: [Fuji88] <author> Fujimoto, R. M., </author> <title> "Lookahead in Parallel Discrete Event Simulation", </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <address> University Park, Pennsylvania, </address> <pages> pp. 34-41, </pages> <month> (August </month> <year> 1988). </year>
Reference-contexts: Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], <ref> [Fuji88] </ref>, [ReMM88], and [FeKl92].). A hardware-based framework can be used to calculate and disseminate the smallest future time that an LP can send event messages. Each LP computes the value it submits to this reduction based on its current local clock and its minimum processing time.
Reference: [Fuji89] <author> Fujimoto, R. M., </author> <title> "The Virtual Time Machine", </title> <booktitle> Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <address> Santa Fe, New Mexico, </address> <pages> pp. 199-208, </pages> <month> (June </month> <year> 1989). </year>
Reference-contexts: Exceptions include Fujimoto's rollback chip [FuTG92] and virtual computer <ref> [Fuji89] </ref> efforts, Filoque's global virtual time (GVT) network [FiGP91] and our own framework [Reyn92]. Recent simulation results [Srin92] show beyond a doubt that specialized hardware such as the framework we describe here can yield significant benefits to parallel simulations.
Reference: [FuTG92] <author> Fujimoto, R. M., Tsai, J. J. and Gopalakrishnan, G. C., </author> <title> "Design and Evaluation of the Rollback Chip: Special Purpose Hardware for Time Warp", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 41, No. 1, </volume> <pages> pp. 68-82, </pages> <month> (January </month> <year> 1992). </year>
Reference-contexts: 1. Introduction Despite the fact that parallel simulation and the potential speed-up it offers are regarded as crucial to many applications digital network simulation, military simulations, air traffic control simulations, and the like very few efforts have focussed on specialized hardware to support parallel simulation. Exceptions include Fujimoto's rollback chip <ref> [FuTG92] </ref> and virtual computer [Fuji89] efforts, Filoque's global virtual time (GVT) network [FiGP91] and our own framework [Reyn92]. Recent simulation results [Srin92] show beyond a doubt that specialized hardware such as the framework we describe here can yield significant benefits to parallel simulations. <p> Simulations [Srin92] have demonstrated the feasibility of this hardware; however, actual PDES implementations on the prototype will validate our performance predictions. Furthermore, we have proposed to integrate our hardware, which offloads global synchronization in a PDES, with Fujimoto's rollback chip <ref> [FuTG92] </ref>, which offloads state saving and state restoration in an aggressive PDES, in order to build a Parallel Simulation Engine. Finally, an open research problem is the construction of the next version of the framework hardware which rapidly disseminates target specific reductions on contributed values.
Reference: [Hosh85] <author> Hoshino, T., </author> <title> PAX Computer: High-Speed Parallel Processing and Scientific Computing, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1985. </year>
Reference-contexts: The goals of both approaches are similar, but our framework is more efficient, more flexible, and more scalable. Several researchers have proposed the use of hardware to implement barrier synchronization. Hoshino <ref> [Hosh85] </ref> has an efficient barrier synchronization in the PAX computer. Stone [Ston90] suggests the use of global busses to compute maximum values and to implement fetch-and-increment. The hardware that we propose, on the other hand, provides support for a larger class of algorithms than barrier synchronization algorithms.
Reference: [Inte89] <author> Intel Corporation, </author> <title> iPSC/2 Programmer's Reference Manual, Intel Scientific Computers, </title> <institution> Beaverton, Oregon, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: The hardware that we propose, on the other hand, provides support for a larger class of algorithms than barrier synchronization algorithms. Many parallel architectures provide for global binary, associative operations across all processors. Global operations on the Intel iPSC/2 <ref> [Inte89] </ref> are provided for arithmetic and logical operations. The Thinking Machines CM-5 [Thin92] contains two separate networks for different types of communication and synchronization: the data network is the primary message-passing network in the machine and the control network provides hardware support for common cooperative operations.
Reference: [JeSo85] <author> Jefferson, D. and Sowizral, H., </author> <title> "Fast Concurrent Simulation Using the Time Warp Mechanism", </title> <booktitle> Proceedings of the Conference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 63-69, </pages> <month> (January </month> <year> 1985). </year>
Reference-contexts: GVT computation and dissemination in this hardware-based framework is a significant improvement in algorithm complexity and implementation efficiency over previously proposed GVT maintenance schemes ([Jeff85], <ref> [JeSo85] </ref>, [Sama85], [LiLa89], [Bell90], [CoKe91]). Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], [Fuji88], [ReMM88], and [FeKl92].).
Reference: [Jeff85] <author> Jefferson, D. R., </author> <title> "Virtual Time", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 7, No. 3, </volume> <pages> pp. 404-425, </pages> <month> (July </month> <year> 1985). </year>
Reference-contexts: The tag field for a message acknowledgement is a unique message ID. In an aggressive PDES synchronization protocol (See [Reyn88].), such as Time Warp <ref> [Jeff85] </ref>, GVT can be efficiently computed by an LP at any time using our framework; it is simply, by definition, the minimum of the two globally reduced values: minimum next event time and minimum outstanding message time.
Reference: [JoSc79] <author> Jordan, H. F., Scalabrin, M. and Calvert, W., </author> <title> "A Comparison of Three Types of Multiprocessor Algorithms", </title> <booktitle> Proceedings of the 1979 International Conference on Parallel Processing, </booktitle> <pages> pp. 231-238, </pages> <month> (August </month> <year> 1979). </year>
Reference-contexts: Lubachevsky [Luba88] suggests using a binary tree implemented in hardware in order to support synchronization barriers and to compute and broadcast a minimum next event time in a bounded lag PDES. His control synchronization network is presented strictly in support of this PDES protocol. The Finite Element Machine <ref> [CrKn85, JoSc79] </ref>, a NASA prototype, utilizes a binary tree-structured max/summation network to perform the global sum and maximum calculations necessary to support structural analysis algorithms. Like the hardware we propose, the sum and max calculations in the FEM are calculated alternately without processor synchronization.
Reference: [LiLa89] <author> Lin, Y. B. and Lazowska, E. D., </author> <title> "Determining the Global Virtual Time in a Distributed Simulation", </title> <type> Technical Report 90-01-02, </type> <institution> Department of Computer Science, University of Washington, </institution> <address> Seattle, Washington, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: GVT computation and dissemination in this hardware-based framework is a significant improvement in algorithm complexity and implementation efficiency over previously proposed GVT maintenance schemes ([Jeff85], [JeSo85], [Sama85], <ref> [LiLa89] </ref>, [Bell90], [CoKe91]). Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], [Fuji88], [ReMM88], and [FeKl92].).
Reference: [Luba88] <author> Lubachevsky, B. D., </author> <title> "Bounded Lag Distributed Discrete Event Simulation", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 183-191, </pages> <month> (February </month> <year> 1988). </year>
Reference-contexts: In [FeKl90] the authors show analytically that a Time Warp simulation can be more efficient if a faster LP is slowed down; they do not propose how the information might be propagated. We have a hardware-based framework for disseminating this information easily. Iterative PDES algorithms, such as Bounded Lag <ref> [Luba88] </ref>, Moving Time Window [SoBW88], and the aggressive Global Windowing Algorithm discussed in [DiRe92], require the rapid computation and dissemination of ceiling values or fault values. Lubachevsky has recognized that a special-purpose network can be used to broadcast a minimum event time in his bounded lag protocol [Luba88]; a reduction network <p> as Bounded Lag <ref> [Luba88] </ref>, Moving Time Window [SoBW88], and the aggressive Global Windowing Algorithm discussed in [DiRe92], require the rapid computation and dissemination of ceiling values or fault values. Lubachevsky has recognized that a special-purpose network can be used to broadcast a minimum event time in his bounded lag protocol [Luba88]; a reduction network can efficiently support this PDES algorithm and other PDES windowing algorithms. The efficiency of these algorithms can be increased since these algorithms typically rely on a host network, much slower than our hardware, to disseminate windowing values. <p> Our reduction network is not as complex or expensive as a combining network, yet it performs global synchronization operations very efficiently. We claim no novelty with respect to reduction networks. Lubachevsky <ref> [Luba88] </ref> suggests using a binary tree implemented in hardware in order to support synchronization barriers and to compute and broadcast a minimum next event time in a bounded lag PDES. His control synchronization network is presented strictly in support of this PDES protocol.
Reference: [LuWS91] <author> Lubachevsky, B., Weiss, A. and Shwartz, A., </author> <title> "An Analysis of Rollback-Based Simulation", </title> <journal> ACM Transactions on Modeling and Computer Simulation, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 154-193, </pages> <month> (April </month> <year> 1991). </year>
Reference-contexts: It has been suggested that an adaptive protocol, one which is an intelligent combination of aggressive and nonaggressive protocols, may be more powerful than either in a pure form <ref> [LuWS91, Reyn88, Reyn92] </ref>. In the future we intend to report on the performance of the prototype PRN, which is a collaborative effort of the Computer Science and Electrical Engineering Departments at the University of Virginia to be completed in Summer 1992.
Reference: [Panc92] <author> Pancerella, C. M., </author> <title> "Improving the Efficiency of a Framework for Parallel Simulations", </title> <booktitle> Proceedings of the 1992 Western Simulation MultiConference on Parallel and Distributed Simulation, </booktitle> <address> Newport Beach, California, </address> <pages> pp. 22-29, </pages> <month> (January </month> <year> 1992). </year> <month> 16 </month>
Reference-contexts: We expect a new global value to be emitted from the reduction network every 150 nanoseconds. One such set of globally reduced values and related synchronization algorithms have been presented in detail in [Reyn92] and <ref> [Panc92] </ref>. The values computed are the minimum next event time and the minimum logical timestamp of messages that have been sent but not acknowledged. <p> The elimination of causality errors allows an LP to recognize when it can commit to processing an irreversible act such as I/O. Simulations [Srin92] show that messages can be acknowledged efficiently in a high-speed reduction network (as proposed by <ref> [Panc92] </ref>) in order to support the maintenance of a minimum outstanding message time. Message acknowledgements in a reduction network are supported by tagged selective reduction operations; in a selective reduction operation, such as minimum or 2 maximum, a tag accompanies the "winning" value of the binary operation. <p> We expect a potential throughput of 25 megabytes per second from host to auxiliary processor. Each AP has 256 Kbytes of RAM expandable up to 1Mbyte to store synchronization programs and related data structures (See [Reyn92], <ref> [Panc92] </ref>, and [Srin92].). <p> High speed synchronization activity in the parallel simulation framework is performed on the dedicated AP's. Host processors are responsible for executing events and sending/receiving event messages, and auxiliary processors are responsible for executing framework synchronization algorithms (See <ref> [Panc92] </ref> and [Srin92].). When an AP reads new globally reduced values from the network, it writes selected groups of these values into the HP-AP interface readable by the host processor.
Reference: [PfBG85] <author> Pfister, G. F., Brantley, W. C., George, D. A., Harvey, S. L., Kleinfelder, W. J., McAuliffe, K. P., Melton, E. A., Norton, V. A. and Weiss, J., </author> <title> "The IBM Research Parallel Prototype (RP3): Introduction and Architecture", </title> <booktitle> Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <address> St. Charles, </address> <publisher> Illinois, </publisher> <pages> pp. 764-771, </pages> <month> (August </month> <year> 1985). </year>
Reference-contexts: We note that an AP never sees a partial state vector. State vectors are either lost in their entirety or not at all. 5. Related Work Using a separate synchronization network for improving system performance is not a new idea. The IBM RP3 <ref> [PfBG85] </ref> was designed as a shared memory multiprocessor that houses both a combining network for synchronization traffic and a low latency network for regular message traffic. Our reduction network is not as complex or expensive as a combining network, yet it performs global synchronization operations very efficiently.
Reference: [ReMM88] <author> Reed, D. A., Malony, A. D. and McCredie, B. D., </author> <title> "Parallel Discrete Event Simulation Using Shared Memory", </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 14, No. 4, </volume> <pages> pp. 541-553, </pages> <month> (April </month> <year> 1988). </year>
Reference-contexts: Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], [Fuji88], <ref> [ReMM88] </ref>, and [FeKl92].). A hardware-based framework can be used to calculate and disseminate the smallest future time that an LP can send event messages. Each LP computes the value it submits to this reduction based on its current local clock and its minimum processing time.
Reference: [Reyn88] <author> Reynolds Jr., P. F., </author> <title> "A Spectrum of Options for Parallel Simulation", </title> <booktitle> Proceedings of the 1988 Winter Simulation Conference, </booktitle> <address> San Diego, California, </address> <pages> pp. 325-332, </pages> <month> (December </month> <year> 1988). </year>
Reference-contexts: The tag field for a message acknowledgement is a unique message ID. In an aggressive PDES synchronization protocol (See <ref> [Reyn88] </ref>.), such as Time Warp [Jeff85], GVT can be efficiently computed by an LP at any time using our framework; it is simply, by definition, the minimum of the two globally reduced values: minimum next event time and minimum outstanding message time. <p> It has been suggested that an adaptive protocol, one which is an intelligent combination of aggressive and nonaggressive protocols, may be more powerful than either in a pure form <ref> [LuWS91, Reyn88, Reyn92] </ref>. In the future we intend to report on the performance of the prototype PRN, which is a collaborative effort of the Computer Science and Electrical Engineering Departments at the University of Virginia to be completed in Summer 1992.
Reference: [Reyn91] <author> Reynolds Jr., P. F., </author> <title> "An Efficient Framework for Parallel Simulations", </title> <booktitle> Proceedings of the SCS Multiconference on Advances in Parallel and Distributed Simulation, </booktitle> <address> Anaheim, California, </address> <pages> pp. 167-174, </pages> <month> (January </month> <year> 1991). </year>
Reference-contexts: All operations, including 32-bit fixed-point arithmetic, can be performed in less than 40 nanoseconds. The importance of attaining our goals will become clearer in the remainder of this paper. In the sections that follow we present a brief overview of the framework first described in <ref> [Reyn91] </ref>. The ease and speed with which important synchronization values such as Time Warp's GVT can be computed will be made evident. Also, we present a set of correctness criteria for the hardware portion of the framework.
Reference: [Reyn92] <author> Reynolds Jr., P. F., </author> <title> "An Efficient Framework for Parallel Simulations", </title> <note> to appear in International Journal on Computer Simulation, </note> <year> (1992). </year>
Reference-contexts: Exceptions include Fujimoto's rollback chip [FuTG92] and virtual computer [Fuji89] efforts, Filoque's global virtual time (GVT) network [FiGP91] and our own framework <ref> [Reyn92] </ref>. Recent simulation results [Srin92] show beyond a doubt that specialized hardware such as the framework we describe here can yield significant benefits to parallel simulations. We describe the details of a hardware realization of the framework described in [Reyn92]. <p> Filoque's global virtual time (GVT) network [FiGP91] and our own framework <ref> [Reyn92] </ref>. Recent simulation results [Srin92] show beyond a doubt that specialized hardware such as the framework we describe here can yield significant benefits to parallel simulations. We describe the details of a hardware realization of the framework described in [Reyn92]. This description is based on a completed design of a four-node prototype expected to be operational Summer, 1992. This prototype is designed to interface with a Sparc Cluster a set of Sparc-1e engines connected through a VME backplane. The interface to the Sparcs is through the Sun SBus. <p> We expect a new global value to be emitted from the reduction network every 150 nanoseconds. One such set of globally reduced values and related synchronization algorithms have been presented in detail in <ref> [Reyn92] </ref> and [Panc92]. The values computed are the minimum next event time and the minimum logical timestamp of messages that have been sent but not acknowledged. <p> When the PRN computes multiple reductions representing a state of a simulation, it is crucial that each LP can access the globally reduced values atomically to guarantee that the values represent a consistent global state. In addition to atomicity, some synchronization algorithms <ref> [Reyn92] </ref> require that the order an LP changes values input to the network be preserved in global counterparts by the underlying hardware. <p> We expect a potential throughput of 25 megabytes per second from host to auxiliary processor. Each AP has 256 Kbytes of RAM expandable up to 1Mbyte to store synchronization programs and related data structures (See <ref> [Reyn92] </ref>, [Panc92], and [Srin92].). <p> It has been suggested that an adaptive protocol, one which is an intelligent combination of aggressive and nonaggressive protocols, may be more powerful than either in a pure form <ref> [LuWS91, Reyn88, Reyn92] </ref>. In the future we intend to report on the performance of the prototype PRN, which is a collaborative effort of the Computer Science and Electrical Engineering Departments at the University of Virginia to be completed in Summer 1992.
Reference: [RePa92] <author> Reynolds Jr., P. F. and Pancerella, C. M., </author> <title> "Hardware Support for Parallel Discrete Event Simulations", </title> <institution> Computer Science Report No. Technical Report-92-08, Department of Computer Science, University of Virginia, Charlottesville, Virginia, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Throughout this paper we use the term "framework" to refer to these three components. Sets of global values can be computed by performing reductions on input values across all processors. The high-speed framework hardware <ref> [RePa92] </ref> rapidly computes and disseminates these values; the framework hardware we propose consists of a parallel reduction network (PRN) augmented with dedicated processors to manage the high frequency I/O from the network and execute synchronization algorithms.
Reference: [Sama85] <author> Samadi, B., </author> <title> "Distributed Simulation, Algorithms, and Performance Analysis", </title> <type> PhD Thesis, </type> <institution> Computer Science Department, University of California, </institution> <address> Los Angeles, </address> <month> January </month> <year> 1985. </year>
Reference-contexts: GVT computation and dissemination in this hardware-based framework is a significant improvement in algorithm complexity and implementation efficiency over previously proposed GVT maintenance schemes ([Jeff85], [JeSo85], <ref> [Sama85] </ref>, [LiLa89], [Bell90], [CoKe91]). Researchers have shown that minimum event processing times and lookahead values can produce significant performance improvements in a non-aggressive PDES protocol (See [Fuji87], [Fuji88], [ReMM88], and [FeKl92].).
Reference: [SoBW88] <author> Sokol, L. M., Briscoe, D. P. and Wieland, A. P., "MTW: </author> <title> A Strategy for Scheduling Discrete Simulation Events for Concurrent Execution", </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <address> San Diego, California, </address> <pages> pp. 34-42, </pages> <month> (February </month> <year> 1988). </year>
Reference-contexts: We have a hardware-based framework for disseminating this information easily. Iterative PDES algorithms, such as Bounded Lag [Luba88], Moving Time Window <ref> [SoBW88] </ref>, and the aggressive Global Windowing Algorithm discussed in [DiRe92], require the rapid computation and dissemination of ceiling values or fault values.
Reference: [Srin92] <author> Srinivasan, S., </author> <title> "Modeling a Framework for Parallel Simulations", </title> <type> Master's Thesis, </type> <institution> School of Engineering and Applied Science, University of Virginia, Charlottesville, Virginia, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Exceptions include Fujimoto's rollback chip [FuTG92] and virtual computer [Fuji89] efforts, Filoque's global virtual time (GVT) network [FiGP91] and our own framework [Reyn92]. Recent simulation results <ref> [Srin92] </ref> show beyond a doubt that specialized hardware such as the framework we describe here can yield significant benefits to parallel simulations. We describe the details of a hardware realization of the framework described in [Reyn92]. <p> The elimination of causality errors allows an LP to recognize when it can commit to processing an irreversible act such as I/O. Simulations <ref> [Srin92] </ref> show that messages can be acknowledged efficiently in a high-speed reduction network (as proposed by [Panc92]) in order to support the maintenance of a minimum outstanding message time. <p> We expect a potential throughput of 25 megabytes per second from host to auxiliary processor. Each AP has 256 Kbytes of RAM expandable up to 1Mbyte to store synchronization programs and related data structures (See [Reyn92], [Panc92], and <ref> [Srin92] </ref>.). <p> High speed synchronization activity in the parallel simulation framework is performed on the dedicated AP's. Host processors are responsible for executing events and sending/receiving event messages, and auxiliary processors are responsible for executing framework synchronization algorithms (See [Panc92] and <ref> [Srin92] </ref>.). When an AP reads new globally reduced values from the network, it writes selected groups of these values into the HP-AP interface readable by the host processor. An LP, executing on a host processor, can compute GVT, avoid deadlocks, and make processing decisions based on the global synchronization values. <p> In the future we intend to report on the performance of the prototype PRN, which is a collaborative effort of the Computer Science and Electrical Engineering Departments at the University of Virginia to be completed in Summer 1992. Simulations <ref> [Srin92] </ref> have demonstrated the feasibility of this hardware; however, actual PDES implementations on the prototype will validate our performance predictions.
Reference: [Ston90] <author> Stone, H. S., </author> <title> High-Performance Computer Architecture, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The goals of both approaches are similar, but our framework is more efficient, more flexible, and more scalable. Several researchers have proposed the use of hardware to implement barrier synchronization. Hoshino [Hosh85] has an efficient barrier synchronization in the PAX computer. Stone <ref> [Ston90] </ref> suggests the use of global busses to compute maximum values and to implement fetch-and-increment. The hardware that we propose, on the other hand, provides support for a larger class of algorithms than barrier synchronization algorithms. Many parallel architectures provide for global binary, associative operations across all processors.
Reference: [SBus90] <institution> Sun Microsystems, SBus Specification B.0, Sun Microsystems, Inc., Mountain View, California, </institution> <year> 1990. </year> <month> 17 </month>
Reference-contexts: The prototype interface between a host, a Sparc-1e, and the 32-bit general purpose auxiliary processor, a 25 MHz Motorola 68020, is a dual-ported RAM connecting the Sun SBus and the auxiliary processor. The SBus has a bandwidth of about 100 megabytes per second for 32-bit words <ref> [SBus90] </ref>. We expect a potential throughput of 25 megabytes per second from host to auxiliary processor. Each AP has 256 Kbytes of RAM expandable up to 1Mbyte to store synchronization programs and related data structures (See [Reyn92], [Panc92], and [Srin92].).
Reference: [Thin92] <institution> Thinking Machines Corporation, The Connection Machine CM-5 Technical Summary , Thinking Machines Corporation, Cambridge, Massachusetts, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Many parallel architectures provide for global binary, associative operations across all processors. Global operations on the Intel iPSC/2 [Inte89] are provided for arithmetic and logical operations. The Thinking Machines CM-5 <ref> [Thin92] </ref> contains two separate networks for different types of communication and synchronization: the data network is the primary message-passing network in the machine and the control network provides hardware support for common cooperative operations.
References-found: 34

