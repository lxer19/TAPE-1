URL: ftp://ftp.cs.washington.edu/tr/1993/06/UW-CSE-93-06-04.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Utility Models for Goal-Directed Decision-Theoretic Planners  
Author: Peter Haddawy Steve Hanks 
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Technical Report 93-06-04 June 15, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [ Anderson and Farley, 1988 ] <author> J. Anderson and A. Farley. </author> <title> Plan abstraction based on operator generalization. </title> <booktitle> In Proceedings AAAI, </booktitle> <pages> pages 100-104, </pages> <year> 1988. </year>
Reference-contexts: He contrasts this to the type of abstraction used in ABSTRIPS [ Sacerdoti, 1974 ] , which Tenenberg calls relaxed model abstraction. For examples of the use of inheritance abstraction in plan generation in a deterministic setting see <ref> [ Nau, 1987, Anderson and Farley, 1988 ] </ref> . The present work generalizes the notion of inheritance abstraction by introducing time, probability, and utility into the representation. We illustrate the planning technique with an example. Consider the following problem of planning a delivery task.
Reference: [ Bellman and Zadeh, 1980 ] <author> R.E. Bellman and L.A. Zadeh. </author> <title> Decision-making in a Fuzzy Environment. </title> <booktitle> Management Science, </booktitle> <address> 17:B141-B164, </address> <year> 1980. </year>
Reference-contexts: In particular our notion of a degree of satisfaction function bears close resemblance to a fuzzy-set membership function. The seminal paper in this area is <ref> [ Bellman and Zadeh, 1980 ] </ref> ; also see the papers in [ Zimmerman et al., 1984 ] , of which the most relevant to this paper is [ Dubois and Prade, 1984 ] . They discuss the role of aggregation operators in the decision-making process.
Reference: [ Boddy, 1991 ] <author> Mark Boddy. </author> <title> Solving Time-Dependent Problems: A Decision-Theoretic Ap-proachPlanning in Dynamic Environments. </title> <type> Technical Report CS-91-06, </type> <institution> Brown University, Department of Computer Science, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: to the planning problem [ Koenig, 1992 ] , [ Feldman and Sproull, 1975 ] , [ Dean and Kanazawa, 1989 ] and to the problem of controlling reasoning|choosing among computational actions as well as those that make physical changes to the world [ Russell and Wefald, 1991a ] , <ref> [ Boddy, 1991 ] </ref> , [ Etzioni, 1991 ] , [ Horvitz et al., 1989 ] .
Reference: [ Charniak and McDermott, 1985 ] <author> E. Charniak and D. McDermott. </author> <title> Introduction to Artificial Intelligence. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1985. </year>
Reference-contexts: This combination of options results in the last four action descriptions in the Figure 6. In order to perform the refinement type planning described, we organize the planning knowledge in an abstraction/decomposition network, shown in Figure 8. Solid links show decompositions <ref> [ Charniak and McDermott, 1985, Ch9 ] </ref> , while dashed links show possible refinements. For example the task "deliver tomatoes" is decomposed into the sequence of the two actions "go to farm" and "load & drive truck". The arrow between the actions signifies temporal succession.
Reference: [ Dean and Kanazawa, 1989 ] <author> Tom Dean and Keiji Kanazawa. </author> <title> A Model for Projection and Action. </title> <booktitle> In Proceedings IJCAI, </booktitle> <pages> pages 985-990, </pages> <year> 1989. </year>
Reference-contexts: None of these efforts incorporate uncertainty or partial satisfaction into the representation, nor do they consider partial satisfaction of the goal's atemporal component. 8.1.2 Decision-theoretic planning and control Decision-theoretic techniques have been applied both to the planning problem [ Koenig, 1992 ] , [ Feldman and Sproull, 1975 ] , <ref> [ Dean and Kanazawa, 1989 ] </ref> and to the problem of controlling reasoning|choosing among computational actions as well as those that make physical changes to the world [ Russell and Wefald, 1991a ] , [ Boddy, 1991 ] , [ Etzioni, 1991 ] , [ Horvitz et al., 1989 ] .
Reference: [ Dean et al., 1988 ] <author> T. Dean, J. Firby, and D. Miller. </author> <title> Hierarchical Planning involving deadlines, travel times, and resources. </title> <journal> Computational Intelligence, </journal> <volume> 4(4) </volume> <pages> 381-398, </pages> <year> 1988. </year>
Reference-contexts: goal expressions: [ Drummond, 1989 ] introduces a crudeform of maintenance goals, allowing the constraint that a proposition remain true throughout the execution of a plan. [ Vere, 1983 ] implements a concept related to deadline goals: a temporal window or interval within which an action must be executed, and <ref> [ Dean et al., 1988 ] </ref> handles deadlines and actions with duration.
Reference: [ Drummond, 1989 ] <author> M. Drummond. </author> <title> Situated Control Rules. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Representation and Reasoning, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: Our work is mainly oriented toward using the resulting structure to build and exploit representations for concepts like partial satisfaction and temporal deadlines in the process of building and comparing plans. 42 A few efforts have been made in the classical planning literature to extend the form of goal expressions: <ref> [ Drummond, 1989 ] </ref> introduces a crudeform of maintenance goals, allowing the constraint that a proposition remain true throughout the execution of a plan. [ Vere, 1983 ] implements a concept related to deadline goals: a temporal window or interval within which an action must be executed, and [ Dean et
Reference: [ Dubois and Prade, 1984 ] <author> Didier Dubois and Henri Prade. </author> <title> Criteria Aggregation and Ranking of Alternatives in the Framework of Fuzzy Set Theory. In H.J Zimmerman, L.A. </title> <editor> Zadeh, and B.R Gaines, editors, </editor> <booktitle> Fuzzy Sets and Decision Analysis, </booktitle> <pages> pages 209-240. </pages> <publisher> North Holland, </publisher> <year> 1984. </year>
Reference-contexts: The seminal paper in this area is [ Bellman and Zadeh, 1980 ] ; also see the papers in [ Zimmerman et al., 1984 ] , of which the most relevant to this paper is <ref> [ Dubois and Prade, 1984 ] </ref> . They discuss the role of aggregation operators in the decision-making process.
Reference: [ Etzioni, 1991 ] <author> Oren Etzioni. </author> <title> Embedding Decision-analytic Control in a Learning Architecture. </title> <journal> Artificial Intelligence, </journal> <volume> 1-3(49):129-160, </volume> <year> 1991. </year> <month> 45 </month>
Reference-contexts: Koenig, 1992 ] , [ Feldman and Sproull, 1975 ] , [ Dean and Kanazawa, 1989 ] and to the problem of controlling reasoning|choosing among computational actions as well as those that make physical changes to the world [ Russell and Wefald, 1991a ] , [ Boddy, 1991 ] , <ref> [ Etzioni, 1991 ] </ref> , [ Horvitz et al., 1989 ] . Most of these works use some variant of the utility model common to Markov decision processes [ Howard, 1960 ] : there is a reward function associated with certain states and a cost function associated with actions.
Reference: [ Feldman and Sproull, 1975 ] <editor> J.R. Feldman and R.F. Sproull. </editor> <booktitle> Decision Theory and Artificial Intelligence II: The Hungry Monkey. Cognitive Science, </booktitle> <volume> 1 </volume> <pages> 158-192, </pages> <year> 1975. </year>
Reference-contexts: None of these efforts incorporate uncertainty or partial satisfaction into the representation, nor do they consider partial satisfaction of the goal's atemporal component. 8.1.2 Decision-theoretic planning and control Decision-theoretic techniques have been applied both to the planning problem [ Koenig, 1992 ] , <ref> [ Feldman and Sproull, 1975 ] </ref> , [ Dean and Kanazawa, 1989 ] and to the problem of controlling reasoning|choosing among computational actions as well as those that make physical changes to the world [ Russell and Wefald, 1991a ] , [ Boddy, 1991 ] , [ Etzioni, 1991 ] ,
Reference: [ Firby, 1989 ] <author> R. James Firby. </author> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> Technical Report 672, </type> <institution> Yale University, Department of Computer Science, </institution> <month> January </month> <year> 1989. </year>
Reference: [ Haddawy and Hanks, 1990 ] <author> Peter Haddawy and Steve Hanks. </author> <title> Issues in Decision-Theoretic Planning: Symbolic Goals and Numeric Utilities. In DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control. </title> <publisher> Morgan Kaufmann, </publisher> <month> November </month> <year> 1990. </year>
Reference-contexts: G and G designate the set of all chronicles in which the goal holds and does not hold, respectively. Previous work, <ref> [ Haddawy and Hanks, 1990 ] </ref> , demonstrates the correspondence between these two policies, showing that the simple class of step functions pictured in Figure 2 is the only class of utility functions for which P (GjP 1 ) &gt; P (GjP 2 ) ) EU (P 1 ) &gt; EU <p> In other words, describing the desired state of the world in terms of a goal conjunction restricts a problem-solver's preference structure to those that can be characterized by a simple step function. ( <ref> [ Haddawy and Hanks, 1990 ] </ref> explores the relationship between goal satisfaction and probability maximization for other situations, e.g. cases in which goal expressions are combined with some preference information about resource consumption.) The analysis points out four obvious limitations to the endeavor of planning to achieve a goal conjunction: 1.
Reference: [ Haddawy, 1991a ] <author> P. Haddawy. </author> <title> A Temporal Probability Logic for Representing Actions. </title> <editor> In Richard Fikes James Allen and Erik Sandewall, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <pages> pages 196-207. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: The logic of time, chance, and action L tca is well suited to our purposes. A simplified version of the logic is described in <ref> [ Haddawy, 1991a ] </ref> and the full logic is described in [ Haddawy, 1991b ] . We describe here just that portion of the language relevant to this paper. We will use the single predicate HOLDS to associate facts with temporal intervals.
Reference: [ Haddawy, 1991b ] <author> P. Haddawy. </author> <title> Representing Plans Under Uncertainty: A Logic of Time, Chance, and Action. </title> <type> PhD thesis, </type> <institution> University of Illinois, </institution> <year> 1991. </year> <note> (Report no. UIUCDCS-R-91-1719). </note>
Reference-contexts: Decision-theoretic problems, on the other hand, are stated in terms of * a probability distribution over possible outcomes, and * preferences over those outcomes. 1 The relationship between the probabilistic model of the world and the operators and initial state has been studied as a problem of probabilistic temporal inference, <ref> [ Haddawy, 1991b ] </ref> , [ Hanks and McDermott, 1993 ] , [ Hanks, 1993 ] . <p> in the classical paradigm is the probability that the goal conjunction will hold when the plan finishes executing: P (P succeeds) P (GjP) X c:HOLDS (G;end (c);end (c)) P (cjP) (1) 1 [ McDermott, 1982 ] defines chronicles in terms of a temporal logic, and [ Hanks, 1990 ] and <ref> [ Haddawy, 1991b ] </ref> extend the notion to a probabilistic framework. 4 and the planner will try to find the plan maximizing that value. <p> The logic of time, chance, and action L tca is well suited to our purposes. A simplified version of the logic is described in [ Haddawy, 1991a ] and the full logic is described in <ref> [ Haddawy, 1991b ] </ref> . We describe here just that portion of the language relevant to this paper. We will use the single predicate HOLDS to associate facts with temporal intervals.
Reference: [ Hanks and Firby, 1990 ] <author> Steve Hanks and R. James Firby. </author> <title> Issues and Architectures for Planning and Execution. In DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control. </title> <publisher> Morgan Kaufmann, </publisher> <month> November </month> <year> 1990. </year>
Reference-contexts: Although it is probably unrealistic to expect any planner to employ only refinement operators, the idea of modeling an execution system using a hierarchy of abstract actions is consistent with Firby's [ 1989 ] RAP system, and the architecture for planning and execution proposed in <ref> [ Hanks and Firby, 1990 ] </ref> . 8 Summary and Related Work Our goal in this work was to take the concept of goals as they have been used in symbolic planning systems and simultaneously extend their functionality and recast the intuitions in a form that can be exploited by a
Reference: [ Hanks and McDermott, 1993 ] <author> Steve Hanks and Drew McDermott. </author> <title> Modeling a Dynamic and Uncertain World I: Symbolic and Probabilistic Reasoning about Change. </title> <journal> Artificial Intelligence, </journal> <note> 1993. To appear. </note>
Reference-contexts: hand, are stated in terms of * a probability distribution over possible outcomes, and * preferences over those outcomes. 1 The relationship between the probabilistic model of the world and the operators and initial state has been studied as a problem of probabilistic temporal inference, [ Haddawy, 1991b ] , <ref> [ Hanks and McDermott, 1993 ] </ref> , [ Hanks, 1993 ] .
Reference: [ Hanks, 1990 ] <author> Steven Hanks. </author> <title> Projecting Plans for Uncertain Worlds. </title> <type> Technical Report 756, </type> <institution> Yale University, Department of Computer Science, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: The probability of success in the classical paradigm is the probability that the goal conjunction will hold when the plan finishes executing: P (P succeeds) P (GjP) X c:HOLDS (G;end (c);end (c)) P (cjP) (1) 1 [ McDermott, 1982 ] defines chronicles in terms of a temporal logic, and <ref> [ Hanks, 1990 ] </ref> and [ Haddawy, 1991b ] extend the notion to a probabilistic framework. 4 and the planner will try to find the plan maximizing that value. <p> Planning is the process of generating this plan as well as choosing among the various ways this plan can be realized in such a way that expected utility is maximized. The descriptions of the available actions are shown in Figure 6. The action descriptions are similar to those in <ref> [ Hanks, 1990 ] </ref> . Actions have conditional effects, and are represented by a tree with conditions labeling the branches. The leaves of the tree are labeled with the outcomes of the action. Deterministic actions are labeled with a single outcome.
Reference: [ Hanks, 1993 ] <author> Steven Hanks. </author> <title> Modelling a Dynamic and Uncertain World II: Action Representation and Plan Evaluation. </title> <journal> Journal of Logic and Computation, </journal> <note> 1993. Submitted. </note>
Reference-contexts: a probability distribution over possible outcomes, and * preferences over those outcomes. 1 The relationship between the probabilistic model of the world and the operators and initial state has been studied as a problem of probabilistic temporal inference, [ Haddawy, 1991b ] , [ Hanks and McDermott, 1993 ] , <ref> [ Hanks, 1993 ] </ref> . <p> We continue until we have incorporated all the conjuncts, at which point we can compute the expected utility of any remaining plans. This ability to consider the conjuncts sequentially has important consequences for the projection process. <ref> [ Hanks, 1993 ] </ref> presents a probabilistic projection algorithm demonstrating that: * it can be much cheaper to project a plan with respect to a single proposition (like one of our goal conjuncts) than it is to reason about all of the plan's effects, * it can be much cheaper to <p> The algorithm in <ref> [ Hanks, 1993 ] </ref> exploits both the symbolic content of the relationship and the numeric threshold to limit inference in establishing whether or not this relationship holds.
Reference: [ Horvitz et al., 1989 ] <author> Eric J. Horvitz, Gregory F. Cooper, and David E. Heckerman. </author> <title> Reflection and Action Under Scarce Resources: Theoretical Principles and Empirical Study. </title> <booktitle> In Proceedings IJCAI, </booktitle> <pages> pages 1121-1127, </pages> <year> 1989. </year>
Reference-contexts: Feldman and Sproull, 1975 ] , [ Dean and Kanazawa, 1989 ] and to the problem of controlling reasoning|choosing among computational actions as well as those that make physical changes to the world [ Russell and Wefald, 1991a ] , [ Boddy, 1991 ] , [ Etzioni, 1991 ] , <ref> [ Horvitz et al., 1989 ] </ref> . Most of these works use some variant of the utility model common to Markov decision processes [ Howard, 1960 ] : there is a reward function associated with certain states and a cost function associated with actions.
Reference: [ Howard, 1960 ] <author> Ronald A. Howard. </author> <title> Dynamic Programming and Markov Processes. </title> <publisher> MIT Press, </publisher> <year> 1960. </year>
Reference-contexts: Most of these works use some variant of the utility model common to Markov decision processes <ref> [ Howard, 1960 ] </ref> : there is a reward function associated with certain states and a cost function associated with actions. The value of a plan is the value associated with the end state less the cost of the actions (e.g. the time they consume) that comprise the plan.
Reference: [ Keeney and Raiffa, 1976 ] <author> Ralph L. Keeney and Howard Raiffa. </author> <title> Decisions with Multiple Objectives: Preferences and Value Tradeoffs. </title> <publisher> John Wiley & Sons, </publisher> <year> 1976. </year>
Reference-contexts: We return to these tradeoffs in Section 7. Equation (5) also implies that the agent's preferences over the component goals are additive independent: preferences over lotteries on the goals depend only on the marginal probability distributions for the goals and not on their joint probability distribution <ref> [ Keeney and Raiffa, 1976, Sect 6.2 ] </ref> . In other words we assume that preference for a particular level of satisfaction for one goal does not depend on the extent to which the other goals are satisfied. <p> The amount of utility accrued for a change is the increase in atemporal utility over the previous maximum, weighted by the CT function that discounts the change according to how well it satisfies the deadline. The basic form of this utility function is similar to that presented by Meyer <ref> [ Keeney and Raiffa, 1976, Sect. 9.3.2 ] </ref> for the utility of a consumption stream. The only difference is that Meyer's formulation defines utility directly in terms of consumption|which is the change in the agent's wealth|while our DSA functions specify this change in utility indirectly. <p> Finally we demonstrated how these relationships could be exploited by two existing planning techniques, particularly in the area of refinement planning. 8.1 Related work A discussion of related work should begin with a mention of multiattribute decision theory, especially <ref> [ Keeney and Raiffa, 1976 ] </ref> . What we have done is built a multiattribute utility model for goal-oriented planning problems that feature partial goal satisfaction and deadlines.
Reference: [ Koenig, 1992 ] <author> Sven Koenig. </author> <title> Optimal Probabilistic and Decision-Theoretic Planning using Markovian Decision Theory. </title> <type> Technical Report UCB/CSD 92/685, </type> <institution> Computer Science Division (EECS), UC Berkeley, </institution> <month> May </month> <year> 1992. </year> <month> 46 </month>
Reference-contexts: None of these efforts incorporate uncertainty or partial satisfaction into the representation, nor do they consider partial satisfaction of the goal's atemporal component. 8.1.2 Decision-theoretic planning and control Decision-theoretic techniques have been applied both to the planning problem <ref> [ Koenig, 1992 ] </ref> , [ Feldman and Sproull, 1975 ] , [ Dean and Kanazawa, 1989 ] and to the problem of controlling reasoning|choosing among computational actions as well as those that make physical changes to the world [ Russell and Wefald, 1991a ] , [ Boddy, 1991 ] ,
Reference: [ Kushmerick et al., 1993 ] <author> Nick Kushmerick, Steve Hanks, and Dan Weld. </author> <title> An Algorithm for Probabilistic Planning. </title> <journal> Artificial Intelligence, </journal> <note> 1993. Submitted. </note>
Reference-contexts: What can we say about the relationship between two partial plans? The next two sections discuss how our model might be applied to two plan-generation paradigms: partial-order planning and refinement planning. 7.1.1 Partial-order planning and search control The buridan planner <ref> [ Kushmerick et al., 1993 ] </ref> is an extension to classical nonlinear planners that allows uncertainty in the initial world state and in the effects of operators.
Reference: [ McDermott, 1982 ] <author> Drew McDermott. </author> <title> A Temporal Logic for Reasoning About Processes and Plans. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 101-155, </pages> <year> 1982. </year>
Reference-contexts: The probability of success in the classical paradigm is the probability that the goal conjunction will hold when the plan finishes executing: P (P succeeds) P (GjP) X c:HOLDS (G;end (c);end (c)) P (cjP) (1) 1 <ref> [ McDermott, 1982 ] </ref> defines chronicles in terms of a temporal logic, and [ Hanks, 1990 ] and [ Haddawy, 1991b ] extend the notion to a probabilistic framework. 4 and the planner will try to find the plan maximizing that value.
Reference: [ Nau, 1987 ] <author> D. Nau. </author> <title> Hierarchical abstraction for process planning. </title> <booktitle> In Proc. of the Int's Conference on Applications of Artificial Intelligence in Engineering, </booktitle> <year> 1987. </year>
Reference-contexts: He contrasts this to the type of abstraction used in ABSTRIPS [ Sacerdoti, 1974 ] , which Tenenberg calls relaxed model abstraction. For examples of the use of inheritance abstraction in plan generation in a deterministic setting see <ref> [ Nau, 1987, Anderson and Farley, 1988 ] </ref> . The present work generalizes the notion of inheritance abstraction by introducing time, probability, and utility into the representation. We illustrate the planning technique with an example. Consider the following problem of planning a delivery task.
Reference: [ Russell and Wefald, 1991a ] <author> Stuart J. Russell and Eric H. Wefald. </author> <title> Do the Right Thing: Studies in Limited Rationality. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: control Decision-theoretic techniques have been applied both to the planning problem [ Koenig, 1992 ] , [ Feldman and Sproull, 1975 ] , [ Dean and Kanazawa, 1989 ] and to the problem of controlling reasoning|choosing among computational actions as well as those that make physical changes to the world <ref> [ Russell and Wefald, 1991a ] </ref> , [ Boddy, 1991 ] , [ Etzioni, 1991 ] , [ Horvitz et al., 1989 ] .
Reference: [ Russell and Wefald, 1991b ] <author> Stuart J. Russell and Eric H. </author> <title> Wefald. </title> <booktitle> Principles of Metarea-soning. Artificial Intelligence, </booktitle> <address> 1-3(49):361-396, </address> <year> 1991. </year>
Reference-contexts: The open truck is easy to load, while the closed truck can be loaded easily if a special quick-loading device is available. There is 4 Or when the intervals narrow to the point where the distinction between the two does not warrant further attention, as <ref> [ Russell and Wefald, 1991b ] </ref> point out. 32 33 34 an 80% chance this device will be available. The next two diagrams in the Figure 6 depict these two actions. Once the truck is loaded we must drive it to the warehouse.
Reference: [ Sacerdoti, 1974 ] <author> E.D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: The type of abstraction we use has been formalized by Tenenberg [ 1991 ] within the framework of the STRIPS representation and termed inheritance abstraction. He contrasts this to the type of abstraction used in ABSTRIPS <ref> [ Sacerdoti, 1974 ] </ref> , which Tenenberg calls relaxed model abstraction. For examples of the use of inheritance abstraction in plan generation in a deterministic setting see [ Nau, 1987, Anderson and Farley, 1988 ] .
Reference: [ Schniederjans, 1984 ] <author> Marc J. Schniederjans. </author> <title> Linear Goal Programming. </title> <publisher> Petrocelli Books, </publisher> <year> 1984. </year>
Reference-contexts: What we have done is built a multiattribute utility model for goal-oriented planning problems that feature partial goal satisfaction and deadlines. Our discussion of strictly ordered goals was motivated by the work in goal programming <ref> [ Schniederjans, 1984 ] </ref> a mathematical optimization technique that deals with ordered conflicting goals. 8.1.1 Goals and utility models In the AI literature the work closest to our own is by Wellman and Doyle [ 1991 ] , [ Wellman and Doyle, 1992 ] , which also analyzes the relationship between
Reference: [ Tenenberg, 1991 ] <author> J.D. Tenenberg. </author> <title> Reasoning About Plans, </title> <booktitle> chapter Abstraction in Planning, </booktitle> <pages> pages 213-283. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference: [ Vere, 1983 ] <author> S. Vere. </author> <title> Planning in Time: Windows and Durations for Activities and Goals. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 5, </volume> <year> 1983. </year>
Reference-contexts: the process of building and comparing plans. 42 A few efforts have been made in the classical planning literature to extend the form of goal expressions: [ Drummond, 1989 ] introduces a crudeform of maintenance goals, allowing the constraint that a proposition remain true throughout the execution of a plan. <ref> [ Vere, 1983 ] </ref> implements a concept related to deadline goals: a temporal window or interval within which an action must be executed, and [ Dean et al., 1988 ] handles deadlines and actions with duration.
Reference: [ Wellman and Doyle, 1991 ] <author> Michael P. Wellman and Jon Doyle. </author> <title> Preferential Semantics for Goals. </title> <booktitle> In Proceedings AAAI, </booktitle> <year> 1991. </year>
Reference-contexts: We begin by defining a goal-oriented agent in terms of its top-level utility function: Definition 1 A goal-directed agent is a decision maker whose preferences correspond to the following utility function: U (c) = n 2 See <ref> [ Wellman and Doyle, 1991 ] </ref> for a more general interpretation of this criterion. 7 The utility function is defined in terms of n subutility functions UG i associated with the agent's n explicit goals.
Reference: [ Wellman and Doyle, 1992 ] <author> Michael P. Wellman and Jon Doyle. </author> <title> Modular Utility Representation for Decision-Theoretic Planning. </title> <booktitle> In Proceedings, First International Conference on AI Planning Systems, </booktitle> <year> 1992. </year>
Reference-contexts: of strictly ordered goals was motivated by the work in goal programming [ Schniederjans, 1984 ] a mathematical optimization technique that deals with ordered conflicting goals. 8.1.1 Goals and utility models In the AI literature the work closest to our own is by Wellman and Doyle [ 1991 ] , <ref> [ Wellman and Doyle, 1992 ] </ref> , which also analyzes the relationship between goals and preference structures. Their work confronts the question of what it means to say that an agent has some goal.
Reference: [ Zimmerman et al., 1984 ] <author> H.J Zimmerman, L.A. Zadeh, and B.R Gaines, </author> <title> editors. Fuzzy Sets and Decision Analysis. </title> <publisher> North Holland, </publisher> <year> 1984. </year> <booktitle> TIMS Studies in the Management Sciences, </booktitle> <volume> Volume 20. </volume> <pages> 47 </pages>
Reference-contexts: In particular our notion of a degree of satisfaction function bears close resemblance to a fuzzy-set membership function. The seminal paper in this area is [ Bellman and Zadeh, 1980 ] ; also see the papers in <ref> [ Zimmerman et al., 1984 ] </ref> , of which the most relevant to this paper is [ Dubois and Prade, 1984 ] . They discuss the role of aggregation operators in the decision-making process.
References-found: 34

