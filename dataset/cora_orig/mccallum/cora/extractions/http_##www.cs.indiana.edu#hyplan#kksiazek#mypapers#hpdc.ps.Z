URL: http://www.cs.indiana.edu/hyplan/kksiazek/mypapers/hpdc.ps.Z
Refering-URL: http://www.cs.indiana.edu/hyplan/kksiazek/pardis.html
Root-URL: http://www.cs.indiana.edu
Email: g@cs.indiana.edu  
Title: PARDIS: A Parallel Approach to CORBA broker to interact directly with the distributed resources of
Author: Katarzyna Keahey and Dennis Gannon fkksiazek, gannon 
Note: SPMD objects allow the request  
Address: 215 Lindley Hall Bloomington, IN 47405  
Affiliation: Department of Computer Science Indiana University  
Abstract: This paper describes PARDIS, a system containing explicit support for interoperability of PARallel DIStributed applications. PARDIS is based on the Common Object Request Broker Architecture (CORBA) [15]. Like CORBA, it provides interoperability between heterogeneous components by specifying their interfaces in a meta-language, the CORBA IDL, which can be translated into the language of interacting components. However, PARDIS extends the CORBA object model by introducing SPMD objects representing data-parallel computations. In this paper we will give a brief description of basic component interaction in PARDIS and give an account of the rationale and support for SPMD objects and distributed sequences. We will then describe two ways of implementing argument transfer in invocations on SPMD objects and evaluate and compare their performance. fl Copyright 1997 IEEE. Published in the Proceedings of IEEE 6th International Symposium on High Performance Distributed Computing, August 5-8, 1997, Portland, OR. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE. This work was supported by DARPA through Army contract DABT63-94-C-0029 ARPA 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Atlas, S. Banerjee, J. Cummings, P. J. Hinker, M. Srikant, J. V. W. Reynders, and M. Tholburn. POOMA: </author> <title> A High Performance Distributed Simulation Environment for Scientific Applications. </title> <booktitle> In Supercomputing '95 Proceedings, </booktitle> <month> Decem-ber </month> <year> 1995. </year>
Reference-contexts: For a truly seamless integration, the sequence will map directly to constructs present in the programmer's package (such as for example distributed vector in HPC++ PSTL [3]). We are currently working on formulating direct mappings for the HPC++ PSTL and POOMA <ref> [1] </ref> libraries. 2.3 General Design Components of PARDIS PARDIS is a distributed software system consisting of an IDL compiler, communication libraries, object repository databases and facilities responsible for locating and activating objects. The relationship between these components is depicted in figure 1.
Reference: [2] <author> P. Beckman and D. Gannon. Tulip: </author> <title> A Portable Run-Time System for Object-Parallel Systems. </title> <booktitle> In Proceedings of the 10th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: To date only one run-time system interface has been specified; it encompasses the functionality of message-passing libraries and has been tested using applications based on MPI [7] and the Tulip <ref> [2] </ref> run-time system. In the future PARDIS will provide an alternative run-time system interface capturing the functionality of the more flexible one-sided run-time systems. 3. Two Methods of Distributed Argument Transfer Experimental Performance We have investigated two methods of implementing transfer of distributed arguments in invocations made on SPMD object.
Reference: [3] <author> P. Beckman, D. Gannon, and E. Johnson. </author> <title> Portable Parallel Programming in HPC++. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <year> 1996. </year>
Reference-contexts: We will discuss distributed sequences in detail in the next section. Based on this specification, the IDL compiler will generate stubs translating the definitions above into the language of package (for example HPC++ <ref> [3] </ref>), in which the client 2 and server are implemented. The stub code contains calls to communication libraries provided by PARDIS. Linked to the object's implementation, it allows the request broker to invoke methods on the object; the client can use it to invoke methods on remote objects. <p> For a truly seamless integration, the sequence will map directly to constructs present in the programmer's package (such as for example distributed vector in HPC++ PSTL <ref> [3] </ref>). We are currently working on formulating direct mappings for the HPC++ PSTL and POOMA [1] libraries. 2.3 General Design Components of PARDIS PARDIS is a distributed software system consisting of an IDL compiler, communication libraries, object repository databases and facilities responsible for locating and activating objects.
Reference: [4] <author> H. Casanova and J. Dongarra. NetSolve: </author> <title> A Network Server for Solving Computational Science Problems. </title> <booktitle> In Supercomputing '96 Proceedings, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: Large-scale metacomputing environments such as Legion [11], Globus [9] or WWVM [6] focus on providing interoperability of many diverse components. They address problems of scheduling, I/O systems, component compilation and resource management. NetSolve <ref> [4] </ref> provides interfaces to standard scientific tools such as Matlab and allows client-server interaction between computing units. It also attempts to load-balance its applications.
Reference: [5] <author> T. DeFanti, I. Foster, M. Papka, R. Stevens, and T. Kuh-fuss. </author> <title> Overview of the I-Way: Wide-Area Visual Supercomputing. The International Journal of Supercomputer Applications and High Performance Computing, </title> <address> 10(2):123131, </address> <year> 1997. </year>
Reference-contexts: These applications make use of the combined computational power of several resources to increase their performance, and exploit the heterogeneity of diverse architectures and software systems by assigning selected tasks to platforms which can best support them. Experiences of the I-WAY <ref> [5] </ref> networking experiment demonstrated that this way of approaching high-performance computing has enormous potential for solving important scientific problems [?].
Reference: [6] <author> K. Dincer and G. C. Fox. </author> <title> Building a World-Wide Virtual Machine Based on Web and HPCC Technologies. </title> <booktitle> In Supercomputing '96 Proceedings, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: As a consequence, the programmer does not need to rewrite the application code and can reuse already existing components in building meta-applications. Large-scale metacomputing environments such as Legion [11], Globus [9] or WWVM <ref> [6] </ref> focus on providing interoperability of many diverse components. They address problems of scheduling, I/O systems, component compilation and resource management. NetSolve [4] provides interfaces to standard scientific tools such as Matlab and allows client-server interaction between computing units. It also attempts to load-balance its applications.
Reference: [7] <author> M. P. I. Forum. </author> <title> MPI:A Message-Passing Interface Standard. </title> <month> June </month> <year> 1995. </year>
Reference-contexts: A generic run-time system interface has therefore been built into PARDIS libraries and may also be used by the compiler-generated stubs. To date only one run-time system interface has been specified; it encompasses the functionality of message-passing libraries and has been tested using applications based on MPI <ref> [7] </ref> and the Tulip [2] run-time system. In the future PARDIS will provide an alternative run-time system interface capturing the functionality of the more flexible one-sided run-time systems. 3. <p> During the experiments, the machines as well as the link were dedicated. Both the client and the server were relying on the MPICH [12] (v 1.0.12, compiled to use shared memory) implementation of MPI <ref> [7] </ref> for their internal communication. Although the hardware we used supports shared memory, our experiments were based on a distributed memory model.
Reference: [8] <author> I. Foster, J. Geisler, C. Kesselman, and S. Tuecke. </author> <title> Mul-timethod Communication for High-Performance Metacom-puting Applications. </title> <booktitle> In Supercomputing '96 Proceedings, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: Related Work Many researchers have investigated the design and efficiency of tools and environments allowing the programmer to build distributed high-performance systems. This research primarily centers on two areas: multimethod run-time systems and metacomputing environments. Multimethod run-time systems, such as Nexus <ref> [8] </ref> and Horus [17], integrate diverse transport mechanisms and protocols under one interface.
Reference: [9] <author> I. Foster and C. Kesselman. Globus: </author> <title> A metacomputing infrastructure toolkit. to appear in The International Journal of Supercomputer Applications and High Performance Computing, </title> <year> 1997. </year>
Reference-contexts: As a consequence, the programmer does not need to rewrite the application code and can reuse already existing components in building meta-applications. Large-scale metacomputing environments such as Legion [11], Globus <ref> [9] </ref> or WWVM [6] focus on providing interoperability of many diverse components. They address problems of scheduling, I/O systems, component compilation and resource management. NetSolve [4] provides interfaces to standard scientific tools such as Matlab and allows client-server interaction between computing units. It also attempts to load-balance its applications.
Reference: [10] <author> I. Foster, C. Kesselman, R. Olson, and S. Tuecke. </author> <title> Nexus: An Interoperability Layer for Parallel and Distributed Computer Systems. </title> <note> Technical Memorandum ANL/MCS-TM-189, </note> <month> May </month> <year> 1994. </year>
Reference-contexts: The current version of PARDIS uses NexusLite to provide network transport; since we do not use the asynchronous features of Nexus, no threads additional to the implementation of client and server are spawned, and the sends and receives for large data sizes are in practice synchronous operations. Refer to <ref> [10] </ref> for details on Nexus implementation. In order to bring out the asymmetry of interaction (different number of interacting processes at client and server, and different hardware) in our invocations we were including one in argument sent only from the client to the server.
Reference: [11] <author> A. S. Grimshaw and W. A. Wulf. </author> <title> Legion A View From 50,000 Feet. </title> <booktitle> In Proceedings of the 5th IEEE International Symposium on High Performance Distributed Computaiton, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: As a consequence, the programmer does not need to rewrite the application code and can reuse already existing components in building meta-applications. Large-scale metacomputing environments such as Legion <ref> [11] </ref>, Globus [9] or WWVM [6] focus on providing interoperability of many diverse components. They address problems of scheduling, I/O systems, component compilation and resource management. NetSolve [4] provides interfaces to standard scientific tools such as Matlab and allows client-server interaction between computing units.
Reference: [12] <author> W. Gropp, E. Lusk, N. Doss, and A. Skjellum. </author> <title> A High Performance, Portable Implementation of the MPI Message Passing Interface Standard. </title> <type> Technical Report ANL/MCS-TM-213, </type> <institution> Argonne National Laboratory, </institution> <year> 1996. </year>
Reference-contexts: The network transfer is conducted over a 155 MB/s ATM link using the LAN Emulation protocol. During the experiments, the machines as well as the link were dedicated. Both the client and the server were relying on the MPICH <ref> [12] </ref> (v 1.0.12, compiled to use shared memory) implementation of MPI [7] for their internal communication. Although the hardware we used supports shared memory, our experiments were based on a distributed memory model.
Reference: [13] <author> K. Keahey. </author> <title> A Model of Interaction for Parallel Objects in a Heterogenous Distributed Environment. </title> <type> Technical Report IUCS TR 467, </type> <institution> Indiana University, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: PARDIS also allows the server to interrupt its computation in order to process outstanding requests; full discussion of these capabilities is beyond the scope of this paper, for details refer to <ref> [13] </ref>. Principles applied in this simple scenario can be used to construct more complex interactions composed of multiple parallel applications, as well as units visualizing or otherwise monitoring their progress (see [13] for an example). <p> process outstanding requests; full discussion of these capabilities is beyond the scope of this paper, for details refer to <ref> [13] </ref>. Principles applied in this simple scenario can be used to construct more complex interactions composed of multiple parallel applications, as well as units visualizing or otherwise monitoring their progress (see [13] for an example).
Reference: [14] <author> M. L. Norman, P. Beckman, G. L. Bryan, J. Dubinski, D. Gannon, L. Hernquist, K. Keahey, J. P. Ostriker, J. Shalf, J. Welling, and S. Yang. </author> <title> Galaxies Collide on the I-WAY: An Example of Heterogenous Wide-Area Collaborative Supercomputing. </title> <journal> The International Journal of Supercomputer Applications and High Performance Computing, </journal> <volume> 10(2):132 144, </volume> <year> 1997. </year>
Reference-contexts: In the case of both the client and the server the generated stub code contains all the code necessary to perform argument marshaling. As the example of the client's stub shows, PARDIS supports non-blocking invocations returning futures (similar to ABC++ futures <ref> [14] </ref>) as its out arguments. This allows the client to use remote resources concurrently with its own, and provides the programmer with an elegant way of representing results which are not yet available.
Reference: [15] <author> W. O'Farrell, F. C. Eigler, S. D. Pullara, and G. V. Wilson. </author> <title> Parallel Programming Using C++, chapter ABC++. </title> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Experiences of the I-WAY [5] networking experiment demonstrated that this way of approaching high-performance computing has enormous potential for solving important scientific problems [?]. At the same time another development in distributed object-oriented technology, the Common Object Request Broker Architecture (CORBA) <ref> [15] </ref> has made it possible to seamlessly integrate heterogeneous distributed objects within one system. CORBA provides interoperability between different components by specifying their interfaces in a meta-language, the CORBA Interface Definition Language (IDL), which is translated into the language of interacting components by a compiler. <p> This kind of interaction can be useful to parallel clients which want to interact in parallel with multiple distributed objects. On the server's side, PARDIS uses the CORBA C++ mapping through inheritance <ref> [15] </ref> to invoke operations on the object. All the programmer of the server needs to do, is provide the implementation of an object computing diffusion simulation, and instantiate that object. <p> Similarly, the local access operations can be used to convert a sequence to the programmers memory management scheme. An in argument on the client's side must set the length and distribution of a distributed sequence before it can be used. An out argument (represented as a managed type <ref> [15] </ref>) should be initialized by a distribution template before calling the operation which returns it; otherwise a uniform blockwise distribution will be assumed. The distribution of return values is always assumed to be blockwise.
Reference: [16] <author> OMG. </author> <title> The Common Object Request Broker: Architecture and Specification. Revision 2.0. OMG Document, </title> <month> June </month> <year> 1995. </year>
Reference-contexts: Far from attempting to incorporate all of their features, PARDIS could exist as one of the communication subsystems in the environments mentioned above. Active research is also being done on optimizing the performance of CORBA for high-speed networks. The TAO project <ref> [16] </ref> focuses on developing a high-performance, real-time ORB providing quality of service guarantees, optimizing the performance of network interfacing and ORB components. This research is concerned mainly with increasing performance by optimizing the architectural components of CORBA, not by introducing new concepts on the level of object model. 5.
Reference: [17] <author> D. Schmidt, A. Gokhale, T. Harrison, and G. </author> <month> Parulkar. </month>
Reference-contexts: Related Work Many researchers have investigated the design and efficiency of tools and environments allowing the programmer to build distributed high-performance systems. This research primarily centers on two areas: multimethod run-time systems and metacomputing environments. Multimethod run-time systems, such as Nexus [8] and Horus <ref> [17] </ref>, integrate diverse transport mechanisms and protocols under one interface. This allows the programmer to treat a collection of supercomputers connected by a network as one virtual metacomputer, knowing that the most optimal communication method will be applied to communication between any two nodes of this virtual machine.
References-found: 17

