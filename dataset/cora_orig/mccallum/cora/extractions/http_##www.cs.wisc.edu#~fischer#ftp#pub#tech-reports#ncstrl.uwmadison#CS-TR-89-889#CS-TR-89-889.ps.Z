URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-889/CS-TR-89-889.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-889/
Root-URL: http://www.cs.wisc.edu
Title: Bottom-Up Evaluation of Logic Programs  
Author: Jeffrey F. Naughton and Raghu Ramakrishnan 
Date: May 7, 1992  
Address: WI 53706, U.S.A.  
Affiliation: Computer Sciences Department University of Wisconsin-Madison,  
Abstract: The Prolog evaluation algorithm has become the standard for logic program evaluation, and bottom-up methods have long been considered impractical because they compute irrelevant facts. Recently, however, bottom-up evaluation algorithms that retain the focusing property of top-down evaluation have been proposed, and in view of these algorithms the choice between top-down and bottom-up methods needs to be re-examined. We believe that in several situations, bottom-up evaluation is now the method of choice. The bottom-up approach can be refined in a number of ways, and we show how various results in the literature can be combined to provide a coherent evaluation framework. We illustrate the power of the approach and relate it to top-down evaluation methods and to optimizations for functional programs. The paper is organized into three broad parts: (1) A review of the bottom-up approach, including program transformations and fixpoint evaluation, (2) A discussion of the choice of methods, including a comparison of Prolog and bottom-up evaluation, and (3) A discussion of memory utilization in bottom-up evaluation and a comparison with techniques in the functional programming literature.
Abstract-found: 1
Intro-found: 1
Reference: [AU79] <author> Alfred V. Aho and Jeffrey D. Ullman. </author> <title> Universality of data retrieval languages. </title> <booktitle> In Proceedings of the Sixth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 110-120, </pages> <address> San Antonio, Texas, </address> <year> 1979. </year>
Reference-contexts: The transitive closure has received a great deal of attention in the deductive database literature | in fact, the inability of relational database systems to express the transitive closure was one of the original reasons for extending database technology to provide logic-based query languages <ref> [AU79] </ref>. If logic-based languages are to succeed as database query languages, they must evaluate queries on the transitive closure efficiently. <p> in which the recursive predicate is unary. 2 20 The previous example illustrated how the adornment algorithm can sometimes push the projection through recursion and thereby reduce the arity of recursive predicates. (The observation that pushing projections could reduce arity of recursive predicates was first made by Aho and Ullman <ref> [AU79] </ref>, and later Kifer and Lozinskii [KL86]. The adornment algorithm above generalizes their results.) The acute reader will have observed that more can be achieved | the recursive rule may be deleted entirely.
Reference: [BD77] <author> R. M. Burstall and John Darlington. </author> <title> A transformation system for developing recursive programs. </title> <journal> Journal of the ACM, </journal> <volume> 24(1) </volume> <pages> 44-67, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: We do not explore this in detail here, due to space constraints, but provide illustrative examples of the potential gains. We also consider the relationship between program transformation systems proposed for functional programs | primarily the one proposed by Burstall and Darlington <ref> [BD77] </ref> | and the program transformations used in the bottom-up approach. We bring out some important differences in the underlying assumptions and objectives, and compare their relative power. <p> Our discussion is in three parts. We begin by introducing some of the ideas in functional program transformation, drawing primarily upon Burstall and Darlington's pioneering work <ref> [BD77] </ref>. This work has somewhat different objectives and assumptions from the program transformations in the bottom-up evaluation literature. However, the two approaches achieve similar improvements in several programs, and this leads to an interesting comparison, which we hope will stimulate interest in both. <p> Applying techniques from the tabulation literature to the bottom-up approach shows promise in improving the space utilization of the bottom-up approach. 8.1 Functional Program Transformations In this section, we describe the transformation approach proposed in <ref> [BD77] </ref>. Burstall and Darlington propose to transform functional programs, expressed as recursion equations, using a library of transformation rules. We begin by establishing a correspondence between recursion 32 equations and the formalism of logic programs. <p> In [DB73], a transformation rule is specified as a schematic rewriting system with constraints on the instances of the schemas for which the rule is valid. This is formalized using using second order unification in [HL78]. We now present several examples, from <ref> [BD77] </ref>, to illustrate the use of transformation rules; the reader is urged to consult [BD77] for a detailed treatment. <p> This is formalized using using second order unification in [HL78]. We now present several examples, from <ref> [BD77] </ref>, to illustrate the use of transformation rules; the reader is urged to consult [BD77] for a detailed treatment. Example 8.1 Consider the Fibonacci example: fib 10 (0; 1): f ib 10 (1; 1): We have seen that a top-down evaluation of this program is exponential time unless the results of all calls are saved.
Reference: [Bir80] <author> R. S. Bird. </author> <title> Tabulation techniques for recursive programs. </title> <journal> Computing Surveys, </journal> <volume> 12(4) </volume> <pages> 403-417, </pages> <month> December </month> <year> 1980. </year>
Reference-contexts: These connections currently are not well understood. An important link to the bottom-up approach, which is based on memoing intermediate results, is provided by the studies on tabulation <ref> [Bir80, Coh83] </ref>. These studies examine how memory can be intelligently utilized in memoing computations, based on a careful compile-time analysis of the source program. These schemes are quite ingenious, but are of limited generality. We examine tabulation in the context of the Magic Templates transformation. <p> This work points to an important new direction of research in bottom-up evaluation, which is the effective utilization of memory through compile-time garbage collection. We follow the presentation in <ref> [Bir80, Coh83] </ref>. We then consider how this work relates to bottom-up evaluation of logic programs. We discuss refinements to the Magic Templates approach that improve space utilization by using ideas related to tabulation [NR90]. <p> We will refer to methods that save intermediate results as tabulation methods, using Bird's terminology <ref> [Bir80] </ref>. There is a wide range of tabulation methods that differ in how much intermediate computation they save. Elsewhere, we have used the term memoing method; we will reserve this to refer to a subset of tabulation methods that save all intermediate results. <p> In this section, we review work on tabulation that aims to determine at compile-time how goals and solutions that are tabulated can be discarded as computation progresses. This allows the development of techniques to allocate memory at compile-time in a way that re-utilizes freed space. We will follow <ref> [Bir80] </ref> for the most part, and rely upon [Coh83] for the rest of our overview. These papers deal with functional programs, and we will adapt the treatment to logic programs where necessary. <p> Bird calls such schemes overtabulation methods. We will not describe these transformations in greater detail here; the reader is asked to consult <ref> [Bir80, Coh83] </ref>. 8.2.1 Sliding Window Tabulation The rules in a program produced by the Magic Templates algorithm (a magic program, for brevity) are of two kinds: "magic" rules, which define "magic" predicates, and "modified" rules, which define adorned predicates and use the magic predicates to restrict the set of generated facts.
Reference: [BMSU86] <author> Francois Bancilhon, David Maier, Yehoshua Sagiv, and Jeffrey D. Ullman. </author> <title> Magic sets and other strange ways to implement logic programs. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 1-15, </pages> <address> Cambridge, Massachusetts, </address> <month> March </month> <year> 1986. </year> <month> 42 </month>
Reference-contexts: The reader is referred to [BR86] and to the recent deductive database literature for more details. A discussion of bottom-up versus top-down approaches that complements the survey in this section may be found in [Bry89]. The first version of the Magic Templates algorithm was introduced in <ref> [BMSU86] </ref>. As defined in that paper, it was only applicable to linear Datalog rules; it was generalized to range-restricted logic programs in [BR87]. These versions of the algorithm were called Magic Sets. It was generalized to full logic programs in [Ram88], and given the name Magic Templates. <p> Counting was originally proposed in <ref> [BMSU86] </ref>, and was refined in [SZ86]. As in the case of Magic Sets, these versions of the algorithm only applied to (programs containing only) range-restricted linear rules; the algorithm was generalized to deal with all range-restricted rules in [BR87]. Counting can be understood as a two-step refinement of Magic Sets.
Reference: [BR86] <author> Francois Bancilhon and Raghu Ramakrishnan. </author> <title> An amateur's introduction to recursive query processing strategies. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 16-52, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1986. </year>
Reference-contexts: To see the difference with respect to N, note that NSN, unlike N, does not generate a in the second step and b in the third step. 2 3.3 Related Work We present a brief discussion of related work. The reader is referred to <ref> [BR86] </ref> and to the recent deductive database literature for more details. A discussion of bottom-up versus top-down approaches that complements the survey in this section may be found in [Bry89]. The first version of the Magic Templates algorithm was introduced in [BMSU86].
Reference: [BR87] <author> Catriel Beeri and Raghu Ramakrishnan. </author> <title> On the power of magic. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 269-283, </pages> <address> San Diego, California, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: In Section 5, we discuss several program transformations that can be used in conjunction with the Magic Templates algorithm in the rewriting step. We consider refinements of fixpoint evaluation in Sections 6 and 8.2.1. 3.1 The Magic Templates Rewriting Algorithm As described in <ref> [BR87, Ram88] </ref>, the initial rewriting of a program and query is guided by a choice of sideways information passing strategies, or sips. For each rule, the associated sip determines the order in which the body literals are evaluated. <p> The supplementary version of the rewriting algorithm essentially identifies these common sub-expressions and stores them (with some optimizations that allow us to delete some columns from these intermediate, or supplementary, relations). We refer the reader to <ref> [BR87] </ref> for details. We now describe a generalization of the Magic Templates algorithm that uses the notion of adornments, similar to modes, to specialize rules for different goals. <p> The first version of the Magic Templates algorithm was introduced in [BMSU86]. As defined in that paper, it was only applicable to linear Datalog rules; it was generalized to range-restricted logic programs in <ref> [BR87] </ref>. These versions of the algorithm were called Magic Sets. It was generalized to full logic programs in [Ram88], and given the name Magic Templates. <p> The Alexander method was proposed independently of the Magic Sets approach in [RLK86]. It is essentially the supplementary variant of the Magic Templates method, described in <ref> [BR87] </ref>. The main difference between the Alexander method and this variant | both of which deal only with range-restricted programs | is that the former does not utilize adornments, and is restricted to use a single, left-to-right sip for each rule, for all possible goals. <p> Counting was originally proposed in [BMSU86], and was refined in [SZ86]. As in the case of Magic Sets, these versions of the algorithm only applied to (programs containing only) range-restricted linear rules; the algorithm was generalized to deal with all range-restricted rules in <ref> [BR87] </ref>. Counting can be understood as a two-step refinement of Magic Sets. Syntactically, the version presented in [BR87], called Generalized Counting (GC), simply adds some index fields to predicates in the Magic program and is applicable to any logic program. <p> As in the case of Magic Sets, these versions of the algorithm only applied to (programs containing only) range-restricted linear rules; the algorithm was generalized to deal with all range-restricted rules in <ref> [BR87] </ref>. Counting can be understood as a two-step refinement of Magic Sets. Syntactically, the version presented in [BR87], called Generalized Counting (GC), simply adds some index fields to predicates in the Magic program and is applicable to any logic program. The additional indices enable a further 14 optimization, called the semijoin optimization 4 , for some programs. <p> The applicability is further limited because the computation of the indices may sometimes cause non-termination. We refer the reader to <ref> [BR87] </ref> for a detailed presentation of the method, and present only the intuition behind the index fields. We also sketch the semijoin optimization, and present an illustrative example. Recall that we limit ourselves in this paper to a left-to-right choice of sips. <p> Similarly, it can be shown that many of the literals in a rule can be discarded. We refer the reader to <ref> [BR87] </ref> for details, and summarize these optimizations to the Generalized Counting program below: 1. The arity of p a is reduced by deleting the bound argument positions. 2. All body literals to the left of the right-most occurrence of p a in the recursive rule are deleted.
Reference: [BR88] <author> Francois Bancilhon and Raghu Ramakrishnan. </author> <title> Performance evaluation of data intensive logic programs. </title> <editor> In Jack Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 439-517, </pages> <address> Los Altos, California, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: With the definitions of Prolog trees and the program P opt , we compare the behavior of Prolog and bottom-up evaluation on several classes of programs. 7.1 Counting and Magic In many cases, the Counting rewriting algorithm produces programs that are more efficient than the corresponding Magic program <ref> [BR88, MSPS87] </ref>. However, if there are facts in the program that can be generated in multiple ways, the Counting rewriting can be worse than even the most straightforward bottom-up approach | ignoring the query and computing the entire queried relation using the original, unrewritten program program.
Reference: [Bry89] <author> Francois Bry. </author> <title> Logic programming as constructivism: A formalization and its application to databases. </title> <booktitle> In Proceedings of the ACM SIGACT-SIGART-SIGMOD Symposium on Principles of Database Systems, </booktitle> <pages> pages 34-50, </pages> <address> Philadelphia, Pennsylvania, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: The reader is referred to [BR86] and to the recent deductive database literature for more details. A discussion of bottom-up versus top-down approaches that complements the survey in this section may be found in <ref> [Bry89] </ref>. The first version of the Magic Templates algorithm was introduced in [BMSU86]. As defined in that paper, it was only applicable to linear Datalog rules; it was generalized to range-restricted logic programs in [BR87]. These versions of the algorithm were called Magic Sets.
Reference: [CGKV88] <author> Stavros S. Cosmadakis, Haim Gaifman, Paris Kanellakis, and Moshe Y. Vardi. </author> <title> Decidable optimization problems for database logic programs. </title> <booktitle> In Proceedings of the Twentieth Symposium on the Theory of Computation, </booktitle> <pages> pages 477-490, </pages> <address> Chicago, Illinois, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: A rich classification of sets of programs for which detecting boundedness is decidable or undecidable has been developed in the literature; see, for example, <ref> [CGKV88, Ioa86, GMSV87, Nau89a, NS87, Var88] </ref>. A related question is when a literal is redundant in a given program.
Reference: [Coh83] <author> Norman H. Cohen. </author> <title> Eliminating redundant recursive calls. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(3) </volume> <pages> 265-299, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: These connections currently are not well understood. An important link to the bottom-up approach, which is based on memoing intermediate results, is provided by the studies on tabulation <ref> [Bir80, Coh83] </ref>. These studies examine how memory can be intelligently utilized in memoing computations, based on a careful compile-time analysis of the source program. These schemes are quite ingenious, but are of limited generality. We examine tabulation in the context of the Magic Templates transformation. <p> two recursive subgoals in the body contain the terms c (T ) and d (T ), where c and d are functions that reduce T to subterms of smaller size. (We will return to this class of programs in Section 8, where c and d are called "descent conditions," after <ref> [Coh83] </ref>.) Definition 4.2 Let r be a recursive definition of the form p (T; R) :- :B (T ); p (c (T ); R 1 ); p (d (T ); R 2 ); R (R 1 ; R 2 ; R): Then r is n-callable on a term t if * <p> This work points to an important new direction of research in bottom-up evaluation, which is the effective utilization of memory through compile-time garbage collection. We follow the presentation in <ref> [Bir80, Coh83] </ref>. We then consider how this work relates to bottom-up evaluation of logic programs. We discuss refinements to the Magic Templates approach that improve space utilization by using ideas related to tabulation [NR90]. <p> This allows the development of techniques to allocate memory at compile-time in a way that re-utilizes freed space. We will follow [Bir80] for the most part, and rely upon <ref> [Coh83] </ref> for the rest of our overview. These papers deal with functional programs, and we will adapt the treatment to logic programs where necessary. <p> We will not consider any variations in this paper. The problem that we must address is therefore to analyze the dependency graph for a program at compile-time and to devise a pebbling strategy that uses as few pebbles as possible. The analysis 36 proposed in <ref> [Coh83] </ref> rests upon a study of descent functions, which describe how immediate subgoals are derived from a goal. In our discussion of Cohen's work, we will restrict ourselves to adorned programs that are equivalent to recursion equations, since this class properly includes all the program schemas that he considers. <p> Bird calls such schemes overtabulation methods. We will not describe these transformations in greater detail here; the reader is asked to consult <ref> [Bir80, Coh83] </ref>. 8.2.1 Sliding Window Tabulation The rules in a program produced by the Magic Templates algorithm (a magic program, for brevity) are of two kinds: "magic" rules, which define "magic" predicates, and "modified" rules, which define adorned predicates and use the magic predicates to restrict the set of generated facts.
Reference: [CW79] <author> J. Lawrence Carter and Mark N. Wegman. </author> <title> Universal classes of hash functions. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18 </volume> <pages> 143-154, </pages> <year> 1979. </year>
Reference-contexts: This assumption of constant-time access is clearly warranted for ground facts, where expected constant-time access can be guaranteed by the use of an appropriate hashing scheme (see, for example, Carter and Wegman <ref> [CW79] </ref>.) It is an important open problem whether the same efficiency can be achieved in practice in the presence of nonground facts, where instead of looking for an exact match or a given ground fact we need to search for general terms that subsume a given general term.
Reference: [CW89] <author> S.R. Cohen and O. Wolfson. </author> <title> Why a single parallelization strategy is not enough in knowledge bases. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 200-216, </pages> <address> Philadelphia, Pennsylvania, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: We present our conclusions in Section 9. Due to space limitations, we have not considered any of the recent results on parallelizing bottom-up computations (e.g., <ref> [CW89, Don86, GST90, Ram90, VG86, WS89] </ref>). This is one of the areas in which we believe that the bottom-up approach shows great promise. 2 Notation and Preliminary Definitions The language considered in this paper is that of Horn logic.
Reference: [DB73] <author> John Darlington and R. M. Burstall. </author> <title> A system which automatically improves programs. </title> <booktitle> In Proceedings of the Third International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 479-485, </pages> <year> 1973. </year>
Reference-contexts: They note that introducing the definitions and choosing appropriate instantiations and abstractions often require hints from the user. In earlier work, Burstall and Darlington developed a system in which transformation rules converted recursive schemas into iterative schemas <ref> [DB73] </ref>; the system that we have discussed arose out of a desire to transform programs extensively before eliminating recursion. In [DB73], a transformation rule is specified as a schematic rewriting system with constraints on the instances of the schemas for which the rule is valid. <p> In earlier work, Burstall and Darlington developed a system in which transformation rules converted recursive schemas into iterative schemas <ref> [DB73] </ref>; the system that we have discussed arose out of a desire to transform programs extensively before eliminating recursion. In [DB73], a transformation rule is specified as a schematic rewriting system with constraints on the instances of the schemas for which the rule is valid. This is formalized using using second order unification in [HL78].
Reference: [Don86] <author> G. Dong. </author> <title> On distributed processing of datalog queries by decomposing databases. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 26-35, </pages> <address> Portland, Oregon, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: We present our conclusions in Section 9. Due to space limitations, we have not considered any of the recent results on parallelizing bottom-up computations (e.g., <ref> [CW89, Don86, GST90, Ram90, VG86, WS89] </ref>). This is one of the areas in which we believe that the bottom-up approach shows great promise. 2 Notation and Preliminary Definitions The language considered in this paper is that of Horn logic.
Reference: [DW87] <author> Suzanne W. Dietrich and David S. Warren. </author> <title> Extension tables: Memo relations in logic programming. </title> <booktitle> In Proceedings of the Symposium on Logic Programming, </booktitle> <pages> pages 264-272, </pages> <year> 1987. </year> <type> Unpublished Manuscript. </type>
Reference-contexts: An intriguing issue is how QSQ with global optimization and Magic Templates with factoring | which is an optimization described in later sections | compare. Dietrich and Warren have proposed a method called Extension Tables that is very similar to QSQ <ref> [DW87] </ref>. Finally, Kifer and Lozinskii have proposed a method called Filtering, which is based on constructing a rule-goal graph [KL86, KL88].
Reference: [DW89] <author> S.K. Debray and D.S. Warren. </author> <title> Functional compositions in logic programs. </title> <journal> Transactions on Programming Languages, </journal> <year> 1989. </year>
Reference-contexts: An important class of such dependencies are functional goals, that is, goals for which there is a single answer. Sufficient conditions for a goal to be functional have been developed in <ref> [Red84, DW89] </ref>. Such goals can be optimized in a number of ways; for example, backtrack points need not be maintained in a Prolog-style evaluation. Indeed, if only the declarative semantics is to be preserved, it may be possible to simply apply evaluation techniques for functional programs, rather than logic programs. <p> Indeed, if only the declarative semantics is to be preserved, it may be possible to simply apply evaluation techniques for functional programs, rather than logic programs. We remark that although functionality was only considered for programs that generated ground facts in <ref> [Red84, DW89] </ref>, the techniques in [MR90] | developed in the somewhat different context of establishing sufficient conditions for subsumption-freedom | enable us to identify functional computations that generate non-ground goals and facts. 6.3 Algebraic Properties of Programs The fixpoint evaluation of a logic program can be refined by taking certain algebraic
Reference: [GMSV87] <author> Haim Gaifman, Harry Mairson, Yehoshua Sagiv, and Moshe Y. Vardi. </author> <title> Undecidable optimization problems for database logic programs. </title> <booktitle> In Proceedings of the Second IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 106-115, </pages> <address> Ithaca, New York, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: A rich classification of sets of programs for which detecting boundedness is decidable or undecidable has been developed in the literature; see, for example, <ref> [CGKV88, Ioa86, GMSV87, Nau89a, NS87, Var88] </ref>. A related question is when a literal is redundant in a given program.
Reference: [GST90] <author> S. Ganguly, A. Silberschatz, and S. Tsur. </author> <title> A framework for the parallel processing of datalog queries. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Atlantic City, New Jersey, </address> <month> May </month> <year> 1990. </year> <note> To appear. </note>
Reference-contexts: We present our conclusions in Section 9. Due to space limitations, we have not considered any of the recent results on parallelizing bottom-up computations (e.g., <ref> [CW89, Don86, GST90, Ram90, VG86, WS89] </ref>). This is one of the areas in which we believe that the bottom-up approach shows great promise. 2 Notation and Preliminary Definitions The language considered in this paper is that of Horn logic.
Reference: [Hel87] <author> Richard Helm. </author> <title> Inductive and deductive control of logic programs. </title> <booktitle> In Proceedings of the International Conference on Logic Programming, </booktitle> <pages> pages 488-511, </pages> <address> Melbourne, Australia, </address> <year> 1987. </year>
Reference-contexts: Kowalski has advocated a separation of logic and control, and Helm has advocated the use of regular expressions over rules as a form of control <ref> [Hel87] </ref>. Providing such a facility could, in general, compromise the completeness of bottom-up evaluation. (Of course, Prolog's depth-first strategy is not complete either.) This must be tempered by several factors.
Reference: [Hel88] <author> A. Richard Helm. </author> <title> Detecting and eliminating redundant derivations in deductive database systems. </title> <type> Technical Report RC 14244 (#63767), </type> <institution> IBM Thomas Watson Research Center, </institution> <month> December </month> <year> 1988. </year> <month> 43 </month>
Reference-contexts: Such refinements, and techniques for detecting when they are applicable, have been investigated by several researchers <ref> [Hel88, IW88, Mah85, Nau88b, RSUV89] </ref>. We discuss these ideas briefly through examples. Example 6.2 We begin with an example that illustrates commutativity of rules. <p> An approach based on analyzing derivation trees and proving containment theorems between sets of derivation trees is presented in [RSUV89]. The derivation tree approach is also explored by Helm <ref> [Hel88] </ref>. In contrast to [RSUV89], he does not attempt to directly establish properties such as commutativity.
Reference: [HL78] <author> Gerard Huet and Bernard Lang. </author> <title> Proving and applying program transformations expressed with second-order patterns. </title> <journal> Acta Informatica, </journal> <volume> 11 </volume> <pages> 31-55, </pages> <year> 1978. </year>
Reference-contexts: In [DB73], a transformation rule is specified as a schematic rewriting system with constraints on the instances of the schemas for which the rule is valid. This is formalized using using second order unification in <ref> [HL78] </ref>. We now present several examples, from [BD77], to illustrate the use of transformation rules; the reader is urged to consult [BD77] for a detailed treatment.
Reference: [HL89] <author> J. Han and L. Liu. </author> <title> Processing multiple linear recursions. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming, </booktitle> <address> Cleveland, Ohio, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: Another variant is based on combining the computation for different rules by computing the union of certain relations, taking advantage of the structure of the Magic Sets transformation <ref> [HL89] </ref>. We have chosen to present the Magic Templates algorithm in detail since it can be described simply as a source-to-source program transformation, and allows for easy consideration of a number of related program transformations and fixpoint evaluation techniques.
Reference: [Ioa86] <author> Yannis E. Ioannidis. </author> <title> Bounded recursion in deductive databases. </title> <journal> Algorithmica, </journal> <volume> 1(4) </volume> <pages> 361-385, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: A rich classification of sets of programs for which detecting boundedness is decidable or undecidable has been developed in the literature; see, for example, <ref> [CGKV88, Ioa86, GMSV87, Nau89a, NS87, Var88] </ref>. A related question is when a literal is redundant in a given program.
Reference: [Ioa89] <author> Yannis E. Ioannidis. </author> <title> Commutativity and its role in the processing of linear recursion. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Very Large Databases, </booktitle> <pages> pages 155-163, </pages> <address> Amsterdam, The Netherlands, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: While commutativity is not explicit in the definition of the class, the rules of a separable recursion do in fact commute, and the algorithm presented for separable recursion evaluation depends upon commutativity for its correctness. A discussion of the relationship between commutativity and separability appears in <ref> [Ioa89] </ref>. We can view SN and NSN iteration as acting on derivation trees instead of atoms.
Reference: [IW88] <author> Yannis E. Ioannidis and Eugene Wong. </author> <title> Towards an algebraic theory of recursion. </title> <type> Technical Report 801, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> October </month> <year> 1988. </year>
Reference-contexts: The following program is finally obtained using the techniques of [RBK88]: t dn (Y ) :- e (X; Y ): query (Y ) :- t dn (Y ). 2 5.5 Linearizing Programs An interesting class of program transformations has recently been explored by a number of researchers <ref> [IW88, ZYT88, Sar89, RSUV89] </ref>. The objective is to transform a program that contains non-linear rules into an equivalent one that contains only linear rules; this may make some of the other transformations surveyed in this paper applicable, or permit simplifications in the implementation of the fixpoint evaluation phase. <p> Such refinements, and techniques for detecting when they are applicable, have been investigated by several researchers <ref> [Hel88, IW88, Mah85, Nau88b, RSUV89] </ref>. We discuss these ideas briefly through examples. Example 6.2 We begin with an example that illustrates commutativity of rules. <p> 0 2 , computes all positive even numbers less than s 2k , and the second program, r 0 4 , computes all even numbers greater than s 2k . 2 Ioannidis presents an algebraic formulation of Datalog programs that is particularly suited to reasoning about such properties of programs <ref> [IW88] </ref>. Naughton [Nau88b] defines a class of recursions called separable recursions. While commutativity is not explicit in the definition of the class, the rules of a separable recursion do in fact commute, and the algorithm presented for separable recursion evaluation depends upon commutativity for its correctness.
Reference: [KL86] <author> Michael Kifer and Eliezer L. Lozinskii. </author> <title> A framework for an efficient implementation of deductive databases. </title> <booktitle> In Proceedings of the Advanced Database Symposium, </booktitle> <address> Tokyo, Japan, </address> <year> 1986. </year>
Reference-contexts: Dietrich and Warren have proposed a method called Extension Tables that is very similar to QSQ [DW87]. Finally, Kifer and Lozinskii have proposed a method called Filtering, which is based on constructing a rule-goal graph <ref> [KL86, KL88] </ref>. There is a node in the graph for each predicate, and for each rule, and arcs from predicate nodes to each rule node in whose body it appears, and from rule nodes to the predicates that they define. <p> unary. 2 20 The previous example illustrated how the adornment algorithm can sometimes push the projection through recursion and thereby reduce the arity of recursive predicates. (The observation that pushing projections could reduce arity of recursive predicates was first made by Aho and Ullman [AU79], and later Kifer and Lozinskii <ref> [KL86] </ref>. The adornment algorithm above generalizes their results.) The acute reader will have observed that more can be achieved | the recursive rule may be deleted entirely.
Reference: [KL88] <author> Michael Kifer and Eliezer L. Lozinskii. SYGRAF: </author> <title> Implementing logic programs in a database style. </title> <journal> IEEE Transactions on Software Engineering, </journal> <year> 1988. </year>
Reference-contexts: Dietrich and Warren have proposed a method called Extension Tables that is very similar to QSQ [DW87]. Finally, Kifer and Lozinskii have proposed a method called Filtering, which is based on constructing a rule-goal graph <ref> [KL86, KL88] </ref>. There is a node in the graph for each predicate, and for each rule, and arcs from predicate nodes to each rule node in whose body it appears, and from rule nodes to the predicates that they define.
Reference: [Mah85] <author> Michael J. Maher. </author> <title> Semantics of Logic Programs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Melbourne, </institution> <address> Melbourne, Australia, </address> <year> 1985. </year>
Reference-contexts: Such refinements, and techniques for detecting when they are applicable, have been investigated by several researchers <ref> [Hel88, IW88, Mah85, Nau88b, RSUV89] </ref>. We discuss these ideas briefly through examples. Example 6.2 We begin with an example that illustrates commutativity of rules. <p> utilized to avoid many redundant derivations by evaluating the fixpoint of the program as follows: first apply rule r 3 , then apply r 2 as often as possible, and finally apply r 1 as often as possible. 2 Example 6.3 This example illustrates decomposability, which was studied by Maher <ref> [Mah85] </ref>. Informally, a program is decomposable if its fixpoint can be computed as the union of the fixpoints of two programs that are subsets of the original program.
Reference: [Mah89] <author> M.J. Maher. </author> <title> A transformation system for deductive database modules with perfect model semantics. </title> <booktitle> In Proceedings of the Conference on Foundations of Software Technology and Theoretical Computer Science, </booktitle> <address> Bangalore, India, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: The repeated application of these transformation rules is guaranteed to preserve soundness in that any inferred answer is in the Herbrand model; however, it may introduce non-termination. Related sets of transformation rules, for the case of logic programs, have been investigated by Tamaki and Sato [TS84] and by Maher <ref> [Mah89] </ref>. The Tamaki-Sato transformation system is shown to preserve the least Herbrand model, and the Maher system is shown to preserve the Clark completion of the program.
Reference: [MPR90] <author> I. S. Mumick, H. Pirahesh, and R. Ramakrishnan. </author> <title> Duplicates and aggregates in deductive databases. </title> <type> Unpublished Manuscript., </type> <year> 1990. </year>
Reference-contexts: These conditions seem to apply to a large class of Prolog programs; intuitively, it is required that no two rules produce the same fact, and that the evaluation of a rule be deterministic. In <ref> [MPR90] </ref>, it is shown that if the original program is subsumption-free, this property can be utilized effectively in the bottom-up evaluation of the program rewritten according to the Magic Templates algorithm.
Reference: [MR90] <author> Michael J. Maher and Raghu Ramakrishnan. </author> <title> Deja vu in fixpoints of logic programs. </title> <booktitle> In Proceedings of the Symposium on Logic Programming, </booktitle> <address> Cleveland, Ohio, </address> <year> 1990. </year>
Reference-contexts: This represents a trade-off in that we avoid the cost of duplicate elimination, but face the possibility of redundant derivations. For some classes of programs, it can be shown that redundant derivations will not arise, and Not-So-Naive evaluation is then the method of choice. We follow the presentation in <ref> [MR90] </ref> in the rest of this section, with some simplifications. Let us first define a binary operator W P , whose role is similar to that of the well-known T P operator of [vEK76]. <p> A more rigorous definition that formally accounts for the multiplicity is given in <ref> [MR90] </ref>; we have chosen to use an informal presentation for ease of exposition. Intuitively, W P only allows deductions from the set of facts X that use the "new" facts Y , and "counts" a fact as often as it is derived (using distinct rule instantiations). <p> Example 6.1 Consider the following program. p (X; Y ) :- X = 5: This program is subsumption-free. However, the following program is not: q (X) :- p (X; Y ); X = 5; Y = 5: p (X; Y ) :- Y = 5: The following result, from <ref> [MR90] </ref>, shows that NSN evaluation | which performs no expensive check for duplicates | performs as well as SN evaluation for programs that are subsumption-free. Theorem 6.1 ([MR90]) In terms of the number of inferences, 1. SN I = NSN for subsumption-free programs P . 2. <p> These properties are important for termination. Theorem 6.2 (<ref> [MR90] </ref>) 1. If SN I terminates, then NSN terminates, for programs P with the finite subsumption property. 2. If SN S terminates, then NSN terminates, for programs P with the finite forest property. 22 Sufficient conditions for subsumption-freedom are presented in [MR90]. These conditions seem to apply to a large class of Prolog programs; intuitively, it is required that no two rules produce the same fact, and that the evaluation of a rule be deterministic. <p> Thus, if the original program is subsumption-free, no subsumption checks need be performed on any non-magic predicates in the rewritten program. 6.2 Determinacy and Functional Goals The determinism required by the sufficient conditions for subsumption-freedom can be formulated in terms of functional dependencies <ref> [MR90] </ref>. An important class of such dependencies are functional goals, that is, goals for which there is a single answer. Sufficient conditions for a goal to be functional have been developed in [Red84, DW89]. <p> Indeed, if only the declarative semantics is to be preserved, it may be possible to simply apply evaluation techniques for functional programs, rather than logic programs. We remark that although functionality was only considered for programs that generated ground facts in [Red84, DW89], the techniques in <ref> [MR90] </ref> | developed in the somewhat different context of establishing sufficient conditions for subsumption-freedom | enable us to identify functional computations that generate non-ground goals and facts. 6.3 Algebraic Properties of Programs The fixpoint evaluation of a logic program can be refined by taking certain algebraic properties of the program into
Reference: [MSPS87] <author> Alberto Marchetti-Spaccamela, Antonella Pelaggi, and Domenico Sacca. </author> <title> Worst-case complexity analysis of methods for logic query implementation. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 294-301, </pages> <address> San Diego, California, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: With the definitions of Prolog trees and the program P opt , we compare the behavior of Prolog and bottom-up evaluation on several classes of programs. 7.1 Counting and Magic In many cases, the Counting rewriting algorithm produces programs that are more efficient than the corresponding Magic program <ref> [BR88, MSPS87] </ref>. However, if there are facts in the program that can be generated in multiple ways, the Counting rewriting can be worse than even the most straightforward bottom-up approach | ignoring the query and computing the entire queried relation using the original, unrewritten program program.
Reference: [Nau88a] <author> Jeffrey F. Naughton. </author> <title> Benchmarking multi-rule recursion evaluation strategies. </title> <type> Technical Report CS-TR-141-88, </type> <institution> Princeton University, </institution> <year> 1988. </year>
Reference-contexts: Note that simply evaluating the original unrewritten program bottom-up can never generate more then n 2 facts in t. 2 This exponential behavior of Counting is not only manifested over specially designed relations | it occurs even over randomly generated sparse relations <ref> [Nau88a] </ref>. Intuitively, the inefficiency arises when some facts can be derived in many different ways, because counting stores a fact corresponding to each derivation.
Reference: [Nau88b] <author> Jeffrey F. Naughton. </author> <title> Compiling separable recursions. </title> <booktitle> In Proceedings of the SIGMOD International Symposium on Management of Data, </booktitle> <pages> pages 312-319, </pages> <address> Chicago, Illinois, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Such refinements, and techniques for detecting when they are applicable, have been investigated by several researchers <ref> [Hel88, IW88, Mah85, Nau88b, RSUV89] </ref>. We discuss these ideas briefly through examples. Example 6.2 We begin with an example that illustrates commutativity of rules. <p> Naughton <ref> [Nau88b] </ref> defines a class of recursions called separable recursions. While commutativity is not explicit in the definition of the class, the rules of a separable recursion do in fact commute, and the algorithm presented for separable recursion evaluation depends upon commutativity for its correctness.
Reference: [Nau89a] <author> Jeffrey F. Naughton. </author> <title> Data independent recursion in deductive databases. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 38(2) </volume> <pages> 259-289, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Note that here we are not asking when recursion can be replaced by iteration; rather, we are asking when a logic program containing recursive clauses has an equivalent finite logic program in which no clause is recursive. Example 5.5 The following example is from <ref> [Nau89a] </ref>. buys (X; Y ) :- likes (X; Y ): buys (X; Y ) :- trendy (X); buys (Z; Y ): In English, a person X buys a product Y if either X likes Y , or X is trendy and a person Z has bought Y . <p> A rich classification of sets of programs for which detecting boundedness is decidable or undecidable has been developed in the literature; see, for example, <ref> [CGKV88, Ioa86, GMSV87, Nau89a, NS87, Var88] </ref>. A related question is when a literal is redundant in a given program.
Reference: [Nau89b] <author> Jeffrey F. Naughton. </author> <title> Minimizing function-free recursive definitions. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 36(1) </volume> <pages> 69-91, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: A rich classification of sets of programs for which detecting boundedness is decidable or undecidable has been developed in the literature; see, for example, [CGKV88, Ioa86, GMSV87, Nau89a, NS87, Var88]. A related question is when a literal is redundant in a given program. Naughton <ref> [Nau89b] </ref> defined a predicate p appearing in a clause C to be recursively redundant if, for any set of base facts, there is a constant k such that any fact provable by that clause has a derivation tree in which there are at most k instances of p. <p> If a predicate is recursively redundant, then the program can be rewritten so that no instance of that predicate appears in any recursive rule. Example 5.6 The following example is taken from <ref> [Nau89b] </ref>. buys (X; Y ) :- likes (X; Y ): buys (X; Y ) :- knows (X; W ); buys (W; Y ); cheap (Y ): Here the predicate cheap is recursively redundant; an equivalent program is 19 buys1 (X; Y ) :- likes (X; Y ): buys2 (X; Y )
Reference: [NR90] <author> Jeffrey F. Naughton and Raghu Ramakrishnan. </author> <title> How to forget the past without repeating it. </title> <note> Submitted for publication., </note> <year> 1990. </year>
Reference-contexts: We follow the presentation in [Bir80, Coh83]. We then consider how this work relates to bottom-up evaluation of logic programs. We discuss refinements to the Magic Templates approach that improve space utilization by using ideas related to tabulation <ref> [NR90] </ref>. <p> Such an analysis can be carried out at compile time, and the implementation of the Seminaive iteration phase can be modified to discard these facts. This approach to garbage collection based upon compile-time analysis is developed in <ref> [NR90] </ref>, and we refer the reader to this paper for details of Sliding Window Tabulation, which we survey in this subsection. <p> An orthogonal concern is how to avoid repeating the same inferences. The Seminaive bottom-up evaluation algorithm can be adapted to ensure that Sliding Window Tabulation does not repeat any inferences. We do not consider this issue here for simplicity; see <ref> [NR90] </ref>. 38 Sliding Window Tabulation of a (rewritten) program P mg proceeds in two phases. In phase one, the "down" phase, only the magic rules are applied. Initially, the only magic fact is the query, and is in the highest window. <p> We state the following theorem, which follows from results in <ref> [NR90] </ref>, without proof. Theorem 8.1 The Sliding Window Tabulation algorithm correctly computes all answers. A variant of Sliding Window Tabulation stores all magic facts encountered in the down phase, and uses these stored magic facts instead of inverted magic rules in the up phase. <p> This requires more storage than basic Sliding Window Tabulation, but can be more time-efficient if basic Sliding Window "overtabulates" on hP; qi <ref> [NR90] </ref>. 8.3 Performance of Sliding Window Tabulation We consider how the refined version of Magic Templates, which we dubbed Sliding Window Tabulation, works on the programs that we used earlier to illustrate the power of the Burstall-Darlington system. <p> that the Sliding Window Tabulation approach does not rely upon user intervention, and is totally correct, that is, it does not introduce non-termination. (Although we have not discussed this aspect of the algorithm, techniques for automatically testing the applicability of Sliding Window Tabulation, based upon sufficient conditions, are presented in <ref> [NR90] </ref>. These techniques are sufficiently powerful to deal with the programs discussed in this section.) In all these examples, we will assume that a "seed" magic fact corresponding to the given query is added to the magic program.
Reference: [NRSU89a] <author> Jeffrey F. Naughton, Raghu Ramakrishnan, Yehoshua Sagiv, and Jeffrey D. Ullman. </author> <title> Argument reduction through factoring. </title> <booktitle> In Proceedings of the Fifteenth International Conference on Very Large Databases, </booktitle> <pages> pages 173-182, </pages> <address> Amsterdam, The Netherlands, </address> <month> August </month> <year> 1989. </year> <month> 44 </month>
Reference-contexts: The declarative semantics is preserved for such code, and the optimizations made possible by it could be utilized.) One example of a powerful optimization made possible by the declarative semantics of bottom-up is factoring <ref> [NRSU89a] </ref>. For example, Prolog is (2 n ) on the transitive closure program, and Magic Templates is O (n 2 ); factoring the Magic program results in a program whose Seminaive evaluation computes only O (n) facts. <p> Our presentation is through the use of examples, and we do not describe sufficient conditions for the optimization to apply in general. We refer the reader to <ref> [NRSU89a] </ref> for a detailed treatment. In essence, we seek to take advantage of the magic predicates to replace the original predicate in P mg by its projection onto its 0 argument positions. <p> ft (Y ) :- m t 10 (X); e (X; W ); bt (W ); f t (Y ): ft (Y ) :- m t 10 (X); e (X; Y ): query (Y ) :- bt (5); f t (Y ): Applying some simple syntactic optimizations, which are discussed in <ref> [NRSU89a] </ref>, we finally obtain the following unary program: m t 10 (W ) :- f t (W ): ft (Y ) :- m t 10 (X); e (X; Y ): query (Y ) :- f t (Y ): 2 The above example is illustrative of a general approach to optimizing programs, <p> We remark that the factoring technique is applicable to logic programs, although the sufficient conditions presented in <ref> [NRSU89a] </ref> are only applicable to Datalog programs. To deal with logic programs, we must first transform them into Extended Datalog programs, that is, Datalog programs with infinite base relations. This allows us to use the sufficient conditions of [NRSU89a]. <p> technique is applicable to logic programs, although the sufficient conditions presented in <ref> [NRSU89a] </ref> are only applicable to Datalog programs. To deal with logic programs, we must first transform them into Extended Datalog programs, that is, Datalog programs with infinite base relations. This allows us to use the sufficient conditions of [NRSU89a]. The following algorithm takes as input a program P and produces as output an Extended Datalog program P ext . 17 Definition 5.1 (Extended Datalog Program) Let P be a Datalog program. <p> The first n arguments are the variables and constants of t, and the last argument is the variable X. These new predicates all denote base relations (with a possibly infinite number of tuples in them). It is easy to extend the proofs of <ref> [NRSU89a] </ref> to show that if the sufficient conditions for factorability are satisfied by P ext , then P can also be factored. Example 5.4 Suppose we want to find all postfixes of a list.
Reference: [NRSU89b] <author> Jeffrey F. Naughton, Raghu Ramakrishnan, Yehoshua Sagiv, and Jeffrey D. Ullman. </author> <title> Effi--cient evaluation of right-, left-, and multi-linear rules. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 235-242, </pages> <address> Portland, Oregon, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Example 5.3 We begin with a familiar example, transitive closure. While efficient algorithms are known, the rewriting algorithms presented in <ref> [NRSU89b] </ref> were the first to automatically derive unary programs for single-selection queries, for all three forms (left-linear, right-linear, non-linear) of the recursive rule. We achieve the same result here by first applying the Magic Templates transformation and then factoring the rewritten program.
Reference: [NS87] <author> Jeffrey F. Naughton and Yehoshua Sagiv. </author> <title> A decidable class of bounded recursions. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 227-236, </pages> <address> San Diego, California, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: A rich classification of sets of programs for which detecting boundedness is decidable or undecidable has been developed in the literature; see, for example, <ref> [CGKV88, Ioa86, GMSV87, Nau89a, NS87, Var88] </ref>. A related question is when a literal is redundant in a given program.
Reference: [NS89] <author> Jeffrey F. Naughton and Yehoshua Sagiv. </author> <title> Minimizing expansions of recursions. </title> <editor> In Hasan Ait-Kaci and Maurice Nivat, editors, </editor> <booktitle> Resolution of Equations in Algebraic Structures, </booktitle> <volume> volume 1, </volume> <pages> pages 321-349, </pages> <address> San Diego, California, 1989. </address> <publisher> Academic Press, Inc. </publisher>
Reference-contexts: His algorithm for detecting redundant literals is interesting in that it is based on the chase procedure for inferring data dependencies. More detail about detecting and eliminating redundancy from recursive Datalog programs appears in <ref> [NS89] </ref>. 5.4 Projecting Arguments Query optimization for relational database queries exploits the commutativity of selection and projection operators with respect to the join operator whenever possible, in order to reduce the size of relations that are being joined. This is often referred to as "pushing" selections and projections.
Reference: [PW83] <author> F.C.N. Pereira and D.H.D. Warren. </author> <title> Parsing as deduction. </title> <booktitle> In Proceedings of the twenty-first Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1983. </year>
Reference-contexts: The Magic and Alexander methods are based on program transformations. Other methods use a combination of top-down and bottom-up control to propagate bindings. Pereira and Warren presented a memoing top-down evaluation procedure based on Earley deduction <ref> [PW83] </ref>. This evaluation procedure may be viewed as a top-down evaluation procedure that incorporates memoing. Vieille has proposed a method called QSQ [Vie87, Vie86] that can be viewed as follows. Goals are generated with a top-down 3 There are some exceptions.
Reference: [Ram88] <author> Raghu Ramakrishnan. </author> <title> Magic templates: A spellbinding approach to logic programs. </title> <booktitle> In Proceedings of the International Conference on Logic Programming, </booktitle> <pages> pages 140-159, </pages> <address> Seattle, Washington, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: In Section 5, we discuss several program transformations that can be used in conjunction with the Magic Templates algorithm in the rewriting step. We consider refinements of fixpoint evaluation in Sections 6 and 8.2.1. 3.1 The Magic Templates Rewriting Algorithm As described in <ref> [BR87, Ram88] </ref>, the initial rewriting of a program and query is guided by a choice of sideways information passing strategies, or sips. For each rule, the associated sip determines the order in which the body literals are evaluated. <p> We generalize to allow a different choice of sip for different goals at the end of this section. The reader is referred to <ref> [Ram88] </ref> for a more general algorithm capable of implementing more sophisticated sip choices, and also for a detailed discussion of bottom-up fixpoint computation in the presence of non-ground facts. The idea is to compute a set of auxiliary predicates that contain the goals. <p> U ); sg (U; V ); down (V; Y ): magic sg (U; V ) :- magic sg (X; Y ); up (X; U ): magic sg (john; Z): 2 We present some results that characterize the transformed program P mg with respect to the original program P , from <ref> [Ram88] </ref>. The following theorem ensures soundness. Theorem 3.1 ([Ram88]) hP; Qi is equivalent to hP mg ; Qi with respect to the set of answers to the query. Definition 3.2 Let us define the Magic Templates Evaluation Method as follows: 1. <p> As defined in that paper, it was only applicable to linear Datalog rules; it was generalized to range-restricted logic programs in [BR87]. These versions of the algorithm were called Magic Sets. It was generalized to full logic programs in <ref> [Ram88] </ref>, and given the name Magic Templates. <p> A perhaps more important issue to consider is the following. While it is known that the approach of Magic Templates rewriting plus Seminaive bottom-up evaluation is never worse than Prolog by more than a constant factor <ref> [Ram88, Sek89, Ull89] </ref> (under the assumption of constant time table lookup operations), the constant factors in the running time for bottom-up evaluation may be larger than the associated constant factors in the top-down Prolog evaluation of the same program.
Reference: [Ram90] <author> Raghu Ramakrishnan. </author> <title> Parallelism in logic programs. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Programming Languages, </booktitle> <address> San Francisco, California, </address> <year> 1990. </year>
Reference-contexts: We present our conclusions in Section 9. Due to space limitations, we have not considered any of the recent results on parallelizing bottom-up computations (e.g., <ref> [CW89, Don86, GST90, Ram90, VG86, WS89] </ref>). This is one of the areas in which we believe that the bottom-up approach shows great promise. 2 Notation and Preliminary Definitions The language considered in this paper is that of Horn logic.
Reference: [RBK88] <author> Raghu Ramakrishnan, Catriel Beeri, and Ravi Krishnamurthy. </author> <title> Optimizing existential dat-alog queries. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 89-102, </pages> <address> Austin, Texas, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: Pushing selections is achieved through the use of the Magic Templates transformation; the introduction of recursion makes it necessary to compute auxiliary sets. Pushing projections has also been explored, and the gains can be significant. We will illustrate the idea through examples, and refer the reader to <ref> [RBK88] </ref> for details. <p> Note that such queries are likely to arise during the course of query optimization. 2 An adornment that distinguishes don't-care argument positions (d) from the rest (needed or n) was used in <ref> [RBK88] </ref> to push projections. An adorned program is generated using an algorithm similar to that described in Section 3.1. <p> Algorithms for deleting redundant rules and literals can be utilized to detect this; in fact, since such opportunities are frequently created by pushing projections, we can devise special algorithms for rule and literal deletion that exploit this. The following example illustrates the power of the techniques developed in <ref> [RBK88] </ref> for this purpose. <p> Notice that the adorned program contains more rules than the original program. (This could happen with 1 and 0 adornments as well.) The additional information in the adornments can, however, be used to delete several of the rules. The following program is finally obtained using the techniques of <ref> [RBK88] </ref>: t dn (Y ) :- e (X; Y ): query (Y ) :- t dn (Y ). 2 5.5 Linearizing Programs An interesting class of program transformations has recently been explored by a number of researchers [IW88, ZYT88, Sar89, RSUV89].
Reference: [Red84] <author> U.S. Reddy. </author> <title> Transformation of logic programs into functional programs. </title> <booktitle> In Proceedings of the Symposium on Logic Programming, </booktitle> <pages> pages 187-196, </pages> <address> Salt Lake City, Utah, </address> <month> September </month> <year> 1984. </year>
Reference-contexts: An important class of such dependencies are functional goals, that is, goals for which there is a single answer. Sufficient conditions for a goal to be functional have been developed in <ref> [Red84, DW89] </ref>. Such goals can be optimized in a number of ways; for example, backtrack points need not be maintained in a Prolog-style evaluation. Indeed, if only the declarative semantics is to be preserved, it may be possible to simply apply evaluation techniques for functional programs, rather than logic programs. <p> Indeed, if only the declarative semantics is to be preserved, it may be possible to simply apply evaluation techniques for functional programs, rather than logic programs. We remark that although functionality was only considered for programs that generated ground facts in <ref> [Red84, DW89] </ref>, the techniques in [MR90] | developed in the somewhat different context of establishing sufficient conditions for subsumption-freedom | enable us to identify functional computations that generate non-ground goals and facts. 6.3 Algebraic Properties of Programs The fixpoint evaluation of a logic program can be refined by taking certain algebraic
Reference: [RLK86] <author> J. Rohmer, R. Lescoeur, and J. M. Kerisit. </author> <title> The Alexander method | a technique for the processing of recursive axioms in deductive database queries. </title> <journal> New Generation Computing, </journal> <volume> 4 </volume> <pages> 522-528, </pages> <year> 1986. </year>
Reference-contexts: The Alexander method was proposed independently of the Magic Sets approach in <ref> [RLK86] </ref>. It is essentially the supplementary variant of the Magic Templates method, described in [BR87].
Reference: [RSUV89] <author> Raghu Ramakrishnan, Yehoshua Sagiv, Jeffrey D. Ullman, and Moshe Vardi. </author> <title> Proof-tree transformation theorems and their applications. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <address> Philadelphia, Pensylvannia, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: The following program is finally obtained using the techniques of [RBK88]: t dn (Y ) :- e (X; Y ): query (Y ) :- t dn (Y ). 2 5.5 Linearizing Programs An interesting class of program transformations has recently been explored by a number of researchers <ref> [IW88, ZYT88, Sar89, RSUV89] </ref>. The objective is to transform a program that contains non-linear rules into an equivalent one that contains only linear rules; this may make some of the other transformations surveyed in this paper applicable, or permit simplifications in the implementation of the fixpoint evaluation phase. <p> Such refinements, and techniques for detecting when they are applicable, have been investigated by several researchers <ref> [Hel88, IW88, Mah85, Nau88b, RSUV89] </ref>. We discuss these ideas briefly through examples. Example 6.2 We begin with an example that illustrates commutativity of rules. <p> For example, commutativity allows us to avoid generating derivation trees in which applications of rules r 1 and rule r 2 are interleaved. An approach based on analyzing derivation trees and proving containment theorems between sets of derivation trees is presented in <ref> [RSUV89] </ref>. The derivation tree approach is also explored by Helm [Hel88]. In contrast to [RSUV89], he does not attempt to directly establish properties such as commutativity. <p> An approach based on analyzing derivation trees and proving containment theorems between sets of derivation trees is presented in <ref> [RSUV89] </ref>. The derivation tree approach is also explored by Helm [Hel88]. In contrast to [RSUV89], he does not attempt to directly establish properties such as commutativity. <p> His approach is noteworthy in that it is able to avoid some redundant derivation even when the program does not satisfy algebraic properties such as commutativity. Further, the results of the more powerful containment tests of <ref> [RSUV89] </ref> and other sufficient conditions for various algebraic properties can be incorporated into the approach by using them to guide the generation of iterative control expressions. 7 On Choosing an Evaluation Method In this section we explore in more detail properties of logic programs that help determine when a particular evaluation
Reference: [Sag88] <author> Yehoshua Sagiv. </author> <title> Optimizing datalog programs. </title> <editor> In Jack Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 659-698, </pages> <address> Los Altos, California, 94022, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Y ) :- knows (X; W ); likes (W; Y ); cheap (Y ): buys2 (X; Y ) :- knows (X; W ); buys2 (W; Y ): buys (X; Y ) :- buys1 (X; Y ): buys (X; Y ) :- buys2 (X; Y ): 2 In related work, Sagiv <ref> [Sag88] </ref> defined a literal to be redundant if the semantics of the program are unchanged by deleting the literal. His algorithm for detecting redundant literals is interesting in that it is based on the chase procedure for inferring data dependencies.
Reference: [Sar89] <author> Yatin Saraiya. </author> <title> Linearizing nonlinear recursions in polynomial time. </title> <booktitle> In Proceedings of the ACM SIGACT-SIGART-SIGMOD Symposium on Principles of Database Systems, </booktitle> <pages> pages 182-189, </pages> <address> Philadelphia, Pennsylvania, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: The following program is finally obtained using the techniques of [RBK88]: t dn (Y ) :- e (X; Y ): query (Y ) :- t dn (Y ). 2 5.5 Linearizing Programs An interesting class of program transformations has recently been explored by a number of researchers <ref> [IW88, ZYT88, Sar89, RSUV89] </ref>. The objective is to transform a program that contains non-linear rules into an equivalent one that contains only linear rules; this may make some of the other transformations surveyed in this paper applicable, or permit simplifications in the implementation of the fixpoint evaluation phase.
Reference: [Sek89] <author> H. Seki. </author> <title> On the power of Alexander templates. </title> <booktitle> In Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 150-159, </pages> <address> Philadel-phia, Pennsylvania, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: The Alexander method also does not deal with function symbols, although this is easily remedied. Seki has generalized the method to deal with non-ground facts and function symbols, and has called the generalized version Alexander Templates <ref> [Sek89] </ref>. This generalization is also restricted to use a single left-to-right sip for each rule, for all possible goals. The Magic and Alexander methods are based on program transformations. Other methods use a combination of top-down and bottom-up control to propagate bindings. <p> A perhaps more important issue to consider is the following. While it is known that the approach of Magic Templates rewriting plus Seminaive bottom-up evaluation is never worse than Prolog by more than a constant factor <ref> [Ram88, Sek89, Ull89] </ref> (under the assumption of constant time table lookup operations), the constant factors in the running time for bottom-up evaluation may be larger than the associated constant factors in the top-down Prolog evaluation of the same program.
Reference: [SS88] <author> Seppo Sippu and Eljas Soisalon-Soinen. </author> <title> An optimization strategy for recursive queries in logic databases. </title> <booktitle> In Proceedings of the Fourth International Conference on Data Engineering, </booktitle> <address> Los Angeles, California, </address> <year> 1988. </year>
Reference-contexts: Several other variants of the Magic Sets idea have also been proposed. For example, it is possible to compute supersets of the magic sets without compromising soundness. Although this results in some irrelevant computation, it may be possible to compute supersets more efficiently than the magic sets themselves <ref> [SS88] </ref>. Another variant is based on combining the computation for different rules by computing the union of certain relations, taking advantage of the structure of the Magic Sets transformation [HL89].
Reference: [SZ86] <author> Domenico Sacca and Carlo Zaniolo. </author> <title> The generalized counting methods for recursive logic queries. </title> <booktitle> In Proceedings of the First International Conference on Database Theory, </booktitle> <year> 1986. </year> <month> 45 </month>
Reference-contexts: Counting was originally proposed in [BMSU86], and was refined in <ref> [SZ86] </ref>. As in the case of Magic Sets, these versions of the algorithm only applied to (programs containing only) range-restricted linear rules; the algorithm was generalized to deal with all range-restricted rules in [BR87]. Counting can be understood as a two-step refinement of Magic Sets.
Reference: [SZ87] <author> Domenico Sacca and Carlo Zaniolo. </author> <title> Magic counting methods. </title> <booktitle> In Proceedings of the ACM--SIGMOD Symposium on the Management of Data, </booktitle> <pages> pages 49-59, </pages> <address> San Fransisco, California, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: To complete the picture, we now examine classes of programs for which Counting will not generate more facts than Magic. In particular, what can be said about programs in which no two cnt p facts differ only in the index values? The Magic Counting method of Sacca and Zaniolo <ref> [SZ87] </ref> aims to exploit such programs by using Counting. (The idea is that if a cnt p fact is derived twice, we abandon Counting and use Magic instead.) Our next result addresses this class of programs and shows that Counting never computes more facts than Magic on such programs.
Reference: [TS84] <author> Hisao Tamaki and Taisuke Sato. </author> <title> Unfold/fold transformations of logic programs. </title> <booktitle> In Proceedings of the Second International Conference on Logic Programming, </booktitle> <pages> pages 127-138, </pages> <institution> Uppsala, Sweden, </institution> <month> July </month> <year> 1984. </year>
Reference-contexts: The repeated application of these transformation rules is guaranteed to preserve soundness in that any inferred answer is in the Herbrand model; however, it may introduce non-termination. Related sets of transformation rules, for the case of logic programs, have been investigated by Tamaki and Sato <ref> [TS84] </ref> and by Maher [Mah89]. The Tamaki-Sato transformation system is shown to preserve the least Herbrand model, and the Maher system is shown to preserve the Clark completion of the program.
Reference: [Ull89] <author> Jeffrey D. Ullman. </author> <title> Bottom-up beats top-down for datalog. </title> <booktitle> In Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 140-149, </pages> <address> Philadelphia, Pennsylvania, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: It was shown in <ref> [Ull89] </ref> that the Magic Sets transformation, in conjunction with some additional rewriting, could deal with all Datalog programs | even programs that are not range-restricted | without generating non-ground tuples. Several other variants of the Magic Sets idea have also been proposed. <p> A perhaps more important issue to consider is the following. While it is known that the approach of Magic Templates rewriting plus Seminaive bottom-up evaluation is never worse than Prolog by more than a constant factor <ref> [Ram88, Sek89, Ull89] </ref> (under the assumption of constant time table lookup operations), the constant factors in the running time for bottom-up evaluation may be larger than the associated constant factors in the top-down Prolog evaluation of the same program.
Reference: [Var88] <author> Moshe Y. Vardi. </author> <title> Decidability and undecidablity results for boundedness of linear recursive queries. </title> <booktitle> In Proceedings of the Seventh ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 341-351, </pages> <address> Austin, Texas, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: A rich classification of sets of programs for which detecting boundedness is decidable or undecidable has been developed in the literature; see, for example, <ref> [CGKV88, Ioa86, GMSV87, Nau89a, NS87, Var88] </ref>. A related question is when a literal is redundant in a given program.
Reference: [vEK76] <author> M. H. van Emden and R. A. Kowalski. </author> <title> The semantics of predicate logic as a programming language. </title> <journal> Journal of the ACM, </journal> <volume> 23(4) </volume> <pages> 733-742, </pages> <month> October </month> <year> 1976. </year>
Reference-contexts: However, the distinction is artificial, and we may choose to consider (a subset of) facts to be rules if we wish. The meaning of a logic program is given by its least Herbrand model <ref> [vEK76] </ref>. Following the syntax of Edinburgh Prolog, definite clauses (rules) are written as 3 p :- q 1 ; . . . ; q n : read declaratively as q 1 and q 2 and . . . and q n implies p. <p> We follow the presentation in [MR90] in the rest of this section, with some simplifications. Let us first define a binary operator W P , whose role is similar to that of the well-known T P operator of <ref> [vEK76] </ref>. <p> The following result shows that the above iterative methods are consistent with the usual least Herbrand model semantics of <ref> [vEK76] </ref>; here implicitly D is the domain for the program in question. We denote the least Herbrand model of the program by M.
Reference: [VG86] <author> Allen Van Gelder. </author> <title> A message passing framework for logical query evaluation. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 349-362, </pages> <address> Washington, DC, </address> <month> May </month> <year> 1986. </year>
Reference-contexts: We present our conclusions in Section 9. Due to space limitations, we have not considered any of the recent results on parallelizing bottom-up computations (e.g., <ref> [CW89, Don86, GST90, Ram90, VG86, WS89] </ref>). This is one of the areas in which we believe that the bottom-up approach shows great promise. 2 Notation and Preliminary Definitions The language considered in this paper is that of Horn logic.
Reference: [Vie86] <author> Laurent Vieille. </author> <title> Recursive axioms in deductive databases: The query-subquery approach. </title> <booktitle> In Proceedings of the First International Conference on Expert Database Systems, </booktitle> <pages> pages 179-193, </pages> <address> Charleston, South Carolina, </address> <year> 1986. </year>
Reference-contexts: Other methods use a combination of top-down and bottom-up control to propagate bindings. Pereira and Warren presented a memoing top-down evaluation procedure based on Earley deduction [PW83]. This evaluation procedure may be viewed as a top-down evaluation procedure that incorporates memoing. Vieille has proposed a method called QSQ <ref> [Vie87, Vie86] </ref> that can be viewed as follows. Goals are generated with a top-down 3 There are some exceptions. The Counting optimization described in Section 5.1 is a direct refinement of the Magic Templates approach, and depends upon the structure of the transformation. <p> To deal with these differences, it is necessary to extend tabulation as defined by Bird; methods such as Vieille's QSQ <ref> [Vie86, Vie87] </ref> are precisely such generalizations (although they were derived independently).
Reference: [Vie87] <author> Laurent Vieille. </author> <title> Database complete proof procedures based on SLD-resolution. </title> <booktitle> In Proceedings of the Fourth International Conference on Logic Programming, </booktitle> <pages> pages 74-103, </pages> <year> 1987. </year>
Reference-contexts: Other methods use a combination of top-down and bottom-up control to propagate bindings. Pereira and Warren presented a memoing top-down evaluation procedure based on Earley deduction [PW83]. This evaluation procedure may be viewed as a top-down evaluation procedure that incorporates memoing. Vieille has proposed a method called QSQ <ref> [Vie87, Vie86] </ref> that can be viewed as follows. Goals are generated with a top-down 3 There are some exceptions. The Counting optimization described in Section 5.1 is a direct refinement of the Magic Templates approach, and depends upon the structure of the transformation. <p> To deal with these differences, it is necessary to extend tabulation as defined by Bird; methods such as Vieille's QSQ <ref> [Vie86, Vie87] </ref> are precisely such generalizations (although they were derived independently).
Reference: [WS89] <author> O. Wolfson and A. Silberschatz. </author> <title> Sharing the load of logic program evaluations. </title> <booktitle> In Proceedings of the 7th ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, </booktitle> <address> Philadelphia, Pennsylvania, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: We present our conclusions in Section 9. Due to space limitations, we have not considered any of the recent results on parallelizing bottom-up computations (e.g., <ref> [CW89, Don86, GST90, Ram90, VG86, WS89] </ref>). This is one of the areas in which we believe that the bottom-up approach shows great promise. 2 Notation and Preliminary Definitions The language considered in this paper is that of Horn logic.
Reference: [ZYT88] <author> W. Zhang, C. T. Yu, and D. Troy. </author> <title> A necessary and sufficient condition to linearize doubly recursive programs in logic databases. </title> <type> Unpublished manuscript, </type> <institution> Department of EECS, University of Illinois at Chicago, </institution> <year> 1988. </year>
Reference-contexts: The following program is finally obtained using the techniques of [RBK88]: t dn (Y ) :- e (X; Y ): query (Y ) :- t dn (Y ). 2 5.5 Linearizing Programs An interesting class of program transformations has recently been explored by a number of researchers <ref> [IW88, ZYT88, Sar89, RSUV89] </ref>. The objective is to transform a program that contains non-linear rules into an equivalent one that contains only linear rules; this may make some of the other transformations surveyed in this paper applicable, or permit simplifications in the implementation of the fixpoint evaluation phase.
References-found: 63

