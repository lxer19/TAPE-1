URL: ftp://info.mcs.anl.gov/pub/tech_reports/ip/pdsn.ps.Z
Refering-URL: http://www-unix.mcs.anl.gov/otc/InteriorPoint/abstracts/Andersen-Christiansen-2.html
Root-URL: http://www.mcs.anl.gov
Email: E-mail: kda@beta.dou.dk  
Phone: 55, 5230  
Title: A symmetric Primal-Dual Newton method for Minimizing a Sum of Norms  
Author: Knud D. Andersen Edmund Christiansen 
Note: 1 This work was supported by a Danish SNF Research Studentship. Most of it was carried out while the author was a visiting  and it is part of this authors ph.d. thesis  
Date: April 11, 1995  
Address: Campusvej  Denmark  rev 1.0  
Affiliation: Odense University  Odense M,  Department of Mathematic and Computer Science Odense University  scholar at the Computer Science Department of Stanford University  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> F. Alizadeh, J.-P. A. Haeberly, </author> <title> and M.L. Overton. Primal-Dual Interior Point Methods for Semidefinite Programming. </title> <type> Technical report, </type> <year> 1994. </year>
Reference-contexts: This way of explicitly symmetries a primal-dual method is well-known from methods for Semidefinite Programming, see <ref> [1] </ref>. For a related primal-dual method for (M SN) problems independent suggested and motivated different, see [7].
Reference: [2] <author> E.D. Andersen and Y. Ye. </author> <title> Combining interior-point and pivoting algorithms for linear programming. </title> <type> Technical report, </type> <year> 1994. </year> <note> In preparation. </note>
Reference-contexts: We have that (0.35) is equivalent to LL T x + Lp 1 * = Lq (0.36) 2 L T x + H * * = b 2 (0.37) and it follows that (H * p T 2 q (0.38) The Cholesky decomposition which is used is described in <ref> [2] </ref>, and how to extend for handling dense columns is described in [9] Linear constraints are handled as described in [5]. One of the advantage with the primal-dual method is that the method now have a dual feasible solution in every itera tion.
Reference: [3] <author> K.D. Andersen. </author> <title> An efficient Newton barrier method for minimizing a sum of eu-clidean norms. </title> <type> preprint 42, </type> <institution> Dept. Of Math. and Computer Sci., Odense University, </institution> <year> 1993. </year> <note> To appear in SIAM J. on Optim. </note> <year> 1995. </year>
Reference-contexts: 1 This work was supported by a Danish SNF Research Studentship. Most of it was carried out while the author was a visiting scholar at the Computer Science Department of Stanford University and it is part of this authors ph.d. thesis Abstract In <ref> [3, 5, 7] </ref> was the dual problem for minimizing a sum of Euclidean Norms described. We will in this paper use this duality theory to develop a symmetric primal-dual Newton method for the minimizing a sum of norms problem (MSN). <p> We will in this paper use this duality theory to develop a symmetric primal-dual Newton method for the minimizing a sum of norms problem (MSN). As in <ref> [3, 5] </ref> the method is actually develop for a smooth approximation problem to (MSN), using a HAP function. Numerical results are presented for large sparse problems arising in plastic collapse analysis. <p> Numerical results are presented for large sparse problems arising in plastic collapse analysis. These results show that the new method is more efficient in measurement of iterations and time than the primal method described in <ref> [3, 5] </ref>. 0.1 Introduction We consider the following unconstrained convex minimization problem (MSN) (P ) &gt; &gt; &gt; &lt; min i=1 s:t: where X = (x; r) 2 R n fi R j A T x r = b (0.1) with A 2 R nfi , b 2 R and r <p> The function P kr i k 2 is convex but is not differentiable at any point (x; r) where r i = 0 for some i 2 f1; : : : ; g. The dual is (see [7] and <ref> [3] </ref>) (D) &gt; &lt; max b T y y 2 Y with Y = fy 2 R j Ay = 0; ky i k 2 1; i = 1; : : : ; g (0.2) This pair of dual problems has several applications, both in the primal form (P ) and <p> Examples are problems in multifacility-location, collapse load analysis ([10]), Steiner trees ([7]) and soap dual films (minization of area) ([8]). As described in <ref> [3] </ref> the non-smoothness can be handled by applying a primal Newton barrier method to the smooth approximating problem: (P * ) &gt; &gt; &gt; &lt; min i=1 kr i k 2 + * 2 2 (x; r) 2 X This method is numerically stable and efficient, but the number of iterations <p> We replace the pair (P ) and (D) with the smooth approximating problem (P * ) and its dual (proved in <ref> [3] </ref>): (D * ) &gt; &gt; &gt; &lt; max b T y + * i=1 2 1 s:t: This pair has the same feasible regions as (P ) and (D) respectively. Furthermore, it is proved in [3] that an optimal solution to (P * ) and (D * ) is at <p> (D) with the smooth approximating problem (P * ) and its dual (proved in <ref> [3] </ref>): (D * ) &gt; &gt; &gt; &lt; max b T y + * i=1 2 1 s:t: This pair has the same feasible regions as (P ) and (D) respectively. Furthermore, it is proved in [3] that an optimal solution to (P * ) and (D * ) is at least *-optimal for (P ) and (D), measured in duality gap. (P * ) and (D * ) can be shown to have the following complementarity conditions r i kr i k 2 + * 2 <p> In the first method which is a barrier method, we see * as a variable with a lower bound. As in <ref> [3] </ref> this lower bound is removed by a log term which keeps * away from zero. The barrier problem is as follows 8 &gt; &gt; &gt; &gt; &gt; : P i 2 j 1 s:t: (0.14) where is the barrier parameter which controls how fast * are going to zero. <p> D. Andersen and E. D. Andersen). The MPS format is used as input format. Implementation details have already been given in <ref> [3] </ref>. A Cholesky decomposition is used for the positive symmetric system which is solved in every iteration. The code include the barrier as well as the non barrier method i.e. * is seen as a constant. <p> The Cholesky factor L is found of A (H 1 y )H r A T . As described in <ref> [3] </ref> the symbolic structure is found once for L, using a minimum degree heuristic to reduce the fill-in in L. However it is the unsymmetric system (0.35) we will find a solution of. <p> Times are in CPU seconds and are measured with the ANSI-C procedure "clock". Computing time includes all processing except time for reading the data. For all computation have we set fi = 1 and = 0:99. We use the same test problems as in <ref> [3, 5] </ref>. The problems is described in [4, 10, 6]. <p> In Table 1 3 is the results shown for the unconstrained problems from <ref> [3] </ref>: Name n jAj jAHA T j=2 jLj ITE CPU 0 terms D gap L fea ssp4 25 15 224 97 105 7 0 0 2E-10 2E-14 ssp50 2601 2499 48800 31010 171083 9 65 0 2E-09 4E-13 ssp300 90601 89999 1792800 1161010 13203975 11 6709 0 1E-09 2E-13 Table 0.1: <p> Compared to the results in <ref> [3] </ref> is the number of iterations much lower for especial the two problems lNa13 and lNa20, with many active norms in the optimal solution. For example for l80a20 the primal method took 164 iterations against the 32 in the primal-dual method. We furthermore see the same reduction in CPU time. <p> For example for l80a20 the primal method took 164 iterations against the 32 in the primal-dual method. We furthermore see the same reduction in CPU time. For the smooth problems sspN is the reduction in iterations practically 0, however the number of iterations is still lower 11 than in <ref> [3] </ref>. Another benefit of the primal-dual method is that the number of iterations increase very slow with problem size and for lNa20, it even seems to be constant. In Table 4 5 is the results shown for the linear constrained problems, which also was used in [5]. <p> the dense column technique described in [9] for handling of dense columns make it possible to find solutions of larger problems for this type problems. 0.6 Conclusion We conclude that the described symmetric primal-dual pseudo (real for l=1) Newton method, is more efficient than the primal Newton method described in <ref> [3, 5] </ref>. The primal-dual method furthermore gives a better method for setting the weight at the l 1 penalty function. Acknowledgment The work described in this paper was first time presented of the first author in a talk at SCCM section of the Computer Science Department at Stanford University.
Reference: [4] <author> K.D. Andersen and E. Christiansen. </author> <title> Limit Analysis with the Dual Affine Scaling Algorithm. </title> <type> Preprint 26, </type> <institution> Dept. Of Math. and Computer Sci., Odense University, </institution> <year> 1993. </year> <note> To appear in the J. of Comput. and Applied Math. </note>
Reference-contexts: Computing time includes all processing except time for reading the data. For all computation have we set fi = 1 and = 0:99. We use the same test problems as in [3, 5]. The problems is described in <ref> [4, 10, 6] </ref>.
Reference: [5] <author> K.D. Andersen and E. Christiansen. </author> <title> A Newton Barrier method for Minimizing a Sum of Euclidean Norms subject to linear equality constraints. </title> <type> Preprint 7, </type> <institution> Dept. of Mathematics and Comp. Sci., Odense University, </institution> <year> 1995. </year> <note> submitted to SIAM Journal on Optimization. </note>
Reference-contexts: 1 This work was supported by a Danish SNF Research Studentship. Most of it was carried out while the author was a visiting scholar at the Computer Science Department of Stanford University and it is part of this authors ph.d. thesis Abstract In <ref> [3, 5, 7] </ref> was the dual problem for minimizing a sum of Euclidean Norms described. We will in this paper use this duality theory to develop a symmetric primal-dual Newton method for the minimizing a sum of norms problem (MSN). <p> We will in this paper use this duality theory to develop a symmetric primal-dual Newton method for the minimizing a sum of norms problem (MSN). As in <ref> [3, 5] </ref> the method is actually develop for a smooth approximation problem to (MSN), using a HAP function. Numerical results are presented for large sparse problems arising in plastic collapse analysis. <p> Numerical results are presented for large sparse problems arising in plastic collapse analysis. These results show that the new method is more efficient in measurement of iterations and time than the primal method described in <ref> [3, 5] </ref>. 0.1 Introduction We consider the following unconstrained convex minimization problem (MSN) (P ) &gt; &gt; &gt; &lt; min i=1 s:t: where X = (x; r) 2 R n fi R j A T x r = b (0.1) with A 2 R nfi , b 2 R and r <p> We therefore in this paper developed a new primal-dual method for (P ) and (D), which in fact uses a number of iterations similar to primal-dual interior-point methods for linear programming. In <ref> [5] </ref> it is demonstrated how the linearly constrained (M SN ) problem can, preserving sparsity structure, be reduced to the unconstrained case by the use of an exact l 1 penalty function. <p> T x + H * * = b 2 (0.37) and it follows that (H * p T 2 q (0.38) The Cholesky decomposition which is used is described in [2], and how to extend for handling dense columns is described in [9] Linear constraints are handled as described in <ref> [5] </ref>. One of the advantage with the primal-dual method is that the method now have a dual feasible solution in every itera tion. This can be used to set the weight at the l 1 penalty function. <p> If we assume that a dual solution (y k ; y k e ) 2 Y is known, the weight ae k at the linear penalty function is set to ae k+1 = max (ae k ; fi2 2 fl e fl 1 motivated of theorem 3 in <ref> [5] </ref>. We simply always try to satisfy the conditions of the theorem. A large ae can introduce ill-condition in the linear system which the method find a solution of in every iteration. <p> Times are in CPU seconds and are measured with the ANSI-C procedure "clock". Computing time includes all processing except time for reading the data. For all computation have we set fi = 1 and = 0:99. We use the same test problems as in <ref> [3, 5] </ref>. The problems is described in [4, 10, 6]. <p> Another benefit of the primal-dual method is that the number of iterations increase very slow with problem size and for lNa20, it even seems to be constant. In Table 4 5 is the results shown for the linear constrained problems, which also was used in <ref> [5] </ref>. As for the unconstrained problems the number of iterations and CPU time is significantly reduced. ae is initial set to 2 p 2, and for no problem did the method reset the weight more than two times, this was a clear improvement of the method used in [5]. <p> used in <ref> [5] </ref>. As for the unconstrained problems the number of iterations and CPU time is significantly reduced. ae is initial set to 2 p 2, and for no problem did the method reset the weight more than two times, this was a clear improvement of the method used in [5]. This was observed to give a better conditioned convergence. <p> 2 NAME CPU ITE kr i k 2 * l DGap jAuj E fea cl3 0 11 1 1.6e-08 4.4e-9 1.0e-15 cl30 31 16 651 4.0e-09 2.3e-13 3.4e-12 cl99 890 24 8234 1.2e-08 1.0e-13 7.0e-13 cl201 6179 24 35803 3.1e-08 1.0e-13 5.1e-13 Table 0.5: Results for "clN" with SPDMSN In <ref> [5] </ref> was the results for the clNa13 problems compared to results achieved with an interior-point method for linear programming, at a linear discretisation of the problem. We have compared the new results to the LP results in Table 0.6. <p> the dense column technique described in [9] for handling of dense columns make it possible to find solutions of larger problems for this type problems. 0.6 Conclusion We conclude that the described symmetric primal-dual pseudo (real for l=1) Newton method, is more efficient than the primal Newton method described in <ref> [3, 5] </ref>. The primal-dual method furthermore gives a better method for setting the weight at the l 1 penalty function. Acknowledgment The work described in this paper was first time presented of the first author in a talk at SCCM section of the Computer Science Department at Stanford University.
Reference: [6] <author> E. Christiansen and K.O. Kortanek. </author> <title> Computation of the collapse state in limit analysis using the lp primal affine scaling algorithm. </title> <journal> J. Comput. Appl. Math., </journal> <volume> 34 </volume> <pages> 47-63, </pages> <year> 1991. </year>
Reference-contexts: Computing time includes all processing except time for reading the data. For all computation have we set fi = 1 and = 0:99. We use the same test problems as in [3, 5]. The problems is described in <ref> [4, 10, 6] </ref>.
Reference: [7] <author> A. R. Conn and M. L. Overton. </author> <title> A primal-dual interior point method for minimizing a sum of Euclidean distances. </title> <note> In preparation. </note>
Reference-contexts: 1 This work was supported by a Danish SNF Research Studentship. Most of it was carried out while the author was a visiting scholar at the Computer Science Department of Stanford University and it is part of this authors ph.d. thesis Abstract In <ref> [3, 5, 7] </ref> was the dual problem for minimizing a sum of Euclidean Norms described. We will in this paper use this duality theory to develop a symmetric primal-dual Newton method for the minimizing a sum of norms problem (MSN). <p> The function P kr i k 2 is convex but is not differentiable at any point (x; r) where r i = 0 for some i 2 f1; : : : ; g. The dual is (see <ref> [7] </ref> and [3]) (D) &gt; &lt; max b T y y 2 Y with Y = fy 2 R j Ay = 0; ky i k 2 1; i = 1; : : : ; g (0.2) This pair of dual problems has several applications, both in the primal form (P <p> A related primal-dual Newton method has been proposed in <ref> [7] </ref>. An outline of the paper is: In Section 0.2 is the theoretical primal-dual method described. In Section 0.3 is the used Newton method described and different techniques for for improving the efficiency of the method is given. Some implementation details are given in 0.4. <p> This way of explicitly symmetries a primal-dual method is well-known from methods for Semidefinite Programming, see [1]. For a related primal-dual method for (M SN) problems independent suggested and motivated different, see <ref> [7] </ref>. <p> This have up to day not been an efficient approach, because of lack of a theory for reducing *. However with feasible dual solutions a true bound is known at the duality gap, and this can be used to reduce *. Furthermore in <ref> [7] </ref> they suggested to see * (see Section 0.2) as centering parameter, and then use a predictor-corrector method to reduce it. <p> i ) 2 2 = a i q 2 2 k y i k 2 It follows that ff d n 2 o where 0 &lt; &lt; 1 is a constant which ensures that the new point y is interior with respect to the quadratic constraints. 0.3.2 High order In <ref> [7] </ref> they suggested to incorporate Mehrotra's predictor-corrector rule, which is known to be effective in the context of primal-dual methods for linear programming [11]. <p> = X fl flr 0 i fl 2 i ) T (y 0 i ) we set ngap dgap ! 2 ngap (0.26) or if the non-barrier method is used (i.e. * constant parameter) * = ngap dgap ! 2 ngap which is equivalent to the predictor-corrector method suggested in <ref> [7] </ref>. The reduction in the duality gap is used as measure for how close the given point is to the central path of optimal points for given . <p> a large reduction means that can be set low, i.e. the center direction is given a small weight. 0.3.3 The use of recentering in the primal-dual Newton method We here look on how to improve the primal-dual Newton method, with * = seen as a penalty (centering) parameter as in <ref> [7] </ref>.
Reference: [8] <author> K.A. Brakke. </author> <title> Numerical solution of soap film dual problems. </title> <type> preprint, </type> <institution> Susquehanna University, Mathematics Department, </institution> <year> 1994. </year>
Reference: [9] <author> K.D. Andersen. </author> <title> A modified Schur complement method for handling dense columns in interior point methods for linear programming . Technical report, </title> <institution> Odense University, </institution> <year> 1994. </year> <note> Submitted to ACM Transaction on Mathematical Software. </note>
Reference-contexts: Lp 1 * = Lq (0.36) 2 L T x + H * * = b 2 (0.37) and it follows that (H * p T 2 q (0.38) The Cholesky decomposition which is used is described in [2], and how to extend for handling dense columns is described in <ref> [9] </ref> Linear constraints are handled as described in [5]. One of the advantage with the primal-dual method is that the method now have a dual feasible solution in every itera tion. This can be used to set the weight at the l 1 penalty function. <p> The cl problems contain one column which is relative dense. Using the technique described in <ref> [9] </ref> to handle this dense column, we receive the results which is shown in Table 0.7 As we can see the size of the L factor falls with up to over 25% without decreasing the numerical accuracy and with nearly the same number of iterations. <p> LP-approach for the test problems NAME jLj CPU ITE D gap L fea P fea cl30 69131 28 16 3.0e-09 6.8e-12 2.7e-13 cl99 1232072 666 24 7.2e-09 1.4e-10 2.0e-13 cl201 6367553 4769 27 9.0e-09 1.0e-07 2.7e-13 Table 0.7: Results for "clN" with SPDMSN, using the dense column technique described in <ref> [9] </ref> for handling of dense columns make it possible to find solutions of larger problems for this type problems. 0.6 Conclusion We conclude that the described symmetric primal-dual pseudo (real for l=1) Newton method, is more efficient than the primal Newton method described in [3, 5].
Reference: [10] <author> K.D. Andersen and E. </author> <title> Christiansen and M.L. Overton. Computing limit loads by Minimizing a sum of norms. </title> <type> Preprint 30, </type> <institution> Dept. of Mathematics and Comp. Sci., Odense University, </institution> <year> 1994. </year> <note> Submitted to SIAM Journal on Scientific Computing. </note>
Reference-contexts: Computing time includes all processing except time for reading the data. For all computation have we set fi = 1 and = 0:99. We use the same test problems as in [3, 5]. The problems is described in <ref> [4, 10, 6] </ref>.
Reference: [11] <author> S. Mehrotra. </author> <title> On the implementation of a primal-dual interior point method. </title> <journal> SIAM J. on Optim., </journal> <volume> 2(4) </volume> <pages> 575-601, </pages> <year> 1992. </year> <month> 14 </month>
Reference-contexts: to the smooth approximating problem: (P * ) &gt; &gt; &gt; &lt; min i=1 kr i k 2 + * 2 2 (x; r) 2 X This method is numerically stable and efficient, but the number of iterations is larger than for primal-dual interior-point methods in linear programming (see e.g. <ref> [11] </ref>). We therefore in this paper developed a new primal-dual method for (P ) and (D), which in fact uses a number of iterations similar to primal-dual interior-point methods for linear programming. <p> where 0 &lt; &lt; 1 is a constant which ensures that the new point y is interior with respect to the quadratic constraints. 0.3.2 High order In [7] they suggested to incorporate Mehrotra's predictor-corrector rule, which is known to be effective in the context of primal-dual methods for linear programming <ref> [11] </ref>.
Reference: [12] <author> M.L. Overton. </author> <title> A quadratically convergent method for minimizing a sum of Euclidian norms. </title> <journal> Math. Programming, </journal> <volume> 27 </volume> <pages> 34-63, </pages> <year> 1983. </year> <month> 15 </month>
References-found: 12

