URL: http://www.sci.tamucc.edu/constraint95/phase.ps
Refering-URL: http://www.sci.tamucc.edu/constraint95/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An empirical investigation into the exceptionally hard problems  
Author: Andrew Davenport and Edward Tsang 
Web: fdaveat,edwardgessex.ac.uk  
Address: Colchester, Essex CO4 3SQ, United Kingdom.  
Affiliation: Department of Computer Science, University of Essex,  
Abstract: Recently "exceptionally hard" problems have been found in the easy region of problem spaces which can be orders of magnitude harder to solve than even the hardest problems in the phase transistion. However there is some uncertainty over whether this phenomena of exceptionally hard problems occurs for all algorithms, occurs only for complete algorithms or is purely algorithm dependent. The purpose of this paper is to assess the performance of a range of algorithms on problems in the easy region in order to address this issue. We present results of an empirical investigation which show that both soluble and insoluble exceptionally hard problems can occur for even very sophisticated complete search algorithms, although the likelihood of such problems oc-curing varies significantly depending on the algorithm being used to solve them. genet, an incomplete, iterative repair-based search did not encounter any soluble, exceptionally hard problems in the easy region.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Brelaz. </author> <title> New methods to color the vertices of a graph. </title> <journal> Communications of the ACM, </journal> <volume> 22(4) </volume> <pages> 251-256, </pages> <year> 1979. </year>
Reference-contexts: Figure 4 shows that for soluble problems the exceptionally hard instances occur at higher connectivities, closer to the peak in median search cost, than for fc-ff. Next we looked at using the Brelaz heuristic <ref> [1, 13] </ref> to order variables instead of the fail-first principle. The Brelaz variable ordering can be regarded as an extension of fail-first| it first selects the unlabelled variables with the smallest domains.
Reference: [2] <author> P. Cheeseman, B. Kanefsky, and W. Tay-lor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <volume> volume 1, </volume> <pages> pages 331-337, </pages> <year> 1991. </year>
Reference-contexts: Introduction Cheeseman et al <ref> [2] </ref> have shown that NP-complete problems display a phase transis-tion between regions of under-constrained, mostly soluble problems and regions of over-constrained, mostly insoluble problems as some parameter is varied. The under-constrained problems tend to be relatively easy to solve and thus form an "easy" region of the problem space. <p> We use the connectivity of the graph as a parameter to distinguish between easy and hard regions of the space of graph colouring problems <ref> [2] </ref>. Empirical evaluation For all experiments we generated graphs varying in connectivity in steps of 0.1. For the smaller sized graphs (50 and 100 nodes) we varied graph connectivity from 2.0 to 5.0.
Reference: [3] <author> A. J. Davenport, E. P. K. Tsang, C. J. Wang, and K. Zhu. GENET: </author> <title> A connectionist architecture for solving constraint satisfaction problems by iterative improvement. </title> <booktitle> In Proc, 12th National Conference on Artificial Intelligence, </booktitle> <volume> volume 1, </volume> <pages> pages 325-330, </pages> <year> 1994. </year>
Reference-contexts: We only ran incomplete algorithms on soluble problems, and required them to find a single 3-colouring. We used forward checking as our base complete search algorithm, and experimented with variable ordering and backjumping strategies 1 . We also experimented with genet <ref> [3] </ref>, an incomplete, local search algorithm based upon the min-conflicts heuristic [8] but with the ability to escape local minima. First we looked at graphs consisting of 50 nodes.
Reference: [4] <author> I.P. Gent and T. Walsh. </author> <title> Easy problems are sometimes hard. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 335-345, </pages> <year> 1994. </year>
Reference-contexts: Recently problems have been found in the easy region of problem spaces which can be orders of magnitude harder to solve than even the hardest problems in the phase transistion <ref> [4, 7, 11] </ref>. Williams and Hogg [7] have found that the hardest problems are concentrated below the phase transistion peak in median search cost and identify these problems with a second phase transistion, corresponding to the transistion between polynomial and exponential scaling of the average search cost. <p> Williams and Hogg [7] have found that the hardest problems are concentrated below the phase transistion peak in median search cost and identify these problems with a second phase transistion, corresponding to the transistion between polynomial and exponential scaling of the average search cost. Gent and Walsh <ref> [4] </ref> observe that the greatest variability in problem solving cost occurs in this region and it occurs for both soluble and insoluble problems. There is some uncertainty over whether the phenomena of exceptionally hard problems occurs for all algorithms, only occurs for all complete algorithms or is purely algorithm dependent. <p> Smith [11] concludes that some exceptionally hard problems are "inherently more difficult than other similiar problems, independently of the number of solutions they have". Gent and Walsh <ref> [4] </ref> make the weaker conjecture that the phenomena of exceptionally hard problems may occur for all complete algorithms. It is interesting to note that nobody has yet reported any exceptionally hard, soluble problems for incomplete, local search. <p> See also [9] transistion but in a region of relatively low connectivity. In fact the peak in search cost that we would expect in the phase transistion is barely recognizable in this figure. These results correspond to what has been reported in the literature on exceptionally hard problems <ref> [4, 7] </ref>. We ran forward-checking with conflict-directed backjumping and fail-first variable ordering (fc-cbj-ff) [9] on the same problem set, and present results for this algorithm in figures 3 and 4. Here we see a significant improvement in performance. <p> This is in contrast to problems in the phase transistion, which appear to be hard for all algorithms. However, Gent and Walsh <ref> [4] </ref> have observed that "the use of better heuristics appears to delay, but not postpone indefinitely, the appearance of these difficult (exceptionally hard) problems". To test this hypothesis we decided to run the algorithms on larger graphs. Our next problem set was graphs consisting of 100 nodes.
Reference: [5] <author> I.P. Gent and T. Walsh. </author> <title> The hardest random SAT problems. </title> <editor> In B. Nebel and L. Dreschler-Fischer, editors, </editor> <booktitle> KI-94: Advances in Artificial Intelligence. 18th German Annual Conference on Artificial Intelligence, </booktitle> <pages> pages 355-366. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: It is interesting to note that nobody has yet reported any exceptionally hard, soluble problems for incomplete, local search. Williams and Hogg [7] have looked at the performance of heuristic repair on graph colour-ing problems while Gent and Walsh <ref> [5] </ref> have examined the performance of gsat on easy 3-sat problems, but neither found any exceptionally hard problems for these algorithms.
Reference: [6] <author> M. Ginsberg. </author> <title> Dynamic backtracking. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 25-46, </pages> <year> 1993. </year>
Reference-contexts: It should be possible to find complete search algorithms which are better than fc-cbj-bz in solving exceptionally hard problems, for instance dynamic backtracking <ref> [6] </ref> or algorithms which use arc-consistency looka head. Similarly it may be possible to improve on the Brelaz variable ordering heuristic, since at some point it still effectively makes a random choice amongst variables.
Reference: [7] <author> T. Hogg and C.P. Williams. </author> <title> The hardest constraint problems: A double phase transistion. </title> <journal> Artificial Intelligence, </journal> <volume> 69 </volume> <pages> 359-377, </pages> <year> 1994. </year>
Reference-contexts: Recently problems have been found in the easy region of problem spaces which can be orders of magnitude harder to solve than even the hardest problems in the phase transistion <ref> [4, 7, 11] </ref>. Williams and Hogg [7] have found that the hardest problems are concentrated below the phase transistion peak in median search cost and identify these problems with a second phase transistion, corresponding to the transistion between polynomial and exponential scaling of the average search cost. <p> Recently problems have been found in the easy region of problem spaces which can be orders of magnitude harder to solve than even the hardest problems in the phase transistion [4, 7, 11]. Williams and Hogg <ref> [7] </ref> have found that the hardest problems are concentrated below the phase transistion peak in median search cost and identify these problems with a second phase transistion, corresponding to the transistion between polynomial and exponential scaling of the average search cost. <p> Gent and Walsh [4] make the weaker conjecture that the phenomena of exceptionally hard problems may occur for all complete algorithms. It is interesting to note that nobody has yet reported any exceptionally hard, soluble problems for incomplete, local search. Williams and Hogg <ref> [7] </ref> have looked at the performance of heuristic repair on graph colour-ing problems while Gent and Walsh [5] have examined the performance of gsat on easy 3-sat problems, but neither found any exceptionally hard problems for these algorithms. <p> See also [9] transistion but in a region of relatively low connectivity. In fact the peak in search cost that we would expect in the phase transistion is barely recognizable in this figure. These results correspond to what has been reported in the literature on exceptionally hard problems <ref> [4, 7] </ref>. We ran forward-checking with conflict-directed backjumping and fail-first variable ordering (fc-cbj-ff) [9] on the same problem set, and present results for this algorithm in figures 3 and 4. Here we see a significant improvement in performance.
Reference: [8] <author> S. Minton, M. Johnston, A.B. Philips, and P. Laird. </author> <title> Minimizing conflicts: a heuristic repair method for constraint satisfaction and scheduling problems. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 161-205, </pages> <year> 1992. </year>
Reference-contexts: We used forward checking as our base complete search algorithm, and experimented with variable ordering and backjumping strategies 1 . We also experimented with genet [3], an incomplete, local search algorithm based upon the min-conflicts heuristic <ref> [8] </ref> but with the ability to escape local minima. First we looked at graphs consisting of 50 nodes.
Reference: [9] <author> P. Prosser. </author> <title> Hybrid algorithms for the constraint satisfaction problem. </title> <journal> Computational Intelligence, </journal> <volume> 9(3) </volume> <pages> 268-299, </pages> <year> 1993. </year>
Reference-contexts: Here the hardest problems for fc-ff, soluble and insoluble, do not occur in the phase 1 Forward-checking and other algorithms used in this paper are described in [12]. See also <ref> [9] </ref> transistion but in a region of relatively low connectivity. In fact the peak in search cost that we would expect in the phase transistion is barely recognizable in this figure. These results correspond to what has been reported in the literature on exceptionally hard problems [4, 7]. <p> In fact the peak in search cost that we would expect in the phase transistion is barely recognizable in this figure. These results correspond to what has been reported in the literature on exceptionally hard problems [4, 7]. We ran forward-checking with conflict-directed backjumping and fail-first variable ordering (fc-cbj-ff) <ref> [9] </ref> on the same problem set, and present results for this algorithm in figures 3 and 4. Here we see a significant improvement in performance. The hardest problems are still in the easy region, however these exceptionally hard problems are mostly insoluble.
Reference: [10] <author> P. Prosser. </author> <title> Exceptionally hard problems. USENET Article 3473dh$27c@@todd-06.cs.strath.ac.uk, </title> <address> comp.constraints, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: that there are no exceptionally hard problems for local search ? If this is the case should we always prefer local search to complete search when tackling problems in the easy region, or can we avoid exceptionally hard problems for complete search by using more sophisticated algorithms ? As Prosser <ref> [10] </ref> puts it, are exceptionally hard problems merely existence proofs for exceptionally bad algorithms ? In this paper we try to go some way towards tackling these issues.
Reference: [11] <author> B. M. Smith. </author> <title> In search of exceptionally difficult constraint satisfaction problems. </title> <booktitle> In 11th European Conference on Artificial Intelligence, Workshop on Constraint Processing, </booktitle> <pages> pages 79-86, </pages> <year> 1994. </year>
Reference-contexts: Recently problems have been found in the easy region of problem spaces which can be orders of magnitude harder to solve than even the hardest problems in the phase transistion <ref> [4, 7, 11] </ref>. Williams and Hogg [7] have found that the hardest problems are concentrated below the phase transistion peak in median search cost and identify these problems with a second phase transistion, corresponding to the transistion between polynomial and exponential scaling of the average search cost. <p> There is some uncertainty over whether the phenomena of exceptionally hard problems occurs for all algorithms, only occurs for all complete algorithms or is purely algorithm dependent. Smith <ref> [11] </ref> concludes that some exceptionally hard problems are "inherently more difficult than other similiar problems, independently of the number of solutions they have". Gent and Walsh [4] make the weaker conjecture that the phenomena of exceptionally hard problems may occur for all complete algorithms. <p> Furthermore the shape of the 100% percentile for genet appears to be becoming more stable as we increase the size of the graph. Discussion Smith <ref> [11] </ref> identifies a number of possible reasons for the occurence of exceptionally hard problems: "The problem has no solutions when most problems in the same region of the problem space have many solutions." We have found insoluble problems in the easy region which can be exceptionally hard to prove insoluble for <p> soluble problems in the easy region. "The problem may have many solutions but they are clustered together in a limited region of the search space, and, because of the variable and value ordering, the algorithm will not reach any solutions until it has traversed most of the search space." Smith <ref> [11] </ref> cites this as the reason why some problems are inherently more difficult than others, independently of the number of solutions they have.
Reference: [12] <author> E.P.K. Tsang. </author> <title> Foundations of Constraint Satisfaction. </title> <publisher> Academic Press, </publisher> <year> 1993. </year>
Reference-contexts: Here the hardest problems for fc-ff, soluble and insoluble, do not occur in the phase 1 Forward-checking and other algorithms used in this paper are described in <ref> [12] </ref>. See also [9] transistion but in a region of relatively low connectivity. In fact the peak in search cost that we would expect in the phase transistion is barely recognizable in this figure.
Reference: [13] <author> J. S. Turner. </author> <title> Almost all k-colorable graphs are easy to color. </title> <journal> Journal of Algorithms, </journal> <volume> 9 </volume> <pages> 63-82, </pages> <year> 1988. </year>
Reference-contexts: Figure 4 shows that for soluble problems the exceptionally hard instances occur at higher connectivities, closer to the peak in median search cost, than for fc-ff. Next we looked at using the Brelaz heuristic <ref> [1, 13] </ref> to order variables instead of the fail-first principle. The Brelaz variable ordering can be regarded as an extension of fail-first| it first selects the unlabelled variables with the smallest domains.
References-found: 13

