URL: ftp://ftp.cs.umass.edu/pub/anw/pub/duff/nips94b.ps.Z
Refering-URL: http://www-anw.cs.umass.edu/People/duff/duff_papers.html
Root-URL: 
Email: duff@cs.umass.edu  
Title: POSTER Control, Navigation, and Planning: Theoretical analysis. A Control Variable Perspective for the Optimal Combination
Author: Michael O. Duff 
Address: Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: This paper details further development of an idea first suggested in (Barto & Duff, 1994)|that of bringing variance reduction techniques to bear upon the problem of optimally combining corrected truncated returns.
Abstract-found: 1
Intro-found: 1
Reference: <author> A. Barto & M. O. </author> <title> Duff (1994). Monte Carlo Matrix Inversion and Reinforcement Learning. </title> <editor> In D. S. Touretzky (ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 5. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In <ref> (Barto & Duff, 1994) </ref>, it was suggested that the estimators X [k] could be interpreted as what are known as "control variables" in the literature of Monte Carlo variance reduction techniques.
Reference: <author> P. </author> <title> Billingsley (1961). Statistical Inference for Markov Processes Univerity of Chicago Press. </title>
Reference-contexts: These are the maximum-liklihood estimates of P and R given the observed data, and one may derive confidence intervals for ^ P and ^ R as well (Nanthi & Wassan, 1987) <ref> (Billingsley, 1961) </ref>.
Reference: <author> P. Dupuis & R. </author> <month> Simha </month> <year> (1991). </year> <title> On sampling controlled stochastic approximation. </title> <booktitle> IEEE-TAC 36 </booktitle> <pages> 915-924. </pages>
Reference-contexts: More recently, <ref> (Dupuis & Simha, 1991) </ref> have suggested taking multiple samples at given operating points to reduce variance. Apart from these acceleration schemes for improving the standard algorithm, it should be noted that stochastic approximation is a rather general method for computing roots of noisy (nonlinear) regression functions.
Reference: <author> P. </author> <month> Gutman </month> <year> (1981). </year> <title> Stabilizing Controllers for Bilinear Systems. </title> <booktitle> IEEE-TAC 26(4), </booktitle> <pages> pp. 917-922. </pages>
Reference-contexts: This is a disrete-time, stochastic, bilinear system (Mohler, 1980) that we would like to drive to zero as quickly as possible (through choice of ff), and there exist advanced methods for doing so <ref> (e.g., Gutman, 1981) </ref>.
Reference: <author> R. </author> <title> Jacobs (1988). Increased Rates of Convergence Through Learning Rate Adaptation. </title> <booktitle> Neural Networks 1 </booktitle> <pages> 295-307. </pages>
Reference-contexts: Some final comments regarding Figure 4: Since the early 1950's when Stochastic Approximation was first introduced, there have been a number of schemes proposed for accelerating convergence. Among them, (Kesten, 1958) suggests maintaining step size at nomimal values until a change in sign of successive estimates occurs; <ref> (Jacobs, 1988) </ref> is recent related work. (Venter, 1967)'s method accelerates the rate of convergence by, in effect, estimating the slope of the underlying regression function at the desired root. More recently, (Dupuis & Simha, 1991) have suggested taking multiple samples at given operating points to reduce variance.
Reference: <author> H. </author> <month> Kesten </month> <year> (1958). </year> <title> Accelerated Stochastic Approximation. </title> <journal> Ann. Math. Statist. </journal> <volume> 29 </volume> <pages> 41-59. </pages>
Reference-contexts: Some final comments regarding Figure 4: Since the early 1950's when Stochastic Approximation was first introduced, there have been a number of schemes proposed for accelerating convergence. Among them, <ref> (Kesten, 1958) </ref> suggests maintaining step size at nomimal values until a change in sign of successive estimates occurs; (Jacobs, 1988) is recent related work. (Venter, 1967)'s method accelerates the rate of convergence by, in effect, estimating the slope of the underlying regression function at the desired root.
Reference: <author> S. Lavenberg & P. </author> <title> Welch (1981). A perspective on the use of Control Variables to increase the efficiency of Monte-Carlo simulations. </title> <booktitle> Management Science 27 </booktitle> <pages> 322-335. </pages>
Reference-contexts: In (Barto & Duff, 1994), it was suggested that the estimators X [k] could be interpreted as what are known as "control variables" in the literature of Monte Carlo variance reduction techniques. A control variable <ref> (Lavenberg & Welch, 1981) </ref> for a random variable Y , whose expected value, , we are trying to estimate, is another random variable, C, that is correlated with Y and whose expected value is known or known to be the same as Y 0 s.
Reference: <author> R. Mohler & W. </author> <month> Kolodzki </month> <year> (1980). </year> <title> An Overview of Stochastic Bilinear Control Systems. </title> <journal> IEEE-TAC pp. </journal> <pages> 917-922. </pages>
Reference-contexts: The error equation may be approximated by * (k+1) = I* (k) + (flP I)ff* (k) + ffw, where w is vector of normal, mean-zero noise. This is a disrete-time, stochastic, bilinear system <ref> (Mohler, 1980) </ref> that we would like to drive to zero as quickly as possible (through choice of ff), and there exist advanced methods for doing so (e.g., Gutman, 1981).
Reference: <author> A. Moore & C. </author> <title> Atkeson (1993). Prioritized Sweeping: Reinforcement Learning with Less Data. </title> <booktitle> Machine Learning 13 </booktitle> <pages> 103-130. </pages>
Reference-contexts: The update gives the exact inverse. Gauss-Seidel takes number-of-contractions fiN 2 per observation, where number-of-contractions depends on the accuracy desired and is usually small but may occasionally spike to &gt; N operations. Prioritized Sweeping <ref> (Moore, 1993) </ref> makes use of maximum liklihood estimates (8) as well and empirically outperforms Gauss-Seidel.
Reference: <author> K. Nanthi & M. </author> <month> Wassan </month> <year> (1987). </year> <title> Statistical Estimation for Stochastic Processes, </title> <booktitle> Queen's Papers in Pure and Applied Mathematics, </booktitle> <volume> no. </volume> <pages> 78. </pages>
Reference-contexts: These are the maximum-liklihood estimates of P and R given the observed data, and one may derive confidence intervals for ^ P and ^ R as well <ref> (Nanthi & Wassan, 1987) </ref> (Billingsley, 1961).
Reference: <author> R. </author> <title> Sutton (1988). Learning to Predict by the Method of Temporal Differences. </title> <booktitle> Machine Learning 3 </booktitle> <pages> 9-44. </pages>
Reference-contexts: It is well known that V uniquely satifies a linear system of equations decribing local consistency: V = R + flP V: One way (Watkins, 1989) of viewing the TD () algorithm <ref> (Sutton, 1988) </ref> is that it updates its current value function estimate ~ V (x t ) in the direction of a weighted combination of the following (infinite) family of estimators: X [k] = r t + flr t+1 + fl k1 r t+k1 + fl k ~ V (x t+k )
Reference: <author> J. </author> <title> Venter (1967). An Extension of the Robbins-Monro procedure. </title> <journal> Ann. Math. Statist. </journal> <volume> 38 </volume> <pages> 181-190. </pages>
Reference-contexts: Among them, (Kesten, 1958) suggests maintaining step size at nomimal values until a change in sign of successive estimates occurs; (Jacobs, 1988) is recent related work. <ref> (Venter, 1967) </ref>'s method accelerates the rate of convergence by, in effect, estimating the slope of the underlying regression function at the desired root. More recently, (Dupuis & Simha, 1991) have suggested taking multiple samples at given operating points to reduce variance.
Reference: <author> C. </author> <title> Watkins (1989). Learning from Delayed Rewards. </title> <type> PhD Thesis Cambridge University. </type>
Reference-contexts: It is well known that V uniquely satifies a linear system of equations decribing local consistency: V = R + flP V: One way <ref> (Watkins, 1989) </ref> of viewing the TD () algorithm (Sutton, 1988) is that it updates its current value function estimate ~ V (x t ) in the direction of a weighted combination of the following (infinite) family of estimators: X [k] = r t + flr t+1 + fl k1 r t+k1
References-found: 13

