URL: http://www.cs.cmu.edu/afs/cs/usr/pstone/public/papers/97robot-paper/robot-paper.ps.gz
Refering-URL: http://www.cs.cmu.edu/~robosoccer/old-page.html
Root-URL: 
Email: fmmv,pstone,kwunhg@cs.cmu.edu  
Title: The CMUnited-97 Robotic Soccer Team: Perception and Multiagent Control autonomous robots; multi-agent teams; coordinating perception,
Author: Manuela Veloso Peter Stone Kwun Han 
Date: October 1997  
Note: Submitted to Autonomous Agents '98,  Abstract Content Areas:  
Web: http://www.cs.cmu.edu/fmmv,pstone,kwunhg  
Address: Pittsburgh, PA 15213  
Affiliation: Computer Science Department Carnegie Mellon University  
Abstract: Robotic soccer is a challenging research domain which involves multiple agents that need to collaborate in an adversarial environment to achieve specific objectives. In this paper, we describe CMUnited, the team of small robotic agents that we developed to enter the RoboCup-97 competition. We designed and built the robotic agents, devised the appropriate vision algorithm, and developed and implemented algorithms for strategic collaboration between the robots in an uncertain and dynamic environment. The robots can organize themselves in formations, hold specific roles, and pursue their goals. In game situations, they have demonstrated their collaborative behaviors on multiple occasions. The robots can also switch roles to maximize the overall performance of the team. We present an overview of the vision processing algorithm which successfully tracks multiple moving objects and predicts trajectories. The paper then focusses on the agent behaviors ranging from low-level individual behaviors to coordinated, strategic team behaviors. CMUnited won the RoboCup-97 small-robot competition at IJCAI-97 in Nagoya, Japan. fl We thank Sorin Achim for developing and building the robots. This research is sponsored in part by the Defense Advanced Research Projects Agency (DARPA), and Rome Laboratory, Air Force Materiel Command, USAF, under agreement number F30602-95-1-0018 and in part by the Department of the Navy, Office of Naval Research under contract number N00014-95-1-0591. Views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of the Air Force, of the Department of the Navy, Office of Naval Research or the United States Government. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sorin Achim, Peter Stone, and Manuela Veloso. </author> <title> Building a dedicated robotic soccer system. </title> <booktitle> In Proceedings of the IROS-96 Workshop on RoboCup, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: We developed the physical robots as actuators, a vision processing algorithm to perceive the world, and strategic reasoning for individual and collaborative behaviors. The team is clearly not a perfect version of our multiple autonomous agents. We have developed previous versions of the team <ref> [1] </ref>, and, as presented in the discussion and conclusion section, we are currently (and will continue) improving the team further.
Reference: [2] <author> M. Asada, S. Noda, S. Tawaratumida, and K. Hosoda. </author> <title> Purposive behavior acquisition for a real robot by vision-based reinforcement learning. </title> <journal> Machine Learning, </journal> <volume> 23:279 303, </volume> <year> 1996. </year>
Reference-contexts: All have found that the reactiveness of soccer robots requires vi 3 sion system with a high processing cycle time. However, due to the rich visual input, researchers have found that dedicated processors or even DSPs are often needed <ref> [2, 8] </ref>. The system we used at RoboCup-97 was surprisingly simple. A framegrabber with framerate transfer from a 3-CCD camera was used as the input. A relatively slow processor (166Mhz Pentium) was at the heart of the system, performing all computation. The detection mechanism was kept as simple as possible.
Reference: [3] <author> Minoru Asada, Yasuo Kuniyoshi, Alexi Drogoul, Hajime Asama, Maja Mataric, Dominique Duhaut, Peter Stone, and Hiroaki Kitano. </author> <title> The robocup physical agent challenge: </title> <journal> Phase-i. </journal> <note> To appear in Applied Artificial Intelligence (AAI) Journal, </note> <year> 1998. </year>
Reference-contexts: Robotic soccer is an example of such complex tasks for which multiple agents need to collaborate in an adversarial environment to achieve specific objectives. Robotic soccer offers a challenging research domain to investigate a large spectrum of issues of relevance to the development of complete autonomous agents <ref> [7, 3] </ref>. The fast-paced nature of the domain necessitates real-time sensing coupled with quick behaving and decision making.
Reference: [4] <author> V. Braitenburg. </author> <title> Vehicles experiments in synthetic psychology. </title> <publisher> MIT Press, </publisher> <year> 1984. </year> <month> 15 </month>
Reference-contexts: All of these skills must be executed while avoiding obstacles such as the walls and other robots. The navigational movement control is done via closed-loop reactive control. The control strategy follows a modified version of a simple Braitenburg vehicle <ref> [4] </ref>. The Braitenburg love vehicle defines a reactive control mechanism that directs a differentially driven robot to a certain destination point (goal).
Reference: [5] <author> Kwun Han and Manuela Veloso. </author> <title> Physical model based multi-objects tracking and prediction in robosoccer. </title> <booktitle> In Working Note of the AAAI 1997 Fall Symposium. </booktitle> <publisher> AAAI, MIT Press, </publisher> <year> 1997. </year>
Reference-contexts: Like for real soccer players, it is often essential for robots to predict future locations of the ball (or even of the other players). We have used an Extended Kalman filter (EKF) for such a purpose <ref> [5] </ref>. The Kalman filter is very suitable for such a purpose since the detection of the ball's location is noisy. The EKF is a recursive estimator for a possibly non-linear system. The goal of the filter is to estimate the state of a system.
Reference: [6] <author> Hiroaki Kitano, Yasuo Kuniyoshi, Itsuki Noda, Minoru Asada, Hitoshi Matsubara, and Ei-Ichi Osawa. </author> <title> Robocup: A challenge problem for ai. </title> <journal> AI Magazine, </journal> <volume> 18(1):73 85, </volume> <month> Spring </month> <year> 1997. </year>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. We have been pursuing research in the robotic soccer domain within the RoboCup initiative <ref> [6] </ref>, which, in 1997, included a simulator league and small-size and medium-size robot leagues. We have been doing research extensively in the simulator league, developing learning techniques and team strategies in simulation [12, 11]. Many of these team strategies were directly incorporated into the robotic system described here.
Reference: [7] <author> Hiroaki Kitano, Milind Tambe, Peter Stone, Manuela Veloso, Silvia Coradeschi, Eiichi Osawa, Hitoshi Matsubara, Itsuki Noda, and Minoru Asada. </author> <title> The robocup synthetic agent challenge 97. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> San Francisco, CA, 1997. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Robotic soccer is an example of such complex tasks for which multiple agents need to collaborate in an adversarial environment to achieve specific objectives. Robotic soccer offers a challenging research domain to investigate a large spectrum of issues of relevance to the development of complete autonomous agents <ref> [7, 3] </ref>. The fast-paced nature of the domain necessitates real-time sensing coupled with quick behaving and decision making.
Reference: [8] <author> Michael K. Sahota, Alan K. Mackworth, Rod A. Barman, and Stewart J. Kingdon. </author> <title> Real-time control of soccer-playing robots using off-board vision: the dynamite testbed. </title> <booktitle> In IEEE International Conference on Systems, Man, and Cybernetics, </booktitle> <pages> pages 36903663, </pages> <year> 1995. </year>
Reference-contexts: This section focusses on presenting our vision processing algorithm whose accuracy makes it a major contribution towards the success of our team. 2.1 Detection The vision requirements for robotic soccer have been examined by different researchers <ref> [8, 9] </ref>. Systems with on-board and off-board types have appeared in recent years. All have found that the reactiveness of soccer robots requires vi 3 sion system with a high processing cycle time. <p> All have found that the reactiveness of soccer robots requires vi 3 sion system with a high processing cycle time. However, due to the rich visual input, researchers have found that dedicated processors or even DSPs are often needed <ref> [2, 8] </ref>. The system we used at RoboCup-97 was surprisingly simple. A framegrabber with framerate transfer from a 3-CCD camera was used as the input. A relatively slow processor (166Mhz Pentium) was at the heart of the system, performing all computation. The detection mechanism was kept as simple as possible.
Reference: [9] <author> Randy Sargent, Bill Bailey, Carl Witty, and Anne Wright. </author> <title> Dynamic object capture using fast vision tracking. </title> <journal> AI Magazine, </journal> <volume> 18(1):6572, </volume> <month> Spring </month> <year> 1997. </year>
Reference-contexts: This section focusses on presenting our vision processing algorithm whose accuracy makes it a major contribution towards the success of our team. 2.1 Detection The vision requirements for robotic soccer have been examined by different researchers <ref> [8, 9] </ref>. Systems with on-board and off-board types have appeared in recent years. All have found that the reactiveness of soccer robots requires vi 3 sion system with a high processing cycle time.
Reference: [10] <author> Peter Stone and Manuela Veloso. </author> <title> Task decomposition and dynamic role assignment for real-time strategic teamwork. </title> <booktitle> In submitted to the Third International Conference on Multi-Agent Systems, </booktitle> <month> November </month> <year> 1997. </year> <note> Draft available by request or from http://www.cs.cmu.edu/ pstone/pstone-papers.html. </note>
Reference-contexts: These high-level, multiagent behaviors were originally developed in simulation and then transferred over to the robot-control code. Only the run-time passing evaluation function was redefined. Further details, particularly about the flexible team structures, are available in <ref> [10] </ref>. 9 3.2.1 Positions, Formations, and Active Modes Positions are defined as flexible regions within which the player attempts to move towards the ball. <p> On the other hand, if winning, they might choose a defensive formation. The precise conditions for switching positions and formations are decided upon in advance, in what we call a locker-room agreement, <ref> [10] </ref> in order to eliminate the need for 10 complex on-line negotiation protocols. Although the default action of each robot is to go to its position and face the ball, there are three active modes from which the robot must choose.
Reference: [11] <author> Peter Stone and Manuela Veloso. </author> <title> Using decision tree confidence factors for mul-tiagent control. </title> <booktitle> In Proceedings of the First International Workshop on RoboCup, </booktitle> <address> Nagoya,Japan, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: We have been pursuing research in the robotic soccer domain within the RoboCup initiative [6], which, in 1997, included a simulator league and small-size and medium-size robot leagues. We have been doing research extensively in the simulator league, developing learning techniques and team strategies in simulation <ref> [12, 11] </ref>. Many of these team strategies were directly incorporated into the robotic system described here. We eventually hope also to transfer these learning techniques to the real system as we develop a complete Robotic Soccer architecture.
Reference: [12] <author> Peter Stone and Manuela Veloso. </author> <title> A layered approach to learning client behaviors in the robocup soccer server. </title> <note> To appear in Applied Artificial Intelligence (AAI) Journal, </note> <year> 1998. </year>
Reference-contexts: We have been pursuing research in the robotic soccer domain within the RoboCup initiative [6], which, in 1997, included a simulator league and small-size and medium-size robot leagues. We have been doing research extensively in the simulator league, developing learning techniques and team strategies in simulation <ref> [12, 11] </ref>. Many of these team strategies were directly incorporated into the robotic system described here. We eventually hope also to transfer these learning techniques to the real system as we develop a complete Robotic Soccer architecture.
Reference: [13] <author> Manuela Veloso, Peter Stone, Kwun Han, and Sorin Achim. Cmunited: </author> <title> A team of robotic soccer agents collaborating in an adversarial environment. </title> <booktitle> In Proceedings of the First International Workshop on RoboCup, </booktitle> <address> Nagoya,Japan, </address> <month> August </month> <year> 1997. </year> <month> 16 </month>
Reference-contexts: The combination of robust hardware, real-time vision, and intelligent control code represented a significant challenge which we were able to successfully meet. The work described in this paper is all fully implemented. Figure 1 shows a picture of our robotic agents. For the hardware description of our robots, see <ref> [13] </ref>. This paper is organized as follows: Section 2 presents the vision processing algorithm. In Section 3, we focus on the agent behaviors ranging from low-level individual behaviors, to coordinated, strategic, multiagent behaviors. <p> Figure 2 sketches the building blocks of the architecture. The complete system is fully autonomous consisting of a well-defined and challenging processing cycle. The global vision algorithm perceives the dynamic 1 For hardware details and specifications of the robots, please see <ref> [13] </ref>. 2 environment and processes the images, giving the positions of each robot and the ball. This information is sent to an off-board controller and distributed to the different agent algorithms. Each agent evaluates the world state and uses its strategic knowledge to decide what to do next.
References-found: 13

