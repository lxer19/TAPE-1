URL: http://www.cs.rpi.edu/~stewart/papers/bias_revised.ps.gz
Refering-URL: http://www.cs.rpi.edu/~stewart/
Root-URL: http://www.cs.rpi.edu
Email: stewart@cs.rpi.edu  
Title: Bias in Robust Estimation Caused by Discontinuities and Multiple Structures  
Author: Charles V. Stewart 
Note: which was described in [25].  
Date: November 27, 1996  
Address: Troy, New York 12180-3590  
Affiliation: Department of Computer Science Rensselaer Polytechnic Institute  
Abstract: When fitting models to data containing multiple structures, such as when fitting surface patches to data taken from a neighborhood that includes a range discontinuity, robust estimators must tolerate both gross outliers and pseudo outliers. Pseudo outliers are outliers to the structure of interest, but inliers to a different structure. They differ from gross outliers because of their coherence. Such data occurs frequently in computer vision problems, including motion estimation, model fitting and range data analysis. The focus in this paper is the problem of fitting surfaces near discontinuities in range data. To characterize the performance of least median of squares, least trimmed squares, M-estimators, Hough transforms, RANSAC, and MINPRAN on this type of data, the "pseudo outlier bias" metric is developed using techniques from the robust statistics literature, and it is used to study the error in robust fits caused by distributions modeling various types of discontinuities. The results show each robust estimator to be biased at small but substantial discontinuities. They also show the circumstances under which different estimators are most effective. Most importantly, the results imply present estimators should be used with care and new estimators should be developed. fl This paper presents a substantial reformulation and improvement of an earlier version of this work, 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ayer and H. Sawhney. </author> <title> Layered representation of motion video using robust maximum likelihood estimation of mixture models and MDL encoding. </title> <booktitle> In Proceedings IEEE International Conference on Computer Vision, </booktitle> <pages> pages 777-784, </pages> <year> 1995. </year>
Reference-contexts: Discontinuity Models and Search scale invariance of both the estimators and pseudo outlier bias, along with several realistic assumptions, allow these discontinuities to be described with just a few parameters. (Refer back to Section 3 for the exact parameter definitions.) For all models, = 1:0 and the x interval is <ref> [0; 1] </ref>. For step edges, fi 1 (x) = 0 and fi 2 (x) = z= | retaining the parameter to make clear the scale invariance | and x 1;0 = 0, x 2;1 = 1, and x 1;1 = x 2;0 = x d . <p> As a final observation, although the results are presented for one-dimensional image domains, they have immediate extension to two dimensions. For example, a two-dimensional analog of the step edge presented here is fi 1 (x; y) = 0 for x 2 [0; x d ] and y 2 <ref> [0; 1] </ref> and fi 2 (x; y) = z= for x 2 [x d ; 1] and y 2 [0; 1]. <p> For example, a two-dimensional analog of the step edge presented here is fi 1 (x; y) = 0 for x 2 [0; x d ] and y 2 [0; 1] and fi 2 (x; y) = z= for x 2 <ref> [x d ; 1] </ref> and y 2 [0; 1]. It is straightforward to show that this model results in exactly the same pseudo outlier bias as a one-dimensional step model having the same mixture parameters and gross outlier distribution. <p> For example, a two-dimensional analog of the step edge presented here is fi 1 (x; y) = 0 for x 2 [0; x d ] and y 2 <ref> [0; 1] </ref> and fi 2 (x; y) = z= for x 2 [x d ; 1] and y 2 [0; 1]. It is straightforward to show that this model results in exactly the same pseudo outlier bias as a one-dimensional step model having the same mixture parameters and gross outlier distribution. Similar results are obtained for natural extensions of the crease edge and parallel lines models. <p> negative results indicate that care should be used when robustly estimating surface parameters in range data, either to obtain local low-order surface approximations or to initialize fits for surface growing algorithms [3, 5, 6, 15]. (Similar problems may occur for the "layers" techniques that have been applied to motion analysis <ref> [1, 6, 28] </ref>.) Robust estimates will be accurate for large scale depth discontinuties and sharp corners, but will be skewed at small magnitude discontinuites, such as near the boundary of a slightly raised or depressed area of a surface.
Reference: [2] <author> P. J. Besl, J. B. Birch, and L. T. Watson. </author> <title> Robust window operators. </title> <booktitle> In Proceedings IEEE International Conference on Computer Vision, </booktitle> <pages> pages 591-600, </pages> <year> 1988. </year>
Reference-contexts: The hard redescending, fixed-scale M-estimator can be made less biased by reducing the values of its tuning parameters, as shown in Figure 8 (b), effectively narrowing h and reducing its finite rejection point. (The parameter set a = 1:0, b = 1:0, c = 2:0 comes from <ref> [2] </ref>; the set a = 1:0, b = 2:0, c = 3:0 was chosen as an intermediate set of values.) Using small parameter values has two disadvantages, however: the optimum statistical efficiency of the standard parameters is lost, giving less accurate fits to the target distribution, and some good data may
Reference: [3] <author> P. J. Besl and R. C. Jain. </author> <title> Segmentation through variable-order surface fitting. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10 </volume> <pages> 167-192, </pages> <year> 1988. </year> <month> 35 </month>
Reference-contexts: When fitting surfaces to range data, a different option for obtaining ^ is often used <ref> [3] </ref>. If depends only on the properties of the sensor then ^ may be estimated once and fixed for all data sets. Theoretically, when ^ is fixed, the M-estimators described by equation 1 are no longer true M-estimators since they are not scale equivariant [10, page 259]. <p> recommendations, which depend on what is known about the data, were made for choosing between current techniques. 6 These negative results indicate that care should be used when robustly estimating surface parameters in range data, either to obtain local low-order surface approximations or to initialize fits for surface growing algorithms <ref> [3, 5, 6, 15] </ref>. (Similar problems may occur for the "layers" techniques that have been applied to motion analysis [1, 6, 28].) Robust estimates will be accurate for large scale depth discontinuties and sharp corners, but will be skewed at small magnitude discontinuites, such as near the boundary of a slightly
Reference: [4] <author> R. C. Bolles and M. A. Fischler. </author> <title> A Ransac-based approach to model fitting and its application to finding cylinders in range data. </title> <booktitle> In Proceedings Seventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 637-643, </pages> <year> 1981. </year>
Reference-contexts: To reflect this, when ^ is fixed a priori, they are called "fixed-scale M-estimators." Both standard M-estimators and fixed-scale M-estimators are studied here. 6 2.2 Fixed-Band Techniques: Hough Transforms and RANSAC Hough transforms [13], RANSAC <ref> [4, 7] </ref>, and Roth's primitive extractor [20] are examples of "fixed-band" techniques [20]. For these techniques, ^ is the fit maximizing the number of points within r b , where r b is an inlier bound which generally depends on ^ (i.e. r b = c^ for some constant c).
Reference: [5] <author> K. L. Boyer, M. J. Mirza, and G. Ganguly. </author> <title> The Robust Sequential Estimator: A general approach and its application to surface organization in range data. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16 </volume> <pages> 987-1001, </pages> <year> 1994. </year>
Reference-contexts: Hard redescenders (Figure 2b), such as Hampel's [9] [10, page 150], force (u) = 0 for juj &gt; c; hence c is a rejection point, beyond which a residual has no influence. Soft redescenders (Figure 2c), such as the maximum likelihood estimator of Student's t-distribution <ref> [5] </ref>, do not have a finite rejection point, but force (u) ! 0 as juj ! 1. <p> and ^ as ( ^ ; ^) = argmin ; i In particular, Huber [12, Chapter 7] uses m (r i; ; ) = [ m (r i; =) + a]; (7) where m (r i; =) is from equation 2 and a is a tuning parameter; Mirza and Boyer <ref> [5] </ref> use s (r i; ; ) = ln + s (r i; =); (8) where s (r i; =) is from equation 4. When fitting surfaces to range data, a different option for obtaining ^ is often used [3]. <p> The example fit shown is ^ (x) for the hard redescending, fixed-scale M-estimator. latter is the maximum likelihood estimate for Student's t distribution <ref> [5] </ref>. distribution and plot "Hard-t" for the t-distribution). Results for the monotone M-estimator are not shown since its bias matches that of least-squares almost exactly. Overall, the results are substantially worse than for fixed-scale M-estimators, especially for " s = 0:6. <p> recommendations, which depend on what is known about the data, were made for choosing between current techniques. 6 These negative results indicate that care should be used when robustly estimating surface parameters in range data, either to obtain local low-order surface approximations or to initialize fits for surface growing algorithms <ref> [3, 5, 6, 15] </ref>. (Similar problems may occur for the "layers" techniques that have been applied to motion analysis [1, 6, 28].) Robust estimates will be accurate for large scale depth discontinuties and sharp corners, but will be skewed at small magnitude discontinuites, such as near the boundary of a slightly
Reference: [6] <author> T. Darrell and A. Pentland. </author> <title> Cooperative robust estimation using layers of support. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17 </volume> <pages> 474-487, </pages> <year> 1995. </year>
Reference-contexts: recommendations, which depend on what is known about the data, were made for choosing between current techniques. 6 These negative results indicate that care should be used when robustly estimating surface parameters in range data, either to obtain local low-order surface approximations or to initialize fits for surface growing algorithms <ref> [3, 5, 6, 15] </ref>. (Similar problems may occur for the "layers" techniques that have been applied to motion analysis [1, 6, 28].) Robust estimates will be accurate for large scale depth discontinuties and sharp corners, but will be skewed at small magnitude discontinuites, such as near the boundary of a slightly <p> negative results indicate that care should be used when robustly estimating surface parameters in range data, either to obtain local low-order surface approximations or to initialize fits for surface growing algorithms [3, 5, 6, 15]. (Similar problems may occur for the "layers" techniques that have been applied to motion analysis <ref> [1, 6, 28] </ref>.) Robust estimates will be accurate for large scale depth discontinuties and sharp corners, but will be skewed at small magnitude discontinuites, such as near the boundary of a slightly raised or depressed area of a surface.
Reference: [7] <author> M. A. Fischler and R. C. Bolles. </author> <title> Random Sample Consensus: A paradigm for model fitting with applications to image analysis and automated cartography. </title> <journal> CACM, </journal> <volume> 24 </volume> <pages> 381-395, </pages> <year> 1981. </year>
Reference-contexts: The bias of a number of estimators | M-estimators [12, Chapter 7], least median of squares (LMS) [16, 21], least trimmed squares (LTS) [21], Hough transforms [13], RANSAC <ref> [7] </ref>, and MINPRAN [26] | will be studied as the target and mixture distributions vary. The application for studying the pseudo outliers problem is fitting surfaces to range data taken from the neighborhood of a surface discontinuity. <p> To reflect this, when ^ is fixed a priori, they are called "fixed-scale M-estimators." Both standard M-estimators and fixed-scale M-estimators are studied here. 6 2.2 Fixed-Band Techniques: Hough Transforms and RANSAC Hough transforms [13], RANSAC <ref> [4, 7] </ref>, and Roth's primitive extractor [20] are examples of "fixed-band" techniques [20]. For these techniques, ^ is the fit maximizing the number of points within r b , where r b is an inlier bound which generally depends on ^ (i.e. r b = c^ for some constant c).
Reference: [8] <author> J. D. Gaskill. </author> <title> Linear Systems, Fourier Transforms, and Optics. </title> <publisher> John Wiley and Sons, </publisher> <year> 1978. </year>
Reference-contexts: When the x i 's are independent and identically distributed, F n converges to F as n ! 1. The least squares location estimate is written in terms of the empirical density by using the sifting property of the delta function <ref> [8, page 56] </ref>: argmin n i (x i ) 2 = argmin n i (x ) 2 ffi (x x i ) dx = argmin (x ) 2 1 X ffi (x x i ) dx = argmin (x ) 2 f n (x) dx Replacing f n with the population <p> Next, the empirical density of the signed residuals follows from h n (x; z) using the sifting property of the ffi function <ref> [8, page 56] </ref>: f s Z 1 h n (x; (x)+r) dx Z 1 1 X ffi (xx i ; (x)+rz i ) dx 1 X ffi ((x i )+rz i ) Finally, the empirical distribution of the absolute residuals is F a Z r f s 4.4 M-Estimators and Fixed-Band
Reference: [9] <author> F. R. Hampel, P. J. Rousseeuw, and E. Ronchetti. </author> <title> The change-of-variance curve and optimal redescending M-estimators. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 76 </volume> <pages> 643-648, </pages> <year> 1981. </year>
Reference-contexts: Monotone M-estimators (Figure 2a), such as Huber's [12, Chapter 7], have non-decreasing, bounded (u) functions. Hard redescenders (Figure 2b), such as Hampel's <ref> [9] </ref> [10, page 150], force (u) = 0 for juj &gt; c; hence c is a rejection point, beyond which a residual has no influence.
Reference: [10] <author> F. R. Hampel, P. J. Rousseeuw, E. Ronchetti, and W. A. Stahel. </author> <title> Robust Statistics: The Approach Based on Influence Functions. </title> <publisher> John Wiley & Sons, </publisher> <year> 1986. </year>
Reference-contexts: Where they prove ineffective, new and perhaps more complicated robust techniques will be needed. 1 To study the pseudo outliers problem, this paper develops a measure of "pseudo outlier bias" using tools from the robust statistics literature <ref> [10, pages 81-95] </ref> [12, page 11]. Pseudo outlier bias will measure the distance between a robust estimator's fit to a "target" distribution and its fit to an outlier corrupted distribution. <p> Monotone M-estimators (Figure 2a), such as Huber's [12, Chapter 7], have non-decreasing, bounded (u) functions. Hard redescenders (Figure 2b), such as Hampel's [9] <ref> [10, page 150] </ref>, force (u) = 0 for juj &gt; c; hence c is a rejection point, beyond which a residual has no influence. <p> If depends only on the properties of the sensor then ^ may be estimated once and fixed for all data sets. Theoretically, when ^ is fixed, the M-estimators described by equation 1 are no longer true M-estimators since they are not scale equivariant <ref> [10, page 259] </ref>. <p> Attention here is restricted to discontinuities in one-dimensional structures, since this will be sufficient to demonstrate the limitations of robust estimators. 3.1 Outlier Distributions To set the context for developing the distributions modeling discontinuities, consider the one-dimensional, outlier corrupted distributions used in the statistics literature to study robust location estimators <ref> [10, page 97] </ref> [12, page 11]: F = (1 ")F 1 + "G 2 MINPRAN has been generalized to any known outlier distribution [26]. 8 Here, F 1 is an inlier distribution (also called a "target distribution"), such as a unit variance Gaussian, and G is an outlier distribution, such as <p> Now, medianf (r i; ) 2 g = F 1 n;y (1=2j; h); (30) In other words, the median is the inverse of the cumulative, evaluated at 1=2. 4 This is the standard functional form of the median <ref> [10, page 89] </ref>. Substituting equation 30 in 10 and 4 When LMS is implemented using random sampling where p points are chosen to instantiate a fit, the median residual is taken from among the remaining n p points. <p> by F a and substituting equation 13 gives the functional T M (H) = argmin min I (nF a (rj; H); n (1F a (rj; H))+1; r=Z 0 ) : (33) Observe that n, the number of points, is still required here, but T M (H) is considered a functional <ref> [10, page 40] </ref>. 17 5 Pseudo Outlier Bias Now that the functional forms of the robust estimators have been derived, the pseudo outlier bias metric can be defined. <p> The bias of the least-squares estimator, calculated by substituting (u) = u 2 into equation 27, is included for comparison. The function tuning parameters values are directly from the literature (c = 1:345 for m [11], a = 1:31, b = 2:04, c = 4:00 for h <ref> [10, page 167] </ref>, and f = 1:5 for s [18]), and r b = 2:5^ for T b . Interestingly, the proportion of gross outliers, " o , has no effect on the results. <p> For the hard redescending M-estimator, which estimates ^ from an initial fit, the optimum fit to the mixture distribution is found in three stages: first find the optimum LMS fit, then calculate the median absolute deviation (MAD) <ref> [10, page 107] </ref> to this fit, scaling it to estimate ^, and finally calculate ^ = T h (H) with ^ fixed.
Reference: [11] <author> P. W. Holland and R. E. Welsch. </author> <title> Robust regression using iteratively reweighted least-squares. </title> <journal> Commun. Statist.-Theor. Meth., </journal> <volume> A6:813-827, </volume> <year> 1977. </year>
Reference-contexts: argmin i 4 where ^ is an estimate of the true scale (noise) term, , and (u) is a robust "loss" function which grows subquadratically for large juj to reduce the effect of outliers. (Often, as discussed below, ^ and ^ are estimated jointly.) M-estimators are categorized into three types <ref> [11] </ref> by the behavior of (u) = 0 (u); one estimator of each type is studied. Monotone M-estimators (Figure 2a), such as Huber's [12, Chapter 7], have non-decreasing, bounded (u) functions. <p> =(b c) + (b + c a)]; b &lt; juj c 2 a (b + c a); c &lt; juj and 1 (1 + f ) log (1 + u 2 =f ): (4) The functions' constants are usually set to optimize asymptotic efficiency relative to a given target distribution <ref> [11] </ref> (e.g. Gaussian residuals). M-estimators typically minimize P (r i; =^) using iterative techniques [11] [12, Chapter 7]. The objective functions of hard and soft redescending M-estimators are non-convex and may have multiple local minima. In general, ^ must be estimated from the data. <p> + c a); c &lt; juj and 1 (1 + f ) log (1 + u 2 =f ): (4) The functions' constants are usually set to optimize asymptotic efficiency relative to a given target distribution <ref> [11] </ref> (e.g. Gaussian residuals). M-estimators typically minimize P (r i; =^) using iterative techniques [11] [12, Chapter 7]. The objective functions of hard and soft redescending M-estimators are non-convex and may have multiple local minima. In general, ^ must be estimated from the data. Hard-redescending M-estimators often use the median absolute deviation (MAD) [11] computed from the residuals to an initial fit, ^ 0 : <p> M-estimators typically minimize P (r i; =^) using iterative techniques <ref> [11] </ref> [12, Chapter 7]. The objective functions of hard and soft redescending M-estimators are non-convex and may have multiple local minima. In general, ^ must be estimated from the data. Hard-redescending M-estimators often use the median absolute deviation (MAD) [11] computed from the residuals to an initial fit, ^ 0 : ^ = k median i fjr i; ^ 0 median j 5 Monotone Hard Soft (u) (a) (b) (c) where k = 1:4826 for consistency at the normal distribution and k = 1:14601 for consistency at Student's t-distribution (when <p> The bias of the least-squares estimator, calculated by substituting (u) = u 2 into equation 27, is included for comparison. The function tuning parameters values are directly from the literature (c = 1:345 for m <ref> [11] </ref>, a = 1:31, b = 2:04, c = 4:00 for h [10, page 167], and f = 1:5 for s [18]), and r b = 2:5^ for T b . Interestingly, the proportion of gross outliers, " o , has no effect on the results.
Reference: [12] <author> P. J. Huber. </author> <title> Robust Statistics. </title> <publisher> John Wiley & Sons, </publisher> <year> 1981. </year>
Reference-contexts: Where they prove ineffective, new and perhaps more complicated robust techniques will be needed. 1 To study the pseudo outliers problem, this paper develops a measure of "pseudo outlier bias" using tools from the robust statistics literature [10, pages 81-95] <ref> [12, page 11] </ref>. Pseudo outlier bias will measure the distance between a robust estimator's fit to a "target" distribution and its fit to an outlier corrupted distribution. <p> This gives a theoretical measure, avoids the need for extensive simulations, and, most importantly, shows the inherent limitations of robust estimators by studying their objective functions independent of their search techniques. The bias of a number of estimators | M-estimators <ref> [12, Chapter 7] </ref>, least median of squares (LMS) [16, 21], least trimmed squares (LTS) [21], Hough transforms [13], RANSAC [7], and MINPRAN [26] | will be studied as the target and mixture distributions vary. <p> The notation ^ (~x) indicates the fit that minimizes an estimator's objective function, with ^ called the "estimate". Each estimator's objective function evaluates hypothesized fits, (~x), via the residuals, r i; = z i (~x i ). 2.1 M-Estimators A regression M-estimate <ref> [12, Chapter 7] </ref> is ^ = argmin i 4 where ^ is an estimate of the true scale (noise) term, , and (u) is a robust "loss" function which grows subquadratically for large juj to reduce the effect of outliers. (Often, as discussed below, ^ and ^ are estimated jointly.) M-estimators <p> Monotone M-estimators (Figure 2a), such as Huber's <ref> [12, Chapter 7] </ref>, have non-decreasing, bounded (u) functions. Hard redescenders (Figure 2b), such as Hampel's [9] [10, page 150], force (u) = 0 for juj &gt; c; hence c is a rejection point, beyond which a residual has no influence. <p> Gaussian residuals). M-estimators typically minimize P (r i; =^) using iterative techniques [11] <ref> [12, Chapter 7] </ref>. The objective functions of hard and soft redescending M-estimators are non-convex and may have multiple local minima. In general, ^ must be estimated from the data. <p> Other M-estimators jointly estimate ^ and ^ as ( ^ ; ^) = argmin ; i In particular, Huber <ref> [12, Chapter 7] </ref> uses m (r i; ; ) = [ m (r i; =) + a]; (7) where m (r i; =) is from equation 2 and a is a tuning parameter; Mirza and Boyer [5] use s (r i; ; ) = ln + s (r i; =); (8) <p> restricted to discontinuities in one-dimensional structures, since this will be sufficient to demonstrate the limitations of robust estimators. 3.1 Outlier Distributions To set the context for developing the distributions modeling discontinuities, consider the one-dimensional, outlier corrupted distributions used in the statistics literature to study robust location estimators [10, page 97] <ref> [12, page 11] </ref>: F = (1 ")F 1 + "G 2 MINPRAN has been generalized to any known outlier distribution [26]. 8 Here, F 1 is an inlier distribution (also called a "target distribution"), such as a unit variance Gaussian, and G is an outlier distribution, such as a large variance
Reference: [13] <author> J. Illingworth and J. Kittler. </author> <title> A survey of the Hough transform. </title> <journal> CVGIP, </journal> <volume> 44 </volume> <pages> 87-116, </pages> <year> 1988. </year>
Reference-contexts: The bias of a number of estimators | M-estimators [12, Chapter 7], least median of squares (LMS) [16, 21], least trimmed squares (LTS) [21], Hough transforms <ref> [13] </ref>, RANSAC [7], and MINPRAN [26] | will be studied as the target and mixture distributions vary. The application for studying the pseudo outliers problem is fitting surfaces to range data taken from the neighborhood of a surface discontinuity. <p> To reflect this, when ^ is fixed a priori, they are called "fixed-scale M-estimators." Both standard M-estimators and fixed-scale M-estimators are studied here. 6 2.2 Fixed-Band Techniques: Hough Transforms and RANSAC Hough transforms <ref> [13] </ref>, RANSAC [4, 7], and Roth's primitive extractor [20] are examples of "fixed-band" techniques [20].
Reference: [14] <author> K.-M. Lee, P. Meer, and R.-H. Park. </author> <title> Robust adaptive segmentation of range images. </title> <journal> (submitted to) IEEE Transactions on Pattern Analysis and Matchine Intelligence, </journal> <year> 1996. </year>
Reference-contexts: Acknowledgements The author would like to acknowledge the financial support of the National Science Foundation under grants IRI-9217195 and IRI-9408700, the assistance of James Miller in various aspects of this work, and the insight offered by the anonymous reviewers which led to sub 6 See <ref> [14, 17] </ref> for new, related techniques. 33 stantial improvements in the presentation. Appendix A: Evaluating F s (rj; H ) This appendix shows how to evaluate the conditional cumulative distribution and conditional density of signed residuals, F s (rj; H) (equation 21) and f s (rj; H) (equation 22).
Reference: [15] <author> A. Leonardis, A. Gupta, and R. </author> <title> Bajcsy. Segmentation of range images as the search for geometric parametric models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 14 </volume> <pages> 253-277, </pages> <year> 1995. </year>
Reference-contexts: recommendations, which depend on what is known about the data, were made for choosing between current techniques. 6 These negative results indicate that care should be used when robustly estimating surface parameters in range data, either to obtain local low-order surface approximations or to initialize fits for surface growing algorithms <ref> [3, 5, 6, 15] </ref>. (Similar problems may occur for the "layers" techniques that have been applied to motion analysis [1, 6, 28].) Robust estimates will be accurate for large scale depth discontinuties and sharp corners, but will be skewed at small magnitude discontinuites, such as near the boundary of a slightly
Reference: [16] <author> P. Meer, D. Mintz, A. Rosenfeld, and D. Y. Kim. </author> <title> Robust regression methods for computer vision: A review. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6 </volume> <pages> 59-70, </pages> <year> 1991. </year>
Reference-contexts: This gives a theoretical measure, avoids the need for extensive simulations, and, most importantly, shows the inherent limitations of robust estimators by studying their objective functions independent of their search techniques. The bias of a number of estimators | M-estimators [12, Chapter 7], least median of squares (LMS) <ref> [16, 21] </ref>, least trimmed squares (LTS) [21], Hough transforms [13], RANSAC [7], and MINPRAN [26] | will be studied as the target and mixture distributions vary. The application for studying the pseudo outliers problem is fitting surfaces to range data taken from the neighborhood of a surface discontinuity. <p> M-estimators with a simple, discontinuous loss function f (u) = &lt; 0; juj c (9) Fixed-band techniques search for ^ using either random sampling or voting techniques. 2.3 LMS and LTS Least median of squares (LMS), introduced by Rousseeuw [21], finds the fit minimizing the median of squared residuals. (See <ref> [16] </ref> for a review.) Specifically, the LMS estimate is ^ = argmin fmedian i Most implementations of LMS use random sampling techniques to find an approximate minimum. Related to LMS and also introduced by Rousseeuw [21] is the least trimmed squares estimator (LTS).
Reference: [17] <author> J. V. Miller and C. V. Stewart. </author> <title> MUSE: Robust surface fitting using unbiased scale estimates. </title> <booktitle> In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 300-306, </pages> <year> 1996. </year>
Reference-contexts: Acknowledgements The author would like to acknowledge the financial support of the National Science Foundation under grants IRI-9217195 and IRI-9408700, the assistance of James Miller in various aspects of this work, and the insight offered by the anonymous reviewers which led to sub 6 See <ref> [14, 17] </ref> for new, related techniques. 33 stantial improvements in the presentation. Appendix A: Evaluating F s (rj; H ) This appendix shows how to evaluate the conditional cumulative distribution and conditional density of signed residuals, F s (rj; H) (equation 21) and f s (rj; H) (equation 22).
Reference: [18] <author> M. J. Mirza and K. L. Boyer. </author> <title> Performance evaluation of a class of M-estimators for surface parameter estimation in noisy range data. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 9 </volume> <pages> 75-85, </pages> <year> 1993. </year> <month> 36 </month>
Reference-contexts: The function tuning parameters values are directly from the literature (c = 1:345 for m [11], a = 1:31, b = 2:04, c = 4:00 for h [10, page 167], and f = 1:5 for s <ref> [18] </ref>), and r b = 2:5^ for T b . Interestingly, the proportion of gross outliers, " o , has no effect on the results.
Reference: [19] <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: The functional form of LTS then is easily written as T T (H) = argmin F 1 y (1=2j;H) 4.6 MINPRAN MINPRAN's functional is derived by first re-writing MINPRAN's objective function, replac ing the binomial distribution with the incomplete beta function <ref> [19, page 229] </ref>: min F (r; k r; ; n) = min I (k r; ; nk r; +1; r=Z 0 ) where I (v; w; p) = (v)(w) 0 and () is the gamma function.
Reference: [20] <author> G. Roth and M. D. Levine. </author> <title> Extracting geometric primitives. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 58 </volume> <pages> 1-22, </pages> <year> 1993. </year>
Reference-contexts: To reflect this, when ^ is fixed a priori, they are called "fixed-scale M-estimators." Both standard M-estimators and fixed-scale M-estimators are studied here. 6 2.2 Fixed-Band Techniques: Hough Transforms and RANSAC Hough transforms [13], RANSAC [4, 7], and Roth's primitive extractor <ref> [20] </ref> are examples of "fixed-band" techniques [20]. For these techniques, ^ is the fit maximizing the number of points within r b , where r b is an inlier bound which generally depends on ^ (i.e. r b = c^ for some constant c). <p> To reflect this, when ^ is fixed a priori, they are called "fixed-scale M-estimators." Both standard M-estimators and fixed-scale M-estimators are studied here. 6 2.2 Fixed-Band Techniques: Hough Transforms and RANSAC Hough transforms [13], RANSAC [4, 7], and Roth's primitive extractor <ref> [20] </ref> are examples of "fixed-band" techniques [20]. For these techniques, ^ is the fit maximizing the number of points within r b , where r b is an inlier bound which generally depends on ^ (i.e. r b = c^ for some constant c).
Reference: [21] <author> P. J. Rousseeuw. </author> <title> Least median of squares regression. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 79 </volume> <pages> 871-880, </pages> <year> 1984. </year>
Reference-contexts: This gives a theoretical measure, avoids the need for extensive simulations, and, most importantly, shows the inherent limitations of robust estimators by studying their objective functions independent of their search techniques. The bias of a number of estimators | M-estimators [12, Chapter 7], least median of squares (LMS) <ref> [16, 21] </ref>, least trimmed squares (LTS) [21], Hough transforms [13], RANSAC [7], and MINPRAN [26] | will be studied as the target and mixture distributions vary. The application for studying the pseudo outliers problem is fitting surfaces to range data taken from the neighborhood of a surface discontinuity. <p> The bias of a number of estimators | M-estimators [12, Chapter 7], least median of squares (LMS) [16, 21], least trimmed squares (LTS) <ref> [21] </ref>, Hough transforms [13], RANSAC [7], and MINPRAN [26] | will be studied as the target and mixture distributions vary. The application for studying the pseudo outliers problem is fitting surfaces to range data taken from the neighborhood of a surface discontinuity. <p> the number of outliers, they become a special case of fixed-scale M-estimators with a simple, discontinuous loss function f (u) = &lt; 0; juj c (9) Fixed-band techniques search for ^ using either random sampling or voting techniques. 2.3 LMS and LTS Least median of squares (LMS), introduced by Rousseeuw <ref> [21] </ref>, finds the fit minimizing the median of squared residuals. (See [16] for a review.) Specifically, the LMS estimate is ^ = argmin fmedian i Most implementations of LMS use random sampling techniques to find an approximate minimum. Related to LMS and also introduced by Rousseeuw [21] is the least trimmed <p> (LMS), introduced by Rousseeuw <ref> [21] </ref>, finds the fit minimizing the median of squared residuals. (See [16] for a review.) Specifically, the LMS estimate is ^ = argmin fmedian i Most implementations of LMS use random sampling techniques to find an approximate minimum. Related to LMS and also introduced by Rousseeuw [21] is the least trimmed squares estimator (LTS). The LTS estimate is ^ = argmin j=1 ) j:N : (11) where the (r 2 ) j:N are the (non-decreasing) ordered squared residuals of fit . Usually h = b (N + 1)=2c. <p> This can be seen most easily by comparing the low bias cutoff plots in Figure 12c and d. Like the advantage of hard redescending M-estimators over fixed-band techniques (Section 6.2), this occurs because LTS is more statistically efficient than LMS <ref> [21] </ref> | its objective function depends on the smallest 50% of the residuals rather than just on the median residual.
Reference: [22] <author> P. J. Rousseeuw and C. Croux. </author> <title> Alternatives to the median absolute deviation. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 88 </volume> <pages> 1273-1283, </pages> <year> 1993. </year>
Reference-contexts: Overall, the results are substantially worse than for fixed-scale M-estimators, especially for " s = 0:6. This is a direct result of ^ being a substantial over-estimate of : for example, when " s = 0:6 and z= = 10, ^= 2:4 for all estimates. (See <ref> [22] </ref> for analysis of bias in estimating ^.) These over-estimates allow a large portion of the residual distribution to fall in the region where is quadratic, causing the estimator to act more like least-squares.
Reference: [23] <author> C. V. Stewart. </author> <title> A new robust operator for computer vision: Application to range images. </title> <booktitle> In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 167-173, </pages> <year> 1994. </year>
Reference-contexts: inliers), ^ a and ^ b , with inlier bounds ^r a and ^r b and inlier counts k ^ a ;^r a and k ^ b ;^r b , minimizing F (^r a + ^r b ; k ^ 1 ;^r a +k ^ b ;^r b ; n) <ref> [23, 26] </ref>. <p> Further, these results, unlike those of MINPRAN, are only marginally affected by the parameters " o and z 0 . Unfortunately, the search for ^ a and ^ b is computationally expensive, and so the present implementation of MINPRAN2 uses a simple search heuristic that yields <ref> [23, 26] </ref> more biased results than the optimum shown here. <p> This technique is preferable to LTS and LMS because it is less sensitive to the number of gross outliers. * When ^ is not known a priori, but the distribution of gross outliers is known, one should use the modified MINPRAN algorithm, MINPRAN2 <ref> [23, 26] </ref>. * When neither ^ nor the distribution of gross outliers is known, LTS should be used, although its performance degrades quickly when there are too few inliers.
Reference: [24] <author> C. V. Stewart. </author> <title> A new robust operator for computer vision: Theoretical analysis. </title> <booktitle> In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 1-8, </pages> <year> 1994. </year>
Reference-contexts: Usually h = b (N + 1)=2c. LTS implementations also use random sampling. 2.4 MINPRAN MINPRAN searches for the fit minimizing the probability that a fit and a collection of inliers to the fit could be due to gross outliers <ref> [24, 26] </ref>. It is derived by assuming that relative to 7 any hypothesized fit (x) the residuals of gross outliers are uniformly distributed 2 in the range Z 0 .
Reference: [25] <author> C. V. Stewart. </author> <title> Expected performance of robust estimators near discontinuities. </title> <booktitle> In Proceedings IEEE International Conference on Computer Vision, </booktitle> <pages> pages 969-974, </pages> <year> 1995. </year>
Reference: [26] <author> C. V. Stewart. MINPRAN: </author> <title> A new robust estimator for computer vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17 </volume> <pages> 925-938, </pages> <year> 1995. </year>
Reference-contexts: The bias of a number of estimators | M-estimators [12, Chapter 7], least median of squares (LMS) [16, 21], least trimmed squares (LTS) [21], Hough transforms [13], RANSAC [7], and MINPRAN <ref> [26] </ref> | will be studied as the target and mixture distributions vary. The application for studying the pseudo outliers problem is fitting surfaces to range data taken from the neighborhood of a surface discontinuity. <p> Usually h = b (N + 1)=2c. LTS implementations also use random sampling. 2.4 MINPRAN MINPRAN searches for the fit minimizing the probability that a fit and a collection of inliers to the fit could be due to gross outliers <ref> [24, 26] </ref>. It is derived by assuming that relative to 7 any hypothesized fit (x) the residuals of gross outliers are uniformly distributed 2 in the range Z 0 . <p> Thus MINPRAN's objective function in evaluating a particular fit is min F (r; k r; ; n) and MINPRAN's estimate is ^ = argmin r MINPRAN is implemented using random sampling techniques (see <ref> [26] </ref>). 3 Modeling Discontinuities The important first step in developing the pseudo outlier bias analysis technique is to model the data taken from near a discontinuity as a probability distribution. <p> Distributions To set the context for developing the distributions modeling discontinuities, consider the one-dimensional, outlier corrupted distributions used in the statistics literature to study robust location estimators [10, page 97] [12, page 11]: F = (1 ")F 1 + "G 2 MINPRAN has been generalized to any known outlier distribution <ref> [26] </ref>. 8 Here, F 1 is an inlier distribution (also called a "target distribution"), such as a unit variance Gaussian, and G is an outlier distribution, such as a large variance Gaussian or an uniform distribution over a large interval. The parameter " is the outlier proportion. <p> inliers), ^ a and ^ b , with inlier bounds ^r a and ^r b and inlier counts k ^ a ;^r a and k ^ b ;^r b , minimizing F (^r a + ^r b ; k ^ 1 ;^r a +k ^ b ;^r b ; n) <ref> [23, 26] </ref>. <p> Further, these results, unlike those of MINPRAN, are only marginally affected by the parameters " o and z 0 . Unfortunately, the search for ^ a and ^ b is computationally expensive, and so the present implementation of MINPRAN2 uses a simple search heuristic that yields <ref> [23, 26] </ref> more biased results than the optimum shown here. <p> This technique is preferable to LTS and LMS because it is less sensitive to the number of gross outliers. * When ^ is not known a priori, but the distribution of gross outliers is known, one should use the modified MINPRAN algorithm, MINPRAN2 <ref> [23, 26] </ref>. * When neither ^ nor the distribution of gross outliers is known, LTS should be used, although its performance degrades quickly when there are too few inliers.
Reference: [27] <author> D. Titterington, A. Smith, and U. Makov. </author> <title> Statistical Analysis of Finite Mixture Distributions. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Pseudo outlier bias will measure the distance between a robust estimator's fit to a "target" distribution and its fit to an outlier corrupted distribution. The target distribution will model the distribution of points drawn from a single structure without outliers, and the outlier corrupted mixture distribution <ref> [27] </ref> will combine distributions modeling the different structures and a gross outlier distribution. The optimal fit is found by applying the functional form of an estimator to these distributions, rather than by applying the estimator's standard form to particular sets of points generated from these distributions. <p> Robust location estimators are analyzed using distribution F rather than using a series of point sets sampled from F . 3.2 Mixture Distributions Modeling Discontinuities The present paper analyzes robust regression estimators by examining their behavior on distributions modeling discontinuities. These mixture distributions <ref> [27] </ref> will be of the form H = (1 " o )[" s H 1 + (1 " s )H 2 ] + " o H o : (14) H 1 , H 2 and H o will be inlier, pseudo outlier and gross outlier distributions, respectively, and " s and <p> single fit ^ if F (^r a + ^r b ; k ^ a ;^r a + k ^ b ;^r b ; n) &lt; F (^r; k ^ ; n): (36) Thus, the modified optimization criteria tests whether one or two inlier distributions are more likely in the data <ref> [27] </ref>. Figure 12 shows the step edge small bias cut-off heights for this new objective function, denoted by MINPRAN2. These are substantially lower than those of the other techniques, including LTS.
Reference: [28] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Layered representation for motion analysis. </title> <booktitle> In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 361-366, </pages> <year> 1993. </year>
Reference-contexts: negative results indicate that care should be used when robustly estimating surface parameters in range data, either to obtain local low-order surface approximations or to initialize fits for surface growing algorithms [3, 5, 6, 15]. (Similar problems may occur for the "layers" techniques that have been applied to motion analysis <ref> [1, 6, 28] </ref>.) Robust estimates will be accurate for large scale depth discontinuties and sharp corners, but will be skewed at small magnitude discontinuites, such as near the boundary of a slightly raised or depressed area of a surface.
References-found: 28

