URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/TR292-cjs-synchronisation.ps.Z
Refering-URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/
Root-URL: 
Title: Synchronisation Services for Digital Continuous Media  
Author: Cormac John Sreenan 
Degree: A dissertation submitted for the degree of Doctor of Philosophy  
Date: October 1992  
Address: Cambridge  
Affiliation: Christ's College University of  
Abstract-found: 0
Intro-found: 1
Reference: [Abate89] <author> J. E. Abate et al. </author> <title> AT&T's New Approach to the Synchroni-sation of Telecommunication Networks. </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 35-45, </pages> <month> April </month> <year> 1989. </year> <title> (p 13) </title>
Reference: [Ades86] <author> S. Ades et al. </author> <title> Protocols for Real Time Voice Communication on a Packet Local Network. </title> <booktitle> In Proceedings of the IEEE International Conference on Communications (ICC '86), Toronto, </booktitle> <pages> pages 525-530, </pages> <month> June </month> <year> 1986. </year> <pages> (pp 8, 12) </pages>
Reference: [Ades87] <author> S. Ades. </author> <title> An Architecture for Integrated Services on the Local Area Network. </title> <type> Ph.D. thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> January </month> <year> 1987. </year> <note> Published as Technical Report No. 114. (pp 11, 17, 36, 37) </note>
Reference-contexts: The arrangements in (b),(c) and (d) deal with the use of devices having a network attachment which is distinct from that of a workstation. Examples include dedicated systems like ISLAND telephones <ref> [Ades87] </ref>, as well as the ATM devices of the DAN system [Hayter91]. Typically, these disjoint devices offer less application control than an integrated solution, but they offer several valuable benefits which assure their continued use. <p> This scheme is similar to the use of a central controller to serialise updates to a shared workspace [Sarin85] and to combine individual voice streams for conferencing <ref> [Ades87] </ref>. In these cases, the amount of communication can also be reduced by eliminating the need for a direct link between each participant. However, this approach is inappropriate for inter-stream synchronisation.
Reference: [Almeida91] <author> N. Almeida et al. </author> <title> End-to-End Synchronisation in Packet Switched Networks. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <pages> (pp 17, 18, 27) </pages>
Reference-contexts: Another benefit of predictable variations in the input thread scheduling is to avoid confusing algorithms for clock drift detection (described in Section 2.4), which typically discriminate jitter from frequency effects based on a probability distribution for network delays <ref> [Almeida91] </ref>. In addition, it gives a false impression of the buffer length, restraining the scope for making adjustments.
Reference: [Anderson86] <author> D. P. Anderson and R. Kuivila. </author> <title> Accurately Timed Generation of Discrete Musical Events. </title> <journal> Computer Music Journal, </journal> <volume> 10(3) </volume> <pages> 48-56, </pages> <year> 1986. </year> <title> (p 20) </title>
Reference: [Anderson89a] <author> D. P. Anderson et al. </author> <title> Integrated Digital Continuous Media: A Framework based on MACH, X11, and TCP/IP. </title> <type> Technical Report UCB/CSD 90/566, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <month> March </month> <year> 1989. </year> <title> (p 103) </title>
Reference-contexts: It is unclear whether ACME operation takes sufficient account of stream QOS requirements. The unbounded waiting period to achieve initial synchronisation can lead to excessive delays and/or buffer overflow. If the latter condition occurs, the prototype server sends an exception message to the client <ref> [Anderson89a] </ref>, relying on it to implement some form of flow control. In addition, during operation of an LTS, it seems that skip and pause adjustments are made without regard for the length of a slave's buffer.
Reference: [Anderson89b] <author> D. P. Anderson et al. </author> <title> Support for Continuous Media in the DASH System. </title> <type> Technical Report UCB/CSD 89/537, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <month> October </month> <year> 1989. </year> <pages> (pp 22, 110) </pages>
Reference-contexts: In particular, the UNIX approach of copying data between kernel and user space buffers is entirely unsuitable. The DASH kernel provides an alternative mechanism which allows messages to be mapped into and between process virtual address spaces, without physical copying of the data <ref> [Anderson89b] </ref>. A scheme based upon access to a contiguous set of I/O buffers, similar to that used in Topaz [McJones87], is supported in the WANDA kernel, used for the experimental programme in Chapter 5. <p> Unless application level processing is controlled within acceptable limits, then jitter due to inappropriate resource scheduling may cause a loss of synchronisation. Providing a jitter guarantee for an application requires deterministic CPU scheduling based on a mechanism for describing processing requirements as proposed in <ref> [Anderson89b] </ref>. Further research is needed to determine the feasibility of operating a scheduler in this manner, where an application effectively negotiates a QOS with the operating system. Even if this is available, processing a stream outside the kernel could still result in significant jitter. <p> The use of a dedicated co-processor is advocated in [Bulterman91] as a solution to this problem, with particular emphasis on the support of synchro-nisation. Predictable performance, coupled with the benefit of running standard UNIX on the central processor are cited as the main benefits. The work described in <ref> [Anderson89b] </ref> uses a resource model (implemented in the DASH kernel) which allows applications to reserve resources in an end to end manner. This model is based on a workload characterisation and set of performance requirements.
Reference: [Anderson90] <author> D. P. Anderson and R. Kuivila. </author> <title> A System for Computer Mu--sic Performance. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1) </volume> <pages> 56-82, </pages> <month> February </month> <year> 1990. </year> <title> (p 20) </title>
Reference: [Anderson91a] <author> D. P. Anderson and G. Homsy. </author> <title> A Continuous Media I/O Server and its Synchronisation Mechanism. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 51-57, </pages> <month> October </month> <year> 1991. </year> <pages> (pp 55, 102) </pages>
Reference-contexts: A mathematical description of a similar algorithm is described in <ref> [Anderson91a] </ref>. The important features of these algorithms are to avoid unnecessary adjustments and minimise the effects of phase alterations. <p> In the prototype, the advance of this scale is driven by a nominated master and it is used by each slave to decide if it needs to skip or pause to minimise skew. This decision uses a rate matching algorithm <ref> [Anderson91a] </ref>, which is executed every time data on a stream is about to be presented. If S is exceeded, all stream output is paused, with the objective 102 of allowing the offending connections to catch up, after which normal operation re-sumes.
Reference: [Anderson91b] <author> D. P. Anderson and G. Homsy. </author> <title> Synchronisation Policies and Mechanisms in a Continuous Media I/O Server. </title> <type> Technical Report UCB/CSD 91/617, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <month> February </month> <year> 1991. </year> <title> (p 102) </title>
Reference-contexts: A critical examination of each project allows a comparative evaluation of the proposed design. The discussion deals only with functional issues, since experimental information is not available for these systems. 6.1.2.1 ACME I/O Server Abstractions for Continuous Media Extensions (ACME) <ref> [Anderson91b] </ref> is a workstation server for stream I/O, similar in style to the X Window System. Implemented as an ordinary UNIX process, it handles streams in user space under control of the window system, and transfers them using the standard Transmission Control Protocol (TCP).
Reference: [ANSA89] <institution> The ANSA Testbench Reference Manual. Poseidon House, </institution> <address> Castle Park, Cambridge, CB3 0RD, </address> <month> March </month> <year> 1989. </year> <pages> (pp 71, 100) </pages>
Reference-contexts: MSNL is implemented within WANDA, Pandora and most locally available versions of UNIX, supporting unreliable communication based upon the use of lightweight virtual circuits in an inter-network environment. At a higher level, an implementation of the Advanced Networked Systems Architecture (ANSA) <ref> [ANSA89] </ref>, known as the Testbench, provides RPC capabilities. 5.2.2 WANDA WANDA is a micro-kernel developed locally to support systems research. Its main intended use is to provide a lightweight platform for running user programs. <p> It is suggested that the approach can handle inter-stream synchronisation within the event-based framework. The issues of employing a synchronous language in an distributed system, notably ANSA <ref> [ANSA89] </ref>, are considered. It is proposed that multi-media applications should embody a reactive kernel to handle all syn-chronisation and real-time aspects of operation, thereby allowing the synchronous properties of the programming language to be supported. Conventional synchronisation primitives are reviewed by [Steinmetz90], for use in the context of multi-media.
Reference: [Arons89] <author> B. Arons. </author> <title> The VOX Audio Server. </title> <booktitle> In Proceedings of the 2nd IEEE Comsoc International Multimedia Communications Workshop (Multimedia '89), </booktitle> <address> Ottawa, </address> <month> April </month> <year> 1989. </year> <title> (p 40) </title>
Reference-contexts: In the latter case, the possibility of having to deal with time-outs for idle resources must be considered if the chosen period is too lengthy. A prepare and act arrangement achieves this aim without relying on a common time system <ref> [Arons89, Schmandt88] </ref>. In this scheme, sources are asked to prepare in advance of the start time, allowing resources to be allocated. The aim is to reduce the latency of the subsequent act command, which in this case is used to initiate data capture.
Reference: [Audsley90] <author> N. Audsley and A. Burns. </author> <title> Real-Time System Scheduling. </title> <type> Technical Report YCS 134(1990), </type> <institution> University of York, </institution> <year> 1990. </year> <title> (p 110) </title>
Reference-contexts: However, the time-constrained nature of dealing with continuous media is of greater relevance in the present context. The general trend has been to use a foundation based upon existing work for conventional real-time systems <ref> [Audsley90] </ref>. However, this work is mainly orientated towards situations where there is considerable information about resource requirements and availability. In particular, such an approach is necessary to adequately support hard real-time systems, where failure to operate within specified time constraints can have catastrophic consequences.
Reference: [Berrocal92] <author> J. Berrocal et al. </author> <title> Assessment of the Synchronisation Functions. </title> <type> Technical Report OSI95/LANC/C2/TR/P/V1, </type> <institution> Computing Department, Lancaster University, </institution> <month> January </month> <year> 1992. </year> <title> Published within ESPRIT Project OSI 95 on High Performance OSI Protocols with Multimedia Support on HSLANs and B-ISDN. </title> <note> (pp 46, 106) </note>
Reference-contexts: For example, it may be desired to reduce the QOS for a video stream when the associated workstation window is obscured, thereby allowing better resource management and perhaps even cost savings. The existence of a re-negotiation facility at the OSI transport level is advised in <ref> [Berrocal92] </ref>. However, analytical work in [Crosby92] questions the benefits of re-negotiation over the static approach, where a network QOS is arranged only when a connection is instantiated. A conclusion of that work is that re-negotiation is not useful when the ratio of source peak to 46 line rate is small. <p> A LLO exists on the source and sink node of each orchestrated stream and may interact with other LLOs using per-stream control circuits. These provide guaranteed bandwidth for out of band signalling, and allow predictable source/sink interactions for control of a rate-based transport protocol <ref> [Berrocal92] </ref>. For each stream, the HLO agent and its local LLO interact at fixed regular periods, allowing skew to be monitored with reference to the clock at the orchestrating node.
Reference: [Blair90] <author> G. S. Blair et al. </author> <title> Distributed Systems Support for Heterogeneous Multimedia Environments. </title> <type> Position Paper, </type> <institution> Computing Department, Lancaster University, </institution> <month> November </month> <year> 1990. </year> <title> (p 16) </title>
Reference: [Blair92] <author> G. S. Blair et al. </author> <title> The Role of Operating Systems in Object-Oriented Distributed Multimedia Platforms. </title> <type> Technical Report, </type> <institution> Computing Department, Lancaster University, </institution> <month> May </month> <year> 1992. </year> <title> (p 22) </title>
Reference-contexts: A recent proposal suggests that it should be possible to execute application modules on a dedicated system by employing it as an object-oriented platform <ref> [Blair92] </ref>. This is a move away from the inflexibility of an embedded system, but retaining a tighter degree of control over system behaviour than is possible in a workstation configuration.
Reference: [Blakowski91] <author> G. Blakowski et al. </author> <title> Tools for Specifying and Executing Synchro-nised Multimedia Presentations. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <title> (p 103) </title>
Reference-contexts: It is reported in [Govindan91], that the delay in using ACME exceeds that which is acceptable to a telephone conversation client. 6.1.2.2 MODE Multimedia Objects in a Distributed Environment (MODE) <ref> [Blakowski91] </ref> is designed to support the specification and performance of multi-media presentations. 103 A graphical editor is used to describe a presentation in terms of the desired spa-tial layout and synchronisation relationships between a collection of media objects.
Reference: [Bulterman91] <author> D. C. A. Bulterman and R. van Liere. </author> <title> Multimedia Synchro--nisation and UNIX. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <pages> (pp 28, 110) </pages>
Reference-contexts: Alternatively, it may run as an I/O processor within the workstation, with data transferred over a separate access channel after demultiplexing at the network interface [McAuley89]. This is similar to the multi-media co-processor of <ref> [Bulterman91] </ref> which intends to allow stream processing to be off-loaded from the main workstation processor, while reaping the benefits of partial integration. <p> A number of systems aim to reproduce this type of arrangement, by dedicating resources or allowing an application to negotiate a guarantee based on reservations made in advance. The use of a dedicated co-processor is advocated in <ref> [Bulterman91] </ref> as a solution to this problem, with particular emphasis on the support of synchro-nisation. Predictable performance, coupled with the benefit of running standard UNIX on the central processor are cited as the main benefits.
Reference: [Campbell92a] <author> A. Campbell et al. </author> <title> A Continuous Media Transport and Orchestration Service. </title> <booktitle> In Proceedings of ACM SIGCOMM '92, Maryland, </booktitle> <pages> pages 99-110, </pages> <month> August </month> <year> 1992. </year> <title> (p 106) </title>
Reference-contexts: It is suggested that higher level synchronisation can be implemented using a programmable manager which executes an application supplied script based on such event occurrences. The system appears not to deal explicitly with intra-stream synchronisation, instead relying on suitable QOS support from the transport level <ref> [Campbell92a] </ref>. In addition, support is only provided for stored streams, thus minimising problems from the significant end to end delays which could be introduced using the rate-based transport protocol, notably at the start of a presentation.
Reference: [Campbell92b] <author> A. Campbell et al. </author> <title> Distributed Multimedia Communication System Requirements. </title> <type> Technical Report OSI95/ELIN-1/C/V1 - Draft Version, </type> <institution> Alcatel, </institution> <month> January </month> <year> 1992. </year> <title> Published within ESPRIT Project OSI 95 on High Performance OSI Protocols with Multimedia Support on HSLANs and B-ISDN. </title> <note> (pp 8, 11) </note>
Reference: [CCETT88] <institution> CCETT (Centre Commun d' Etudes de Telediffusion et Telecommunications), France. Rapport final du groupe A.F.N.O.R. Z60R-76 sur la normalisation de la representation et des protocoles pour l'exchange des applications audiovisuelles interactives (AVI), </institution> <year> 1988. </year> <title> (p 34) </title>
Reference-contexts: Selecting this value is influenced by several factors including data sampling rates, encoding and com 33 pression as well as quality related factors like video image resolution. Results of experiments reported in <ref> [CCETT88] </ref>, suggest that skew between audio and video should be bounded to 150ms. Recent experience with the Pandora system indicates that skew greater than 80ms 1 can be noticeable, while a range of -20ms to 40ms between audio and video is suggested in [Leydekkers91].
Reference: [CCITT88] <institution> CCITT Study Group XVIII Draft Recommendation I.121. Broadband Aspects of ISDN, </institution> <month> February </month> <year> 1988. </year> <pages> (pp 2, 35) </pages>
Reference-contexts: Within a bundle, each circuit traverses the same path and the data input sequence is reproduced at the destination. It is proposed in [Dixon91] that this could be implemented using a B-ISDN Virtual Path, which provides a suitable facility to support signalling for a collection of Virtual Channels <ref> [CCITT88] </ref>. In general however, this type of protocol support is not common due to the complexity which it introduces. While interleaving is a simple technique it has several drawbacks which make it unattractive in general terms.
Reference: [Chen89] <author> T. M. Chen et al. </author> <title> Dynamic Priority Protocols for Packet Voice. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(5) </volume> <pages> 632-643, </pages> <month> June </month> <year> 1989. </year> <title> (p 13) </title>
Reference: [Cochennec85] <author> J. Y. Cochennec et al. </author> <title> Asynchronous Time-Division Networks: Terminal Synchronisation for Video and Sound Signals. </title> <booktitle> In Proceedings of IEEE GlobeCom '85, </booktitle> <pages> pages 791-794, </pages> <month> December </month> <year> 1985. </year> <title> (p 17) </title>
Reference: [Coulson91] <author> G. Coulson et al. </author> <title> Protocol Support for Distributed Multimedia Applications. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <title> (p 105) </title>
Reference-contexts: The latency and reliability of signals and replies, along with the possibility of stream failures, are significant in this respect. 6.1.2.3 Orchestration Orchestration is a protocol architecture for continuous media synchronisation in a distributed system <ref> [Coulson91] </ref>. It is described using OSI terminology and is said to exist at a level corresponding to the Upper Layer Architecture (ULA), i.e. the application, presentation and session layers. From the application viewpoint, synchronisation is initiated by making a request to a High Level Orchestrator (HLO).
Reference: [Crosby92] <author> S. A. Crosby. </author> <title> In Call Renegotiation of Traffic Parameters. </title> <type> Internal Report, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <year> 1992. </year> <note> Submitted to IEEE INFOCOM '93. (p 46) 116 </note>
Reference-contexts: The existence of a re-negotiation facility at the OSI transport level is advised in [Berrocal92]. However, analytical work in <ref> [Crosby92] </ref> questions the benefits of re-negotiation over the static approach, where a network QOS is arranged only when a connection is instantiated. A conclusion of that work is that re-negotiation is not useful when the ratio of source peak to 46 line rate is small.
Reference: [Damm89] <author> A. Damm et al. </author> <title> The Real-Time Operating System of MARS. </title> <journal> ACM Operating Systems Review, </journal> <volume> 23(3) </volume> <pages> 141-157, </pages> <month> July </month> <year> 1989. </year> <pages> (pp 14, 41) </pages>
Reference-contexts: Time-based message passing is employed in several real-time operating systems, including those for the support of process control <ref> [Damm89] </ref> and computer music [Puckette86]; while a proposal for a real-time RPC protocol is discussed in [Li91].
Reference: [De Prycker87] <author> M. De Prycker et al. </author> <title> Terminal Synchronisation in Asynchronous Networks. </title> <booktitle> In Proceedings of the International Conference on Communication (ICC '87), </booktitle> <pages> pages 800-807, </pages> <month> June </month> <year> 1987. </year> <title> (p 17) </title>
Reference: [Dixon91] <author> M. J. Dixon. </author> <title> System Support for Multi-Service Traffic. </title> <type> Ph.D. thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <note> Septem-ber 1991. Published as Technical Report No. 245. (pp 11, 35, 71, 77, 85) </note>
Reference-contexts: Alternatively, the transport protocol may support a bundle of virtual circuits. Within a bundle, each circuit traverses the same path and the data input sequence is reproduced at the destination. It is proposed in <ref> [Dixon91] </ref> that this could be implemented using a B-ISDN Virtual Path, which provides a suitable facility to support signalling for a collection of Virtual Channels [CCITT88]. In general however, this type of protocol support is not common due to the complexity which it introduces. <p> This allows audio and video data to be transferred over a CFR and can be controlled by communicating directly with a process running on the workstation. Machines used experimentally run the WANDA micro-kernel <ref> [Dixon91] </ref>, which is described in the next section. Most of these machines have access to a CFR, while a small subset are additionally equipped with interfaces for Ethernet and/or the Cambridge Backbone Network (CBN) [Greaves90]. <p> Originally designed to serve as a backbone for CFR interconnection, it has a slotted ring access mechanism and ATM properties. The use of this network for continuous media traffic undergoes experimental analysis in <ref> [Dixon91] </ref>. The main communication protocol is the Multi-Service Network Level (MSNL), defined within the Multi-Service Network Architecture (MSNA) [McAuley89]. MSNL is implemented within WANDA, Pandora and most locally available versions of UNIX, supporting unreliable communication based upon the use of lightweight virtual circuits in an inter-network environment. <p> These run on a pair of 68040 based WANDA machines and operate in cell forwarding mode as described in Section 5.2.2. Cell queueing within a gateway is performed using a FIFO mechanism, for which experimental results are presented in <ref> [Dixon91] </ref>. The source of a stream is either a Pandora Box or the Continuous Media File Server (CMFS) [Jardetzky92]. The CMFS allows Pandora streams to be stored and retrieved in real time and runs on a 68030 based WANDA machine, equipped with a set of conventional hard disks. <p> Hence, unless stated otherwise, it can be assumed throughout the experiments that such losses either do not occur or are negligible. The implications of having a single cell CFR FIFO are also discussed in <ref> [McAuley89, Dixon91] </ref>. Another cause of jitter for an incoming segment is due to the latency variations in scheduling the related input thread. Unsuitable scheduling at this point can result in the segment being placed in the elastic buffer after it is due to be dispatched.
Reference: [Ferrari90a] <author> D. Ferrari. </author> <title> Client Requirements for Real-Time Communication Services. </title> <institution> Internet RFC-1193, </institution> <month> November </month> <year> 1990. </year> <title> (p 8) </title>
Reference: [Ferrari90b] <author> D. Ferrari and D. C. Verma. </author> <title> A Scheme for Real-Time Channel Establishment in Wide-Area Networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3) </volume> <pages> 368-379, </pages> <month> April </month> <year> 1990. </year> <title> (p 24) </title>
Reference-contexts: Thus, a synchronisation QOS refers to the expected performance of a stream agent within the all encompassing device to device arrangements. This series of guarantees could be established using a mechanism similar to that proposed by <ref> [Ferrari90b] </ref>, which incorporates a two-phase protocol to negotiate required performance with relays along the route of a stream. Thus, intra-stream synchronisation is viewed as a service which augments network supported QOS guarantees in order to meet end to end QOS requirements.
Reference: [Ferrari91] <author> D. Ferrari. </author> <title> Design and Applications of a Delay Jitter Control Scheme for Packet-Switching Internetworks. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <title> (p 32) </title>
Reference-contexts: This is compatible with the proposal in [Partridge91], which advocates the use of significant quantities of buffering near the sink to support communications protocols which provide guarantees on delay, but not jitter. A multi-stage approach is proposed in 31 <ref> [Ferrari91] </ref>, which makes use of gateways along the route of the stream to maintain the same QOS at each stage. This approach reduces the amount of jitter which must be dealt with at the destination, but complicates the operation and design of network relays.
Reference: [Fujikawa91] <author> K. Fujikawa et al. </author> <title> Multimedia Presentation System Harmony with Temporal and Active Media. </title> <booktitle> In Proceedings of the USENIX Summer '91 Conference, Nashville, </booktitle> <pages> pages 75-93, </pages> <month> June </month> <year> 1991. </year> <title> (p 4) </title>
Reference: [Gifford88] <author> D. K. Gifford and N. Glasser. </author> <title> Remote Pipes and Procedures for Efficient Distributed Communication. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(3) </volume> <pages> 258-283, </pages> <month> August </month> <year> 1988. </year> <title> (p 64) </title>
Reference-contexts: The other project, described in section 6.1.2.5, allows control over the processing order of presentation requests, both within and between streams. This may be compared to the scheme in <ref> [Gifford88] </ref>, where the order in which asynchronous RPCs are dispatched over a group of channels may be reproduced at the sink. These schemes are designed for situations where related streams have the same destination, hence simplifying the task of synchronisation.
Reference: [Glauert91] <author> T. Glauert and J. Gettys. </author> <title> X Synchronisation Extension. Overview of version 2.0 from the X Window System (version 11, release 5) documentation, </title> <booktitle> 1991. (p 108) </booktitle>
Reference-contexts: Similarly, by embedding synchronisation deep in the protocol stack, it complicates the introduction of new stream formats if so desired. 107 6.1.2.5 X Synchronisation Extension The X synchronisation extension <ref> [Glauert91] </ref> aims to allow X Window System applications to co-ordinate data presentation. In the basic X protocol for client/server interaction, data to be presented is transferred within a stream of asynchronous requests to the server.
Reference: [Govindan91] <author> R. Govindan and D. P. Anderson. </author> <title> Scheduling and IPC Mechanisms for Continuous Media. </title> <type> Technical Report UCB/CSD 91/622, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <month> March </month> <year> 1991. </year> <booktitle> Also appears in the Proceedings of the 117 13th ACM Symposium on Operating Systems Principles, </booktitle> <year> 1991. </year> <pages> (pp 27, 103) </pages>
Reference-contexts: An alternative scheme is to allow user level scheduling of lightweight processes with CPU time divided amongst different conventional processes. A hybrid proposal in <ref> [Govindan91] </ref>, extends this approach with a mechanism for influencing kernel scheduling based on the needs of individual lightweight processes. Conventional algorithms such as FCFS and Round-Robin are unsuitable for scheduling threads which have real time operating constraints. <p> Consequently, audio is made to suffer large adjustments of approximately 32ms. The initial implementation was prone to noticeable timing errors and data loss which occurred in the presence of other concurrent activity in the system <ref> [Govindan91] </ref>. A technique whereby kernel scheduling could be influenced by the priorities of threads existing in user-space was proposed to remedy the situation. It is unclear whether ACME operation takes sufficient account of stream QOS requirements. <p> Decreasing the size below N bytes increases the possibility of excessive jitter, while at the other extreme, the acceptable end to end delay for the stream can be violated. It is reported in <ref> [Govindan91] </ref>, that the delay in using ACME exceeds that which is acceptable to a telephone conversation client. 6.1.2.2 MODE Multimedia Objects in a Distributed Environment (MODE) [Blakowski91] is designed to support the specification and performance of multi-media presentations. 103 A graphical editor is used to describe a presentation in terms of
Reference: [Greaves90] <editor> D. Greaves et al. </editor> <booktitle> The Cambridge Backbone Ring. In Proceedings of IEEE INFOCOM '90, </booktitle> <address> San Francisco, </address> <year> 1990. </year> <title> (p 71) </title>
Reference-contexts: Machines used experimentally run the WANDA micro-kernel [Dixon91], which is described in the next section. Most of these machines have access to a CFR, while a small subset are additionally equipped with interfaces for Ethernet and/or the Cambridge Backbone Network (CBN) <ref> [Greaves90] </ref>. The CBN is a fibre optic based, Metropolitan Area Network (MAN), which currently operates at 500 Mb/s. Originally designed to serve as a backbone for CFR interconnection, it has a slotted ring access mechanism and ATM properties.
Reference: [Gusella83] <author> R. Gusella and S. Zatti. </author> <title> TEMPO A Network Time Controller for a Distributed Berkeley UNIX System. </title> <type> Technical Report UCB/CSD 83/163, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <month> December </month> <year> 1983. </year> <pages> (pp 13, 52) </pages>
Reference-contexts: Their main benefit over the centrally controlled techniques is increased fault tolerance, gained at the expense of a greater amount of communication. In many cases these schemes produce a correction term which requires a clock to adjust backwards as implemented in <ref> [Gusella83] </ref>. This can have undesirable consequences by making time appear to run in reverse [Lamport78], prompting a solution which spreads an adjustment over the next re-synchronisation interval [Kopetz87, Mills89].
Reference: [Hanko91a] <author> J. G. Hanko et al. </author> <title> Integrated Multimedia at Sun Microsystems. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <title> (p 22) </title>
Reference-contexts: A proposal by Sun for a UNIX multi-media environment envisages a scheme whereby streams are normally dealt with in the kernel, but if necessary may be accessed directly by those applications willing to incur the additional overheads <ref> [Hanko91a] </ref>. In most systems to date, sink processing for a stream is confined to data movement and decompression.
Reference: [Hanko91b] <author> J. G. Hanko et al. </author> <title> Workstation Support for Time-Critical Applications. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <title> (p 110) </title>
Reference-contexts: Related work provided a real-time version of the Mach kernel [Tokuda90]. This is a comprehensive re-design of the facilities for thread scheduling, synchronisation and memory management, in order to increase predictability. In contrast to the approach of providing guarantees to applications, the work described in <ref> [Hanko91b] </ref> is based on the premise that time constraint violation will remain a common occurrence in a workstation operating system. In these situations it is suggested that the system should be designed to either signal the affected applications or follow guidelines which they define in advance.
Reference: [Hayter91] <author> M. Hayter and D. McAuley. </author> <title> The Desk Area Network. </title> <type> Technical Report 228, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> May </month> <year> 1991. </year> <note> Published in ACM Operating Systems Review, 25(4), </note> <month> October </month> <year> 1991. </year> <pages> (pp 30, 36) </pages>
Reference-contexts: The characteristics of a local ATM network should support this configuration, without having to make excessive resource reservations and incur associated real costs. This approach is particularly suitable for the novel architecture of the Desk Area Network (DAN) <ref> [Hayter91] </ref>. This uses an ATM network as the interconnect for a multi-media workstation allowing the use of multiple high bandwidth streams without significant contention. Devices exist as nodes attached directly to the switch as illustrated in Figure 2.12. <p> The arrangements in (b),(c) and (d) deal with the use of devices having a network attachment which is distinct from that of a workstation. Examples include dedicated systems like ISLAND telephones [Ades87], as well as the ATM devices of the DAN system <ref> [Hayter91] </ref>. Typically, these disjoint devices offer less application control than an integrated solution, but they offer several valuable benefits which assure their continued use. Firstly, they increase independence from the workstation, allowing greater flexibility in selecting a device, its location and portability.
Reference: [Hazard91] <author> L. Hazard et al. </author> <title> Notes on Architectural Support for Distributed Multimedia Applications. </title> <type> Technical Report ESPRIT ISA Project Number 2267, </type> <institution> CNET (Centre National d' Etudes des Telecommunications), Issy les Moulineaux, France, </institution> <month> March </month> <year> 1991. </year> <title> (p 99) </title>
Reference-contexts: Operating below the specification level, a number of projects concentrate on the semantics of operating system and programming language primitives to support synchronisa-tion. This work is motivated by the need to acknowledge the importance of time constrained synchronisation in presentations which involve continuous media. In <ref> [Hazard91] </ref>, existing work on formalisms for reactive systems is used as a basis for programming time constrained synchronisation. A reactive system is defined as one which interacts in an ongoing manner with its environment, expressed in terms of input and output event occurrences.
Reference: [Hodges89] <author> M. E. Hodges et al. </author> <title> A Construction Set for Multimedia Applications. </title> <journal> IEEE Software, </journal> <pages> pages 37-43, </pages> <month> January </month> <year> 1989. </year> <title> (p 4) </title>
Reference: [Hopper88] <author> A. Hopper and R. M. Needham. </author> <title> The Cambridge Fast Ring Networking System. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(10) </volume> <pages> 1214-1223, </pages> <month> October </month> <year> 1988. </year> <title> (p 3) </title>
Reference: [Hopper90] <author> A. Hopper. </author> <title> Pandora An Experimental System for Multimedia Applications. </title> <journal> ACM Operating Systems Review, </journal> <volume> 24(2) </volume> <pages> 19-34, </pages> <month> April </month> <year> 1990. </year> <pages> (pp 3, 11, 39, 40, 71) </pages>
Reference-contexts: This is because they allow synchronisation issues to be encapsulated with the data and dealt with at production time, rather than during presentation. In a more dynamic environment using magnetic disks, streams are more likely to be stored separately as in <ref> [Jardetzky92, Hopper90] </ref>, thus providing considerable flexibility in comparison. Issues related to the support of synchronised retrieval using multiple storage systems for multi-media presentations are outlined in [Sreenan90]. This dissertation encourages the use of a non-interleaved scheme and does not impose constraints on the use of multiple stream sources and sinks. <p> The sink based approach has been adopted for the storage facilities of the Pandora system <ref> [Hopper90, Jardetzky92] </ref>, where recording begins only when the audio and related video stream are both being received. An alternative scheme is to synchronise streams so that their capture begins at approximately the same real time. <p> Workstations running the UNIX operating system have Ethernet access and provide support for development, as well as a platform for executing applications. Several of these can support multi-media applications by using a directly attached Pandora Box <ref> [Hopper90] </ref> as described in Chapter 1. This allows audio and video data to be transferred over a CFR and can be controlled by communicating directly with a process running on the workstation. Machines used experimentally run the WANDA micro-kernel [Dixon91], which is described in the next section.
Reference: [Hopper92] <author> A. Hopper. </author> <title> Improving Communications at the Desktop. </title> <type> Technical Report 92-3, </type> <institution> Olivetti Research Ltd., </institution> <address> Cambridge, </address> <month> March </month> <year> 1992. </year> <title> (p 3) </title>
Reference: [Jardetzky92] <author> P. W. Jardetzky. </author> <title> Network File Server Design for Continuous Media. </title> <type> Ph.D. thesis, </type> <institution> Computer Laboratory, University of Cam-bridge, </institution> <month> August </month> <year> 1992. </year> <pages> (pp 39, 40, 77) </pages>
Reference-contexts: This is because they allow synchronisation issues to be encapsulated with the data and dealt with at production time, rather than during presentation. In a more dynamic environment using magnetic disks, streams are more likely to be stored separately as in <ref> [Jardetzky92, Hopper90] </ref>, thus providing considerable flexibility in comparison. Issues related to the support of synchronised retrieval using multiple storage systems for multi-media presentations are outlined in [Sreenan90]. This dissertation encourages the use of a non-interleaved scheme and does not impose constraints on the use of multiple stream sources and sinks. <p> The sink based approach has been adopted for the storage facilities of the Pandora system <ref> [Hopper90, Jardetzky92] </ref>, where recording begins only when the audio and related video stream are both being received. An alternative scheme is to synchronise streams so that their capture begins at approximately the same real time. <p> Cell queueing within a gateway is performed using a FIFO mechanism, for which experimental results are presented in [Dixon91]. The source of a stream is either a Pandora Box or the Continuous Media File Server (CMFS) <ref> [Jardetzky92] </ref>. The CMFS allows Pandora streams to be stored and retrieved in real time and runs on a 68030 based WANDA machine, equipped with a set of conventional hard disks.
Reference: [Jeffay91] <author> K. Jeffay et al. </author> <title> Kernel Support for Live Digital Audio and Video. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <pages> (pp 11, 45, 110) </pages>
Reference-contexts: Should the video stream subsequently incur a delay of similar magnitude, then tolerable skew bounds could be 2 Information supplied by G. J. Stark of the University of Cambridge Computer Laboratory. 44 violated without having exceeded typical values for overall latency. A similar ob-servation is reported in <ref> [Jeffay91] </ref>, where video is delayed by up to 230ms, mainly because of the pipelined frame processing of DVI hardware. Of course, it may be possible to avoid excessive skew by arranging comprehensive QOS guarantees. <p> This model is based on a workload characterisation and set of performance requirements. Within a resource, scheduling is based on deadlines which are assigned individually to messages within a stream. A similar approach, implemented for the YARTOS kernel, is described in <ref> [Jeffay91] </ref>. This provides a guarantee on the latency of message receipt and processing, by executing a scheduling algorithm prior to running the application. An extension to the Mach kernel for time constrained signal handling is discussed in [Nakajima91].
Reference: [Khanna92] <author> S. Khanna et al. </author> <title> Realtime Scheduling in SunOS 5.0. </title> <booktitle> In Proceedings of the USENIX Winter '92 Conference, </booktitle> <pages> pages 375-390, </pages> <year> 1992. </year> <title> (p 16) </title>
Reference: [King92] <author> T. King. Pandora: </author> <title> An Experiment in Distributed Multimedia. </title> <type> Technical Report, </type> <institution> Olivetti Research Ltd., </institution> <address> Cambridge, </address> <month> May </month> <year> 1992. </year> <title> Presented at EuroGraphics '92, </title> <publisher> Cambridge. </publisher> <pages> (pp 3, 12) </pages>
Reference: [Kopetz87] <author> H. Kopetz and W. Ochsenreiter. </author> <title> Clock Synchronisation in Distributed Real-Time Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(8) </volume> <pages> 933-940, </pages> <month> August </month> <year> 1987. </year> <pages> (pp 14, 52) </pages>
Reference-contexts: In many cases these schemes produce a correction term which requires a clock to adjust backwards as implemented in [Gusella83]. This can have undesirable consequences by making time appear to run in reverse [Lamport78], prompting a solution which spreads an adjustment over the next re-synchronisation interval <ref> [Kopetz87, Mills89] </ref>. A similar restriction applies in relation to inter-stream synchro-nisation, where a stream can be advanced, slowed down or paused, but backwards motion is unacceptable unless it is a feature of the presentation. Even in that case, reverse motion in the longer term is only possible for stored streams.
Reference: [Lamport78] <author> L. Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year> <title> (p 52) </title>
Reference-contexts: In many cases these schemes produce a correction term which requires a clock to adjust backwards as implemented in [Gusella83]. This can have undesirable consequences by making time appear to run in reverse <ref> [Lamport78] </ref>, prompting a solution which spreads an adjustment over the next re-synchronisation interval [Kopetz87, Mills89]. A similar restriction applies in relation to inter-stream synchro-nisation, where a stream can be advanced, slowed down or paused, but backwards motion is unacceptable unless it is a feature of the presentation.
Reference: [Le Gall91] <author> D. Le Gall. </author> <title> MPEG: A Video Compression Standard for Multimedia Applications. </title> <journal> Communications of the ACM, </journal> <month> April </month> <year> 1991. </year> <title> (p 11) </title>
Reference: [Leslie84] <author> I. M. Leslie et al. </author> <title> The Architecture of the Universe Network. </title> <booktitle> In Proceedings of ACM SIGCOMM '84, </booktitle> <address> Montreal, </address> <month> June </month> <year> 1984. </year> <title> (p 12) </title>
Reference: [Leung90] <author> W. F. Leung et al. </author> <title> A Software Architecture for Workstations Supporting Multimedia Conferencing in Packet Switching Networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3) </volume> <pages> 380-390, </pages> <month> April </month> <year> 1990. </year> <title> (p 35) </title>
Reference-contexts: A potential conflict exists when multiple streams with different QOS requirements are multiplexed over a single transport connection. For example, less reliability may be acceptable for video but not for text. Thus, it becomes necessary to use the strictest combination of QOS parameters <ref> [Leung90] </ref>, resulting in the inefficient use of network resources. A non-interleaved approach allows per-stream QOS to be selected and can exploit parallelism, giving considerable freedom in the choice of network, route and protocol for each stream.
Reference: [Levi90] <author> S. Levi and A. K. Agrawala. </author> <title> Real-Time System Design. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1990. </year> <title> (p 13) </title>
Reference: [Leydekkers91] <author> P. Leydekkers and B. Teunissen. </author> <title> Synchronisation of Multimedia Data Streams in Open Distributed Environments. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <pages> (pp 8, 34) 119 </pages>
Reference-contexts: Results of experiments reported in [CCETT88], suggest that skew between audio and video should be bounded to 150ms. Recent experience with the Pandora system indicates that skew greater than 80ms 1 can be noticeable, while a range of -20ms to 40ms between audio and video is suggested in <ref> [Leydekkers91] </ref>. An important factor in choosing a skew bound can only be provided by the application, as it is a description of the stream content and usage.
Reference: [Li91] <author> G. Li. </author> <title> Towards a Real-Time ANSA. </title> <type> Internal report, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> December </month> <year> 1991. </year> <title> (p 41) </title>
Reference-contexts: Time-based message passing is employed in several real-time operating systems, including those for the support of process control [Damm89] and computer music [Puckette86]; while a proposal for a real-time RPC protocol is discussed in <ref> [Li91] </ref>.
Reference: [Little90a] <author> T. D. C. Little and A. Ghafoor. </author> <title> Network Considerations for Distributed Multimedia Object Composition and Communication. </title> <journal> IEEE Network Magazine, </journal> <pages> pages 32-49, </pages> <month> November </month> <year> 1990. </year> <title> (p 101) </title>
Reference-contexts: Each logical synchronisation frame results in an RPC call back to the application, which may be used to perform synchronisation expressed in terms of programming language synchronisation primitives. The system described in <ref> [Little90a] </ref> directly executes a high level statement of application synchronisation requirements. Synchronisation is specified using a logic of temporal intervals and takes the form of a timed Petri Net [Little90b].
Reference: [Little90b] <author> T. D. C. Little and A. Ghafoor. </author> <title> Synchronisation and Storage Models for Multimedia Objects. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3) </volume> <pages> 413-427, </pages> <month> April </month> <year> 1990. </year> <title> (p 101) </title>
Reference-contexts: The system described in [Little90a] directly executes a high level statement of application synchronisation requirements. Synchronisation is specified using a logic of temporal intervals and takes the form of a timed Petri Net <ref> [Little90b] </ref>. These specifications are stored in a database, from which they are extracted and executed at presentation time, relying on the use of a communications protocol which provides highly predictable end to end delays for each stream [Little91].
Reference: [Little91] <author> T. D. C. Little and A. Ghafoor. </author> <title> Spatio-Temporal Composition of Distributed Multimedia Objects for Value-Added Networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 42-50, </pages> <month> October </month> <year> 1991. </year> <title> (p 101) </title>
Reference-contexts: These specifications are stored in a database, from which they are extracted and executed at presentation time, relying on the use of a communications protocol which provides highly predictable end to end delays for each stream <ref> [Little91] </ref>. Event information is obtained using logical synchronisation points within each stream, based on the proposal from [Nicolaou90b] described above. A common theme in each of these projects is the important role of event notifications.
Reference: [Luther89] <author> A. C. </author> <title> Luther. Digital Video in the PC Environment. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1989. </year> <pages> (pp 30, 38, 62) </pages>
Reference-contexts: Similarly, facilities such as synchronisation and decompression are viewed as shared networked services within a DAN. In conventional architectures, lack of bus bandwidth generally forces decompression to be performed on the same physical board as the device <ref> [Luther89, Szabo91] </ref>, requiring hardware which is dedicated to each workstation. The local nature of the environment provides highly predictable communication delays, allowing a stream agent to operate in a remote, or in fact, a distributed form. <p> Algorithms which aim to provide an optimal layout for audio on a CD-ROM are given in [Yu89]. The file format used in the DVI system for CD-ROM is composed of a sequence of blocks which may contain data interleaved from a collection of video and audio streams <ref> [Luther89] </ref>. The DVI Audio/Video Support System (AVSS) also allows still images, application data and real-time underlay data to be incorporated into an interleaved file. A similar approach is used in the MPEG standard which aims to be both application and device independent [Szabo91]. <p> Finally, content related events require comprehension of the actual encoding of the data or alternatively must rely on explicit marker events. An example is the interleaved underlay stream of the DVI system <ref> [Luther89] </ref> which contains data to be delivered to the application in synchronisation with stream pre 62 sentation.
Reference: [McAuley89] <author> D. R. McAuley. </author> <title> Protocol Design for High Speed Networks. </title> <type> Ph.D. thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <note> Septem-ber 1989. Published as Technical Report No. 186. (pp 15, 28, 71, 85) </note>
Reference-contexts: The sink may exist with its own network interface, possibly controlled over a direct link from the workstation. Alternatively, it may run as an I/O processor within the workstation, with data transferred over a separate access channel after demultiplexing at the network interface <ref> [McAuley89] </ref>. This is similar to the multi-media co-processor of [Bulterman91] which intends to allow stream processing to be off-loaded from the main workstation processor, while reaping the benefits of partial integration. <p> The use of this network for continuous media traffic undergoes experimental analysis in [Dixon91]. The main communication protocol is the Multi-Service Network Level (MSNL), defined within the Multi-Service Network Architecture (MSNA) <ref> [McAuley89] </ref>. MSNL is implemented within WANDA, Pandora and most locally available versions of UNIX, supporting unreliable communication based upon the use of lightweight virtual circuits in an inter-network environment. <p> Hence, unless stated otherwise, it can be assumed throughout the experiments that such losses either do not occur or are negligible. The implications of having a single cell CFR FIFO are also discussed in <ref> [McAuley89, Dixon91] </ref>. Another cause of jitter for an incoming segment is due to the latency variations in scheduling the related input thread. Unsuitable scheduling at this point can result in the segment being placed in the elastic buffer after it is due to be dispatched.
Reference: [McJones87] <author> P. R. McJones and G. F. Swart. </author> <title> Evolving the UNIX System Interface to Support Multithreaded Programs. </title> <type> Technical Report 21, </type> <institution> DEC Systems Research Centre, Palo Alto, </institution> <month> September </month> <year> 1987. </year> <title> (p 22) </title>
Reference-contexts: The DASH kernel provides an alternative mechanism which allows messages to be mapped into and between process virtual address spaces, without physical copying of the data [Anderson89b]. A scheme based upon access to a contiguous set of I/O buffers, similar to that used in Topaz <ref> [McJones87] </ref>, is supported in the WANDA kernel, used for the experimental programme in Chapter 5.
Reference: [Meissner91] <author> K. Meissner. </author> <title> Architectural Aspects of Multimedia CD-I Integration in UNIX/X-Windows Workstations. </title> <booktitle> In Proceedings of the 2nd International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year> <title> (p 68) </title>
Reference-contexts: Such a handler would process notifications on behalf of an application using advance information, which has the effect of relieving the application burden. This could take the form of the application supplied, time critical call-backs in the CD-I system <ref> [Meissner91] </ref>, which can be installed at runtime for execution on an embedded operating system with real-time characteristics. In essence, the use of a proxy handler arrangement is advisable where synchronisation requirements can be expressed in a relatively straightforward fashion and timeliness constraints are tightly bounded.
Reference: [Mills83] <author> D. L. Mills. </author> <title> Internet Delay Experiments. </title> <institution> Internet RFC-889, </institution> <month> December </month> <year> 1983. </year> <title> (p 14) </title>
Reference: [Mills89] <author> D. L. Mills. </author> <title> Internet Time Synchronisation: the Network Time Protocol. </title> <institution> Internet RFC-1129, </institution> <month> October </month> <year> 1989. </year> <pages> (pp 13, 52) </pages>
Reference-contexts: Both algorithms can be employed in a hierarchical configuration, with the accuracy rating of nodes, known as the stratum, increasing towards the root <ref> [Mills89] </ref>. Distributed algorithms operate by having each host determine the required update to its own clock after receiving the values of other clocks and taking account of estimates of their correctness. <p> In many cases these schemes produce a correction term which requires a clock to adjust backwards as implemented in [Gusella83]. This can have undesirable consequences by making time appear to run in reverse [Lamport78], prompting a solution which spreads an adjustment over the next re-synchronisation interval <ref> [Kopetz87, Mills89] </ref>. A similar restriction applies in relation to inter-stream synchro-nisation, where a stream can be advanced, slowed down or paused, but backwards motion is unacceptable unless it is a feature of the presentation. Even in that case, reverse motion in the longer term is only possible for stored streams.
Reference: [Montgomery83] <author> W. A. Montgomery. </author> <title> Techniques for Packet Voice Synchroni-sation. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 1(6) </volume> <pages> 1022-1028, </pages> <month> December </month> <year> 1983. </year> <note> (p 14) 120 </note>
Reference: [Nakajima91] <author> J. Nakajima et al. </author> <title> Multimedia/Realtime Extensions for the Mach Operating System. </title> <booktitle> In Proceedings of the USENIX Summer '91 Conference, Nashville, </booktitle> <pages> pages 183-197, </pages> <month> June </month> <year> 1991. </year> <title> (p 110) </title>
Reference-contexts: A similar approach, implemented for the YARTOS kernel, is described in [Jeffay91]. This provides a guarantee on the latency of message receipt and processing, by executing a scheduling algorithm prior to running the application. An extension to the Mach kernel for time constrained signal handling is discussed in <ref> [Nakajima91] </ref>. This is used in combination with a preemptive deadline scheduling algorithm to support multi-media device access from user space. Related work provided a real-time version of the Mach kernel [Tokuda90].
Reference: [Nicolaou90a] <author> C. A. Nicolaou. </author> <title> An Architecture for Real-Time Multimedia Communication Systems. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3), </volume> <month> April </month> <year> 1990. </year> <title> (p 18) </title>
Reference: [Nicolaou90b] <author> C. A. Nicolaou. </author> <title> A Distributed Architecture for Multimedia Communication Systems. </title> <type> Ph.D. thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> December </month> <year> 1990. </year> <note> Published as Technical Report No. 220. (pp 11, 35, 67, 101) </note>
Reference-contexts: The very act of interleaving is also likely to introduce jitter, through the buffering and delays associated with multiplexing and demultiplexing. Flexibility is reduced for performing inter-stream synchronisa-tion and, as pointed out in <ref> [Nicolaou90b] </ref>, the ability of the application to influence and possibly relax skew constraints is removed. 3.2.2 Source and Sink Constraints The benefit of interleaving is lost if pre-multiplexing and post-demultiplexing delays can cause a loss of synchronisation. <p> Within each agent a local synchronisation mechanism is used to signal the occurrence of events to those components which are responsible for interacting with clients. The subsequent task of making an external notification requires the use of an RPC or message passing protocol. Research in <ref> [Nicolaou90b] </ref> suggests that an RPC based call-back mechanism is most appropriate in this respect. Hence, a client provides the agent with the identification of a remote procedure which is to be invoked when events of a particular type occur. <p> This is exemplified in 100 event occurrence on stream B in relation to that on stream A. The availability of event information provides a highly adaptable foundation for higher level synchronisation. This is illustrated by the work reported in <ref> [Nicolaou90b] </ref>, which defines an architecture with support for notification of stream related events. The proposal consists of a two-level event model, in which a stream handler performs a mapping between physical and logical synchronisation frames. <p> Event information is obtained using logical synchronisation points within each stream, based on the proposal from <ref> [Nicolaou90b] </ref> described above. A common theme in each of these projects is the important role of event notifications.
Reference: [Partridge91] <author> C. Partridge. </author> <title> Isochronous Applications Do Not Require Jitter-Controlled Networks. </title> <institution> Internet RFC-1257, </institution> <month> September </month> <year> 1991. </year> <title> (p 31) </title>
Reference-contexts: The alternative is to try to extend local QOS requirements into an inter-network. The synchronisation service approach allows an application to balance support for its QOS requirements between the inter-network and destination network. This is compatible with the proposal in <ref> [Partridge91] </ref>, which advocates the use of significant quantities of buffering near the sink to support communications protocols which provide guarantees on delay, but not jitter.
Reference: [Postel80] <author> J. B. Postel. </author> <title> A Structured Format for Transmission of MultiMedia Documents. </title> <institution> Internet RFC-767, </institution> <month> August </month> <year> 1980. </year> <title> (p 107) </title>
Reference-contexts: This is done by making reference to points within the streams and indicating whether the associated data items are to be synchronised for simultaneous, sequential or independent presentation. These relationships correspond with the existing proposals for use with elements of multi-media documents <ref> [Postel80] </ref>. It is suggested that streams should be synchronised initially and that data points could be identified in terms of either the byte offset or packet sequence number. The manner in which synchronisation could be used as a transport layer service is described.
Reference: [Puckette86] <author> M. Puckette. </author> <title> Interprocess Communication and Timing in Real-Time Computer Music Performance. </title> <booktitle> In Proceedings of the International Computer Music Conference, </booktitle> <pages> pages 43-46, </pages> <year> 1986. </year> <title> (p 41) </title>
Reference-contexts: Time-based message passing is employed in several real-time operating systems, including those for the support of process control [Damm89] and computer music <ref> [Puckette86] </ref>; while a proposal for a real-time RPC protocol is discussed in [Li91].
Reference: [Rangan91] <author> P. V. Rangan et al. </author> <title> A Testbed for Managing Digital Video and Audio Storage. </title> <type> Technical Report CS91-193, </type> <institution> Department of Computer Science and Engineering, University of California, </institution> <address> San Diego, </address> <month> April </month> <year> 1991. </year> <pages> (pp 36, 61) </pages>
Reference-contexts: Typically, these disjoint devices offer less application control than an integrated solution, but they offer several valuable benefits which assure their continued use. Firstly, they increase independence from the workstation, allowing greater flexibility in selecting a device, its location and portability. For example, the system described in <ref> [Rangan91] </ref> employs a PC to deal with continuous media, since the DVI hardware being used is not available for the target workstation. Secondly, since they are usually cheaper than a workstation, although more expensive than an integrated solution, the potential for a large scale of production exists. <p> Thus, 60 for example, a file server can be expected to support events which identify the start and end of retrieval for a given stream, as provided in <ref> [Rangan91] </ref>. Similarly, it may be prepared to offer information on its progress within the play-back of a continuous media file.
Reference: [Ripley89] <author> G. D. Ripley. </author> <title> DVI A Digital Multimedia Technology. </title> <journal> Communications of the ACM, </journal> <volume> 32(7) </volume> <pages> 811-822, </pages> <month> July </month> <year> 1989. </year> <title> (p 63) </title>
Reference-contexts: An example is the interleaved underlay stream of the DVI system [Luther89] which contains data to be delivered to the application in synchronisation with stream pre 62 sentation. This is in addition to DVI support for embedded time stamps <ref> [Ripley89] </ref> and an application supplied hook routine which, if installed, is invoked by the support system for each frame of video which is processed. The use of such a variety of techniques for conveying stream events strengthens the argument for using typed stream agents for event detection.
Reference: [Sarin85] <author> S. Sarin and I. Grief. </author> <title> Computer-Based Real-Time Conferencing Systems. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 33-45, </pages> <month> October </month> <year> 1985. </year> <title> (p 37) </title>
Reference-contexts: This has a matching demultiplexer at the other end of the connection, from which streams diverge to their respective destinations as shown in Figure 3.3. This scheme is similar to the use of a central controller to serialise updates to a shared workspace <ref> [Sarin85] </ref> and to combine individual voice streams for conferencing [Ades87]. In these cases, the amount of communication can also be reduced by eliminating the need for a direct link between each participant. However, this approach is inappropriate for inter-stream synchronisation.
Reference: [Scheifler86] <author> R. W. Scheifler and Gettys J. </author> <title> The X Window System. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 5(2) </volume> <pages> 79-109, </pages> <month> April </month> <year> 1986. </year> <title> (p 3) </title>
Reference: [Schmandt88] <author> C. Schmandt and M. A. McKenna. </author> <title> An Audio and Telephone Server for Multi-Media Workstations. </title> <booktitle> In Proceedings of the 2nd IEEE Conference on Computer Workstations, </booktitle> <address> Santa Clara, California, </address> <year> 1988. </year> <note> (p 40) 121 </note>
Reference-contexts: In the latter case, the possibility of having to deal with time-outs for idle resources must be considered if the chosen period is too lengthy. A prepare and act arrangement achieves this aim without relying on a common time system <ref> [Arons89, Schmandt88] </ref>. In this scheme, sources are asked to prepare in advance of the start time, allowing resources to be allocated. The aim is to reduce the latency of the subsequent act command, which in this case is used to initiate data capture.
Reference: [Schmidt85] <author> B. L. Schmidt and J. M. Roth. </author> <title> The Synchronisation of Au--dio Production in Computer Music. </title> <booktitle> In Proceedings of the International Computer Music Conference, </booktitle> <pages> pages 341-345, </pages> <year> 1985. </year> <title> (p 55) </title>
Reference-contexts: Over time, a comparison of these progress times is used to determine suggested alterations to the behaviour of individual stream agents. An appropriate rate matching algorithm using phase adjustment has been described for computer music <ref> [Schmidt85] </ref>. In that system it is used to synchronise the playback of a stream of stored samples, in Musical Instrument Digital Interface (MIDI) format, with the operation of a tape recorder, which makes progress information available in the form of SMPTE 3 time codes.
Reference: [Shepherd89] <author> D. Shepherd and M. Salmony. </author> <title> Extending OSI to Support Syn-chronisation Required by Multimedia Applications. </title> <type> Technical Report 43.8904, </type> <institution> IBM European Network Centre, </institution> <address> Heidelberg, Germany, </address> <month> April </month> <year> 1989. </year> <title> (p 106) </title>
Reference-contexts: As discussed in Section 2.5.1, the effectiveness of performing synchronisation in a protocol stack, as in this system, is dependent of the ability to control the behaviour of subsequent application processing so that streams remain synchronised. 6.1.2.4 OSI Extensions Support for inter-stream synchronisation within an OSI context is discussed in <ref> [Shepherd89] </ref>. It is argued that this function is best provided at the transport layer 106 within the receiver's protocol stack.
Reference: [Sreenan90] <author> C. J. Sreenan. </author> <title> Synchronised Retrieval of Multi-Media Data. </title> <booktitle> In Proceedings of the 1st International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Berke-ley, </address> <month> November </month> <year> 1990. </year> <note> Published as Technical Report TR-90-062, </note> <institution> International Computer Science Institute (ICSI), Berkeley. (p 39) </institution>
Reference-contexts: In a more dynamic environment using magnetic disks, streams are more likely to be stored separately as in [Jardetzky92, Hopper90], thus providing considerable flexibility in comparison. Issues related to the support of synchronised retrieval using multiple storage systems for multi-media presentations are outlined in <ref> [Sreenan90] </ref>. This dissertation encourages the use of a non-interleaved scheme and does not impose constraints on the use of multiple stream sources and sinks.
Reference: [Staehli91] <author> R. Staehli. </author> <title> The Utility of Prefetching Data in a Distributed Multimedia Storage Server. </title> <type> Internal report, </type> <institution> Oregon Graduate Institute, </institution> <month> May </month> <year> 1991. </year> <note> A related position paper appeared in ACM Operating Systems Review, </note> <month> April </month> <year> 1992. </year> <title> (p 68) </title>
Reference-contexts: Determining the requirements for guiding advance preparation is a complex issue requiring further research. The concept of programming synchronisation requirements in this way may be compared with the proposal in <ref> [Staehli91] </ref>, where filing system retrieval events are used in combination with an application supplied script to drive the retrieval order of continuous media files. This general approach is only suitable when synchronisation 68 requirements can be expressed in a relatively simple manner.
Reference: [Steinmetz90] <author> R. Steinmetz. </author> <title> Synchronisation Properties in Multimedia Systems. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3) </volume> <pages> 401-412, </pages> <month> April </month> <year> 1990. </year> <title> (p 100) </title>
Reference-contexts: It is proposed that multi-media applications should embody a reactive kernel to handle all syn-chronisation and real-time aspects of operation, thereby allowing the synchronous properties of the programming language to be supported. Conventional synchronisation primitives are reviewed by <ref> [Steinmetz90] </ref>, for use in the context of multi-media. The concept of restricted blocking is proposed as a semantic extension in order to allow the desired behaviour of a waiting stream to be explicitly directed.
Reference: [Sventek87] <author> J. S. Sventek. </author> <title> An Architecture Supporting Multi-Media Integration. </title> <type> Technical Report AO.33.02, </type> <institution> Advanced Networked Systems Architecture (ANSA), </institution> <month> January </month> <year> 1987. </year> <pages> (pp 11, 34) </pages>
Reference-contexts: This works by multiplexing data from each related stream to form an aggregate stream. In essence, this data is grouped to indicate a simultaneous presentation requirement <ref> [Sventek87] </ref>. This aggregate stream is sent over an order preserving communications channel from source to sink as illustrated in Figure 3.1. This could be implemented using a single 1 Information supplied by G. J.
Reference: [Swinehart83] <author> D. C. Swinehart et al. </author> <title> Adding Voice to an Office Computer Network. </title> <booktitle> In Proceedings of IEEE GlobeCom '83, </booktitle> <month> November </month> <year> 1983. </year> <note> Also available as Xerox PARC technical report CSL-83-8, February 1983. (p 7) </note>
Reference: [Szabo91] <author> B. I. Szabo and G. K. Wallace. </author> <title> Design Considerations for JPEG Video and Synchronized Audio in a UNIX Workstation Environment. </title> <booktitle> In Proceedings of the USENIX Summer '91 Conference, Nashville, </booktitle> <pages> pages 353-367, </pages> <month> June </month> <year> 1991. </year> <pages> (pp 30, 38, 53) </pages>
Reference-contexts: Similarly, facilities such as synchronisation and decompression are viewed as shared networked services within a DAN. In conventional architectures, lack of bus bandwidth generally forces decompression to be performed on the same physical board as the device <ref> [Luther89, Szabo91] </ref>, requiring hardware which is dedicated to each workstation. The local nature of the environment provides highly predictable communication delays, allowing a stream agent to operate in a remote, or in fact, a distributed form. <p> The DVI Audio/Video Support System (AVSS) also allows still images, application data and real-time underlay data to be incorporated into an interleaved file. A similar approach is used in the MPEG standard which aims to be both application and device independent <ref> [Szabo91] </ref>. Both of these schemes currently use hardware support for interleaving. An alternative to interleaved storage is to employ the method used in the conventional analog Video Cassette Recorder (VCR), where video and associated audio are recorded on individual tracks and played back using physically separate reading heads. <p> Selecting a primary stream indicates its relative importance, in that the other secondary streams should be adjusted in preference to maintain synchroni-sation. This functionality could be used, for example, to reproduce the hardware based algorithm of <ref> [Szabo91] </ref>, where video output is dictated by the related audio in order to minimise audible interference.
Reference: [Tennenhouse89] <author> D. L. Tennenhouse. </author> <title> Layered Multiplexing Considered Harmful. In Proceedings of the IFIP Workshop on Protocol Design for High-Speed Networks, </title> <journal> IBM Zurich Research Laboratories, </journal> <pages> pages 1-6, </pages> <month> May </month> <year> 1989. </year> <note> (p 15) 122 </note>
Reference: [Tokuda90] <author> H. Tokuda et al. </author> <title> Real-Time Mach: Towards a Predictable Real--Time System. </title> <booktitle> In Proceedings of USENIX Mach Workshop, </booktitle> <address> Burlington, Vermont, </address> <pages> pages 73-82, </pages> <month> October </month> <year> 1990. </year> <title> (p 110) </title>
Reference-contexts: An extension to the Mach kernel for time constrained signal handling is discussed in [Nakajima91]. This is used in combination with a preemptive deadline scheduling algorithm to support multi-media device access from user space. Related work provided a real-time version of the Mach kernel <ref> [Tokuda90] </ref>. This is a comprehensive re-design of the facilities for thread scheduling, synchronisation and memory management, in order to increase predictability.
Reference: [Verbiest86] <author> W. Verbiest. </author> <title> Video Coding in an ATD Environment. </title> <booktitle> In Proceedings of the 3rd International Conference on New System Services for Telecommunications, Liege, </booktitle> <address> Belgium, </address> <pages> pages 249-253, </pages> <month> November </month> <year> 1986. </year> <title> (p 18) </title>
Reference: [Verbiest88] <author> W. Verbiest et al. </author> <title> The Impact of the ATM Concept on Video Coding. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 6(9) </volume> <pages> 1623-1632, </pages> <month> December </month> <year> 1988. </year> <title> (p 26) </title>
Reference-contexts: The default reaction to an exceptional occurrence is specific to the stream agent, but typically results in the provision of a best effort service. For video this could be achieved using a layered coding technique <ref> [Verbiest88] </ref> and degrading in a controlled manner as deemed appropriate in the prevailing circumstances. Internally, the stream agent is composed of a buffer module and a number of paths of execution, known as threads.
Reference: [Verma90] <author> D. C. Verma et al. </author> <title> Guaranteeing Delay Jitter Bounds in Packet-Switching Networks. </title> <booktitle> In Proceedings of the 1st International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Berkeley, </address> <month> November </month> <year> 1990. </year> <note> Published as Technical Report TR-90-062, </note> <institution> International Computer Science Institute (ICSI), Berkeley. (p 45) </institution>
Reference-contexts: Thus, data is buffered if, after processing, it is ready to be dispatched at a time which would violate the minimum delay of the negotiated QOS for that element. This is similar to the operation of the protocol described in <ref> [Verma90] </ref>, where each relay node on the network route operates a time ordered buffer for outgoing data, in order to ensure that jitter bounds can be guaranteed. Having suitable QOS is very important for interactive applications which demand that delay, and hence jitter, are low and bounded.
Reference: [Wayner91] <author> P. Wayner. </author> <title> Inside QuickTime. </title> <journal> BYTE, </journal> <pages> pages 189-196, </pages> <month> December </month> <year> 1991. </year> <title> (p 4) </title>
Reference: [Yu89] <author> C. Yu et al. </author> <title> Efficient Placement of Audio Data on Optical Disks for Real-Time Applications. </title> <journal> Communications of the ACM, </journal> <volume> 32(7), </volume> <month> July </month> <year> 1989. </year> <title> (p 38) </title>
Reference-contexts: Consequently, it is necessary to carefully plan the layout of data on the disk as illustrated in Figure 3.4. Algorithms which aim to provide an optimal layout for audio on a CD-ROM are given in <ref> [Yu89] </ref>. The file format used in the DVI system for CD-ROM is composed of a sequence of blocks which may contain data interleaved from a collection of video and audio streams [Luther89].
Reference: [Zellweger89] <author> P. T. Zellweger. </author> <title> Scripted Documents: A Hypermedia Path Mechanism. </title> <booktitle> In Proceedings of the ACM Hypertext'89 Conference, </booktitle> <pages> pages 1-14, </pages> <month> November </month> <year> 1989. </year> <note> Also available as Xerox PARC technical report EDL-89-3, December 1989. (p 4) 123 </note>
References-found: 95

