URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1234/CS-TR-94-1234.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1234/
Root-URL: http://www.cs.wisc.edu
Email: fshatdal,ck,naughtong@cs.wisc.edu  
Title: Cache Conscious Algorithms for Relational Query Processing  
Author: Ambuj Shatdal Chander Kant Jeffrey F. Naughton 
Date: 1234  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  Computer Sciences  
Pubnum: Technical Report  
Abstract: The current main memory (DRAM) access speeds lag far behind CPU speeds. Cache memory, made of static RAM, is being used in today's architectures to bridge this gap. It provides access latencies of 2-4 processor cycles, in contrast to main memory which requires 15-25 cycles. Therefore, the performance of the CPU depends upon how well the cache can be utilized. We show that there are significant benefits in redesigning our traditional query processing algorithms so that they can make better use of the cache. The new algorithms run 8%-200% faster than the traditional ones.
Abstract-found: 1
Intro-found: 1
Reference: [BE77] <author> M. W. Blasgen and K. P. Eswaran. </author> <title> Storage and access in relational databases. </title> <journal> IBM Systems Journal, </journal> <volume> 16(4), </volume> <year> 1977. </year>
Reference-contexts: In this section we describe the algorithms, point out the optimizations we made and the speedup obtained on the four machines. 4.2.1 The Sort Merge Join The in-memory sort merge join <ref> [BE77] </ref> works as follows. First, both relations R and S are sorted on the join attribute by using an efficient sorting mechanism e.g. quicksort. Then the 10 sorted relations are merged and the matching tuples are output.
Reference: [DKO + 84] <author> David J. DeWitt, Randy H. Katz, Frank Olken, Lenard D. Shapiro, Michael R. Stonebraker, and David Wood. </author> <title> Implementation techniques for main memory database systems. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 1-8, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: The number of groups was 20. In section 4.3 we show that our results hold even when we vary these parameters. All reported timings are in seconds. 4.1 Case Study: Optimizing Hash Joins We describe how we optimized the basic in-memory hash join algorithm <ref> [DKO + 84] </ref> in detail on the DECstation 5000/125. We used the cache profiler cprof [LW94] to gain detailed information about the cache performance of the algorithms. That guided us quickly to the code having poor cache behavior and thus exposed the opportunities for optimization. <p> This implies that an infinite (or no cache) would actually show that the basic algorithm is the best. However, this also shows the importance of cache optimization, because it demonstrates 1 A keen observer would note that this is analogous to the GRACE algorithm <ref> [DKO + 84] </ref> for join processing of disk resident relations. 9 Algorithm Cache Misses Time Speedup Base 379060 0.699 | Extraction 341193 0.652 7.2% Partitioned 284037 0.656 6.6% Table 5: Optimizations for the Hash Join that theoretically similar algorithms can have significantly differing performance depending on the way they utilize the
Reference: [Eps79] <author> Robert Epstein. </author> <title> Techniques for Processing of Aggregates in Relational Database Systems. </title> <institution> Memorandum UCB/ERL M79/8, Electronics Research Laboratory, College of Engineering, University of California, Berkeley, </institution> <month> February </month> <year> 1979. </year>
Reference-contexts: Time Speedup Time Speedup Time Speedup NestedLoop 2244.05 | 490.11 | 569.10 | 413.51 | Blocked 741.54 202.6% 205.11 138.9% 305.71 86.2% 348.16 18.8% Table 8: Optimizations for Nested Loop Algorithm 4.2.3 Aggregation Algorithms Aggregation with the group by clause involves more than a simple scan of the participating relation <ref> [Eps79] </ref>. We consider the two popular aggregation algorithms: the hash based aggregation and the sort based aggregation. Hash Based Aggregation The in-memory hash aggregation on relation R works as follows.
Reference: [HS89] <author> Mark D. Hill and Alan Jay Smith. </author> <title> Evaluating Associativity in CPU Caches. </title> <journal> IEEE Transaca-tions on Computers, </journal> <volume> 38(12) </volume> <pages> 1612-1630, </pages> <month> December </month> <year> 1989. </year>
Reference: [KH92] <author> R. E. Kessler and Mark D. Hill. </author> <title> Page Placement Algorithms for Real-Indexed Caches. </title> <journal> ACM Transactions in Computer Systems, </journal> <volume> 10(4) </volume> <pages> 338-359, </pages> <month> November </month> <year> 1992. </year>
Reference: [Lar93] <author> James R. Larus. </author> <title> Efficient Program Tracing. </title> <journal> IEEE Computer, </journal> <volume> 26(5) </volume> <pages> 52-61, </pages> <month> May </month> <year> 1993. </year>
Reference: [LW94] <author> Alvin R. Lebeck and David A. Wood. </author> <title> Cache Profiling and the SPEC Benchmarks: A Case Study. </title> <note> IEEE Computer (to appear), </note> <month> June </month> <year> 1994. </year> <month> 19 </month>
Reference-contexts: All reported timings are in seconds. 4.1 Case Study: Optimizing Hash Joins We describe how we optimized the basic in-memory hash join algorithm [DKO + 84] in detail on the DECstation 5000/125. We used the cache profiler cprof <ref> [LW94] </ref> to gain detailed information about the cache performance of the algorithms. That guided us quickly to the code having poor cache behavior and thus exposed the opportunities for optimization.
Reference: [NBC + 94] <author> Chris Nyberg, Tom Barclay, Zarca Cvetanovic, Jim Gray, and Dave Lomet. AlphaSort: </author> <title> A RISC Machine Sort. </title> <booktitle> In Proc. of the 1994 ACM SIGMOD Conf., </booktitle> <pages> pages 233-242, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: These partitions are created such that each partition fits in the cache. AlphaSort <ref> [NBC + 94] </ref> uses this technique to speedup the in-memory sorting. There is an overhead of creating the partitions but in most cases the benefit gained overshadows it. In many database algorithms, a good way of generating partitions is by hash partitioning the relations. <p> This more than compensates for the extra merge step resulting in greater overall sorting speed (for large enough N). This is the essence of the in-memory AlphaSort <ref> [NBC + 94] </ref> algorithm. 2 Note that blocking and partitioning are distinct techniques. <p> This optimization can be taken a little further as in using only key prefixes instead of keys for sorting <ref> [NBC + 94] </ref>. For example, from a 200 byte record, we could extract an 12 byte key and a 4 byte pointer to do the sorting. <p> First, both relations R and S are sorted on the join attribute by using an efficient sorting mechanism e.g. quicksort. Then the 10 sorted relations are merged and the matching tuples are output. As mentioned earlier, we use the optimization proposed in <ref> [NBC + 94] </ref> to extract the join attribute and a pointer to the tuple. The basic algorithm sorts both the relations and merges them.
Reference: [Smi82] <author> Alan J. Smith. </author> <title> Cache Memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference: [Val87] <author> Patrick Valduriez. </author> <title> Join Indices. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(2):218 - 246, </volume> <month> June </month> <year> 1987. </year> <month> 20 </month>
Reference-contexts: Under these assumptions, in practice and in our study, an algorithm starts its processing on the relations stored in the buffer pool. The join result is left in the form of an in-memory join index <ref> [Val87] </ref>. In section 4.4 we discuss the tradeoffs and options in the generation of result relation. Furthermore, we incorporated the optimization of extracting the join attribute (group by attribute in case of aggregation) from the tuples for the processing whenever it was appropriate. <p> generation in join algorithms. 1. the result tuple is produced on the fly (e.g. as soon as a match is found in case of a join). 2. upon finding a match two pointers to the participating tuples are stored along with a projection list thus generating an in-memory join index <ref> [Val87] </ref>. Later, depending upon need, the result is generated by accessing the pointed to tuples and doing the projection. This can be considered as lazy evaluation of the result relation.
References-found: 10

