URL: ftp://db.stanford.edu/pub/papers/dapd.ps
Refering-URL: http://www.cs.toronto.edu/~mendel/dwbib.html
Root-URL: 
Title: Consistency Algorithms for Multi-Source Warehouse View Maintenance  
Author: YUE ZHUGE, HECTOR GARCIA-MOLINA, AND JANET L. WIENER 
Keyword: Editor: Keywords: data warehouse, data consistency, view maintenance  
Address: STANFORD, CA 94305-2140, USA  
Affiliation: COMPUTER SCIENCE DEPARTMENT STANFORD UNIVERSITY  
Note: 1-36 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Email: fZHUGE,HECTOR,WIENERg@CS.STANFORD.EDU  
Web: HTTP://WWW-DB.STANFORD.EDU/WAREHOUSING  
Abstract: A warehouse is a data repository containing integrated information for efficient querying and analysis. Maintaining the consistency of warehouse data is challenging, especially if the data sources are autonomous and views of the data at the warehouse span multiple sources. Transactions containing multiple updates at one or more sources, e.g., batch updates, complicate the consistency problem. In this paper we identify and discuss three fundamental transaction processing scenarios for data warehousing. We define four levels of consistency for warehouse data and present a new family of algorithms, the Strobe family, that maintain consistency as the warehouse is updated, under the various warehousing scenarios. All of the algorithms are incremental and can handle a continuous and overlapping stream of updates from the sources. Our implementation shows that the algorithms are practical and realistic choices for a wide variety of update scenarios. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Alonso, D. Barbara, and H. Garcia-Molina. </author> <title> Data caching issues in an information retrieval system. </title> <journal> ACM Transaction on Database Systems, </journal> <volume> 15(3) </volume> <pages> 359-384, </pages> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view at the warehouse is M V = ;. We consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>). Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. <p> The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. Since the current view is empty, no action is taken for this deletion. 4. The warehouse receives A 2 1 = [1; 2; 3; 4] from source z, which is the final answer for Q 1 . <p> The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. <p> The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to is store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref> which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains [1; 2; 3; 4] which should not exist after <ref> [1; 2] </ref> was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> A good overview of the mechanisms for managing replicated data may be found in [3]. However, because of the autonomy of the sources, traditional concurrency mechanisms are often not applicable [5]. A variety of concurrency control schemes have been suggested over the years for such environments (for example, <ref> [1, 26, 10] </ref>). They either provide weaker notions of consistency, or exploit the semantics of applications. The algorithms we present in this paper exploit the semantics of materialized view maintenance to obtain consistency without traditional distributed concurrency control. <p> Initially, the relations are A B r 2 : C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The resulting AL = hkey delete (M V; U 2 )i. 4. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The resulting AL = hkey delete (M V; U 2 )i. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the warehouse applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Example 3: T-Strobe provides stronger consistency than Strobe Consider a simple view over one source defined as V = r 1 . Assume attribute A is the key of relation r 1 . Originally, let the relation r 1 contain a single tuple <ref> [1; 2] </ref>. Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; [3; 4])i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> Assume attribute A is the key of relation r 1 . Originally, let the relation r 1 contain a single tuple <ref> [1; 2] </ref>. Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; [3; 4])i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> Initially, the relations are: r 1 : A B r 2 : B C 3 5 The materialized view M V = ;. AL = h i. We consider two source transactions: T 1 = hU 1 = insert (r 1 ; <ref> [1; 3] </ref>)i and T 2 = hU 2 = delete (r 2 ; [3; 4]); U 3 = insert (r 1 ; [2; 3])i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. <p> T 1 = hU 1 = insert (r 1 ; <ref> [1; 3] </ref>)i and T 2 = hU 2 = delete (r 2 ; [3; 4]); U 3 = insert (r 1 ; [2; 3])i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. <p> The warehouse receives U 1 = insert (r 1 ; <ref> [1; 3] </ref>) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. The warehouse receives U 2 = delete (r 2 ; [3; 4]) from source y. 2 Since U 2 belongs to a global transaction, it arrives at the warehouse with a transaction id attached. <p> Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the C-Strobe algorithm. 23 There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> The warehouse receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 4. The warehouse receives A 1;1;0 = A 2 1;1;0 = ([1; 2; 3; 4]) from source z, which is the final answer to Q 1;1;0 . <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the warehouse generates a query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 3. The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> It saves this update in a queue. 3. The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the warehouse generates the compensating query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 24 4. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5. <p> For example, suppose the view definition is V = r 1 ./ r 2 , r 1 has attributes A; B, and r 2 has attributes B; C. Further suppose that the current M V contains tuple <ref> [1; 2; 3] </ref> and we know that B is a key for r 2 . If the warehouse receives an update U 1 = insert (r 1 ; [4; 2]), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . <p> If the warehouse receives an update U 1 = insert (r 1 ; [4; 2]), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . Because B is the key for r 2 , and because the view contains <ref> [1; 2; 3] </ref>, we know that r 2 must contain [2; 3]. Therefore, we need to add (exactly) the tuple [4; 2; 3] to the view. 4. <p> Let BT (t) be the set of base relation tuples that derive view tuple t. For example, say we have base relations R (A; B), S (B; C), with A and B as keys of R and S, respectively. If R contains a single tuple <ref> [1; 2] </ref> and S contains a single tuple [2; 3], and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. <p> If R contains a single tuple <ref> [1; 2] </ref> and S contains a single tuple [2; 3], and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. <p> If R contains a single tuple <ref> [1; 2] </ref> and S contains a single tuple [2; 3], and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. However, because of our key constraints on view definitions, a view tuple has only one derivation at a given time. We consider the following three scenarios: 1.
Reference: 2. <author> E. Baralis, S. Ceri, and S. Paraboschi. </author> <title> Conservative timestamp revised for materialized view maintenance in a data warehouse. </title> <booktitle> In Workshop on Materialized Views, </booktitle> <pages> pages 1-9, </pages> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view at the warehouse is M V = ;. We consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. <p> Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view at the warehouse is M V = ;. We consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>). Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. <p> The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. Since the current view is empty, no action is taken for this deletion. 4. The warehouse receives A 2 1 = [1; 2; 3; 4] from source z, which is the final answer for Q 1 . <p> The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. <p> The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to is store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref> which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains [1; 2; 3; 4] which should not exist after <ref> [1; 2] </ref> was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> Furthermore, they require a notion of global time. We compare our definition of consistency with theirs in Section 4. Another recent paper by Baralis, et al. <ref> [2] </ref> also uses timestamps to maintain materialized views at a warehouse. However, they assume that the warehouse never needs to query the sources for more data, hence circumventing all of the consistency problems that we address. A warehouse often processes updates (from one or more transactions) in batch mode. <p> Initially, the relations are A B r 2 : C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 <p> Initially, the relations are A B r 2 : C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The resulting AL = hkey delete (M V; U 2 )i. 4. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The resulting AL = hkey delete (M V; U 2 )i. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the warehouse applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Example 3: T-Strobe provides stronger consistency than Strobe Consider a simple view over one source defined as V = r 1 . Assume attribute A is the key of relation r 1 . Originally, let the relation r 1 contain a single tuple <ref> [1; 2] </ref>. Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; [3; 4])i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> Assume attribute A is the key of relation r 1 . Originally, let the relation r 1 contain a single tuple <ref> [1; 2] </ref>. Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; [3; 4])i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> AL = h i. We consider two source transactions: T 1 = hU 1 = insert (r 1 ; [1; 3])i and T 2 = hU 2 = delete (r 2 ; [3; 4]); U 3 = insert (r 1 ; <ref> [2; 3] </ref>)i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. <p> The warehouse receives U 3 from source x, with an attached transaction id for T 2 . Now that the T 2 updates have been fully received, T-Strobe adds key delete (W C; U 2 ) to AL and sends query Q 2 = <ref> [2; 3] </ref> ./ r 2 to source y. 5. The warehouse receives A 2 = ([2; 3; 5]) from source y and adds insert (M V; A 2 ) to AL. <p> Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the C-Strobe algorithm. 23 There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. <p> Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the C-Strobe algorithm. 23 There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. <p> Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = [1; 2; 3] from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> The warehouse receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 4. The warehouse receives A 1;1;0 = A 2 1;1;0 = ([1; 2; 3; 4]) from source z, which is the final answer to Q 1;1;0 . <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the warehouse generates a query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the warehouse generates a query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> We now consider a different set of events at the warehouse. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> We now consider a different set of events at the warehouse. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 3. The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 3. The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> It saves this update in a queue. 3. The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the warehouse generates the compensating query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 24 4. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5. <p> The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the warehouse generates the compensating query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 24 4. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5. <p> For example, suppose the view definition is V = r 1 ./ r 2 , r 1 has attributes A; B, and r 2 has attributes B; C. Further suppose that the current M V contains tuple <ref> [1; 2; 3] </ref> and we know that B is a key for r 2 . If the warehouse receives an update U 1 = insert (r 1 ; [4; 2]), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . <p> Further suppose that the current M V contains tuple [1; 2; 3] and we know that B is a key for r 2 . If the warehouse receives an update U 1 = insert (r 1 ; <ref> [4; 2] </ref>), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain [2; 3]. <p> Further suppose that the current M V contains tuple [1; 2; 3] and we know that B is a key for r 2 . If the warehouse receives an update U 1 = insert (r 1 ; <ref> [4; 2] </ref>), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain [2; 3]. <p> If the warehouse receives an update U 1 = insert (r 1 ; [4; 2]), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . Because B is the key for r 2 , and because the view contains <ref> [1; 2; 3] </ref>, we know that r 2 must contain [2; 3]. Therefore, we need to add (exactly) the tuple [4; 2; 3] to the view. 4. <p> Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain <ref> [2; 3] </ref>. Therefore, we need to add (exactly) the tuple [4; 2; 3] to the view. 4. <p> Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain [2; 3]. Therefore, we need to add (exactly) the tuple <ref> [4; 2; 3] </ref> to the view. 4. Although we argued against keeping copies of all base relations at the ware house, it may make sense to copy the most frequently accessed ones (or portions thereof), if they are not too large or expensive to keep up to date. <p> Let BT (t) be the set of base relation tuples that derive view tuple t. For example, say we have base relations R (A; B), S (B; C), with A and B as keys of R and S, respectively. If R contains a single tuple <ref> [1; 2] </ref> and S contains a single tuple [2; 3], and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. <p> For example, say we have base relations R (A; B), S (B; C), with A and B as keys of R and S, respectively. If R contains a single tuple [1; 2] and S contains a single tuple <ref> [2; 3] </ref>, and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. <p> If R contains a single tuple <ref> [1; 2] </ref> and S contains a single tuple [2; 3], and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. <p> If R contains a single tuple <ref> [1; 2] </ref> and S contains a single tuple [2; 3], and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. However, because of our key constraints on view definitions, a view tuple has only one derivation at a given time. We consider the following three scenarios: 1. <p> If R contains a single tuple [1; 2] and S contains a single tuple <ref> [2; 3] </ref>, and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. However, because of our key constraints on view definitions, a view tuple has only one derivation at a given time. We consider the following three scenarios: 1.
Reference: 3. <author> P. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view at the warehouse is M V = ;. We consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. <p> consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> Using a conventional incremental view maintenance algorithm [4], the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. <p> The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. <p> The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to is store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref> which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> A warehouse holds a copy of the source data, so essentially we have a distributed database system with replicated data. A good overview of the mechanisms for managing replicated data may be found in <ref> [3] </ref>. However, because of the autonomy of the sources, traditional concurrency mechanisms are often not applicable [5]. A variety of concurrency control schemes have been suggested over the years for such environments (for example, [1, 26, 10]). They either provide weaker notions of consistency, or exploit the semantics of applications. <p> Initially, the relations are A B r 2 : C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 <p> We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the warehouse first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The resulting AL = hkey delete (M V; U 2 )i. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the warehouse applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Assume attribute A is the key of relation r 1 . Originally, let the relation r 1 contain a single tuple [1; 2]. Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; <ref> [3; 4] </ref>)i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> Initially, the relations are: r 1 : A B r 2 : B C 3 5 The materialized view M V = ;. AL = h i. We consider two source transactions: T 1 = hU 1 = insert (r 1 ; <ref> [1; 3] </ref>)i and T 2 = hU 2 = delete (r 2 ; [3; 4]); U 3 = insert (r 1 ; [2; 3])i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. <p> AL = h i. We consider two source transactions: T 1 = hU 1 = insert (r 1 ; [1; 3])i and T 2 = hU 2 = delete (r 2 ; <ref> [3; 4] </ref>); U 3 = insert (r 1 ; [2; 3])i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. <p> AL = h i. We consider two source transactions: T 1 = hU 1 = insert (r 1 ; [1; 3])i and T 2 = hU 2 = delete (r 2 ; [3; 4]); U 3 = insert (r 1 ; <ref> [2; 3] </ref>)i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. <p> T 1 = hU 1 = insert (r 1 ; <ref> [1; 3] </ref>)i and T 2 = hU 2 = delete (r 2 ; [3; 4]); U 3 = insert (r 1 ; [2; 3])i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. <p> The warehouse receives U 1 = insert (r 1 ; <ref> [1; 3] </ref>) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. The warehouse receives U 2 = delete (r 2 ; [3; 4]) from source y. 2 Since U 2 belongs to a global transaction, it arrives at the warehouse with a transaction id attached. <p> The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. The warehouse receives U 2 = delete (r 2 ; <ref> [3; 4] </ref>) from source y. 2 Since U 2 belongs to a global transaction, it arrives at the warehouse with a transaction id attached. The warehouse temporarily stores U 2 in a holding queue, and does not process it until the remaining T 2 updates arrive. 3. <p> The warehouse receives U 3 from source x, with an attached transaction id for T 2 . Now that the T 2 updates have been fully received, T-Strobe adds key delete (W C; U 2 ) to AL and sends query Q 2 = <ref> [2; 3] </ref> ./ r 2 to source y. 5. The warehouse receives A 2 = ([2; 3; 5]) from source y and adds insert (M V; A 2 ) to AL. <p> Therefore, it is not possible to receive a transaction (e.g., T 2 ) without first receiving at least one of the updates of every transaction on which it depends (e.g., T 1 ), in the sense of transaction dependencies <ref> [3] </ref>. That is, condition 2 is automatically enforced. If, on the other hand, site z reports all of the updates of T 2 , then these updates could arrive before the warehouse receives any of T 1 's updates. <p> Initially, the relations are r 1 : 1 2 B C r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the C-Strobe algorithm. 23 There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. <p> Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = [1; 2; 3] from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the warehouse generates a query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> We now consider a different set of events at the warehouse. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> We now consider a different set of events at the warehouse. 1. Delta = ;. The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The warehouse receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the warehouse first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 3. The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> The warehouse receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the warehouse generates the compensating query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 24 4. The warehouse receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5. <p> For example, suppose the view definition is V = r 1 ./ r 2 , r 1 has attributes A; B, and r 2 has attributes B; C. Further suppose that the current M V contains tuple <ref> [1; 2; 3] </ref> and we know that B is a key for r 2 . If the warehouse receives an update U 1 = insert (r 1 ; [4; 2]), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . <p> If the warehouse receives an update U 1 = insert (r 1 ; [4; 2]), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . Because B is the key for r 2 , and because the view contains <ref> [1; 2; 3] </ref>, we know that r 2 must contain [2; 3]. Therefore, we need to add (exactly) the tuple [4; 2; 3] to the view. 4. <p> Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain <ref> [2; 3] </ref>. Therefore, we need to add (exactly) the tuple [4; 2; 3] to the view. 4. <p> Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain [2; 3]. Therefore, we need to add (exactly) the tuple <ref> [4; 2; 3] </ref> to the view. 4. Although we argued against keeping copies of all base relations at the ware house, it may make sense to copy the most frequently accessed ones (or portions thereof), if they are not too large or expensive to keep up to date. <p> For example, say we have base relations R (A; B), S (B; C), with A and B as keys of R and S, respectively. If R contains a single tuple [1; 2] and S contains a single tuple <ref> [2; 3] </ref>, and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. <p> If R contains a single tuple [1; 2] and S contains a single tuple <ref> [2; 3] </ref>, and we have V = A;B (R ./ S), then [1; 2] is a view tuple and BT ([1; 2]) = f [1; 2]; [2; 3]g. As we can see, different sets of base tuples may derive the same view tuple. However, because of our key constraints on view definitions, a view tuple has only one derivation at a given time. We consider the following three scenarios: 1.
Reference: 4. <author> J. Blakeley, P.-A. Larson, and F. Tompa. </author> <title> Efficiently updating materialized views. </title> <booktitle> In SIG MOD, </booktitle> <pages> pages 61-71, </pages> <address> Washington, D.C., </address> <month> June </month> <year> 1986. </year>
Reference-contexts: We consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm <ref> [4] </ref>, the following events may occur at the warehouse. 1. The warehouse receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> The warehouse receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. <p> The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to is store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref> which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems <ref> [4, 14, 6, 16, 21, 24, 8] </ref> and a good overview of materialized views and their maintenance can be found in [13]. <p> As we showed in Example 1, when a centralized algorithm is applied to the warehouse, the warehouse user may see inconsistent views of the source data. These inconsistent views arise regardless of whether the centralized algorithm computes changes using the old base relations, as in <ref> [4] </ref>, or using the new base relations, as in [8]. The crux of the warehouse problem is that the exact state of the base relations (old or new) when the incremental changes are computed at the sources is unknown, and our algorithms filter out or add in recent modifications dynamically. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The resulting AL = hkey delete (M V; U 2 )i. 4. The warehouse receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the warehouse applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Assume attribute A is the key of relation r 1 . Originally, let the relation r 1 contain a single tuple [1; 2]. Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; <ref> [3; 4] </ref>)i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> AL = h i. We consider two source transactions: T 1 = hU 1 = insert (r 1 ; [1; 3])i and T 2 = hU 2 = delete (r 2 ; <ref> [3; 4] </ref>); U 3 = insert (r 1 ; [2; 3])i and apply the T-Strobe algorithm. 1. The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. <p> The warehouse receives U 1 = insert (r 1 ; [1; 3]) from source x. It generates query Q 1 = [1; 3] ./ r 2 and sends Q 1 to source y for evaluation. 2. The warehouse receives U 2 = delete (r 2 ; <ref> [3; 4] </ref>) from source y. 2 Since U 2 belongs to a global transaction, it arrives at the warehouse with a transaction id attached. The warehouse temporarily stores U 2 in a holding queue, and does not process it until the remaining T 2 updates arrive. 3. <p> Further suppose that the current M V contains tuple [1; 2; 3] and we know that B is a key for r 2 . If the warehouse receives an update U 1 = insert (r 1 ; <ref> [4; 2] </ref>), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain [2; 3]. <p> Further suppose that the current M V contains tuple [1; 2; 3] and we know that B is a key for r 2 . If the warehouse receives an update U 1 = insert (r 1 ; <ref> [4; 2] </ref>), there is no need to send the query [4; 2] ./ r 2 to the source containing r 2 . Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain [2; 3]. <p> Because B is the key for r 2 , and because the view contains [1; 2; 3], we know that r 2 must contain [2; 3]. Therefore, we need to add (exactly) the tuple <ref> [4; 2; 3] </ref> to the view. 4. Although we argued against keeping copies of all base relations at the ware house, it may make sense to copy the most frequently accessed ones (or portions thereof), if they are not too large or expensive to keep up to date. <p> Given these costs, users can now determine what is best for them, given their consistency requirements and their transactional scenario. Third, when updates arrive infrequently at the warehouse, or only in periodic batches with large gaps in between, the Strobe algorithms are as efficient as conventional algorithms such as <ref> [4] </ref>. They only introduce extra complexity when updates must be processed while other updates are arriving at the warehouse, which is when conventional algorithms cannot guarantee a consistent view. Recall that in Section 3 we made a critical "event ordering" assumption.
Reference: 5. <author> Y. Breitbart, H. Garcia-Molina, and A. Silberschatz. </author> <title> Overview of multidatabase transaction management. </title> <journal> VLDB Journal, </journal> <volume> 1(2) </volume> <pages> 181-239, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: A good overview of the mechanisms for managing replicated data may be found in [3]. However, because of the autonomy of the sources, traditional concurrency mechanisms are often not applicable <ref> [5] </ref>. A variety of concurrency control schemes have been suggested over the years for such environments (for example, [1, 26, 10]). They either provide weaker notions of consistency, or exploit the semantics of applications.
Reference: 6. <author> S. Ceri and J. Widom. </author> <title> Deriving production rules for incremental view maintenance. </title> <booktitle> In VLDB, </booktitle> <pages> pages 577-589, </pages> <address> Barcelona, Spain, </address> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems <ref> [4, 14, 6, 16, 21, 24, 8] </ref> and a good overview of materialized views and their maintenance can be found in [13].
Reference: 7. <author> M. Cochinwala and J. Bradley. </author> <title> A multidatabase system for tracking and retrieval of financial data. </title> <booktitle> In VLDB, </booktitle> <pages> pages 714-721, </pages> <year> 1994. </year>
Reference-contexts: In our company example, we would need to update the stock prices of all companies, as the prices change. This can represent a very high update load <ref> [7] </ref>, much of it to data we may never need. Third, due to cost, copyright or security, storing copies of all of the source data may not be feasible. For example, the source access charges may be proportional to the amount of data we track at the warehouse.
Reference: 8. <author> L. Colby, T. Griffin, L. Libkin, I. Mumick, and H. Trickey. </author> <title> Algorithms for deferred view maintenance. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 469-480, </pages> <address> Montreal, Quebec, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems <ref> [4, 14, 6, 16, 21, 24, 8] </ref> and a good overview of materialized views and their maintenance can be found in [13]. <p> These inconsistent views arise regardless of whether the centralized algorithm computes changes using the old base relations, as in [4], or using the new base relations, as in <ref> [8] </ref>. The crux of the warehouse problem is that the exact state of the base relations (old or new) when the incremental changes are computed at the sources is unknown, and our algorithms filter out or add in recent modifications dynamically.
Reference: 9. <author> A. Courtney, W. Janssen, D. Severson, M. Spreitzer, and F. Wymore. </author> <note> Inter-language unifica tion, release 1.5. Technical Report ISTL-CSA-94-01-01 (Xerox accession number P94-00058, Xerox PARC, </note> <month> May </month> <year> 1994. </year> <month> 36 </month>
Reference-contexts: Figure 8.2 shows the architecture of the WHIPS system. Each box in the figure is a module that performs a specific function. Each module is implemented as a CORBA object. They communicate with each other using ILU, a COBRA compliant object library developed by Xerox PARC <ref> [9] </ref>. Different modules can reside on different machines and can be implemented in different language. Similar to a real-world data warehousing system, data sources are separated from the integration modules, and the warehouse is a separate database which may or may not be closely coupled with the integration components.
Reference: 10. <author> R. Gallersdorfer and M. Nicola. </author> <title> Improving performance in replicated databases through relaxed coherency. </title> <booktitle> In VLDB, </booktitle> <pages> pages 445-456, </pages> <address> Zurich, Switzerland, </address> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: A good overview of the mechanisms for managing replicated data may be found in [3]. However, because of the autonomy of the sources, traditional concurrency mechanisms are often not applicable [5]. A variety of concurrency control schemes have been suggested over the years for such environments (for example, <ref> [1, 26, 10] </ref>). They either provide weaker notions of consistency, or exploit the semantics of applications. The algorithms we present in this paper exploit the semantics of materialized view maintenance to obtain consistency without traditional distributed concurrency control.
Reference: 11. <author> H. Garcia-Molina and G. Wiederhold. </author> <title> Read-only transactions in a distributed database. </title> <journal> ACM Transaction on Database Systems, </journal> <volume> 7(2) </volume> <pages> 209-234, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: Our definition is compatible with standard serializability theory. In fact, our consistency definition can be rephrased in terms of serializability theory, by treating the warehouse view evaluation as a read only transaction <ref> [11] </ref> at the sources. Although completeness is a nice property since it states that the view "tracks" the base data exactly, we believe it may be too strong a requirement and unnecessary in most practical warehousing scenarios.
Reference: 12. <author> R. Goldring and B. Hamel, </author> <month> Jan. </month> <year> 1996. </year> <title> Personal correspondence about IBM's data warehouse customer needs. </title>
Reference-contexts: Furthermore, as more and more updates occur, the down time window may no longer be sufficient to process all of the updates <ref> [12] </ref>. Thus, there is substantial interest in warehouses that can absorb incoming updates and incrementally modify the materialized views at the warehouse, without halting query processing. In this paper we focus on this process and on how to ensure that queries see consistent data. <p> Note that as concurrent query and update processing at warehouses becomes more common, and as warehouse applications grow beyond "statistical analysis," there will be more concern from users about the consistency of the data they are accessing <ref> [12] </ref>. Thus, we believe it is important to offer customers a variety of consistency options and ways to enforce them. 3. We develop the Strobe family of algorithms to provide consistency for each of the transaction scenarios.
Reference: 13. <author> A. Gupta and I. Mumick. </author> <title> Maintenance of materialized views: Problems, techniques, </title> <journal> and applications. IEEE Data Engineering Bulletin, Special Issue on Materialized Views and Data Warehousing, </journal> <volume> 18(2) </volume> <pages> 3-18, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems [4, 14, 6, 16, 21, 24, 8] and a good overview of materialized views and their maintenance can be found in <ref> [13] </ref>. Most of these solutions assume that a single system controls all of the base relations and understands the views and hence can intelligently monitor activities and compute all of the information that is needed for updating the views. <p> Further discussion of how to treat a modification as an insert and a delete may be found in <ref> [13] </ref>. 5.2. Strobe The Strobe algorithm processes updates as they arrive, sending queries to the sources when necessary. However, the updates are not performed immediately on the materialized view M V ; instead, we generate a list of actions AL to be performed on the view.
Reference: 14. <author> A. Gupta, I. Mumick, and V. Subrahmanian. </author> <title> Maintaining views incrementally. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 157-166, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems <ref> [4, 14, 6, 16, 21, 24, 8] </ref> and a good overview of materialized views and their maintenance can be found in [13].
Reference: 15. <author> A. Gupta and J. Widom. </author> <title> Local verification of global integrity constraints in distributed databases. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 49-58, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: However, delaying update processing means the warehouse view will not be as up to date, so there is a clear tradeoff that we would like to explore. 3. We can use key information to avoid sending some queries to sources <ref> [15] </ref>. For example, suppose the view definition is V = r 1 ./ r 2 , r 1 has attributes A; B, and r 2 has attributes B; C.
Reference: 16. <author> J. Harrison and S. Dietrich. </author> <title> Maintenance of materialized views in a deductive database: An update propagation approach. </title> <booktitle> In Proceedings of the 1992 JICLSP Workshop on Deductive Databases, </booktitle> <pages> pages 56-65, </pages> <year> 1992. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems <ref> [4, 14, 6, 16, 21, 24, 8] </ref> and a good overview of materialized views and their maintenance can be found in [13].
Reference: 17. <author> R. Hull and G. Zhou. </author> <title> A framework for supporting data integration using the materialized and virtual approaches. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 481-492, </pages> <address> Montreal, Quebec, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Previous distributed algorithms for view maintenance, such as those in [22, 23, 20], rely on timestamping the updated tuples. For a warehousing environment, sources can be legacy systems so we cannot assume that they will help by transmitting all necessary data or by attaching timestamps. Hull and Zhou <ref> [17] </ref> provide a framework for supporting distributed data integration using materialized views. However, their approach first materializes each base relation (or relevant portion), then computes the view from the materialized copies. <p> That is, there is a complete order-preserving mapping between the states of the view and the states of the sources. Hull and Zhou's definition of consistency for replicated data <ref> [17] </ref> is similar to our strong consistency, except that they also require a global timestamps across sources, which we do not. Also, our strong consistency is less restrictive than theirs in that we do not require any fixed order between two non-conflicting actions.
Reference: 18. <author> W. Inmon and C. Kelley. Rdb/VMS: </author> <title> Developing the Data Warehouse. </title> <publisher> QED Publishing Group, </publisher> <address> Boston, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: We discuss each in turn. Data warehouses are large repositories for analytical data, and have recently generated tremendous interest in industry. A general description of the data warehousing idea may be found in <ref> [18] </ref>. Companies such as Red Brick and Prism have built specialized data warehousing software, while almost all other database vendors, such as Sybase, Oracle and IBM, are targeting their existing products to data warehousing applications.
Reference: 19. <author> W. Labio and H. Garcia-Molina. </author> <title> Efficient snapshot differential algorithms in data warehous ing. </title> <booktitle> In VLDB, </booktitle> <pages> pages 63-74, </pages> <address> Bombay, India, </address> <month> Sept. </month> <year> 1996. </year>
Reference-contexts: When the system is running, one view manager maintains one view. After a view is initialized and stored at the warehouse, source monitors detect changes on the source data and notify the integrator <ref> [19] </ref>. The integrator then forwards source updates to the relevant view managers. All view managers work concurrently to maintain their own view. A view manager manages source updates and maintains data structures for view maintenance.
Reference: 20. <author> B. Lindsay, L. Haas, C. Mohan, H. Pirahesh, and P. Wilms. </author> <title> A snapshot differential refresh algorithm. </title> <booktitle> In SIGMOD, </booktitle> <address> Washington, D.C., </address> <month> May </month> <year> 1986. </year>
Reference-contexts: We allow modifications to the base relations to execute concurrently, and then compensate the proposed view changes for those modifications. Previous distributed algorithms for view maintenance, such as those in <ref> [22, 23, 20] </ref>, rely on timestamping the updated tuples. For a warehousing environment, sources can be legacy systems so we cannot assume that they will help by transmitting all necessary data or by attaching timestamps. Hull and Zhou [17] provide a framework for supporting distributed data integration using materialized views.
Reference: 21. <author> X. Qian and G. Wiederhold. </author> <title> Incremental recomputation of active relational expressions. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 3(3) </volume> <pages> 337-341, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems <ref> [4, 14, 6, 16, 21, 24, 8] </ref> and a good overview of materialized views and their maintenance can be found in [13].
Reference: 22. <author> A. Segev and W. Fang. </author> <title> Currency-based updates to distributed materialized views. </title> <booktitle> In ICDE, </booktitle> <pages> pages 512-520, </pages> <address> Los Alamitos, </address> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: We allow modifications to the base relations to execute concurrently, and then compensate the proposed view changes for those modifications. Previous distributed algorithms for view maintenance, such as those in <ref> [22, 23, 20] </ref>, rely on timestamping the updated tuples. For a warehousing environment, sources can be legacy systems so we cannot assume that they will help by transmitting all necessary data or by attaching timestamps. Hull and Zhou [17] provide a framework for supporting distributed data integration using materialized views.
Reference: 23. <author> A. Segev and J. Park. </author> <title> Updating distributed materialized views. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(2) </volume> <pages> 173-184, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: We allow modifications to the base relations to execute concurrently, and then compensate the proposed view changes for those modifications. Previous distributed algorithms for view maintenance, such as those in <ref> [22, 23, 20] </ref>, rely on timestamping the updated tuples. For a warehousing environment, sources can be legacy systems so we cannot assume that they will help by transmitting all necessary data or by attaching timestamps. Hull and Zhou [17] provide a framework for supporting distributed data integration using materialized views.
Reference: 24. <author> O. Shmueli and A. Itai. </author> <title> Maintenance of views. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 240-255, </pages> <address> Boston, Mas sachusetts, </address> <month> May </month> <year> 1984. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems <ref> [4, 14, 6, 16, 21, 24, 8] </ref> and a good overview of materialized views and their maintenance can be found in [13].
Reference: 25. <institution> Sybase, Inc. </institution> <note> Command Reference Manual, release 4.9 edition, </note> <year> 1992. </year>
Reference-contexts: We assume that each single update transaction and source-local transaction is reported in one message, at the time that the transaction commits. For example, a relational database source might trigger sending a message on transaction commit <ref> [25] </ref>. However, batching multiple transactions into the same message does not affect the algorithms of Section 5. For global transactions, updates can be delivered in a variety of ways.
Reference: 26. <author> G. Wiederhold and X. Qian. </author> <title> Consistency control of replicated data in federated databases. </title> <booktitle> In Proceedings of the IEEE Workshop on Management of Replicated Data, </booktitle> <pages> pages 130-132, </pages> <address> Houston, Texas, </address> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: A good overview of the mechanisms for managing replicated data may be found in [3]. However, because of the autonomy of the sources, traditional concurrency mechanisms are often not applicable [5]. A variety of concurrency control schemes have been suggested over the years for such environments (for example, <ref> [1, 26, 10] </ref>). They either provide weaker notions of consistency, or exploit the semantics of applications. The algorithms we present in this paper exploit the semantics of materialized view maintenance to obtain consistency without traditional distributed concurrency control.
Reference: 27. <author> J. Wiener, H. Gupta, W. Labio, Y. Zhuge, H. Garcia-Molina, and J. Widom. </author> <title> A system prototype for warehouse view maintenance. </title> <booktitle> In Workshop on Materialized Views, </booktitle> <pages> pages 26-33, </pages> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Thus, we believe it is important to offer customers a variety of consistency options and ways to enforce them. 3. We develop the Strobe family of algorithms to provide consistency for each of the transaction scenarios. We have implemented each of the Strobe algorithms in our warehouse prototype <ref> [27] </ref>, demonstrating that the algorithms are practical and efficient. 4. We map out the space of warehouse maintenance algorithms (Figure 9.3). The algorithms we present in this paper provide a wide number of options for this consistency and distribution space. The remainder of the paper is organized as follows. <p> We call this algorithm C-TStrobe, but do not describe it here further. 8. Implementation of the Strobe family of algorithms The Strobe family of algorithms, include Strobe, T-Strobe and C-Strobe are implemented in the WHIPS prototype (WareHousing Information Project at Stanford) <ref> [27] </ref>. Figure 8.2 shows the architecture of the WHIPS system. Each box in the figure is a module that performs a specific function. Each module is implemented as a CORBA object. They communicate with each other using ILU, a COBRA compliant object library developed by Xerox PARC [9].
Reference: 28. <author> Y. Zhuge, H. Garcia-Molina, J. Hammer, and J. Widom. </author> <title> View maintenance in a warehousing environment. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 316-327, </pages> <address> San Jose, California, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: They are substantially more complex than the ones presented here | another reason for including keys in the view.) 5 In our previous work <ref> [28] </ref> we considered a very restricted scenario: all warehouse data arrived from a single source. Even in that simple case, there are consistency problems, and we developed algorithms for solving them. <p> Even in that simple case, there are consistency problems, and we developed algorithms for solving them. However, in the more realistic multi-source scenario, it becomes significantly more complex to maintain consistent views. (For instance, the ECA and ECA-Key algorithms of <ref> [28] </ref> do not provide consistency in Example 1; they lead to the same incorrect execution shown.) In particular, the complexities not covered in our earlier work are as follows. * An update from one source may need to be integrated with data from several other sources. <p> In this paper we present view maintenance algorithms that address these problems. Finally, as we mentioned in Section 1, in <ref> [28] </ref> we showed how to provide consistency in a restricted single-source environment. Here we study the more general case of multiple sources and transactions that may span sources. 3. Warehouse transaction environment The complexity of designing consistent warehouse algorithms is closely related to the scope of transactions at the sources. <p> We define four levels of consistency for warehouse views. Each level subsumes all prior levels. These definition are a generalization of the ones in <ref> [28] </ref> for a multi-source warehouse environment. 1. Convergence: For all finite executions, V (ws f ) = V (ss q ). That is, after the last update and after all activity has ceased, the view is consistent with the source data. 2. <p> Figure 9.3 summarizes the algorithms we discussed in this paper and their correctness. In the figure, "Conventional" refers to a conventional centralized view maintenance algorithm, while "ECA" and "ECA-Key" are algorithms from <ref> [28] </ref>. <p> Therefore, although not all source states will be reflected in the view, the view always reflects a consistent set of source states. We note that the ECA-key algorithm in <ref> [28] </ref> does not always process deletions correctly even in a single source environment. The problem occurs when the deleted tuple is the same as an inserted tuple participating in an ongoing query. The Strobe algorithm corrects this error and processes all updates correctly.
Reference: 29. <author> Y. Zhuge, H. Garcia-Molina, and J. Wiener. </author> <title> The Strobe algorithms for multi-source ware house consistency. </title> <type> Technical report, </type> <institution> Stanford University, </institution> <month> October </month> <year> 1995. </year> <note> Available via anonymous ftp from host db.stanford.edu as pub/zhuge/1995/consistency-full.ps. </note>
Reference-contexts: C-Strobe is complete because M V is updated once after each update, and the resulting warehouse state corresponds to the source state after the same update. We prove the correctness of C-Strobe in <ref> [29] </ref>. The compensating process (the loop in the algorithm) always terminates because any expression Q i;j;k hU p i always has one fewer base relation than Q i;j;k .
Reference: 30. <author> Y. Zhuge, J. L. Wiener, and H. Garcia-Molina. </author> <title> Multiple view consistency for data warehous ing. </title> <booktitle> In ICDE, </booktitle> <address> Birmingham, UK, </address> <month> Apr. </month> <year> 1997. </year> <note> Received Date Accepted Date Final Manuscript Date </note>
Reference-contexts: We are also extending the algorithms to handle more general type of views, for example, views with insufficient key information, and views defined by more complex relational algebra expressions. Our future work includes designing maintenance algorithms that coordinate updates to multiple warehouse views <ref> [30] </ref>. Acknowledgments We would like to thank Jennifer Widom and Jose Blakely for discussions that led to some of the ideas in this paper. Appendix A.1. Proof of correctness for Strobe Algorithm The Strobe algorithm provides strong consistency for all single-update transaction environments.
References-found: 30

