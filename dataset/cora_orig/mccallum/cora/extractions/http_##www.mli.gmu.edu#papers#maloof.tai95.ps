URL: http://www.mli.gmu.edu/papers/maloof.tai95.ps
Refering-URL: http://www.mli.gmu.edu/kpubs.html
Root-URL: 
Title: A Method for Partial-Memory Incremental Learning and its Application to Computer Intrusion Detection Machine Learning
Author: Marcus A. Maloof Ryszard S. Michalski 
Address: Fairfax, VA 22030-4444  
Affiliation: 422 Science Technology II George Mason University  Also: Institute of Computer Science, Polish Academy of Science  
Note: Proceedings of the 7th IEEE International Conference on Tools with Artificial Intelligence, 392397 Washington, DC,  
Pubnum: Laboratory  
Email: maloof, michalski-@aic.gmu.edu  
Date: November 5-8, 1995  
Abstract: This paper describes a partial-memory incremental learning method based on the AQ15c inductive learning system. The method maintains a representative set of past training examples that are used together with new examples to appropriately modify the currently held hypotheses. Incremental learning is evoked by feedback from the environment or from the user. Such a method is useful in applications involving intelligent agents acting in a changing environment, active vision, and dynamic knowledge-bases. For this study, the method is applied to the problem of computer intrusion detection in which symbolic profiles are learned for a computer systems users. In the experiments, the proposed method yielded significant gains in terms of learning time and memory requirements at the expense of slightly lower predictive accuracy and higher concept complexity, when compared to batch learning, in which all examples are given at once. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. S. Michalski, </author> <title> On the quasi-minimal solution of the general covering problem, </title> <booktitle> F i f t h International Symposium on Information Processing, </booktitle> <volume> vol. </volume> <pages> A3, pp. 125128, </pages> <year> 1969. </year>
Reference-contexts: 1 Introduction This paper describes a partial-memory incremental learning method. The method is based on the AQ inductive learning algorithm and uses Variable-Valued Logic (VL 1 ) as a representation language <ref> [1, 2, 3, 4] </ref>. The proposed method is incremental in that (a) static concepts are learned over time, and (b) concepts that change over time are learned.
Reference: [2] <author> R. S. Michalski, </author> <title> A variable-valued logic system as applied to picture description and recognition, </title> <booktitle> IFIP Working Conference on Graphic Languages, </booktitle> <pages> pp. 2147, </pages> <year> 1972. </year> <month> 6 </month>
Reference-contexts: 1 Introduction This paper describes a partial-memory incremental learning method. The method is based on the AQ inductive learning algorithm and uses Variable-Valued Logic (VL 1 ) as a representation language <ref> [1, 2, 3, 4] </ref>. The proposed method is incremental in that (a) static concepts are learned over time, and (b) concepts that change over time are learned.
Reference: [3] <author> R. S. Michalski, </author> <title> AQVAL/1 computer implementation of a variable-valued logic system VL 1 and examples of its application to pattern recognition, </title> <booktitle> First International Joint Conference on Pattern Recognition, </booktitle> <volume> 317, </volume> <year> 1973. </year>
Reference-contexts: 1 Introduction This paper describes a partial-memory incremental learning method. The method is based on the AQ inductive learning algorithm and uses Variable-Valued Logic (VL 1 ) as a representation language <ref> [1, 2, 3, 4] </ref>. The proposed method is incremental in that (a) static concepts are learned over time, and (b) concepts that change over time are learned.
Reference: [4] <author> R. S. Michalski, </author> <title> Pattern recognition as rule guided inductive inference, </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 2, no. 4, </volume> <pages> pp. 349361, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction This paper describes a partial-memory incremental learning method. The method is based on the AQ inductive learning algorithm and uses Variable-Valued Logic (VL 1 ) as a representation language <ref> [1, 2, 3, 4] </ref>. The proposed method is incremental in that (a) static concepts are learned over time, and (b) concepts that change over time are learned.
Reference: [5] <author> R. E. Reinke and R. S. Michalski, </author> <title> Incremental learning of concept descriptions: a method and experimental results, </title> <booktitle> Machine Intelligence 11, </booktitle> <editor> J. E. Hayes, D. Michie and J. Richards (Eds), </editor> <publisher> Clarendon Press, Oxford, </publisher> <pages> pp. 263288, </pages> <year> 1988. </year>
Reference-contexts: The proposed method is incremental in that (a) static concepts are learned over time, and (b) concepts that change over time are learned. The proposed method operates using a partial-memory mode <ref> [5] </ref>, in which representative examples are maintained throughout the learning process that maximally expand and constrain learned concepts in the event space. Learned concepts aid in determining the set of representative concepts. <p> Learned concepts aid in determining the set of representative concepts. This partial-memory scheme is contrasted by no-memory incremental learning (e.g., reinforcement learning), and full-memory incremental learning <ref> [6, 5, 7] </ref>. New applications, such as intelligent agents (e.g., [8]) and active vision (e.g., [9]), require autonomous or semi-autonomous functioning and adaptation to changes in the domain, the environment, or the user. Such requirements suggest that incremental learning, as opposed to batch learning, is needed. <p> There are probably ways to optimize rules based on the representative examples that will yield simpler rules. This notion will be investigated during implementation. Note that these results are consistent with the full-memory incremental learning results reported by Reinke and Michalski <ref> [5] </ref>. Future work will compare partial-memory incremental learning with AQ15 full-memory incremental learning. 4 Discussion and Future Work users daffy and elmer.
Reference: [6] <author> J. Hong, I. Mozetic and R. S. Michalski, </author> <title> AQ15: incremental learning of attribute-based descriptions from examples, the method and users guide, </title> <institution> UIUCDCS-F-86-949, Department of Computer Science, University of Illinois, Urbana, IL, </institution> <year> 1986. </year>
Reference-contexts: Learned concepts aid in determining the set of representative concepts. This partial-memory scheme is contrasted by no-memory incremental learning (e.g., reinforcement learning), and full-memory incremental learning <ref> [6, 5, 7] </ref>. New applications, such as intelligent agents (e.g., [8]) and active vision (e.g., [9]), require autonomous or semi-autonomous functioning and adaptation to changes in the domain, the environment, or the user. Such requirements suggest that incremental learning, as opposed to batch learning, is needed.
Reference: [7] <author> M. K. Bhandaru and M. N. Murty, </author> <title> Incremental learning from examples using HC-expressions, </title> <journal> Pattern Recognition, </journal> <volume> vol. 24, no. 4, </volume> <pages> pp. 273 282, </pages> <year> 1991. </year>
Reference-contexts: Learned concepts aid in determining the set of representative concepts. This partial-memory scheme is contrasted by no-memory incremental learning (e.g., reinforcement learning), and full-memory incremental learning <ref> [6, 5, 7] </ref>. New applications, such as intelligent agents (e.g., [8]) and active vision (e.g., [9]), require autonomous or semi-autonomous functioning and adaptation to changes in the domain, the environment, or the user. Such requirements suggest that incremental learning, as opposed to batch learning, is needed.
Reference: [8] <author> P. Maes, </author> <title> Agents that reduce work and information overload, </title> <journal> Communications of the ACM, </journal> <volume> vol. 37, no. 7, </volume> <pages> pp. 3140, </pages> <year> 1994. </year>
Reference-contexts: Learned concepts aid in determining the set of representative concepts. This partial-memory scheme is contrasted by no-memory incremental learning (e.g., reinforcement learning), and full-memory incremental learning [6, 5, 7]. New applications, such as intelligent agents (e.g., <ref> [8] </ref>) and active vision (e.g., [9]), require autonomous or semi-autonomous functioning and adaptation to changes in the domain, the environment, or the user. Such requirements suggest that incremental learning, as opposed to batch learning, is needed.
Reference: [9] <author> D. Ballard and C. Brown, </author> <title> Principles of animate vision, Active Perception, </title> <editor> Y. Aloimonos (Ed), </editor> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. 245282, </pages> <year> 1993. </year>
Reference-contexts: Learned concepts aid in determining the set of representative concepts. This partial-memory scheme is contrasted by no-memory incremental learning (e.g., reinforcement learning), and full-memory incremental learning [6, 5, 7]. New applications, such as intelligent agents (e.g., [8]) and active vision (e.g., <ref> [9] </ref>), require autonomous or semi-autonomous functioning and adaptation to changes in the domain, the environment, or the user. Such requirements suggest that incremental learning, as opposed to batch learning, is needed.
Reference: [10] <author> D. E. Denning, </author> <title> An intrusion-detection model, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-13, no. 2, </volume> <pages> pp. 222232, </pages> <year> 1987. </year>
Reference-contexts: Although incremental learning is needed in application areas such as intelligent agents and active vision, the application considered here is a dynamic knowledge-based system for computer intrusion detection <ref> [10] </ref>. Quite a bit of research has been conducted in attempts to statistically model user behavior [11, 12, 13, 14]. Statistical models, or profiles, once acquired, are subsequently used to verify that a users recent behavior is consistent with past behavior.
Reference: [11] <author> S. E. Smaha, Haystack: </author> <title> an intrusion detection system, </title> <booktitle> Proceedings of the Fourth Aerospace Computer Security Applications Conference, </booktitle> <pages> pp. 3744, </pages> <year> 1988. </year>
Reference-contexts: Although incremental learning is needed in application areas such as intelligent agents and active vision, the application considered here is a dynamic knowledge-based system for computer intrusion detection [10]. Quite a bit of research has been conducted in attempts to statistically model user behavior <ref> [11, 12, 13, 14] </ref>. Statistical models, or profiles, once acquired, are subsequently used to verify that a users recent behavior is consistent with past behavior. While a statistical approach to this problem is certainly valid, there are advantages to the machine learning approach taken here.
Reference: [12] <author> T. F. Lunt, R. Jagannathan, R. Lee, A. Whitehurst, and S. Listgarten, </author> <title> Knowledge-based intrusion detection, </title> <booktitle> Proceedings of the Annual Artificial Intelligence Systems in Government Conference, </booktitle> <pages> pp. 102107, </pages> <year> 1989. </year>
Reference-contexts: Although incremental learning is needed in application areas such as intelligent agents and active vision, the application considered here is a dynamic knowledge-based system for computer intrusion detection [10]. Quite a bit of research has been conducted in attempts to statistically model user behavior <ref> [11, 12, 13, 14] </ref>. Statistical models, or profiles, once acquired, are subsequently used to verify that a users recent behavior is consistent with past behavior. While a statistical approach to this problem is certainly valid, there are advantages to the machine learning approach taken here.
Reference: [13] <author> H. S. Vaccaro, </author> <title> Detection of anomalous computer session activity, </title> <booktitle> Proceedings of the 1989 IEEE Symposium on Research in Security and Privacy, </booktitle> <pages> pp. 280289, </pages> <year> 1989. </year>
Reference-contexts: Although incremental learning is needed in application areas such as intelligent agents and active vision, the application considered here is a dynamic knowledge-based system for computer intrusion detection [10]. Quite a bit of research has been conducted in attempts to statistically model user behavior <ref> [11, 12, 13, 14] </ref>. Statistical models, or profiles, once acquired, are subsequently used to verify that a users recent behavior is consistent with past behavior. While a statistical approach to this problem is certainly valid, there are advantages to the machine learning approach taken here.
Reference: [14] <author> D. Anderson, T. Frivold and A. Valdes, </author> <title> Next Generation Intrusion Detection Expert System (NIDES): </title> <type> final technical report, </type> <institution> S R I International Final Technical Report A008, SRI International, </institution> <address> Menlo Park, CA, </address> <year> 1994. </year>
Reference-contexts: Although incremental learning is needed in application areas such as intelligent agents and active vision, the application considered here is a dynamic knowledge-based system for computer intrusion detection [10]. Quite a bit of research has been conducted in attempts to statistically model user behavior <ref> [11, 12, 13, 14] </ref>. Statistical models, or profiles, once acquired, are subsequently used to verify that a users recent behavior is consistent with past behavior. While a statistical approach to this problem is certainly valid, there are advantages to the machine learning approach taken here.
Reference: [15] <author> M. A. Maloof and R. S. Michalski, </author> <title> A partial memory incremental learning methodology and its application to intrusion detection, Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 952, </type> <institution> Department of Computer Science, George Mason University, Fairfax, VA, </institution> <year> 1995. </year>
Reference-contexts: See <ref> [15] </ref> for a more complete literature review. The organization of this paper is as follows. The next section introduces the incremental learning architecture and method based on VL 1 and the AQ algorithm. Section 3 describes experimental results. <p> Only two users were selected, since the bulk of the experimentation was carried out manually. Performance comparisons are made between AQ15c batch learning and partial-memory incremental learning. Further details regarding batch learning experimental results and the specific learning parameters used can be found in <ref> [15] </ref>. 3 . 1 Data Preparation The first task involved extracting training examples for each user. A session is defined as a contiguous period of activity bounded by a gap in activity of 20 minutes or more. This includes idle time and logouts. <p> Batch learning experiments on the entire data set are reported by Maloof and Michalski <ref> [15] </ref>. The training data for these two classes were partitioned into 10 sets and used for partial-memory incremental 4 learning experiments, which were compared to AQ15c batch learning. The batch learning experiment involved accumulating the training examples from the 10 data partitions for learning.
Reference: [16] <author> J. Wnek, K. Kaufman, E. Bloedorn and R. S. Michalski, </author> <title> Selective Induction Learning System AQ15c: the method and users guide, Reports of the Machine Learning and Inference Laboratory, MLI 954, Machine Learning and Inference Laboratory, </title> <institution> Department of Computer Science, George Mason University, Fairfax, VA, </institution> <year> 1995. </year>
Reference-contexts: These would include making a entry in a systems log file or even forcing the suspect user off the system. Because of AQs flexible matching algorithm <ref> [16] </ref>, the intrusion detection system not only produces a decision or classification (i.e., a users identity), but it also provides a measure of certainty using the degree of match.
Reference: [17] <author> H. S. Teng, K. Chen, and S. C-Y. Lu, </author> <title> Security audit trail analysis using inductively generated predictive rules, </title> <booktitle> Proceedings of the Sixth Confe re nce on Artific ial I ntellig enc e Applications, </booktitle> <pages> pp. 2429, </pages> <year> 1990. </year>
Reference-contexts: Typically, an intruder masquerades as one of the legitimate system users. If machine learning could be used to learn use patterns for the users of the computer system, then these patterns could be used to detect intruders. This research is most similar to the work of Teng et al. <ref> [17] </ref> in the sense that we are inductively learning symbolic rules. It differs in that we do not learn from temporal sequences of actions.
Reference: [18] <author> H. S. Javitz and A. Valdes, </author> <title> The NIDES Statistical Component: description and justification, </title> <booktitle> SRI International Annual Report A010, SRI International, </booktitle> <address> Menlo Park, CA, </address> <year> 1994. </year>
Reference-contexts: Because of AQs flexible matching algorithm [16], the intrusion detection system not only produces a decision or classification (i.e., a users identity), but it also provides a measure of certainty using the degree of match. The degree of match functions similarly to the abnormality measure in NIDES <ref> [18] </ref>. 3 Experimental Results A series of experiments was conducted using Unix acctcom audit data. Accounting data was collecting for a period of three weeks yielding over 11,200 audit records. A set of experiments involved partial-memory incremental learning from two of the systems active users.
Reference: [19] <author> J. H. Davis, CONVART: </author> <title> a program for constructive induction on time dependent data, </title> <type> Masters Thesis, </type> <institution> Department of Computer Science, University of Illinois, Urbana, IL, </institution> <year> 1981. </year>
Reference-contexts: This includes idle time and logouts. Audit data produced by the Unix acctcom command was parsed into sessions by user. Attributes were then computed from the various data fields in the audit file. Each numeric metric in an audit file is a time series. Davis <ref> [19] </ref> characterized time series data for symbolic learning by taking the minimum, maximum, and average values of a time series over a window. For this application, a window is a session of activity.
Reference: [20] <author> E. Bloedorn, J. Wnek, R. S. Michalski and K. Kaufman, </author> <title> AQ17 A multistrategy learning system: the method and users guide, Reports of the Machine Learning and Inference Laboratory, MLI 9312, Machine Learning and Inference Laboratory, </title> <institution> Department of Computer Science, George Mason University, Fairfax, VA, </institution> <year> 1993. </year>
Reference-contexts: Consequently, each training example, which was derived from a single user session, consisted of 21 continuous or real-valued attributes. Totally, there were 239 training examples distributed over 9 classes, which correspond to 9 selected users. AQ15c requires discrete-valued attributes, so the SCALE implementation <ref> [20] </ref> of the ChiMerge algorithm [21] was used. The ChiMerge algorithm merges real-valued attributes into discrete intervals using the chisquare statistic to correlate intervals to classes. For example, the minchar attribute, which is the minimum number of characters transferred during a session, ranged from 0.0 to 18747.28.
Reference: [21] <author> R. Kerber, ChiMerge: </author> <title> discretization of numeric attributes, </title> <booktitle> AAAI-92, </booktitle> <pages> pp. 123128, </pages> <year> 1992. </year>
Reference-contexts: Consequently, each training example, which was derived from a single user session, consisted of 21 continuous or real-valued attributes. Totally, there were 239 training examples distributed over 9 classes, which correspond to 9 selected users. AQ15c requires discrete-valued attributes, so the SCALE implementation [20] of the ChiMerge algorithm <ref> [21] </ref> was used. The ChiMerge algorithm merges real-valued attributes into discrete intervals using the chisquare statistic to correlate intervals to classes. For example, the minchar attribute, which is the minimum number of characters transferred during a session, ranged from 0.0 to 18747.28.
Reference: [22] <author> J. R. Quinlan, </author> <title> Learning efficient classification procedures and their application to chess end games, Machine Learning: An Artificial Intelligence Approach, </title> <editor> R. S. Michalski, J. G. Carbonell and T. M. Mitchell (Eds), </editor> <publisher> Tioga Publishing, </publisher> <address> Palo Alto, CA, </address> <booktitle> vol. </booktitle> <volume> 1, </volume> <pages> pp. 463482, </pages> <year> 1983. </year>
Reference-contexts: ChiMerge determined that only seven discrete levels were needed for this attribute. After ChiMerge scaling, attribute levels for the training data ranged between 5 and 76. The final step in data preparation was to select the most relevant attributes. The entropy measure <ref> [22] </ref> and the PROMISE score [23] were computed for each discrete attribute.
Reference: [23] <author> P. W. Baim, </author> <title> Automated acquisition of decision rules: the problems of attribute construction and selection, </title> <type> Masters Thesis, </type> <institution> Department of Computer Science, University of Illinois, Urbana, IL, </institution> <year> 1984. </year>
Reference-contexts: ChiMerge determined that only seven discrete levels were needed for this attribute. After ChiMerge scaling, attribute levels for the training data ranged between 5 and 76. The final step in data preparation was to select the most relevant attributes. The entropy measure [22] and the PROMISE score <ref> [23] </ref> were computed for each discrete attribute.
References-found: 23

