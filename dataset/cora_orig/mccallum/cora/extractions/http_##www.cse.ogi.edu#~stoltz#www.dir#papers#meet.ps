URL: http://www.cse.ogi.edu/~stoltz/www.dir/papers/meet.ps
Refering-URL: http://www.cse.ogi.edu/~stoltz/
Root-URL: http://www.cse.ogi.edu
Email: fstoltz,mwolfeg@cse.ogi.edu  
Phone: (503) 690-1121 ext. 7404  
Title: Sparse Data-Flow Analysis for DAG Parallel Programs  
Author: Eric Stoltz and Michael Wolfe 
Date: September 19, 1994  
Address: P.O. Box 91000 Portland, OR 97291-1000  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: We contrast abstract flow of control in a sequential program environment which uses a control flow graph (CFG) to the abstraction of execution order within DAG parallelism using a simple precedence graph (PG). We note that often the analogous concepts are duals of each other with regard to universal and existential quantifiers. We are studying sparse data-flow analysis techniques, which include methods of placing operators at confluence points to merge the flow of information. While the placement of merge operators is well-known for CFGs (at the iterated dominance frontier of nodes with non-identity transfer functions), we determine and prove correct placement points for merge operators within a PG in the case of reaching definitions. We also show how to conservatively implement the placement of parallel merge operators in an efficient manner with respect to the reaching definitions problem.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: The CFG has been the most common intermediate representation for program flow analysis for a number of years <ref> [1, 9] </ref>. Data-flow analysis is a method of collecting information about a program, such as reaching definitions, dominance, or live variables [1, 10]. <p> The CFG has been the most common intermediate representation for program flow analysis for a number of years [1, 9]. Data-flow analysis is a method of collecting information about a program, such as reaching definitions, dominance, or live variables <ref> [1, 10] </ref>.
Reference: [2] <author> Per Brinch Hansen. </author> <title> Operating Systems Principles. Automatic Computation. </title> <publisher> Prentice-Hall, </publisher> <year> 1973. </year>
Reference-contexts: For the purposes of this paper, we deal with DAG parallelism (a subset of task parallelism [7]), specifically explicit parallel sections fashioned after the Parallel Sections construct [11], which is similar to the cobegin-coend syntax of Brinch Hansen <ref> [2] </ref>. An example is shown in the code in Section B may begin. 2.1 An Abstract Representation The ordering of sections is arranged within a precedence graph (PG), an abstract representation which dictates what sections may execute in what order.
Reference: [3] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> Automatic construction of sparse data flow evaluation graphs. </title> <booktitle> In Conf. Record 18th Annual ACM Symp. Principles of Programming Languages, </booktitle> <pages> pages 55-66, </pages> <address> Orlando, Florida, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: We define merge nodes as nodes at which information converges from more than one predecessor, which are equivalent to the meet nodes of sparse evaluation graphs <ref> [3] </ref>; these identify nodes which merge data-flow information, as opposed to confluence nodes in a control-flow graph. Information is merged at these nodes in a sparse intermediate representation by inserting a merge operator to collect the information from each data-flow predecessor. <p> Here, Y dom Z, and Y 2 shield (d; Z)8d 2 fQ; S ; T ; W g. Considering the problem of merging information within a data-flow framework in general, it suffices to merge information at the iterated dominance frontier of the interesting nodes <ref> [3] </ref>. For reaching definitions, -functions are placed at DF + (S), where S is the set of all definition sites for each variable [5]. A -function has an argument for each control flow predecessor, thus coalescing all definitions which reach that node into a single definition. <p> Thus, merging information at the DF + of the set of interesting nodes within a PG has been shown to be a safe method, and is relatively efficient since it can be performed with the same complexity as that for -function placement and the techniques employed for sparse evaluation graphs <ref> [3] </ref>. 5 Conclusions and Extensions In this paper we have contrasted the order of execution within a DAG parallel environment which uses precedence graphs to that of control flow graphs for sequential programs. Further, we have discovered the minimal set of points in precedence graphs to merge information.
Reference: [4] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> On the efficient engineering of ambitious program analysis. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(2) </volume> <pages> 105-114, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: In the case of a CFG where n definitions and n uses are separated by a confluence node, n 2 reaching definition chains are generated to connect each definition to its possible uses. This problem has been discussed in detail elsewhere <ref> [4, 5] </ref>.
Reference: [5] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing Static Single Assignment form and the control dependence graph. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: In the case of a CFG where n definitions and n uses are separated by a confluence node, n 2 reaching definition chains are generated to connect each definition to its possible uses. This problem has been discussed in detail elsewhere <ref> [4, 5] </ref>. <p> Information is merged at these nodes in a sparse intermediate representation by inserting a merge operator to collect the information from each data-flow predecessor. For reaching definitions, merge operators (known as -functions) for variable v need to be placed at the iterated join of the set of interesting nodes <ref> [5] </ref>. In this case, interesting nodes are those in which there is a definition to v. <p> Calculating the iterated join of S, J + (S), may seem expensive, but it has been shown <ref> [5] </ref> to be equal to the iterated dominance frontier of S. The dominance frontier (DF) of a node X is all nodes Z such that X does not strictly dominate Z, but X dominates some predecessor of Z. <p> Considering the problem of merging information within a data-flow framework in general, it suffices to merge information at the iterated dominance frontier of the interesting nodes [3]. For reaching definitions, -functions are placed at DF + (S), where S is the set of all definition sites for each variable <ref> [5] </ref>. A -function has an argument for each control flow predecessor, thus coalescing all definitions which reach that node into a single definition. In this way, linearity of reaching definitions is achieved. <p> also define M + (S) as the limit of increasing sequences analogous to that used for join and dominance frontier: M 1 (S) = M (S) M i+1 (S) = M (S [ M i (S)) The definition of Join (Definition 2, and the basis of work to place -functions <ref> [5] </ref>) is a well-known concept. Although in a CFG J + (S) = J (S) [15], the dual definition of join for PGs, meet, does not possess this property. Consider Figure 3 (a). Let S= fX,Yg. <p> Again, referring to the reaching definitions problem within a CFG, after placing -functions a technique known as renaming transforms each variable definition into a unique name and each use into the name of its unique reaching definition <ref> [5] </ref>. The method employed to perform this renaming is depth-first, in that it recursively traverses the dominator tree in a depth-first order, keeping a stack of current definitions for each variable. <p> The key property that this renaming scheme satisfies is that at each node the correct "current" definition (an original definition or -function) of each variable is the most recent definition on the depth-first path to this node from Entry, i.e., the definition on top of the definition stack <ref> [5, Lemma 10] </ref>. In fact, a depth-first traversal of any spanning tree of the CFG will also satisfy this property. Unfortunately, a depth-first traversal of the nodes of a PG will not satisfy this key property with merge operators at M + (S). <p> Next, we show that the iterated dominance frontier is a superset of the iterated reaching frontier on all graphs. Theorem 7 DF + (S) RF + (S) Proof: It has been shown <ref> [5, Lemma 4] </ref> that for any node Z that X reaches, some node Y 2 fX [DF + (X)g dominates Z.
Reference: [6] <author> Ron Cytron, Michael Hind, and Wilson Hsieh. </author> <title> Automatic generation of DAG parallelism. </title> <booktitle> In Proc. ACM SIGPLAN '89 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 54-68, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Precedence graphs can easily be used to express DAG parallelism <ref> [6] </ref> by using Wait clauses to enforce constraints between section nodes. A precedence graph is also a simplified, special case of a Parallel Program Graph [12] which only contains synchronization edges, with the synchronization condition that all code in a node completes before beginning execution of any successor.
Reference: [7] <author> Fox et al. </author> <title> Common runtime support for high-performance parallel languages. </title> <booktitle> In Proceedings of Supercomputing 93, </booktitle> <pages> pages 752-757, </pages> <address> Portland, OR, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: For the purposes of this paper, we deal with DAG parallelism (a subset of task parallelism <ref> [7] </ref>), specifically explicit parallel sections fashioned after the Parallel Sections construct [11], which is similar to the cobegin-coend syntax of Brinch Hansen [2].
Reference: [8] <author> Dirk Grunwald and Harini Srinivasan. </author> <title> Data flow equations for explicitly parallel programs. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 159-168, </pages> <address> San Diego, California, May 1993. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Kill information is computed quite differently within a PG as opposed to a CFG <ref> [8] </ref>. In a PG, a definition of v in node A is killed before reaching node C if any path from A to C passes through node B, where B contains a definition of v.
Reference: [9] <author> Matthew S. Hecht. </author> <title> Flow Analysis of Computer Programs. </title> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: The CFG has been the most common intermediate representation for program flow analysis for a number of years <ref> [1, 9] </ref>. Data-flow analysis is a method of collecting information about a program, such as reaching definitions, dominance, or live variables [1, 10].
Reference: [10] <editor> Steven S. Muchnick and Neil D. Jones, editors. </editor> <title> Program Flow Analysis: Theory and Applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: The CFG has been the most common intermediate representation for program flow analysis for a number of years [1, 9]. Data-flow analysis is a method of collecting information about a program, such as reaching definitions, dominance, or live variables <ref> [1, 10] </ref>.
Reference: [11] <author> Parallel Computing Forum. </author> <title> PCF Parallel Fortran extensions. </title> <journal> Fortran Forum, </journal> <volume> 10(3), </volume> <month> September </month> <year> 1991. </year> <note> (special issue). </note>
Reference-contexts: For the purposes of this paper, we deal with DAG parallelism (a subset of task parallelism [7]), specifically explicit parallel sections fashioned after the Parallel Sections construct <ref> [11] </ref>, which is similar to the cobegin-coend syntax of Brinch Hansen [2].
Reference: [12] <author> Vivek Sarkar and Barbara Simons. </author> <title> Parallel program graphs and their classification. </title> <editor> In Utpal Banerjee, David Gelernter, Alexandru Nicolau, and David A. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, number 768 in Lecture Notes in Computer Science, </booktitle> <pages> pages 633 - 655. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <month> 17 </month>
Reference-contexts: Precedence graphs can easily be used to express DAG parallelism [6] by using Wait clauses to enforce constraints between section nodes. A precedence graph is also a simplified, special case of a Parallel Program Graph <ref> [12] </ref> which only contains synchronization edges, with the synchronization condition that all code in a node completes before beginning execution of any successor.
Reference: [13] <author> Harini Srinivasan, James Hook, and Michael Wolfe. </author> <title> Static single assignment for explicitly parallel programs. </title> <booktitle> In Conf. Record 20th Annual ACM Symp. Principles of Programming Languages, </booktitle> <pages> pages 16-28, </pages> <address> Charleston, SC, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: This highlights another major difference between sequential and parallel merges; therefore we will use a new operator, the -function, as the merge operator for reaching definitions within the PG <ref> [13] </ref>. The -function is similar to the -function in that it acts as a non-killing definition in terms of data-flow analysis, but it is also a use for all definitions which reach the -function via its arguments. <p> Since Srepresents nodes with non-identity transfer functions, this result holds for data-flow problems in general by extending Definition 1 for reaching definitions to kill information for other data-flow problems. The concept of iterated meet is a refinement of the -function placement method suggested earlier <ref> [13] </ref>, in that the iterated meet is smaller and, in fact, the minimal set. <p> of the PG visits node C after node A; when visiting node C, the current definition of variable x will be the definition in A, but the current definition of variable y will be wrong. 12 In order to use a depth-first renaming algorithm, we introduce additional -functions as placeholders <ref> [13, 14] </ref>. The renaming algorithm described in this earlier work visits the PG nodes in a depth-first traversal of a spanning tree that satisfies topological ordering, and identifies and removes these spurious -functions.
Reference: [14] <author> Eric Stoltz, Harini Srinivasan, James Hook, and Michael Wolfe. </author> <title> Static Single Assignment form for explicitly parallel programs: </title> <journal> Theory and practice. </journal> <note> submitted for publication, </note> <month> August </month> <year> 1994. </year>
Reference-contexts: of the PG visits node C after node A; when visiting node C, the current definition of variable x will be the definition in A, but the current definition of variable y will be wrong. 12 In order to use a depth-first renaming algorithm, we introduce additional -functions as placeholders <ref> [13, 14] </ref>. The renaming algorithm described in this earlier work visits the PG nodes in a depth-first traversal of a spanning tree that satisfies topological ordering, and identifies and removes these spurious -functions. <p> However, for the common depth-first implementations which use renaming, such as -functions for reaching definitions within PGs, placing merge operators at DF + (S) may well be necessary for correct propagation of information, as discussed above. Another paper <ref> [14] </ref> has shown that placing -functions at these points does correctly propagate reaching definitions, albeit through placeholder -functions at times. 15 How conservative is the use of DF + (S) as an approximation for M + (S)? First, if there is only one member of S, then M + (S) will
Reference: [15] <author> Michael Wolfe. </author> <title> J + = J. </title> <journal> ACM Sigplan Notices, </journal> <volume> 29(7) </volume> <pages> 51-53, </pages> <month> July </month> <year> 1994. </year> <month> 18 </month>
Reference-contexts: Although in a CFG J + (S) = J (S) <ref> [15] </ref>, the dual definition of join for PGs, meet, does not possess this property. Consider Figure 3 (a). Let S= fX,Yg. Then M (S) = fW,Zg; in fact, A 62 M (S), but A 2 M (S [ M (S)) = M (X,Y,W,Z) = fW,Z,Ag.
References-found: 15

