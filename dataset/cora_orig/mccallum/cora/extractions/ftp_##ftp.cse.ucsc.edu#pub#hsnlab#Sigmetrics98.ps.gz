URL: ftp://ftp.cse.ucsc.edu/pub/hsnlab/Sigmetrics98.ps.gz
Refering-URL: http://www.cse.ucsc.edu/~lampros/papers.html
Root-URL: http://www.cse.ucsc.edu
Email: E-mail: lampros, varma@cse.ucsc.edu  E-mail: kkrama@research.att.com  
Title: Improving TCP Throughput over Two-Way Asymmetric Links: Analysis and Solutions  
Author: Lampros Kalampoukas Anujan Varma K. K. Ramakrishnan 
Address: Santa Cruz, CA 95064  Florham Park, NJ 07932  
Affiliation: Computer Engineering Department University of California  AT&T Research  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> V. Jacobson, </author> <title> "Congestion avoidance and control," </title> <booktitle> in Proc. of ACM SIGCOMM'88, </booktitle> <pages> pp. 314-329, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction The Transmission Control Protocol (TCP) has become the most widely used transport-layer protocol today, due largely to the explosive growth of the TCP/IP Internet in recent years. An important component of TCP is the collection of algorithms used to perform congestion control and recovery <ref> [1, 2] </ref>. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively [3, 4, 5, 6]. In this paper, our interest is in analyzing the dynamics of TCP connections over asymmetric access links in the presence of two-way traffic. <p> The genesis of ack compression can be traced to the slow-start phase of the TCP connection that increases the window progressively at startup <ref> [1] </ref>. The slow-start algorithm sets the initial window size to one and increases it by one with every acknowledgment received. This effectively doubles the window every round-trip time. Thus, during slow start, the receipt of every ack causes the end system to add two segments to its outgoing queue. <p> The model of TCP used in the simulations is based on the TCP-Reno version. It supports the congestion control mechanism described by Jacobson <ref> [1] </ref>, exponential back-off, enhanced round-trip (RTT) estimation based on both the mean and 9 the variance of the measured RTT, and the fast retransmit and fast recovery mechanisms.
Reference: [2] <author> V. Jacobson, </author> <title> "Modified TCP congestion avoidance algorithm." message to end2end-interest mailing list, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The Transmission Control Protocol (TCP) has become the most widely used transport-layer protocol today, due largely to the explosive growth of the TCP/IP Internet in recent years. An important component of TCP is the collection of algorithms used to perform congestion control and recovery <ref> [1, 2] </ref>. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively [3, 4, 5, 6]. In this paper, our interest is in analyzing the dynamics of TCP connections over asymmetric access links in the presence of two-way traffic.
Reference: [3] <author> S. Floyd and V. Jacobson, </author> <title> "On traffic phase effects in packet-switched gateways," Internetworking: </title> <journal> Research and Experience, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 115-156, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections over asymmetric access links in the presence of two-way traffic.
Reference: [4] <author> J. C. Mogul, </author> <title> "Observing TCP dynamics in real networks," </title> <booktitle> in Proc. of ACM SIGCOMM'92, </booktitle> <pages> pp. 305-317, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections over asymmetric access links in the presence of two-way traffic.
Reference: [5] <author> L. Zhang and D. D. Clark, </author> <title> "Oscillating behavior of network traffic: A case study simulation," </title> <journal> Intenet-working: Research and Experience, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 101-112, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections over asymmetric access links in the presence of two-way traffic.
Reference: [6] <author> L. Zhang, S. Shenker, and D. D. Clark, </author> <title> "Observations on the dynamics of a congestion control algorithm: The effects of two-way traffic," </title> <booktitle> in Proc. of ACM SIGCOMM'91, </booktitle> <pages> pp. 133-147, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [1, 2]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [3, 4, 5, 6] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections over asymmetric access links in the presence of two-way traffic. <p> These data segments and acknowledgments may share a common buffer in the end systems as well as network switches/routers. This sharing has been shown to result in an effect called ack compression, where acks of a connection arrive at the source bunched together <ref> [6, 7] </ref>. The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect [7]. Ack compression may occur either at the end system or in a switch/router. <p> Ack compression may occur either at the end system or in a switch/router. In either case, the smooth flow of acknowledgments to the source is disturbed, potentially resulting in reduced overall throughput. While previous studies provide a qualitative treatment of the ack compression problem <ref> [6, 7] </ref>, our objective in this paper is to analyze the dynamic behavior and quantify the throughput degradation of TCP connections in a two-way environment when the bandwidths of the links in the two directions differ significantly, possibly by several orders of magnitude. <p> For example, the transmission time of a 1500 byte packet over a 100 Kbits/sec link is about 120 msecs, while the TCP protocol processing time in modern workstations does not exceed a few hundred microseconds <ref> [6, 12, 13] </ref>. Thus, we can safely assume that t pr is zero. We now review the analytical results on connection throughputs from [8] for the asymmetric case.
Reference: [7] <author> R. Wilder, K. K. Ramakrishnan, and A. Mankin, </author> <title> "Dynamics of congestion control and avoidance of two-way traffic in an OSI testbed," </title> <journal> ACM Computer Communication Review, </journal> <volume> vol. 21, no. 2, </volume> <pages> pp. 43-58, </pages> <month> April </month> <year> 1991. </year> <month> 25 </month>
Reference-contexts: These data segments and acknowledgments may share a common buffer in the end systems as well as network switches/routers. This sharing has been shown to result in an effect called ack compression, where acks of a connection arrive at the source bunched together <ref> [6, 7] </ref>. The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect [7]. Ack compression may occur either at the end system or in a switch/router. <p> The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect <ref> [7] </ref>. Ack compression may occur either at the end system or in a switch/router. In either case, the smooth flow of acknowledgments to the source is disturbed, potentially resulting in reduced overall throughput. <p> Ack compression may occur either at the end system or in a switch/router. In either case, the smooth flow of acknowledgments to the source is disturbed, potentially resulting in reduced overall throughput. While previous studies provide a qualitative treatment of the ack compression problem <ref> [6, 7] </ref>, our objective in this paper is to analyze the dynamic behavior and quantify the throughput degradation of TCP connections in a two-way environment when the bandwidths of the links in the two directions differ significantly, possibly by several orders of magnitude.
Reference: [8] <author> L. Kalampoukas, A. Varma, and K. K. Ramakrishnan, </author> <title> "Two-way TCP traffic over ATM: Effects and analysis," </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-96-23, Univ. of California, Santa Cruz, </institution> <year> 1996. </year>
Reference-contexts: However, even when routers and their links have adequate bandwidth, undesirable interaction between bidirectional connections can still occur in the end systems, leading to ack compression and throughput loss <ref> [8] </ref>. This is due to the sharing of a common queue by data packets and acknowledgments. With asymmetric link speeds, the effect of ack compression is more pronounced at the end system with the lower-speed upstream channel. <p> Meanwhile, the acks of the reverse connection are queued behind the data segments, causing them to be bunched. This behavior can persist in steady state when the windows reach their final values <ref> [8] </ref>. 1 This paper extends the analysis approach in [8] by considering the effect of asymmetric access links on the performance of two-way TCP traffic. <p> Meanwhile, the acks of the reverse connection are queued behind the data segments, causing them to be bunched. This behavior can persist in steady state when the windows reach their final values <ref> [8] </ref>. 1 This paper extends the analysis approach in [8] by considering the effect of asymmetric access links on the performance of two-way TCP traffic. Asymmetric link speeds are likely to be common in the future, with the widespread deployment of cable and high-speed DSL (Digital Subscriber Line) [9] access networks to homes and businesses. <p> Finally, we conclude in Section 7 with some observations. 2 Network Models and Effects of Two-Way TCP Traffic In this section, we describe our models of the network and the end nodes and review the results presented in <ref> [8] </ref> on the effects of two-way TCP traffic. In the following sections we build upon the analysis presented in [8] by devising and analyzing solutions that can potentially improve the efficiency of the network under two-way traffic scenarios even in networks with asymmetric link speeds. <p> some observations. 2 Network Models and Effects of Two-Way TCP Traffic In this section, we describe our models of the network and the end nodes and review the results presented in <ref> [8] </ref> on the effects of two-way TCP traffic. In the following sections we build upon the analysis presented in [8] by devising and analyzing solutions that can potentially improve the efficiency of the network under two-way traffic scenarios even in networks with asymmetric link speeds. <p> Furthermore, the data packets added to the IP queue in response to a burst of acks arriving from the opposite node are transmitted as a bunch with no intervening acks. This behavior causes the entire window of each connection to be transmitted always as a single bunch <ref> [8] </ref>, giving rise to the effects we study in this paper. The functionality assumed for the IP layer is simple. For incoming traffic the IP layer is responsible for forwarding data from the lower layer to the local TCP process. <p> The interaction between TCP and IP described above is consistent with the 4.4 BSD-Lite Unix Release [11]. The analytical models in this paper ignore the TCP processing time in end systems. In <ref> [8] </ref> we have shown how the TCP processing time, denoted as t pr , may be incorporated into the analytical models. <p> Thus, we can safely assume that t pr is zero. We now review the analytical results on connection throughputs from <ref> [8] </ref> for the asymmetric case. First, we note that the sum of the windows of the two connections must be large enough to fill the round-trip pipe for ack compression to occur. <p> We call the ratio of the throughput of a connection to the corresponding link capacity as its throughput efficiency, or simply efficiency. The following results from <ref> [8] </ref> estimate the connection efficiencies and maximum queue sizes for two-way TCP traffic under ack compression. Detailed derivations of these results can be found in [8]. <p> The following results from <ref> [8] </ref> estimate the connection efficiencies and maximum queue sizes for two-way TCP traffic under ack compression. Detailed derivations of these results can be found in [8].
Reference: [9] <author> K. Maxwell, </author> <title> "Asymmetric Digital Subscribe Line: Interim Technology for the Next Forty Years," </title> <journal> IEEE Communications Magazine, </journal> <volume> vol. 34, no. 10, </volume> <pages> pp. 100-106, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Asymmetric link speeds are likely to be common in the future, with the widespread deployment of cable and high-speed DSL (Digital Subscriber Line) <ref> [9] </ref> access networks to homes and businesses. These access networks have substantially higher speed in one direction than the other. We demonstrate that the asymmetry in link bandwidth has a dramatic effect on the performance of the connection going through the faster down-link.
Reference: [10] <author> T. V. Lakshman, U. Madhow, and B. Suter, </author> <title> "Window-based error recovery and flow control with a slow acknowledgement channel: A study of TCP/IP performance," </title> <booktitle> in Proc. of INFOCOM'97, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Lakshman et. al. <ref> [10] </ref> have also investigated the effect of link asymmetry on TCP performance, primarily in the context of network environments with one-way TCP traffic (only acks are transported over the slow link) and limited buffering. In [10], the effect of the cumulative nature of TCP acknowledgements, when acks are lost, on the <p> Lakshman et. al. <ref> [10] </ref> have also investigated the effect of link asymmetry on TCP performance, primarily in the context of network environments with one-way TCP traffic (only acks are transported over the slow link) and limited buffering. In [10], the effect of the cumulative nature of TCP acknowledgements, when acks are lost, on the burstiness of transmitted data traffic is analyzed and guidelines for the proper sizing of the bottleneck buffers are provided. <p> It is also relevant when interfacing to a rate controlled network with an intelligent buffer management strategy that avoids losses. In such environments, the degradation is only due to interactions taking place between data and acks. Therefore, this paper complements the analysis presented in <ref> [10] </ref>. The remainder of the paper is organized as follows: In the next section we define our models of the network and the end nodes, briefly review the dynamics of two-way TCP connections in an asymmetric network, and quantify the resulting throughput degradation. <p> Through a simple counter-based implementation, we showed that it is possible to guarantee a minimum throughput for the slow connection, making the fast connection's throughput sensitive to only its own parameters. Lakshman et. al. <ref> [10] </ref> have also shown that flow isolation provided by the use of an appropriate scheduling policy is required in order to achieve the desired degree of fairness in the network.
Reference: [11] <author> W. R. Stevens and G. R. </author> <title> Wright, </title> <journal> TCP/IP Illustrated, </journal> <volume> vol. 2. </volume> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1995. </year>
Reference-contexts: Therefore, to avoid packet losses at the source node, we assume that the IP queue has a size equal to the maximum window size of the sending TCP. The interaction between TCP and IP described above is consistent with the 4.4 BSD-Lite Unix Release <ref> [11] </ref>. The analytical models in this paper ignore the TCP processing time in end systems. In [8] we have shown how the TCP processing time, denoted as t pr , may be incorporated into the analytical models.
Reference: [12] <author> K. K. Ramakrishnan, </author> <title> "Performance considerations in designing network interfaces," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 203-219, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: For example, the transmission time of a 1500 byte packet over a 100 Kbits/sec link is about 120 msecs, while the TCP protocol processing time in modern workstations does not exceed a few hundred microseconds <ref> [6, 12, 13] </ref>. Thus, we can safely assume that t pr is zero. We now review the analytical results on connection throughputs from [8] for the asymmetric case.
Reference: [13] <author> C.-H. Chang, D. Flower, J. Forecase, H. Gray, B. Hawe, A. Nadkarni, K. K. Ramakrishnan, U. Shikarpur, and K. Wilde, </author> <title> "High-performance TCP/IP and UDP/IP networking in DEC OSF/1 for Alpha AXP," </title> <booktitle> in Proc. of the Third IEEE International Symposium on High Performance Distributed Computing, </booktitle> <pages> pp. 35-42, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: For example, the transmission time of a 1500 byte packet over a 100 Kbits/sec link is about 120 msecs, while the TCP protocol processing time in modern workstations does not exceed a few hundred microseconds <ref> [6, 12, 13] </ref>. Thus, we can safely assume that t pr is zero. We now review the analytical results on connection throughputs from [8] for the asymmetric case.
Reference: [14] <author> V. Jacobson, </author> <title> "Compressing TCP/IP headers for low-speed serial links," Request for Comments: </title> <type> 1144, </type> <month> February </month> <year> 1990. </year>
Reference-contexts: With link-layer data compression, the effective bandwidth of the upstream channel was found to be approximately 50 Kbits/sec. With IP header compression <ref> [14] </ref> enabled, we observed an ack size of 9 bytes on the serial link. We used "ttcp" to measure throughput of TCP connections between the workstations. Through separate 6 measurements, we ensured that the workstations were not a bottleneck. <p> The size of acknowledgments was set as 28 bytes after IP header compression <ref> [14] </ref>, and including link layer overhead.
Reference: [15] <author> L. Kalampoukas, A. Varma, and K. K. Ramakrishnan, </author> <title> "Explicit Window Adaptation: A method to enhance TCP performance," </title> <note> in to appear in Proc. of Infocom'98, 1998. 26 </note>
Reference-contexts: Such an approach is realistic in configurations where the network adapter to the slow link is directly attached to the end-system. It is also appropriate in networks where the buffer occupancy is controlled by using buffer management schemes that avoid losses <ref> [15] </ref>. The backpressure approach has the potential to control of the throughput efficiency of the connections in both directions by varying the maximum allowable number of data packets in the outgoing IP queue.
References-found: 15

