URL: http://www-dbv.informatik.uni-bonn.de/postscript/puzicha.iconip96.ps.gz
Refering-URL: 
Root-URL: 
Email: jan@cs.uni-bonn.de  fgoerke,eckmillerg@nero.uni-bonn.de  
Title: Optimal Trajectory Generation for an Industrial Robot by Markovian Networks  
Phone: 1996.  
Author: Jan Puzichay, Nils Goerkez and Rolf Eckmillerz 
Affiliation: Institut fur Informatik  Institut fur Informatik  University of Bonn, F. R.  
Address: Hong Kong,  VI,  Germany  
Note: to appear in the Proc. of the IInt. Conf. on Neural Information Processing Systems,  III,  
Abstract: Optimal trajectory generation can be represented as a constrained variational problem posed simultaneously in cartesian and joint coordinate spaces. Markovian Networks are presented as a class of neural networks especially suited for solving general constrained variational problems. By incorporation of the kinematic map an iterative network dynamic is created, which gradually converges to an optimal solution. The capability of this approach is demonstrated by generating optimal 6-DOF movements along surfaces for an industrial robot arm with remarkable improvements compared to a standard algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Antonio. </author> <title> Optimal trajectory planning for spray coating. </title> <booktitle> In Proceedings of the International Conference on Robotics and Automation, </booktitle> <pages> pages 2570-2577, </pages> <year> 1994. </year>
Reference-contexts: The special property of the selected algorithm is its ability to optimize simultaneously in both spaces. Second, there is a growing need for fulfilling abstract quality demands specified through a priori unknown cost functions, e.g. minimal variation in film thickness in spray coating of complex surfaces <ref> [1] </ref>. We thus take an abstracting step towards high level planning by specifying the optimal trajectory as a general constrained variational problem. Markovian Networks are presented as a class of neural networks with local interactions and iterative dynamics (like the dynamics of Hopfield-Nets or Boltzmann-Machines) [4, 7, 11]. <p> The neural algorithms are tested by generating trajectories along surfaces for a 6-DOF industrial manipulator, as it is important in industrial applications like welding or spray coating <ref> [1] </ref>. 2 Trajectory Generation Most tasks of a manipulator require one of the following types of movements: point-to-point, pick-and-place, path tracking (no time specification), trajectory tracking (with time specification) and movements along surfaces.
Reference: [2] <author> J. Besag. </author> <title> On the statistical analysis of dirty pictures. </title> <journal> Journal of the Royal Statistical Society, Series B, </journal> <volume> 48 </volume> <pages> 25-37, </pages> <year> 1986. </year>
Reference-contexts: Approximating functional (3) yields a sum of (clique-dependent) potentials. J [Y ] t i 2S 3 Using the ICM-algorithm <ref> [2] </ref> this can be used to define a network dynamic gradually converging to the solution: D l;V (l) ( ~ t) = arg min J (t 1 ; : : : ; t V (l1) ; w; t V (l+1) ; : : : ; t n ) (6) with D
Reference: [3] <author> K. Fu, R. Gonzales, and C. Lee. </author> <title> Robotics: </title> <journal> Control, Sensing, Vision and Intelligence, </journal> <volume> chapter 4, </volume> <pages> pages 149-200. </pages> <publisher> McGraw-Hill Book Company, </publisher> <year> 1987. </year>
Reference-contexts: First, optimality conditions are posed simultaneously in cartesian and joint spaces, as constraints like constant distance to a surface or approximately constant tool velocity as well as maximal values for position, velocity and acceleration of joints have to be satisfied <ref> [3] </ref>. The special property of the selected algorithm is its ability to optimize simultaneously in both spaces. Second, there is a growing need for fulfilling abstract quality demands specified through a priori unknown cost functions, e.g. minimal variation in film thickness in spray coating of complex surfaces [1]. <p> The tasks of a manipulator can be classified according to their difficulty: * Tasks with optimality conditions exclusively in the joint domain can often be solved easily <ref> [3] </ref>. * For time optimal movements there exists a large number of approaches (see the references in [11]). * Cartesian path tracking can be solved by recursive pointwise mapping using a differential inverse kinematic map and applying interpolation [3] and rescaling [8] techniques in the joint domain. * Time dependent cartesian <p> optimality conditions exclusively in the joint domain can often be solved easily <ref> [3] </ref>. * For time optimal movements there exists a large number of approaches (see the references in [11]). * Cartesian path tracking can be solved by recursive pointwise mapping using a differential inverse kinematic map and applying interpolation [3] and rescaling [8] techniques in the joint domain. * Time dependent cartesian movements, especially when the type of deviation is crucial (as in the surface scenario), have to be optimized simultaneously in both spaces [3]. <p> be solved by recursive pointwise mapping using a differential inverse kinematic map and applying interpolation <ref> [3] </ref> and rescaling [8] techniques in the joint domain. * Time dependent cartesian movements, especially when the type of deviation is crucial (as in the surface scenario), have to be optimized simultaneously in both spaces [3]. There exist a vast amount of heuristic approaches to trajectory formation, but these hardly solve the last type of problems, because they decouple kinematic map and optimization and thus lead to sub-optimal or useless trajectories (see discussion and references in [11]).
Reference: [4] <author> D. Geman. </author> <title> Random fields and inverse problems in imaging. </title> <booktitle> Lecture Notes Mathematics, </booktitle> <volume> 1427 </volume> <pages> 117-193, </pages> <year> 1990. </year>
Reference-contexts: We thus take an abstracting step towards high level planning by specifying the optimal trajectory as a general constrained variational problem. Markovian Networks are presented as a class of neural networks with local interactions and iterative dynamics (like the dynamics of Hopfield-Nets or Boltzmann-Machines) <ref> [4, 7, 11] </ref>. They are closely related to the statistical framework of Markov-Random-Fields [4], which has been used to solve complex optimization problems with topological structured variables [5]. <p> Markovian Networks are presented as a class of neural networks with local interactions and iterative dynamics (like the dynamics of Hopfield-Nets or Boltzmann-Machines) [4, 7, 11]. They are closely related to the statistical framework of Markov-Random-Fields <ref> [4] </ref>, which has been used to solve complex optimization problems with topological structured variables [5]. In this work we develop Markovian Networks for solving constraint variational problems and apply them on the formation of optimal trajectories by incorporating the forward kinematic map in the definition of a network dynamic.
Reference: [5] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6(6) </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference-contexts: They are closely related to the statistical framework of Markov-Random-Fields [4], which has been used to solve complex optimization problems with topological structured variables <ref> [5] </ref>. In this work we develop Markovian Networks for solving constraint variational problems and apply them on the formation of optimal trajectories by incorporating the forward kinematic map in the definition of a network dynamic. <p> In the robotic application the position of the robot at a specific time instant is coded through a (vectoriell) state of a neuron. During optimization the manipulator position at a time instant is asynchronously optimized given the positions before and after. Using the nomenclature known from the MRF-framework <ref> [5] </ref> a Markovian Network can be stated as a tuple (S; G; T; V; D i ) with a graph (S; G), a realization of a family of (random) variables T := (T s ) s2S with state space := N s2S fl s and a network dynamic defined by a
Reference: [6] <author> P. Gill, W. Murray, and M. Wright. </author> <title> Practical Optimization. </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: Let S = ft i : i = 1; : : : ; ng be a discretization of [a; b]. Approximating the derivatives by symmetric differences <ref> [6] </ref> the function F in (3) can then be approximated by the variational function values at t i and at a neighborhood of t i : F t i ; Y (t i ); Y 0 (t i ); : : : ; Y (n) (t i ) F i (t <p> For trajectory optimization we use the joint representation fi i = fi (t i ) and incorporate the (fast computable) forward kinematic map in the network dynamic to compute the cartesian representation Y . To satisfy the hard constraint (2) we apply a penalty function method <ref> [6] </ref> by choosing a monotonically increasing schedule L : IN ! IR with lim l!1 L (l) = 1. Adding the discretization of (2) to (5) we define a potential function J l J l [Y ] t i 2S relative to a modified Graph .
Reference: [7] <author> J. Hertz, A. Krogh, and R. Palmer. </author> <title> Introduction to the Theory of Neural Computation. </title> <publisher> Addis. Wesley, </publisher> <year> 1991. </year>
Reference-contexts: We thus take an abstracting step towards high level planning by specifying the optimal trajectory as a general constrained variational problem. Markovian Networks are presented as a class of neural networks with local interactions and iterative dynamics (like the dynamics of Hopfield-Nets or Boltzmann-Machines) <ref> [4, 7, 11] </ref>. They are closely related to the statistical framework of Markov-Random-Fields [4], which has been used to solve complex optimization problems with topological structured variables [5].
Reference: [8] <author> J. Hollerbach. </author> <title> Dynamic scaling of manipulator trajectories. </title> <type> Technical report, </type> <institution> MIT AI-Memo 700, </institution> <year> 1983. </year>
Reference-contexts: in the joint domain can often be solved easily [3]. * For time optimal movements there exists a large number of approaches (see the references in [11]). * Cartesian path tracking can be solved by recursive pointwise mapping using a differential inverse kinematic map and applying interpolation [3] and rescaling <ref> [8] </ref> techniques in the joint domain. * Time dependent cartesian movements, especially when the type of deviation is crucial (as in the surface scenario), have to be optimized simultaneously in both spaces [3].
Reference: [9] <author> Y. Nakamura. </author> <title> Advanced Robotics, Redundancy and Optimisation. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: The network was initialized by splining the via-points together and computing the corresponding joint trajectory using a regularized differential inverse kinematic. This is an elaborated 'state of the art' method for trajectory generation from a sequence of via-points <ref> [9] </ref>. chosen example is depicted. It demonstrates a significant improvement of the initial solution. Especially the computed solution becomes kinematically valid after a few iterations. In Fig. 1b the optimization progress for the table example is illustrated.
Reference: [10] <author> W. Press, S. Teukolsky, W. Vetterling, and B. Flannery. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <address> 2. edition, </address> <year> 1992. </year>
Reference-contexts: In the robotic application the minimization in (6) solely has to be carried out varying the robot position at one time instant. For this low-dimensional optimization we decided to use the Method of Powell as described in <ref> [10] </ref>. For trajectory optimization we use the joint representation fi i = fi (t i ) and incorporate the (fast computable) forward kinematic map in the network dynamic to compute the cartesian representation Y .
Reference: [11] <author> J. Puzicha. </author> <title> Neuronale Generierung von Trajektorien aus Bewegungsanforderungen. </title> <type> Diploma thesis, </type> <institution> University of Bonn, </institution> <year> 1995. </year>
Reference-contexts: We thus take an abstracting step towards high level planning by specifying the optimal trajectory as a general constrained variational problem. Markovian Networks are presented as a class of neural networks with local interactions and iterative dynamics (like the dynamics of Hopfield-Nets or Boltzmann-Machines) <ref> [4, 7, 11] </ref>. They are closely related to the statistical framework of Markov-Random-Fields [4], which has been used to solve complex optimization problems with topological structured variables [5]. <p> By a weighted summation J [Y ] = P competing optimality conditions this defines a general (constrained) variational problem in two coupled coordinate spaces <ref> [11] </ref>: minimize J [Y ] = a with a vector valued function Y 2 C 2 (a; b) as the variational parameter, given boundary values a; b; Y (a) = y a ; Y (b) = y b and a differentiable function F under the constraint G [fi] = 0. <p> The tasks of a manipulator can be classified according to their difficulty: * Tasks with optimality conditions exclusively in the joint domain can often be solved easily [3]. * For time optimal movements there exists a large number of approaches (see the references in <ref> [11] </ref>). * Cartesian path tracking can be solved by recursive pointwise mapping using a differential inverse kinematic map and applying interpolation [3] and rescaling [8] techniques in the joint domain. * Time dependent cartesian movements, especially when the type of deviation is crucial (as in the surface scenario), have to be <p> There exist a vast amount of heuristic approaches to trajectory formation, but these hardly solve the last type of problems, because they decouple kinematic map and optimization and thus lead to sub-optimal or useless trajectories (see discussion and references in <ref> [11] </ref>). We thus focus on tasks of this type. 3 Markovian Networks A Markovian Network constitutes itself of state variables, called neurons or nodes, and a local neighborhood defining possible dependencies among the variables. <p> Improvements of this order of magnitude are crucial to enable industrial applications like welding or spray coating. The technical details as well as many more examples and an empirical analysis of the behavior of the algorithms can be found in <ref> [11] </ref>. The presented examples were validated with the real robot. a deviation of the optimal orientation. In (b) the optimization progress for the chosen example is shown.
References-found: 11

