URL: http://arch.cs.ucdavis.edu/~chong/250C/now/workshop.ps
Refering-URL: http://arch.cs.ucdavis.edu/~chong/250C/now/
Root-URL: http://www.cs.ucdavis.edu
Title: Adaptive Parallelism with Piranha  
Author: Nicholas Carriero David Gelernter David Kaminsky Jeffery Westbrook 
Abstract: Adaptive parallelism" refers to parallel computations on a dynamically changing set of processors: processors may join or withdraw from the computation as it proceeds. Networks of fast workstations are the most important setting for adaptive parallelism at present. Workstations at most sites are typically idle for significant fractions of the day, and those idle cycles may constitute in the aggregate a powerful computing resource. For this reason and others, we believe that adaptive parallelism is assured of playing an increasingly prominent role in parallel applications development over the next decade. The "Piranha" system now up and running on a heterogeneous network at Yale is a general-purpose adaptive parallelism environment. It has been used to run a variety of production applications, including applications in graphics, theoretical physics, electrical engineering and computational fluid dynamics. In this paper we describe the Piranha model and several archetypal Piranha algorithms. Our main goals are to show that it is an effective and workable approach, to explain how the Piranha model constrains algorithm design, and to suggest directions for theoretical and practical research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agha, G. </author> <title> Actors: A Model of Concurent Computation in Distributed Systems. </title> <publisher> MIT Press (Cambridge: </publisher> <year> 1986). </year>
Reference: [2] <author> Aho, A., Hopcroft, J., and Ullman, J, </author> <title> "The Design and Analysis of Computer Algorithms," </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference: [3] <author> Baker, H. and Hewitt, C., </author> <title> "The incremental garbage collection of processes." </title> <booktitle> In Conference Record of the Conference on AI and Programming Languages, </booktitle> <pages> pp 55-59, </pages> <publisher> ACM, </publisher> <address> Rochester, New York, </address> <month> 8/77. </month>
Reference: [4] <author> Bjornson, R., Kaminsky, D., and Weston, S., </author> <title> "LU Decomposition in an Adaptive Parallel Environment", </title> <booktitle> in progress, </booktitle> <year> 1993. </year>
Reference: [5] <author> Carriero, N and Gelernter, D. </author> <title> How to Write Parallel Programs: A First Course. </title> <publisher> MIT Press (Cambridge: </publisher> <year> 1990). </year>
Reference-contexts: General process migration is expensive, and it poses obvious difficulties on heterogenous networks of processors. Holding processes constant while the node pool contracts may lead to excessive process management overhead in the shrinking pool of active nodes. Piranha, in contrast, is an adaptive version of master-worker parallelism <ref> [5] </ref>. Algorithm designers specify in effect a single general purpose "worker function," by convention named "piranha ()." They do not create processes and their applications do not rely on any particular set of named active processes. <p> Data and task descriptors are stored in distributed data structures accessible to all worker processes; the more workers, the faster the program completes, but there is no reliance on any particular number of active workers. The Piranha system uses the shared associatve object memories ("tuple spaces") provided by Linda <ref> [5] </ref> to manage coordination and the distributed data structures in which the problem state is stored. This approach has a number of advantages. Processes need never be moved around. <p> Transfer into distributed memory the set T (t; n). 3. Transfer into distributed memory the output data from any completed tasks. 4. Relinquish all local memory. Thus any intermediate results of the task computation are lost. 1 A description of tuple space access functions is found in <ref> [5] </ref>. 4 A retreat returns a task being processed to distributed memory as if it had never been started. 2 Thus if a processor is becomes available for just slightly less than the time required to complete a task, all the work is wasted and we are not making good use
Reference: [6] <author> Chase, J.S., Amador, F.G., Lazowska, E.D., Levy, H.M., Littlefield, </author> <title> R.J. "The Amber System: Parallel Programming on a Network of Multiprocessors," </title> <booktitle> Proceedings of the Twelth ACM Symp. on Operating Systems Principles, </booktitle> <pages> pp 147-158, 12/89. </pages>
Reference-contexts: Such an approach was investigated as long ago as the "MuNet" project and the early stages of Actors research (e.g. [1],[3]); a variant of this approach formed the basis of the "Amber" adaptive parallelism system <ref> [6] </ref>. This approach, while theoretically appealing, has drawbacks in practice. General process migration is expensive, and it poses obvious difficulties on heterogenous networks of processors. Holding processes constant while the node pool contracts may lead to excessive process management overhead in the shrinking pool of active nodes.
Reference: [7] <author> Gelernter, D. and Kaminsky, D., </author> <title> "Supercomputing out of Recycled Garbage: Preliminary Experience with Piranha," </title> <booktitle> Sixth ACM International Conference on Supercomputing, </booktitle> <address> Washington D.C., </address> <month> July 19-23, </month> <year> 1992. </year>
Reference-contexts: Several ad hoc systems have been designed to solve specific computational tasks adaptively| for example testing primality or computing travelling salesman tours [8, 10]. The "Piranha" system now up and running on a heterogeneous network at Yale <ref> [7] </ref> is a general-purpose adaptive parallelism environment. It has been used to run a variety of production applications, including applications in graphics, theoretical physics, electrical engineering and computational fluid dynamics. In this paper we describe the Piranha model and several archetypal Piranha algorithms.
Reference: [8] <author> Lenstra, A.K., and Manasse, M., </author> <title> "Factoring by Electronic Mail," </title> <booktitle> Proc. Eurocrypt '89, Lecture Notes in Computer Science 434, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year> <month> 15 </month>
Reference-contexts: Algorithms research targeted at adaptive parallelism is a necessity if algorithms are to keep pace with ongoing practical developments in parallel systems. Several ad hoc systems have been designed to solve specific computational tasks adaptively| for example testing primality or computing travelling salesman tours <ref> [8, 10] </ref>. The "Piranha" system now up and running on a heterogeneous network at Yale [7] is a general-purpose adaptive parallelism environment. It has been used to run a variety of production applications, including applications in graphics, theoretical physics, electrical engineering and computational fluid dynamics.
Reference: [9] <author> Mutka, M.W. and Livny, M. </author> <title> "Profiling Workstations' Available Capacity for Remote Execution", </title> <booktitle> Performance '87, </booktitle> <pages> pp 529-544, </pages> <publisher> Elsevier Science Publishers B.V. (North Holland), </publisher> <year> 1988. </year>
Reference: [10] <author> N. Reingold, </author> <title> private communication, </title> <booktitle> 1993. </booktitle> <pages> 16 </pages>
Reference-contexts: Algorithms research targeted at adaptive parallelism is a necessity if algorithms are to keep pace with ongoing practical developments in parallel systems. Several ad hoc systems have been designed to solve specific computational tasks adaptively| for example testing primality or computing travelling salesman tours <ref> [8, 10] </ref>. The "Piranha" system now up and running on a heterogeneous network at Yale [7] is a general-purpose adaptive parallelism environment. It has been used to run a variety of production applications, including applications in graphics, theoretical physics, electrical engineering and computational fluid dynamics.
References-found: 10

