URL: ftp://rtcl.eecs.umich.edu/outgoing/ashish/end-rll.ps
Refering-URL: http://www.eecs.umich.edu/~ashish/
Root-URL: http://www.cs.umich.edu
Email: atri@cisco.com mehraa@watson.ibm.com kgshin@eecs.umich.edu  
Phone: 704  
Title: Receive Livelock Elimination via Intelligent Interface Backoff  
Author: Atri Indiresan Ashish Mehra Kang G. Shin 
Keyword: Key Words Receive livelock, network adapters, interrupt management, operating system.  
Address: 130 W. Tasman Drive P.O. Box  San Jose, CA 95134 Yorktown Heights, NY 10598  Ann Arbor, MI 48109  
Affiliation: Cisco Systems Inc. IBM T. J. Watson Research Center Real-time Computing Lab.  Dept. of Electrical Engr.  and Computer Science The University of Michigan  
Abstract: In interrupt-driven operating systems, high packet arrival rates can result in receive livelock, a situation where the host uses all of its capacity to receive incoming data, and cannot usefully process any of it. Solutions to eliminate or prevent receive livelock typically involve extensive (and potentially costly) modifications to the host operating system. In this paper we propose a novel adapter-based solution to eliminate receive livelock, called intelligent interface backoff. This solution utilizes additional intelligence on network adapters to detect host input load levels and dynamically modulate the rate at which interrupts are delivered to the host. Using qualitative and quantitative comparisons, we argue that an adapter-based approach for receive livelock elimination performs at least as well as, but is more cost-effective than, the host-based approaches proposed in the literature. We also demonstrate how intelligent interface backoff can be employed effectively in multi-homed hosts engaged in simultaneous network input from multiple network interfaces, while providing minimum input bandwidths to each interface even under extreme overload conditions. The work reported in this paper was performed at the University of Michigan. It was supported in part by the Defense Advanced Research Projects Agency, monitored by the US Air Force Rome Laboratory under Grant F30602-95-1-0044, the National Science Foundation under Grant MIP-9203895 and the Office of Naval Research under Grant N00014-94-1-0229. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. K. Ramakrishnan, </author> <title> "Performance considerations in designing network interfaces," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 203-219, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: At low packet arrival rates, such systems can provide low overhead and latency for handling incoming packets. However, packet input overhead directly increases with an increase in the packet arrival rate, causing receive livelock <ref> [1] </ref>, a condition where a network host (such as a server or router) expends all its processing resources handling interrupts. As a result, under receive livelock the host is unable to usefully process incoming network data [2]. <p> Subsequently, we provide a brief description of our experimentation platform and evaluation framework used to evaluate host-based and adapter-based strategies for receive livelock elimination in Sections 3 and 4, respectively. 2.1 Receive Livelock A description of the receive livelock problem (summarized from <ref> [1, 2] </ref>) is presented below. Packets received at a host must either be forwarded to other hosts (as in the case of a router), or to application programs where they are consumed. The delivered system throughput is a measure of the rate at which such packets are processed successfully. <p> Packets received at a host must either be forwarded to other hosts (as in the case of a router), or to application programs where they are consumed. The delivered system throughput is a measure of the rate at which such packets are processed successfully. Figure 1 (adapted from <ref> [1] </ref>) demonstrates the possible behaviors of delivered throughput versus offered input load. Ideally, no matter what the packet arrival rate, every incoming packet is processed. <p> However, all practical systems have finite capacity, and cannot receive and process packets beyond a maximum rate (determined by their processing capacity, and the cost of receiving and processing the packet), called the Maximum Loss-Free Receive Rate (MLFRR) <ref> [1] </ref>. In poorly-designed communication subsystems, under network input overload, a host can be swamped with receiving arriving packets to the extent that the effective system throughput falls to zero. <p> Similarly, under receive livelock, a router may be unable to forward packets to the outgoing interface, resulting in transmit starvation <ref> [1] </ref>. <p> In the following sections, we describe our implementations of variants of the schemes described in the literature <ref> [1, 2, 7] </ref>. We then propose and implement a novel adapter-based solution to avoid receive livelock and demonstrate how it achieves our goals of performance, generality and simplicity. 2.3 Evaluation Framework A typical sequence of events following the arrival of a packet from the network is shown in Figure 2.
Reference: [2] <author> J. Mogul and K. K. Ramakrishnan, </author> <title> "Eliminating receive livelock in an interrupt-driven kernel," </title> <journal> ACM Trans. Computer Systems, </journal> <volume> vol. 15, no. 3, </volume> <pages> pp. 217-252, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: As a result, under receive livelock the host is unable to usefully process incoming network data <ref> [2] </ref>. A number of solutions have been proposed for the prevention or elimination of receive livelock [2, 3]. In one of these approaches, significant modifications to the operating system (especially the networking subsystem) are developed to exercise precise control over the input and processing of incoming traffic [2]. <p> As a result, under receive livelock the host is unable to usefully process incoming network data [2]. A number of solutions have been proposed for the prevention or elimination of receive livelock <ref> [2, 3] </ref>. In one of these approaches, significant modifications to the operating system (especially the networking subsystem) are developed to exercise precise control over the input and processing of incoming traffic [2]. <p> incoming network data <ref> [2] </ref>. A number of solutions have been proposed for the prevention or elimination of receive livelock [2, 3]. In one of these approaches, significant modifications to the operating system (especially the networking subsystem) are developed to exercise precise control over the input and processing of incoming traffic [2]. In another approach known as lazy receiver processing (LRP) [3], incoming network data is demultiplexed early on but its processing is delayed until the destination application is ready to receive it. <p> Subsequently, we provide a brief description of our experimentation platform and evaluation framework used to evaluate host-based and adapter-based strategies for receive livelock elimination in Sections 3 and 4, respectively. 2.1 Receive Livelock A description of the receive livelock problem (summarized from <ref> [1, 2] </ref>) is presented below. Packets received at a host must either be forwarded to other hosts (as in the case of a router), or to application programs where they are consumed. The delivered system throughput is a measure of the rate at which such packets are processed successfully. <p> Further, reception mechanisms must be made as efficient as possible to lower the probability of livelock and to increase the MLFRR. 2.2 Existing Solutions The problem of avoiding receive livelock has been addressed at length in <ref> [2] </ref>. The authors' goals in designing packet reception policies and mechanisms were to guarantee acceptable system throughput, reasonable latency and jitter , fair allocation of resources, and overall system stability. <p> Note that prevention of receive livelock is facilitated by allowing the host to exercise control over the packet arrival interrupts. This can be done either by eliminating device interrupts entirely in favor of polling [7], or using a hybrid scheme <ref> [2] </ref> to limit the input arrival rate. Pure polling imposes significant CPU overhead and tends to exacerbate the average latencies seen by incoming packets, with the additional disadvantage that it is difficult to choose the proper polling frequency. In the hybrid scheme of [2], interrupts are used only to 3 Phase <p> polling [7], or using a hybrid scheme <ref> [2] </ref> to limit the input arrival rate. Pure polling imposes significant CPU overhead and tends to exacerbate the average latencies seen by incoming packets, with the additional disadvantage that it is difficult to choose the proper polling frequency. In the hybrid scheme of [2], interrupts are used only to 3 Phase Network Adapter Device Driver Initialization store packet in buffer initialize data structures send read ! interrupt host ! initialize data structures complete host handshake send read ack DMA send address DMA packet to host ! send read end ! interrupt host ! demux <p> Under a burst of incoming packets, it is likely that the polling thread may continue running until the capacity threshold is reached for that polling period. As the authors of <ref> [2] </ref> also point out, this introduces additional latency for applications that require received packets to be queued for processing by another thread. Further, there is also the question of selecting the polling timeout to re-enable interrupts on the attached interface. <p> In the following sections, we describe our implementations of variants of the schemes described in the literature <ref> [1, 2, 7] </ref>. We then propose and implement a novel adapter-based solution to avoid receive livelock and demonstrate how it achieves our goals of performance, generality and simplicity. 2.3 Evaluation Framework A typical sequence of events following the arrival of a packet from the network is shown in Figure 2. <p> However, such changes do increase the complexity of the operating system, and may not be readily portable from one platform to another or adapt well to changes in the workload. We now examine some techniques that are partly derived from solutions proposed in <ref> [2, 6, 7] </ref>. 3.1 Interrupt-based Reception This is the default operating system kernel mode where the adapter interrupts the host with every command (CTRL MODE INTR). These interrupts are high priority and preempt all other host processing. Clearly, in this mode, the kernel is susceptible to receive livelock. <p> With a more heavily-loaded system, the delay is likely to complete before the host can re-enable interrupts, resulting in behavior similar to clocked interrupts. Other forms of explicit interrupt management have been proposed earlier <ref> [2, 6] </ref>. This is a complex solution that dynamically adjusts the host parameters and policies in response to the system load, which may be measured by factors such as queue occupancy and CPU utilization by interrupts and applications. <p> of over 1500 packets per second was the highest we observed for any scheme. 11 4.3 Discussion In Section 2.1, the goals of designing packet reception mechanisms and policies were identified to be to guarantee acceptable system throughput, reasonable latency and jitter, fair allocation of resources, and overall system stability <ref> [2] </ref>. Further, we required that these techniques be as general as possible and must minimize implementation complexity. Host-based schemes are often very sensitive to parameter settings and the specific scheduling paradigm. Even with a single source of interrupts, they have to be debugged carefully and tuned for stability of performance. <p> Host-based schemes are often very sensitive to parameter settings and the specific scheduling paradigm. Even with a single source of interrupts, they have to be debugged carefully and tuned for stability of performance. While this might be acceptable for special-purpose systems like the routers described in <ref> [2] </ref>, a more general approach is desirable. Intelligent interface backoff performs at least as well as the host-based solutions on all the performance criteria. While such a scheme does require some minor changes to the adapter firmware, changes to the host OS are minimal. <p> A more general purpose OS (like Unix) requires complex changes to the OS scheduler, and other parts of the kernel, to meet the demands of the different executing tasks <ref> [2, 6] </ref>. However, the intelligent interface backoff solution would work well on any platform since it simply regulates the receive interrupt rate based on the progress of the processes that consume received packets and make available buffers to receive more data.
Reference: [3] <author> P. Druschel and G. Banga, </author> <title> "Lazy receiver processing (LRP): A network subsystem architecture for server systems," </title> <booktitle> in Proc. Second USENIX Symp. on Operating Systems Design and Implementation, </booktitle> <pages> pp. 261-276, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: As a result, under receive livelock the host is unable to usefully process incoming network data [2]. A number of solutions have been proposed for the prevention or elimination of receive livelock <ref> [2, 3] </ref>. In one of these approaches, significant modifications to the operating system (especially the networking subsystem) are developed to exercise precise control over the input and processing of incoming traffic [2]. <p> In one of these approaches, significant modifications to the operating system (especially the networking subsystem) are developed to exercise precise control over the input and processing of incoming traffic [2]. In another approach known as lazy receiver processing (LRP) <ref> [3] </ref>, incoming network data is demultiplexed early on but its processing is delayed until the destination application is ready to receive it. <p> It is also consistent with other efforts to selectively enhance the intelligence of network adapters in order to improve end-to-end data transfer performance, e.g., support for outboard checksumming, early demultiplexing, buffer management, etc. <ref> [3, 4] </ref>. The rest of this paper is organized as follows. <p> In addition to the goals presented above, it is also desirable that any techniques must be as general as possible and must minimize implementation complexity . Another solution to receive livelock is lazy receiver processing (LRP) <ref> [3] </ref>, which has been implemented on Unix platforms with UDP/IP and TCP/IP based protocol stacks. As seen in the discussion above, receive livelock occurs since reception protocol processing is performed by the OS kernel at a very high priority. <p> While this delays the onset of livelock, it does not prevent it, and neither does it raise the value of MLF RR. This is similar to what was observed using the early discard policy in <ref> [3] </ref>. 3.2 Continuous Polling Since receive livelock is caused by interrupts, one solution is to eliminate interrupts completely and use polling instead. <p> In Section 5, we demonstrate how our adapter based solution may be extended to solve this problem, again, without modifying the host OS. 9 4 Adapter-based Intelligent Interrupt Management Intelligent (programmable) adapters may also be used to help avoid receive livelock. In LRP <ref> [3] </ref>, the adapter determines the destination of a packet, and since it has access to socket queues on the host, drops excess packets without interrupting the host.
Reference: [4] <author> P. Druschel, L. L. Peterson, and B. S. Davie, </author> <title> "Experiences with a high-speed network adaptor: A software perspective," </title> <booktitle> in Proc. of ACM SIGCOMM, </booktitle> <pages> pp. 2-13, </pages> <address> London, UK, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: However, these modifications are relatively simple and can be located primarily within the lowest layers of the network protocol stack. Note that our approach is consistent with the current trend of a tighter integration of the network subsystem with the internal components of a high-performance network host <ref> [4] </ref>. It is also consistent with other efforts to selectively enhance the intelligence of network adapters in order to improve end-to-end data transfer performance, e.g., support for outboard checksumming, early demultiplexing, buffer management, etc. [3, 4]. The rest of this paper is organized as follows. <p> It is also consistent with other efforts to selectively enhance the intelligence of network adapters in order to improve end-to-end data transfer performance, e.g., support for outboard checksumming, early demultiplexing, buffer management, etc. <ref> [3, 4] </ref>. The rest of this paper is organized as follows.
Reference: [5] <author> S. J. Le*er, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD Unix Operating System, </title> <publisher> Addison Wesley, </publisher> <month> May </month> <year> 1989. </year>
Reference-contexts: The primary reason for receive livelock is that most traditional network adapters interrupt the attached host for every arriving packet, and these hardware interrupts are handled at a very high priority (e.g., higher than software interrupts in BSD Unix-derived systems <ref> [5] </ref>) or input threads that process the packet further up the protocol stack. At lower packet arrival rates, this design allows the host to consume a packet almost immediately on arrival, freeing up (limited) buffer space on the adapter for future packets.
Reference: [6] <author> J. S. Hansen and E. </author> <month> Jul, </month> <title> "A scheduling scheme for network saturated NT multiprocessors," </title> <booktitle> in Proc. of the USENIX Windows NT Workshop, </booktitle> <address> Seattle, Washington, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: These techniques include limiting interrupt arrival rates to shed overload, polling the transmit and receive interfaces to provide fairness, processing received packets to completion, and explicitly regulating CPU usage for packet processing. A variant of these solutions was implemented for Windows NT platforms <ref> [6] </ref> that simply turned off interrupts and used polling under high load, and turned the interrupts back on when the load declined. These techniques constitute significant kernel enhancements and may also need to be customized based on the organization of the operating system, protocol stack and communicating applications. <p> However, such changes do increase the complexity of the operating system, and may not be readily portable from one platform to another or adapt well to changes in the workload. We now examine some techniques that are partly derived from solutions proposed in <ref> [2, 6, 7] </ref>. 3.1 Interrupt-based Reception This is the default operating system kernel mode where the adapter interrupts the host with every command (CTRL MODE INTR). These interrupts are high priority and preempt all other host processing. Clearly, in this mode, the kernel is susceptible to receive livelock. <p> With a more heavily-loaded system, the delay is likely to complete before the host can re-enable interrupts, resulting in behavior similar to clocked interrupts. Other forms of explicit interrupt management have been proposed earlier <ref> [2, 6] </ref>. This is a complex solution that dynamically adjusts the host parameters and policies in response to the system load, which may be measured by factors such as queue occupancy and CPU utilization by interrupts and applications. <p> A more general purpose OS (like Unix) requires complex changes to the OS scheduler, and other parts of the kernel, to meet the demands of the different executing tasks <ref> [2, 6] </ref>. However, the intelligent interface backoff solution would work well on any platform since it simply regulates the receive interrupt rate based on the progress of the processes that consume received packets and make available buffers to receive more data.
Reference: [7] <author> C. B. S. Traw and J. M. Smith, </author> <title> "Hardware/software organization of a high-performance ATM host interface," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 240-253, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Note that prevention of receive livelock is facilitated by allowing the host to exercise control over the packet arrival interrupts. This can be done either by eliminating device interrupts entirely in favor of polling <ref> [7] </ref>, or using a hybrid scheme [2] to limit the input arrival rate. Pure polling imposes significant CPU overhead and tends to exacerbate the average latencies seen by incoming packets, with the additional disadvantage that it is difficult to choose the proper polling frequency. <p> In the following sections, we describe our implementations of variants of the schemes described in the literature <ref> [1, 2, 7] </ref>. We then propose and implement a novel adapter-based solution to avoid receive livelock and demonstrate how it achieves our goals of performance, generality and simplicity. 2.3 Evaluation Framework A typical sequence of events following the arrival of a packet from the network is shown in Figure 2. <p> However, such changes do increase the complexity of the operating system, and may not be readily portable from one platform to another or adapt well to changes in the workload. We now examine some techniques that are partly derived from solutions proposed in <ref> [2, 6, 7] </ref>. 3.1 Interrupt-based Reception This is the default operating system kernel mode where the adapter interrupts the host with every command (CTRL MODE INTR). These interrupts are high priority and preempt all other host processing. Clearly, in this mode, the kernel is susceptible to receive livelock.
Reference: [8] <author> A. Indiresan, </author> <title> Exploting Quality-of-Service Issues in Network Adapter Design, </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, The University of Michigan, </institution> <address> Ann Arbor, MI 48109, </address> <month> October </month> <year> 1997. </year>
Reference-contexts: In this example, each packet reception involves four commands two from the adapter to the host (possibly with an interrupt with each command) and two from the host to the adapter. END <ref> [8, 9] </ref> (described below) is used to capture this model, and evaluate alternatives that solve the receive livelock problem. 2.3.1 The END: A Network Adapter Design Tool END (Emulated Network Device) is an emulation-based network adapter design tool. <p> END -based models interact with the hosts in real time and are sufficiently detailed to study communication subsystems while including the effects of overhead like interrupts and cache behavior. Detailed descriptions of the architecture of END , and various applications using END, may be found in <ref> [8, 9] </ref>. Though all the implementations and experiments were performed using END , in the rest of this paper, we shall refer to adapters, unless we wish to highlight a feature of END that might not be necessary/possible to implement on a real adapter.
Reference: [9] <author> A. Indiresan, A. Mehra, and K. G. Shin, </author> <title> "The END: A network adapter design tool," </title> <booktitle> in IEEE INFOCOM, </booktitle> <month> March </month> <year> 1998. </year> <note> (To appear). </note>
Reference-contexts: In this example, each packet reception involves four commands two from the adapter to the host (possibly with an interrupt with each command) and two from the host to the adapter. END <ref> [8, 9] </ref> (described below) is used to capture this model, and evaluate alternatives that solve the receive livelock problem. 2.3.1 The END: A Network Adapter Design Tool END (Emulated Network Device) is an emulation-based network adapter design tool. <p> END -based models interact with the hosts in real time and are sufficiently detailed to study communication subsystems while including the effects of overhead like interrupts and cache behavior. Detailed descriptions of the architecture of END , and various applications using END, may be found in <ref> [8, 9] </ref>. Though all the implementations and experiments were performed using END , in the rest of this paper, we shall refer to adapters, unless we wish to highlight a feature of END that might not be necessary/possible to implement on a real adapter.
Reference: [10] <author> N. C. Hutchinson and L. L. Peterson, </author> <title> "The x-Kernel: An architecture for implementing network protocols," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 1-13, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: The various policies and their respective commands are discussed in detail in Sections 3 and 4. 2.3.2 System Parameters Table 2 shows the measured values of important parameters of the reception subsystem on our platform (25MHz Motorola MC68040 running the x-kernel <ref> [10] </ref>). When the host receives a packet, it takes C ri time units to handle the reception protocol processing, and C pp time units for the application to process the packet.
Reference: [11] <author> C.-H. Chang, R. Flower, J. Forecast, H. Gray, W. R. Hawe, A. P. Nadkarni, K. K. Ramakrishnan, U. N. Shikarpur, and K. M. Wilde, </author> <title> "High-performance TCP/IP and UDP/IP networking in DEC OSF/1 for Alpha AXP," </title> <journal> Digital Technical Journal of Digital Equipment Corporation, </journal> <volume> vol. 5, no. 1, </volume> <pages> pp. 44-61, </pages> <month> Winter </month> <year> 1993. </year>
Reference-contexts: In LRP [3], the adapter determines the destination of a packet, and since it has access to socket queues on the host, drops excess packets without interrupting the host. Similarly, in DEFTA <ref> [11] </ref>, the device driver ensures that the packets are dropped in the adapter when the host is starved of resources to receive data.
References-found: 11

