URL: http://www.cs.wisc.edu/~fischer/course/html/submissions/128.ps.gz
Refering-URL: http://www.cs.wisc.edu/~fischer/course/html/submissions/
Root-URL: http://www.cs.wisc.edu
Title: Applying Compiler Optimization in Distributed Real-Time Systems  
Author: Mohamed F. Younis Thomas J. Marlowe Grace Tsai Alexander D. Stoyenko 
Abstract: Compiler optimization techniques have been applied to facilitate development and performance tuning of non-real-time systems. Unfortunately, regular compiler optimization can complicate the analysis and destroy timing properties of real-time systems. In this paper, we discuss the difficulties associated with performing compiler optimization in distributed real-time systems. We present an algorithm to apply machine-independent compiler optimization safely to distributed real-time systems. The algorithm uses resources' busy-idle profiles to investigate effects of optimizing one process on other processes. A restricted form of resource contention is assumed to simplify the analysis.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Amarasinghe, M. Lam, </author> <title> Communication Optimization and Code Generation for Distributed Memory Machines. </title> <booktitle> Proceedings of ACM SIGPLAN 1993 Conference on Programming Language Design and Implementation, </booktitle> <pages> 126-138. </pages>
Reference-contexts: The second type of code improvement transformations is multiprocess optimization. Optimizing interpro-cess communication is a common approach. Compilers can detect useless messages, or redundant parameters in a message. Another common approach for asynchronous messages moves sends upward and receives downward <ref> [1, 7] </ref>. The removal of unnecessary messages and parameters, or optimizing asynchronous messages, is usually locally safe because it shortens execution time. However, it may affect other resources' busy-idle profiles. The third form is multiprocessor optimization.
Reference: [2] <author> S. Baruah, L. Rosier, </author> <title> Limitations concerning on-line scheduling algorithms for overloaded real-time systems. </title> <booktitle> IEEE/IFAC Real-Time Operating Systems Workshop, </booktitle> <address> Atlanta, Georgia, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Not only do resources then become available to other system tasks or users, but also this may make the programs more robust in the face of faults or unpredictable system overload <ref> [2] </ref>. For example, achieving a speedup of 10% for an overall system of 100 processes by optimization may permit the system to accept an extra load of perhaps 10 processes (assuming all processes have similar requirements).
Reference: [3] <author> V. Cherkassky, </author> <title> Redundant task-allocation in multicomputer systems. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol 3, No. 41, </volume> <pages> pp 336-342, </pages> <month> Sept. </month> <year> 1992 </year>
Reference-contexts: However, it may affect other resources' busy-idle profiles. The third form is multiprocessor optimization. Migration and speculative execution, remote calls, and moving code in/out of a call are examples of this category <ref> [3, 4, 27] </ref>. Multiprocess and multiprocessor optimizations can also be unsafe with respect to other processes, processors, and resources. We are concerned with the results of transformations/optimizations, and making them safe for a multiprocess real-time application.
Reference: [4] <author> K. Cooper, M. Hall, K. Kennedy, </author> <title> A methodology for procedure cloning. </title> <booktitle> Proceedings of the IEEE international conf. on Computer Languages, </booktitle> <month> April </month> <year> 1992 </year>
Reference-contexts: However, it may affect other resources' busy-idle profiles. The third form is multiprocessor optimization. Migration and speculative execution, remote calls, and moving code in/out of a call are examples of this category <ref> [3, 4, 27] </ref>. Multiprocess and multiprocessor optimizations can also be unsafe with respect to other processes, processors, and resources. We are concerned with the results of transformations/optimizations, and making them safe for a multiprocess real-time application.
Reference: [5] <author> R. Gerber, S. Hong, </author> <title> Compiling Real-Time Programs with Timing Constraints Refinement and Structural Code Motion. </title> <institution> CS-TR-3323, UMIACS-TR-94-90, Department of Computer Science, University of Maryland, </institution> <month> Jul, </month> <year> 1994. </year>
Reference-contexts: We consider two categories of transformations: (1) code transformations to improve overall performance or enhance schedulability of processes, (2) transformations to reduce the complexity of schedulability analysis. Code motion is used in <ref> [5, 8] </ref> to re-organize the code of a sequential process to meet timing requirements. Forking new processes to speculatively execute blocks of the code without destroying timeliness of in case of rollback is discussed in [27].
Reference: [6] <author> R. Gupta, M. Spezialetti, </author> <title> Busy-Idle Profiles and Compact Task Graphs: Compile-time Support for Interleaved and Overlapped Scheduling of Real-Time Tasks. </title> <booktitle> Proceedings of the 15th IEEE Real-Time Systems Symposium, </booktitle> <address> San Juan, Puerto Rico, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: Simplification techniques have been developed to perform that kind of analysis, either by restricting the resource access model [23], or by assuming a smart scheduler <ref> [6] </ref>, as illustrated in Section 4. Our approach uses the restricted resource contention model of [23] to predict the response time of resource requests. We rely on extracting the busy-idle profiles of shared resources during compilation. <p> We rely on extracting the busy-idle profiles of shared resources during compilation. Consulting the resource busy-idle profile before applying the code improving transformations, we can predict the effects of optimizing a process on other communicating processes. 3 Previous Work In addition to <ref> [6, 10, 23] </ref>, related work includes work in real-time optimization, and work on simplifying schedulability analysis. We consider two categories of transformations: (1) code transformations to improve overall performance or enhance schedulability of processes, (2) transformations to reduce the complexity of schedulability analysis. <p> In fact, multiprocess analysis in the presence of speculative execution is harder than that for code improvement, due to increased contention for communication links. Busy-idle profiles of resources were introduced in [17], where they are used to schedule monitoring activities non-intrusively. In <ref> [6] </ref>, profiles are used to expose the potential for parallelism across tasks to the scheduler. Here, we use busy-idle profiles to check the effects of transformations on other processes. We try to speed up individual processes without affecting others, rather than simply informing the scheduler. <p> The output of this step is a timing profile of requests being initiated from each individual process, as in Figure 3. There are many algorithms proposed in the literature which can be used to build such profiles, for example <ref> [6] </ref>. 4.2 The Restricted Resource Contention Model Once we extract resource access profiles per process, the next step is to build the resource's busy-idle profile. Because, at compile-time, we have no clue about the order of requests from various processes, one of two assumptions can be used.
Reference: [7] <author> R. von Hanxleden, K. Kennedy, </author> <title> Give-N-Take | A Balanced Code Placement Framework. </title> <booktitle> Proceedings of ACM SIGPLAN 1994 Conference on Programming Language Design and Implementation, </booktitle> <pages> 107-120. </pages>
Reference-contexts: The second type of code improvement transformations is multiprocess optimization. Optimizing interpro-cess communication is a common approach. Compilers can detect useless messages, or redundant parameters in a message. Another common approach for asynchronous messages moves sends upward and receives downward <ref> [1, 7] </ref>. The removal of unnecessary messages and parameters, or optimizing asynchronous messages, is usually locally safe because it shortens execution time. However, it may affect other resources' busy-idle profiles. The third form is multiprocessor optimization.
Reference: [8] <author> S. Hong, R. Gerber, </author> <title> Compiling Real-Time Programs into Schedulable Code. </title> <booktitle> Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> ACMPRESS, </address> <month> Jun, </month> <year> 1993, </year> <journal> SIGPLAN Notices, </journal> <volume> 28(6) </volume> <pages> 166-176. </pages>
Reference-contexts: We consider two categories of transformations: (1) code transformations to improve overall performance or enhance schedulability of processes, (2) transformations to reduce the complexity of schedulability analysis. Code motion is used in <ref> [5, 8] </ref> to re-organize the code of a sequential process to meet timing requirements. Forking new processes to speculatively execute blocks of the code without destroying timeliness of in case of rollback is discussed in [27].
Reference: [9] <author> D. Lienbaugh, M. Yamini, </author> <title> Guaranteed Response Times in a Distributed Hard Real Time Environment. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-12, No. 12, </volume> <pages> pages 1139-1144, </pages> <month> December </month> <year> 1986. </year> <month> 22 </month>
Reference-contexts: As a result, schedulability analysis can either be (1) exact and efficient analysis of single process or multiple processes of simple form, or with highly constrained interactions [12, 14, 15, 26], (2) highly imprecise though efficient analysis of multiple process programs <ref> [9] </ref>, or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as [22, 23, 24]. <p> However, not all processes will make those requests at the same time. An accurate queue size can be calculated considering all (possibly exponential number) execution paths of the processes. Analysis, similar to <ref> [9] </ref> and transformations, like [23, 24], can be applied to decrease the number of paths to be considered. Our approach to calculate shared resource access time requires the following two steps: 1.
Reference: [10] <author> T. Marlowe, S. Masticola, </author> <title> Safe Optimization for Hard Real-Time Programming, </title> <booktitle> Special Session on Real-Time Program--ming, Second International Conference on Systems Integration (June 1992), </booktitle> <volume> 438 - 446. </volume>
Reference-contexts: Thus the delay time for process C may be increased, causing it to miss its deadline. Marlowe and Masticola <ref> [10] </ref> showed that we can optimize a system with a single process without disturbing timing constraints in the form of "no later than some deadline". <p> We rely on extracting the busy-idle profiles of shared resources during compilation. Consulting the resource busy-idle profile before applying the code improving transformations, we can predict the effects of optimizing a process on other communicating processes. 3 Previous Work In addition to <ref> [6, 10, 23] </ref>, related work includes work in real-time optimization, and work on simplifying schedulability analysis. We consider two categories of transformations: (1) code transformations to improve overall performance or enhance schedulability of processes, (2) transformations to reduce the complexity of schedulability analysis. <p> In the first phase, we consider each individual process in isolation. Code improvement transformations will be applied safely, in the sense of <ref> [10] </ref>, for individual processes. However, in all cases gains in performance are compensated by injecting delays to preserve the shared resource access profile. These delay statements are the seeds for delay propagation in the second phase.
Reference: [11] <author> S. Midkiff, D. Padua, </author> <title> Issues in the optimization of parallel programs. </title> <booktitle> Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <volume> vol. II, </volume> <pages> 105-113. </pages>
Reference-contexts: Using a simple machine model and real-time language, they were able to decide whether an optimization is valid, and to recover much of the benefit 2 of optimization. A similar approach to optimization for explicitly parallel programs is discussed in <ref> [11] </ref>. However, in multiprocess real-time systems, it is hard to guarantee that an optimization in one process will not negatively affect the other processes in the system. Access time of resources can be easily disturbed, and other processes may anticipate extra delays.
Reference: [12] <author> A. Mok, P. Amerasinghe, M. Chen, K. Tarntisivat, </author> <title> Evaluating Tight Execution Time Bounds of Programs by Annotations. </title> <booktitle> IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <address> Pittsburgh, PA, </address> <pages> pp. 74 - 80, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: As a result, schedulability analysis can either be (1) exact and efficient analysis of single process or multiple processes of simple form, or with highly constrained interactions <ref> [12, 14, 15, 26] </ref>, (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as
Reference: [13] <author> F. Mueller, D. Whalley, M. </author> <title> Harmon Predicting Instruction Cache Behavior. </title> <booktitle> Proceedings of the ACM SIGPLAN Workshop on Language, Compiler, and Tool Support for Real-Time Systems, </booktitle> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Timing information is extracted during semantic analysis. Various techniques, like loop unwinding and call inlining, may be used to obtain estimates 5 of the execution time of loops, recursive calls, etc. Architecture-dependent analysis can be used to tighten those estimates, as for example in <ref> [13] </ref>. The output of this step is a timing profile of requests being initiated from each individual process, as in Figure 3.
Reference: [14] <author> V. Nirkhe, W. Pugh, </author> <title> A partial evaluator for the Maruti Hard-Real-Time System, </title> <booktitle> Real-Time Systems, </booktitle> <volume> 5 (1), </volume> <pages> pp. 13-30, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: As a result, schedulability analysis can either be (1) exact and efficient analysis of single process or multiple processes of simple form, or with highly constrained interactions <ref> [12, 14, 15, 26] </ref>, (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as
Reference: [15] <author> C. Park, </author> <title> Predicting program execution times by analyzing static and dynamic program paths. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 5 (1), </volume> <pages> pp. 31-62, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: As a result, schedulability analysis can either be (1) exact and efficient analysis of single process or multiple processes of simple form, or with highly constrained interactions <ref> [12, 14, 15, 26] </ref>, (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as
Reference: [16] <author> J. Snyder, D. Whalley, T. Baker, </author> <title> Fast Context Switches: Compiler and Architectural Support for Preemptive Scheduling. </title> <note> Journal of Microprocessors and Microsystems (to appear). </note>
Reference-contexts: Code motion is used in [5, 8] to re-organize the code of a sequential process to meet timing requirements. Forking new processes to speculatively execute blocks of the code without destroying timeliness of in case of rollback is discussed in [27]. Register remapping is introduced in <ref> [16] </ref> to provide fast context switch points for preemptive scheduling. Basically, they only consider single process transformations; none consider the effect of transformations in a multitask environment.
Reference: [17] <author> M. Spezialetti, R. Gupta, </author> <title> Timed Perturbation Analysis: An Approach for Non-Intrusive Monitoring of Real time Computations. </title> <booktitle> Proceedings of the ACM SIGPLAN Workshop on Language, Compiler, and Tool Support for Real-Time Systems, </booktitle> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Basically, they only consider single process transformations; none consider the effect of transformations in a multitask environment. In fact, multiprocess analysis in the presence of speculative execution is harder than that for code improvement, due to increased contention for communication links. Busy-idle profiles of resources were introduced in <ref> [17] </ref>, where they are used to schedule monitoring activities non-intrusively. In [6], profiles are used to expose the potential for parallelism across tasks to the scheduler. Here, we use busy-idle profiles to check the effects of transformations on other processes.
Reference: [18] <author> G. Steele Jr., et. al. </author> <title> Fortran at ten gigaflops: the Connection Machine Convolution Compiler. </title> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation 145-156. </booktitle>
Reference-contexts: 1 Introduction Although compiler optimization techniques have been applied successfully to non-real-time systems <ref> [18] </ref>, they can destroy safety guarantees and deadlines of real-time systems. For this reason, real-time systems developers have tended to avoid automatic compiler optimization of their code. However, real-time applications have been growing substantially in size and complexity in recent years.
Reference: [19] <author> A. Stoyenko, </author> <title> A Schedulability Analyzer for Real-Time Euclid. </title> <booktitle> Proceedings of the IEEE 1987 Real-Time Systems Symposium, </booktitle> <pages> pages 218 - 225, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: Second, resultant changes in the execution behavior of other processes must be analyzed. This analysis checks adherence of processes to their critical timing constraints under all possible execution orders compatible with the scheduling discipline in use. Such analysis, introduced by Stoyenko <ref> [19, 20, 21] </ref> and commonly referred to as schedulability analysis, must be applied even in the absence of optimization. However, finding precise solutions considering contention and branching is, in general, an NP-complete problem, and it can add significantly to the cost of program compilation. <p> analysis can either be (1) exact and efficient analysis of single process or multiple processes of simple form, or with highly constrained interactions [12, 14, 15, 26], (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes <ref> [19, 21] </ref>. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as [22, 23, 24]. Detecting the shared resource access time is a key difficulty in multiprocess analysis of real-time systems.
Reference: [20] <author> A. Stoyenko, </author> <title> A Real-Time Language with A Schedulability Analyzer, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1987. </year>
Reference-contexts: Second, resultant changes in the execution behavior of other processes must be analyzed. This analysis checks adherence of processes to their critical timing constraints under all possible execution orders compatible with the scheduling discipline in use. Such analysis, introduced by Stoyenko <ref> [19, 20, 21] </ref> and commonly referred to as schedulability analysis, must be applied even in the absence of optimization. However, finding precise solutions considering contention and branching is, in general, an NP-complete problem, and it can add significantly to the cost of program compilation.
Reference: [21] <author> A. D. Stoyenko, V. C. Hamacher, R. C. Holt, </author> <title> Analyzing Hard-Real-Time Programs for Guaranteed Schedulability. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> pages 737 - 750, SE-17, No. 8, </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: Second, resultant changes in the execution behavior of other processes must be analyzed. This analysis checks adherence of processes to their critical timing constraints under all possible execution orders compatible with the scheduling discipline in use. Such analysis, introduced by Stoyenko <ref> [19, 20, 21] </ref> and commonly referred to as schedulability analysis, must be applied even in the absence of optimization. However, finding precise solutions considering contention and branching is, in general, an NP-complete problem, and it can add significantly to the cost of program compilation. <p> analysis can either be (1) exact and efficient analysis of single process or multiple processes of simple form, or with highly constrained interactions [12, 14, 15, 26], (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes <ref> [19, 21] </ref>. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as [22, 23, 24]. Detecting the shared resource access time is a key difficulty in multiprocess analysis of real-time systems.
Reference: [22] <author> A. D. Stoyenko, T. J. Marlowe, </author> <title> Schedulability, program transformations and real-time programming. </title> <booktitle> IEEE/IFAC Real-Time Operating Systems Workshop, </booktitle> <address> Atlanta, Georgia May 1991. </address>
Reference-contexts: 14, 15, 26], (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as <ref> [22, 23, 24] </ref>. Detecting the shared resource access time is a key difficulty in multiprocess analysis of real-time systems. The response time depends on the time of the call and the queue size of the resource during the call.
Reference: [23] <author> A. D. Stoyenko, T. J. Marlowe. </author> <title> Polynomial-Time Transformations and Schedulability Analysis of Parallel Real-Time Programs with Restricted Resource Contention. </title> <journal> Journal of Real-Time Systems, </journal> <volume> Vol 4, No. 4, </volume> <pages> pages 307 - 329, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: 14, 15, 26], (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as <ref> [22, 23, 24] </ref>. Detecting the shared resource access time is a key difficulty in multiprocess analysis of real-time systems. The response time depends on the time of the call and the queue size of the resource during the call. <p> The analysis needs to consider every combination of possible queue orders for requests from various processes, which makes the analysis exponential in the number of processes. Simplification techniques have been developed to perform that kind of analysis, either by restricting the resource access model <ref> [23] </ref>, or by assuming a smart scheduler [6], as illustrated in Section 4. Our approach uses the restricted resource contention model of [23] to predict the response time of resource requests. We rely on extracting the busy-idle profiles of shared resources during compilation. <p> Simplification techniques have been developed to perform that kind of analysis, either by restricting the resource access model <ref> [23] </ref>, or by assuming a smart scheduler [6], as illustrated in Section 4. Our approach uses the restricted resource contention model of [23] to predict the response time of resource requests. We rely on extracting the busy-idle profiles of shared resources during compilation. <p> We rely on extracting the busy-idle profiles of shared resources during compilation. Consulting the resource busy-idle profile before applying the code improving transformations, we can predict the effects of optimizing a process on other communicating processes. 3 Previous Work In addition to <ref> [6, 10, 23] </ref>, related work includes work in real-time optimization, and work on simplifying schedulability analysis. We consider two categories of transformations: (1) code transformations to improve overall performance or enhance schedulability of processes, (2) transformations to reduce the complexity of schedulability analysis. <p> Here, we use busy-idle profiles to check the effects of transformations on other processes. We try to speed up individual processes without affecting others, rather than simply informing the scheduler. A polynomial-time code transformation to simplify schedulability analysis of parallel real-time programs is presented in <ref> [23] </ref>, where a restricted form of shared resource contention of processes is assumed to simplify 4 the analysis. The effect of conditional branches on complexity can be reduced if by inserting fixed delays into one branch, it can be transformed into a timewise replica of the other, longer branch. <p> However, not all processes will make those requests at the same time. An accurate queue size can be calculated considering all (possibly exponential number) execution paths of the processes. Analysis, similar to [9] and transformations, like <ref> [23, 24] </ref>, can be applied to decrease the number of paths to be considered. Our approach to calculate shared resource access time requires the following two steps: 1. Extract for each process (as precisely as possible) its access profile with respect to every shared resource in the system. 2. <p> These points will be used by the second phase to correctly propagate delays towards the end of the process. We refer to this array as T est P oints. Delay points includes delays which have been introduced by other transformations, for example <ref> [23] </ref>. Resource request points contain the resource busy interval id. We extend the T est P oints list by replicating the points of the first period, a number of times equal to the number of instances of the process in LCM (LCM/period size). <p> program control flow graph is traversed and the array T est P oints of points of interest is generated, as discussed in Subsection 7.1. 19 Constructing Resources Access Profile: As discussed in Section 4, to build resources access profile for each process, first we have to apply the analysis of <ref> [23] </ref> to balance access to shared resources along branches of conditionals. Loops need to be unrolled (which may have been done in the previous step while calculating WCET) to calculate the call time to the shared resource.
Reference: [24] <author> A. D. Stoyenko, T. J. Marlowe, W. A. Halang, M. Younis. </author> <title> Enabling Efficient Schedulability Analysis through Conditional Linking and Program Transformations. </title> <journal> Control Engineering Practice, </journal> <volume> Vol 1, No. 1, </volume> <pages> pages 85 - 105, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: 14, 15, 26], (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as <ref> [22, 23, 24] </ref>. Detecting the shared resource access time is a key difficulty in multiprocess analysis of real-time systems. The response time depends on the time of the call and the queue size of the resource during the call. <p> The effect of conditional branches on complexity can be reduced if by inserting fixed delays into one branch, it can be transformed into a timewise replica of the other, longer branch. Linking of conditions has been added in <ref> [24] </ref> to enable additional transformation. 4 Calculating Resource Access Time As discussed in Section 2, a major difficulty in applying compiler optimization in multiprocess real-time systems is the prediction of effects on shared resource response time. <p> However, not all processes will make those requests at the same time. An accurate queue size can be calculated considering all (possibly exponential number) execution paths of the processes. Analysis, similar to [9] and transformations, like <ref> [23, 24] </ref>, can be applied to decrease the number of paths to be considered. Our approach to calculate shared resource access time requires the following two steps: 1. Extract for each process (as precisely as possible) its access profile with respect to every shared resource in the system. 2. <p> Generating Workloads: A program is a group of statements selected out of the following; IF, WHILE, ASSIGNMENT, CALL, BLOCKING CALL, READ, and WRITE. The frequency of each type of statement is controlled by a probability density function. Based on our experience with the code of real-time systems <ref> [24] </ref>, we assigned the probabilities in Figure 12 to each statement type. 18 IF LOOP ASSIGNMENT CALL BLOCKING CALL READ/WRITE 10% 10% 35% 20% 5% 20% Both READ and WRITE use buffers. Consequently they are considered non-blocking, although writes to a common location are ordered.
Reference: [25] <author> A. Stoyenko, T. Marlowe, M. Younis, </author> <title> A Language for Complex Real-Time Systems. </title> <journal> To appear in the Computer Journal, </journal> <volume> Vol. 38, No 5, </volume> <month> Nov </month> <year> 1995. </year>
Reference-contexts: Currently, we try to extend our resource model to allow for resource optimization. We also are studying how to integrate multiprocess optimization safely in real-time systems. In the future, we intend to integrate our algorithm in a platform, currently under development, for complex real-time systems <ref> [25] </ref>. We are planning to test the applicability of compiler optimization techniques in realistic applications, and to investigate how to apply machine-dependent optimization safely to distributed real-time systems. We will also study whether repeating our algorithm achieves additional gains in performance.
Reference: [26] <author> H. F. Wedde, B. Korel, D. M. Huizinga, </author> <title> Static analysis of timing properties for distributed real-time programs. </title> <booktitle> IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <month> May </month> <year> 1991, </year> <pages> 88-95. </pages>
Reference-contexts: As a result, schedulability analysis can either be (1) exact and efficient analysis of single process or multiple processes of simple form, or with highly constrained interactions <ref> [12, 14, 15, 26] </ref>, (2) highly imprecise though efficient analysis of multiple process programs [9], or (3) nearly exact though highly inefficient analysis of some multiple processes [19, 21]. 3 To combat some sources of combinatorial explosion, there has been work to reduce the cost of precise schedulability analysis, such as
Reference: [27] <author> M. Younis, T. Marlowe, A. Stoyenko, </author> <title> Compiler Transformations for Speculative Execution in a Real-Time System. </title> <booktitle> Proceedings of the 15th Real-Time Systems Symposium, </booktitle> <address> San Juan, Puerto Rico, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: The authors are indebted to the many constructive comments by members of the Real-Time Computing Lab., and to B. Ghahyazi for conducting the simulation. 1 into deadline-satisfying programs. New opportunities for parallelism can be detected, enhancing resource utilization and speeding up execution <ref> [27] </ref>. Moreover, optimization of hard real-time programs has benefits even for real-time programs which are running, and which can be proved to meet their timing constraints. For these programs, it is often preferable to reduce resource usage (time, space, or processors), especially in multiuser or multiprogramming environments. <p> Code motion is used in [5, 8] to re-organize the code of a sequential process to meet timing requirements. Forking new processes to speculatively execute blocks of the code without destroying timeliness of in case of rollback is discussed in <ref> [27] </ref>. Register remapping is introduced in [16] to provide fast context switch points for preemptive scheduling. Basically, they only consider single process transformations; none consider the effect of transformations in a multitask environment. <p> However, it may affect other resources' busy-idle profiles. The third form is multiprocessor optimization. Migration and speculative execution, remote calls, and moving code in/out of a call are examples of this category <ref> [3, 4, 27] </ref>. Multiprocess and multiprocessor optimizations can also be unsafe with respect to other processes, processors, and resources. We are concerned with the results of transformations/optimizations, and making them safe for a multiprocess real-time application.
Reference: [28] <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year> <month> 23 </month>
References-found: 28

