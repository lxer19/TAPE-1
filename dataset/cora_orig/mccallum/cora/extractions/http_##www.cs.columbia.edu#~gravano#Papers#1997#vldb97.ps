URL: http://www.cs.columbia.edu/~gravano/Papers/1997/vldb97.ps
Refering-URL: http://www.cs.columbia.edu/~gravano/publications.html
Root-URL: http://www.cs.columbia.edu
Email: gravano@cs.stanford.edu  hector@cs.stanford.edu  
Title: Merging Ranks from Heterogeneous Internet Sources  
Author: Luis Gravano Hector Garca-Molina 
Keyword: given condition.  
Note: This material is based upon work supported by the National Science Foundation under Cooperative Agreement IRI-9411306. Funding for this cooperative agreement is also provided by DARPA, NASA, and the industrial partners of the Stanford Digital Libraries Project. Any opinions, finding, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation or the other sponsors. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 23rd VLDB Conference Athens, Greece, 1997 is this condition necessary but it is also suf  
Address: Stanford, CA 94305-9040, USA  Stanford, CA 94305-9040, USA  
Affiliation: Computer Science Department Stanford University  Computer Science Department Stanford University  
Abstract: Many sources on the Internet and elsewhere rank the objects in query results according to how well these objects match the original query. For example, a real-estate agent might rank the available houses according to how well they match the user's preferred location and price. In this environment, "meta-brokers" usually query multiple autonomous, heterogeneous sources that might use varying result-ranking strategies. A crucial problem that a meta-broker then faces is extracting from the underlying sources the top objects for a user query according to the meta-broker's ranking function. This problem is challenging because these top objects might not be ranked high by the sources where they appear. In this paper we discuss strategies for solving this "meta-ranking" problem. In particular, we present a condition that a source must satisfy so that a meta-broker can extract the top objects for a query from the source without examining its entire contents. Not only ficient, and we show an algorithm to extract the top objects from sources that satisfy the
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gerard Salton. </author> <title> Automatic text processing: the transformation, analysis, and retrieval of information by computer. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Instead, query results are sorted starting from the top object for the query at hand. A typical example of this kind of sources is a source that indexes text documents and answers queries using some variation of the vector-space model of document retrieval <ref> [1] </ref>. Example 1: Consider a World-Wide Web search engine like Excite (http://www.excite.com). Given a query consisting of a series of words, like "distributed databases," Excite returns the matching documents sorted according to how well they match the query. <p> ; : : : ; A n for every object returned. (In Section 4 we discuss sources for which this property does not hold.) Property 1: Information in query results: The record for an object t in the query results returned by a source S contains all the values t <ref> [1] </ref>; : : :; t [n] for the attributes A 1 ; : : : ; A n that can be used to formulate queries over S.
Reference: [2] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, P. Yanker, and C. Faloutsos. </author> <title> The QBIC project: Querying images by content using color, texture, and shape. </title> <booktitle> In Storage and retrieval for image and video databases (SPIE), </booktitle> <pages> pages 173-187, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Although text sources are probably the best known example, sources with multimedia objects like images are also becoming common. Matches between query values and objects in such sources are inherently "fuzzy" <ref> [2] </ref>. Even sources with more "traditional" and structured data that rank their query results are appearing on the Internet. These sources rank the highest those objects that match the user's specification the best.
Reference: [3] <author> Ronald Fagin. </author> <title> Combining fuzzy information from multiple systems. </title> <booktitle> In 15 th ACM Symposium on Principles of Database Systems, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: Some of the v i values might be don't care values (noted "*"). The rest of the v i values are the significant values in the query. Given a query, source S responds with the objects (i.e., tuples) of R S that "best match" the query values <ref> [3] </ref>. <p> These objects might have attributes like images and text. Thus, the matches between query values and such multimedia attributes are inherently fuzzy, and the objects are ranked according to how well they match the query values. The work in <ref> [3] </ref> and [4] studies how to query such repositories efficiently. In particular, [3] studies upper and lower bounds on the number of objects that we need to extract from a repository so that the overall top objects are retrieved and returned to the user that issued a query. [4] addresses the <p> Thus, the matches between query values and such multimedia attributes are inherently fuzzy, and the objects are ranked according to how well they match the query values. The work in <ref> [3] </ref> and [4] studies how to query such repositories efficiently. In particular, [3] studies upper and lower bounds on the number of objects that we need to extract from a repository so that the overall top objects are retrieved and returned to the user that issued a query. [4] addresses the cost-based optimization of queries over such repositories. <p> An interesting open issue is then the optimization of queries over multiple sources, perhaps using statistics on the sources' contents to obtain small * i and large g i values, for example. A promising direction is to adapt the work in <ref> [3] </ref> and [4] to our distributed, heterogeneous scenario. Another interesting issue is how to deal with sources that do not satisfy the properties and assumptions that our results need.
Reference: [4] <author> Surajit Chaudhuri and Luis Gravano. </author> <title> Optimizing queries over multimedia repositories. </title> <booktitle> In Proceedings of the 1996 ACM SIGMOD Conference, </booktitle> <year> 1996. </year>
Reference-contexts: This way, we will be able to work with sources at which a given query is not manageable (Example 7), or that would otherwise require potentially inefficient executions (Example 5). 2 The notion of cover is related to that of a complete set of atomic conditions in <ref> [4] </ref>. (See Section 6.) Example 8: Let Q 1 be the single-attribute query for Q and the Location attribute, and Q 2 be the single-attribute query for Q and the Price attribute. Consider the Target and Source scores of Example 5. <p> refer to as Top, extracts the top Target objects for Q from S 3 . 3 Algorithm Top reduces the problem of finding the top Target objects for Q in S to the problem of finding all objects t in S with Target (Q; t) &gt; G, for some G. <ref> [4] </ref> uses a similar strategy for processing queries over a multimedia repository. Example 10 : Consider the real-estate agent and the scenario of Example 5. Then, Algorithm Top can choose fQ 1 ; Q 2 g as the cover for query Q (Step (1)). <p> These objects might have attributes like images and text. Thus, the matches between query values and such multimedia attributes are inherently fuzzy, and the objects are ranked according to how well they match the query values. The work in [3] and <ref> [4] </ref> studies how to query such repositories efficiently. In particular, [3] studies upper and lower bounds on the number of objects that we need to extract from a repository so that the overall top objects are retrieved and returned to the user that issued a query. [4] addresses the cost-based optimization <p> work in [3] and <ref> [4] </ref> studies how to query such repositories efficiently. In particular, [3] studies upper and lower bounds on the number of objects that we need to extract from a repository so that the overall top objects are retrieved and returned to the user that issued a query. [4] addresses the cost-based optimization of queries over such repositories. This work assumes that a single repository handles all attributes of an object. Therefore, there is no need to "calibrate" the scores that an object gets for a particular attribute, for example. <p> An interesting open issue is then the optimization of queries over multiple sources, perhaps using statistics on the sources' contents to obtain small * i and large g i values, for example. A promising direction is to adapt the work in [3] and <ref> [4] </ref> to our distributed, heterogeneous scenario. Another interesting issue is how to deal with sources that do not satisfy the properties and assumptions that our results need.
Reference: [5] <author> Luis Gravano and Hector Garca-Molina. </author> <title> Merging ranks from heterogeneous Internet sources. </title> <type> Technical Report SIDL-WP-1997-0063, </type> <institution> Stanford University, </institution> <month> February </month> <year> 1997. </year> <note> Accessible as http://www-diglib.- stanford.edu/cgi-bin/WP/get/SIDL-WP-1997-0063. </note>
Reference-contexts: Theorem 1: Let Q be a query and S a source that is tractable for Q. Then, Algorithm Top extracts the top Target objects for Q from S. <ref> [5] </ref> Consider a source S that is tractable for a query Q. We cannot guarantee that Algorithm Top never extracts all the objects in S. <p> Then, there exist instances of S where Algorithm Top finds the top Target objects for Q before extracting all of the objects in S. <ref> [5] </ref> Theorem 2 shows that source tractability, together with the assumption in the theorem that 8i, g i * i &gt; 0, form a sufficient condition for being able to sometimes extract a top Target object from a source without accessing all of its objects. <p> Lemma 1 : Let Q be a query and S a source for which 90 &lt; x y &lt; 1 such that 8 object t, either Source (Q; t) &gt; x or Target (Q; t) &lt; y. Then, Q is manageable at source S. <ref> [5] </ref> We are now ready for our main result. Consider a partial retrieval for a query Q and a source S that is not tractable for Q and that has no objects with a Target score of 1. <p> Then, we can still build an object l as in Theorem 3 for any partial retrieval for Q and S using C. <ref> [5] </ref> Note that the main results of this section only cover algorithms that work via multiple single-attribute queries.
Reference: [6] <author> Ellen M. Voorhees, Narendra K. Gupta, and Ben Johnson-Laird. </author> <title> The collection fusion problem. </title> <booktitle> In Proceedings of the 3 rd Text Retrieval Conference (TREC-3), </booktitle> <year> 1995. </year>
Reference-contexts: As with our problem, key decisions include how far "down" each document rank to explore, and how to translate Source scores (local similarity measures) into Target scores (usually global similarity measures). An approach to address these problems is to learn from the results of training queries <ref> [6] </ref>. Another approach is to calibrate the document scores from each collection using statistics about the word distribution in the collections [7].
Reference: [7] <author> James P. Callan, Zhihong Lu, and W. Bruce Croft. </author> <title> Searching distributed collections with inference networks. </title> <booktitle> In Proceedings of the 18 th Annual SIGIR Conference, </booktitle> <year> 1995. </year>
Reference-contexts: An approach to address these problems is to learn from the results of training queries [6]. Another approach is to calibrate the document scores from each collection using statistics about the word distribution in the collections <ref> [7] </ref>. One important difference between this line of work and ours is that we want to guarantee that meta-brokers extract the top Target objects from the sources and return these objects ordered according to their Target scores.
Reference: [8] <author> Luis Gravano, Chen-Chuan K. Chang, Hector Garca-Molina, and Andreas Paepcke. </author> <title> STARTS: Stanford proposal for Internet meta-searching. </title> <booktitle> In Proceedings of the 1997 ACM SIGMOD Conference, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: In effect, these results do not include entire documents, and have very little information other than the Source scores. To address this problem, the STARTS protocol proposal <ref> [8] </ref> developed at Stan-ford specifies what information should accompany the query results that a text search engine returns so that document rank merging is facilitated. A closely related problem is how to query a repository of complex, multimedia objects. These objects might have attributes like images and text.
Reference: [9] <author> J.-C. Franchitti and R. King. Amalgame: </author> <title> a tool for creating interoperating persistent, heterogeneous components. </title> <booktitle> In Advanced Database Systems, </booktitle> <pages> pages 313-36. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: In this paper, we assume that all sources export a uniform interface so they can all answer queries over the same set of attributes. We can use the techniques in <ref> [9, 10] </ref>, for example, to build wrappers around the sources and provide the illusion of such a uniform interface. 7 Conclusion Many sources rank the objects in query results according to how well these objects match the original query.
Reference: [10] <author> Yannis Papakonstantinou, Hector Garcia-Molina, Ashish Gupta, and Jeffrey Ullman. </author> <title> A query translation scheme for rapid implementation of wrappers. </title> <booktitle> In Fourth International Conference on Deductive and Object-Oriented Databases, </booktitle> <pages> pages 161-186, </pages> <institution> National University of Singapore(NUS), Singapore, </institution> <year> 1995. </year>
Reference-contexts: In this paper, we assume that all sources export a uniform interface so they can all answer queries over the same set of attributes. We can use the techniques in <ref> [9, 10] </ref>, for example, to build wrappers around the sources and provide the illusion of such a uniform interface. 7 Conclusion Many sources rank the objects in query results according to how well these objects match the original query.
References-found: 10

