URL: ftp://ftp.gmd.de/ml-archive/GMD/papers/ML42.ps
Refering-URL: http://nathan.gmd.de/projects/ml/lit/mlpublist.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: kietz@gmdzi.gmd.de, wrobel@gmdzi.gmd.de  
Title: Controlling the Complexity of Learning in Logic through Syntactic and Task-Oriented Models  
Author: Jorg-Uwe Kietz, Stefan Wrobel 
Address: Pf. 1240, W-5205 St. Augustin 1, Germany  
Affiliation: GMD (German Natl. Research Center for Comp. Science) Institute for Applied Information Technology  
Abstract: Due to the inadequacy of attribute-only representations for many learning problems, there is now a renewed interest in algorithms employing first-order logic or restricted variants thereof as their knowledge representation. In this paper, we give a brief overview of the dimensions along which the complexity of learning in such representations can be controlled. We then present RDT, a model-based learning algorithm for function-free Horn clauses with negation that introduces two new means of complexity control, namely the use of syntactic rule models, and the use of a task-oriented domain topology. We briefly describe some preliminary application results of RDT within the knowledge acquisition system MOBAL, and present directions of further research.
Abstract-found: 1
Intro-found: 1
Reference: [BFOS84] <author> L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. </author> <title> Classifikation and regression trees. Belmont, </title> <publisher> Wadsworth, </publisher> <year> 1984. </year>
Reference-contexts: For the computed predicate "eq" (and for constants in non-computed predicates), all possible remaining instantiations of the variable must be tried; for comparison predicates on ordered values like "ge" (greater than or equal) etc., special techniques such as the ones described in <ref> [BFOS84] </ref> for attribute-value systems will be useful. To make the process of looking for constants maximally efficient, it needs to be properly integrated into RDT's incremental process of instantiating and testing partial rule schemata.
Reference: [BS85] <author> Ronald J. Brachman and J. G. Schmolze. </author> <title> An overview of the KL-ONE knowledge representation system. </title> <journal> Cognitive Science, </journal> <volume> 9, </volume> <year> 1985. </year>
Reference-contexts: The topology nodes thus provide a means of subdividing a domain into regions with different purposes, and the links allow the user to restrict the hypotheses that 9 This can be compared to a requirement on "functional" knowledge representations that originated in the KL-ONE school <ref> [BS85] </ref>: that the set of inferences provided be easily recognizable by a user. 8 will be examined by the system to those that are interesting in the specific task context. Furthermore, the direction of the links can be used to reflect the desired direction of inference in the domain.
Reference: [Bun88] <author> Wray Buntine. </author> <title> Generalized subsumption and its applications to induction and redundancy. </title> <journal> Artificial Intelligence, </journal> <volume> 36:149 - 176, </volume> <year> 1988. </year>
Reference-contexts: LPF2 [Wir89], also based on inverse resolution, is not restricted to unit-clauses, but uses restrictions on the inverse substitutions that may be assumed. Restricted background knowledge In Horn clause logic, the generalization relationship between two clauses is easy to handle without background knowledge <ref> [Bun88] </ref>. Thus, the form of allowed background knowledge has an important influence on the complexity of the learning task. One often used restriction is the use of background knowledge only in the form of ground unit clauses (facts).
Reference: [CGT90] <author> S. Ceri, G. Gottlob, and L. Tanca. </author> <title> Logic Programming and Databases. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, New York, </address> <year> 1990. </year> <month> 20 </month>
Reference-contexts: Instead, most research concentrates on Horn clause logic (pure Prolog) and subclasses thereof, in particular the subclass of function-free Horn clause programs (Datalog programs, <ref> [CGT90] </ref>) in which the generalization relationship is decidable. This choice of representation was made eg. in ARCH [Win75], INDUCE [Mic83], MARVIN [SB86], CLINT [DB89], and FOIL [Qui90].
Reference: [DB89] <author> L. DeRaedt and M. Bruynooghe. </author> <title> Towards friendly concept-learners. </title> <booktitle> In Proc. of the 11th Int. Joint Conf. on Artif. Intelligence, </booktitle> <pages> pages 849 - 854, </pages> <address> Los Altos, CA, 1989. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Instead, most research concentrates on Horn clause logic (pure Prolog) and subclasses thereof, in particular the subclass of function-free Horn clause programs (Datalog programs, [CGT90]) in which the generalization relationship is decidable. This choice of representation was made eg. in ARCH [Win75], INDUCE [Mic83], MARVIN [SB86], CLINT <ref> [DB89] </ref>, and FOIL [Qui90]. MIS [Sha83], even though operational in full Horn clause logic, suffered from complexity problems that prevented it from learning certain concepts even though they were in its hypothesis space [Mug90]. <p> This can be done either by explicitly defining language subsets through restrictions on the form of hypotheses, or by using generalization/specialization operators that produce only selected members of the hypothesis space. For example, DeRaedt's CLINT <ref> [DB89] </ref> uses a series of languages that are defined by allowing increasingly more existential variables (variables not found in the head of the clause), and increasingly more relations between those variables.
Reference: [dRB89] <author> Luc de Raedt and Maurice Bruynooghe. </author> <title> Constructive induction by analogy: a method to learn how to learn? In Proc. </title> <booktitle> Fourth European Working Session on Learning (EWSL), </booktitle> <pages> pages 189 - 199, </pages> <address> London/Los Altos, CA, 1989. </address> <publisher> Pitman/Morgan Kaufman. </publisher>
Reference-contexts: In section 6, we discuss ways of extending R automatically through the use of rule schema modification operators. The approach presented here originated in Emde's METAXA system [Emd87] and was also used in the BLIP system [Wro88]. DeRaedt and Bruynooghe <ref> [dRB89] </ref> have examined the use of rule schemata as defined here to propose new concept definitions by analogy (the CIA/CLINT technique). 3.4 The topology Almost all learning approaches cope with the complexity of learning in logic by defining various syntactic restrictions on their hypothesis space or learning operators.
Reference: [EKK + 89] <author> Werner Emde, Ingo Keller, Jorg-Uwe Kietz, Katharina Morik, Sabine Thieme, and Stefan Wrobel. </author> <title> Abschlussbericht des BMFT-Projektes 3 b LERNER. </title> <address> KIT-Report 71, Technische Universitat Berlin, D-1000 Berlin, West Germany, </address> <month> April </month> <year> 1989. </year> <note> (English book version in preparation). </note>
Reference-contexts: In this section, we want to briefly describe the use of RDT within the knowledge acquisition system MOBAL [Wro89], a successor of BLIP <ref> [EKK + 89] </ref>. MOBAL is a system that integrates manual knowledge acquisition and machine learning according to the so-called sloppy modeling paradigm [Mor89, Mor90]. MOBAL provides a comfortable and graphical interface for the entry and manipulation of facts, rules, rule models, and topology (among others).
Reference: [Emd87] <author> Werner Emde. </author> <booktitle> Non-cumulative learning in METAXA.3. In IJCAI-87, </booktitle> <address> Los Altos, CA, August 1987. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: In section 6, we discuss ways of extending R automatically through the use of rule schema modification operators. The approach presented here originated in Emde's METAXA system <ref> [Emd87] </ref> and was also used in the BLIP system [Wro88].
Reference: [Emd89a] <author> Werner Emde. </author> <title> An inference engine for representing multiple theories. </title> <editor> In Katharina Morik, editor, </editor> <booktitle> Knowledge Representation and Organization in Machine Learning, </booktitle> <pages> pages 148-176. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, New York, </address> <year> 1989. </year> <note> auch: KIT-Report Nr. 64, </note> <institution> TU Berlin, </institution> <year> 1988. </year>
Reference-contexts: Now, we will present the means by which the subspace 6 This task is performed by IM2 <ref> [Emd89a] </ref>, the inference engine of the MOBAL system. 7 Or the negation thereof, see section 5. 6 that will actually be searched is defined. The first such means, rule models, is of a syntactical nature.
Reference: [Emd89b] <editor> Werner Emde. Lernen im geschlossenen Kreislauf. In W. Brauer, editor, </editor> <booktitle> 3. Internationaler GI-KongreWissensbasierte Systeme (SYSTEMS), In-formatik Fachberichte, </booktitle> <address> Berlin, New York, 1989. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: The rules are not required to cover all instances of the target concept, and they may overlap (see section 4). All learned rules are entered into the knowledge base, and thus become background knowledge for further learning (closed-loop learning <ref> [Emd89b] </ref>). 3.3 Rule models In the preceding section, we have defined RDT's base representation that defines its maximal space of hypotheses.
Reference: [Fen90] <author> Cao Feng. </author> <title> Application of CIGOL for fault diagnosis for the power subsystem of Skynet satellite. MLT Technical Note, </title> <booktitle> The Turing Institute, </booktitle> <address> Glasgow, Scotland, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: We have also begun work on the diagnosis of time-dependent fault states in satellites, a domain on which CIGOL has already been tried <ref> [Fen90] </ref>. 6 Future Research At present, the version RDT described here is being implemented and integrated into the MOBAL system.
Reference: [Kie88] <author> Jorg-Uwe Kietz. </author> <title> Incremental and reversible acquisition of taxonomies. </title> <booktitle> Proceedings of EKAW-88, </booktitle> <pages> pages 24.1-24.11, </pages> <year> 1988. </year> <note> Also as KIT-Report 66, Technical University Berlin. </note>
Reference-contexts: The search is along the generality hierarchy with pruning of specializations of accepted and failed hypotheses. Acceptance and failure are decided with a user-settable acceptance criterion. Further effectiveness comes from the use of a many sorted logic. The sort taxonomy tool STT <ref> [Kie88] </ref> automatically builds up a lattice of sorts. Thus, the user does not need to define the sorts | instead, the sort lattice is created by the system based on the input facts.
Reference: [Kli91] <author> Volker Klingspor. </author> <title> Abstraktion von Inferenzstrukturen in MOBAL. </title> <type> Master's thesis, </type> <institution> Univ. Bonn, </institution> <year> 1991. </year> <note> In German. To appear. </note>
Reference-contexts: Topology construction Currently under work is a tool for the automatic construction of the topology <ref> [Kli91] </ref>. The automatically constructed topology is an abstraction of the rules in the knowledge base, i.e. it is built from user given and previously learned rules.
Reference: [Llo87] <author> J.W. Lloyd. </author> <title> Foundations of Logic Programming. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, New York, 2nd edition, </address> <year> 1987. </year>
Reference-contexts: Following the terminology from <ref> [Llo87] </ref>, we can define this representation more precisely as follows 5 . A predicate is denoted by a predicate symbol (usually p, q, r . . . ) and has a fixed arity a.
Reference: [MB88] <author> Stephen Muggleton and Wray Buntine. </author> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> In Proc. Fifth Intern. Conf. on Machine Learning, </booktitle> <address> Los Altos, CA, 1988. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Both of those restrictions are ways of defining subspaces of the general Horn clause hypothesis space. The alternative way, i.e., using restricted operators, has been used eg. in the CIGOL system <ref> [MB88] </ref>. This system uses inverse resolution generalization operators (absorption and identification) that are in principle capable of producing any Horn clause expression, but are restricted to unit clauses to reduce their complexity. Rouveirol and Puget [RP89] discuss the difficulties involved in removing this restriction for their IRES system. <p> Such an approach has been used in the AQ/INDUCE program [Mic83], a bottom-up (generalizing) learner where a user-settable criterion (LEF) was used to determine which generalizations to keep in the focus of the system's beam search. The CIGOL system <ref> [MB88] </ref>, also a bottom-up learner, uses information compression as a measure to judge promising or less promising generalizations. In FOIL [Qui90], a top-down (specializing) learner, the information gain measure popular from ID3 is used to judge whether the addition of a literal improves the current hypothesis.
Reference: [MF90] <author> Stephen Muggleton and Cao Feng. </author> <title> Efficient induction of logic programs. </title> <booktitle> In Proc. First Conf. on Algorithmic Learning Theory, </booktitle> <address> Tokyo, 1990. </address> <publisher> Ohmsha Publishers. </publisher> <pages> 21 </pages>
Reference-contexts: For example, DeRaedt's CLINT [DB89] uses a series of languages that are defined by allowing increasingly more existential variables (variables not found in the head of the clause), and increasingly more relations between those variables. In GOLEM <ref> [MF90] </ref>, the related notion of ij-determinacy is used that limits the indeterminate introduction of new variables in the body of a clause. Both of those restrictions are ways of defining subspaces of the general Horn clause hypothesis space. <p> One often used restriction is the use of background knowledge only in the form of ground unit clauses (facts). In MARVIN [SB86], this is done by forward applying the available inference rules to generate additional facts about an example ("elaboration" of the example). In GOLEM <ref> [MF90] </ref>, a program based on an extension of Plotkin's relative least general generalization (RLLG) approach, the background knowledge is required to be "generative", which again means that all derived unit clauses will be ground. 3 Search control Besides using the generalization relation to prune its search (which is guaranteed not to <p> Here, the system would derive only married (john,vivian) To ensure that these facts are ground, only those rules are used for inferencing where all conclusion variables occur in the premises also ("generative" rules in the terminology of <ref> [MF90] </ref>) . A depth-limit is used to keep the expense of this forward inferencing process under control. Within the depth limit, the system effectively generates a ground model of its background knowledge. <p> A depth-limit is used to keep the expense of this forward inferencing process under control. Within the depth limit, the system effectively generates a ground model of its background knowledge. This is a technique that is also used in MARVIN [SB86] (the "elaboration" of the examples), and in GOLEM <ref> [MF90] </ref> (the generation of h-easy ground Herbrand models for generalization).
Reference: [Mic83] <author> Ryszard S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <booktitle> In Machine Learning | An Artificial Intelligence Approach, </booktitle> <pages> pages 83 - 134. </pages> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, CA, </address> <year> 1983. </year>
Reference-contexts: Instead, most research concentrates on Horn clause logic (pure Prolog) and subclasses thereof, in particular the subclass of function-free Horn clause programs (Datalog programs, [CGT90]) in which the generalization relationship is decidable. This choice of representation was made eg. in ARCH [Win75], INDUCE <ref> [Mic83] </ref>, MARVIN [SB86], CLINT [DB89], and FOIL [Qui90]. MIS [Sha83], even though operational in full Horn clause logic, suffered from complexity problems that prevented it from learning certain concepts even though they were in its hypothesis space [Mug90]. <p> Such an approach has been used in the AQ/INDUCE program <ref> [Mic83] </ref>, a bottom-up (generalizing) learner where a user-settable criterion (LEF) was used to determine which generalizations to keep in the focus of the system's beam search. The CIGOL system [MB88], also a bottom-up learner, uses information compression as a measure to judge promising or less promising generalizations.
Reference: [Mit82] <author> Tom M. Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18(2):203 - 226, </volume> <year> 1982. </year>
Reference-contexts: 1 Introduction As described by Mitchell <ref> [Mit82] </ref>, concept learning from examples can be seen as a process of search in a space of hypotheses that is ordered by the generality relationship between hypotheses.
Reference: [Mor89] <author> Katharina Morik. </author> <title> Sloppy modeling. </title> <editor> In Katharina Morik, editor, </editor> <booktitle> Knowledge Representation and Organization in Machine Learning, </booktitle> <pages> pages 107-134. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, New York, </address> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: In this section, we want to briefly describe the use of RDT within the knowledge acquisition system MOBAL [Wro89], a successor of BLIP [EKK + 89]. MOBAL is a system that integrates manual knowledge acquisition and machine learning according to the so-called sloppy modeling paradigm <ref> [Mor89, Mor90] </ref>. MOBAL provides a comfortable and graphical interface for the entry and manipulation of facts, rules, rule models, and topology (among others).
Reference: [Mor90] <author> Katharina Morik. </author> <title> Integrating manual and automatic knowledge aquisi-tion BLIP. </title> <editor> In Karen L. McGraw and Christopher R. Westphal, editors, </editor> <booktitle> Readings in Knowledge Acquisition Current Practices and Trends, chapter 14, </booktitle> <pages> pages 213 - 232. </pages> <publisher> Ellis Horwood, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Any learning program is used to achieve a specific goal, its output is to subserve a specific task. Thus, task-oriented restrictions on the hypothesis space can tap into an important source of efficiency. In RDT, we implemented such a task-oriented restriction in form of a predicate topology <ref> [Mor90] </ref>. A predicate topology consists of a grouping T = fT 1 ; . . . ; T m g of the predicates P into possibly non-disjoint sets T i , the so-called topology nodes, each of which is labelled with a mnemonic name by the user. <p> In this section, we want to briefly describe the use of RDT within the knowledge acquisition system MOBAL [Wro89], a successor of BLIP [EKK + 89]. MOBAL is a system that integrates manual knowledge acquisition and machine learning according to the so-called sloppy modeling paradigm <ref> [Mor89, Mor90] </ref>. MOBAL provides a comfortable and graphical interface for the entry and manipulation of facts, rules, rule models, and topology (among others).
Reference: [Mug90] <author> Stephen Muggleton. </author> <title> Inductive logic programming. </title> <booktitle> In Proc. First Conf. on Algorithmic Learning Theory, </booktitle> <address> Tokyo, 1990. </address> <publisher> Ohmsha Publishers. </publisher>
Reference-contexts: [Qui90] for a detailed discussion of the limits of attribute-only representations. 2 We are ignoring the use of oracles, which is also a common approach. 3 RDT stands for Rule Discovery Tool. 2 least general generalization (RLLG) method [Plo70], which uses definite clauses, but was severely limited in its implementation <ref> [Mug90] </ref>. Instead, most research concentrates on Horn clause logic (pure Prolog) and subclasses thereof, in particular the subclass of function-free Horn clause programs (Datalog programs, [CGT90]) in which the generalization relationship is decidable. <p> This choice of representation was made eg. in ARCH [Win75], INDUCE [Mic83], MARVIN [SB86], CLINT [DB89], and FOIL [Qui90]. MIS [Sha83], even though operational in full Horn clause logic, suffered from complexity problems that prevented it from learning certain concepts even though they were in its hypothesis space <ref> [Mug90] </ref>. Other programs that use full Horn clauses as their basic hypothesis space typically use other restrictions to reduce the size of the space (eg. CIGOL, IRES, LFP2, or GOLEM, see below).
Reference: [Plo70] <author> Gordon D. Plotkin. </author> <title> A note on inductive generalization. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 5, chapter 8, </booktitle> <pages> pages 153 - 163. </pages> <publisher> Edinburgh Univ. Press, Edinburgh, </publisher> <year> 1970. </year>
Reference-contexts: not used by any existing learning algorithm except Plotkin's relative 1 See [Qui90] for a detailed discussion of the limits of attribute-only representations. 2 We are ignoring the use of oracles, which is also a common approach. 3 RDT stands for Rule Discovery Tool. 2 least general generalization (RLLG) method <ref> [Plo70] </ref>, which uses definite clauses, but was severely limited in its implementation [Mug90]. Instead, most research concentrates on Horn clause logic (pure Prolog) and subclasses thereof, in particular the subclass of function-free Horn clause programs (Datalog programs, [CGT90]) in which the generalization relationship is decidable. <p> This means we do not have a specialization operator as e.g. MIS [Sha83] or FOIL [Qui90] that incrementally builds the hypothesis space to be searched. Instead MOBAL's model knowledge can be partially ordered by an extended form of -subsumption <ref> [Plo70] </ref> defined below. The proposed algorithm searches this partial ordering from the most general to the more specific hypotheses. A breadth first search strategy is used to avoid testing hypotheses that are later subsumed by more general ones (this could happen if one were to use depth first search). <p> This generality relation is trivial to compute if the available background knowledge is not taken into account. If we take for a moment the P i as predicates and not as predicate variables then we could use -subsumption from <ref> [Plo70] </ref>, i.e., a hypothesis H -subsumes a hypothesis H 0 (in clausal form), H H 0 , iff there is a substitution such that H H 0 . But because the P i are predicate variables, the situation is a little bit more complicated.
Reference: [Qui83] <author> J. Ross Quinlan. </author> <title> Learning efficient classification procedures and their application to chess end games. In R.S. </title> <editor> Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning | An Artificial Intelligence Approach, </booktitle> <pages> pages 463 - 482. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA, </address> <year> 1983. </year>
Reference-contexts: For attribute-based (propositional, feature-vector) formalisms, the space of hypotheses is finite, and there are only a few generalizations/specializations of any given hypothesis. As a result, it has been possible to construct very efficient learning programs for attribute-only languages, such as ID3 <ref> [Qui83] </ref> and its successors. In many practical applications, however, attribute-based representations are insufficient. This includes domains where structural properties or time-dependent 1 relationships need to be expressed, as in medical diagnosis [Wro90] 1 .
Reference: [Qui90] <author> J.R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3):239 - 266, </volume> <year> 1990. </year>
Reference-contexts: To our knowledge, full FOL is not used by any existing learning algorithm except Plotkin's relative 1 See <ref> [Qui90] </ref> for a detailed discussion of the limits of attribute-only representations. 2 We are ignoring the use of oracles, which is also a common approach. 3 RDT stands for Rule Discovery Tool. 2 least general generalization (RLLG) method [Plo70], which uses definite clauses, but was severely limited in its implementation [Mug90]. <p> This choice of representation was made eg. in ARCH [Win75], INDUCE [Mic83], MARVIN [SB86], CLINT [DB89], and FOIL <ref> [Qui90] </ref>. MIS [Sha83], even though operational in full Horn clause logic, suffered from complexity problems that prevented it from learning certain concepts even though they were in its hypothesis space [Mug90]. <p> The CIGOL system [MB88], also a bottom-up learner, uses information compression as a measure to judge promising or less promising generalizations. In FOIL <ref> [Qui90] </ref>, a top-down (specializing) learner, the information gain measure popular from ID3 is used to judge whether the addition of a literal improves the current hypothesis. <p> All facts are required to be ground, i.e., contain no variables. * If n 1, such a clause is called a rule. In contrast to Prolog and eg. FOIL <ref> [Qui90] </ref>, negative literals as premises of a rule are not treated as negation by failure, but as proper negation, i.e., negative premises require explicitly negated facts in the knowledge base to be satisfied. <p> This way of defining a hypothesis subspace can be contrasted with the use of specialization operators as in MIS [Sha83], or FOIL <ref> [Qui90] </ref>. Even though R is simply an unordered list of rule schemas, a generalization relation on R can be defined by suitably extending the standard clause subsumption relation. <p> This means we do not have a specialization operator as e.g. MIS [Sha83] or FOIL <ref> [Qui90] </ref> that incrementally builds the hypothesis space to be searched. Instead MOBAL's model knowledge can be partially ordered by an extended form of -subsumption [Plo70] defined below. The proposed algorithm searches this partial ordering from the most general to the more specific hypotheses.
Reference: [RP89] <author> Celine Rouveirol and Jean Fran~cois Puget. </author> <title> Beyond inversion of resolution. </title> <booktitle> In Proc. Sixth Intern. Workshop on Machine Learning, </booktitle> <pages> pages 122 - 130, </pages> <address> Los Altos, CA, 1989. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: This system uses inverse resolution generalization operators (absorption and identification) that are in principle capable of producing any Horn clause expression, but are restricted to unit clauses to reduce their complexity. Rouveirol and Puget <ref> [RP89] </ref> discuss the difficulties involved in removing this restriction for their IRES system. LPF2 [Wir89], also based on inverse resolution, is not restricted to unit-clauses, but uses restrictions on the inverse substitutions that may be assumed.
Reference: [SB86] <author> Claude Sammut and Ranan B. Banerji. </author> <title> Learning concepts by asking questions. In R.S. </title> <editor> Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning | An Artificial Intelligence Approach, volume II, chapter 7, </booktitle> <pages> pages 167 - 191. </pages> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: Instead, most research concentrates on Horn clause logic (pure Prolog) and subclasses thereof, in particular the subclass of function-free Horn clause programs (Datalog programs, [CGT90]) in which the generalization relationship is decidable. This choice of representation was made eg. in ARCH [Win75], INDUCE [Mic83], MARVIN <ref> [SB86] </ref>, CLINT [DB89], and FOIL [Qui90]. MIS [Sha83], even though operational in full Horn clause logic, suffered from complexity problems that prevented it from learning certain concepts even though they were in its hypothesis space [Mug90]. <p> Thus, the form of allowed background knowledge has an important influence on the complexity of the learning task. One often used restriction is the use of background knowledge only in the form of ground unit clauses (facts). In MARVIN <ref> [SB86] </ref>, this is done by forward applying the available inference rules to generate additional facts about an example ("elaboration" of the example). <p> A depth-limit is used to keep the expense of this forward inferencing process under control. Within the depth limit, the system effectively generates a ground model of its background knowledge. This is a technique that is also used in MARVIN <ref> [SB86] </ref> (the "elaboration" of the examples), and in GOLEM [MF90] (the generation of h-easy ground Herbrand models for generalization).
Reference: [SG87] <author> Devika Subramanian and Michael Genesereth. </author> <title> The relevance of irrelevance. </title> <booktitle> In Proc. 10th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 416 - 422, </pages> <address> Los Altos, CA, 1987. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: RDT can be used without a topology as well; in this case, H is the relevant hypothesis space. Our topology approach is similar in spirit to approaches that allow the specification of irrelevance relationships, such as the one discussed by Subramanian and Genesereth <ref> [SG87] </ref>.
Reference: [Sha83] <author> Ehud Y. Shapiro. </author> <title> Algorithmic Program Debugging. </title> <publisher> ACM Distinguished Doctoral Dissertations. The MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1983. </year> <month> 22 </month>
Reference-contexts: This choice of representation was made eg. in ARCH [Win75], INDUCE [Mic83], MARVIN [SB86], CLINT [DB89], and FOIL [Qui90]. MIS <ref> [Sha83] </ref>, even though operational in full Horn clause logic, suffered from complexity problems that prevented it from learning certain concepts even though they were in its hypothesis space [Mug90]. <p> This way of defining a hypothesis subspace can be contrasted with the use of specialization operators as in MIS <ref> [Sha83] </ref>, or FOIL [Qui90]. Even though R is simply an unordered list of rule schemas, a generalization relation on R can be defined by suitably extending the standard clause subsumption relation. <p> Finally, we present a pseudocode summary of the algorithm. 4.1 Exploiting the generality structure of the rule models Since RDT is a model-driven algorithm, the hypothesis space is defined by the set of rule models. This means we do not have a specialization operator as e.g. MIS <ref> [Sha83] </ref> or FOIL [Qui90] that incrementally builds the hypothesis space to be searched. Instead MOBAL's model knowledge can be partially ordered by an extended form of -subsumption [Plo70] defined below. The proposed algorithm searches this partial ordering from the most general to the more specific hypotheses.
Reference: [Win75] <author> P. H. Winston. </author> <title> Learning structural descriptions from examples. </title> <editor> In P.H. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Instead, most research concentrates on Horn clause logic (pure Prolog) and subclasses thereof, in particular the subclass of function-free Horn clause programs (Datalog programs, [CGT90]) in which the generalization relationship is decidable. This choice of representation was made eg. in ARCH <ref> [Win75] </ref>, INDUCE [Mic83], MARVIN [SB86], CLINT [DB89], and FOIL [Qui90]. MIS [Sha83], even though operational in full Horn clause logic, suffered from complexity problems that prevented it from learning certain concepts even though they were in its hypothesis space [Mug90].
Reference: [Wir89] <author> Ruediger Wirth. </author> <title> Completing logic programs by inverse resolution. </title> <editor> In Katharina Morik, editor, </editor> <booktitle> Proc. Fourth European Working Session on Learning (EWSL), </booktitle> <pages> pages 239 - 250, </pages> <address> London/San Mateo, CA, 1989. </address> <publisher> Pitman/Morgan Kaufmann. </publisher>
Reference-contexts: This system uses inverse resolution generalization operators (absorption and identification) that are in principle capable of producing any Horn clause expression, but are restricted to unit clauses to reduce their complexity. Rouveirol and Puget [RP89] discuss the difficulties involved in removing this restriction for their IRES system. LPF2 <ref> [Wir89] </ref>, also based on inverse resolution, is not restricted to unit-clauses, but uses restrictions on the inverse substitutions that may be assumed. Restricted background knowledge In Horn clause logic, the generalization relationship between two clauses is easy to handle without background knowledge [Bun88].
Reference: [Wro88] <author> Stefan Wrobel. </author> <title> Automatic representation adjustment in an observational discovery system. </title> <editor> In D. Sleeman, editor, </editor> <booktitle> Proc. of the 3rd Europ. Working Session on Learning, </booktitle> <pages> pages 253 - 262, </pages> <address> London, 1988. </address> <publisher> Pitman. </publisher>
Reference-contexts: In section 6, we discuss ways of extending R automatically through the use of rule schema modification operators. The approach presented here originated in Emde's METAXA system [Emd87] and was also used in the BLIP system <ref> [Wro88] </ref>. <p> It is not required to learn rules that cover all examples 10 , nor that each example is covered only once. 10 CLT, the concept learning tool of MOBAL, has this global view and checks the quality of the rule set <ref> [Wro88] </ref>. 9 The hypothesis space, defined by the sets of available rule models and predicates and the topology, is searched top-down from general to specific. The search is along the generality hierarchy with pruning of specializations of accepted and failed hypotheses. <p> RDT is used in three ways within the MOBAL system: * The user may call RDT and explicitly provide the target predicate. * The concept learning tool CLT calls RDT to learn rules 14 about a proposed concept, and then evaluates their quality as a concept description <ref> [Wro88] </ref>. * RDT is used as a background learning process that continuously tries to induce rules and include them in the knowledge base.
Reference: [Wro89] <editor> Stefan Wrobel. </editor> <booktitle> MLT Deliverable 4.0/G: Description of MOBAL. </booktitle> <institution> GMD (German Natl. Research Center for Computer Science), </institution> <address> P.O.Box 1240, W-5205 St. Augustin 1, Germany, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: In this section, we want to briefly describe the use of RDT within the knowledge acquisition system MOBAL <ref> [Wro89] </ref>, a successor of BLIP [EKK + 89]. MOBAL is a system that integrates manual knowledge acquisition and machine learning according to the so-called sloppy modeling paradigm [Mor89, Mor90]. MOBAL provides a comfortable and graphical interface for the entry and manipulation of facts, rules, rule models, and topology (among others).
Reference: [Wro90] <author> Stefan Wrobel. </author> <title> Application of MOBAL to the medical domains of ICS/FORTH (MLT technical note). </title> <institution> GMD (German Natl. Research Center for Computer Science), </institution> <address> P.O.Box 1240, W-5205 St. Augustin 1, Ger-many, </address> <month> September </month> <year> 1990. </year> <month> 23 </month>
Reference-contexts: In many practical applications, however, attribute-based representations are insufficient. This includes domains where structural properties or time-dependent 1 relationships need to be expressed, as in medical diagnosis <ref> [Wro90] </ref> 1 . In response, learning in representations that are variants of first-order logic (FOL) has received more interest recently. Here, the learning problem can generally be stated as follows. <p> The hypotheses that have already been confirmed or pruned as too special (the leaves of the search, see below) are remembered and checked to avoid exploring their specializations. Suppose for example the rule model developed to learn in the ICS/FORTH domain Maldecensus Testis (see next section and <ref> [Wro90] </ref>). This rule model was constructed for learning in domains that consist largely of feature vector data. <p> The previous version of RDT was also able to find all rules that used the target concept in the premises. 17 Within MOBAL, RDT has been applied to a number of toy and real-world problems 15 . In <ref> [Wro90] </ref>, we describe the application of MOBAL to the medical domain Maldecensus Testis that we are developing together with ICS/FORTH of Greece. In this application, rules about the proper treatment of infants and children with a certain testicle problem are to be learned.
References-found: 33

