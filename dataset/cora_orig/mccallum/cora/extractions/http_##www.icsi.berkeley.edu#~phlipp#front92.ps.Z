URL: http://www.icsi.berkeley.edu/~phlipp/front92.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/~phlipp/phlipp.publ.html
Root-URL: http://www.icsi.berkeley.edu
Title: Automatic Data Distribution for Nearest Neighbor Networks algorithm for mapping an arbitrary, multidimensional array onto
Author: Michael Philippsen 
Note: An  that can either be provided by the programmer or can be derived by  
Address: D-7500 Karlsruhe, F.R.G.  
Affiliation: Universitat Karlsruhe  
Abstract: phlipp@ira.uka.de This paper appeared in: Frontiers'92: The Fourth Symposium on the Frontiers of Massively Parallel Computation, pages 178-185, McLean, Virginia, October 19-21, 1992 Abstract We describe the integration of this technique into an optimizing compiler for Modula-2* and derive extensions that render efficient translation of nested parallelism possible and provide some support for thread scheduling. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> American National Standards Institute, Inc., </institution> <address> Washington, D.C. </address> <month> ANSI, </month> <title> Programming Language Fortran Extended (Fortran 90). ANSI X3.198-1992, </title> <year> 1992. </year>
Reference-contexts: Some languages re quire an explicit mapping of the data onto the topology [19, 20, 12, 16, 2], others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions <ref> [4, 13, 10, 18, 1, 14, 3] </ref>. Even a data distribution language has been developed for this purpose [7]. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [2] <author> Ingo Barth, Thomas Braunl, Stefan Engelhardt, and Frank Sembach. </author> <title> Parallaxis (vers. 2) user manual. </title> <type> Technical Report 2/91, </type> <institution> Universitat Stuttgart, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: Whereas the goals are agreed upon, totally different approaches to reach them have been developed. In many programming languages the user must program the data layout explicitly. Some languages re quire an explicit mapping of the data onto the topology <ref> [19, 20, 12, 16, 2] </ref>, others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions [4, 13, 10, 18, 1, 14, 3].
Reference: [3] <author> Barbara M. Chapman, Heinz Herbeck, and Hans P. Zima. </author> <title> Automatic support for data distribution. </title> <booktitle> In Proc. of the 6th Distributed Memory Computing Conference, </booktitle> <pages> pages 51-58, </pages> <address> Portland, Oregon, </address> <month> April 28 May 1, </month> <year> 1991. </year>
Reference-contexts: Some languages re quire an explicit mapping of the data onto the topology [19, 20, 12, 16, 2], others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions <ref> [4, 13, 10, 18, 1, 14, 3] </ref>. Even a data distribution language has been developed for this purpose [7]. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [4] <author> Geoffrey Fox, Seema Hiranandani, Ken Kennedy, Charles Koelbel, Uli Kremer, Chau-Wen Tseng, and Min-You Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report CRPC-TR90079, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Some languages re quire an explicit mapping of the data onto the topology [19, 20, 12, 16, 2], others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions <ref> [4, 13, 10, 18, 1, 14, 3] </ref>. Even a data distribution language has been developed for this purpose [7]. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [5] <author> Manish Gupta and Prithviraj Banerjee. </author> <title> Automatic data partitioning on distributed memory multiprocessors. </title> <booktitle> In Proc. of the 6th Distributed Memory Computing Conference, </booktitle> <pages> pages 43-50, </pages> <address> Portland, Oregon, </address> <month> April 28 May 1, </month> <year> 1991. </year>
Reference-contexts: Even a data distribution language has been developed for this purpose [7]. Recent work <ref> [8, 9, 5, 17, 11] </ref> focuses on static compile-time analysis to automatically find data decomposition that achieves both goals. <p> We define 0 = 0 for notational convenience. 3 Array Allocation By studying several approaches for explicit declaration of layout patterns [19, 20, 12, 16, 22, 1, 14, 4, 13, 18, 10, 21] and for intermediate representation of allocation information in modern compilers <ref> [8, 9, 5, 17, 11, 15] </ref>, we realized that a set of three machine-independent types of distribution information is used most often. Consider a m-dimensional array. Each of the dimensions can be labeled with either spread, cycle, or local.
Reference: [6] <author> Ernst A. Heinz. </author> <title> Automatische Elimination von Synchronisationsbarrieren in synchronen FORALLs. </title> <type> Master's thesis, </type> <institution> University of Karl-sruhe, Department of Informatics, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: In the figure, the general architecture of the optimization phase of our Modula-2* compilers is depicted. The compiler detects redundant synchronization events by data dependence analysis. The elimination process is described in more detail in <ref> [15, 6] </ref>. This transformation is a prerequisite for an efficient translation for MIMD machines, where synchronization is expensive, and it improves machines utilization on SIMD machines, since larger code sections can be fused into single virtualization loops.
Reference: [7] <author> K. Kennedy and H.P. Zima. </author> <title> Virtual shared memory for distributed-memory machines. </title> <booktitle> In Proc. of the 4th Conference on Hypercubes, Concurrent Computers and Applications, </booktitle> <volume> volume 1, </volume> <pages> pages 361-366, </pages> <address> Monterey, CA, 1989. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: Even a data distribution language has been developed for this purpose <ref> [7] </ref>. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [8] <author> Kathleen Knobe, Joan D. Lukas, and Guy L. Steele. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(2) </volume> <pages> 102-118, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: Even a data distribution language has been developed for this purpose [7]. Recent work <ref> [8, 9, 5, 17, 11] </ref> focuses on static compile-time analysis to automatically find data decomposition that achieves both goals. <p> We define 0 = 0 for notational convenience. 3 Array Allocation By studying several approaches for explicit declaration of layout patterns [19, 20, 12, 16, 22, 1, 14, 4, 13, 18, 10, 21] and for intermediate representation of allocation information in modern compilers <ref> [8, 9, 5, 17, 11, 15] </ref>, we realized that a set of three machine-independent types of distribution information is used most often. Consider a m-dimensional array. Each of the dimensions can be labeled with either spread, cycle, or local. <p> Whereas Inter is machine-independent, because it is based solely on the cost values determined by Intra, the latter needs to know about computation costs, the topology of the network, and the communication costs. Inter is based on Knobe's work <ref> [8, 9] </ref>: we construct a graph of machine-independent alignment preferences, i.e., we decide which dimensions of two arrays should be aligned to achieve locality of the elements. Alignment is done by constructing super-arrays and by providing functions that map the original arrays onto the super-array.
Reference: [9] <author> Kathleen Knobe and Venkataraman Natarajan. </author> <title> Data optimization: Minimizing residual interpro-cessor data motion on SIMD machines. </title> <editor> In Joseph JaJa, editor, </editor> <booktitle> Frontiers '90:The Third Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <institution> College Park, University of Maryland, </institution> <address> Oc-tober 8-10, </address> <year> 1990. </year>
Reference-contexts: Even a data distribution language has been developed for this purpose [7]. Recent work <ref> [8, 9, 5, 17, 11] </ref> focuses on static compile-time analysis to automatically find data decomposition that achieves both goals. <p> We define 0 = 0 for notational convenience. 3 Array Allocation By studying several approaches for explicit declaration of layout patterns [19, 20, 12, 16, 22, 1, 14, 4, 13, 18, 10, 21] and for intermediate representation of allocation information in modern compilers <ref> [8, 9, 5, 17, 11, 15] </ref>, we realized that a set of three machine-independent types of distribution information is used most often. Consider a m-dimensional array. Each of the dimensions can be labeled with either spread, cycle, or local. <p> Whereas Inter is machine-independent, because it is based solely on the cost values determined by Intra, the latter needs to know about computation costs, the topology of the network, and the communication costs. Inter is based on Knobe's work <ref> [8, 9] </ref>: we construct a graph of machine-independent alignment preferences, i.e., we decide which dimensions of two arrays should be aligned to achieve locality of the elements. Alignment is done by constructing super-arrays and by providing functions that map the original arrays onto the super-array.
Reference: [10] <author> Charles Koelbel and Piyush Mehrotra. </author> <title> Supporting shared data structures on distributed memory architectures. </title> <booktitle> In Proc. of the 2nd ACM SIG-PLAN Symposium on Principles and Practice of Parallel Programming, PPOPP, </booktitle> <pages> pages 177-186, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Some languages re quire an explicit mapping of the data onto the topology [19, 20, 12, 16, 2], others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions <ref> [4, 13, 10, 18, 1, 14, 3] </ref>. Even a data distribution language has been developed for this purpose [7]. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [11] <author> Jingke Li and Marina Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing between distributed arrays. </title> <editor> In Joseph JaJa, editor, </editor> <booktitle> Frontiers '90: The Third Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 424-433, </pages> <institution> College Park, University of Maryland, </institution> <month> October 8-10, </month> <year> 1990. </year>
Reference-contexts: Even a data distribution language has been developed for this purpose [7]. Recent work <ref> [8, 9, 5, 17, 11] </ref> focuses on static compile-time analysis to automatically find data decomposition that achieves both goals. <p> We define 0 = 0 for notational convenience. 3 Array Allocation By studying several approaches for explicit declaration of layout patterns [19, 20, 12, 16, 22, 1, 14, 4, 13, 18, 10, 21] and for intermediate representation of allocation information in modern compilers <ref> [8, 9, 5, 17, 11, 15] </ref>, we realized that a set of three machine-independent types of distribution information is used most often. Consider a m-dimensional array. Each of the dimensions can be labeled with either spread, cycle, or local.
Reference: [12] <author> MasPar Computer Corporation. </author> <title> MasPar Parallel Application Language (MPL) Reference Manual, </title> <month> September </month> <year> 1990. </year>
Reference-contexts: Whereas the goals are agreed upon, totally different approaches to reach them have been developed. In many programming languages the user must program the data layout explicitly. Some languages re quire an explicit mapping of the data onto the topology <ref> [19, 20, 12, 16, 2] </ref>, others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions [4, 13, 10, 18, 1, 14, 3].
Reference: [13] <author> Piyush Mehrotra and John Van Rosendale. </author> <title> The BLAZE language: A parallel language for scientific programming. </title> <journal> Parallel Computing, </journal> <volume> 5 </volume> <pages> 339-361, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: Some languages re quire an explicit mapping of the data onto the topology [19, 20, 12, 16, 2], others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions <ref> [4, 13, 10, 18, 1, 14, 3] </ref>. Even a data distribution language has been developed for this purpose [7]. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [14] <author> Michael Metcalf and John Reid. </author> <title> Fortran 90 Explained. </title> <publisher> Oxford Science Publications, </publisher> <year> 1990. </year>
Reference-contexts: Some languages re quire an explicit mapping of the data onto the topology [19, 20, 12, 16, 2], others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions <ref> [4, 13, 10, 18, 1, 14, 3] </ref>. Even a data distribution language has been developed for this purpose [7]. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [15] <author> Michael Philippsen and Walter F. Tichy. </author> <title> Modula-2* and its compilation. </title> <booktitle> In First International Conference of the Austrian Center for Parallel Computation, </booktitle> <address> Salzburg, Austria, </address> <year> 1991, </year> <pages> pages 169-183. </pages> <publisher> Springer Verlag, Lecture Notes in Computer Science 591, </publisher> <year> 1992. </year>
Reference-contexts: We define 0 = 0 for notational convenience. 3 Array Allocation By studying several approaches for explicit declaration of layout patterns [19, 20, 12, 16, 22, 1, 14, 4, 13, 18, 10, 21] and for intermediate representation of allocation information in modern compilers <ref> [8, 9, 5, 17, 11, 15] </ref>, we realized that a set of three machine-independent types of distribution information is used most often. Consider a m-dimensional array. Each of the dimensions can be labeled with either spread, cycle, or local. <p> In the figure, the general architecture of the optimization phase of our Modula-2* compilers is depicted. The compiler detects redundant synchronization events by data dependence analysis. The elimination process is described in more detail in <ref> [15, 6] </ref>. This transformation is a prerequisite for an efficient translation for MIMD machines, where synchronization is expensive, and it improves machines utilization on SIMD machines, since larger code sections can be fused into single virtualization loops.
Reference: [16] <editor> Prentice Hall, </editor> <address> Englewood Cliffs, New Jersey. </address> <note> INMOS Limited: Occam Programming Manual, </note> <year> 1984. </year>
Reference-contexts: Whereas the goals are agreed upon, totally different approaches to reach them have been developed. In many programming languages the user must program the data layout explicitly. Some languages re quire an explicit mapping of the data onto the topology <ref> [19, 20, 12, 16, 2] </ref>, others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions [4, 13, 10, 18, 1, 14, 3].
Reference: [17] <author> J. Ramanujam and P. Sadayappan. </author> <title> Access based data decomposition for distributed memory machines. </title> <booktitle> In Proc. of the 6th Distributed Memory Computing Conference, </booktitle> <pages> pages 196-199, </pages> <address> Portland, Oregon, </address> <month> April 28 May 1, </month> <year> 1991. </year>
Reference-contexts: Even a data distribution language has been developed for this purpose [7]. Recent work <ref> [8, 9, 5, 17, 11] </ref> focuses on static compile-time analysis to automatically find data decomposition that achieves both goals. <p> We define 0 = 0 for notational convenience. 3 Array Allocation By studying several approaches for explicit declaration of layout patterns [19, 20, 12, 16, 22, 1, 14, 4, 13, 18, 10, 21] and for intermediate representation of allocation information in modern compilers <ref> [8, 9, 5, 17, 11, 15] </ref>, we realized that a set of three machine-independent types of distribution information is used most often. Consider a m-dimensional array. Each of the dimensions can be labeled with either spread, cycle, or local.
Reference: [18] <author> M. Rosing, R. Schnabel, and R. Weaver. DINO: </author> <title> Summary and example. </title> <booktitle> In Proc. of the Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pages 472-481, </pages> <address> Pasadena, CA, 1988. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: Some languages re quire an explicit mapping of the data onto the topology [19, 20, 12, 16, 2], others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions <ref> [4, 13, 10, 18, 1, 14, 3] </ref>. Even a data distribution language has been developed for this purpose [7]. Recent work [8, 9, 5, 17, 11] focuses on static compile-time analysis to automatically find data decomposition that achieves both goals.
Reference: [19] <institution> Thinking Machines Corporation, Cambridge, Massachusetts. </institution> <note> *Lisp Reference Manual, Version 5.0, </note> <year> 1988. </year>
Reference-contexts: Whereas the goals are agreed upon, totally different approaches to reach them have been developed. In many programming languages the user must program the data layout explicitly. Some languages re quire an explicit mapping of the data onto the topology <ref> [19, 20, 12, 16, 2] </ref>, others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions [4, 13, 10, 18, 1, 14, 3].
Reference: [20] <institution> Thinking Machines Corporation, Cambridge, Massachusetts. </institution> <note> C* Language Reference Manual, </note> <month> April </month> <year> 1991. </year>
Reference-contexts: Whereas the goals are agreed upon, totally different approaches to reach them have been developed. In many programming languages the user must program the data layout explicitly. Some languages re quire an explicit mapping of the data onto the topology <ref> [19, 20, 12, 16, 2] </ref>, others are more abstract and provide either sets of directives for the compiler or interactive or knowledge-based environments that help determine alignment of array dimensions and mapping functions [4, 13, 10, 18, 1, 14, 3].
Reference: [21] <author> Walter F. Tichy and Christian G. Herter. </author> <title> Modula-2*: An extension of Modula-2 for highly parallel, portable programs. </title> <type> Technical Report No. 4/90, </type> <institution> University of Karlsruhe, Department of Informatics, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: In this case performance can be improved by gray-coding of the bit sequence, which is also a fast bit operations. 5 Data Allocation in Modula-2* In Modula-2* (complete definition in <ref> [21] </ref>) there is no explicit mapping of data elements to processors. Data layouts are derived automatically by the compiler.
Reference: [22] <author> U.S. </author> <title> Government, Ada Joint Program Office. ANSI/MIL-Std 1815 A, Reference Manual for the Ada Programming Language, </title> <month> January </month> <year> 1983. </year>
References-found: 22

