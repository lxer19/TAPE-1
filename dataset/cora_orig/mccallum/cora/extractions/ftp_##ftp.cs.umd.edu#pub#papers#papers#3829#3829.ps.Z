URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3829/3829.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: TIKHONOV REGULARIZATION AND TOTAL LEAST SQUARES  
Author: GENE H. GOLUB PER CHRISTIAN HANSEN AND DIANNE P. O'LEARY 
Keyword: Key words. total least squares, discrete ill-posed problems, regularization, bidiagonalization.  
Note: AMS(MOS) subject classifications. 65F20, 65F30.  
Abstract: Discretizations of inverse problems lead to systems of linear equations with a highly ill-conditioned coefficient matrix, and in order to compute stable solutions to these systems it is necessary to apply regularization methods. We show how Tikhonov's regularization method, which in its original formulation involves a least squares problem, can be recast in a total least squares formulation, suited for problems in which both the coefficient matrix and the right-hand side are known only approximately. We analyze the regularizing properties of this method and demonstrate by a numerical example that in certain cases with large perturbations, the new method is superior to standard regularization methods. 1. Introduction. In this paper we study a class of methods for producing an 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bj orck, </author> <title> Numerical Methods for Least Squares Problems, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: 1=2 B T L C T I I n A @ J T s 1 0 H T b 0 A :(19) Since I changes more frequently than L in our approach, we will now use Givens rotations to annihilate 1=2 L C using B by means of Elden's algorithm <ref> [1, Section 5.3.4] </ref>, which can be represented as L C = G ^ B G 21 G 22 ^ B 6 When we insert this G into the augmented system (19), it becomes 0 I n 0 ^ B ^ B T 0 I I n A @ ^s 1 0
Reference: [2] <author> H. W. Engl, </author> <title> Regularization methods for the stable solution of inverse problems, </title> <institution> Surv. Math. Ind. </institution> <month> 3 </month> <year> (1993), </year> <pages> 71-143. </pages>
Reference-contexts: Such problems arise, for example, from the discretization of ill-posed problems such as integral equations of the first kind. See, e.g., <ref> [2] </ref>, [3], [7], [8], and [10] for examples and details. In these problems, the solutions to the two formulations in (1) and (2) can be hopelessly contaminated by the noise in directions corresponding to small singular values of A or (A ; b).
Reference: [3] <author> H. W. Engl, M. Hanke and A. Neubauer, </author> <title> Regularization of Inverse Problems, </title> <publisher> Kluwer, </publisher> <address> Dordrecht, </address> <year> 1996. </year>
Reference-contexts: Such problems arise, for example, from the discretization of ill-posed problems such as integral equations of the first kind. See, e.g., [2], <ref> [3] </ref>, [7], [8], and [10] for examples and details. In these problems, the solutions to the two formulations in (1) and (2) can be hopelessly contaminated by the noise in directions corresponding to small singular values of A or (A ; b).
Reference: [4] <author> R. D. Fierro, G. H. Golub, P. C. Hansen, D. P. O'Leary, </author> <title> Regularization by Truncated Total Least Squares, </title> <note> Report UNIC-93-14, December 1993 (20 pages); submitted to SIAM J. </note> <institution> Sci. Comput. </institution>
Reference-contexts: Alternatively, one can truncate the SVD expansion of the solution, leaving out all the SVD components corresponding to the small singular values. For the total least squares problem, the truncation approach has already been studied by Fierro, Golub, Hansen, and O'Leary <ref> [4] </ref>. <p> This is in contrast to the truncating approach, since we have shown in <ref> [4] </ref> that truncated TLS can be superior to truncated LS. 2.2. The General-Form Case. In many applications, it is necessary to choose a matrix L different from the identity matrix; these issues are discussed, e.g., in [10, x4.3]. <p> Our computations are carried out in Matlab using the Regularization Tools package [9]. It is a generally accepted fact that for small noise levels, we should not expect the ordinary TLS solution to differ much from the ordinary least squares solution; see [14]. The same observation is made in <ref> [4] </ref> for the T-TLS solution, and the numerical results presented below also support this observation for the R-TLS method. We emphasize that the precise meaning of "small" depends on the particular problem.
Reference: [5] <author> G. H. Golub and C. F. Van Loan, </author> <title> An analysis of the total least squares problem, </title> <journal> SIAM J. Numer. Anal. </journal> <volume> 17 (1980), </volume> <pages> 883-893. </pages>
Reference-contexts: We assume that the elements of A and those of b are contaminated by some noise. An appropriate statement of the problem in the case of noisy data is the total least squares (TLS) formulation <ref> [5] </ref>, [6, x12.3], [16]: min k (A ; b) ( ~ A ; ~ b)k F subject to ~ b = ~ A x :(1) In contrast, if the elements of A are exact and only b contains noise, then the corre sponding formulation is the least squares (LS) problem min <p> For ffi = kL x TLS k 2 , the Lagrange multiplier is zero, and the solution becomes the unconstrained minimizer x TLS . The value 2 n+1 follows from <ref> [5, Theorem 4.1] </ref>. The constraint is never again active for larger ffi, so the solution remains unchanged.
Reference: [6] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, 3. </title> <editor> Ed., </editor> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1996. </year>
Reference-contexts: We assume that the elements of A and those of b are contaminated by some noise. An appropriate statement of the problem in the case of noisy data is the total least squares (TLS) formulation [5], <ref> [6, x12.3] </ref>, [16]: min k (A ; b) ( ~ A ; ~ b)k F subject to ~ b = ~ A x :(1) In contrast, if the elements of A are exact and only b contains noise, then the corre sponding formulation is the least squares (LS) problem min kAx
Reference: [7] <author> C. W. Groetsch, </author> <title> Inverse Problems in the Mathematical Sciences, </title> <publisher> Vieweg, Wiesbaden, </publisher> <year> 1993. </year>
Reference-contexts: Such problems arise, for example, from the discretization of ill-posed problems such as integral equations of the first kind. See, e.g., [2], [3], <ref> [7] </ref>, [8], and [10] for examples and details. In these problems, the solutions to the two formulations in (1) and (2) can be hopelessly contaminated by the noise in directions corresponding to small singular values of A or (A ; b).
Reference: [8] <author> M. Hanke and P. C. Hansen, </author> <title> Regularization methods for large-scale problems, </title> <institution> Surv. Math. Ind. </institution> <month> 3 </month> <year> (1993), </year> <pages> 253-315. </pages>
Reference-contexts: Such problems arise, for example, from the discretization of ill-posed problems such as integral equations of the first kind. See, e.g., [2], [3], [7], <ref> [8] </ref>, and [10] for examples and details. In these problems, the solutions to the two formulations in (1) and (2) can be hopelessly contaminated by the noise in directions corresponding to small singular values of A or (A ; b).
Reference: [9] <author> P. C. Hansen, </author> <title> Regularization tools, a Matlab package for analysis of discrete regularization problems, </title> <booktitle> Numerical Algorithms 6 (1994), </booktitle> <pages> 1-35. </pages>
Reference-contexts: We illustrate Theorem 2.2 with an example: discretization of a Fredholm integral equation with the second derivative operator as kernel. The implementation is deriv2 from <ref> [9] </ref>, the size of the matrix A is 64 fi 32, and both A and b are perturbed by Gaussian noise with zero mean and standard deviation 10 5 . We have 2 n+1 2:38 Fig. 1. <p> Numerical Results. In this section we present a numerical example that demonstrates the usefulness of the R-TLS method. Our computations are carried out in Matlab using the Regularization Tools package <ref> [9] </ref>. It is a generally accepted fact that for small noise levels, we should not expect the ordinary TLS solution to differ much from the ordinary least squares solution; see [14]. <p> The test problem we have chosen to illustrate the R-TLS algorithm is a discretiza-tion by means of Gauss-Laguerre quadrature of the inverse Laplace transform Z 1 exp (s t) f (t) dt = 2 1 ; 0 s originating from [17] and implemented in the function ilaplace (n,2) in <ref> [9] </ref>. The matrix L approximates the first derivative operator.
Reference: [10] <author> P. C. Hansen, </author> <title> Rank-Deficient and Discrete Ill-Posed Problems, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1997. </year>
Reference-contexts: Such problems arise, for example, from the discretization of ill-posed problems such as integral equations of the first kind. See, e.g., [2], [3], [7], [8], and <ref> [10] </ref> for examples and details. In these problems, the solutions to the two formulations in (1) and (2) can be hopelessly contaminated by the noise in directions corresponding to small singular values of A or (A ; b). <p> This is in contrast to the truncating approach, since we have shown in [4] that truncated TLS can be superior to truncated LS. 2.2. The General-Form Case. In many applications, it is necessary to choose a matrix L different from the identity matrix; these issues are discussed, e.g., in <ref> [10, x4.3] </ref>. In this case, the R-TLS solution x ffi is different from the Tikhonov solution whenever the residual b Ax is different from zero, since both I and L are nonzero.
Reference: [11] <author> P. C. Hansen and D. P. O'Leary, </author> <title> The use of the L-curve in the regularization of discrete ill-posed problems, </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 14 (1993), </volume> <pages> pp. 1487-1503. </pages>
Reference-contexts: problem (2), a general version of Tikhonov's method takes the form min kA x bk 2 2 ;(3) where is a positive constant chosen to control the size of the solution vector, and L is a matrix that defines a (semi)norm on the solution through which the "size" is measured <ref> [11] </ref>. Often, L represents the first or second derivative operator. If L is the identity matrix, then the Tikhonov problem is said to be in standard form.
Reference: [12] <author> P. C. Hansen and D. P. O'Leary, </author> <title> Regularization algorithms based on total least squares; in S. </title> <editor> Van Huffel (Ed.), </editor> <title> Recent Advances in Total Least Squares Techniques and Errors-in-Variables Modeling, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <note> 1996; pp. 127-137. </note>
Reference-contexts: Our paper is organized as follows. In x2 we introduce the regularized TLS method, and we study its regularizing properties. Computational aspects are described in x3, and we conclude the paper with a numerical example in x4. A preliminary report on this work appeared as <ref> [12] </ref>. 2. The Regularized TLS Method. Our regularization of the TLS problem is based on Tikhonov regularization.
Reference: [13] <author> T. A. Hua and R. F. Gunst, </author> <title> Generalized ridge regression: a note on negative ridge parameters, </title> <journal> Commun. Statist. - Theor. Meth., </journal> <volume> 12 (1983), </volume> <pages> pp. 37-45. </pages>
Reference-contexts: On the other hand, I is always negative, and thus adds some de-regularization to the solution. Statistical aspects of a negative regularization parameter in Tikhonov's method are discussed in <ref> [13] </ref>. For a given ffi, there are usually several pairs of parameters I and L , and thus several solutions x, that satisfy relations (9)-(11), but only one of these solves the optimization problem (7).
Reference: [14] <author> G. W. Stewart, </author> <title> On the invariance of perturbed null vectors under column scaling, </title> <journal> Numer. Math., </journal> <volume> 44 (1984), </volume> <pages> pp. 61-65. 9 </pages>
Reference-contexts: Our computations are carried out in Matlab using the Regularization Tools package [9]. It is a generally accepted fact that for small noise levels, we should not expect the ordinary TLS solution to differ much from the ordinary least squares solution; see <ref> [14] </ref>. The same observation is made in [4] for the T-TLS solution, and the numerical results presented below also support this observation for the R-TLS method. We emphasize that the precise meaning of "small" depends on the particular problem.
Reference: [15] <author> A. N. Tikhonov and V. Y. Arsenin, </author> <title> Solutions of Ill-Posed Problems, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1977. </year>
Reference: [16] <author> S. Van Huffel and J. Vandewalle, </author> <title> The Total Least Squares Problem Computational Aspects and Analysis, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: We assume that the elements of A and those of b are contaminated by some noise. An appropriate statement of the problem in the case of noisy data is the total least squares (TLS) formulation [5], [6, x12.3], <ref> [16] </ref>: min k (A ; b) ( ~ A ; ~ b)k F subject to ~ b = ~ A x :(1) In contrast, if the elements of A are exact and only b contains noise, then the corre sponding formulation is the least squares (LS) problem min kAx bk 2 <p> If ffi = kx TLS k 2 then = 2 n+1 , where n+1 is the smallest singular value of (A ; b) (see <ref> [16, Theorem 2.7] </ref>), and therefore we have 2 n+1 &lt; &lt; 0 in the third case and = 2 n+1 in the fourth. <p> In other words, replacing the least squares residual with the TLS residual in the Tikhonov formulation has no effect when L = I n and ffi kx LS k 2 . We remark that since kx TLS k 2 kx LS k 2 (see <ref> [16, Corollary 6.2] </ref>) there is usually a nontrivial set of "large" values of ffi for which the multiplier IL is negative.
Reference: [17] <author> J. M. Varah, </author> <title> On the numerical solution of ill-conditioned linear systems with applications to ill-posed problems, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 10 (1973), </volume> <pages> pp. 257-267. 10 </pages>
Reference-contexts: The test problem we have chosen to illustrate the R-TLS algorithm is a discretiza-tion by means of Gauss-Laguerre quadrature of the inverse Laplace transform Z 1 exp (s t) f (t) dt = 2 1 ; 0 s originating from <ref> [17] </ref> and implemented in the function ilaplace (n,2) in [9]. The matrix L approximates the first derivative operator.
References-found: 17

