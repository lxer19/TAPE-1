URL: ftp://ftp.sics.se/pub/SICS-reports/Reports/SICS-R--95-06--SE.ps.Z
Refering-URL: http://www.sics.se/libindex.html
Root-URL: 
Author: ISRN SICS-R -/- -SE 
Note: Erik Schon  
Abstract: SICS Research Report R95:06 ISSN 0283-3638 On the Computation of Fixpoints in Static Program Analysis with an Application to Analysis of AKL 
Abstract-found: 1
Intro-found: 1
Reference: [AH87] <editor> Samson Abramsky and Chris Hankin. </editor> <title> Abstract Interpretation of Declarative Languages. </title> <publisher> Ellis Horwood, </publisher> <address> Chichester, </address> <year> 1987. </year>
Reference-contexts: ABSTRACT INTERPRETATION 25 6 - concrete indata concrete execution concrete outdata abstraction concretization concrete domain Galois connection abstract domain abstract indata abstract abstract execution outdata 5.3 Abstract Interpretation The theory of abstract interpretation <ref> [AH87, CC92a, CC92b] </ref> facilitates a systematic approach to the problem of extracting properties from programs in order to provide provably correct answers to questions about their run-time behaviour. These properties are properties of some semantic function which characterizes certain aspects of the program.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers. Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Example 4.2 (Chains) In Figure 4.2, the only chains are f9; 1g and f2; 3; 4g. 4.2 Reducible Graphs The following concepts lead to the definition of reducible graphs, which are often used as flow-charts when modeling inter-procedural execution of languages without the "goto"- construct <ref> [ASU86] </ref>. Definition 4.6 (head, tail, initial vertex) Let G = hV; Ei be a directed graph and let e = hv; wi be an edge in G. The head of e is v and the tail of e is w. <p> What should be minimized is not the number of function applications, but the total execution time. 7.5 Related Work One way of sorting a directed graph is to partition the graph into disjoint intervals and then collapse the intervals into a limit flow graph <ref> [ASU86] </ref>. A limit flow graph can only be found if the graph is reducible. A method for overcoming this difficulty is using node splitting, but this is rather ad-hoc.
Reference: [BBP93] <editor> Dines Bjtrner, Manfred Broy, and Igor V. Pottosin, editors. </editor> <booktitle> Formal Methods in Programming and Their Applications, volume 735 of Lecture Notes in Computer Science, </booktitle> <address> Academgorodok, Novosibirsk, Russia, June/July 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference: [Big85] <author> Norman L. Biggs. </author> <title> Discrete Mathematics. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1985. </year>
Reference-contexts: Hence, in this chapter, basic material from graph theory is presented. A modern textbook where a good treatment of graph theory can be found is <ref> [Big85] </ref>. 4.1 Basic Concepts Intuitively, a directed graph is just a generalization of an ordered set in the sense that the only requirement on the relation holding between objects in a directed graph is that it should have a direction, i.e. the members of the relation should be ordered pairs.
Reference: [Bou92a] <author> Fran~cois Bourdoncle. </author> <title> Abstract interpretation by dynamic partitioning. </title> <type> Technical Report 18, </type> <institution> DIGITAL Paris Research Laboratory, </institution> <month> March </month> <year> 1992. </year>
Reference: [Bou92b] <author> Fran~cois Bourdoncle. </author> <title> Semantiques des langages imperatifs d'ordre superieur et interpretation abstraite. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <year> 1992. </year>
Reference-contexts: Its major advantage is that it both subsumes a topological sort of the strongly connected components of a directed graph and automatically, i.e. without using dynamic heuristics (cf. above), orders the the vertices inside each SCC in an ingenious way <ref> [Bou92b, Bou93] </ref>. Bourdoncle's algorithm for finding a weak topological order makes a hierarchical decomposition of a directed graph into strongly connected components and subcomponents, by recursively applying Tarjan's algorithm to each non-trivial component after having removed w (the head of the component) and every back-edge v ! w. <p> The time complexity of Tarjan's algorithm is linear in the number of edges. 7.2 Weak Topological Orders When surveying the field of fixpoint computations, the method based on a weak topological order (WTO) <ref> [Bou92b, Bou93] </ref> of the static dependency graph seemed to be the best way of improving the execution speed of the fixpoint solver in the AKL analysis 1 The original idea was first published by Tarjan in [Tar72]; the papers [NSS94] and [Jia93] are recent enhancements. 2 The pseudo code loosely resembles <p> is a lattice with `(L) = l, then the time complexity of the recursive strategy for a strongly connected graph G = hV; Ei is: O (l v2V and the time complexity of the iterative strategy is: O (l jV j jHj); where H is the set of component-heads Proof. <ref> [Bou92b] </ref>, Section 3.7.1. The theoretical upper bound of the recursive strategy is always better than that of the iterative strategy, since ffi (v) jHj; 8v 2 V . Note, however, that the above time complexity results are based on the number of function applications.
Reference: [Bou93] <author> Fran~cois Bourdoncle. </author> <title> Efficient chaotic iteration strategies with widenings. </title> <editor> In Bjtrner et al. </editor> <booktitle> [BBP93], </booktitle> <pages> pages 128-141. </pages>
Reference-contexts: Its major advantage is that it both subsumes a topological sort of the strongly connected components of a directed graph and automatically, i.e. without using dynamic heuristics (cf. above), orders the the vertices inside each SCC in an ingenious way <ref> [Bou92b, Bou93] </ref>. Bourdoncle's algorithm for finding a weak topological order makes a hierarchical decomposition of a directed graph into strongly connected components and subcomponents, by recursively applying Tarjan's algorithm to each non-trivial component after having removed w (the head of the component) and every back-edge v ! w. <p> The time complexity of Tarjan's algorithm is linear in the number of edges. 7.2 Weak Topological Orders When surveying the field of fixpoint computations, the method based on a weak topological order (WTO) <ref> [Bou92b, Bou93] </ref> of the static dependency graph seemed to be the best way of improving the execution speed of the fixpoint solver in the AKL analysis 1 The original idea was first published by Tarjan in [Tar72]; the papers [NSS94] and [Jia93] are recent enhancements. 2 The pseudo code loosely resembles <p> The stability of a component is detected by examining its component-head. Lemma 7.2 A set of consecutive vertices, V 0 , of depth 0 in a WTO requires only one iteration. Proof. <ref> [Bou93] </ref>. Assume that 8v 2 V 0 : ffi (v) = 0. <p> PRACTICAL ITERATION STRATEGIES ? ? - S S Sw Theory Algorithm SCC Tarjan WTO Bourdoncle Topological sort l l l l l l - 6 X X X X X X X X Xz -1 2 4 5 6 8 Proof. <ref> [Bou93] </ref>. Without loss of generality, suppose that the WTO consists of a single outermost component C, i.e. a SCC. Furthermore, assume that after applying all the equations in C and stabilizing each sub-component recursively, the value of the component-head of C remains unchanged. <p> Once again the stability is checked by investigating component-heads. Theorem 7.4 (Detection of stability, iterative strategy) In the iterative strategy, an outermost component C of a weak topological order is stable, if all component-heads of C and its subcomponents are stable. Proof. <ref> [Bou93] </ref>. Without loss of generality, suppose that the WTO consists of a single outermost component C, i.e. a SCC.
Reference: [BP93] <editor> Maurice Bruynooghe and Jaan Penjam, editors. </editor> <booktitle> 5th International Symposium on Programming Language Implementation and Logic Programming, PLILP '93, volume 714 of Lecture Notes in Computer Science, </booktitle> <address> Tallinn, Estonia, </address> <month> August </month> <year> 1993. </year> <note> Springer-Verlag. </note>
Reference: [Bra94] <author> Per Brand. </author> <title> Enhancing the AKL compiler using global analysis. </title> <booktitle> Deliverable number D.WP.2.1.3.M2 of the ESPRIT project ParForce 6707, </booktitle> <address> ftp://ftp.sics.se/www/ps/parforce/deliverables/D.WP.2.1.3.M2.ps.Z, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: 4 The analyzer provides the compiler with: * Alias information: two variables are definitely not aliased at program point i * Type information: a variable has type T at program point i 4 Exactly how the AKL compiler can be enhanced by using global, static program analysis is described in <ref> [Bra94] </ref>. 26 CHAPTER 5. PROGRAM ANALYSIS The interesting program properties, alias and type, are modeled by a complete lattice called the AT -domain.
Reference: [CAA + 94] <author> Mats Carlsson, Johan Andersson, Stefan Andersson, Kent Boortz, Hans Nilsson, Thomas Sjoland, and Johan Widen. </author> <note> SICStus Prolog User's Manual Version 2.1 #9. SICS Research Report R93:01, </note> <month> April </month> <year> 1994. </year>
Reference: [CC77] <author> Patrick Cousot and Radhia Cousot. </author> <title> Automatic synthesis of optimal invariant assertions: </title> <journal> Mathematical foundations. SIGPLAN Notices, </journal> <volume> 12(8) </volume> <pages> 1-12, </pages> <year> 1977. </year> <note> 68 BIBLIOGRAPHY </note>
Reference: [CC92a] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation and application to logic programs. </title> <journal> The Journal of Logic Programming, </journal> <volume> 13(2 </volume> & 3):103-179, July 1992. 
Reference-contexts: ABSTRACT INTERPRETATION 25 6 - concrete indata concrete execution concrete outdata abstraction concretization concrete domain Galois connection abstract domain abstract indata abstract abstract execution outdata 5.3 Abstract Interpretation The theory of abstract interpretation <ref> [AH87, CC92a, CC92b] </ref> facilitates a systematic approach to the problem of extracting properties from programs in order to provide provably correct answers to questions about their run-time behaviour. These properties are properties of some semantic function which characterizes certain aspects of the program. <p> 1 (x k 2 ; : : :; x k n ); 2 = 2 (x k+1 2 ; : : :; x k n ); x k+1 1 ; x k+1 n1 ; x k The above two iteration strategies are special cases of the chaotic iteration strat egy <ref> [Cou81, CC92a] </ref>, which intuitively states that in each step in the sequence of iterations, an arbitrary equation i may be chosen, as long as no equation is forgotten indefinitely (fairness). <p> Theorem 6.1 (Convergence of ascending sequences of chaotic iterations) Let hP n ; vi be a CPO or a complete lattice. If x k is an ascending sequence of chaotic iterations for the map : P n ! P n , then () = F Proof. <ref> [CC92a] </ref>. The proof consists of four steps: (i) Let x v (x) v (). <p> If the number of steps necessary for every component to evolve in chaotic iteration x k is bounded by m, then () = x lm . 6.5. STATIC DEPENDENCIES 33 Proof. <ref> [CC92a] </ref>. From (6.1) and (6.3) in the proof of convergence of an ascending sequence of chaotic iterations it is known that 8k 0 : x k v (x k ) v x k+m .
Reference: [CC92b] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation frameworks. </title> <journal> Journal of Logic and Computation, </journal> <volume> 2(4) </volume> <pages> 511-547, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: ABSTRACT INTERPRETATION 25 6 - concrete indata concrete execution concrete outdata abstraction concretization concrete domain Galois connection abstract domain abstract indata abstract abstract execution outdata 5.3 Abstract Interpretation The theory of abstract interpretation <ref> [AH87, CC92a, CC92b] </ref> facilitates a systematic approach to the problem of extracting properties from programs in order to provide provably correct answers to questions about their run-time behaviour. These properties are properties of some semantic function which characterizes certain aspects of the program.
Reference: [CFFR93] <author> Patrick Cousot, Moreno Falaschi, </author> <title> Gilberto File, </title> <editor> and Antoine Rauzy, editors. </editor> <booktitle> Third International Workshop on Static Analysis, WSA '93, volume 724 of Lecture Notes in Computer Science, </booktitle> <address> Padova, Italy, </address> <month> September </month> <year> 1993. </year> <note> Springer-Verlag. </note>
Reference: [Che94] <author> Li-Ling Chen. </author> <title> Efficient Computation of Fixpoints that Arise in Abstract Interpretation. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: Note that phi may trigger sub-simulations and extend dependency graphs. In [LCDMVH93] an instance of the above universal top-down algorithm for Prolog along with caching of operations is described. Optimizations Chen <ref> [Che94] </ref> expresses an analysis problem as the least fixpoint of an abstract semantic functional over abstract domains.
Reference: [Cou81] <author> Patrick Cousot. </author> <title> Semantic Foundations of Program Analysis, </title> <note> chapter 10. In [MJ81], </note> <year> 1981. </year>
Reference-contexts: 1 (x k 2 ; : : :; x k n ); 2 = 2 (x k+1 2 ; : : :; x k n ); x k+1 1 ; x k+1 n1 ; x k The above two iteration strategies are special cases of the chaotic iteration strat egy <ref> [Cou81, CC92a] </ref>, which intuitively states that in each step in the sequence of iterations, an arbitrary equation i may be chosen, as long as no equation is forgotten indefinitely (fairness).
Reference: [DM90] <editor> Pierre Deransart and Jan Ma luszynski, editors. </editor> <booktitle> 2nd International Symposium on Programming Language Implementation and Logic Programming, PLILP '90, volume 456 of Lecture Notes in Computer Science, </booktitle> <address> Linkoping, </address> <month> August </month> <year> 1990. </year> <note> Springer-Verlag. </note>
Reference: [DP90] <author> B.A. Davey and H.A. Priesley. </author> <title> Introduction to Lattices and Order. </title> <publisher> Cam-bridge University Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: PRELIMINARIES Part I Foundations of Fixpoint Computations 7 Chapter 3 Lattice Theory and Fixpoints This chapter gives a very brief introduction to the theory of ordered sets, lattices and fixpoints. The material is well-known and the presentation relies heavily on Chapters 1-4 of <ref> [DP90] </ref> and, to some extent, on Chapter 1 of [Llo87]. Further information can be found in [DP90], which is a modern textbook, or in the more advanced treatment [Gra78]. 3.1 Ordered Sets In lattice theory the first objective is to impose a certain structure on sets. <p> The material is well-known and the presentation relies heavily on Chapters 1-4 of <ref> [DP90] </ref> and, to some extent, on Chapter 1 of [Llo87]. Further information can be found in [DP90], which is a modern textbook, or in the more advanced treatment [Gra78]. 3.1 Ordered Sets In lattice theory the first objective is to impose a certain structure on sets. This is done by means of a binary relation, relating elements to each other. <p> Then the following statements are equivalent: (i) P is a complete lattice; (ii) S exists in P for every subset S of P ; (iii) P has a top element, &gt;, and S exists in P for every non-empty subset S of P . Proof. <ref> [DP90] </ref>, 2.16. Definition 3.10 (join-irreducible) Let hL; vi be a complete lattice. An element x 2 L is join-irreducible, if x 6= ? and x = a t b implies x = a or x = b, for all a; b 2 L. <p> From the above definitions it is clear that a lattice of finite length is noetherian and hence satisfies both (ACC) and (DCC). The theorems below characterize noetherian ordered sets. Theorem 3.2 (Infinite chain condition.) An ordered set is noetherian iff it satisfies both (ACC) and (DCC). Proof. <ref> [DP90] </ref>, 2.27. Theorem 3.3 (Completeness of noetherian ordered sets) A lattice which is noethe-rian is complete. Proof. [DP90], 2.28. 3.3 Complete Partial Orders It is sometimes important to realize an element in an ordered set as the join of a set of approximating elements below it. <p> The theorems below characterize noetherian ordered sets. Theorem 3.2 (Infinite chain condition.) An ordered set is noetherian iff it satisfies both (ACC) and (DCC). Proof. <ref> [DP90] </ref>, 2.27. Theorem 3.3 (Completeness of noetherian ordered sets) A lattice which is noethe-rian is complete. Proof. [DP90], 2.28. 3.3 Complete Partial Orders It is sometimes important to realize an element in an ordered set as the join of a set of approximating elements below it. The concept of complete partial order is defined in order to guarantee that such an element can be consistently found. <p> The n-fold composite, n , of a map : P ! P is defined as follows: n is the identity map, if n = 0; and n = ffi n1 for n &gt; 0. If is monotone, so is n . Theorem 3.4 Every continuous map is monotone. Proof. <ref> [DP90] </ref>. Let : P ! Q be a continuous map, which implies that for every directed set D in P , G (D) v Q ( D): Now, choose x; y 2 P such that x v P y. Then D := fx; yg is directed with F definition. <p> Theorem 3.5 (CPO Fixpoint I) Let hP ; vi be a CPO, let : P ! P be a monotone map and define ff := F (i) If ff 2 fix (), then ff = (). (ii) If is continuous, then ff = (). Proof. <ref> [DP90] </ref>. (i) Certainly, ? v (?), whence n (?) v n+1 (?) by monotonicity of n . Hence, there is a chain ? v (?) v : : : n (?) v n+1 (?) v : : : in P . <p> The following theorems are important for the clues they provide to a systematic search for fixpoints. Theorem 3.6 (Knaster-Tarski) If hL; vi is a complete lattice and : L ! L is a monotone map, then F Proof. <ref> [DP90] </ref>. Put G = fx 2 L j x v (x)g and g = F G. By definition, x v g; 8x 2 G, so x v (x) v (g), by monotonicity of . Thus (g) 2 G u , whence g v (g). <p> Thus, g = g 0 . Theorem 3.8 (CPO Fixpoint II) If hP ; vi is a CPO and : P ! P is a map such that x v (x) for all x 2 P , then has a fixpoint. Proof. <ref> [DP90] </ref>, 4.14 (hard). Theorem 3.9 (CPO Fixpoint III) If hP ; vi is a CPO and : P ! P is a monotone map, then has a least fixpoint. Proof. [DP90] 4.15. 3.5 Summary To summarize; the existence of a least fixpoint is guaranteed when the ordered set is a CPO <p> Proof. <ref> [DP90] </ref>, 4.14 (hard). Theorem 3.9 (CPO Fixpoint III) If hP ; vi is a CPO and : P ! P is a monotone map, then has a least fixpoint. Proof. [DP90] 4.15. 3.5 Summary To summarize; the existence of a least fixpoint is guaranteed when the ordered set is a CPO and the map is continuous or monotone; or, when the ordered set is a complete lattice and the map is monotone.
Reference: [Fri94] <editor> Peter A. Fritzson, editor. </editor> <booktitle> 5th International Conference on Compiler Construction, CC '94, volume 786 of Lecture Notes in Computer Science, </booktitle> <address> Edinburgh, U.K., April 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Thus, it is of great interest to find the minimal feedback vertex set as this will reduce the time spent checking whether the equation system is stable or not. Finding this set is a classical problem which unfortunately is NP-complete <ref> [GJ79] </ref> and the time complexity of the naive algorithm is quadratic in the number of vertices. Bourdoncle is the first author to investigate the possibility of combining the order of computation and the checking for stability.
Reference: [Gra78] <author> George Gratzer. </author> <title> General Lattice Theory. </title> <publisher> Birkhauser Verlag, </publisher> <address> Basel, </address> <year> 1978. </year>
Reference-contexts: The material is well-known and the presentation relies heavily on Chapters 1-4 of [DP90] and, to some extent, on Chapter 1 of [Llo87]. Further information can be found in [DP90], which is a modern textbook, or in the more advanced treatment <ref> [Gra78] </ref>. 3.1 Ordered Sets In lattice theory the first objective is to impose a certain structure on sets. This is done by means of a binary relation, relating elements to each other. Definition 3.1 (order, ordered set) Let P be a set.
Reference: [HDT87] <author> Susan Horowitz, Alan Demers, and Tim Teitelbaum. </author> <title> An efficient general iterative algorithm for dataflow analysis. </title> <journal> Acta Informatica, </journal> (24):679-694, 1987. 
Reference-contexts: Thus, in a workstack approach, the functions are added to and removed from the worklist in a LIFO-manner, i.e. pushed and popped, until the stack is empty [O'K87]. Priority-Queues According to the priority-queue method <ref> [HDT87] </ref>, the vertices in the worklist should be ordered in reverse postorder. 6.5.2 Topological Sorting When the static dependency graph is acyclic, the problem of finding an optimal chaotic iteration strategy is easy; just sort the graph topologically and evaluated the functions at vertices in the order given. <p> This is an algorithmic optimization used in the AKL analysis framework [SS95]. 34 CHAPTER 6. A SURVEY OF FIXPOINT COMPUTATIONS k l ? - 6 2 3 * Reverse postorder. Perform a reverse postorder traversal <ref> [HDT87] </ref>. * Reverse postorder and worklist. The vertices are picked in reverse postorder from the worklist [HDT87]. The following optimizations are all based on a workstack, adding various heuristics. * Youngest vertex first. <p> A SURVEY OF FIXPOINT COMPUTATIONS k l ? - 6 2 3 * Reverse postorder. Perform a reverse postorder traversal <ref> [HDT87] </ref>. * Reverse postorder and worklist. The vertices are picked in reverse postorder from the worklist [HDT87]. The following optimizations are all based on a workstack, adding various heuristics. * Youngest vertex first. When choosing between two vertices, the youngest (the one which has been evaluated a smaller number of times of the two) should be evaluated first.
Reference: [HU79] <author> John E. Hopcroft and Jeffrey D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1979. </year>
Reference-contexts: Normally, analysis is global, which means that no part of the program being analyzed is investigated in isolation. The descriptions of program properties must be approximate, since Rice's theorem <ref> [HU79] </ref> says that all interesting extensional properties of programs are undecidable. 3 Examples of interesting (and thus undecidable) program properties are "The program terminates" and "Variables x and y must be aliased at some point during the program execution".
Reference: [Jan94] <author> Sverker Jansson. </author> <title> AKL a Multiparadigm Programming Language. </title> <booktitle> Uppsala Theses in Computing Science 19, SICS Dissertation Series 14, </booktitle> <year> 1994. </year>
Reference: [Jia93] <author> Bin Jiang. </author> <title> I/O- and CPU-optimal recognition of strongly connected components. </title> <journal> Information Processing Letters, </journal> <volume> 45 </volume> <pages> 111-115, </pages> <year> 1993. </year>
Reference-contexts: the method based on a weak topological order (WTO) [Bou92b, Bou93] of the static dependency graph seemed to be the best way of improving the execution speed of the fixpoint solver in the AKL analysis 1 The original idea was first published by Tarjan in [Tar72]; the papers [NSS94] and <ref> [Jia93] </ref> are recent enhancements. 2 The pseudo code loosely resembles Pascal, the modifications being that arguments to functions may be labeled in, out or inout signifying how values of the arguments are passed through the function interface. The symbol :: denotes list concatenation 45 46 CHAPTER 7.
Reference: [Jtr93] <author> Niels Jtrgensen. </author> <title> Chaotic fixpoint iteration guided by dynamic dependency. </title> <editor> In Cousot et al. </editor> <booktitle> [CFFR93], </booktitle> <pages> pages 27-44. BIBLIOGRAPHY 69 </pages>
Reference-contexts: OPTIMIZATIONS BASED ON PROPERTIES OF FUNCTIONS 41 where Seen 0 = S 0 Seen n+1 = Seen n [ N [E] n n+1 Seen thus accumulates neededness information. Example 6.2 An instantiation of the above scheme can be found in <ref> [Jtr93] </ref> which maintains a distinction between the different ways in which a Prolog predicate can be called (the running example is groundness analysis). The dynamics of algorithm is due to the following definition.
Reference: [Jtr94] <author> Niels Jtrgensen. </author> <title> Finding fixpoints in finite function spaces using needed-ness analysis and chaotic iteration. </title> <booktitle> In Le Charlier [LC94], </booktitle> <pages> pages 329-345. </pages>
Reference-contexts: The goal is now to find a function P roject such that P roject () is as small as possible. 6.6.2 The Denotational Approach The papers by Rosendahl [Ros93] and Jtrgensen <ref> [Jtr94] </ref> approach the problem of finding fixpoints of functionals from a denotational semantics perspective.
Reference: [JS94] <author> Gerda Janssens and Wim Simoens. </author> <title> On the implementation of A.I systems for (constraint) logic programs. </title> <booktitle> In Fritzson [Fri94], </booktitle> <pages> pages 27-44. </pages>
Reference: [Kle52] <author> Stephen C. Kleene. </author> <title> Introduction to Metamathematics. </title> <address> D. </address> <publisher> van Nostrand, </publisher> <address> Princeton, New Jersey, </address> <year> 1952. </year>
Reference-contexts: 1 ; : : : ; y m there exists a function S m n such that x 1 ; : : : ; x n :(y 1 ; : : : ; y m ; x 1 ; : : : ; x n ) := S m Proof. <ref> [Kle52] </ref>, Theorem XXIII (Kleene's s m n theorem). Recursive definitions are defined in [Kle52], x43. <p> m n such that x 1 ; : : : ; x n :(y 1 ; : : : ; y m ; x 1 ; : : : ; x n ) := S m Proof. <ref> [Kle52] </ref>, Theorem XXIII (Kleene's s m n theorem). Recursive definitions are defined in [Kle52], x43.
Reference: [Las87] <editor> Jean-Louis Lassez, editor. </editor> <booktitle> Fourth International Conference of Logic Programming, ICLP '87, </booktitle> <address> Melbourne, May 1987. </address> <publisher> MIT Press. </publisher>
Reference: [LC94] <editor> Baudouin Le Charlier, editor. </editor> <booktitle> First International Static Analysis Symposium, SAS '94, volume 864 of Lecture Notes in Computer Science, </booktitle> <address> Namur, Belgium, </address> <month> September </month> <year> 1994. </year> <note> Springer-Verlag. </note>
Reference: [LCDMVH93] <author> Baudouin Le Charlier, Olivier Degimbe, Laurent Michel, and Pascal Van Hentenryck. </author> <title> Optimization techniques for general purpose fixpoint algorithms. Practical efficiency for the abstract interpretation of Prolog. </title> <editor> In Cousot et al. </editor> <booktitle> [CFFR93], </booktitle> <pages> pages 15-26. </pages>
Reference-contexts: Note that phi may trigger sub-simulations and extend dependency graphs. In <ref> [LCDMVH93] </ref> an instance of the above universal top-down algorithm for Prolog along with caching of operations is described. Optimizations Chen [Che94] expresses an analysis problem as the least fixpoint of an abstract semantic functional over abstract domains.
Reference: [LCVH92] <author> Baudouin Le Charlier and Pascal Van Hentenryck. </author> <title> A universal top-down fixpoint algorithm. </title> <type> Technical Report 25, </type> <institution> Brown University Computer Science, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: An equation is stable, if an evaluation of the function does not lead to a new value. Granularity Le Charlier and Van Hentenryck introduce the following terminology concerning granularity for comparing static program analysis frameworks. The granularity is finer, if more program points are considered; coarser otherwise <ref> [LCVH92] </ref>. By analogy with partial evaluation, the granularity is polyvariant, if the analysis deals with multiple abstract descriptions for each object in the program depending on the context in which these objects are used and monovariant, when only one abstract description for each object in the program is considered. <p> of functional equations. f i (x 1 ; : : : ; x k ) = E i (f 1 ; : : : ; f n ; x 1 ; : : : ; x k ); 1 j n 6.6.1 The Operational Approach Le Charlier and Van Hentenryck <ref> [LCVH92] </ref> describe a universal algorithm which finds the local least fixpoint of a monotone functional on a noetherian CPO. The actual computation is top-down in the sense that it is viewed as a generalization of computing the values of a function from its recursive definition. <p> The main difference compared to <ref> [LCVH92] </ref> is that the neededness analysis of Jtrgen-sen's algorithm is more shallow, i.e. it cares only about direct needs, whereas the algorithm in [LCVH92] also deals with indirect needs by performing a transitive closure operation. <p> The main difference compared to <ref> [LCVH92] </ref> is that the neededness analysis of Jtrgen-sen's algorithm is more shallow, i.e. it cares only about direct needs, whereas the algorithm in [LCVH92] also deals with indirect needs by performing a transitive closure operation. <p> Jtrgensen's algorithm is also more iterative as each iteration corresponds to the processing of a single element 2 D k , during which all needs need are treated by look-ups in the table holding the previous fixpoint approximation, whereas the "depth-first" strategy of <ref> [LCVH92] </ref> sometimes suspends the processing of an element in order to improve the approximating value for a need. <p> global fixpoint, it should be less expensive to find a local fixpoint, i.e. a functional fixpoint only defined for a subset of the domain 8 2 S 0 : = (E [E]) where S 0 2 D k is the set of tuples for which fixpoint values are sought (cf. <ref> [LCVH92] </ref>). The idea is to select tuples from the workset according to the following scheme n+1 2 W n " Seen n 6.7.
Reference: [Llo87] <author> John W. Lloyd. </author> <title> Foundations of Logic Programming. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <note> second, extended edition edition, </note> <year> 1987. </year>
Reference-contexts: The material is well-known and the presentation relies heavily on Chapters 1-4 of [DP90] and, to some extent, on Chapter 1 of <ref> [Llo87] </ref>. Further information can be found in [DP90], which is a modern textbook, or in the more advanced treatment [Gra78]. 3.1 Ordered Sets In lattice theory the first objective is to impose a certain structure on sets. <p> Theorem 3.7 (Tarski) If hL; vi is a complete lattice and : L ! L is a monotone map, then has a least fixpoint () = fx j (x) = xg = fx j (x) v xg. Proof. <ref> [Llo87] </ref>. Let G = fx 2 L j (x) v xg, g = G, and, similarly, let G 0 = fix () = fx 2 L j (x) = xg and g 0 = G 0 . As hL; vi is a complete lattice, both g and g 0 exists.
Reference: [MJ81] <author> Steven S. Muchnik and Neil D. Jones. </author> <title> Program Flow Analysis: Theory and Applications. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1981. </year>
Reference-contexts: Fixpoint Computations in Static Program Analysis 21 Chapter 5 Program Analysis The purpose of this chapter is to establish the connection between (static) program analysis and the computation of fixpoints, and to introduce the analysis framework for AKL. 1 Good introductions to static program analysis and analysis of AKL are <ref> [MJ81] </ref> and [SS95], respectively. 5.1 Basic Concepts Program analysis is a way of extracting semantic information from a program; static program analysis is a method for discovering (approximate) global properties of the run-time behaviour of a program on arbitrary input data without actually running it, whereas dynamic program analysis is a
Reference: [Nil92] <author> Ulf Nilsson. </author> <title> Abstract Interpretations & Abstract Machines. </title> <type> PhD thesis, </type> <institution> Linkoping University, </institution> <year> 1992. </year>
Reference-contexts: In recent years, however, more effort has been put into research in the area and this chapter features a survey of fixpoint computations in static program analysis. Chapter six in Nilsson's thesis <ref> [Nil92] </ref> and the paper by Vergauwen et al. [VWL94] are two highly readable accounts of fixpoint computations. 6.1 The Problem In static program analysis, the program properties, program points and program functions add up to give an equation system x = (x) which can be written as x i = i
Reference: [NN92] <author> Hanne Riis Nielson and Flemming Nielson. </author> <title> Bounded fixed-point iteration. </title> <journal> Journal of Logic and Computation, </journal> <volume> 2(4) </volume> <pages> 441-464, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: A SURVEY OF FIXPOINT COMPUTATIONS framework X w k total or monotone A jAj `(B) completely additive fx 2 A j x 2 J (A)g jJ (A)j `(B) iterative scheme fwg `(A) Table 6.1: Iteration bounds for fixpoints of functionals 6.8 Characterization of Frameworks In <ref> [NN92] </ref> Nielson and Nielson conducts a theoretical study of various frameworks for fixpoint computations. To each program the analysis associates an element d of a complete lattice hD; vi of abstract values.
Reference: [NSS94] <author> Esko Nuutila and Eljas Soisalon-Soininen. </author> <title> On finding the strongly connected components in a directed graph. </title> <journal> Information Processing Letters, </journal> <volume> 49(1) </volume> <pages> 9-14, </pages> <year> 1994. </year>
Reference-contexts: fixpoint computations, the method based on a weak topological order (WTO) [Bou92b, Bou93] of the static dependency graph seemed to be the best way of improving the execution speed of the fixpoint solver in the AKL analysis 1 The original idea was first published by Tarjan in [Tar72]; the papers <ref> [NSS94] </ref> and [Jia93] are recent enhancements. 2 The pseudo code loosely resembles Pascal, the modifications being that arguments to functions may be labeled in, out or inout signifying how values of the arguments are passed through the function interface. The symbol :: denotes list concatenation 45 46 CHAPTER 7.
Reference: [O'K87] <author> Richard A. O'Keefe. </author> <title> Finite fixed-point problems. </title> <booktitle> In Lassez [Las87], </booktitle> <pages> pages 729-743. </pages>
Reference-contexts: Finer, polyvariant granularity is likely to giver better results at the price of a higher computation cost compared to coarser, monovariant granularity. Dependencies How are the equations in the equation system related to each other? There are in fact certain dependencies <ref> [O'K87] </ref> between the equations; say that if function i needs the value of function j (j is one of its arguments), then function i depends on function j and function j should perhaps be evaluated before function i. <p> Workstacks One way of choosing functions from a worklist is to see it as a stack. Thus, in a workstack approach, the functions are added to and removed from the worklist in a LIFO-manner, i.e. pushed and popped, until the stack is empty <ref> [O'K87] </ref>. <p> The solving of the corresponding equations system is different in that the goal is to find the fixpoint of a monotone functional instead of the fixpoint of a function. The main idea is to use a dependency relation in the style of <ref> [O'K87] </ref> and to transfer it from an ordinary system of equations to the more expressive system of functional equations. f i (x 1 ; : : : ; x k ) = E i (f 1 ; : : : ; f n ; x 1 ; : : : ;
Reference: [Ros93] <author> Mads Rosendahl. </author> <title> Higher-order chaotic iteration sequences. </title> <booktitle> In Bruynooghe and Penjam [BP93], </booktitle> <pages> pages 332-345. </pages>
Reference-contexts: ITERATION STRATEGIES 31 The search space should be kept small, as variables which were added to S may cease to be needed, but can still cause further, useless expansions of the search space. Such variables (or, in some cases, calls) are called spurious <ref> [Ros93] </ref>. To keep the search space small, the procedure U pdate should be given priority over Expand. <p> The goal is now to find a function P roject such that P roject () is as small as possible. 6.6.2 The Denotational Approach The papers by Rosendahl <ref> [Ros93] </ref> and Jtrgensen [Jtr94] approach the problem of finding fixpoints of functionals from a denotational semantics perspective.
Reference: [Sah90] <author> Dan Sahlin. </author> <title> Finding the least fixed point using wait-declarations in Pro-log. </title> <booktitle> In Deransart and Ma luszynski [DM90], </booktitle> <pages> pages 332-345. </pages>
Reference-contexts: Now, the vertices in a strongly connected subgraph of type lub can be collapsed into a single vertex, as they will all get the same value [SS93]. * Incremental computation on totally ordered domains. The method in <ref> [Sah90] </ref> essentially uses the old value of a vertex when computing the new value, instead of computing every new value from scratch. This is possible when the domain is a chain and the functions are monotone. <p> Recursive definitions are defined in [Kle52], x43. Starting from this theorem the goal is to investigate the functions S m n (E; y 1 ; : : : ; y m ) which are computationally inexpensive. 8.1 Argument-change dependence An idea of Sahlin <ref> [Sah90] </ref> is to compute a function incrementally, which means that the old value of a function is used when computing a new function value. A slightly different viewpoint is to see the new function value as depending on the changes in its arguments since the last evaluation.
Reference: [Sar93] <author> Vijay A. Saraswat. </author> <title> Concurrent Constraint Programming. Logic Programming and Doctoral Dissertation Award. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1993. </year>
Reference: [SS86] <author> Leon Sterling and Ehud Shapiro. </author> <title> The Art of Prolog. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1986. </year> <note> 70 BIBLIOGRAPHY </note>
Reference: [SS93] <author> Dan Sahlin and Thomas Sjoland. </author> <title> Towards an analysis tool for AKL. </title> <booktitle> Deliverable number D.WP.1.6.1.M1 of the ESPRIT project ParForce 6707, </booktitle> <address> ftp://ftp.sics.se/www/ps/parforce/deliverables/D.WP.1.6.1.M1.ps.Z, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Applied to a sequence of vertices, it works by computing the equations represented by the vertices in the order given, repeating this procedure until every equation in the sequence is stable. Optimizations In order to classify various optimizations Sahlin and Sjoland <ref> [SS93] </ref> have introduced the following terminology. Optimizations which guarantee an improvement are algorithmic; those giving an improvement in practice are heuristic. <p> When choosing between two vertices, the youngest (the one which has been evaluated a smaller number of times of the two) should be evaluated first. This captures the requirement of "fairness" in chaotic iteration strategies; that no equation should be forgotten indefinitely <ref> [SS93] </ref>. In Figure 6.1 this means that the order of evaluation should be 1; 2; 3; 4. * Depth first. Perform a depth first traversal of the spanning tree of the SCC [SS93]. <p> This captures the requirement of "fairness" in chaotic iteration strategies; that no equation should be forgotten indefinitely <ref> [SS93] </ref>. In Figure 6.1 this means that the order of evaluation should be 1; 2; 3; 4. * Depth first. Perform a depth first traversal of the spanning tree of the SCC [SS93]. The vertices in Figure 6.2 should then be visited in the order 1; 2; 4; 5; 3. * Direct dependency. If vertices A and B are put on the workstack for reevaluation and B depends on A, then A should be visited first [SS93]. <p> the spanning tree of the SCC <ref> [SS93] </ref>. The vertices in Figure 6.2 should then be visited in the order 1; 2; 4; 5; 3. * Direct dependency. If vertices A and B are put on the workstack for reevaluation and B depends on A, then A should be visited first [SS93]. In Figure 6.2 the vertices should be visited in the order: 1; 2; 5 ; 4; 3, whereas in Figure 6.3 the visiting sequence should be 1; 2 ; 3; 4; 5. * Indirect dependency. <p> If vertices A and B need to be evaluated and the paths from A to B do not contain vertices in need of evaluation, then vertex A should be visited first <ref> [SS93] </ref>. * Prefer global effects. The vertex with the largest number of edges should be chosen first [SS93]. Weak Topological Orders The concept of a weak topological order is a generalization of a topological order of a directed graph possibly containing cycles. <p> If vertices A and B need to be evaluated and the paths from A to B do not contain vertices in need of evaluation, then vertex A should be visited first <ref> [SS93] </ref>. * Prefer global effects. The vertex with the largest number of edges should be chosen first [SS93]. Weak Topological Orders The concept of a weak topological order is a generalization of a topological order of a directed graph possibly containing cycles. <p> For an associative, commutative and idempotent operator, all duplicate arguments may be removed, leading to a shorter evaluation time <ref> [SS93] </ref>. * Simplifying single equations. The lub-function has certain nice properties, facili tating simplification [SS93]. <p> For an associative, commutative and idempotent operator, all duplicate arguments may be removed, leading to a shorter evaluation time <ref> [SS93] </ref>. * Simplifying single equations. The lub-function has certain nice properties, facili tating simplification [SS93]. <p> Now, the vertices in a strongly connected subgraph of type lub can be collapsed into a single vertex, as they will all get the same value <ref> [SS93] </ref>. * Incremental computation on totally ordered domains. The method in [Sah90] essentially uses the old value of a vertex when computing the new value, instead of computing every new value from scratch. This is possible when the domain is a chain and the functions are monotone.
Reference: [SS95] <author> Thomas Sjoland and Dan Sahlin. </author> <title> Fixpoint analysis of type and alias in AKL programs. </title> <institution> SICS Research Report R94:13b, ftp://ftp.sics.se/pub/SICS-reports/Reports/SICS-R-94-13b- -SE.ps.Z, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: GRAPH THEORY l l l l - ? ? fl l l l l @ @R 6 - @ @R 1 5 9 A chain in a directed graph <ref> [SS95] </ref> consists of sequence of connected vertices, where each vertex has only one in-going and one outgoing edge, with the exception of the starting vertex which may have several in-going edges, and the end vertex which may have several outgoing edges. <p> in Static Program Analysis 21 Chapter 5 Program Analysis The purpose of this chapter is to establish the connection between (static) program analysis and the computation of fixpoints, and to introduce the analysis framework for AKL. 1 Good introductions to static program analysis and analysis of AKL are [MJ81] and <ref> [SS95] </ref>, respectively. 5.1 Basic Concepts Program analysis is a way of extracting semantic information from a program; static program analysis is a method for discovering (approximate) global properties of the run-time behaviour of a program on arbitrary input data without actually running it, whereas dynamic program analysis is a way of <p> project the infinite concrete domain of the original program onto a finite abstract domain, where it is possible to execute the program completely; the guarantee that this approximation is correct is then given by abstract interpretation based on the Galois connection. 5.4 Analysis of AKL The purpose of analyzing AKL <ref> [SS95] </ref> is to provide the compiler with information which facilitates optimization of guard computations, leading to faster program execution and less memory consumption. 4 The analyzer provides the compiler with: * Alias information: two variables are definitely not aliased at program point i * Type information: a variable has type T <p> Then use a workstack, except when the value of the first vertex in a chain has changed; then all the vertices in the chain should be recomputed. This is an algorithmic optimization used in the AKL analysis framework <ref> [SS95] </ref>. 34 CHAPTER 6. A SURVEY OF FIXPOINT COMPUTATIONS k l ? - 6 2 3 * Reverse postorder. Perform a reverse postorder traversal [HDT87]. * Reverse postorder and worklist. The vertices are picked in reverse postorder from the worklist [HDT87].
Reference: [Sto77] <author> Joseph E. Stoy. </author> <title> Denotational Semantics: The Scott-Strachey Approach to Programming Language Theory. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1977. </year>
Reference-contexts: produces one sequence of states the data and control pass through, static program analysis produces a static semantics defined as follows: for each control point in the program, a finite description of the set of 1 Appendix A gives a brief introduction to the Agents Kernel Language (AKL). 2 See <ref> [Sto77] </ref> for a textbook on semantics in general and denotational semantics in particular. 23 24 CHAPTER 5. PROGRAM ANALYSIS data states the program could be in when any conceivable execution passes through that point, is given.
Reference: [Tar72] <author> Robert E. Tarjan. </author> <title> Depth-first search and linear graph algorithms. </title> <journal> SIAM Journal of Computing, </journal> <volume> 1(2) </volume> <pages> 146-160, </pages> <month> June </month> <year> 1972. </year>
Reference-contexts: the field of fixpoint computations, the method based on a weak topological order (WTO) [Bou92b, Bou93] of the static dependency graph seemed to be the best way of improving the execution speed of the fixpoint solver in the AKL analysis 1 The original idea was first published by Tarjan in <ref> [Tar72] </ref>; the papers [NSS94] and [Jia93] are recent enhancements. 2 The pseudo code loosely resembles Pascal, the modifications being that arguments to functions may be labeled in, out or inout signifying how values of the arguments are passed through the function interface.
Reference: [VWL94] <author> B. Vergauwen, J. Wauman, and J. Lewi. </author> <title> Efficient fixpoint computation. </title> <booktitle> In Le Charlier [LC94], </booktitle> <pages> pages 314-328. </pages>
Reference-contexts: In recent years, however, more effort has been put into research in the area and this chapter features a survey of fixpoint computations in static program analysis. Chapter six in Nilsson's thesis [Nil92] and the paper by Vergauwen et al. <ref> [VWL94] </ref> are two highly readable accounts of fixpoint computations. 6.1 The Problem In static program analysis, the program properties, program points and program functions add up to give an equation system x = (x) which can be written as x i = i (x 1 ; x 2 ; : : <p> The dependency on a certain domain or on specific properties of functions in the equation system is expressed by saying that the optimizations are either domain (function) dependent or domain (function) independent. 6.3 A Declarative View In order to illustrate the above concepts, this section follows <ref> [VWL94] </ref> in giving a declarative view on how to solve the problem.
Reference: [Zus91] <author> Horst Zuse. </author> <title> Software Complexity: Measures and Methods. </title> <publisher> de Gruyter, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: Given a static program analysis and the resulting equation system, the weak topological order of the dependency graph can be used as a way of automatically measuring the complexity (or, perhaps better, the degree of intricacy) of a program statically <ref> [Zus91] </ref>. This measure should then be based on the intrinsic complexity of the graph, as given by the weak topological order, e.g. as (max depth) edges, or, as the sum of the mean values of depth edges in every strongly connected component.
References-found: 49

