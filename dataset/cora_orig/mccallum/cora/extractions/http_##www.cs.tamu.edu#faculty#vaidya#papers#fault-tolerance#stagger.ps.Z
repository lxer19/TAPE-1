URL: http://www.cs.tamu.edu/faculty/vaidya/papers/fault-tolerance/stagger.ps.Z
Refering-URL: http://www.cs.tamu.edu/faculty/vaidya/Vaidya-ftc.html
Root-URL: http://www.cs.tamu.edu
Title: Staggered Consistent Checkpointing  
Author: Nitin H. Vaidya 
Keyword: Key words: Staggered checkpoints, consistent recovery line, rollback recovery, stable storage contention, fault tolerance.  
Note: This research is supported in part by National Science Foundation grant MIP-9502563 and Texas Ad vanced Technology Program grant 009741-052-C. To be presented in part at the IEEE Symposium on Parallel and Distributed Processing (SPDP),  1996, New Orleans.  
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Email: E-mail: vaidya@cs.tamu.edu  
Phone: Phone: 409-845-0512 Fax: 409-847-8578  
Web: Web: http://www.cs.tamu.edu/faculty/vaidya  
Date: September 17, 1996  October  
Abstract: A consistent checkpointing algorithm saves a consistent view of a distributed application's state on stable storage. The traditional consistent checkpointing algorithms require different processes to save their state at about the same time. This causes contention for the stable storage, potentially resulting in large overheads. Staggering the checkpoints taken by various processes can reduce checkpoint overhead [13]. This paper presents a simple approach to arbitrarily stagger the checkpoints. Our approach requires that the processes take consistent logical checkpoints, as compared to consistent physical checkpoints enforced by existing algorithms. Experimental results on nCube-2 are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Cabillic, G. Muller, and I. Puaut, </author> <title> "The performance of consistent checkpointing in distributed shared memory systems," </title> <booktitle> in Int. Symp. Reliable Distr. Systems (SRDS), </booktitle> <pages> pp. 96-105, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency.
Reference: [2] <author> K. M. Chandy and L. Lamport, </author> <title> "Distributed snapshots: Determining global states in distributed systems," </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> vol. 3, </volume> <pages> pp. 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency. <p> The paper is organized as follows. Section 2 discusses the related work. Section 3 discusses the notion of a logical checkpoint. Section 4 presents consistent checkpointing algorithms proposed by Chandy and Lamport <ref> [2] </ref> and Plank [13]. Section 5 presents the proposed algorithm. Section 6 presents experimental results. Some variations of the proposed scheme are discussed in Section 7. <p> Section 8 summarizes the paper. 2 Related Work Plank [13] was the first to observe that stable storage contention can be a problem for consistent checkpointing, and suggested checkpoint staggering as a solution. The degree of staggering with Plank's algorithm (based on the Chandy-Lamport algorithm <ref> [2] </ref>) is limited in that checkpoints of many processes are not staggered. In contrast, our algorithm allows arbitrary and controlled staggering of checkpoints. Plank [13] also presents another approach for staggering checkpoints, that is applicable to wormhole routed networks. This algorithm also does not permit arbitrary/controlled staggering. <p> We summarize this approach as: anti-message log + physical checkpoint = logical checkpoint The anti-messages can possibly be formed by the application itself, or they may consist of a copy of the (old) process state modified by the message (similar to copy-on-write [10]). 4 Chandy-Lamport Algorithm <ref> [2] </ref> Chandy and Lamport [2] presented an algorithm for taking a consistent checkpoint of a distributed system. Assume that the processes communicate with each other using first-in-first-out (FIFO) unidirectional communication channels; a bidirectional channel can be modeled as two unidirectional channels. <p> We summarize this approach as: anti-message log + physical checkpoint = logical checkpoint The anti-messages can possibly be formed by the application itself, or they may consist of a copy of the (old) process state modified by the message (similar to copy-on-write [10]). 4 Chandy-Lamport Algorithm <ref> [2] </ref> Chandy and Lamport [2] presented an algorithm for taking a consistent checkpoint of a distributed system. Assume that the processes communicate with each other using first-in-first-out (FIFO) unidirectional communication channels; a bidirectional channel can be modeled as two unidirectional channels. <p> For simplicity, we assume that the communication graph is fully connected. 2 The algorithm presented next is essentially identical to 2 Note that Chandy-Lamport algorithm is applicable to any strongly connected graph. Our algorithm can also be generalized to strongly connected graphs. 7 Chandy-Lamport <ref> [2, 13] </ref> and assumes that a certain process (named P 0 ) is designated as the checkpoint coordinator. <p> Messages M4 and M5 are also logged during the second phase (as they represent the channel state). Message M6 is not logged. Proof of correctness: The correctness follows directly from the proof of correctness of the Chandy-Lamport algorithm <ref> [2] </ref>. Recovery: After a failure, each process rolls back to its recent physical checkpoint and re-executes (using the logged messages) to restore the process state to the logical checkpoint that belongs to the most recent consistent recovery line.
Reference: [3] <author> C. J. Date, </author> <title> An Introduction to Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: For each relevant message (whose effect must be undone), an anti-message is saved on the stable storage. The notion of an anti-message here is similar to that used in time warp mechanism [7] or that of UNDO records <ref> [3] </ref> in database systems. Anti-message M fl corresponding to a message M can be used to undo the state change caused by message M. at time t 1 . Process P delivers messages M4 and M5 between time t 1 and t 2 .
Reference: [4] <author> E. N. Elnozahy, D. B. Johnson, and W. Zwaenepoel, </author> <title> "The performance of consistent checkpointing," </title> <booktitle> in Symposium on Reliable Distributed Systems, </booktitle> <year> 1992. </year> <month> 20 </month>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency.
Reference: [5] <author> E. N. Elnozahy and W. Zwaenepoel, "Manetho: </author> <title> Transparent rollback-recovery with low overhead, limited rollback, and fast output commit," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 41, </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency.
Reference: [6] <author> J. Fowler and W. Zwaenepoel, </author> <title> "Causal distributed breakpoints," </title> <booktitle> in International Conf. Distributed Computing Systems, </booktitle> <pages> pp. 134-141, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: In contrast, our algorithm allows arbitrary and controlled staggering of checkpoints. Plank [13] also presents another approach for staggering checkpoints, that is applicable to wormhole routed networks. This algorithm also does not permit arbitrary/controlled staggering. Fowler and Zwaenepoel <ref> [6] </ref> present an algorithm for determining causal breakpoints (for the purpose of debugging). As a part of the breakpoint algorithm, they establish consistent recovery lines using an algorithm similar to ours. Our approach can be considered to be a modification of the algorithm in [6] to facilitate checkpoint staggering. <p> Fowler and Zwaenepoel <ref> [6] </ref> present an algorithm for determining causal breakpoints (for the purpose of debugging). As a part of the breakpoint algorithm, they establish consistent recovery lines using an algorithm similar to ours. Our approach can be considered to be a modification of the algorithm in [6] to facilitate checkpoint staggering. Because the algorithm in [6] was designed for debugging purposes, various possibilities for checkpoint staggering, and different approaches for establishing checkpoints were not considered. Long et al. [11] discuss an evolutionary checkpointing approach, that is similar to logical checkpointing. <p> As a part of the breakpoint algorithm, they establish consistent recovery lines using an algorithm similar to ours. Our approach can be considered to be a modification of the algorithm in <ref> [6] </ref> to facilitate checkpoint staggering. Because the algorithm in [6] was designed for debugging purposes, various possibilities for checkpoint staggering, and different approaches for establishing checkpoints were not considered. Long et al. [11] discuss an evolutionary checkpointing approach, that is similar to logical checkpointing. <p> Checkpoint size for each process is approximately 1.85 Mbyte. For this application, the overhead of STAGGER is larger than that of CL/P. The performance of STAGGER can be improved by reducing the amount of information logged, using an optimization similar to that in <ref> [6] </ref>.
Reference: [7] <author> D. Jefferson, </author> <title> "Virtual time," </title> <journal> ACM Trans. Prog. Lang. Syst., </journal> <volume> vol. 3, </volume> <pages> pp. 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: For each relevant message (whose effect must be undone), an anti-message is saved on the stable storage. The notion of an anti-message here is similar to that used in time warp mechanism <ref> [7] </ref> or that of UNDO records [3] in database systems. Anti-message M fl corresponding to a message M can be used to undo the state change caused by message M. at time t 1 . Process P delivers messages M4 and M5 between time t 1 and t 2 .
Reference: [8] <author> D. B. Johnson, </author> <title> Distributed System Fault Tolerance Using Message Logging and Check-pointing. </title> <type> PhD thesis, </type> <institution> Computer Science, Rice University, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency. <p> This recovery line is used to recover from the failure. Their goal is to determine the "latest" consistent recovery line using the information saved on the stable storage. Message logging and independent checkpointing schemes, such as <ref> [8] </ref>, also, effectively, determine a recovery line consisting of consistent logical checkpoints after a failure occurs. In these schemes, during failure-free operation, each process is allowed to independently take checkpoints and log messages. On the other hand, our scheme coordinates logical checkpoints before a failure occurs. <p> Therefore, techniques such as staggering are of interest even though they may result in greater checkpoint latency. 3 A Logical Checkpoint A process is said to be deterministic if its state depends only on its initial state and the messages delivered to it <ref> [8, 14] </ref>. A deterministic process can take two types of checkpoints: a physical checkpoint or a logical checkpoint. A process is said to have taken a physical checkpoint at some time t 1 , if the process state at time t 1 is available on the stable storage.
Reference: [9] <author> S. Kaul, </author> <title> "Evaluation of consistent logical checkpointing." M.S. </title> <type> Thesis, </type> <institution> Dept. of Computer Science, Texas A&M University, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: To achieve this we partition the processes into clusters, the number of clusters being identical to the number of stable storages. Each cluster is associated with a unique stable storage; processes within a cluster access only the associated stable storage <ref> [9] </ref>. 17 The algorithm STAGGER, modified to use multiple stable storages, differs from the original STAGGER algorithm only in the first phase (i.e., staggered checkpointing phase). We illustrate the modified staggered checkpointing phase with an example. Consider a system consisting of 6 processes, and 2 stable storages.
Reference: [10] <author> K. Li, J. F. Naughton, and J. S. Plank, </author> <title> "Low-latency, concurrent checkpointing for parallel programs," </title> <journal> IEEE Trans. Par. Distr. Syst., </journal> <volume> vol. 5, </volume> <pages> pp. 874-879, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: We summarize this approach as: anti-message log + physical checkpoint = logical checkpoint The anti-messages can possibly be formed by the application itself, or they may consist of a copy of the (old) process state modified by the message (similar to copy-on-write <ref> [10] </ref>). 4 Chandy-Lamport Algorithm [2] Chandy and Lamport [2] presented an algorithm for taking a consistent checkpoint of a distributed system. Assume that the processes communicate with each other using first-in-first-out (FIFO) unidirectional communication channels; a bidirectional channel can be modeled as two unidirectional channels.
Reference: [11] <author> J. Long, B. Janssens, and W. K. Fuchs, </author> <title> "An evolutionary approach to concurrent checkpointing," </title> <type> manuscript, </type> <year> 1994. </year>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency. <p> Our approach can be considered to be a modification of the algorithm in [6] to facilitate checkpoint staggering. Because the algorithm in [6] was designed for debugging purposes, various possibilities for checkpoint staggering, and different approaches for establishing checkpoints were not considered. Long et al. <ref> [11] </ref> discuss an evolutionary checkpointing approach, that is similar to logical checkpointing. Our algorithm staggers the checkpoints, while the scheme in [11] does not allow staggering. [11] also assumes synchronized communication and an upper bound 3 on communication delays; no such assumptions are made in the proposed scheme. <p> Because the algorithm in [6] was designed for debugging purposes, various possibilities for checkpoint staggering, and different approaches for establishing checkpoints were not considered. Long et al. <ref> [11] </ref> discuss an evolutionary checkpointing approach, that is similar to logical checkpointing. Our algorithm staggers the checkpoints, while the scheme in [11] does not allow staggering. [11] also assumes synchronized communication and an upper bound 3 on communication delays; no such assumptions are made in the proposed scheme. Wang et al. [18] introduced the term logical checkpoint. <p> Long et al. <ref> [11] </ref> discuss an evolutionary checkpointing approach, that is similar to logical checkpointing. Our algorithm staggers the checkpoints, while the scheme in [11] does not allow staggering. [11] also assumes synchronized communication and an upper bound 3 on communication delays; no such assumptions are made in the proposed scheme. Wang et al. [18] introduced the term logical checkpoint. They present an algorithm to determine a recovery line consisting of consistent logical checkpoints, after a failure occurs. <p> Therefore, it will often be desirable to take a physical checkpoint first (possibly an incremental checkpoint), followed by an incremental logical checkpoint. The evolutionary checkpointing scheme by Long et al. <ref> [11] </ref> also takes incremental checkpoints similar to the above procedure. Approach 3: The above two approaches take a physical checkpoint prior to the desired logical checkpoint, followed by logging of additional information (either messages or incremental state change). The third approach is the converse of the above two approaches.
Reference: [12] <author> J. S. Plank, M. Beck, G. Kingsley, and K. Li, "Libckpt: </author> <title> Transparent checkpointing under Unix," </title> <booktitle> in Usenix Winter 1995 Technical Conference, </booktitle> <address> New Orleans, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: A physical checkpoint is trivially a logical checkpoint, however, the converse is not true. Physical checkpoint itself can be taken in two different ways: One possibility is to save the entire process state on the stable storage. The second possibility is to take an incremental checkpoint <ref> [12] </ref>. (That is, only the difference between the current state and the state at the previous physical checkpoint needs to be saved.) We will return to incremental 4 checkpointing soon again. Now we summarize three approaches for taking a logical checkpoint at time t 1 .
Reference: [13] <author> J. S. Plank, </author> <title> Efficient Checkpointing on MIMD Architectures. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Princeton University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency. <p> Staggering the checkpoints taken by various processes can reduce the overhead of consistent checkpointing by reducing stable storage contention, as observed by Plank <ref> [13] </ref>. Plank proposed some techniques for staggering the checkpoints [13], however, these techniques result in "limited" staggering in that not all processes' checkpoints can be staggered. Moreover, the previous algorithms do not have much control on which checkpoints are staggered. <p> Staggering the checkpoints taken by various processes can reduce the overhead of consistent checkpointing by reducing stable storage contention, as observed by Plank <ref> [13] </ref>. Plank proposed some techniques for staggering the checkpoints [13], however, these techniques result in "limited" staggering in that not all processes' checkpoints can be staggered. Moreover, the previous algorithms do not have much control on which checkpoints are staggered. <p> The paper is organized as follows. Section 2 discusses the related work. Section 3 discusses the notion of a logical checkpoint. Section 4 presents consistent checkpointing algorithms proposed by Chandy and Lamport [2] and Plank <ref> [13] </ref>. Section 5 presents the proposed algorithm. Section 6 presents experimental results. Some variations of the proposed scheme are discussed in Section 7. Section 8 summarizes the paper. 2 Related Work Plank [13] was the first to observe that stable storage contention can be a problem for consistent checkpointing, and suggested <p> Section 4 presents consistent checkpointing algorithms proposed by Chandy and Lamport [2] and Plank <ref> [13] </ref>. Section 5 presents the proposed algorithm. Section 6 presents experimental results. Some variations of the proposed scheme are discussed in Section 7. Section 8 summarizes the paper. 2 Related Work Plank [13] was the first to observe that stable storage contention can be a problem for consistent checkpointing, and suggested checkpoint staggering as a solution. The degree of staggering with Plank's algorithm (based on the Chandy-Lamport algorithm [2]) is limited in that checkpoints of many processes are not staggered. <p> The degree of staggering with Plank's algorithm (based on the Chandy-Lamport algorithm [2]) is limited in that checkpoints of many processes are not staggered. In contrast, our algorithm allows arbitrary and controlled staggering of checkpoints. Plank <ref> [13] </ref> also presents another approach for staggering checkpoints, that is applicable to wormhole routed networks. This algorithm also does not permit arbitrary/controlled staggering. Fowler and Zwaenepoel [6] present an algorithm for determining causal breakpoints (for the purpose of debugging). <p> For simplicity, we assume that the communication graph is fully connected. 2 The algorithm presented next is essentially identical to 2 Note that Chandy-Lamport algorithm is applicable to any strongly connected graph. Our algorithm can also be generalized to strongly connected graphs. 7 Chandy-Lamport <ref> [2, 13] </ref> and assumes that a certain process (named P 0 ) is designated as the checkpoint coordinator. <p> Q records the state of channel c as being empty. end else Q records the state of channel c as the sequence of messages received along c, after Q had taken a checkpoint and before Q received the marker along c. 4.1 Plank's Staggering Scheme Plank <ref> [13] </ref> suggested that the processes should send markers after taking their checkpoints, rather than before taking the checkpoint (unlike the algorithm above). This simple modification introduces some staggering of checkpoints. However, not all checkpoints can be staggered. In our experiments, we use the Chandy-Lamport algorithm that incorporates Plank's modification. <p> This simple modification introduces some staggering of checkpoints. However, not all checkpoints can be staggered. In our experiments, we use the Chandy-Lamport algorithm that incorporates Plank's modification. In the rest of this paper, this modified algorithm will be referred to as Chandy-Lamport/Plank algorithm, or CL/P for brevity. Observations: Plank <ref> [13] </ref> observed that his staggering scheme works better than the original "non-staggered" algorithm when (i) degree of synchronization (or communication) amongst the processes is relatively small, and (ii) the message volume is relatively small (message volume is the amount of information communicated by messages). <p> In Figure 5, the horizontal axis indicates degree of synchronization in an application, and the vertical 8 axis indicates the message volume. As shown in the figure, when synchronization is very frequent and/or message volume is large, it is better to avoid staggering checkpoints <ref> [13] </ref>. Extrapolating Plank's results, it follows that, the region where a given staggering algorithm works best shrinks with the degree of staggering. Greater staggering is beneficial for applications with less synchronization and small message volume. This paper does not alter the above conclusions. <p> Greater staggering is beneficial for applications with less synchronization and small message volume. This paper does not alter the above conclusions. Our work provides an user the ability to choose the degree of staggering. Our approach can achieve completely controlled staggering of checkpoints, unlike Plank <ref> [13] </ref>. 5 Staggered Consistent Checkpointing The extent of checkpoint staggering using CL/P algorithm is dependent on the application's communication pattern, and also on how the algorithm is implemented (e.g., whether the markers are sent asynchronously or not). <p> Therefore, process 0 sends asynchronous markers. We will return to the issue of using asynchronous markers later in Section 7. The first application used for evaluation of STAGGER is a synthetic program, named sync-loop, similar to a program used by Plank <ref> [13] </ref>. The pseudo-code for the program is presented below using a C-like syntax. sync-loop (iter, size, M) - char state [size]; initialize (state); repeat (iter) times - perform M floating-point multiplications; synchronize with all other processes; - Process state size (and checkpoint size) is controlled by the size parameter. <p> Which markers (if any) are sent asynchronously can affect performance of STAGGER and CL/P algorithms. As noted previously, in our implementation, markers sent by process 0 are asynchronous, other markers are synchronous. Plank <ref> [13] </ref> does not address the distinction between asynchronous and synchronous markers.
Reference: [14] <author> R. E. Strom and S. A. Yemini, </author> <title> "Optimistic recovery: An asynchronous approach to fault-tolerance in distributed systems," </title> <booktitle> Digest of papers: The 14 th Int. Symp. Fault-Tolerant Comp., </booktitle> <pages> pp. 374-379, </pages> <year> 1984. </year>
Reference-contexts: Therefore, techniques such as staggering are of interest even though they may result in greater checkpoint latency. 3 A Logical Checkpoint A process is said to be deterministic if its state depends only on its initial state and the messages delivered to it <ref> [8, 14] </ref>. A deterministic process can take two types of checkpoints: a physical checkpoint or a logical checkpoint. A process is said to have taken a physical checkpoint at some time t 1 , if the process state at time t 1 is available on the stable storage.
Reference: [15] <author> N. H. Vaidya, </author> <booktitle> "On checkpoint letency," in Pacific Rim International Conference on Fault-Tolerant Systems, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: One consequence of this approach is that our scheme does not log all messages; only those messages which make the logical checkpoints consistent are logged. Staggering the checkpoints taken by various processes tends to increase the elapsed time (sometimes called checkpoint "latency" <ref> [15] </ref>) while the checkpointing algorithm is in progress. Our previous work [15] shows that a large increase in checkpoint latency is acceptable if it is accompanied by even a small decrease in checkpoint overhead. <p> Staggering the checkpoints taken by various processes tends to increase the elapsed time (sometimes called checkpoint "latency" <ref> [15] </ref>) while the checkpointing algorithm is in progress. Our previous work [15] shows that a large increase in checkpoint latency is acceptable if it is accompanied by even a small decrease in checkpoint overhead.
Reference: [16] <author> N. H. Vaidya, </author> <title> "On staggered checkpointing," </title> <booktitle> in Eighth IEEE Symposium on Parallel and Distributed Processing (SPDP), </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: On the other hand, the proposed algorithm can stagger the checkpoints in any manner desired. Many variations are possible, depending on which checkpoints are desired to be staggered <ref> [16] </ref>. As an illustration, we assume that the objective is to stagger all checkpoints, i.e., no two checkpoints should overlap in time. Later, we will illustrate a situation where some overlap in checkpointing is desired.
Reference: [17] <author> Y. M. Wang and W. K. Fuchs, </author> <title> "Lazy checkpoint coordination for bounding rollback propagation," </title> <booktitle> in Symposium on Reliable Distributed Systems, </booktitle> <pages> pp. 78-85, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Applications executed on a large number of processors, either in a distributed environment, or on multicomputers such as nCube, are subject to processor failures. Consistent check-pointing is a commonly used technique to prevent complete loss of computation upon a failure <ref> [1, 2, 4, 5, 8, 11, 13, 17] </ref>. A consistent checkpointing algorithm saves a consistent view of a distributed application's state on a stable storage (often, a disk is used as a stable storage). The loss of computation upon a failure is bounded by taking consistent checkpoints with adequate frequency.
Reference: [18] <author> Y. M. Wang, Y. Huang, and W. K. Fuchs, </author> <title> "Progressive retry for software error recovery in distributed systems," </title> <booktitle> in Digest of papers: The 23 rd Int. Symp. Fault-Tolerant Comp., </booktitle> <pages> pp. 138-144, </pages> <year> 1993. </year>
Reference-contexts: Our algorithm staggers the checkpoints, while the scheme in [11] does not allow staggering. [11] also assumes synchronized communication and an upper bound 3 on communication delays; no such assumptions are made in the proposed scheme. Wang et al. <ref> [18] </ref> introduced the term logical checkpoint. They present an algorithm to determine a recovery line consisting of consistent logical checkpoints, after a failure occurs. This recovery line is used to recover from the failure. <p> This approach is essentially identical to that presented by Wang et al. <ref> [18] </ref>. Figure 1 presents an example wherein process P takes a physical checkpoint at time t 0 . Messages M1, M2 and M3 are delivered to process P by time t 1 .
References-found: 18

