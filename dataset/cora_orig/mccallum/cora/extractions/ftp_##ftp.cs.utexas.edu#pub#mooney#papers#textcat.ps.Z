URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/textcat.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: fmooney,pbennettg@cs.utexas.edu  loriene@gslis.utexas.edu  
Title: on Learning for Text Categorization and the AAAI-98 Workshop on Recommender Systems Book Recommending Using
Author: Raymond J. Mooney Paul N. Bennett Loriene Roy 
Address: Austin, TX 78712-1188  Library  Austin, TX 78712-1188  
Affiliation: Department of Computer Sciences University of Texas  Graduate School of  and Information Science University of Texas  
Note: Appears in the AAAI-98/ICML-98 Workshop  
Abstract: Content-based recommender systems suggest documents, items, and services to users based on learning a profile of the user from rated examples containing information about the given items. Text categorization methods are very useful for this task but generally rely on unstructured text. We have developed a book-recommending system that utilizes semi-structured information about items gathered from the web using simple information extraction techniques. Initial experimental results demonstrate that this approach can produce fairly accurate recommendations. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, T., and Finn, J. D. </author> <year> 1996. </year> <title> The New Statistical Analysis of Data. </title> <address> New York: </address> <publisher> Springer-Verlag, Inc. </publisher>
Reference: <author> Balabanovic, M., and Shoham, Y. </author> <year> 1997. </year> <title> Fab: Content-based, collaborative recommendation. </title> <journal> Communications of the Association for Computing Machinery 40(3) </journal> <pages> 66-72. </pages>
Reference-contexts: This approach assumes that a given user's tastes are generally the same as some other user of the system and that a sufficient number of users and ratings are available. Learning individualized profiles from descriptions of examples (content-based recommending <ref> (Balabanovic & Shoham 1997) </ref>), on the other hand, allows a system to uniquely characterize each patron without having to match their interests to someone else's. Learning for text-categorization has been applied to content-based recommending of web pages (Pazzani, Muramatsu, & Billsus 1996) and newsgroup messages (Lang 1995).
Reference: <author> Califf, M. E., and Mooney, R. J. </author> <year> 1998. </year> <title> Relational learning of pattern-match rules for information extraction. </title> <booktitle> In Working Notes of AAAI Spring Symposium on Applying Machine Learning to Discourse Processing, </booktitle> <pages> 6-11. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Cardie, C. </author> <year> 1997. </year> <title> Empirical methods in information extraction. </title> <journal> AI Magazine 18(4) </journal> <pages> 65-79. </pages>
Reference-contexts: Libra's extraction system is handwritten and employs a pattern matcher that utilizes pre-filler, filler, and post-filler patterns as described by Califf & Mooney (1998). In other applications, more sophisticated information extraction methods and inductive learning of extraction rules might be useful <ref> (Cardie 1997) </ref>. The text in each slot is then processed into an unordered set of words/tokens and the examples represented as a vector of set-valued features. Learning a Profile Next, the user selects and rates a set of training books.
Reference: <author> Cohen, W. W. </author> <year> 1996a. </year> <title> Learning rules that classify e-mail. </title> <booktitle> In Papers from the AAAI Spring Symposium on Machine Learning in Information Access, </booktitle> <pages> 18-25. </pages> <publisher> AAAI Press. </publisher>
Reference: <author> Cohen, W. W. </author> <year> 1996b. </year> <title> Learning trees and rules with set-valued features. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> 709-716. </pages>
Reference: <author> Joachims, T. </author> <year> 1997. </year> <title> A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Machine Learning, </booktitle> <pages> 143-151. </pages> <address> San Fran-cisco, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Kohavi, R.; Becker, B.; and Sommerfield, D. </author> <year> 1997. </year> <title> Improving simple Bayes. </title> <booktitle> In Proceedings of the European Conference on Machine Learning. </booktitle>
Reference-contexts: Each word appearing in a given slot is treated as a binary feature and hash tables are used to efficiently store and index conditional probabilities for only the words actually occurring in each slot in the training data. 2 Probabilities are smoothed using Laplace estimates <ref> (Kohavi, Becker, & Sommerfield 1997) </ref>, which also provides nonzero probabilities for any novel words encountered during testing. Calculation with logarithms of probabilities is used to avoid underflow.
Reference: <author> Lang, K. </author> <year> 1995. </year> <title> NewsWeeder: Learning to filter netnews. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> 331-339. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Learning for text-categorization has been applied to content-based recommending of web pages (Pazzani, Muramatsu, & Billsus 1996) and newsgroup messages <ref> (Lang 1995) </ref>. We have been exploring book recommending by applying text-categorization to semi-structured text extracted from the web.
Reference: <author> Lehnert, W., and Sundheim, B. </author> <year> 1991. </year> <title> A performance evaluation of text-analysis technologies. </title> <journal> AI Magazine 12(3) </journal> <pages> 81-94. </pages>
Reference: <author> Maes, P. </author> <year> 1994. </year> <title> Agents that reduce work and information overload. </title> <journal> Communications of the Association for Computing Machinery 37(7) </journal> <pages> 31-40. </pages>
Reference: <author> Mitchell, T. </author> <year> 1997. </year> <title> Machine Learning. </title> <address> New York, NY: </address> <publisher> McGraw-Hill. </publisher>
Reference: <author> Pazzani, M., and Billsus, D. </author> <year> 1997. </year> <title> Learning and revising user profiles: The identification of interesting web sites. </title> <booktitle> Machine Learning 27(3) </booktitle> <pages> 313-331. </pages>
Reference-contexts: Combining information about an item extracted from multiple sources (e.g. Amazon and BarnesAndNoble) is yet another issue. Allowing a user to initially provide keywords that are of known interest and incorporating this information into learned profiles could also be helpful <ref> (Pazzani & Billsus 1997) </ref>. Combining the current content-based approach with information about other users' ratings (such as those extracted from Amazon) is another interesting direction. Conclusions Content-based recommender systems for books and other items is an interesting and challenging application for learning and text categorization.
Reference: <author> Pazzani, M.; Muramatsu, J.; and Billsus, D. </author> <year> 1996. </year> <title> Syskill & Webert: Identifying interesting web sites. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> 54-61. </pages>
Reference-contexts: Learning individualized profiles from descriptions of examples (content-based recommending (Balabanovic & Shoham 1997)), on the other hand, allows a system to uniquely characterize each patron without having to match their interests to someone else's. Learning for text-categorization has been applied to content-based recommending of web pages <ref> (Pazzani, Muramatsu, & Billsus 1996) </ref> and newsgroup messages (Lang 1995). We have been exploring book recommending by applying text-categorization to semi-structured text extracted from the web.
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <address> San Fran-cisco, CA: </address> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Inc., </address> <note> revised second printing edition. </note>
Reference-contexts: When using this 10-category model to predict a binary category (positive: rating &gt; 5; negative: rating 5), we classify an example as positive if and only if P 10 P 5 i=1 P (i). Libra can also be trained specifically for binary categorization with the posterior odds <ref> (Pearl 1988) </ref> of the positive category used to rank the test examples. A third option, which we will call the weighted binary approach, maps the user's 1 - 10 rating r into a weight, w r , in the closed interval [0,1], where w r = r1 9 .
Reference: <author> Resnik, P., and Varian, H. R. </author> <year> 1997. </year> <title> Introduction (to the special section on recommender systems). </title> <journal> Communications of the Association for Computing Machinery 40(3) </journal> <pages> 56-59. </pages>
Reference: <author> Salton, G., and Buckley, C. </author> <year> 1990. </year> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science 41 </journal> <pages> 288-297. </pages>
Reference-contexts: After reviewing the recommendations, the user may assign their own rating to examples they believe to be incorrectly ranked and retrain the system to produce improved recommendations. As with relevance feedback in information retrieval <ref> (Salton & Buckley 1990) </ref>, this cycle can be repeated several times in order to produce the best results. Experimental Results Methodology Data Collection Of the first 5,500 URL's returned from the keyword search "literature fiction" on Amazon, 3,061 were judged as unique (differing ISBN's) adequate information pages.
Reference: <author> Spatz, C., and Johnston, J. O. </author> <year> 1984. </year> <title> Basic Statistics, Tales of Distributions. </title> <address> Belmont, CA: </address> <publisher> Wadsworth, Inc., </publisher> <address> third edition. </address>
Reference-contexts: When there are no ties, this reduces to the form given in most introductory statistics texts <ref> (Spatz & Johnston 1984) </ref>. Systems and Hypotheses Our current experiments compare a simple binary classifier, a 10-ratings classifier which uses the expected value to predict ratings, and a weighted binary classifier (hereafter referred to as Binary, 10-Ratings, and Weighted Binary, respectively).
References-found: 18

