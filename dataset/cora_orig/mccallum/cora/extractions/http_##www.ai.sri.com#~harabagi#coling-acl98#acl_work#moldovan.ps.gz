URL: http://www.ai.sri.com/~harabagi/coling-acl98/acl_work/moldovan.ps.gz
Refering-URL: http://www.ai.sri.com/~harabagi/coling-acl98/acl_work/acl_work.html
Root-URL: 
Email: frada,moldovang@seas.smu.edu  
Title: Word Sense Disambiguation based on Semantic Density  
Author: Rada Mihalcea and Dan I. Moldovan 
Note: 73% for top three ranked.  
Address: Dallas, Texas, 75275-0122  
Affiliation: Department of Computer Science and Engineering Southern Methodist University  
Abstract: This paper presents a Word Sense Disambiguation method based on the idea of semantic density between words. The disambiguation is done in the context of WordNet. The Internet is used as a raw corpora to provide statistical information for word associations. A metric is introduced and used to measure the semantic density and to rank all possible combinations of the senses of two words. This method provides a precision of 58% in indicating the correct sense for both words at the same time. The precision increases as we consider more choices: 70% for top two ranked and 
Abstract-found: 1
Intro-found: 1
Reference: <institution> Digital Equipment Corporation. AltaVista Home Page. URL:http://www.altavista.digital.com. </institution>
Reference: <author> E. Agirre and G. Rigau, </author> <title> A Proposal for Word Sense Disambiguation using Conceptual Distance, </title> <booktitle> Proceedings of the 1st International Conference on Recent Advances in Natural Language Processing, </booktitle> <editor> Velingrad, 1995 R. Bruce and J. </editor> <title> Wiebe, Word Sense Disambiguation using Decomposable Models, </title> <booktitle> Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics (ACL-94), </booktitle> <pages> 139-146, </pages> <address> LasCruces, NM, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al.1992), (Miller et al.1994), <ref> (Agirre and Rigau, 1995) </ref>, (Li et al.1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale, Church et al., 1992), (Ng and Lee, 1996); 3. <p> Methods that do not need large corpora are usually based exclusively on MRD. A proposal in this sense has been made in <ref> (Agirre and Rigau, 1995) </ref>; they measure the conceptual density between nouns, by using WordNet, but the method proposed in their paper cannot be applied to measuring a conceptual distance between a verb and a noun, as no direct links are provided in MRDs between the nouns and verbs hierarchies. <p> We considered also the metrics indicated in <ref> (Agirre and Rigau, 1995) </ref>. But after running the program on several examples, the formula indicated in (1) provided the best results.
Reference: <author> J. Cowie, L. Guthrie and J. Guthrie, </author> <title> Lexical disambiguation using simulated annealing. </title> <booktitle> Proceedings of the Fifth International Conference on Computational Linguistics COLING-92, </booktitle> <pages> 157-161, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries <ref> (Cowie et al.1992) </ref>, (Miller et al.1994), (Agirre and Rigau, 1995), (Li et al.1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale, Church et al., 1992), (Ng and Lee, 1996); 3.
Reference: <author> S. Francis and H. </author> <title> Kucera, </title> <booktitle> Computational Analisys of present-day American English, </booktitle> <address> Providence, RI: </address> <publisher> Brown University Press, </publisher> <editor> 1967 W. Gale, K. Church and D. Yarowsky, </editor> <title> One Sense per Discourse, </title> <booktitle> Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <address> Harriman, New York, </address> <year> 1992. </year>
Reference-contexts: In order to determine the sub-hierarchies that should be used for v i and n j , we used statistics provided by SemCor, a sense tagged version of the Brown corpus <ref> (Francis and Kucera, 1967) </ref> (Miller, Leacock et al., 1993), containing 250,000 words. Each word (noun, verb, adjective, adverb) is included in a synset within a hierarchy. The tops of these hierarchies denominate the class of the word.
Reference: <author> X. Li, S. Szpakowicz and S. Matwin. </author> <title> A WordNet-based algorithm for word semantic sense disambiguation. </title> <booktitle> Proceedings of the 14th International Joint Conference on Artificial Intelligence IJCAI-95, </booktitle> <address> Montreal, Canada, </address> <year> 1995. </year>
Reference-contexts: Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al.1992), (Miller et al.1994), (Agirre and Rigau, 1995), <ref> (Li et al.1995) </ref>, (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale, Church et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky 1995) (Resnik 1997). <p> Essentially, it is the length of the shortest path connecting the concepts (Rada et al.1989), (Rigau, Asterias et al., 1997). By measuring the conceptual distance between words, it is possible to determine the likelihood of word sense associations. For example, the method proposed in <ref> (Li et al.1995) </ref> tries to determine the possible sense of a noun associated with a verb using WordNet and a large text. Based on other occurrences of the verb or semantically related verbs in the text, the possible object is determined by measuring the semantic similarity between the noun objects.
Reference: <author> S. McRoy, </author> <title> Using multiple Knowledge Sources for Word Sense Disambiguation, </title> <journal> Computational Linguistics, </journal> <volume> 18(1) </volume> <pages> 1-30, </pages> <year> 1992. </year>
Reference-contexts: Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al.1992), (Miller et al.1994), (Agirre and Rigau, 1995), (Li et al.1995), <ref> (McRoy, 1992) </ref>; 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale, Church et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky 1995) (Resnik 1997). <p> WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky 1995) (Resnik 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others <ref> (McRoy, 1992) </ref> (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau, Asterias et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods.
Reference: <author> G.A. Miller, </author> <title> WordNet: An on-line lexical database. </title> <journal> International Journal of Lexicography, </journal> <volume> 3(4) </volume> <pages> 235-312, </pages> <year> 1990. </year>
Reference-contexts: Even the phrase may be ambiguous by having a poor context, still the results of a search or interface based on such a sentence can be improved if the possible associations between the senses of the verb and the noun are determined. In WordNet <ref> (Miller 1990) </ref>, the gloss of a verb synset provides a noun-context for that verb, i.e. the possible nouns occurring in the context of that particular verb.
Reference: <author> G.A. Miller, C. Leacock, T. Randee and R. </author> <note> Bunker, </note>
References-found: 8

