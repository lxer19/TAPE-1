URL: http://www.cri.ensmp.fr/doc/A-274.ps.Z
Refering-URL: http://www.cri.ensmp.fr/rapports.html
Root-URL: 
Title: Optimal Compilation of HPF Remappings (Extended Abstract)  
Author: Fabien Coelho, Corinne Ancourt 
Keyword: Hpf Compilation, Array remappings, Distributed Memory Mimd machines. Number of words:  
Note: FTP:  4984 words, not including figures, references, and L a  
Address: 35, rue Saint-Honore, 77305 Fontainebleau Cedex, France.  directives.  
Affiliation: Centre de Recherche en Informatique, Ecole des mines de Paris,  T E X  
Pubnum: Report A-274-CRI  
Email: anonymous@ftp.cri.ensmp.fr  fcoelho,ancourtg@cri.ensmp.fr  
Phone: Phone: +33 1 64 69 47 08. Fax: 33 1 64 69 47 09.  
Date: July 18, 1995  
Web: URL: http://www.cri.ensmp.fr,  
Abstract: Applications with varying array access patterns in a parallel distributed memory machine require to dynamically change array mappings. Hpf (High Performance Fortran) provides such remappings, possibly on partially replicated data, explicitly through the realign and redistribute directives and implicitly at procedure calls and returns. However such features are left out of the hpf subset or of the currently discussed hpf kernel for efficiency reason. This paper presents a new compilation technique to handle hpf remappings for message-passing parallel architectures. The first phase is global and removes all useless remappings that naturally appear in procedures. The second phase generates the actual remapping code and takes advantage of replications to shorten the remapping time. A minimal number of messages, containing only the required data, is sent over the network.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Saman P. Amarasinghe and Monica S. Lam. </author> <title> Communication Optimization and Code Generation for Distributed Memory Machines. </title> <booktitle> In ACM SIGPLAN International Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches [15, 29, 17], diophantine equations [26, 4, 34] or polyhedra <ref> [1, 3, 32, 30] </ref>. However none of these techniques does take advantage of replications and broadcasts. <p> Thus, a simple guard pid ( ) 6= pid ( 0 D ) can be added outside of the packing loop to achieve this goal. The usual Fourier elimination technique needs to instantiate the number of processors. However the parametric extension presented in <ref> [1] </ref> allows to generate code if this number is parametric. Since processor dimensions are independent in E, the practical complexity of the code generation for multiple dimensions is the number of dimensions times the com plexity of the code generation for one dimension.
Reference: [2] <author> Corinne Ancourt. </author> <title> Generation automatique de codes de transfert pour multiprocesseurs a memoires locales. </title> <type> PhD thesis, </type> <institution> Universite Paris VI, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: That is a parametric polyhedron on variables Z. * X jY (V ) is the system after the projection of variables Y V . A projection may be exact or approximate <ref> [2, 27] </ref>, that is the integer solution to the projection may always reflects, or not, an integer solutions in the original polyhedron. * X 3 (Z 1 [ Z 2 ) = X 1 (Z 1 ) [ X 2 (Z 2 ) denotes the union of systems X 1 and <p> The data are just copied from the source to target array. The copy is performed on the receive part in order not to delay the messages sending. The generated code necessitates the enumeration of some polyhedra. Techniques for generating such codes are based on Fourier elimination <ref> [19, 2] </ref> or a parametric simplex [12]. Such techniques generate code to enumerate exactly the solutions to a polyhedron. The correctness of the communications requires that the messages are packed and unpacked in the same order.
Reference: [3] <author> Corinne Ancourt, Fabien Coelho, Fran~cois Irigoin, and Ronan Keryell. </author> <title> A Linear Algebra Framework for Static HPF Code Distribution. </title> <booktitle> In Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, </address> <month> December </month> <year> 1993. </year> <note> Also available as TR EMP A/250/CRI on http://www.cri.ensmp.fr. </note>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches [15, 29, 17], diophantine equations [26, 4, 34] or polyhedra <ref> [1, 3, 32, 30] </ref>. However none of these techniques does take advantage of replications and broadcasts. <p> linearizing list V = ( 1 ; 3 ) where 1 1 2; 1 3 2 gives the linearization equality: lin (V ) = 2 3 + 1 3. 2.2 Linear formalization hpf directives, program variable declarations and the local addressing scheme are translated into linear constraints, as suggested in <ref> [3, 9] </ref>. This gives a linear description of the data distribution and of the communication problem, that is the enumeration of the elements to be sent and received. Figure 7 shows the linear constraints derived for the running example presented in Figure 6. These equations are detailed in the appendix.
Reference: [4] <author> Siegfried Benkner, Peter Brezany, and Hans Zima. </author> <title> Processing array statements and procedure interfaces in the prepare high performance fortran compiler. </title> <booktitle> In 5th International Conference on Compiler Construction, </booktitle> <address> April 1994. </address> <publisher> Springer-Verlag LNCS vol. </publisher> <pages> 786, pages 324-338. </pages>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches [15, 29, 17], diophantine equations <ref> [26, 4, 34] </ref> or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [5] <author> Siddhartha Chatterjee, John R. Gilbert, Fred J. E. Long, Robert Schreiber, and Shang-Hua Teng. </author> <title> Generating local addresses and communication sets for data-parallel programs. </title> <booktitle> In Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1993. </year>
Reference-contexts: Any technique that claims to handle all hpf array assignments may be used to compile remappings, since communications involved in a remapping are equivalent to an array assignment A = B, where B (resp. A) has the source (resp. target) mapping. Such techniques are based on finite state machines <ref> [5, 18, 23] </ref>, closed form approaches [15, 29, 17], diophantine equations [26, 4, 34] or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [6] <author> Siddhartha Chatterjee, John R. Gilbert, Robert Schreiber, and Thomas J. She*er. </author> <title> Array disttribution in data-parallel programs. </title> <booktitle> In Language and Compilers for Parallel Computing, </booktitle> <pages> pages 6.1-6.17, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: A parallel matrix multiplication accesses a whole row and column of data to compute each single element of the matrix, hence the need to remap data with some replication. Moreover, automatic tools for data layout <ref> [22, 6] </ref> may suggest data remappings between computation phases of an application. Thus handling data remappings is an important issue for high performance computing. Hpf (High Performance Fortran [13, 25]) is a data-parallel language based on Fortran 90. It targets distributed memory parallel architectures.
Reference: [7] <author> Fabien Coelho. </author> <title> Etude de la Compilation du high performance fortran. </title> <type> Master's thesis, </type> <institution> Universite Paris VI, </institution> <month> September </month> <year> 1993. </year> <institution> Rapport de DEA Systemes Informatiques. TR EMP E/178/CRI. </institution>
Reference-contexts: Correctness and optimality results are presented and discussed for both phases of the compilation. This technique has been successfully implemented in hpfc <ref> [7, 8, 9] </ref>, a prototype hpf compiler developed within the pips project [20]. <p> Thus the technique minimizes both latency and bandwith-related costs of the network, through message aggregation and exact enumeration of elements to be sent. Moreover load balancing issues are discussed and (possibly partial) broadcasts are used when possible. This technique is implemented in hpfc <ref> [7, 8, 9] </ref>, a prototype hpf compiler developed within the pips project [20]. Portable pvm code is generated. However, there is still a need for runtime support. Some hpf programs may instantiate too many mapping parameters at runtime, making the parametric compile time code generation phase codes too tricky.
Reference: [8] <author> Fabien Coelho. </author> <title> Experiments with HPF compilation for a network of workstations. In High-Performance Computing and Networking, </title> <publisher> Springer-Verlag LNCS 797, </publisher> <pages> pages 423-428, </pages> <month> April </month> <year> 1994. </year> <note> Also available as TR EMP A/257/CRI. </note>
Reference-contexts: Correctness and optimality results are presented and discussed for both phases of the compilation. This technique has been successfully implemented in hpfc <ref> [7, 8, 9] </ref>, a prototype hpf compiler developed within the pips project [20]. <p> Thus the technique minimizes both latency and bandwith-related costs of the network, through message aggregation and exact enumeration of elements to be sent. Moreover load balancing issues are discussed and (possibly partial) broadcasts are used when possible. This technique is implemented in hpfc <ref> [7, 8, 9] </ref>, a prototype hpf compiler developed within the pips project [20]. Portable pvm code is generated. However, there is still a need for runtime support. Some hpf programs may instantiate too many mapping parameters at runtime, making the parametric compile time code generation phase codes too tricky.
Reference: [9] <author> Fabien Coelho. </author> <title> Compilation of I/O communications for HPF. </title> <booktitle> In 5th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 102-109, </pages> <month> February </month> <year> 1995. </year> <note> Also available as TR-CRI A/264. </note>
Reference-contexts: Correctness and optimality results are presented and discussed for both phases of the compilation. This technique has been successfully implemented in hpfc <ref> [7, 8, 9] </ref>, a prototype hpf compiler developed within the pips project [20]. <p> linearizing list V = ( 1 ; 3 ) where 1 1 2; 1 3 2 gives the linearization equality: lin (V ) = 2 3 + 1 3. 2.2 Linear formalization hpf directives, program variable declarations and the local addressing scheme are translated into linear constraints, as suggested in <ref> [3, 9] </ref>. This gives a linear description of the data distribution and of the communication problem, that is the enumeration of the elements to be sent and received. Figure 7 shows the linear constraints derived for the running example presented in Figure 6. These equations are detailed in the appendix. <p> Thus the technique minimizes both latency and bandwith-related costs of the network, through message aggregation and exact enumeration of elements to be sent. Moreover load balancing issues are discussed and (possibly partial) broadcasts are used when possible. This technique is implemented in hpfc <ref> [7, 8, 9] </ref>, a prototype hpf compiler developed within the pips project [20]. Portable pvm code is generated. However, there is still a need for runtime support. Some hpf programs may instantiate too many mapping parameters at runtime, making the parametric compile time code generation phase codes too tricky.
Reference: [10] <author> Beatrice Creusillet. </author> <title> IN and OUT array region analyses. </title> <booktitle> In Workshop on Compilers for Parallel Computers, </booktitle> <month> June </month> <year> 1995. </year> <title> Optimal Compilation of Hpf Remappings 18 </title>
Reference-contexts: Future work includes: Optimal Compilation of Hpf Remappings 17 * mappings code motion to reduce the number of executed remappings, * reducing the remapped elements set to what is needed through advanced compile time analyses <ref> [11, 10] </ref>. * generating temporary copies for read-only remapped arrays to avoid backward remappings, * compiling for other models, such as get/put/synchro communications.
Reference: [11] <author> Beatrice Creusillet and Fran~cois Irigoin. </author> <title> Interprocedural array regions analyses. </title> <booktitle> In Language and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: Future work includes: Optimal Compilation of Hpf Remappings 17 * mappings code motion to reduce the number of executed remappings, * reducing the remapped elements set to what is needed through advanced compile time analyses <ref> [11, 10] </ref>. * generating temporary copies for read-only remapped arrays to avoid backward remappings, * compiling for other models, such as get/put/synchro communications.
Reference: [12] <author> Paul Feautrier. </author> <title> Parametric integer programming. </title> <journal> RAIRO Recherche Operationnelle, </journal> <volume> 22 </volume> <pages> 243-268, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: The copy is performed on the receive part in order not to delay the messages sending. The generated code necessitates the enumeration of some polyhedra. Techniques for generating such codes are based on Fourier elimination [19, 2] or a parametric simplex <ref> [12] </ref>. Such techniques generate code to enumerate exactly the solutions to a polyhedron. The correctness of the communications requires that the messages are packed and unpacked in the same order.
Reference: [13] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification. </title> <institution> Rice University, Houston, Texas, </institution> <month> May </month> <year> 1993. </year> <note> Version 1.0. </note>
Reference-contexts: Moreover, automatic tools for data layout [22, 6] may suggest data remappings between computation phases of an application. Thus handling data remappings is an important issue for high performance computing. Hpf (High Performance Fortran <ref> [13, 25] </ref>) is a data-parallel language based on Fortran 90. It targets distributed memory parallel architectures. It provides standard directives to declare processor sets and array mappings onto these. Hpf mappings may involve some replication.
Reference: [14] <institution> High Performance Fortran Forum. HPF-2 Scope of Activities and Motivation Examples. Rice University, Houston, Texas, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: However useful these features are, they are perceived as difficult to compile efficiently and thus are left out of the hpf subset or the currently discussed hpf kernel <ref> [14] </ref>. If not supported, or even not well supported, remappings will not be used for applications aiming at high efficiency, indeed all hpf applications. It also decreases the number of codes that can be efficiently ported to hpf.
Reference: [15] <author> S. K. S. Gupta, S. D. Kaushik, S. Mufti, S. Sharma, C.-H. Huang, and P. Sadayappan. </author> <title> On compiling array expressions for efficient execution on distributed-memory machines. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages II-301-II-305, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches <ref> [15, 29, 17] </ref>, diophantine equations [26, 4, 34] or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [16] <author> S.K.S. Gupta, C.-H. Huang, and P. Sadayappan. </author> <title> Implementing fast fourier transforms on distributed-memory multiprocessors using data redistributions. </title> <journal> Parallel Processing Letters, </journal> <volume> 4(4) </volume> <pages> 477-488, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Introduction Many applications require the ability to have different array mappings at different phases of computations for efficient execution on distributed-memory parallel machines, such as the Cray t3d or the Ibm sp2. ADI (Alternating Direction Integration) and FFT (Fast Fourier Transform) are examples of such applications <ref> [16] </ref>. Data replication is also useful to share data between processors. The combination of both features enables elegant programming techniques: for instance, the distributed definition of an array and its efficient use after replication.
Reference: [17] <author> S.K.S. Gupta, S. D. Kaushik, C.-H. Huang, and P. Sadayappan. </author> <title> On compiling array expressions for efficient execution on distributed-memory machines. </title> <type> TR 19, </type> <institution> Department of Computer and Information Science, The Ohio State University, </institution> <year> 1994. </year>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches <ref> [15, 29, 17] </ref>, diophantine equations [26, 4, 34] or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [18] <author> Semma Hirannandani, Ken Kennedy, John Mellor-Crummey, and Ajay Sethi. </author> <title> Advanced compilation techniques for fortran d. </title> <type> CRPC-TR 93338, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Any technique that claims to handle all hpf array assignments may be used to compile remappings, since communications involved in a remapping are equivalent to an array assignment A = B, where B (resp. A) has the source (resp. target) mapping. Such techniques are based on finite state machines <ref> [5, 18, 23] </ref>, closed form approaches [15, 29, 17], diophantine equations [26, 4, 34] or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [19] <author> Fran~cois Irigoin. </author> <title> Code generation for the hyperplane method and for loop interchange. </title> <institution> ENSMP-CAI-88 E102/CAI/I, CRI, Ecole des mines de Paris, </institution> <month> October </month> <year> 1988. </year>
Reference-contexts: The data are just copied from the source to target array. The copy is performed on the receive part in order not to delay the messages sending. The generated code necessitates the enumeration of some polyhedra. Techniques for generating such codes are based on Fourier elimination <ref> [19, 2] </ref> or a parametric simplex [12]. Such techniques generate code to enumerate exactly the solutions to a polyhedron. The correctness of the communications requires that the messages are packed and unpacked in the same order.
Reference: [20] <author> Fran~cois Irigoin, Pierre Jouvelot, and Remi Triolet. </author> <title> Semantical interprocedural paralleliza-tion: An overview of the PIPS project. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Correctness and optimality results are presented and discussed for both phases of the compilation. This technique has been successfully implemented in hpfc [7, 8, 9], a prototype hpf compiler developed within the pips project <ref> [20] </ref>. <p> Moreover load balancing issues are discussed and (possibly partial) broadcasts are used when possible. This technique is implemented in hpfc [7, 8, 9], a prototype hpf compiler developed within the pips project <ref> [20] </ref>. Portable pvm code is generated. However, there is still a need for runtime support. Some hpf programs may instantiate too many mapping parameters at runtime, making the parametric compile time code generation phase codes too tricky.
Reference: [21] <author> Ken Kennedy. </author> <title> A survey of data flow analysis techniques. </title> <editor> In S. Muchnick and N. Jones, editors, </editor> <title> Program Flow Analysis: </title> <booktitle> Theory and Applications, </booktitle> <pages> pages 5-54. </pages> <publisher> Prentice-Hall, Inc., </publisher> <address> Engelwood Cliffs, </address> <year> 1979. </year>
Reference-contexts: This is a forward may data flow problem <ref> [24, 21] </ref> on G R : initialization: Used 1-step reaching mappings 8v; 8A 2 S (v); R A (v) = w2pred (v) A2S (w); Used A (w) L A (v 0 ) optimizing function: propagation 8v; 8A 2 S (v); R A (v) = R A (v) [ w2pred (v) A2S
Reference: [22] <author> Ken Kennedy and Ulrich Kremer. </author> <title> Automatic data layout for high performance fortran. CRPC-TR94 498-S, Center for Research on Parallel Computation, </title> <institution> Rice University, </institution> <month> De-cember </month> <year> 1994. </year>
Reference-contexts: A parallel matrix multiplication accesses a whole row and column of data to compute each single element of the matrix, hence the need to remap data with some replication. Moreover, automatic tools for data layout <ref> [22, 6] </ref> may suggest data remappings between computation phases of an application. Thus handling data remappings is an important issue for high performance computing. Hpf (High Performance Fortran [13, 25]) is a data-parallel language based on Fortran 90. It targets distributed memory parallel architectures.
Reference: [23] <author> Ken Kennedy, Nenad Nedeljkovic, and Ajay Sethi. </author> <title> A linear time algorithm for computing the memory access sequence in data-parallel programs. CRPC-TR 94485-S, Center for Research on Parallel Computation, </title> <institution> Rice University, </institution> <month> October </month> <year> 1994. </year> <note> Submitted to PPoPP'95. </note>
Reference-contexts: Any technique that claims to handle all hpf array assignments may be used to compile remappings, since communications involved in a remapping are equivalent to an array assignment A = B, where B (resp. A) has the source (resp. target) mapping. Such techniques are based on finite state machines <ref> [5, 18, 23] </ref>, closed form approaches [15, 29, 17], diophantine equations [26, 4, 34] or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [24] <author> Gary A. Kildall. </author> <title> A unified approach to global program optimization. </title> <booktitle> In Symposium on Principles of Programming Language, </booktitle> <pages> pages 194-206, </pages> <year> 1973. </year>
Reference-contexts: This is a forward may data flow problem <ref> [24, 21] </ref> on G R : initialization: Used 1-step reaching mappings 8v; 8A 2 S (v); R A (v) = w2pred (v) A2S (w); Used A (w) L A (v 0 ) optimizing function: propagation 8v; 8A 2 S (v); R A (v) = R A (v) [ w2pred (v) A2S
Reference: [25] <author> Charles Koelbel, David Loveman, Robert Schreiber, Guy Steele, and Mary Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Moreover, automatic tools for data layout [22, 6] may suggest data remappings between computation phases of an application. Thus handling data remappings is an important issue for high performance computing. Hpf (High Performance Fortran <ref> [13, 25] </ref>) is a data-parallel language based on Fortran 90. It targets distributed memory parallel architectures. It provides standard directives to declare processor sets and array mappings onto these. Hpf mappings may involve some replication.
Reference: [26] <author> Edwin M. Paalvast, Henk J. Sips, and A.J. van Gemund. </author> <title> Automatic parallel program generation and optimization from data decompositions. </title> <booktitle> In 1991 International Conference on Parallel Processing | Volume II : Software, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches [15, 29, 17], diophantine equations <ref> [26, 4, 34] </ref> or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [27] <author> William Pugh. </author> <title> A pratical algorithm for exact array dependence analysis. </title> <journal> CACM, </journal> <volume> 35(8) </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year> <title> Optimal Compilation of Hpf Remappings 19 </title>
Reference-contexts: That is a parametric polyhedron on variables Z. * X jY (V ) is the system after the projection of variables Y V . A projection may be exact or approximate <ref> [2, 27] </ref>, that is the integer solution to the projection may always reflects, or not, an integer solutions in the original polyhedron. * X 3 (Z 1 [ Z 2 ) = X 1 (Z 1 ) [ X 2 (Z 2 ) denotes the union of systems X 1 and
Reference: [28] <author> Shankar Ramaswamy and Prithviraj Banerjee. </author> <title> Automatic generation of efficient array redistribution routines for distributed memory multicomputers. </title> <booktitle> In 5th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 342-349, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Algorithms are presented for simple cases involving no shape changing (the distributed dimensions are the same for both source and target mappings), no alignment and no replication. Multidimensional remappings are decomposed into 1-d remappings, hence resulting in several remap-pings at runtime. In the Paradigme project <ref> [28] </ref>, a compile time technique based on ad hoc data descriptors called pitfalls is presented. Alignment, replication and shape changing are not considered. For the Eppp project [33], a polyhedron based approach is outlined. Only realignments with a fixed block-cyclic distribution onto a 1-d processor array are handled.
Reference: [29] <author> J. Stichnoth, D. O'Hallaron, and T. Gross. </author> <title> Generating communication for array statements: Design, implementation and evaluation. </title> <booktitle> In Language and Compilers for Parallel Computing, </booktitle> <month> pages ??-??, August </month> <year> 1993. </year>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches <ref> [15, 29, 17] </ref>, diophantine equations [26, 4, 34] or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [30] <author> Ernesto Su, Antonio Lain, Shankar Ramaswamy, Daniel J. Palermo, Eugene W. Hodges IV, and Prithviraj Banerjee. </author> <title> Advanced compilation techniques in the paradigme compiler for distributed-memory multicomputers. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <pages> pages 424-433, </pages> <month> July 95. </month>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches [15, 29, 17], diophantine equations [26, 4, 34] or polyhedra <ref> [1, 3, 32, 30] </ref>. However none of these techniques does take advantage of replications and broadcasts.
Reference: [31] <author> Rajeev Thakur, Alok Choudhary, and Geoffrey Fox. </author> <title> Runtime array redistribution in HPF programs. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 309-316, </pages> <year> 1994. </year>
Reference-contexts: Also issues such as handling different processor sets, multidimensional distributions, communication set generation and allocation of temporary arrays are not all clearly and efficiently addressed in these papers, therefore the need for dedicated techniques, that can include more optimizations. In <ref> [31] </ref> a runtime library support is suggested. Algorithms are presented for simple cases involving no shape changing (the distributed dimensions are the same for both source and target mappings), no alignment and no replication. Multidimensional remappings are decomposed into 1-d remappings, hence resulting in several remap-pings at runtime.
Reference: [32] <author> Vincent Van Dongen. </author> <title> Compiling distributed loops onto SPMD code. </title> <journal> Parallel Processing Letters, </journal> <volume> 4(3) </volume> <pages> 301-312, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches [15, 29, 17], diophantine equations [26, 4, 34] or polyhedra <ref> [1, 3, 32, 30] </ref>. However none of these techniques does take advantage of replications and broadcasts.
Reference: [33] <author> Vincent Van Dongen. </author> <title> Array redistribution by scanning polyhedra. Personnal communication: One page summary for PARCO'95, </title> <month> July </month> <year> 1995. </year>
Reference-contexts: Multidimensional remappings are decomposed into 1-d remappings, hence resulting in several remap-pings at runtime. In the Paradigme project [28], a compile time technique based on ad hoc data descriptors called pitfalls is presented. Alignment, replication and shape changing are not considered. For the Eppp project <ref> [33] </ref>, a polyhedron based approach is outlined. Only realignments with a fixed block-cyclic distribution onto a 1-d processor array are handled. However the alignments, unlike hpf, involve arbitrary affine functions.
Reference: [34] <author> C. van Reuuwijk, H. J. Sips, W. Denissen, and E. M. Paalvast. </author> <title> Implementing HPF distributed arrays on a message-passing parallel computer system. Computational Physics Report Series, </title> <type> CP-95 006, </type> <institution> Delft University of Technology, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: A) has the source (resp. target) mapping. Such techniques are based on finite state machines [5, 18, 23], closed form approaches [15, 29, 17], diophantine equations <ref> [26, 4, 34] </ref> or polyhedra [1, 3, 32, 30]. However none of these techniques does take advantage of replications and broadcasts.
Reference: [35] <author> Hans Zima, Peter Brezany, Barbara Chapman, Piyush Mehrotra, and Andreas Schwald. </author> <title> Vienna fortran a language specification. </title> <note> ftp cs.rice.edu public/HPFF/papers/vf.tex, 1992. Version 1.1. </note>
Reference-contexts: T, distribute T... =&gt; B and C mappings: 0 use C 1 redistribute T =&gt; B and C mappings: 1 DO ... 2 remap A... =&gt; A mapping 1 use A 3 remap A... =&gt; A mapping 2 use A ENDDO use B 1 Even when no templates are used <ref> [35] </ref> array alignment generates the problem Optimal Compilation of Hpf Remappings 4 Let us consider Example remaps in Figure 1. The loop nest involving two remap-pings is typical of ADI computations. Template T is redistributed at 1, inducing B and C remappings, but C is not referenced afterwards.
References-found: 35

