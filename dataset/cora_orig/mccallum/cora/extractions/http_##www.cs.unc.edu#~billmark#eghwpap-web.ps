URL: http://www.cs.unc.edu/~billmark/eghwpap-web.ps
Refering-URL: http://www.cs.unc.edu/~billmark/research.html
Root-URL: http://www.cs.unc.edu
Title: Memory Access Patterns of Occlusion-Compatible 3D Image Warping  
Author: William R. Mark Gary Bishop 
Keyword: CR Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture/Image Generation Display Algorithms; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Visible line/surface algorithms; I.3.1 [Computer Graphics]: Hardware Architecture Graphics processors Additional Keywords: image-based rendering, 3D image warp, occlusion-compatible warp order.  
Affiliation: Department of Computer Science University of North Carolina at  
Date: August 3-4, 1997, pp. 35-44  
Address: Los Angeles, CA,  Chapel Hill  
Note: In Proceedings of 1997 SIGGRAPH/Eurographics Workshop on Graphics Hardware,  
Abstract: McMillan and Bishop's 3D image warp can be efficiently implemented by exploiting the coherency of its memory accesses. We analyze this coherency, and present algorithms that take advantage of it. These algorithms traverse the reference image in an occlusion-compatible order, which is an order that can resolve visibility using a painter's algorithm. Required cache sizes are calculated for several one-pass 3D warp algorithms, and we develop a two-pass algorithm which requires a smaller cache size than any of the practical one-pass algorithms. We also show that reference image traversal orders that are occlusion-compatible for continuous images are not always occlusion-compatible when applied to the discrete images used in practice. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Loren Carpenter. </author> <title> The A-buffer, an antialiased hidden surface method. </title> <booktitle> Computer Graphics (Proceedings of SIGGRAPH 84), </booktitle> <volume> 18(3) </volume> <pages> 103-108, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: In addition to eliminating the need for Z-buffering, the occlusion compatible order can be used to provide a front-to-back or back-to-front order which allows for efficient anti-aliasing of the 3D warp. We have implemented Carpenter's A-buffer algorithm <ref> [1] </ref> in a software test-bed using a front-to-back order, providing super-sampled quality with only one bit of storage per sub-pixel. Gortler et al. [5] use a back-to-front order to composite pixels into the output image using a splat footprint with fractional alpha values.
Reference: [2] <author> Ed Catmull and Alvy Ray Smith. </author> <title> 3-D transformations of images in scanline order. </title> <booktitle> Computer Graphics (Proceedings of SIGGRAPH 80), </booktitle> <volume> 14(3) </volume> <pages> 279-285, </pages> <month> July </month> <year> 1980. </year>
Reference-contexts: The pixels in each bin are warped in the same order that they were placed into the bin originally, so that the occlusion compatible order of the first pass traversal is maintained. Our two pass algorithm was inspired by earlier two pass image-warping techniques. Catmull and Smith <ref> [2] </ref> developed a 2-pass technique for several classes of image warp, including planar-to-planar perspective warps. Many other researchers have extended this work; Wolberg's book [14] provides a good overview. Our two-pass technique differs from this earlier work in two ways.
Reference: [3] <author> Shenchang Eric Chen and Lance Williams. </author> <title> View interpolation for image synthesis. </title> <booktitle> In Computer Graphics Annual Conference Series (Proceedings of SIGGRAPH 93), </booktitle> <pages> pages 279-288, </pages> <address> Anaheim, California, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Wolberg's book [14] provides a good overview of projective warps, and of image warping in general. The view interpolation system developed by Chen and Williams <ref> [3] </ref> used a 3D warp during pre-processing, but used a simpler interpolation algorithm at run-time. McMillan and Bishop developed a real-time 3D warp [12, 13]. Their system uses incremental evaluation of the 3D warp equations and an occlusion-compatible image-traversal order to achieve real-time performance.
Reference: [4] <author> Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and Michael F. Cohen. </author> <booktitle> The lumigraph. In Computer Graphics Annual Conference Series (Proceedings of SIGGRAPH 96), </booktitle> <pages> pages 43-54, </pages> <address> New Orleans, Louisiana, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: The 3D image warp has been used to explore natural scenes acquired using cameras [13] and to accelerate the display of computer generated imagery [5, 8, 9]. The alternative Lumigraph / Light Field approach to image-based rendering <ref> [4, 6] </ref> may produce higher quality output, but requires a very large input data set. All implementations of the 3D warp to date have been software-based, and none has been faster than a few frames per second for 640 x 480 images.
Reference: [5] <author> Steven J. Gortler, Li wei He, and Michael F. Cohen. </author> <title> Rendering layered depth images. </title> <type> Technical Report #97-09, </type> <institution> Microsoft Research, </institution> <month> Mar </month> <year> 1997. </year> <note> Available at http://www.research.microsoft.com/pubs. </note>
Reference-contexts: The 3D image warp has been used to explore natural scenes acquired using cameras [13] and to accelerate the display of computer generated imagery <ref> [5, 8, 9] </ref>. The alternative Lumigraph / Light Field approach to image-based rendering [4, 6] may produce higher quality output, but requires a very large input data set. <p> We have implemented Carpenter's A-buffer algorithm [1] in a software test-bed using a front-to-back order, providing super-sampled quality with only one bit of storage per sub-pixel. Gortler et al. <ref> [5] </ref> use a back-to-front order to composite pixels into the output image using a splat footprint with fractional alpha values. In order to maintain the occlusion compatible order, certain restrictions must be followed in traversing the reference image. McMillan's dissertation [11] and papers [10, 12] discuss this point in detail. <p> Figure 10 illustrates how this type of error can occur. Pixels from later-drawn lines can incorrectly overwrite pixels from earlier-drawn lines, due to the compression of the epipolar lines near the positive epipole. The problem is especially acute if a splat-type reconstruction algorithm <ref> [5, 7] </ref> is used, which can expand one reference pixel into several output pixels. This overwriting also indicates that a cache size of p pixels is not in fact sufficientthe potentially overwritten pixels need to be held in cache as well.
Reference: [6] <author> Marc Levoy and Pat Hanrahan. </author> <title> Light field rendering. </title> <booktitle> In Computer Graphics Annual Conference Series (Proceedings of SIGGRAPH 96), </booktitle> <pages> pages 31-42, </pages> <address> New Orleans, Louisiana, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: The 3D image warp has been used to explore natural scenes acquired using cameras [13] and to accelerate the display of computer generated imagery [5, 8, 9]. The alternative Lumigraph / Light Field approach to image-based rendering <ref> [4, 6] </ref> may produce higher quality output, but requires a very large input data set. All implementations of the 3D warp to date have been software-based, and none has been faster than a few frames per second for 640 x 480 images.
Reference: [7] <author> William R. Mark, Gary Bishop, and Leonard McMillan. </author> <title> Post-rendering image warping for latency compensation. </title> <type> Technical Report UNC-CH TR96-020, </type> <institution> Univ. of North Carolina at Chapel Hill, Dept. of Computer Science, </institution> <month> January </month> <year> 1996. </year> <note> Available at http://www.cs.unc.edu/Research/tech-reports.html. </note>
Reference-contexts: Figure 10 illustrates how this type of error can occur. Pixels from later-drawn lines can incorrectly overwrite pixels from earlier-drawn lines, due to the compression of the epipolar lines near the positive epipole. The problem is especially acute if a splat-type reconstruction algorithm <ref> [5, 7] </ref> is used, which can expand one reference pixel into several output pixels. This overwriting also indicates that a cache size of p pixels is not in fact sufficientthe potentially overwritten pixels need to be held in cache as well.
Reference: [8] <author> William R. Mark, Leonard McMillan, and Gary Bishop. </author> <title> Post-rendering 3D warping. </title> <booktitle> In Proceedings of the 1997 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 7-16, </pages> <address> Providence, RI, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: The 3D image warp has been used to explore natural scenes acquired using cameras [13] and to accelerate the display of computer generated imagery <ref> [5, 8, 9] </ref>. The alternative Lumigraph / Light Field approach to image-based rendering [4, 6] may produce higher quality output, but requires a very large input data set. <p> The bound on translation is determined in one of several different ways depending on the application. When reference images are pre-stored, the translation bound is calculated from the distance between reference images, and possibly from restrictions on the user's movement. In a post rendering warping system <ref> [8] </ref>, it comes from a bound on the user's speed. 3.1 Bounded discontinuities The bound on discontinuity in the 3D warp can be mathematically formulated in terms of the bounds on object distance and view-position translation.
Reference: [9] <author> Nelson Max and Keiichi Ohsaki. </author> <title> Rendering trees from precomputed Z-buffer views. </title> <editor> In Patrick M. Hanrahan and Werner Purgathofer, editors, </editor> <booktitle> Rendering Techniques '95: Proceedings of the Eurographics Rendering Workshop 1995, </booktitle> <pages> pages 45-54, </pages> <address> Dublin, Ireland, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The 3D image warp has been used to explore natural scenes acquired using cameras [13] and to accelerate the display of computer generated imagery <ref> [5, 8, 9] </ref>. The alternative Lumigraph / Light Field approach to image-based rendering [4, 6] may produce higher quality output, but requires a very large input data set.
Reference: [10] <author> Leonard McMillan. </author> <title> Computing visibility without depth. </title> <type> Technical Report UNC-CH TR95-047, </type> <institution> University of North Carolina at Chapel Hill, Dept. of Computer Science, </institution> <year> 1995. </year> <note> Available at http://www.cs.unc.edu/Research/tech-reports.html. </note>
Reference-contexts: Gortler et al. [5] use a back-to-front order to composite pixels into the output image using a splat footprint with fractional alpha values. In order to maintain the occlusion compatible order, certain restrictions must be followed in traversing the reference image. McMillan's dissertation [11] and papers <ref> [10, 12] </ref> discuss this point in detail. We provide a quick summary of these results here. The projection of the output-image view position onto the reference-image plane defines a point, referred to in the computer vision literature as an epipole. There are two types of reference-image epipoles, positive and negative.
Reference: [11] <author> Leonard McMillan. </author> <title> An Image-Based Approach to Three-Dimensional Computer Graphics. </title> <type> PhD thesis, </type> <institution> University of North Carolina at Chapel Hill, </institution> <year> 1997. </year> <note> Available as UNC-CH Computer Science TR97-013, at http://www.cs.unc.edu/Research/tech-reports.html. </note>
Reference-contexts: Gortler et al. [5] use a back-to-front order to composite pixels into the output image using a splat footprint with fractional alpha values. In order to maintain the occlusion compatible order, certain restrictions must be followed in traversing the reference image. McMillan's dissertation <ref> [11] </ref> and papers [10, 12] discuss this point in detail. We provide a quick summary of these results here. The projection of the output-image view position onto the reference-image plane defines a point, referred to in the computer vision literature as an epipole. <p> We begin this mathematical formulation by restating McMillan's 3D warp equation <ref> [11] </ref>: x 2 = ffi (x 1 )P 2 ( _ C 1 _ C 2 ) + P 2 P 1 x 1 ; (1) where x 1 is the reference-image location, x 2 is the output-image location, and ffi (x 1 ) is the generalized disparity associated with the
Reference: [12] <author> Leonard McMillan and Gary Bishop. </author> <title> Head-tracked stereoscopic display using image warping. </title> <editor> In S. Fisher, J. Merritt, and B. Bolas, editors, </editor> <booktitle> Proceedings SPIE, </booktitle> <volume> volume 2409, </volume> <pages> pages 21-30, </pages> <address> San Jose, CA, </address> <month> Feb </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Image-based rendering produces realistic-looking 3D graphics at a relatively low cost. The 3D image warp developed by McMillan and Bishop <ref> [12, 13] </ref> is particularly appropriate for low-cost implementation, because it requires a relatively small input data set. The 3D image warp has been used to explore natural scenes acquired using cameras [13] and to accelerate the display of computer generated imagery [5, 8, 9]. <p> Wolberg's book [14] provides a good overview of projective warps, and of image warping in general. The view interpolation system developed by Chen and Williams [3] used a 3D warp during pre-processing, but used a simpler interpolation algorithm at run-time. McMillan and Bishop developed a real-time 3D warp <ref> [12, 13] </ref>. Their system uses incremental evaluation of the 3D warp equations and an occlusion-compatible image-traversal order to achieve real-time performance. The rest of our presentation assumes that the reader understands this earlier work. The occlusion-compatible image-traversal order is an important part of McMillan and Bishop's work. <p> Gortler et al. [5] use a back-to-front order to composite pixels into the output image using a splat footprint with fractional alpha values. In order to maintain the occlusion compatible order, certain restrictions must be followed in traversing the reference image. McMillan's dissertation [11] and papers <ref> [10, 12] </ref> discuss this point in detail. We provide a quick summary of these results here. The projection of the output-image view position onto the reference-image plane defines a point, referred to in the computer vision literature as an epipole. There are two types of reference-image epipoles, positive and negative. <p> A standard raster organization of the output-image pixels in memory would result in poor utilization of the cache. 4.1 Standard Order The usual occlusion-compatible sheet-traversal order is a line-at-a-time raster scan of the sheet <ref> [12] </ref>. For a worst-case reference image that conforms to our pixel-movement bounds, this traversal order requires a large cache to avoid thrashing. Figure 7 illustrates this traversal order and its cache requirements.
Reference: [13] <author> Leonard McMillan and Gary Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In Computer Graphics Annual Conference Series (Proceedings of SIGGRAPH 95), </booktitle> <pages> pages 39-46, </pages> <address> Los Angeles, CA, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Image-based rendering produces realistic-looking 3D graphics at a relatively low cost. The 3D image warp developed by McMillan and Bishop <ref> [12, 13] </ref> is particularly appropriate for low-cost implementation, because it requires a relatively small input data set. The 3D image warp has been used to explore natural scenes acquired using cameras [13] and to accelerate the display of computer generated imagery [5, 8, 9]. <p> The 3D image warp developed by McMillan and Bishop [12, 13] is particularly appropriate for low-cost implementation, because it requires a relatively small input data set. The 3D image warp has been used to explore natural scenes acquired using cameras <ref> [13] </ref> and to accelerate the display of computer generated imagery [5, 8, 9]. The alternative Lumigraph / Light Field approach to image-based rendering [4, 6] may produce higher quality output, but requires a very large input data set. <p> Wolberg's book [14] provides a good overview of projective warps, and of image warping in general. The view interpolation system developed by Chen and Williams [3] used a 3D warp during pre-processing, but used a simpler interpolation algorithm at run-time. McMillan and Bishop developed a real-time 3D warp <ref> [12, 13] </ref>. Their system uses incremental evaluation of the 3D warp equations and an occlusion-compatible image-traversal order to achieve real-time performance. The rest of our presentation assumes that the reader understands this earlier work. The occlusion-compatible image-traversal order is an important part of McMillan and Bishop's work.
Reference: [14] <author> George Wolberg. </author> <title> Digital Image Warping. </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> California, </address> <year> 1992. </year> <month> 10 </month>
Reference-contexts: The 3D warp requires per-pixel depth information from the reference image, as well as the usual color information. Simpler projective image warps do not use per-pixel depth information, and thus for general images can compensate only for changes in view direction, ignoring changes in view position. Wolberg's book <ref> [14] </ref> provides a good overview of projective warps, and of image warping in general. The view interpolation system developed by Chen and Williams [3] used a 3D warp during pre-processing, but used a simpler interpolation algorithm at run-time. McMillan and Bishop developed a real-time 3D warp [12, 13]. <p> Our two pass algorithm was inspired by earlier two pass image-warping techniques. Catmull and Smith [2] developed a 2-pass technique for several classes of image warp, including planar-to-planar perspective warps. Many other researchers have extended this work; Wolberg's book <ref> [14] </ref> provides a good overview. Our two-pass technique differs from this earlier work in two ways. First, our algorithm is designed for the 3D warp rather than a projective warp. Second, the output of our first pass is a set of bins, rather than a complete image.
References-found: 14

