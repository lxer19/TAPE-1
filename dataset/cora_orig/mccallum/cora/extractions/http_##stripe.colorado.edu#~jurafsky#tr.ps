URL: http://stripe.colorado.edu/~jurafsky/tr.ps
Refering-URL: http://stripe.colorado.edu/~jurafsky/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Switchboard Discourse Language Modeling Project Final Report  
Author: Daniel Jurafsky Klaus Ries (CMU/Universitat Karlsruhe), Elizabeth Shriberg (SRI), Andreas Stolcke (SRI), Paul Taylor 
Date: January 23, 1998  
Note: Carol Van Ess-Dykema (DoD)  
Affiliation: Johns Hopkins  (University of Colorado), Rebecca Bates (Boston University), Noah Coccaro (University of Colorado), Rachel Martin (Johns Hopkins University), Marie Meteer (BBN),  (University of Edinburgh),  
Pubnum: LVCSR Workshop-97  
Abstract: We describe a new approach for statistical modeling and detection of discourse structure for natural conversational speech. Our model is based on 42 `Dialog Acts' (DAs), (question, answer, backchannel, agreement, disagreement, apology, etc). We labeled 1155 conversations from the Switchboard (SWBD) database (Godfrey et al. 1992) of human-to-human telephone conversations with these 42 types and trained a Dialog Act detector based on three distinct knowledge sources: sequences of words which characterize a dialog act, prosodic features which characterize a dialog act, and a statistical Discourse Grammar. Our combined detector, although still in preliminary stages, already achieves a 65% Dialog Act detection rate based on acoustic waveforms, and 72% accuracy based on word transcripts. Using this detector to switch among the 42 dialog-act-specific trigram LMs also gave us an encouraging but not statistically significant reduction in SWBD word error.
Abstract-found: 1
Intro-found: 1
Reference: <author> ALLEN, JAMES, and MARK CORE, </author> <year> 1997. </year> <title> Draft of DAMSL: Dialog act markup in several layers. </title>
Reference-contexts: We refer to these latter two types of discourse structure as SHALLOW DISCOURSE STRUCTURE. We chose to follow a recent standard for shallow discourse structure markup, the Discourse Annotation and Markup System of Labeling (DAMSL) tag-set, which was recently designed by the natural-language processing community 2 <ref> (Allen and Core 1997) </ref>. We began with this markup system and modified in a number of ways to make it more useful for our purposes in annotating Switchboard. Our initial tag-set consists of approximately 60 basic tags, many of which can be combined. <p> labeling accuracy; average pairwise Kappa (as of the end of the project) was 0.80. (0.8 or higher is considered high reliability (Carletta 1996; Flammia and Zue 1995).) There is a deterministic mapping between about 80% of the SWBD-DAMSL labels we used and the standard DAMSL labels that we started from <ref> (Allen and Core 1997) </ref>. In a few cases a mapping is not possible, usually for one of two reasons: either we and the coders were unable to accurately mark a distinction which the DAMSL standard 3 4 5 Table 2: 42 Dialog Acts with counts from the 197K-utterance training set.
Reference: <author> BARD, E., C. SOTILLO, A. ANDERSON, and M. TAYLOR. </author> <year> 1995. </year> <title> The DCIEM map task corpus: Spontaneous dialogues under sleep deprivation and drug. </title> <booktitle> Proc. ESCA-NATO Tutorial and Workshop on Speech under Stress, </booktitle> <address> Lisbon. </address>
Reference-contexts: The event features obtained using the event recognizer described in (Taylor et al. 1997). This detector relies on the intuition that different utterance types are characterized by different intonational `tunes' (Kowtko 1996), and has been applied successfully to the detection of move types in the Maptask corpus <ref> (Bard et al. 1995) </ref>. The system detects sequences of distinctive pitch patterns which characterize particular utterance types, by training one continuous density HMM for each DA to be detected (Taylor et al. 1997). Taylor et al.'s (1997) algorithm actually proceeds in 3 steps.
Reference: <author> BREIMAN, L., J. H. FRIEDMAN, R. A. OLSHEN, and C. J. STONE. </author> <year> 1983. </year> <title> Classification and Regression Trees. </title> <address> Pacific Grove, California: </address> <publisher> Wadsworth & Brooks. </publisher>
Reference-contexts: We also included the gender of the listener to check for a possible sociolinguistic interaction between the ways in which speakers employ different prosodic features and the conversational dyad 4.7.8 Decision Tree Classifiers For our prosodic classifiers, we used CART-style decision trees <ref> (Breiman et al. 1983) </ref>. Decision trees allow combination of discrete and continuous features, and can be inspected to gain an understanding of the role of different features and feature combinations. We downsampled our data to obtain an equal number of datapoints in each class.
Reference: <author> CARLETTA, JEAN. </author> <year> 1996. </year> <title> Assessing agreement on classification tasks: The Kappa statistic. </title> <note> Computational Linguistics 22.249254. </note> , <author> AMY ISARD, STEPHEN ISARD, JACQUELINE C. KOWTKO, GWYNETH DOHERTY-SNEDDON, </author> <title> and ANNE H. </title>
Reference: <author> ANDERSON. </author> <year> 1997. </year> <title> The reliability of a dialogue structure coding scheme. </title> <note> Computational Linguistics 23.1332. </note>
Reference: <author> DELLA PIETRA, S., V. DELLA PIETRA, and J. LAFFERTY. </author> <year> 1997. </year> <title> Inducing features in random fields. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 19.113. </journal>
Reference: <author> FLAMMIA, GIOVANNI, and VICTOR ZUE. </author> <year> 1995. </year> <title> Empirical evaluation of human performance and agreement in parsing discourse constituents in spoken dialogue. </title> <address> EUROSPEECH-95, 19651968, Madrid. </address>
Reference: <author> GODFREY, J., E. HOLLIMAN, and J. MCDANIEL. </author> <year> 1992. </year> <title> SWITCHBOARD: Telephone speech corpus for research and development. </title> <booktitle> Proceedings of ICASSP-92, 517520, </booktitle> <address> San Francisco. </address>
Reference: <author> GORIN, ALLEN. </author> <year> 1995. </year> <title> On automated language acquistition. </title> <journal> Journal of the Acoustical Society of America 97.3441 3461. </journal>
Reference: <author> GROSZ, BARBARA, and JULIA HIRSCHBERG. </author> <year> 1992. </year> <title> Some intonational characteristics of discourse structure. </title> <address> ICSLP-92, 429432, Banff, Canada. </address>
Reference: <author> GROSZ, BARBARA J., ARAVIND K. JOSHI, and SCOTT WEINSTEIN. </author> <year> 1995. </year> <title> Centering: A framework for modeling the local coherence of discourse. </title> <note> Computational Linguistics 21.203225. </note>
Reference: <author> HEARST, MARTI A. </author> <year> 1997. </year> <title> Texttiling: Segmenting text into multi-paragraph subtopic passages. </title> <note> Computational Linguistics 23.3364. </note>
Reference-contexts: This technique is common in subtopic identification <ref> (Hearst 1997) </ref> and in the cue-word literature (Garner et al 1996, Hirschberg and Litman 1993, etc). This technique relies on the fact that utterances have very distinct word strings, and indeed they seem to.
Reference: <author> HIRSCHBERG, JULIA, and CHRISTINE NAKATANI. </author> <year> 1996. </year> <title> A prosodic analysis of discourse segments in direction-giving monologues. </title> <booktitle> Proceedings of ACL-96, </booktitle> <pages> 286293. </pages>
Reference-contexts: This technique is common in subtopic identification (Hearst 1997) and in the cue-word literature <ref> (Garner et al 1996, Hirschberg and Litman 1993, etc) </ref>. This technique relies on the fact that utterances have very distinct word strings, and indeed they seem to. For example, 92.4% of the uh huh's occur in Backchannels 88.4%, while of the trigrams &lt;start&gt; do you occur in Yes-No-Questions.
Reference: <author> IYER, RUKMINI, MARI OSTENDORF, and J. ROBIN ROHLICEK. </author> <year> 1994. </year> <title> Language modeling with sentence-level mixtures. </title> <booktitle> ARPA Human Language Technologies Workshop, 8286, </booktitle> <address> Plainsboro, N.J. </address> <note> 47 JEFFERSON, GAIL. 1984. Notes on a systematic deployment of the acknowledgement tokens 'yeah' and 'mm hm'. Papers in Linguistics 197216. </note>
Reference-contexts: The experiment consisted of two phases. In the first phase, posterior DA probabilities P (U i jA) were computed, using the N-best based DA detector (Section 4.5). These probabilities were then used in a sentence-level mixture <ref> (Iyer et al. 1994) </ref> of the 42 DA-specific (smoothed) language models, such that the mixture weight for each LM corresponded to the posterior probability of the corresponding DA.
Reference: <author> JURAFSKY, DANIEL, REBECCA BATES, NOAH COCCARO, RACHEL MARTIN, MARIE METEER, KLAUS RIES, ELIZABETH SHRIBERG, ANDREAS STOLCKE, PAUL TAYLOR, and CAROL VAN ESS-DYKEMA. </author> <year> 1997a. </year> <title> Automatic detection of discourse structure for speech recognition and understanding. </title> <booktitle> Proceedings of the 1997 IEEE Workshop on Speech Recognition and Understanding, </booktitle> <address> Santa Barbara. </address>
Reference: <author> JURAFSKY, DANIEL, ELIZABETH SHRIBERG, and DEBRA BIASCA, </author> <year> 1997b. </year> <title> Switchboard-DAMSL Labeling Project Coder's Manual. </title> <address> http://stripe.colorado.edu/jurafsky/ manual.august1.html. </address>
Reference-contexts: We have not attempted in this report to map these DAMSL-style tags into other theories of speech acts, intention-tracking in discourse, discourse commitment, centering, etc. See our Coders' Manual <ref> (Jurafsky et al. 1997b) </ref> for more theoretical justifications for the particular tagging philosophy. 3.1 Examples of the Dialog Acts See Jurafsky et al. (1997b) for a complete description of the discourse acts.
Reference: <author> KATZ, SLAVA M. </author> <year> 1987. </year> <title> Estimation of probabilities from sparse data for the language model component of a speech recogniser. </title> <journal> IEEE Trans. ASSP 35.400401. </journal>
Reference-contexts: We implemented this approach by estimating backoff N-gram models <ref> (Katz 1987) </ref> from the hand-labeled DA sequences of the training data available to us.
Reference: <author> KITA, KENJI, YOSHIKAZU FUKUI, MASAAKI NAGATA, and TSUYOSHI MORIMOTO. </author> <year> 1996. </year> <title> Automatic acquisition of probabilistic dialogue models. </title> <address> ICSLP-96, 196199, Philadephia. </address>
Reference: <author> KOWTKO, JACQUELINE C., </author> <year> 1996. </year> <title> The Function of Intonation in Task Oriented Dialogue. </title> <institution> University of Edinburgh dissertation. </institution>
Reference-contexts: The event features obtained using the event recognizer described in (Taylor et al. 1997). This detector relies on the intuition that different utterance types are characterized by different intonational `tunes' <ref> (Kowtko 1996) </ref>, and has been applied successfully to the detection of move types in the Maptask corpus (Bard et al. 1995). The system detects sequences of distinctive pitch patterns which characterize particular utterance types, by training one continuous density HMM for each DA to be detected (Taylor et al. 1997).
Reference: <author> KUHN, ROLAND, and RENATO DE MORI. </author> <year> 1990. </year> <title> A cache-based natural language model for speech recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 12.570583. </journal>
Reference-contexts: Our preliminary conclusion is therefore that ME and backoff models produce roughly equivalent results when used as discourse grammars. Cache models We used a standard unigram and bigram cache model <ref> (Kuhn and de Mori 1990) </ref> and interpolated it with a backoff model that was generated as described above. This technique typical achieves a significant perplexity win on standard SWBD language models for words and we had hoped to see a similar improvement if not more for the Discourse Grammar.
Reference: <author> LAVIE, ALON, DONNA GATES, NOAH COCCARO, and LORI LEVIN. </author> <year> 1996a. </year> <title> Input segmentation of spontaneous speech in janus: A speech-to-speech translation system. </title> <booktitle> Proceedings of the ECAI 96, </booktitle> <address> Budapest. </address>
Reference: <author> LAVIE, ALON, LORI LEVIN, YAN QU, ALEX WAIBEL, DONNA GATES, MARSAL GAVALDA, LAURA MAYFIELD, and MAITE TABOADA. </author> <year> 1996b. </year> <title> Dialogue processing in a conversational speech translation system. </title> <publisher> ICSLP-96, Philadephia. </publisher>
Reference: <author> LITMAN, DIANE J., and JAMES F. ALLEN. </author> <year> 1987. </year> <title> A plan recognition model for subdialogues in conversations. </title> <journal> Cognitive Science 11.163200. </journal>
Reference: <author> MAST, M., R. KOMPE, ST. HARBECK, A. KIESSLING, H. NIEMANN, , and E. N OTH. </author> <year> 1996. </year> <title> Dialog act classification with the help of prosody. </title> <journal> ICSLP-96, </journal> <volume> 17281731, </volume> <month> Philadephia. </month>
Reference: <author> METEER, MARIE, and OTHERS. </author> <year> 1995. </year> <title> Dysfluency Annotation Stylebook for the Switchboard Corpus. Linguistic Data Consortium. </title> <note> Revised June 1995 by Ann Taylor. ftp://ftp.cis.upenn.edu/pub/treebank/swbd/doc/DFL-book.ps.gz. </note>
Reference-contexts: The 8 labelers were CU Boulder linguistics grad students: Debra Biasca (supervisor), Marion Bond, Traci Curl, Anu Erringer, Michelle Gregory, Lori Heintzel-man, Taimi Metzler, and Amma Oduro. Most of the utterances were presegmented by the Linguistic Data Consortium <ref> (Meteer et al. 1995) </ref>, although a few had not been segmented, and had to be segmented by the labelers prior to labeling. By the end of the labeling the labelers took just under 30 minutes to label a conversation (conversations averaged 144-turns, 271 utterances). <p> to the saying, There's no data like more data. 6.2 Extensions: Above and Below the Statement In the work described so far, the unit over which the algorithms operated is the sentence, or linguistic segment as defined by the annotation of the SWBD corpus done by the LDC in 1996 <ref> (Meteer, et al 1995) </ref>, and utterances in the terminology of this document.
Reference: <author> MORGAN, NELSON, ERIC FOSLER, and NIKKI MIRGHAFORI. </author> <year> 1997. </year> <title> Speech recognition using on-line estimation of speaking rate. </title> <address> EUROSPEECH-97, Rhodes, Greece. </address>
Reference-contexts: For this purpose, we experimented with a signal processing measure, enrate, which is currently under development at ICSI by Nelson Morgan, Nikki Mirghafori and Eric Fosler. This measure runs directly on the speech signal, and has been shown to correlate moderately with lexical measures of speaking rate <ref> (Morgan et al. 1997) </ref>. The measure can be run over the entire signal, but because it uses a large window, values are less meaningful if significant pause time is included in the window.
Reference: <author> NAGATA, MASAAKI, and TSUYOSHI MORIMOTO. </author> <year> 1994. </year> <title> First steps toward statistical modeling of dialogue to predict the speech act type of the next utterance. Speech Communication 15.193203. </title>
Reference: <author> NEUMEYER, LEONARDO, and MITCH WEINTRAUB. </author> <year> 1994. </year> <title> Microphone-independent robust signal processing using probabilistic optimum filtering. </title> <booktitle> ARPA HLT Workshop, 336341, </booktitle> <address> Plainsboro, NJ. </address> , <month> and . </month> <year> 1995. </year> <title> Robust speech recognition in noise using adaptation and mapping techniques. </title> <journal> ICASSP-95, </journal> <volume> volume 1, </volume> <pages> 141144, </pages> <address> Detroit. </address>
Reference: <author> OSTENDORF, M., and N. VEILLEUX. </author> <year> 1994. </year> <title> A hierarchical stochastic model for automatic prediction of prosodic boundary location. </title> <note> Computational Linguistics 20. </note>
Reference: <author> PASSONNEAU, REBECCA, and DIANE LITMAN. </author> <year> 1993. </year> <title> Feasibility of automated discourse segmentation. </title> <booktitle> Proceedings of the 31st ACL, </booktitle> <pages> 148155. </pages>
Reference: <author> PERRAULT, C. R., and J. F. ALLEN. </author> <year> 1980. </year> <title> A plan-based analysis of indirect speech acts. </title> <journal> American Journal of Computational Linguistics 6.167182. </journal>
Reference: <author> RABINER, L. R., and B. H. JUANG. </author> <year> 1986. </year> <title> An introduction to hidden Markov models. </title> <journal> IEEE ASSP Magazine 3.416. </journal> <note> 48 REITHINGER, </note> <author> NORBERT, RALF ENGEL, MICHAEL KIPP, and MARTIN KLESEN. </author> <year> 1996. </year> <title> Predicting dialogue acts for a speech-to-speech translation system. </title> <journal> ICSLP-96, </journal> <volume> 654657, </volume> <month> Philadephia. </month>
Reference-contexts: The importance of the Markov assumption for the discourse grammar is that we can now view the whole system of discourse grammar and local utterance-based likelihoods as a kth-order hidden Markov model (HMM) <ref> (Rabiner and Juang 1986) </ref>. The HMM states correspond to DAs, observations corresponds to utterances, transition probabilities are given by the discourse grammar, and observation probabilities are given by the local likelihoods P (E i jU i ).
Reference: <author> ROSENFELD, R., R. AGARWAL, B. BYRNE, R. IYER, M. LIBERMAN, E. SHRIBERG, J. UNVERFUEHRT, D. VER-GYRI, and E. VIDAL. </author> <year> 1996. </year> <title> LM95 Project Report: Language modeling of spontaneous speech. </title> <note> Technical Report Research Note No. 1, Center for Language and Speech Processing, </note> <institution> Johns Hopkins University, Baltimore. </institution>
Reference-contexts: The baseline language model was a standard trigram trained on 1.8 million words from Switchboard. Since earlier WS95 work had shown that N-gram LMs based on complete utterance units give lower perplexity than those trained on acoustic segments <ref> (Rosenfeld et al. 1996) </ref>, this language model included a token marking utterance boundaries. However only 1.4 million of the 1.8 million SWBD words (i.e. the WS97-TRAIN `linguistically segmented' corpus) had hand-coded utterance boundaries.
Reference: <author> ROSENFELD, RONI. </author> <year> 1996. </year> <title> A maximum entropy approach to adaptive statistical language modeling. </title> <booktitle> Computer Speech and Language 10.187228. </booktitle>
Reference-contexts: The baseline language model was a standard trigram trained on 1.8 million words from Switchboard. Since earlier WS95 work had shown that N-gram LMs based on complete utterance units give lower perplexity than those trained on acoustic segments <ref> (Rosenfeld et al. 1996) </ref>, this language model included a token marking utterance boundaries. However only 1.4 million of the 1.8 million SWBD words (i.e. the WS97-TRAIN `linguistically segmented' corpus) had hand-coded utterance boundaries.
Reference: <author> SACKS, HARVEY, EMANUEL A. SCHEGLOFF, and GAIL JEFFERSON. </author> <year> 1974. </year> <title> A simplest systematics for the organization of turn-taking for conversation. </title> <booktitle> Language 50.696735. </booktitle> <address> SCHEGLOFF, EMANUAL. </address> <year> 1968. </year> <title> Sequencing in conversational openings. </title> <publisher> American Anthropologist 70.10751095. </publisher>
Reference: <author> SCHEGLOFF, EMANUAL A. </author> <year> 1982. </year> <title> Discourse as an interactional achievement: Some uses of 'uh huh' and other things that come between sentences. Analyzing discourse: Text and talk, edited by deborah tannen. </title> <address> Washington, D.C.: </address> <publisher> Georgetown University Press. </publisher>
Reference: <author> SEARLE, JOHN R. </author> <year> 1969. </year> <title> Speech Acts. </title> <publisher> Cambridge: Cambridge University Press. </publisher>
Reference: <author> SHRIBERG, ELIZABETH, REBECCA BATES, and ANDREAS STOLCKE. </author> <year> 1997. </year> <title> A prosody-only decision-tree model for disfluency detection. </title> <journal> EUROSPEECH-97, </journal> <volume> volume 5, 23832386, </volume> <pages> Rhodes, </pages> <address> Greece. </address>
Reference-contexts: Our approach builds on recent methodology that has achieved good success on conversational speech for a different task <ref> (Shriberg et al. 1997) </ref>. The method involves construction of a large database of automatically extracted acoustic-prosodic features. In training, decision tree classifiers are inferred from the features; the trees are then applied to an unseen set of data to evaluate performance. We apply the trees to four DA-classification tasks.
Reference: <author> SHRIBERG, ELIZABETH, REBECCA BATES, PAUL TAYLOR, ANDREAS STOLCKE, DANIEL JURAFSKY, KLAUS RIES, NOAH COCCARO, RACHEL MARTIN, MARIE METEER, and CAROL VAN ESS-DYKEMA. </author> <year> 1998. </year> <title> Can prosody aid the automatic classification of dialog acts in conversational speech? Submitted to Language and Speech </title> . 
Reference: <author> STOLCKE, ANDREAS. </author> <year> 1997. </year> <title> Modeling linguistic segment and turn boundaries for N-best rescoring of of spontaneous speech. </title> <journal> EUROSPEECH-97, </journal> <volume> volume 5, </volume> <pages> 27792782. </pages> , <note> YOCHAI KONIG, </note> <author> and MITCH WEINTRAUB. </author> <year> 1997. </year> <title> Explicit word error minimization in N-best list rescoring. </title> <journal> EUROSPEECH-97, </journal> <volume> volume 1, 163166. </volume> , <editor> and ELIZABETH SHRIBERG. </editor> <year> 1996. </year> <title> Automatic linguistic segmentation of conversational speech. </title> <journal> ICSLP-96, </journal> <note> 10051008, </note> <author> Philadephia. , , REBECCA BATES, NOAH COCCARO, DANIEL JURAFSKY, RACHEL MARTIN, MARIE METEER, KLAUS RIES, PAUL TAYLOR, and CAROL VAN ESS-DYKEMA. </author> <year> 1998. </year> <title> Dialog act modeling for conversational speech. </title> <note> AAAI Spring Symposium on Applying Machine Learning to Discourse Processing . to appear. </note>
Reference-contexts: likelihoods and Markovian discourse grammar it will therefore find precisely the DA sequence with the highest posterior probability: U fl = argmax U This maximizes the probability of getting the entire DA sequence correct, but it does not necessarily find the DA sequence that has the most DA labels correct <ref> (Stolcke et al. 1997) </ref>. To minimize the overall utterance labeling error, we need to maximize the probability of getting each DA label correct individually, i.e., we need to maximize P (U i jE) for each i = 1; : : : ; n.
Reference: <author> SUHM, B., and A. WAIBEL. </author> <year> 1994. </year> <title> Toward better language models for spontaneous speech. </title> <journal> ICSLP-94, </journal> <volume> 831834. </volume>
Reference: <author> TAYLOR, PAUL, SIMON KING, STEPHEN ISARD, and HELEN WRIGHT. </author> <year> 1998. </year> <title> Intonation and dialogue context as constraints for speech recognition. Submitted to Language and Speech . , , , , and JACQUELINE KOWTKO. 1997. Using intonation to constrain language models in speech recognition. </title> <journal> EUROSPEECH-97, </journal> <volume> 27632766, </volume> <pages> Rhodes, </pages> <address> Greece. </address>
Reference: <author> TAYLOR, PAUL, H. SHIMODAIRA, STEPHEN ISARD, SIMON KING, and JACQUELINE KOWTKO. </author> <year> 1996. </year> <title> Using prosodic information to constrain language models for spoken dialogue. </title> <address> ICSLP'96, Philadelphia. </address>
Reference: <author> TERRY, MARK, RANDALL SPARKS, and PATRICK OBENCHAIN. </author> <year> 1994. </year> <title> Automated query identification in English dialogue. </title> <journal> ICSLP-94, </journal> <volume> 891894. </volume>
Reference: <author> WAIBEL, ALEX. </author> <year> 1988. </year> <title> Prosody and Speech Recognition. </title> <address> San Mateo, CA.: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> WALKER, MARILYN A., and ELLEN F. PRINCE. </author> <year> 1993. </year> <title> A bilateral approach to givenness: A hearer-status algorithm and a centering algorithm. Reference and referent accessibility, </title> <editor> ed. by T. Fretheim and J. Gundel. </editor> <publisher> Amsterdam: John Benjamins. 49 WEBER, </publisher> <editor> ELIZABETH G. </editor> <year> 1993. </year> <title> Varieties of Questions in English Conversation. </title> <publisher> Amsterdam: John Benjamins. </publisher>
Reference: <author> WITTEN, I. H., and T. C. BELL. </author> <year> 1991. </year> <title> The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression. </title> <journal> IEEE Trans. Information Theory 37.10851094. </journal>
Reference-contexts: The Witten-Bell smoothing scheme was used to discount the relative frequencies <ref> (Witten and Bell 1991) </ref>. 4.3.2 Modeling turns So far we have ignore the fact that DAs are associated with multiple speakers. Surely it is important to model not only the DA sequence, but also which speaker said what. <p> In our first experiment, we built 42 separate trigram language models, one for each DA. Each was based on a standard backoff trigram with Witten-Bell discounting <ref> (Witten and Bell 1991) </ref>.
Reference: <author> WOSZCZYNA, M., and A. WAIBEL. </author> <year> 1994. </year> <title> Inferring linguistic structure in spoken language. </title> <address> ICSLP-94, 847850, Yokohama, Japan. </address>
Reference: <author> YAMAOKA, TAKAYUKI, and HITOSHI IIDA. </author> <year> 1991. </year> <title> Dialogue interpretation model and its application to next utterance prediction for spoken language processing. EUROSPEECH-91, </title> <type> 849852, </type> <institution> Genova, Italy. </institution>
Reference: <author> YNGVE, VICTOR H. </author> <year> 1970. </year> <title> On getting a word in edgewise. </title> <booktitle> Papers from the 6th Regional Meeting of the Chicago Linguistics Society, 567577, </booktitle> <address> Chicago. </address> <month> 50 </month>
References-found: 50

