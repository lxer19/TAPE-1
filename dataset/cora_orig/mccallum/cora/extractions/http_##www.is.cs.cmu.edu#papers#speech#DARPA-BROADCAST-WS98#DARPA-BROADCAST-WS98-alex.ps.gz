URL: http://www.is.cs.cmu.edu/papers/speech/DARPA-BROADCAST-WS98/DARPA-BROADCAST-WS98-alex.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: (waibel,mbett,finkem)@cs.cmu.edu  
Title: Meeting Browser: Tracking and Summarizing Meetings speech transcription engine, based on the JANUS recognition toolkit,
Author: A. Waibel, M. Bett M. Finke 
Note: The system consists of four major components: 1.) the  For  1)  were carried  
Address: Pittsburgh, PA 15213, USA  
Affiliation: Interactive Systems Laboratories Carnegie Mellon University  
Abstract: To provide rapid access to meetings between human beings, transcription, tracking, retrieval and summarization of ongoing human-to-human conversation has to be achieved. In DARPA and DoD sponsored work (projects GENOA and CLARITY) we aim to develop strategies to transcribe human discourse and provide rapid access to the structure and content of this human exchange. results in a increase in error rate. This is explained by the greater confusion between the dictionary entries, particularly, for short reduced words. We developed a probabilistic model based on context dependent phonetic rewrite rules to derive a list of possible pronunciations for all words or sequences of words [2][4]. In order to reduce the confusion of this expanded dictionary, each variant of a word is annotated with an observation probability. To this aim we automatically retranscribe the corpus based on all allowable variants using flexible utterance transcription graphs (Flexible Transcription Alignment (FTA) [5]) and speaker adapted models. The alignments are then used to train a model of how likely which form of variation (i.e. rule) is and how likely a variant is, to be observed in a certain context (acoustic, word, speaking mode or dialogue) is. To date, we have experimented with three different meeting environments and tasks to assess the performance in terms of word accuracy and summarization quality: i.) Switchboard human to human telephone conversations, ii.) Research group meetings recorded in the Interactive Systems labs and iii.) Simulated crisis management meetings (3 participants) which also include video capture of the individuals. We report results from speech recognition experiments in the first two conditions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Carbonell, J. G., Geng, Y., and Goldstein, J., </author> <title> Automated Query-Relevant Summarization and Diversity-Based Reranking, </title> <booktitle> IJCAI-97 Workshop on AI and Digital Libraries, </booktitle> <year> 1997. </year>
Reference-contexts: In the following experiments, we attempt to quantify the quality and compression achieved by this approach. As a first metric for selecting salient, informative passages from a human dialog, we have explored the Maximal Marginal Relevance (MMR) metric <ref> [1] </ref> first introduced for text summarization in the TIPSTER project ( Carbonell [1]). The MMR iteratively maximizes the similarity between a query and each section of a document while it minimizes the similarity among previously ranked document sections. <p> As a first metric for selecting salient, informative passages from a human dialog, we have explored the Maximal Marginal Relevance (MMR) metric <ref> [1] </ref> first introduced for text summarization in the TIPSTER project ( Carbonell [1]). The MMR iteratively maximizes the similarity between a query and each section of a document while it minimizes the similarity among previously ranked document sections. It thereby identifies the most relevant, yet most diverse, nonredundant sections of a document.
Reference: [2] <author> Michael Finke and Alex Waibel, </author> <title> Speaking Mode Dependent Pronunciation Modeling in Large Vocabulary Conversational Speech Recognition,; </title> <booktitle> Eurospeech 97, </booktitle> <address> Rhodes, Greece. </address>
Reference: [3] <author> M. Finke and J. Fritsch and P. Geutner and K. Ries and T. Zeppenfeld and A. Waibel, </author> <title> The JanusRTk Switchboard/Callhome 1997 Evaluation System, </title> <booktitle> Proceedings of LVCSR Hub 5-e Workshop, </booktitle> <month> May </month> <year> 1997, </year>
Reference: [4] <author> M. Finke, </author> <title> The JanusRTk Switchboard/ Callhome 1997 Evaluation System: Pronunciation Modeling, </title> <booktitle> Proceedings of LVCSR Hub 5-e Workshop, </booktitle> <month> May </month> <year> 1997 </year>
Reference-contexts: 1) Human to Human Telephone The test set to evaluate the use of the flexible transcription alignment approach consisted of the Switchboard and CallHome partitions of the 1996 NIST Hub-5e evaluation set. All test runs were carried out using a Switchboard recognizer trained with the JANUS Recognition Toolkit (JRTk) <ref> [4] </ref>. The preprocessing of the system begins by extracting MFCC based feature vectors every 10 ms. A truncated LDA transformation is performed over a concatenation of MFCCs and their first and second order derivatives are determined.
Reference: [5] <author> M. Finke and A. Waibel, </author> <title> Flexible Transcription Alignment, </title> <booktitle> 1997 IEEE Workshop on Speech Recognition and Understanding, </booktitle> <address> Santa Barbara, California, </address> <month> December </month> <year> 1997 </year>
Reference: [6] <author> M. Ostendorf and B. Byrne and M. Bacchiani and M. Finke and A. Gunawardana and K. Ross and S. Roweis and E. Shriberg and D. Talkin and A.Waibel and B. Wheatley and T. Zeppenfeld, </author> <title> Systematic Variations in Pronunciation via a Language-Dependent Hidden Speaking Mode, </title> <booktitle> ICSLP, </booktitle> <address> Philadelphia, USA, </address> <year> 1996 </year>
Reference: [7] <institution> An Algorithm for Suffix Stripping, Porter , Computer Lab, </institution> <month> July </month> <year> 1980, </year> <journal> vol 14, </journal> <volume> no. 3, </volume> <pages> p 130-137. </pages>
Reference-contexts: As a further simplification, we are only considering the first four letters of a word to be significant. This technique has proven successful [8] as compromise taking the place of better stemming algorithms <ref> [7] </ref>. Once the common stem has been identified, in the third step each turn that has not previously been included in the summary is weighted. We count the number of occurrences of the common word stem in the turn.
Reference: [8] <institution> Fast Generation of Abstracts from General Domain Text Corpora by Extracting Relevant Sentences, </institution> <note> Zechner, </note> <editor> Klaus, </editor> <booktitle> Proceedings of COLING-96, </booktitle> <pages> pp. 986-989, </pages> <address> Kopenhagen, </address> <year> 1996 </year>
Reference-contexts: We believe that finding the common stem provides an indication of the most important remaining topic in the document. As a further simplification, we are only considering the first four letters of a word to be significant. This technique has proven successful <ref> [8] </ref> as compromise taking the place of better stemming algorithms [7]. Once the common stem has been identified, in the third step each turn that has not previously been included in the summary is weighted. We count the number of occurrences of the common word stem in the turn.
Reference: [9] <author> T. Zeppenfeld and M. Finke and K. Ries and M. Westphal and A. Waibel, </author> <title> Recognition of Conversational Telephone Speech using the JANUS Speech Engine, </title> <booktitle> IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Munich, Germany, </address> <publisher> IEEE, </publisher> <year> 1997 </year>
Reference-contexts: Such acoustic stability often identifies a good candidate for adaptation. Using only these words in the adaptation procedure produces 1-2% gains in word accuracy over blind adaptation <ref> [9] </ref>. The baseline performance of the JRTk based WSJ Recognizer over the Hub4-Nov94 test set is about 7% WER.
References-found: 9

