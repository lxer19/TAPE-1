URL: ftp://ftp.cs.brown.edu/pub/techreports/96/cs96-19.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-96-19.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler activations: effective kernel support for the user-level management of parallelism. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principle, </booktitle> <pages> pages 95-109. </pages> <publisher> ACM SIGOPS, </publisher> <month> October </month> <year> 1991. </year> <note> Published in ACM Operating Systems Review Vol.25, No.5, 1991. Also published ACM Transactions on Computer Systems Vol.10 No.1, pp.53-70, </note> <month> Feb 92. </month>
Reference-contexts: Anderson et. al. suggest a dramatically different approach using scheduler actvia-tions <ref> [1] </ref>.
Reference: [2] <author> Ben Catanzaro. </author> <title> Multiprocessor System Architectures. </title> <publisher> SunSoft Press, </publisher> <year> 1994. </year>
Reference-contexts: The kernel knows only about the kernel-level threads; it does not know of the multiplexing performed by the user-level scheduler. Due to the many-to-many relationship between cold threads and hot threads, this is referred to as the M-to-N model [8] (it is also referred to as the two-level model <ref> [2] </ref>, the split model [11] and the LWP model). By taking a hybrid approach, this model aims to combine the advantages of both the N-to-1 model and 1-to-1 model, while minimizing those models' disadvantages. <p> This latency is particularly exacerbated when contention is moderately high. The M-to-N model is touted as providing inexpensive synchronization <ref> [9, 2, 11, 8] </ref>, but it appears that this is not always the case. 5.2 Coarse-grained barriers We noticed that once the amount of work done between each barrier synchronization became nontrivial, the difference between n bound threads and n unbound threads with an LWP pool of size n disappeared.
Reference: [3] <author> Ding-Kai Chen, Hong-Hen Su, and Pen-Chung Yew. </author> <title> The impact of synchronization and granularity in parallel systems. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 239-248, </pages> <year> 1990. </year> <note> Also as Tech report 942 University of Illinois at Urbana-Champaign, </note> <institution> Centre of Supercomputing Research and Development. </institution>
Reference-contexts: In an effort to simulate commonly used techniques, our experiments analyzed the performance of the model using barrier synchronization <ref> [3] </ref>. All threads perform some amount of computation, and block until the others reach a common synchronization point.
Reference: [4] <author> Roger Faulkner and Ron Gomes. </author> <title> The process file system and process model in UNIX system V. </title> <booktitle> In USENIX Conference Proceedings, </booktitle> <pages> pages 243-252, </pages> <address> Dallas, TX, </address> <month> January 21-25 </month> <year> 1991. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: The most important data gathered by the library is done so by interpositioning between the user-level threads library and itself. That is, ThreadMon redefines many of the functions which the user-level threads library uses internally to change the state of threads and LWPs. * Process file system <ref> [4] </ref>. The /proc filesystem offers a wealth of performance information. Specifically, PIOCLUSAGE is used to determine LWP states. * Kernel statistics interface. The kstat (7d) interface is used to obtain CPU usage statistics. * Trace Normal Form.
Reference: [5] <author> David Golub, Randall Dean, Alessandro Forin, and Richard Rashid. </author> <title> UNIX as an application program. </title> <booktitle> In USENIX Conference Proceedings, </booktitle> <pages> pages 87-96, </pages> <address> Anaheim, CA, </address> <month> Summer </month> <year> 1990. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: Many stock kernels associate a process entry directly with one runnable hot thread; separating these two entities is a nontrivial coding effort. 2.3 M-to-N model In an attempt to combine these two models, some operating systems, notably Mach 3.0 <ref> [5] </ref>, SVR4/MP and SunOS 5.x [9], provide both user-level threads and kernel threads to the programmer. User-level threads are multiplexed on top of kernel-level threads, which in turn are scheduled on top of processors.
Reference: [6] <institution> Institute for Electrical and Electronic Engineers. POSIX P1003.4a, Threads Extensions for Portable Operating Systems, </institution> <year> 1994. </year>
Reference-contexts: 1 Introduction Since the approval of the POSIX threads standard <ref> [6] </ref>, multithreaded programming has experienced an explosion of interest. Many applications have appreciated performance gains through multithreading; the popular Netscape web browser is a highly visible example of a program whose multithreading has an obvious and substantial performance impact. <p> Threads which are critical can have a 1-to-1 relationship with an underlying hot thread, while a large number of less critical threads can be multiplexed on a single hot thread. Under the POSIX specification <ref> [6] </ref>, this mapping is specified by the contention scope of each thread. Threads may have either a system scope (and are thus associated in a 1-to-1 fashion with underlying hot threads) or a process scope (in which case they're multiplexed on top of hot threads 4 ).
Reference: [7] <author> Thomas W. Doeppner Jr. </author> <title> Threads: A system for the support of concurrent programming. </title> <type> Technical Report CS-87-11, </type> <institution> Brown University, Department of Computer Science, </institution> <address> Providence, RI 02912, </address> <month> Jun </month> <year> 1987. </year>
Reference-contexts: The blocking hot thread will block the entire process, even in the presence of runnable cold threads. While it adds significantly to implementation complexity, the library can circumvent this problem where asynchronous variants of system calls exist <ref> [7] </ref>. * Nonscalable. Multithreaded programs under the N-to-1 model will run no faster on multiprocessors than they run on uniprocessors. The single hot thread acts as a bottle neck, preventing optimal use of the multiprocessor.
Reference: [8] <author> Steve Kleiman, Devang Shah, and Bart Smaalders. </author> <title> Programming with Threads. </title> <publisher> SunSoft Press, </publisher> <year> 1996. </year> <note> ISBN: 0131723898. </note>
Reference-contexts: As multiprocessors proliferate, the performance characteristics of the underlying thread scheduling model will become increasingly significant. In this paper, we perform runtime analysis of one of the more popular models, the M-to-N <ref> [8] </ref> model, as implemented on SunOS 5.5 1 . Our results were not what we expected; to explain the phenomena behind them, we use a runtime tool we developed, ThreadMon, to effectively identify some performance caveats of the model. <p> Due to the many-to-one relationship between cold threads and hot threads, this is referred to as the N-to-1 model <ref> [8] </ref>. There are several advantages to this model: * Cheap synchronization. When a cold thread wishes to perform synchronization, the user-level thread library checks to see if the thread needs to block. <p> The kernel knows only about the kernel-level threads; it does not know of the multiplexing performed by the user-level scheduler. Due to the many-to-many relationship between cold threads and hot threads, this is referred to as the M-to-N model <ref> [8] </ref> (it is also referred to as the two-level model [2], the split model [11] and the LWP model). By taking a hybrid approach, this model aims to combine the advantages of both the N-to-1 model and 1-to-1 model, while minimizing those models' disadvantages. <p> This latency is particularly exacerbated when contention is moderately high. The M-to-N model is touted as providing inexpensive synchronization <ref> [9, 2, 11, 8] </ref>, but it appears that this is not always the case. 5.2 Coarse-grained barriers We noticed that once the amount of work done between each barrier synchronization became nontrivial, the difference between n bound threads and n unbound threads with an LWP pool of size n disappeared. <p> We wished to explore the performance of coarse-grained barriers when the number of threads exceeded the number of LWPs in the pool. Specifically, we believed that based on the monitoring of code from <ref> [8] </ref>, the nonpreemptability of the user-level threads package would have nondesirable performance effects. Indeed, our results (figure 4) show that when the number of threads is not a multiple of the number of processors, the version using unbound threads experiences significant performance degradation. (right figure).
Reference: [9] <author> M. L. Powell, Steve R. Kleiman, Steve Barton, Devang Shah, Dan Stein, and Mary Weeks. </author> <title> SunOS multi-thread architecture. </title> <booktitle> In Proceedings of the Winter 1991 USENIX Technical Conference and Exhibition, </booktitle> <pages> pages 65-80, </pages> <address> Dallas, TX, USA, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Because kernel threads require kernel involvement to be descheduled, hot thread synchronization will require a system call if the lock is not immediately acquired 3 . Estimates vary, but if a trap is required, synchronization will be from three to ten times more costly than for the N-to-1 case <ref> [9, 11] </ref>. * Expensive creation. Under the 1-to-1 model, every thread creation requires explicit kernel involvement and consumes kernel resources. <p> Many stock kernels associate a process entry directly with one runnable hot thread; separating these two entities is a nontrivial coding effort. 2.3 M-to-N model In an attempt to combine these two models, some operating systems, notably Mach 3.0 [5], SVR4/MP and SunOS 5.x <ref> [9] </ref>, provide both user-level threads and kernel threads to the programmer. User-level threads are multiplexed on top of kernel-level threads, which in turn are scheduled on top of processors. The kernel knows only about the kernel-level threads; it does not know of the multiplexing performed by the user-level scheduler. <p> This model appears to elegantly solve many of the problems of the M-to-N family of models; its greatest drawback is the frequent crossings of the user-kernel boundary. 3 Solaris Implementation of the M-to-N Model 3.1 Overview SunOS 5.x implements the M-to-N thread scheduling model <ref> [9] </ref>, and introduces a new set of vocabulary: A kernel thread in Solaris is referred to as a lightweight process (LWP), while a cold thread is simply a thread. <p> This latency is particularly exacerbated when contention is moderately high. The M-to-N model is touted as providing inexpensive synchronization <ref> [9, 2, 11, 8] </ref>, but it appears that this is not always the case. 5.2 Coarse-grained barriers We noticed that once the amount of work done between each barrier synchronization became nontrivial, the difference between n bound threads and n unbound threads with an LWP pool of size n disappeared.
Reference: [10] <author> Sun Microsystems. </author> <title> SunOS 5.3 Linker and Libraries Manual, </title> <year> 1993. </year>
Reference-contexts: In order to allow monitoring of arbitrary binaries, the library side is implemented as a shared library. Thus, to monitor a program, the user sets the LD PRELOAD environment variable to point to the ThreadMon library. This will force ThreadMon to be loaded before other shared libraries <ref> [10] </ref> (including libthread.so). Once loaded, ThreadMon connects to the remote display side, and continues the program. As the program continues, ThreadMon wakes up every 10 milliseconds 8 , gathers data, and forwards that data to the display side.
Reference: [11] <author> Uresh Vahalia. </author> <title> UNIX Internals: The New Frontiers. </title> <publisher> Prentice Hall, </publisher> <year> 1996. </year> <month> 15 </month>
Reference-contexts: Because kernel threads require kernel involvement to be descheduled, hot thread synchronization will require a system call if the lock is not immediately acquired 3 . Estimates vary, but if a trap is required, synchronization will be from three to ten times more costly than for the N-to-1 case <ref> [9, 11] </ref>. * Expensive creation. Under the 1-to-1 model, every thread creation requires explicit kernel involvement and consumes kernel resources. <p> Under the 1-to-1 model, every thread creation requires explicit kernel involvement and consumes kernel resources. The difference in creation cost depends on the specific implementation, but creating a hot thread is generally between three and ten times more expensive than creating a cold thread <ref> [11] </ref>. * Resource inefficiency. Every thread that the user creates requires kernel memory for a stack, as well as some sort of kernel data structure to keep track of it. <p> Due to the many-to-many relationship between cold threads and hot threads, this is referred to as the M-to-N model [8] (it is also referred to as the two-level model [2], the split model <ref> [11] </ref> and the LWP model). By taking a hybrid approach, this model aims to combine the advantages of both the N-to-1 model and 1-to-1 model, while minimizing those models' disadvantages. <p> This latency is particularly exacerbated when contention is moderately high. The M-to-N model is touted as providing inexpensive synchronization <ref> [9, 2, 11, 8] </ref>, but it appears that this is not always the case. 5.2 Coarse-grained barriers We noticed that once the amount of work done between each barrier synchronization became nontrivial, the difference between n bound threads and n unbound threads with an LWP pool of size n disappeared.
References-found: 11

