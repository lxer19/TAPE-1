URL: http://www.cs.utexas.edu/users/vlr/papers/aqrqw.ps
Refering-URL: http://www.cs.utexas.edu/users/vlr/pub.html
Root-URL: 
Email: gibbons@research.bell-labs.com  matias@research.bell-labs.com  vlr@cs.utexas.edu  
Title: The Queue-Read Queue-Write Asynchronous PRAM Model  
Author: Phillip B. Gibbons Yossi Matias Vijaya Ramachandran 
Address: 600 Mountain Avenue Murray Hill NJ 07974  600 Mountain Avenue Murray Hill NJ 07974  Austin TX 78712  
Affiliation: Bell Laboratories  Bell Laboratories  Dept. of Computer Sciences University of Texas at Austin  
Note: To appear in THEORETICAL COMPUTER SCIENCE, 1997. Copyright Elsevier  
Abstract: This paper presents results for the queue-read, queue-write asynchronous parallel random access machine (qrqw asynchronous pram) model, which is the asynchronous variant of the qrqw pram model. The qrqw pram family of models, which was introduced earlier by the authors, permit concurrent reading and writing to shared memory locations, but each memory location is viewed as having a queue which can service at most one request at a time. In the basic qrqw pram model each processor executes a series of reads to shared memory locations, a series of local computation steps, and a series of writes to shared memory locations, and then synchronizes with all other processors; thus this can be viewed as a bulk-synchronous model. In contrast, in the qrqw asynchronous pram model discussed in this paper, there is no imposed bulk-synchronization between processors, and each processor proceeds at its own pace. Thus, the qrqw asynchronous pram serves as a better model for designing and analyzing truly asynchronous parallel algorithms than the original qrqw pram. In this paper we elaborate on the qrqw asynchronous pram model, and we demonstrate the power of asynchrony over bulk-synchrony by presenting a work and time optimal deterministic algorithm on the qrqw asynchronous pram for the leader election problem and a simple randomized work and time optimal algorithm on the qrqw asynchronous pram for sorting. In contrast, no tight bounds are known on the qrqw pram for either deterministic or randomized parallel algorithms for leader election and the only work and time optimal algorithms for sorting known on the qrqw pram are those inherited from the erew pram, which are considerably more complicated. Our sorting algorithm is an asynchronous version of an earlier sorting algorithm we developed for the qrqw pram, for which we use an interesting analysis to bound the running time to be O(lg n). We also present a randomized algorithm to simulate one step of a crcw pram on a qrqw asynchronous pram in sublogarithmic time if the maximum contention in the step is relatively small. fl Supported in part by NSF grant CCR/GER-90-23059 and Texas Advanced Research Projects Grant 003658386.
Abstract-found: 1
Intro-found: 1
Reference: [ABM93] <author> Y. Afek, G. M. Brown, and M. Merritt. </author> <title> Lazy caching. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 15(1) </volume> <pages> 182-205, </pages> <year> 1993. </year>
Reference-contexts: We elaborate on the correctness issues and analysis issues below, and then proceed to define the model. Functionality and correctness. A shared memory multiprocessor supports a consistency condition on its memory system. The most widely-used memory consistency condition is sequential consistency <ref> [Lam79, ABM93] </ref>, in which the memory system appears to be a serial memory, processing one read or write at a time, in an order consistent with the individual program orders at each processor. The SGI Challenge and the (now defunct) KSR machines are examples of multiprocessors supporting sequential consistency.
Reference: [Adl96] <author> M. Adler. </author> <title> Asynchronous shared memory search structures. </title> <booktitle> In Proc. 8th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 42-51, </pages> <month> June </month> <year> 1996. </year> <month> 21 </month>
Reference-contexts: We have also shown adaptations of several qrqw pram algorithms to the qrqw asynchronous pram with the same work-time bounds and a simulation of a fetch&add pram on the qrqw asynchronous pram. Additional results for the qrqw asynchronous pram can be found in a recent paper by Adler <ref> [Adl96] </ref>. That paper presents a number of new results on low-contention search structures, beyond the binary search fat-tree considered in this paper. One interesting direction for future work is to develop a good emulation of the qrqw asynchronous pram on a distributed memory machine model such as the bsp.
Reference: [AJ96] <author> C. Armen and D. B. Johnson. </author> <title> Deterministic leader election on the Asynchronous QRQW PRAM. </title> <note> Parallel Processing Letters, 1996. To appear. </note>
Reference-contexts: First, we present a simple deterministic algorithm for computing the or of n bits on the qrqw asynchronous pram that exploits the lack of bulk-synchrony and runs in O (lg n= lg lg n) time, linear work. A similar algorithm was found independently by Armen and Johnson <ref> [AJ96] </ref>. We also present a matching lower bound. In contrast, no o (lg n) time qrqw pram algorithm is known, and even on a Concurrent-Read Queue-Write (crqw) pram, no deterministic o (lg n) time algorithm is known for this problem. <p> In this section, we present a faster, O (lg n= lg lg n) time deterministic qrqw asynchronous pram algorithm for leader election and computing the or function, and a matching lower bound for the stronger crqw asynchronous pram. A similar algorithm was found independently by Armen and Johnson <ref> [AJ96] </ref>. Theorem 5.1 There is a deterministic qrqw asynchronous pram algorithm for the leader election problem (and the or function) that runs in O (lg n= lg lg n) time and O (n) work. Proof. Let s = lg n= lg lg n. We describe the algorithm for n=s processors.
Reference: [AKS83] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Sorting in c lg n parallel steps. </title> <journal> Combinatorica, </journal> <volume> 3(1) </volume> <pages> 1-19, </pages> <year> 1983. </year>
Reference-contexts: the following theorem that gives the desired lower bound. 10 Table 1: PRAM Sorting Results Model time work space constant factors Reference erew pram O (lg 2 n) O (n lg 2 n) O (n) small [Bat68] erew pram O (lg n) O (n lg n) O (n) very large <ref> [AKS83] </ref> erew pram O (lg n) O (n lg n) O (n) large [Col88] crew pram O (lg n) w.h.p. O (n lg n) w.h.p. O (n 1+* ) moderate [Rei85] qrqw pram O (lg 2 n= lg lg n) w.h.p. O (n lg n) w.h.p. <p> Thus T = (lg n= lg lg n). 6 Sorting We consider the problem of general sorting, i.e. sorting an array of n keys from a totally-ordered set. On the erew pram, there are two known O (lg n) time, O (n lg n) work algorithms for general sorting <ref> [AKS83, Col88] </ref>; these deterministic algorithms match the asymptotic lower bounds for general sorting on the erew and crew pram models. Unfortunately, these two algorithms are not as simple and practical as one would like.
Reference: [And92] <author> R. J. Anderson. </author> <title> Primitives for asynchronous list compression. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 199-208, </pages> <month> June-July </month> <year> 1992. </year>
Reference-contexts: Most asynchronous shared memory models of computation assume that a processor can have 4 at most one pending memory request at a time: there is no pipelining of memory requests by a processor (e.g. <ref> [CZ89, Nis90, And92, MPS92, DHW93] </ref>). 1 On the other hand, high-performance shared memory machines such as the Tera MTA permit the pipelining of memory accesses by a processor, in order to amortize the round-trip time to memory over a collection of accesses. <p> The stronger crqw asynchronous pram model is used primarily to prove stronger lower bounds. Related work. A variety of asynchronous pram models have been studied in the literature (c.f. <ref> [CZ89, Gib89, Nis90, And92, MPS92] </ref>). <p> This extra overhead is due to designing for a cost metric that accounts for worst case asynchrony. The advantage of this algorithm arises only in cases of very large delays among the machine processors. Most asynchronous models, e.g. <ref> [CZ89, CZ90, Nis90, And92, AR92, DHW93, LAB93] </ref>, account for more general asynchrony among the processors in their cost metrics, and hence algorithms designed using these models suffer from similar overheads in order to more robustly handle cases with very large delays.
Reference: [AR92] <author> Y. Aumann and M. O. Rabin. </author> <title> Clock construction in fully asynchronous parallel systems and PRAM simulation. </title> <booktitle> In Proc. 33rd IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 147-156, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This extra overhead is due to designing for a cost metric that accounts for worst case asynchrony. The advantage of this algorithm arises only in cases of very large delays among the machine processors. Most asynchronous models, e.g. <ref> [CZ89, CZ90, Nis90, And92, AR92, DHW93, LAB93] </ref>, account for more general asynchrony among the processors in their cost metrics, and hence algorithms designed using these models suffer from similar overheads in order to more robustly handle cases with very large delays.
Reference: [Bat68] <author> K. E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proc. AFIPS Spring Joint Summer Computer Conference, </booktitle> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: The above lemma leads to the following theorem that gives the desired lower bound. 10 Table 1: PRAM Sorting Results Model time work space constant factors Reference erew pram O (lg 2 n) O (n lg 2 n) O (n) small <ref> [Bat68] </ref> erew pram O (lg n) O (n lg n) O (n) very large [AKS83] erew pram O (lg n) O (n lg n) O (n) large [Col88] crew pram O (lg n) w.h.p. O (n lg n) w.h.p. <p> If failure is reported for any subproblem, we restart the algorithm from the beginning. 5. Recursively sort the items within each group, for all groups in parallel. When n i+1 is at most 2 (lg n) 1=2 , finish sorting the group using the erew pram bitonic sort algorithm <ref> [Bat68] </ref>. This cut-off point suffices for n sufficiently large; for general n, the cut-off point is maxf2 (lg n) 1=2 ; lg c ng, for c &gt; 6=* a suitable constant.
Reference: [BGMZ95] <author> G. E. Blelloch, P. B. Gibbons, Y. Matias, and M. Zagha. </author> <title> Accounting for memory bank contention and delay in high-bandwidth multiprocessors. </title> <booktitle> In Proc. 7th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 84-94, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Efficient bulk-synchronization is an option on these machines, but is not imposed. An extensive study of algorithms and results for the qrqw pram can be found in [GMR97, GMR96]. In addition, experimental results for the qrqw pram on the Cray C90 and J90 can be found in <ref> [BGMZ95] </ref>. The model we study in this paper, the qrqw asynchronous pram model, permits more asynchronous behavior than the bulk-synchrony imposed by the qrqw pram. Thus it can be used to design and analyze algorithms for machines such as the MTA in contexts in which bulk-synchrony is not employed.
Reference: [BH89] <author> P. Beame and J. H-astad. </author> <title> Optimal bounds for decision problems on the CRCW PRAM. </title> <journal> Journal of the ACM, </journal> <volume> 36(3) </volume> <pages> 643-670, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: other hand, the parity and the prefix sums problems with input size n can be solved in constant time on a fetch&add pram using n processors, while requiring (lg n= lg lg n) (expected) time on a crcw pram when using n c processors, for any constant c &gt; 0 <ref> [BH89] </ref>. In this section we give an emulation of one step of a fetch&add pram on a qrqw asynchronous pram that takes sub-logarithmic time for moderate contention.
Reference: [CKP + 93] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proc. 4th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 1-12, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: This separation of correctness from analysis, with correctness accounting for asynchrony but analysis assuming synchrony, was pioneered by Gibbons [Gib89] and has been subsequently adapted by several other asynchronous models such as the LogP model <ref> [CKP + 93] </ref>. As an example of the ease of designing algorithms under such a cost metric consider designing an algorithm to find the maximum of n numbers on an asynchronous parallel machine.
Reference: [Col88] <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(4) </volume> <pages> 770-785, </pages> <year> 1988. </year>
Reference-contexts: Sorting Results Model time work space constant factors Reference erew pram O (lg 2 n) O (n lg 2 n) O (n) small [Bat68] erew pram O (lg n) O (n lg n) O (n) very large [AKS83] erew pram O (lg n) O (n lg n) O (n) large <ref> [Col88] </ref> crew pram O (lg n) w.h.p. O (n lg n) w.h.p. O (n 1+* ) moderate [Rei85] qrqw pram O (lg 2 n= lg lg n) w.h.p. O (n lg n) w.h.p. O (n) moderate [GMR96] qrqw a.p. O (lg n) w.h.p. O (n lg n) w.h.p. <p> Thus T = (lg n= lg lg n). 6 Sorting We consider the problem of general sorting, i.e. sorting an array of n keys from a totally-ordered set. On the erew pram, there are two known O (lg n) time, O (n lg n) work algorithms for general sorting <ref> [AKS83, Col88] </ref>; these deterministic algorithms match the asymptotic lower bounds for general sorting on the erew and crew pram models. Unfortunately, these two algorithms are not as simple and practical as one would like.
Reference: [CZ89] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating asynchrony into the PRAM model. </title> <booktitle> In Proc. 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 169-178, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Most asynchronous shared memory models of computation assume that a processor can have 4 at most one pending memory request at a time: there is no pipelining of memory requests by a processor (e.g. <ref> [CZ89, Nis90, And92, MPS92, DHW93] </ref>). 1 On the other hand, high-performance shared memory machines such as the Tera MTA permit the pipelining of memory accesses by a processor, in order to amortize the round-trip time to memory over a collection of accesses. <p> The stronger crqw asynchronous pram model is used primarily to prove stronger lower bounds. Related work. A variety of asynchronous pram models have been studied in the literature (c.f. <ref> [CZ89, Gib89, Nis90, And92, MPS92] </ref>). <p> This extra overhead is due to designing for a cost metric that accounts for worst case asynchrony. The advantage of this algorithm arises only in cases of very large delays among the machine processors. Most asynchronous models, e.g. <ref> [CZ89, CZ90, Nis90, And92, AR92, DHW93, LAB93] </ref>, account for more general asynchrony among the processors in their cost metrics, and hence algorithms designed using these models suffer from similar overheads in order to more robustly handle cases with very large delays.
Reference: [CZ90] <author> R. Cole and O. Zajicek. </author> <title> The expected advantage of asynchrony. </title> <booktitle> In Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 85-94, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: This extra overhead is due to designing for a cost metric that accounts for worst case asynchrony. The advantage of this algorithm arises only in cases of very large delays among the machine processors. Most asynchronous models, e.g. <ref> [CZ89, CZ90, Nis90, And92, AR92, DHW93, LAB93] </ref>, account for more general asynchrony among the processors in their cost metrics, and hence algorithms designed using these models suffer from similar overheads in order to more robustly handle cases with very large delays.
Reference: [DHW93] <author> C. Dwork, M. Herlihy, and O. Waarts. </author> <title> Contention in shared memory algorithms. </title> <booktitle> In Proc. 25th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 174-183, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Each memory location is viewed as having a queue which can service at most one request at a time. Unlike related models accounting for contention (e.g. <ref> [DHW93, LAB93] </ref>), the qrqw pram and the qrqw asynchronous pram models permit pipelining: individual processors may have multiple requests in progress concurrently. Some of the results presented here are mentioned without any details in earlier extended abstracts by the authors on qrqw pram results. <p> Most asynchronous shared memory models of computation assume that a processor can have 4 at most one pending memory request at a time: there is no pipelining of memory requests by a processor (e.g. <ref> [CZ89, Nis90, And92, MPS92, DHW93] </ref>). 1 On the other hand, high-performance shared memory machines such as the Tera MTA permit the pipelining of memory accesses by a processor, in order to amortize the round-trip time to memory over a collection of accesses. <p> The atomic message passing model [LAB93] is a message-passing model in which messages destined for the same processor are serviced one-at-a-time in an arbitrary order. The model permits general asynchronous algorithms, but each processor can have at most one message outstanding at a time. Dwork, Herlihy and Waarts <ref> [DHW93] </ref> defined an asynchronous shared memory model with a stall metric: If several processes have reads or writes pending to a location, v, and one of them receives a response, then all the others incur a stall. <p> This extra overhead is due to designing for a cost metric that accounts for worst case asynchrony. The advantage of this algorithm arises only in cases of very large delays among the machine processors. Most asynchronous models, e.g. <ref> [CZ89, CZ90, Nis90, And92, AR92, DHW93, LAB93] </ref>, account for more general asynchrony among the processors in their cost metrics, and hence algorithms designed using these models suffer from similar overheads in order to more robustly handle cases with very large delays.
Reference: [DKR94] <author> M. Dietzfelbinger, M. Kuty lowski, and R. Reischuk. </author> <title> Exact lower time bounds for computing boolean functions on CREW PRAMs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 48(2) </volume> <pages> 231-254, </pages> <year> 1994. </year>
Reference-contexts: Thus the time is O (s) as claimed. We can derive a matching (lg n= lg lg n) lower bound for the or function on the (more powerful) crqw asynchronous pram using a lower bound result of Dietzfelbinger, Kutylowski and Reischuk <ref> [DKR94] </ref> for the few-write pram models. <p> O (lg n) w.h.p. O (n lg n) w.h.p. O (n lg n) moderate this paper Theorem 5.3 Any deterministic algorithm for computing the or function on a crqw asynchronous pram with arbitrarily many processors requires (lg n= lg lg n) time. Proof. Dietzfelbinger, Kutylowski and Reischuk <ref> [DKR94] </ref> proved an (lg n= lg ) lower bound for the or function on the -write pram. Let T be the time for the or function on the crqw asynchronous pram.
Reference: [GGK + 83] <author> A. Gottlieb, R. Grishman, C. P. Kruskal, K. P. McAuliffe, L. Rudolph, and M. Snir. </author> <title> The NYU Ultracomputer designing an MIMD shared memory parallel computer. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-32(2):175-189, </volume> <year> 1983. </year>
Reference-contexts: t 0 l &gt; ffc 0 lg lg n + (b + 2ff) lg n) &lt; n (b1) : Thus the cumulative delay of any element through fat-trees at all levels of recursion is O (lg n) w.h.p. 7 Emulating Fetch&Add PRAM on QRQW Asynchronous PRAM The fetch&add pram model <ref> [GGK + 83, Vis83] </ref> is a strong, non-standard variant of the crcw pram.
Reference: [Gib89] <author> P. B. Gibbons. </author> <title> A more practical PRAM model. </title> <booktitle> In Proc. 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-168, </pages> <month> June </month> <year> 1989. </year> <title> Full version in The Asynchronous PRAM: A semi-synchronous model for shared memory MIMD machines, </title> <type> PhD thesis, </type> <institution> U.C. Berkeley 1989. </institution>
Reference-contexts: Other synchronization constructs such as barriers can be constructed using shared memory reads, writes, and test&sets. Analysis. In defining how algorithms are analyzed in the model, the qrqw asynchronous pram aims for a simple cost model that captures important realities of multiprocessors. As in Gibbons' asynchronous pram model <ref> [Gib89] </ref>, our cost model assumes that processors issue instructions at the same speed, as this is presumed to be the typical scenario in a multiprocessor. A local operation takes unit time. <p> The stronger crqw asynchronous pram model is used primarily to prove stronger lower bounds. Related work. A variety of asynchronous pram models have been studied in the literature (c.f. <ref> [CZ89, Gib89, Nis90, And92, MPS92] </ref>). <p> Models based on "interleaving" or "rounds" charge the same for an interleaving of reads/writes to the same location as for an interleaving of reads/writes to different locations. 3 An exception is the erew variant of Gibbons' asynchronous pram model <ref> [Gib89] </ref>, which permits contention in synchronization primitives, at a cost, but enforces the erew rule on reads and writes occurring between synchronization points. 6 x when it reaches the head of the queue. <p> On the other hand, algorithms must be correct under worst case assumptions on the finite delays incurred by processors and in processing memory requests. This separation of correctness from analysis, with correctness accounting for asynchrony but analysis assuming synchrony, was pioneered by Gibbons <ref> [Gib89] </ref> and has been subsequently adapted by several other asynchronous models such as the LogP model [CKP + 93]. As an example of the ease of designing algorithms under such a cost metric consider designing an algorithm to find the maximum of n numbers on an asynchronous parallel machine.
Reference: [GLL + 90] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proc. 17th International Symp. on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The SGI Challenge and the (now defunct) KSR machines are examples of multiprocessors supporting sequential consistency. Relaxed consistency conditions such as release consistency <ref> [GLL + 90, GMG91] </ref> support sequential consistency for PL programs; these are programs with two types of accesses, synchronization and data, such that there are no race conditions between data accesses. The Stanford DASH machine and the Tera MTA are examples of multiprocessors supporting release consistency.
Reference: [GM92] <author> P. B. Gibbons and M. Merritt. </author> <title> Specifying nonblocking shared memories. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 306-315, </pages> <month> June-July </month> <year> 1992. </year> <month> 22 </month>
Reference-contexts: However, the first subsequent RAM operation that uses the result of such a shared memory request will wait for the value to be returned. The global memory is a sequentially consistent nonblocking shared memory <ref> [GM92] </ref>, as follows. Each processor issues shared memory requests (read, write, test&set) one at a time. There is a partial order on the requests by a processor, called the local order for that processor.
Reference: [GMG91] <author> P. B. Gibbons, M. Merritt, and K. Gharachorloo. </author> <title> Proving sequential consistency of high-performance shared memories. </title> <booktitle> In Proc. 3rd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 292-303, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: The SGI Challenge and the (now defunct) KSR machines are examples of multiprocessors supporting sequential consistency. Relaxed consistency conditions such as release consistency <ref> [GLL + 90, GMG91] </ref> support sequential consistency for PL programs; these are programs with two types of accesses, synchronization and data, such that there are no race conditions between data accesses. The Stanford DASH machine and the Tera MTA are examples of multiprocessors supporting release consistency.
Reference: [GMR93] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. QRQW: </author> <title> Accounting for concurrency in PRAMs and Asynchronous PRAMs. </title> <type> Technical report, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: As discussed in [GMR97], the contention properties of most existing multiprocessors are well-approximated by the queue-read, queue-write rule. In this paper we consider the Queue-Read Queue-Write (qrqw) asynchronous pram model. The qrqw asynchronous pram <ref> [GMR93] </ref> was introduced by the authors as the asynchronous variant of the qrqw pram family of models [GMR97], suitable for designing algorithms for asynchronous (mimd) multiprocessors. The qrqw family of models includes the simd-qrqw pram model, the qrqw pram model and the qrqw asynchronous pram model.
Reference: [GMR96] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Efficient low-contention parallel algorithms. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 53(3) </volume> <pages> 417-442, </pages> <year> 1996. </year> <note> Special issue devoted to selected papers from the 1994 ACM Symp. on Parallel Algorithms and Architectures. </note>
Reference-contexts: Efficient bulk-synchronization is an option on these machines, but is not imposed. An extensive study of algorithms and results for the qrqw pram can be found in <ref> [GMR97, GMR96] </ref>. In addition, experimental results for the qrqw pram on the Cray C90 and J90 can be found in [BGMZ95]. The model we study in this paper, the qrqw asynchronous pram model, permits more asynchronous behavior than the bulk-synchrony imposed by the qrqw pram. <p> The algorithm is almost exactly the same as the fi (lg 2 n= lg lg n) time, O (n lg n) work randomized sorting algorithm we developed earlier for the qrqw pram <ref> [GMR96] </ref>, but we exploit asynchrony by allowing elements to flow through the `binary search fat-tree' data structures employed by the sorting algorithm at their own pace. <p> The goal in adapting algorithms designed for the qrqw pram to the qrqw asynchronous pram is to make do with less synchronization so as to maintain the same complexity bounds. In this section, we sketch simple adaptations of several qrqw pram algorithms from <ref> [GMR97, GMR96] </ref>, showing that the same complexities can be obtained for the qrqw asynchronous pram. <p> We next consider the problem of generating a random permutation. Theorem 4.2 There is a randomized Las Vegas qrqw asynchronous pram algorithm for generating a random permutation that runs in O (lg n) time with O (n) work w.h.p. Proof. In <ref> [GMR96] </ref>, we presented the following qrqw pram algorithm. <p> The algorithm is adapted to the qrqw asynchronous pram by using the test&set primitive to decide which writer claims a particular cell, and judiciously inserting explicit synchronizations among subsets of processors as needed. The time and work bounds follow from the bounds for the qrqw pram shown in <ref> [GMR96] </ref>. We next consider the multiple compaction problem. The input consists of n items given in an array; each item has a label, a count, and a pointer, all from [1::O (n)]. <p> The goal is to move each item into a private cell in the sub-array of its set. Theorem 4.3 There is a randomized Las Vegas qrqw asynchronous pram algorithm for multiple compaction that runs in O (lg n) time with O (n) work w.h.p. Proof. In <ref> [GMR96] </ref>, we presented a qrqw pram algorithm with these time and work bounds. The reader is referred to that paper for a description of the algorithm. <p> O (n lg n) w.h.p. O (n 1+* ) moderate [Rei85] qrqw pram O (lg 2 n= lg lg n) w.h.p. O (n lg n) w.h.p. O (n) moderate <ref> [GMR96] </ref> qrqw a.p. O (lg n) w.h.p. O (n lg n) w.h.p. O (n lg n) moderate this paper Theorem 5.3 Any deterministic algorithm for computing the or function on a crqw asynchronous pram with arbitrarily many processors requires (lg n= lg lg n) time. Proof. <p> When the size of a group is at most lg n, finish sorting the group by comparing all pairs of items. In an earlier paper <ref> [GMR96] </ref> we build on this p n-sample sort algorithm and obtained an O (lg 2 n= lg lg n) time, O (n lg n) work, O (n) space randomized sorting algorithm, on the qrqw pram. <p> In this section, we present a simple sorting algorithm on the qrqw asynchronous pram that runs in O (lg n) time with O (n lg n) work w.h.p. The algorithm is almost the same as the O (n lg n)- work algorithm for the qrqw pram given in <ref> [GMR96] </ref>, but we are able to bring down the running time from fi (lg 2 n= lg lg n) to O (lg n) by making effective use of asynchrony. <p> Table 1 summarizes the comparison between various pram sorting algorithms. We start by reviewing the high-level algorithm, which is the same for the qrqw pram and the 11 qrqw asynchronous pram. 6.1 The high-level sorting algorithm The following sorting algorithm is presented in <ref> [GMR96] </ref>. Algorithm A. Let * be any constant such that 0 &lt; * &lt; 1=2. <p> Let n = n 0 be the number of input items, and for i 1, let 1 i1 : W.h.p., n i is an upper bound on the number of items in each subproblem at the ith recursive call to A <ref> [GMR96] </ref>. For subproblems at the ith level of recursion: 1. Let S be the set of at most n i items in this subproblem. Select in parallel p n i items drawn uniformly at random from S. 2. <p> In particular, we use a variant of multiple compaction in which (1) the size of each set is (lg 2 n) and (2) the set sizes may exceed their upper bounds, in which case the algorithm reports failure <ref> [GMR96] </ref>. W.h.p., the number of items with the same label is at most n i+1 and thus the multiple compaction succeeds in placing all items in each such group into its designated subarray. If failure is reported for any subproblem, we restart the algorithm from the beginning. 5. <p> Theorem 6.1 Algorithm A can be implemented on the qrqw asynchronous pram in O (lg n) time and O (n lg n) work w.h.p., using O (n lg n) space. Proof. Consider all O (n=n i ) subproblems at the ith level of recursion. As shown in <ref> [GMR96] </ref> using Chernoff bounds, the maximum contention in step 1 is O ( p lg n) w.h.p. The work is O (n= p n i ). <p> We then label each item using a random search into the fat-tree, as described above. This step is analyzed below. By the analysis in <ref> [GMR96] </ref>, step 4 takes O (lg fl n i lg n= lg lg n) time and O (n) work w.h.p. Let t be the number of levels of recursion.
Reference: [GMR97] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The Queue-Read Queue-Write PRAM model: Accounting for contention in parallel algorithms. </title> <journal> SIAM Journal on Computing, </journal> <note> 1997. To appear. Preliminary version appears in Proc. </note> <editor> 5th ACM-SIAM Symp. </editor> <booktitle> on Discrete Algorithms, </booktitle> <pages> pages 638-648, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: These two rules can be applied independently to reads and writes; the resulting models are denoted in the literature as the erew, crew, ercw, and crcw pram models. In a previous paper <ref> [GMR97] </ref>, we argued that neither the exclusive nor the concurrent rules accurately reflect the contention capabilities of most commercial and research multiprocessors: The exclusive rule is too strict, and the concurrent rule ignores the large performance penalty of high contention steps. <p> Thus the worst case time to read or write a location is linear in the number of concurrent readers or writers to the same location. As discussed in <ref> [GMR97] </ref>, the contention properties of most existing multiprocessors are well-approximated by the queue-read, queue-write rule. In this paper we consider the Queue-Read Queue-Write (qrqw) asynchronous pram model. The qrqw asynchronous pram [GMR93] was introduced by the authors as the asynchronous variant of the qrqw pram family of models [GMR97], suitable for <p> discussed in <ref> [GMR97] </ref>, the contention properties of most existing multiprocessors are well-approximated by the queue-read, queue-write rule. In this paper we consider the Queue-Read Queue-Write (qrqw) asynchronous pram model. The qrqw asynchronous pram [GMR93] was introduced by the authors as the asynchronous variant of the qrqw pram family of models [GMR97], suitable for designing algorithms for asynchronous (mimd) multiprocessors. The qrqw family of models includes the simd-qrqw pram model, the qrqw pram model and the qrqw asynchronous pram model. <p> Efficient bulk-synchronization is an option on these machines, but is not imposed. An extensive study of algorithms and results for the qrqw pram can be found in <ref> [GMR97, GMR96] </ref>. In addition, experimental results for the qrqw pram on the Cray C90 and J90 can be found in [BGMZ95]. The model we study in this paper, the qrqw asynchronous pram model, permits more asynchronous behavior than the bulk-synchrony imposed by the qrqw pram. <p> A random variable X that gives the number of successes in a sequence of n independent Bernoulli trials is a binomial random variable with expectation E [X] = np. In Section 7 we apply the following "Chernoff-type" bound on the tail of a binomial random variable X (see, e.g. <ref> [GMR97] </ref>): Lemma 2.1 Let X be a binomial random variable. For all f = O (lg n), if E [X] 1=2 f , then X = O (lg n=f ) w.h.p. 3 The QRQW Asynchronous PRAM In this section, we present the definition of the qrqw asynchronous pram model. <p> The goal in adapting algorithms designed for the qrqw pram to the qrqw asynchronous pram is to make do with less synchronization so as to maintain the same complexity bounds. In this section, we sketch simple adaptations of several qrqw pram algorithms from <ref> [GMR97, GMR96] </ref>, showing that the same complexities can be obtained for the qrqw asynchronous pram. <p> There is a randomized Las Vegas qrqw asynchronous pram algorithm that runs in O (lg k max + p lg n) time with O (n) work w.h.p. Proof. We describe first the qrqw pram algorithm from <ref> [GMR97] </ref> for the first problem above for n= lg n processors. Let = min (1; 2 c p lg n = ^ k), for a constant c 1, to be determined by the analysis. <p> If ^ k 2 lg n then = 1 and this is a Las Vegas algorithm. Alternatively, on the crqw, a Las Vegas algorithm is obtained by repeating steps 2 and 3 until there is a nonzero index in A; termination is detected by using the concurrent-read capability. In <ref> [GMR97] </ref>, we show that the time on the qrqw and crqw pram is O ( p adapt the algorithm to the qrqw and crqw asynchronous pram as follows. In step 2, processors perform a test&set to their selected cell instead of writing an index. <p> The leader is the leader bit of the processor that succeeds in claiming the root. We now describe the qrqw pram algorithm from <ref> [GMR97] </ref> for the second problem above, for n=(lg k max + lg n) processors. The input bits are partitioned among the processors such that each processor is assigned lg k max + p lg n bits. <p> Each processor selects a leader from among its input bits that are 1, if any. Then each processor with a leader writes to a cell of A selected uniformly at random. Finally, m of the processors participate to select a nonzero index from among those written to A. In <ref> [GMR97] </ref>, we show that the time on the qrqw pram is O (lg k max + lg n) w.h.p. We adapt the algorithm to the qrqw asynchronous pram using the same modifications as in the first problem above, to obtain the stated bounds. <p> We begin by proving a more general result for emulating the crqw asynchronous pram on the few-write pram, and then provide the or lower bound. The same two-part approach is used in <ref> [GMR97] </ref> to prove an (lg n= lg lg n) time lower bound for the deterministic crqw pram; here we extend the lower bound to the asynchronous model. <p> That paper presents a number of new results on low-contention search structures, beyond the binary search fat-tree considered in this paper. One interesting direction for future work is to develop a good emulation of the qrqw asynchronous pram on a distributed memory machine model such as the bsp. In <ref> [GMR97] </ref> we presented an optimal work emulation of the qrqw pram on the bsp with only a logarithmic slowdown. It appears that the strategy used in that emulation does not carry over directly to the qrqw asynchronous pram and new insights are needed.
Reference: [JaJ92] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction The Parallel Random Access Machine (pram) model of computation (see, e.g., <ref> [KR90, JaJ92, Rei93] </ref>) consists of a number of processors operating in lock-step and communicating by reading and writing locations in a shared memory. Standard pram models can be distinguished by their rules regarding contention for shared memory locations.
Reference: [KR90] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel algorithms for shared-memory machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume A, </booktitle> <pages> pages 869-941. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction The Parallel Random Access Machine (pram) model of computation (see, e.g., <ref> [KR90, JaJ92, Rei93] </ref>) consists of a number of processors operating in lock-step and communicating by reading and writing locations in a shared memory. Standard pram models can be distinguished by their rules regarding contention for shared memory locations.
Reference: [LAB93] <author> P. Liu, W. Aiello, and S. Bhatt. </author> <title> An atomic model for message-passing. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 154-163, </pages> <month> June-July </month> <year> 1993. </year>
Reference-contexts: Each memory location is viewed as having a queue which can service at most one request at a time. Unlike related models accounting for contention (e.g. <ref> [DHW93, LAB93] </ref>), the qrqw pram and the qrqw asynchronous pram models permit pipelining: individual processors may have multiple requests in progress concurrently. Some of the results presented here are mentioned without any details in earlier extended abstracts by the authors on qrqw pram results. <p> These models were developed independently of the qrqw asynchronous pram and differ in several important ways. The atomic message passing model <ref> [LAB93] </ref> is a message-passing model in which messages destined for the same processor are serviced one-at-a-time in an arbitrary order. The model permits general asynchronous algorithms, but each processor can have at most one message outstanding at a time. <p> This extra overhead is due to designing for a cost metric that accounts for worst case asynchrony. The advantage of this algorithm arises only in cases of very large delays among the machine processors. Most asynchronous models, e.g. <ref> [CZ89, CZ90, Nis90, And92, AR92, DHW93, LAB93] </ref>, account for more general asynchrony among the processors in their cost metrics, and hence algorithms designed using these models suffer from similar overheads in order to more robustly handle cases with very large delays.
Reference: [Lam79] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multipro-cess programs. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-28(9):690-691, </volume> <year> 1979. </year>
Reference-contexts: We elaborate on the correctness issues and analysis issues below, and then proceed to define the model. Functionality and correctness. A shared memory multiprocessor supports a consistency condition on its memory system. The most widely-used memory consistency condition is sequential consistency <ref> [Lam79, ABM93] </ref>, in which the memory system appears to be a serial memory, processing one read or write at a time, in an order consistent with the individual program orders at each processor. The SGI Challenge and the (now defunct) KSR machines are examples of multiprocessors supporting sequential consistency.
Reference: [MPS92] <author> C. Martel, A. Park, and R. Subramonian. </author> <title> Work-optimal asynchronous algorithms for shared memory parallel computers. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(6) </volume> <pages> 1070-1099, </pages> <year> 1992. </year>
Reference-contexts: Most asynchronous shared memory models of computation assume that a processor can have 4 at most one pending memory request at a time: there is no pipelining of memory requests by a processor (e.g. <ref> [CZ89, Nis90, And92, MPS92, DHW93] </ref>). 1 On the other hand, high-performance shared memory machines such as the Tera MTA permit the pipelining of memory accesses by a processor, in order to amortize the round-trip time to memory over a collection of accesses. <p> The stronger crqw asynchronous pram model is used primarily to prove stronger lower bounds. Related work. A variety of asynchronous pram models have been studied in the literature (c.f. <ref> [CZ89, Gib89, Nis90, And92, MPS92] </ref>). <p> In case of small delays among the machine processors the running time will increase only slightly. This algorithm can be contrasted with algorithms designed using asynchronous models whose cost metrics account for more general asynchrony among the processors. For example, Martel et al. <ref> [MPS92] </ref> describe a randomized algorithm to compute the maximum of n numbers on their a-pram model, a model whose cost metric accounts for worst case asynchrony.
Reference: [Nis90] <author> N. Nishimura. </author> <title> Asynchronous shared memory parallel computation. </title> <booktitle> In Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 76-84, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Most asynchronous shared memory models of computation assume that a processor can have 4 at most one pending memory request at a time: there is no pipelining of memory requests by a processor (e.g. <ref> [CZ89, Nis90, And92, MPS92, DHW93] </ref>). 1 On the other hand, high-performance shared memory machines such as the Tera MTA permit the pipelining of memory accesses by a processor, in order to amortize the round-trip time to memory over a collection of accesses. <p> The stronger crqw asynchronous pram model is used primarily to prove stronger lower bounds. Related work. A variety of asynchronous pram models have been studied in the literature (c.f. <ref> [CZ89, Gib89, Nis90, And92, MPS92] </ref>). <p> This extra overhead is due to designing for a cost metric that accounts for worst case asynchrony. The advantage of this algorithm arises only in cases of very large delays among the machine processors. Most asynchronous models, e.g. <ref> [CZ89, CZ90, Nis90, And92, AR92, DHW93, LAB93] </ref>, account for more general asynchrony among the processors in their cost metrics, and hence algorithms designed using these models suffer from similar overheads in order to more robustly handle cases with very large delays.
Reference: [Rei85] <author> R. Reischuk. </author> <title> Probabilistic parallel algorithms for sorting and selection. </title> <journal> SIAM Journal on Computing, </journal> <volume> 14(2) </volume> <pages> 396-409, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: O (n lg n) w.h.p. O (n 1+* ) moderate <ref> [Rei85] </ref> qrqw pram O (lg 2 n= lg lg n) w.h.p. O (n lg n) w.h.p. O (n) moderate [GMR96] qrqw a.p. O (lg n) w.h.p. O (n lg n) w.h.p. <p> Unfortunately, these two algorithms are not as simple and practical as one would like. Another relatively simple parallel sorting algorithm is a randomized p n-sample sort algorithm for the crew pram that runs in O (lg n) time, O (n lg n) work, and O (n 1+* ) space <ref> [Rei85] </ref>.
Reference: [Rei93] <author> J. H. Reif, </author> <title> editor. A Synthesis of Parallel Algorithms. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction The Parallel Random Access Machine (pram) model of computation (see, e.g., <ref> [KR90, JaJ92, Rei93] </ref>) consists of a number of processors operating in lock-step and communicating by reading and writing locations in a shared memory. Standard pram models can be distinguished by their rules regarding contention for shared memory locations.
Reference: [Smi95] <author> B. Smith. </author> <booktitle> Invited lecture, 7th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Thus it can be used to design and analyze algorithms for machines such as the MTA in contexts in which bulk-synchrony is not employed. Indeed, Burton Smith, Chairman and Chief Scientist of Tera Computer, refers to the MTA as "roughly a qrqw asynchronous pram" <ref> [Smi95] </ref> (and to our knowledge makes no such claims about other models). In more detail, the differences between the qrqw pram and the qrqw asynchronous pram are as follows.
Reference: [Vis83] <author> U. Vishkin. </author> <title> On choice of a model of parallel computation. </title> <type> Technical Report 61, </type> <institution> Department of Computer Science, Courant Institute of Mathematical Sciences, </institution> <address> New York University, 251 Mercer St., New York, NY 10012, </address> <year> 1983. </year> <month> 23 </month>
Reference-contexts: t 0 l &gt; ffc 0 lg lg n + (b + 2ff) lg n) &lt; n (b1) : Thus the cumulative delay of any element through fat-trees at all levels of recursion is O (lg n) w.h.p. 7 Emulating Fetch&Add PRAM on QRQW Asynchronous PRAM The fetch&add pram model <ref> [GGK + 83, Vis83] </ref> is a strong, non-standard variant of the crcw pram.
References-found: 33

