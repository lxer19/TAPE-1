URL: http://www.cs.cornell.edu/Info/Courses/Spring-98/CS612/papers/mckinley.ps
Refering-URL: http://www.cs.cornell.edu/Info/Courses/Spring-98/CS612/projects/prefetch.html
Root-URL: 
Email: scoleman@dsd.camb.inmet.com mckinley@cs.umass.edu  
Title: Tile Size Selection Using Cache Organization and Data Layout  
Author: Stephanie Coleman Kathryn S. M c Kinley 
Address: 733 Concord Ave.  Cambridge, MA 02138 Amherst, MA 01003  
Affiliation: Intermetrics, Inc.,  Computer Science, LGRC, University of Massachusetts  
Abstract: When dense matrix computations are too large to fit in cache, previous research proposes tiling to reduce or eliminate capacity misses. This paper presents a new algorithm for choosing problem-size dependent tile sizes based on the cache size and cache line size for a direct-mapped cache. The algorithm eliminates both capacity and self-interference misses and reduces cross-interference misses. We measured simulated miss rates and execution times for our algorithm and two others on a variety of problem sizes and cache organizations. At higher set associativity, our algorithm does not always achieve the best performance. However on direct-mapped caches, our algorithm improves simulated miss rates and measured execution times when compared with previous work. 
Abstract-found: 1
Intro-found: 1
Reference: [BJWE92] <author> F. Bodin, W. Jalby, D. Windheiser, and C. Eisenbeis. </author> <title> A quantitative algorithm for data locality optimza-tion. In Code Generation-Concepts, Tools, Techniques. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. [Ess93, LRW91]. 2 Related Work Several researchers describe methods for how to tile nests <ref> [BJWE92, CK92, CL95, IT88, GJG88, Wol89] </ref>. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes [Ess93, LRW91].
Reference: [CK92] <author> S. Carr and K. Kennedy. </author> <title> Compiler blockability of numerical algorithms. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <address> Minneapolis, MN, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Much previous work focuses on how to do the loop nest restructuring step in tiling <ref> [CK92, CL95, IT88, GJG88, WL91, Wol89] </ref>. This work however ignores the effects of real caches such as low associativity and cache line size on the cache performance of tiled nests. Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91]. <p> Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. [Ess93, LRW91]. 2 Related Work Several researchers describe methods for how to tile nests <ref> [BJWE92, CK92, CL95, IT88, GJG88, Wol89] </ref>. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes [Ess93, LRW91]. <p> Previous research has focused on how to transform a nest into a tiled version to eliminate these capacity misses <ref> [CK92, CL95, IT88, GJG88, Wol89] </ref>. We assume as input a tiled nest produced by one of these methods and turn our attention the selection of tile sizes for the nest. For example, tiled matrix multiply appears in Figure 1 (b) and its corresponding reuse pattern in Figure 2 (b).
Reference: [CL95] <author> S. Carr and R. B. Lehoucq. </author> <title> A compiler-blockable algorithm for QR decomposition. </title> <booktitle> In Proceedings of the Eighth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> San Francisco, CA, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: Much previous work focuses on how to do the loop nest restructuring step in tiling <ref> [CK92, CL95, IT88, GJG88, WL91, Wol89] </ref>. This work however ignores the effects of real caches such as low associativity and cache line size on the cache performance of tiled nests. Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91]. <p> Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. [Ess93, LRW91]. 2 Related Work Several researchers describe methods for how to tile nests <ref> [BJWE92, CK92, CL95, IT88, GJG88, Wol89] </ref>. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes [Ess93, LRW91]. <p> Previous research has focused on how to transform a nest into a tiled version to eliminate these capacity misses <ref> [CK92, CL95, IT88, GJG88, Wol89] </ref>. We assume as input a tiled nest produced by one of these methods and turn our attention the selection of tile sizes for the nest. For example, tiled matrix multiply appears in Figure 1 (b) and its corresponding reuse pattern in Figure 2 (b).
Reference: [CMT94] <author> S. Carr, K. S. M c Kinley, and C. Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Due to the wide gap between processor and memory speed in current architectures, achieving good performance requires high cache efficiency. Compiler optimizations to improve data locality for uniprocessors is increasingly becoming a critical part of achieving good performance <ref> [CMT94] </ref>. One of the most well-known compiler optimizations is tiling (also known as blocking).
Reference: [Col94] <author> S. Coleman. </author> <title> Selecting tile sizes based on cache and data organization. </title> <type> Master's thesis, </type> <institution> Dept. of Computer Science, University of Massachusetts, Amherst, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: We used a variety of cache parameters: a cache size of 8K and 64K; set-associativity of 1, 2, and 4; and a cache line size of 32, 64, and 128 <ref> [Col94] </ref>. Of these, we present cache parameters corresponding to the DEC Alpha Model 3000/400 (8K, 32 byte line, direct-mapped) and the RS/6000 Model 540 (64K, 128 byte line, 4-way) with variations in line size and associativity. We also executed the kernels on these machines. <p> TSS has consistently lower simulated miss rates than Esseghir, on average a factor of 6.66 (excluding arrays of size 256fi256, including them 5.34). For example, on SOR2D 301fi301 4-way, TSS improves miss rates by a factor of 50 over Esseghir. These results hold for larger line sizes as well <ref> [Col94] </ref>. TSS's lower simulated miss rates translate into better performance. Table 4 presents execution time results on the DEC Alpha (first level cache: 8K, direct-mapped, 32 byte line; second level cache: 512K, banked). We measured the execution times for TSS with and without computing the tile sizes at runtime.
Reference: [Ess93] <author> K. Esseghir. </author> <title> Improving data locality for caches. </title> <type> Master's thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: We present simulated miss rates and execution times for a variety of tiled nests that illustrate the effectiveness of the TSS algorithm. We compare these results to previous algorithms by Lam et al. [LRW91] and Esseghir <ref> [Ess93] </ref>. On average, TSS achieves better miss rates and performance on direct-mapped caches than previous algorithms because it selects rectangular tile sizes that use the majority of the cache. In some cases, it achieves significantly better performance. <p> Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. <ref> [Ess93, LRW91] </ref>. 2 Related Work Several researchers describe methods for how to tile nests [BJWE92, CK92, CL95, IT88, GJG88, Wol89]. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. <p> None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes <ref> [Ess93, LRW91] </ref>. Esseghir selects tile sizes for a variety of tiled nests [Ess93]. His algorithm chooses the maximum number of complete columns that fit in the cache. This algorithm leaves one large gap of unused cache. <p> More recent work has addressed some of these factors for selecting tile sizes [Ess93, LRW91]. Esseghir selects tile sizes for a variety of tiled nests <ref> [Ess93] </ref>. His algorithm chooses the maximum number of complete columns that fit in the cache. This algorithm leaves one large gap of unused cache. All of his experiments were performed on the RS6000 (64K, 128 byte line, 4-way set associative). <p> The number of complete columns that fit in the cache is simply ColsPerSet = bCS=N c: (1) For Figure 3, ColsPerSet = 5 for a tile of 200fi5 (Esseghir selects this tile size <ref> [Ess93] </ref>). A 200fi5 tile uses 97% percent of a 1024 element cache, but leaves a single contiguous gap. If N evenly divides CS, we also select this tile size. <p> For 4-way caches, all of the untiled kernels have lower miss rates for 128 byte lines because the increased set associativity has overcome the interference. 5.2 Comparing Algorithms In both simulations and execution results, we compare our tile sizes to those chosen by Lam et al. [LRW91] and Esseghir's algorithms <ref> [Ess93] </ref>. We use the algorithms presented in their papers to compute tile sizes for the different cache organizations and data sets. LRW generates the largest square tiles without self interference. Esseghir chooses the column length, N for the column tile size and bCS=N c c for the row size. <p> Average Improvement 1.06 0.98 Average Improvement without 256fi256 cases 1.02 0.97 Table 6: Execution Times in seconds on the RS/6000 (64K, 4-way, 128 byte lines) formance, we compared execution times for tiled matrix multiply using tile sizes chosen by TSS to execution times for code generated by Esseghir's Tile-and-Copy algorithm <ref> [Ess93] </ref>. These results appear in Table 7. The execution times for TSS include computing the tile sizes at runtime. Tile sizes for Esseghir's code were calculated using the formula T S = p where T S is the tile size.
Reference: [GJG88] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Much previous work focuses on how to do the loop nest restructuring step in tiling <ref> [CK92, CL95, IT88, GJG88, WL91, Wol89] </ref>. This work however ignores the effects of real caches such as low associativity and cache line size on the cache performance of tiled nests. Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91]. <p> Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. [Ess93, LRW91]. 2 Related Work Several researchers describe methods for how to tile nests <ref> [BJWE92, CK92, CL95, IT88, GJG88, Wol89] </ref>. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes [Ess93, LRW91]. <p> Previous research has focused on how to transform a nest into a tiled version to eliminate these capacity misses <ref> [CK92, CL95, IT88, GJG88, Wol89] </ref>. We assume as input a tiled nest produced by one of these methods and turn our attention the selection of tile sizes for the nest. For example, tiled matrix multiply appears in Figure 1 (b) and its corresponding reuse pattern in Figure 2 (b).
Reference: [IT88] <author> F. Irigoin and R. Triolet. </author> <title> Supernode partitioning. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> San Diego, CA, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: Much previous work focuses on how to do the loop nest restructuring step in tiling <ref> [CK92, CL95, IT88, GJG88, WL91, Wol89] </ref>. This work however ignores the effects of real caches such as low associativity and cache line size on the cache performance of tiled nests. Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91]. <p> Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. [Ess93, LRW91]. 2 Related Work Several researchers describe methods for how to tile nests <ref> [BJWE92, CK92, CL95, IT88, GJG88, Wol89] </ref>. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes [Ess93, LRW91]. <p> Previous research has focused on how to transform a nest into a tiled version to eliminate these capacity misses <ref> [CK92, CL95, IT88, GJG88, Wol89] </ref>. We assume as input a tiled nest produced by one of these methods and turn our attention the selection of tile sizes for the nest. For example, tiled matrix multiply appears in Figure 1 (b) and its corresponding reuse pattern in Figure 2 (b).
Reference: [Kob87] <author> Neal Koblitz. </author> <title> Graduate Texts in Mathematics. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: If N evenly divides CS, we also select this tile size. Otherwise, we look for a smaller column dimension with a larger row size that does not incur interference, combining to use a higher percentage of the cache. We use the Euclidean algorithm <ref> [Kob87] </ref> to generate potential column dimensions. The Euclidean algorithm finds the g.c.d.(a; b) a &gt; b, in O (log 3 (a)) time.
Reference: [LRW91] <author> M. Lam, E. Rothberg, and M. E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: This work however ignores the effects of real caches such as low associativity and cache line size on the cache performance of tiled nests. Because of these factors, performance for a given problem size can vary wildly with tile size <ref> [LRW91] </ref>. In addition, performance can vary wildly when the same tile sizes are used on very similar problem sizes [LRW91, NJL94]. These results occur because low associativity causes interference misses in addition to capacity misses. Published in SIGPLAN'95: Conference on Programming Language Design and Implementation, La Jolla, CA, June 1995. <p> Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91]. In addition, performance can vary wildly when the same tile sizes are used on very similar problem sizes <ref> [LRW91, NJL94] </ref>. These results occur because low associativity causes interference misses in addition to capacity misses. Published in SIGPLAN'95: Conference on Programming Language Design and Implementation, La Jolla, CA, June 1995. In this paper, we focus on how to choose the tile sizes given a tiled nest. <p> We present simulated miss rates and execution times for a variety of tiled nests that illustrate the effectiveness of the TSS algorithm. We compare these results to previous algorithms by Lam et al. <ref> [LRW91] </ref> and Esseghir [Ess93]. On average, TSS achieves better miss rates and performance on direct-mapped caches than previous algorithms because it selects rectangular tile sizes that use the majority of the cache. In some cases, it achieves significantly better performance. <p> Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. <ref> [Ess93, LRW91] </ref>. 2 Related Work Several researchers describe methods for how to tile nests [BJWE92, CK92, CL95, IT88, GJG88, Wol89]. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. <p> None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes <ref> [Ess93, LRW91] </ref>. Esseghir selects tile sizes for a variety of tiled nests [Ess93]. His algorithm chooses the maximum number of complete columns that fit in the cache. This algorithm leaves one large gap of unused cache. <p> All of his experiments were performed on the RS6000 (64K, 128 byte line, 4-way set associative). For this cache organization, Esseghir's strategy slightly out performs the TSS algorithm by a factor of 1.03. However, when compared to TSS or Lam et al. <ref> [LRW91] </ref> on an 8K cache with 1, 2, or 4-way set associative caches using matrices that are relatively large with respect to cache size (e.g., 300fi300), Esseghir's algorithm results in significantly higher miss rates. <p> For example, TSS out performs it on the DEC Alpha (8K, 32 byte line, direct mapped) for matrix multiply by an average factor of 2 (Section 5). Lam et al. present cache performance data for tiled matrix multiply and describe a model for evaluating cache interference <ref> [LRW91] </ref>. The model evaluates reuse for one variable, and quantifies self-interference misses for matrix multiply as a function of tile size. They show choosing a tile size that uses a fixed fraction of the cache performs poorly compared to tile sizes that are tailored for a problem and cache size. <p> For 4-way caches, all of the untiled kernels have lower miss rates for 128 byte lines because the increased set associativity has overcome the interference. 5.2 Comparing Algorithms In both simulations and execution results, we compare our tile sizes to those chosen by Lam et al. <ref> [LRW91] </ref> and Esseghir's algorithms [Ess93]. We use the algorithms presented in their papers to compute tile sizes for the different cache organizations and data sets. LRW generates the largest square tiles without self interference.
Reference: [NJL94] <author> J. J. Navarro, T. Juan, and T. Lang. </author> <title> Mob forms: A class of multilevel block algorithms for dense linear algebra operations. </title> <booktitle> In Proceedings of the 1994 ACM International Conference on Supercomputing, </booktitle> <pages> pages 354-363, </pages> <address> Manchester, England, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91]. In addition, performance can vary wildly when the same tile sizes are used on very similar problem sizes <ref> [LRW91, NJL94] </ref>. These results occur because low associativity causes interference misses in addition to capacity misses. Published in SIGPLAN'95: Conference on Programming Language Design and Implementation, La Jolla, CA, June 1995. In this paper, we focus on how to choose the tile sizes given a tiled nest.
Reference: [Smi82] <author> A. J. Smith. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: In this paper, we concentrate on tiling for the first level of cache memory. The cache is described by its size, line size, and set associativity <ref> [Smi82] </ref>. Unless otherwise indicated, we assume a direct-mapped cache. We divide cache misses into three categories. Compulsory misses occur when a cache line is referenced for the first time. Without prefetching, these misses are un avoidable.
Reference: [TGJ93] <author> O. Temam, E. Granston, and W. Jalby. </author> <title> To copy or not to copy: A compile-time technique for assessing when data copying should be used to eliminate cache conflicts. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: TSS consistently improves execution times over Lam et al. by an average factor of 1.12 on the DEC Alpha and a smaller factor of 1.02 on the RS6000. Esseghir, Lam et al., and Temam et al. <ref> [TGJ93] </ref> all recommend copying as a method to avoid self-interference and cross-interference misses. Copying also requires knowledge of array sizes which may not be available until runtime. It makes performance much more predictable for varying tile sizes.
Reference: [WL91] <author> M. E. Wolf and M. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Much previous work focuses on how to do the loop nest restructuring step in tiling <ref> [CK92, CL95, IT88, GJG88, WL91, Wol89] </ref>. This work however ignores the effects of real caches such as low associativity and cache line size on the cache performance of tiled nests. Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91].
Reference: [Wol89] <author> M. J. Wolfe. </author> <title> More iteration space tiling. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <pages> pages 655-664, </pages> <address> Reno, NV, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: Much previous work focuses on how to do the loop nest restructuring step in tiling <ref> [CK92, CL95, IT88, GJG88, WL91, Wol89] </ref>. This work however ignores the effects of real caches such as low associativity and cache line size on the cache performance of tiled nests. Because of these factors, performance for a given problem size can vary wildly with tile size [LRW91]. <p> Section 5 presents simulation and execution time results that demonstrate the efficacy of our approach and compares it to the work of Esseghir and Lam et al. [Ess93, LRW91]. 2 Related Work Several researchers describe methods for how to tile nests <ref> [BJWE92, CK92, CL95, IT88, GJG88, Wol89] </ref>. None of this work however addresses interference, cache replacement policies, cache line size, or spatial locality which are important factors that determine performance for current machines. More recent work has addressed some of these factors for selecting tile sizes [Ess93, LRW91]. <p> Previous research has focused on how to transform a nest into a tiled version to eliminate these capacity misses <ref> [CK92, CL95, IT88, GJG88, Wol89] </ref>. We assume as input a tiled nest produced by one of these methods and turn our attention the selection of tile sizes for the nest. For example, tiled matrix multiply appears in Figure 1 (b) and its corresponding reuse pattern in Figure 2 (b). <p> Between reuse of an element of Y, the J and K loops access TK distinct elements of X, TJ elements of Z, and TK * TJ elements of Y. We call the portion of an array which is referenced by a loop the footprint of that array reference <ref> [Wol89] </ref>. We call the number of times the same element is referenced by a loop the reuse factor. We call the innermost loop that has not been strip mined and interchanged the target loop, the I loop in matrix multiply; the target nest accesses a tile of data. <p> Inspection of the array accesses, loop nesting, and loop bounds of the tiled nest determines the footprint and reuse factor <ref> [Wol89] </ref>. Table 1 illustrates these quantities for the version of tiled matrix multiply in Figure 1 (b). The largest tile with the most reuse on the I loop is the access to Y. We therefore target this reference to fit and stay in cache.
References-found: 15

