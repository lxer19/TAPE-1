URL: http://vis-www.cs.umass.edu/vislib/Papers/zhang/cvpr94.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/vislib/Papers/zhang/files.html
Root-URL: 
Email: Email: zzhang@cs.umass.edu  
Title: QUALITATIVE OBSTACLE DETECTION  
Author: Zhongfei Zhang Richard Weiss Allen R. Hanson 
Address: Amherst, MA 01003  
Affiliation: Computer Science Department University of Massachusetts  
Abstract: Three different algorithms for qualitative obstacle detection are presented in this paper. Each one is based on different assumptions. The first two algorithms are aimed at yes/no obstacle detection without indicating which points are obstacles. They have the advantage of fast determination of the existence of obstacles in a scene based on the solvability of a linear system. The first algorithm uses information about the ground plane, while the second algorithm only assumes that the ground is planar. The third algorithm continuously estimates the ground plane, and based on that determines the height of each matched point in the scene. Experimental results are presented for real and simulated data, and performances of the three algorithms under different noise levels are compared in simulation. We conclude that in terms of the robustness of performance, the third one works best. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Enkelmann. </author> <title> Obstacle detection by evaluation of optical flow fields. </title> <booktitle> In Proc. 1st ECCV, </booktitle> <year> 1990. </year>
Reference-contexts: This paper shows that it is possible to recover partial metric information from partial calibration. Because of its practical interest, obstacle detection has received widespread attention in the research literature <ref> [1, 8, 5] </ref>. Most existing algorithms for detecting obstacles use active range sensors, stereo, or optical flow. For example, Nelson and Aloimonos [8] used flow field divergence for obstacle detection and avoidance in visual navigation. <p> Most existing algorithms for detecting obstacles use active range sensors, stereo, or optical flow. For example, Nelson and Aloimonos [8] used flow field divergence for obstacle detection and avoidance in visual navigation. Enkelmann <ref> [1] </ref> approached this problem by evaluating the difference between the calculated optical flow and the predicted model-based flow. This method assumes the vehicle motion is pure translation, which may not be true in real environment.
Reference: [2] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig? In Proc. </title> <booktitle> 2nd ECCV, </booktitle> <pages> pages 563-578, </pages> <address> Santa Margherita Ligure, Italy, May 1992. </address> <publisher> Springer-verlag. </publisher>
Reference-contexts: The third algorithm adaptively updates its knowledge of the environment by estimating the ground plane over a sequence of partially calibrated stereo pairs. This algorithm estimates the height above the ground plane for all points in a region of interest in an image. Faugeras <ref> [2] </ref> and Hartley [7] have independently shown that from uncalibrated stereo one can recover 3D structure up to a family of projective transformations. This paper shows that it is possible to recover partial metric information from partial calibration.
Reference: [3] <author> O.D. Faugeras and F. Lustman. </author> <title> Motion and structure from motion in a piecewise planar environment. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 485-508, </pages> <year> 1988. </year>
Reference-contexts: If there are obstacle points, then Rank (Db) = i + 1: Thus, one would first determine i; then determine the consistency of the linear system. UGP works in a similar way. It is easy to show <ref> [3] </ref> that given an arbitrary ground plane point, p i () p i 0 , there is an invariant 3 by 3 matrix: A = h c R + tn T (4) such that k i p i where h c is the height of the focal point of the first
Reference: [4] <author> G.H. Golub and C.F.V. Loan. </author> <title> Matrix Computations, 2nd Ed. </title> <publisher> The Johns Hopkins University Press, </publisher> <year> 1989. </year>
Reference-contexts: Note that this criterion is the most conservative one, since a singular value of a matrix is always less than or equal to the corresponding singular value of its augmented matrix <ref> [4] </ref>. Let 1 2 ::: 6 be the six singular values of matrix D, and 1 2 ::: 7 be the seven singular values of the augmented matrix (Db).
Reference: [5] <author> P. Grandjean and L. Matthies. </author> <title> Perception control for obstacle detection by a cross-country rover. </title> <booktitle> In Proc. ICRA, </booktitle> <pages> pages 20-27, </pages> <address> Atlanta, Georgia, </address> <month> May </month> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: This paper shows that it is possible to recover partial metric information from partial calibration. Because of its practical interest, obstacle detection has received widespread attention in the research literature <ref> [1, 8, 5] </ref>. Most existing algorithms for detecting obstacles use active range sensors, stereo, or optical flow. For example, Nelson and Aloimonos [8] used flow field divergence for obstacle detection and avoidance in visual navigation. <p> Enkelmann [1] approached this problem by evaluating the difference between the calculated optical flow and the predicted model-based flow. This method assumes the vehicle motion is pure translation, which may not be true in real environment. More recently, Grandjean and Matthies <ref> [5] </ref> attacked the problem for real-time vehicle navigation by using stereo maps. Throughout this paper, the following notation will be used. Let p denote the calibrated image vector for the left camera (in stereo) or for the first camera (in motion) represented in homogeneous coordinates.
Reference: [6] <author> A.R. Hanson, </author> <title> E.M. </title> <booktitle> Riseman, and C.A. Weems. Progress in computer vision at the university of massachusetts. In IUW, </booktitle> <pages> pages 39-47. </pages> <publisher> Morgan Haufmann, </publisher> <month> April </month> <year> 1993. </year>
Reference-contexts: Due to the limitation of space, we here only report part of one experimental results with EGP algorithms. Fig.1 is the left image of a sample of a sequence taken by the stereo cameras onboard our Mobile Perception Lab <ref> [6] </ref>. The height of the cameras, h c , is 7.8 ft. The 6 points labeled in the image are the obstacle points. The ground truth heights for points 1 to 5 are 2.35 ft., and for point 6 is 1.50 ft.
Reference: [7] <author> R. Hartley, R. Gupta, and T. Chang. </author> <title> Stereo from uncalibrated cameras. </title> <booktitle> In CVPR. IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: The third algorithm adaptively updates its knowledge of the environment by estimating the ground plane over a sequence of partially calibrated stereo pairs. This algorithm estimates the height above the ground plane for all points in a region of interest in an image. Faugeras [2] and Hartley <ref> [7] </ref> have independently shown that from uncalibrated stereo one can recover 3D structure up to a family of projective transformations. This paper shows that it is possible to recover partial metric information from partial calibration.
Reference: [8] <author> R.C. Nelson and J. Aloimonos. </author> <title> Obstacle avoidance using flow field divergence. </title> <journal> Trans. PAMI, </journal> <volume> 11(10), </volume> <year> 1989. </year>
Reference-contexts: This paper shows that it is possible to recover partial metric information from partial calibration. Because of its practical interest, obstacle detection has received widespread attention in the research literature <ref> [1, 8, 5] </ref>. Most existing algorithms for detecting obstacles use active range sensors, stereo, or optical flow. For example, Nelson and Aloimonos [8] used flow field divergence for obstacle detection and avoidance in visual navigation. <p> Because of its practical interest, obstacle detection has received widespread attention in the research literature [1, 8, 5]. Most existing algorithms for detecting obstacles use active range sensors, stereo, or optical flow. For example, Nelson and Aloimonos <ref> [8] </ref> used flow field divergence for obstacle detection and avoidance in visual navigation. Enkelmann [1] approached this problem by evaluating the difference between the calculated optical flow and the predicted model-based flow. This method assumes the vehicle motion is pure translation, which may not be true in real environment.
Reference: [9] <author> Zhongfei Zhang. </author> <title> Decomposition of A matrix. </title> <type> CMPSCI TR, </type> <year> 1994. </year>
Reference-contexts: can be rewritten as follows: h i = (x i 0 )( R 3 p i 0 ) 1 h c 00 y i R 2 p i y i (15) 1 With given A, the rotation R and the translation t can be completely recovered in a closed-form solution <ref> [9] </ref>. The accuracy of the recovered parameters, however, highly depends on the accuracy of the camera internal parameters, especially the coordinates of the principal point, according to the experimental results in [9]. <p> 1 With given A, the rotation R and the translation t can be completely recovered in a closed-form solution <ref> [9] </ref>. The accuracy of the recovered parameters, however, highly depends on the accuracy of the camera internal parameters, especially the coordinates of the principal point, according to the experimental results in [9]. That is why we usually use known relative rotation, especially the alignment of the two cameras in practice, which also has the advantage of independence of the camera internal calibration, as shown in the text This solution looks very simple.
Reference: [10] <author> Zhongfei Zhang, Richard Weiss, and Allen R. Hanson. </author> <title> Qualitative obstacle detection. </title> <address> CMP-SCI TR94-20, </address> <year> 1994. </year> <title> sequence Table 1 | Height estimate errors Note: Absolute error in ft. </title> <note> Relative error in % Point predict estimate Labels Abs Rel Abs Rel 1 0.23 9.8% 0.11 4.7% 3 0.21 8.9% 0.15 6.4% 5 -0.08 -3.4% -0.05 -2.1% </note>
Reference-contexts: Both algorithms can be applied to either a stereo pair or motion images. Based on the assumptions made, UGP is more general than KGP. However, KGP performs better in general if one has good a priori estimates for the parameters of the ground plane/camera calibration. <ref> [10] </ref> shows how the two algorithms compare in practice. <p> relationship between the 3D point P and its corresponding 2D image point p, together with the ground plane equation, produces the following matrix equation of the flow of point p: _p = HM (2) Here H is a function of ground plane equation coefficients and the image point p (see <ref> [10] </ref> for the detailed derivation). We regard H as a linear function, which transforms a motion parameter vector M into a flow vector for p, when the image of a ground plane point is given. <p> It can be shown <ref> [10] </ref> that the following proposition holds: Proposition: The n points are all ground plane points iff the linear system Eq.3 has a solution; that is, iff Rank (D) = Rank (Db). <p> A feasible criterion for determining if Rank (D) = Rank (Db) is to check if the ratio min (D) is suffi ciently large. Based on our simulation analysis under different noise levels, and our experimental results on real images <ref> [10] </ref>, a threshold ffi between 5 to 10 on this ratio value is sufficient to detect obstacle points 1 ft. or more off the ground plane. <p> In practice, the road surface may have bumps and dents. Thus, the surface may not satisfy the coplanarity constraint. Although we can use a lower threshold to tolerate this kind of variation of the road surface, the simulation results in <ref> [10] </ref> show that when the noise increases, the ratio value decreases dramatically. That means these two algo rithms are sensitive to noise. <p> tn T ]p i (7) where h c is the height of the left camera above the reference plane, h i is the distance of the 3D point P i above the reference plane, and k i 0 is the scale factor corresponding to p i () p i 0 <ref> [10] </ref>. We define the state vector S to be the vector consisting of the eight variable elements of the matrix A in Eq.6. Note that this vector combines information about the ground plane and the transformation between cameras. <p> R = (R 1 ; R 2 ; R 3 ) T , and t = (t X ; t Y ; t Z ) T . Since we have P i () p i () p i 00 by the definition of k i <ref> [10] </ref>, k i Z i Z i t Z (11) 00 = 0 = R 3 p i + Z Qi Based on the matrix A, we can solve for the rota tion R and the translation t 1 . <p> In practice, this may not be true, and there may be hills at different scales. Hills at large scales can be accommodated by weighting previous estimates so that the Kalman Filter only accumulates its history from the last n frames. Experimental results <ref> [10] </ref> show that this modified version works much better for real road scenes. 4 Experiments A thorough comparison among the three algorithms with respect to robustness in the presence of noise in real and simulated image sequences can be found in [10], in which we addressed the question of what is <p> Experimental results <ref> [10] </ref> show that this modified version works much better for real road scenes. 4 Experiments A thorough comparison among the three algorithms with respect to robustness in the presence of noise in real and simulated image sequences can be found in [10], in which we addressed the question of what is the smallest obstacle that can be reliably detected for a given level of noise. <p> Generally speaking, according to our simulation results, EGP is the most robust algorithm of the three with respect to small-scale variation in the ground height. All the three algorithms have been tested on real image data <ref> [10] </ref>. Due to the limitation of space, we here only report part of one experimental results with EGP algorithms. Fig.1 is the left image of a sample of a sequence taken by the stereo cameras onboard our Mobile Perception Lab [6]. <p> The ground truth heights for points 1 to 5 are 2.35 ft., and for point 6 is 1.50 ft. Table 1 shows the estimated heights based on EGP algorithm for the 6 obstacle points. When more frames are used <ref> [10] </ref>, we can see that both the absolute and relative errors monotonically decrease as the vehicle approaches the obstacles. The relative error is of the same order as in the simulation [10]. 5 Conclusions In terms of robustness with respect to ground plane variation, the experimental results [10] show that the <p> When more frames are used <ref> [10] </ref>, we can see that both the absolute and relative errors monotonically decrease as the vehicle approaches the obstacles. The relative error is of the same order as in the simulation [10]. 5 Conclusions In terms of robustness with respect to ground plane variation, the experimental results [10] show that the EGP algorithm is the best. <p> frames are used <ref> [10] </ref>, we can see that both the absolute and relative errors monotonically decrease as the vehicle approaches the obstacles. The relative error is of the same order as in the simulation [10]. 5 Conclusions In terms of robustness with respect to ground plane variation, the experimental results [10] show that the EGP algorithm is the best. This algorithm does have many other advantages as well since it is adaptive to changes in the ground plane and the Kalman filter updates are fast to compute.
References-found: 10

