URL: http://www.csc.ncsu.edu/faculty/WStewart/Publications/PS_files/Atif_paper.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/WStewart/Publications/Publications.html
Root-URL: http://www.csc.ncsu.edu
Title: The Numerical Solution of Stochastic Automata Networks  
Author: William J. Stewart Karim Atif Brigitte Plateau 
Keyword: Key words: Markov processes; Stochastic automata networks; Numerical solutions; Projection methods; Preconditioning.  
Date: August 9, 1996  
Abstract: Stochastic Automata Networks (SAN's) have recently received attention in the literature as an efficient means of modelling parallel systems such as communicating processes, concurrent processors, shared memory, etc. The advantage that the SAN approach has over generalized stochastic Petri nets, and indeed over any Markovian analysis that requires the generation of a transition matrix, is that its representation remains compact even as the number of states in the underlying Markov chain begins to explode. Our concern in this paper is with the numerical issues that are involved in solving SAN networks. We introduce stochastic automata and consider the numerical difficulties that result from their interaction. We examine how the product of a vector with a compact SAN descriptor may be formed, for this operation is basis to all iterative solution methods. We describe possible solution methods, including the power method, the method of Arnoldi and GMRES, and show that the two latter methods greatly out-perform the power method | the method usually used in conjunction with stochastic automata networks. Finally, we consider one possible means of preconditioning, but conclude that further research is needed. y Department of Computer Science, North Carolina State University, Raleigh, USA. | On sabattical leave at IMAG-LGI, 46 Avenue Felix Viallet, Grenoble, France. Research supported in part by NSF Grant No. CCR-8906248A. fl LMC-IMAG, 46 Avenue Felix Viallet, Grenoble, France. Research supported by C 3 and Greco Automatique. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W.E. </author> <title> Arnoldi. The principle of minimized iteration in the solution of the matrix eigenvalue problem. </title> <journal> Quart. Appl. Math., </journal> <volume> Vol. 9, </volume> <year> 1951, </year> <pages> pp. 17-29. </pages>
Reference-contexts: Theorem 5.2 Let X = (X (1) ; X (2) ; : : : ; X (N) ) be an N -dimensional Markov chain with infinitesimal generator N i=1 Q (i) and stationary probability vector . Let oe be a permutation of the integers <ref> [1; 2; : : :; N ] </ref>. Then: 1. The infinitesimal generator of the permuted Markov chain, X oe = (X (oe 1 ) ; X (oe 2 ) ; : : :; X (oe N ) ), is given by N i=1 Q (oe i ) . 2. <p> Form the approximate solution: * Among all vectors of R m , find the vector y m which minimizes the function J (y) = kfie 1 H m yk 2 where e 1 = <ref> [1; 0; : : :0] </ref> T . * Compute x m = x 0 + V m y m 4.
Reference: [2] <author> K. </author> <month> Atif. </month> <institution> Modelisation du Parallelisme et de la Synchronisation. These de Docteur de l'Institut National Polytechnique de Grenoble, </institution> <address> 24 Septembre 1988, Grenoble, France. </address>
Reference-contexts: Certain experimental studies have shown this to give reasonably accurate results when the number of functional transitions is not large and those that do exist are not vastly different, <ref> [2] </ref>. If this is not acceptable, then it may be possible to generate the global infinitesimal generator and to apply one of the standard numerical solution methods, [13, 21]. <p> Theorem 5.2 Let X = (X (1) ; X (2) ; : : : ; X (N) ) be an N -dimensional Markov chain with infinitesimal generator N i=1 Q (i) and stationary probability vector . Let oe be a permutation of the integers <ref> [1; 2; : : :; N ] </ref>. Then: 1. The infinitesimal generator of the permuted Markov chain, X oe = (X (oe 1 ) ; X (oe 2 ) ; : : :; X (oe N ) ), is given by N i=1 Q (oe i ) . 2. <p> Much more research needs to be conducted into finding preconditioning techniques that can be applied to SAN descriptors without the need to expand the global generator. Other approaches were tried in our work, but with even less success, (see <ref> [2] </ref>). On the other hand, the results clearly demonstrate the success of the Arnoldi and GMRES methods, both in terms of number of iterations and total time. These results are confirmed in an examination of the results obtained when these methods are applied to all three models.
Reference: [3] <author> P. Buchholz. </author> <title> Numerical Solution Methods Based on Structured Descriptions of Markovian Models. </title> <booktitle> The 5th International Conference on Modelling Techniques and Tools for Computer Performance Evaluation, </booktitle> <editor> G. Balbo and G. Serrazzi Eds., </editor> <address> Torino, </address> <month> February </month> <year> 1991, </year> <pages> Elsevier, pp. 242-258. </pages>
Reference-contexts: We note in passing that other recently proposed techniques to overcome the state space explosion problem include decomposition [5], model simplification [18] and a-priori structuring of the model <ref> [3, 10, 11, 17] </ref>. In Sections 2 and 3 we provide a brief, intuitive introduction on modelling with Stochastic Automata Networks and the general formulation is described in Section 4. <p> Finally, in Section 7 we describe numerical experiments on three different models to show the respective efficiency of the different methods. The methods we describe are all exact methods in that they converge to the exact stationary distribution vector. This differs from the work of Buchholz, <ref> [3, 4] </ref> where the numerical methods are based on an approximate aggregation-disaggregation procedure for hierarchical model structures. 2 Non-Interacting Stochastic Automata 2.1 Independent, Two-dimensional Markov Chains Consider the case of a system that may be modelled by two completely independent stochastic automata, each of which may be represented by a discrete-time
Reference: [4] <author> P. Buchholz. </author> <title> Hierarchical Markovian Models Symmetries and Aggregation; Modelling Techniques and Tools for Computer Performance Evaluation, </title> <editor> Ed. R. Pooley, J.Hillston, </editor> <address> Edinburgh, Scotland, </address> <year> 1992, </year> <pages> pp. 234-246. </pages>
Reference-contexts: Finally, in Section 7 we describe numerical experiments on three different models to show the respective efficiency of the different methods. The methods we describe are all exact methods in that they converge to the exact stationary distribution vector. This differs from the work of Buchholz, <ref> [3, 4] </ref> where the numerical methods are based on an approximate aggregation-disaggregation procedure for hierarchical model structures. 2 Non-Interacting Stochastic Automata 2.1 Independent, Two-dimensional Markov Chains Consider the case of a system that may be modelled by two completely independent stochastic automata, each of which may be represented by a discrete-time
Reference: [5] <author> G. Ciardo and K. Trivedi. </author> <title> Solution of Large GSPN Models. Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Marcel Dekker Publisher, </publisher> <address> New York, </address> <year> 1991, </year> <pages> pp. 565-595. </pages>
Reference-contexts: We note in passing that other recently proposed techniques to overcome the state space explosion problem include decomposition <ref> [5] </ref>, model simplification [18] and a-priori structuring of the model [3, 10, 11, 17]. In Sections 2 and 3 we provide a brief, intuitive introduction on modelling with Stochastic Automata Networks and the general formulation is described in Section 4.
Reference: [6] <author> M. Davio. </author> <title> Kronecker Products and Shu*e Algebra. </title> <journal> IEEE Trans. Comput, </journal> <volume> Vol. C-30, No. 2, </volume> <month> Feb. </month> <year> 1981, </year> <pages> pp. 116-125. </pages>
Reference-contexts: 12 b 13 a 12 0 0 b 31 b 32 a 11 + b 33 0 0 a 12 0 a 21 0 b 21 a 22 + b 22 b 23 1 C C C A More information concerning the properties of tensor algebra may be found in <ref> [6] </ref>. 2.3 Probability Distributions Let us return to the system modelled as two independent stochastic automata. Let (1) the probability that the first automaton is in state i at time t and (2) j (t) the probability that the second is in state j, at time t.
Reference: [7] <author> A. Greenbaum, P.F. Dubois and G.H. Rodrique. </author> <title> Approximating the Inverse of a Matrix for use in Iterative Algorithms on Vector Processors. </title> <journal> Computing, </journal> <volume> Vol. 22, </volume> <year> 1979, </year> <pages> pp. 257-268. </pages>
Reference: [8] <author> A. Jennings and W.J. Stewart. </author> <title> Simultaneous iteration for Partial Eigensolution of Real Matrices. </title> <journal> J. Inst. Math. Applics., </journal> <volume> Vol. 15, </volume> <year> 1975, </year> <pages> pp. 351-361. 26 </pages>
Reference-contexts: These include the class of methods known as simultaneous iteration or subspace iteration, <ref> [8, 19, 20] </ref>, which iterate continuously with a fixed number of vectors, as well as methods that begin with a single vector and construct a subspace one vector at a time, [15].
Reference: [9] <author> C.D. Meyer. </author> <title> The Role of the Group Generalized Inverse in the Theory of Finite Markov Chains. </title> <journal> Siam Review, </journal> <volume> Vol. 17, No. 3, </volume> <month> July </month> <year> 1974, </year> <pages> pp 443-464. </pages>
Reference-contexts: Unfortunately in the context of stochastic automata networks where the infinitesimal generator is in the form of a sum of tensor products, this approach is not possible. We need to adopt a different strategy. 21 From equation (12), we have I P = tQ. Furthermore, it is shown in <ref> [9] </ref> that (I P ) # = k=0 where the superscript # denotes the generalized inverse and L is an n fi n matrix whose rows are all equal to the stationary probability vector .
Reference: [10] <author> B. </author> <title> Plateau. On the Stochastic Structure of Parallelism and Synchronization Models for Distributed Algorithms. </title> <booktitle> Proc. ACM Sigmetrics Conference on Measurement and Modelling of Computer Systems, </booktitle> <address> Austin, Texas, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: We note in passing that other recently proposed techniques to overcome the state space explosion problem include decomposition [5], model simplification [18] and a-priori structuring of the model <ref> [3, 10, 11, 17] </ref>. In Sections 2 and 3 we provide a brief, intuitive introduction on modelling with Stochastic Automata Networks and the general formulation is described in Section 4. <p> Our immediate reaction in observing these altered matrices may be to assume that a major disadvantage of incorporating synchronizing transitions is to remove the possibility of representing the global transition rate matrix as a (sum of) tensor products. However, Plateau <ref> [10] </ref> has shown that, by separating local transitions from synchronizing transitions, this is not necessarily so; that the global transition rate matrix can still be written as a (sum of) tensor products. To observe this we proceed as follows. <p> This is the approach that is used in the software package PEPS, <ref> [10] </ref>.
Reference: [11] <author> B. Plateau and K. Atif. </author> <title> Stochastic Automata Network for Modelling Parallel Systems. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. 17, No. 10, </volume> <year> 1991, </year> <pages> pp. 1093-1108. </pages>
Reference-contexts: We note in passing that other recently proposed techniques to overcome the state space explosion problem include decomposition [5], model simplification [18] and a-priori structuring of the model <ref> [3, 10, 11, 17] </ref>. In Sections 2 and 3 we provide a brief, intuitive introduction on modelling with Stochastic Automata Networks and the general formulation is described in Section 4. <p> In contrast to functional transitions, synchronizing events affect the global system by possibly altering the state of several automata. Given this information on functional transition rates and synchronizing events, it is possible to formally define a network of stochastic automata. This has been done by Atif and Plateau <ref> [11] </ref>, and we refer the reader to their work for further information on this subject. We shall continue by considering the effects of both synchronizing events and functional transition rates on our ability to efficiently solve networks of stochastic automata.
Reference: [12] <author> B. Plateau and J.M. Fourneau. </author> <title> A Methodology for Solving Markov Models of Parallel Systems. </title> <journal> Journal of Parallel and Distributed Computing. </journal> <volume> Vol. 12, </volume> <year> 1991, </year> <pages> pp. 370-387. </pages>
Reference-contexts: However, it is still possible to profit from the fact that the nonzero structure is unchanged. This is essentially what Plateau has done in her extension of the classical tensor algebraic concepts, <ref> [12] </ref>. The descriptor is still written as in equation (6), but now the elements of Q (i) j may be functions. This means that it is necessary to track elements that are functions and to substitute the appropriate numerical value each time the functional rate is needed. <p> It is important to note however, that this complexity result is valid only when the stochastic automata contain non-functional rates. A proof is given in <ref> [12] </ref>. Some examples will help us see this more clearly and at the same time show us where extra multiplications are needed for functional transitions. <p> Indeed, the following theorem is proven in <ref> [12] </ref>. Theorem 5.2 Let X = (X (1) ; X (2) ; : : : ; X (N) ) be an N -dimensional Markov chain with infinitesimal generator N i=1 Q (i) and stationary probability vector . <p> This results in a model with a total of 8192 states. Model 3 has already been discussed in the context of stochastic automata networks, <ref> [12] </ref> and readers interested in further details should consult this reference. The model consists of a set of N jobs that are processed at a finite capacity service center. The server, a multiprocessor, offers P different service rates according to the load imposed upon it.
Reference: [13] <author> B. Philippe, Y. Saad and W.J. Stewart. </author> <title> Numerical Methods in Markov Chain Modelling. </title> <journal> Operations Research, Vol.40, </journal> <volume> No. 6, </volume> <year> 1992, </year> <pages> pp. 1156-1179. </pages>
Reference-contexts: If this is not acceptable, then it may be possible to generate the global infinitesimal generator and to apply one of the standard numerical solution methods, <ref> [13, 21] </ref>. However, if the objective is to analyze several modest sized stochastic automata for which the transition matrices are dense, a quick analysis will reveal that the amount of memory needed to store the expanded matrix may exceed the capacity of the computer destined to perform the computation. <p> We shall only consider this latter class of method, since they appear to be more effective in Markov chain problems, <ref> [13] </ref>. In particular, we shall concentrate on the method of Arnoldi and GMRES, both of which are based on Krylov subspaces.
Reference: [14] <author> Y. Saad. </author> <title> Variations on Arnoldi's method for computing eigenelements of large unsymmetric matrices. </title> <journal> Lin. Alg. Appl., </journal> <volume> Vol. 34, </volume> <year> 1980, </year> <pages> pp. 269-295. </pages>
Reference: [15] <author> Y. Saad. </author> <title> Krylov Subspace Methods for Solving Unsymmetric Linear Systems. </title> <journal> Mathematics of Computation, </journal> <volume> Vol. 37, </volume> <year> 1981, </year> <pages> pp. 105-126. </pages>
Reference-contexts: These include the class of methods known as simultaneous iteration or subspace iteration, [8, 19, 20], which iterate continuously with a fixed number of vectors, as well as methods that begin with a single vector and construct a subspace one vector at a time, <ref> [15] </ref>. One subspace of particular importance that is built in this fashion is the Krylov subspace given by K m (A; v) = spanfv; Av; A 2 v; : : :; A m1 vg: Notice that this subspace is spanned by consecutive iterates of the power method.
Reference: [16] <author> Y. Saad and M.H. Schultz. </author> <title> GMRES: A generalized minimal residual algorithm for solving non-symmetric linear systems. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> Vol. 7, </volume> <year> 1986, </year> <pages> pp. 856-869. </pages>
Reference-contexts: This is Arnoldi's method in its simplest form. 6.2.2 GMRES | The Generalized Minimal Residual Method Like the version of Arnoldi given immediately above, the Generalized Minimum Residual, GM-RES algorithm, <ref> [16] </ref>, begins by constructing an orthonormal basis for a Krylov subspace. However, the initial vector with which to begin the construction of the subspace, is not chosen to be an approximation to the solution, but rather the residual produced by an initial approximation.
Reference: [17] <author> M. Siegle. </author> <title> On Efficient Markov Modelling. </title> <booktitle> In Proc. QMIPS Workshop on Stochastic Petri Nets, </booktitle> <pages> pp. 213-225, </pages> <address> Sophia-Antipolis, France, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: We note in passing that other recently proposed techniques to overcome the state space explosion problem include decomposition [5], model simplification [18] and a-priori structuring of the model <ref> [3, 10, 11, 17] </ref>. In Sections 2 and 3 we provide a brief, intuitive introduction on modelling with Stochastic Automata Networks and the general formulation is described in Section 4.
Reference: [18] <author> C. Simone and M.A. Marsan. </author> <title> The Application of the EB-Equivalence Rules to the Structural Reduction of GSPN Models. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 15, No. 3, </volume> <year> 1991, </year> <pages> pp. 296-302. </pages>
Reference-contexts: We note in passing that other recently proposed techniques to overcome the state space explosion problem include decomposition [5], model simplification <ref> [18] </ref> and a-priori structuring of the model [3, 10, 11, 17]. In Sections 2 and 3 we provide a brief, intuitive introduction on modelling with Stochastic Automata Networks and the general formulation is described in Section 4.
Reference: [19] <author> G.W. Stewart. </author> <title> Simultaneous iteration for computing invariant subspaces of non-Hermitian matrices. </title> <journal> Numer. Mat., </journal> <volume> Vol. 25, </volume> <year> 1976, </year> <pages> pp. 123-136. </pages>
Reference-contexts: These include the class of methods known as simultaneous iteration or subspace iteration, <ref> [8, 19, 20] </ref>, which iterate continuously with a fixed number of vectors, as well as methods that begin with a single vector and construct a subspace one vector at a time, [15].
Reference: [20] <author> W.J. Stewart and A. Jennings. </author> <title> A Simultaneous Iteration Algorithm for Real Matrices. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> Vol. 7, No. 2, </volume> <year> 1981, </year> <pages> pp. 184-198. </pages>
Reference-contexts: These include the class of methods known as simultaneous iteration or subspace iteration, <ref> [8, 19, 20] </ref>, which iterate continuously with a fixed number of vectors, as well as methods that begin with a single vector and construct a subspace one vector at a time, [15].
Reference: [21] <author> W.J. Stewart and W. Wu. </author> <title> Numerical Experiments with Iteration and Aggregation for Markov Chains. </title> <journal> ORSA Journal on Computing, </journal> <volume> July/August, </volume> <year> 1992, </year> <pages> pp. 336-350. </pages>
Reference-contexts: If this is not acceptable, then it may be possible to generate the global infinitesimal generator and to apply one of the standard numerical solution methods, <ref> [13, 21] </ref>. However, if the objective is to analyze several modest sized stochastic automata for which the transition matrices are dense, a quick analysis will reveal that the amount of memory needed to store the expanded matrix may exceed the capacity of the computer destined to perform the computation.
Reference: [22] <author> J.H. Wilkinson. </author> <title> The Algebraic Eigenvalue Problem. </title> <publisher> Clarendon Press, </publisher> <address> New York, </address> <year> 1965. </year> <month> 27 </month>
Reference-contexts: Neither can the iterative aggregation/disaggregation methods be used since these methods work with submatrices of the transition matrix, submatrices that are not easily extracted from the SAN descriptor. 6.1 The Power Method The power method, (see, for example, <ref> [22] </ref>), is well known in the context of determining the right-hand eigenvector corresponding to the dominant eigenvalue of a matrix. Let A be a square matrix of order n.
References-found: 22

