URL: http://www.cs.cornell.edu/Info/People/ronitt/PAP/approx.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/ronitt/papers.html
Root-URL: 
Title: Approximate Checking of Polynomials and Functional Equations  
Author: Funda Ergun S Ravi Kumar Ronitt Rubinfeld 
Date: September 16, 1997  
Address: Ithaca, NY 14853.  
Affiliation: Department of Computer Science Cornell University  
Abstract: In this paper, we show how to check programs that compute polynomials and functions defined by addition theorems | in the realistic setting where the output of the program is approximate instead of exact. We present results showing how to perform approximate checking, self-testing, and self-correcting of polynomials, settling in the affirmative a question raised by [GLR + 91, RS92, RS96]. We then show how to perform approximate checking, self-testing, and self-correcting for those functions that satisfy addition theorems, settling a question raised by [Rub94]. In both cases, we show that the properties used to test programs for these functions are both robust (in the approximate sense) and stable. Finally, we explore the use of reductions between functional equations in the context of approximate self-testing. Our results have implications for the stability theory of functional equations. fl This work is partially supported by NSF Career grant CCR-9624552 and the Alfred P. Sloan Research Award. The first and second authors are also supported by NSF grant DMI-91157199. The third author is also supported by the grant No. 92-00226 from the United States-Israel Binational Science Foundation (BSF), Jerusalem, Israel. Part of this research was conducted while visiting the M.I.T. Lab. for Computer Science. 
Abstract-found: 1
Intro-found: 1
Reference: [Acz66] <author> J. Aczel. </author> <title> Lectures on Functional Equations and their Applications. </title> <publisher> Academic Press, </publisher> <year> 1966. </year>
Reference-contexts: An addition theorem is a mathematical identity of the form 8x; y; f (x + y) = G [f (x); f (y)]. Addition theorems characterize many useful and interesting mathematical functions <ref> [Acz66, CR92] </ref>. When G is algebraic, they can be used to characterize families of functions that are rational functions of x, e cx , and doubly periodic functions (see Table 1 for examples).
Reference: [AB83] <author> M. Albert and J.A. Baker. </author> <title> Functions with bounded n-th differences. </title> <journal> Ann. Polonici Mathematici, </journal> <volume> 43:93 - 103, </volume> <year> 1983. </year> <month> 34 </month>
Reference-contexts: The problem of stability of univariate polynomials over continuous domains is first addressed in <ref> [AB83] </ref> and the problem of local stability on R is solved in [Gaj90]. See [For95] for a survey. These domains cannot be represented on a computer. Also, the above results are not always extendible in an obvious manner to discrete domains. <p> Strongly Approximate Case. One must be careful in defining polynomial h that is close to g. Attempts to define h based on the values of g at some d + 1 points do not seem to work. We proceed by modifying techniques in <ref> [AB83, Gaj90] </ref>, using the following fact: Fact 17 If f is a symmetric k-linear function, then r t 1 ;:::;t d f fl (x) = k!f (t 1 ; : : : ; t k ) if k = d and 0 if k &lt; d.
Reference: [ABC + 93] <author> S. Ar, M. Blum, B. Codenotti, and P. </author> <title> Gemmell. Checking approximate compu-tations over the reals. </title> <booktitle> Proc. 25th STOC, </booktitle> <pages> pp. 786-795, </pages> <year> 1993. </year>
Reference-contexts: The framework presented by <ref> [GLR + 91, ABC + 93] </ref> accommodates these inherently inevitable or acceptably small losses of information, by overlooking small precision errors while detecting actual "bugs", which manifest themselves with greater magnitude. <p> Previous Work. Previously, not many of the known checkers have been extended to the approximate case. The issue is first mentioned in [GLR + 91], where approximate checkers for mod, exponentiation, and logarithm are constructed. The domain is assumed to be closed in all of these results. In <ref> [ABC + 93] </ref> approximate checkers for sin, cos, matrix multiplication, 6 matrix inversion, linear system solving, and determinant are given. The domain is assumed to be closed in the results on sin and cos. In [BW94] an approximate checker for floating-point division is given. <p> The domain is assumed to be closed in the results on sin and cos. In [BW94] an approximate checker for floating-point division is given. In [Sud91], a clever technique using approximation theory is used to test univariate polynomials of degree 9. It is left open in <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> whether the properties used to test polynomial, hyperbolic, and other trigonometric functions are stable. <p> For those that can be extended, the error bounds obtained by naive extensions are not optimal. Our different approach allows us to operate on D n;s and obtain tight bounds. Results. In this paper, we answer the questions of <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> in the affirmative, by giving the first approximate versions of most of their testers. All of our results apply to non-closed discrete domains. We first present an approximate tester for linear and multilinear functions with tight bounds. <p> Hence, 00 = (L + U ) 4 + (L + U ) 2 : 5.4 Reductions Between Functional Equations This section explores the idea of using reductions among functions (as in <ref> [BK89, ABC + 93] </ref>) to obtain approximate self-testers for new functions. Consider any pair of functions f 1 ; f 2 that are interreducible via functional equations.
Reference: [ALM + 92] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> Proc. 33rd FOCS, </booktitle> <pages> pp. 14-23, </pages> <year> 1992. </year>
Reference-contexts: Related notions of self-testing and self-correcting were further explored in [BLR93, Lip91]. These notions have proved to be very powerful from a practical point of view (e.g., [BW94]) and from a theoretical angle (e.g., <ref> [AS92, ALM + 92] </ref>) as well. The techniques used usually consist of tests which compare the output of the program either to a predetermined value or to a function of outputs of the same program at different inputs. <p> When G is algebraic, they can be used to characterize families of functions that are rational functions of x, e cx , and doubly periodic functions (see Table 1 for examples). Polynomials of degree d can be characterized via several different robust functional equations (e.g., <ref> [BFL91, Lun91, ALM + 92, RS96] </ref>). Approximate Robustness and Stability. When the program works with finite precision, the properties upon which the testers are built will rarely be satisfied, even by a good program, since they involve equalities.
Reference: [AS92] <author> S. Arora and S. Safra. </author> <title> Probabilistic checking of proofs: A new characterization of NP. </title> <booktitle> Proc. 33rd FOCS, </booktitle> <pages> pp. 2-13, </pages> <year> 1992. </year>
Reference-contexts: Related notions of self-testing and self-correcting were further explored in [BLR93, Lip91]. These notions have proved to be very powerful from a practical point of view (e.g., [BW94]) and from a theoretical angle (e.g., <ref> [AS92, ALM + 92] </ref>) as well. The techniques used usually consist of tests which compare the output of the program either to a predetermined value or to a function of outputs of the same program at different inputs.
Reference: [BFL91] <author> L. Babai, L. Fortnow, and C. Lund. </author> <title> Non-deterministic exponential time has two-prover interactive protocols. </title> <booktitle> Computational Complexity, </booktitle> <pages> pp. 3-40, </pages> <year> 1991. </year>
Reference-contexts: When G is algebraic, they can be used to characterize families of functions that are rational functions of x, e cx , and doubly periodic functions (see Table 1 for examples). Polynomials of degree d can be characterized via several different robust functional equations (e.g., <ref> [BFL91, Lun91, ALM + 92, RS96] </ref>). Approximate Robustness and Stability. When the program works with finite precision, the properties upon which the testers are built will rarely be satisfied, even by a good program, since they involve equalities.
Reference: [BK89] <author> M. Blum and S. Kannan. </author> <title> Designing programs that check their work. </title> <booktitle> Proc. 21st STOC, </booktitle> <pages> pp. 86-97, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Program checking, which uses the program to verify its own correctness, was first formalized and developed in <ref> [BK89] </ref>. Related notions of self-testing and self-correcting were further explored in [BLR93, Lip91]. These notions have proved to be very powerful from a practical point of view (e.g., [BW94]) and from a theoretical angle (e.g., [AS92, ALM + 92]) as well. <p> Hence, 00 = (L + U ) 4 + (L + U ) 2 : 5.4 Reductions Between Functional Equations This section explores the idea of using reductions among functions (as in <ref> [BK89, ABC + 93] </ref>) to obtain approximate self-testers for new functions. Consider any pair of functions f 1 ; f 2 that are interreducible via functional equations.
Reference: [BLR93] <author> M. Blum, M. Luby, and R. Rubinfeld. </author> <title> Self-testing/correcting with applications to numerical problems. </title> <journal> J. Comp. Sys. Sci., </journal> <volume> 47(3) </volume> <pages> 549-595, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Program checking, which uses the program to verify its own correctness, was first formalized and developed in [BK89]. Related notions of self-testing and self-correcting were further explored in <ref> [BLR93, Lip91] </ref>. These notions have proved to be very powerful from a practical point of view (e.g., [BW94]) and from a theoretical angle (e.g., [AS92, ALM + 92]) as well. <p> If, by testing on random inputs, we conclude that the program P satisfies this property for most x; y, it can be shown that P agrees with a linear function g on most inputs <ref> [BLR93, Rub94] </ref>. We call linearity, and any property that exhibits such behavior, a robust property. We now describe more formally how to build a self-tester for a class F of functions. <p> All of our self-testers satisfy these requirements.) In the case of linearity, D = D n;s ; D 0 = D n=11;s , and the property is robust <ref> [BLR93, Rub94] </ref>. <p> In addition to new combinatorial arguments, we employ tools from approximation theory and stability theory. Our techniques appear to be more generally applicable and cleaner to work with than those previously used. Self-correctors are built by taking advantage of the random self-reducibility of polynomials and functional equations <ref> [BLR93, Lip91] </ref> in the exact case. We employ a similar idea for the approximate case by making several guesses at the answer and returning their median as the output. <p> To build an approximate checker for all of these functions, we combine the approximate self-tester and approximate self-corrector as in <ref> [BLR93] </ref>. 2 Definitions The following definitions from [GLR + 91] capture the idea of approximate checking, self-testing, and self-correcting in a formal manner. Let P denote a program for f , x an input to P , and fi the confidence parameter.
Reference: [BW94] <author> M. Blum and H. Wasserman. </author> <title> Program result-checking: A theory of testing meets a test of theory. </title> <booktitle> Proc. 35th FOCS, </booktitle> <pages> pp. 382-392, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Program checking, which uses the program to verify its own correctness, was first formalized and developed in [BK89]. Related notions of self-testing and self-correcting were further explored in [BLR93, Lip91]. These notions have proved to be very powerful from a practical point of view (e.g., <ref> [BW94] </ref>) and from a theoretical angle (e.g., [AS92, ALM + 92]) as well. The techniques used usually consist of tests which compare the output of the program either to a predetermined value or to a function of outputs of the same program at different inputs. <p> The domain is assumed to be closed in all of these results. In [ABC + 93] approximate checkers for sin, cos, matrix multiplication, 6 matrix inversion, linear system solving, and determinant are given. The domain is assumed to be closed in the results on sin and cos. In <ref> [BW94] </ref> an approximate checker for floating-point division is given. In [Sud91], a clever technique using approximation theory is used to test univariate polynomials of degree 9.
Reference: [BW94] <author> M. Blum and H. Wasserman. </author> <title> Reflections on the Pentium division bug. </title> <booktitle> Proc. 8th Intl. Software Quality Week, </booktitle> <year> 1994. </year>
Reference-contexts: 1 Introduction Program checking, which uses the program to verify its own correctness, was first formalized and developed in [BK89]. Related notions of self-testing and self-correcting were further explored in [BLR93, Lip91]. These notions have proved to be very powerful from a practical point of view (e.g., <ref> [BW94] </ref>) and from a theoretical angle (e.g., [AS92, ALM + 92]) as well. The techniques used usually consist of tests which compare the output of the program either to a predetermined value or to a function of outputs of the same program at different inputs. <p> The domain is assumed to be closed in all of these results. In [ABC + 93] approximate checkers for sin, cos, matrix multiplication, 6 matrix inversion, linear system solving, and determinant are given. The domain is assumed to be closed in the results on sin and cos. In <ref> [BW94] </ref> an approximate checker for floating-point division is given. In [Sud91], a clever technique using approximation theory is used to test univariate polynomials of degree 9.
Reference: [CR92] <author> E. </author> <title> Castillo and M.R. </title> <booktitle> Ruiz-Cobo. Functional Equations and Modeling in Science and Engineering. </booktitle> <publisher> Marcel Dekker Inc., </publisher> <year> 1992. </year>
Reference-contexts: An addition theorem is a mathematical identity of the form 8x; y; f (x + y) = G [f (x); f (y)]. Addition theorems characterize many useful and interesting mathematical functions <ref> [Acz66, CR92] </ref>. When G is algebraic, they can be used to characterize families of functions that are rational functions of x, e cx , and doubly periodic functions (see Table 1 for examples).
Reference: [Cho84] <author> P.W. Cholewa. </author> <title> The stability problem for a generalized Cauchy type functional equation. </title> <journal> Rev. Roumaine Math. Pures Appl., </journal> <volume> 29 </volume> <pages> 457-460, </pages> <year> 1984. </year>
Reference-contexts: There has been significant work on the stability of specific functional equations. The stability of linearity and other homomorphisms is addressed in <ref> [Hye41, For80, FS89, Cho84] </ref>.
Reference: [Cod91] <author> W.J. Cody. </author> <title> Performance evaluation of programs related to the real gamma function. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 17(1) </volume> <pages> 46-54, </pages> <year> 1991. </year>
Reference-contexts: Thus, we see that this method, when used naively, does not yield a self-tester that works according to our specifications. Nevertheless, this approach has been used as a good heuristic to check the correctness of programs <ref> [Cod91, CS91, Vai93] </ref>. As an example of a property that does yield a good tester, consider the linearity property f (x + y) = f (x) + f (y), satisfied in D n;s only by functions of the form f (x) = cx; c 2 D n;s .
Reference: [CS91] <author> W.J. Cody and I. Stoltz. </author> <title> The use of Taylor series to test accuracy of function programs. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 17(1) </volume> <pages> 55-63, </pages> <year> 1991. </year> <month> 35 </month>
Reference-contexts: Thus, we see that this method, when used naively, does not yield a self-tester that works according to our specifications. Nevertheless, this approach has been used as a good heuristic to check the correctness of programs <ref> [Cod91, CS91, Vai93] </ref>. As an example of a property that does yield a good tester, consider the linearity property f (x + y) = f (x) + f (y), satisfied in D n;s only by functions of the form f (x) = cx; c 2 D n;s .
Reference: [Dji69] <author> D.Z. Djokovic. </author> <title> A representation theorem for (X 1 1)(X 2 1) : : : (X n 1) and its applications. </title> <journal> Ann. Polonici Mathematici, </journal> <volume> 22:189 - 198, </volume> <year> 1969. </year>
Reference-contexts: Let x [k] denote k x; : : : ; x. For any k-ary symmetric f , let f fl (x) = f (x [k] ) denote its diagonal restriction. We use the following characterization of polynomials <ref> [MO34, Dji69] </ref>. <p> Now, e d = jg h d j = jg h d1 H fl d j = jg 0 h d1 j Unwinding the recurrence, the final error jg h d j = Q d Weakly Approximate Case. We need the following useful fact <ref> [Dji69] </ref> which helps us to go from equally spaced points to unequally spaced points: Fact 19 For any 1 ; : : : ; d 2 f0; 1g d , if t 0 1 ;:::; d = i=1 1 ;:::; d = i=1 i t i then r t 1 ;:::;t
Reference: [For80] <author> G.L. Forti. </author> <title> An existence and stability theorem for a class of functional equations. </title> <journal> Stochastica, </journal> <volume> 4 </volume> <pages> 23-30, </pages> <year> 1980. </year>
Reference-contexts: There has been significant work on the stability of specific functional equations. The stability of linearity and other homomorphisms is addressed in <ref> [Hye41, For80, FS89, Cho84] </ref>.
Reference: [For95] <author> G.L. Forti. </author> <title> Hyers-Ulam stability of functional equations in several variables. </title> <journal> Aeq. Mathematicae, </journal> <volume> 50 </volume> <pages> 143-190, </pages> <year> 1995. </year>
Reference-contexts: The problem of stability of univariate polynomials over continuous domains is first addressed in [AB83] and the problem of local stability on R is solved in [Gaj90]. See <ref> [For95] </ref> for a survey. These domains cannot be represented on a computer. Also, the above results are not always extendible in an obvious manner to discrete domains. For those that can be extended, the error bounds obtained by naive extensions are not optimal.
Reference: [FS89] <author> G.L. Forti and J. Schwaiger. </author> <title> Stability of homomorphisms and completeness. </title> <journal> C.R. Math. Rep. Acad. Sci. Canada, </journal> <volume> 11 </volume> <pages> 215-220, </pages> <year> 1989. </year>
Reference-contexts: There has been significant work on the stability of specific functional equations. The stability of linearity and other homomorphisms is addressed in <ref> [Hye41, For80, FS89, Cho84] </ref>.
Reference: [Gaj90] <author> Z. Gajda. </author> <title> Local stability of the functional equation characterizing polynomial functions. </title> <journal> Ann. Polonici Mathemtici, </journal> <volume> 52:119 - 137, </volume> <year> 1990. </year>
Reference-contexts: The problem of stability of univariate polynomials over continuous domains is first addressed in [AB83] and the problem of local stability on R is solved in <ref> [Gaj90] </ref>. See [For95] for a survey. These domains cannot be represented on a computer. Also, the above results are not always extendible in an obvious manner to discrete domains. For those that can be extended, the error bounds obtained by naive extensions are not optimal. <p> Proof. If construction in the proof of the theorem yields a symmetric h, then h 0 = h. Assume that it does not. Obtain a symmetric h 0 from h as in <ref> [Gaj90] </ref>. For a permutation of f1; 2; : : : ; kg, ~x = x 1 ; : : : ; x k , let (~x) denote x (1) ; : : : ; x (k) . Then, set h 0 (~x) = 1=k! h ((~x)). <p> Strongly Approximate Case. One must be careful in defining polynomial h that is close to g. Attempts to define h based on the values of g at some d + 1 points do not seem to work. We proceed by modifying techniques in <ref> [AB83, Gaj90] </ref>, using the following fact: Fact 17 If f is a symmetric k-linear function, then r t 1 ;:::;t d f fl (x) = k!f (t 1 ; : : : ; t k ) if k = d and 0 if k &lt; d.
Reference: [GLR + 91] <author> P. Gemmell, R. Lipton, R. Rubinfeld, M. Sudan, and A. Wigderson. </author> <title> Self-testing/correcting for polynomials and for approximate functions. </title> <booktitle> Proc. 23rd STOC, </booktitle> <pages> pp. 32-42, </pages> <year> 1991. </year>
Reference-contexts: The framework presented by <ref> [GLR + 91, ABC + 93] </ref> accommodates these inherently inevitable or acceptably small losses of information, by overlooking small precision errors while detecting actual "bugs", which manifest themselves with greater magnitude. <p> If furthermore we have a method of doing approximate equality testing, then we can construct an approximate self-tester. Previous Work. Previously, not many of the known checkers have been extended to the approximate case. The issue is first mentioned in <ref> [GLR + 91] </ref>, where approximate checkers for mod, exponentiation, and logarithm are constructed. The domain is assumed to be closed in all of these results. In [ABC + 93] approximate checkers for sin, cos, matrix multiplication, 6 matrix inversion, linear system solving, and determinant are given. <p> The domain is assumed to be closed in the results on sin and cos. In [BW94] an approximate checker for floating-point division is given. In [Sud91], a clever technique using approximation theory is used to test univariate polynomials of degree 9. It is left open in <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> whether the properties used to test polynomial, hyperbolic, and other trigonometric functions are stable. <p> For those that can be extended, the error bounds obtained by naive extensions are not optimal. Our different approach allows us to operate on D n;s and obtain tight bounds. Results. In this paper, we answer the questions of <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> in the affirmative, by giving the first approximate versions of most of their testers. All of our results apply to non-closed discrete domains. We first present an approximate tester for linear and multilinear functions with tight bounds. <p> To build an approximate checker for all of these functions, we combine the approximate self-tester and approximate self-corrector as in [BLR93]. 2 Definitions The following definitions from <ref> [GLR + 91] </ref> capture the idea of approximate checking, self-testing, and self-correcting in a formal manner. Let P denote a program for f , x an input to P , and fi the confidence parameter. <p> The results in this section, in addition to being interesting in themselves, are crucial to our results in Section 4. As in <ref> [GLR + 91] </ref>, approximate robustness is easy to show by appropriately modifying the proof of robustness [Rub94]. This involves replacing each exact equality by an approximate equality and keeping track of the error accrued at each step of the proof. <p> This is quite unattractive since the error bound depends on the domain size. Thus, the problem of obtaining a linear h whose discrepancy from g is independent of the size of the domain is non-trivial. In <ref> [GLR + 91] </ref>, a solution is given when the domain is a finite group. Their bootstrapping technique requires that the domain be closed under addition, and therefore does not work for D n;s . We give a brief overview of the scheme in [GLR + 91] and point out where it <p> In <ref> [GLR + 91] </ref>, a solution is given when the domain is a finite group. Their bootstrapping technique requires that the domain be closed under addition, and therefore does not work for D n;s . We give a brief overview of the scheme in [GLR + 91] and point out where it breaks down for non-closed domains. The existence of a linear h that is close to g is done in [GLR + 91] by "bootstrapping" if D is sufficiently large, then an error of at least at the maximum error point x fl would <p> We give a brief overview of the scheme in <ref> [GLR + 91] </ref> and point out where it breaks down for non-closed domains. The existence of a linear h that is close to g is done in [GLR + 91] by "bootstrapping" if D is sufficiently large, then an error of at least at the maximum error point x fl would imply an even bigger error at 2x fl , contradicting the maximality assumption about error at x fl . <p> Its left (resp. right) child (if exists) is x=2 (resp. (x + n s )=2). Thus, by Corollary 42, we have e ( x 2 ) + e (x)=2 2 (resp. e ( x+ n 2 ) + e (x)=2 2). 5.3 Approximate Robustness for Functional Equations As in <ref> [GLR + 91, RS92] </ref>, we test the program on the larger test domain D 2p;s and make conclusions about a smaller safe domain D n;s . The relationship between p and n will be determined later. The domain has to be such that G is analytic in it. <p> Thus, we have have an (2ffi 1 ; * 1 ; ffi 2 ; * 2 =2)- approximate self-tester for f 2 from a (ffi 1 ; * 1 ; ffi 2 ; * 2 )- approximate self-tester for f 1 , given by <ref> [GLR + 91] </ref>. 32 6 Constructions 6.1 Constructing Approximate Self-Correctors We illustrate how to build approximate self-correctors for functional equations. Suppose P (; *)-approximates f for * &lt; 1=8 and f (x + y) = G [f (x); f (y)].
Reference: [Hye41] <author> D.H. Hyers. </author> <title> On the stability of the linear functional equation. </title> <booktitle> Proc. </booktitle> <institution> Nat. Acad. Sci. U.S, </institution> <month> 27 </month> <pages> 222-224, </pages> <year> 1941. </year>
Reference-contexts: There has been significant work on the stability of specific functional equations. The stability of linearity and other homomorphisms is addressed in <ref> [Hye41, For80, FS89, Cho84] </ref>. <p> These results can be applied to give the first approximate self-testers for several functions over D n;s including multiplication, exponentiation, and logarithm (Section 3.2). 9 3.1 Approximate Linearity A function g is -approximately linear if 8x; y 2 D n;s ; g (x+y) g (x)+g (y). Hyers <ref> [Hye41] </ref> and Skof [Sko83] obtain a linear approximation to an approximately linear function when the domain is R. (See Appendix A for their approach). Their methods are not extendible to discrete domains. Suppose we define h ( 1 s ) = g ( 1 s ).
Reference: [KS95] <author> S.R. Kumar and D. </author> <title> Sivakumar. </title> <type> Manuscript. </type> <year> 1995. </year>
Reference-contexts: Hence, the total error is !(; 0) + !(0; ) = 2!(; 0) by Fact 27 and the equality holds with probability 1 12ffi 2fl. The following lemma is from <ref> [KS95] </ref>. Lemma 47 ([KS95]) If G = hV; Ei is a random graph with edges inserted with probability 1 ffi, then G 2 = hV; f (x; y) : 9z 2 V; (x; z) 2 E ^ (z; y) 2 Egi is a graph where the probability that a node is
Reference: [Lip91] <author> R. Lipton. </author> <title> New directions in testing. </title> <booktitle> Proc. DIMACS Workshop on Distr. Comp. and Cryptography, </booktitle> <pages> pp. 191-202, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Program checking, which uses the program to verify its own correctness, was first formalized and developed in [BK89]. Related notions of self-testing and self-correcting were further explored in <ref> [BLR93, Lip91] </ref>. These notions have proved to be very powerful from a practical point of view (e.g., [BW94]) and from a theoretical angle (e.g., [AS92, ALM + 92]) as well. <p> In addition to new combinatorial arguments, we employ tools from approximation theory and stability theory. Our techniques appear to be more generally applicable and cleaner to work with than those previously used. Self-correctors are built by taking advantage of the random self-reducibility of polynomials and functional equations <ref> [BLR93, Lip91] </ref> in the exact case. We employ a similar idea for the approximate case by making several guesses at the answer and returning their median as the output.
Reference: [Lor66] <author> G. G. Lorentz. </author> <title> Approximation of Functions. </title> <publisher> Holt, Rinehart and Winston, </publisher> <year> 1966. </year>
Reference-contexts: We need a notion of "smoothness" of G. The following notions are well-known in approximation theory <ref> [Lor66, Tim63] </ref>.
Reference: [Lun91] <author> C. Lund. </author> <title> The Power of Interaction. </title> <type> Ph.D. Thesis, </type> <institution> U. of Chicago, </institution> <year> 1991. </year>
Reference-contexts: When G is algebraic, they can be used to characterize families of functions that are rational functions of x, e cx , and doubly periodic functions (see Table 1 for examples). Polynomials of degree d can be characterized via several different robust functional equations (e.g., <ref> [BFL91, Lun91, ALM + 92, RS96] </ref>). Approximate Robustness and Stability. When the program works with finite precision, the properties upon which the testers are built will rarely be satisfied, even by a good program, since they involve equalities.
Reference: [MO34] <author> S. Mazur and W. </author> <title> Orlicz. </title> <journal> Grundlegende Eigenschaften der Polynomischen Opera-tionen. Erste Mitteilung, Studia Math., </journal> <volume> 5:50 - 68, </volume> <year> 1934. </year>
Reference-contexts: Let x [k] denote k x; : : : ; x. For any k-ary symmetric f , let f fl (x) = f (x [k] ) denote its diagonal restriction. We use the following characterization of polynomials <ref> [MO34, Dji69] </ref>.
Reference: [Rub94] <author> R. Rubinfeld. </author> <title> Robust functional equations with applications to self-testing/correcting. </title> <booktitle> Proc. 35th FOCS, </booktitle> <pages> pp. 288-299, </pages> <year> 1994. </year> <month> 36 </month>
Reference-contexts: If, by testing on random inputs, we conclude that the program P satisfies this property for most x; y, it can be shown that P agrees with a linear function g on most inputs <ref> [BLR93, Rub94] </ref>. We call linearity, and any property that exhibits such behavior, a robust property. We now describe more formally how to build a self-tester for a class F of functions. <p> All of our self-testers satisfy these requirements.) In the case of linearity, D = D n;s ; D 0 = D n=11;s , and the property is robust <ref> [BLR93, Rub94] </ref>. <p> Also, f (x) = x is the only function that satisfies the linearity property and the above equality property. This combined approach yields extremely efficient testers for programs computing homo-morphisms (e.g., multiplication of integers and matrices, exponentiation, logarithm). This idea is further generalized in <ref> [Rub94] </ref>, where the class of functional equations called addition theorems are shown to be useful for self-testing. An addition theorem is a mathematical identity of the form 8x; y; f (x + y) = G [f (x); f (y)]. Addition theorems characterize many useful and interesting mathematical functions [Acz66, CR92]. <p> When the program works with finite precision, the properties upon which the testers are built will rarely be satisfied, even by a good program, since they involve equalities. Thus, when testing, one might be willing to pass 1 This definition is a simplified form of that in <ref> [Rub94] </ref>. 4 G [f (x); f (y)] f (x) G [f (x); f (y)] f (x) q q f (x)+f (y) f (x)+f (y)2f (x)f (y) 1 f (x)f (y)1 f (x)+f (y)2f (x)f (y) cos a sin Ax f (x)+f (y)1 1 f (x)+f (y)2f (x)f (y) cosh a 1f <p> The domain is assumed to be closed in the results on sin and cos. In [BW94] an approximate checker for floating-point division is given. In [Sud91], a clever technique using approximation theory is used to test univariate polynomials of degree 9. It is left open in <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> whether the properties used to test polynomial, hyperbolic, and other trigonometric functions are stable. <p> For those that can be extended, the error bounds obtained by naive extensions are not optimal. Our different approach allows us to operate on D n;s and obtain tight bounds. Results. In this paper, we answer the questions of <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> in the affirmative, by giving the first approximate versions of most of their testers. All of our results apply to non-closed discrete domains. We first present an approximate tester for linear and multilinear functions with tight bounds. <p> The results in this section, in addition to being interesting in themselves, are crucial to our results in Section 4. As in [GLR + 91], approximate robustness is easy to show by appropriately modifying the proof of robustness <ref> [Rub94] </ref>. This involves replacing each exact equality by an approximate equality and keeping track of the error accrued at each step of the proof. <p> addition theorems; e.g., in the full version they are used to show that Jensen's equation is approximately robust and stable. (Section 5.2.4) 5.1 Preliminaries For addition theorems, we can assume that G is algebraic and a symmetric function (the latter is true in general under some technical assumptions as in <ref> [Rub94] </ref>). We need a notion of "smoothness" of G. The following notions are well-known in approximation theory [Lor66, Tim63]. <p> The solution to this functional equation is affine linearity i.e., f (x) = ax + b for some constants a; b. Jensen's equation can be proved approximately robust by modifying the proof of its robustness in <ref> [Rub94] </ref>. We will show a modified version of our technique for proving its stability. As before, we have 8x; y 2 D n;s ; g ( x+y 2 ) 2 . To prove the stability of this equation, we construct an affine linear h.
Reference: [RS92] <author> R. Rubinfeld and M. Sudan. </author> <title> Testing polynomial functions efficiently and over rational domains. </title> <booktitle> Proc. 3rd SODA, </booktitle> <pages> pp. 23-43, </pages> <year> 1992. </year>
Reference-contexts: Since a degree d k-variate polynomial can have (d + 1) k terms, this leads to exponential running times. Furthermore, it is not obvious how error bounds that are independent of the domain size can be obtained. Our test uses the same "evenly spaced" interpolation identity as that in <ref> [RS92] </ref>: for all x; t 2 D, i=0 i f (x + it) = 0: This identity is computed by the method of successive differences which never explicitly interpolates the polynomial computed by the program, thus giving a particularly simple and efficient (O (d 2 ) operations) test. <p> We can show that the interpolation identity is approximately robust by modifying the robustness theorem in <ref> [RS92] </ref>. (Section 4.3). Our proof of stability of the interpolation identity (Section 4.2), however, uses a characterization of polynomials in terms of multilinear functions that previously has not been applied to program checking. <p> Its left (resp. right) child (if exists) is x=2 (resp. (x + n s )=2). Thus, by Corollary 42, we have e ( x 2 ) + e (x)=2 2 (resp. e ( x+ n 2 ) + e (x)=2 2). 5.3 Approximate Robustness for Functional Equations As in <ref> [GLR + 91, RS92] </ref>, we test the program on the larger test domain D 2p;s and make conclusions about a smaller safe domain D n;s . The relationship between p and n will be determined later. The domain has to be such that G is analytic in it.
Reference: [RS96] <author> R. Rubinfeld and M. Sudan. </author> <title> Robust characterizations of polynomials and their applications to program testing. </title> <journal> SIAM J. of Computing, </journal> <volume> 25(2) </volume> <pages> 252-271, </pages> <year> 1996. </year>
Reference-contexts: When G is algebraic, they can be used to characterize families of functions that are rational functions of x, e cx , and doubly periodic functions (see Table 1 for examples). Polynomials of degree d can be characterized via several different robust functional equations (e.g., <ref> [BFL91, Lun91, ALM + 92, RS96] </ref>). Approximate Robustness and Stability. When the program works with finite precision, the properties upon which the testers are built will rarely be satisfied, even by a good program, since they involve equalities. <p> The domain is assumed to be closed in the results on sin and cos. In [BW94] an approximate checker for floating-point division is given. In [Sud91], a clever technique using approximation theory is used to test univariate polynomials of degree 9. It is left open in <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> whether the properties used to test polynomial, hyperbolic, and other trigonometric functions are stable. <p> For those that can be extended, the error bounds obtained by naive extensions are not optimal. Our different approach allows us to operate on D n;s and obtain tight bounds. Results. In this paper, we answer the questions of <ref> [GLR + 91, ABC + 93, RS96, Rub94] </ref> in the affirmative, by giving the first approximate versions of most of their testers. All of our results apply to non-closed discrete domains. We first present an approximate tester for linear and multilinear functions with tight bounds.
Reference: [Sko83] <author> F. </author> <month> Skof. </month> <institution> Sull'approssimazione delle applicazioni localmente ffi-additive. Atti della Accademia delle Scienze di Torino, </institution> <month> 117 </month> <pages> 377-389, </pages> <year> 1983. </year>
Reference-contexts: For instance, a finite precision rational domain is not closed under addition.) The stronger property of stability in a non-closed space, called local stability, is addressed by Skof <ref> [Sko83] </ref> who proves that Cauchy functional equations are locally stable on a finite interval in R. The problem of stability of univariate polynomials over continuous domains is first addressed in [AB83] and the problem of local stability on R is solved in [Gaj90]. See [For95] for a survey. <p> Hyers [Hye41] and Skof <ref> [Sko83] </ref> obtain a linear approximation to an approximately linear function when the domain is R. (See Appendix A for their approach). Their methods are not extendible to discrete domains. Suppose we define h ( 1 s ) = g ( 1 s ). <p> Instead, we employ a different constructive technique to obtain a linear h on D n;s given a -approximately linear g. Our technique yields a tight bound of 2 on the error e h g (instead of 4 in <ref> [Sko83] </ref>) and does not require that the domain be closed under addition. Recall that n s is the greatest positive element of the domain, and note that e is a -approximately linear function.
Reference: [Sud91] <author> M. </author> <title> Sudan. </title> <type> Personal Communication, </type> <year> 1991. </year>
Reference-contexts: In [ABC + 93] approximate checkers for sin, cos, matrix multiplication, 6 matrix inversion, linear system solving, and determinant are given. The domain is assumed to be closed in the results on sin and cos. In [BW94] an approximate checker for floating-point division is given. In <ref> [Sud91] </ref>, a clever technique using approximation theory is used to test univariate polynomials of degree 9. It is left open in [GLR + 91, ABC + 93, RS96, Rub94] whether the properties used to test polynomial, hyperbolic, and other trigonometric functions are stable.
Reference: [Tim63] <author> A.F. Timan. </author> <title> Theory of Approximation of Functions of a Real Variable. </title> <publisher> Pergamon Press, </publisher> <year> 1963. </year>
Reference-contexts: We need a notion of "smoothness" of G. The following notions are well-known in approximation theory <ref> [Lor66, Tim63] </ref>.
Reference: [Tit47] <author> E.C. Titchmarsh. </author> <title> The Theory of Functions. </title> <publisher> Oxford U. Press, </publisher> <year> 1947. </year>
Reference-contexts: An Example. Wherever necessary, we will illustrate our scheme using the following functional equation f (x + y) = f (x)f (y) , i.e., G [x; y] = xy=(x + y). The solution to this functional equation is f (x) = C=x for some constant C. The following fact <ref> [Tit47] </ref> is useful in locating the maxima of analytic functions. Fact 28 (Maximum Modulus Principle) If f is analytic in a compact region D, then f attains extremum only on the boundary of D.
Reference: [Vai93] <author> F. Vainstein. </author> <title> Algebraic Methods in Hardware/Software Testing. </title> <type> PhD thesis, </type> <institution> Boston University, </institution> <year> 1993. </year>
Reference-contexts: Thus, we see that this method, when used naively, does not yield a self-tester that works according to our specifications. Nevertheless, this approach has been used as a good heuristic to check the correctness of programs <ref> [Cod91, CS91, Vai93] </ref>. As an example of a property that does yield a good tester, consider the linearity property f (x + y) = f (x) + f (y), satisfied in D n;s only by functions of the form f (x) = cx; c 2 D n;s .
References-found: 34

