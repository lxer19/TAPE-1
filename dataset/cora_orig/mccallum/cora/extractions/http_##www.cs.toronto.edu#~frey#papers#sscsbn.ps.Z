URL: http://www.cs.toronto.edu/~frey/papers/sscsbn.ps.Z
Refering-URL: http://www.cs.toronto.edu/~frey/papers/sscsbn.abs.html
Root-URL: http://www.cs.toronto.edu
Title: Continuous sigmoidal belief networks trained using slice sampling  
Author: Brendan J. Frey In M. C. Mozer, M. I. Jordan and T. 
Note: Petsche (editors), Advances in Neural Infor mation Processing Systems 9, MIT Press,  
Address: 6 King's College Road, Toronto, Canada M5S 1A4  Cambridge MA, 1997.  
Affiliation: Department of Computer Science, University of Toronto  
Abstract: Real-valued random hidden variables can be useful for modelling latent structure that explains correlations among observed variables. I propose a simple unit that adds zero-mean Gaussian noise to its input before passing it through a sigmoidal squashing function. Such units can produce a variety of useful behaviors, ranging from deterministic to binary stochastic to continuous stochastic. I show how "slice sampling" can be used for inference and learning in top-down networks of these units and demonstrate learning on two simple problems. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bishop, C. M, Svensen, M., and Williams, C.K.I. </author> <year> 1996. </year> <title> EM optimization of latent-variable density models. </title> <editor> In D. Touretzky, M. Mozer, and M. Hasselmo (editors), </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Dayan, P., Hinton, G. E., Neal, R. M., and Zemel, R. S. </author> <year> 1995. </year> <title> The Helmholtz machine. </title> <booktitle> Neural Computation 7, </booktitle> <pages> 889-904. </pages>
Reference: <author> Heckerman, D., and Geiger, D. </author> <year> 1994. </year> <title> Learning Bayesian networks: a unification for discrete and Gaussian domains. </title> <editor> In P. Besnard and S. Hanks (editors), </editor> <booktitle> Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <pages> 274-284. </pages>
Reference: <author> Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. </author> <year> 1995. </year> <title> The wake-sleep algorithm for unsupervised neural networks. </title> <booktitle> Science 268, </booktitle> <pages> 1158-1161. </pages>
Reference-contexts: In particular, if two units have very highly correlated activities, the procedure of changing one activity at a time will converge extremely slowly. Also, the Markov chain method may be prohibitive for larger networks. One approach to avoiding these problems is to use the Helmholtz machine <ref> (Hinton et al. 1995) </ref> or mean field methods (Jaakkola et al. 1996). Other variations on the theme presented in this paper include the use of other types of distributions for the hidden units (e.g., Poisson variables may be more biologically plausible) and different ways of parameterizing the modes of behavior.
Reference: <author> Hinton, G. E., and Sejnowski, T. J. </author> <year> 1986. </year> <title> Learning and relearning in Boltzmann machines. </title> <editor> In D. E. Rumelhart and J. L. McClelland (editors), </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: 1 Introduction A variety of unsupervised connectionist models containing discrete-valued hidden units have been developed. These include Boltzmann machines <ref> (Hinton and Se-jnowski 1986) </ref>, binary sigmoidal belief networks (Neal 1992) and Helmholtz machines (Hinton et al. 1995; Dayan et al. 1995). However, some hidden variables, such as translation or scaling in images of shapes, are best represented using continuous values.
Reference: <author> Hofmann, R., and Tresp, V. </author> <year> 1996. </year> <title> Discovering structure in continuous variables using Bayesian networks. </title> <editor> In D. Touretzky, M. Mozer, and M. Hasselmo (editors), </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Jaakkola, T., Saul, L. K., and Jordan, M. I. </author> <year> 1996. </year> <title> Fast learning by bounding likelihoods in sigmoid type belief networks. </title> <editor> In D. Touretzky, M. Mozer and M. Hasselmo (editors), </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: &gt; 0:5 or, equivalently, x i &gt; 0): p (i onj i ; oe 2 Z 1 exp [(x i ) 2 =2oe 2 p i Z i exp [x 2 =2oe 2 p i i i j This sort of stochastic activation is found in binary sigmoidal belief networks <ref> (Jaakkola et al. 1996) </ref> and in the decision-making components of mixture of ex pert models and hierarchical mixture of expert models. 3 Continuous sigmoidal belief networks If the mean of each unit depends on the activities of other units and there are feedback connections, it is difficult to relate the density <p> Also, the Markov chain method may be prohibitive for larger networks. One approach to avoiding these problems is to use the Helmholtz machine (Hinton et al. 1995) or mean field methods <ref> (Jaakkola et al. 1996) </ref>. Other variations on the theme presented in this paper include the use of other types of distributions for the hidden units (e.g., Poisson variables may be more biologically plausible) and different ways of parameterizing the modes of behavior.
Reference: <author> Lauritzen, S. L., Dawid, A. P., Larsen, B. N., and Leimer, H. G. </author> <year> 1990. </year> <title> Independence properties of directed Markov Fields. </title> <booktitle> Networks 20, </booktitle> <pages> 491-505. </pages>
Reference: <author> MacKay, D. J. C. </author> <year> 1995. </year> <title> Bayesian neural networks and density networks. Nuclear Instruments and Methods in Physics Research, </title> <booktitle> A 354, </booktitle> <pages> 73-80. </pages>
Reference: <author> Movellan, J. R., and McClelland, J. L. </author> <year> 1992. </year> <title> Learning continuous probability distributions with symmetric diffusion networks. </title> <booktitle> Cognitive Science 17, </booktitle> <pages> 463-496. </pages>
Reference: <author> Neal, R. M. </author> <year> 1992. </year> <title> Connectionist learning of belief networks. </title> <booktitle> Artificial Intelligence 56, </booktitle> <pages> 71-113. </pages>
Reference-contexts: 1 Introduction A variety of unsupervised connectionist models containing discrete-valued hidden units have been developed. These include Boltzmann machines (Hinton and Se-jnowski 1986), binary sigmoidal belief networks <ref> (Neal 1992) </ref> and Helmholtz machines (Hinton et al. 1995; Dayan et al. 1995). However, some hidden variables, such as translation or scaling in images of shapes, are best represented using continuous values.
Reference: <author> Neal, R. M. </author> <year> 1997. </year> <title> Markov chain Monte Carlo methods based on "slicing" the density function. </title> <note> In preparation. </note>
Reference-contexts: However, it is difficult to sample from this distribution because it may have many peaks that range from broad to narrow. I use a new Markov chain Monte Carlo method called "slice sampling" <ref> (Neal 1997) </ref> to pick a new activity for each unit. Consider the problem of drawing a value y from a univariate distribution P (y) | in this application, P (y) is the conditional distri bution p (y i jfy j g j6=i ).
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The proposed top-down model can be viewed as a continuous-valued belief network, which can be simulated by performing a quick top-down pass <ref> (Pearl 1988) </ref>. Work done on continuous-valued belief networks has focussed mainly on Gaussian random variables that are linked linearly such that the joint distribution over all variables is also Gaussian (Pearl 1988; Heckerman and Geiger 1995). <p> These approaches infer the distribution over unobserved unit activities given observed ones by "probability propagation" <ref> (Pearl 1988) </ref>. However, this procedure is highly suboptimal for the richly connected networks that I am interested in. Also, these approaches tend to assume that all the conditional Gaussian distributions represented by the belief network can be easily derived using information elicited from experts. <p> This ordered arrangement is the foundation of belief networks <ref> (Pearl, 1988) </ref>. I let the mean of each unit be determined by a linear combination of the postsigmoid activities of preceding units: i = j&lt;i w ij y j ; (7) where y 0 j 1 is used to implement biases.
Reference: <author> Tibshirani, R. </author> <year> (1992). </year> <title> Principal curves revisited. </title> <journal> Statistics and Computing 2, </journal> <pages> 183-190. </pages>
References-found: 14

