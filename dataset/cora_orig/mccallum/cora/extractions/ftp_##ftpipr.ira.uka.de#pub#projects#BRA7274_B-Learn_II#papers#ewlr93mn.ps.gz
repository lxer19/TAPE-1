URL: ftp://ftpipr.ira.uka.de/pub/projects/BRA7274_B-Learn_II/papers/ewlr93mn.ps.gz
Refering-URL: http://wwwipr.ira.uka.de/projects/blearn/blearnpub.html
Root-URL: 
Email: e-mail nuttin@mech.kuleuven.ac.be e-mail attilio@di.unito.it  
Title: Fuzzy Controller Synthesis in Robotic Assembly: Procedure and Experiments  
Author: Marnix Nuttin Attilio Giordana 
Date: October 18, 1993  
Address: Celestijnenlaan 300B, B-3001 Heverlee, Belgium Corso Svizzera 185, 10149 Torino, Italy  
Affiliation: Katholieke Universiteit Leuven Universit a di Torino Dpt. of Mechanical Engineering, Division PMA Dipartimento di Informatica  
Abstract: In controller synthesis for basic robotic assembly tasks, the optimal performance is characterized by high level criteria. Performance of a peg-into-hole task is e.g. measured in insertion time and average/maximum force level. Moreover, the unknown optimal control of a peg-into-hole task was shown to be non-linear. Fuzzy rules are used in our approach to approximate this non-linear control. The fuzzy controller synthesis can be automated with the use of a machine learning tool SMART+ , provided that examples are available. Besides examples, SMART+ can also handle domain knowledge as input. Its output can also be a learning fuzzy controller, in order to achieve on-line performance improvement. The paper presents this approach and initial experiments. Keywords: machine learning, robotic assembly, fuzzy control, automated fuzzy controller synthesis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C.W. Anderson. </author> <title> Learning and Problem Solving with Multilayer Connectionist Systems. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <year> 1986. </year>
Reference-contexts: Basically GARIC, which is an evolution of Anderson's ARIC <ref> [1] </ref>, consists of two neural networks: the Action Selection Network (ASN) and the Action Evaluaton Network (AEN). The former one is basically a fuzzy controller which is used to predict the control signal and can be refined on-line by a kind of back-propagation.
Reference: [2] <author> H. Asada. </author> <title> Teaching and learning of compliance using neural nets: Representation and generation of nonlinear compliance. </title> <booktitle> In Proceedings of the 1990 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1237 - 1244, </pages> <year> 1990. </year>
Reference-contexts: A (better) force-velocity control relationship is envisioned. This basic operation can be part of a (sub)assembly sequence as illustrated in section 3.3. The intensely studied peg-in-hole task is selected for the experiments. The unknown optimal controller of a peg-into-hole task is necessarily non-linear <ref> [2] </ref>. Fuzzy rules create a non-linear control surface based upon domain knowledge. Linguistic variables make a closer link to higher level performance criteria via symbolic concepts. The symbolic level is also useful in monitoring and error recovery of the assembly process.
Reference: [3] <author> H.R. Berenji. </author> <title> Learning and tuning fuzzy controllers through reinforcements. </title> <journal> IEEE Transactions on neural networks, </journal> <volume> 3(5) </volume> <pages> 724-740, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The on-line approach aims at generating a high performance controller by refining an initial one manually generated or obtained from a general template. Examples of this approach are self-organizing controllers [13], the methods for on-line controller tuning [7], and reinforcement learning, as proposed by Berenji <ref> [3] </ref>. Examples of the off-line approach can be found in [4, 5] where tools are proposed for helping the generation of a controller from a pre-existing domain theory, and in [21] where an algorithm is proposed for inducing the controller knowledge base from a set of examples. <p> Finally we will discuss in section 5 how a fuzzy controller generated in this way can be easily refined on-line, using a reinforcement learning algorithm. To this aim we are currently investigating the GARIC architecture proposed by Berenji <ref> [3] </ref>. 4.1 Controller Synthesis from Examples In order to manually design a fuzzy controller a human expert is required who is able to supply the necessary background knowledge. However, this is still quite an expensive task requiring several months of work. <p> In particular, they share with neural networks many of the training algorithms based on gradient descent and weight adjustment such as the well known back propagation algorithm. For a survey see <ref> [3] </ref>. In order to apply error back propagation it is necessary, that the functions for combining evidences and the functions describing fuzzy sets are derivable. For this reason, triangular fuzzy sets can be replaced by a Gaussian or by a pair of sigmoid functions (see [12]). Alternatively, according to Berenji [3], <p> <ref> [3] </ref>. In order to apply error back propagation it is necessary, that the functions for combining evidences and the functions describing fuzzy sets are derivable. For this reason, triangular fuzzy sets can be replaced by a Gaussian or by a pair of sigmoid functions (see [12]). Alternatively, according to Berenji [3], an approximate derivative for triangular fuzzy sets can be found without the need of using other functions which are more costly to compute on-line. Therefore, by properly applying back propagation, it is possible to implement on-line refinement algorithms for fuzzy controllers based on reinforcement learning. <p> The fundamental algorithm is Q-learning developed by Watkins [22] and for which several improvements are now available. From the side of fuzzy set literature we can also find some examples of applying reinforcement techniques to fuzzy controllers, such as the system GARIC by Berenji <ref> [3] </ref>, which proved to be able to learn an effective control strategy for classical problems such as pole balancing. Basically GARIC, which is an evolution of Anderson's ARIC [1], consists of two neural networks: the Action Selection Network (ASN) and the Action Evaluaton Network (AEN).
Reference: [4] <author> Piero P. Bonissone. </author> <title> A compiler for fuzzy logic controllers. In Control Theory and Advanced Technology, </title> <journal> Special Issue on Expert Systems and Fuzzy Control. </journal> <month> Semptember </month> <year> 1986. </year>
Reference-contexts: Examples of this approach are self-organizing controllers [13], the methods for on-line controller tuning [7], and reinforcement learning, as proposed by Berenji [3]. Examples of the off-line approach can be found in <ref> [4, 5] </ref> where tools are proposed for helping the generation of a controller from a pre-existing domain theory, and in [21] where an algorithm is proposed for inducing the controller knowledge base from a set of examples. However, the two approaches should be seen as complementary ones.
Reference: [5] <author> Piero P. Bonissone and Kenneth H. Chiang. </author> <title> Fuzzy logic controllers: from development to deployment. </title> <booktitle> In IEEE International Conference on Neural Networks, volume II, </booktitle> <address> San Francisco, CA, </address> <year> 1993. </year>
Reference-contexts: Examples of this approach are self-organizing controllers [13], the methods for on-line controller tuning [7], and reinforcement learning, as proposed by Berenji [3]. Examples of the off-line approach can be found in <ref> [4, 5] </ref> where tools are proposed for helping the generation of a controller from a pre-existing domain theory, and in [21] where an algorithm is proposed for inducing the controller knowledge base from a set of examples. However, the two approaches should be seen as complementary ones.
Reference: [6] <author> M. Botta and A. Giordana. </author> <title> SMART+: a multi-strategy learning tool. </title> <booktitle> In Proc. of the International Joint Conference on Artificial Intelligence, IJCAI-93, </booktitle> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: Then, the problem of learning a continuous control function will be mapped to the problem of learning j H j classification theories: one for each of the linguistic variables H in output to the rule matcher. In the experiment, described here, the system SMART+ <ref> [6] </ref> has been used to accomplish the inductive task. In particular, SMART+ is an inductive system capable of inducing first order logic concept descriptions from examples; the propositional calculus is seen just as a particular case. <p> This feature is useful when the amount of learning events is not large enough to induce a reliable description, or, alternatively, when one wants to force solutions of a particular type. A detailed description of SMART+ can be found in <ref> [6] </ref>. A second feature of SMART+, which is very useful in the particular task we are facing, is the possibility of dealing with numerical constants by means of "parametric predicates". As an example, suppose F x is the force component along the x-axis, as described in Figure 10.
Reference: [7] <author> David G. Burkhardt and Piero P. Bonissone. </author> <title> Automated fuzzy knowledge base generation and tuning. </title> <booktitle> In IEEE International Conference on Fuzzy Systems, </booktitle> <pages> pages 179-188, </pages> <address> San Diego, CA, </address> <year> 1992. </year> <month> 9 </month>
Reference-contexts: The on-line approach aims at generating a high performance controller by refining an initial one manually generated or obtained from a general template. Examples of this approach are self-organizing controllers [13], the methods for on-line controller tuning <ref> [7] </ref>, and reinforcement learning, as proposed by Berenji [3].
Reference: [8] <author> J. De Schutter, S. Demey, H. Van Brussel, S. Dutr e, W. Persoons, W. Witvrouw, and P. Van De Poel. </author> <title> Model based and sensor based programming of compliant motion tasks. </title> <booktitle> In 24th International Symposium on Industrial Robots, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: In this case the fuzzy controller should be implemented as an ANN (section 5). 3.3 The fuzzy controller in an assembly sequence The fuzzy controller software was integrated into the COMRADE software developed at PMA <ref> [8] </ref>. The advantage of this integration is that the resulting software package allows the use of other command types, so that the best controller can be selected for each assembly phase.
Reference: [9] <author> J. De Schutter and H. Van Brussel. </author> <title> Compliant robot motion I, a formalism for specifying compliant motion tasks. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 7(4), </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: And it is in these algorithms that we want to integrate learning techniques. Two classes of active compliant techniques can be distinguished: fine-motion planning and reactive control. This paper follows the reactive control approach. More information on compliant motion and the peg-into-hole task can be found in <ref> [9, 11, 15, 16, 23] </ref>. 1 This section can be skipped by readers only interested in fuzzy controller synthesis. 2 3 A fuzzy controller for the peg-into-hole task 3.1 The fuzzy controller The strength of a fuzzy controller is its capability to handle both linguistic knowledge and numerical sensor data.
Reference: [10] <author> J. De Schutter and H. Van Brussel. </author> <title> Compliant robot motion II, a control approach based on external control loops. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 7(4), </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: To achieve this frequency the rules and fuzzification and defuzzification procedure were implemented as macros. This avoids the time waste of parameter passing and stack operations due to function calls. 3.2.2 Sensor traces Several insertions were performed to compare the fuzzy controller with the task frame controller described in <ref> [10] </ref>. Sensor traces of two insertions with each controller are shown in figures 4,5,6 and 7. As mentioned above, it is in the nature of the task that short jamming periods occur frequently. This makes the controller's performance highly variable. The performance is measured by insertion time and force level.
Reference: [11] <author> V. Gullapalli, R.A. Grupen, and A.G. Barto. </author> <title> Learning reactive admittance control. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: And it is in these algorithms that we want to integrate learning techniques. Two classes of active compliant techniques can be distinguished: fine-motion planning and reactive control. This paper follows the reactive control approach. More information on compliant motion and the peg-into-hole task can be found in <ref> [9, 11, 15, 16, 23] </ref>. 1 This section can be skipped by readers only interested in fuzzy controller synthesis. 2 3 A fuzzy controller for the peg-into-hole task 3.1 The fuzzy controller The strength of a fuzzy controller is its capability to handle both linguistic knowledge and numerical sensor data.
Reference: [12] <author> Jyh-Shing Roger Jang. ANFIS: </author> <title> Adaptive-Network-Based Fuzzy Inference System. </title> <journal> IEEE Transactions SMC, </journal> <note> 1993. to appear. </note>
Reference-contexts: For a survey see [3]. In order to apply error back propagation it is necessary, that the functions for combining evidences and the functions describing fuzzy sets are derivable. For this reason, triangular fuzzy sets can be replaced by a Gaussian or by a pair of sigmoid functions (see <ref> [12] </ref>). Alternatively, according to Berenji [3], an approximate derivative for triangular fuzzy sets can be found without the need of using other functions which are more costly to compute on-line.
Reference: [13] <author> G. Langari and M. Tomizuka. </author> <title> Self organizing fuzzy linguistic control with application to arc welding. </title> <booktitle> In IEEE International Workshop on Intelligent Robots and Systems, IROS 90, </booktitle> <pages> pages 1007-1014, </pages> <year> 1990. </year>
Reference-contexts: In particular, two basic approaches have been followed: an on-line approach, and an off-line approach. The on-line approach aims at generating a high performance controller by refining an initial one manually generated or obtained from a general template. Examples of this approach are self-organizing controllers <ref> [13] </ref>, the methods for on-line controller tuning [7], and reinforcement learning, as proposed by Berenji [3].
Reference: [14] <author> Lin L.J. </author> <title> Programming robots using reinforcement learning and teaching. </title> <booktitle> In 9th International Conference on Artificial Intelligence, </booktitle> <address> AAA-91, </address> <year> 1991. </year>
Reference-contexts: The output of the AEN is used to estimate the error signal necessary to train the ASN. Similar approaches can be 8 found in the RL literature for learning Q-functions in continuous state spaces <ref> [14] </ref>.
Reference: [15] <author> B. J. McCarragher and H. Asada. </author> <title> Qualitative template matching using dynamic process models for state transition recognition of robotic assembly. Journal of Dynamic Systems, </title> <booktitle> Measurement, and Control, </booktitle> <pages> pages 261-269, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: And it is in these algorithms that we want to integrate learning techniques. Two classes of active compliant techniques can be distinguished: fine-motion planning and reactive control. This paper follows the reactive control approach. More information on compliant motion and the peg-into-hole task can be found in <ref> [9, 11, 15, 16, 23] </ref>. 1 This section can be skipped by readers only interested in fuzzy controller synthesis. 2 3 A fuzzy controller for the peg-into-hole task 3.1 The fuzzy controller The strength of a fuzzy controller is its capability to handle both linguistic knowledge and numerical sensor data.
Reference: [16] <author> Brenan J. McCarragher and Haruhiko Asada. </author> <title> A discrete event approach to the control of robotic assembly tasks. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 331-336, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: And it is in these algorithms that we want to integrate learning techniques. Two classes of active compliant techniques can be distinguished: fine-motion planning and reactive control. This paper follows the reactive control approach. More information on compliant motion and the peg-into-hole task can be found in <ref> [9, 11, 15, 16, 23] </ref>. 1 This section can be skipped by readers only interested in fuzzy controller synthesis. 2 3 A fuzzy controller for the peg-into-hole task 3.1 The fuzzy controller The strength of a fuzzy controller is its capability to handle both linguistic knowledge and numerical sensor data.
Reference: [17] <author> M. Pazzani and D. Kibler. </author> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> (9):57-94, 1992. 
Reference-contexts: The inductive process follows a general to specific strategy similar to the one used by other system such as FOIL [18] and FOCL <ref> [17] </ref>. The inductive search can be biased using a domain theory in order to guide the discovery of descriptions in agreement with existing background knowledge. As a particular case, a partial concept description can be suggested by an expert and then refined automatically by the system.
Reference: [18] <author> R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> (5):239-266, 1990. 
Reference-contexts: In particular, SMART+ is an inductive system capable of inducing first order logic concept descriptions from examples; the propositional calculus is seen just as a particular case. The inductive process follows a general to specific strategy similar to the one used by other system such as FOIL <ref> [18] </ref> and FOCL [17]. The inductive search can be biased using a domain theory in order to guide the discovery of descriptions in agreement with existing background knowledge. As a particular case, a partial concept description can be suggested by an expert and then refined automatically by the system.
Reference: [19] <author> H. Van Brussel and J. Simons. </author> <title> The adaptable compliance concept and its use for automatic assembly by active force feedback accommodations. </title> <booktitle> In Proceedings of the 9th International Symposium on Industrial Robots, </booktitle> <month> March </month> <year> 1979. </year>
Reference-contexts: In these kinds of techniques, the programmed path of the end-effector is not modified by the contact forces. The path of the manipulated object is modified by the deflections of a flexible structure between the manipulated object and the end-effector: the compliance. Programmable compliances have been developed <ref> [19, 20] </ref>. A fourth approach is to introduce sensors and techniques of active compliance. Here the programmed path is modified by an algorithm that uses the sensed contact forces as input. And it is in these algorithms that we want to integrate learning techniques.
Reference: [20] <author> H. Van Brussel, H. Thielemans, and J. Simons. </author> <title> Further developments of the active adaptive compliant wrist (aacw) for robot assembly. </title> <booktitle> In Proceedings of the 11th International Symposium on Industrial Robots, </booktitle> <month> October </month> <year> 1981. </year>
Reference-contexts: In these kinds of techniques, the programmed path of the end-effector is not modified by the contact forces. The path of the manipulated object is modified by the deflections of a flexible structure between the manipulated object and the end-effector: the compliance. Programmable compliances have been developed <ref> [19, 20] </ref>. A fourth approach is to introduce sensors and techniques of active compliance. Here the programmed path is modified by an algorithm that uses the sensed contact forces as input. And it is in these algorithms that we want to integrate learning techniques.
Reference: [21] <author> Li-Xing Wang and Jerry M. Mendel. </author> <title> Generating fuzzy rules by learning from examples. </title> <journal> IEEE Transactions on systems, man, and cybernetics, </journal> <volume> 22(6) </volume> <pages> 1414-1427, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Examples of the off-line approach can be found in [4, 5] where tools are proposed for helping the generation of a controller from a pre-existing domain theory, and in <ref> [21] </ref> where an algorithm is proposed for inducing the controller knowledge base from a set of examples. However, the two approaches should be seen as complementary ones.
Reference: [22] <author> C.J.C.H. Watkins. </author> <title> Learning from delayed rewards. </title> <type> PhD thesis, </type> <institution> University of Cambridge, U.K., </institution> <year> 1989. </year>
Reference-contexts: Criteria for assigning the performance evaluation can be the time necessary for the goal achievement, the power dissipated during the operation and so on. Several techniques have been developed in reinforcement learning literature which can be experimented in our framework. The fundamental algorithm is Q-learning developed by Watkins <ref> [22] </ref> and for which several improvements are now available.
Reference: [23] <author> D. E. Whitney. </author> <title> Quasi-static assembly of compliantly supported rigid parts. </title> <booktitle> 104 </booktitle> <pages> 65-77, </pages> <month> March </month> <year> 1982. </year> <note> 10 11 step on the figure corresponds to 1/30 second. 12 step on the figure corresponds to 1/30 second. on the figure corresponds to 1/30 second. 13 on the figure corresponds to 1/30 second. 14 15 16 17 18 the synthesised controller. 19 </note>
Reference-contexts: And it is in these algorithms that we want to integrate learning techniques. Two classes of active compliant techniques can be distinguished: fine-motion planning and reactive control. This paper follows the reactive control approach. More information on compliant motion and the peg-into-hole task can be found in <ref> [9, 11, 15, 16, 23] </ref>. 1 This section can be skipped by readers only interested in fuzzy controller synthesis. 2 3 A fuzzy controller for the peg-into-hole task 3.1 The fuzzy controller The strength of a fuzzy controller is its capability to handle both linguistic knowledge and numerical sensor data.
References-found: 23

