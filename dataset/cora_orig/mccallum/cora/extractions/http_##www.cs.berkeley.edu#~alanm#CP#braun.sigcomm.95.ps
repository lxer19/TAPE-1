URL: http://www.cs.berkeley.edu/~alanm/CP/braun.sigcomm.95.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Title: Protocol Implementation Using Integrated Layer Processing  Human Capital and Mobility Programme  
Author: Torsten Braun and Christophe Diot 
Note: 1 on leave from the University of Karlsruhe, sponsored as a research fellow by the Commission of the European Communities under the  
Address: Lucioles, F-06902 Sophia-Antipolis Cedex, France  
Affiliation: rte des  
Pubnum: HCM (no. ERBCHBGCT930254)  
Email: e-mail: [Torsten.Braun|Christophe.Diot]@sophia.inria.fr  
Date: 2004  Abstract  
Abstract: Integrated Layer Processing (ILP) is an implementation concept which "permit[s] the implementor the option of performing all the [data] manipulation steps in one or two integrated processing loops" [1]. To estimate the achievable benefits of ILP, a file transfer application with an encryption function on top of a user-level TCP has been implemented and the performance of the application in terms of throughput and packet processing times has been measured. The results show that it is possible to obtain performance benefits by integrating marshalling, encryption and TCP checksum calculation. They also show that the benefits are smaller than in simple experiments, where ILP effects have not been evaluated in a complete protocol environment. Simulations of memory access and cache hit rate show that the main benefit of ILP is reduced memory accesses rather than an improved cache hit rate. The results further show that data manipulation characteristics may significantly inuence the cache behavior and the achievable performance gain of ILP. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Clark, </author> <title> D.D.; Tennenhouse, D.L.: Architectural Considerations for a New Generation of Protocols, </title> <booktitle> ACM SIGCOMM 1990, </booktitle> <pages> pp. 200-208 </pages>
Reference-contexts: The concept of Integrated Layer Processing (ILP) tries to gain from both sides, namely avoiding memory access and using cache memories. ILP allows the implementor to perform all manipulation steps in one or two integrated processing loops <ref> [1] </ref>. This integrated processing of data is commonly called "ILP loop". Theoretically, an ILP protocol stack implementation reads once from main memory, keeps the read data within registers or cache memory, and performs all the data manipulations for several protocol layers within the ILP loop (Figure 1). <p> By applying ILP to simple data manipulations like data copying and TCP checksum calculations, Clark and Tennenhouse achieved performance gains of up to 50% <ref> [1] </ref>. We carried out a similar experiment which yields nearly the same results. The XDR marshalling routine obtained from a stub compiler for an array of 20 integer values has been combined with the TCP checksum routine. <p> concatenation, and segmentation that should be avoided in general according to [5] and [6] have also to be avoided within the ILP loop to ensure that single data units do not interfere with other data units and to preserve their frame boundaries according to the ALF (Application Level Framing) concept <ref> [1] </ref>. Further problems with ILP are identified by Clark and Tennenhouse [1] as well as by Abbott and Peterson [2]: Ordering constraints between different protocol functions occur because protocol processing consists of interactions between control functions (such as header and connection processing) and data manipulation functions [1]. <p> [5] and [6] have also to be avoided within the ILP loop to ensure that single data units do not interfere with other data units and to preserve their frame boundaries according to the ALF (Application Level Framing) concept <ref> [1] </ref>. Further problems with ILP are identified by Clark and Tennenhouse [1] as well as by Abbott and Peterson [2]: Ordering constraints between different protocol functions occur because protocol processing consists of interactions between control functions (such as header and connection processing) and data manipulation functions [1]. Control functions often depend on the result of data manipulations. <p> (Application Level Framing) concept <ref> [1] </ref>. Further problems with ILP are identified by Clark and Tennenhouse [1] as well as by Abbott and Peterson [2]: Ordering constraints between different protocol functions occur because protocol processing consists of interactions between control functions (such as header and connection processing) and data manipulation functions [1]. Control functions often depend on the result of data manipulations. For example, a TCP header can only be completed after calculating the checksum over the TCP data. On the receiving side, data can be passed to higher functions only after a successful checksum evaluation. <p> Header and data dependencies The solution proposed in <ref> [1] </ref> for the problem of header and data dependencies is to use segregated messages. This concept cannot be used in many situations, e.g. for encryption if a higher layer protocol header to encrypt is not aligned to the processing unit size of the encryption function. <p> ILP throughput improvements are limited and depend heavily on several issues such as the complexity of data manipulations, the communication subsystem architecture, and the host environment characteristics. In our experiments, these issues decrease the throughput gain to 10-20% in contrast to the 50% gain achieved for simple loop experiments <ref> [1] </ref>. ILP is very sensitive to various issues, which makes its use debatable in existing communication systems and workstations.
Reference: [2] <author> Abbott, M. B.; Peterson, </author> <title> L.L: Increasing Network Throughput by Integrating Protocol Layers, </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> Vol. 1, No. 5, </volume> <month> October </month> <year> 1993, </year> <pages> pp. 600-610 </pages>
Reference-contexts: The performance comparison shows over 40% gain in favor of the ILP implementation. The achievable performance improvements gained by ILP depend on various parameters. The ILP benefits may increase with the number of integrated data manipulations as shown by Abbott and Peterson <ref> [2] </ref>. Partridge and Pink showed that performance gains by combining checksum calculation and copy operations may differ on different machines [3]. Experiments by Gunningberg, Partridge, and others proved that ILP is also sensitive to the complexity of data manipulation functions. <p> Further problems with ILP are identified by Clark and Tennenhouse [1] as well as by Abbott and Peterson <ref> [2] </ref>: Ordering constraints between different protocol functions occur because protocol processing consists of interactions between control functions (such as header and connection processing) and data manipulation functions [1]. Control functions often depend on the result of data manipulations. <p> A so-called three stage approach is proposed in <ref> [2] </ref> to manage ordering constraints dividing protocol processing into initial control operations, integrated data manipulations (or ILP loop), and a final protocol stage. The initial operations can usually be very small, and possibly reduced to demultiplexing and packet parsing operations. Messages are accepted or rejected in the final stage. <p> Messages are accepted or rejected in the final stage. Integrating code from different protocol layers may violate the modularity of the implementation. Preserving modularity in ILP implementations may be achieved by an automatic synthesis tool, e.g., based on a macro pre-processor <ref> [2] </ref>, to generate the ILP protocol code. Another approach studied by us is the ILP extension of a stub compiler. <p> The size of the processing unit to be manipulated may differ in various layers; e.g. an XDR marshalling procedure usually operates in 4-byte units, while encryption functions often manipulate the data in 8-byte units. Word filters are used in <ref> [2] </ref> to solve the mismatch which occurs when data passes from one data manipulation function to another one. A word filter operates on words (commonly 4 bytes). <p> The dependencies of data and headers make it impossible to process first the header part of layer N by a layer N-1 data manipulation function, and then the data part of layer N by the N data manipulation function. The solution proposed in <ref> [2] </ref> to avoid this problem are so-called segregated messages, which create a clear separation between protocol headers and application data. ILP is only applied to user data. <p> ILP is only applied to user data. Headers added at various layers in the protocol stack, which themselves become data, are processed separately, in a non ILP way. 2.2 Remaining Problems and Solutions The solutions proposed in <ref> [2] </ref> to overcome ordering constraints and to preserve modularity are very general solutions, and we are using similar approaches in our ILP implementation. <p> Another issue which has significant impact on the total throughput is the complexity of the data manipulations. Replacing the encryption/decryption algorithm by a very simple algorithm similar to the one used in <ref> [2] </ref> yields similar total improvements in packet processing times (70 ms less for sending a 1kbyte packet and 64 ms less for receiving a packet on a SPARCstation 10-30) compared with the simplified SAFERK64 algorithm (Figure 11). The relative improvements (32 and 40%) are significantly higher.
Reference: [3] <author> Partridge, C.; Pink, S.: </author> <title> A Faster UDP, </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> Vol. 1, No. 4, </volume> <month> August </month> <year> 1993, </year> <pages> pp. 429-440 </pages>
Reference-contexts: The achievable performance improvements gained by ILP depend on various parameters. The ILP benefits may increase with the number of integrated data manipulations as shown by Abbott and Peterson [2]. Partridge and Pink showed that performance gains by combining checksum calculation and copy operations may differ on different machines <ref> [3] </ref>. Experiments by Gunningberg, Partridge, and others proved that ILP is also sensitive to the complexity of data manipulation functions. They show that the integration of the processing unit . . .
Reference: [4] <author> Gunningberg, P.; Partridge, C.; Sirotkin, T.; Victor, B.: </author> <title> Delayed Evaluation of Gigabit Protocols, </title> <booktitle> Proceedings of the 2nd MultiG Workshop, </booktitle> <month> June </month> <year> 1991 </year>
Reference-contexts: They show that the integration of the processing unit . . . ILP loop function 1 ILP packet function N packet packet packet DES (data encryption standard) algorithm into the ILP loop can reduce the performance gains significantly <ref> [4] </ref>. In this paper we demonstrate that benefits obtained from ILP not only depend on the data manipulation function complexity, but also on other characteristics of these functions such as the number and the size of required memory tables, and the necessary interaction between data manipulations and control functions. <p> A fast encryption algorithm based on the SAFERK64 algorithm [9] has been chosen because the processing time spent in the more complex DES encryption algorithm can hide totally the ILP performance gain <ref> [4] </ref>. Even a high-speed implementation achieves only a 1 Mbps throughput on a SPARCs-tation [10].
Reference: [5] <author> Feldmeier, </author> <title> D.C.: Multiplexing Issues in Communication System Design, </title> <booktitle> ACM SIGCOMM 1990, </booktitle> <pages> pp. 209-219 </pages>
Reference-contexts: Section 3 presents the architecture for non-ILP an for ILP implementations. Section 4 shows performance results and comparisons with conventional implementations. 2 Limitations of ILP and Possible Solutions 2.1 Related work Operations such as multiplexing, concatenation, and segmentation that should be avoided in general according to <ref> [5] </ref> and [6] have also to be avoided within the ILP loop to ensure that single data units do not interfere with other data units and to preserve their frame boundaries according to the ALF (Application Level Framing) concept [1].
Reference: [6] <author> Tennenhouse, </author> <title> D.L.: Layered Multiplexing Considered Harmful, Protocols for High-Speed Networks I, 1989, </title> <publisher> North-Holland, </publisher> <pages> pp. 143-148 </pages>
Reference-contexts: Section 3 presents the architecture for non-ILP an for ILP implementations. Section 4 shows performance results and comparisons with conventional implementations. 2 Limitations of ILP and Possible Solutions 2.1 Related work Operations such as multiplexing, concatenation, and segmentation that should be avoided in general according to [5] and <ref> [6] </ref> have also to be avoided within the ILP loop to ensure that single data units do not interfere with other data units and to preserve their frame boundaries according to the ALF (Application Level Framing) concept [1].
Reference: [7] <author> Feldmeier, </author> <title> D.C.; McAuley, A.J.: Reducing Protocol Ordering Constraints to Improve Performance, Protocols for High-Speed Networks III, 1992, </title> <publisher> North-Holland, </publisher> <pages> pp. 3-18 </pages>
Reference-contexts: An ordering constrained function requires that data are processed in a serial order to ensure a correct result <ref> [7] </ref>. Examples of ordering constrained functions are the cyclic redundancy code (CRC) calculation for error detection and stream cipher encryption algorithms. The TCP checksum and block cipher encryption algorithms are examples of non-ordering constrained functions.
Reference: [8] <author> Huitema, C.: MAVROS: </author> <title> Highlights on an ASN.1 compiler, </title> <type> INRIA technical report </type>
Reference-contexts: The request and reply message formats have been described using ASN.1. For sending a request or a reply message, the application has to invoke the appropriate marshalling routine, which has been generated using the MAVROS ASN.1 stub compiler <ref> [8] </ref>. The marshalling routine generates the RPC header and the XDR format of the message. The encryption function encrypts the output of the marshalling routine.
Reference: [9] <author> Massey, J.: SAFER K-64: </author> <title> A Byte-Oriented Block-Ciphering Algorithm, </title> <booktitle> Lecture Notes in Computer Science 809, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993, </year> <pages> pp. 1-17 </pages>
Reference-contexts: The length of the message before encryption is written into a length field, which builds the encryption header. A fast encryption algorithm based on the SAFERK64 algorithm <ref> [9] </ref> has been chosen because the processing time spent in the more complex DES encryption algorithm can hide totally the ILP performance gain [4]. Even a high-speed implementation achieves only a 1 Mbps throughput on a SPARCs-tation [10].
Reference: [10] <author> Feldmeier, </author> <title> D.C; Karn, P.R.: UNIX Password Security - Ten Years Later, </title> <booktitle> in: Advances in Cryptology - CRYPTO '89, Lecture Notes in Computer Science 435, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990, </year> <month> pp.44-53 </month>
Reference-contexts: A fast encryption algorithm based on the SAFERK64 algorithm [9] has been chosen because the processing time spent in the more complex DES encryption algorithm can hide totally the ILP performance gain [4]. Even a high-speed implementation achieves only a 1 Mbps throughput on a SPARCs-tation <ref> [10] </ref>. SAFERK64 that is extremely fast compared to other standard algorithms such as DES (25 Mbps for SAFERK64 with 1 round compared to 0.5 Mbps for the system implementation of DES on a SPARCstation 10 with a 30 MHz clock) is still too time consuming for the ILP experiment.
Reference: [11] <author> Hoglander, A.: </author> <title> Experimental Evaluation of TCP in User Space, </title> <type> INRIA technical report, </type> <month> September </month> <year> 1994 </year>
Reference-contexts: The add/xor operations require reading the key, while the logarithm/exponential operations access tables of pre-calculated values to avoid too costly run time calculations. The encrypted message is delivered to TCP, which calculates the checksum over the pseudo header and the data. The user-level TCP implementation <ref> [11] </ref> is divided into two parts: a kernel part and a library to be linked to an application running in user space. The kernel part provides a datagram oriented socket interface and is activated for all connections, while there exists a separate user-level part for each application.
Reference: [12] <author> Druschel, P.; Peterson, L.L.: Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1993, </year> <pages> pp. 189-202 </pages>
Reference: [13] <author> Metzler, B.; Miloucheva, I.: </author> <title> Design and Implementation of a Flexible User Protocol Interface, </title> <booktitle> Proceedings of the 1st International Workshop on High Performance Protocol Architectures, </booktitle> <month> December 15-16, </month> <year> 1994, </year> <institution> Sophia-Antipolis, France </institution>
Reference: [14] <author> Ahlgren, B., Gunningberg, P.: </author> <title> A minimal copy network interface architecture supporting ILP and ALF, </title> <booktitle> Proceedings of the 1st International Workshop on High Performance Protocol Architectures, </booktitle> <month> December 15-16, </month> <year> 1994, </year> <institution> Sophia-Antipo-lis, France </institution>
Reference: [15] <author> Sterbenz, J.P.G, Parulkar, G.M.: Axon: </author> <title> A High-Speed Communication Architecture for Distributed Applications, </title> <booktitle> IEEE Infocom 90 </booktitle>
Reference: [16] <author> Diot, C.; Huitema, C; Turletti, T.: </author> <title> Multimedia Applications should be adaptive. </title> <booktitle> Submitted to the 3rd IEEE Workshop on the Architecture and Implementation of High Performance Communication Subsystems, </booktitle> <month> August 23-25, </month> <year> 1995, </year> <note> Mystic, Connecticut </note>
Reference: [17] <author> Oechslin, P.; Leue, S.: </author> <title> Enhancing Integrated Layer Processing Using Common Case Anticipation and Data Dependence Analysis, </title> <booktitle> Proceedings of the 1st International Workshop on High Performance Protocol Architectures, </booktitle> <month> December 15-16, </month> <year> 1994, </year> <institution> Sophia-Antipolis, France </institution>
Reference-contexts: For example, the retransmission buffer may contain many unacknowledged data such that a packet of maximum size (= MTU size) cannot be stored. Data manipulations can be performed as early as possible to minimize delays <ref> [17] </ref>. Data above the TCP level is manipulated in advance; the checksum calculation and the copy to the TCP buffer are done when there is enough buffer space available again.
Reference: [18] <author> Sun Microsystems Inc.: </author> <title> Introduction to Shade, </title> <month> April </month> <year> 1993 </year>
Reference-contexts: These simulations have been performed using a cache simulator called "cachesim", which is part of the shade analyzing tools from SUN Microsystems <ref> [18] </ref>. The tool calculates the number of memory accesses and the number of cache misses. The "atom" tool [19] has been used here to investigate the memory behavior on DEC AXP workstations.
Reference: [19] <institution> Digital Equipment Corporation: </institution> <note> ATOM Reference Manual, </note> <month> December </month> <year> 1993. </year>
Reference-contexts: These simulations have been performed using a cache simulator called "cachesim", which is part of the shade analyzing tools from SUN Microsystems [18]. The tool calculates the number of memory accesses and the number of cache misses. The "atom" tool <ref> [19] </ref> has been used here to investigate the memory behavior on DEC AXP workstations. It simulates the memory system of AXP 3000/500 (150 MHz) models with 8 KB on-chip (first-level) data (write-through), 8 KB instruction cache and 512 KB external (second-level) cache.
Reference: [20] <author> Jain, P.G.; Hutchinson, </author> <title> N.C.; Chanson, S.T.: A Framework for the Non-Monolithic Implementation of Protocols in the x-Kernel, </title> <booktitle> Usenix, </booktitle> <month> August </month> <year> 1994, </year> <booktitle> High-Speed Networking Symposium, </booktitle> <pages> pp. 13-30 </pages>
Reference: [21] <author> Thekkath, C.A.; Nguyen, T.D.; Moy, E.; Lazowska, E.D.: </author> <title> Implementing Network Protocols at User Level, </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> Vol. 1, No. 5, </volume> <month> October </month> <year> 1993, </year> <pages> pp. 554-565 </pages>
Reference: [22] <author> Maeda, Ch.; Bershad, B. N.: </author> <title> Protocol Service Decomposition for High-Performance Networking, </title> <booktitle> 14th ACM Symposium on Operating Systems Principles, </booktitle> <month> December 5-8, </month> <year> 1993 </year>
Reference: [23] <author> Biersack, E.W.; Rtsche, E.; Unterschtz, </author> <title> T: Demultiplexing on the ATM Adapter: Experiments with Internet Protocols in User Space, </title> <booktitle> Proceedings of the 1st International Workshop on High Performance Protocol Architectures, </booktitle> <month> December 15-16, </month> <year> 1994, </year> <institution> Sophia-Antipolis, France </institution>
Reference: [24] <author> Crowcroft, J.; Wakeman, I.;Wang, Z.: </author> <title> Layering Considered Harmful, </title> <journal> IEEE Network, </journal> <volume> Vol. 6, No. 1, </volume> <month> January </month> <year> 1992 </year>
Reference-contexts: The implementor has to decide depending on application and sys-tem characteristics whether it is worth to apply ILP with all advantages and drawbacks. Using advanced protocol features such as non-layered architectures <ref> [24] </ref>, fixed size headers, trailers for data dependent fields, different packet types for control information and data, uniform processing unit sizes for different data manipulation functions could be advantageous for ILP. These features should be studied in future protocol designs.

References-found: 24

