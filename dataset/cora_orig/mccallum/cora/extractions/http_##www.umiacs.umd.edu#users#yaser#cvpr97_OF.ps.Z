URL: http://www.umiacs.umd.edu/users/yaser/cvpr97_OF.ps.Z
Refering-URL: http://www.cs.gatech.edu/computing/classes/cs7322_98_spring/readings.html
Root-URL: 
Title: Temporal Multi-scale Models for Flow and Acceleration  
Author: Yaser Yacoob and Larry S. Davis 
Address: College Park, MD 20742, USA  
Affiliation: Computer Vision Laboratory Center for Automation Research University of Maryland,  
Note: To appear in CVPR 97  
Abstract: A model for computing image flow in image sequences containing a very wide range of instantaneous flows is proposed. This model integrates the spatio-temporal image derivatives from multiple temporal scales to provide both reliable and accurate instantaneous flow estimates. The integration employs robust regression and automatic scale weighting in a generalized brightness constancy framework. In addition to instantaneous flow estimation the model supports recovery of dense estimates of image acceleration and can be readily combined with parameterized flow and acceleration models. A demonstration of performance on image sequences of typical human actions taken with a high frame-rate camera, is given. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adiv G. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. </title> <journal> IEEE PAMI, </journal> <volume> Vol. 7(4), </volume> <year> 1985, </year> <pages> 384-401. </pages>
Reference-contexts: Recall that the flow constraint given in Equation (2) assumes constant flow over a small neighborhood around the point (x; y). Over larger neighborhoods, a more accurate model of the image flow is given by low-order polynomials <ref> [1] </ref>. For example, affine motion is given by U (x; y) = a 0 + a 1 x + a 2 y (15) where a i 's are constants and (U; V ) is the instanta neous velocity vector.
Reference: [2] <author> S.S. Beauchemin and J.L. Barron. </author> <title> The Computation of Optical Flow. </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 27, No. 3, </volume> <year> 1995, </year> <pages> 433-467. </pages>
Reference-contexts: The majority of published algorithms for estimation of image flow are based on two images (for a recent survey see <ref> [2] </ref>). Several approaches, however, consider the incremental estimation of flow [4, 13]; then, temporal continuity of the flow applied over a few images (for example, assuming constant acceleration) can improve the accuracy of the flow estimate. These approaches are based on computations between consecutive images.
Reference: [3] <author> J.R. Bergen, P. Anandan, K.J. Hanna and R. Hin-gorani. </author> <title> Heirarchical model-based motion estimation. </title> <editor> In G. Sandini, editor, ECCV-92, </editor> <volume> Vol. </volume> <booktitle> 588 of LNCS-Series, </booktitle> <pages> 237-252, </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Afterwords, iteratively, the estimates are refined by decreasing w . This temporal multi-scale procedure is accompanied by a spatial coarse-to-fine strategy <ref> [3] </ref> that constructs a pyramid of the spatially filtered and sub-sampled im ages (for more information see [4]) and computes the flow initially at the coarsest level and then propagates the results to finer levels.
Reference: [4] <author> M.J. Black and P. Anandan. </author> <title> A Frame-work for Robust Estimation of Optical Flow. </title> <booktitle> ICCV 1993, </booktitle> <pages> 231-236. </pages>
Reference-contexts: The majority of published algorithms for estimation of image flow are based on two images (for a recent survey see [2]). Several approaches, however, consider the incremental estimation of flow <ref> [4, 13] </ref>; then, temporal continuity of the flow applied over a few images (for example, assuming constant acceleration) can improve the accuracy of the flow estimate. These approaches are based on computations between consecutive images. <p> Equation (5) now becomes E D (u; v) = s=1 (x;y)2R x u + I s t )) 2 Instead of the least squares minimization in Equation (6) we choose a robust estimation approach as pro posed in <ref> [4] </ref>, resulting in E D (u; v) = s=1 (x;y)2R x u + I s t ); e ) where is a robust error norm that is a function of a scale parameter e . <p> Afterwords, iteratively, the estimates are refined by decreasing w . This temporal multi-scale procedure is accompanied by a spatial coarse-to-fine strategy [3] that constructs a pyramid of the spatially filtered and sub-sampled im ages (for more information see <ref> [4] </ref>) and computes the flow initially at the coarsest level and then propagates the results to finer levels. <p> The computational aspects of the multi-scale model follow, generally, the approach proposed by Black and Anandan <ref> [4, 5] </ref>. 4 Experimental Results In the following figures we show the results of image flow computation when w = 20:0 and is decreased at a rate of 0:85 for five iterations, and e = 100:0 and is decreased also at a rate of 0:85 for 40 iterations. <p> The former leads to a computation based on weighting of spatio-temporal derivatives while the latter leads to weighting of parametric models. Once a choice for the weighting function has been made the computation of the parameters of the model follows the approach proposed in <ref> [4] </ref>. In the examples in this chapter we adopt the weight of parametric models. Recall that the parameters of the affine and planar models capture several aspects of the region's motion (see [6]).
Reference: [5] <author> M.J. Black and P. Anandan. </author> <title> The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields. </title> <note> 1994 Revision of Technical Report P93-00104, Xerox PARC, De-cember 1993. </note>
Reference-contexts: a wide range of temporal scales, and combine these estimates (using The support of the Defense Advanced Research Projects Agency (ARPA Order No. #C635), the Office of Naval Research (contract N000149510521) is gratefully acknowledged both spatial and temporal constraints) using a combination of robust estimation and parametric modeling as in <ref> [5] </ref>. To motivate both the problem and our proposed solution consider a pendulum arm moving in front of a camera. The image flow will vary depending upon the distance of the measured point from the hanging point (see Figure 1). <p> The computational aspects of the multi-scale model follow, generally, the approach proposed by Black and Anandan <ref> [4, 5] </ref>. 4 Experimental Results In the following figures we show the results of image flow computation when w = 20:0 and is decreased at a rate of 0:85 for five iterations, and e = 100:0 and is decreased also at a rate of 0:85 for 40 iterations. <p> Algorithms for motion estimation can be quite noisy since they are based on local operators applied over very small neighborhoods between two images. Temporal smoothing was proposed by <ref> [5] </ref> in a regularization framework; in contrast our multi-scale approach employs well-understood scale-space concepts [11, 12] to create smooth estimates. Due to the integrative nature of the multi-scale estimation, motion smoothing is achieved through the estimation process.
Reference: [6] <author> M.J. Black and Y. Yacoob. </author> <title> Recognizing facial expressions in image sequences using local parameterized models of image motion. </title> <address> ICCV, </address> <year> 1995, </year> <pages> 374-381. </pages>
Reference-contexts: Recently, it has been demonstrated that parameterized flow models can provide a powerful tool for reason-ing about image motion between successive images (see <ref> [6] </ref>). The multi-scale flow estimation algorithm can be extended in a straightforward way to parameterized models of image flow. In this section we describe the extension of the muti-scale framework to affine and planar parameterized image motion models. <p> In the examples in this chapter we adopt the weight of parametric models. Recall that the parameters of the affine and planar models capture several aspects of the region's motion (see <ref> [6] </ref>). <p> The parameterized flow is used to automatically track the hand 1264 1310 1400 1500 1600 1670 1760 arm in motion (top).Flow results without acceleration model, a 3 and a 0 (left, solid and dashed lines, respec tively) and curl (center row left to right). motion throughout the sequence similar to <ref> [6] </ref> (assuming an initial manual hand segmentation in the first image). The frame numbers are shown with the images. The left graph shows the horizontal and vertical translations (solid and dashed lines, respectively) and the right graph shows the curl of the hand.
Reference: [7] <author> A. Blake and A. Zisserman. </author> <title> Visual Reconstruction The MIT Press, </title> <address> Cambridge, Massachusetts, </address> <year> 1987. </year>
Reference: [8] <author> D.J. Fleet and A.D. Jepson. </author> <title> Computation of Component Image Velocity from Local Phase Information. </title> <journal> IJCV, </journal> <volume> Vol. 3, No. 4, </volume> <pages> 77-104. </pages>
Reference-contexts: These approaches are based on computations between consecutive images. Other approaches use velocity-tuned filters (i.e., frequency-based methods) <ref> [8, 10] </ref> to compute the flow, and can be extended to flow estimation from several frames. The use of scale-space theory to compute optical flow was recently proposed by Lindeberg [12].
Reference: [9] <author> S. Geman and D.E. McClure. </author> <title> Statistical Methods for Tomographic Image Reconstruction. </title> <journal> Bulletin of the International Statistical Institute, </journal> <volume> LII-4:5-21, </volume> <year> 1987. </year>
Reference: [10] <author> D.J. Heeger. </author> <title> Optical Flow Using Spatio-temporal Filters. </title> <journal> IJCV, </journal> <volume> Vol. 1, </volume> <pages> 279-302. </pages>
Reference-contexts: These approaches are based on computations between consecutive images. Other approaches use velocity-tuned filters (i.e., frequency-based methods) <ref> [8, 10] </ref> to compute the flow, and can be extended to flow estimation from several frames. The use of scale-space theory to compute optical flow was recently proposed by Lindeberg [12].
Reference: [11] <author> T. Lindeberg. </author> <title> Scale-Space Theory in Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: The practical problem, of course, is that we do not know a priori which parts of the image are moving with which speed. Our solution is a scale-space like solution <ref> [11] </ref> in which we estimate image flow over a wide range of temporal scales, and combine these estimates (using The support of the Defense Advanced Research Projects Agency (ARPA Order No. #C635), the Office of Naval Research (contract N000149510521) is gratefully acknowledged both spatial and temporal constraints) using a combination of <p> Algorithms for motion estimation can be quite noisy since they are based on local operators applied over very small neighborhoods between two images. Temporal smoothing was proposed by [5] in a regularization framework; in contrast our multi-scale approach employs well-understood scale-space concepts <ref> [11, 12] </ref> to create smooth estimates. Due to the integrative nature of the multi-scale estimation, motion smoothing is achieved through the estimation process. In this paper we developed a new multi-temporal framework for computing flow and acceleration in images.
Reference: [12] <author> T. Lindeberg. </author> <title> A Scale Selection Principle for Estimating Image Deformations. </title> <type> Technical Report, </type> <institution> Stockholm University, </institution> <address> CVAP 196, </address> <year> 1996. </year>
Reference-contexts: These approaches are based on computations between consecutive images. Other approaches use velocity-tuned filters (i.e., frequency-based methods) [8, 10] to compute the flow, and can be extended to flow estimation from several frames. The use of scale-space theory to compute optical flow was recently proposed by Lindeberg <ref> [12] </ref>. The proposed algorithm focused on scale selection in the spatial dimension so that different size im a long sequence of a moving arm age structures lead to different selection of scales for flow computation. <p> Algorithms for motion estimation can be quite noisy since they are based on local operators applied over very small neighborhoods between two images. Temporal smoothing was proposed by [5] in a regularization framework; in contrast our multi-scale approach employs well-understood scale-space concepts <ref> [11, 12] </ref> to create smooth estimates. Due to the integrative nature of the multi-scale estimation, motion smoothing is achieved through the estimation process. In this paper we developed a new multi-temporal framework for computing flow and acceleration in images.
Reference: [13] <author> A. Singh. </author> <title> Incremental Estimation of Image Flow Using a Kalman Filter. </title> <booktitle> IEEE Proceedings of the Workshop on Visual Motion 1991, </booktitle> <pages> 36-43. </pages>
Reference-contexts: The majority of published algorithms for estimation of image flow are based on two images (for a recent survey see [2]). Several approaches, however, consider the incremental estimation of flow <ref> [4, 13] </ref>; then, temporal continuity of the flow applied over a few images (for example, assuming constant acceleration) can improve the accuracy of the flow estimate. These approaches are based on computations between consecutive images.
References-found: 13

