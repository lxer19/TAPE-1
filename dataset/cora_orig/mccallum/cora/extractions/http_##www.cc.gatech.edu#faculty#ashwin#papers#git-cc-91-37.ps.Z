URL: http://www.cc.gatech.edu/faculty/ashwin/papers/git-cc-91-37.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Title: Learning Momentum: On-line Performance Enhancement for Reactive Systems  
Author: Russell J. Clark, Ronald C. Arkin, and Ashwin Ram 
Abstract: Technical Report GIT-CC-91/37 College of Computing Georgia Institute of Technology Atlanta, GA 30332-0280 Abstract We describe a reactive robotic control system which incorporates aspects of machine learning to improve the system's ability to successfully navigate in unfamiliar environments. This system overcomes limitations of completely reactive systems by exercising on-line performance enhancement without the need for high level planning. The results of extensive simulation studies using the learning enhanced reactive controller are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arkin, </author> <title> R.C., "Motor Schema-Based Mobile Robot Navigation", </title> <journal> International Journal of Robotics Research, </journal> <volume> Vol. 8, No. 4, </volume> <month> August </month> <year> 1989, </year> <pages> pp. 92-112. </pages>
Reference-contexts: In this paper, we describe a reactive robotic controller with the ability to adapt and improve a mobile robot's performance. This research builds on the schema control system based on our previous work <ref> [1] </ref> which is summarized in section 3. Section 4 outlines a rule-based adaptive system capable of adjusting schema control parameters and gain values and improving the reactive system's ability to successfully navigate in complex environments. <p> If a schema currently has a very high gain value, that schema's behavior will likely dominate the command passed to the robot drive system. If a single schema gain value remains consistently high, that schema will dominate the overall system behavior <ref> [1] </ref>. While many possible schemas have been defined, the motor schemas used in this particular research are: * Move-to-goal: Attract to goal with variable gain. Set high when heading for a particular goal. <p> For instance, an exploration behavior can be observed by providing a relatively high gain and persistence to the noise schema with an accompanying avoid-obstacle schema <ref> [1] </ref>. The task of determining appropriate a priori gain values is non-trivial in highly cluttered environments. For a given environment, this gain determination process involves empirical evaluation of the system's performance. The process is repeated until further changes result in no visible improvement.
Reference: [2] <author> Arkin, </author> <title> R.C., "Integrating behavioral, perceptual, and world knowledge in reactive navigation.", </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 6 </volume> <pages> 105-122, </pages> <year> 1990. </year>
Reference-contexts: One difference between this and our work is that our system learns varying levels of behavior (schema) activation rather than merely active versus inactive. 3. Schema-Based Navigation Schema-based robotic control is one form of reactive control system. It forms the reactive basis of AuRA, The Autonomous Robot Architecture <ref> [2] </ref>, a framework for providing reactive control for an autonomous mobile system. Each motor schema represents one fundamental motor behavior currently available to the robot. The action to be performed is the result of collectively summing the contributions of all currently active schemas rather than arbitrating between them. <p> For a given environment, this gain determination process involves empirical evaluation of the system's performance. The process is repeated until further changes result in no visible improvement. When structural environmental knowledge is available, this task becomes simpler <ref> [2] </ref>, but for purely reactive systems with no knowledge of the world, highly complex environments can produce difficulty in reaching near optimal solutions.
Reference: [3] <author> Arkin, </author> <title> R.C., "The Impact of Cybernetics on the Design of a Mobile Robot System: A Case Study", </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> Vol. 20, No. 6, </volume> <month> Nov/Dec </month> <year> 1990, </year> <pages> pp. 1245-1257. </pages>
Reference: [4] <author> Bennett, </author> <title> S.W., "Reducing Real-world Failures of Approximate Explanation-Based Rules", </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <month> June </month> <year> 1990, </year> <pages> pp. 226-234. </pages>
Reference-contexts: Bennett described a robotic arm controller based on an Explanation Based Learning (EBL) system which uses approximations to deal with inconsistencies between reactive rules and real-world experience <ref> [4] </ref>. Mitchell's Theo-Agent architecture is an EBL system which learns to be more reactive by generating rules from explanations of failure [10]. The Minimal Deliberation approach proposed by Chien [6] combines reaction-based control with a classical planning system to create plans for dealing with situations where reaction rules fail.
Reference: [5] <author> Brooks, R., </author> <title> "A Robust Layered Control System for a Mobile Robot", </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> Vol. RA-2, No. 1, </volume> <pages> pp. 14-23, </pages> <year> 1986. </year> <month> 19 </month>
Reference: [6] <author> Chien, S.A., </author> <title> M.T. Gervasio and G.F. DeJong, "On Becoming Decreasingly Reactive: Learning to Deliberate Minimally", </title> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <month> June </month> <year> 1991, </year> <pages> pp. 288-292. </pages>
Reference-contexts: Mitchell's Theo-Agent architecture is an EBL system which learns to be more reactive by generating rules from explanations of failure [10]. The Minimal Deliberation approach proposed by Chien <ref> [6] </ref> combines reaction-based control with a classical planning system to create plans for dealing with situations where reaction rules fail. Both of these systems require extensive domain 2 knowledge in the non-reactive planning systems in order to deal with limitations in reactive control.
Reference: [7] <author> Christiansen, </author> <title> A.D., M.T. Mason and T.M. Mitchell, "Learning Reliable Strategies without Initial Physical Models", </title> <booktitle> IEEE Conf. on Robotics and Auto., </booktitle> <pages> pp. 1224-1230, </pages> <year> 1990. </year>
Reference-contexts: Much of this work is not based on reactive control systems but is aimed at systems which improve navigational ability by learning environmental features [12] or developing models of actions in the environment <ref> [7] </ref>. Bennett described a robotic arm controller based on an Explanation Based Learning (EBL) system which uses approximations to deal with inconsistencies between reactive rules and real-world experience [4]. Mitchell's Theo-Agent architecture is an EBL system which learns to be more reactive by generating rules from explanations of failure [10].
Reference: [8] <author> Kolodner, J.L., </author> <title> An Introduction to Case-Based Reasoning, </title> <type> Technical Report No. </type> <institution> GIT-ICS-90/19. College of Computing. Georgia Institute of Technology. </institution> <address> Atlanta, GA., </address> <year> 1990. </year>
Reference-contexts: For each schema value there is also a range specifying the minimum and maximum allowable values. These ranges prevent the ADJUSTER from continuing to make changes to a value beyond a reasonable limit. The adjustment values to be used for a mission are specified in a case <ref> [8] </ref> and stored in a datafile. When a particular mission is initiated, the appropriate case is retrieved and the rule adjustment values are established.
Reference: [9] <author> Maes, P., R.A. </author> <title> Brooks "Learning To Coordinate Behaviors", </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, MA, </address> <month> Aug </month> <year> 1990, </year> <pages> pp. 796-802. </pages>
Reference-contexts: Unlike these systems, our approach does not fall back on slow nonreactive techniques for improving reactive control. The behavior based learning system proposed by Maes is a distributed algorithm in which the behaviors learn when to become active based on feedback during execution <ref> [9] </ref>. One difference between this and our work is that our system learns varying levels of behavior (schema) activation rather than merely active versus inactive. 3. Schema-Based Navigation Schema-based robotic control is one form of reactive control system.
Reference: [10] <author> Mitchell, </author> <title> T.M. "Becoming Increasingly Reactive", </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, MA, </address> <month> Aug </month> <year> 1990, </year> <pages> pp. 1051-1058. </pages>
Reference-contexts: Bennett described a robotic arm controller based on an Explanation Based Learning (EBL) system which uses approximations to deal with inconsistencies between reactive rules and real-world experience [4]. Mitchell's Theo-Agent architecture is an EBL system which learns to be more reactive by generating rules from explanations of failure <ref> [10] </ref>. The Minimal Deliberation approach proposed by Chien [6] combines reaction-based control with a classical planning system to create plans for dealing with situations where reaction rules fail.
Reference: [11] <author> Payton, D., </author> <title> "An Architecture for Reflexive Autonomous Vehicle Control", </title> <booktitle> IEEE Conf. on Robotics and Auto., </booktitle> <pages> pp. 1838-1845, </pages> <year> 1986. </year>
Reference: [12] <author> Zelinsky, A., </author> <title> A Mobile Robot Environmental Learning Algorithm, </title> <institution> Department of Computing Science, University of Wollongong, </institution> <month> April, </month> <year> 1988. </year> <month> 20 </month>
Reference-contexts: Related Work in Robotic Learning This work takes inspiration from other recent work combining the ideas of machine learning with robotic control. Much of this work is not based on reactive control systems but is aimed at systems which improve navigational ability by learning environmental features <ref> [12] </ref> or developing models of actions in the environment [7]. Bennett described a robotic arm controller based on an Explanation Based Learning (EBL) system which uses approximations to deal with inconsistencies between reactive rules and real-world experience [4].
References-found: 12

