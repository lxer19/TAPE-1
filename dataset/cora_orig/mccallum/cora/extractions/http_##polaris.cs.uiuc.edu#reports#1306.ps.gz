URL: http://polaris.cs.uiuc.edu/reports/1306.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Title: Polaris: A New-Generation Parallelizing Compiler for MPPs  
Author: A. Padua Rudolf Eigenmann Jay Hoeflinger Paul Petersen Peng Tu Stephen Weatherford Keith Faigin 
Date: 1306  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign. CSRD  
Note: David  
Pubnum: Report No.  
Abstract: R & D Status Report June 15, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [AWZ88] <author> B. Alpern, M. N. Wegman, and F. K. Zadeck. </author> <title> Detecting Equality of Variables in Programs. </title> <booktitle> In Proc. of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-11, </pages> <year> 1988. </year>
Reference-contexts: SSA is an intermediate representation of a program which has two useful properties: 1. Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. <ref> [AWZ88, RWZ88, WZ91] </ref> present various applications of SSA, and [CFR + 91] deals with efficiently transforming programs into SSA form. Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: [Ban88] <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Section 5 presents a goal-directed technique that uses the SSA form of a program to determine symbolic values in the presence of conditional statements, loops, and index arrays. Section 6 presents the conslusion. Background Data dependence <ref> [Ban88] </ref> specifies the precedence constraints in the execution of statements in a program due to data producer and consumer relationships. <p> When there is more than one subscript of A in P RI b (L), we need to test if there are dependences among each pair of subscripted variables. We can use the Banerjee Test <ref> [Ban88] </ref> to determine if within the loop boundaries two references referred to the same location.
Reference: [BCFH89] <author> M. Burke, R. Cytron, J. Ferrante, and W. Hsieh. </author> <title> Automatic generation of nested, fork-join parallelism. </title> <journal> Journal of Supercomputing, </journal> <pages> pages 71-88, </pages> <year> 1989. </year>
Reference-contexts: For each loop in the target program, privatizable arrays are annotated; last-value assignment statements for live privatizable arrays after the loop are also annotated. The algorithm has been implemented in the POLARIS parallelizing compiler. Previous work on eliminating memory-related dependences focused on scalar expansion [Wol82], scalar privatization <ref> [BCFH89] </ref>, scalar renaming [CF87], and array expansion [PW86] [Fea88]. Recently there have been several papers on array priva-tization [Li92][MAL92][TP92]. Our work on automatic array privatization presents the following new results: * We use data flow-based analysis for array reference.
Reference: [CF87] <author> Ron Cytron and Jeanne Ferante. </author> <title> What's in a Name? or The Value of Renaming for Parallelism Detection and Storage Allocation. </title> <booktitle> In Proc. 1987 International Conf. on Parallel Processing, </booktitle> <pages> pages 19-27, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: The algorithm has been implemented in the POLARIS parallelizing compiler. Previous work on eliminating memory-related dependences focused on scalar expansion [Wol82], scalar privatization [BCFH89], scalar renaming <ref> [CF87] </ref>, and array expansion [PW86] [Fea88]. Recently there have been several papers on array priva-tization [Li92][MAL92][TP92]. Our work on automatic array privatization presents the following new results: * We use data flow-based analysis for array reference.
Reference: [CFR + 91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. [AWZ88, RWZ88, WZ91] present various applications of SSA, and <ref> [CFR + 91] </ref> deals with efficiently transforming programs into SSA form. Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: [CK88a] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedural side effects in a parallel programming environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: A range includes expressions for the lower bound, upper bound, and stride. The notion of subarray we use in this paper is an extension at the regular section used by others <ref> [CK88a] </ref>. Using subarray, we can represent the triangular region and banded region, as well as the strip, grid, column, row, and block of a array.
Reference: [CK88b] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference: [EHJP92] <author> R. Eigenmann, J. Hoeflinger, G. Jaxon, and D. Padua. </author> <title> The Cedar Fortran Project. </title> <type> Technical Report 1262, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomp. R&D, </institution> <year> 1992. </year>
Reference-contexts: analysis in real programs Table 26 shows the results of an analysis of the array subscript expressions in the most time-consuming loops in the suite of Perfect Bechmarks R fl programs 1 , that is, all the loops that were manually parallelized in order to achieve the performance previously reported <ref> [EHJP92] </ref>. This performance, and its comparison to the performance achieved by commercially available compilers, is displayed in Table 25. The last two columns of Table 26 show the programs that need be preprocessed by two transformation techniques, array privatization and reduction analysis.
Reference: [EHLP91] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the automatic parallelization of four Perfect-Benchmark programs. </title> <booktitle> In Proc. 4-th Workshop on Programming Languages and Compilers for Parallel Computing. </booktitle> <publisher> Pitman/MIT Press, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: By providing a distinct instance of a variable to each processor, privatization can eliminate memory related dependences. Previous studies on the effectiveness of automatic program parallelization show that privatization is one of the most effective transformations for the exploitation of parallelism <ref> [EHLP91] </ref>. A related technique called expansion [PW86] transforms each reference to a particular scalar into a reference to a vector element in such a way that each thread accesses a different vector element. When applied to an array, expansion creates a new dimension for the array. <p> We compare the automatic privatization with manual privatization described in a previous study <ref> [EHLP91] </ref> and find that we need more sophisticated techniques to determine the relationship between symbolic values for further improvement. * To facilitate further improvement, we present a goal-directed technique to determine symbolic values in the present of conditional statements, loops, and index arrays. <p> We compared the number of private arrays found by the algorithm with that of the manual array privatization reported in <ref> [EHLP91] </ref>. The result is shown in Table 1. The first column reports the number of private arrays identified by both manual and automatic privatization. The second column reports the number of private arrays identified by manual privatization but not by automatic privatization. <p> The algorithms have been implemented in the POLARIS system to perform array privatization both intraprocedurally and interprocedurally. Our experiments have thus far indicated that the algorithms can privatize most of the arrays priva-tized by hand in <ref> [EHLP91] </ref>. To increase the effectiveness of the algorithms, it seems necessary to use more sophisticated techniques for determining the equivalence of symbolic variables and interprocedural values and bounds propagation of symbolic variables.
Reference: [Fea88] <author> P. Feautrier. </author> <title> Array expansion. </title> <booktitle> In Proc. 1988 ACM Int'l Conf. on Supercomputing, </booktitle> <month> July </month> <year> 1988. </year>
Reference-contexts: The algorithm has been implemented in the POLARIS parallelizing compiler. Previous work on eliminating memory-related dependences focused on scalar expansion [Wol82], scalar privatization [BCFH89], scalar renaming [CF87], and array expansion [PW86] <ref> [Fea88] </ref>. Recently there have been several papers on array priva-tization [Li92][MAL92][TP92]. Our work on automatic array privatization presents the following new results: * We use data flow-based analysis for array reference.
Reference: [For93] <author> High Performance Fortran Forum. </author> <title> High performance fortran language specification (draft). </title> <type> Technical report, </type> <institution> High Performance Fortran Forum, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: The conflict can be resolved by declaring A to be private to each iteration of loop S1. We add the followin directives to the loop: C$DIR INDEPENDENT C$DIR PRIVATE A (1:N) C$DIR LAST VALUE A (1:N) WHEN (I.EQ.N) The INDEPENDENT directive is borrowed from HPF <ref> [For93] </ref>. It specifies that the iterations of loop S1 are independent. There are two directives for a private array. The PRIVATE directive associates the privatizable arrays with each iteration of a 51 loop.
Reference: [Li92] <author> Zhiyuan Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proc. of ICS'92, </booktitle> <pages> pages 313-322, </pages> <year> 1992. </year>
Reference: [MAL92] <author> D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. </author> <title> Data dependence and data-flow analysis of arrays. </title> <booktitle> In Proc. 5rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year> <month> 76 </month>
Reference-contexts: Recently there have been several papers on array priva-tization [Li92]<ref> [MAL92] </ref>[TP92]. Our work on automatic array privatization presents the following new results: * We use data flow-based analysis for array reference. Compared with the dependence analysis-based approach [MAL92], which has to employ parametric integer programming in its most general case, our approach is more efficient and can handle nonlinear subscripts that cannot be handled by integer pro gramming. * We distinguish private arrays whose last value assignment can be determined statically from those whose last values have to
Reference: [PP93] <author> Paul M. Petersen and David A. Padua. </author> <title> Static and Dynamic Evaluation of Data Dependence Analysis. </title> <booktitle> In Proc. of ICS'93, </booktitle> <address> Tokyo, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Our analysis agrees with earlier studies done by Yew/Li [SLY90], who found a large number of simple subscript patterns. It also agrees with the findings of Petersen/Padua <ref> [PP93] </ref> who showed that new, more powerful linear subscript tests add little to the program performance. Our study has not only shown what is needed to advance the situation in data dependence testing, it has also shown us how far we can get with improved methods.
Reference: [PW86] <author> D. Padua and M. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: By providing a distinct instance of a variable to each processor, privatization can eliminate memory related dependences. Previous studies on the effectiveness of automatic program parallelization show that privatization is one of the most effective transformations for the exploitation of parallelism [EHLP91]. A related technique called expansion <ref> [PW86] </ref> transforms each reference to a particular scalar into a reference to a vector element in such a way that each thread accesses a different vector element. When applied to an array, expansion creates a new dimension for the array. <p> The algorithm has been implemented in the POLARIS parallelizing compiler. Previous work on eliminating memory-related dependences focused on scalar expansion [Wol82], scalar privatization [BCFH89], scalar renaming [CF87], and array expansion <ref> [PW86] </ref> [Fea88]. Recently there have been several papers on array priva-tization [Li92][MAL92][TP92]. Our work on automatic array privatization presents the following new results: * We use data flow-based analysis for array reference.
Reference: [RP89] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In Proc. the SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: In the transformed program, it is easy for them to allocate a register to a scalar X. The transformation can also reduce the amount of false sharing in multiprocessor caches. In a distributed memory system with owner computes rule [ZBG88][CK88b] <ref> [RP89] </ref>, the transformed program effectively transfers the ownership of A (i) to iteration i; hence the processor scheduled to execute the iteration i can execute operations in S2 even if it does not own A (i). This transformation can facilitate data distribution to reduce communication and improve load balance [TP92].
Reference: [RWZ88] <author> B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> Global Value Numbers and Redundant Computation. </title> <booktitle> In Proc. of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 12-27, </pages> <year> 1988. </year>
Reference-contexts: SSA is an intermediate representation of a program which has two useful properties: 1. Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. <ref> [AWZ88, RWZ88, WZ91] </ref> present various applications of SSA, and [CFR + 91] deals with efficiently transforming programs into SSA form. Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: [SLY90] <author> Zhiyu Shen, Zhiyuan Li, and Pen-Chung Yew. </author> <title> An Empirical Study of Fortran Programs for Parallelizing Compilers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(3) </volume> <pages> 350-364, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Our analysis agrees with earlier studies done by Yew/Li <ref> [SLY90] </ref>, who found a large number of simple subscript patterns. It also agrees with the findings of Petersen/Padua [PP93] who showed that new, more powerful linear subscript tests add little to the program performance.
Reference: [TP92] <author> Peng Tu and David Padua. </author> <title> Array privatization for shared and distributed memory machines. </title> <booktitle> In Proc. 2nd Workshop on Languages, Compilers, and Run-Time Environments for Distributed Memory Machines, to appear on ACM SIGPLAN Notices 1993, </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: Because the access to a private variable is inherently local, privatization reduces the communication and facilitates data distribution. Since private instances of a variable are spread among all the active processors, privatization provides opportunities to spread computation among the processors and improve load balancing <ref> [TP92] </ref>. We present an algorithm for automatically generating an annotated parallel program from a sequential program represented by a control flow graph. For each loop in the target program, privatizable arrays are annotated; last-value assignment statements for live privatizable arrays after the loop are also annotated. <p> This transformation can facilitate data distribution to reduce communication and improve load balance <ref> [TP92] </ref>. For the purpose of eliminating memory-related dependences in this paper, the array A in the previous example need not be privatized. The condition for priva-tization exists when different iterations of the loop access same location. This can be determined by examining P RI b (L).
Reference: [Wol82] <author> Michael Joseph Wolfe. </author> <title> Optimizing supercompilers for supercomputers. </title> <type> Technical Report UIUCDCS-R-82-1105, </type> <institution> Department of Computer Science, University of Illinois, </institution> <month> October </month> <year> 1982. </year>
Reference-contexts: For each loop in the target program, privatizable arrays are annotated; last-value assignment statements for live privatizable arrays after the loop are also annotated. The algorithm has been implemented in the POLARIS parallelizing compiler. Previous work on eliminating memory-related dependences focused on scalar expansion <ref> [Wol82] </ref>, scalar privatization [BCFH89], scalar renaming [CF87], and array expansion [PW86] [Fea88]. Recently there have been several papers on array priva-tization [Li92][MAL92][TP92]. Our work on automatic array privatization presents the following new results: * We use data flow-based analysis for array reference.
Reference: [Wol92] <author> Michael Wolfe. </author> <title> Beyond induction variables. </title> <booktitle> ACM PLDI'92, </booktitle> <year> 1992. </year>
Reference-contexts: Bounds for Monotonic Variables Induction variables and other variables will have values dependent on the structure of the loop to which they are assigned. For an induction variable, its last value can be determined by technique in induction variable substitution such as presented in <ref> [Wol92] </ref>. In this section, we will show how to estimate bounds for monotonic variables. <p> In this example, we further extend the PHI function to include loop label L3 in it to identify the loop control. Following the terminology used by Wolfe on induction variables <ref> [Wol92] </ref>, L 2 will appear as a Strongly Connected Region (SCR) that includes a loop header PHI function and some conditional PHI functions. Because we need to know the upper bounds of L 2, we actually want to find the SCR with maximum increment to L 2.
Reference: [WZ91] <author> M. N. Wegman and F. K. Zadeck. </author> <title> Constant propagation with conditional branches. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 181-210, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: SSA is an intermediate representation of a program which has two useful properties: 1. Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. <ref> [AWZ88, RWZ88, WZ91] </ref> present various applications of SSA, and [CFR + 91] deals with efficiently transforming programs into SSA form. Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: [ZBG88] <author> H. Zima, H.-J. Bast, and M. Gerndt. </author> <title> Superb: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year>
Reference: [ZC91] <author> Hans Zima and Barbara Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: A definition of variable v in a basic block S is said to be outward exposed if it is the last definition of v in S. A use of v is outward exposed if S does not contain a definition of v before this use <ref> [ZC91] </ref>. Definition 4 Let S be a basic block and V AR be the set of scalar variables, subscripted variables, and subarrays in the program. Henceforth these are called variables. 1. DEF (S) := fv 2 V AR : v has an outward exposed definition in S g 2.
Reference: [ZY87] <author> Chuan-Qi Zhu and Pen-Chung Yew. </author> <title> A scheme to enforce data dependence on large multiprocessor systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13(6) </volume> <pages> 726-739, </pages> <month> June </month> <year> 1987. </year> <month> 77 </month>
Reference-contexts: A is still privatizable because it satisfies the privatizability conditions, but its last-value assignment cannot be determined at compile time. We use the key word DYNAMIC to specify that run-time resolution techniques such as synchronization variable <ref> [ZY87] </ref> will have to be used for the array section A (2:N). These cases are termed dynamic last-value assignment. For instance, the compiler can associate the subarray A (2:N) with a synchronization variable last-iteration, which stores the last iteration that was written to A (2:N). <p> Another problem is that some complicated subscript expressions make it inefficient to compute at compile time which iteration will assign the last value. In these cases, we will use well-known run-time techniques such as <ref> [ZY87] </ref> to resolve the output dependences. Our first step is to identify the private arrays that need dynamic last-value assignments because of conditional definition.
References-found: 25

