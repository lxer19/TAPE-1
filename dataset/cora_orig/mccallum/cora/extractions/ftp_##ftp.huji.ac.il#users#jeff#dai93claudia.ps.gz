URL: ftp://ftp.huji.ac.il/users/jeff/dai93claudia.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/dai/papers.html
Root-URL: 
Email: clag@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Emergent Coordination through the Use of Cooperative State-Changing Rules  
Author: Claudia V. Goldman Jeffrey S. Rosenschein 
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University  
Abstract: Various researchers in Distributed Artificial Intelligence (DAI) have suggested that it would be worthwhile to isolate "aspects of cooperative behavior," general rules that would cause agents to act in ways conducive to cooperation. The hypothesis is that when agents act in certain ways (e.g., share information, act in predictable ways, defer globally constraining choices), it will be easier for them to carry out effective joint action. Another kind of cooperative behavior, less explored in the literature, is when agents independently alter the environment to make it easier for everyone to function effectively. Cooperative behavior of this kind might be to put away a hammer that one finds lying on the floor, knowing that another agent will be able to find it more easily later on. In this paper we are concerned with cooperation of this latter type, state-changing behavior that improves the environment for everyone. We examine the effect that a specific "cooperativity rule" has on agents in the multi-agent tileworld domain. This domain is one in which agent actions are highly constrained, and the potential for cooperative behavior is great. We present a sociability rule by which agents are encouraged to increase tiles' degrees of freedom, even when the specific tile in question is not involved in an agent's own primary plan. The amount of extra work that an agent is willing to do in order to free these non-primary tiles is captured in the agent's cooperation level. Results from simulations are presented, comparing the amount of effort expended by agents engaged in tileworld hole-filling with and without this rule of cooperation. Comparisons are also made with the corresponding optimal multi-agent plans. It is shown that a relatively simple, easily calculated rule can be used to greatly improve global system performance. Coordination emerges from agents who use this rule of cooperation, without any explicit coordination or negotiation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Robert Axelrod. </author> <title> The Evolution of Cooperation. </title> <publisher> Basic Books, Inc., </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: The solution to these problems often relies on penalty mechanisms of one sort or another. For example, it may be possible for agents to act uncooperatively in encounters with known uncooperative agents, while acting cooperatively with cooperative agents (a strategy similar to TIT-FOR-TAT <ref> [1] </ref>). Alternatively, it may be possible to alter the cooperation rule itself so that it becomes stable.
Reference: [2] <author> Susan E. Conry, Robert A. Meyer, and Victor R. Lesser. </author> <title> Multistage negotiation in distributed planning. </title> <editor> In Alan H. Bond and Les Gasser, editors, </editor> <booktitle> Readings in Distributed Artificial Intelligence, </booktitle> <pages> pages 367-384. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [3] <author> Randall Davis. </author> <title> A model for planning in a multi-agent environment: steps toward principles for teamwork. </title> <type> Working Paper 217, </type> <institution> Massachusetts Institute of Technology AI Laboratory, </institution> <month> October </month> <year> 1981. </year>
Reference-contexts: An agent that acts predictably, shares its information, and defers globally constraining choices as long as possible, will be an easier one with which to coordinate. Work in this area includes early research by Davis and his colleagues at MIT <ref> [3] </ref>, and some of the RAND work on cooperative behavior in the air traffic control domain [11]. More recently, Tennenholtz, Shoham, and Moses have considered how social laws for artificial agent societies could be developed and evaluated [18, 14].
Reference: [4] <author> Edmund H. Durfee. </author> <title> Coordination of Distributed Problem Solvers. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [5] <author> Michael R. Genesereth, Matthew L. Ginsberg, and Jeffrey S. Rosenschein. </author> <title> Cooperation without communication. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 51-57, </pages> <address> Philadelphia, Pennsylvania, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques [15, 10, 9, 2, 8, 4, 16, 17, 7], as well as implicit modeling of other agents beliefs and desires <ref> [5, 6] </ref>. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [6] <author> Piotr Gmytrasiewicz and Edmund H. Durfee. </author> <title> A logic of knowledge and belief for recursive modeling: Preliminary report. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 628-634, </pages> <address> San Jose, California, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques [15, 10, 9, 2, 8, 4, 16, 17, 7], as well as implicit modeling of other agents beliefs and desires <ref> [5, 6] </ref>. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [7] <author> Sarit Kraus and Jonathan Wilkenfeld. </author> <title> Negotiations over time in a multi agent environment: Preliminary report. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 56-61, </pages> <address> Sydney, Australia, </address> <month> August </month> <year> 1991. </year> <month> 14 </month>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [8] <author> T. Kreifelts and F. Martial. </author> <title> A negotiation framework for autonomous agents. </title> <booktitle> In Pro--ceedings of the Second European Workshop on Modeling Autonomous Agents and Multi-Agent Worlds, </booktitle> <pages> pages 169-182, </pages> <institution> Saint-Quentin en Yvelines, France, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [9] <author> Kazuhiro Kuwabara and Victor R. Lesser. </author> <title> Extended protocol for multistage negotiation. </title> <booktitle> In Proceedings of the Ninth Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 129-161, </pages> <address> Rosario, Washington, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [10] <author> T. Malone, R. Fikes, and M. Howard. </author> <title> Enterprise: A market-like task scheduler for distributed computing environments. </title> <editor> In B. A. Huberman, editor, </editor> <booktitle> The Ecology of Computation. </booktitle> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [11] <author> D. McArthur, R. Steeb, and S. Cammarata. </author> <title> A framework for distributed problem solving. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 181-184, </pages> <address> Pittsburgh, Pennsylvania, </address> <month> August </month> <year> 1982. </year>
Reference-contexts: Work in this area includes early research by Davis and his colleagues at MIT [3], and some of the RAND work on cooperative behavior in the air traffic control domain <ref> [11] </ref>. More recently, Tennenholtz, Shoham, and Moses have considered how social laws for artificial agent societies could be developed and evaluated [18, 14]. While these streams of research have considered how agents' plans could be adapted to maximal cooperative effect, we take a different approach to the question.
Reference: [12] <author> T. A. Montgomery, J. Lee, D. J. Musliner, E. H. Durfee, D. Damouth, and Y. </author> <title> So. MICE Users Guide. </title> <institution> Artificial Intelligence Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: Such a destructive agent, of course, would also be harming itself (by expending energy to no private benefit). In the current simulations, only agents of the first two classes were designed. 3 Experiments Several simulations were carried out using the MICE distributed agent testbed <ref> [12] </ref>. We here describe the simulations, and the results of agents carrying out tasks with and without the cooperative meta-rule described above. 3.1 Scenario One Let's review the example of Figure 2.
Reference: [13] <author> Martha E. Pollack and Marc Ringuette. </author> <title> Introducing the tileworld: Experimentally evaluating agent architectures. </title> <booktitle> In Proceedings of The National Conference on Artificial Intelligence, </booktitle> <pages> pages 183-189, </pages> <address> Boston, Massachusetts, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Finally, in Section 4, we consider some of the issues this cooperative meta-rule establishment has on cooperative problem solving systems versus the issues it raises for multi-agent systems. 2 2 Tileworld Interactions 2.1 The Domain We will be considering agent interactions in a multi-agent version of the Tileworld <ref> [13] </ref> (see A 1 h 2 h 4 We use a simple variation of the multi-agent tileworld introduced in [19]. A hole in the grid is represented by a dashed line surrounding the letter h i . Tiles are represented by black squares ( ) inside the grid squares.
Reference: [14] <author> Yoav Shoham and Moshe Tennenholtz. </author> <title> On the synthesis of useful social laws for artificial agent societies. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 276-281, </pages> <address> San Jose, California, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: More recently, Tennenholtz, Shoham, and Moses have considered how social laws for artificial agent societies could be developed and evaluated <ref> [18, 14] </ref>. While these streams of research have considered how agents' plans could be adapted to maximal cooperative effect, we take a different approach to the question.
Reference: [15] <author> Reid G. Smith. </author> <title> A Framework for Problem Solving in a Distributed Processing Environment. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1978. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [16] <author> K. Sycara. </author> <title> Resolving goal conflicts via negotiation. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 245-250, </pages> <address> St. Paul, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [17] <author> Katia P. Sycara. </author> <title> Argumentation: Planning other agents' plans. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 517-523, </pages> <address> Detroit, Michigan, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Distributed Artificial Intelligence (DAI) is concerned with effective agent interactions, and the mechanisms by which these interactions can be achieved. Researchers in DAI have taken many approaches to this overall question, considering in particular explicit coordination and negotiation techniques <ref> [15, 10, 9, 2, 8, 4, 16, 17, 7] </ref>, as well as implicit modeling of other agents beliefs and desires [5, 6]. There have also been repeated attempts by researchers to establish norms of cooperative behavior, general rules that would cause agents to act in ways conducive to cooperation.
Reference: [18] <author> Moshe Tennenholtz and Yoram Moses. </author> <title> On cooperation in a multi-entity model (preliminary report). </title> <booktitle> In Proceedings of the Eleventh International Conference on Artificial Intelligence, </booktitle> <pages> pages 918-923, </pages> <address> Detroit, Michigan, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: More recently, Tennenholtz, Shoham, and Moses have considered how social laws for artificial agent societies could be developed and evaluated <ref> [18, 14] </ref>. While these streams of research have considered how agents' plans could be adapted to maximal cooperative effect, we take a different approach to the question.
Reference: [19] <author> Gilad Zlotkin and Jeffrey S. Rosenschein. </author> <title> Compromise in negotiation: Exploiting worth functions over states. </title> <type> Technical Report 93-3, </type> <institution> Leibniz Center for Computer Science, Hebrew University, </institution> <year> 1993. </year> <month> 15 </month>
Reference-contexts: problem solving systems versus the issues it raises for multi-agent systems. 2 2 Tileworld Interactions 2.1 The Domain We will be considering agent interactions in a multi-agent version of the Tileworld [13] (see A 1 h 2 h 4 We use a simple variation of the multi-agent tileworld introduced in <ref> [19] </ref>. A hole in the grid is represented by a dashed line surrounding the letter h i . Tiles are represented by black squares ( ) inside the grid squares. Obstacles are represented by thick black lines ( ). <p> Consider, for example, the simple interaction shown in Figure 2 (a variation on an example from <ref> [19] </ref>). h 2 h 3 0 4 9 For the moment, let's assume that agent A 1 wants to fill holes 1 and 2, and that agent A 2 wants to fill holes 2 and 3 (this assumes that the agents were assigned these goals a priori ).
References-found: 19

