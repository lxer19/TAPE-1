URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/project/scandal/public/papers/CMU-CS-98-114.ps.gz
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/project/scandal/public/papers/CMU-CS-98-114.html
Root-URL: http://www.cs.cmu.edu
Email: narlikar@cs.cmu.edu  blelloch@cs.cmu.edu  
Title: Pthreads for Dynamic Parallelism  
Author: Girija J. Narlikar Guy E. Blelloch 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: April 1998  
Pubnum: CMU-CS-98-114  
Abstract: Expressing a large number of lightweight, parallel threads in a shared address space significantly eases the task of writing a parallel program. Threads can be dynamically created to execute individual parallel tasks; the implementation schedules these threads onto the processors and effectively balances the load. However, unless the threads scheduler is designed carefully, such a parallel program may suffer poor space and time performance. In this paper, we evaluate the performance of a native, lightweight POSIX threads (Pthreads) library on a shared memory machine using a set of parallel benchmarks that dynamically create a large number of threads. By studying the performance of one of the benchmarks, matrix multiply, we show how simple, yet provably good modifications to the library can result in significantly improved space and time performance. With the modified Pthreads library, each of the parallel benchmarks performs as well as its coarse-grained, hand-partitioned counterpart. These results demonstrate that, provided we use a good scheduler, the rich functionality and standard API of Pthreads can be combined with the advantages of dynamic, lightweight threads to result in high performance. This research is supported by ARPA Contract No. DABT63-96-C-0071. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation thereon. Views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of ARPA or the U.S. Government. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.J. Aarseth, M. Henon, and R. Wielen. </author> <title> Numerical methods for the study of star cluster dynamics. Astronomy and Astrophysics, </title> <address> 37(2):183187, </address> <year> 1974. </year>
Reference-contexts: In addition, no per-processor data structures were required in our code, and the final version was significantly simpler than the original code. The simulation was run on a system of 100,000 bodies generated under the Plummer model <ref> [1] </ref> for four timesteps 12 . Figure 8 shows that our simpler approach achieves the same high performance as the original code. However, the library's scheduler needs to be carefully implemented to achieve this performance.
Reference: [2] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler activations: effective kernel support for the user-level management of parallelism. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principle, </booktitle> <pages> pages 95109, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model.
Reference: [3] <author> Hesheng Bao, Jacobo Bielak, Omar Ghattas, Loukas F. Kallivokas, David R. O'Hallaron, Jonathan R. Shewchuk, and Jifeng Xu. </author> <title> Large-scale Simulation of Elastic Wave Propagation in Heterogeneous Media on Parallel Computers. </title> <booktitle> Computer Methods in Applied Mechanics and Engineering, </booktitle> <volume> 152(1 2):85102, </volume> <month> January </month> <year> 1998. </year>
Reference-contexts: The code is a modified version of the Spark98 kernels [34] written for symmetric matrices. The sparse matrix in our experiments is generated from a finite element mesh used to simulate the motion of the ground after an earthquake in the San Fernando valley <ref> [4, 3] </ref>; it has 30,169 rows and 151,239 non-zeroes 14 . In the coarse-grained version, one thread is created for each processor at the beginning of the simulation, and the threads execute a barrier at the end of each iteration.
Reference: [4] <author> Hesheng Bao, Jacobo Bielak, Omar Ghattas, David R. O'Hallaron, Loukas F. Kallivokas, Jonathan Richard Shewchuk, and Jifeng Xu. </author> <title> Earthquake Ground Motion Modeling on Parallel Computers. </title> <booktitle> In Supercomputing '96, </booktitle> <address> Pittsburgh, Pennsylvania, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: The code is a modified version of the Spark98 kernels [34] written for symmetric matrices. The sparse matrix in our experiments is generated from a finite element mesh used to simulate the motion of the ground after an earthquake in the San Fernando valley <ref> [4, 3] </ref>; it has 30,169 rows and 151,239 non-zeroes 14 . In the coarse-grained version, one thread is created for each processor at the beginning of the simulation, and the threads execute a barrier at the end of each iteration.
Reference: [5] <author> Frank Bellosa and Martin Steckermeier. </author> <title> The performance implications of locality information usage in shared-memory multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1):113121, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements. <p> Thus a serial execution of the graph in would result in at most 3 active threads. The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space <ref> [41, 16, 39, 5, 29, 20, 27] </ref>. For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism. <p> For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism. In <ref> [5] </ref>, stack and other thread resources are conserved by allocating them lazily, that is, only when the thread is first scheduled, rather than when it is created. Similarly, lazy thread creation [29, 20] avoids allocating resources for a thread unless it is executed in parallel.
Reference: [6] <author> B. N. Bershad, E. Lazowska, and H. Levy. </author> <title> PRESTO : A system for object-oriented parallel programming. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8):713732, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model.
Reference: [7] <author> Guy Blelloch and Girija Narlikar. </author> <title> A practical comparison of n-body algorithms. </title> <booktitle> In Parallel Algorithms, Series in Discrete Mathematics and Theoretical Computer Science. </booktitle> <publisher> American Mathematical Society, </publisher> <year> 1997. </year>
Reference-contexts: The FMM in three dimensions, although more complex, has been shown to do less work than the Barnes-Hut algorithm for simulations requiring high accuracy, such as electrostatic systems <ref> [7] </ref>. The main work in FMM involves the computation of local and multipole expansion series that describe the potential field within and outside a cell, respectively. We first wrote the serial C version for the uniform FMM algorithm, and then parallelized it using Pthreads.
Reference: [8] <author> Guy E. Blelloch, Phillip B. Gibbons, and Yossi Matias. </author> <title> Provably efficient scheduling for languages with fine-grained parallelism. </title> <booktitle> In Proceedings of the 7th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 112, </pages> <address> Santa Barbara, California, </address> <month> July 1719, </month> <year> 1995. </year> <note> ACM SIGACT/SIGARCH and EATCS. </note>
Reference-contexts: Filaments [27] is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. Recent work has resulted in provably efficient scheduling techniques that provide upper bounds on the space required by the parallel computation <ref> [11, 12, 10, 8, 32] </ref>. Since there are several possible execution orders for lightweight threads in a computation with a high degree of parallelism, the provably space-efficient schedulers restrict the execution order for the threads to bound the space requirement.
Reference: [9] <author> R. D. Blumofe and D. Papadopoulos. </author> <title> The performance of work stealing in multipro-grammed environments, </title> <month> November </month> <year> 1997. </year> <note> Draft submitted for publication, available from http://www.cs.utexas.edu/users/rdb/papers.html. </note>
Reference-contexts: This is particularly useful in a multiprogramming environment, where the number of processors available to the computation may vary over the course of its execution <ref> [9] </ref>. * Since the number of threads expressed is much larger than the number of processors, the threads can be effectively load balanced by the implementation.
Reference: [10] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Keith H. Ran-dall, and Yuli Zhou. Cilk: </author> <title> An efficient multithreaded runtime system. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1):5569, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model. <p> In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements. <p> Filaments [27] is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. Recent work has resulted in provably efficient scheduling techniques that provide upper bounds on the space required by the parallel computation <ref> [11, 12, 10, 8, 32] </ref>. Since there are several possible execution orders for lightweight threads in a computation with a high degree of parallelism, the provably space-efficient schedulers restrict the execution order for the threads to bound the space requirement. <p> Since there are several possible execution orders for lightweight threads in a computation with a high degree of parallelism, the provably space-efficient schedulers restrict the execution order for the threads to bound the space requirement. For example, the Cilk multithreaded system <ref> [10] </ref> guarantees space-efficiency by maintaining per-processor stacks of ready threads. When a processor runs out of threads on its own stack, it picks another processor at random, and steals from the bottom of its stack. <p> While previous work on space-efficient scheduling supports a restricted set of thread operations and requires a specialized runtime system, in this paper we focus on the standard Pthreads API. Providing very fine-grained threads with overheads close to a function call, similar to <ref> [10, 27] </ref>, makes it difficult to support a variety of user-level synchronization primitives (such as locks) that require the lightweight thread to suspend. Instead, in this work, we focus on providing an efficient scheduling mechanism to support the complete, standard Pthreads functionality, which includes locks and condition variables. <p> Each processor is a 167 MHz UltraSPARC with a 512KB L2 cache. 3 The matrix multiply code was adapted from an example Cilk program available with the Cilk distribution <ref> [10] </ref>. 5 Creation of a bound or unbound thread without a preallocated stack incurs an additional overhead 200s for the smallest stack size of a page (8KB).
Reference: [11] <author> F. W. Burton. </author> <title> Storage management in virtual tree machines. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 37(3):321 328, </volume> <year> 1988. </year>
Reference-contexts: Filaments [27] is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. Recent work has resulted in provably efficient scheduling techniques that provide upper bounds on the space required by the parallel computation <ref> [11, 12, 10, 8, 32] </ref>. Since there are several possible execution orders for lightweight threads in a computation with a high degree of parallelism, the provably space-efficient schedulers restrict the execution order for the threads to bound the space requirement.
Reference: [12] <author> F. W. Burton and D. J. Simpson. </author> <title> Space efficient execution of deterministic parallel programs. </title> <type> Manuscript, </type> <month> December </month> <year> 1994. </year>
Reference-contexts: Filaments [27] is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. Recent work has resulted in provably efficient scheduling techniques that provide upper bounds on the space required by the parallel computation <ref> [11, 12, 10, 8, 32] </ref>. Since there are several possible execution orders for lightweight threads in a computation with a high degree of parallelism, the provably space-efficient schedulers restrict the execution order for the threads to bound the space requirement.
Reference: [13] <author> Martin C. Carlisle, Anne Rogers, John H. Reppy, and Laurie J. Hendren. </author> <title> Early experiences with Olden. </title> <editor> In Uptal Banerjee, David Gelernter, Alex Nicolau, and David Padua, editors, </editor> <booktitle> Proceedings of the 6th International Workshop on Languages and Compilers for Parallel Computing, Lecture Notes in Computer Science, </booktitle> <pages> pages 120, </pages> <address> Portland, Oregon, </address> <month> August 1214, </month> <year> 1993. </year> <title> Intel Corp. and the Portland Group, </title> <publisher> Inc., Springer-Verlag. </publisher> <pages> 17 </pages>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements.
Reference: [14] <author> Rohit Chandra, Anoop Gupta, and John L. Hennessy. </author> <title> Data locality and load balancing in COOL. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, </booktitle> <pages> pages 239259, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements.
Reference: [15] <author> J. W. Cooley and J. W Tukey. </author> <title> An algorithm for the machine computation of complex fourier series. </title> <booktitle> Mathematics of Computation, </booktitle> <address> 19:297301, </address> <month> Apr. </month> <year> 1965. </year>
Reference-contexts: The FFTW library is typically faster than all other publicly available DFT code, and is competitive or better than proprietary, highly optimized versions such as Sun's Performance Library code. FFTW implements the divide-and-conquer Cooley-Tukey algorithm <ref> [15] </ref>. The algorithm factors the size N of the transform into N = N 1 N 2 , and recursively computes N 1 transforms of size N 2 , followed by N 2 transforms of size N 1 .
Reference: [16] <author> D. E. Culler and G. Arvind. </author> <title> Resource requirements of dataflow programs. </title> <editor> In H. J. Siegel, editor, </editor> <booktitle> Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 141151, </pages> <address> Honolulu, Hawaii, MayJune 1988. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Thus a serial execution of the graph in would result in at most 3 active threads. The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space <ref> [41, 16, 39, 5, 29, 20, 27] </ref>. For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism.
Reference: [17] <author> J. J. Dongarra, J. Du Croz, S. Hammarling, and R. J. Hanson. </author> <title> An extended set of fortran basic linear algebra subprograms: Model implementation and test programs. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 14:1832, </volume> <year> 1988. </year>
Reference-contexts: All the speedups in Figure 7 (a) are with respect to the serial C version of matrix multiply. For comparison, the figure also shows the speedup obtained by the BLAS3 library routine for matrix multiplication <ref> [17] </ref> with respect to the serial C version. This library is hand-optimized by the manufacturer for the specific hardware and software system [45], and is widely considered to yield optimal performance. The modifications on the native Pthreads library are described in the order in which they were performed: 1.
Reference: [18] <author> Jeremy D. Frens and David S. Wise. </author> <title> Auto-blocking matrix-multiplication or tracking BLAS3 performance from source code. </title> <booktitle> In Proceedings of the Sixth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 206216, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: This is particularly encouraging since our code is high-level and platform-independent, while BLAS3 is hand-optimized. Note, however, that BLAS3 handles general matrix sizes, while our code handles sizes that are powers of 2. For a more complete implementation of a portable, divide-and-conquer matrix multiply, an algorithm such as <ref> [18] </ref> would need to be implemented. The two versions of the new scheduling technique differ in their memory requirements, as seen in preemptions added in the Final version make the scheduling technique provably space-efficient (see [32] for details).
Reference: [19] <author> Matteo Frigo and Steven G. Johnson. </author> <title> The fastest fourier transform in the west. </title> <type> Technical Report MIT-LCS-TR-728, </type> <institution> Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1997. </year>
Reference-contexts: The 8-processor speedups obtained with the original and new library are shown in Figure 8; both the libraries result in good time performance; however, the new library resulted in a lower space requirement (see Figure 9 (b)). 5.4 Fast Fourier Transform The FFTW (Fastest Fourier Transform in the West) library <ref> [19] </ref> computes the one- and multidimensional complex discrete Fourier transform (DFT). The FFTW library is typically faster than all other publicly available DFT code, and is competitive or better than proprietary, highly optimized versions such as Sun's Performance Library code. FFTW implements the divide-and-conquer Cooley-Tukey algorithm [15].
Reference: [20] <author> Seth C. Goldstein, Klaus E. Schauser, and David E. Culler. </author> <title> Enabling primitives for compiling parallel languages. </title> <booktitle> In Third Workshop on Languages, Compilers, and Run-Time Systems for Scalable Computers, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: Thus a serial execution of the graph in would result in at most 3 active threads. The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space <ref> [41, 16, 39, 5, 29, 20, 27] </ref>. For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism. <p> In [5], stack and other thread resources are conserved by allocating them lazily, that is, only when the thread is first scheduled, rather than when it is created. Similarly, lazy thread creation <ref> [29, 20] </ref> avoids allocating resources for a thread unless it is executed in parallel. Filaments [27] is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. <p> We estimate that the additional slowdown is due to lower locality within each thread, as well as increased contention for the bus and the scheduling queue. Therefore, if our current scheduler were applied to a system that schedules very fine-grained threads such as <ref> [20, 27] </ref> we do not expect the performance to remain high. However, the scheduler can be extended to use globally ordered per-processor task queues.
Reference: [21] <author> L. Greengard. </author> <title> The rapid evaluation of potential fields in particle systems. </title> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: The performance of our modified Pthreads library is not affected by the high usage of locks (Pthread mutexes) in the tree-building phase. 5.2 Fast Multipole Method This application executes a different N -Body algorithm called the Fast Multipole Method or FMM <ref> [21] </ref>. The FMM in three dimensions, although more complex, has been shown to do less work than the Barnes-Hut algorithm for simulations requiring high accuracy, such as electrostatic systems [7].
Reference: [22] <author> Dirk Grunwald and Richard Neves. </author> <title> Whole-program optimization for time and space efficient threads. </title> <booktitle> In Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 5059, </pages> <address> Cambridge, Massachusetts, </address> <month> 15 October </month> <year> 1996. </year> <note> ACM Press. </note>
Reference-contexts: For example, the space required for a recursive function in a thread may vary depending on the input data. For such cases, an alternate strategy to conserve stack space is required to efficiently support a large number of threads, such as the one suggested in <ref> [22] </ref>. 3. LIFO scheduler. Next, we modified the scheduling queue to be last-in-first-out (LIFO) instead of FIFO. The motivation for this change was to reduce the total number of active threads created by the library at any time during the execution.
Reference: [23] <author> Michael Halbherr, Yuli Zhou, and Chris F. Joerg. </author> <title> Parallel programming based on continuation-passing thread. </title> <booktitle> In Proceedings of the 2nd International Workshop on Massive Parallelism: Hardware, Software and Applications, </booktitle> <address> Capri, Italy, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements. <p> When a processor runs out of threads on its own stack, it picks another processor at random, and steals from the bottom of its stack. Various other systems use a similar work stealing strategy <ref> [23, 33, 29, 46] </ref> to control the parallelism. In [32], we present a new, provably space-efficient scheduling algorithm that uses a shared parallel stack and results in lower space requirements for parallel benchmarks compared to Cilk, while maintaining good performance.
Reference: [24] <author> IEEE. </author> <title> Information TechnologyPortable Operating System Interface (POSIX)Part 1: System Application: Program Interface (API) [C Language]. </title> <address> IEEE/ANSI Std 1003.1, 1996 Edition. </address>
Reference-contexts: Several lightweight, user-level threads packages have been developed [44, 6, 30, 28, 2, 10, 26, 31], which include implementations of the POSIX standard threads or Pthreads API <ref> [24] </ref>. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model. Despite the existence of lightweight implementations of Pthreads, most programmers still write applications with one or a small constant number of Pthreads per processor.
Reference: [25] <author> J.E.Barnes and P.Hut. </author> <title> A hierarchical O(N log N ) force calculation algorithm. </title> <journal> Nature, </journal> <volume> 324(4):446 449, </volume> <month> December </month> <year> 1986. </year>
Reference-contexts: Preliminary results on 16 processors of a Sun Enterprise 6000 are presented at the end of this section. 5.1 Barnes Hut This program simulates the interactions in a system of N bodies over several timesteps using the Barnes-Hut algorithm <ref> [25] </ref>. Each timestep has three phases: an octree is first built from the set of bodies, the force on each body is then calculated by traversing this octree, and finally, the position and velocity of each body is updated accordingly.
Reference: [26] <author> David K. Lowenthal and Gregory R. Andrews. </author> <title> Shared filaments: Efficient fine-grain parallelism. </title> <type> Technical Report TR 93-13a, </type> <institution> University of Arizona, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model.
Reference: [27] <author> David K. Lowenthal, Vincent W. Freeh, and Gregory R. Andrews. </author> <title> Efficient support for fine-grain parallelism on shared memory machines. </title> <type> Technical Report TR 96-1, </type> <institution> University of Arizona, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements. <p> Thus a serial execution of the graph in would result in at most 3 active threads. The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space <ref> [41, 16, 39, 5, 29, 20, 27] </ref>. For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism. <p> In [5], stack and other thread resources are conserved by allocating them lazily, that is, only when the thread is first scheduled, rather than when it is created. Similarly, lazy thread creation [29, 20] avoids allocating resources for a thread unless it is executed in parallel. Filaments <ref> [27] </ref> is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. <p> While previous work on space-efficient scheduling supports a restricted set of thread operations and requires a specialized runtime system, in this paper we focus on the standard Pthreads API. Providing very fine-grained threads with overheads close to a function call, similar to <ref> [10, 27] </ref>, makes it difficult to support a variety of user-level synchronization primitives (such as locks) that require the lightweight thread to suspend. Instead, in this work, we focus on providing an efficient scheduling mechanism to support the complete, standard Pthreads functionality, which includes locks and condition variables. <p> We estimate that the additional slowdown is due to lower locality within each thread, as well as increased contention for the bus and the scheduling queue. Therefore, if our current scheduler were applied to a system that schedules very fine-grained threads such as <ref> [20, 27] </ref> we do not expect the performance to remain high. However, the scheduler can be extended to use globally ordered per-processor task queues.
Reference: [28] <author> T. Miyazaki, C. Sakamoto, M. Kuwayama, L. Saisho, and A. Fukuda. </author> <title> Parallel pthread library (PPL): user-level thread library with parallelism and portability. </title> <booktitle> In Proceedings of Eighteenth Annual International Computer Software and Applications Conference (COMPSAC 94), </booktitle> <pages> pages 301306, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model.
Reference: [29] <author> Eric Mohr, David Kranz, and Robert Halstead. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <year> 1990. </year>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements. <p> Thus a serial execution of the graph in would result in at most 3 active threads. The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space <ref> [41, 16, 39, 5, 29, 20, 27] </ref>. For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism. <p> In [5], stack and other thread resources are conserved by allocating them lazily, that is, only when the thread is first scheduled, rather than when it is created. Similarly, lazy thread creation <ref> [29, 20] </ref> avoids allocating resources for a thread unless it is executed in parallel. Filaments [27] is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. <p> When a processor runs out of threads on its own stack, it picks another processor at random, and steals from the bottom of its stack. Various other systems use a similar work stealing strategy <ref> [23, 33, 29, 46] </ref> to control the parallelism. In [32], we present a new, provably space-efficient scheduling algorithm that uses a shared parallel stack and results in lower space requirements for parallel benchmarks compared to Cilk, while maintaining good performance.
Reference: [30] <author> Frank Mueller. </author> <title> A library implementation of POSIX threads under unix. </title> <booktitle> In Proceedings of the Winter 1993 USENIX Technical Conference and Exhibition, </booktitle> <pages> pages 2941, </pages> <address> San Diego, CA, USA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model.
Reference: [31] <author> Bodhisattwa Mukherjee, Greg Eisenhauer, and Kaushik Ghosh. </author> <title> A machine independent interface for lightweight threads. </title> <journal> ACM Operating Systems Review, </journal> <volume> 28(1):3347, </volume> <month> January </month> <year> 1994. </year>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model.
Reference: [32] <author> Girija J. Narlikar and Guy E. Blelloch. </author> <title> Space-efficient implementation of nested parallelism. </title> <booktitle> In Proceedings of the Sixth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 2536, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: This prevents the compute intensive benchmark from scaling well. We then describe several simple modifications we make to the Pthreads library that improve space and time performance. The final version of the scheduler uses a provably efficient scheduling mechanism <ref> [32] </ref> that results in a good speedup for the matrix multiply benchmark, while keeping memory allocation low. The simple and portable code for matrix multiply runs within 10% of hand-optimized BLAS3 code for small matrices, and outperforms it for larger matrices. <p> Filaments [27] is a package that supports fine-grained fork-join or loop parallelism using non-preemptive, stateless threads; it further reduces overheads by coarsening and pruning excess parallelism. Recent work has resulted in provably efficient scheduling techniques that provide upper bounds on the space required by the parallel computation <ref> [11, 12, 10, 8, 32] </ref>. Since there are several possible execution orders for lightweight threads in a computation with a high degree of parallelism, the provably space-efficient schedulers restrict the execution order for the threads to bound the space requirement. <p> When a processor runs out of threads on its own stack, it picks another processor at random, and steals from the bottom of its stack. Various other systems use a similar work stealing strategy [23, 33, 29, 46] to control the parallelism. In <ref> [32] </ref>, we present a new, provably space-efficient scheduling algorithm that uses a shared parallel stack and results in lower space requirements for parallel benchmarks compared to Cilk, while maintaining good performance. In this paper, we implement a variation of the scheduling strategy from [32] in the context of Pthreads. <p> In <ref> [32] </ref>, we present a new, provably space-efficient scheduling algorithm that uses a shared parallel stack and results in lower space requirements for parallel benchmarks compared to Cilk, while maintaining good performance. In this paper, we implement a variation of the scheduling strategy from [32] in the context of Pthreads. While previous work on space-efficient scheduling supports a restricted set of thread operations and requires a specialized runtime system, in this paper we focus on the standard Pthreads API. <p> As expected, this reduced the memory requirements of the execution to some extent (see curve labeled as LIFO in Figure 7), and simultaneously improved the speedup. 9 4. Space-efficient scheduler. Finally, we implemented a variation of the space-efficient scheduling technique described in <ref> [32] </ref>. The main difference between this technique and the LIFO scheduler described above are * There is an entry in the scheduling queue for every thread that has been created but that has not yet exited. Thus threads represented in the queue may be either ready, blocked, or executing. <p> The constant K can be used as a parameter to adjust the trade-off between space and time (see <ref> [32] </ref>). <p> The two versions of the new scheduling technique differ in their memory requirements, as seen in preemptions added in the Final version make the scheduling technique provably space-efficient (see <ref> [32] </ref> for details). With the final scheduling technique, the performance was also less sensitive to the stack size, since fewer threads are simultaneously active, and stacks can therefore be effectively cached by the library. 5 Other parallel benchmarks In this section, we describe our experiments with 6 additional parallel benchmarks.
Reference: [33] <author> Rishiyur S. Nikhil. Cid: </author> <title> A parallel, shared-memory C for distributed-memory machines. </title> <editor> In Keshav Pingali, Uptal Banerjee, David Gelernter, Alex Nicolau, and David Padua, editors, </editor> <booktitle> Proceedings of the 7th International Workshop on Languages and Compilers for Parallel Computing, Lecture Notes in Computer Science, </booktitle> <pages> pages 376390, </pages> <address> Ithaca, New York, </address> <month> August 810, </month> <title> 1994. </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements. <p> When a processor runs out of threads on its own stack, it picks another processor at random, and steals from the bottom of its stack. Various other systems use a similar work stealing strategy <ref> [23, 33, 29, 46] </ref> to control the parallelism. In [32], we present a new, provably space-efficient scheduling algorithm that uses a shared parallel stack and results in lower space requirements for parallel benchmarks compared to Cilk, while maintaining good performance.
Reference: [34] <author> D. O'Hallaron. Spark98: </author> <title> Sparse matrix kernels for shared memory and message passing systems. </title> <type> Technical Report CMU-CS-97-178, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> Octo-ber </month> <year> 1997. </year>
Reference-contexts: The code is a modified version of the Spark98 kernels <ref> [34] </ref> written for symmetric matrices. The sparse matrix in our experiments is generated from a finite element mesh used to simulate the motion of the ground after an earthquake in the San Fernando valley [4, 3]; it has 30,169 rows and 151,239 non-zeroes 14 .
Reference: [35] <author> James Philbin, Jan Edler, Otto J. Anshus, and Craig C. Douglas. </author> <title> Thread scheduling for cache locality. </title> <booktitle> In Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 6071, </pages> <address> Cambridge, Massachusetts, </address> <month> 15 October </month> <year> 1996. </year> <note> ACM Press. </note>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements.
Reference: [36] <author> M. L. Powell, Steve R. Kleiman, Steve Barton, Devang Shah, Dan Stein, and Mary Weeks. </author> <title> SunOS multi-thread architecture. </title> <booktitle> In Proceedings of the Winter 1991 USENIX Technical Conference and Exhibition, </booktitle> <pages> pages 6580, </pages> <address> Dallas, TX, USA, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: The Solaris 2.5 operating system contains kernel support for multiple threads within a single process address space <ref> [36] </ref> 2 . The goal of the Solaris Pthreads implementation is to make the threads sufficiently lightweight so that thousands of them can be present within a process. <p> Note that this feature is not required when the LWPs are temporarily blocked in the kernel; it is, however, useful to avoid deadlocks when the LWPs are blocked in possibly indefinite, external events (such as a poll ()). As suggested in <ref> [36] </ref>, we recommend distinguishing between such blocks and allowing the user to disable the creation of new LWPs during short-term blocks.
Reference: [37] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <booktitle> Machine learning, </booktitle> <address> 1(1):81106, </address> <year> 1986. </year>
Reference-contexts: We implemented a decision tree builder to classify instances with continuous attributes. The algorithm used is similar to ID3 <ref> [37] </ref>, with C4.5-like additions to handle continuous attributes [38]. The algorithm builds the decision tree in a top-down, divide-and-conquer fashion, by choosing a split along the continuous-valued attributes based on the best gain ratio at each stage. The instances are sorted by each attribute to calculate the optimal split.
Reference: [38] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: We implemented a decision tree builder to classify instances with continuous attributes. The algorithm used is similar to ID3 [37], with C4.5-like additions to handle continuous attributes <ref> [38] </ref>. The algorithm builds the decision tree in a top-down, divide-and-conquer fashion, by choosing a split along the continuous-valued attributes based on the best gain ratio at each stage. The instances are sorted by each attribute to calculate the optimal split.
Reference: [39] <author> Jr. R. H. Halstead. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 7(4):501538, </volume> <year> 1985. </year>
Reference-contexts: Thus a serial execution of the graph in would result in at most 3 active threads. The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space <ref> [41, 16, 39, 5, 29, 20, 27] </ref>. For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism. <p> The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space [41, 16, 39, 5, 29, 20, 27]. For example, Multilisp <ref> [39] </ref>, a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism. In [5], stack and other thread resources are conserved by allocating them lazily, that is, only when the thread is first scheduled, rather than when it is created.
Reference: [40] <author> L. Rudolph, M. Slivkin-Allalouf, and E. Upfal. </author> <title> A simple load balancing scheme for task allocation in parallel machines. </title> <editor> In ACM-SIGACT; ACM-SIGARCH, editor, </editor> <booktitle> Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 237245, </pages> <address> Hilton Head, SC, July 1991. </address> <publisher> ACM Press. </publisher>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements.
Reference: [41] <author> C. A. Ruggiero and J. Sargeant. </author> <title> Control of parallelism in the manchester dataflow machine. </title> <editor> In G. Kahn, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 116. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, DE, </address> <year> 1987. </year>
Reference-contexts: Thus a serial execution of the graph in would result in at most 3 active threads. The initial approaches to conserving memory were based on heuristics that work well for some applications, but do not provide guaranteed bounds on space <ref> [41, 16, 39, 5, 29, 20, 27] </ref>. For example, Multilisp [39], a flavor of Lisp that supports parallelism through the future construct, uses per-processor stacks of ready threads to limit the parallelism.
Reference: [42] <author> Jaswinder Pal Singh, Anoop Gupta, and Marc Levoy. </author> <title> Parallel visualization algorithms: Performance and architectural implications. </title> <booktitle> Computer, </booktitle> <address> 27(7):4555, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: of the Spark98 kernels. 15 For this matrix size, creating 128 threads results in over 5% overhead compared to 8 threads; therefore we did not create any more threads. 14 5.6 Volume Rendering This application from the Splash-2 benchmark suite uses a ray casting algorithm to render a 3D volume <ref> [47, 42] </ref> . The volume is represented by a cube of volume elements, and an octree data structure is used to traverse the volume quickly. The program renders a sequence of frames from changing viewpoints.
Reference: [43] <author> Jaswinder Pal Singh, Chris Holt, Takashi Totsuka, Anoop Gupta, and John Hennessy. </author> <title> Load balancing and data locality in adaptive hierarchical N -body methods: Barnes-Hut, fast multipole, and radiosity. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 27(2):118141, </volume> <month> June </month> <year> 1995. </year> <month> 19 </month>
Reference-contexts: The Barnes code therefore uses a costzones partitioning scheme to partition the bodies among processors <ref> [43] </ref>. This scheme tries to assign to each processor a set of bodies that involve roughly the same amount of work, and are located close to each other in the tree to get better locality.
Reference: [44] <author> Dan Stein and Devang Shah. </author> <title> Implementing lightweight threads. </title> <booktitle> In Proceedings of the Summer 1992 USENIX Technical Conference and Exhibition, </booktitle> <pages> pages 110, </pages> <address> San Antonio, TX, 1992. </address> <publisher> USENIX. </publisher>
Reference-contexts: In fact, the threads library can support multiple scheduling techniques, allowing the user to pick the technique that best suits his or her application. Several lightweight, user-level threads packages have been developed <ref> [44, 6, 30, 28, 2, 10, 26, 31] </ref>, which include implementations of the POSIX standard threads or Pthreads API [24]. Pthreads are now becoming a popular standard for expressing parallelism in the shared memory programming model. <p> Lightweight Pthreads on Solaris are implemented by multiplexing them on top of kernel-supported threads called LWPs. The assignment of lightweight threads to LWPs is controlled by the user-level threads library <ref> [44] </ref>. A thread may be either bound to an LWP (to schedule it on a system-wide basis) or may be multiplexed along with other unbound threads of the process on top of one or more LWPs. <p> The modifications on the native Pthreads library are described in the order in which they were performed: 1. Disabling creation of new LWPs. The current implementation of the thread library attempts to avoid deadlocks by creating new LWPs when all the existing LWPs are blocked <ref> [44] </ref>. Since in the original library, LWPs are often blocked making system calls to allocate more memory, this results in a very large number of LWPs getting created.
Reference: [45] <author> Sun Microsystems, Inc. </author> <title> Sun Performance Library Reference. Part No.: </title> <publisher> 802-6439-10. </publisher>
Reference-contexts: For comparison, the figure also shows the speedup obtained by the BLAS3 library routine for matrix multiplication [17] with respect to the serial C version. This library is hand-optimized by the manufacturer for the specific hardware and software system <ref> [45] </ref>, and is widely considered to yield optimal performance. The modifications on the native Pthreads library are described in the order in which they were performed: 1. Disabling creation of new LWPs.
Reference: [46] <author> M. T. Vandevoorde and E. S. Roberts. WorkCrews: </author> <title> an abstraction for controlling parallelism. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 17(4):347366, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: In particular, we are interested in implementing a scheduler that efficiently supports dynamic and irregular parallelism. 2.1 Scheduling lightweight threads A variety of systems have been developed to schedule lightweight, dynamic threads <ref> [5, 10, 27, 40, 23, 29, 33, 46, 14, 13, 35] </ref>. Although the main goal has been to achieve good load balancing and/or locality, a large body of work has also focused on developing scheduling techniques to conserve memory requirements. <p> When a processor runs out of threads on its own stack, it picks another processor at random, and steals from the bottom of its stack. Various other systems use a similar work stealing strategy <ref> [23, 33, 29, 46] </ref> to control the parallelism. In [32], we present a new, provably space-efficient scheduling algorithm that uses a shared parallel stack and results in lower space requirements for parallel benchmarks compared to Cilk, while maintaining good performance.
Reference: [47] <author> S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. </author> <title> The SPLASH-2 programs: Characteriation and methodological considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2437, </pages> <address> New York, June 2224 1995. </address> <publisher> ACM Press. </publisher> <pages> 20 </pages>
Reference-contexts: We used the Barnes application code from the SPLASH-2 benchmark suite <ref> [47] </ref> in our experiments. In the SPLASH-2 Barnes code, one Pthread is created for each processor at the beginning of the execution; the threads (processors) synchronize using a barrier after each phase within a timestep. Once the tree is constructed, the bodies are partitioned among the processors. <p> of the Spark98 kernels. 15 For this matrix size, creating 128 threads results in over 5% overhead compared to 8 threads; therefore we did not create any more threads. 14 5.6 Volume Rendering This application from the Splash-2 benchmark suite uses a ray casting algorithm to render a 3D volume <ref> [47, 42] </ref> . The volume is represented by a cube of volume elements, and an octree data structure is used to traverse the volume quickly. The program renders a sequence of frames from changing viewpoints.
References-found: 47

