URL: file://ftp.cis.ohio-state.edu/pub/communication/papers/icpp97-packet_mcast.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~kesavan/publications.html
Root-URL: 
Email: Email: fkesavan,pandag@cis.ohio-state.edu  
Title: Optimal Multicast with Packetization and Network Interface Support  
Author: Ram Kesavan and Dhabaleswar K. Panda 
Address: Columbus, OH 43210-1277  
Affiliation: Department of Computer and Information Science The Ohio State University,  
Abstract: Modern networks typically limit the size of the largest packet for efficient communication. Thus, long messages are packetized and transmitted. Such networks also provide network interface support for nodes, which typically includes a coprocessor and memory, to implement the lower layers of the communication protocol. This paper presents a concept of smart network interface support for packetization and an optimal multicast algorithm for systems with such support. Two implementations of smart network interface, First-Child-First-Served (FCFS) and First-Packet-First-Served (FPFS), are studied and compared. It is shown that the FPFS network interface support is more practical and efficient. Next, the components of multicast latency under FPFS implementation are analyzed by using a pipelined model. A concept of k-binomial tree is introduced, and proved to be optimal for multicasting under the FPFS scheme. A method to construct contention-free k-binomial trees on contention-free orderings of the nodes is presented. For a 64-node system with irregular network, simulation results indicate that the optimal k-binomial tree is upto 2 times better than the conventional binomial tree for a range of multicast set sizes and message lengths. Thus, these results demonstrate significant potential to be applied to current and future generation high performance systems including MPPs and NOWs, where network interface support for multicast is provided. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. J. Boden, D. Cohen, and et al. Myrinet: </author> <title> A Gigabit-per-Second Local Area Network. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 2935, </pages> <month> Feb </month> <year> 1995. </year>
Reference-contexts: However, on further increase of ffi r of a multi-cast tree beyond dlog 2 ne, the value of L 1 increases. Therefore, for getting the minimum value for L 1 +(m1)ffi r , we need to only consider the interval <ref> [1; dlog 2 ne] </ref> to compute the optimal value of ffi r . If ffi r of a tree is less than dlog 2 ne, we get the special case of a restricted binomial tree. Let us call this tree a k-binomial tree. <p> However, this value can be easily computed by checking all possible values of k in the interval <ref> [1; dlog 2 ne] </ref> Thus, the optimal value of k can be precom-puted and stored in a table for all possible values of n and m. <p> Since ATM switches provide hardware multicast capability, the network interface support in this work is primarily geared towards achieving reliable multicast over the unreliable ATM layer. Another recent work [12] describes an implementation of packetized multicast over the Myrinet network interface <ref> [1] </ref>. This work is also geared towards development of a reliable multicast communication layer and does not provide any formal multicast algorithms. 7 Conclusions In this paper we have analyzed the features of network interface to support packetized multicast.
Reference: [2] <author> L. De Coster, N. Dewulf, and C.-T. Ho. </author> <title> Efficient Multi-packet Multicast Algorithms on Meshes with Wormhole and Dimension-Ordered Routing. </title> <booktitle> In ICPP, </booktitle> <pages> pp III:137141, </pages> <month> Aug </month> <year> 1995. </year>
Reference-contexts: This is true of nodes on a NOW, as well as on systems like the IBM SP2. Recently, a solution for implementing multicast under packetization has been proposed in <ref> [2] </ref>. However, this work assumes host processor handling of packetization and user/system control of determining optimal packet size for a given multicast set and message length. Thus, this result is not practical for modern systems with fixed packet lengths and network interface support for packetization.
Reference: [3] <author> T. V. Eicken, A. Basu, V. Buch, and W. Vogels. </author> <month> U-Net: </month>
Reference-contexts: Recent implementations of high performance messaging systems show a trend of circumventing the operating system and providing applications direct access to the network device <ref> [3, 8, 10] </ref>. This reduces the send and receive overheads for messaging, so that the low latency and high bandwidth host node. requirements of cluster computing can be achieved. The programmable coprocessor at the network interface controls the actual sending and receiving of the messages. <p> Alternatively, the host processor copies data into the host DMA memory, writes the message pointers to the network interface, and the coprocessor uses DMA to copy the packets to the send queue <ref> [3] </ref>. Subsequently, the software executing at the coprocessor detects entries in the send queue, and sends the packets out to the network channel. At the receiver side, the incoming packets join the receive queue at the network interface.
References-found: 3

