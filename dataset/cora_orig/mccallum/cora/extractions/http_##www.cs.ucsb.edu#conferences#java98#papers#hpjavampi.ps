URL: http://www.cs.ucsb.edu/conferences/java98/papers/hpjavampi.ps
Refering-URL: http://www.cs.ucsb.edu/conferences/java98/program.html
Root-URL: http://www.cs.ucsb.edu
Title: High-Performance Parallel Programming in Java: Exploiting Native Libraries  
Author: Vladimir Getov Susan Flynn-Hummel Sava Mintchev IBM T. J. 
Web: http://perun.hscs.wmin.ac.uk  http://www.watson.ibm.com  
Address: Harrow HA1 3TP, UK  Yorktown Heights, NY10598, USA  
Affiliation: School of Computer Science, University of Westminster,  Watson Research Center,  
Abstract: With most of today's fast scientific software written in Fortran and C, Java has a lot of catching up to do. In this paper we discuss how new Java programs can capitalize on high-performance libraries for other languages. With the help of a tool we have automatically created Java bindings for several standard libraries: MPI, BLAS, BLACS, PBLAS, ScaLAPACK. Performance results are presented for Java versions of two benchmarks from the NPB and PARKBENCH suites on an IBM SP2 distributed-memory machine using JDK and IBM's high-performance Java compiler. The results confirm that fast parallel computing in Java is indeed possible.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Bailey et al. </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report RNR-94-007, </type> <institution> NASA Ames Research Center, </institution> <year> 1994. </year> <note> http://science.nas.nasa.gov/Software/NPB. </note>
Reference-contexts: An example of such a function is idamax from BLAS (Example 4.1). 5 Experimental results In order to evaluate the performance of the Java binding to native libraries, we have translated into Java a C + MPI benchmark | the IS kernel from the NAS Parallel Benchmark suite NPB2.2 <ref> [1] </ref> The program sorts in parallel an array of N integers; N = 8M for IS Class A. The original C and the new Java versions of IS are quite similar, which allows a meaningful comparison of performance results.
Reference: [2] <author> A.J.C. Bik and D.B. Gannon. </author> <title> A note on native Level 1 BLAS in Java. </title> <booktitle> In [15], </booktitle> <year> 1997. </year>
Reference-contexts: This is not possible in Java; therefore a Java program cannot pass part of an array starting at a certain offset to a (native library) function. One way round this restriction, applied in the Java Linpack benchmark <ref> [7, 2] </ref>, is to add one integer "offset" argument for each array argument of a function. The JCI-generated bindings support a more elegant solution as well, which does not involve extra arguments to native library functions. <p> by the benchmark program. 6 Discussion and related work Until the Java compiler technology reaches maturity, the use of native numerical code in Java programs is certain to improve performance, as recent experiments with the Java Linpack benchmark [7] and several BLAS Level 1 functions written in C have shown <ref> [2, 15] </ref>. By binding the original native libraries like BLAS, Java programs can gain in performance on all those hardware platforms where the libraries are efficiently implemented. A Java-to-PVM interface is publicly available [19].
Reference: [3] <author> L.S. Blackford, J. Choi, A. Cleary, E. D'Azevedo, J. Demmel, I. Dhillon, J. Dongarra, S. Hammarling, G. Henry, A. Petitet, K. Stanley, D. Walker, and R.C. Whaley. ScaLA-PACK: </author> <title> A linear algebra library for message-passing computers. </title> <booktitle> In SIAM Conference on Parallel Processing, </booktitle> <year> 1997. </year>
Reference-contexts: In addition, it is thread-safe by design, and caters for heterogeneous networks. MPI aims to ensure portability of software without introducing a substantial performance penalty, and has vendor-supplied implementations on a range of hardware architectures. ScaLAPACK <ref> [3] </ref> is a high-performance linear algebra package built on top of a message-passing library like MPI. It has been designed to be both efficient and portable, by restricting most machine dependency to two standard libraries: the Basic Linear Algebra Subprograms (BLAS), and the Basic Linear Algebra Communication Subprograms (BLACS).
Reference: [4] <author> B. Carpenter, Y-J. Chang, G. Fox, D. Leskiw, and X. Li. </author> <title> Experiments with "HPJava". </title> <booktitle> In [14], </booktitle> <year> 1996. </year>
Reference-contexts: By binding the original native libraries like BLAS, Java programs can gain in performance on all those hardware platforms where the libraries are efficiently implemented. A Java-to-PVM interface is publicly available [19]. A Java binding for a subset of MPI has also been written <ref> [4, 6] </ref> and run on up to 8 processors of Sun Ultra Sparc.
Reference: [5] <author> H. Casanova, J.J. Dongarra, </author> <title> and D.M. Doolin. Java access to numerical libraries. </title> <booktitle> In [15], </booktitle> <year> 1997. </year>
Reference-contexts: Furthermore, a Java program can only use a native library in a single threaded manner unless that library is thread-safe. Some closely related work involves the automatic translation of existing Fortran library code to Java with the help of a tool like f2j <ref> [5] </ref>. This approach offers a very important long-term perspective as it preserves Java portability, while achieving high performance in this case would obviously be more difficult.
Reference: [6] <author> Y-J. Chang and B. Carpenter. </author> <title> MPI Java wrapper download page. </title> <address> 27 March, </address> <year> 1997. </year> <note> http://www.npac.syr.edu/users/yjchang/javaMPI. </note>
Reference-contexts: By binding the original native libraries like BLAS, Java programs can gain in performance on all those hardware platforms where the libraries are efficiently implemented. A Java-to-PVM interface is publicly available [19]. A Java binding for a subset of MPI has also been written <ref> [4, 6] </ref> and run on up to 8 processors of Sun Ultra Sparc.
Reference: [7] <author> J. Dongarra and R. Wade. </author> <title> Linpack benchmark - Java version. </title> <address> http://www.netlib.org/benchmark/linpackjava. </address>
Reference-contexts: This is not possible in Java; therefore a Java program cannot pass part of an array starting at a certain offset to a (native library) function. One way round this restriction, applied in the Java Linpack benchmark <ref> [7, 2] </ref>, is to add one integer "offset" argument for each array argument of a function. The JCI-generated bindings support a more elegant solution as well, which does not involve extra arguments to native library functions. <p> a native library (MPI) only for communication, and all computations are done by the benchmark program. 6 Discussion and related work Until the Java compiler technology reaches maturity, the use of native numerical code in Java programs is certain to improve performance, as recent experiments with the Java Linpack benchmark <ref> [7] </ref> and several BLAS Level 1 functions written in C have shown [2, 15]. By binding the original native libraries like BLAS, Java programs can gain in performance on all those hardware platforms where the libraries are efficiently implemented. A Java-to-PVM interface is publicly available [19].
Reference: [8] <author> S. I. Feldman and P. J. Weinberger. </author> <title> A Portable Fortran 77 Compiler. UNIX Time Sharing System Programmer's Manual, Tenth Edition. </title> <institution> AT&T Bell Laboratories, </institution> <year> 1990. </year>
Reference-contexts: The C prototypes for the library functions have been inferred by f2c <ref> [8] </ref>. Table 2 gives some idea of the sizes of JCI-generated bindings for individual libraries. In addition, there are some 2280 lines of Java class declarations produced by JCI which are common to all libraries.
Reference: [9] <author> J. Gosling, W. Joy, and G. Steele. </author> <title> The Java Language Specification, Version 1.0. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1996. </year>
Reference-contexts: Binding a native library to Java may also be accompanied by portability problems. The native interface was not part of the original Java language specification <ref> [9] </ref>, and different vendors have offered incompatible interfaces. The Java Native Interface (JNI) in Sun's JDK 1.1 is now the definitive interface, but it is not yet supported in all Java implementations on different platforms by other vendors. <p> The operations in Table 1 are used for constructing derived data types. MPI data structures and other derived types must be used in conformance with the Java data layout as described in the language specification <ref> [9] </ref>. Example 3.1 shows how two separate Java objects can be bundled together in one message by means of an MPI structure type.
Reference: [10] <author> S.F. Hummel, T. Ngo, and H. Srinivasan. </author> <title> SPMD programming in Java. </title> <booktitle> In [14], </booktitle> <year> 1996. </year>
Reference-contexts: A different way of employing Java in high performance computing is to utilize the potential of Java concurrent threads for programming parallel shared-memory machines [14]. A very interesting related theme is the implementation on the IBM POWERparallel System SP machine of a Java run-time system with parallel threads <ref> [10] </ref>, using message passing to emulate shared memory. The run-time system would eventually be written in Java with MPI. MPI offers message-passing operations portable over a large variety of machines, but has not to date been bound to many languages.
Reference: [11] <institution> IBM. </institution> <note> alphaWorks web site. http://www.alphaWorks.ibm.com/formula. </note>
Reference-contexts: Some performance results are shown in Figure 1. The Java implementations used are IBM's port of JDK 1.0.2D [13] (with the JIT compiler enabled), IBM's Java compiler hpcj <ref> [11] </ref> (with flags -O and jnoruncheck), and Toba 1.0.b6 of The University of Arizona. The hpcj optimizing compiler generates native RS/6000 code, while Toba translates Java byte code into C. The MPI libraries are LAM 6.1 and Fujitsu MPIAP.
Reference: [12] <author> IBM. </author> <title> PE for AIX: MPI Programming and Subroutine Reference. </title> <address> http://www.rs6000.ibm.com/resource/aix resource/sp books/pe/. </address>
Reference-contexts: The MPI libraries are LAM 6.1 and Fujitsu MPIAP. We opted for LAM rather than the proprietary IBM MPI library because the version of the latter available to us (PSSP 2.1) does not support the re-entrant C library required for Java <ref> [12] </ref>. A fully thread-safe implementation of MPI has not been required in our experiments so far since MPI is used in a single-threaded way.
Reference: [13] <institution> IBM UK Hursley Lab. Centre for Java Technology Development. </institution> <note> http://ncc.hursley.ibm.com/javainfo/hurindex.html. </note>
Reference-contexts: Some performance results are shown in Figure 1. The Java implementations used are IBM's port of JDK 1.0.2D <ref> [13] </ref> (with the JIT compiler enabled), IBM's Java compiler hpcj [11] (with flags -O and jnoruncheck), and Toba 1.0.b6 of The University of Arizona. The hpcj optimizing compiler generates native RS/6000 code, while Toba translates Java byte code into C. The MPI libraries are LAM 6.1 and Fujitsu MPIAP.
Reference: [14] <institution> Workshop on Java for High Performance Scientific and Engineering Computing, Simulation and Modelling, Syracuse, </institution> <address> New York, </address> <month> December </month> <year> 1996. </year> <title> Concurrency: </title> <journal> Practice and Experience, </journal> <month> June </month> <year> 1997. </year> <note> http://www.npac.syr.edu/ projects/javaforcse. </note>
Reference-contexts: This approach offers a very important long-term perspective as it preserves Java portability, while achieving high performance in this case would obviously be more difficult. A different way of employing Java in high performance computing is to utilize the potential of Java concurrent threads for programming parallel shared-memory machines <ref> [14] </ref>. A very interesting related theme is the implementation on the IBM POWERparallel System SP machine of a Java run-time system with parallel threads [10], using message passing to emulate shared memory. The run-time system would eventually be written in Java with MPI.
Reference: [15] <institution> ACM Workshop on Java for Science and Engineering Computation, </institution> <address> Las Vegas, Nevada, </address> <month> June 21 </month> <year> 1997. </year> <note> To appear in Concurrency: Practice and Experience. http://www.cs.rochester.edu/u/wei/javaworkshop.html. </note>
Reference-contexts: by the benchmark program. 6 Discussion and related work Until the Java compiler technology reaches maturity, the use of native numerical code in Java programs is certain to improve performance, as recent experiments with the Java Linpack benchmark [7] and several BLAS Level 1 functions written in C have shown <ref> [2, 15] </ref>. By binding the original native libraries like BLAS, Java programs can gain in performance on all those hardware platforms where the libraries are efficiently implemented. A Java-to-PVM interface is publicly available [19].
Reference: [16] <author> S. Mintchev and V. Getov. </author> <title> Towards portable message passing in Java: Binding MPI. </title> <booktitle> In Proceedings of EuroPVM-MPI, </booktitle> <pages> pages 135-142, </pages> <address> Krakow, Poland, </address> <month> November, </month> <year> 1997. </year> <note> Springer LNCS 1332. </note>
Reference-contexts: Clearly an additional interface layer must be written in order to bind a native library to Java. A large library like MPI can have over a hundred exported functions, therefore it is preferable to automate the creation of the additional interface layer. The Java-to-C interface generator (JCI) <ref> [16] </ref> takes as input a header file containing the C function prototypes of the native library. It outputs a number of files comprising the additional interface: * a file of C stub-functions; * files of Java class and native method declarations; * shell scripts for doing the compilation and linking. <p> whose types correspond directly to those of the Java native method, and converts the arguments into the form expected by the C library function. 3 The Java binding for MPI The largest native library we have bound to Java so far is MPI: it has in excess of 120 functions <ref> [16] </ref>. The JCI tool allowed us to bind all those functions to Java without extra effort. Since the MPI specification is a de facto standard, the binding generated by JCI should be applicable without modification to any MPI implementation.
Reference: [17] <author> MPI Forum. </author> <title> MPI: A message-passing interface standard. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 8(3/4), </volume> <year> 1994. </year>
Reference-contexts: In that way programs using a library can be both portable and efficient across a wide range of machines. Standard libraries often used for high-performance scientific programming include the Message-Passing Interface (MPI), and the Scalable Linear Algebra PACKage (ScaLAPACK). MPI <ref> [17] </ref> has over 120 different operations, ranging from primitive point-to-point communication functions to powerful collective operations, as well as built-in support for writing new libraries. In addition, it is thread-safe by design, and caters for heterogeneous networks. <p> The run-time system would eventually be written in Java with MPI. MPI offers message-passing operations portable over a large variety of machines, but has not to date been bound to many languages. The MPI-1 standard <ref> [17] </ref> includes bindings for just two languages | C and Fortran-77. C++ bindings are included in the MPI-2 document for both MPI-1 and MPI-2. 7 Conclusion In this paper we have summarised our work on high performance computation in Java.
Reference: [18] <author> PARKBENCH Committe (assembled by R. Hockney and M. Berry). </author> <title> PARKBENCH report - 1: Public international benchmarks for parallel computers. </title> <journal> Scientific Programming, </journal> <volume> 3(2) </volume> <pages> 101-146, </pages> <year> 1994. </year> <note> http://www.netlib.org/parkbench. </note>
Reference-contexts: The C libraries for which we have created Java bindings are the Parallel Basic Linear Algebra Subprograms (PBLAS) and the Communication Subprograms (BLACS). The library function prototypes have been taken from the PARKBENCH 2.1.1 distribution <ref> [18] </ref>. The JCI tool can be used to generate Java bindings for libraries written in languages other than C, provided that the library can be linked to C programs, and prototypes for the library functions are given in C. <p> The performance of Java IS programs compiled with hpcj is very impressive, and provides evidence that the Java language can be used successfully in high-performance computing. Further experiments have been carried out with a Java translation of the MATMUL benchmark from the PARKBENCH suite <ref> [18] </ref>.
Reference: [19] <author> D.A. Thurman. JavaPVM: </author> <title> The Java to PVM interface. </title> <address> http://www.isye.gatech.edu/chmsr/JavaPVM. </address>
Reference-contexts: By binding the original native libraries like BLAS, Java programs can gain in performance on all those hardware platforms where the libraries are efficiently implemented. A Java-to-PVM interface is publicly available <ref> [19] </ref>. A Java binding for a subset of MPI has also been written [4, 6] and run on up to 8 processors of Sun Ultra Sparc.
References-found: 19

