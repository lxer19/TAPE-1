URL: http://www.cis.ohio-state.edu/~cesmeli/ijcnn98paper.ps
Refering-URL: http://www.cis.ohio-state.edu/~cesmeli/research.html
Root-URL: 
Title: Abstract  
Abstract: A motion segmentation method is proposed for an input sequence of random dot and binary images. The method is composed of two main stages, inspired by primate visual system. The first stage determines local velocity information at each location in every image frame using its two neighboring image frames. Measurements of a particular velocity at all locations form the corresponding velocity layer. The second stage performs segmentation based on the motion information in the velocity layers. Each velocity layer provides input to a LEGION (Locally Excitatory Globally Inhibitory Oscillator Networks), which is a 2D array of neural oscillators. When LEGION networks are simulated, the oscillators corresponding to the region of a uniform velocity oscillate in synchrony, whereas the regions with different velocities tend to attain different phases. Final output is displayed in the segmentation network. Results demonstrating the performance of our method on synthetic image sequences are provided and related to psychophysics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. H. Adelson and J. Bergen, </author> <title> Spatiotemporal energy models for the perception of motion, </title> <journal> J. Opt. Soc. Amer. A, </journal> <volume> 2 </volume> <pages> 284-299, </pages> <year> 1985. </year>
Reference-contexts: Approaches to motion analysis can be categorized into two groups. The first group includes approaches based on tracking salient features in the frames of an image sequence (see [10] for review). The second group involves motion energy filters and seeks representation of moving patterns in the spatiotemporal frequency domain <ref> [1] </ref>, [10], [16]. Gradient based approaches fall under the second category since the derivative operation can also be viewed as one type of filtering [11].
Reference: [2] <author> H. Blthof, J. Little, and T. Poggio, </author> <title> A parallel algorithm for real-time computation of optical ow, </title> <journal> Nature, </journal> <volume> 337 </volume> <pages> 549-553, </pages> <year> 1989. </year>
Reference-contexts: Similarly, our method is composed of two stages including TBM and LEGION networks. Even though TBM in our method is similar to the local motion extraction method in <ref> [2] </ref>, we employ two neighboring frames instead of just one (Fig. 5). Because of temporal locality, segmentation result for a given image frame is not affected by temporally distant frames.
Reference: [3] <author> B. Hassenstein and W. E. Reichardt, </author> <title> Functional structure of a mechanism of perception of optical movement, </title> <booktitle> Proc. First International Congress of Cybernetics in Namar, </booktitle> <pages> 797-801, </pages> <year> 1956. </year>
Reference-contexts: Gradient based approaches fall under the second category since the derivative operation can also be viewed as one type of filtering [11]. The Elementary Motion Detector (EMD) developed by Reichardt <ref> [3] </ref> with appropriate addition of spatial and temporal filters [9] is considered to be equivalent to motion energy models. In its simple form, EMD falls under the first category as well, since it involves correlation of luminance at different locations across time. Our method consists of two stages.
Reference: [4] <author> E. Hirisi and R. Blake, </author> <title> Direction repulsion in motion transparency, </title> <journal> Visual Neuroscience, </journal> <volume> 13 </volume> <pages> 187-197, </pages> <year> 1996. </year>
Reference-contexts: Even though our examples are composed of random dot images, which are relatively simpler than real images, they capture many properties of visual motion. Current implementation of our method has only a limited number of velocity layers, which can be increased easily without efficiently <ref> [4] </ref>, [5], [17]. Future goals include testing our method on real images as well as on other psychophysical characteristics of motion perception such as direction repulsion [4]. <p> Current implementation of our method has only a limited number of velocity layers, which can be increased easily without efficiently <ref> [4] </ref>, [5], [17]. Future goals include testing our method on real images as well as on other psychophysical characteristics of motion perception such as direction repulsion [4]. Acknowledgments This work was supported in part by an ONR grant (N00014-93-10335), an NSF grant (IRI-9423312), an ONR Young Investigator Award (N00014-96-1-0676) to DLW, and an OSU Interdisciplinary Seed Grant.
Reference: [5] <author> M. Kikuchi and K. Fukushima, </author> <title> Neural network model of visual system: binding form and motion, </title> <booktitle> Neural Networks, </booktitle> <volume> 9 </volume> <pages> 1417-1427, </pages> <year> 1996. </year>
Reference-contexts: Even though our examples are composed of random dot images, which are relatively simpler than real images, they capture many properties of visual motion. Current implementation of our method has only a limited number of velocity layers, which can be increased easily without efficiently [4], <ref> [5] </ref>, [17]. Future goals include testing our method on real images as well as on other psychophysical characteristics of motion perception such as direction repulsion [4].
Reference: [6] <author> K. Koffka, </author> <booktitle> Principles of Gestalt Psychology. </booktitle> <address> New York: </address> <publisher> Harcourt, </publisher> <year> 1935. </year>
Reference-contexts: Motion information is a major cue to identify camouaged targets and sometimes, is the only cue for figure/ground segregation. It is one of the Gestalt grouping principles, which is also known as common fate <ref> [6] </ref>. Thus, a computational vision model involving dynamic scene analysis has to have motion as one of its functional tokens. Approaches to motion analysis can be categorized into two groups.
Reference: [7] <author> C. von der Malsburg and W. Schneider, </author> <title> A neural cocktail-party processor, </title> <journal> Biol. Cybern., </journal> <volume> 54 </volume> <pages> 29-40, </pages> <year> 1986. </year>
Reference-contexts: By evaluating TBM at all locations a stack of velocity layers is obtained. In the second stage, each velocity layer is associated with a corresponding LEGION network [13]. LEGION has been proposed to deal with static image segmentation [15]. It is based on the idea of oscillatory correlation <ref> [7] </ref>, [13], whereby phases of neural oscillators encode region labeling. Oscillators corresponding to one region have the same phase which is different from that of other regions [15]. In this paper, we describe a method that combines TBM and LEGION for motion segmentation. 2.
Reference: [8] <author> D. Marr and E. C. Hildreth, </author> <title> Theory of edge detection, </title> <journal> Proc. Royal Society of London, B, </journal> <volume> 207 </volume> <pages> 187-217, </pages> <year> 1980. </year>
Reference-contexts: For a given image sequence, one segmentation result is determined for each image frame except for the first and the last frames. Prior to TBM, input sequence of images is filtered by a Laplacian of Gaussian filter (LoG) of size <ref> [8] </ref>. Subsequently, filtered images are thresholded i H k N p i ( ) l 0&gt; m e q x q z dt s 1= x i q zx m m oscillator. The x-nullcline is the dotted line and the y-nullcline is the solid line.
Reference: [9] <author> J. P. H. van Santen and G. Sperling, </author> <title> Elaborated Reichardt Detectors, </title> <journal> J. Opt. Soc. Amer. A, </journal> <volume> 2 </volume> <pages> 300-321, </pages> <year> 1985. </year>
Reference-contexts: Gradient based approaches fall under the second category since the derivative operation can also be viewed as one type of filtering [11]. The Elementary Motion Detector (EMD) developed by Reichardt [3] with appropriate addition of spatial and temporal filters <ref> [9] </ref> is considered to be equivalent to motion energy models. In its simple form, EMD falls under the first category as well, since it involves correlation of luminance at different locations across time. Our method consists of two stages.
Reference: [10] <author> M. E. Sereno, </author> <title> Neural Computation of pattern motion: modeling stages of motion analysis in the primate visual cortex. </title> <address> Cambridge MA: </address> <publisher> MIT press, </publisher> <year> 1993. </year>
Reference-contexts: Thus, a computational vision model involving dynamic scene analysis has to have motion as one of its functional tokens. Approaches to motion analysis can be categorized into two groups. The first group includes approaches based on tracking salient features in the frames of an image sequence (see <ref> [10] </ref> for review). The second group involves motion energy filters and seeks representation of moving patterns in the spatiotemporal frequency domain [1], [10], [16]. Gradient based approaches fall under the second category since the derivative operation can also be viewed as one type of filtering [11]. <p> The first group includes approaches based on tracking salient features in the frames of an image sequence (see <ref> [10] </ref> for review). The second group involves motion energy filters and seeks representation of moving patterns in the spatiotemporal frequency domain [1], [10], [16]. Gradient based approaches fall under the second category since the derivative operation can also be viewed as one type of filtering [11]. <p> The Model: TBM and LEGION There is a strong evidence from both psychology and neurophysiology that there exist at least two separate stages of motion processing in primate visual system (see <ref> [10] </ref> for review). Similarly, our method is composed of two stages including TBM and LEGION networks. Even though TBM in our method is similar to the local motion extraction method in [2], we employ two neighboring frames instead of just one (Fig. 5).
Reference: [11] <author> E. P. Simoncelli, </author> <title> Distributed Analysis and Representation of Visual Motion, </title> <type> Ph.D. thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge MA, </address> <year> 1993. </year>
Reference-contexts: The second group involves motion energy filters and seeks representation of moving patterns in the spatiotemporal frequency domain [1], [10], [16]. Gradient based approaches fall under the second category since the derivative operation can also be viewed as one type of filtering <ref> [11] </ref>. The Elementary Motion Detector (EMD) developed by Reichardt [3] with appropriate addition of spatial and temporal filters [9] is considered to be equivalent to motion energy models. <p> Thus, motion information is the only cue for segmentation. We also included a binary image sequence with a moving region of uniform luminance to test the performance of our method on the challenging blank-wall problem <ref> [11] </ref>. In all random dot image sequences used in this study, the pattern of dots forming the object (s) does not change throughout the sequence. A new set of random dots corresponding to the region outside the object (s) is generated independently at each time frame. <p> In the final sequence, a uniformly white rectangular region is moving to the right with a speed of 1 pixel/frame (Fig. 10 A). This image has the blank-wall problem, where the true motion of the rectangles inner region is difficult to recover <ref> [11] </ref>. In spite of this, by the help of the last term in (7), our method is able to segment the inner region together with the edges whose motion is detected correctly (Fig. 10 B). Segmentation result is obtained with . 5.
Reference: [12] <author> O. Sporns, G. Tononi, and G. M. Edelman, </author> <title> Modeling perceptual grouping and figure-ground segregation by means of active reentrant connections, </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 88 </month> <pages> 129-133, </pages> <year> 1991. </year>
Reference: [13] <author> D. Terman and D. L. Wang, </author> <title> Global competition and local cooperation in a network of neural oscillators, </title> <journal> Physica D, </journal> <volume> 81 </volume> <pages> 148-176, </pages> <year> 1995. </year>
Reference-contexts: The first stage extracts motion information by performing temporal block matching (TBM), where intensities within displaced blocks are correlated across consecutive frames. By evaluating TBM at all locations a stack of velocity layers is obtained. In the second stage, each velocity layer is associated with a corresponding LEGION network <ref> [13] </ref>. LEGION has been proposed to deal with static image segmentation [15]. It is based on the idea of oscillatory correlation [7], [13], whereby phases of neural oscillators encode region labeling. Oscillators corresponding to one region have the same phase which is different from that of other regions [15]. <p> By evaluating TBM at all locations a stack of velocity layers is obtained. In the second stage, each velocity layer is associated with a corresponding LEGION network <ref> [13] </ref>. LEGION has been proposed to deal with static image segmentation [15]. It is based on the idea of oscillatory correlation [7], [13], whereby phases of neural oscillators encode region labeling. Oscillators corresponding to one region have the same phase which is different from that of other regions [15]. In this paper, we describe a method that combines TBM and LEGION for motion segmentation. 2. <p> there is a stack of velocity layers for each image frame except for the first and the last frames in the input image sequence (Fig. 2) 2.2 LEGION LEGION is based on the idea of oscillatory correlation, where the phases of the neural oscillators encode the binding of the features <ref> [13] </ref>, [14].
Reference: [14] <author> D. L. Wang and D. Terman, </author> <title> Locally excitatory globally inhibitory oscillator networks, </title> <journal> IEEE Trans. Neural Networks, </journal> <volume> 6 </volume> <pages> 283-286, </pages> <year> 1995. </year>
Reference-contexts: is a stack of velocity layers for each image frame except for the first and the last frames in the input image sequence (Fig. 2) 2.2 LEGION LEGION is based on the idea of oscillatory correlation, where the phases of the neural oscillators encode the binding of the features [13], <ref> [14] </ref>.
Reference: [15] <author> D. L. Wang and D. Terman, </author> <title> Image segmentation based on oscillatory correlation, </title> <journal> Neural Comp., </journal> <volume> 9 </volume> <pages> 805-836, </pages> <year> 1997. </year>
Reference-contexts: By evaluating TBM at all locations a stack of velocity layers is obtained. In the second stage, each velocity layer is associated with a corresponding LEGION network [13]. LEGION has been proposed to deal with static image segmentation <ref> [15] </ref>. It is based on the idea of oscillatory correlation [7], [13], whereby phases of neural oscillators encode region labeling. Oscillators corresponding to one region have the same phase which is different from that of other regions [15]. <p> LEGION has been proposed to deal with static image segmentation <ref> [15] </ref>. It is based on the idea of oscillatory correlation [7], [13], whereby phases of neural oscillators encode region labeling. Oscillators corresponding to one region have the same phase which is different from that of other regions [15]. In this paper, we describe a method that combines TBM and LEGION for motion segmentation. 2. Model Components 2.1 Temporal block matching (TBM) EMD, which is a motion model based on ys visual system, is composed of two symmetric parts including the rightward and the leftward motion detectors. <p> The typical neural network structure used in our image analysis is a two dimensional array of oscillators and one GI as shown in segmentation <ref> [15] </ref>. 3. The Model: TBM and LEGION There is a strong evidence from both psychology and neurophysiology that there exist at least two separate stages of motion processing in primate visual system (see [10] for review). Similarly, our method is composed of two stages including TBM and LEGION networks. <p> These velocities are (0,0), (1,0), (0,1), (-1,0), and (0,-1) pixel/frame, where the values represent horizontal and vertical components of the velocities, respectively. In the simulation of LEGION networks, a functionally equivalent algorithm is employed, where only the following parameters are needed <ref> [15] </ref>: , , , , , and . The only parameter that needs to be adjusted from one image sequence to another is . All images and LEGION networks are of size .
Reference: [16] <author> A. B. Watson and A. J. Ahumada, </author> <title> Model of visual-motion sensing, </title> <journal> J. Opt. Soc. Amer. A, </journal> <volume> 2 </volume> <pages> 322-341, </pages> <year> 1985. </year>
Reference-contexts: The first group includes approaches based on tracking salient features in the frames of an image sequence (see [10] for review). The second group involves motion energy filters and seeks representation of moving patterns in the spatiotemporal frequency domain [1], [10], <ref> [16] </ref>. Gradient based approaches fall under the second category since the derivative operation can also be viewed as one type of filtering [11]. The Elementary Motion Detector (EMD) developed by Reichardt [3] with appropriate addition of spatial and temporal filters [9] is considered to be equivalent to motion energy models.

References-found: 16

