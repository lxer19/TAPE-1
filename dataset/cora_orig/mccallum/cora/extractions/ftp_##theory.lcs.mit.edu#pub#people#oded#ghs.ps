URL: ftp://theory.lcs.mit.edu/pub/people/oded/ghs.ps
Refering-URL: http://theory.lcs.mit.edu/~oded/papers.html
Root-URL: 
Email: E-mail: oded@csa.cs.technion.ac.il.  Email: amir@watson.ibm.com.  E-mail: segall@csa.cs.technion.ac.il.  
Title: Quantitative Analysis of Dynamic Network Protocols  
Author: Oded Goldreich Amir Herzberg Adrian Segall 
Note: Part of this work was done while this author was with the  
Address: Israel.  POB 704, Yorktown Heights, NY 10598.  Israel.  
Affiliation: Dept. of Computer Science, Technion, Haifa,  IBM T. J. Watson Research Center,  Computer Science Dept., Technion, Israel Dept. of Computer Science, Technion, Haifa,  
Date: January 3, 1994  
Abstract: We present a quantitative approach to the analysis of dynamic network protocols. Dynamic networks, extensively studied in the last decade, are asynchronous communication networks in which links repeatedly fail and recover. Loosely speaking, we quantify the reliability of a link at a given moment as the time since the link last recovered. This corresponds to the intuition that a link is `useful' only after some `warming up' period since it recovered. To compare the quantitative approach to the existing (qualitative) approaches, we consider the broadcast task, used extensively in actual networks. The existing formulations of broadcast seem too difficult for dynamic networks. In particular, protocols with bounded storage must have unbounded time complexity. Our quantitative formulation of broadcast seems to be closer to the realistic requirements, and escapes such difficulties. We present a protocol for the quantitative formulation of broadcast. Namely, this broadcast protocol operates in networks which satisfy a weak, quantified reliability assumption. The protocol is efficient, with linear message complexity and high throughput. fl This work was partially supported by the Fund for the Promotion of Research in the Technion. This manuscript continues and improves our work in PODC 90. 
Abstract-found: 1
Intro-found: 1
Reference: [AAG87] <author> Yehuda Afek, Baruch Awerbuch, and Eli Gafni. </author> <title> Applying static network protocols to dynamic networks. </title> <booktitle> In 28 th Annual Symposium on Foundations of Computer Science. IEEE, </booktitle> <month> October </month> <year> 1987. </year>
Reference-contexts: There are many factors to consider, and these factors interact in a complex manner. In particular, the delays and failures involved in the transmission of information through the network are critical factors which are difficult to deal with. In this paper we investigate dynamic networks <ref> [AAG87, AE86] </ref>, where the communication is asynchronous and where links may fail and recover. Most works about dynamic networks assume some `reliability', in order to avoid banal impossibilities due to extreme unreliability. For example, we wish to exclude the absurd scenario where all links are always faulty. <p> Most theoretical works on dynamic networks use either the `eventual connectivity' assumption or the `eventual stability' assumption (see x1.1). Each of these assumptions is the weakest sufficient assumption for an important and general class of tasks. In <ref> [AAG87, Fin79] </ref> it was shown that `eventual stability' is sufficient for tasks whose output depends on the topology of the network. In [AG91, AE86, AMS89, Vis83] it was shown that `eventual connectivity' is sufficient for tasks whose output is independent of the topology. <p> Section 5 contains enhancements to the simplified protocol, yielding the final version, which achieves bounded storage and optimal (fi (1)) throughput. broad:def update:July 15, 1993 L a T E X:August 26, 1996 11 2 Definitions 2.1 The Dynamic Networks Model We consider the dynamic network model of <ref> [AAG87, AE86, BS88] </ref>. The network is represented by an undirected graph, with n vertices corresponding to the processors and m edges corresponding to communication links between some pairs of processors (neighbors). <p> However, the processors know 2 n and each processor has a distinct identity. The model is asynchronous in that the processors do not have clocks and the delays are finite but unbounded. Hence, some events are concurrent, and events are only partially ordered. Like previous authors <ref> [AAG87, AE86, BS88, GHS83] </ref>, we find it easier to consider a total order between events. This total order should be interpreted as an arbitrary extension of the actual partial order. This extension is unknown to the processors, and our results hold for any such extension. <p> This extension is unknown to the processors, and our results hold for any such extension. It is possible to obtain equivalent results without assuming total order (see [AGH90b]). We now make a further important simplification, again following <ref> [AAG87, AE86, BS88, GHS83] </ref>. Namely, we associate a positive number time (e) with each event e. The number time (e) represents the `normalized time' of event e. The time is `normalized' in the sense that for complexity analysis purposes, one time unit is defined as the maximal transmission delay. <p> We use the natural notions of a link being up or down at a processor, and of an up interval, following <ref> [AAG87, AE86, BS88] </ref>. Messages are sent and received only when the link is up. <p> This implies the simplified form C (n; m; a; f; r) = f C (n; m; a), broad:def update:July 15, 1993 L a T E X:August 26, 1996 19 where C is the amortized communication complexity <ref> [AAG87] </ref>. Expressing the communication complexity in this way is justified when the actual communication is indeed linear in the number of failures. This is indeed the case in many of these works, where every failure or recovery may cause the protocol to restart operating from the beginning. <p> This is indeed the case in many of these works, where every failure or recovery may cause the protocol to restart operating from the beginning. Many eventual-stability protocols work in this `blast-away' technique [Gal76], [Fin79], [Seg83], <ref> [AAG87] </ref>. However, the `blast-away' technique is wasteful; it is desirable, and often possible, to recover from a failure at a cost much smaller than restarting the task. In particular, our protocol recovers from failures with a small fixed cost, independent of the number of broadcasts done so far. <p> important to bound the maximal time since a message is accepted from the higher layer, at the source, and until it is delivered to the higher layer at the last processor. 2.4.6 Space Complexity We use the standard measure of space complexity used in most works dealing with dynamic networks <ref> [AAG87, AE86] </ref>.
Reference: [ACK90] <author> Baruch Awerbuch, Israel Cidon, and Shay Kutten. </author> <title> Optimal maintenance of replicated information. </title> <booktitle> In Proc. 31 st Symp. on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: In particular, our protocol recovers from failures with a small fixed cost, independent of the number of broadcasts done so far. There have been several previous works which featured a smaller cost per recovery than the `blast-away' approach <ref> [ACK90] </ref>, [Awe88], [AS88],[BGS88], [MS79],[SS81]. We therefore propose another simplified form for the communication complexity. This communication complexity consists of fixed cost per each accept, failure and recovery event. The cost depends on the kind of the event.
Reference: [ADLS90] <author> Hagit Attiya, Cynthia Dwork, Nancy Lynch, and Larry Stock-meyer. </author> <title> Bounds on the time to reach agreement in the presence of timing uncertainty. </title> <booktitle> In STOC 1991, </booktitle> <year> 1990. </year>
Reference-contexts: We now define our model of an execution, called a timed dynamic execution. Where no ambiguity may arise, we sometimes say simply execution, meaning a timed dynamic execution. This definition is simplified, e.g. by ignoring local processing. For a more precise definition, see <ref> [ADLS90] </ref>. broad:def update:July 15, 1993 L a T E X:August 26, 1996 14 Definition 3 An algorithm is a mapping from a state and a set of input events to a (new) state and a set of output events.
Reference: [AE86] <author> Baruch Awerbuch and Shimon Even. </author> <title> Reliable broadcast protocols in unreliable networks. </title> <journal> Networks, </journal> <volume> 16(4) </volume> <pages> 381-396, </pages> <month> Winter </month> <year> 1986. </year>
Reference-contexts: There are many factors to consider, and these factors interact in a complex manner. In particular, the delays and failures involved in the transmission of information through the network are critical factors which are difficult to deal with. In this paper we investigate dynamic networks <ref> [AAG87, AE86] </ref>, where the communication is asynchronous and where links may fail and recover. Most works about dynamic networks assume some `reliability', in order to avoid banal impossibilities due to extreme unreliability. For example, we wish to exclude the absurd scenario where all links are always faulty. <p> Each of these assumptions is the weakest sufficient assumption for an important and general class of tasks. In [AAG87, Fin79] it was shown that `eventual stability' is sufficient for tasks whose output depends on the topology of the network. In <ref> [AG91, AE86, AMS89, Vis83] </ref> it was shown that `eventual connectivity' is sufficient for tasks whose output is independent of the topology. <p> This, of course, is not meant literally, but it is rather assumed that from that moment on, an entire execution of the protocol can be completed within a period containing no new failures. In the eventual-connectivity approach <ref> [AG91, AE86, AMS89, Vis83] </ref>, the only restriction on the nature of failures is that they do not disconnect the network forever. Both approaches are elegant and gave rise to interesting research problems and important techniques. However, there are severe limitations to the application of these approaches to actual networks. <p> Every broadcast message must be stored in the network until this processor reconnects. If the source bounds the number of messages broadcasted until the processor reconnects, then the throughput may be arbitrarily small. Hence, assuming only eventual connectivity, broadcast with high throughput requires unbounded storage. Indeed, the solution of <ref> [AE86] </ref> uses unbounded storage. <p> The Intelligent Flood protocol [Per83, Seg83] require unbounded 1 storage, both due to `infinite counters' and to unbounded link capacity requirements. Our protocol is almost as simple as these `classical' protocols, especially the version for static networks presented in x3.1. The known fault-tolerant broadcast protocols <ref> [AE86] </ref> are variations of the Flood protocol, and also require unbounded storage. We develop and analyse the protocol in a modular manner. We begin with a simple version, which has poor throughput and unbounded storage. <p> Section 5 contains enhancements to the simplified protocol, yielding the final version, which achieves bounded storage and optimal (fi (1)) throughput. broad:def update:July 15, 1993 L a T E X:August 26, 1996 11 2 Definitions 2.1 The Dynamic Networks Model We consider the dynamic network model of <ref> [AAG87, AE86, BS88] </ref>. The network is represented by an undirected graph, with n vertices corresponding to the processors and m edges corresponding to communication links between some pairs of processors (neighbors). <p> However, the processors know 2 n and each processor has a distinct identity. The model is asynchronous in that the processors do not have clocks and the delays are finite but unbounded. Hence, some events are concurrent, and events are only partially ordered. Like previous authors <ref> [AAG87, AE86, BS88, GHS83] </ref>, we find it easier to consider a total order between events. This total order should be interpreted as an arbitrary extension of the actual partial order. This extension is unknown to the processors, and our results hold for any such extension. <p> This extension is unknown to the processors, and our results hold for any such extension. It is possible to obtain equivalent results without assuming total order (see [AGH90b]). We now make a further important simplification, again following <ref> [AAG87, AE86, BS88, GHS83] </ref>. Namely, we associate a positive number time (e) with each event e. The number time (e) represents the `normalized time' of event e. The time is `normalized' in the sense that for complexity analysis purposes, one time unit is defined as the maximal transmission delay. <p> We use the natural notions of a link being up or down at a processor, and of an up interval, following <ref> [AAG87, AE86, BS88] </ref>. Messages are sent and received only when the link is up. <p> This is natural in protocols where each packet sent may be easily associated with a single corresponding message, as in most protocols using infinite counters, e.g. <ref> [AE86] </ref>, [JBS86]. However, in many works the same packet may serve several accept events. In fact, many protocols improve complexities by performing some tasks periodically, instead of doing them for each message, thereby amortizing their costs over many messages. <p> important to bound the maximal time since a message is accepted from the higher layer, at the source, and until it is delivered to the higher layer at the last processor. 2.4.6 Space Complexity We use the standard measure of space complexity used in most works dealing with dynamic networks <ref> [AAG87, AE86] </ref>. <p> High congestion may be caused, for example, by the Intelligent Flood protocol and its variants <ref> [Per83, Seg83, AE86] </ref>, since the source may issue messages much faster than some links can transfer them. Hence, these messages must be stored in the source (resulting in unbounded space complexity) or in the links (resulting in unbounded link concurrency). <p> It is trivial to achieve either synchronization or progress; the difficulty is to achieve both properties together. Synchronization alone is trivially achieved, for example, if no messages are delivered, or by the PIF protocol. Progress alone is achieved by the intelligent flood protocol <ref> [AE86, Per83, Seg83] </ref>. We begin by presenting a weak progress property, that does not use the flood mechanism.
Reference: [AG91] <author> Yehuda Afek and Eli Gafni. </author> <title> Bootstrap network resynchroniza-tion. </title> <booktitle> In Proceedings of the 10 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Montreal, Quebec, Canada, </address> <pages> pages 295-307. </pages> <booktitle> ACM SIGACT and SIGOPS, ACM, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Each of these assumptions is the weakest sufficient assumption for an important and general class of tasks. In [AAG87, Fin79] it was shown that `eventual stability' is sufficient for tasks whose output depends on the topology of the network. In <ref> [AG91, AE86, AMS89, Vis83] </ref> it was shown that `eventual connectivity' is sufficient for tasks whose output is independent of the topology. <p> This, of course, is not meant literally, but it is rather assumed that from that moment on, an entire execution of the protocol can be completed within a period containing no new failures. In the eventual-connectivity approach <ref> [AG91, AE86, AMS89, Vis83] </ref>, the only restriction on the nature of failures is that they do not disconnect the network forever. Both approaches are elegant and gave rise to interesting research problems and important techniques. However, there are severe limitations to the application of these approaches to actual networks. <p> It seems desirable to reflect such `bursty' intervals, i.e. the congestion caused by the protocol, in a refined measure of communication complexity. In particular, there seems no apparent reason for considering only prefixes of the execution and not any interval. Possibly with this motivation, the communication complexity of <ref> [AG91, AMS89] </ref> is defined as the maximal number of packet transmissions between two accept events. Namely, [AG91, AMS89] measure the number of packet transmissions in intervals with exactly one accept event, instead of amortizing the ratio of sends to accepts over prefixes of the execution. <p> In particular, there seems no apparent reason for considering only prefixes of the execution and not any interval. Possibly with this motivation, the communication complexity of <ref> [AG91, AMS89] </ref> is defined as the maximal number of packet transmissions between two accept events. Namely, [AG91, AMS89] measure the number of packet transmissions in intervals with exactly one accept event, instead of amortizing the ratio of sends to accepts over prefixes of the execution. Therefore, a protocol with low complexity as defined in [AG91, AMS89] would not cause congestion by `bursty' intervals. <p> Namely, <ref> [AG91, AMS89] </ref> measure the number of packet transmissions in intervals with exactly one accept event, instead of amortizing the ratio of sends to accepts over prefixes of the execution. Therefore, a protocol with low complexity as defined in [AG91, AMS89] would not cause congestion by `bursty' intervals. However, we believe that in most realistic scenarios, performing some tasks periodically, once for several messages, is useful and would not cause congestion. Unfortunately, the measure of [AMS89] does not amortize such periodic tasks at all. <p> As a result, this measure seems to be artificially high for many protocols that do not cause congestion in practice. For example, under this measure, the communication complexity of the Intelligent Flood protocol is O (nm) instead of O (m) when amortization is for prefixes <ref> [AG91] </ref>. We therefore propose a new complexity measure. Our goal is to identify the `bursty' congestion caused by some protocols, but to allow some amortization and pipeline operation. Instead of defining the amortization intervals explicitly, we define the communication complexity with respect to a given predicate P (ff; t; l).
Reference: [AGH90a] <author> Baruch Awerbuch, Oded Goldreich, and Amir Herzberg. </author> <title> A quantitative approach to dynamic networks. </title> <booktitle> In Proceedings of the 9 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 189-204, </pages> <month> August </month> <year> 1990. </year> <title> broad:end update:Feb 2, 1994 L a T E X:August 26, </title> <year> 1996 </year> <month> 63 </month>
Reference-contexts: The `sufficient up' amount required from the links may change from protocol to protocol. For example, in this exposition we present a broadcast protocol that requires less reliability than the protocols in an earlier version <ref> [AGH90a] </ref>. Hence, we may quantitatively compare the reliability requirements of different protocols. It is plausible that there will be tradeoffs between the reliability requirements and the efficiency of protocols. <p> However, in many works the same packet may serve several accept events. In fact, many protocols improve complexities by performing some tasks periodically, instead of doing them for each message, thereby amortizing their costs over many messages. For example, in <ref> [AGH90a] </ref> we suggested an end-to-end protocol which transmitted an exponential number of packets for a `clean-up' task which was performed once per an exponentially long period of time. <p> Another challenge is to apply the quantitative approach to additional tasks. In [Her91] we have briefly discussed how the protocol presented in this paper may be adapted to end to end communication and to implement a fault-tolerant synchronizer. In [Her92] we used the quantitative approach 5 The construction of <ref> [AGH90a] </ref> does not require that the entire network would be reliable, and allowed crashes. However, a full proof did not appear. broad:end update:Feb 2, 1994 L a T E X:August 26, 1996 62 to analyze and improve connection-based communication schemes. <p> However, a full proof did not appear. broad:end update:Feb 2, 1994 L a T E X:August 26, 1996 62 to analyze and improve connection-based communication schemes. Acknowledgments We thank Baruch Awerbuch for collaborating with us in earlier stages of this research <ref> [AGH90a] </ref>. Special thanks to Hagit Attiya, who made a substantial contribution to the present definitions of reliability, and for other encouraging and helpful remarks. We thank Shimon Even for discussing shortcomings of the eventual stability approach, and thereby planting the seeds of the quantitative approach.
Reference: [AGH90b] <author> Baruch Awerbuch, Oded Goldreich, and Amir Herzberg. </author> <title> A quantitative approach to dynamic networks (version without global time). </title> <type> Technical Report 624, </type> <institution> Computer Science Dept., Technion, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: This total order should be interpreted as an arbitrary extension of the actual partial order. This extension is unknown to the processors, and our results hold for any such extension. It is possible to obtain equivalent results without assuming total order (see <ref> [AGH90b] </ref>). We now make a further important simplification, again following [AAG87, AE86, BS88, GHS83]. Namely, we associate a positive number time (e) with each event e. The number time (e) represents the `normalized time' of event e. <p> In particular, the processors are not aware of the `time' of events during the execution. Hence, the model remains completely asynchronous. Namely, associating time to events simplifies the formalization, but is not essential (see again <ref> [AGH90b] </ref>). We consider send, receive, fail and recover events, each referring to a specific processor and link of that processor and having the natural meanings. The send event is an output event; the other events are input events. Additional task specific events are described in subsection 2.3.
Reference: [AMS89] <author> Baruch Awerbuch, Yishay Mansour, and Nir Shavit. </author> <title> Polynomial end-to-end communication. </title> <booktitle> In Proc. of the 30th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 358-363, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Each of these assumptions is the weakest sufficient assumption for an important and general class of tasks. In [AAG87, Fin79] it was shown that `eventual stability' is sufficient for tasks whose output depends on the topology of the network. In <ref> [AG91, AE86, AMS89, Vis83] </ref> it was shown that `eventual connectivity' is sufficient for tasks whose output is independent of the topology. <p> This, of course, is not meant literally, but it is rather assumed that from that moment on, an entire execution of the protocol can be completed within a period containing no new failures. In the eventual-connectivity approach <ref> [AG91, AE86, AMS89, Vis83] </ref>, the only restriction on the nature of failures is that they do not disconnect the network forever. Both approaches are elegant and gave rise to interesting research problems and important techniques. However, there are severe limitations to the application of these approaches to actual networks. <p> This requires an entire path to be up simultaneously for some time, which is obviously stronger than requiring eventual connectivity. Awerbuch et al. <ref> [AMS89] </ref> observed, that if the failure probability of each individual link is constant, then the "failure probability" of the path becomes exponentially close to 1 as a function of the length of the path. They conclude that the requirement that the entire path is up is too strong. <p> Theory: the analysis where the failure probability is constant and only the length of the path grows is misleading. It is reasonable to expect that as networks grow, processors would be connected mostly by links which are highly reliable. It is easy to see that the analysis of <ref> [AMS89] </ref> fails, for example, if the failure probability of each link is inversely proportional to the length of the path. <p> It seems desirable to reflect such `bursty' intervals, i.e. the congestion caused by the protocol, in a refined measure of communication complexity. In particular, there seems no apparent reason for considering only prefixes of the execution and not any interval. Possibly with this motivation, the communication complexity of <ref> [AG91, AMS89] </ref> is defined as the maximal number of packet transmissions between two accept events. Namely, [AG91, AMS89] measure the number of packet transmissions in intervals with exactly one accept event, instead of amortizing the ratio of sends to accepts over prefixes of the execution. <p> In particular, there seems no apparent reason for considering only prefixes of the execution and not any interval. Possibly with this motivation, the communication complexity of <ref> [AG91, AMS89] </ref> is defined as the maximal number of packet transmissions between two accept events. Namely, [AG91, AMS89] measure the number of packet transmissions in intervals with exactly one accept event, instead of amortizing the ratio of sends to accepts over prefixes of the execution. Therefore, a protocol with low complexity as defined in [AG91, AMS89] would not cause congestion by `bursty' intervals. <p> Namely, <ref> [AG91, AMS89] </ref> measure the number of packet transmissions in intervals with exactly one accept event, instead of amortizing the ratio of sends to accepts over prefixes of the execution. Therefore, a protocol with low complexity as defined in [AG91, AMS89] would not cause congestion by `bursty' intervals. However, we believe that in most realistic scenarios, performing some tasks periodically, once for several messages, is useful and would not cause congestion. Unfortunately, the measure of [AMS89] does not amortize such periodic tasks at all. <p> Therefore, a protocol with low complexity as defined in [AG91, AMS89] would not cause congestion by `bursty' intervals. However, we believe that in most realistic scenarios, performing some tasks periodically, once for several messages, is useful and would not cause congestion. Unfortunately, the measure of <ref> [AMS89] </ref> does not amortize such periodic tasks at all. Furthermore, even a protocol which transmits the same number of packets for each message may have higher complexity with the measure of [AMS89], if it may transmit packets due to a message even after accepting a new message (pipeline). <p> Unfortunately, the measure of <ref> [AMS89] </ref> does not amortize such periodic tasks at all. Furthermore, even a protocol which transmits the same number of packets for each message may have higher complexity with the measure of [AMS89], if it may transmit packets due to a message even after accepting a new message (pipeline). As a result, this measure seems to be artificially high for many protocols that do not cause congestion in practice.
Reference: [AS88] <author> Baruch Awerbuch and Michael Sipser. </author> <title> Dynamic networks are as fast as static networks. </title> <booktitle> In 29 th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 206-220. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1988. </year>
Reference: [Awe85] <author> Baruch Awerbuch. </author> <title> Complexity of network synchronization. </title> <journal> J. ACM, </journal> <volume> 32(4) </volume> <pages> 804-823, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: Our protocol prevents high congestion by limiting the number of messages in transit over any link. This is achieved by synchronizing between each pair of neighbors. This synchronization resembles synchronizer ff of <ref> [Awe85] </ref> and the minimal hop protocol of [Gal76, Seg83]. In the rest of this subsection we informally describe this synchronization mechanism, which is the core of the protocol, and suffices for operation in static networks.
Reference: [Awe88] <author> Baruch Awerbuch. </author> <title> On the effect of feedback in dynamic network protocols. </title> <booktitle> In Proc. 29th IEEE Symp. on Foundation of Computer Science, </booktitle> <pages> pages 231-245, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: In particular, our protocol recovers from failures with a small fixed cost, independent of the number of broadcasts done so far. There have been several previous works which featured a smaller cost per recovery than the `blast-away' approach [ACK90], <ref> [Awe88] </ref>, [AS88],[BGS88], [MS79],[SS81]. We therefore propose another simplified form for the communication complexity. This communication complexity consists of fixed cost per each accept, failure and recovery event. The cost depends on the kind of the event.
Reference: [BGG + 85] <author> A. E. Baratz, J. P. Gray, P. E. Green Jr., J. M. Jaffe, and D. P. Pozefsky. </author> <title> SNA networks of small systems. </title> <journal> IEEE Journal on Selected Areas in Comm., </journal> <volume> SAC-3(3):416-426, </volume> <month> May </month> <year> 1985. </year>
Reference-contexts: Networks are designed with sufficient redundancy (alternative paths) so that it is easy to ensure reliable communication. Accordingly, protocols employed in actual networks usually make strong reliability assumptions <ref> [BGG + 85, LR90, Per83, Her92] </ref>. These `practical' protocols are simple and efficient. In particular, these protocols do not wait for `eventual' conditions, and in this sense are more efficient than the best possible solutions under the `eventual connectivity' or `eventual stability' assumptions. <p> They conclude that the requirement that the entire path is up is too strong. We disagree with this conclusion, for both practical and theoretical considerations: Practice: Actual networks <ref> [BGG + 85, LR90] </ref> are designed and implemented so that the probability of a failure along a path is quite small. As a result, many networks use only a small number of the possible alternative paths between each two processors [LR90]. <p> These networks still operate successfully and are considered fault-tolerant, since the probability that there will be a failure in several disjoint paths at about the same time is negligible. Also, many networks perform end-to-end communication by sending messages over a single, efficient path connecting the two end stations <ref> [Her92, BGG + 85] </ref>. Furthermore, it seems that the technological improvements in link reliability are growing faster than the growth of the networks. Theory: the analysis where the failure probability is constant and only the length of the path grows is misleading.
Reference: [BGS88] <author> Alan E. Baratz, Inder Gopal, and Adrian Segall. </author> <title> Fault tolerant queries in computer networks. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Distributed Algorithms: Second International Workshop. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1988. </year> <note> Lecure notes in computer science number 312. </note>
Reference: [BS88] <author> Alan E. Baratz and Adrian Segall. </author> <title> Reliable link initialization procedures. </title> <journal> IEEE Trans. on Communication, </journal> <volume> COM-36:144-152, </volume> <month> February </month> <year> 1988. </year>
Reference-contexts: Section 5 contains enhancements to the simplified protocol, yielding the final version, which achieves bounded storage and optimal (fi (1)) throughput. broad:def update:July 15, 1993 L a T E X:August 26, 1996 11 2 Definitions 2.1 The Dynamic Networks Model We consider the dynamic network model of <ref> [AAG87, AE86, BS88] </ref>. The network is represented by an undirected graph, with n vertices corresponding to the processors and m edges corresponding to communication links between some pairs of processors (neighbors). <p> However, the processors know 2 n and each processor has a distinct identity. The model is asynchronous in that the processors do not have clocks and the delays are finite but unbounded. Hence, some events are concurrent, and events are only partially ordered. Like previous authors <ref> [AAG87, AE86, BS88, GHS83] </ref>, we find it easier to consider a total order between events. This total order should be interpreted as an arbitrary extension of the actual partial order. This extension is unknown to the processors, and our results hold for any such extension. <p> This extension is unknown to the processors, and our results hold for any such extension. It is possible to obtain equivalent results without assuming total order (see [AGH90b]). We now make a further important simplification, again following <ref> [AAG87, AE86, BS88, GHS83] </ref>. Namely, we associate a positive number time (e) with each event e. The number time (e) represents the `normalized time' of event e. The time is `normalized' in the sense that for complexity analysis purposes, one time unit is defined as the maximal transmission delay. <p> We use the natural notions of a link being up or down at a processor, and of an up interval, following <ref> [AAG87, AE86, BS88] </ref>. Messages are sent and received only when the link is up. <p> We assume that the events satisfy DLC ( Data Link Control) reliability. This is guaranteed by using a reliable DLC procedure as a lower layer on all links. DLC reliability is defined in <ref> [BS88, GS92] </ref>, and is restated below in Definition 2. Normally, the DLC procedure ensures that all packets sent are received at the other end of the link, in the correct sequence.
Reference: [Cha82] <author> Ernest J. H. Chang. </author> <title> Echo algorithms: Depth parallel operations on general graphs. </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 8(4) </volume> <pages> 391-401, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: In fact, by combining high throughput with bounded (O (n)) storage, our protocol improves upon the known, `classical' broadcast protocols, Echo, PIF and Intelligent Flood, used in many actual networks. (Details follow.) Furthermore, these classical protocols work only for static asynchronous networks. The Echo and PIF protocols <ref> [Cha82, DS80, Seg83] </ref> have lower throughput. <p> On one hand, the protocol should have high throughput (rate). To achieve this, the source does not wait for network-wide progress, before enabling a new accept event. Instead, the source waits only for progress of its immediate neighbors. This should be contrasted with the Echo and PIF protocols <ref> [DS80, Cha82, MRR80, Seg83] </ref>, that wait before accepting a new message until an entire spanning tree converges. broad:prot update:January 3, 1994 L a T E X:August 26, 1996 24 On the other hand, the protocol should not cause high congestion on links.
Reference: [CR87] <author> Israel Cidon and Raphael Rom. </author> <title> Failsafe end-to-end protocols in computer networks with changing topology. </title> <journal> IEEE Trans. Comm., </journal> <volume> COM-35(4):410-413, </volume> <month> April </month> <year> 1987. </year> <title> broad:end update:Feb 2, 1994 L a T E X:August 26, </title> <year> 1996 </year> <month> 64 </month>
Reference-contexts: This rate is limited by the capacity of the network and by the time that it takes the protocol to remove messages from the network. Throughput, in this sense, is a very practical measure. For example, the advantage of <ref> [CR87] </ref> over [Fin79] is exactly in improving the throughput. However, it is difficult to define the throughput since it cannot be measured for a single message accepted. As stated above, throughput is related to the average time used to broadcast messages over the number of messages. <p> This definition seems to formalize practical notions of the throughput of protocols. In particular, this definition allows to analyse the advantage of window mechanisms. Such mechanisms are used, to enhance throughput, in many protocols, e.g. <ref> [CR87] </ref>. In fact, we also improve the throughput of our protocol by using a window mechanism. 2.4.3 Predicate defined by length of interval. Typically, and in this work, the predicate P of definitions 9, 10 and 12 would be the length of the interval in time units.
Reference: [DS80] <author> W. Dijkstra and C. S. Scholten. </author> <title> Termination detection for diffusing computations. </title> <journal> Information Processing Letters, </journal> <volume> 11(1) </volume> <pages> 1-4, </pages> <month> August </month> <year> 1980. </year>
Reference-contexts: In fact, by combining high throughput with bounded (O (n)) storage, our protocol improves upon the known, `classical' broadcast protocols, Echo, PIF and Intelligent Flood, used in many actual networks. (Details follow.) Furthermore, these classical protocols work only for static asynchronous networks. The Echo and PIF protocols <ref> [Cha82, DS80, Seg83] </ref> have lower throughput. <p> On one hand, the protocol should have high throughput (rate). To achieve this, the source does not wait for network-wide progress, before enabling a new accept event. Instead, the source waits only for progress of its immediate neighbors. This should be contrasted with the Echo and PIF protocols <ref> [DS80, Cha82, MRR80, Seg83] </ref>, that wait before accepting a new message until an entire spanning tree converges. broad:prot update:January 3, 1994 L a T E X:August 26, 1996 24 On the other hand, the protocol should not cause high congestion on links.
Reference: [Fin79] <author> S. G. Finn. </author> <title> Resynch procedures and a failsafe network protocol. </title> <journal> IEEE Tran. Comm., </journal> <volume> COM-27(6):840-846, </volume> <month> June </month> <year> 1979. </year>
Reference-contexts: Most theoretical works on dynamic networks use either the `eventual connectivity' assumption or the `eventual stability' assumption (see x1.1). Each of these assumptions is the weakest sufficient assumption for an important and general class of tasks. In <ref> [AAG87, Fin79] </ref> it was shown that `eventual stability' is sufficient for tasks whose output depends on the topology of the network. In [AG91, AE86, AMS89, Vis83] it was shown that `eventual connectivity' is sufficient for tasks whose output is independent of the topology. <p> This rate is limited by the capacity of the network and by the time that it takes the protocol to remove messages from the network. Throughput, in this sense, is a very practical measure. For example, the advantage of [CR87] over <ref> [Fin79] </ref> is exactly in improving the throughput. However, it is difficult to define the throughput since it cannot be measured for a single message accepted. As stated above, throughput is related to the average time used to broadcast messages over the number of messages. <p> This is indeed the case in many of these works, where every failure or recovery may cause the protocol to restart operating from the beginning. Many eventual-stability protocols work in this `blast-away' technique [Gal76], <ref> [Fin79] </ref>, [Seg83], [AAG87]. However, the `blast-away' technique is wasteful; it is desirable, and often possible, to recover from a failure at a cost much smaller than restarting the task. In particular, our protocol recovers from failures with a small fixed cost, independent of the number of broadcasts done so far.
Reference: [Gal76] <author> Robert G. Gallager. </author> <title> A shortest path routing algorithm with automatic resynch. unpublished note, </title> <month> March </month> <year> 1976. </year>
Reference-contexts: This is indeed the case in many of these works, where every failure or recovery may cause the protocol to restart operating from the beginning. Many eventual-stability protocols work in this `blast-away' technique <ref> [Gal76] </ref>, [Fin79], [Seg83], [AAG87]. However, the `blast-away' technique is wasteful; it is desirable, and often possible, to recover from a failure at a cost much smaller than restarting the task. <p> Our protocol prevents high congestion by limiting the number of messages in transit over any link. This is achieved by synchronizing between each pair of neighbors. This synchronization resembles synchronizer ff of [Awe85] and the minimal hop protocol of <ref> [Gal76, Seg83] </ref>. In the rest of this subsection we informally describe this synchronization mechanism, which is the core of the protocol, and suffices for operation in static networks. In the code, appearing in Figs. 8-11, the lines which implement this mechanism are marked by S in the right margin.
Reference: [GHS83] <author> Robert G. Gallager, Pierre A. Humblet, and P. M. Spira. </author> <title> A distributed algorithm for minimum-weight spanning trees. </title> <journal> ACM Trans. Prog. Lang. and Syst., </journal> <volume> 5(1) </volume> <pages> 66-77, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: However, the processors know 2 n and each processor has a distinct identity. The model is asynchronous in that the processors do not have clocks and the delays are finite but unbounded. Hence, some events are concurrent, and events are only partially ordered. Like previous authors <ref> [AAG87, AE86, BS88, GHS83] </ref>, we find it easier to consider a total order between events. This total order should be interpreted as an arbitrary extension of the actual partial order. This extension is unknown to the processors, and our results hold for any such extension. <p> This extension is unknown to the processors, and our results hold for any such extension. It is possible to obtain equivalent results without assuming total order (see [AGH90b]). We now make a further important simplification, again following <ref> [AAG87, AE86, BS88, GHS83] </ref>. Namely, we associate a positive number time (e) with each event e. The number time (e) represents the `normalized time' of event e. The time is `normalized' in the sense that for complexity analysis purposes, one time unit is defined as the maximal transmission delay.
Reference: [GS92] <author> George Grover and Adrian Segall. </author> <title> A full duplex dlc protocol on two links. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-40(1):210-223, </volume> <month> January </month> <year> 1992. </year>
Reference-contexts: We assume that the events satisfy DLC ( Data Link Control) reliability. This is guaranteed by using a reliable DLC procedure as a lower layer on all links. DLC reliability is defined in <ref> [BS88, GS92] </ref>, and is restated below in Definition 2. Normally, the DLC procedure ensures that all packets sent are received at the other end of the link, in the correct sequence.
Reference: [Her88] <author> Amir Herzberg. </author> <title> Network management in the presence of faults. </title> <booktitle> In Ninth International Conference on Computers and Communication (ICCC), </booktitle> <month> October </month> <year> 1988. </year> <note> Updated version: `Early Termination in Unreliable Communication Networks' is technical report TR-650 of computer science dept., </note> <institution> Technion, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: Is it possible to solve 5 such problems, using bounded resources, and allowing cuts in the network, or processor crashes? Also, it is interesting to try to combine the approach of this work with a more realistic approach to time complexity which permits `timeouts' such as suggested in <ref> [Her88, HK89] </ref>. The broadcast task addressed in this work is closely related to practical broadcast and multicast problems of audio and video data streams, such as video-conferencing and radio/video broadcasts over computer networks.
Reference: [Her91] <author> Amir Herzberg. </author> <title> Communication Networks in the Presence of Faults. </title> <type> PhD thesis, </type> <institution> Computer Science Faculty, Technion, Israel, </institution> <year> 1991. </year> <note> In Hebrew. </note>
Reference-contexts: This could be very helpful in some realistic scenarios, where specific links or gateways may be temporary congested; a protocol which allows redundant connectivity (cycles) may be able to route around the congested areas. Another challenge is to apply the quantitative approach to additional tasks. In <ref> [Her91] </ref> we have briefly discussed how the protocol presented in this paper may be adapted to end to end communication and to implement a fault-tolerant synchronizer.
Reference: [Her92] <author> Amir Herzberg. </author> <title> Connection-based communication in dynamic networks. </title> <booktitle> In Proceedings of the Eleventh Annual ACM Symposium on Principles of Distributed Computing (PODC), </booktitle> <pages> pages 13-24, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Networks are designed with sufficient redundancy (alternative paths) so that it is easy to ensure reliable communication. Accordingly, protocols employed in actual networks usually make strong reliability assumptions <ref> [BGG + 85, LR90, Per83, Her92] </ref>. These `practical' protocols are simple and efficient. In particular, these protocols do not wait for `eventual' conditions, and in this sense are more efficient than the best possible solutions under the `eventual connectivity' or `eventual stability' assumptions. <p> These networks still operate successfully and are considered fault-tolerant, since the probability that there will be a failure in several disjoint paths at about the same time is negligible. Also, many networks perform end-to-end communication by sending messages over a single, efficient path connecting the two end stations <ref> [Her92, BGG + 85] </ref>. Furthermore, it seems that the technological improvements in link reliability are growing faster than the growth of the networks. Theory: the analysis where the failure probability is constant and only the length of the path grows is misleading. <p> Another challenge is to apply the quantitative approach to additional tasks. In [Her91] we have briefly discussed how the protocol presented in this paper may be adapted to end to end communication and to implement a fault-tolerant synchronizer. In <ref> [Her92] </ref> we used the quantitative approach 5 The construction of [AGH90a] does not require that the entire network would be reliable, and allowed crashes. However, a full proof did not appear. broad:end update:Feb 2, 1994 L a T E X:August 26, 1996 62 to analyze and improve connection-based communication schemes.
Reference: [HK89] <author> Amir Herzberg and Shay Kutten. </author> <title> Efficient detection of message forwarding faults. </title> <booktitle> In Proceedings of the 8 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 339-353, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Is it possible to solve 5 such problems, using bounded resources, and allowing cuts in the network, or processor crashes? Also, it is interesting to try to combine the approach of this work with a more realistic approach to time complexity which permits `timeouts' such as suggested in <ref> [Her88, HK89] </ref>. The broadcast task addressed in this work is closely related to practical broadcast and multicast problems of audio and video data streams, such as video-conferencing and radio/video broadcasts over computer networks.
Reference: [JBS86] <author> Jeff Jaffe, Alan E. Baratz, and Adrian Segall. </author> <title> Subtle design issues in the implementation of distributed dynamic routing algorithms. </title> <journal> Computer networks and ISDN systems, </journal> <volume> 12(3) </volume> <pages> 147-158, </pages> <year> 1986. </year> <title> broad:end update:Feb 2, 1994 L a T E X:August 26, </title> <year> 1996 </year> <month> 65 </month>
Reference-contexts: This is natural in protocols where each packet sent may be easily associated with a single corresponding message, as in most protocols using infinite counters, e.g. [AE86], <ref> [JBS86] </ref>. However, in many works the same packet may serve several accept events. In fact, many protocols improve complexities by performing some tasks periodically, instead of doing them for each message, thereby amortizing their costs over many messages. <p> Updating is needed if processor v received broad:prot update:January 3, 1994 L a T E X:August 26, 1996 26 more messages than u, and in this case processor v sends to u the messages that u may have not received yet. This updating action is a standard practice <ref> [MRR80, Per83, JBS86] </ref>. Our protocol requires precise synchronization between the messages delivered by two neighbors connected by a 3nUp link. The update operation cannot achieve such precise synchronization; in particular, it does not prevent v from delivering more messages.
Reference: [LR90] <author> K. Lougheed and Yacov Rekhter. </author> <title> A border gateway protocol. Internet RFC 1163, </title> <institution> Network Working Group, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: Networks are designed with sufficient redundancy (alternative paths) so that it is easy to ensure reliable communication. Accordingly, protocols employed in actual networks usually make strong reliability assumptions <ref> [BGG + 85, LR90, Per83, Her92] </ref>. These `practical' protocols are simple and efficient. In particular, these protocols do not wait for `eventual' conditions, and in this sense are more efficient than the best possible solutions under the `eventual connectivity' or `eventual stability' assumptions. <p> Indeed, many large practical networks have taken special precautions to prevent frequent failures and recoveries from degrading the performance of the network by excessive overhead of topology update message and reroutings <ref> [MRR80, LR90, RS91] </ref>. Doubtlessly, in these networks, we cannot use protocols which restart most or all of the computation at every new failure or recovery, as most `eventually stable' works do. <p> They conclude that the requirement that the entire path is up is too strong. We disagree with this conclusion, for both practical and theoretical considerations: Practice: Actual networks <ref> [BGG + 85, LR90] </ref> are designed and implemented so that the probability of a failure along a path is quite small. As a result, many networks use only a small number of the possible alternative paths between each two processors [LR90]. <p> As a result, many networks use only a small number of the possible alternative paths between each two processors <ref> [LR90] </ref>. These networks still operate successfully and are considered fault-tolerant, since the probability that there will be a failure in several disjoint paths at about the same time is negligible.
Reference: [MRR80] <author> John M. McQuillan, Ira Richer, and Eric C. Rosen. </author> <title> The new routing algorithm for the ARPANET. </title> <journal> IEEE Trans. Comm., </journal> <volume> 28(5) </volume> <pages> 711-719, </pages> <month> May </month> <year> 1980. </year>
Reference-contexts: Indeed, many large practical networks have taken special precautions to prevent frequent failures and recoveries from degrading the performance of the network by excessive overhead of topology update message and reroutings <ref> [MRR80, LR90, RS91] </ref>. Doubtlessly, in these networks, we cannot use protocols which restart most or all of the computation at every new failure or recovery, as most `eventually stable' works do. <p> On one hand, the protocol should have high throughput (rate). To achieve this, the source does not wait for network-wide progress, before enabling a new accept event. Instead, the source waits only for progress of its immediate neighbors. This should be contrasted with the Echo and PIF protocols <ref> [DS80, Cha82, MRR80, Seg83] </ref>, that wait before accepting a new message until an entire spanning tree converges. broad:prot update:January 3, 1994 L a T E X:August 26, 1996 24 On the other hand, the protocol should not cause high congestion on links. <p> Updating is needed if processor v received broad:prot update:January 3, 1994 L a T E X:August 26, 1996 26 more messages than u, and in this case processor v sends to u the messages that u may have not received yet. This updating action is a standard practice <ref> [MRR80, Per83, JBS86] </ref>. Our protocol requires precise synchronization between the messages delivered by two neighbors connected by a 3nUp link. The update operation cannot achieve such precise synchronization; in particular, it does not prevent v from delivering more messages.
Reference: [MS79] <author> P. Merlin and A. Segall. </author> <title> Failsafe distributed routing protocol. </title> <journal> IEEE Trans. Comm., </journal> <volume> COM-27:1280-1288, </volume> <month> September </month> <year> 1979. </year>
Reference: [Per83] <author> Radia Perlman. </author> <title> Fault tolerant broadcast of routing information. </title> <booktitle> Computer Networks, </booktitle> <month> December </month> <year> 1983. </year>
Reference-contexts: Networks are designed with sufficient redundancy (alternative paths) so that it is easy to ensure reliable communication. Accordingly, protocols employed in actual networks usually make strong reliability assumptions <ref> [BGG + 85, LR90, Per83, Her92] </ref>. These `practical' protocols are simple and efficient. In particular, these protocols do not wait for `eventual' conditions, and in this sense are more efficient than the best possible solutions under the `eventual connectivity' or `eventual stability' assumptions. <p> The Intelligent Flood protocol <ref> [Per83, Seg83] </ref> require unbounded 1 storage, both due to `infinite counters' and to unbounded link capacity requirements. Our protocol is almost as simple as these `classical' protocols, especially the version for static networks presented in x3.1. <p> High congestion may be caused, for example, by the Intelligent Flood protocol and its variants <ref> [Per83, Seg83, AE86] </ref>, since the source may issue messages much faster than some links can transfer them. Hence, these messages must be stored in the source (resulting in unbounded space complexity) or in the links (resulting in unbounded link concurrency). <p> Updating is needed if processor v received broad:prot update:January 3, 1994 L a T E X:August 26, 1996 26 more messages than u, and in this case processor v sends to u the messages that u may have not received yet. This updating action is a standard practice <ref> [MRR80, Per83, JBS86] </ref>. Our protocol requires precise synchronization between the messages delivered by two neighbors connected by a 3nUp link. The update operation cannot achieve such precise synchronization; in particular, it does not prevent v from delivering more messages. <p> The improvement is by adding a flooding mechanism. In the code, appearing in Figs. 8-11, the lines which implement the flood mechanism are marked by F on the right margin. The flood mechanism is an application of the Intelligent Flood protocol <ref> [Per83] </ref> or PI protocol [Seg83]. The flood mechanism uses a new type of packets, called flood packets. A flood packet, like a sync packet, consists of a pair of a message and its index. The flood packets are generated by the source. <p> It is trivial to achieve either synchronization or progress; the difficulty is to achieve both properties together. Synchronization alone is trivially achieved, for example, if no messages are delivered, or by the PIF protocol. Progress alone is achieved by the intelligent flood protocol <ref> [AE86, Per83, Seg83] </ref>. We begin by presenting a weak progress property, that does not use the flood mechanism. <p> In this case the claim holds from Lemmas 4 and 25. 2 From Lemma 34 it follows that it suffices to use numeric variables reduced modulo 6n + 3 (or more), when the comparisons are performed in the standard manner when using a cyclic counter <ref> [Per83] </ref>. Namely, x is larger than y if jx yj 3n + 1. By performing this modification, the protocol uses only short messages. The properties of this version of the protocol are summarized in the following Theorem.
Reference: [RS91] <author> T. L. Rodeheffer and M. D. Schroeder. </author> <title> Automatic reconfiguration in autonet. </title> <booktitle> In Symp. on Principles of Operating Systems, </booktitle> <year> 1991. </year>
Reference-contexts: Indeed, many large practical networks have taken special precautions to prevent frequent failures and recoveries from degrading the performance of the network by excessive overhead of topology update message and reroutings <ref> [MRR80, LR90, RS91] </ref>. Doubtlessly, in these networks, we cannot use protocols which restart most or all of the computation at every new failure or recovery, as most `eventually stable' works do.
Reference: [Seg83] <author> A. Segall. </author> <title> Distributed network protocols. </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> IT-29(1), </volume> <month> January </month> <year> 1983. </year>
Reference-contexts: In fact, by combining high throughput with bounded (O (n)) storage, our protocol improves upon the known, `classical' broadcast protocols, Echo, PIF and Intelligent Flood, used in many actual networks. (Details follow.) Furthermore, these classical protocols work only for static asynchronous networks. The Echo and PIF protocols <ref> [Cha82, DS80, Seg83] </ref> have lower throughput. <p> The Intelligent Flood protocol <ref> [Per83, Seg83] </ref> require unbounded 1 storage, both due to `infinite counters' and to unbounded link capacity requirements. Our protocol is almost as simple as these `classical' protocols, especially the version for static networks presented in x3.1. <p> This is indeed the case in many of these works, where every failure or recovery may cause the protocol to restart operating from the beginning. Many eventual-stability protocols work in this `blast-away' technique [Gal76], [Fin79], <ref> [Seg83] </ref>, [AAG87]. However, the `blast-away' technique is wasteful; it is desirable, and often possible, to recover from a failure at a cost much smaller than restarting the task. In particular, our protocol recovers from failures with a small fixed cost, independent of the number of broadcasts done so far. <p> On one hand, the protocol should have high throughput (rate). To achieve this, the source does not wait for network-wide progress, before enabling a new accept event. Instead, the source waits only for progress of its immediate neighbors. This should be contrasted with the Echo and PIF protocols <ref> [DS80, Cha82, MRR80, Seg83] </ref>, that wait before accepting a new message until an entire spanning tree converges. broad:prot update:January 3, 1994 L a T E X:August 26, 1996 24 On the other hand, the protocol should not cause high congestion on links. <p> High congestion may be caused, for example, by the Intelligent Flood protocol and its variants <ref> [Per83, Seg83, AE86] </ref>, since the source may issue messages much faster than some links can transfer them. Hence, these messages must be stored in the source (resulting in unbounded space complexity) or in the links (resulting in unbounded link concurrency). <p> Our protocol prevents high congestion by limiting the number of messages in transit over any link. This is achieved by synchronizing between each pair of neighbors. This synchronization resembles synchronizer ff of [Awe85] and the minimal hop protocol of <ref> [Gal76, Seg83] </ref>. In the rest of this subsection we informally describe this synchronization mechanism, which is the core of the protocol, and suffices for operation in static networks. In the code, appearing in Figs. 8-11, the lines which implement this mechanism are marked by S in the right margin. <p> The improvement is by adding a flooding mechanism. In the code, appearing in Figs. 8-11, the lines which implement the flood mechanism are marked by F on the right margin. The flood mechanism is an application of the Intelligent Flood protocol [Per83] or PI protocol <ref> [Seg83] </ref>. The flood mechanism uses a new type of packets, called flood packets. A flood packet, like a sync packet, consists of a pair of a message and its index. The flood packets are generated by the source. <p> It is trivial to achieve either synchronization or progress; the difficulty is to achieve both properties together. Synchronization alone is trivially achieved, for example, if no messages are delivered, or by the PIF protocol. Progress alone is achieved by the intelligent flood protocol <ref> [AE86, Per83, Seg83] </ref>. We begin by presenting a weak progress property, that does not use the flood mechanism. <p> If the path is (k + 2)Up at some time t, and the synchronization condition holds during [t (k + 2); t], then R u 0 (t) R u k (t k). Proof: This Lemma extends Theorem PI-1 of <ref> [Seg83] </ref> to deal with recoveries. We first prove the Lemma for k = 1. Namely, we assume that link (u 0 ; u 1 ) is 3Up at t, and prove that R u 1 (t 1) R u 0 (t).
Reference: [SS81] <author> A. Segall and M. Sidi. </author> <title> A failsafe distributed protocol for minimum delay routing. </title> <journal> IEEE Trans. Comm., </journal> <volume> COM-29(5):689-695, </volume> <month> May </month> <year> 1981. </year>
Reference: [Vis83] <author> Uzi Vishkin. </author> <title> A distributed orientation algorithm. </title> <journal> IEEE Trans. Info. Theory, </journal> <month> June </month> <year> 1983. </year>
Reference-contexts: Each of these assumptions is the weakest sufficient assumption for an important and general class of tasks. In [AAG87, Fin79] it was shown that `eventual stability' is sufficient for tasks whose output depends on the topology of the network. In <ref> [AG91, AE86, AMS89, Vis83] </ref> it was shown that `eventual connectivity' is sufficient for tasks whose output is independent of the topology. <p> This, of course, is not meant literally, but it is rather assumed that from that moment on, an entire execution of the protocol can be completed within a period containing no new failures. In the eventual-connectivity approach <ref> [AG91, AE86, AMS89, Vis83] </ref>, the only restriction on the nature of failures is that they do not disconnect the network forever. Both approaches are elegant and gave rise to interesting research problems and important techniques. However, there are severe limitations to the application of these approaches to actual networks.
References-found: 34

