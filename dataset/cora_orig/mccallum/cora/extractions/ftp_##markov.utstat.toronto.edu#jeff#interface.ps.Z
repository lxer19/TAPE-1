URL: ftp://markov.utstat.toronto.edu/jeff/interface.ps.Z
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Phone: Phone: (416) 978-4594.  
Title: Theoretical rates of convergence for Markov chain Monte Carlo  
Author: by Jeffrey S. Rosenthal* 
Date: June 1994.)  
Note: Internet: jeff@utstat.toronto.edu (Conference proceedings, Interface '94,  
Address: Toronto, Toronto, Ontario, Canada M5S 1A1  
Affiliation: Department of Statistics, University of  
Abstract: We present a general method for proving rigorous, a priori bounds on the number of iterations required to achieve convergence of Markov chain Monte Carlo. We describe bounds for specific models of the Gibbs sampler, which have been obtained from the general method. We discuss possibilities for obtaining bounds more generally. 
Abstract-found: 1
Intro-found: 1
Reference: <author> J.R. Baxter and J.S. </author> <title> Rosenthal (1994), Rates of convergence for everywhere-positive Markov chains. </title> <type> Tech. Rep. 9406, </type> <institution> Dept. of Statistics, University of Toronto. </institution>
Reference: <editor> M.K. Cowles and B.P. </editor> <month> Carlin </month> <year> (1994), </year> <title> Evaluation and comparison of Markov chain Monte Carlo convergence diagnostics. </title> <type> Tech. Rep., </type> <institution> Dept. of Biostatistics, University of Minnesota. </institution>
Reference-contexts: Hence, further work is required before these methods are easily usable in very general applied settings. It is possible that the theoretical approach described here can be combined with a more practical analysis, for example by attempting to verify drift and minorization conditions through additional simulation <ref> (Cowles and Rosenthal, 1994) </ref>, which might allow for wider use. In any case, while there is much work to be done, the methods described here appear to hold promise for providing rigorous rates of convergence for many additional examples of Markov chain Monte Carlo. Acknowledgements.
Reference: <editor> M.K. Cowles and J.S. </editor> <booktitle> Rosenthal (1994), work in progress. </booktitle>
Reference-contexts: Hence, further work is required before these methods are easily usable in very general applied settings. It is possible that the theoretical approach described here can be combined with a more practical analysis, for example by attempting to verify drift and minorization conditions through additional simulation <ref> (Cowles and Rosenthal, 1994) </ref>, which might allow for wider use. In any case, while there is much work to be done, the methods described here appear to hold promise for providing rigorous rates of convergence for many additional examples of Markov chain Monte Carlo. Acknowledgements.
Reference: <author> B. Efron and C. </author> <title> Morris (1975), Data analysis using Stein's estimator and its generalizations. </title> <journal> J. Amer. Stat. Assoc., </journal> <volume> Vol. 70, No. 350, </volume> <pages> 311-319. </pages>
Reference: <author> A. Frieze, R. Kannan, and N.G. </author> <month> Polson </month> <year> (1993), </year> <title> Sampling from log-concave distributions. </title> <type> Tech. Rep., </type> <institution> School of Computer Science, Carnegie-Mellon University. </institution>
Reference: <author> A.E. Gelfand and A.F.M. </author> <title> Smith (1990), Sampling based approaches to calculating marginal densities. </title>
Reference: <author> J. </author> <title> Amer. </title> <journal> Stat. Assoc. </journal> <volume> 85, </volume> <pages> 398-409. </pages>
Reference: <author> A.E. Gelfand, S.E. Hills, A. Racine-Poon, and A.F.M. </author> <title> Smith (1990), Illustration of Bayesian inference in normal data models using Gibbs sampling. </title> <journal> J. Amer. Stat. Soc. </journal> <volume> 85, </volume> <pages> 972-985. </pages>
Reference: <author> A. </author> <title> Gelman and D.B. Rubin (1992), Inference from iterative simulation using multiple sequences. </title> <journal> Stat. Sci., </journal> <volume> Vol. 7, No. 4, </volume> <pages> 457-472. </pages>
Reference: <author> S. Geman and D. </author> <title> Geman (1984), Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. </title> <journal> IEEE Trans. on pattern analysis and machine intelligence 6, </journal> <pages> 721-741. </pages>
Reference: <author> W. James and C. </author> <title> Stein (1961), Estimation with Quadratic Loss. </title> <booktitle> Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, </booktitle> <volume> Vol. 1, </volume> <publisher> University of California Press, </publisher> <address> Berkeley, </address> <pages> 361-379. </pages>
Reference-contexts: The bound is also not absurdly large: for example, if E = 2 and k = 150, this bound is equal to 0:03, implying that 150 iterations are sufficient to achieve randomness. In Rosenthal (1994), the Gibbs sampler applied to a model related to James-Stein estimators <ref> (James and Stein, 1961) </ref> was analyzed. The model (suggested by Jun Liu) was designed to avoid the use of guesses and empirical estimates in the usual (empirical Bayes) formulation of James-Stein estimators. The Gibbs sampler was intended to facilitate computations related to the associated posterior distribution.
Reference: <author> W.K. </author> <title> Hastings (1970), Monte Carlo sampling methods using Markov chains and their applications. </title> <booktitle> Bio-metrika 57, </booktitle> <pages> 97-109. </pages>
Reference: <author> M. Jerrum and A. </author> <title> Sinclair (1989), Approximating the permanent. </title> <journal> SIAM J. Comput. </journal> <volume> 18, </volume> <pages> 1149-1178. </pages>
Reference: <author> J. Liu, W. Wong, and A. </author> <title> Kong (1991a), Correlation structure and the convergence of the Gibbs sampler, I. </title> <type> Tech Rep. 299, </type> <institution> Dept. of Statistics, University of Chicago. </institution> <note> Biometrika, to appear. </note>
Reference: <author> J. Liu, W. Wong, and A. </author> <title> Kong (1991b), Correlation structure and the convergence of the Gibbs sampler, II: Applications to various scans. </title> <type> Tech Rep. 304, </type> <institution> Dept. of Statistics, University of Chicago. J. Royal Stat. Sci. (B), </institution> <note> to appear. </note>
Reference: <author> R.B. Lund and R.L. </author> <month> Tweedie </month> <year> (1993), </year> <title> Geometric convergence rates for stochastically ordered Markov chains. </title> <type> Tech. Rep., </type> <institution> Dept. of Statistics, Colorado State University. </institution>
Reference: <author> P. </author> <title> Matthews (1993), A slowly mixing Markov chain with implications for Gibbs sampling. </title> <journal> Stat. Prob. Lett. </journal> <volume> 17, </volume> <pages> 231-236. </pages>
Reference: <author> K.L. Mengersen and R.L. </author> <month> Tweedie </month> <year> (1993), </year> <title> Rates of convergence of the Hastings and Metropolis algorithms. </title> <type> Tech. Rep. 93/30, </type> <institution> Dept. of Statistics, Colorado State University. </institution>
Reference: <author> N. Metropolis, A. Rosenbluth, M. </author> <title> Rosenbluth, </title> <publisher> A. </publisher>
Reference: <author> Teller, and E. </author> <title> Teller (1953), Equations of state calculations by fast computing machines. </title> <journal> J. Chem. Phys. </journal> <volume> 21, </volume> <pages> 1087-1091. </pages>
Reference: <author> S.P. Meyn and R.L. </author> <month> Tweedie </month> <year> (1993), </year> <title> Computable bounds for convergence rates of Markov chains. </title> <type> Tech. Rep., </type> <institution> Dept. of Statistics, Colorado State University. </institution>
Reference: <author> C. </author> <title> Morris (1983), Parametric empirical Bayes confidence intervals. Scientific Inference, Data Analysis, </title> <booktitle> and Robustness, </booktitle> <pages> 25-50. </pages>
Reference: <author> P. Mykland, L. Tierney, and B. </author> <title> Yu (1992), Regeneration in Markov chain samplers. </title> <type> Tech. Rep. 585, </type> <institution> School of Statistics, University of Minnesota. </institution>
Reference: <author> G.O. </author> <title> Roberts (1992), Convergence diagnostics of the Gibbs sampler. In Bayesian Statistics 4 (J.M. </title> <editor> Ber-nardo et al., eds.), </editor> <address> 777-784. </address> <publisher> Oxford University Press. </publisher>
Reference: <author> J.S. </author> <title> Rosenthal (1991), Rates of convergence for Gibbs sampler for variance components models. </title> <type> Tech. Rep. 9322, </type> <institution> Dept. of Statistics, University of Toronto. (Tentatively accepted in Annals of Statistics.) </institution> <month> J.S. </month> <title> Rosenthal (1993a), Rates of convergence for Data Augmentation on finite sample spaces. </title> <journal> Ann. Appl. Prob., </journal> <volume> Vol. 3, No. 3, </volume> <pages> 319-339. </pages>
Reference: <author> J.S. </author> <title> Rosenthal (1993b), Minorization conditions and convergence rates for Markov chain Monte Carlo. </title> <type> Tech. Rep. 9321, </type> <institution> Dept. of Statistics, University of Toronto. </institution>
Reference: <author> J.S. </author> <title> Rosenthal (1994), Analysis of the Gibbs sampler for a model related to James-Stein estimators. </title> <type> Tech. Rep. 9413, </type> <institution> Dept. of Statistics, University of Toronto. </institution>
Reference-contexts: When applied to the baseball data analyzed in Efron and Morris (1975) and Mor-ris (1983), it proved that the Gibbs sampler would converge in less than 200 iterations. For certain other prior distributions, it was shown <ref> (Rosenthal, 1994) </ref> that this Gibbs sampler would in fact not converge at all. This information was used, together with standard convergence theory, to prove that for these (improper) priors, the model itself was improper, i.e. the posterior distribution was non-normalizable. <p> Hence, further work is required before these methods are easily usable in very general applied settings. It is possible that the theoretical approach described here can be combined with a more practical analysis, for example by attempting to verify drift and minorization conditions through additional simulation <ref> (Cowles and Rosenthal, 1994) </ref>, which might allow for wider use. In any case, while there is much work to be done, the methods described here appear to hold promise for providing rigorous rates of convergence for many additional examples of Markov chain Monte Carlo. Acknowledgements.
Reference: <author> M.J. Schervish and B.P. </author> <month> Carlin </month> <year> (1992), </year> <title> On the convergence of successive substitution sampling, </title> <journal> J. Comp. Graph. Stat. </journal> <volume> 1, </volume> <pages> 111-127. </pages>
Reference: <author> M.A. </author> <title> Tanner and W.H. Wong (1987), The calculation of posterior distributions by data augmentation (with discussion). </title> <journal> J. Amer. Stat. Assoc. </journal> <volume> 82, </volume> <pages> 528-550. </pages>
Reference: <author> L. </author> <month> Tierney </month> <year> (1994), </year> <title> Markov chains for exploring posterior distributions. </title> <type> Tech. Rep. 560, </type> <institution> School of Statistics, University of Minnesota. Ann. Stat., </institution> <note> to appear. </note>
Reference-contexts: A fundamental issue regarding such techniques is their convergence properties, specifically whether or not the algorithm will converge to the correct distribution, and if so how quickly. Many general convergence results <ref> (e.g. Tierney, 1994) </ref>, qualitative convergence-rate results (Schervish and Carlin, 1992; Liu, Wong, and Kong, 1991a, 1991b; Baxter and Rosenthal, 1994), and convergence diagnostics (e.g. Roberts, 1992; Gel-man and Rubin, 1992; Mykland, Tierney, and Yu, 1992) have been developed.
References-found: 30

