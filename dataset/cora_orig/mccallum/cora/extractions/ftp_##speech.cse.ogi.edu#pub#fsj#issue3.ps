URL: ftp://speech.cse.ogi.edu/pub/fsj/issue3.ps
Refering-URL: http://www.cse.ogi.edu/CSLU/fsj/html/pastvolumes.html
Root-URL: http://www.cse.ogi.edu
Title: EXPERIMENTS WITH A SPOKEN DIALOGUE SYSTEM FOR TAKING THE U.S. CENSUS  for Spoken Language Understanding  
Author: R.A. Cole, D.G. Novick, P.J.E. Vermeulen, S. Sutton, M. Fanty L.F.A. Wessels, J.H. de Villiers, J. Schalkwyk, B. Hansen, D. Burnett 
Address: P.O.Box 91000, Portland, OR 97291-1000  
Affiliation: Center  Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: This paper reports the results of the development, deployment and testing of a large spoken-language dialogue application for use by the general public. We built an automated spoken questionnaire for the U.S. Bureau of the Census. In the project's first phase, the basic recognizers and dialogue system were developed using 4,000 calls. In the second phase, the system was adapted to meet Census Bureau requirements and deployed in the Bureau's 1995 national test of new technologies. In the third phase, we refined the system and showed empirically that an automated spoken questionnaire could successfully collect and recognize census data, and that subjects preferred the spoken system to written questionnaires. Our large data collection effort and two subsequent field tests showed that, when questions are asked correctly, the answers contain information within the desired response categories about 99 percent of the time.
Abstract-found: 1
Intro-found: 1
Reference: <author> Barnard, E., Cole, R., Fanty, M., and Vermeulen, P. </author> <year> (1995). </year> <title> Real-world speech recognition with neural networks. </title> <booktitle> In Proceedings of the International Workshop on Applications of Neural Networks to Telecommunications 2, </booktitle> <pages> pages 186-193. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference-contexts: Instead, we sub-sampled the data so that 1000 frames of each category were selected. The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization (Barnard and Cole, 1989), using a mean-squared criterion function (cf. <ref> (Barnard et al., 1995) </ref>, (Fontaine et al., 1996), (Hutter, 1995), (Richard and Lippmann, 1991), (Bishop, 1995), (Konig et al., 1996) for the advantages and disadvantages 5 of neural networks versus multivariate Gaussians). 2.1.2 Viterbi Search.
Reference: <author> Barnard, E. and Cole, R. A. </author> <year> (1989). </year> <title> A neural-net training program based on conjugate-gradient optimization. </title> <type> Technical Report CSE 89-014, </type> <institution> Oregon Graduate Institute, 20000 N.W. Walker Rd., Beaverton, </institution> <address> OR. </address>
Reference-contexts: We did not have the computational resources to train on every available frame of training data. Instead, we sub-sampled the data so that 1000 frames of each category were selected. The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization <ref> (Barnard and Cole, 1989) </ref>, using a mean-squared criterion function (cf. (Barnard et al., 1995), (Fontaine et al., 1996), (Hutter, 1995), (Richard and Lippmann, 1991), (Bishop, 1995), (Konig et al., 1996) for the advantages and disadvantages 5 of neural networks versus multivariate Gaussians). 2.1.2 Viterbi Search.
Reference: <author> Bishop, C. M. </author> <year> (1995). </year> <title> Neural Networks for Pattern Recognition. </title> <publisher> Oxford University Press. </publisher>
Reference-contexts: The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization (Barnard and Cole, 1989), using a mean-squared criterion function (cf. (Barnard et al., 1995), (Fontaine et al., 1996), (Hutter, 1995), (Richard and Lippmann, 1991), <ref> (Bishop, 1995) </ref>, (Konig et al., 1996) for the advantages and disadvantages 5 of neural networks versus multivariate Gaussians). 2.1.2 Viterbi Search. The phonetic classification produces an estimate of the probability that each phoneme part is present at each 10 msec time frame.
Reference: <author> Boite, J., Boulard, H., D'Hoore, B., and Haesen, M. </author> <year> (1993). </year> <title> A new approach toward keyword spotting. </title> <booktitle> In Proceedings of the 3rd European Conference on Speech Communication and Technology, </booktitle> <pages> pages 1273-1276, </pages> <address> Berlin. </address>
Reference-contexts: In addition, there is a great deal of background noise in many of the calls. To overcome these problems, we implemented a simple word-spotting approach in which all words and sounds not in the target set match a single garbage model. We use the approach described in <ref> (Boite et al., 1993) </ref>, in which the output score for the garbage word is computed as the median value of the top N phoneme scores for each frame, where N varies with the task and is set empirically.
Reference: <author> Cole, R., Hirschman, L., Atlas, L., Beckman, M., Bierman, A., Bush, M., Cohen, J., Garcia, O., Hanson, B., Hermansky, H., Levinson, S., McKeown, K., Morgan, N., Novick, D., Ostendorf, M., Oviatt, S., Price, P., Silverman, H., Spitz, J., Waibel, A., Weinstein, C., Zahorian, S., and Zue, V. </author> <year> (1995a). </year> <title> The challengee of spoken language systems: Research directions for the nineties. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> 3(1) </volume> <pages> 1-21. </pages> <note> 29 Cole, </note> <author> R., Novick, D., Burnett, D., Hansen, B., Sutton, S., and Fanty, M. </author> <year> (1994a). </year> <title> Towards automatic collection of the U.S. census. </title> <booktitle> In Proceedings of ICASSP'94, </booktitle> <volume> volume I, </volume> <pages> pages 93-96, </pages> <address> Adelaide, Australia. </address>
Reference-contexts: Through careful design of the wording of questions, or prompts, the system can constrain the caller to produce an acceptable range of responses. In highly constrained tasks with relatively small vocabularies, spoken language systems can produce acceptable performance today <ref> (Cole et al., 1995a) </ref>. Moreover, recognition technology is improving at a steady 2 rate, and very low error rates can be expected by the year 2000, especially if large amounts of training data are used to capture the many sources of variability in the signal.
Reference: <author> Cole, R., Novick, D., Fanty, M., Sutton, S., Hansen, B., and Burnett, D. </author> <year> (1993). </year> <title> Rapid prototyping of spoken-language systems: The Year 2000 Census project. </title> <booktitle> In Proceedings of the Conference on Spoken Language Systems, </booktitle> <pages> pages 19-23, </pages> <address> Tokyo, Japan. </address>
Reference: <author> Cole, R., Novick, D., Fanty, M., Vermeulen, P., Sutton, S., and Burnett, D. </author> <year> (1994b). </year> <title> A prototype voice-response questionnaire for the U.S. Census. </title> <booktitle> In Proceedings of ICSLP-94, </booktitle> <pages> pages 683-686. </pages>
Reference: <author> Cole, R. A., Noel, M., Burnett, D. C., Fanty, M., Lander, T., Oshika, B., and Sutton, S. </author> <year> (1994c). </year> <title> Corpus development activities at the Center for Spoken Language Understanding. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology. </booktitle>
Reference-contexts: All the networks had between 25 and 45 hidden units; the performance was not sensitive to the exact number. The networks were trained on a combination of the hand-transcribed portion of the phase 1 corpus, using automatically located phoneme boundaries and a phonetically hand-labeled corpus of telephone speech <ref> (Cole et al., 1994c) </ref>. In the case of hand-labeled data, each labeled phoneme is cut into equal thirds and relabeled according to context as described above. The frames so labeled provide the training data for the network.
Reference: <author> Cole, R. A., Noel, M., Lander, T., and Durham, T. </author> <year> (1995b). </year> <title> New telephone speech corpora at CSLU. </title> <booktitle> In Proceedings of Eurospeech95, </booktitle> <address> Madrid, Spain. </address>
Reference-contexts: The recognizers were trained on OGI's phonetically labeled speech corpora <ref> (Cole et al., 1995b) </ref>. 4.2 The Two-Day Census Load Test Because so few calls were received during the actual test, a two-day load test was performed to assess the ability of the system to handle multiple simultaneous calls.
Reference: <author> Cole, R. A., Roginski, K., and Fanty, M. </author> <note> (to appear, </note> <year> 1992). </year> <title> English alphabet recognition with telephone speech. </title> <booktitle> In Advances in Neural Information Processing Systems 4. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: If the number of keywords is large (as in the case of the year and day recognizers), a single threshold is used. 2.2 Name Retrieval. The name retrieval algorithm is more complex than the other recognition tasks. It uses the OGI alphabet recognizer <ref> (Cole et al., 1992) </ref> together with a database of first and last names. The alphabet recognizer has two stages. The first is essentially similar to the isolated word recognizer described above, where the words are the letters of the alphabet and any number of letters is allowed, separated by pauses.
Reference: <author> Fanty, M., Cole, R. A., and Roginski, K. </author> <year> (1992). </year> <title> English alphabet recognition with telephone speech. </title> <editor> In Moody, J. E., Hanson, S. J., and Lippman, R. P., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Only responses containing a target word were run. The data collected for this task is noisier than other corpora we have collected. It is also regionally very diverse. Name Recognition The OGI name retrieval algorithm is designed for spelling with pauses between the letters <ref> (Fanty et al., 1992) </ref>. However, callers were not asked to pause during the collection of this corpus in order to create a data set on which to develop fluent letter 13 recognition.
Reference: <author> Fontaine, V., Ris, C., Leich, H., Vantieghen, J., Accaino, S., and Compernolle, D. </author> <year> (1996). </year> <title> Comparison between two hybrid hmm/mlp approaches in speech recognition. </title> <booktitle> In Proceedings 1996 IEEE International Conference on Acoustics, Speech, and Signal Processing. </booktitle>
Reference-contexts: Instead, we sub-sampled the data so that 1000 frames of each category were selected. The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization (Barnard and Cole, 1989), using a mean-squared criterion function (cf. (Barnard et al., 1995), <ref> (Fontaine et al., 1996) </ref>, (Hutter, 1995), (Richard and Lippmann, 1991), (Bishop, 1995), (Konig et al., 1996) for the advantages and disadvantages 5 of neural networks versus multivariate Gaussians). 2.1.2 Viterbi Search.
Reference: <author> Hermansky, H. </author> <year> (1990). </year> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> Journal of Acoustical Society of America, </journal> <volume> 87(4) </volume> <pages> 1738-1752. </pages> <note> 30 Hutter, </note> <author> H. </author> <year> (1995). </year> <title> Comparison of a new hybrid connectionist-schmm approach with other hybrid approaches for speech recognition. </title> <booktitle> In Proceedings 1995 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 3311-3314. </pages>
Reference-contexts: In all cases, the incoming speech (in this case 8-bit mu-law encoded digital samples at a rate of 8KHz), is converted to a representation suitable for recognition. We use perceptual linear predictive (PLP) analysis <ref> (Hermansky, 1990) </ref>, which is based on linear predictive coding and takes into account some of the properties of human hearing. The seventh-order PLP coefficients and the energy in a window are computed every 10 msec and form a frame of speech. 2.1 Isolated Word Recognition.
Reference: <author> Jenkins, C. and Kemper, J. </author> <year> (1994). </year> <title> Report on respondents' attitudes towards a computer administered voice-recognition census short form. </title> <type> Internal report, </type> <institution> Statistical Research Division, U.S. Bureau of the Census, </institution> <month> October 28, </month> <year> 1994. </year>
Reference-contexts: About 90 percent of the respondents in both the pre- and the posttest said that they were willing to answer the census by computer... In general, respondents were impressed with the system, ranking it just below a comparable interviewer-administered questionnaire <ref> (Jenkins and Kemper, 1994) </ref>." 3.5 Summary of Feasibility Study Phase 1 of the OGI Census project demonstrated that a voice questionnaire could be designed to capture information on the census form with high reliability.
Reference: <author> Konig, Y., Bourlard, H., and Morgan, N. </author> <year> (1996). </year> <title> Remap experiments with speech recognition. </title> <booktitle> In Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 3350-3353. </pages> <institution> National Center for Education Statistics (1993). Adult literacy in America. </institution> <type> Technical Report GPO 065-000-00588-3, U.S. </type> <institution> Department of Education, </institution> <address> Washington, DC. </address>
Reference-contexts: The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization (Barnard and Cole, 1989), using a mean-squared criterion function (cf. (Barnard et al., 1995), (Fontaine et al., 1996), (Hutter, 1995), (Richard and Lippmann, 1991), (Bishop, 1995), <ref> (Konig et al., 1996) </ref> for the advantages and disadvantages 5 of neural networks versus multivariate Gaussians). 2.1.2 Viterbi Search. The phonetic classification produces an estimate of the probability that each phoneme part is present at each 10 msec time frame.
Reference: <author> Richard, M. D. and Lippmann, R. P. </author> <year> (1991). </year> <title> Neural network classifiers estimate bayesian a posteriori probabilities. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 461-483. </pages>
Reference-contexts: The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization (Barnard and Cole, 1989), using a mean-squared criterion function (cf. (Barnard et al., 1995), (Fontaine et al., 1996), (Hutter, 1995), <ref> (Richard and Lippmann, 1991) </ref>, (Bishop, 1995), (Konig et al., 1996) for the advantages and disadvantages 5 of neural networks versus multivariate Gaussians). 2.1.2 Viterbi Search. The phonetic classification produces an estimate of the probability that each phoneme part is present at each 10 msec time frame.

References-found: 16

