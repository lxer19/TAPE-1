URL: ftp://ftp.cs.umass.edu/pub/osl/papers/iwmm92.ps.Z
Refering-URL: http://spa-www.cs.umass.edu/bibliography.html
Root-URL: 
Email: hudson@cs.umass.edu  moss@cs.umass.edu  
Phone: 2  
Title: Incremental Collection of Mature Objects  
Author: Richard L. Hudson and J. Eliot B. Moss 
Address: Amherst, MA 01003, USA  Amherst, MA 01003, USA  
Affiliation: 1 University Computing Services University of Massachusetts  Object Systems Laboratory Department of Computer Science University of Massachusetts  
Abstract: We present a garbage collection algorithm that extends generational scavenging to collect large older generations (mature objects) non-disruptively. The algorithm's approach is to process bounded-size pieces of mature object space at each collection; the subtleties lie in guaranteeing that it eventually collects any and all garbage. The algorithm does not assume any special hardware or operating system support, e.g., for forwarding pointers or protection traps. The algorithm copies objects, so it naturally supports compaction and reclustering. Keywords: clustering, compaction, copying collection, garbage collection, garbage collector toolkits, generation scavenging, incremental collection, mature objects, non disruptive collection.
Abstract-found: 1
Intro-found: 1
Reference: [Appel et al., 1988] <author> Andrew W. Appel, John R. Ellis, and Kai Li. </author> <title> Realtime concurrent collection on stock multiprocessors. </title> <booktitle> In Proceedings of the ACM SIGPLAN '88 Conference on Programming Language Design and Implementation (Atlanta, </booktitle> <address> Georgia, </address> <month> June </month> <year> 1988), </year> <journal> ACM SIGPLAN Not. </journal> <volume> 23, </volume> <month> 7 (July </month> <year> 1988), </year> <pages> pp. 11-20. </pages>
Reference-contexts: Ungar was concerned only with young objects, and collected older objects off-line. This work made the time to perform most garbage collections reasonable and the majority of collections non-disruptive. The drawback was the large cost and disruption when large old generations needed to be collected. Appel, Ellis, and Li <ref> [Appel et al., 1988] </ref> suggested collecting on stock hardware by using read-protected or no-access pages in older generations: when a page is touched, it is scanned and all pointers to moved objects are updated. For efficiency their algorithm depends on two properties.
Reference: [Baker, 1978] <author> H. G. Baker. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM 21, </journal> <month> 4 (April </month> <year> 1978), </year> <pages> 280-294. </pages>
Reference-contexts: Pieces of the problem of doing garbage collection non-disruptively have been worked on for years. In this section, we will review some of these attempts and discuss some of their drawbacks. Baker <ref> [Baker, 1978] </ref> discussed the problem of constructing a non-disruptive garbage collector. His solution was a modification of a stop-and-copy algorithm first discussed by Fenichel and Yochelson [Fenichel and Yochelson, 1969].
Reference: [Bishop, 1977] <author> Peter B. Bishop. </author> <title> Computer Systems with a Very Large Address Space and Garbage Collection. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1977. </year>
Reference-contexts: Compaction and Clustering: The algorithm supports compaction and reclustering of objects via copying. Efficient Implementation: The algorithm can be implemented on stock hardware and does not rely on operating system features such as protected pages. Bishop <ref> [Bishop, 1977] </ref> discussed how related objects should be placed in the same area and references into these areas should be handled by a level of indirection so that each area could be collected independently of other areas. <p> While temporal opportunism uses hints about when to do collections, key object opportunism adds hints about where to do collections. Bishop <ref> [Bishop, 1977] </ref> presented a garbage collection algorithm that divided the heap into multiple areas. Users specified the area in which each object was allocated. These areas were designed to be garbage collected individually.
Reference: [Boehm et al., 1991] <author> Hans-J. Boehm, Alan J. Demers, and Scott Shenker. </author> <title> Mostly parallel garbage collection. </title> <booktitle> In [OOPSLA, </booktitle> <year> 1991], </year> <pages> pp. 157-164. </pages>
Reference-contexts: Providing such a fast mechanism may require modifying the operating system. Second, the algorithm requires high locality of reference in the application being run. Without this property, the scanning resulting from touching several pages shortly after a collection would make collection effectively disruptive. Boehm <ref> [Boehm et al., 1991] </ref> showed how collectors could be made mostly parallel in the trace phase of a collector. His algorithm also relies on using the page trap hardware and operating system support to do bookkeeping during the mark phase. This choice reduces the amount of mutator cooperation needed.
Reference: [Cheney, 1970] <author> C. J. </author> <title> Cheney. A nonrecursive list compacting algorithm. </title> <journal> Communications of the ACM 13, </journal> <month> 11 (November </month> <year> 1970), </year> <pages> 677-678. </pages>
Reference-contexts: All objects directly reachable from the roots are copied into new space, and the roots updated to point to the copied object. All objects reachable from the new space objects are then copied over using a non-recursive Cheney scan <ref> [Cheney, 1970] </ref>. 4 As each object is copied, a forwarding pointer is left in the old copy, so that other references to the object can be updated as they are encountered.
Reference: [Diwan et al., 1992] <author> Amer Diwan, J. Eliot B. Moss, and Richard L. Hudson. </author> <title> Compiler support for garbage collection in a statically typed language. </title> <booktitle> In Conference on Programming Language Design and Implementation (San Francisco, </booktitle> <address> California, </address> <month> June </month> <year> 1992), </year> <title> SIGPLAN, </title> <publisher> ACM Press, </publisher> <pages> pp. 273-282. </pages>
Reference-contexts: We insist on copying in order to support compaction and clustering (e.g., hierarchical decomposition [Wilson et al., 1991]). Because copying collectors move objects, we assume the safety property that all pointers (and pointer derived quantities) can be found and updated appropriately (see, e.g., <ref> [Diwan et al., 1992] </ref>). Pieces of the problem of doing garbage collection non-disruptively have been worked on for years. In this section, we will review some of these attempts and discuss some of their drawbacks. Baker [Baker, 1978] discussed the problem of constructing a non-disruptive garbage collector.
Reference: [Fenichel and Yochelson, 1969] <author> Robert R. Fenichel and Jerome C. Yochelson. </author> <title> A LISP garbage-collector for virtual-memory computer systems. </title> <journal> Communications of the ACM 12, </journal> <month> 11 (November </month> <year> 1969), </year> <pages> 611-612. </pages>
Reference-contexts: In this section, we will review some of these attempts and discuss some of their drawbacks. Baker [Baker, 1978] discussed the problem of constructing a non-disruptive garbage collector. His solution was a modification of a stop-and-copy algorithm first discussed by Fenichel and Yochelson <ref> [Fenichel and Yochelson, 1969] </ref>. Baker used a read barrier that trapped all reads of old objects and then copied the objects or updated the pointers to moved objects.
Reference: [Hayes, 1991] <author> Barry Hayes. </author> <title> Using key object opportunism to collect old objects. </title> <booktitle> In [OOPSLA, </booktitle> <year> 1991], </year> <pages> pp. 33-46. </pages>
Reference-contexts: Wilson [Wilson and Moher, 1989] tries to make his collector non-disruptive using temporal opportunism, a technique that tries to hide long garbage collection by piggy-backing onto long computations or onto long interactive pauses. Hayes <ref> [Hayes, 1991] </ref> suggested key object opportunism, which monitors key objects. When a key object become unreachable, one attempts to collect the objects associated with it.
Reference: [Hosking et al., 1992] <author> Antony L. Hosking, J. Eliot B. Moss, and Darko Stefanovic. </author> <title> A comparative performance evaluation of write barrier implementations. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications (Vancouver, </booktitle> <address> Canada, </address> <month> October </month> <year> 1992). </year> <note> To appear. </note>
Reference-contexts: The toolkit leaves the structure of the remembered sets up to the language implementor. The toolkit does, however, provide several alternative implementations including remembering slots, objects, cards, or pages. See <ref> [Hosking et al., 1992] </ref> for performance studies comparing the available techniques. 4.3 Collecting an Area in Mature Object Space As previously mentioned, we process areas in round robin order, collecting one area (or car) upon each scavenge of MOS (which implies that all young generations are also scavenged at the same
Reference: [Hudson et al., 1991] <author> Richard L. Hudson, J. Eliot B. Moss, Amer Diwan, and Christopher F. </author> <title> Weight. A language-independent garbage collector toolkit. </title> <type> COINS Technical Report 91-47, </type> <institution> University of Massachusetts, Amherst, </institution> <month> September </month> <year> 1991. </year> <note> Submitted for publication. </note>
Reference-contexts: A typical block size might be 64K bytes. The number of blocks in a step may vary over time. While the blocks of a step 3 For a more detailed discussion of the toolkit see <ref> [Hudson et al., 1991] </ref>. are usually not contiguous, a nursery may be set up to consist of a number of contiguous blocks, so that one might more readily use a page trap (rather than an explicit limit check) to detect nursery overflow and trigger a scavenge.
Reference: [Jones, 1986] <author> Douglas W. Jones. </author> <title> An empirical comparison of priority-queue and event-set implementations. </title> <journal> Communications of the ACM 29, </journal> <month> 4 (April </month> <year> 1986), </year> <pages> 300-311. </pages>
Reference-contexts: Further, as also discussed in [Ungar and Jackson, 1988], any object that contains few pointers and that exceeds some threshold in size should be stored in LOS to avoid the overhead of copying. LOS uses free list allocation based on splay trees <ref> [Sleator and Tarjan, 1983, Sleator and Tarjan, 1985, Jones, 1986] </ref> and, once allocated, an LOS object is never moved. However, LOS objects still belong to a step, which is indicated by threading the objects onto a doubly linked list rooted in the step data structure.
Reference: [Lang and Dupont, 1987] <author> Bernard Lang and Francis Dupont. </author> <title> Incremental incrementally compacting garbage collection. </title> <booktitle> SIGPLAN '87 Symposium on Interpreters and Interpretive Techniques (1987), </booktitle> <pages> 253-263. </pages>
Reference-contexts: Unfortunately, mutation of objects requires periodic reclustering. To allow this reclustering and compaction, the objects need to be moved and pointers to the moved objects updated appropriately. Lang <ref> [Lang and Dupont, 1987] </ref> showed how the incremental compaction of a large heap can be done using a hybrid mark/sweep and copying collector. The algorithm copies as much of the heap as there is contiguous free space during each collection thus compacting some portion of the heap.
Reference: [Lieberman and Hewitt, 1983] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collection based on the lifetimes of objects. </title> <journal> Communications of the ACM 26, </journal> <month> 6 (June </month> <year> 1983), </year> <pages> 419-429. </pages>
Reference-contexts: Both Baker and White assumed special pointer forwarding hardware support for their algorithms. Lieberman and Hewitt <ref> [Lieberman and Hewitt, 1983] </ref>, Moon [Moon, 1984], and Ungar [Ungar, 1984] all presented algorithms that reduced the running time required by most garbage collections by focusing attention on the youngest and most volatile generations of objects.
Reference: [Moon, 1984] <author> David Moon. </author> <title> Garbage collection in a large Lisp system. </title> <booktitle> In Proceedings of the ACM Symposium on Lisp and Functional Programming (Austin, </booktitle> <address> TX, </address> <month> August </month> <year> 1984), </year> <pages> pp. 235-246. </pages>
Reference-contexts: Both Baker and White assumed special pointer forwarding hardware support for their algorithms. Lieberman and Hewitt [Lieberman and Hewitt, 1983], Moon <ref> [Moon, 1984] </ref>, and Ungar [Ungar, 1984] all presented algorithms that reduced the running time required by most garbage collections by focusing attention on the youngest and most volatile generations of objects. Lieberman and Hewitt relied on special hardware and a Baker-style algorithm to achieve incremental performance. <p> The Lisp Machine [Weinreb and Moon, 1981] demonstrated how linked lists could be compacted using cdr-coding. Wilson [Wilson et al., 1991] showed how hierarchical decomposition could also be used to compress data, in addition to improving locality of reference. Wilson's scheme is similar to Moon's approximately depth-first algorithm <ref> [Moon, 1984] </ref> and demonstrates the gains in locality that can be made by reclustering items based on their reachability path characteristics. Unfortunately, mutation of objects requires periodic reclustering. To allow this reclustering and compaction, the objects need to be moved and pointers to the moved objects updated appropriately.
Reference: [OOPSLA, 1991] <institution> Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications (Phoenix, Arizona, </institution> <month> October </month> <year> 1991), </year> <journal> ACM SIGPLAN Not. </journal> <volume> 26, </volume> <month> 11 (November </month> <year> 1991). </year>
Reference: [Sleator and Tarjan, 1983] <author> Daniel Dominic Sleator and Robert Endre Tarjan. </author> <title> Self-adjusting binary search trees. </title> <booktitle> In Proceedings of the ACM SIGACT Symposium on Theory (Boston, </booktitle> <address> Massachusetts, </address> <month> April </month> <year> 1983), </year> <pages> pp. 235-245. </pages>
Reference-contexts: Further, as also discussed in [Ungar and Jackson, 1988], any object that contains few pointers and that exceeds some threshold in size should be stored in LOS to avoid the overhead of copying. LOS uses free list allocation based on splay trees <ref> [Sleator and Tarjan, 1983, Sleator and Tarjan, 1985, Jones, 1986] </ref> and, once allocated, an LOS object is never moved. However, LOS objects still belong to a step, which is indicated by threading the objects onto a doubly linked list rooted in the step data structure.
Reference: [Sleator and Tarjan, 1985] <author> Daniel Dominic Sleator and Robert Endre Tarjan. </author> <title> Self-adjusting binary search trees. </title> <journal> Journal of the ACM 32, </journal> <month> 3 (July </month> <year> 1985). </year>
Reference-contexts: Further, as also discussed in [Ungar and Jackson, 1988], any object that contains few pointers and that exceeds some threshold in size should be stored in LOS to avoid the overhead of copying. LOS uses free list allocation based on splay trees <ref> [Sleator and Tarjan, 1983, Sleator and Tarjan, 1985, Jones, 1986] </ref> and, once allocated, an LOS object is never moved. However, LOS objects still belong to a step, which is indicated by threading the objects onto a doubly linked list rooted in the step data structure.
Reference: [Ungar, 1984] <author> David Ungar. </author> <title> Generation scavenging: A non-disruptive high performance storage reclamation algorithm. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments (Pittsburgh, </booktitle> <address> Pennsylvania, </address> <month> April </month> <year> 1984), </year> <journal> ACM SIGPLAN Not. </journal> <volume> 19, </volume> <month> 5 (May </month> <year> 1984), </year> <pages> pp. 157-167. </pages>
Reference-contexts: Both Baker and White assumed special pointer forwarding hardware support for their algorithms. Lieberman and Hewitt [Lieberman and Hewitt, 1983], Moon [Moon, 1984], and Ungar <ref> [Ungar, 1984] </ref> all presented algorithms that reduced the running time required by most garbage collections by focusing attention on the youngest and most volatile generations of objects. Lieberman and Hewitt relied on special hardware and a Baker-style algorithm to achieve incremental performance.
Reference: [Ungar and Jackson, 1988] <author> David Ungar and Frank Jackson. </author> <title> Tenuring policies for generation-based storage reclamation. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications (San Diego, </booktitle> <address> California, </address> <month> September </month> <year> 1988), </year> <journal> ACM SIGPLAN Not. </journal> <volume> 23, </volume> <month> 11 (November </month> <year> 1988), </year> <pages> pp. 1-17. </pages>
Reference-contexts: The degree of advantage depends on the survival rate a=b, but may be significant in some applications. Blocks do introduce a problem, however. They cannot handle objects larger than the block size. To handle such objects we provide a large object space (LOS), as suggested in <ref> [Ungar and Jackson, 1988] </ref>. In fact, it is probably a good idea to put into LOS any object that consumes a significant fraction of a block; we used the heuristic threshold of 1/8 of a block. Further, as also discussed in [Ungar and Jackson, 1988], any object that contains few pointers <p> provide a large object space (LOS), as suggested in <ref> [Ungar and Jackson, 1988] </ref>. In fact, it is probably a good idea to put into LOS any object that consumes a significant fraction of a block; we used the heuristic threshold of 1/8 of a block. Further, as also discussed in [Ungar and Jackson, 1988], any object that contains few pointers and that exceeds some threshold in size should be stored in LOS to avoid the overhead of copying.
Reference: [Weinreb and Moon, 1981] <author> Daniel Weinreb and David Moon. </author> <title> Lisp Machine Manual, third ed. </title> <institution> Massachusetts Institute of Technology, </institution> <year> 1981. </year>
Reference-contexts: His algorithm also relies on using the page trap hardware and operating system support to do bookkeeping during the mark phase. This choice reduces the amount of mutator cooperation needed. The Lisp Machine <ref> [Weinreb and Moon, 1981] </ref> demonstrated how linked lists could be compacted using cdr-coding. Wilson [Wilson et al., 1991] showed how hierarchical decomposition could also be used to compress data, in addition to improving locality of reference.
Reference: [White, 1980] <author> Jon L. White. </author> <title> Address/memory management for a gigantic Lisp environment or, GC considered harmful. </title> <booktitle> In Proceedings of the ACM Symposium on Lisp and Functional Programming (Stanford, </booktitle> <address> California, </address> <month> August </month> <year> 1980), </year> <booktitle> ACM, </booktitle> <pages> pp. 119-127. </pages>
Reference-contexts: His solution was a modification of a stop-and-copy algorithm first discussed by Fenichel and Yochelson [Fenichel and Yochelson, 1969]. Baker used a read barrier that trapped all reads of old objects and then copied the objects or updated the pointers to moved objects. White <ref> [White, 1980] </ref> suggested that collecting unreachable objects was not as much of a problem as improving the locality of reference of live objects, and proposed a scheme that improved locality of reference of running programs but that collected unreachable objects off-line.
Reference: [Wilson et al., 1991] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Effective static-graph reorganization to improve locality in garbage-collected systems. </title> <booktitle> In Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation (Toronto, </booktitle> <address> Canada, </address> <month> June </month> <year> 1991), </year> <journal> ACM SIGPLAN Not. </journal> <volume> 26, </volume> <month> 6 (June </month> <year> 1991), </year> <pages> pp. 177-191. </pages>
Reference-contexts: We insist on copying in order to support compaction and clustering (e.g., hierarchical decomposition <ref> [Wilson et al., 1991] </ref>). Because copying collectors move objects, we assume the safety property that all pointers (and pointer derived quantities) can be found and updated appropriately (see, e.g., [Diwan et al., 1992]). Pieces of the problem of doing garbage collection non-disruptively have been worked on for years. <p> His algorithm also relies on using the page trap hardware and operating system support to do bookkeeping during the mark phase. This choice reduces the amount of mutator cooperation needed. The Lisp Machine [Weinreb and Moon, 1981] demonstrated how linked lists could be compacted using cdr-coding. Wilson <ref> [Wilson et al., 1991] </ref> showed how hierarchical decomposition could also be used to compress data, in addition to improving locality of reference. <p> The toolkit does 4 The toolkit might be adapted to support mark-sweep or other approaches to collection, but currently it provides only copying collection. Also, it would not be hard to incorporate suggestions such as hierarchical clustering <ref> [Wilson et al., 1991] </ref>. determine automatically where to allocate the new copy of the object, given the object's size (which must be determined by language-specific code). <p> Since the algorithm periodically copies all reachable objects in mature space, it reclusters live objects at no additional cost. During the copying, we can apply sophisticated compaction and clustering techniques such as those described by Wilson <ref> [Wilson et al., 1991] </ref>. In addition, this algorithm avoids the fragmentation that can occur with mark and sweep collectors. 4.4 Why the Collector Works Having presented the collection algorithm, we now argue that it will eventually collect all unreachable objects, even large cycles of garbage.
Reference: [Wilson and Moher, 1989] <author> Paul R. Wilson and Thomas G. Moher. </author> <title> Design of the Opportunistic Garbage Collector. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications (New Orleans, </booktitle> <address> Louisiana, </address> <month> October </month> <year> 1989), </year> <journal> ACM SIGPLAN Not. </journal> <volume> 24, </volume> <month> 10 (October </month> <year> 1989), </year> <pages> pp. 23-35. </pages>
Reference-contexts: This process incrementally continues until the entire heap is compacted. This algorithm requires that all live objects be inspected and possible updated during each pass of the collector. Such romping through memory becomes disruptive as the heap grows large enough to affect the cache and virtual memory mechanisms. Wilson <ref> [Wilson and Moher, 1989] </ref> tries to make his collector non-disruptive using temporal opportunism, a technique that tries to hide long garbage collection by piggy-backing onto long computations or onto long interactive pauses. Hayes [Hayes, 1991] suggested key object opportunism, which monitors key objects.
References-found: 23

