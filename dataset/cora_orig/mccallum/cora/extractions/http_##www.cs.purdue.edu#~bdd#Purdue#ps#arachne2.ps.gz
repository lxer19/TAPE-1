URL: http://www.cs.purdue.edu/~bdd/Purdue/ps/arachne2.ps.gz
Refering-URL: http://www.cs.purdue.edu/~bdd/Purdue/resume.html
Root-URL: http://www.cs.purdue.edu
Title: Arachne: A Portable Threads System Supporting Migrant Threads on Heterogeneous Network Farms  
Author: Bozhidar Dimitrov and Vernon Rego 
Keyword: heterogeneous thread migration, user-level threads, compile-time code transformations, C++  
Note: Supported in part by ONR-9310233, ARO-93G0045 and BMDO-34798-MA.  
Address: West Lafayette, IN 47907  
Affiliation: Department of Computer Sciences Purdue University  
Abstract: We present the design and implementation of Arachne, a threads system that can be interfaced with a communications library for multi-threaded distributed computations. In particular, Arachne supports thread migration between heterogeneous platforms, with dynamic stack size management and recursive thread functions. Arachne is efficient, flexible and portable | it is based entirely on C and C++. To facilitate heterogeneous thread operations, we have added three keywords to the C++ language. The Arachne preprocessor takes as input code written in that language, and outputs C++ code, suitable for compilation with a conventional C++ compiler. The Arachne runtime system manages all threads during program execution. We present some performance measurements on the costs of basic thread operations and thread migration in Arachne, and compare these to costs in other threads systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Banks and J. Carson. </author> <title> Process interaction simulation languages. </title> <journal> Simulation, </journal> <volume> 44(5) </volume> <pages> 225-235, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: In particular, we have significant experience with the use of threads in distributed simulations [13, 10, 16] and network protocols [6, 5, 7]. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model <ref> [1] </ref>, and are surprisingly easy to construct using threads [22]. Indeed, users need never know that powerful application-level constructs, provided in a domain-layer above a simulator kernel, are actually implemented in terms of threads. On large distributed-memory systems, multi-threading offers untold promise.
Reference: [2] <author> J. S. Chase, F. G. Amador, E. D. Lazowska, H. M. Levy, and R. J. Littlefield. </author> <title> The Amber System: Parallel Programming on a Network of Multiprocessors. </title> <booktitle> In Symposium on Operating System Principles, </booktitle> <pages> pages 147-158, </pages> <year> 1989. </year>
Reference-contexts: In either case we call the access a remote access, since it involves crossing a process boundary. 3 heterogeneous networked machines. On networks of homogeneous machines <ref> [15, 11, 2] </ref> thread contexts and stacks are well-defined across process boundaries and thus, in such environments, efficient migration is hinged upon conventional context and stack manipulation. On networks of heterogeneous machines, however, contexts and stacks are meaningless across architectures. <p> In general, user-space threads systems are runtime-only, and implement context-switch actions by using either assembly code [19] or C-library setjmp () and longjmp () primitives [15, 8]. Very few user-space systems support thread migration. Those that do (e.g., <ref> [2, 15, 19] </ref>) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type. In general, the Ariadne system [15, 14] is the least restrictive system in this class, and even provides support for time-slicing and user-defined scheduling.
Reference: [3] <author> E. Dijikstra and B. P. Scholten. </author> <title> Termination Detection for Diffusing Computations. </title> <journal> Information Processing Letters, </journal> <volume> 11(1) </volume> <pages> 1-4, </pages> <year> 1980. </year>
Reference-contexts: Such messages may potentially reactivate an idle process. Some termination algorithms (see, for example, <ref> [3] </ref>) assume specific network topologies. In Arachne, we use an algorithm that is capable of handling any topology|an algorithm that is also used by the Ariadne [15] threads system. This algorithm has proven to be simple and effective, and exhibits low demands on the network.
Reference: [4] <author> I. Foster, C. Kesselman, and S. Tuecke. </author> <title> The Nexus Approach to Integrating Multithreading and Communication. </title> <type> Technical report, </type> <institution> Argonne National Laboratory, </institution> <year> 1995. </year>
Reference-contexts: In the general case, there are many questions yet to be dealt with, particularly in regard to the semantics of threads-based messaging <ref> [4, 7] </ref> and the structure of computations with distributed communicating threads. Regardless of how these questions are eventually addressed, there are two factors that significantly impact upon the runtime performance of large systems of distributed threads: load-imbalance and non-local data access.
Reference: [5] <author> J. Gomez, E. Mascarenhas, and V. Rego. </author> <title> The CLAM Approach to Multithreaded Communication on Shared-Memory Multiprocessors: Design and Experiments. </title> <type> Technical report, </type> <note> Purdue 21 University CSD-TR (to appear in IEEE Transactions on Parallel & Distributed Systems), </note> <institution> West Lafayette, </institution> <note> IN 47907, </note> <year> 1998. </year>
Reference-contexts: Our motivation for designing and building threads systems lies in their ability to deliver requisite functionality and performance in different applications. In particular, we have significant experience with the use of threads in distributed simulations [13, 10, 16] and network protocols <ref> [6, 5, 7] </ref>. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22].
Reference: [6] <author> J. Gomez, V. Rego, and V. Sunderam. </author> <title> Scheduling Communication in Multithreaded Programs: Experimental Results. </title> <type> Technical Report TR-97, </type> <institution> Purdue University, West Lafayette, </institution> <note> IN 47907, </note> <year> 1997. </year>
Reference-contexts: Our motivation for designing and building threads systems lies in their ability to deliver requisite functionality and performance in different applications. In particular, we have significant experience with the use of threads in distributed simulations [13, 10, 16] and network protocols <ref> [6, 5, 7] </ref>. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22].
Reference: [7] <author> J. C. Gomez, V. Rego, and V. S. Sunderam. </author> <title> Efficient multithreaded user-space transport for network com puting: Design and test of the TRAP protocol. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 40(1) </volume> <pages> 103-117, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: Our motivation for designing and building threads systems lies in their ability to deliver requisite functionality and performance in different applications. In particular, we have significant experience with the use of threads in distributed simulations [13, 10, 16] and network protocols <ref> [6, 5, 7] </ref>. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22]. <p> In the general case, there are many questions yet to be dealt with, particularly in regard to the semantics of threads-based messaging <ref> [4, 7] </ref> and the structure of computations with distributed communicating threads. Regardless of how these questions are eventually addressed, there are two factors that significantly impact upon the runtime performance of large systems of distributed threads: load-imbalance and non-local data access.
Reference: [8] <author> IEEE. </author> <title> Information Technology|Portable Operating System Interface (POSIX)|Part 1: System Application Program Interface (API) [C Language]. </title> <address> Std. 1003.1c-1995, </address> <year> 1995. </year>
Reference-contexts: At the time a user-space thread is created, a limit must be provided for its stack size. In general, user-space threads systems are runtime-only, and implement context-switch actions by using either assembly code [19] or C-library setjmp () and longjmp () primitives <ref> [15, 8] </ref>. Very few user-space systems support thread migration. Those that do (e.g., [2, 15, 19]) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type.
Reference: [9] <author> E. Jul, H. Levy, N. Hutchinson, and A. Black. </author> <title> Fine-Grained Mobility in the Emerald System. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <year> 1988. </year>
Reference-contexts: Finally, there is the important issue of performance. It was found that the compiler developed in the project [24] took 60% longer to migrate and subsequently invoke a function than the Emerald compiler that supports only homogeneous thread migration <ref> [9] </ref>. SimCal The idea behind our design, especially the use of a code preprocessor, has its origins in work done by Malloy and Soffa [12]. By augmenting Pascal with certain Simula control structures, the authors defined a language called SimCal. <p> But there is one restriction: all points where a thread may be suspended must be known 2 Emerald <ref> [9] </ref> is a language in which objects may migrate between homogeneous machine architectures. 5 at the time of compilation.
Reference: [10] <author> F. Knop. </author> <title> Software Architectures for Fault-Tolerant Replications and Multithreaded Decompositions: Experiments with Practical Parallel Simulation. </title> <type> PhD thesis, </type> <institution> Purdue University, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: Our motivation for designing and building threads systems lies in their ability to deliver requisite functionality and performance in different applications. In particular, we have significant experience with the use of threads in distributed simulations <ref> [13, 10, 16] </ref> and network protocols [6, 5, 7]. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22]. <p> Once there, it resumes execution starting with the instruction immediately following the call to migrate. With appropriate layering and support for locating objects [15, 13], thread migration can be made transparent to end-users. We have successfully adopted this approach in the ParaSol parallel simulation system <ref> [13, 10, 16] </ref>, which exploits optimistic and adaptive simulation protocols. In this effort, we focus on the design of a threads system that supports thread migration on 1 The other process may be running on the same processor or on a remote machine.
Reference: [11] <author> K. Li. IVY: </author> <title> A shared virtual memory system for parallel computing. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 94-101, </pages> <year> 1988. </year>
Reference-contexts: In either case we call the access a remote access, since it involves crossing a process boundary. 3 heterogeneous networked machines. On networks of homogeneous machines <ref> [15, 11, 2] </ref> thread contexts and stacks are well-defined across process boundaries and thus, in such environments, efficient migration is hinged upon conventional context and stack manipulation. On networks of heterogeneous machines, however, contexts and stacks are meaningless across architectures.
Reference: [12] <author> B. Malloy and M. Soffa. </author> <title> Conversion of Simulation Processes to Pascal Constructs. </title> <journal> Software: Practice and Experience, </journal> 202(2) 191-207, February 1990. 
Reference-contexts: SimCal The idea behind our design, especially the use of a code preprocessor, has its origins in work done by Malloy and Soffa <ref> [12] </ref>. By augmenting Pascal with certain Simula control structures, the authors defined a language called SimCal. They were not interested in thread systems or thread migration, but wanted to add retentive control capabilities to Pascal.
Reference: [13] <author> E. Mascarenhas, F. Knop, and V. Rego. ParaSol: </author> <title> A Multi-threaded System for Parallel Simulation Based on Mobile Threads. </title> <booktitle> In Proceedings of the Winter Simulation Conference, </booktitle> <pages> pages 690-697, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Our motivation for designing and building threads systems lies in their ability to deliver requisite functionality and performance in different applications. In particular, we have significant experience with the use of threads in distributed simulations <ref> [13, 10, 16] </ref> and network protocols [6, 5, 7]. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22]. <p> By invoking a migration primitive on host A, a thread suspends its own execution on A and transfers to host B. Once there, it resumes execution starting with the instruction immediately following the call to migrate. With appropriate layering and support for locating objects <ref> [15, 13] </ref>, thread migration can be made transparent to end-users. We have successfully adopted this approach in the ParaSol parallel simulation system [13, 10, 16], which exploits optimistic and adaptive simulation protocols. <p> Once there, it resumes execution starting with the instruction immediately following the call to migrate. With appropriate layering and support for locating objects [15, 13], thread migration can be made transparent to end-users. We have successfully adopted this approach in the ParaSol parallel simulation system <ref> [13, 10, 16] </ref>, which exploits optimistic and adaptive simulation protocols. In this effort, we focus on the design of a threads system that supports thread migration on 1 The other process may be running on the same processor or on a remote machine.
Reference: [14] <author> E. Mascarenhas and V. Rego. </author> <title> Migrant Threads on Process Farms: Parallel Programming with Ariadne. </title> <type> Technical Report TR 95-081, </type> <institution> Department of Computer Sciences, Purdue University, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: Indeed, users need never know that powerful application-level constructs, provided in a domain-layer above a simulator kernel, are actually implemented in terms of threads. On large distributed-memory systems, multi-threading offers untold promise. Some inkling of this potential can be found in <ref> [14] </ref>, where four diverse applications are presented in the context of the Ariadne threads system [15]. While Ariadne supports threads on shared-memory, and|with the help of communication libraries|also on distributed-memory machines (e.g., Intel Paragon, workstation clusters), its threads can only migrate between homogeneous platforms. The examples provided in [14] include adaptive <p> found in <ref> [14] </ref>, where four diverse applications are presented in the context of the Ariadne threads system [15]. While Ariadne supports threads on shared-memory, and|with the help of communication libraries|also on distributed-memory machines (e.g., Intel Paragon, workstation clusters), its threads can only migrate between homogeneous platforms. The examples provided in [14] include adaptive quadrature for numerical integration and a parallel quicksort on shared-memory, and a linear solver based on SOR (successive over-relaxation) and a particle physics application on distributed-memory. The examples in [14] show how threads support, and in particular thread migration, enables a simpler distributed programming model than the standard <p> The examples provided in <ref> [14] </ref> include adaptive quadrature for numerical integration and a parallel quicksort on shared-memory, and a linear solver based on SOR (successive over-relaxation) and a particle physics application on distributed-memory. The examples in [14] show how threads support, and in particular thread migration, enables a simpler distributed programming model than the standard single-threaded model with send and receive primitives. <p> Threads from highly loaded processors may migrate to processors with less load. Though, in general, this is best done under the supervision 2 of an appropriate load-balancing algorithm, there are situations where such algorithms may not be necessary. For example, on shared-memory multiprocessors, Ariadne <ref> [15, 14] </ref> sees balanced loads as a direct result of placing runnable threads in a shared queue. To appreciate the utility of thread migration, consider a distributed (discrete-event) simulation application, for example, a large queuing system. Such a system may be used as a modeling abstraction of a telecommunication system. <p> Because of the lack of direct OS support, however, user-space threads exhibit some limitations. For example, user-space threads cannot be scheduled by the OS scheduler, though they may be scheduled (i.e., time-sliced, preempted) by a user-level threads scheduler <ref> [15, 14] </ref> that is not recognized by the OS. If a user-space thread blocks on a system call, the process that hosts this thread must also block. At the time a user-space thread is created, a limit must be provided for its stack size. <p> Very few user-space systems support thread migration. Those that do (e.g., [2, 15, 19]) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type. In general, the Ariadne system <ref> [15, 14] </ref> is the least restrictive system in this class, and even provides support for time-slicing and user-defined scheduling.
Reference: [15] <author> E. Mascarenhas and V. Rego. Ariadne: </author> <title> Architecture of a Portable Threads System Supporting Thread Migration. </title> <journal> Software Practice and Experience, </journal> <volume> 26(3) </volume> <pages> 327-357, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: On large distributed-memory systems, multi-threading offers untold promise. Some inkling of this potential can be found in [14], where four diverse applications are presented in the context of the Ariadne threads system <ref> [15] </ref>. While Ariadne supports threads on shared-memory, and|with the help of communication libraries|also on distributed-memory machines (e.g., Intel Paragon, workstation clusters), its threads can only migrate between homogeneous platforms. <p> Threads from highly loaded processors may migrate to processors with less load. Though, in general, this is best done under the supervision 2 of an appropriate load-balancing algorithm, there are situations where such algorithms may not be necessary. For example, on shared-memory multiprocessors, Ariadne <ref> [15, 14] </ref> sees balanced loads as a direct result of placing runnable threads in a shared queue. To appreciate the utility of thread migration, consider a distributed (discrete-event) simulation application, for example, a large queuing system. Such a system may be used as a modeling abstraction of a telecommunication system. <p> By invoking a migration primitive on host A, a thread suspends its own execution on A and transfers to host B. Once there, it resumes execution starting with the instruction immediately following the call to migrate. With appropriate layering and support for locating objects <ref> [15, 13] </ref>, thread migration can be made transparent to end-users. We have successfully adopted this approach in the ParaSol parallel simulation system [13, 10, 16], which exploits optimistic and adaptive simulation protocols. <p> In either case we call the access a remote access, since it involves crossing a process boundary. 3 heterogeneous networked machines. On networks of homogeneous machines <ref> [15, 11, 2] </ref> thread contexts and stacks are well-defined across process boundaries and thus, in such environments, efficient migration is hinged upon conventional context and stack manipulation. On networks of heterogeneous machines, however, contexts and stacks are meaningless across architectures. <p> Because of the lack of direct OS support, however, user-space threads exhibit some limitations. For example, user-space threads cannot be scheduled by the OS scheduler, though they may be scheduled (i.e., time-sliced, preempted) by a user-level threads scheduler <ref> [15, 14] </ref> that is not recognized by the OS. If a user-space thread blocks on a system call, the process that hosts this thread must also block. At the time a user-space thread is created, a limit must be provided for its stack size. <p> At the time a user-space thread is created, a limit must be provided for its stack size. In general, user-space threads systems are runtime-only, and implement context-switch actions by using either assembly code [19] or C-library setjmp () and longjmp () primitives <ref> [15, 8] </ref>. Very few user-space systems support thread migration. Those that do (e.g., [2, 15, 19]) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type. <p> In general, user-space threads systems are runtime-only, and implement context-switch actions by using either assembly code [19] or C-library setjmp () and longjmp () primitives [15, 8]. Very few user-space systems support thread migration. Those that do (e.g., <ref> [2, 15, 19] </ref>) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type. In general, the Ariadne system [15, 14] is the least restrictive system in this class, and even provides support for time-slicing and user-defined scheduling. <p> Very few user-space systems support thread migration. Those that do (e.g., [2, 15, 19]) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type. In general, the Ariadne system <ref> [15, 14] </ref> is the least restrictive system in this class, and even provides support for time-slicing and user-defined scheduling. <p> Such messages may potentially reactivate an idle process. Some termination algorithms (see, for example, [3]) assume specific network topologies. In Arachne, we use an algorithm that is capable of handling any topology|an algorithm that is also used by the Ariadne <ref> [15] </ref> threads system. This algorithm has proven to be simple and effective, and exhibits low demands on the network. In Arachne, a process is either active or inactive. Each thread created by a process is an offspring of that process. <p> We also intend to provide two mechanisms for obtaining multiple current threads of control on shared-memory multiprocessors. One mechanism is based on a kernel-space threads interface. 20 The other is based on Ariadne's multiprocess design <ref> [15] </ref>, meant for architectures that do not support kernel-space threads. Besides providing for a thread migration functionality, we also aimed for a robust and practical implementation.
Reference: [16] <author> E. Masceranhas. </author> <title> A System for Multithreaded Parallel Simulation and Computation with Migrant Threads and Objects. </title> <type> PhD thesis, </type> <institution> Purdue University, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: Our motivation for designing and building threads systems lies in their ability to deliver requisite functionality and performance in different applications. In particular, we have significant experience with the use of threads in distributed simulations <ref> [13, 10, 16] </ref> and network protocols [6, 5, 7]. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22]. <p> Once there, it resumes execution starting with the instruction immediately following the call to migrate. With appropriate layering and support for locating objects [15, 13], thread migration can be made transparent to end-users. We have successfully adopted this approach in the ParaSol parallel simulation system <ref> [13, 10, 16] </ref>, which exploits optimistic and adaptive simulation protocols. In this effort, we focus on the design of a threads system that supports thread migration on 1 The other process may be running on the same processor or on a remote machine.
Reference: [17] <author> J. A. Roskind. cpp5.y: </author> <title> Yacc-compatible input file defining a C++ grammar. </title> <note> ftp: ics.uci.edu:/pub/gnu/c++grammar2.0.tar.Z, e-mail: jar@netscape.com. </note>
Reference-contexts: If there is a need to output manipulated tokens or to insert code in the preprocessed stream, the parser turns the scanner output off, writes the necessary tokens, and then turns scanner output back on. To develop app, we extended the public C and C++ grammars written by Roskind <ref> [17, 18] </ref>. Our parser has 115 terminals, 186 non-terminals, 681 grammar rules, and 1290 states. Context-Switching between Threads While an Arachne program executes, the scheduler executes the following loop.
Reference: [18] <author> J. A. Roskind. cpp5.l: </author> <title> Flex input file defining a C++ lexical analyzer. </title> <address> ftp: ics.uci.edu:/pub/gnu/c++grammar2.0.tar.Z, e-mail: </address> <publisher> jar@netscape.com, </publisher> <pages> 1989-1990. </pages>
Reference-contexts: If there is a need to output manipulated tokens or to insert code in the preprocessed stream, the parser turns the scanner output off, writes the necessary tokens, and then turns scanner output back on. To develop app, we extended the public C and C++ grammars written by Roskind <ref> [17, 18] </ref>. Our parser has 115 terminals, 186 non-terminals, 681 grammar rules, and 1290 states. Context-Switching between Threads While an Arachne program executes, the scheduler executes the following loop.
Reference: [19] <author> J. Sang, F. Knop, V. Rego, J. Lee, and C. King. </author> <title> The Xthreads Library: </title> <booktitle> Design, Implementation and Applications. In Proceedings of the 17th Annual Computer Software and Applications Conference (COMPSAC '93), </booktitle> <month> November </month> <year> 1993. </year> <month> 22 </month>
Reference-contexts: At the time a user-space thread is created, a limit must be provided for its stack size. In general, user-space threads systems are runtime-only, and implement context-switch actions by using either assembly code <ref> [19] </ref> or C-library setjmp () and longjmp () primitives [15, 8]. Very few user-space systems support thread migration. Those that do (e.g., [2, 15, 19]) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type. <p> In general, user-space threads systems are runtime-only, and implement context-switch actions by using either assembly code [19] or C-library setjmp () and longjmp () primitives [15, 8]. Very few user-space systems support thread migration. Those that do (e.g., <ref> [2, 15, 19] </ref>) invariably impose some restrictions and, in particular, offer threads that can migrate only between machines of the same type. In general, the Ariadne system [15, 14] is the least restrictive system in this class, and even provides support for time-slicing and user-defined scheduling.
Reference: [20] <author> J. Sang, E. Mascarenhas, and V. Rego. </author> <title> Mobile-Process Based Parallel Simulation. </title> <journal> Journal of Parallel & Distributed Computing, </journal> <volume> 33(1) </volume> <pages> 12-23, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: In particular, we have significant experience with the use of threads in distributed simulations [13, 10, 16] and network protocols [6, 5, 7]. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si <ref> [20] </ref>) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22]. Indeed, users need never know that powerful application-level constructs, provided in a domain-layer above a simulator kernel, are actually implemented in terms of threads. On large distributed-memory systems, multi-threading offers untold promise.
Reference: [21] <author> J. Sang, G. Peters, and V. Rego. </author> <title> Thread Migration on Heterogeneous Systems via Compile-Time Transformations. </title> <booktitle> In Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS, </booktitle> <pages> pages 634-639, </pages> <year> 1994. </year>
Reference-contexts: Because of this, the formidable problems of context and stack translation make thread migration on heterogeneous systems a real challenge. To accommodate heterogeneity, we take a transformation-oriented approach that both builds upon and removes a limitation of our earlier work, namely the Ythreads <ref> [21] </ref> system. In Ythreads, each thread is allowed to perform thread operations (creation, changing priority, yielding, etc.) only within the base thread function associated with the thread. <p> Because transforming stacks at runtime is prohibitively complicated, our prior work, viz. the Ythreads system, advocated a solution based on the use of a preprocessor for an existing language <ref> [21] </ref>. With such a setup, the user writes programs in that language, preprocesses the code, and compiles with a conventional compiler. Though Ythreads provides for heterogeneous thread migration, it is limited in that thread primitives can only be invoked in top-level thread functions. They cannot be invoked in nested functions. <p> functions (the values of their local variables and the point reached in execution) in such a way that these thread functions can be restarted at a later time by an appropriate scheduling mechanism. 3 The Arachne System Arachne provides complete support for heterogeneous thread migration, building upon the Ythreads work <ref> [21] </ref>. But there is one restriction: all points where a thread may be suspended must be known 2 Emerald [9] is a language in which objects may migrate between homogeneous machine architectures. 5 at the time of compilation.
Reference: [22] <author> J. Sang and V. Rego. </author> <title> A Simulation Testbed based on Lightweight Processes. </title> <journal> Software, Practice & Experience, </journal> <volume> 24(5) </volume> <pages> 485-505, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM [23], Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads <ref> [22] </ref>. Indeed, users need never know that powerful application-level constructs, provided in a domain-layer above a simulator kernel, are actually implemented in terms of threads. On large distributed-memory systems, multi-threading offers untold promise.
Reference: [23] <author> H. D. Schwetman. </author> <title> Using CSIM to model complex systems. </title> <booktitle> In Proceedings of the Winter Simulation Conference, </booktitle> <pages> pages 246-253, </pages> <year> 1988. </year>
Reference-contexts: In particular, we have significant experience with the use of threads in distributed simulations [13, 10, 16] and network protocols [6, 5, 7]. Within the class of discrete-event simulation paradigms, for example, it is generally accepted that process-oriented simulations (e.g., CSIM <ref> [23] </ref>, Si [20]) offer the simplest programming model [1], and are surprisingly easy to construct using threads [22]. Indeed, users need never know that powerful application-level constructs, provided in a domain-layer above a simulator kernel, are actually implemented in terms of threads. On large distributed-memory systems, multi-threading offers untold promise.
Reference: [24] <author> B. Steensgaard and E. </author> <month> Jul. </month> <title> Object and native code thread mobility among heterogeneous computers. </title> <booktitle> In Proceedings of the ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 68-78, </pages> <year> 1995. </year>
Reference-contexts: Though Ythreads provides for heterogeneous thread migration, it is limited in that thread primitives can only be invoked in top-level thread functions. They cannot be invoked in nested functions. Emerald A somewhat similar effort has been reported in <ref> [24] </ref>, where a group of researchers rewrote an existing Emerald compiler in a way that enables heterogeneous thread migration. 2 This compiler examines the source code and inserts appropriate instructions immediately before migration requests. These instructions encode and pack a function's state. <p> Also, there are practical problems related to integrating Emerald threads and objects with software that already relies on some threads library. Finally, there is the important issue of performance. It was found that the compiler developed in the project <ref> [24] </ref> took 60% longer to migrate and subsequently invoke a function than the Emerald compiler that supports only homogeneous thread migration [9]. SimCal The idea behind our design, especially the use of a code preprocessor, has its origins in work done by Malloy and Soffa [12].
References-found: 24

