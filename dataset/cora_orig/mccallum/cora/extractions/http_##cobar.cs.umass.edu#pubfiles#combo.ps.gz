URL: http://cobar.cs.umass.edu/pubfiles/combo.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: flarkey,croftg@cs.umass.edu  
Title: Combining Classifiers in Text Categorization  
Author: Leah S. Larkey and W. Bruce Croft 
Address: Amherst, MA 01003-4610  
Affiliation: Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts  
Abstract: Three different types of classifiers were investigated in the context of a text categorization problem in the medical domain: the automatic assignment of ICD9 codes to dictated inpatient discharge summaries. K-nearest-neighbor, relevance feedback, and Bayesian independence classifers were applied individually and in combination. A combination of different classifiers produced better results than any single type of classifier. For this specific medical categorization problem, new query formulation and weighting methods used in the k-nearest-neighbor classifier improved performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James Allan, Lisa Ballesteros, James P. Callan, W. Bruce Croft, and Zhihong Lu. </author> <title> Recent experiments with INQUERY. </title> <editor> In Donna K. Harmon, editor, </editor> <booktitle> The Fourth Text REtrieval Conference (TREC-4), </booktitle> <address> Gaithersburg, MD, </address> <year> 1996. </year> <institution> National Institute of Standards and Technology, </institution> <note> special publication. To appear. </note>
Reference-contexts: The relevance feedback algorithm was essentially the same as that used in TREC4 <ref> [1] </ref> and is more fully described there. Relevance feedback began with null queries. First, 40 terms were chosen by comparing their oc currences in relevant and non-relevant training documents. A weighted sum query was built from these 40 terms with weights from the Rocchio formula applied to INQUERY's weighting scheme.
Reference: [2] <author> Chidinand Apte, Fred Damerau, and Sholom M. Weiss. </author> <title> Automated learning of decision rules for text categorization. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 12(3) </volume> <pages> 233-251, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The most common approaches use a large corpus of previously coded documents to infer codes for new documents. Many different algorithms have been used for text categorization, including k-nearest-neighbor algorithms [6, 26, 18], Bayesian independence classifiers [13], relevance feedback [21], and rule-induction algorithms from machine learning, like decision trees <ref> [2, 16] </ref>. These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text [29].
Reference: [3] <author> N. Belkin, C. Cool, W. Bruce Croft, and James P. Callan. </author> <title> The effect of multiple query representations on information retrieval system performance. </title> <booktitle> In Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 339-346, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Past research in information retrieval has shown that one can improve retrieval effectiveness by using multiple representations in indexing and query formulation [27] [19] <ref> [3] </ref> [11] and by using multiple search strategies [5] [24] [7]. In this work, we investigate whether we can attain similar improvements in the domain of text categorization by combining different representations and classification methods. Our domain is the automatic assignment of ICD9 codes to dictated inpatient discharge summaries.
Reference: [4] <author> Chris Buckley and Gerard Salton. </author> <title> Optimization of relevance feedback weights. </title> <booktitle> In Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 351-357, </pages> <year> 1995. </year>
Reference-contexts: A weighted sum query was built from these 40 terms with weights from the Rocchio formula applied to INQUERY's weighting scheme. Finally, the weights were adjusted using an iterative technique similar to that of Buckley and Salton and others <ref> [4, 20] </ref>. The relevance feedback classifier is very much like the Bayesian classifier. In our instantiation of the two approaches there are two major differences, concerning the use of term frequency and the use of terms that don't occur in relevant training documents.
Reference: [5] <author> W. B. Croft, T. J. Lucia, J. Cringean, and P. Willett. </author> <title> Retrieving documents by plausible inference: An experimental study. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 25(6) </volume> <pages> 599-614, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Past research in information retrieval has shown that one can improve retrieval effectiveness by using multiple representations in indexing and query formulation [27] [19] [3] [11] and by using multiple search strategies <ref> [5] </ref> [24] [7]. In this work, we investigate whether we can attain similar improvements in the domain of text categorization by combining different representations and classification methods. Our domain is the automatic assignment of ICD9 codes to dictated inpatient discharge summaries.
Reference: [6] <author> Richard O. Duda and Peter E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Because this coding determines reimbursement, it is important to accomplish this task as easily and as accurately as possible. The most common approaches use a large corpus of previously coded documents to infer codes for new documents. Many different algorithms have been used for text categorization, including k-nearest-neighbor algorithms <ref> [6, 26, 18] </ref>, Bayesian independence classifiers [13], relevance feedback [21], and rule-induction algorithms from machine learning, like decision trees [2, 16]. These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text [29]. <p> Each possible code is a category, and we want to determine whether documents belong in each category, or more generally, the probability that a document belongs in each category. We use three different classification techniques, a k-nearest-neighbor <ref> [6] </ref> approach using the belief scores from INQUERY as the distance metric, Bayesian independence classifiers [13], and relevance feedback [21]. At some time in the future, we may also experiment with direct lookup in the ICD-9-CM manuals (Alphabetic Index and TabularList). <p> Two subtasks, described in detail in [12], made up this part of the research: identifying document sections, and tuning the weights on the sections. Sections were identified heuristically. Weights were tuned using the tuning set divided into two sets with 255 documents each. We used a hill-climbing algorithm <ref> [6] </ref>, and accepted each successive change in weights that improved the first tuning set without hurting performance on the second tuning set. 2.3 Bayesian Independence Classifiers A set of 1068 classifiers were trained, one for each code that occurred 6 or more times in the training data, using the training corpus
Reference: [7] <author> Edward A. Fox and Joseph A. Shaw. </author> <title> Combination of multiple searches. </title> <editor> In Donna K. Harmon, editor, </editor> <booktitle> The Second Text REtrieval Conference (TREC-2), </booktitle> <pages> pages 243-252, </pages> <address> Gaithersburg, MD, </address> <year> 1994. </year> <institution> National Institute of Standards and Technology, </institution> <note> special publication 500-215. </note>
Reference-contexts: 1 Introduction Past research in information retrieval has shown that one can improve retrieval effectiveness by using multiple representations in indexing and query formulation [27] [19] [3] [11] and by using multiple search strategies [5] [24] <ref> [7] </ref>. In this work, we investigate whether we can attain similar improvements in the domain of text categorization by combining different representations and classification methods. Our domain is the automatic assignment of ICD9 codes to dictated inpatient discharge summaries.
Reference: [8] <author> Norbert Fuhr. </author> <title> Models for retrieval with probabilistic indexing. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 25(1) </volume> <pages> 55-72, </pages> <year> 1989. </year>
Reference-contexts: Various improvements to Maron's approach have been explored by other researchers <ref> [8, 15, 13] </ref>. We adopt a form of classifier very close to one used by Lewis [13]. Highlights of this probabilistic model are the following: A small set of features is selected separately for each code. Independent binary classifiers are trained for each ICD9 code. <p> Preliminary experiments showed that increasing the number of features above 40 per code did not improve performance. Classifiers were trained according to the probabilistic model described by Lewis [13], which was derived from a retrieval model proposed by Fuhr <ref> [8] </ref>. The model supports probabilistic indexing [8], however we implement a simplified version in which only estimates of 0 or 1 are used for the probability that a document has a feature. <p> Preliminary experiments showed that increasing the number of features above 40 per code did not improve performance. Classifiers were trained according to the probabilistic model described by Lewis [13], which was derived from a retrieval model proposed by Fuhr <ref> [8] </ref>. The model supports probabilistic indexing [8], however we implement a simplified version in which only estimates of 0 or 1 are used for the probability that a document has a feature.
Reference: [9] <author> Norbert Fuhr, Stephan Hartmann, Gerhard Lustig, Michael Schwantner, Konstadinos Tzeras, and Gerhard Knorz. </author> <title> AIR/X a rule-based multistage indexing system for large subject fields. </title> <booktitle> In Proceedings of the RIAO '91, </booktitle> <pages> pages 606-623, </pages> <address> Barcelona Spain, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts <ref> [9] </ref>, and medical text [29]. <p> Such an interactive system has proven useful to human experts in indexing physics abstracts <ref> [9] </ref> and may be useful in coding patient records. 4.3 Future Directions Our next step is to take advantage of yet another level of structure in these documents. <p> Another advantage of a two-level classifier would be to capture co-occurrence patterns among different classifers, as Fuhr, et. al. do in the AIR/X system <ref> [9] </ref>. Our current models lose this information because classifiers for each code are completely independent of each other. 5 Acknowledgments We would like to thank David Aronow for his help in categorizing the section titles in the documents.
Reference: [10] <author> Donna K. Harmon, </author> <title> editor. </title> <booktitle> The Third Text REtrieval Conference (TREC-3), </booktitle> <address> Gaithersburg, MD, </address> <year> 1995. </year> <institution> National Institute of Standards and Technology, </institution> <note> special publication 500-225. </note>
Reference: [11] <author> J. Katzer, M.J. McGill, J.A. Tessier, W. Frakes, and P. DasGupta. </author> <title> A study of the overlap among document representations. </title> <journal> Information Technology: Research and Development, </journal> <volume> 1 </volume> <pages> 261-274, </pages> <year> 1982. </year> <month> 9 </month>
Reference-contexts: 1 Introduction Past research in information retrieval has shown that one can improve retrieval effectiveness by using multiple representations in indexing and query formulation [27] [19] [3] <ref> [11] </ref> and by using multiple search strategies [5] [24] [7]. In this work, we investigate whether we can attain similar improvements in the domain of text categorization by combining different representations and classification methods. Our domain is the automatic assignment of ICD9 codes to dictated inpatient discharge summaries.
Reference: [12] <author> Leah S. Larkey and W. Bruce Croft. </author> <title> Automatic assign-ment of ICD9 codes to discharge summaries. </title> <type> Technical Report IR-64, </type> <institution> University of Massachusetts Center for Intelligent Information Retrieval, </institution> <year> 1995. </year>
Reference-contexts: Because the discharge summaries contain large amounts of text that are not relevant to the coding task, we have incorporated a method for differentially weighting sections that provide the most diagnostic evidence, described in <ref> [12] </ref>. For the Bayesian and relevance feedback classifiers, the documents are represented by a small set of features (terms, phrases), and they are selected by slightly different criteria. We do not try to make representations consistent across classifiers. <p> We have tested several different weighting methods for determining w ic , which are discussed in <ref> [12] </ref>. <p> Besides manipulating document-score weighting, we experimented with query formulation, turning the 187 test documents into structured queries using #wsum (weighted sum) and #sum operators, as in Figure 3. Two subtasks, described in detail in <ref> [12] </ref>, made up this part of the research: identifying document sections, and tuning the weights on the sections. Sections were identified heuristically. Weights were tuned using the tuning set divided into two sets with 255 documents each. <p> The model supports probabilistic indexing [8], however we implement a simplified version in which only estimates of 0 or 1 are used for the probability that a document has a feature. The model also considers features which are absent in the test document, which many models do not. (See <ref> [12] </ref> for more detail.) The classifier yields an estimate of the log probability that a code is assigned to a test document. We do not attempt to determine a threshold and make a binary membership decision.
Reference: [13] <author> David Lewis. </author> <title> An evaluation of phrasal and clustered representations on a text categorization task. </title> <booktitle> In Proceedings of the Fifteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 37-50, </pages> <year> 1992. </year>
Reference-contexts: The most common approaches use a large corpus of previously coded documents to infer codes for new documents. Many different algorithms have been used for text categorization, including k-nearest-neighbor algorithms [6, 26, 18], Bayesian independence classifiers <ref> [13] </ref>, relevance feedback [21], and rule-induction algorithms from machine learning, like decision trees [2, 16]. These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text [29]. <p> We use three different classification techniques, a k-nearest-neighbor [6] approach using the belief scores from INQUERY as the distance metric, Bayesian independence classifiers <ref> [13] </ref>, and relevance feedback [21]. At some time in the future, we may also experiment with direct lookup in the ICD-9-CM manuals (Alphabetic Index and TabularList). <p> Various improvements to Maron's approach have been explored by other researchers <ref> [8, 15, 13] </ref>. We adopt a form of classifier very close to one used by Lewis [13]. Highlights of this probabilistic model are the following: A small set of features is selected separately for each code. Independent binary classifiers are trained for each ICD9 code. <p> Various improvements to Maron's approach have been explored by other researchers [8, 15, 13]. We adopt a form of classifier very close to one used by Lewis <ref> [13] </ref>. Highlights of this probabilistic model are the following: A small set of features is selected separately for each code. Independent binary classifiers are trained for each ICD9 code. Bayes theorem is used to estimate the probability of category membership for each category and each document. <p> The exceptions were codes with few training examples, where fewer than forty terms met the criteria. Preliminary experiments showed that increasing the number of features above 40 per code did not improve performance. Classifiers were trained according to the probabilistic model described by Lewis <ref> [13] </ref>, which was derived from a retrieval model proposed by Fuhr [8]. The model supports probabilistic indexing [8], however we implement a simplified version in which only estimates of 0 or 1 are used for the probability that a document has a feature.
Reference: [14] <author> David Lewis. </author> <title> Evaluating and optimizing autonomous text classification systems. </title> <booktitle> In Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 246-254, </pages> <year> 1995. </year>
Reference-contexts: Instead we take advantage of the diversity of the representations when the classifiers are combined. These classification techniques yield a ranked list of codes (categories) for each document. A purely automatic coder would need cutoff criteria for which codes should actually get assigned. Lewis <ref> [14] </ref> has argued that in evaluating a classification system, one should use effectiveness measures based on estimates of class membership rather than measures based on rankings, like recall-precision.
Reference: [15] <author> David D. Lewis. </author> <title> Representation and Learning in Information Retrieval. </title> <type> PhD thesis, </type> <institution> University of Mas-sachusetts, </institution> <year> 1992. </year>
Reference-contexts: Various improvements to Maron's approach have been explored by other researchers <ref> [8, 15, 13] </ref>. We adopt a form of classifier very close to one used by Lewis [13]. Highlights of this probabilistic model are the following: A small set of features is selected separately for each code. Independent binary classifiers are trained for each ICD9 code.
Reference: [16] <author> David D. Lewis and Marc Ringuette. </author> <title> A comparison of two learning algorithms for text categorization. </title> <booktitle> In Third Annual Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pages 81-93, </pages> <institution> University of Nevada, </institution> <address> Las Vegas, </address> <year> 1994. </year>
Reference-contexts: The most common approaches use a large corpus of previously coded documents to infer codes for new documents. Many different algorithms have been used for text categorization, including k-nearest-neighbor algorithms [6, 26, 18], Bayesian independence classifiers [13], relevance feedback [21], and rule-induction algorithms from machine learning, like decision trees <ref> [2, 16] </ref>. These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text [29].
Reference: [17] <author> M.E. Maron. </author> <title> Automatic indexing: An experimental inquiry. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 8 </volume> <pages> 404-417, </pages> <year> 1961. </year>
Reference-contexts: We consider not only whether a category (code) is assigned to a retrieved document, but also whether that category is the principal diagnosis code for the retrieved document. 1.2 Bayesian Independence Classifier The Bayesian independence classifier was first proposed by Maron <ref> [17] </ref> as a way to estimate a probability that a category or key word should be assigned to a document, given the presence of "clue words" in the document. Various improvements to Maron's approach have been explored by other researchers [8, 15, 13].
Reference: [18] <author> Brij Masand, Gordon Linoff, and David Waltz. </author> <title> Classifying news stories using memory based reasoning. </title> <booktitle> In Proceedings of the Fifteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 59-65, </pages> <year> 1992. </year>
Reference-contexts: Because this coding determines reimbursement, it is important to accomplish this task as easily and as accurately as possible. The most common approaches use a large corpus of previously coded documents to infer codes for new documents. Many different algorithms have been used for text categorization, including k-nearest-neighbor algorithms <ref> [6, 26, 18] </ref>, Bayesian independence classifiers [13], relevance feedback [21], and rule-induction algorithms from machine learning, like decision trees [2, 16]. These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text [29]. <p> The already-coded documents make up an INQUERY database, and the to-be-coded coded documents (also referred to as test documents) are queries attempting to retrieve similar documents from the database. A similar approach has been used for other classification tasks and is sometimes referred to as memory-based reasoning <ref> [18] </ref> [26]. Our approach is similar to that of Yang and Chute [29] except that we use INQUERY rather than cosine similarity for the similarity metric. We go beyond their work in representing the document as a structured query, and in combining k-nearest-neighbor with other classifiers.
Reference: [19] <author> T. B. Rajashekar and W. Bruce Croft. </author> <title> Combining automatic and manual index representations in probabilistic retrieval. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 6(4) </volume> <pages> 272-283, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Past research in information retrieval has shown that one can improve retrieval effectiveness by using multiple representations in indexing and query formulation [27] <ref> [19] </ref> [3] [11] and by using multiple search strategies [5] [24] [7]. In this work, we investigate whether we can attain similar improvements in the domain of text categorization by combining different representations and classification methods. Our domain is the automatic assignment of ICD9 codes to dictated inpatient discharge summaries.
Reference: [20] <author> S. Robertson, S. Walker, S. Jones, M.M. Hancock-Beaulieu, and M. Gatford. </author> <note> Okapi at TREC-3. In Har-mon [10]. </note>
Reference-contexts: A weighted sum query was built from these 40 terms with weights from the Rocchio formula applied to INQUERY's weighting scheme. Finally, the weights were adjusted using an iterative technique similar to that of Buckley and Salton and others <ref> [4, 20] </ref>. The relevance feedback classifier is very much like the Bayesian classifier. In our instantiation of the two approaches there are two major differences, concerning the use of term frequency and the use of terms that don't occur in relevant training documents.
Reference: [21] <author> J.J. Rocchio. </author> <title> Relevance feedback in information retrieval. </title> <editor> In Gerard Salton, editor, </editor> <title> The SMART Retrieval System Experiments in Automatic Document Processing, chapter 14. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1971. </year>
Reference-contexts: The most common approaches use a large corpus of previously coded documents to infer codes for new documents. Many different algorithms have been used for text categorization, including k-nearest-neighbor algorithms [6, 26, 18], Bayesian independence classifiers [13], relevance feedback <ref> [21] </ref>, and rule-induction algorithms from machine learning, like decision trees [2, 16]. These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text [29]. <p> We use three different classification techniques, a k-nearest-neighbor [6] approach using the belief scores from INQUERY as the distance metric, Bayesian independence classifiers [13], and relevance feedback <ref> [21] </ref>. At some time in the future, we may also experiment with direct lookup in the ICD-9-CM manuals (Alphabetic Index and TabularList). <p> The original query and terms from the indicated relevant documents are combined to produce a new query which is better at ranking relevant documents over nonrelevant documents. Term weights in the new query depend upon the occurrence of the terms in relevant and nonrelevant documents <ref> [21, 23] </ref>. Although the original query typically plays an important role in relevance feedback, it does not have to.
Reference: [22] <author> Gerard Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: These measures reflect the success at getting all the codes as high as possible in the list of candidates without considering a cutoff for acceptance. Average 11 point precision. Precision and recall have been standard measures of retrieval effectiveness in information retrieval <ref> [22] </ref>. When the task is retrieval, these measures are computed from the ranked list of documents retrieved for each query.
Reference: [23] <author> Gerard Salton and Chris Buckley. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(4) </volume> <pages> 288-297, </pages> <year> 1990. </year>
Reference-contexts: The original query and terms from the indicated relevant documents are combined to produce a new query which is better at ranking relevant documents over nonrelevant documents. Term weights in the new query depend upon the occurrence of the terms in relevant and nonrelevant documents <ref> [21, 23] </ref>. Although the original query typically plays an important role in relevance feedback, it does not have to.
Reference: [24] <author> Joseph A. Shaw and Edward A. Fox. </author> <title> Combination of multiple searches. </title> <note> In Harmon [10]. </note>
Reference-contexts: 1 Introduction Past research in information retrieval has shown that one can improve retrieval effectiveness by using multiple representations in indexing and query formulation [27] [19] [3] [11] and by using multiple search strategies [5] <ref> [24] </ref> [7]. In this work, we investigate whether we can attain similar improvements in the domain of text categorization by combining different representations and classification methods. Our domain is the automatic assignment of ICD9 codes to dictated inpatient discharge summaries.
Reference: [25] <author> Stephen Soderland, David Fisher, Jon Aseltine, and Wendy Lehnert. </author> <title> CRYSTAL: Inducing a conceptual dictionary. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Our associates are using NLP techniques to tag phrases in the discharge summaries with five subtypes each of diagnoses and signs or symptoms <ref> [25] </ref>. Our hypothesis is that performance will be improved by giving more weight to these items in k-nearest-neighbor classification, or to consider such phrases as candidate features along with the single terms we now use in the Bayesian or relevance feedback classifiers.
Reference: [26] <author> C. Stanfill and David Waltz. </author> <title> Toward memory-based reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1213-1228, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Because this coding determines reimbursement, it is important to accomplish this task as easily and as accurately as possible. The most common approaches use a large corpus of previously coded documents to infer codes for new documents. Many different algorithms have been used for text categorization, including k-nearest-neighbor algorithms <ref> [6, 26, 18] </ref>, Bayesian independence classifiers [13], relevance feedback [21], and rule-induction algorithms from machine learning, like decision trees [2, 16]. These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text [29]. <p> The already-coded documents make up an INQUERY database, and the to-be-coded coded documents (also referred to as test documents) are queries attempting to retrieve similar documents from the database. A similar approach has been used for other classification tasks and is sometimes referred to as memory-based reasoning [18] <ref> [26] </ref>. Our approach is similar to that of Yang and Chute [29] except that we use INQUERY rather than cosine similarity for the similarity metric. We go beyond their work in representing the document as a structured query, and in combining k-nearest-neighbor with other classifiers.
Reference: [27] <author> Howard Turtle and W. Bruce Croft. </author> <title> Evaluation of an inference network-based retrieval model. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 9(3) </volume> <pages> 187-222, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Past research in information retrieval has shown that one can improve retrieval effectiveness by using multiple representations in indexing and query formulation <ref> [27] </ref> [19] [3] [11] and by using multiple search strategies [5] [24] [7]. In this work, we investigate whether we can attain similar improvements in the domain of text categorization by combining different representations and classification methods. <p> This material is based on work supported by the National Science Foundation, Library of Congress, and Department of Commerce under cooperative agreement number EEC-9209623 and on work supported by NRaD Contract Number N66001-94-D-6054. coding, all of them incorporating INQUERY, a probabilistic information retrieval system based on an inference net model <ref> [27] </ref>. Each possible code is a category, and we want to determine whether documents belong in each category, or more generally, the probability that a document belongs in each category.
Reference: [28] <editor> C.J. van Rijsbergen. </editor> <booktitle> Information Retrieval. </booktitle> <address> Butter-worths, London, </address> <note> second edition, </note> <year> 1979. </year>
Reference-contexts: MEDICATIONS ON ADMISSION: At the time of admission, the patient was on Ferrous Sulfate 325 mg po t.i.d. ALLERGIES: NKDA. ) . . . ) (stemmed terms) were chosen for each classifier (code) according to mutual information <ref> [28] </ref>, subject to the following constraints: Terms must have length &gt;1, they cannot begin with a digit, they must contain at least one alphabetic character, they must co-occur at least two times with the code. Forty terms were obtained for most codes.
Reference: [29] <author> Yiming Yang and Christopher G. Chute. </author> <title> An application of Expert Network to clinical classification and MEDLINE indexing. </title> <booktitle> In Proceedings of the Eighteenth Annual Symposium on Computer Applications in Medical Care, </booktitle> <pages> pages 157-161, </pages> <year> 1994. </year> <month> 10 </month>
Reference-contexts: These categorization algorithms have been applied to many different subject domains, usually news stories, but also physics abstracts [9], and medical text <ref> [29] </ref>. <p> A similar approach has been used for other classification tasks and is sometimes referred to as memory-based reasoning [18] [26]. Our approach is similar to that of Yang and Chute <ref> [29] </ref> except that we use INQUERY rather than cosine similarity for the similarity metric. We go beyond their work in representing the document as a structured query, and in combining k-nearest-neighbor with other classifiers. <p> Clearly performance is better when each code has 25 or more training examples. 4.2 Comparison with other research How do these results compare to other attempts at automatic coding and categorization in the medical domain? Researchers at the Mayo Clinic <ref> [29] </ref> have used a method called ExpNet which is very similar to our k-nearest-neighbor classifier and which yields performance very similar to that of our k-nearest-neighbor classifier when applied to a problem with similar parameters.
References-found: 29

