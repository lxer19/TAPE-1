URL: ftp://ftp.cs.utexas.edu/pub/garbage/kakkad-dissertation.ps.gz
Refering-URL: http://www.cs.utexas.edu/users/oops/papers.html
Root-URL: http://www.cs.utexas.edu
Title: Address Translation and Storage Management for Persistent Object Stores  
Degree: by Sheetal Vinod Kakkad, B.E., M.S.C.S. Dissertation Presented to the Faculty of the Graduate School of  in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: December 1997  
Address: Austin  Austin  
Affiliation: The University of Texas at  The University of Texas at  
Abstract-found: 0
Intro-found: 1
Reference: [ABC + 83a] <author> Malcolm P. Atkinson, Peter J. Bailey, Ken J. Chisholm, W. Paul Cockshott, and Ron Morrison. </author> <title> An Approach to Persistent Programming. </title> <journal> Computer Journal, </journal> <volume> 26(4) </volume> <pages> 360-365, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: Introduction It is often desirable to support a virtual address space that is larger than what can be specified directly by the word size of the available hardware. Applications such as persistent object stores (e.g., <ref> [ABC + 83a, SKW92, DSZ90, AM92] </ref>), operating systems with a single shared address space (e.g., [CLLBH92]), distributed shared memories (e.g., [Li86]), etc. can benefit from large address spaces. <p> Also, this approach does not work for builtin types because their definitions cannot be changed easily in most languages. Unlike class-based persistence, orthogonal persistence <ref> [ABC + 83a, AM95] </ref> decouples the lifetime of an object from its type. In other words, persistence is viewed as a storage class 2 rather than as a property of the object type. <p> Since persistence is decoupled from the type system, this approach supports a clean implementation model that is transparent to the application programmer who does not need to make any major modifications to the application code to use the persistence mechanism. Finally, reachability-based persistence <ref> [ABC + 83a, ACCM83] </ref> is a general form of orthogonal persistence. The basic principle of this approach requires that all objects reachable from a well-defined persistent root (or roots) automatically become persistent. <p> We focus exclusively on advanced languages that support object-oriented data models, and do not discuss database programming languages (e.g., Pascal/R, RIGEL, etc.) that extend relational programming techniques because the former are more relevant to our research. PS-algol PS-algol <ref> [ACC82, ABC + 83a, ABC + 83b] </ref> was the first truly persistent programming language, and has contributed much to the study and development of efficient persistent systems. The notion of orthogonal persistence was pioneered in the implementation of PS-algol, which supports full reachability-based orthogonal persistence. <p> Texas (Chapter 4) and other persistent object stores <ref> [ABC + 83a, AM95, LLOW91, WD94] </ref> that use pointer swizzling techniques such as pointer swizzling at page fault time need to know the locations of pointers in data objects at run time in order to find and manipulate these pointers correctly.
Reference: [ABC + 83b] <author> Malcolm P. Atkinson, Peter J. Bailey, Ken J. Chisholm, W. Paul Cockshott, and Ron Morrison. </author> <title> PS-Algol: A Language for Persistent Programming. </title> <booktitle> In Proceedings of the 10th Australian National Computer Conference, </booktitle> <pages> pages 70-79, </pages> <address> Melbourne, Australia, </address> <year> 1983. </year>
Reference-contexts: We focus exclusively on advanced languages that support object-oriented data models, and do not discuss database programming languages (e.g., Pascal/R, RIGEL, etc.) that extend relational programming techniques because the former are more relevant to our research. PS-algol PS-algol <ref> [ACC82, ABC + 83a, ABC + 83b] </ref> was the first truly persistent programming language, and has contributed much to the study and development of efficient persistent systems. The notion of orthogonal persistence was pioneered in the implementation of PS-algol, which supports full reachability-based orthogonal persistence.
Reference: [ABM + 90] <author> T. Lougenia Anderson, Arne J. Berre, Moira Mallison, Harry T. Porter, and Bruce Schneider. </author> <title> The HyperModel Benchmark. </title> <booktitle> In Proceedings of the International Conference on Extending Database Technology, </booktitle> <pages> pages 317-331, </pages> <address> Venice, Italy, </address> <year> 1990. </year>
Reference-contexts: OO1 was also one of the first widely-used database benchmarks, followed by others such the HyperModel <ref> [ABM + 90] </ref> and OO7 [CDN93] benchmarks. The OO7 benchmark is designed as a successor to the OO1 benchmark, and supports some advanced data structures and complex operations over these structures to represent a hypothetical CAD application. We used OO1 for all our performance measurements because of several fundamental reasons.
Reference: [ACC82] <author> Malcolm P. Atkinson, Ken J. Chisholm, and W. Paul Cockshott. </author> <title> PS-Algol: An Algol with a Persistent Heap. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 17(7) </volume> <pages> 24-31, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: We focus exclusively on advanced languages that support object-oriented data models, and do not discuss database programming languages (e.g., Pascal/R, RIGEL, etc.) that extend relational programming techniques because the former are more relevant to our research. PS-algol PS-algol <ref> [ACC82, ABC + 83a, ABC + 83b] </ref> was the first truly persistent programming language, and has contributed much to the study and development of efficient persistent systems. The notion of orthogonal persistence was pioneered in the implementation of PS-algol, which supports full reachability-based orthogonal persistence.
Reference: [ACCM83] <author> Malcolm P. Atkinson, Ken J. Chisholm, W. Paul Cockshott, and Richard Mar-shall. </author> <title> Algorithms for a Persistent Heap. </title> <journal> Software Practice and Experience, </journal> <volume> 13(3) </volume> <pages> 259-272, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: Since persistence is decoupled from the type system, this approach supports a clean implementation model that is transparent to the application programmer who does not need to make any major modifications to the application code to use the persistence mechanism. Finally, reachability-based persistence <ref> [ABC + 83a, ACCM83] </ref> is a general form of orthogonal persistence. The basic principle of this approach requires that all objects reachable from a well-defined persistent root (or roots) automatically become persistent.
Reference: [AEL88] <author> Andrew W. Appel, John R. Ellis, and Kai Li. </author> <title> Real-Time Concurrent Garbage Collection on Stock Multiprocessors. </title> <booktitle> In Proceedings of the 1988 SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20, </pages> <address> At-lanta, Georgia, June 1988. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Of course, address space for any other page (s) not already reserved (page E in our example) must be allocated and access-protected as usual. Our approach is analogous to that of Appel, Ellis and Li's incremental copying garbage collection scheme <ref> [AEL88] </ref> which, in turn, is a variation incremental copying scheme described by Baker [Bak78, Bak91]. However, unlike the Appel-Ellis-Li model which incrementally relocates objects from from-space to to-space, our scheme relocates pages of objects from persistent memory to transient memory. <p> To support incremental copying/faulting of large objects, the language implementation must support operations for locating object boundaries and maintaining mapping tables to track pages that belong to large objects. These requirements are similar to those of garbage collected systems that must perform page-wise (or "card-wise") operations <ref> [AEL88, WM89] </ref> 5 An example of such an object would be a large array which spans multiple pages, even though the size of each individual element may be smaller than a page. 43 within the heap. <p> Most of this interaction stems from the use of virtual memory protection and access-protection violation handling for implementing coarse-grained address translation. In addition to Texas, there are many other useful system-level extensions and libraries (for example, garbage collectors <ref> [AEL88, Wil97] </ref>, distributed shared virtual memory systems [Li86, LH89], virtual memory tracing and compression facilities [WKBK97, WKB97a], advanced profiling, etc.) that closely interact with the operating system. We believe that operating system implementors should take interactions of such low-level systems and libraries into consideration when designing new systems.
Reference: [AL91] <author> Andrew W. Appel and Kai Li. </author> <title> Virtual Memory Primitives For User Programs. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV) [ASP91], </booktitle> <pages> pages 96-107. </pages>
Reference-contexts: Examples of other applications include garbage collectors, distributed shared virtual memory systems, and compressed virtual memory. With a wide variety of "non-traditional" uses for exceptions <ref> [AL91] </ref>, it is becoming increasingly necessary that operating system implementors recognize the need for efficient exception handling and improve their implementations appropriately. Experimental Design We have measured the performance of access-protection violation handling on both Solaris and Linux using our clock cycle timer. <p> A cost effective approach to bridge this gap is to introduce a new level into the memory hierarchy. Compressed in-memory storage uses part of main memory as a cache for compressed pages <ref> [Wil90, WLM91, Wil91, AL91, Dou93] </ref>; this divides the main memory into partitions for uncompressed pages and compressed pages. The use of compressed in-memory storage can improve overall system performance because "paging" from the compression cache may be faster than paging from disk.
Reference: [ALBL91] <author> Thomas E. Anderson, Henry M. Levy, Brian N. Bershad, and Edward D. La-zowska. </author> <title> The Interaction of Architecture and Operating Systems Design. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV) [ASP91], </booktitle> <pages> pages 108-120. </pages>
Reference-contexts: This is an extremely impressive result, given that our best performance on Linux is more than an order of magnitude slower. Anderson et al. <ref> [ALBL91] </ref> have discussed the interaction between hardware architecture and operating systems, including virtual memory and fault handling. 7.5.2 Virtual Memory Page Size and Sub-page Protections Pointer swizzling at page fault time generally benefits from the use of a smaller page size because it reduces the amount of swizzling that is required
Reference: [AM92] <editor> Antonio Albano and Ron Morrison, editors. </editor> <booktitle> Fifth International Workshop on Persistent Object Systems, </booktitle> <address> San Miniato, Italy, </address> <month> September </month> <year> 1992. </year> <note> Springer-Verlag. </note>
Reference-contexts: Introduction It is often desirable to support a virtual address space that is larger than what can be specified directly by the word size of the available hardware. Applications such as persistent object stores (e.g., <ref> [ABC + 83a, SKW92, DSZ90, AM92] </ref>), operating systems with a single shared address space (e.g., [CLLBH92]), distributed shared memories (e.g., [Li86]), etc. can benefit from large address spaces.
Reference: [AM95] <author> Malcolm P. Atkinson and Ron Morrison. </author> <title> Orthogonally Persistent Object Systems. </title> <journal> VLDB Journal, </journal> <volume> 4(3), </volume> <year> 1995. </year> <month> 193 </month>
Reference-contexts: Also, this approach does not work for builtin types because their definitions cannot be changed easily in most languages. Unlike class-based persistence, orthogonal persistence <ref> [ABC + 83a, AM95] </ref> decouples the lifetime of an object from its type. In other words, persistence is viewed as a storage class 2 rather than as a property of the object type. <p> As discussed in Chapter 2, we use pointer swizzling at page fault time to implement orthogonal persistence <ref> [AM95] </ref>. The orthogonal persistence model allows both transient and persistent objects to be treated in exactly the same way. This allows existing code, typically object code libraries, to be linked with an application without requiring any recompilation, as long as these libraries do not need to create persistent objects. <p> Texas (Chapter 4) and other persistent object stores <ref> [ABC + 83a, AM95, LLOW91, WD94] </ref> that use pointer swizzling techniques such as pointer swizzling at page fault time need to know the locations of pointers in data objects at run time in order to find and manipulate these pointers correctly.
Reference: [ARG89] <author> Vadim Abrossimov, Marc Rozier, and Michel Gien. </author> <title> Virtual Memory Manage--ment in Chorus. </title> <booktitle> In Proceedings of Workshop on Progress in Distributed Operating Systems and Distributed Systems Management, </booktitle> <address> Berlin, Germany, </address> <month> April </month> <year> 1989. </year> <note> Springer-Verlag. Also Chorus systemes TR CS/TR-89-30. </note>
Reference-contexts: Some operating systems such as Mach [BKLL93], Choices [Rus91], and Chorus <ref> [ARG89] </ref> already provide some form of external memory management. Mach allows user-level tasks to act as external pagers that fully control the use of memory within the process address space.
Reference: [ASP91] <institution> Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV), </institution> <address> Santa Clara, California, </address> <month> April </month> <year> 1991. </year>
Reference: [Bak78] <author> Henry G. Baker, Jr. </author> <title> List Processing in Real Time on a Serial Computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: Our approach is analogous to that of Appel, Ellis and Li's incremental copying garbage collection scheme [AEL88] which, in turn, is a variation incremental copying scheme described by Baker <ref> [Bak78, Bak91] </ref>. However, unlike the Appel-Ellis-Li model which incrementally relocates objects from from-space to to-space, our scheme relocates pages of objects from persistent memory to transient memory.
Reference: [Bak91] <author> Henry G. Baker, Jr. </author> <title> The Treadmill: Real-Time Garbage Collection without Motion Sickness. </title> <booktitle> In OOPSLA '91 Workshop on Garbage Collection in Object-Oriented Systems, </booktitle> <month> October </month> <year> 1991. </year> <note> Position paper. Also appears as ACM SIGPLAN Notices 27(3) 66-70, </note> <month> March </month> <year> 1992. </year>
Reference-contexts: Our approach is analogous to that of Appel, Ellis and Li's incremental copying garbage collection scheme [AEL88] which, in turn, is a variation incremental copying scheme described by Baker <ref> [Bak78, Bak91] </ref>. However, unlike the Appel-Ellis-Li model which incrementally relocates objects from from-space to to-space, our scheme relocates pages of objects from persistent memory to transient memory.
Reference: [BC92] <editor> Yves Bekkers and Jacques Cohen, editors. </editor> <booktitle> International Workshop on Memory Management, number 637 in Lecture Notes in Computer Science, </booktitle> <address> St. Malo, France, </address> <month> September </month> <year> 1992. </year> <note> Springer-Verlag. </note>
Reference: [BJLM92] <author> Michael Burrows, Charles Jerian, Butler Lampson, and Timothy Mann. </author> <title> Online Data Compression in a Log-structured File System. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS V), </booktitle> <pages> pages 2-9, </pages> <address> Boston, Massachusetts, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: It should be noted that unlike other compression-based memory management schemes, our primary goal is not to increase the available disk storage, but to increase system throughput by reducing the average memory latency and increasing effective performance. Our system should also give benefits similar to those of file-compression schemes <ref> [CG91, BJLM92] </ref>. Further research is currently underway and detailed results will be presented in an upcoming paper [WKB97a]. 8.3 Advanced Issues In Chapter 1, we briefly mentioned some advanced issues that are beyond the scope of this dissertation.
Reference: [BKLL93] <author> Joseph Boykin, David Kirschen, Alan Langerman, and Susan LoVerso. </author> <title> Programming under Mach. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: An even better approach is to modify operating systems to support external memory management mechanisms. Operating systems that support such models already exist (e.g., Mach <ref> [BKLL93] </ref>, and L3/L4 microkernels [Lie95]) and can be exploited. For example, Mach supports external pagers which can be used as pointer swizzling servers to swizzle pages before loading them into memory so that they appear clean to the virtual memory system. <p> Texas could easily be modified to evict pages back to the persistent store, given control over page-outs. One approach for achieving this is to use something similar to Mach's external pager facility <ref> [BKLL93] </ref>, but it would make the system somewhat more complex and less portable. We will discuss this issue in detail in Chapter 7. It is also possible to implement the persistent store as a normal file in the file system (see Section 4.4.6). <p> Modern operating systems provide various primitives that allow application programs to interact with (and exploit) the virtual memory system; such interactions can range from a simple allocation (and deallocation) model to advanced interfaces such as shared memory [Li86, LH89] and memory inheritance as supported by Mach <ref> [BKLL93] </ref>. In the absence of a virtual memory system, if an application program outgrew the size of available memory, it was the programmer's responsibility to manually split the code into overlays that had to be explicitly controlled. <p> Some operating systems such as Mach <ref> [BKLL93] </ref>, Choices [Rus91], and Chorus [ARG89] already provide some form of external memory management. Mach allows user-level tasks to act as external pagers that fully control the use of memory within the process address space.
Reference: [BL92] <author> Thomas Ball and Jim Larus. </author> <title> Optimal Profiling and Tracing of Programs. </title> <booktitle> In Conference Record of the Nineteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 59-70. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1992. </year>
Reference: [BS76] <author> Jean-Loup Baer and Gary R. Sager. </author> <title> Dynamic Improvement of Locality in Virtual Memory Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-2(1):54-62, </volume> <month> March </month> <year> 1976. </year>
Reference-contexts: When the pages are (eventually) paged 183 out, they can be written to disk in a new order that reflects the recent access ordering. If future access orderings are correlated with past orderings, then this enables a very convenient form of prefetching. In the mid-1970's, Baer and Sager <ref> [BS76] </ref> simulated a prefetching policy that relied on reorganizing pages on disk using the order of initial accesses by the program.
Reference: [BS96] <author> Stephen M. Blackburn and Robin B. Stanton. </author> <title> Multicomputer Object Stores: The Multicomputer Texas Experiment. </title> <editor> In Scott Nettles and Richard Connor, editors, </editor> <booktitle> Seventh International Workshop on Persistent Object Systems, </booktitle> <address> Cape May, New Jersey, May 1996. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, it is not an impossible task|we are aware of at least one project where the Texas persistent store has been ported to a Fujitsu AP1000 multicom puter <ref> [BS96] </ref>. 1.3 Organization of the Dissertation The rest of this dissertation is organized as follows. Chapter 2 describes several important design issues for implementing an orthogonal persistence mechanism. <p> Of particular interest is the issue of distribution and concurrency control. Our current implementation of Texas does not support either of these; however, we are aware of at least one system, MC-Texas <ref> [BS96] </ref>, implemented on a Fujitsu AP1000 multicomputer as a precursor to developing a reference architecture for distributed persistence. Blackburn and Stanton report encouraging results regarding the overall scalability of Texas, modulo a couple of situations related to false sharing of implementation meta-data that should be relatively easy to resolve.
Reference: [BW88] <author> Hans-Juergen Boehm and Mark Weiser. </author> <title> Garbage Collection in an Uncooperative Environment. </title> <journal> Software Practice and Experience, </journal> <volume> 18(9) </volume> <pages> 807-820, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: There is no major difficulty supporting such operations efficiently for lan-guages like Lisp or ML; slightly conservative versions of these schemes will work well for languages with derived pointers and (limited) pointer arithmetic, in much the same way that conservative garbage collectors operate with languages like C or C++ <ref> [BW88] </ref>. The main modifications are to the allocation and deallocation routines, which must provide headers and/or groupings and/or alignment restrictions to allow objects to be identified. Large objects still pose a potential problem for our system in terms of exhaustion of virtual address space. <p> Recently, the C++ standard has added RTTI to support operations such as "downcasts" without circumventing the type system. Unfortunately, the standard RTTI information is insufficient for our purposes since it does not describe 1 Traditional garbage collectors for languages such as C++ have been conservative <ref> [BW88] </ref>. That is, any data value which "looks" like a pointer is treated as such while tracing the reachability graph.
Reference: [Car89] <author> Michael J. Carey. </author> <title> The EXODUS Extensible DBMS Project: An Overview. </title> <editor> In Stanley B. Zdonik and David Maier, editors, </editor> <booktitle> Readings in Object-Oriented Databases. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year> <month> 194 </month>
Reference-contexts: In addition, the E Persistent Virtual Machine (EPVM), an interpreter, is used for accessing persistent objects. The code generated by the compiler invokes the interpreter to load persistent objects and translate pointers as necessary. The Exodus Storage Manager (ESM) <ref> [Car89] </ref> is used as the object storage management layer in the language implementation. Each persistent pointer is represented by a 12-byte OID in the storage manager, and is swizzled to the word size of the local hardware.
Reference: [Cat91] <author> R. G. G. Cattell. </author> <title> An Engineering Database Benchmark. </title> <editor> In Jim Gray, editor, </editor> <booktitle> The Benchmark Handbook for Database and Transaction Processing Systems, </booktitle> <pages> pages 247-281. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Based on the results presented in [Whi94], E is about 48% slower than transient C/C++ for the hot traversals of the OO1 database benchmark <ref> [Cat91, CS92] </ref>. 11 This is a fairly significant overhead considering that the overhead of our system is zero for hot traversals and much smaller (less than 5%) otherwise. <p> In this chapter, we discuss various issues regarding the performance of Texas and pointer swizzling at page fault time, and present results that support our original assertions about the performance. We use the standard OO1 database benchmark <ref> [Cat91] </ref> with some minor variations as the workload for most of our performance measurements. Note that the OO1 benchmark is a synthetic benchmark designed specifically with the purpose of measuring the performance of object-oriented database systems and persistence facilities.
Reference: [CBL90] <author> Danny Chen, Ronald E. Barkley, and T. Paul Lee. </author> <title> Insuring Improved VM Performance: Some No-Fault Policies. </title> <booktitle> In Proceedings of the USENIX Winter 1990 Technical Conference, </booktitle> <pages> pages 11-22, </pages> <address> Berkeley, California, </address> <month> January </month> <year> 1990. </year> <institution> USENIX Association. </institution>
Reference-contexts: This will obviously impact the overall performance, and indeed Chen et al. <ref> [CBL90] </ref> have shown that layering of components adds a 20% overhead to fault handling. However, the empirical results that we have obtained indicate a slowdown factor of six, definitely much larger than what can be accounted by the extra 20% penalty.
Reference: [CDN93] <author> Michael J. Carey, David J. DeWitt, and Jeffrey F. Naughton. </author> <title> The OO7 Benchmark. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Washington DC., June 1993. </address> <publisher> ACM Press. </publisher>
Reference-contexts: OO1 was also one of the first widely-used database benchmarks, followed by others such the HyperModel [ABM + 90] and OO7 <ref> [CDN93] </ref> benchmarks. The OO7 benchmark is designed as a successor to the OO1 benchmark, and supports some advanced data structures and complex operations over these structures to represent a hypothetical CAD application. We used OO1 for all our performance measurements because of several fundamental reasons. <p> During this period, several benchmarks have also been developed for measuring the performance of these new systems. Of these, the OO1 [CS92] and OO7 <ref> [CDN93] </ref> benchmarks have become the most popular, and have been used widely for measuring the performance of various systems in isolation, as well as for comparing two or more systems. The canonical application domain for object-oriented databases (OODBs) is the Computer Aided Design (CAD) domain. <p> The benchmark database schema is very simple and is based on a network of biased random interconnections of part objects, which are manipulated using some simple benchmark operations. The OO7 benchmark <ref> [CDN93] </ref> was developed at the University of Wisconsin as a successor to the OO1 benchmark. While the benchmark retains the CAD application model, the data structures are enhanced to add much more hierarchy and additional complexity is incorporated for tuning various benchmark parameters.
Reference: [CG91] <author> Vincent Cate and Thomas Gross. </author> <title> Combining the Concepts of Compression and Caching for a Two-Level File System. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV) [ASP91], </booktitle> <pages> pages 200-209. </pages>
Reference-contexts: It should be noted that unlike other compression-based memory management schemes, our primary goal is not to increase the available disk storage, but to increase system throughput by reducing the average memory latency and increasing effective performance. Our system should also give benefits similar to those of file-compression schemes <ref> [CG91, BJLM92] </ref>. Further research is currently underway and detailed results will be presented in an upcoming paper [WKB97a]. 8.3 Advanced Issues In Chapter 1, we briefly mentioned some advanced issues that are beyond the scope of this dissertation.
Reference: [Cha92] <author> Craig Chambers. </author> <title> The Design and Implementation of the SELF Compiler, an Optimizing Compiler for an Object-Oriented Programming Language. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: It incurs zero overhead during normal CPU-bound operations on data that has already been loaded into memory, and a small overhead|roughly 1 to 5 percent depending on the underlying hardware and operating system|when data is 1 It is possible to use compiler optimizations (similar to the Self system <ref> [Cha92] </ref>) to infer information about the data and reduce the excessive checking overhead. However, such optimizations are fairly hard to implement because of inherent distinctions between object types and object residency. 4 being faulted into virtual memory from persistent storage on disk. <p> Furthermore, such extra optimizations will probably cause unwanted code bloat (e.g., excessive loop unrolling). * Although the residency property can be treated as a type so that Self-style optimizations <ref> [Cha92] </ref> can be applied to eliminate residency checking, it is not quite easy to do so because unlike types, residency can changes across procedure calls depending on the dynamic run-time state.
Reference: [CLLBH92] <author> Jeffrey S. Chase, Henry M. Levy, Edward D. Lazowska, and Miche Baker-Harvey. </author> <title> Lightweight Shared Objects in a 64-bit Operating System. </title> <editor> In Andreas Paepcke, editor, </editor> <booktitle> Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '92), </booktitle> <pages> pages 397-413, </pages> <address> Vancouver, British Columbia, </address> <month> October </month> <year> 1992. </year> <note> ACM Press. Published as ACM SIGPLAN Notices 27(10), </note> <month> October </month> <year> 1992. </year>
Reference-contexts: Introduction It is often desirable to support a virtual address space that is larger than what can be specified directly by the word size of the available hardware. Applications such as persistent object stores (e.g., [ABC + 83a, SKW92, DSZ90, AM92]), operating systems with a single shared address space (e.g., <ref> [CLLBH92] </ref>), distributed shared memories (e.g., [Li86]), etc. can benefit from large address spaces. <p> Of course, language support for reflective techniques would be very helpful in such an implementation; * security: We also do not address security issues for access to data in the persistent object store, but it is easy to imagine an implementation along the lines of protection domains in Opal <ref> [CLLBH92] </ref> or "areas" as in ObjectStore [LLOW91], or just Unix-style owner and group privileges (also supported by Opal); and * distribution and fault tolerance: These issues need to be carefully designed and ar-chitected, and must be implemented to interface well with the basic address translation mechanism. <p> Even in a world of purely 64-bit hardware, this is very desirable. For example, consider the case of merging two local-area networks, each with its own flat shared address space (a la <ref> [CLLBH92] </ref>). Pointer swizzling can be used to resolve conflicts between address spaces without an agonizing renaming process|by its very nature, pointer swizzling at page fault time allows different machines (or sub-nets) to map the same data to different local virtual addresses. <p> As persistent storage becomes more popular, data security will also become increasingly important because persistent data must be protected against unauthorized access. Previous work has been done in this area and various solutions are possible (e.g., protection domains in Opal <ref> [CLLBH92] </ref> and areas in ObjectStore [LLOW91]). 185 Chapter 9 Conclusions Coarse-grained address translation techniques have been disregarded in the past as a viable alternative to traditional fine-grained address translation techniques for building efficient persistence mechanisms in general-purpose languages.
Reference: [CM84] <author> George P. Copeland and David Maier. </author> <title> Making Smalltalk a Database System. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 316-325, </pages> <address> Boston, Massachusetts, </address> <month> June </month> <year> 1984. </year> <note> ACM Press. ACM SIGMOD Record 14(2). </note>
Reference-contexts: This creates a fundamental impedance mismatch <ref> [CM84] </ref> between the two representations. Persistent systems are designed to solve this impedance mismatch between volatile and non-volatile storage, and to alleviate the efficiency problems associated with file systems.
Reference: [CM88] <author> Albert Chang and Mark F. Mergen. </author> <title> 801 Storage: Architecture and Programming. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 28-50, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: In fact, the ARM600 processor provides such support [SW91] facilitating the easy implementation of sub-page protections in the Apple Newton. The 801 prototype RISC machine also incorporated support for protections at the sub-page granularity <ref> [CM88] </ref>.
Reference: [CRRS93] <author> Khien-Mien Chew, Jyothy Reddy, Theodore H. Romer, and Abraham Silber-schatz. </author> <title> Kernel Support for Recoverable-Persistent Virtual Memory. </title> <booktitle> In Proceedings of the 3rd Symposium on Mach, </booktitle> <pages> pages 215-234, </pages> <address> Santa Fe, New Mexico, </address> <month> April </month> <year> 1993. </year> <institution> USENIX Association. </institution>
Reference-contexts: Below, we provide a brief overview of some of the more interesting systems. Recoverable-Persistent Virtual Memory The Recoverable-Persistent Virtual Memory (RPVM) system <ref> [CS93, CRRS93] </ref> promotes the extension of virtual memory to support a Recoverable-Persistent Update (RPU) model for realizing a wide range of recovery services. Although the model essentially supports a mechanism for implementing persistence, the primary focus is on ensuring that the state of virtual memory can be recovered.
Reference: [CS92] <author> Rick G. G. Cattell and J. Skeen. </author> <title> Object Operations Benchmark. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(1) </volume> <pages> 1-31, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Based on the results presented in [Whi94], E is about 48% slower than transient C/C++ for the hot traversals of the OO1 database benchmark <ref> [Cat91, CS92] </ref>. 11 This is a fairly significant overhead considering that the overhead of our system is zero for hot traversals and much smaller (less than 5%) otherwise. <p> Finally, we describe the hardware and operating systems used for gathering our results. 5.2.1 Benchmarks One of the most popular object database benchmarks that has become the de facto standard is the OO1 (Object Operations One) benchmark <ref> [CS92] </ref>. OO1 was also one of the first widely-used database benchmarks, followed by others such the HyperModel [ABM + 90] and OO7 [CDN93] benchmarks. <p> During this period, several benchmarks have also been developed for measuring the performance of these new systems. Of these, the OO1 <ref> [CS92] </ref> and OO7 [CDN93] benchmarks have become the most popular, and have been used widely for measuring the performance of various systems in isolation, as well as for comparing two or more systems. The canonical application domain for object-oriented databases (OODBs) is the Computer Aided Design (CAD) domain. <p> Of course, the results should be interpreted cautiously to ensure that the conclusions drawn from those results are valid for real application behaviors. The OO1 and OO7 Benchmarks. The OO1 benchmark <ref> [CS92] </ref> was one of the first widely-used benchmarks for performance measurements of OODBs, designed to model applications in the engineering CAD domain. The benchmark database schema is very simple and is based on a network of biased random interconnections of part objects, which are manipulated using some simple benchmark operations.
Reference: [CS93] <author> Khien-Mien Chew and Abraham Silberschatz. </author> <title> The Recoverable-Persistent Virtual Memory Paradigm. </title> <type> Technical Report TR-93-08, </type> <institution> The University of Texas at Austin, Austin, Texas, </institution> <month> March </month> <year> 1993. </year> <note> Available at ftp://ftp.cs.utexas.edu/ pub/techreports/tr93-08.ps.Z. 195 </note>
Reference-contexts: Below, we provide a brief overview of some of the more interesting systems. Recoverable-Persistent Virtual Memory The Recoverable-Persistent Virtual Memory (RPVM) system <ref> [CS93, CRRS93] </ref> promotes the extension of virtual memory to support a Recoverable-Persistent Update (RPU) model for realizing a wide range of recovery services. Although the model essentially supports a mechanism for implementing persistence, the primary focus is on ensuring that the state of virtual memory can be recovered.
Reference: [Den70] <author> Peter J. Denning. </author> <title> Virtual Memory. </title> <journal> ACM Computing Surveys, </journal> <volume> 2(3) </volume> <pages> 153-189, </pages> <month> September </month> <year> 1970. </year>
Reference-contexts: We also briefly describe other related issues such as efficient handling of access-protection violations that are generated by attempts to access protected memory. Although we focus mostly on Unix-like operating systems, the basic ideas are also applicable to other modern operating systems. 7.1.1 Background: Virtual Memory Virtual memory <ref> [Den70, KELS82] </ref> was originally designed simply to manage two distinct levels of memory hierarchies|main memory and secondary storage|while giving the applications an illusion of a single level of storage that is larger than the size of the available physical memory. 151 Today, however, virtual memory is essential for smooth operation of
Reference: [Det92] <author> David L. Detlefs. </author> <title> Garbage Collection and Run-Time Typing as a C++ Library. </title> <booktitle> In USENIX C++ Conference [USE92]. </booktitle>
Reference-contexts: The second task of the precompiler is to parse the type definitions and emit a member function for each garbage-collected type to identify the internal pointers within that type. Detlefs <ref> [Det92] </ref> describes a modified scheme that is also based on smart pointers. This scheme extends the smart pointer definition further and constrains the programmer to use this interface for all garbage-collected objects.
Reference: [Dou93] <author> Fred Douglis. </author> <title> The Compression Cache: Using On-line Compression to Extend Physical Memory. </title> <booktitle> In Proceedings of 1993 Winter USENIX Conference, </booktitle> <pages> pages 519-529, </pages> <address> San Diego, California, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: A cost effective approach to bridge this gap is to introduce a new level into the memory hierarchy. Compressed in-memory storage uses part of main memory as a cache for compressed pages <ref> [Wil90, WLM91, Wil91, AL91, Dou93] </ref>; this divides the main memory into partitions for uncompressed pages and compressed pages. The use of compressed in-memory storage can improve overall system performance because "paging" from the compression cache may be faster than paging from disk.
Reference: [DSZ90] <editor> Alan Dearle, Gail M. Shaw, and Stanley B. Zdonik, editors. </editor> <title> Implementing Persistent Object Bases: </title> <booktitle> Principles and Practice (Proceedings of the Fourth International Workshop on Persistent Object Systems), </booktitle> <address> Martha's Vineyard, Mas-sachusetts, September 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Introduction It is often desirable to support a virtual address space that is larger than what can be specified directly by the word size of the available hardware. Applications such as persistent object stores (e.g., <ref> [ABC + 83a, SKW92, DSZ90, AM92] </ref>), operating systems with a single shared address space (e.g., [CLLBH92]), distributed shared memories (e.g., [Li86]), etc. can benefit from large address spaces.
Reference: [Ede92a] <author> Daniel R. Edelson. </author> <title> Precompiling C++ for Garbage Collection. </title> <note> In Bekkers and Cohen [BC92]. </note>
Reference-contexts: Edelson <ref> [Ede92a] </ref> proposes using a precompiler to automatically augment a C++ source program with additional RTTD information for garbage collection.
Reference: [Ede92b] <author> Daniel Ross Edelson. </author> <title> Smart Pointers: They're Smart, But They're Not Pointers. </title> <booktitle> In USENIX C++ Conference [USE92], </booktitle> <pages> pages 1-19. </pages> <note> Technical Report UCSC-CRL-92-27, </note> <institution> University of California at Santa Cruz, Baskin Center for Computer Engineering and Information Sciences, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: A mixed-granularity scheme (that is, coarse-grained address translation by default, and fine-grained address translation for selected data structures) should provide most of the benefit without much additional overhead. We have implemented fine-grained address translation by using the C++ smart pointer idiom <ref> [Str87, Ede92b] </ref>. Smart pointers allow implementation of pointer-wise address translation that behaves well with the standard page-wise pointer swizzling scheme without requiring additional hardware support. <p> There are many ways of implementing a fine-grained (pointer-wise) address translation mechanism. We have selected an implementation strategy that remains consistent with our goals of maintaining portability and compatibility with existing off-the-shelf compilers, by using the C++ smart pointer abstraction <ref> [Str87, Ede92b] </ref>. In this section, we first briefly explain the smart pointers abstraction and then describe how we use smart pointers for implementing fine-grained translation in Texas. <p> In essence, it is an attempt to introduce reflection [KdRB91] into C++ for builtin data types (i.e., pointers). 8 However, as described in <ref> [Ede92b] </ref>, it is impossible to truly replace the functionality of regular pointers in a completely transparent fashion. Part of the problem stems from some of the inconsistencies in the language definition and the implementation dependence. <p> The underlying idea is based on using smart point 32 Thanks to Tom Porcaro of IBM-Austin for implementing the platform-specific part for OS/2. 33 The count excludes blank lines, comments and source lines that do not get compiled into executable code. 34 Marc Shapiro, personal communication, May 1996. 148 ers <ref> [Ede92b] </ref> which are class objects that emulate normal (raw) pointers. The precompiler performs two tasks that are necessary for safe garbage collection for C++, namely finding the root set 35 and accurately identifying internal pointers within objects.
Reference: [GMS87] <author> Robert A. Gingell, Joseph P. Moran, and William A. Shannon. </author> <title> Virtual Memory Architecture for SunOS. </title> <booktitle> In USENIX Summer 1987 Technical Conference, </booktitle> <pages> pages 81-94, </pages> <address> Phoenix, Arizona, </address> <month> June </month> <year> 1987. </year> <institution> USENIX Association. </institution>
Reference-contexts: Historically, most Unix variants have always supported sbrk in some form or other, while mmap is a newer feature that originally existed in 4.2BSD but has since appeared in other variants within the last decade <ref> [GMS87] </ref>. All currently popular flavors of Unix for workstations and PCs now support mmap, albeit with minor differences in the interface. <p> We have seen that the virtual memory primitives under Solaris are several times slower than those under Linux, on identical hardware setups. It can be argued that this is not a fair comparison because Solaris implements a layered VM architecture <ref> [GMS87] </ref> which affords cleaner abstractions and better portability, but also has an impact on the overall performance. <p> Table 7.1 shows the actual cost for each operating system. The results clearly show that exception handling on Linux is several times faster than on Solaris. Both SunOS 4.x and Solaris 2.x implement a layered VM architecture <ref> [GMS87] </ref> that is substantially different from the 4.3BSD memory management architecture. In particular, it is more modular and requires 176 Operating system Cost (in cycles) Linux 2.0.x 2,500 Solaris 2.5.1 17,500 Table 7.1: Cost of handling an access-protection violation many function calls, sometimes indirected via a function table lookup.
Reference: [GR89] <author> Adele Goldberg and David Robson. </author> <title> Smalltalk-80: The Language. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: The ability to support run-time type queries about data objects is available for some high-level languages such as Smalltalk <ref> [GR89] </ref>, CLU [LAB + 81] and Modula-3 [Nel91]. The term Run-Time Type Identification (RTTI) [SL92] has been used to represent language-level semantics and the ability to support operations that allow the application to ask whether a given type is a subtype of some other type.
Reference: [HH87] <author> R. Nigel Horspool and Ronald M. Huberman. </author> <title> Analysis and Development of Demand Prepaging Policies. </title> <journal> Journal of Systems and Software, </journal> <volume> 7 </volume> <pages> 183-194, </pages> <year> 1987. </year>
Reference-contexts: One-block lookahead is an attractive policy because it is easy to implement; consecutively-numbered pages are usually consecutive on disk, and can be brought into memory without an additional seek. 182 Whether to Prefetch: The "fool-me-once" Rule We believe Horspool and Huberman's work on prefetching <ref> [HH87] </ref> to be among the most interesting, though not for the reasons they intended. They experimented with a variation of one-block lookahead that was designed to be easy to simulate efficiently. <p> Details of the scheme can be found in <ref> [HH87] </ref>. Horspool and Huberman were surprised to find that their algorithm actually outperformed conventional one-block lookahead.
Reference: [HN97] <author> Antony L. Hosking and Aria P. Novianto. </author> <title> Mostly-copying Reachability-based Orthogonal Persistence for C, C++ and Other Intransigents. </title> <booktitle> In OOPSLA '97 Workshop on Memory Management and Garbage Collection, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: We are aware of at least one project that is using pointer swizzling at page fault time techniques and extending Texas to implement reachability-based persistence for C++ and Modula-3 <ref> [HN97] </ref>. 2.3 Address Translation Taxonomies Persistence has been an active research area for over a decade and several researchers have put forth taxonomies for pointer swizzling techniques [Mos92, KK95, MS95, Whi94].
Reference: [Hos95] <author> Antony L. Hosking. </author> <title> Lightweight Support for Fine-Grained Persistence on Stock Hardware. </title> <type> PhD thesis, </type> <institution> University of Massachussetts at Amherst, Amherst, Mas-sachussetts, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: The granularity of checkpointing is in terms of individual objects because the system updates them in the database from their corresponding copies in virtual memory. 26 PS-Smalltalk PS-Smalltalk <ref> [Hos95] </ref> is also designed to implement persistence for Smalltalk. The basic architecture of the system is similar to the EPVM 2.0 object caching architecture [WD92] but the underlying storage manager is Mneme [Mos92].
Reference: [HP96] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year> <note> 2nd Edition. </note>
Reference-contexts: In general, virtual memory page size plays an important role in the implementation and performance of systems that exploit virtual memory features to implement new abstractions. Unfortunately, opposing forces are usually at work when a page size needs to be selected <ref> [HP96] </ref>. On one hand, larger sizes are preferable from the perspective of reducing hardware costs|page tables and Translation Lookaside Buffers (TLBs) can be made smaller|and for improving efficiency of data transfer between memory and secondary storage because larger units of transfer reduce the effect of latency. <p> Our original paper on Texas [SKW92] describes further details about the log-structured storage system, including a description of its data structures. 8.2.2 Adaptive Prefetching Modern computer memory systems are hierarchical, being composed of several levels of memory <ref> [HP96] </ref>. The lower levels (e.g., magnetic disks and tapes) are inexpensive and therefore large but slow, while the higher levels (e.g., RAM and caches) are expensive but small and fast.
Reference: [HR83] <author> Theo Haerder and Andreas Reuter. </author> <title> Principles of Transaction-Oriented Database Recovery. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4) </volume> <pages> 287-317, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: modified by the application and save those pages to the persistent store; the actual checkpointing is triggered by a programmer-controlled language-level interface. 5 Typically, VFT pointers reference virtual function tables corresponding to a specific executable. 62 Texas is most conducive to both no-undo/redo and undo/no-redo logging strategies as described in <ref> [HR83] </ref>. Our current implementation uses a two-phase, write-ahead logging mechanism to provide atomic checkpoints. We implement the no-undo/redo strategy as shown in Figure 4.2. The basic idea is to ensure that "dirty" (modified) copies of pages are safely stored in the log before the persistent store is updated.
Reference: [IL90] <author> John A. Interrante and Mark A. Linton. </author> <title> Run-Time Access to Type Information in C++. </title> <booktitle> In USENIX C++ Conference, </booktitle> <address> Berkeley, California, </address> <year> 1990. </year> <booktitle> USENIX Association. </booktitle> <pages> 196 </pages>
Reference-contexts: In addition, Edelson's precompiler is quite similar to a preprocessor because it needs to parse type definitions from the source code, and hence is susceptible to the same problems we described earlier for preprocessors. Interrante and Linton <ref> [IL90] </ref> proposed a Dossier class as a standard interface for run-time type information in C++. A (preprocessor-style) dossier generator is used to create Dossier objects from the source code.
Reference: [JLR + 94] <author> Hosagrahar V. Jagadish, Daniel Lieuwen, Rajeev Rastogi, Avi Silberschatz, and S. Sudarshan. </author> <title> Dali: A High Performance Main Memory Storage Manager. </title> <booktitle> In Twentieth International Conference on Very Large Data Bases, </booktitle> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: This also means that the size of the database is restricted by the maximum address space supported by the operating system. The granularity of address translation is obviously not applicable in this case, and the granularities of address mapping and data fetching correspond to the entire database. Dali Dali <ref> [JLR + 94] </ref> is a storage manager optimized for main memory databases, that is, situations where the persistent store resides in memory. It does not perform any address translation, and uses memory mapping techniques to map database files into the virtual address space of a user process.
Reference: [Joh97] <author> Mark S. Johnstone. </author> <title> Non-Moving Memory Allocation and Real-Time Garbage Collection. </title> <type> PhD thesis, </type> <institution> The University of Texas at Austin, Austin. Texas, </institution> <month> December </month> <year> 1997. </year>
Reference-contexts: In general, segregated storage policies are known to be prone to higher fragmentation <ref> [Joh97] </ref>. However, we still chose to implement a memory manager based on this policy primarily because study of memory allocation policies is not our research focus, and because we only needed a fast implementation of a simple allocation policy. <p> For such applications, a majority of objects need not to be saved to stable storage because they constitute transient data that does not live for very long <ref> [Wil97, WJNB95, Joh97] </ref>. In such situations, execution costs are dominated by operations over transient data; the persistence mechanism must not interfere with these operations, making them as fast as possible. In contrast, database program behavior denotes applications that are usually I/O-intensive and do not perform significant computation during their execution.
Reference: [Kae86] <author> Ted Kaehler. </author> <title> Virtual Memory on a Narrow Machine for an Object-Oriented Language. </title> <booktitle> In Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '86) Proceedings [OOP86]. </booktitle>
Reference-contexts: The various granularity choices for persistence are also same as before, that is, individual objects are loaded from the database on demand when OIDs that reference non-resident objects are traversed by the application. LOOM LOOM <ref> [KK83, Kae86] </ref>, or Large Object-Oriented Memory, is a virtual memory system that was designed to support large address spaces for early Smalltalk-80 implementations on machines with 16-bit hardware word size. <p> Early schemes for supporting large virtual addresses on normal hardware (e.g., LOOM <ref> [KK83, Kae86] </ref>, E [WD92], etc.) have typically incurred significant overhead due to their use of traditional fine-grained address translation techniques. There are at least two basic approaches that are commonly used for implementing large address spaces in software.
Reference: [KC86] <author> Setrag N. Khoshafian and George P. Copeland. </author> <title> Object Identity. </title> <booktitle> In Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '86) Proceedings [OOP86], </booktitle> <pages> pages 406-416. </pages>
Reference-contexts: By this definition, an object identifier is never reused, even after the object is deleted. A detailed study of various forms of object identity is available in <ref> [KC86] </ref>. It is often necessary to send data from one host to another, or to save application data structures to stable storage so that they can be either operated on later (possibly by other applications) or used for recovering the application state in case of a crash.
Reference: [KdRB91] <author> Gregor Kiczales, Jim des Rivieres, and Daniel G. Bobrow. </author> <title> The Art of the Metaob-ject Protocol. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: As part of this dissertation, we have implemented coarse-grained address translation using pointer swizzling at page fault time to provide an efficient persistence mechanism for C++. In doing so, we have essentially implemented a form of reflection <ref> [KdRB91] </ref> 2 for C++ via a "back door" because the language itself does not provide builtin support for it. 3 Although our approach is simple and elegant, there are still some complexities|albeit hidden from the average user|in the implementation, due to a lack of language features. <p> Smart pointers were designed with the goal of transparently replacing regular pointers (except for declarations), and providing additional flexibility because arbitrary code can be executed for every pointer operation. In essence, it is an attempt to introduce reflection <ref> [KdRB91] </ref> into C++ for builtin data types (i.e., pointers). 8 However, as described in [Ede92b], it is impossible to truly replace the functionality of regular pointers in a completely transparent fashion. Part of the problem stems from some of the inconsistencies in the language definition and the implementation dependence.
Reference: [KELS82] <author> T. Kilburn, D. B. G. Edwards, M. J. Lanigan, and F. H. Sumner. </author> <title> One-level Storage System. </title> <editor> In D. P. Siewiorek, C. G. Bell, and A. Newell, editors, </editor> <booktitle> Computer Structures: Principles and Examples, </booktitle> <pages> pages 135-148. </pages> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1982. </year> <note> Originally appeared in IRE Transactions EC-11:(2), 223-235, </note> <month> April </month> <year> 1962. </year>
Reference-contexts: We also briefly describe other related issues such as efficient handling of access-protection violations that are generated by attempts to access protected memory. Although we focus mostly on Unix-like operating systems, the basic ideas are also applicable to other modern operating systems. 7.1.1 Background: Virtual Memory Virtual memory <ref> [Den70, KELS82] </ref> was originally designed simply to manage two distinct levels of memory hierarchies|main memory and secondary storage|while giving the applications an illusion of a single level of storage that is larger than the size of the available physical memory. 151 Today, however, virtual memory is essential for smooth operation of
Reference: [KK83] <author> Ted Kaehler and Glenn Krasner. </author> <title> LOOM|Large Object-Oriented Memory for Smalltalk-80 Systems. </title> <editor> In Glenn Krasner, editor, </editor> <title> Smalltalk-80: Bits of History, </title> <booktitle> Words of Advice, </booktitle> <pages> pages 251-271. </pages> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: The various granularity choices for persistence are also same as before, that is, individual objects are loaded from the database on demand when OIDs that reference non-resident objects are traversed by the application. LOOM LOOM <ref> [KK83, Kae86] </ref>, or Large Object-Oriented Memory, is a virtual memory system that was designed to support large address spaces for early Smalltalk-80 implementations on machines with 16-bit hardware word size. <p> Early schemes for supporting large virtual addresses on normal hardware (e.g., LOOM <ref> [KK83, Kae86] </ref>, E [WD92], etc.) have typically incurred significant overhead due to their use of traditional fine-grained address translation techniques. There are at least two basic approaches that are commonly used for implementing large address spaces in software.
Reference: [KK95] <author> Alfons Kemper and Donald Kossmann. </author> <title> Adaptable Pointer Swizzling Strategies in Object Bases: Design, Realization, and Quantitative Analysis. </title> <journal> VLDB Journal, </journal> <volume> 4(3) </volume> <pages> 519-566, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Pointer swizzling at page fault time is classified as a coarse-grained address translation technique because the granularity of translation is a virtual memory page. New Classification Scheme Various researchers have put forth different taxonomies for address translation approaches based on differences in the pointer swizzling techniques used <ref> [Mos92, KK95, MS95, Whi94] </ref>. Unfortunately, some of these classifications are unclear, and sometimes even contradictory to each other. Instead of attempting to clarify these taxonomies, we present a new classification scheme using several design choices that we consider important for implementing orthogonal persistence. <p> one project that is using pointer swizzling at page fault time techniques and extending Texas to implement reachability-based persistence for C++ and Modula-3 [HN97]. 2.3 Address Translation Taxonomies Persistence has been an active research area for over a decade and several researchers have put forth taxonomies for pointer swizzling techniques <ref> [Mos92, KK95, MS95, Whi94] </ref>. In this section, we describe important details about each of these taxonomies and highlights various similarities and differences among them. In addition, we also provide motivation for a general classification of persistent systems based on granularity issues. 2.3.1 Eager vs. <p> That is, there is no predetermined or bounded collection of objects that must be swizzled together. Instead, the execution dynamically locates and swizzles new objects depending on the access patterns of the application. Other researchers (Kemper and Kossman <ref> [KK95] </ref>, and McAuliffe and Solomon [MS95]) have also used classifications along similar lines in their own studies. However, we consider this classification to be ambiguous for general use because it does not clearly identify the fundamental issue|the granularity of address translation|that is important in this context. <p> In such cases, the object cannot be evicted from memory without first invalidating all edges that reference it. This obviously requires knowledge about all references to the object being evicted. Kemper and Kossman <ref> [KK95] </ref> solved this by using a per-object data structure known as a Reverse Reference List (RRL) to maintain a set of back-pointers to all objects that reference a given object.
Reference: [KLM + 93] <author> Gregor Kiczales, John Lamping, Chris Maeda, David Keppel, </author> <title> and Dylan Mc-Namee. The Need for Customizable Operating Systems. </title> <booktitle> Proceedings of the Fourth Workshop on Workstation Operating Systems (WWOS-IV), </booktitle> <month> October </month> <year> 1993. </year>
Reference-contexts: There is evidence that other researchers also have similar goals for improving operating system implementations <ref> [KLM + 93] </ref>. 180 Chapter 8 Future Work 8.1 Introduction The previous chapters have described the design and implementation of Texas, our portable persistent storage mechanism based on high-performance coarse-grained address translation using pointer swizzling at page fault time.
Reference: [LAB + 81] <author> Barbara Liskov, Russell Atkinson, Toby Bloom, J. Eliot B. Moss, J. Craig Schaf-fert, Robert Scheifler, and Alan Snyder. </author> <title> CLU Reference Manual. </title> <booktitle> Number 114 in Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1981. </year>
Reference-contexts: The ability to support run-time type queries about data objects is available for some high-level languages such as Smalltalk [GR89], CLU <ref> [LAB + 81] </ref> and Modula-3 [Nel91]. The term Run-Time Type Identification (RTTI) [SL92] has been used to represent language-level semantics and the ability to support operations that allow the application to ask whether a given type is a subtype of some other type.
Reference: [LH89] <author> Kai Li and Paul Hudak. </author> <title> Memory Coherence in Shared Virtual Memory Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: Most of this interaction stems from the use of virtual memory protection and access-protection violation handling for implementing coarse-grained address translation. In addition to Texas, there are many other useful system-level extensions and libraries (for example, garbage collectors [AEL88, Wil97], distributed shared virtual memory systems <ref> [Li86, LH89] </ref>, virtual memory tracing and compression facilities [WKBK97, WKB97a], advanced profiling, etc.) that closely interact with the operating system. We believe that operating system implementors should take interactions of such low-level systems and libraries into consideration when designing new systems. <p> Modern operating systems provide various primitives that allow application programs to interact with (and exploit) the virtual memory system; such interactions can range from a simple allocation (and deallocation) model to advanced interfaces such as shared memory <ref> [Li86, LH89] </ref> and memory inheritance as supported by Mach [BKLL93]. In the absence of a virtual memory system, if an application program outgrew the size of available memory, it was the programmer's responsibility to manually split the code into overlays that had to be explicitly controlled.
Reference: [Li86] <author> Kai Li. </author> <title> Shared Virtual Memory on Loosely-Coupled Processors. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, Connecticut, </address> <year> 1986. </year> <month> 197 </month>
Reference-contexts: Applications such as persistent object stores (e.g., [ABC + 83a, SKW92, DSZ90, AM92]), operating systems with a single shared address space (e.g., [CLLBH92]), distributed shared memories (e.g., <ref> [Li86] </ref>), etc. can benefit from large address spaces. <p> Most of this interaction stems from the use of virtual memory protection and access-protection violation handling for implementing coarse-grained address translation. In addition to Texas, there are many other useful system-level extensions and libraries (for example, garbage collectors [AEL88, Wil97], distributed shared virtual memory systems <ref> [Li86, LH89] </ref>, virtual memory tracing and compression facilities [WKBK97, WKB97a], advanced profiling, etc.) that closely interact with the operating system. We believe that operating system implementors should take interactions of such low-level systems and libraries into consideration when designing new systems. <p> Modern operating systems provide various primitives that allow application programs to interact with (and exploit) the virtual memory system; such interactions can range from a simple allocation (and deallocation) model to advanced interfaces such as shared memory <ref> [Li86, LH89] </ref> and memory inheritance as supported by Mach [BKLL93]. In the absence of a virtual memory system, if an application program outgrew the size of available memory, it was the programmer's responsibility to manually split the code into overlays that had to be explicitly controlled.
Reference: [Lie93] <author> Jochen Liedtke. </author> <title> Improved IPC by Kernel Design. </title> <booktitle> In Proceedings of the Fourteenth Symposium on Operating Systems Principles, </booktitle> <pages> pages 175-188, </pages> <address> Asheville, North Carolina, </address> <month> December </month> <year> 1993. </year> <note> ACM Press. Published as Operating Systems Review 27(5). </note>
Reference-contexts: Another great example of fast exception handling mechanism is the L3 (and subsequently, L4) microkernel [Lie95, Lie96]; the full cost of a kernel call in the L3 microkernel is between 123 and 180 cycles <ref> [Lie93] </ref>, or less than one microsecond on a modern 200MHz processor. This is an extremely impressive result, given that our best performance on Linux is more than an order of magnitude slower.
Reference: [Lie95] <author> Jochen Liedtke. </author> <title> On Microkernel Construction. </title> <booktitle> In Proceedings of the Fifteenth Symposium on Operating Systems Principles, </booktitle> <pages> pages 237-250, </pages> <address> Copper Mountain Resort, Colorado, </address> <month> December </month> <year> 1995. </year> <note> ACM Press. </note>
Reference-contexts: An even better approach is to modify operating systems to support external memory management mechanisms. Operating systems that support such models already exist (e.g., Mach [BKLL93], and L3/L4 microkernels <ref> [Lie95] </ref>) and can be exploited. For example, Mach supports external pagers which can be used as pointer swizzling servers to swizzle pages before loading them into memory so that they appear clean to the virtual memory system. <p> Implemented by modifying the DEC Ultrix 4.2A kernel, their approach requires only 8 microseconds for handling a null exception compared to 80 microseconds taken by the unmodified kernel. Another great example of fast exception handling mechanism is the L3 (and subsequently, L4) microkernel <ref> [Lie95, Lie96] </ref>; the full cost of a kernel call in the L3 microkernel is between 123 and 180 cycles [Lie93], or less than one microsecond on a modern 200MHz processor.
Reference: [Lie96] <author> Jochen Liedtke. </author> <title> Toward Real Microkernels. </title> <journal> Communications of the ACM, </journal> <volume> 39(9) </volume> <pages> 70-77, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Implemented by modifying the DEC Ultrix 4.2A kernel, their approach requires only 8 microseconds for handling a null exception compared to 80 microseconds taken by the unmodified kernel. Another great example of fast exception handling mechanism is the L3 (and subsequently, L4) microkernel <ref> [Lie95, Lie96] </ref>; the full cost of a kernel call in the L3 microkernel is between 123 and 180 cycles [Lie93], or less than one microsecond on a modern 200MHz processor.
Reference: [Lip91] <author> Stanley B. Lippman. </author> <title> C++ Primer. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1991. </year> <note> 2nd Edition. </note>
Reference-contexts: The system is available via anonymous ftp in source form under the GNU Library General Public License. A Technique for Dynamically Resolving C++ Method Dispatch Tables C++ implements dynamic binding by using virtual functions <ref> [Lip91] </ref>, and pointers to these functions are stored in virtual function tables (VFTs). <p> Chapter 6 provides the description of our RTTD approach, including details about the C++ implementation used for Texas. 61 4.4.5 Handling Virtual Function Table Pointers The most common implementation used for dynamic binding in C++ is via virtual functions <ref> [Lip91] </ref>. To minimize performance impacts of dynamic binding, virtual functions are implemented via virtual function tables (VFTs). <p> calling the new operator is: 16 In the remainder of the chapter, we use the phrase "new operator" to refer to the operator and "operator new ()" to refer to the storage allocation function. 17 An excellent discussion about the new operator and semantics of overloading can be found in <ref> [Lip91] </ref>. 18 This term was originally used to provide "placement" information for the object as an additional argument to the underlying allocator.
Reference: [LLOW91] <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The Object-Store Database System. </title> <journal> Communications of the ACM, </journal> <volume> 34(10) </volume> <pages> 50-63, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: reflective techniques would be very helpful in such an implementation; * security: We also do not address security issues for access to data in the persistent object store, but it is easy to imagine an implementation along the lines of protection domains in Opal [CLLBH92] or "areas" as in ObjectStore <ref> [LLOW91] </ref>, or just Unix-style owner and group privileges (also supported by Opal); and * distribution and fault tolerance: These issues need to be carefully designed and ar-chitected, and must be implemented to interface well with the basic address translation mechanism. <p> Once again, note the similarity between protected object table entries and fault blocks in PS-Smalltalk or leaves in LOOM. 16 Pointer swizzling at page fault time does not have this problem because we alway translate pointers into valid virtual addresses, which do not need to be changed. 28 ObjectStore ObjectStore <ref> [LLOW91] </ref> is a commercial system that also uses pointer swizzling at page fault time as the primary address translation mechanism to implement persistence for C++. <p> More importantly, it affects portability because the same mappings and virtual address ranges cannot be used across different operating systems. A slightly better alternative is to use an approach similar to the one used in ObjectStore <ref> [LLOW91] </ref> and QuickStore [WD94]; specifi 3 Our own environment is an example of this situation. 4 Systems administrators typically tend to frown upon software that arbitrarily changes the application paging behavior and adversely affects general performance in networked environments. 42 cally, this approach swizzles a page only if it cannot be <p> Texas (Chapter 4) and other persistent object stores <ref> [ABC + 83a, AM95, LLOW91, WD94] </ref> that use pointer swizzling techniques such as pointer swizzling at page fault time need to know the locations of pointers in data objects at run time in order to find and manipulate these pointers correctly. <p> As persistent storage becomes more popular, data security will also become increasingly important because persistent data must be protected against unauthorized access. Previous work has been done in this area and various solutions are possible (e.g., protection domains in Opal [CLLBH92] and areas in ObjectStore <ref> [LLOW91] </ref>). 185 Chapter 9 Conclusions Coarse-grained address translation techniques have been disregarded in the past as a viable alternative to traditional fine-grained address translation techniques for building efficient persistence mechanisms in general-purpose languages.
Reference: [MBC + 89] <author> Ron. Morrison, Alfred L. Brown, Ray Carrick, Richard Connor, Alan Dearle, and Malcolm P. Atkinson. </author> <title> The Napier Type System. </title> <editor> In J. Rosenberg and D. Koch, editors, </editor> <booktitle> Third International Workshop on Persistent Object Systems, </booktitle> <pages> pages 3-18, </pages> <address> Newcastle, Australia, </address> <month> September </month> <year> 1989. </year> <note> Springer-Verlag. </note>
Reference-contexts: Persistent references are implemented as object identifiers 24 (OIDs), and the granularity of address translation is individual pointers. The granularities of address mapping and data fetching is individual objects which are loaded from the database into the heap by the run-time system. Napier88 Napier88 <ref> [MBC + 89] </ref> is the successor to PS-algol; while PS-algol uses dynamic typing, Napier88 attempts to use strong typing in most cases. There are some special situations where run-time dynamic type checking is necessary because the type cannot be determined statically.
Reference: [MG89] <author> Jose Alves Marques and Paulo Guedes. </author> <title> Extending the Operating System to Support an Object-Oriented Environment. </title> <booktitle> In Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '89) Proceedings [OOP89], </booktitle> <pages> pages 113-122. </pages>
Reference-contexts: The other half of the field goes to waste, but this space cost is relatively small, especially for languages such as C/C++ because most fields are not pointers. This is similar to the approach used in the Commandos <ref> [MG89] </ref> operating system, where object identifiers are used on disk, but are swizzled to actual pointers when data is 47 loaded into memory. However, Commandos does not use page-wise swizzling and incurs high overhead in checking for unswizzled pointers.
Reference: [MGST70] <author> R. L. Mattson, J. Gecsei, D. R. Slutz, and I. L. Traiger. </author> <title> Evaluation Techniques for Storage Hierarchies. </title> <journal> IBM Systems Journal, </journal> <volume> 9 </volume> <pages> 78-117, </pages> <year> 1970. </year>
Reference: [Mos92] <author> J. Eliot B. Moss. </author> <title> Working with Persistent Objects: </title> <journal> To Swizzle or Not to Swizzle? IEEE Transactions on Software Engineering, </journal> <volume> 18(8) </volume> <pages> 657-673, </pages> <month> August </month> <year> 1992. </year> <note> Also available as Technical Report 90-38, </note> <institution> University of Massachusetts, Amherst, Massachusetts, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: Pointer swizzling at page fault time is classified as a coarse-grained address translation technique because the granularity of translation is a virtual memory page. New Classification Scheme Various researchers have put forth different taxonomies for address translation approaches based on differences in the pointer swizzling techniques used <ref> [Mos92, KK95, MS95, Whi94] </ref>. Unfortunately, some of these classifications are unclear, and sometimes even contradictory to each other. Instead of attempting to clarify these taxonomies, we present a new classification scheme using several design choices that we consider important for implementing orthogonal persistence. <p> one project that is using pointer swizzling at page fault time techniques and extending Texas to implement reachability-based persistence for C++ and Modula-3 [HN97]. 2.3 Address Translation Taxonomies Persistence has been an active research area for over a decade and several researchers have put forth taxonomies for pointer swizzling techniques <ref> [Mos92, KK95, MS95, Whi94] </ref>. In this section, we describe important details about each of these taxonomies and highlights various similarities and differences among them. In addition, we also provide motivation for a general classification of persistent systems based on granularity issues. 2.3.1 Eager vs. <p> In this section, we describe important details about each of these taxonomies and highlights various similarities and differences among them. In addition, we also provide motivation for a general classification of persistent systems based on granularity issues. 2.3.1 Eager vs. Lazy Swizzling Moss <ref> [Mos92] </ref> describes one of the first studies of different address translation approaches and the associated terminology developed for classifying these techniques. The primary classification is in terms of "eager" and "lazy" swizzling based on when the address translation is performed. <p> The basic architecture of the system is similar to the EPVM 2.0 object caching architecture [WD92] but the underlying storage manager is Mneme <ref> [Mos92] </ref>. Objects are copied from the Mneme buffer pool into virtual memory on demand, translating Mneme OIDs into virtual memory address values. Mneme implements reachability-based persistence, as well as garbage collection for all objects reachable from a persistent root. <p> Unfortunately, translating individual pointers may involve checking each pointer at each use to determine if it is a valid address, thereby increasing the overhead. Alternatively, it is possible to swizzle pointers in an object the first time the object is referenced <ref> [Mos92] </ref>. However, this approach also requires that pointers are checked before each use to ensure that they are swizzled as necessary.
Reference: [MS95] <author> Mark L. McAuliffe and Marvin H. Solomon. </author> <title> A Trace-Based Simulation of Pointer Swizzling Techniques. </title> <booktitle> In Proceedings of the International Conference on Database Engineering, </booktitle> <pages> pages 52-61, </pages> <address> Taipei, Taiwan, </address> <month> March </month> <year> 1995. </year> <note> IEEE. </note>
Reference-contexts: Pointer swizzling at page fault time is classified as a coarse-grained address translation technique because the granularity of translation is a virtual memory page. New Classification Scheme Various researchers have put forth different taxonomies for address translation approaches based on differences in the pointer swizzling techniques used <ref> [Mos92, KK95, MS95, Whi94] </ref>. Unfortunately, some of these classifications are unclear, and sometimes even contradictory to each other. Instead of attempting to clarify these taxonomies, we present a new classification scheme using several design choices that we consider important for implementing orthogonal persistence. <p> one project that is using pointer swizzling at page fault time techniques and extending Texas to implement reachability-based persistence for C++ and Modula-3 [HN97]. 2.3 Address Translation Taxonomies Persistence has been an active research area for over a decade and several researchers have put forth taxonomies for pointer swizzling techniques <ref> [Mos92, KK95, MS95, Whi94] </ref>. In this section, we describe important details about each of these taxonomies and highlights various similarities and differences among them. In addition, we also provide motivation for a general classification of persistent systems based on granularity issues. 2.3.1 Eager vs. <p> That is, there is no predetermined or bounded collection of objects that must be swizzled together. Instead, the execution dynamically locates and swizzles new objects depending on the access patterns of the application. Other researchers (Kemper and Kossman [KK95], and McAuliffe and Solomon <ref> [MS95] </ref>) have also used classifications along similar lines in their own studies. However, we consider this classification to be ambiguous for general use because it does not clearly identify the fundamental issue|the granularity of address translation|that is important in this context. <p> This obviously requires knowledge about all references to the object being evicted. Kemper and Kossman [KK95] solved this by using a per-object data structure known as a Reverse Reference List (RRL) to maintain a set of back-pointers to all objects that reference a given object. McAuliffe and Solomon <ref> [MS95] </ref> use a different data structure, called the swizzle table, which is a fixed-size hash table that maintains a list of all swizzled pointers in the system.
Reference: [Nel91] <author> Greg Nelson, </author> <title> editor. Systems Programming in Modula-3. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, New Jersey, </address> <year> 1991. </year>
Reference-contexts: The ability to support run-time type queries about data objects is available for some high-level languages such as Smalltalk [GR89], CLU [LAB + 81] and Modula-3 <ref> [Nel91] </ref>. The term Run-Time Type Identification (RTTI) [SL92] has been used to represent language-level semantics and the ability to support operations that allow the application to ask whether a given type is a subtype of some other type.
Reference: [NNM + 96] <author> Vivek R. Narasayya, Tze Sing Eugene Ng, Dylan McNamee, Ashutosh Tiwary, and Henry M. Levy. </author> <title> Reducing the Virtual Memory Overhead of Swizzling. </title> <booktitle> In Proceedings of the FifthInternational Workshop on Object Orientation in Operating Systems, </booktitle> <address> Seattle, Washington, </address> <month> October </month> <year> 1996. </year> <note> IEEE Press. 198 </note>
Reference-contexts: In essence, we are "paging" from the persistent store rather than from local swap space. Narasayya et al. <ref> [NNM + 96] </ref> originally raised the issue about swizzled pages that are erroneously marked as dirty by the virtual memory system and the corresponding page-outs that are unnecessary if paging from the persistent store. <p> However, this approach still has limitations in the general case, and does not resolve the basic problem. Narasayya et al. <ref> [NNM + 96] </ref> suggest a special system call to clear the dirty status bit of a page. While this is a good idea, it can be generalized to implement an extended primitive that can communicate a variety of information from an application to the virtual memory system. <p> Finally, between the two extremes, there are a variety of levels that afford different degrees of interaction with the virtual memory system. We briefly describe some of these approaches and discuss how they can be applied to solve the mistaken-dirty-pages problem. Special-purpose Virtual Memory Primitive (s) Narasayya et al. <ref> [NNM + 96] </ref>, who originally identified the mistaken-dirty-pages problem, propose a special system call that allows the application to clear the dirty status bit of a page.
Reference: [OOP86] <editor> Conference on Object Oriented Programming Systems, </editor> <booktitle> Languages and Applica--tions (OOPSLA '86) Proceedings. </booktitle> <publisher> ACM Press, </publisher> <month> October </month> <year> 1986. </year> <note> Published as ACM SIGPLAN Notices 21(11), </note> <month> November </month> <year> 1986. </year>
Reference: [OOP89] <editor> Conference on Object Oriented Programming Systems, </editor> <booktitle> Languages and Applications (OOPSLA '89) Proceedings, </booktitle> <address> New Orleans, Louisiana, 1989. </address> <publisher> ACM Press. </publisher>
Reference: [RC89] <author> Joel E. Richardson and Michael J. Carey. </author> <title> Persistence in the E Language: Issues and Implementation. </title> <journal> Software Practice and Experience, </journal> 19(12) 1115-1150, December 1989. 
Reference-contexts: Since fine-grained schemes typically translate one pointer at a time, the mapping tables must contain one entry per pointer. This is likely to significantly increase the size of the mapping table, making it harder to manipulate efficiently. We believe that the E system <ref> [RC89, SCD90] </ref> is probably the fastest fine-grained scheme that is comparable to a coarse-grained address translation scheme; however, it still falls short in terms of performance. <p> Finally, it should be noted that LOOM does not provide support for transactions or for saving recovery data in case of a crash/failure because it was primarily designed to implement a virtual memory system, not a persistence storage system. The E Programming Language The E programming language <ref> [RC89, SCD90] </ref> was developed at University of Wisconsin as a persistent extension to C++. Persistence is implemented by adding special database types such that only objects of these types can persist. This is a necessary but not sufficient condition for persistence. <p> Thus a simple equality check, on average, can become more expensive than desired. One obvious solution is to make the pointer field large enough to store both the persistent and virtual address values as implemented in E <ref> [RC89, SCD90] </ref>. In the current context, the smart pointer internal representation could be extended such that it can hold both the pointer fields.
Reference: [RK68] <author> Brian Randell and C. J. Kuehner. </author> <title> Dynamic Storage Allocation Systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(7) </volume> <pages> 297-306, </pages> <month> May </month> <year> 1968. </year>
Reference-contexts: Un--fortunately, it is also subject to potentially severe external fragmentation <ref> [RK68] </ref> because no attempt is made to split or coalesce blocks in order to satisfy requests for other size classes. However, there is a tradeoff between expected internal fragmentation and external fragmentation.
Reference: [RO91] <author> Mendel Rosenblum and John K. Ousterhout. </author> <title> The Design and Implementation of a Log-Structured File System. </title> <booktitle> In Proceedings of the Thirteenth Symposium on Operating Systems Principles, </booktitle> <pages> pages 1-15, </pages> <address> Pacific Grove, California, </address> <month> October </month> <year> 1991. </year> <note> ACM Press. Published as Operating Systems Review 25(5). </note>
Reference-contexts: Log-structured Storage System Instead of refining our simple write-ahead logging scheme, we can replace both the log and the persistent storage file with a log-structured storage system (LSS) that supports checkpointing and recovery both directly and efficiently. An LSS is essentially the lower levels of a log-structured file system <ref> [RO91] </ref>; and manipulates a single large uncached file (typically, a raw Unix disk partition). In a log-structured store, the entire disk (or file) is used as a log, and the log itself acts as the final repository of data pages. Blocks do not have a single "home" location on disk. <p> We can replace the simple logging mechanism with a more flexible log-structured storage system that supports additional functionality. 181 A log-structured storage system (LSS) is essentially the lower levels of a log-structured file system <ref> [RO91] </ref>. The storage system typically manages a single raw disk partition, although a normal file could be used instead. We choose not to implement an entire file system because the complexity is not needed for simple persistent storage management.
Reference: [Rus91] <author> V. F. Russo. </author> <title> An Object-Oriented Operating System. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Champaign-Urbana, Illinois, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Some operating systems such as Mach [BKLL93], Choices <ref> [Rus91] </ref>, and Chorus [ARG89] already provide some form of external memory management. Mach allows user-level tasks to act as external pagers that fully control the use of memory within the process address space.
Reference: [SCD90] <author> Daniel T. Schuh, Michael J. Carey, and David J. DeWitt. </author> <title> Persistence in E Revisited|Implementation Experiences. </title> <editor> In Dearle et al. </editor> <publisher> [DSZ90]. </publisher>
Reference-contexts: Since fine-grained schemes typically translate one pointer at a time, the mapping tables must contain one entry per pointer. This is likely to significantly increase the size of the mapping table, making it harder to manipulate efficiently. We believe that the E system <ref> [RC89, SCD90] </ref> is probably the fastest fine-grained scheme that is comparable to a coarse-grained address translation scheme; however, it still falls short in terms of performance. <p> Finally, it should be noted that LOOM does not provide support for transactions or for saving recovery data in case of a crash/failure because it was primarily designed to implement a virtual memory system, not a persistence storage system. The E Programming Language The E programming language <ref> [RC89, SCD90] </ref> was developed at University of Wisconsin as a persistent extension to C++. Persistence is implemented by adding special database types such that only objects of these types can persist. This is a necessary but not sufficient condition for persistence. <p> Thus a simple equality check, on average, can become more expensive than desired. One obvious solution is to make the pointer field large enough to store both the persistent and virtual address values as implemented in E <ref> [RC89, SCD90] </ref>. In the current context, the smart pointer internal representation could be extended such that it can hold both the pointer fields.
Reference: [SKT94] <author> Shinji Suzuki, Masaru Kitsuregawa, and Mikio Takagi. </author> <title> An Efficient Pointer Swiz-zling Method for Navigation Intensive Applications. </title> <editor> In Antonio Albano and Ron Morrison, editors, </editor> <booktitle> Sixth International Workshop on Persistent Object Systems, </booktitle> <pages> pages 79-95, </pages> <address> Tarascon, France, </address> <month> September </month> <year> 1994. </year> <note> Springer-Verlag. </note>
Reference-contexts: Checkpointing and crash recovery is implemented using either physical (data) logging or operation logging. The granularity of checkpointing in the usual case is in terms of predetermined checkpointing units (or chunks) as defined by the system. P3L P3L, developed by Suzuki et al. <ref> [SKT94] </ref>, is a persistent variant of the C language. The system introduces and describes the notion of reservation and residency in the context of object faulting. <p> The Exodus Storage Manager is used for underlying persistent storage, although a specific storage manager is not dictated by any design choice of the system. <ref> [SKT94] </ref> presents a performance comparison between the software-only approach of P3L and several other systems, including pointer swizzling at page fault time, using the OO1 database benchmark. The results show that coarse-grained address translation is generally superior to other approaches in almost all situations.
Reference: [SKW92] <author> Vivek Singhal, Sheetal V. Kakkad, and Paul R. Wilson. </author> <title> Texas: An Efficient, Portable Persistent Store. </title> <booktitle> In Albano and Morrison [AM92], </booktitle> <pages> pages 11-33. </pages>
Reference-contexts: Introduction It is often desirable to support a virtual address space that is larger than what can be specified directly by the word size of the available hardware. Applications such as persistent object stores (e.g., <ref> [ABC + 83a, SKW92, DSZ90, AM92] </ref>), operating systems with a single shared address space (e.g., [CLLBH92]), distributed shared memories (e.g., [Li86]), etc. can benefit from large address spaces. <p> At checkpoint time, modified pages are written to a log on stable storage before the actual database is updated. 5 The granularity of checkpointing can be refined by the use of sub-page logging. The approach relies on a page "diffing" technique that we originally proposed in <ref> [SKW92] </ref>, and also briefly describe it again in Chapter 4 of this dissertation. <p> implementation of E, this allows the system to directly manage physical memory and the client buffer pool by explicitly moving data between the two hierarchies. 29 In the area of checkpointing for saving recovery information, QuickStore uses a page "diffing" technique similar to the idea that we first proposed in <ref> [SKW92] </ref>. The results presented in [Whi94] indicate that such "diffing" should perform well depending on the locality characteristics of the application. This observation is in line with our original projections of expected performance characteristics. <p> While our system is designed primarily for applications with relatively long transactions, such as typical CAD applications, we would like to provide support for small transactions as well. Sub-page logging (as we originally proposed in <ref> [SKW92] </ref>) is attractive for short transactions because we can checkpoint areas of memory that are smaller than pages. Rather than writing out entire dirty pages, we write out only those parts of a page that have actually changed by "diffing" against a clean copy of the page. <p> We believe that this approach should be used with caution because it makes page-wise checkpointing look unnecessarily bad, while making page-wise "diffing" <ref> [SKW92, Whi94] </ref> look unrealistically attractive. Although the randomized interconnection scheme exhibits some locality (that is, 90% of connections are close by), it has disastrous effects on locality of simple algorithms operating over the data because, on average, every tenth pointer traversal accesses a randomly-chosen part that is not close. <p> Given the "write anywhere" strategy of log-structured systems, writes can also be clustered such that related data are stored consecutively on disk, improving the read latency and bandwidth for future access. Our original paper on Texas <ref> [SKW92] </ref> describes further details about the log-structured storage system, including a description of its data structures. 8.2.2 Adaptive Prefetching Modern computer memory systems are hierarchical, being composed of several levels of memory [HP96].
Reference: [SL92] <author> Bjarne Stroustrup and Dmitry Lenkov. </author> <title> Run-time Type Identification for C++ (revised). </title> <booktitle> In USENIX C++ Conference [USE92]. </booktitle>
Reference-contexts: The ability to support run-time type queries about data objects is available for some high-level languages such as Smalltalk [GR89], CLU [LAB + 81] and Modula-3 [Nel91]. The term Run-Time Type Identification (RTTI) <ref> [SL92] </ref> has been used to represent language-level semantics and the ability to support operations that allow the application to ask whether a given type is a subtype of some other type. Recently, the C++ standard has added RTTI to support operations such as "downcasts" without circumventing the type system.
Reference: [Sta82] <author> James William Stamos. </author> <title> A Large Object-Oriented Virtual Memory: Grouping Strategies, Measurements, and Performance. </title> <type> Technical Report SCG-82-2, </type> <institution> Xerox Palo Alto Research Center, Palo Alto, California, </institution> <month> May </month> <year> 1982. </year>
Reference-contexts: This reduces the size of tables required to hold mappings between persistent and transient addresses|only the page numbers (addresses) must be recorded, not individual objects. It also meshes well with page faulting mechanisms; caching pages is more attractive than faulting objects when memories are not very small <ref> [Sta82, Wil91, WD92] </ref>. The technique reserves virtual address space "one step ahead" of the access pattern of the application, essentially forming a read barrier in a page-wise "wavefront" that is extended just past the pages that are already referenced by the application. This is shown pictorially 37 in Figure 3.4.
Reference: [Str87] <author> Bjarne Stroustrup. </author> <title> The Evolution of C++, </title> <booktitle> 1985 to 1987. In USENIX C++ Workshop, </booktitle> <pages> pages 1-22. </pages> <publisher> USENIX Association, </publisher> <year> 1987. </year>
Reference-contexts: A mixed-granularity scheme (that is, coarse-grained address translation by default, and fine-grained address translation for selected data structures) should provide most of the benefit without much additional overhead. We have implemented fine-grained address translation by using the C++ smart pointer idiom <ref> [Str87, Ede92b] </ref>. Smart pointers allow implementation of pointer-wise address translation that behaves well with the standard page-wise pointer swizzling scheme without requiring additional hardware support. <p> There are many ways of implementing a fine-grained (pointer-wise) address translation mechanism. We have selected an implementation strategy that remains consistent with our goals of maintaining portability and compatibility with existing off-the-shelf compilers, by using the C++ smart pointer abstraction <ref> [Str87, Ede92b] </ref>. In this section, we first briefly explain the smart pointers abstraction and then describe how we use smart pointers for implementing fine-grained translation in Texas.
Reference: [SW91] <author> Walter R. Smith and Robert V. Welland. </author> <title> A Model for Address-Oriented Software and Hardware. </title> <booktitle> In Proceedings of the 25th Hawaii International Conference on System Sciences. IEEE, </booktitle> <month> January </month> <year> 1991. </year>
Reference-contexts: We believe that with a little hardware support, operating systems should be able to provide sub-page protection facilities relatively easily. In fact, the ARM600 processor provides such support <ref> [SW91] </ref> facilitating the easy implementation of sub-page protections in the Apple Newton. The 801 prototype RISC machine also incorporated support for protections at the sub-page granularity [CM88].
Reference: [SZ90] <author> Eugene Shekita and Michael Zwilling. Cricket: </author> <title> A Mapped, Persistent Object Store. </title> <editor> In Dearle et al. </editor> <booktitle> [DSZ90], </booktitle> <pages> pages 89-102. 199 </pages>
Reference-contexts: The granularity of address translation is not applicable because no swizzling is performed, while granularities of address mapping and data fetching correspond to the entire database which is mapped into memory in a single step. Cricket Cricket <ref> [SZ90] </ref> uses the memory management primitives supported by Mach to implement a single-level persistent object store. The primary strategy relies on Mach external pager facilities [You89] to locate and load the persistent data from the disk into memory. Cricket also supports transparent concurrency control and recovery facilities. <p> An obvious solution is to not do pointer swizzling at all, following an approach similar to the one used by systems that directly map the entire persistent store in memory <ref> [SZ90] </ref>. However, this usually limits the amount of persistent data that can be accessed at one time. More importantly, it affects portability because the same mappings and virtual address ranges cannot be used across different operating systems.
Reference: [TL93] <author> Chandramohan A. Thekkath and Henry M. Levy. </author> <title> Limits to Low-Latency Com--muniation on High-Speed Network. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2) </volume> <pages> 179-203, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: However, if the application has good locality and accesses most objects on a page, the advantage of fine-grained loading and swizzling is quickly lost. Furthermore, although experimental network protocols have achieved surprisingly good performance <ref> [TL93, vEBB95] </ref>, most widely available current networks are still an order of magnitude (or more) slower, further reducing potential benefits of fine-grained schemes. In addition to the I/O cost, the cost of maintaining meta-data for address translation is also likely to affect the performance of a fine-grained scheme.
Reference: [TL94] <author> Chandramohan A. Thekkath and Henry M. Levy. </author> <title> Hardware and Software Support for Efficient Exception Handling. </title> <booktitle> In Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VI), </booktitle> <pages> pages 110-119, </pages> <address> San Jose, California, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: However, the empirical results that we have obtained indicate a slowdown factor of six, definitely much larger than what can be accounted by the extra 20% penalty. Discussion Other researchers have also recognized the problem with slow exception handling on various operating systems. Thekkath and Levy <ref> [TL94] </ref> contend that it is easier to improve performance of handling synchronous exceptions than it is for asynchronous exceptions because the information needed for servicing the former is already available in the user space of the process. <p> In fact, the ARM600 processor provides such support [SW91] facilitating the easy implementation of sub-page protections in the Apple Newton. The 801 prototype RISC machine also incorporated support for protections at the sub-page granularity [CM88]. Finally, Thekkath and Levy <ref> [TL94] </ref> have shown that a little kernel support can be used to emulate sub-page protections in a simple manner at a higher level of abstraction. 7.5.3 Support for Raw I/O In any computer system, disk I/O is usually much slower compared to the performance of other components, most notably the CPU.
Reference: [TNL95] <author> Ashutosh Tiwary, Vivek R. Narasayya, and Henry M. Levy. </author> <title> Evaluation of OO7 as a System and an Application Benchmark. In OOPSLA '95 Workshop on Object Database Behavior, Benchmarks and Performance, </title> <address> Austin, Texas, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: However, to the best of our knowledge, OO7 has not been validated against real applications from the CAD domain to ensure that it indeed represents a realistic workload. We believe that OO7 is not representative of typical CAD applications; other researchers <ref> [TNL95] </ref> have also reached similar conclusions. 112 5.8.2 Common Problems with the OO1 and OO7 Benchmarks We are primarily interested in the behavior of the OO1 and OO7 benchmarks, specifically for performance measurements in an orthogonally persistent systems such as ours. <p> We are not aware of any studies that measures this factor; the closest appears to be one by Tiwary et al. <ref> [TNL95] </ref>, and their conclusions indicate that OO7 is unsuitable as a generic CAD workload. Our own preliminary analysis of OO7 (not presented in this dissertation) has shown that the OO7 database connectivity exhibits poor locality of reference characteristics. <p> In addition, each persistent pointer is dereferenced only once during a traversal. This is unrealistic for CAD applications; for example, Tiwary et al. <ref> [TNL95] </ref> found that OO7 reused pointers 20 about 100 times less frequently than their CAD visualization application. Furthermore, no transient pointer traversal is included in both benchmarks.
Reference: [USE92] <editor> USENIX Association. </editor> <booktitle> USENIX C++ Conference, </booktitle> <address> Portland, Oregon, </address> <month> August </month> <year> 1992. </year>
Reference: [Vah96] <author> Uresh Vahalia. </author> <title> Unix Internals: The New Frontiers. </title> <publisher> Prentice-Hall, </publisher> <address> Upper Saddle River, New Jersey, </address> <year> 1996. </year>
Reference-contexts: Another solution that does not require external memory management support or other kernel modifications is based on exploiting the virtual file system (VFS) and vnode interface provided by most operating systems <ref> [Vah96] </ref>. Using this interface, a special "file system" can be implemented to handle the paging for a given persistent store; this file system can be designed to handle the pointer swizzling mechanism such that the virtual memory system only receives clean, swizzled pages thereby avoiding the mistaken-dirty-pages problem. <p> File I/O vs. Raw I/O On most operating systems, under normal circumstances, reads and writes to a regular file go through the kernel (for example, using the seg map driver on SVR4 systems <ref> [Vah96] </ref>). When a read system call is invoked, data is first read from the file into kernel space and then copied into user space (into a user-specified buffer). <p> Major page faults are a good indicator of real I/O activity because all reads and writes through the file system are implemented via internal kernel page faults for most modern Unix variants <ref> [Vah96] </ref>. all traversals.
Reference: [VD92] <author> Francis Vaughan and Alan Dearle. </author> <title> Supporting Large Persistent Stores Using Conventional Hardware. </title> <note> In Albano and Morrison [AM92]. </note>
Reference-contexts: an absolute requirement to use virtual memory protection facilities to implement persistence outside the language's run-time system, all three approaches described here are similar to Texas in that respect. 14 Note the similarity between PS-Smalltalk's fault blocks and LOOM's leaf objects. 27 Vaughan and Dearle's Hybrid Approach Vaughan and Dearle <ref> [VD92] </ref> have developed a scheme that is similar to ours because it also utilizes virtual memory protections for residency checking, but differs in the way the actual swizzling is performed.
Reference: [vEBB95] <author> Thorsten von Eicken, Anindya Basu, </author> <title> and Vineet Buch. Low-Latency Communication over ATM Networks using Active Messages. </title> <journal> IEEE Micro, </journal> <volume> 15(1) </volume> <pages> 46-53, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: However, if the application has good locality and accesses most objects on a page, the advantage of fine-grained loading and swizzling is quickly lost. Furthermore, although experimental network protocols have achieved surprisingly good performance <ref> [TL93, vEBB95] </ref>, most widely available current networks are still an order of magnitude (or more) slower, further reducing potential benefits of fine-grained schemes. In addition to the I/O cost, the cost of maintaining meta-data for address translation is also likely to affect the performance of a fine-grained scheme.
Reference: [WC96] <author> ISO WG21 and ANSI X3J16 Committee. </author> <title> Working Paper for Draft Proposed International Standard for Information Systems|Programming Language C++, </title> <month> December </month> <year> 1996. </year> <title> Document numbers WG21/N1043 (ISO) and X3J16/96-0225 (ANSI). </title> <note> Current public draft available at http://www.cygnus.com/misc/wp/. </note>
Reference-contexts: RTTI The current C++ draft standard <ref> [WC96] </ref> describes a proposal for Run-Time Type Identification (RTTI) as part of the language. Similar features are also available in other languages such as Java.
Reference: [WD92] <author> Seth J. White and David J. Dewitt. </author> <title> A Performance Study of Alternative Object Faulting and Pointer Swizzling Strategies. </title> <booktitle> In 18th International Conference on Very Large Data Bases, </booktitle> <address> Vancouver, British Columbia, October 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A new architecture, EPVM 2.0, has since been implemented to improve performance by copying data into virtual memory while translating OIDs into virtual memory addresses, and then unpinning the original page from the memory <ref> [WD92] </ref>. Copying into virtual memory can be done in terms of either individual objects or entire pages containing those objects. Applications manipulate data directly in virtual memory and no further overhead is incurred in OID translation, while pinning is only required during copying. <p> The basic architecture of the system is similar to the EPVM 2.0 object caching architecture <ref> [WD92] </ref> but the underlying storage manager is Mneme [Mos92]. Objects are copied from the Mneme buffer pool into virtual memory on demand, translating Mneme OIDs into virtual memory address values. Mneme implements reachability-based persistence, as well as garbage collection for all objects reachable from a persistent root. <p> Early schemes for supporting large virtual addresses on normal hardware (e.g., LOOM [KK83, Kae86], E <ref> [WD92] </ref>, etc.) have typically incurred significant overhead due to their use of traditional fine-grained address translation techniques. There are at least two basic approaches that are commonly used for implementing large address spaces in software. <p> This reduces the size of tables required to hold mappings between persistent and transient addresses|only the page numbers (addresses) must be recorded, not individual objects. It also meshes well with page faulting mechanisms; caching pages is more attractive than faulting objects when memories are not very small <ref> [Sta82, Wil91, WD92] </ref>. The technique reserves virtual address space "one step ahead" of the access pattern of the application, essentially forming a read barrier in a page-wise "wavefront" that is extended just past the pages that are already referenced by the application. This is shown pictorially 37 in Figure 3.4. <p> Given the above declaration of a smart pointer class, we can then use it as follows: 7 A pointer is "found" when its location becomes known. This is similar to the notion of "swizzling upon discovery" as described in <ref> [WD92] </ref>. 49 class Node; // assume previously defined Node *node_p; // regular pointer to Node object Ptr&lt;Node&gt; node_sp; // smart pointer to Node object ... node_p-&gt;some_method (); // invoke method via regular pointer node_sp-&gt;some_method (); // invoke method via smart pointer It is obvious from the above code fragment that the <p> The Insertion operation is suitable for measuring performance of checkpointing and updates because it actually modifies the database on disk. Another approach for this is a variation on the traversal operation described in <ref> [WD92] </ref>; the basic idea is similar to the traversal except that, in addition to invoking an empty procedure on visited parts, it also allows for updates with some predetermined probability.
Reference: [WD94] <author> Seth J. White and David J. Dewitt. </author> <title> QuickStore: A High Performance Mapped Object Store. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 395-406, </pages> <address> Minneapolis, Minnesota, May 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: It would be relatively easy to incorporate a similar optimization in Texas; however, we have not done it so far because it does not appear to provide any major benefits. QuickStore QuickStore <ref> [WD94, Whi94] </ref> is a research system that is very similar to ObjectStore in terms of its implementation strategy. QuickStore also uses pointer swizzling at page fault time approach for address translation, and like ObjectStore, it maintains additional mapping information to avoid swizzling as far as possible. <p> More importantly, it affects portability because the same mappings and virtual address ranges cannot be used across different operating systems. A slightly better alternative is to use an approach similar to the one used in ObjectStore [LLOW91] and QuickStore <ref> [WD94] </ref>; specifi 3 Our own environment is an example of this situation. 4 Systems administrators typically tend to frown upon software that arbitrarily changes the application paging behavior and adversely affects general performance in networked environments. 42 cally, this approach swizzles a page only if it cannot be mapped at the <p> Texas (Chapter 4) and other persistent object stores <ref> [ABC + 83a, AM95, LLOW91, WD94] </ref> that use pointer swizzling techniques such as pointer swizzling at page fault time need to know the locations of pointers in data objects at run time in order to find and manipulate these pointers correctly.
Reference: [Whi94] <author> Seth J. White. </author> <title> Pointer Swizzling Techniques for Object-Oriented Database Systems. </title> <type> PhD thesis, </type> <institution> University of Wisconsin|Madison, Madison, Wisonsin, </institution> <year> 1994. </year>
Reference-contexts: Pointer swizzling at page fault time is classified as a coarse-grained address translation technique because the granularity of translation is a virtual memory page. New Classification Scheme Various researchers have put forth different taxonomies for address translation approaches based on differences in the pointer swizzling techniques used <ref> [Mos92, KK95, MS95, Whi94] </ref>. Unfortunately, some of these classifications are unclear, and sometimes even contradictory to each other. Instead of attempting to clarify these taxonomies, we present a new classification scheme using several design choices that we consider important for implementing orthogonal persistence. <p> one project that is using pointer swizzling at page fault time techniques and extending Texas to implement reachability-based persistence for C++ and Modula-3 [HN97]. 2.3 Address Translation Taxonomies Persistence has been an active research area for over a decade and several researchers have put forth taxonomies for pointer swizzling techniques <ref> [Mos92, KK95, MS95, Whi94] </ref>. In this section, we describe important details about each of these taxonomies and highlights various similarities and differences among them. In addition, we also provide motivation for a general classification of persistent systems based on granularity issues. 2.3.1 Eager vs. <p> of each other, are typically combined in implementations of fine-grained schemes. * Another important component of the overall cost is related to the implementation of a custom object replacement policy, which is typically required because physical memory 6 The basic "diffing" technique has been implemented in the context of QuickStore <ref> [Whi94] </ref>; preliminary results are encouraging, although more investigation is required. 7 For example, all swizzled pointers in Texas must contain valid virtual memory address values. 20 is directly managed by the mechanism that implements persistence. <p> We believe that the E system [RC89, SCD90] is probably the fastest fine-grained scheme that is comparable to a coarse-grained address translation scheme; however, it still falls short in terms of performance. Based on the results presented in <ref> [Whi94] </ref>, E is about 48% slower than transient C/C++ for the hot traversals of the OO1 database benchmark [Cat91, CS92]. 11 This is a fairly significant overhead considering that the overhead of our system is zero for hot traversals and much smaller (less than 5%) otherwise. <p> It would be relatively easy to incorporate a similar optimization in Texas; however, we have not done it so far because it does not appear to provide any major benefits. QuickStore QuickStore <ref> [WD94, Whi94] </ref> is a research system that is very similar to ObjectStore in terms of its implementation strategy. QuickStore also uses pointer swizzling at page fault time approach for address translation, and like ObjectStore, it maintains additional mapping information to avoid swizzling as far as possible. <p> The results presented in <ref> [Whi94] </ref> indicate that such "diffing" should perform well depending on the locality characteristics of the application. This observation is in line with our original projections of expected performance characteristics. <p> We believe that this approach should be used with caution because it makes page-wise checkpointing look unnecessarily bad, while making page-wise "diffing" <ref> [SKW92, Whi94] </ref> look unrealistically attractive. Although the randomized interconnection scheme exhibits some locality (that is, 90% of connections are close by), it has disastrous effects on locality of simple algorithms operating over the data because, on average, every tenth pointer traversal accesses a randomly-chosen part that is not close.
Reference: [Wil90] <author> Paul R. Wilson. </author> <title> Some Issues and Strategies in Heap Management and Memory Hierarchies. </title> <booktitle> In OOPSLA/ECOOP '90 Workshop on Garbage Collection in Object-Oriented Systems, </booktitle> <month> October </month> <year> 1990. </year> <note> Also appears in ACM SIGPLAN Notices 23(3) 45-52, </note> <month> March </month> <year> 1991. </year> <month> 200 </month>
Reference-contexts: A cost effective approach to bridge this gap is to introduce a new level into the memory hierarchy. Compressed in-memory storage uses part of main memory as a cache for compressed pages <ref> [Wil90, WLM91, Wil91, AL91, Dou93] </ref>; this divides the main memory into partitions for uncompressed pages and compressed pages. The use of compressed in-memory storage can improve overall system performance because "paging" from the compression cache may be faster than paging from disk.
Reference: [Wil91] <author> Paul R. Wilson. </author> <title> Operating System Support for Small Objects. </title> <booktitle> In International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 80-86, </pages> <address> Palo Alto, California, </address> <month> October </month> <year> 1991. </year> <note> IEEE Press. </note>
Reference-contexts: This reduces the size of tables required to hold mappings between persistent and transient addresses|only the page numbers (addresses) must be recorded, not individual objects. It also meshes well with page faulting mechanisms; caching pages is more attractive than faulting objects when memories are not very small <ref> [Sta82, Wil91, WD92] </ref>. The technique reserves virtual address space "one step ahead" of the access pattern of the application, essentially forming a read barrier in a page-wise "wavefront" that is extended just past the pages that are already referenced by the application. This is shown pictorially 37 in Figure 3.4. <p> A cost effective approach to bridge this gap is to introduce a new level into the memory hierarchy. Compressed in-memory storage uses part of main memory as a cache for compressed pages <ref> [Wil90, WLM91, Wil91, AL91, Dou93] </ref>; this divides the main memory into partitions for uncompressed pages and compressed pages. The use of compressed in-memory storage can improve overall system performance because "paging" from the compression cache may be faster than paging from disk.
Reference: [Wil92] <author> Paul R. Wilson. </author> <title> Uniprocessor Garbage Collection Techniques. </title> <booktitle> In Bekkers and Cohen [BC92], </booktitle> <pages> pages 1-42. </pages>
Reference-contexts: In fact, as will be clear from our discussion about variations in fine-grained address translation mechanisms, the smart pointer will need to be implemented differently for different situations and implementation choices. Smart pointers were originally used in garbage collectors to implement write barriers <ref> [Wil92, Wil97] </ref> so that pointer updates by the application (also called the mutator) can be tracked easily, allowing the garbage collector to do its job.
Reference: [Wil97] <author> Paul R. Wilson. </author> <title> Garbage Collection. </title> <journal> ACM Computing Surveys, </journal> <note> 1997. Expanded version of [Wil92]. Draft available at ftp://ftp.cs.utexas.edu/pub/garbage/ bigsurv.ps. In revision, to appear. </note>
Reference-contexts: Furthermore, many such applications usually also operate extensively on transient data. Typically, a large majority of these transient objects constitute temporary data that die fairly "young" <ref> [Wil97, WJNB95] </ref>. Thus the total execution costs in a CPU-intensive application 3 are dominated by operations on transient objects and in-memory persistent objects. A high--performance persistent system should allow these operations to be executed as fast as possible, while imposing minimal overheads on the overall performance. <p> Compiled code then contains extra instructions|usually inserted by the compiler|to implement the read barrier. (Alternatively, 8 The term read barrier is borrowed from garbage collection research <ref> [Wil97] </ref>, and is used to denote a trigger that is activated on every read operation. <p> Research in garbage collection techniques has shown that typically 75-80% of the pointers in an application are likely to be unique <ref> [Wil97] </ref>. This means that the mapping table lookup will also fail as often. As table sizes increase, the cost of probing (and inserting new mappings) also tends to increase, adding to the overall costs of translation. <p> In fact, as will be clear from our discussion about variations in fine-grained address translation mechanisms, the smart pointer will need to be implemented differently for different situations and implementation choices. Smart pointers were originally used in garbage collectors to implement write barriers <ref> [Wil92, Wil97] </ref> so that pointer updates by the application (also called the mutator) can be tracked easily, allowing the garbage collector to do its job. <p> For such applications, a majority of objects need not to be saved to stable storage because they constitute transient data that does not live for very long <ref> [Wil97, WJNB95, Joh97] </ref>. In such situations, execution costs are dominated by operations over transient data; the persistence mechanism must not interfere with these operations, making them as fast as possible. In contrast, database program behavior denotes applications that are usually I/O-intensive and do not perform significant computation during their execution. <p> Most of this interaction stems from the use of virtual memory protection and access-protection violation handling for implementing coarse-grained address translation. In addition to Texas, there are many other useful system-level extensions and libraries (for example, garbage collectors <ref> [AEL88, Wil97] </ref>, distributed shared virtual memory systems [Li86, LH89], virtual memory tracing and compression facilities [WKBK97, WKB97a], advanced profiling, etc.) that closely interact with the operating system. We believe that operating system implementors should take interactions of such low-level systems and libraries into consideration when designing new systems.
Reference: [WJ93] <author> Paul R. Wilson and Mark S. Johnstone. </author> <title> Truly Real-Time Non-Copying Garbage Collection. </title> <booktitle> In OOPSLA '93 Workshop on Memory Management and Garbage Collection, </booktitle> <month> December </month> <year> 1993. </year> <note> Available at ftp://ftp.cs.utexas.edu/pub/garbage/ GC93. </note>
Reference-contexts: Similarly, precise garbage collectors <ref> [WJ93] </ref> also use this information to locate pointers in objects for tracing the reachability graph and reclaiming garbage. 1 Other applications that benefit from the knowledge of low-level layout information are: * data structure browsing, * data structure pickling, * data format conversion for sharing between machines with opposite endianness, * <p> We have implemented this system for multiple platforms by leveraging code from the GNU debugger, gdb, and the source is publicly available under the GNU General Public License (GPL) 2 at ftp://ftp.cs.utexas.edu/pub/garbage/texas. We are currently using this system in Texas (Chapter 4) and a real-time garbage collector for C++ <ref> [WJ93] </ref>. <p> In this section, we describe our case study implementation of RTTD for C++. We currently use this implementation in the Texas Persistent Store and a real-time garbage collector for C++ <ref> [WJ93] </ref>. As described earlier, type descriptor generation relies on the existence of debugging information in object files, and as such, does not directly depend on the source language. <p> We use these in our Texas Persistent Store (Chapter 4) and a real-time garbage collector for C++ <ref> [WJ93] </ref>. Currently, we have two versions of the type descriptor generator available: one for most modern Unix systems and the other for OS/2, the only difference between the two being the platform-specific code to parse the debugging information.
Reference: [WJNB95] <author> Paul R. Wilson, Mark S. Johnstone, Michael Neely, and David Boles. </author> <title> Dynamic Storage Allocation: A Survey and Critical Review. </title> <booktitle> In 1995 International Workshop on Memory Management, </booktitle> <address> Kinross, Scotland, UK, 1995. </address> <publisher> Springer Verlag LNCS. </publisher>
Reference-contexts: Furthermore, many such applications usually also operate extensively on transient data. Typically, a large majority of these transient objects constitute temporary data that die fairly "young" <ref> [Wil97, WJNB95] </ref>. Thus the total execution costs in a CPU-intensive application 3 are dominated by operations on transient objects and in-memory persistent objects. A high--performance persistent system should allow these operations to be executed as fast as possible, while imposing minimal overheads on the overall performance. <p> For such applications, a majority of objects need not to be saved to stable storage because they constitute transient data that does not live for very long <ref> [Wil97, WJNB95, Joh97] </ref>. In such situations, execution costs are dominated by operations over transient data; the persistence mechanism must not interfere with these operations, making them as fast as possible. In contrast, database program behavior denotes applications that are usually I/O-intensive and do not perform significant computation during their execution. <p> We are not interested in high-level standard library routines such as malloc or free which represent an implementation of some allocation policy (such as first-fit or best-fit <ref> [WJNB95] </ref>) 153 on top of the low-level primitives. Of course, the flexibility and features of the underlying virtual memory primitives are likely to guide the implementation choices of these high-level allocation mechanisms. Most modern Unix flavors provide two standard primitives, sbrk and mmap, for virtual memory allocation.
Reference: [WKB97a] <author> Paul R. Wilson, Scott F. Kaplan, and V. B. Balayogahan. </author> <title> Compressed Paging. </title> <note> In preparation, </note> <year> 1997. </year>
Reference-contexts: As the checkpoint-related data is streamed to disk, we intervene to perform some inline compression using specialized algorithms tuned to heap data. Further research has been initiated in this area <ref> [WKB97a, WKB97b] </ref> and preliminary results indicate that the I/O cost can be reduced by at least a factor of two (based on a 2-to-1 compression ratio). <p> In addition to Texas, there are many other useful system-level extensions and libraries (for example, garbage collectors [AEL88, Wil97], distributed shared virtual memory systems [Li86, LH89], virtual memory tracing and compression facilities <ref> [WKBK97, WKB97a] </ref>, advanced profiling, etc.) that closely interact with the operating system. We believe that operating system implementors should take interactions of such low-level systems and libraries into consideration when designing new systems. <p> Our system should also give benefits similar to those of file-compression schemes [CG91, BJLM92]. Further research is currently underway and detailed results will be presented in an upcoming paper <ref> [WKB97a] </ref>. 8.3 Advanced Issues In Chapter 1, we briefly mentioned some advanced issues that are beyond the scope of this dissertation. Specifically, we discussed issues related to distribution, concurrency control and fault tolerance, schema evolution, and security.
Reference: [WKB97b] <author> Paul R. Wilson, Scott F. Kaplan, and V. B. Balayogahan. </author> <title> Current Research in Compressed Virtual Memory. </title> <note> In preparation, </note> <year> 1997. </year>
Reference-contexts: As the checkpoint-related data is streamed to disk, we intervene to perform some inline compression using specialized algorithms tuned to heap data. Further research has been initiated in this area <ref> [WKB97a, WKB97b] </ref> and preliminary results indicate that the I/O cost can be reduced by at least a factor of two (based on a 2-to-1 compression ratio).
Reference: [WKBK97] <author> Paul R. Wilson, Scott F. Kaplan, V. B. Balayogahan, and Sheetal V. Kakkad. </author> <title> Virtual Memory Reference Tracing Using User-Level Access Protections. </title> <note> In preparation, </note> <year> 1997. </year>
Reference-contexts: In addition to Texas, there are many other useful system-level extensions and libraries (for example, garbage collectors [AEL88, Wil97], distributed shared virtual memory systems [Li86, LH89], virtual memory tracing and compression facilities <ref> [WKBK97, WKB97a] </ref>, advanced profiling, etc.) that closely interact with the operating system. We believe that operating system implementors should take interactions of such low-level systems and libraries into consideration when designing new systems. <p> While more refined experiments and a wider selection of test programs are required, we believe that the early results are very promising. We expect to reduce the time cost by another factor of two based on more fine-tuning of the basic implementation. Furthermore, our virtual memory trace-gathering tool <ref> [WKBK97] </ref> can also be extended to gather compressibility information on the fly, and our simulators can be modified to evaluate adaptive compressed paging techniques based on information from the traces.
Reference: [WKM94] <author> Paul R. Wilson, Sheetal V. Kakkad, and Shubhendu S. Mukherjee. </author> <title> Anomalies and Adaptation in the Analysis and Development of Prepaging Policies. </title> <journal> Journal of Systems and Software, </journal> <volume> 27 </volume> <pages> 147-153, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Unfortunately, the details of Horspool and Huberman's algorithms introduce unexpected anomalous properties <ref> [WKM94] </ref>. In particular, their policies are not properly timescale relative|events occurring on a timescale that should only matter to some sizes of memory adversely affect replacement decisions for memories of very different sizes. As we describe in [WKM94], slight changes to the algorithms can restore timescale relativity and make them much <p> Unfortunately, the details of Horspool and Huberman's algorithms introduce unexpected anomalous properties <ref> [WKM94] </ref>. In particular, their policies are not properly timescale relative|events occurring on a timescale that should only matter to some sizes of memory adversely affect replacement decisions for memories of very different sizes. As we describe in [WKM94], slight changes to the algorithms can restore timescale relativity and make them much better-behaved. What to Prefetch Horspool and Huberman's policy decides whether to prefetch based on previous observations of reference behavior. It is equally interesting what to prefetch.
Reference: [WLM91] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Effective Static-Graph Reorganization to Improve Locality in Garbage-Collected Systems. </title> <booktitle> In Proceedings of the 1991 SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 177-191, </pages> <address> Toronto, Ontario, </address> <month> June </month> <year> 1991. </year> <note> ACM Press. Published as ACM SIGPLAN Notices 26(6), </note> <month> June </month> <year> 1992. </year>
Reference-contexts: A cost effective approach to bridge this gap is to introduce a new level into the memory hierarchy. Compressed in-memory storage uses part of main memory as a cache for compressed pages <ref> [Wil90, WLM91, Wil91, AL91, Dou93] </ref>; this divides the main memory into partitions for uncompressed pages and compressed pages. The use of compressed in-memory storage can improve overall system performance because "paging" from the compression cache may be faster than paging from disk.
Reference: [WM89] <author> Paul R. Wilson and Thomas G. Moher. </author> <title> Design of the Opportunistic Garbage Collector. </title> <booktitle> In Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '89) Proceedings [OOP89], </booktitle> <pages> pages 23-35. </pages>
Reference-contexts: To support incremental copying/faulting of large objects, the language implementation must support operations for locating object boundaries and maintaining mapping tables to track pages that belong to large objects. These requirements are similar to those of garbage collected systems that must perform page-wise (or "card-wise") operations <ref> [AEL88, WM89] </ref> 5 An example of such an object would be a large array which spans multiple pages, even though the size of each individual element may be smaller than a page. 43 within the heap.
Reference: [WWH87] <author> Ifor W. Williams, Mario I. Wolczko, and Trevor P. Hopkins. </author> <title> Dynamic Grouping in an Object-Oriented Virtual Memory Hierarchy. </title> <booktitle> In European Conference on Object Oriented Programming, </booktitle> <pages> pages 87-96, </pages> <address> Paris, France, June 1987. </address> <publisher> Springer-Verlag. </publisher> <pages> 201 </pages>
Reference-contexts: Ideally, we would like this scheme to operate efficiently on standard hardware without requiring any special-purpose hardware such as that of the MUSHROOM project <ref> [WWH87] </ref>. Our approach, called pointer swizzling at page fault time (PS@PFT), is to load pages into virtual memory on demand, swizzling persistent pointers into normal hardware-supported virtual memory addresses at page fault time.
Reference: [You89] <author> Michael W. Young. </author> <title> Exporting a User Interface to Memory Management from a Communication-Oriented Operating System. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, Pittsburgh, Pennsylvania, </institution> <month> November </month> <year> 1989. </year> <note> Also available as Technical Report CMU-CS-89-202. 202 </note>
Reference-contexts: Cricket Cricket [SZ90] uses the memory management primitives supported by Mach to implement a single-level persistent object store. The primary strategy relies on Mach external pager facilities <ref> [You89] </ref> to locate and load the persistent data from the disk into memory. Cricket also supports transparent concurrency control and recovery facilities. The basic architecture is distributed, with a centralized server that is the primary interface of clients for accessing the persistent object store on disk.
References-found: 110

