URL: http://www.cs.bris.ac.uk/Tools/Reports/Ps/1997-burdsall-0.ps.gz
Refering-URL: http://www.cs.bris.ac.uk/Tools/Reports/Abstracts/1997-burdsall-0.html
Root-URL: 
Email: burdsall@gti.enst-bretagne.fr  cgc@cs.bris.ac.uk  
Title: GA-RBF: A Self-Optimising RBF Network  
Author: Ben Burdsall Christophe Giraud-Carrier 
Address: BP 832 29285 Brest Cedex, France  Bristol, BS8 1UB, England  
Affiliation: ENST de Bretagne,  Department of Computer Science University of Bristol  
Pubnum: Mastere 2IA  
Abstract: The effects of a neural network's topology on its performance are well known, yet the question of finding optimal configurations automatically remains largely open. This paper proposes a solution to this problem for RBF networks. A self- optimising approach, driven by an evolutionary strategy, is taken. The algorithm uses output information and a computationally efficient approximation of RBF networks to optimise the K-means clustering process by co-evolving the two determinant parameters of the network's layout: the number of centroids and the centroids' positions. Empirical results demonstrate promise. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Baroglio, et al. </author> <title> Learning Controllers for Industrial Robots. </title> <journal> Machine Learning, </journal> 23(2/3):221-249, 1996. 
Reference-contexts: A variety of techniques have been suggested to overcome the limitations of the traditional, K- means-based approach to centroid selection. They range from algebraic solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees [2] and concept learning algorithms <ref> [1] </ref> to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions [12] to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation. <p> They range from algebraic solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees [2] and concept learning algorithms <ref> [1] </ref> to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions [12] to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation.
Reference: [2] <author> E. Blanzieri, et al. </author> <title> Growing Radial Basis Function Networks. </title> <booktitle> In Proceedings of the Fourth Workshop on Learning Robots, </booktitle> <year> 1995. </year>
Reference-contexts: A variety of techniques have been suggested to overcome the limitations of the traditional, K- means-based approach to centroid selection. They range from algebraic solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees <ref> [2] </ref> and concept learning algorithms [1] to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions [12] to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation.
Reference: [3] <author> B. Burdsall and C. Giraud-Carrier. </author> <title> Evolving Fuzzy Prototypes for Efficient Data Clustering. </title> <booktitle> In Proceedings of ISFL'97, </booktitle> <year> 1997. </year>
Reference-contexts: The objective fitness function used for evaluating individuals consists of the application of the K-means algorithm to the clustering set using the starting positions encoded in the individual's genes, followed by a test classification of the evaluation set using the K-means- computed centroids and the nearest-attracting prototype (NAP) classifier <ref> [3] </ref>. Hence, f itness def correct classif ications size of evaluation set fi 100 The NAP classifier extends the classical nearest- neighbour classifier by using infinite fuzzy support as in RBF networks.
Reference: [4] <author> C. Decaestecker. </author> <title> Design of a Neural Net Classifier Using Prototypes. </title> <type> Technical Report, </type> <institution> IRIDIA, Universite Libre de Bruxelles, </institution> <year> 1994. </year>
Reference-contexts: They range from algebraic solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees [2] and concept learning algorithms [1] to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions [12] to more ad hoc techniques such as elimination <ref> [4] </ref>. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation.
Reference: [5] <author> L.J. Fogel. </author> <title> Evolutionary Programming in Perspective: The Top Down View. </title> <editor> In J.M. Zurada, et al. (Eds.), </editor> <booktitle> Computational Intelligence: Imitating Life, </booktitle> <publisher> IEEE Press, Inc., </publisher> <address> NY, </address> <year> 1994. </year>
Reference-contexts: The classical crossover operator is replaced by a novel operator, called gene-pooling, and three different types of mutation are introduced. Gene-pooling takes two parents and produces a single offspring. Following <ref> [5] </ref>, a population is viewed as a pool of genes rather than a collection of individuals. A gene, here, is a single centroid's starting position. During crossover the genes of two parents are mixed together into a kind of genetic soup.
Reference: [6] <author> B. Lemarie and A-G. Debroise. </author> <title> A Dynamical Architecture for Radial Basis Function Networks. </title> <booktitle> In Proceedings of ICANNGA'95, </booktitle> <volume> 305308, </volume> <year> 1995. </year>
Reference-contexts: They range from algebraic solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees [2] and concept learning algorithms [1] to statistical solutions using means tracking [14], clustering [1] and simulated annealing <ref> [6] </ref> to genetically-based solutions [12] to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation.
Reference: [7] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: The propagation of super-individuals leads to rapid exploitation but often results in premature convergence to a local optimum. A reasonable amount of exploration must be maintained. To address this issue, the notion of a life span for individuals has been suggested (see, <ref> [7] </ref>). GA-RBF follows this idea and defines the life span of individual i, at "birth", to be: Lif e span (i) def f itness (i) M ean where M ean is the average fitness of the population and fi is some constant.
Reference: [8] <author> J. Moody and C. Darken. </author> <title> Learning with Localized Receptive Fields. </title> <booktitle> In Proceedings of the 1988 Connectionist Models Summer School, </booktitle> <address> Pittsburgh, PA, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Radial basis function (RBF) networks (e.g., <ref> [8, 9, 13] </ref>) are a class of hybrid connectionist models.
Reference: [9] <author> J. Moody and C. Darken. </author> <title> Fast Learning in Networks of Locally-Tuned Processing Units. </title> <journal> Neural Computation, </journal> <volume> 1(2) </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Radial basis function (RBF) networks (e.g., <ref> [8, 9, 13] </ref>) are a class of hybrid connectionist models.
Reference: [10] <author> S. Mukherjee and S. Nayar. </author> <title> Automatic Generation of RBF Networks. </title> <type> Technical Report CUCS-001-95, </type> <institution> Columbia University, Department of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: A variety of techniques have been suggested to overcome the limitations of the traditional, K- means-based approach to centroid selection. They range from algebraic solutions inspired by wavelet transforms <ref> [10] </ref> to symbolic solutions using dynamic regression trees [2] and concept learning algorithms [1] to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions [12] to more ad hoc techniques such as elimination [4].
Reference: [11] <author> P.M. Murphy and D.W. Aha. </author> <title> UCI Repository of Machine Learning Databases. </title> <institution> University of California, Irvine, Department of Information and Computer Science. </institution>
Reference-contexts: Upon convergence, the starting positions encoded in the fittest individual are used by K-means to compute the centroids which are then fed into the hidden layer of the RBF network. Finally, the output layer of the network is trained using SVD. 3 Experimental Results Two datasets from <ref> [11] </ref> were used to test GA-RBF. The noisy versions contain the original data with substantial noise added. Multiple simulations and cross-validation techniques were used to increase the validity of the results.
Reference: [12] <author> R. Neruda. </author> <title> Functional Equivalence and Genetic Learning. </title> <booktitle> In Proceedings of ICANNGA'95, </booktitle> <pages> 53-56, </pages> <year> 1995. </year>
Reference-contexts: They range from algebraic solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees [2] and concept learning algorithms [1] to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions <ref> [12] </ref> to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation. Un- like [12], where the genetic algorithm (GA) evolves functionally-equivalent canonical parametrisations Page 1 of RBF networks, the GA here evolves fuzzy cen-- troids <p> solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees [2] and concept learning algorithms [1] to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions <ref> [12] </ref> to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation. Un- like [12], where the genetic algorithm (GA) evolves functionally-equivalent canonical parametrisations Page 1 of RBF networks, the GA here evolves fuzzy cen-- troids that become the basis functions of the network's hidden layer. <p> and concept learning algorithms [1] to statistical solutions using means tracking [14], clustering [1] and simulated annealing [6] to genetically-based solutions <ref> [12] </ref> to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation. Un- like [12], where the genetic algorithm (GA) evolves functionally-equivalent canonical parametrisations Page 1 of RBF networks, the GA here evolves fuzzy cen-- troids that become the basis functions of the network's hidden layer. Both the number of centroids per class and their positions are optimised.
Reference: [13] <author> T. Poggio and F. Girosi. </author> <title> Networks for Approximation and Learning. </title> <booktitle> Proceedings of IEEE, </booktitle> <volume> 78(9) </volume> <pages> 1481-1497, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Radial basis function (RBF) networks (e.g., <ref> [8, 9, 13] </ref>) are a class of hybrid connectionist models.
Reference: [14] <author> K. Warwick, et al. </author> <title> Center Selection for a Radial Basis Function Network. </title> <booktitle> In Proceedings of ICANNA'95, </booktitle> <pages> 309-312, </pages> <year> 1995. </year> <pages> Page 4 </pages>
Reference-contexts: A variety of techniques have been suggested to overcome the limitations of the traditional, K- means-based approach to centroid selection. They range from algebraic solutions inspired by wavelet transforms [10] to symbolic solutions using dynamic regression trees [2] and concept learning algorithms [1] to statistical solutions using means tracking <ref> [14] </ref>, clustering [1] and simulated annealing [6] to genetically-based solutions [12] to more ad hoc techniques such as elimination [4]. The solution proposed here, like [12], is based on the use of an evolutionary strategy for self-optimisation.
References-found: 14

