URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1998/tr-98-035.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1998.html
Root-URL: http://www.icsi.berkeley.edu
Email: fbilmes,krste,cheewhye,demmelg@cs.berkeley.edu  
Title: The PHiPAC v1.0 Matrix-Multiply Distribution.  
Phone: (510) 643-9153 FAX (510) 643-7684  
Author: Jeff Bilmes Krste Asanovic Chee-Whye Chin Jim Demmel 
Note: The author acknowledges the support of JSEP contract F49620-94-C-0038.  The author acknowledges the support of ONR URI Grant N00014-92-J-1617. Department of Mathematics, Princeton University. The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02).  The author acknowledges the support of ARPA contract DAAL03-91-C-0047 (University of Tennessee Subcontract ORA4466.02), ARPA contract DAAH04-95-1-0077 (University of Tennessee Subcontract ORA7453.02), DOE grant DE-FG03-94ER25219, DOE contract W-31-109-Eng-38, NSF grant ASC-9313958, and DOE grant DE-FG03-94ER25206.  
Date: October 1998  
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  Berkeley CA, 94720  Berkeley CA, 94704  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  CS Division, University of California at Berkeley  International Computer Science Institute  CS Division, University of California at Berkeley and the International Computer Science Institute.  CS Division, University of California at Berkeley and the International Computer Science Institute.  CS Division and Mathematics Dept., University of California at Berkeley.  
Pubnum: TR-98-35  
Abstract: Modern microprocessors can achieve high performance on linear algebra kernels but this currently requires extensive machine-specific hand tuning. We have developed a methodology whereby near-peak performance on a wide range of systems can be achieved automatically for such routines. First, by analyzing current machines and C compilers, we've developed guidelines for writing Portable, High-Performance, ANSI C (PHiPAC, pronounced fee-pack). Second, rather than code by hand, we produce parameterized code generators. Third, we write search scripts that find the best parameters for a given system. We report on a BLAS GEMM compatible multi-level cache-blocked matrix multiply generator which produces code that achieves around 90% of peak on the Sparcstation-20/61, IBM RS/6000-590, HP 712/80i, SGI Power Challenge R8k, and SGI Octane R10k, and over 80% of peak on the SGI Indigo R4k. In this paper, we provide a detailed description of the PHiPAC V1.0 matrix multiply distribution. We describe the code generator in detail including the various register and higher level blocking strategies. We also document the organization and parameters of the search scripts. This technical report is an expanded version of [BACD97]. 
Abstract-found: 1
Intro-found: 1
Reference: [ABB + 92] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <note> LAPACK users' guide, release 1.0. In SIAM, Philadelphia, </note> <year> 1992. </year>
Reference-contexts: We are currently working, therefore, on a better L1 and L2 blocking strategy and accompanying methods for search based on more intelligent criteria [LRW91]. The PHiPAC GEMM can be used with Bo Kagstrom's GEMM-based BLAS3 package [BLL93] and LAPACK <ref> [ABB + 92] </ref>. We have also written parameterized generators for matrix-vector and vector-matrix multiply, dot product, AXPY, convolution, and outer-product, and further generators, such as for FFT, are planned.
Reference: [ACF95] <author> B. Alpern, L. Carter, and J. Ferrante. </author> <title> Space-limited procedures: A methodology for portable high-performance. </title> <booktitle> In International Working Conference on Massively Parallel Programming Models, </booktitle> <year> 1995. </year>
Reference-contexts: Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine. There is a large literature on relevant compiler techniques, many of which use matrix multiplication as a test case <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref> 1 . While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. Also, a high-level language's semantics might obstruct aggressive compiler optimizations. <p> The PHiPAC methodology has three components. First, we have developed a generic model of current C compilers and microprocessors that provides guidelines for producing portable high-performance ANSI C code. Second, rather than hand code particular routines, we write parameterized generators <ref> [ACF95, MS95] </ref> that produce code according to our guidelines. Third, we write scripts that automatically tune code for a particular system by varying the generators' parameters and benchmarking the resulting routines.
Reference: [AGZ94] <author> R. Agarwal, F. Gustavson, and M. Zubair. </author> <title> IBM Engineering and Scientific Subroutine Library, Guide and Reference, 1994. Available through IBM branch offices. </title>
Reference-contexts: 1 Introduction The use of a standard linear algebra library interface, such as BLAS [LHKK79, DCHH88, DCDH90], enables portable application code to obtain high-performance provided that an optimized library (e.g., <ref> [AGZ94, KHM94] </ref>) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task. <p> Another commonly used method is to code in a high level language but with manual tuning to match the underlying architecture <ref> [AGZ94, KHM94] </ref>. While less tedious than coding in assembler, this approach still requires writing machine specific code which is not performance-portable across a range of systems. Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine.
Reference: [Asaa] <author> K. Asanovic. </author> <note> The IPM WWW home page. http://www.icsi.berkeley. edu/krste/IPM.html. </note>
Reference-contexts: These additional options are given every time the code generator is called. For a normal run of the search script, no additional generator options is necessary. * timer args: The timer args parameter specifies any options to be passed to the underlying IPM/RPRF <ref> [Asaa, Asab] </ref> timer program for benchmarking. 4.3 Compiler Specifications File This file simply specifies the optimization options for the compiler that the search script should use to compile the matrix code. Multiple compiler options can be specified and an entire search will be performed for each one.
Reference: [Asab] <author> K. Asanovic. </author> <note> The RPRF WWW home page. http://www.icsi.berkeley. edu/krste/RPRF.html. </note>
Reference-contexts: They can be independently compiled on your system to yield the executable code generator. Alternatively, the search scripts can be run to compile them automatically. * ipm-2.0/, rprf-v0 19/ Interval Performance Monitor, version 2.0.[Asaa] and Realization group (at ICSI) Performance measurement library, alpha version 0.19. <ref> [Asab] </ref>. These are the timing libraries PHiPAC uses for benchmarking generated code. They provide a uniform interface to a wide variety of machine timers on a variety of platforms. <p> These additional options are given every time the code generator is called. For a normal run of the search script, no additional generator options is necessary. * timer args: The timer args parameter specifies any options to be passed to the underlying IPM/RPRF <ref> [Asaa, Asab] </ref> timer program for benchmarking. 4.3 Compiler Specifications File This file simply specifies the optimization options for the compiler that the search script should use to compile the matrix code. Multiple compiler options can be specified and an entire search will be performed for each one.
Reference: [BACD97] <author> J. Bilmes, K. Asanovic, C.W. Chin, and J. Demmel. </author> <title> Optimizing matrix multiply using PHiPAC: a portable, high-performance, ANSI C coding methodology. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year> <note> ACM SIGARC. </note>
Reference-contexts: While both microarchitectures and compilers will improve over time, we expect it will be many years before a single version of a library routine can be compiled to give near-peak performance across a wide range of machines. We have developed a methodology, named PHiPAC <ref> [BAD + 96, BACD97] </ref>, for developing Portable High-Performance linear algebra libraries in ANSI C. Our goal is to produce, with minimal effort, high-performance linear algebra libraries for a wide range of systems. The PHiPAC methodology has three components. <p> Section 5 presents performance results on several architectures comparing against vendor-supplied BLAS GEMM. Section 6 describes the availability of the distribution, and discusses future work. This technical report is an expanded version of <ref> [BACD97] </ref>. 1 A longer list appears in [Wol96]. 1 2 PHiPAC By analyzing the microarchitectures of a range of machines, such as workstations and microprocessor-based SMP and MPP nodes, and the output of their ANSI C compilers, we derived a set of guidelines that help us attain high performance across a
Reference: [BAD + ] <author> J. Bilmes, K. Asanovic, J. Demmel, D. Lam, and C.W. Chin. </author> <note> The PHiPAC WWW home page. http://www.icsi.berkeley.edu/bilmes/phipac. </note>
Reference-contexts: We have created a Web site from which the release, and all relevant documentation, is available and on which we plan at some point to list blocking parameters and GEMM libraries for many systems <ref> [BAD + ] </ref>. We wish to thank Ed Rothberg of SGI for help obtaining the R8K and R10K performance plots.
Reference: [BAD + 96] <author> J. Bilmes, K. Asanovic, J. Demmel, D. Lam, and C.W. Chin. PHiPAC: </author> <title> A portable, high-performance, ANSI C coding methodology and its application to matrix multiply. </title> <note> LAPACK working note 111, </note> <institution> University of Tennessee, </institution> <year> 1996. </year> <month> 27 </month>
Reference-contexts: While both microarchitectures and compilers will improve over time, we expect it will be many years before a single version of a library routine can be compiled to give near-peak performance across a wide range of machines. We have developed a methodology, named PHiPAC <ref> [BAD + 96, BACD97] </ref>, for developing Portable High-Performance linear algebra libraries in ANSI C. Our goal is to produce, with minimal effort, high-performance linear algebra libraries for a wide range of systems. The PHiPAC methodology has three components. <p> [Wol96]. 1 2 PHiPAC By analyzing the microarchitectures of a range of machines, such as workstations and microprocessor-based SMP and MPP nodes, and the output of their ANSI C compilers, we derived a set of guidelines that help us attain high performance across a range of machine and compiler combinations <ref> [BAD + 96] </ref>. From our analysis of various ANSI C compilers, we determined we could usually rely on reasonable register allocation, instruction selection, and instruction scheduling.
Reference: [BLL93] <author> B.Kagstrom, P. Ling, and C. Van Loan. </author> <title> Portable high performance GEMM-based level 3 BLAS. In R.F. </title> <editor> Sincovec et al., editor, </editor> <booktitle> Parallel Processing for Scientific Computing, </booktitle> <pages> pages 339-346, </pages> <address> Philadelphia, 1993. </address> <publisher> SIAM Publications. </publisher>
Reference-contexts: We are currently working, therefore, on a better L1 and L2 blocking strategy and accompanying methods for search based on more intelligent criteria [LRW91]. The PHiPAC GEMM can be used with Bo Kagstrom's GEMM-based BLAS3 package <ref> [BLL93] </ref> and LAPACK [ABB + 92]. We have also written parameterized generators for matrix-vector and vector-matrix multiply, dot product, AXPY, convolution, and outer-product, and further generators, such as for FFT, are planned.
Reference: [BLS91] <author> D. H. Bailey, K. Lee, and H. D. Simon. </author> <title> Using Strassen's algorithm to accelerate the solution of linear systems. </title> <journal> J. Supercomputing, </journal> <volume> 4 </volume> <pages> 97-371, </pages> <year> 1991. </year>
Reference-contexts: Developing an optimized library, however, is a difficult and time-consuming task. Even excluding algorithmic variants such as Strassen's method <ref> [BLS91] </ref> for matrix multiplication, these routines have a large design space with many parameters such as blocking sizes, loop nesting permutations, loop unrolling depths, software pipelining strategies, register allocations, and instruction schedules. Furthermore, these parameters have complicated interactions with the increasingly sophisticated microarchitectures of new microprocessors.
Reference: [CDD + 96] <author> J. Choi, J. Demmel, I. Dhillon, J. Dongarra, S. Ostrouchov, A. Petitet, K. Stanley, D. Walker, and R.C. Whaley. ScaLAPAC: </author> <title> A portable linear algebra library for distributed memory computers design issues and performance. </title> <note> LAPACK working note 95, </note> <institution> University of Tennessee, </institution> <year> 1996. </year>
Reference-contexts: We focus on matrix multiplication in this paper, but we have produced other generators including dot-product, AXPY, and convolution, which have similarly demonstrated portable high performance. We concentrate on producing high quality uniprocessor libraries for microprocessor-based systems because multiprocessor libraries, such as <ref> [CDD + 96] </ref>, can be readily built from uniprocessor libraries. For vector and other architectures, however, our machine model would likely need substantial modification. Section 2 describes our generic C compiler and microprocessor model, and develops the resulting guidelines for writing portable high-performance C code.
Reference: [CFH95] <author> L. Carter, J. Ferrante, and S. Flynn Hummel. </author> <title> Hierarchical tiling for improved superscalar performance. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine. There is a large literature on relevant compiler techniques, many of which use matrix multiplication as a test case <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref> 1 . While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. Also, a high-level language's semantics might obstruct aggressive compiler optimizations. <p> Within the K-loop is our fully-unrolled 2 fi 2 fi 2 core matrix multiply. The code is not unlike the register code in <ref> [CFH95] </ref>. In our terminology, the leading dimensions LDA, LDB, and LDC are called Astride, Bstride, and Cstride respectively. The four local variables c0 0 through c1 1 hold a complete C destination block.
Reference: [DCDH90] <author> J. Dongarra, J. Du Croz, I. Duff, and S. Hammarling. </author> <title> A set of level 3 basic linear algebra subprograms. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 16(1) </volume> <pages> 1-17, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The use of a standard linear algebra library interface, such as BLAS <ref> [LHKK79, DCHH88, DCDH90] </ref>, enables portable application code to obtain high-performance provided that an optimized library (e.g., [AGZ94, KHM94]) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task.
Reference: [DCHH88] <author> J. Dongarra, J. Du Cros, S. Hammarling, and R.J. Hanson. </author> <title> An extended set of FORTRAN basic linear algebra subroutines. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 14 </volume> <pages> 1-17, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: 1 Introduction The use of a standard linear algebra library interface, such as BLAS <ref> [LHKK79, DCHH88, DCDH90] </ref>, enables portable application code to obtain high-performance provided that an optimized library (e.g., [AGZ94, KHM94]) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task.
Reference: [GL89] <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <year> 1989. </year>
Reference-contexts: We create a full BLAS-compatible GEMM by generating all required matrix multiply variants and linking with our GEMM-compatible interface that includes error checking. The code generators can produce a cache-blocked matrix multiply <ref> [GL89, LRW91, MS95] </ref>, restructuring the algorithm for unit stride, and reducing the number of cache misses and unnecessary loads and stores.
Reference: [KHM94] <author> C. Kamath, R. Ho, </author> <title> and D.P. Manley. DXML: A high-performance scientific subroutine library. </title> <journal> Digital Technical Journal, </journal> <volume> 6(3) </volume> <pages> 44-56, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The use of a standard linear algebra library interface, such as BLAS [LHKK79, DCHH88, DCDH90], enables portable application code to obtain high-performance provided that an optimized library (e.g., <ref> [AGZ94, KHM94] </ref>) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task. <p> Another commonly used method is to code in a high level language but with manual tuning to match the underlying architecture <ref> [AGZ94, KHM94] </ref>. While less tedious than coding in assembler, this approach still requires writing machine specific code which is not performance-portable across a range of systems. Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine.
Reference: [LHKK79] <author> C. Lawson, R. Hanson, D. Kincaid, and F. Krogh. </author> <title> Basic linear algebra subprograms for FORTRAN usage. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 5 </volume> <pages> 308-323, </pages> <year> 1979. </year>
Reference-contexts: 1 Introduction The use of a standard linear algebra library interface, such as BLAS <ref> [LHKK79, DCHH88, DCDH90] </ref>, enables portable application code to obtain high-performance provided that an optimized library (e.g., [AGZ94, KHM94]) is available and affordable. Developing an optimized library, however, is a difficult and time-consuming task.
Reference: [LRW91] <author> M. S. Lam, E. E. Rothberg, and M. E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proceedings of ASPLOS IV, </booktitle> <pages> pages 63-74, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine. There is a large literature on relevant compiler techniques, many of which use matrix multiplication as a test case <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref> 1 . While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. Also, a high-level language's semantics might obstruct aggressive compiler optimizations. <p> We create a full BLAS-compatible GEMM by generating all required matrix multiply variants and linking with our GEMM-compatible interface that includes error checking. The code generators can produce a cache-blocked matrix multiply <ref> [GL89, LRW91, MS95] </ref>, restructuring the algorithm for unit stride, and reducing the number of cache misses and unnecessary loads and stores. <p> The K loop updates the set of pointers to the A source block, one of which is used for loop termination. Currently, mm cgen does not vary the loop permutation <ref> [MS95, LRW91] </ref> because the resulting gains in locality are subsumed by the method described below, at least for non-outer-product shaped matrices. The parameter K 0 controls the extent of inner loop unrolling as can be seen in Figure 2. <p> We would like to make the L1 blocks large to increase data reuse but larger L1 blocks increase the probability of cache conflicts <ref> [LRW91] </ref>. Tradeoffs between M- and N- loop overheads, memory access patterns, and TLB structure also affect the best L1 size. We currently perform a relatively simple search of the L1 parameter space. <p> Our measurements exaggerate this effect by including all power-of-2 sized matrices, and by allocating all regions contiguously in memory. For matrix multiply, we can reduce cache conflicts by copying to contiguous memory when pathological strides are encountered <ref> [LRW91] </ref>. Unfortunately, this approach does not help dot product. One drawback of the PHiPAC approach is that we can not control the order compilers schedule independent loads. <p> DGEMM from SGI's R10K-optimized libblas. 26 however, for decomposing matrices for performing L1 and L2 matrix multiply and the associated search strategy is rather naive. We are currently working, therefore, on a better L1 and L2 blocking strategy and accompanying methods for search based on more intelligent criteria <ref> [LRW91] </ref>. The PHiPAC GEMM can be used with Bo Kagstrom's GEMM-based BLAS3 package [BLL93] and LAPACK [ABB + 92]. We have also written parameterized generators for matrix-vector and vector-matrix multiply, dot product, AXPY, convolution, and outer-product, and further generators, such as for FFT, are planned.
Reference: [MS95] <author> J.D. McCalpin and M. Smotherman. </author> <title> Automatic benchmark generation for cache optimization of matrix algorithms. </title> <editor> In R. Geist and S. Junkins, editors, </editor> <booktitle> Proceedings of the 33rd Annual Southeast Conference, </booktitle> <pages> pages 195-204. </pages> <publisher> ACM, </publisher> <month> March </month> <year> 1995. </year>
Reference-contexts: Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine. There is a large literature on relevant compiler techniques, many of which use matrix multiplication as a test case <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref> 1 . While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. Also, a high-level language's semantics might obstruct aggressive compiler optimizations. <p> The PHiPAC methodology has three components. First, we have developed a generic model of current C compilers and microprocessors that provides guidelines for producing portable high-performance ANSI C code. Second, rather than hand code particular routines, we write parameterized generators <ref> [ACF95, MS95] </ref> that produce code according to our guidelines. Third, we write scripts that automatically tune code for a particular system by varying the generators' parameters and benchmarking the resulting routines. <p> We create a full BLAS-compatible GEMM by generating all required matrix multiply variants and linking with our GEMM-compatible interface that includes error checking. The code generators can produce a cache-blocked matrix multiply <ref> [GL89, LRW91, MS95] </ref>, restructuring the algorithm for unit stride, and reducing the number of cache misses and unnecessary loads and stores. <p> The K loop updates the set of pointers to the A source block, one of which is used for loop termination. Currently, mm cgen does not vary the loop permutation <ref> [MS95, LRW91] </ref> because the resulting gains in locality are subsumed by the method described below, at least for non-outer-product shaped matrices. The parameter K 0 controls the extent of inner loop unrolling as can be seen in Figure 2.
Reference: [SMP + 96] <author> R. Saavedra, W. Mao, D. Park, J. Chame, and S. Moon. </author> <title> The combined effectiveness of unimodular transformations, tiling, and software prefetching. </title> <booktitle> In Proceedings of the 10th International Parallel Processing Symposium, </booktitle> <month> April 15-19 </month> <year> 1996. </year>
Reference-contexts: Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine. There is a large literature on relevant compiler techniques, many of which use matrix multiplication as a test case <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref> 1 . While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. Also, a high-level language's semantics might obstruct aggressive compiler optimizations.
Reference: [WL91] <author> M. E. Wolf and M. S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Ideally, the routines would be written once in a high-level language and fed to an optimizing compiler for each machine. There is a large literature on relevant compiler techniques, many of which use matrix multiplication as a test case <ref> [WL91, LRW91, MS95, ACF95, CFH95, SMP + 96] </ref> 1 . While these compiler heuristics generate reasonably good code in general, they tend not to generate near-peak code for any one operation. Also, a high-level language's semantics might obstruct aggressive compiler optimizations.
Reference: [Wol96] <author> M. Wolfe. </author> <title> High performance compilers for parallel computing. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year> <month> 28 </month>
Reference-contexts: Section 5 presents performance results on several architectures comparing against vendor-supplied BLAS GEMM. Section 6 describes the availability of the distribution, and discusses future work. This technical report is an expanded version of [BACD97]. 1 A longer list appears in <ref> [Wol96] </ref>. 1 2 PHiPAC By analyzing the microarchitectures of a range of machines, such as workstations and microprocessor-based SMP and MPP nodes, and the output of their ANSI C compilers, we derived a set of guidelines that help us attain high performance across a range of machine and compiler combinations [BAD
References-found: 22

