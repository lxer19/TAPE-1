URL: http://www.cs.unc.edu/~anderson/papers/podc99.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: Wait-Free Synchronization in Multiprogrammed Systems: Integrating Priority-Based and Quantum-Based Scheduling (Extended Abstract)  
Author: James H. Anderson Mark Moir 
Address: Chapel Hill  Pittsburgh  
Affiliation: Department of Computer Science University of North Carolina at  Department of Computer Science University of  
Abstract: We consider wait-free synchronization in multipro-grammed uniprocessor and multiprocessor systems in which "hybrid" schedulers are employed that use both priority information and a scheduling quantum in making scheduling decisions. The main contribution of this paper is to show that, in any hybrid-scheduled system, any object with consensus number C P in Herlihy's wait-free hierarchy is universal for any number of processes executing on P processors, provided the scheduling quantum is of a certain size. We also show that if a C-consensus object must be "hard-wired" to the processors that access it, then our characterization of the required quantum is asymptotically tight. If C = P or if C 2P , then this characterization is asymptotically tight regardless of whether objects must be "hard-wired". 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson, R. Jain, and D. Ott. </author> <title> Wait-free synchronization in quantum-based multiprogrammed systems. </title> <booktitle> In Proceedings of the 12th International Symposium on Distributed Computing, </booktitle> <pages> pp. 34-48. </pages> <publisher> Springer Verlag, </publisher> <month> Sept. </month> <year> 1998. </year>
Reference-contexts: In subsequent work, Anderson, Jain, and Ott considered multiprogrammed systems in which quantum-based scheduling is used <ref> [1] </ref>. Under quantum-based scheduling, each processor is allocated to its assigned processes in discrete time units called quanta. <p> However, if a process can ever detect that it has "crossed" a quantum boundary, then it can be sure that the next few instructions it executes will be performed without preemption. Many of the quantum-based algorithms presented by Anderson et al. in <ref> [1] </ref> employ such a detection mechanism. In the algorithms presented in this paper, mechanisms are incorporated to allow processes to deal with both priority-based and quantum-based preemptions. The remainder of this paper is organized as follows. <p> This implementation uses only reads and writes and is correct if the quantum exceeds a certain constant value. Uniprocessor consensus can be solved using the algorithm in Fig. 3. This algorithm was originally proposed for quantum-scheduled systems (as noted in <ref> [1] </ref>, the algorithm is due to Moir and Ramamurthy, but they did not publish it). We show here that it is also correct in hybrid-scheduled systems. The algorithm is correct provided Q is large enough to ensure that each process can be quantum-preempted at most once during the for loop. <p> The algorithm is correct provided Q is large enough to ensure that each process can be quantum-preempted at most once during the for loop. By replacing the for loop by straight-line code, it can be seen that Q = 8 suffices. The algorithm employs three shared variables, P <ref> [1] </ref>, P [2], and P [3]. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. <p> By replacing the for loop by straight-line code, it can be seen that Q = 8 suffices. The algorithm employs three shared variables, P <ref> [1] </ref>, P [2], and P [3]. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. <p> The dashed line indicates that it could be that r2 = s2 and (I)=(F).) (J) r2 previously reads P [2] = ? (must be before (H) because P [i] 6= ? is stable). (K) Similarly, r1 previously reads P [2] = ?. (L) r1 reads P <ref> [1] </ref> = v1 or writes P [1] := v1 before (K). (M) r2 reads P [1] = v2 or writes P [1] := v2 before (J). (N) In the diagram, we have assumed (L) &lt; (M). <p> line indicates that it could be that r2 = s2 and (I)=(F).) (J) r2 previously reads P [2] = ? (must be before (H) because P [i] 6= ? is stable). (K) Similarly, r1 previously reads P [2] = ?. (L) r1 reads P <ref> [1] </ref> = v1 or writes P [1] := v1 before (K). (M) r2 reads P [1] = v2 or writes P [1] := v2 before (J). (N) In the diagram, we have assumed (L) &lt; (M). The rest of the proof is symmetric for the other case. (O) Some process p writes P [1] := v1 at <p> s2 and (I)=(F).) (J) r2 previously reads P [2] = ? (must be before (H) because P [i] 6= ? is stable). (K) Similarly, r1 previously reads P [2] = ?. (L) r1 reads P <ref> [1] </ref> = v1 or writes P [1] := v1 before (K). (M) r2 reads P [1] = v2 or writes P [1] := v2 before (J). (N) In the diagram, we have assumed (L) &lt; (M). The rest of the proof is symmetric for the other case. (O) Some process p writes P [1] := v1 at or before (L). (N.B. <p> reads P [2] = ? (must be before (H) because P [i] 6= ? is stable). (K) Similarly, r1 previously reads P [2] = ?. (L) r1 reads P <ref> [1] </ref> = v1 or writes P [1] := v1 before (K). (M) r2 reads P [1] = v2 or writes P [1] := v2 before (J). (N) In the diagram, we have assumed (L) &lt; (M). The rest of the proof is symmetric for the other case. (O) Some process p writes P [1] := v1 at or before (L). (N.B. <p> or writes P <ref> [1] </ref> := v1 before (K). (M) r2 reads P [1] = v2 or writes P [1] := v2 before (J). (N) In the diagram, we have assumed (L) &lt; (M). The rest of the proof is symmetric for the other case. (O) Some process p writes P [1] := v1 at or before (L). (N.B. The dashed line indicates that it could be that p = r1 and (O)=(L).) (P) Some process q writes P [1] := v2 after (L) and at or before (M). (N.B. <p> The rest of the proof is symmetric for the other case. (O) Some process p writes P <ref> [1] </ref> := v1 at or before (L). (N.B. The dashed line indicates that it could be that p = r1 and (O)=(L).) (P) Some process q writes P [1] := v2 after (L) and at or before (M). (N.B. The dashed line indicates that it could be that q = r2 and (P)=(M).) (Q) q reads P [1] = ? before (P) and before (O) because P [i] 6= ? is stable. <p> The dashed line indicates that it could be that p = r1 and (O)=(L).) (P) Some process q writes P <ref> [1] </ref> := v2 after (L) and at or before (M). (N.B. The dashed line indicates that it could be that q = r2 and (P)=(M).) (Q) q reads P [1] = ? before (P) and before (O) because P [i] 6= ? is stable. Observe that process p takes a step ((O)) between two steps of process q ((Q) and (P)). Therefore, priority (p) priority (q). <p> ; 3: w := P [i]; 4: if w 6= ? then 5: v := w else 6: P [i] := v od; 7: return P [3] s1 r1 p P [3]:=v2P [2]=v2 A B E G P [2]:=v2 P [2]:=v1 K P <ref> [1] </ref>=v2 N Q P P [1]:=v1 P [1]= P [2]= completion before (M), contradicting P [2] = ? at (J). Also, if priority (q) = priority (r2), then q would run to completion before (H), contradicting P [3] = ? at (C). <p> Our consensus algorithm is shown in Fig. 5. This algorithm has been obtained by modifying a similar algorithm presented previously in <ref> [1] </ref> for purely quantum-scheduled systems. The modifications allow multiple priority levels to be supported. In addition to C-consensus objects, the algorithm employs a number of uniprocessor compare-and-swap (C&S), fetch-and-increment (F&I), and consensus objects. We use "local-C&S", "local-F&I", and "local-consensus" in Fig. 5 to emphasize that these are uniprocessor objects. <p> We use "local-C&S", "local-F&I", and "local-consensus" in Fig. 5 to emphasize that these are uniprocessor objects. Operations on these uniprocessor objects can be implemented in constant time using algorithms for quantum-scheduled systems given in <ref> [1] </ref>. We begin our description of the algorithm by giving a very brief overview of it; details are provided in the following paragraphs. The algorithm works by having each process participate in a series of "consensus levels". There are L consensus levels, as illustrated in Fig. 6. <p> Because Port [i; v] is updated only by processes with the same priority, the F&I and C&S operations used in updating it can be implemented from reads and writes using the constant-time algorithms for purely quantum-scheduled systems presented in <ref> [1] </ref>. The local consensus object for each port can also be implemented from reads and writes in constant time, using the algorithm given in Sec. 3. Having explained how ports are acquired, we now explain in more detail how an overall decision value is reached. <p> It is therefore updated using a C&S operation instead of F&I (see line 33). Like Port [i; v], Lastpub [i; v] is updated only by pro cesses with priority v, so the C&S operations that update Lastpub [i; v] can be implemented from reads and writes in constant time <ref> [1] </ref>. If a process on processor i is pre empted by higher-priority processes, or if a decision is reached before it starts, then it may safely return the output value from level L (lines 2 and 15).
Reference: [2] <author> J. Anderson and M. Moir. </author> <title> Wait-free synchronization in multiprogrammed systems: </title> <note> integrating priority-based and quantum-based scheduling (expanded version of this paper). Available at http: //www.cs.unc.edu/ ~anderson/papers.html. </note>
Reference-contexts: We end the paper with concluding remarks in Sec. 5. Due to space limitations, only proof sketches are provided for some of our results. Complete proofs can be found in the full paper <ref> [2] </ref>. 2 Preliminaries In this section, we describe the schedulers considered in this paper, and then formally define our execution model. We consider pure priority- and quantum-based sched-ulers, and also hybrid schedulers. Hybrid schedulers generalize both priority- and quantum-based schedulers, so we present formal definitions for hybrid systems only. <p> By replacing the for loop by straight-line code, it can be seen that Q = 8 suffices. The algorithm employs three shared variables, P [1], P <ref> [2] </ref>, and P [3]. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. <p> By replacing the for loop by straight-line code, it can be seen that Q = 8 suffices. The algorithm employs three shared variables, P [1], P <ref> [2] </ref>, and P [3]. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. <p> The algorithm employs three shared variables, P [1], P <ref> [2] </ref>, and P [3]. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. Lemma 1: In the consensus algorithm in Fig. 3, each process returns the same value. 2 Proof : Suppose towards a contradiction that two processes return different values v1 and v2. <p> Specifically, we have the following: (A) s1 reads P [3] = ? and then (B) writes P [3] := v1 and (C) s2 reads P [3] = ? and then (D) writes P [3] := v2. This implies that (E) s1 either reads P <ref> [2] </ref> = v1 or writes P [2] := v1 before (A) and (F) s2 either reads P [2] = v2 or writes P [2] := v2 before (C). (G) We assume, without loss of generality, that E &lt; F . (H) Some process r1 writes P [2] := v1 at or <p> This implies that (E) s1 either reads P <ref> [2] </ref> = v1 or writes P [2] := v1 before (A) and (F) s2 either reads P [2] = v2 or writes P [2] := v2 before (C). (G) We assume, without loss of generality, that E &lt; F . (H) Some process r1 writes P [2] := v1 at or before (E). (N.B. <p> This implies that (E) s1 either reads P <ref> [2] </ref> = v1 or writes P [2] := v1 before (A) and (F) s2 either reads P [2] = v2 or writes P [2] := v2 before (C). (G) We assume, without loss of generality, that E &lt; F . (H) Some process r1 writes P [2] := v1 at or before (E). (N.B. <p> This implies that (E) s1 either reads P <ref> [2] </ref> = v1 or writes P [2] := v1 before (A) and (F) s2 either reads P [2] = v2 or writes P [2] := v2 before (C). (G) We assume, without loss of generality, that E &lt; F . (H) Some process r1 writes P [2] := v1 at or before (E). (N.B. <p> s1 either reads P <ref> [2] </ref> = v1 or writes P [2] := v1 before (A) and (F) s2 either reads P [2] = v2 or writes P [2] := v2 before (C). (G) We assume, without loss of generality, that E &lt; F . (H) Some process r1 writes P [2] := v1 at or before (E). (N.B. The dashed line indicates that it could be that r1 = s1 and (H)=(E).) (I) Also, some process r2 writes P [2] := v2 after (E) and at or before (F). (N.B. <p> v2 before (C). (G) We assume, without loss of generality, that E &lt; F . (H) Some process r1 writes P <ref> [2] </ref> := v1 at or before (E). (N.B. The dashed line indicates that it could be that r1 = s1 and (H)=(E).) (I) Also, some process r2 writes P [2] := v2 after (E) and at or before (F). (N.B. The dashed line indicates that it could be that r2 = s2 and (I)=(F).) (J) r2 previously reads P [2] = ? (must be before (H) because P [i] 6= ? is stable). (K) Similarly, r1 previously reads P [2] <p> dashed line indicates that it could be that r1 = s1 and (H)=(E).) (I) Also, some process r2 writes P <ref> [2] </ref> := v2 after (E) and at or before (F). (N.B. The dashed line indicates that it could be that r2 = s2 and (I)=(F).) (J) r2 previously reads P [2] = ? (must be before (H) because P [i] 6= ? is stable). (K) Similarly, r1 previously reads P [2] = ?. (L) r1 reads P [1] = v1 or writes P [1] := v1 before (K). (M) r2 reads P [1] = v2 or writes P [1] := v2 <p> <ref> [2] </ref> := v2 after (E) and at or before (F). (N.B. The dashed line indicates that it could be that r2 = s2 and (I)=(F).) (J) r2 previously reads P [2] = ? (must be before (H) because P [i] 6= ? is stable). (K) Similarly, r1 previously reads P [2] = ?. (L) r1 reads P [1] = v1 or writes P [1] := v1 before (K). (M) r2 reads P [1] = v2 or writes P [1] := v2 before (J). (N) In the diagram, we have assumed (L) &lt; (M). <p> Observe that process p takes a step ((O)) between two steps of process q ((Q) and (P)). Therefore, priority (p) priority (q). If priority (p) &gt; priority (q), then p completes execution before q resumes, which contradicts P <ref> [2] </ref> = ? at (J). Thus, priority (p) = priority (q). <p> w := P [i]; 4: if w 6= ? then 5: v := w else 6: P [i] := v od; 7: return P [3] s1 r1 p P [3]:=v2P <ref> [2] </ref>=v2 A B E G P [2]:=v2 P [2]:=v1 K P [1]=v2 N Q P P [1]:=v1 P [1]= P [2]= completion before (M), contradicting P [2] = ? at (J). Also, if priority (q) = priority (r2), then q would run to completion before (H), contradicting P [3] = ? at (C). <p> w 6= ? then 5: v := w else 6: P [i] := v od; 7: return P [3] s1 r1 p P [3]:=v2P <ref> [2] </ref>=v2 A B E G P [2]:=v2 P [2]:=v1 K P [1]=v2 N Q P P [1]:=v1 P [1]= P [2]= completion before (M), contradicting P [2] = ? at (J). Also, if priority (q) = priority (r2), then q would run to completion before (H), contradicting P [3] = ? at (C). To see this, observe that q has already been preempted once by a process of the same priority (namely p) before (P). <p> In the statement of this lemma, we consider a process to access a level iff it successfully acquires a port for that level. A proof of this lemma is given in <ref> [2] </ref>. <p> Due to space limitations, we only sketch the main ideas of the C = P proof here. The complete proof can be found in <ref> [2] </ref>. We restrict attention to systems with schedulers that are purely quantum-based, i.e., we assume there is only one priority level per processor. Clearly, lower bounds for such a system will apply to a system with multiple priority levels as well.
Reference: [3] <author> M. Fischer, N. Lynch, and M. Patterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: By replacing the for loop by straight-line code, it can be seen that Q = 8 suffices. The algorithm employs three shared variables, P [1], P [2], and P <ref> [3] </ref>. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. <p> The algorithm employs three shared variables, P [1], P [2], and P <ref> [3] </ref>. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. Lemma 1: In the consensus algorithm in Fig. 3, each process returns the same value. 2 Proof : Suppose towards a contradiction that two processes return different values v1 and v2. <p> The algorithm employs three shared variables, P [1], P [2], and P <ref> [3] </ref>. The idea behind the algorithm is to attempt to copy a value from P [1] to P [2], and then from P [2] to P [3]. Each process returns the value in P [3]. Correctness follows from the following lemma. Lemma 1: In the consensus algorithm in Fig. 3, each process returns the same value. 2 Proof : Suppose towards a contradiction that two processes return different values v1 and v2. Then, some process s1 must write v1 to P [3] and some process <p> value in P <ref> [3] </ref>. Correctness follows from the following lemma. Lemma 1: In the consensus algorithm in Fig. 3, each process returns the same value. 2 Proof : Suppose towards a contradiction that two processes return different values v1 and v2. Then, some process s1 must write v1 to P [3] and some process s2 must write v2 to P [3]. Fig. 4 depicts what a history leading to such a situation must look like. Specifically, we have the following: (A) s1 reads P [3] = ? and then (B) writes P [3] := v1 and (C) s2 reads P [3] <p> Then, some process s1 must write v1 to P <ref> [3] </ref> and some process s2 must write v2 to P [3]. Fig. 4 depicts what a history leading to such a situation must look like. Specifically, we have the following: (A) s1 reads P [3] = ? and then (B) writes P [3] := v1 and (C) s2 reads P [3] = ? and then (D) writes P [3] := v2. <p> Then, some process s1 must write v1 to P <ref> [3] </ref> and some process s2 must write v2 to P [3]. Fig. 4 depicts what a history leading to such a situation must look like. Specifically, we have the following: (A) s1 reads P [3] = ? and then (B) writes P [3] := v1 and (C) s2 reads P [3] = ? and then (D) writes P [3] := v2. <p> some process s1 must write v1 to P <ref> [3] </ref> and some process s2 must write v2 to P [3]. Fig. 4 depicts what a history leading to such a situation must look like. Specifically, we have the following: (A) s1 reads P [3] = ? and then (B) writes P [3] := v1 and (C) s2 reads P [3] = ? and then (D) writes P [3] := v2. <p> <ref> [3] </ref> and some process s2 must write v2 to P [3]. Fig. 4 depicts what a history leading to such a situation must look like. Specifically, we have the following: (A) s1 reads P [3] = ? and then (B) writes P [3] := v1 and (C) s2 reads P [3] = ? and then (D) writes P [3] := v2. <p> to P <ref> [3] </ref>. Fig. 4 depicts what a history leading to such a situation must look like. Specifically, we have the following: (A) s1 reads P [3] = ? and then (B) writes P [3] := v1 and (C) s2 reads P [3] = ? and then (D) writes P [3] := v2. <p> If priority (p) &gt; priority (q), then p completes execution before q resumes, which contradicts P [2] = ? at (J). Thus, priority (p) = priority (q). Similarly, priority (r1) = priority (r2). (Note that (J) &lt; (H) &lt; (I) and that if r1 completed execution before (I), P <ref> [3] </ref> 6= ? would hold at (C).) If priority (q) &gt; priority (r2), then q would run to shared variable P : array [1::3] of valtype [ ? initially ? procedure decide (val: valtype) returns valtype private variable v; w: valtype 1: v := val ; 3: w := P [i]; <p> : array [1::3] of valtype [ ? initially ? procedure decide (val: valtype) returns valtype private variable v; w: valtype 1: v := val ; 3: w := P [i]; 4: if w 6= ? then 5: v := w else 6: P [i] := v od; 7: return P <ref> [3] </ref> s1 r1 p P [3]:=v2P [2]=v2 A B E G P [2]:=v2 P [2]:=v1 K P [1]=v2 N Q P P [1]:=v1 P [1]= P [2]= completion before (M), contradicting P [2] = ? at (J). <p> P <ref> [3] </ref>:=v2P [2]=v2 A B E G P [2]:=v2 P [2]:=v1 K P [1]=v2 N Q P P [1]:=v1 P [1]= P [2]= completion before (M), contradicting P [2] = ? at (J). Also, if priority (q) = priority (r2), then q would run to completion before (H), contradicting P [3] = ? at (C). To see this, observe that q has already been preempted once by a process of the same priority (namely p) before (P). Therefore, q runs to completion before any other process of the same priority runs again. <p> Therefore, q runs to completion before any other process of the same priority runs again. However, because process r1 executes a statement at (H) and because priority (r1) = priority (r2), this contradicts P <ref> [3] </ref> = ? at (C). Therefore, priority (q) &lt; priority (r2), which implies that priority (q) &lt; priority (r1) (recall that priority (r1) = priority (r2)). But q executed a statement ((P)) between two statement executions of r1 ((L) and (H)). <p> Assume, to the contrary, that A is correct in such a system. We show that this assumption leads to a contradiction. Our proof is based on a valency argument <ref> [3, 4] </ref>, and we assume that the reader is familiar with the general structure of such an argument. <p> In particular, we assume that the reader knows what it means for a state of A to be bi-valent, uni-valent , or x-valent , where x is the input value of some process <ref> [3, 4] </ref>. We derive a contradiction by showing that there exists a history of A consisting of an infinite sequence of bi-valent states, contradicting the fact that A is wait-free. The proof is similar to other valency arguments presented elsewhere [3, 4], with two important exceptions. <p> , where x is the input value of some process <ref> [3, 4] </ref>. We derive a contradiction by showing that there exists a history of A consisting of an infinite sequence of bi-valent states, contradicting the fact that A is wait-free. The proof is similar to other valency arguments presented elsewhere [3, 4], with two important exceptions. First, we must carefully keep track of when a given process may be preempted. Second, we define the valency of a state with respect to the set of currently-running processes at that state.
Reference: [4] <author> M. Herlihy. </author> <title> Wait-free synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 124-149, </pages> <year> 1991. </year>
Reference-contexts: In a priority-scheduled system, each scheduler always selects for execution the highest-priority process that is available for execution on its processor. Ramamurthy et al. showed that, for priority-based systems, any object with consensus number C P in Herlihy's wait-free hierarchy <ref> [4] </ref> is universal for any number of processes executing on P processors, i.e., universality is a function of the number of processors in the system, not the number of processes. In subsequent work, Anderson, Jain, and Ott considered multiprogrammed systems in which quantum-based scheduling is used [1]. <p> In this table, T is a constant denoting the maximum time required to perform any atomic operation, Q is the length of the scheduling quantum, and c is a constant that follows from the algorithms we present. Obviously, if C &lt; P , then universal algorithms are impossible <ref> [4] </ref>. If P C 2P , then an object with consensus number C is universal if Q is a value proportional to (2P +1 C)T . If C = 1, then Q (obviously) can be any value [4]. <p> Obviously, if C &lt; P , then universal algorithms are impossible <ref> [4] </ref>. If P C 2P , then an object with consensus number C is universal if Q is a value proportional to (2P +1 C)T . If C = 1, then Q (obviously) can be any value [4]. To see the difference between a priority-based and a quantum-based system, consider Fig. 1. <p> Assume, to the contrary, that A is correct in such a system. We show that this assumption leads to a contradiction. Our proof is based on a valency argument <ref> [3, 4] </ref>, and we assume that the reader is familiar with the general structure of such an argument. <p> In particular, we assume that the reader knows what it means for a state of A to be bi-valent, uni-valent , or x-valent , where x is the input value of some process <ref> [3, 4] </ref>. We derive a contradiction by showing that there exists a history of A consisting of an infinite sequence of bi-valent states, contradicting the fact that A is wait-free. The proof is similar to other valency arguments presented elsewhere [3, 4], with two important exceptions. <p> , where x is the input value of some process <ref> [3, 4] </ref>. We derive a contradiction by showing that there exists a history of A consisting of an infinite sequence of bi-valent states, contradicting the fact that A is wait-free. The proof is similar to other valency arguments presented elsewhere [3, 4], with two important exceptions. First, we must carefully keep track of when a given process may be preempted. Second, we define the valency of a state with respect to the set of currently-running processes at that state.
Reference: [5] <author> S. Ramamurthy, M. Moir, and J. Anderson. </author> <title> Real-time object sharing with minimal support. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 233-242. </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Sloan Research Fellowship. y Work supported in part by an NSF CAREER Award, grant number CCR 9702767. processor are scheduled by priority <ref> [5] </ref>. In a priority-scheduled system, each scheduler always selects for execution the highest-priority process that is available for execution on its processor. <p> This is because q has higher priority and will not relinquish the processor until it completes. Thus, operations of higher-priority processes "automatically" appear to be atomic to lower priority processes executing on the same processor. This is the fundamental insight behind the results of Rama-murthy et al. <ref> [5] </ref>. In contrast, in a quantum-based system, if a process is ever preempted while accessing some object, then there are no guarantees that the process preempting it will complete any pending object invocation before relinquishing the processor.
References-found: 5

