URL: http://www.cs.msu.edu/~huangyih/Publications/SC95_Marray.ps
Refering-URL: http://www.cs.msu.edu/~huangyih/Publications/index.html
Root-URL: http://www.cs.msu.edu
Email: fhuangyih,huangch,mckinleyg@cps.msu.edu  
Title: Multicast Virtual Topologies for Collective Communication in MPCs and ATM Clusters  
Author: Y. Huang, C. C. Huang, and P. K. McKinley 
Note: This work was supported in part by DOE grant DE-FG02-93ER25167,and by NSF grants MIP-9204066, CDA-9222901, and CCR-9503838.  
Address: East Lansing, Michigan 48824  
Affiliation: Department of Computer Science Michigan State University  
Abstract: This paper defines and describes the properties of a multicast virtual topology, the M-array, and a resource-efficient variation, the REM-array. It is shown how several collective operations can be implemented efficiently using these virtual topologies, while maintaining low complexity. Because the methods are applicable to any parallel computing environment that supports multicast communication in hardware, they provide a framework for collective communication libraries that are portable and yet take advantage of such low-level hardware functionality. In particular, the paper describes the practical issues of using these methods in wormhole-routed massively parallel computers (MPCs) and in workstation clusters connected by Asynchronous Transfer Mode (ATM) networks. Performance results are given for both environments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. J. Dally and C. L. Seitz, </author> <title> "The torus routing chip," </title> <journal> Journal of Distributed Computing, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 187-196, </pages> <year> 1986. </year>
Reference-contexts: Commercial massively parallel computers (MPCs) include both message passing systems, such as the Intel Paragon and TMC CM-5, as well as systems that support distributed shared memory, such as the Cray T3D. Many such systems use a cut-through switching technique, wormhole-routing <ref> [1] </ref>, in which data is pipelined through routers in the network. An alternative platform for parallel scientific computing is the cluster [2], in which collections of off-the-shelf systems are connected to form a parallel computer. <p> The increasing interest in collective operations is evidenced by their inclusion in the Message Passing Interface (MPI) standard [7], and by their use in a wide variety of parallel algorithms [8]. 3 2.2 Hardware Multicast in MPCs In wormhole routing <ref> [1] </ref>, each message is divided into small pieces called flits that are pipelined through the network by way of routers at each node.
Reference: [2] <author> H. T. Kung, R. Sansom, S. Schlick, P. Steenkiste, M. Arnould, F. J. Bitz, F. Christianson, E. C. Cooper, O. Menzilcioglu, D. Ombres, and B. Zill, </author> <title> "Network-based multicomputers: An emerging parallel architecture," </title> <booktitle> in Proceedings of Supercomputing'91, </booktitle> <pages> pp. 664-673, </pages> <publisher> IEEE CS Press, </publisher> <year> 1991. </year>
Reference-contexts: Many such systems use a cut-through switching technique, wormhole-routing [1], in which data is pipelined through routers in the network. An alternative platform for parallel scientific computing is the cluster <ref> [2] </ref>, in which collections of off-the-shelf systems are connected to form a parallel computer. Many clusters are connected by high-speed switches, which provide large aggregate capacity compared to shared media.
Reference: [3] <author> P. K. McKinley, H. Xu, A.-H. Esfahanian, and L. M. Ni, </author> <title> "Unicast-Based Multicast Communication in Wormhole-Routed Direct Networks," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 5, </volume> <pages> pp. 1254-1265, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Our research addresses the design of collective communication operations for parallel and distributed computing. Approaches to this problem range from the implementation of special-purpose hardware for individual collective operations, to the use of so-called unicast-based collective algorithms <ref> [3] </ref>, which are implemented purely in software atop send and receive primitives.
Reference: [4] <author> NCUBE Company, </author> <title> NCUBE 6400 Processor Manual, </title> <year> 1990. </year>
Reference-contexts: A special case of multicast is broadcast, in which the destination set contains every node in the network. Several parallel processing platforms already support multicast in hardware. Examples include both wormhole-routed MPCs, such as the nCUBE-2 <ref> [4] </ref> and CM-5 [5], and switch-based LANs, such as the Fore 2 Systems ASX100 ATM switch [6], which can be used to interconnect workstation clusters. For such parallel computing environments, collections of nodes that communicate across hardware-supported multicast channels can be viewed logically as a directed hypergraph.
Reference: [5] <author> C. E. Leiserson, et al., </author> <title> "The network architecture of the connection machine CM-5," </title> <booktitle> in Proc. 4th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 272-285, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: A special case of multicast is broadcast, in which the destination set contains every node in the network. Several parallel processing platforms already support multicast in hardware. Examples include both wormhole-routed MPCs, such as the nCUBE-2 [4] and CM-5 <ref> [5] </ref>, and switch-based LANs, such as the Fore 2 Systems ASX100 ATM switch [6], which can be used to interconnect workstation clusters. For such parallel computing environments, collections of nodes that communicate across hardware-supported multicast channels can be viewed logically as a directed hypergraph.
Reference: [6] <author> Fore Systems Inc., </author> <title> 1000 Gamma Drive, Pittsburgh, PA 15238, ForeRunner ASX-100 ATM Switch Architecture Manual, </title> <year> 1992. </year>
Reference-contexts: Several parallel processing platforms already support multicast in hardware. Examples include both wormhole-routed MPCs, such as the nCUBE-2 [4] and CM-5 [5], and switch-based LANs, such as the Fore 2 Systems ASX100 ATM switch <ref> [6] </ref>, which can be used to interconnect workstation clusters. For such parallel computing environments, collections of nodes that communicate across hardware-supported multicast channels can be viewed logically as a directed hypergraph.
Reference: [7] <author> Message Passing Interface Forum, </author> <title> "Document for standard message-passing interface," </title> <type> Tech. Rep. </type> <institution> CS-93-214, University of Tennessee, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Collective operations may be used for process control, data movement, or global operations within the process group. The increasing interest in collective operations is evidenced by their inclusion in the Message Passing Interface (MPI) standard <ref> [7] </ref>, and by their use in a wide variety of parallel algorithms [8]. 3 2.2 Hardware Multicast in MPCs In wormhole routing [1], each message is divided into small pieces called flits that are pipelined through the network by way of routers at each node.
Reference: [8] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis, </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> Redwood City, California: Benjamin/Cummings, </address> <year> 1994. </year>
Reference-contexts: Collective operations may be used for process control, data movement, or global operations within the process group. The increasing interest in collective operations is evidenced by their inclusion in the Message Passing Interface (MPI) standard [7], and by their use in a wide variety of parallel algorithms <ref> [8] </ref>. 3 2.2 Hardware Multicast in MPCs In wormhole routing [1], each message is divided into small pieces called flits that are pipelined through the network by way of routers at each node.
Reference: [9] <author> L. M. Ni and P. K. McKinley, </author> <title> "A survey of wormhole routing techniques in direct networks," </title> <journal> IEEE Computer, </journal> <volume> vol. 26, </volume> <pages> pp. 62-76, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: Compared to the store-and-forward switching method that was used in early multicomputers, the pipelining operation of wormhole routing often reduces the effect of path length on communication latency. As a result, wormhole routing has been adopted in many MPC systems <ref> [9] </ref>. Figure 1 (a) shows a node/router pair in a 2D mesh. Each router is connected to its local processor/memory by internal channels, or ports. One method that has been proposed to support multicast in wormhole-routed systems is intermediate reception (IR).
Reference: [10] <author> X. Lin and L. M. Ni, </author> <title> "Deadlock-free multicast wormhole routing in multicomputer networks," </title> <booktitle> in Proceedings of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 116-125, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Although IR requires a relatively minor modification to existing MPC routers, it can be used to deliver a message to multiple destinations in nearly the same time that is needed to send a message to a single destination. Such communication methods are termed path-based <ref> [10, 11] </ref>, while the constituent messages are called multi-destination worms [12]. An important issue in wormhole-routed systems is the avoidance of deadlock among messages, which is typically handled in the routing algorithm. <p> An important issue in wormhole-routed systems is the avoidance of deadlock among messages, which is typically handled in the routing algorithm. One approach to deadlock-free, path-based routing is to base routing decisions on an ordering imposed by a Hamiltonian Path (HP) in the network. Lin, et al. <ref> [10, 11] </ref> used the HP approach to develop a family of path-based multicast routing algorithms for mesh and hypercube networks. <p> All-to-all broadcast can be implemented in log N communication steps by carrying out an N/N global reduction with "message concatenation" as the operator. 5 Application to Wormhole-Routed Net works The availability of intermediate reception allows a wormhole-routed network to be used as a multicast topology. In a path-based approach <ref> [10, 11] </ref>, the intermediate nodes of a multi-destination message lie on the path (defined by the underlying routing algorithm) towards the last destination. 5.1 M-array mappings In a wormhole-routed 2D mesh with intermediate reception, the M-array approach may be applied in different ways.
Reference: [11] <author> X. Lin, P. K. McKinley, and L. M. Ni, </author> <title> "Deadlock-free multicast wormhole routing in 2D mesh multicomputers," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 5, </volume> <pages> pp. 793-804, </pages> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: Although IR requires a relatively minor modification to existing MPC routers, it can be used to deliver a message to multiple destinations in nearly the same time that is needed to send a message to a single destination. Such communication methods are termed path-based <ref> [10, 11] </ref>, while the constituent messages are called multi-destination worms [12]. An important issue in wormhole-routed systems is the avoidance of deadlock among messages, which is typically handled in the routing algorithm. <p> An important issue in wormhole-routed systems is the avoidance of deadlock among messages, which is typically handled in the routing algorithm. One approach to deadlock-free, path-based routing is to base routing decisions on an ordering imposed by a Hamiltonian Path (HP) in the network. Lin, et al. <ref> [10, 11] </ref> used the HP approach to develop a family of path-based multicast routing algorithms for mesh and hypercube networks. <p> All-to-all broadcast can be implemented in log N communication steps by carrying out an N/N global reduction with "message concatenation" as the operator. 5 Application to Wormhole-Routed Net works The availability of intermediate reception allows a wormhole-routed network to be used as a multicast topology. In a path-based approach <ref> [10, 11] </ref>, the intermediate nodes of a multi-destination message lie on the path (defined by the underlying routing algorithm) towards the last destination. 5.1 M-array mappings In a wormhole-routed 2D mesh with intermediate reception, the M-array approach may be applied in different ways. <p> If the underlying routing is based on a Hamiltonian path <ref> [11] </ref> (see Figure 1 (c)), then that path defines a total ordering on the N nodes, and the nodes in the mesh can be considered as an M-array of length N . Figure 5 illustrates this mapping in a 4 fi 4 mesh.
Reference: [12] <author> D. K. Panda, S. Singal, and P. Prabhakaran, </author> <title> "Multidestination message passing mechanism conforming to base wormhole routing scheme," </title> <booktitle> in Proceedings of the First International Parallel Computer Routing and Communication Workshop, </booktitle> <address> (Seattle, Washington), </address> <pages> pp. 131-145, </pages> <publisher> Springer-Verlag, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: Such communication methods are termed path-based [10, 11], while the constituent messages are called multi-destination worms <ref> [12] </ref>. An important issue in wormhole-routed systems is the avoidance of deadlock among messages, which is typically handled in the routing algorithm. One approach to deadlock-free, path-based routing is to base routing decisions on an ordering imposed by a Hamiltonian Path (HP) in the network. <p> The use of multi destination worms for various "base routing" schemes, such as dimension-ordered routing and adaptive routing, is described in <ref> [12] </ref>. 11 Definition 4 An M-mesh topology is a 2D grid in which M-arrays are constructed along every row and every column. Due to space limitations, descriptions of M-mesh algorithms are omitted in this paper, but may be found in [17].
Reference: [13] <author> C. C. Huang and P. K. McKinley, </author> <title> "Communication issues in parallel computing across ATM networks," </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> vol. 2, no. 4, </volume> <pages> pp. 73-86, </pages> <year> 1994. </year> <month> 21 </month>
Reference-contexts: The increasing popularity of ATM LANs has led to their use in cluster-based parallel computing <ref> [13, 14, 15] </ref>. Some ATM LANs support hardware multicast. For example, the Fore Systems ASX100 ATM switch [16] allows attached workstations to communicate across multicast virtual channels. Figure 2 (a) shows the configuration of an ATM cluster testbed, which we have constructed using 5 three such switches. <p> While many shared-media LANs also support multicasting, a switched environment with this capability permits multiple multicasts to be transmitted concurrently across the network, a feature that can be useful in many collective operations <ref> [13] </ref>. 3 The M-Array and REM-Array Virtual Topologies If certain patterns of communication are known in advance and used repeatedly over the lifetime of the application, performance may be improved by establishing a virtual topology when the application begins execution. <p> be particularly useful 14 (a) DELTA parameters (b) J-Machine parameters in large systems, where the M-array scheme can suffer due to long path lengths. 15 6 Application to ATM-Based Clusters Our experience has shown that the cost of establishing ATM virtual channels can be very high relative to transmission time <ref> [13, 20] </ref>. Therefore, the M-array, which supports many collective operations with a single multicast virtual topology, is particularly well-suited for ATM LAN environments. <p> The study of distributed parallel computing across ATM networks is growing rapidly, and efficient communication is a key issue <ref> [13, 14, 15] </ref>. Perhaps the work most closely related to multicast virtual topologies is the study of reconfigurable meshes [22]. In such studies, buses connecting nodes in processor arrays are assumed to be separable and are used as (dynamic) multicast media.
Reference: [14] <author> M. Lin, J. Hsieh, D. H. C. Du, J. P. Thomas, and J. A. MacDonald, </author> <title> "Distributed network computing over local ATM networks," </title> <journal> IEEE Journal of Selected Areas in Communications, </journal> <volume> vol. 13, </volume> <pages> pp. 733-748, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: The increasing popularity of ATM LANs has led to their use in cluster-based parallel computing <ref> [13, 14, 15] </ref>. Some ATM LANs support hardware multicast. For example, the Fore Systems ASX100 ATM switch [16] allows attached workstations to communicate across multicast virtual channels. Figure 2 (a) shows the configuration of an ATM cluster testbed, which we have constructed using 5 three such switches. <p> The study of distributed parallel computing across ATM networks is growing rapidly, and efficient communication is a key issue <ref> [13, 14, 15] </ref>. Perhaps the work most closely related to multicast virtual topologies is the study of reconfigurable meshes [22]. In such studies, buses connecting nodes in processor arrays are assumed to be separable and are used as (dynamic) multicast media.
Reference: [15] <author> T. von Eicken, V. Avula, A. Basu, and V. </author> <title> Buch, "Low-latency communication over ATM networks using active messages," in Proceedings of Hot Interconnects II, </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> Calif., </address> <month> Aug. </month> <year> 1994. </year> <note> Also appears in IEEE Micro, </note> <month> February </month> <year> 1995. </year>
Reference-contexts: The increasing popularity of ATM LANs has led to their use in cluster-based parallel computing <ref> [13, 14, 15] </ref>. Some ATM LANs support hardware multicast. For example, the Fore Systems ASX100 ATM switch [16] allows attached workstations to communicate across multicast virtual channels. Figure 2 (a) shows the configuration of an ATM cluster testbed, which we have constructed using 5 three such switches. <p> The study of distributed parallel computing across ATM networks is growing rapidly, and efficient communication is a key issue <ref> [13, 14, 15] </ref>. Perhaps the work most closely related to multicast virtual topologies is the study of reconfigurable meshes [22]. In such studies, buses connecting nodes in processor arrays are assumed to be separable and are used as (dynamic) multicast media.
Reference: [16] <author> E. Biagioni and E. C. R. Sansom, </author> <title> "Designing a practical ATM LAN," </title> <journal> IEEE Network, </journal> <pages> pp. 32-39, </pages> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: The increasing popularity of ATM LANs has led to their use in cluster-based parallel computing [13, 14, 15]. Some ATM LANs support hardware multicast. For example, the Fore Systems ASX100 ATM switch <ref> [16] </ref> allows attached workstations to communicate across multicast virtual channels. Figure 2 (a) shows the configuration of an ATM cluster testbed, which we have constructed using 5 three such switches. Each workstation is connected through fiber optic links to one of the switches.
Reference: [17] <author> Y. Huang and P. K. McKinley, </author> <title> "Multicast virtual topologies for efficient collective communication," </title> <type> Tech. Rep. </type> <institution> MSU-CPS-94-47, Department of Computer Science, Michigan State University, East Lansing, Michigan, </institution> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: In this section, we define two multicast virtual topologies. Both 6 topologies are linear in the sense that they are based on a total ordering of nodes. Several properties of the topologies are stated. Due to space limitations, we omit formal proofs; these may be found in <ref> [17] </ref>. Definition 1 A multicast-based array (M-array) of length N = 2 n is recursively defined as follows: 1. A single node is an M-array of length 2 0 . 2. <p> ATM networks with large process groups, where it is desirable to reduce the density of the topology. 8 4 Collective Communication Algorithms on M-Arrays In this section, we show that a broad range of collective operations can be executed efficiently on the M-array; algorithms for the REM-array are described in <ref> [17] </ref>. All these algorithms are designed to execute such that, within every communication step, all involved channels are at the same level. Such algorithms are called normal. Normal algorithms minimize contention for ports and channels during execution. <p> An example on a 16-node M-array is shown below, where the source is node 1010; the formal algorithm is straightforward <ref> [17] </ref>. Example 1 Broadcast from node 1010 in a 16-node M-array. As with a unicast-based binomial tree algorithm, this broadcast algorithm requires log N steps to reach all destinations. <p> Due to space limitations, descriptions of M-mesh algorithms are omitted in this paper, but may be found in <ref> [17] </ref>. Table 1 presents analytical results for collective operations implemented in three different virtual topologies: the M-Array, the M-Mesh, and a unicast-based spanning binomial tree. <p> Summary of performances transmission time, M the message length in all-to-all broadcast, and N the total number of nodes. The tree-based reduction and all-to-all broadcast operations use a spanning binomial tree in each row and column (see Figure 7). Details can be found in <ref> [17] </ref>. <p> Therefore, the M-array, which supports many collective operations with a single multicast virtual topology, is particularly well-suited for ATM LAN environments. Also, since the operations are based on disjoint sets of destinations, the probability of message contention is reduced compared to other implementations (even more so using an REM-array <ref> [17] </ref>). In this section, we briefly describe an implementation of the M-array on the ATM testbed in our laboratory. 6.1 ATM multicast channels In our testbed, user-level processes executing on workstations may access the ATM network in one of two ways. <p> In our environment, the M-array implementation benefits from the lack of message contention within the bus-based switch fabric. It is worth noting, however, that the M-array can be mapped onto other switch fabrics, such as the Butterfly and the Omega, without contention among channels; details are given in <ref> [17] </ref>. 7 Related Work The subject of collective communication in wormhole-routed networks has been extensively studied in that last several years, and the contributions are too numerous to list here; a survey can be found in [21].
Reference: [18] <author> P. K. McKinley and C. Trefftz, "MultiSim: </author> <title> A tool for the study of large-scale multiprocessors," </title> <booktitle> in Proc. 1993 International Workshop on Modeling, Analysis and Simulation of Computer and Telecommunication Networks (MASCOTS), </booktitle> <pages> pp. 57-62, </pages> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: A simulation study was conducted, using a simulation tool called MultiSim <ref> [18] </ref>, which we developed for the study of large-scale multiprocessors. MultiSim is based on an event-driven simulation package, CSIM [19].
Reference: [19] <author> H. D. Schwetman, "Csim: </author> <title> A C-based, process-oriented simulation language," </title> <type> Tech. Rep. </type> <institution> PP-080-85, Microelectronics and Computer Technology Corporation, </institution> <year> 1985. </year>
Reference-contexts: A simulation study was conducted, using a simulation tool called MultiSim [18], which we developed for the study of large-scale multiprocessors. MultiSim is based on an event-driven simulation package, CSIM <ref> [19] </ref>. Using MultiSim, we compared the three reduction algorithms using parameters reported for two different wormhole-routed systems, the Intel Touchstone DELTA and the MIT J-Machine; the relevant parameters are summarized in Table 2. In all our comparisons, we assume that the physical topology is a 2D mesh.
Reference: [20] <author> C. Huang, Y. Huang, and P. K. McKinley, </author> <title> "A thread-based interface for collective communication on ATM networks," </title> <booktitle> in Proceedings of the 15th IEEE International Conference on Distributed Computing Systems, </booktitle> <address> (Vancouver, British Columbia), </address> <pages> pp. 254-261, </pages> <year> 1995. </year>
Reference-contexts: be particularly useful 14 (a) DELTA parameters (b) J-Machine parameters in large systems, where the M-array scheme can suffer due to long path lengths. 15 6 Application to ATM-Based Clusters Our experience has shown that the cost of establishing ATM virtual channels can be very high relative to transmission time <ref> [13, 20] </ref>. Therefore, the M-array, which supports many collective operations with a single multicast virtual topology, is particularly well-suited for ATM LAN environments. <p> However, the ATM connections do not provide either reliability or even flow control, which must be built to our own interface software. Our present implementations of reliable ATM multicast channels and other collective operations execute as a user-level library based on concurrent threads <ref> [20] </ref>. The threads share a common address space and synchronize with one another using semaphores and mutual-exclusive locks provided in the SunOS 5.3 Threads library. with a multicast channel from one process to seven destination processes. <p> Multiple reliable multicast channels, each as described above, are established to form the M-array topology. Independent thread sets are used to manage each channel. Here, we discuss only all-to-all broadcast; results for other collective operations can be found in <ref> [20] </ref>. We conducted a series of tests with different group sizes and message lengths in order to evaluate the performance of our ATM implementations of collective operations.
Reference: [21] <author> P. K. McKinley, Y.-J. Tsai, and D. Robinson, </author> <title> "Collective communication in wormhole-routed massively parallel computers." </title> <journal> IEEE Computer, </journal> <note> accepted to appear. </note>
Reference-contexts: as the Butterfly and the Omega, without contention among channels; details are given in [17]. 7 Related Work The subject of collective communication in wormhole-routed networks has been extensively studied in that last several years, and the contributions are too numerous to list here; a survey can be found in <ref> [21] </ref>. The study of distributed parallel computing across ATM networks is growing rapidly, and efficient communication is a key issue [13, 14, 15]. Perhaps the work most closely related to multicast virtual topologies is the study of reconfigurable meshes [22].

References-found: 21

