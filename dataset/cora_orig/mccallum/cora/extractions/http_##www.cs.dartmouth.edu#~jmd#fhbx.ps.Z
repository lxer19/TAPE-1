URL: http://www.cs.dartmouth.edu/~jmd/fhbx.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~jmd/decs/DECSpage.html
Root-URL: http://www.cs.dartmouth.edu
Email: fjmd,zhangq,gesselg@cs.dartmouth.edu  
Phone: fax: (603) 646-1672  
Title: Fast Higher Bandwidth X  
Author: John M. Danskin Qin Zhang D. M. Abrahams-Gessel 
Address: 6211 Sudikoff Laboratory Hanover, NH 03755 USA  
Affiliation: Dartmouth College  
Abstract: This paper proposes an X Window System protocol compression scheme called Fast Higher Bandwidth X (FHBX). Previous X protocol compression schemes were either much slower (Higher Bandwidth X) or much less effective (Xremote). By using an application specific predictive hashing technique, FHBX is able to deliver three times the compression performance of Xremote, while running ten times as fast as HBX. The family of structured compression techniques illustrated by FHBX is applicable to other structured protocols, and should enable a host of interactive applications on low bandwidth wireless devices and telephone links. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bell, Timothy C., John G. Cleary, and Ian H. Witten, </author> <title> "Text Compression," </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990 </year>
Reference-contexts: The arithmetic decoder in the receiver decodes the bits using its identical table of probabilities as an inverse map. By using arithmetic coding, bits are shared between adjacent fields, which means that individual fields can be expressed in fractional bits. For more about arithmetic coding see <ref> [1] </ref>. To the extent that the model's probability estimates are accurate and fully express all available knowledge, this arithmetic coding procedure is optimal. <p> If a value is not found in the short list, an escape code is transmitted, and the value is transmitted using an efficient integer coding scheme similar to those described in <ref> [1] </ref>. each of the first few list indices is typically less than half of its predecessor, with index 1 being sent 60% or more of the time. The usage distribution of larger indices (5-8) is approximately equal (each less than 2% of the time).
Reference: [2] <author> J. Bentley, D. Sleator, R. Tarjan and V. Wei, </author> <title> "A Locally Adaptive Data Compression Scheme," </title> <journal> Communication of ACM, </journal> <volume> 29, </volume> <pages> pp. 320-330, </pages> <year> 1986. </year>
Reference-contexts: In hash based prediction we use context to select a move-to-front list. * HBX uses arithmetic coding to encode a value appearing in a histogram optimally. Hash based prediction uses a move-to-front list to encode val ues appearing in the list nearly optimally <ref> [2] </ref>. Hash based prediction is fully as expressive as statistical modeling: the contexts used to select move-to-front lists can be arbitrary (as required by HBX), and there is no barrier to preconditioning the input, or to compressing fields of varying size and type. <p> Because we use fewer bits to code elements near the front of the list, our goal is to put the most frequently accessed values into the list and push them toward the front of the list. Bentley et al. discussed a similar problem in <ref> [2] </ref>. They use a move-to-front heuristic. Each time a value is referenced, it is moved to the front of the list. If a character has been recently used, it will be near the front of the list and therefore have a short encoding.
Reference: [3] <author> Burrows, Michael, et al, </author> <title> "On-line Data Compression in a Log-structured File System," </title> <booktitle> the Proceedings of the Fifth International Conference on Architechu-ral Support for Programming Languages and Operating Systems(ASPLOS-V), </booktitle> <month> 12-15 October, </month> <year> 1992, </year> <note> ACM Press. </note>
Reference-contexts: What we want is an algorithm with the compression performance of HBX and the CPU performance of Xremote. Such an algorithm would dominate previous techniques for graphics protocol compression. 4 Hash Based Prediction Burrows <ref> [3] </ref> and Raita and Teuhola [11] report a hashing based text compression technique which seems to have been developed first by David Wheeler in his red and exp programs developed at AT&T Bell Labs in 1983 [3]. <p> algorithm would dominate previous techniques for graphics protocol compression. 4 Hash Based Prediction Burrows <ref> [3] </ref> and Raita and Teuhola [11] report a hashing based text compression technique which seems to have been developed first by David Wheeler in his red and exp programs developed at AT&T Bell Labs in 1983 [3]. In this technique, the last few characters of text are used as a context to generate a hash code which is used to index a hash table. Stored at each location in the hash table is a move-to-front list. <p> Furthermore, the speed of this method is such that Burrows used a variant of this technique to implement software disk compression <ref> [3] </ref>. The main drawback of hash based prediction is that while its compression performance is within a constant factor of optimal, the text compression performance of hash based prediction still falls short of the commonly used LZ algorithms.
Reference: [4] <author> Cornelius, David, "XRemote: </author> <title> a serial line protocol for X" 6th Annual X Technical Conference, </title> <address> Boston, MA, </address> <year> 1992 </year>
Reference-contexts: The Xremote protocol is described by Cornelius <ref> [4] </ref>. A follow-on protocol to Xremote, called Low Bandwidth X, has been proposed [9], and partially implemented, but work on LBX seems to have halted.
Reference: [5] <author> Danskin, John and Pat Hanrahan, </author> <title> "Compression Performance of the Xremote Protocol," 1994 Data Compression Conference. </title> <note> Full paper in Technical Report CS-TR-441-94, </note> <institution> Department of Computer Science, Princeton University, Princeton, NJ, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Both of these pipelined components work by removing repeated byte-strings from the input stream. They are very fast, and the LZ coder can be quite effective on the right kind of input <ref> [5] </ref>. Xremote achieves about server thinks the pseudo client is the client. Traffic between the pseudo server and the pseudo client is multiplexed and compressed. <p> For more details on Xremote performance see [7] or <ref> [5] </ref>. 2.2 Higher Bandwidth X (HBX) HBX's connection level architecture is illustrated in Figure 1. HBX is transparent to both clients and server; clients connect to HBX as if HBX were the X server, and HBX connects to the X server as if it were the clients.
Reference: [6] <author> Danskin, John, </author> <title> "Higher Bandwidth X," </title> <booktitle> ACM Multimedia 94, Second ACM International Conference on Multimedia. </booktitle> <address> 15-20 October 1994, San Francisco Cal-ifornia. </address> <pages> pp 89-96. </pages>
Reference-contexts: Upon receiving the bits `01' the decoder uses its identical tables and the same context to look up the value at index 2 in list 232, recovering the value `C'. than Xremote. A complete discussion of HBX can be found in [7]; shorter discussions are available in <ref> [6] </ref> and [8]. 3 The Goal In order to achieve the kind of compression HBX achieves, we need an algorithm with the expressive power of generalized statistical modeling, which is what HBX uses. Unfortunately, this modeling is expensive. <p> Mouse positions are predicted using linear extrapolation from the previous two mouse positions, and then the error is coded using a list indexed by the appropriate unique field identifier. These techniques are analogous to the techniques used for compression in HBX as discussed above and in <ref> [7, 6, 8] </ref>. The expressive power is the same, the implementation is much faster, and the compression is only slightly less effective.
Reference: [7] <author> Danskin, John, </author> <title> "Compressing The X Graphics Protocol," </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, Princeton University, Princeton, NJ. </institution> <note> Available as Princeton Technical Report CS-TR-465-94. </note>
Reference-contexts: For more details on Xremote performance see <ref> [7] </ref> or [5]. 2.2 Higher Bandwidth X (HBX) HBX's connection level architecture is illustrated in Figure 1. HBX is transparent to both clients and server; clients connect to HBX as if HBX were the X server, and HBX connects to the X server as if it were the clients. <p> Upon receiving the bits `01' the decoder uses its identical tables and the same context to look up the value at index 2 in list 232, recovering the value `C'. than Xremote. A complete discussion of HBX can be found in <ref> [7] </ref>; shorter discussions are available in [6] and [8]. 3 The Goal In order to achieve the kind of compression HBX achieves, we need an algorithm with the expressive power of generalized statistical modeling, which is what HBX uses. Unfortunately, this modeling is expensive. <p> Mouse positions are predicted using linear extrapolation from the previous two mouse positions, and then the error is coded using a list indexed by the appropriate unique field identifier. These techniques are analogous to the techniques used for compression in HBX as discussed above and in <ref> [7, 6, 8] </ref>. The expressive power is the same, the implementation is much faster, and the compression is only slightly less effective.
Reference: [8] <author> Danskin, John, </author> <title> "Previewing PostScript over a Telephone in 3 Seconds Per Page," </title> <booktitle> 9th Annual X Technical Conference, </booktitle> <month> January </month> <year> 1995, </year> <institution> O'Reilly and Associates. </institution>
Reference-contexts: Upon receiving the bits `01' the decoder uses its identical tables and the same context to look up the value at index 2 in list 232, recovering the value `C'. than Xremote. A complete discussion of HBX can be found in [7]; shorter discussions are available in [6] and <ref> [8] </ref>. 3 The Goal In order to achieve the kind of compression HBX achieves, we need an algorithm with the expressive power of generalized statistical modeling, which is what HBX uses. Unfortunately, this modeling is expensive. <p> Mouse positions are predicted using linear extrapolation from the previous two mouse positions, and then the error is coded using a list indexed by the appropriate unique field identifier. These techniques are analogous to the techniques used for compression in HBX as discussed above and in <ref> [7, 6, 8] </ref>. The expressive power is the same, the implementation is much faster, and the compression is only slightly less effective.
Reference: [9] <author> Fulton Jim, and Chris Kent Kantarjiev, </author> <title> "An update on low bandwidth X (LBX)," </title> <booktitle> Proceedings of the 7th Annual X Technical Conference, </booktitle> <month> January </month> <year> 1993, </year> <institution> O'Reilly and Associates. </institution>
Reference-contexts: The Xremote protocol is described by Cornelius [4]. A follow-on protocol to Xremote, called Low Bandwidth X, has been proposed <ref> [9] </ref>, and partially implemented, but work on LBX seems to have halted. To the extent that it conforms to the citation, LBX is very similar to Xremote: we do not expect LBX to materially outperform Xremote when and if it is completed.
Reference: [10] <author> Gettys, James, Philip L. Karlton, and Scott Mcgre-gor, </author> <title> "The X Window System, </title> <note> Version 11," Software Practice and Experience vol. 20(S2), S2/35-S2/67, </note> <month> October </month> <year> 1991 </year>
Reference-contexts: This dramatic bandwidth elimination enables applications, unloads networks, and solves a host of other problems. The X Window System <ref> [10] </ref> (X or X11) is the window system used on most UNIX based workstations today.
Reference: [11] <author> T. Raita and J. Teuhola, </author> <title> "Predictive Text Compression by Hashing," </title> <booktitle> Proceedings of the 10th Annual ACM SIGIR conference on Research and Development in Information Retrieval," </booktitle> <address> New Orleans, </address> <month> 3-5 June </month> <year> 1987, </year> <month> pp.223-233. </month>
Reference-contexts: By using hashing to index predictive move-to-front lists as in <ref> [11] </ref>, we avoid the time and space overhead associated with the histograms and arithmetic coding used in Higher Bandwidth X (HBX)[7, 8, 6]. The techniques outlined in [11] were not terribly effective at compressing English text, although they are provably within a constant factor of entropy. <p> By using hashing to index predictive move-to-front lists as in <ref> [11] </ref>, we avoid the time and space overhead associated with the histograms and arithmetic coding used in Higher Bandwidth X (HBX)[7, 8, 6]. The techniques outlined in [11] were not terribly effective at compressing English text, although they are provably within a constant factor of entropy. We will show, however, that these techniques can be extremely effective when the input is more predictable, as is the case for the X Protocol. <p> What we want is an algorithm with the compression performance of HBX and the CPU performance of Xremote. Such an algorithm would dominate previous techniques for graphics protocol compression. 4 Hash Based Prediction Burrows [3] and Raita and Teuhola <ref> [11] </ref> report a hashing based text compression technique which seems to have been developed first by David Wheeler in his red and exp programs developed at AT&T Bell Labs in 1983 [3].
Reference: [12] <author> Scheifler Robert W., </author> <title> "The X Window System Protocol," </title> <institution> M.I.T. Laboratory for Computer Science. </institution> <year> 1988. </year>
Reference: [13] <author> Thomas, S. W., J. McKie, S. Davies, K. Turkowski, J. A. Woods, and J. W. Orost. </author> <title> "Compress (version 4.0) program and documentation," </title> <note> available from joe@petsd.uucp, </note> <year> 1985. </year>
Reference-contexts: LZ78 Coder: Implements a dictionary based LZ [15, 14] coder similar to the one in the UNIX com press <ref> [13] </ref> program. Both of these pipelined components work by removing repeated byte-strings from the input stream. They are very fast, and the LZ coder can be quite effective on the right kind of input [5]. Xremote achieves about server thinks the pseudo client is the client.
Reference: [14] <author> Welch, T. A., </author> <title> "A technique for high-performance data compression," </title> <journal> IEEE Computer, </journal> <volume> 17 (6), </volume> <pages> 8-19, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: LZ78 Coder: Implements a dictionary based LZ <ref> [15, 14] </ref> coder similar to the one in the UNIX com press [13] program. Both of these pipelined components work by removing repeated byte-strings from the input stream. They are very fast, and the LZ coder can be quite effective on the right kind of input [5].
Reference: [15] <author> Ziv, J. and Lempel, A. </author> <title> "Compression of individual sequences via variable-rate coding," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> IT-24 (5), </volume> <pages> 530-536, </pages> <month> September </month> <year> 1978 </year>
Reference-contexts: LZ78 Coder: Implements a dictionary based LZ <ref> [15, 14] </ref> coder similar to the one in the UNIX com press [13] program. Both of these pipelined components work by removing repeated byte-strings from the input stream. They are very fast, and the LZ coder can be quite effective on the right kind of input [5].
References-found: 15

