URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/99,tip,cgp.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/jour.html
Root-URL: http://www.eecs.umich.edu
Title: Conjugate-Gradient Preconditioning Methods for Shift-Variant PET Image Reconstruction  
Author: Jeffrey A. Fessler and Scott D. Booth 
Keyword: Tomography, PET, Image Restoration, Edge-preserving, Circulant Matrix  
Address: Ann Arbor, MI 48109-2122  734-764-8041  
Affiliation: Dept. of Electrical Engineering and Computer Science and Dept. of Bioengineering 4240 EECS Bldg., University of Michigan,  
Note: IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. 1  
Email: Email: fessler@umich.edu,  
Phone: Voice: 734-763-1434, FAX:  
Abstract: Gradient-based iterative methods often converge slowly for tomographic image reconstruction and image restoration problems, but can be accelerated by suitable preconditioners. Diagonal precondition-ers offer some improvement in convergence rate, but do not incorporate the structure of the Hessian matrices in imaging problems. Circulant preconditioners can provide remarkable acceleration for inverse problems that are approximately shift-invariant, i.e. for those with approximately block-Toeplitz or block-circulant Hessians. However, in applications with nonuniform noise variance, such as arises from Poisson statistics in emission tomography and in quantum-limited optical imaging, the Hessian of the weighted least-squares objective function is quite shift-variant, and cir-culant preconditioners perform poorly. Additional shift-variance is caused by edge-preserving regularization methods based on nonquadratic penalty functions. This paper describes new preconditioners that approximate more accurately the Hessian matrices of shift-variant imaging problems. Compared to diagonal or circulant preconditioning, the new precondi-tioners lead to significantly faster convergence rates for the unconstrained conjugate-gradient (CG) iteration. We also propose a new efficient method for the line-search step required by CG methods. Applications to positron emission tomography (PET) illustrate the method. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Artzy, T. Elfving, and G. T. Herman, </author> <title> Quadratic optimization for image reconstruction, II, </title> <journal> Comp. Graphics and Im. Proc., </journal> <volume> vol. 11, </volume> <pages> pp. 24261, </pages> <year> 1979. </year>
Reference-contexts: precompute the 2D-DFT coefficients of K (j) in (10) for those values: k = (~j k ); k = 1; : : : ; m: We then apply interpolation to approximate the 2D-DFT's corresponding to the required values j j : 1=2 (j j (x)) k=1 1=2 where k 2 <ref> [0; 1] </ref> are the interpolation factors with P m k=1 k = 1: Since the j's are positively valued, we currently determine the k 's by using linear interpolation with a logarithmic scale for the j's: k (j) = &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; log ~j k+1
Reference: [2] <author> S. Kawata and O. Nalcioglu, </author> <title> Constrained iterative reconstruction by the conjugate gradient method, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 4, no. 2, </volume> <pages> pp. 6571, </pages> <month> June </month> <year> 1985. </year>
Reference: [3] <author> A. R. Formiconi, A. Pupi, and A. Passeri, </author> <title> Compensation of spatial system response in SPECT with conjugate gradient reconstruction technique, </title> <journal> Phys. Med. Biol., </journal> <volume> vol. 34, no. 1, </volume> <pages> pp. 6984, </pages> <year> 1989. </year>
Reference-contexts: The estimate-dependence of this preconditioner affects the conjugacy of the direction vectors, leading Lalush et al. to advocate an iteration-independent diagonal preconditioner <ref> [3, 14] </ref>. 2 We use 0 to denote matrix and vector Hermitian transpose. 2 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. lant preconditioners have also been applied to total variation methods for nonlinear image restoration [23, 24].
Reference: [4] <author> L. Kaufman, </author> <title> Maximum likelihood, least squares, and penalized least squares for PET, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 12, no. 2, </volume> <pages> pp. </pages> <address> 200214, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: tomography literature is not the usual diagonal matrix (8) formed from the Hessian, but is rather the particular estimate-dependent diagonal matrix that is implicit in the popular expectation-maximization (EM) algorithm. (For emission tomography the EM algorithm is equivalent to a gradient-ascent iteration with a certain estimate-dependent diagonal preconditioner [13].) Kaufman <ref> [4] </ref> and Mumcuoglu et al. [6] incorporated this diagonal preconditioner into conjugate-gradient algorithms.
Reference: [5] <author> K. Sauer and C. Bouman, </author> <title> A local update strategy for iterative reconstruction from projections, </title> <journal> IEEE Tr. Sig. Proc., </journal> <volume> vol. 41, no. 2, </volume> <pages> pp. 534548, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: However, the proposed methods apply generally to problems of the form (1) for which G 0 G is approximately block Toeplitz. A. The Objective Function One useful statistical criterion for estimating x from y is the following penalized weighted least-squares 3 objective function <ref> [5, 27] </ref>: (x) = 2 0 where R (x) is a penalty function that encourages smooth or piecewise-smooth estimates, and fi is a parameter that controls the tradeoff between spatial resolution and noise [30]. (Methods for choosing fi to specify a desired resolution are described in [30].) Usually, W is the <p> The log-likelihood for Poisson transmission data is non-quadratic [50], and therefore not directly of the form given in (2). A conventional approach is to make a ray-by-ray 2nd-order Taylor expansion of the log-likelihood <ref> [5, 51] </ref> 10 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. to yield a quadratic functional of the form (2). Unfortunately that approximation leads to systematic bias [51, 52]. <p> Thus FFT-based precondi-tioners are very practical and effective for tomographic imaging problems. We also compared the CG algorithm using the proposed preconditioners to the coordinate-descent algorithms of <ref> [5, 27] </ref>. As in [5], we found that coordinate-descent often converged faster than unpreconditioned CG [33]. However, we consistently found that the CG algorithm with the proposed preconditioners converged significantly faster than coordinate descent [33]. How a nonnegativity constraint would affect the results requires further evaluation. VI. <p> Thus FFT-based precondi-tioners are very practical and effective for tomographic imaging problems. We also compared the CG algorithm using the proposed preconditioners to the coordinate-descent algorithms of [5, 27]. As in <ref> [5] </ref>, we found that coordinate-descent often converged faster than unpreconditioned CG [33]. However, we consistently found that the CG algorithm with the proposed preconditioners converged significantly faster than coordinate descent [33]. How a nonnegativity constraint would affect the results requires further evaluation. VI.
Reference: [6] <author> E. U. Mumcuoglu, R. Leahy, S. R. Cherry, and Z. Zhou, </author> <title> Fast gradient-based methods for Bayesian reconstruction of transmission and emission PET images, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 13, no. 3, </volume> <pages> pp. 687701, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: usual diagonal matrix (8) formed from the Hessian, but is rather the particular estimate-dependent diagonal matrix that is implicit in the popular expectation-maximization (EM) algorithm. (For emission tomography the EM algorithm is equivalent to a gradient-ascent iteration with a certain estimate-dependent diagonal preconditioner [13].) Kaufman [4] and Mumcuoglu et al. <ref> [6] </ref> incorporated this diagonal preconditioner into conjugate-gradient algorithms. <p> Regularization methods are generally designed to ensure such positive definiteness. Since this paper focuses on comparing various pre-conditioners, for simplicity we ignore any nonnegativity constraint for x. One could extend the methods to include a nonnegativity barrier/penalty function <ref> [6, 35] </ref>, or active-set or gradient projection method [36,37]. Improvements in convergence rate due to improved precondition-ers should extend to methods that incorporate nonnegativ ity, as shown in [38]. B. <p> Conjugate-gradient methods modify the search directions to ensure that they are mutually con jugate (or approximately so for nonquadratic problems). We use the following preconditioned form of the Polak-Ribiere CG method <ref> [6, 39] </ref>: g n = r 0 (x n ) (-gradient: see (4)) p = M g (precondition) (6) fl n = &lt; 0; n = 0 hg n1 ; p n1 i d n = p n + fl n d n1 (search direction) ff n = arg min (x
Reference: [7] <author> D. S. Lalush and B. M. W. Tsui, </author> <title> A fast and stable maximum a posteriori conjugate gradient reconstruction algorithm, </title> <journal> Med. Phys., </journal> <volume> vol. 22, no. 8, </volume> <pages> pp. 127384, </pages> <month> August </month> <year> 1995. </year>
Reference: [8] <author> S. D. Booth and J. A. Fessler, </author> <title> Combined diagonal/Fourier preconditioning methods for image reconstruction in emission tomography, </title> <booktitle> in Proc. IEEE Intl. Conf. on Image Processing, </booktitle> <volume> volume 2, </volume> <pages> pp. 4414, </pages> <year> 1995. </year>
Reference-contexts: Since statistical methods for image reconstruction yield higher-quality images than FBP reconstruction but at a price of increased computation, it is important to develop methods for accelerating convergence of the iterative algorithms. This paper generalizes the quadratic method described in <ref> [8] </ref> by developing improved preconditioners that accommodate the shift-variance caused by nonuniform noise and nonquadratic penalties. Section II reviews the image reconstruction problem and the preconditioned conjugate gradient iteration. Section III summarizes the preconditioners. Section IV describes a new method for the CG line-search step. <p> Under approximation (31), one can verify that j j = fi 8j for the quadratic penalty. Thus from (17) and (11), the fol lowing preconditioner is well-suited to the quadratic objective with the modified penalty: M CDC = D 1 : (32) Based on <ref> [8] </ref>, we refer to this approach as the combined diagonal/circulant preconditioner. The seemingly minor addition to (12) of the D terms in (32) provides significant improvement in convergence rate as shown in Fig. 4 (see Section V). <p> V. NUMERICAL RESULTS To compare the convergence rates of the CG algorithm using the preconditioners described above, we have applied the algorithms to both simulated and real PET transmission scans. Results for PET emission scans were reported in <ref> [8] </ref>. We have investigated the effects of the initial image, the type of penalty, the choice of weights W ii , and several measures of convergence rates. We synopsize representative results only; complete details are given in [33].
Reference: [9] <author> A. H. Delaney and Y. Bresler, </author> <title> A fast and accurate Fourier algorithm for iterative parallel-beam tomography, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 5, no. 5, </volume> <pages> pp. 74053, </pages> <month> May </month> <year> 1996. </year>
Reference: [10] <author> J. A. Fessler and E. P. Ficaro, </author> <title> Fully 3D PET image reconstruction using a Fourier preconditioned conjugate-gradientalgorithm, </title> <booktitle> in Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> volume 3, </volume> <pages> pp. 15991602, </pages> <year> 1996. </year>
Reference-contexts: We expect these preconditioners will be particularly useful for fully 3D PET <ref> [10] </ref>. The inherent shift-variance of G 0 G for such systems will add to the challenge. For 3D SPECT reconstruction, one may be able to form suitable precon-ditioners by adapting linear methods such as in [56]. We plan to investigate such methods in the near future.
Reference: [11] <author> J. A. Fessler, </author> <title> Preconditioning methods for shift-variant image reconstruction, </title> <booktitle> in Proc. IEEE Intl. Conf. on Image Processing, </booktitle> <volume> volume 1, </volume> <pages> pp. 1858, </pages> <year> 1997. </year>
Reference: [12] <author> O. Axelsson, </author> <title> Iterative solution methods, </title> <address> Cambridge, Cambridge, </address> <year> 1994. </year>
Reference: [13] <author> L. Kaufman, </author> <title> Implementing and accelerating the EM algorithm for positron emission tomography, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 6, no. 1, </volume> <pages> pp. 37 51, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: the emission tomography literature is not the usual diagonal matrix (8) formed from the Hessian, but is rather the particular estimate-dependent diagonal matrix that is implicit in the popular expectation-maximization (EM) algorithm. (For emission tomography the EM algorithm is equivalent to a gradient-ascent iteration with a certain estimate-dependent diagonal preconditioner <ref> [13] </ref>.) Kaufman [4] and Mumcuoglu et al. [6] incorporated this diagonal preconditioner into conjugate-gradient algorithms.
Reference: [14] <author> D. Lalush and B. M. W. Tsui, </author> <title> The importance of preconditioners in fast Poisson based iterative reconstruction algorithms for SPECT, </title> <booktitle> in Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> volume 3, </volume> <pages> pp. 132630, </pages> <year> 1995. </year> <note> 12 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. </note>
Reference-contexts: The estimate-dependence of this preconditioner affects the conjugacy of the direction vectors, leading Lalush et al. to advocate an iteration-independent diagonal preconditioner <ref> [3, 14] </ref>. 2 We use 0 to denote matrix and vector Hermitian transpose. 2 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. lant preconditioners have also been applied to total variation methods for nonlinear image restoration [23, 24].
Reference: [15] <author> R. H. Chan and M. K. Ng, </author> <title> Conjugate gradient methods for Toeplitz systems, </title> <journal> SIAM Review, </journal> <volume> vol. 38, no. 3, </volume> <pages> pp. 42782, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Such circulant approximations to Toeplitz matrices have been studied extensively, e.g. <ref> [15, 22, 41] </ref>. 8 See [33] for details about computing , which consists of the 2D DFT coefficients of the column of K corresponding to the pixel at the center of the image. 9 For any p 1 fi p 2 2D image lexicographically ordered as a vector u, Qu is
Reference: [16] <author> T. F. Chan, </author> <title> An optimal circulant preconditioner for Toeplitz systems, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> vol. 9, no. 4, </volume> <pages> pp. 766771, </pages> <month> July </month> <year> 1988. </year>
Reference: [17] <author> R. H. Chan, J. G. Nagy, and R. J. Plemmons, </author> <title> FFT-based preconditioners for Toeplitz-block least-squares problems, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> vol. 30, no. 6, </volume> <pages> pp. 174068, </pages> <month> December </month> <year> 1993. </year>
Reference: [18] <author> R. H. Chan and C. K. Wong, </author> <title> Best-conditionedcirculant preconditioners, </title> <journal> Linear Algebra and its Applications, </journal> <volume> vol. 218, </volume> <pages> pp. </pages> <address> 205211, </address> <year> 1995. </year>
Reference: [19] <author> R. H. Chan, M. K. Ng, and C. K. Wong, </author> <title> Sine transform based precondi-tioners for symmetric Toeplitz systems, </title> <journal> Linear Algebra and its Applications, </journal> <volume> vol. 232, </volume> <pages> pp. 23759, </pages> <month> January </month> <year> 1996. </year>
Reference: [20] <author> N. H. Clinthorne, T. S. Pan, P. C. Chiao, W. L. Rogers, and J. A. Stamos, </author> <title> Preconditioning methods for improved convergence rates in iterative reconstructions, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 12, no. 1, </volume> <pages> pp. 7883, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Combining (9) with the circulant approximation (11) for l = 1 leads to the following circulant preconditioner: M C = ff Clinthorne et al. applied this type of preconditioner to shift-invariant image reconstruction <ref> [20] </ref>. Circulant pre-conditioners can be efficiently incorporated into the CG algorithm using 2D FFTs. For comparison purposes, we have investigated the effectiveness of the circulant preconditioner even for shift-variant problems where the circulant approximation is poor. The best choice of ff is unclear in the shift-variant case.
Reference: [21] <author> R. H. Chan, M. K. Ng, and R. J. Plemmons, </author> <title> Generalization of Strang's preconditioner with applications to Toeplitz least squares problems, Numerical Linear Algebra with Applications, </title> <journal> vol. </journal> <volume> 3, no. 1, </volume> <pages> pp. 4564, </pages> <year> 1996. </year>
Reference: [22] <author> J. G. Nagy, R. J. Plemmons, and T. C. Torgersen, </author> <title> Iterative image restoration using approximate inverse preconditioning, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 5, no. 7, </volume> <pages> pp. 115162, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: Such circulant approximations to Toeplitz matrices have been studied extensively, e.g. <ref> [15, 22, 41] </ref>. 8 See [33] for details about computing , which consists of the 2D DFT coefficients of the column of K corresponding to the pixel at the center of the image. 9 For any p 1 fi p 2 2D image lexicographically ordered as a vector u, Qu is
Reference: [23] <author> R. Chan, T. F. Chan, and C. wong, </author> <title> Cosine transform based precondi-tioners for total variation minimization problems in image processing, in Iterative Methods in Linear Algebra, II, </title> <booktitle> V3, IMACS Series in Computational and Applied Mathematics, Proceedings of the Second IMACS International Symposium on Iterative Methods in Linear Algebra, </booktitle> <editor> S. Margenov and P. Vassilevski, editors, </editor> <booktitle> pp. 31129, IMACS, </booktitle> <address> New Jersey, </address> <year> 1996. </year>
Reference-contexts: SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. lant preconditioners have also been applied to total variation methods for nonlinear image restoration <ref> [23, 24] </ref>. Unfortunately, many imaging problems are shift variant, for the following reasons. Firstly, many imaging systems produce heteroscedastic measurements, particularly in quantum-limited applications such as emission tomography and photon-limited optical imaging [25, 26].
Reference: [24] <author> C. R. Vogel and M. E. Oman, </author> <title> Fast numerical methods for total variation minimization in image reconstruction, </title> <booktitle> in Proc. SPIE 2563, Adv. Signal Proc. Alg., </booktitle> <pages> pp. 35967, </pages> <year> 1995. </year>
Reference-contexts: SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. lant preconditioners have also been applied to total variation methods for nonlinear image restoration <ref> [23, 24] </ref>. Unfortunately, many imaging problems are shift variant, for the following reasons. Firstly, many imaging systems produce heteroscedastic measurements, particularly in quantum-limited applications such as emission tomography and photon-limited optical imaging [25, 26].
Reference: [25] <author> D. L. Snyder, A. M. Hammoud, and R. L. White, </author> <title> Image recovery from data acquired with a charge-couple-device camera, </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> vol. 10, no. 5, </volume> <pages> pp. 10141023, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: TO APPEAR. lant preconditioners have also been applied to total variation methods for nonlinear image restoration [23, 24]. Unfortunately, many imaging problems are shift variant, for the following reasons. Firstly, many imaging systems produce heteroscedastic measurements, particularly in quantum-limited applications such as emission tomography and photon-limited optical imaging <ref> [25, 26] </ref>. In these applications, the measurement noise covariance is a diagonal matrix with very nonuniform entries, due to both nonuniform Poisson variance and to physical effects such as detector efficiency and attenuation [27].
Reference: [26] <author> D. L. Snyder, C. W. Helstrom, A. D. Lanterman, M. Faisal, and R. L. White, </author> <title> Compensation for readout noise in CCD images, </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> vol. 12, no. 2, </volume> <pages> pp. 27283, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: TO APPEAR. lant preconditioners have also been applied to total variation methods for nonlinear image restoration [23, 24]. Unfortunately, many imaging problems are shift variant, for the following reasons. Firstly, many imaging systems produce heteroscedastic measurements, particularly in quantum-limited applications such as emission tomography and photon-limited optical imaging <ref> [25, 26] </ref>. In these applications, the measurement noise covariance is a diagonal matrix with very nonuniform entries, due to both nonuniform Poisson variance and to physical effects such as detector efficiency and attenuation [27].
Reference: [27] <author> J. A. Fessler, </author> <title> Penalized weighted least-squares image reconstruction for positron emission tomography, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 13, no. 2, </volume> <pages> pp. 290300, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In these applications, the measurement noise covariance is a diagonal matrix with very nonuniform entries, due to both nonuniform Poisson variance and to physical effects such as detector efficiency and attenuation <ref> [27] </ref>. Therefore the Fisher information term G 0 W G within the Hessian (see (5) and Fig. 1 below) is shift variant and thus poorly approximated by any circulant preconditioner. <p> However, the proposed methods apply generally to problems of the form (1) for which G 0 G is approximately block Toeplitz. A. The Objective Function One useful statistical criterion for estimating x from y is the following penalized weighted least-squares 3 objective function <ref> [5, 27] </ref>: (x) = 2 0 where R (x) is a penalty function that encourages smooth or piecewise-smooth estimates, and fi is a parameter that controls the tradeoff between spatial resolution and noise [30]. (Methods for choosing fi to specify a desired resolution are described in [30].) Usually, W is the <p> piecewise-smooth estimates, and fi is a parameter that controls the tradeoff between spatial resolution and noise [30]. (Methods for choosing fi to specify a desired resolution are described in [30].) Usually, W is the inverse of the covariance matrix of y (accounting for any measurement precorrections) or an estimate thereof <ref> [27] </ref>. We restrict the presentation to cases where W is a diagonal matrix, although generalizations are possible 4 . Our goal is to compute an estimate ^x of x true from y by finding the minimizer of the objective function (x). <p> j (x): (18) It is easily shown that B is symmetric and positive definite under the (reasonable) sufficient conditions that k (t) 6= 0 8t and that the only vector in the nullspace of C is the vector of p ones, which must not be in the nullspace of G <ref> [27] </ref>. The approximations and preconditioners that we derive below all have the same form as (17), but with different approximations to B 1 (x). The requirement that the pre-conditioners be symmetric positive definite increases the challenge here. <p> Thus FFT-based precondi-tioners are very practical and effective for tomographic imaging problems. We also compared the CG algorithm using the proposed preconditioners to the coordinate-descent algorithms of <ref> [5, 27] </ref>. As in [5], we found that coordinate-descent often converged faster than unpreconditioned CG [33]. However, we consistently found that the CG algorithm with the proposed preconditioners converged significantly faster than coordinate descent [33]. How a nonnegativity constraint would affect the results requires further evaluation. VI.
Reference: [28] <author> R. I. D. </author> <title> by Spatially-Variant Blur and, J g Nagy d p O'Leary, </title> <note> SIAM J. Sci. Comp., 1997. To appear. approximate locally shift-invariant PSF. </note>
Reference-contexts: Finally, for some imaging systems (e.g. SPECT, 3D PET, and helical CT), even if we were to disregard the nonuniform noise variance, the matrix G 0 still inherently shift-variant due to the system geometry and/or spatial variations in detector response. (See <ref> [28] </ref> for an image restoration method for shift-variant imaging systems.) Thus, neither diagonal nor circulant preconditioning is well-suited to shift-variant imaging problems.
Reference: [29] <author> P. J. Green, </author> <title> Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resistant alternatives, </title> <journal> J. Royal Stat. Soc. Ser. B, </journal> <volume> vol. 46, no. 2, </volume> <pages> pp. 149192, </pages> <year> 1984. </year>
Reference-contexts: This penalty is the special case of (3) where K is the number of pairs of neighboring pixels 5 , the vector c = 0, 3 One could generalize the approach to produce penalized-likelihood estimates by using iteratively reweighted least-squares <ref> [29] </ref>. 4 It suffices to have G 0 W G DM D where D is diagonal and M is approximately block-circulant. 5 K 2p and K 4p for first and second-order neighborhoods respectively.
Reference: [30] <author> J. A. Fessler and W. L. Rogers, </author> <title> Spatial resolution properties of penalized-likelihood image reconstruction methods: </title> <journal> Space-invariant tomographs, IEEE Tr. Im. Proc., </journal> <volume> vol. 5, no. 9, </volume> <pages> pp. 134658, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: useful statistical criterion for estimating x from y is the following penalized weighted least-squares 3 objective function [5, 27]: (x) = 2 0 where R (x) is a penalty function that encourages smooth or piecewise-smooth estimates, and fi is a parameter that controls the tradeoff between spatial resolution and noise <ref> [30] </ref>. (Methods for choosing fi to specify a desired resolution are described in [30].) Usually, W is the inverse of the covariance matrix of y (accounting for any measurement precorrections) or an estimate thereof [27]. <p> least-squares 3 objective function [5, 27]: (x) = 2 0 where R (x) is a penalty function that encourages smooth or piecewise-smooth estimates, and fi is a parameter that controls the tradeoff between spatial resolution and noise <ref> [30] </ref>. (Methods for choosing fi to specify a desired resolution are described in [30].) Usually, W is the inverse of the covariance matrix of y (accounting for any measurement precorrections) or an estimate thereof [27]. We restrict the presentation to cases where W is a diagonal matrix, although generalizations are possible 4 . <p> However, in the special case of 6 This assumption precludes the choice [31] k (t) = jtj p for p &lt; 2 which has unbounded second derivative. 7 For certain ROI quantification tasks the quadratic penalty is useful <ref> [30] </ref> and even outperforms nonquadratic penalties [34]. quadratic penalty functions with k (t) = ! k t 2 =2, the vector z (x) simplifies to z (x) = D [! k ] (Cx c); and the gradient simplifies to r (x) = b Hx where H = G 0 G + <p> The results in Section V demonstrate that our proposed preconditioners lead to significantly accelerated convergence, despite possibly crude approximations in the development! The first key approximation is one that we have previously used for analyzing the spatial resolution properties of tomographic image reconstruction in <ref> [30] </ref>. <p> The matrices on the two sides of approximation (13) are exactly equal along their diagonals, and would also be equal off-diagonal if the W ii 's were all equal. (The results in <ref> [30] </ref> demonstrate the accuracy and utility of this approximation.) Combining the exchange (13) with (5) leads to our first Hessian approximation: H (x) H 1 (x) = D G GD + fiC D (x)C: The inverse of this approximation is not a practical pre conditioner, so we must further simplify. <p> Furthermore, in the quadratic penalty case with k (t) = t 2 =2, we have D =I so (15) is then exact. The factor j j (x) is an effective regularization parame ter for the jth pixel <ref> [30] </ref>. To illustrate, note that if W =I and k (t) = t 2 =2, then j = 1 and j j (x) = fi for all j and x. <p> The usual uniform 1st-order 2D roughness penalty matrix R 0 has 4's along its diagonal and 1's in the off-diagonal positions corresponding to each pixel's four neighbors. Surprisingly, this uni form penalty leads to nonuniform spatial resolution when W 6= I <ref> [30] </ref>. Thus, for quadratic penalties we use the modified penalty of [30], for which R D R 0 D : (31) This modified penalty leads to more uniform spatial resolution [30], which in turn leads to a Hessian that is particularly amenable to preconditioning, since uniform spatial resolution and shift-invariance are <p> Surprisingly, this uni form penalty leads to nonuniform spatial resolution when W 6= I <ref> [30] </ref>. Thus, for quadratic penalties we use the modified penalty of [30], for which R D R 0 D : (31) This modified penalty leads to more uniform spatial resolution [30], which in turn leads to a Hessian that is particularly amenable to preconditioning, since uniform spatial resolution and shift-invariance are equivalent concepts. <p> Surprisingly, this uni form penalty leads to nonuniform spatial resolution when W 6= I <ref> [30] </ref>. Thus, for quadratic penalties we use the modified penalty of [30], for which R D R 0 D : (31) This modified penalty leads to more uniform spatial resolution [30], which in turn leads to a Hessian that is particularly amenable to preconditioning, since uniform spatial resolution and shift-invariance are equivalent concepts. Under approximation (31), one can verify that j j = fi 8j for the quadratic penalty. <p> G. Summary We recommend the circulant preconditioner (12) for shift-invariant problems, the combined diagonal/circulant preconditioner (32) for quadratic penalized weighted least squares with the modified penalty of <ref> [30] </ref>, and the new preconditioner (30) for the general shift-variant case. FESSLER AND BOOTH: PRECONDITIONED TOMOGRAPHIC RECONSTRUCTION 9 IV. LINE SEARCH METHOD For nonquadratic objectives, gradient-based methods require a line search in (7) to find the step size ff that minimizes the objective function along the current search direction. <p> The reconstructed images were 128 fi 128 pixels of width 0.42 cm. We reconstructed a FBP image by first smoothing the ratio of the transmission over the blank scan with the constrained least squares filter described in <ref> [30, 49] </ref>, computing the logarithm, and finally applying the ramp filter prior to pixel-driven backprojection. This approach closely matches the spatial resolution of the FBP image with that of the quadratically penalized statistical methods. <p> The second objective function was quadratically penalized weighted least squares (QPWLS), where W is the curvature term in the 2nd-order Taylor expansion of the transmission log-likelihood [33, 51]. In this case we used the modified penalty that provides more uniform spatial resolution <ref> [30] </ref>. As illustrated in Fig. 2, the QPWLS objective function leads to a less noisy image, since ray measurements with greater uncertainty are given lower weight. However, this nonuniform weighting leads to significant shift-variance. As illustrated in Fig. 4, for QPWLS the standard circulant preconditioner performs very poorly. <p> This function is approximately quadratic for jtj o ffi, but is approximately linear for jtj AE ffi, which provides a degree of edge preservation. We did not use the modified penalty weighting of <ref> [30] </ref> here, since its effect is currently unknown for nonquadratic penalties. The nonquadratic penalty provides shift-variant smoothing, which, as illustrated in Fig. 2, can lead to (somewhat) improved image quality (particularly for nearly piecewise-constant objects. <p> A more direct approach might begin with bases that better accommodate shift-variance, such as wavelets. Although this paper focuses on image reconstruction, the preconditioning methods are also useful for calculating analytical metrics related to imaging system performance, such as bias, variance, and spatial resolution <ref> [30, 52, 55] </ref>. Many of these calculations require iterative methods for solving large-scale linear systems of equations involving the Hessian of the objective function.
Reference: [31] <author> C. Bouman and K. Sauer, </author> <title> A generalized Gaussian image model for edge-preserving MAP estimation, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 2, no. 3, </volume> <pages> pp. 296 310, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: The unregularized problem (with fi=0) is poorly conditioned or even under-determined, so some regularization is required to ensure a stable solution. Gradient-based iterative methods generally converge only to local minima for non-convex regularizing functions, so we focus here on convex penalty functions <ref> [31] </ref>. <p> However, in the special case of 6 This assumption precludes the choice <ref> [31] </ref> k (t) = jtj p for p &lt; 2 which has unbounded second derivative. 7 For certain ROI quantification tasks the quadratic penalty is useful [30] and even outperforms nonquadratic penalties [34]. quadratic penalty functions with k (t) = ! k t 2 =2, the vector z (x) simplifies to
Reference: [32] <author> A. R. De Pierro, </author> <title> A modified expectation maximization algorithm for penalized likelihood estimation in emission tomography, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 14, no. 1, </volume> <pages> pp. 132137, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: The unregularized problem (with fi=0) is poorly conditioned or even under-determined, so some regularization is required to ensure a stable solution. Gradient-based iterative methods generally converge only to local minima for non-convex regularizing functions, so we focus here on convex penalty functions [31]. The following general form <ref> [32] </ref> expresses most of the convex penalty functions that have been proposed for regularization of imaging problems: R (x) = k=1 where C is a K fi p matrix and c 2 R K , for some user-defined number K of soft constraints of the form [Cx] k c k :
Reference: [33] <author> J. A. Fessler, </author> <title> Conjugate-gradient preconditioning methods: numerical results, </title> <type> Technical Report 303, </type> <institution> Comm. and Sign. Proc. Lab., Dept. of EECS, Univ. of Michigan, </institution> <address> Ann Arbor, MI, 48109-2122, </address> <month> January </month> <year> 1997. </year> <note> Available on WWW from http://www.eecs.umich.edu/fessler. </note>
Reference-contexts: FESSLER AND BOOTH: PRECONDITIONED TOMOGRAPHIC RECONSTRUCTION 3 and each row of C contains one +1 and one -1 entry so that [Cx] k corresponds to the difference between two neighboring pixel values <ref> [33] </ref>. In this paper we first consider general convex non-quadratic functions k that are symmetric, twice-differentiable, and that have bounded, nonzero second derivatives 6 . <p> Such circulant approximations to Toeplitz matrices have been studied extensively, e.g. [15, 22, 41]. 8 See <ref> [33] </ref> for details about computing , which consists of the 2D DFT coefficients of the column of K corresponding to the pixel at the center of the image. 9 For any p 1 fi p 2 2D image lexicographically ordered as a vector u, Qu is the lexicographically ordered vector of <p> TO APPEAR. This approximation leads to the following preconditioner: M 10 (x) = m X D k (x)T 0 Q 0 1 ! ; which also requires 2m FFT's per iteration. However, we have found empirically that M 9 leads to faster convergence than M 10 for nonquadratic penalties <ref> [33] </ref>. Since M 9 and M 10 have equivalent computation time, we consider M 9 to be the preferred preconditioner for the non-quadratic case. <p> Results for PET emission scans were reported in [8]. We have investigated the effects of the initial image, the type of penalty, the choice of weights W ii , and several measures of convergence rates. We synopsize representative results only; complete details are given in <ref> [33] </ref>. We acquired a 12-minute PET transmission scan of a Data Spectrum thorax phantom on an CTI ECAT 921 EXACT PET scanner. This scan produced 920653 prompt coincidences, which is quite noisy data. <p> Regularized versions of this objective function were then minimized using the PCG algorithm. The exact form for y i and W ii are given in <ref> [33] </ref>. The system model G used for reconstruction assumed parallel strip integrals of width 0.3375 cm. We investigated the convergence rates of the PCG algorithm with both the FBP image and a zero image as the initial image x 0 . The FBP initialization always led to faster convergence [33], so <p> in <ref> [33] </ref>. The system model G used for reconstruction assumed parallel strip integrals of width 0.3375 cm. We investigated the convergence rates of the PCG algorithm with both the FBP image and a zero image as the initial image x 0 . The FBP initialization always led to faster convergence [33], so we report only those results here. A manually determined subset of the pixels (see Fig. 2) was reconstructed, which specifies the matrix T in (11). <p> To compare convergence rates, we examined the normalized l 2 distance between the nth iterate x n and the limiting value x 1 : kx n x 1 k=kx 1 k: (We also examined the l 1 and l 1 norms, which led to comparable conclusions <ref> [33] </ref>.) The PCG algorithms were implemented in ANSI C [53] using single floating-point precision on a DEC AlphaStation 600/5-333 workstation. However, to compute x 1 , we implemented a grouped-coordinate ascent algorithm similar to that described in [50] in Mat-lab using double precision. <p> Fig. 3 shows that the circu-lant preconditioner (12) provides significant acceleration for this nearly shift-invariant problem, as expected from previous reports. The second objective function was quadratically penalized weighted least squares (QPWLS), where W is the curvature term in the 2nd-order Taylor expansion of the transmission log-likelihood <ref> [33, 51] </ref>. In this case we used the modified penalty that provides more uniform spatial resolution [30]. As illustrated in Fig. 2, the QPWLS objective function leads to a less noisy image, since ray measurements with greater uncertainty are given lower weight. However, this nonuniform weighting leads to significant shift-variance. <p> Increasing m gave negligible improvements, which is expected from Table I of <ref> [33] </ref>; increasing m may make M 9 a better approximation to H 1 5 , but that can only accelerate convergence slightly since H 5 is an imperfect approximation to H. <p> Thus FFT-based precondi-tioners are very practical and effective for tomographic imaging problems. We also compared the CG algorithm using the proposed preconditioners to the coordinate-descent algorithms of [5, 27]. As in [5], we found that coordinate-descent often converged faster than unpreconditioned CG <ref> [33] </ref>. However, we consistently found that the CG algorithm with the proposed preconditioners converged significantly faster than coordinate descent [33]. How a nonnegativity constraint would affect the results requires further evaluation. VI. <p> We also compared the CG algorithm using the proposed preconditioners to the coordinate-descent algorithms of [5, 27]. As in [5], we found that coordinate-descent often converged faster than unpreconditioned CG <ref> [33] </ref>. However, we consistently found that the CG algorithm with the proposed preconditioners converged significantly faster than coordinate descent [33]. How a nonnegativity constraint would affect the results requires further evaluation. VI.
Reference: [34] <author> E. U. Mumcuoglu, R. M. Leahy, Z. Zhou, and S. R. Cherry, </author> <title> A phantom study of the quantitative behavior of Bayesian PET reconstruction methods, </title> <booktitle> in Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> volume 3, </volume> <pages> pp. 17037, </pages> <year> 1995. </year>
Reference-contexts: However, in the special case of 6 This assumption precludes the choice [31] k (t) = jtj p for p &lt; 2 which has unbounded second derivative. 7 For certain ROI quantification tasks the quadratic penalty is useful [30] and even outperforms nonquadratic penalties <ref> [34] </ref>. quadratic penalty functions with k (t) = ! k t 2 =2, the vector z (x) simplifies to z (x) = D [! k ] (Cx c); and the gradient simplifies to r (x) = b Hx where H = G 0 G + fiC 0 D [! k ]
Reference: [35] <author> E. U. Mumcuoiglu, R. M. Leahy, and S. R. Cherry, </author> <title> Bayesian reconstruction of PET images: methodology and performance analysis, </title> <journal> Phys. Med. Biol., </journal> <volume> vol. 41, no. 9, </volume> <pages> pp. 17771807, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Regularization methods are generally designed to ensure such positive definiteness. Since this paper focuses on comparing various pre-conditioners, for simplicity we ignore any nonnegativity constraint for x. One could extend the methods to include a nonnegativity barrier/penalty function <ref> [6, 35] </ref>, or active-set or gradient projection method [36,37]. Improvements in convergence rate due to improved precondition-ers should extend to methods that incorporate nonnegativ ity, as shown in [38]. B.
Reference: [36] <author> E. U. Mumcuoiglu and R. M. Leahy, </author> <title> A gradient projection conjugate gradient algorithm for Bayesian PET reconstruction, </title> <booktitle> in Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> volume 3, </volume> <pages> pp. 12126, </pages> <year> 1994. </year>
Reference: [37] <author> J. J. More and G. Toraldo, </author> <title> On the solution of large quadratic programming problems with bound constraints, </title> <journal> SIAM J. Optim., </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 93113, </pages> <month> February </month> <year> 1991. </year>
Reference: [38] <author> M. Bierlaire, P. L. Toint, and D. Tuyttens, </author> <title> On iterative algorithms for linear least squares problems with bound constraints, </title> <journal> Linear Algebra and its Applications, </journal> <volume> vol. 143, </volume> <pages> pp. 11143, </pages> <year> 1991. </year>
Reference-contexts: One could extend the methods to include a nonnegativity barrier/penalty function [6, 35], or active-set or gradient projection method [36,37]. Improvements in convergence rate due to improved precondition-ers should extend to methods that incorporate nonnegativ ity, as shown in <ref> [38] </ref>. B. The Gradients Under the above assumptions, one can determine the unique minimizer ^x of the objective function by finding the zero of its gradient.
Reference: [39] <author> W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling, </author> <title> Numerical recipes in C, </title> <publisher> Cambridge Univ. Press, </publisher> <year> 1988. </year>
Reference-contexts: The re mainder of this section reviews the PCG algorithm. C. Minimization Using Conjugate Gradients Gradient-based minimization methods use the gradient of the objective function r 0 (x n ) to determine a series of direction vectors fd n g along which is minimized via 1D line search <ref> [39] </ref>. Conjugate-gradient methods modify the search directions to ensure that they are mutually con jugate (or approximately so for nonquadratic problems). <p> Conjugate-gradient methods modify the search directions to ensure that they are mutually con jugate (or approximately so for nonquadratic problems). We use the following preconditioned form of the Polak-Ribiere CG method <ref> [6, 39] </ref>: g n = r 0 (x n ) (-gradient: see (4)) p = M g (precondition) (6) fl n = &lt; 0; n = 0 hg n1 ; p n1 i d n = p n + fl n d n1 (search direction) ff n = arg min (x <p> and n y are the image column and row dimensions and p = n x n y . p n = D 1 m X p n : Even less computation and storage is actually required since one can compute a pair of real FFT's using just one complex FFT <ref> [39] </ref>, and the summations can be done by in-place accumulation. F. <p> FESSLER AND BOOTH: PRECONDITIONED TOMOGRAPHIC RECONSTRUCTION 9 IV. LINE SEARCH METHOD For nonquadratic objectives, gradient-based methods require a line search in (7) to find the step size ff that minimizes the objective function along the current search direction. General purpose line-search methods <ref> [39] </ref> are applicable but suboptimal since they fail to exploit the specific form (particularly convexity) of our objective function (2). In this section we present a new recursive line-search algorithm that is simple to implement and is guaranteed to monotonically minimize the objective function with respect to ff.
Reference: [40] <author> M. Al-Baali and R. Fletcher, </author> <title> On the order of convergence of preconditioned nonlinear conjugate gradient methods, </title> <journal> SIAM J. Sci. Comp., </journal> <volume> vol. 17, no. 3, </volume> , <month> May </month> <year> 1996. </year>
Reference-contexts: For nonquadratic , the inverse-Hessian preconditioner M 0 (x) = H (x) = [G W G + fiC D (x)C] yields superlinear convergence rates, as does the Newton-Raphson method <ref> [40] </ref>. Since we cannot compute H 1 for large p, we must develop preconditioners that approximate H 1 . A.
Reference: [41] <author> A. K. Jain, </author> <title> Fundamentals of digital image processing, </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1989. </year>
Reference-contexts: Such circulant approximations to Toeplitz matrices have been studied extensively, e.g. <ref> [15, 22, 41] </ref>. 8 See [33] for details about computing , which consists of the 2D DFT coefficients of the column of K corresponding to the pixel at the center of the image. 9 For any p 1 fi p 2 2D image lexicographically ordered as a vector u, Qu is
Reference: [42] <author> P. J. Huber, </author> <title> Robust statistics, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: In this section we present a new recursive line-search algorithm that is simple to implement and is guaranteed to monotonically minimize the objective function with respect to ff. This algorithm is an adaptation of the iteration proposed by Huber <ref> [42] </ref> for robust M-estimation. (The essence of Huber's algorithm has also resurfaced in the imaging literature as the half-quadratic method [4345].) The convergence proof in [42] requires the following assumptions: 1) k is convex, symmetric, and differentiable, and 2) ! k (t) = _ k (t)=t (33) is bounded and decreasing <p> This algorithm is an adaptation of the iteration proposed by Huber <ref> [42] </ref> for robust M-estimation. (The essence of Huber's algorithm has also resurfaced in the imaging literature as the half-quadratic method [4345].) The convergence proof in [42] requires the following assumptions: 1) k is convex, symmetric, and differentiable, and 2) ! k (t) = _ k (t)=t (33) is bounded and decreasing for t &gt; 0. (The ! k functions act as weighting functions that diminish the influence of neighboring pixels near edges between object regions for <p> assumptions: 1) k is convex, symmetric, and differentiable, and 2) ! k (t) = _ k (t)=t (33) is bounded and decreasing for t &gt; 0. (The ! k functions act as weighting functions that diminish the influence of neighboring pixels near edges between object regions for nonquadratic penalty functions <ref> [42, 46, 47] </ref>.) These assumptions are reasonable for the convex penalty functions used in imaging. The line-search algorithm can be stated as follows. Let x and d denote the current estimate and search direction respectively. <p> tion is guaranteed to converge to ^ff: ff i+1 = ff i f 2 + fi k h 2 ; (34) where ! k was defined in (33). (We initialize with ff 0 = 0.) The iteration monotonically decreases f (ff i ) by the proof of Lemma 8 in <ref> [42] </ref>. One can also show that the above iteration is a strict contraction: jff i ^ffj monotonically decreases each iteration [47]. We use about five sub-iterations of the above recursion for each iteration of the CG algorithm.
Reference: [43] <author> P. Charbonnier, L. Blanc-Feraud, G. Aubert, and M. Barlaud, </author> <title> Two deterministic half-quadratic regularization algorithms for computed imaging, </title> <booktitle> in Proc. IEEE Intl. Conf. on Image Processing, </booktitle> <volume> volume 2, </volume> <pages> pp. 168171, </pages> <year> 1994. </year>
Reference: [44] <author> D. Geman and G. Reynolds, </author> <title> Constrained restoration and the recovery of discontinuities, </title> <journal> IEEE Tr. Patt. Anal. Mach. Int., </journal> <volume> vol. 14, no. 3, </volume> <pages> pp. 367 383, </pages> <month> March </month> <year> 1992. </year>
Reference: [45] <author> D. Geman and C. Yang, </author> <title> Nonlinear image recovery with half-quadratic regularization, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 4, no. 7, </volume> <pages> pp. 93246, </pages> <month> July </month> <year> 1995. </year>
Reference: [46] <author> P. Charbonnier, L. Blanc-Feraud, G. Aubert, and M. Barlaud, </author> <title> Deterministic edge-preserving regularization in computed imaging, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 6, no. 2, </volume> , <month> February </month> <year> 1997. </year>
Reference-contexts: assumptions: 1) k is convex, symmetric, and differentiable, and 2) ! k (t) = _ k (t)=t (33) is bounded and decreasing for t &gt; 0. (The ! k functions act as weighting functions that diminish the influence of neighboring pixels near edges between object regions for nonquadratic penalty functions <ref> [42, 46, 47] </ref>.) These assumptions are reasonable for the convex penalty functions used in imaging. The line-search algorithm can be stated as follows. Let x and d denote the current estimate and search direction respectively.
Reference: [47] <author> J. A. Fessler, </author> <title> Grouped coordinate descent algorithms for robust edge-preserving image restoration, </title> <booktitle> in Proc. SPIE 3071, Im. Recon. and Restor. II, </booktitle> <pages> pp. 18494, </pages> <year> 1997. </year>
Reference-contexts: assumptions: 1) k is convex, symmetric, and differentiable, and 2) ! k (t) = _ k (t)=t (33) is bounded and decreasing for t &gt; 0. (The ! k functions act as weighting functions that diminish the influence of neighboring pixels near edges between object regions for nonquadratic penalty functions <ref> [42, 46, 47] </ref>.) These assumptions are reasonable for the convex penalty functions used in imaging. The line-search algorithm can be stated as follows. Let x and d denote the current estimate and search direction respectively. <p> One can also show that the above iteration is a strict contraction: jff i ^ffj monotonically decreases each iteration <ref> [47] </ref>. We use about five sub-iterations of the above recursion for each iteration of the CG algorithm. Since no forward or backward projections are required, these sub-iterations are a fairly small component of the computation time for each iteration.
Reference: [48] <author> M. Yavuz and J. A. Fessler, </author> <title> New statistical models for randoms-precorrected PET scans, in Information Processing in Medical Im., </title> <editor> J. Duncan and G. Gindi, editors, </editor> <booktitle> volume 1230 of Lecture Notes in Computer Science, </booktitle> <pages> pp. </pages> <address> 190203, </address> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1997. </year>
Reference-contexts: The sinogram size was 160 radial bins by 192 angles, with 0.3375 cm radial spacing, so n = 30720. Prompt and random coincidences were collected separately. The mean contributions of randoms were estimated by time scaling the delayed coincidences from a 15 hour blank scan, as described in <ref> [48] </ref>. The reconstructed images were 128 fi 128 pixels of width 0.42 cm.
Reference: [49] <author> J. A. Fessler, </author> <title> Resolution properties of regularized image reconstruction methods, </title> <type> Technical Report 297, </type> <institution> Comm. and Sign. Proc. Lab., Dept. of EECS, Univ. of Michigan, </institution> <address> Ann Arbor, MI, 48109-2122, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: The reconstructed images were 128 fi 128 pixels of width 0.42 cm. We reconstructed a FBP image by first smoothing the ratio of the transmission over the blank scan with the constrained least squares filter described in <ref> [30, 49] </ref>, computing the logarithm, and finally applying the ramp filter prior to pixel-driven backprojection. This approach closely matches the spatial resolution of the FBP image with that of the quadratically penalized statistical methods.
Reference: [50] <author> J. A. Fessler, E. P. Ficaro, N. H. Clinthorne, and K. Lange, </author> <title> Grouped-coordinate ascent algorithms for penalized-likelihood transmission image reconstruction, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 16, no. 2, </volume> <pages> pp. 16675, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: This approach closely matches the spatial resolution of the FBP image with that of the quadratically penalized statistical methods. The log-likelihood for Poisson transmission data is non-quadratic <ref> [50] </ref>, and therefore not directly of the form given in (2). A conventional approach is to make a ray-by-ray 2nd-order Taylor expansion of the log-likelihood [5, 51] 10 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. <p> SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. to yield a quadratic functional of the form (2). Unfortunately that approximation leads to systematic bias [51, 52]. Therefore, we used the FBP image to initialize the grouped-coordinate ascent algorithm of <ref> [50] </ref>, which was run for two iterations to produce an intermediate estimate ~x. We then computed a 2nd-order Taylor expansion of the transmission log-likelihood about the reprojec-tion of ~x to produce a quadratic data-fit term of the form given in (2). <p> However, to compute x 1 , we implemented a grouped-coordinate ascent algorithm similar to that described in <ref> [50] </ref> in Mat-lab using double precision. Several hundred iterations of this algorithm were run, until the change in the estimates reached the limiting precision.
Reference: [51] <author> J. A. Fessler, </author> <title> Hybrid Poisson/polynomial objective functions for to-mographic image reconstruction from transmission scans, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 4, no. 10, </volume> <pages> pp. 143950, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: The log-likelihood for Poisson transmission data is non-quadratic [50], and therefore not directly of the form given in (2). A conventional approach is to make a ray-by-ray 2nd-order Taylor expansion of the log-likelihood <ref> [5, 51] </ref> 10 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. to yield a quadratic functional of the form (2). Unfortunately that approximation leads to systematic bias [51, 52]. <p> A conventional approach is to make a ray-by-ray 2nd-order Taylor expansion of the log-likelihood [5, 51] 10 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. to yield a quadratic functional of the form (2). Unfortunately that approximation leads to systematic bias <ref> [51, 52] </ref>. Therefore, we used the FBP image to initialize the grouped-coordinate ascent algorithm of [50], which was run for two iterations to produce an intermediate estimate ~x. <p> Fig. 3 shows that the circu-lant preconditioner (12) provides significant acceleration for this nearly shift-invariant problem, as expected from previous reports. The second objective function was quadratically penalized weighted least squares (QPWLS), where W is the curvature term in the 2nd-order Taylor expansion of the transmission log-likelihood <ref> [33, 51] </ref>. In this case we used the modified penalty that provides more uniform spatial resolution [30]. As illustrated in Fig. 2, the QPWLS objective function leads to a less noisy image, since ray measurements with greater uncertainty are given lower weight. However, this nonuniform weighting leads to significant shift-variance.
Reference: [52] <author> J. A. Fessler, </author> <title> Mean and variance of implicitly defined biased estimators (such as penalized maximum likelihood): Applications to tomography, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 493506, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: A conventional approach is to make a ray-by-ray 2nd-order Taylor expansion of the log-likelihood [5, 51] 10 IEEE TRANSACTIONS ON IMAGE PROCESSING, EDICS 2.3. SUBMITTED 1/28/97. REVISION June 17, 1998. TO APPEAR. to yield a quadratic functional of the form (2). Unfortunately that approximation leads to systematic bias <ref> [51, 52] </ref>. Therefore, we used the FBP image to initialize the grouped-coordinate ascent algorithm of [50], which was run for two iterations to produce an intermediate estimate ~x. <p> A more direct approach might begin with bases that better accommodate shift-variance, such as wavelets. Although this paper focuses on image reconstruction, the preconditioning methods are also useful for calculating analytical metrics related to imaging system performance, such as bias, variance, and spatial resolution <ref> [30, 52, 55] </ref>. Many of these calculations require iterative methods for solving large-scale linear systems of equations involving the Hessian of the objective function.
Reference: [53] <author> J. A. Fessler, </author> <title> ASPIRE 3.0 user's guide: A sparse iterative reconstruction library, </title> <type> Technical Report 293, </type> <institution> Comm. and Sign. Proc. Lab., Dept. of EECS, Univ. of Michigan, </institution> <address> Ann Arbor, MI, 48109-2122, </address> <month> July </month> <year> 1995. </year> <note> Available on WWW from http://www.eecs.umich.edu/fessler. </note>
Reference-contexts: examined the normalized l 2 distance between the nth iterate x n and the limiting value x 1 : kx n x 1 k=kx 1 k: (We also examined the l 1 and l 1 norms, which led to comparable conclusions [33].) The PCG algorithms were implemented in ANSI C <ref> [53] </ref> using single floating-point precision on a DEC AlphaStation 600/5-333 workstation. However, to compute x 1 , we implemented a grouped-coordinate ascent algorithm similar to that described in [50] in Mat-lab using double precision.
Reference: [54] <author> K. Lange, </author> <title> Convergence of EM image reconstruction algorithms with Gibbs smoothing, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 9, no. 4, </volume> <pages> pp. 439446, </pages> <address> De-cember 1990. Corrections, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: However, the proposed combined diagonal/circulant pre-conditioner (32) provides significant acceleration, with negligible increase in computation time per iteration over the circulant preconditioner. The third objective function was nonquadratically-penalized weighted least squares (NPWLS). We used one of the penalties proposed in <ref> [54] </ref> for k : (t) = ffi 2 [ jt=ffij log (1 + jt=ffij) ] ; (35) with ffi = 0:004 cm. This function is approximately quadratic for jtj o ffi, but is approximately linear for jtj AE ffi, which provides a degree of edge preservation.
Reference: [55] <author> A. O. Hero, M. Usman, A. C. Sauve, and J. A. Fessler, </author> <title> Recursive algorithms for computing the Cramer-Rao bound, </title> <journal> IEEE Tr. Sig. Proc., </journal> <volume> vol. 45, no. 3, </volume> <pages> pp. 8037, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: A more direct approach might begin with bases that better accommodate shift-variance, such as wavelets. Although this paper focuses on image reconstruction, the preconditioning methods are also useful for calculating analytical metrics related to imaging system performance, such as bias, variance, and spatial resolution <ref> [30, 52, 55] </ref>. Many of these calculations require iterative methods for solving large-scale linear systems of equations involving the Hessian of the objective function.

References-found: 55

