URL: http://www.cs.berkeley.edu/~gribble/papers/msc_thesis.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~gribble/papers/papers.html
Root-URL: http://www.cs.berkeley.edu
Title: System Design Issues for Internet Middleware Services: Deductions from a Large Client Trace  
Author: by Steven D. Gribble Professor Randy H. Katz 
Degree: 1995 A dissertation submitted in partial satisfaction of the requirements for the degree of Master of Science in Computer Science in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA at BERKELEY Committee in charge: Professor Eric A. Brewer, Chair  
Date: 1997  
Affiliation: B.Sc. (University of British Columbia)  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Allpen Software Home Page. </institution> <note> http://www.allpen.com. </note>
Reference-contexts: Furthermore, we observed a total 166 different UserAgent values within the traces, representing a wide range of desktop systems (MacOS, Win16, NetBSD, Linux, etc.) More significantly, however, we saw requests from a number of exotic clients such as Newton PDAs running the NetHopper <ref> [1] </ref> browser. Internet services that do not want to limit the effective audience of their content must therefore be able to deliver content that suits the needs of all of these diverse clients.
Reference: [2] <author> Thomas E. Anderson, Henry M. Levy, Brian N. Bershad, and Edward D. Lazowska. </author> <title> The interaction of architecture and operating system design. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: Previous work has explored the performance of operating system primitives and their relationship to architecture ([30], <ref> [2] </ref>), and operating system design issues for busy Internet services ([19], [27]).
Reference: [3] <author> Rob Barrett, Paul P. Maglio, and Daniel C. Kellem. </author> <title> How to personalize the web. </title> <booktitle> In Proceedings of the 1997 Conference on Human Factors in Compuer Systems (CHI 1997), </booktitle> <address> Atlanta, Georgia, USA, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: 1 Introduction The recent explosive growth of the Internet [32] has resulted in a similar explosion of web-oriented middleware services ([15], <ref> [3] </ref>, [6]). These middleware services, particularly the more popular services that experience extremely high load, must overcome a number of challenging system design issues in order to maintain fast response time, constant availability, and capacity. Services must accommodate a client population with wide variation in hardware, software, and network connectivity.
Reference: [4] <author> Jan Beran, Robert Sherman, Murad S. Taqqu, and Walter Willinger. </author> <title> Long-range dependence in variable-bit-rate video traffic. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 43 </volume> <pages> 1566-79, </pages> <month> March </month> <year> 1995. </year>
Reference: [5] <author> Tim Berners-Lee, R. Fielding, and H. Frystyk. </author> <title> Hypertext transfer protocol - http/1.0. RFC 1945, </title> <month> May </month> <year> 1996. </year>
Reference-contexts: In contrast, this paper raises a number of system design issues specifically for Internet middleware services that we encountered during two separate but related efforts: the analysis of a set of extensive client-side HTTP <ref> [5] </ref> traces that we gathered from the University of California at Berkeley's dial-in modem banks during October and November of 1996, and the implementation and deployment experience we gained from the TranSend Internet middleware service [15].
Reference: [6] <author> Timothy C. Bickmore and Bill N. Schilit. Digestor: </author> <title> Device-independent access to the world wide web. </title> <booktitle> In Proceedings for the Sixth International World Wide Web Conference, </booktitle> <year> 1997. </year> <note> available at http://www.fxpal.xerox.com/papers/bic97/. 37 </note>
Reference-contexts: 1 Introduction The recent explosive growth of the Internet [32] has resulted in a similar explosion of web-oriented middleware services ([15], [3], <ref> [6] </ref>). These middleware services, particularly the more popular services that experience extremely high load, must overcome a number of challenging system design issues in order to maintain fast response time, constant availability, and capacity. Services must accommodate a client population with wide variation in hardware, software, and network connectivity.
Reference: [7] <author> C. Brooks, M. S. Mazer, S. Meeks, and J. Miller. </author> <title> Application-specific proxy servers as http stream transducers. </title> <booktitle> In Proceedings of the 4th International World Wide Web Conference, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Either the services themselves must adapt their content, or they must rely on the emergence of middleware services (such as in [13], [14], and <ref> [7] </ref>) to adapt content on the fly to better suit the clients' particular needs. 9 Browser OS % Seen Windows 95 55.1 Macintosh 19.7 Netscape Windows (other) 8.8 Windows NT 3.5 Linux 2.2 Other 0.4 Windows 95 7.6 Macintosh 0.6 MSIE Windows NT 0.7 Windows (other) 0.1 Other 1.3 Table 1:
Reference: [8] <author> A. Chankhunthod, P. B. Danzig, C. Neerdaels, M. F. Schwartz, and K. J. Worrell. </author> <title> A hierarchical internet object cache. </title> <booktitle> In Proceedings of the 1996 Usenix Annual Technical Conference, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: Investigation revealed that this spike is caused by the extremely popular Netscape Corporation "Net Search" page. 17 3.4 Locality of Reference A near-universal assumption in systems is that of locality of reference, and the typical mechanism used to take advantage of this locality of reference is caching <ref> [11, 8] </ref>. The effectiveness of caching depends upon a number of factors, including the size of the user population that the cache serves and the size of the cache.
Reference: [9] <author> Mark E. Crovella and Azer Bestavros. </author> <title> Explaining world wide web traffic self-similarity. </title> <type> Technical Report TR-95-015, </type> <institution> Computer Science Department, Boston University, </institution> <month> Oct </month> <year> 1995. </year>
Reference-contexts: At the scale of tens of seconds, very pronounced bursts of activity can be seen; peak to average ratios of more than 5:1 are common. Many studies have explored the self-similarity of network traffic ([4], [16], [21], [22], [24], [31]), including web traffic <ref> [9] </ref>. Self-similarity implies burstiness at all timescale, which is not compatible with our observations. One indicator of self-similarity is a heavy-tailed interarrival process. As Figure 6 clearly shows, the interarrival time of GIF requests seen within the traces is exponentially distributed, and therefore not heavy tailed. <p> Many papers have been written on the topic of web server and client trace analysis. In [34], removal policies for network caches of WWW documents are explored, based in part on simulations driven by traces gathered from the Computer Science department of Virginia Tech. In <ref> [9] </ref>, WWW traffic self-similarity is demonstrated and in part explained through analysis of the Boston University web client traces. In [25], a series of proxy-cache 32 experiments are run on a sophisticated proxy-cache simulation environment called SPA (Squid Proxy Analysis), using the DEC SQUID proxy traces to drive the simulation.
Reference: [10] <author> Carlos R. Cunha, Azer Bestavros, and Mark E. Crovella. </author> <title> Characteristics of www client-traces. </title> <type> Technical Report BU-CS-95-010, </type> <institution> Computer Science Department, Boston University, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: One of the earliest was performed by Boston University <ref> [10] </ref>, in which about a half million client requests were captured. These traces are unique in that the Mosaic browser was exclusively used by the client population; the Boston University researchers instrumented the browser source code in order to capture their traces.
Reference: [11] <author> P. B. Danzig, R. S. Hall, and M. F. Schwartz. </author> <title> A case for caching file objects inside internetworks. </title> <booktitle> In Proceedings of SIGCOMM '93, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: Investigation revealed that this spike is caused by the extremely popular Netscape Corporation "Net Search" page. 17 3.4 Locality of Reference A near-universal assumption in systems is that of locality of reference, and the typical mechanism used to take advantage of this locality of reference is caching <ref> [11, 8] </ref>. The effectiveness of caching depends upon a number of factors, including the size of the user population that the cache serves and the size of the cache.
Reference: [12] <author> Fred Douglis, Anja Feldmann, Balachander Krishnamurthy, and Jeffrey Mogul. </author> <title> Rate of change and other metrics: a live study of the world wide web. </title> <booktitle> In Proceedings of the 1997 USENIX Symposium on Internet Technolgoies and Systems (USITS), </booktitle> <address> Monterey, CA, USA, </address> <month> December </month> <year> 1997. </year>
Reference-contexts: In [25], a series of proxy-cache 32 experiments are run on a sophisticated proxy-cache simulation environment called SPA (Squid Proxy Analysis), using the DEC SQUID proxy traces to drive the simulation. A collection of proxy-level and packet-level traces are analyzed and presented in <ref> [12] </ref> to motivate a caching model in which updates to documents are transmitted instead of complete copies of modified documents. Finally, an empirical model of HTTP network traffic and a simulator called INSANE is developed in [23] based on HTTP packet traces captured using the tcpdump tool.
Reference: [13] <author> Armando Fox and Eric A. Brewer. </author> <title> Reducing WWW Latency and Bandwidth Requirements via Real-Time Distillation. </title> <booktitle> In Proceedings of the 5th International World Wide Web Conference, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Either the services themselves must adapt their content, or they must rely on the emergence of middleware services (such as in <ref> [13] </ref>, [14], and [7]) to adapt content on the fly to better suit the clients' particular needs. 9 Browser OS % Seen Windows 95 55.1 Macintosh 19.7 Netscape Windows (other) 8.8 Windows NT 3.5 Linux 2.2 Other 0.4 Windows 95 7.6 Macintosh 0.6 MSIE Windows NT 0.7 Windows (other) 0.1 Other
Reference: [14] <author> Armando Fox, Steven D. Gribble, Eric A. Brewer, and Elan Amir. </author> <title> Adapting to network and client variation via on-demand dynamic distillation. </title> <booktitle> In Fifth International Con 38 ference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: Either the services themselves must adapt their content, or they must rely on the emergence of middleware services (such as in [13], <ref> [14] </ref>, and [7]) to adapt content on the fly to better suit the clients' particular needs. 9 Browser OS % Seen Windows 95 55.1 Macintosh 19.7 Netscape Windows (other) 8.8 Windows NT 3.5 Linux 2.2 Other 0.4 Windows 95 7.6 Macintosh 0.6 MSIE Windows NT 0.7 Windows (other) 0.1 Other 1.3 <p> In the next section, we discuss how these observations relate to a real Internet middleware service designed at Berkeley, the TranSend distillation proxy. 26 4 System Design Experience from TranSend The TranSend middleware service provides distillation ([13], <ref> [14] </ref>) services for the Berkeley Home IP modem user population, representing roughly 8,000 active users of a bank of 600-700 modems. Distillation is data-type specific, lossy compression for example, a distilled image may have reduced resolution or color depth, sacrificing image quality for compactness of representation.
Reference: [15] <author> Armando Fox, Steven D. Gribble, Yatin Chawathe, Eric A. Brewer, and Paul Gauthier. </author> <title> Scalable cluster-based network services. </title> <booktitle> In To Appear in the Proceedings of the 15th ACM Symposium on Operating Systems Principles (SOSP-16), </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: during two separate but related efforts: the analysis of a set of extensive client-side HTTP [5] traces that we gathered from the University of California at Berkeley's dial-in modem banks during October and November of 1996, and the implementation and deployment experience we gained from the TranSend Internet middleware service <ref> [15] </ref>. Since nearly 70% of all Internet clients use dial-in modems of speeds of 28.8 Kb/s or less [18], we use the traces to make a number of observations about the Internet user population and the services with which they communicate. <p> Client requests are load balanced across machines in the cluster in order to maximize request throughput and minimize the end-to-end latency of each request through the system <ref> [15] </ref>. As observed in the Home IP traces, the load presented to TranSend is quite bursty on time scales on the order of seconds.
Reference: [16] <author> Nicolas D. Georganas. </author> <title> Self-similar ("fractal") traffic in atm networks. </title> <booktitle> In Proceedings of the 2nd International Workshop on Advanced Teleservices and High-Speed Communications Architectures (IWACA '94), </booktitle> <pages> pages 1-7, </pages> <address> Heidelberg, Germany, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: At the scale of tens of seconds, very pronounced bursts of activity can be seen; peak to average ratios of more than 5:1 are common. Many studies have explored the self-similarity of network traffic ([4], <ref> [16] </ref>, [21], [22], [24], [31]), including web traffic [9]. Self-similarity implies burstiness at all timescale, which is not compatible with our observations. One indicator of self-similarity is a heavy-tailed interarrival process.
Reference: [17] <author> Ian Goldberg. </author> <title> The internet protocol scanning engine. </title> <type> Personal communications. </type>
Reference: [18] <author> Graphic, </author> <title> Visualization, & Usability Center. 6th www user survey. </title> <note> Summary available at http://www.cc.gatech.edu/gvu/user surveys/survey-10-1996/. </note>
Reference-contexts: Since nearly 70% of all Internet clients use dial-in modems of speeds of 28.8 Kb/s or less <ref> [18] </ref>, we use the traces to make a number of observations about the Internet user population and the services with which they communicate.
Reference: [19] <author> M. Frans Kaashoek, Dawson R. Engler, Gregory R. Ganger, and Deborah A. Wal-lach. </author> <title> Server operating systems. </title> <booktitle> In Proceedings of the SIGOPS European Workshop, </booktitle> <month> September </month> <year> 1996. </year>
Reference: [20] <author> Tom M. Kroeger, Jeff Mogul, and Carlos Maltzahn. </author> <title> Digital's web proxy traces. </title> <booktitle> Online at ftp://ftp.digital.com/pub/DEC/traces/proxy/ webtraces.html, </booktitle> <month> aug </month> <year> 1996. </year>
Reference-contexts: Also, our traces were taken from a much larger and more active client population (8,000 users generating more than 24,000,000 requests over a 45 day period, as compared to the Boston University traces' 591 users generating 500,000 requests over a 6 month period). In <ref> [20] </ref>, a set of web proxy traces gathered for all external web requests from Digital Electronics Corporation (DEC) is presented. These traces were gathered by modifying DEC's two SQUID proxy caches. These traces represent over 24,000,000 requests gathered over a 24 day period.
Reference: [21] <author> Will E. Leland, Murad S. Taqqu, Walter Willinger, and Daniel V. Wilson. </author> <title> On the self-similar nature of Ethernet traffic (extended version). </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 2, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: At the scale of tens of seconds, very pronounced bursts of activity can be seen; peak to average ratios of more than 5:1 are common. Many studies have explored the self-similarity of network traffic ([4], [16], <ref> [21] </ref>, [22], [24], [31]), including web traffic [9]. Self-similarity implies burstiness at all timescale, which is not compatible with our observations. One indicator of self-similarity is a heavy-tailed interarrival process.
Reference: [22] <author> Nikolai Likhanov, Boris Tsybakov, and Nicolas D. Georganas. </author> <title> Analysis of an atm buffer with self-similar ("fractal") input traffic. </title> <booktitle> In Proceedings of IEEE INFOCOM '95, </booktitle> <address> Boston, MA, </address> <month> April </month> <year> 1995. </year> <journal> IEEE. </journal> <volume> 39 </volume>
Reference-contexts: At the scale of tens of seconds, very pronounced bursts of activity can be seen; peak to average ratios of more than 5:1 are common. Many studies have explored the self-similarity of network traffic ([4], [16], [21], <ref> [22] </ref>, [24], [31]), including web traffic [9]. Self-similarity implies burstiness at all timescale, which is not compatible with our observations. One indicator of self-similarity is a heavy-tailed interarrival process.
Reference: [23] <author> Bruce Mah. </author> <title> An empirical model of http network traffic. </title> <booktitle> In Proceedings of INFOCOM '97, </booktitle> <address> Kobe, Japan, </address> <month> apr </month> <year> 1997. </year>
Reference-contexts: A collection of proxy-level and packet-level traces are analyzed and presented in [12] to motivate a caching model in which updates to documents are transmitted instead of complete copies of modified documents. Finally, an empirical model of HTTP network traffic and a simulator called INSANE is developed in <ref> [23] </ref> based on HTTP packet traces captured using the tcpdump tool. In [35], a tool is described for the capture of HTTP packet traces. This tool, called HTTPDUMP, is implemented as a set of multithreaded C routines that communicated with a packet filter via a FIFO IPC mechanism.
Reference: [24] <author> Benoit Mandelbrot. </author> <title> Self-similar error clusters in communication systems and the concept of conditional stationarity. </title> <journal> IEEE Transactions on Communication Technology, </journal> <volume> COM-13, </volume> <year> 1965. </year>
Reference-contexts: At the scale of tens of seconds, very pronounced bursts of activity can be seen; peak to average ratios of more than 5:1 are common. Many studies have explored the self-similarity of network traffic ([4], [16], [21], [22], <ref> [24] </ref>, [31]), including web traffic [9]. Self-similarity implies burstiness at all timescale, which is not compatible with our observations. One indicator of self-similarity is a heavy-tailed interarrival process.
Reference: [25] <author> David Marwood and Brad Duska. </author> <note> Squid proxy analysis (spa). Report available at http://www.cs.ubc.ca/spider/marwood/, 1996. </note>
Reference-contexts: In [9], WWW traffic self-similarity is demonstrated and in part explained through analysis of the Boston University web client traces. In <ref> [25] </ref>, a series of proxy-cache 32 experiments are run on a sophisticated proxy-cache simulation environment called SPA (Squid Proxy Analysis), using the DEC SQUID proxy traces to drive the simulation.
Reference: [26] <institution> Microsoft Corporation Home Page. </institution> <note> http://www.microsoft.com. </note>
Reference-contexts: From this table, it is easy to make a common misconclusion about web clients, namely that the set of web clients in use is extremely homogeneous, as nearly all browsers observed in our traces are either the Netscape Navigator [28] or Microsoft Internet Explorer (MSIE) <ref> [26] </ref> browsers running on the Windows or Macintosh operating systems. However, there is significant heterogeneity arising from the many versions of these browsers and their widely varying feature sets.
Reference: [27] <author> Jeffrey C. Mogul. </author> <title> Operating systems support for busy internet servers. </title> <booktitle> In Proceedings HotOS-V, </booktitle> <address> Orcas Island, Washington, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Previous work has explored the performance of operating system primitives and their relationship to architecture ([30], [2]), and operating system design issues for busy Internet services ([19], <ref> [27] </ref>).
Reference: [28] <institution> Netscape Corporation Home Page. </institution> <note> http://www.netscape.com. </note>
Reference-contexts: From this table, it is easy to make a common misconclusion about web clients, namely that the set of web clients in use is extremely homogeneous, as nearly all browsers observed in our traces are either the Netscape Navigator <ref> [28] </ref> or Microsoft Internet Explorer (MSIE) [26] browsers running on the Windows or Macintosh operating systems. However, there is significant heterogeneity arising from the many versions of these browsers and their widely varying feature sets.
Reference: [29] <institution> Lawrence Berkeley Laboratory Network Research Group. </institution> <address> Libpcap packet capture library. </address> <note> available at http://www-nrg.ee.lbl.gov/ftp.html. </note>
Reference-contexts: We only traced traffic destined for port 80, ignoring all non-HTTP protocols and HTTP connections to other ports. Each user of the Home IP service is assigned a static IP address, so we could track individual users over the entire duration of the tracing experiment. <ref> [29] </ref> library. In the first case, packet filtering is performed at the user level, and in the second case in-kernel filtering is performed if available. The packet dispatcher sends these packets to the appropriate IPSE module, which is loaded dynamically when IPSE starts up.
Reference: [30] <author> John K. Ousterhout. </author> <title> Why aren't operating systems getting faster as fast as hardware? In Proceedings of USENIX Technical Conference, </title> <month> June </month> <year> 1990. </year>
Reference: [31] <author> Vern Paxson and Sally Floyd. </author> <title> Wide-area traffic: the failure of Poisson modeling. </title> <booktitle> In ACM SIGCOMM '94 Conference on Communications Architectures, Protocols and Applications, </booktitle> <address> London, UK, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: At the scale of tens of seconds, very pronounced bursts of activity can be seen; peak to average ratios of more than 5:1 are common. Many studies have explored the self-similarity of network traffic ([4], [16], [21], [22], [24], <ref> [31] </ref>), including web traffic [9]. Self-similarity implies burstiness at all timescale, which is not compatible with our observations. One indicator of self-similarity is a heavy-tailed interarrival process. As Figure 6 clearly shows, the interarrival time of GIF requests seen within the traces is exponentially distributed, and therefore not heavy tailed.
Reference: [32] <author> Margo I. Selzter. </author> <title> Issues and challenges facing the world wide web. </title> <note> Talk presented to Lotus Corporation, available at http://www.eecs.harvard.edu/margo/slides/ lotus.html, </note> <month> March </month> <year> 1997. </year>
Reference-contexts: 1 Introduction The recent explosive growth of the Internet <ref> [32] </ref> has resulted in a similar explosion of web-oriented middleware services ([15], [3], [6]). These middleware services, particularly the more popular services that experience extremely high load, must overcome a number of challenging system design issues in order to maintain fast response time, constant availability, and capacity.
Reference: [33] <author> David Wagner. </author> <title> Personal communications regarding the home ip trace anonymization. </title> <month> June </month> <year> 1997. </year> <month> 40 </month>
Reference-contexts: We also preserved filename extensions in URLs in order to deduce data type information. David Wagner <ref> [33] </ref> pointed out that if either the client or server population space is small, or if the hash digest size is small, then the hash function could be reversed through an exhaustive search.
Reference: [34] <author> Stephen Williams, Marc Abrams, Charles R. Standridge, Ghaleb Abdulla, and Ed-ward A. Fox. </author> <title> Removal policies in network caches for world-wide web documents. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <address> Stanford, CA, USA, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: Many papers have been written on the topic of web server and client trace analysis. In <ref> [34] </ref>, removal policies for network caches of WWW documents are explored, based in part on simulations driven by traces gathered from the Computer Science department of Virginia Tech. In [9], WWW traffic self-similarity is demonstrated and in part explained through analysis of the Boston University web client traces.
Reference: [35] <author> Roland Wooster, Stephen Williams, and Patrick Brooks. </author> <note> Httpdump network http packet snooper. available at http://ei.cs.vt.edu/ succeed/96httpdump/. </note>
Reference-contexts: Finally, an empirical model of HTTP network traffic and a simulator called INSANE is developed in [23] based on HTTP packet traces captured using the tcpdump tool. In <ref> [35] </ref>, a tool is described for the capture of HTTP packet traces. This tool, called HTTPDUMP, is implemented as a set of multithreaded C routines that communicated with a packet filter via a FIFO IPC mechanism.
References-found: 35

