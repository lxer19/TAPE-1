URL: ftp://ftp.idiap.ch/pub/papers/neural/thimm.gain.ps.Z
Refering-URL: http://www.idiap.ch/~perry/allpubs.html
Root-URL: http://www.idiap.ch/~perry/allpubs.html
Email: Thimm@IDIAP.CH  
Title: Reprint: The Interchangeability of Learning Rate and Gain in Backpropagation Neural Networks  
Author: Georg Thimm Perry Moerland Emile Fiesler 
Date: 8(2), Feb. 1996  
Note: Appeared in Neural Computation  IDIAP, CH-1920 Martigny, Switzerland, Electronic mail:  
Abstract: The backpropagation algorithm is widely used for training multilayer neural networks. In this publication the gain of its activation function(s) is investigated. In specific, it is proven that changing the gain of the activation function is equivalent to changing the learning rate and the weights. This simplifies the backpropagation learning rule by eliminating one of its parameters. The theorem can be extended to hold for some well-known variations on the backpropagation algorithm, such as using a momentum term, flat spot elimination, or adaptive gain. Furthermore, it is successfully applied to compensate for the non-standard gain of optical sigmoids for optical neural networks. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bachmann, C. M. </author> <year> 1990. </year> <title> Learning and Generalization in Neural Networks. </title> <type> PhD thesis, </type> <institution> Department of Physics, Brown University, Providence, RI, USA. </institution>
Reference: <author> Brown, M., </author> <title> An, P.C., </title> <editor> Harris, C.J., and Wang H. </editor> <year> 1993. </year> <title> How Biased is your Multi-Layer Perceptron. </title> <booktitle> World Congress on Neural Networks, </booktitle> <volume> 3, </volume> <pages> 507-511, </pages> <address> Portland, Oregon, USA. </address>
Reference: <author> Brown, M. and Harris, C. </author> <year> 1994. </year> <title> Neurofuzzy Adaptive Modelling and Control. Prentice Hall International Series in Systems and Control Engineering, </title> <editor> M. J. Grimble, ed., </editor> <publisher> Prentice Hall. </publisher> <address> ISBN: 0-13-134453-6. </address>
Reference: <author> Cho, T.-H., Conners, R. W., and Araman, P. A. </author> <year> 1991. </year> <title> Fast Back-Propagation Learning Using Steep Activation Functions and Automatic Weight Reinitialization. </title> <booktitle> Proceedings of the 1991 IEEE International Conference on Systems, Man, and Cybernetics: Decision Aiding for Complex Systems, </booktitle> <volume> 3, </volume> <pages> 1587-1592, </pages> <address> Charlottesville, USA. ISBN: 0-7803-0223-8. </address>
Reference: <author> Codrington, C., and Tenorio, M. </author> <year> 1994. </year> <title> Adaptive Gain Networks. </title> <booktitle> Proceedings of the IEEE International Conference on Neural Networks (ICNN94), </booktitle> <volume> 1, </volume> <pages> 339-344, </pages> <address> Orlando, Florida. </address> <publisher> IEEE Catalog Number 94CH3429-8. </publisher>
Reference: <author> Corwin, E., Logar, A., and Oldham, W. </author> <year> 1994. </year> <title> An Iterative Method for Training Multilayer Networks with Threshold Functions. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(3), </volume> <pages> 507-508. </pages>
Reference: <author> Fahlman, S. E. </author> <year> 1988. </year> <title> An Empirical Study of Learning Speed in Backpropagation Networks. </title> <type> Technical Report CMU-CS-88-162, </type> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh, PA. </institution> <note> Preprint: The Learning Rate and the Gain are Exchangeable 7 Fiesler, </note> <author> E. </author> <year> 1994. </year> <title> Neural Network Classification and Formalization. Computer Standards & Interfaces, special issue on Neural Network Standardization, Fulcher, </title> <editor> J., ed., </editor> <volume> 16(3), </volume> <pages> 231-239, </pages> <publisher> North-Holland / Elsevier Science Publishers, </publisher> <address> Amsterdam, The Netherlands. ISSN: </address> <pages> 0920-5489. </pages>
Reference-contexts: Momentum (Rumelhart et al. 1986): Theorem 1 holds when both networks have identical momentum terms. Batch or off-line learning: Theorem 1 holds without modification of the network parameters when off-line learning is used. Flat spot elimination <ref> (Fahlman 1988) </ref>: Theorem 1 holds if the constant c (0:1 in S. Fahlman's paper) added to the derivative in network N equals c=fi. Weight discretization with multiple thresholding of the real-valued weights (Fiesler et al. 1995) requires an adaptation of the threshold values for the weight discretization.
Reference: <author> Fiesler, E., Choudry, A., and Caulfield, H. J. </author> <year> 1995. </year> <title> A Universal Weight Discretization Method for Multi-Layer Neural Networks. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics (IEEE-SMC), </journal> <note> accepted for publication. </note>
Reference-contexts: It thus seems advisable to keep at a standard value of 1, and to control learning speed using solely the learning constant j ...". 1 See for example (Rumelhart et al. 1986) . 2 Note that gain and steepness are identical for activation functions with fl = 1 <ref> (Saxena and Fiesler 1995) </ref>. The term temperature is sometimes used as a synonym for the reciprocal of gain. 3 L. Wessels et al. use a weight initialization method which scales the initial weight range according to the gain of the activation function. 1 2 G. Thimm, P. Moerland, and E. <p> Flat spot elimination (Fahlman 1988): Theorem 1 holds if the constant c (0:1 in S. Fahlman's paper) added to the derivative in network N equals c=fi. Weight discretization with multiple thresholding of the real-valued weights <ref> (Fiesler et al. 1995) </ref> requires an adaptation of the threshold values for the weight discretization. If d and d are the discretization functions applied on the weights, theorem 1 holds if 8x : fid (x) = d (fix). <p> In the final stage of the training process the activation functions can be replaced by a threshold if this does not cause a degradation in performance. A major problem in using optical activation functions is their non-standard gain <ref> (Saxena and Fiesler 1995) </ref>. In figure 2, an optical activation function and its approximation by a shifted sigmoid, with a gain of approximately 1=24, are depicted. Note that the domain of the optical activation function is restricted to positive values due to constraints imposed by the optical implementation. <p> w `+1;j;k for layers 2 ` L1. (5) After the calculation of all error signals, the weights and biases are updated: w `;i;j := w `;i;j + j `;j ffi `;j a `1;i ; (6) where j `;j denotes the learning rate of neuron j in layer `. 4 See <ref> (Thimm and Fiesler 1995) </ref> for an in-depth study of weight initialization. Preprint: The Learning Rate and the Gain are Exchangeable 5 5. Convergence test If no convergence go to Pattern presentation.
Reference: <author> See also: Fiesler, E., Choudry, A., and Caulfield, H. J. </author> <year> 1990. </year> <title> A Weight Discretization paradigm for Optical Neural Networks. </title> <booktitle> Proceedings of the International Congress on Optical Science and Engineering, volume SPIE 1281, </booktitle> <pages> 164-173, </pages> <address> SPIE, Bellingham, Washington. ISBN: 0-8194-0328-8. </address>
Reference: <author> Izui, Y., and Pentland, A. </author> <year> 1990. </year> <title> Analysis of Neural Networks With Redundancy. </title> <journal> Neural Computation, </journal> <volume> 2, </volume> <pages> 226-238. </pages>
Reference-contexts: The theorem includes momentum and is related to <ref> (Izui and Pentland 1990) </ref> and (Sperduti and Starita 1993) by the authors.
Reference: <author> Jia, Q., Hagiwara, K., Toda, N. and Usui, S. </author> <year> 1994. </year> <title> Equivalence Relation Between the Backpropagation Learning Process of an FNN and That of an FNNG, </title> <booktitle> Neural Networks, </booktitle> <volume> 7(2), 411, </volume> <publisher> Pergamon Press. </publisher>
Reference-contexts: holds on account of the induction hypothesis fi `+1;j ffi `+1;j = ffi `+1;j .2 An induction over the number of pattern presentations, using these lemmas, concludes the proof of theorem 1. 2 Addendum For completeness the authors would like to include the reference to a letter in Neural Networks <ref> (Jia et al. 1994) </ref>, that was brought to their attention after the submission of this paper to Neural Computation, in which a similar theorem is presented, albeit without proof or applications. The theorem includes momentum and is related to (Izui and Pentland 1990) and (Sperduti and Starita 1993) by the authors.
Reference: <author> Kruschke, J. K., and Movellan, J. R. </author> <year> 1991. </year> <title> Benefits of Gain: Speeded Learning and Minimal Hidden Layers in Backpropagation Networks. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 21(1), </volume> <pages> 273-280. </pages>
Reference: <author> Mundie, D. B., and Massengill, L. W. </author> <year> 1992. </year> <title> Threshold Non-Linearity Effects on Weight-Decay Tolerance in Analog Neural Networks. </title> <booktitle> Proceedings of the International Joint Conference on Neural Networks (IJCNN92), </booktitle> <volume> 2, </volume> <pages> 583-587, </pages> <address> Baltimore, MD, USA. ISBN: 0-7803-0559-0. </address>
Reference: <author> Plaut, D., Nowlan, S., and Hinton, G. </author> <year> 1986. </year> <title> Experiments on Learning by Back Propagation. </title> <type> Technical report CMU-CS-86-126, </type> <institution> Carnegie-Mellon University, Pittsburgh, USA. </institution>
Reference: <author> Rumelhart, D., Hinton, G., and Williams, R. </author> <year> 1986. </year> <title> Learning Internal Representations by Error Propagation. Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </title> <booktitle> 1: Foundations, </booktitle> <pages> 318-362, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. ISBN: 0-262-18210-7. </address>
Reference-contexts: It thus seems advisable to keep at a standard value of 1, and to control learning speed using solely the learning constant j ...". 1 See for example <ref> (Rumelhart et al. 1986) </ref> . 2 Note that gain and steepness are identical for activation functions with fl = 1 (Saxena and Fiesler 1995). The term temperature is sometimes used as a synonym for the reciprocal of gain. 3 L. <p> A list of common variations and their interdependence with theorem 1 is presented here. The corresponding proofs are omitted, as they are analogous to the proof of theorem 1. Preprint: The Learning Rate and the Gain are Exchangeable 3 1.0 -50 0 50 100 200 300 line). Momentum <ref> (Rumelhart et al. 1986) </ref>: Theorem 1 holds when both networks have identical momentum terms. Batch or off-line learning: Theorem 1 holds without modification of the network parameters when off-line learning is used. Flat spot elimination (Fahlman 1988): Theorem 1 holds if the constant c (0:1 in S. <p> One can compensate for their non-standard gain by modifying the learning rate and initial weight according to the theorem to optimize the performance of the neural network. Appendix Before proving theorem 1 a generalization of the on-line backpropagation learning rule <ref> (Rumelhart et al. 1986) </ref> is described, in which every neuron has its own (local) learning rate and activation function. The standard case of a unique learning rate and activation function corresponds to all local learning rates and activation functions being equal for the whole network.
Reference: <author> Saxena, I., and Fiesler, E. </author> <year> 1995. </year> <title> Adaptive Multilayer Optical Neural Network with Optical Thresholding. Invited paper for Optical Engineering, special on Optics in Switzerland, Rastogi, </title> <editor> P., ed. </editor> <address> ISSN: 0091-3286, </address> <publisher> in press. </publisher>
Reference-contexts: It thus seems advisable to keep at a standard value of 1, and to control learning speed using solely the learning constant j ...". 1 See for example (Rumelhart et al. 1986) . 2 Note that gain and steepness are identical for activation functions with fl = 1 <ref> (Saxena and Fiesler 1995) </ref>. The term temperature is sometimes used as a synonym for the reciprocal of gain. 3 L. Wessels et al. use a weight initialization method which scales the initial weight range according to the gain of the activation function. 1 2 G. Thimm, P. Moerland, and E. <p> In the final stage of the training process the activation functions can be replaced by a threshold if this does not cause a degradation in performance. A major problem in using optical activation functions is their non-standard gain <ref> (Saxena and Fiesler 1995) </ref>. In figure 2, an optical activation function and its approximation by a shifted sigmoid, with a gain of approximately 1=24, are depicted. Note that the domain of the optical activation function is restricted to positive values due to constraints imposed by the optical implementation.
Reference: <author> Sperduti, A., and Starita, A. </author> <year> 1993. </year> <title> Speed Up Learning and Network Optimization with Extended Backpropagation. </title> <booktitle> Neural Networks, </booktitle> <volume> 6, </volume> <pages> 365-383, </pages> <publisher> Pergamon Press. </publisher>
Reference-contexts: The theorem includes momentum and is related to (Izui and Pentland 1990) and <ref> (Sperduti and Starita 1993) </ref> by the authors.
Reference: <author> Thimm, G., and Fiesler, E. </author> <year> 1995. </year> <title> Weight Initialization for High Order and Multilayer Perceptrons. </title> <journal> IEEE Transactions on Neural Networks, </journal> <note> submitted. </note>
Reference-contexts: w `+1;j;k for layers 2 ` L1. (5) After the calculation of all error signals, the weights and biases are updated: w `;i;j := w `;i;j + j `;j ffi `;j a `1;i ; (6) where j `;j denotes the learning rate of neuron j in layer `. 4 See <ref> (Thimm and Fiesler 1995) </ref> for an in-depth study of weight initialization. Preprint: The Learning Rate and the Gain are Exchangeable 5 5. Convergence test If no convergence go to Pattern presentation.
Reference: <author> See also: Thimm, G., and Fiesler, E. </author> <year> 1994. </year> <title> Weight Initialization for High Order and Multilayer Perceptrons. </title> <booktitle> Proceedings of the '94 SIPAR-Workshop on Parallel and Distributed Computing, </booktitle> <editor> Aguilar, M., ed., </editor> <address> 91-94, </address> <institution> Institute of Informatics, University Perolles, Chemin du Musee 3, Fribourg, Switzerland. SI Group for Parallel Systems. </institution>
Reference: <author> Wessels, L. F. A., and Barnard, E. </author> <year> 1992. </year> <title> Avoiding false local minima by proper initialization of connections. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3, </volume> <pages> 899-905. </pages>
Reference: <author> Yu, X., Loh, N., and Miller, W. </author> <year> 1994. </year> <title> Training Hard-Limiting Neurons Using Back-Propagation Algorithm by Updating Steepness Factors. </title> <booktitle> Proceedings of the IEEE International Conference on Neural Networks (ICNN94), </booktitle> <volume> 1, </volume> <pages> 526-530, </pages> <address> Orlando, Florida, </address> <publisher> IEEE Catalog Number 94CH3429-8. </publisher>
Reference: <author> Zurada, J. M. </author> <year> 1992. </year> <title> Introduction to Artificial Neural Systems. </title> <publisher> West Publishing Company. </publisher> <address> ISBN: 0-314-93391-3. </address>
References-found: 22

