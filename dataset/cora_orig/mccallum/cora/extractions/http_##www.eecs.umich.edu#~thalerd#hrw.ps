URL: http://www.eecs.umich.edu/~thalerd/hrw.ps
Refering-URL: http://www.eecs.umich.edu/~thalerd/docs.html
Root-URL: http://www.cs.umich.edu
Email: thalerd@eecs.umich.edu ravi@eecs.umich.edu  
Title: Using Name-Based Mappings to Increase Hit Rates multicast routing protocols PIMv2 and CBTv2 as its
Author: David G. Thaler and Chinya V. Ravishankar 
Note: HRW has now been adopted by the  
Address: Ann Arbor, Michigan 48109-2122  
Affiliation: Electrical Engineering and Computer Science Department The University of Michigan,  
Abstract: Clusters of identical intermediate servers are often created to improve availability and robustness in many domains. The use of proxy servers for the WWW and of Rendezvous Points in multicast routing are two such situations. However, this approach can be inefficient if identical requests are received and processed by multiple servers. We present an analysis of this problem, and develop a method called the Highest Random Weight (HRW) Mapping that eliminates these difficulties. Given an object name and a set of servers, HRW maps a request to a server using the object name, rather than any a priori knowledge of server states. Since HRW always maps a given object name to the same server within a given cluster, it may be used locally at client sites to achieve consensus on object-server mappings. We present an analysis of HRW and validate it with simulation results showing that it gives faster service times than traditional request allocation schemes such as round-robin or least-loaded, and adapts well to changes in the set of servers. HRW is particularly applicable to domains in which there are a large number of requestable objects, there is a significant probability that a requested object will be requested again, and the CPU load due to any single object can be handled by a single server. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Tony Ballardie, Paul Francis, and Jon Crowcroft. </author> <title> An architecture for scalable inter-domain multicast routing. </title> <booktitle> In Proceedings of the ACM SIGCOMM, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: That is, the CPU load due to any single object can be handled by a single server. The above characteristics cover a wide variety of do mains. Some examples include: Real-time producer-consumer systems For example, in multicast routing protocols such as CBT <ref> [1] </ref> and PIM [2], receivers' routers request data for a specific session by sending a join request towards the root of a distribution tree for that session, and sources send data to a session via the root of its tree. <p> (d) Sequential D (k), Sequential S i gating other weight functions was not necessary. 7 Case Studies To show how HRW applies to a variety of domains, we now examine two applications in more detail. 7.1 Shared-Tree Multicast Routing In shared-tree multicast routing protocols such as PIM [2] and CBT <ref> [1] </ref>, receivers' routers request packets for a specific session by sending a "join session" request toward the root of a distribution tree for that session. Sources send data to a session by sending it toward the root of its tree.
Reference: [2] <author> Stephen Deering, Deborah Estrin, Dino Farinacci, Van Ja-cobson, Ching-Gung Liu, and Liming Wei. </author> <title> An architecture for wide-area multicast routing. </title> <booktitle> In Proceedings of the ACM SIGCOMM, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: That is, the CPU load due to any single object can be handled by a single server. The above characteristics cover a wide variety of do mains. Some examples include: Real-time producer-consumer systems For example, in multicast routing protocols such as CBT [1] and PIM <ref> [2] </ref>, receivers' routers request data for a specific session by sending a join request towards the root of a distribution tree for that session, and sources send data to a session via the root of its tree. <p> Sequential S i (d) Sequential D (k), Sequential S i gating other weight functions was not necessary. 7 Case Studies To show how HRW applies to a variety of domains, we now examine two applications in more detail. 7.1 Shared-Tree Multicast Routing In shared-tree multicast routing protocols such as PIM <ref> [2] </ref> and CBT [1], receivers' routers request packets for a specific session by sending a "join session" request toward the root of a distribution tree for that session. Sources send data to a session by sending it toward the root of its tree. <p> The conditions of Corollary 1 are thus satisfied, and the situation is ideal for the use of HRW. We focus on Sparse-Mode PIM in particular, since its evolution illustrates many of the concepts and goals discussed in Section 3. The original description of PIMv1 <ref> [2] </ref> did not specify any mapping algorithm for assigning join requests to servers. Since replication was not prevented, providers sent session data to all servers in a cluster. This resulted in undesirable complexity and resource consumption.
Reference: [3] <author> James Gwertzman and Margo Seltzer. </author> <title> World-wide web cache consistency. </title> <booktitle> In Proceedings of the 1996 USENIX Technical Conference, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: The root thus takes on the role of a server, with receivers and sources becoming clients. Sources and receivers must rendezvous at the root for effective data transfer. Client-side WWW proxy caches In the World Wide Web (WWW), pages can be cached at proxy servers <ref> [3, 4] </ref>. All outbound client requests can then go through a local proxy server. If the proxy server has the page cached, the page is returned to the client without accessing the remote provider. Otherwise, the page is retrieved and cached for future use. <p> One solution to this problem is to cache web pages at HTTP proxies <ref> [3, 4, 24] </ref>. Client requests then go through a local proxy server. If the proxy server has the page cached, the page is returned to the client without accessing the remote server. Otherwise, the page is retrieved and cached for future use.
Reference: [4] <author> C. Mic Bowman, Peter B. Danzig, Darren R. Hardy, Udi Manber, and Michael F. Schwartz. </author> <title> The Harvest information discovery and access system. </title> <booktitle> Proceedings of the Second International World Wide Web Conference, </booktitle> <pages> pages 763-771, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: The root thus takes on the role of a server, with receivers and sources becoming clients. Sources and receivers must rendezvous at the root for effective data transfer. Client-side WWW proxy caches In the World Wide Web (WWW), pages can be cached at proxy servers <ref> [3, 4] </ref>. All outbound client requests can then go through a local proxy server. If the proxy server has the page cached, the page is returned to the client without accessing the remote provider. Otherwise, the page is retrieved and cached for future use. <p> Thus, f t (i) = (response time for S i ). When all servers are equally distant, this mapping is similar to the least-loaded scheme (with the same advantages and disadvantages), since the server with the least load typically responds first. The Harvest <ref> [4] </ref> web cache implementation and the Andrew File System (AFS) [14] both use this method. 3.4 Round-Robin Mapping A simpler scheme is round-robin, where successive requests are sent to consecutive servers. <p> One solution to this problem is to cache web pages at HTTP proxies <ref> [3, 4, 24] </ref>. Client requests then go through a local proxy server. If the proxy server has the page cached, the page is returned to the client without accessing the remote server. Otherwise, the page is retrieved and cached for future use.
Reference: [5] <author> Mark S. Squillante and Edward D. Lazowska. </author> <title> Using processor-cache affinity information in shared-memory multiprocessor scheduling. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(2) </volume> <pages> 131-143, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: We will refer to this concept as a "name-based" mapping. It is possible to view the case where all clients send requests for the same object to the same server as defining affinities between objects and servers in a cluster (Figure 1). A number of studies (e.g., <ref> [5, 6, 7] </ref>) have examined the related notion of "cache-affinity" scheduling in the context of shared-memory multiprocessors, in which tasks are sent to processors which already have data cached. This achieves higher cache hit rates at the possible expense of load balancing.
Reference: [6] <author> Raj Vaswani and John Zahorjan. </author> <title> The implications of cache affinity on processor scheduling for multiprogrammed, shared memory multiprocessors. </title> <booktitle> In Proc. 13th Symp. Operating Syst. Principles, </booktitle> <pages> pages 26-40, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: We will refer to this concept as a "name-based" mapping. It is possible to view the case where all clients send requests for the same object to the same server as defining affinities between objects and servers in a cluster (Figure 1). A number of studies (e.g., <ref> [5, 6, 7] </ref>) have examined the related notion of "cache-affinity" scheduling in the context of shared-memory multiprocessors, in which tasks are sent to processors which already have data cached. This achieves higher cache hit rates at the possible expense of load balancing.
Reference: [7] <author> James D. Salehi, James F. Kurose, and Don Towsley. </author> <title> The effectiveness of affinity-based scheduling in multiprocessor network protocol processing (extended version). </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 4(4) </volume> <pages> 516-530, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: We will refer to this concept as a "name-based" mapping. It is possible to view the case where all clients send requests for the same object to the same server as defining affinities between objects and servers in a cluster (Figure 1). A number of studies (e.g., <ref> [5, 6, 7] </ref>) have examined the related notion of "cache-affinity" scheduling in the context of shared-memory multiprocessors, in which tasks are sent to processors which already have data cached. This achieves higher cache hit rates at the possible expense of load balancing.
Reference: [8] <author> Vern Paxson and Sally Floyd. </author> <title> Wide-area traffic: The failure of poisson modeling. </title> <booktitle> In Proceedings of the ACM SIG-COMM, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: To ensure that this goal is realized, one must first define what load balancing means, and consider how loads are generated. It is well-known (e.g., <ref> [8] </ref>) that patterns of requests can be very bursty when the request stream includes machine-initiated requests, so that the arrival process of requests is not, in general, Poisson.
Reference: [9] <author> Raj Jain and Shawn A. Routhier. </author> <title> Packet trains measurements and a new model for computer network traffic. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 4(6) </volume> <pages> 986-995, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: It is well-known (e.g., [8]) that patterns of requests can be very bursty when the request stream includes machine-initiated requests, so that the arrival process of requests is not, in general, Poisson. The Packet Train <ref> [9] </ref> model is a widely-used alternative to the traditional Poisson arrival model, and appears to model such request patterns well. We therefore adopt this model, and assume that requests arrive in batches, or "trains". <p> We now demonstrate formally that round-robin achieves load balancing when the request rate is high. As discussed earlier, we will use the packet-train model <ref> [9] </ref> for our analysis. Let N be the number of requests in the batch or train. Let r be a random variable describing the service time for one request.
Reference: [10] <author> Marek Fisz. </author> <title> Probability Theory and Mathematical Statistics. </title> <publisher> John Wiley & sons, Inc., </publisher> <year> 1963. </year>
Reference-contexts: The distribution of l i is approximately normal with mean k and variance k 2 as N ! 1. Proof: The result follows immediately from the Central-Limit Theorem. See any standard book dealing with sampling theory, <ref> [10] </ref>, for example. fl Hence, for sufficiently large packet train sizes, loads on all servers are normally distributed. We will now show that loads in a server cluster become balanced if the coefficient of variation (ratio of mean to standard deviation) of the load distribution on servers tends to zero. <p> Proof: Let l be the sample mean, and let y i = l i l. By the usual definition of sample variance, we have (m 1)s 2 y 1 2 y m 2 The sum on the right side follows the 2 distribu-tion <ref> [10] </ref> with m 1 degrees of freedom 1 . Thus, we may write s 2 = 2 [ 2 m1 =(m 1)]. Therefore, (s=) 2 = (=) 2 [ 2 m1 =(m 1)]. <p> We know from sampling theory <ref> [10] </ref> that E [ p i ] = p = 1=K, so E [q i ] = k p = (K=m)(1=K) = (1=m) (11) We also know from sampling theory [10] that V ar [ p i ] = (K k)( 2 p =k)=(K 1). <p> We know from sampling theory <ref> [10] </ref> that E [ p i ] = p = 1=K, so E [q i ] = k p = (K=m)(1=K) = (1=m) (11) We also know from sampling theory [10] that V ar [ p i ] = (K k)( 2 p =k)=(K 1).
Reference: [11] <author> Peter B. Danzig, Richard S. Hall, and Michael F. Schwartz. </author> <title> A case for caching file objects inside internetworks. </title> <type> Technical Report CU-CS-642-93, </type> <institution> University of Colorado, Boulder, </institution> <month> March </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: The last of these options may be viewed as defining affinities between objects and servers. Replication can also reduce hit rates in caching schemes by decreasing the effective cache size of the servers in the cluster. For example, a study conducted in 1992 <ref> [11] </ref> reported that a 4 GB cache was necessary for intermediaries to achieve a cache hit rate of 45% for FTP transfers.
Reference: [12] <author> Cisco Systems. </author> <title> Scaling the world wide web. </title> <note> Available from http://cio.cisco.com/warp/public/751/advtg/swww wp.htm. </note>
Reference-contexts: In the worst case, all clients issue requests to the same, previously idle, server, resulting in a very high load. Minimum-Load Mapping is, however, the approach taken in many existing systems. For example, Cisco's Lo-calDirector <ref> [12] </ref>, which redirects WWW requests to one of a set of local servers, periodically queries the servers for status information, thus potentially using out-of-date information.
Reference: [13] <author> Reid G. Smith. </author> <title> The Contract Net protocol: High-level communication and control in a distributed problem solver. </title> <journal> ACM Transactions on Computers, </journal> <pages> pages 1104-1113, </pages> <month> De-cember </month> <year> 1980. </year>
Reference-contexts: Minimum-Load Mapping is, however, the approach taken in many existing systems. For example, Cisco's Lo-calDirector [12], which redirects WWW requests to one of a set of local servers, periodically queries the servers for status information, thus potentially using out-of-date information. In the Contract Net protocol <ref> [13] </ref>, servers are 5 queried for load information when a request is ready, in-troducing additional latency. 3.3 Fastest-Response Mapping In the fastest-response scheme, a client pings the servers, and picks the one that responds first. Thus, f t (i) = (response time for S i ).
Reference: [14] <author> Mahadev Satyanarayanan. </author> <title> Scalable, secure, and highly available distributed file access. </title> <journal> IEEE Computer, </journal> <volume> 23(5) </volume> <pages> 9-21, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: When all servers are equally distant, this mapping is similar to the least-loaded scheme (with the same advantages and disadvantages), since the server with the least load typically responds first. The Harvest [4] web cache implementation and the Andrew File System (AFS) <ref> [14] </ref> both use this method. 3.4 Round-Robin Mapping A simpler scheme is round-robin, where successive requests are sent to consecutive servers. For example, when a name in the Domain Name Service (DNS) resolves to multiple IP addresses, DNS returns this list of IP addresses, rotated circularly after each request. <p> rate increases (i.e., when large batches of requests arrive within a short period of time). 3.5 Random Mapping Another way to balance the expected number of requests assigned to each server, is to send requests to a server chosen at random (e.g., f (i) = random ()), as suggested in <ref> [14] </ref>. This is referred to in queueing theory as a random split. As before, let N be the number of requests in the batch or train. Let r be a random variable describing the service time for one request.
Reference: [15] <author> T. Brisco. </author> <title> DNS support for load balancing, </title> <month> April </month> <year> 1995. </year> <month> RFC-1794. </month>
Reference-contexts: If clients use the first address on this list, requests will be sent to the various IP addresses in round-robin fashion 2 , thereby balancing the number of requests sent to each <ref> [15] </ref>. The NCSA scalable web server configuration [16] is one example of such use of DNS. When all servers are up, a true Round-Robin scheme maps the n th request sent to the cluster to the n th server (modulo m). Thus, F (r n ) = n (mod m).
Reference: [16] <author> Eric Katz, Michelle Butler, and Robert McGrath. </author> <title> A scalable HTTP server: The NCSA prototype. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 27 </volume> <pages> 155-164, </pages> <year> 1994. </year>
Reference-contexts: If clients use the first address on this list, requests will be sent to the various IP addresses in round-robin fashion 2 , thereby balancing the number of requests sent to each [15]. The NCSA scalable web server configuration <ref> [16] </ref> is one example of such use of DNS. When all servers are up, a true Round-Robin scheme maps the n th request sent to the cluster to the n th server (modulo m). Thus, F (r n ) = n (mod m).
Reference: [17] <author> Estrin, Farinacci, Helmy, Thaler, Deering, Handley, Ja-cobson, Liu, Sharma, and Wei. </author> <title> Protocol independent multicast-sparse mode (PIM-SM): Specification. </title> <type> Internet Draft, </type> <month> September </month> <year> 1996. </year>
Reference-contexts: Therefore, the output of such a hash function must be an ordered list of servers rather than a single server name. In some domains, such as PIMv2 <ref> [17] </ref>, the list of servers is dynamically updated to exclude unreachable servers. In this case, it suffices for the hash function to map a name to a single server. <p> HRW has already been applied to multicast routing, where it has been recently incorporated by both the PIM <ref> [17] </ref> and CBT [31] protocols. HRW is also applicable to the World Wide Web. WWW clients could improve response time by using HRW to select servers in a cluster, rather than simply using the order presented by DNS.
Reference: [18] <author> D. Estrin, A. Helmy, P. Huang, and D. Thaler. </author> <title> A dynamic bootstrap mechanism for rendezvous-based multicast routing. </title> <note> Submitted to ACM/IEEE Transactions on Networking. </note>
Reference-contexts: Again, we assume that the server list is known to clients a priori. For example, it may be statically configured, resolved at client startup time, or periodically distributed to clients. See <ref> [18] </ref> for further discussion of these issues. 5.4 Minimal disruption When a server S i goes down, all objects which mapped to that server must be reassigned. All other objects will be unaffected, and so the optimum disruption bound is achieved. <p> Low latency is also important to receivers who want to join a session in progress. One example motivating the low latency requirement is known as the "bursty-source problem" <ref> [18] </ref>, where a source periodically sends a burst of data, and then remains silent for a long time. An example is an application which broadcasts its current state once a day.
Reference: [19] <author> Donald E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> volume 1. </volume> <publisher> Addison-Wesley, </publisher> <address> 2nd edition, </address> <year> 1973. </year>
Reference-contexts: After changing the summation index appropriately, this reduces to E [p] = m i=1 i It is well-known (see <ref> [19] </ref>, for example) that m X 1 = ln m + fl + 2m Substituting above, the theorem follows. fl It is clear that full replication is achieved rather quickly. With 10 servers in a cluster, the expected number of requests to reach full replication is about 30.
Reference: [20] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and intractability: A guide to the theory of NP-completeness, </title> <month> June </month> <year> 1988. </year>
Reference-contexts: Thus, the optimal set of objects to cache at time t in a cache of size C maximizes P k2C p k (t), subject to the constraint that P k2C s k C. This is an instance of the Knapsack problem, which is known to be NP-complete <ref> [20] </ref>. Cache replacement strategies can then be viewed as heuristics to solve this problem. Since the future is unknown, they must use local estimates of the p k (t)'s based on statistics such as recency or frequency of reference, typically deriving them from past history.
Reference: [21] <author> Ivan Niven, Herbert S. Zuckerman, and Hugh L. Mont-gomery. </author> <title> An Introduction to the Theory of Numbers. </title> <publisher> John Wiley & sons, Inc., </publisher> <address> 5th edition, </address> <year> 1991. </year>
Reference-contexts: Then, since modulo-2 31 congruence is pre served under subtraction: A ((AS i + B) XOR D (k)) where A = 1103515245, B = 12345. But A and 2 31 are rel atively prime, so a standard result from number theory <ref> [21] </ref> tells us that we may cancel A, leaving us with: (AS i + B) XOR D (k) (AS j + B) XOR D (k) (mod 2 31 ) 3 Since rand is no longer the same on all platforms, implementa tions should use Equation 16 directly. 4 E.g., 7 on
Reference: [22] <author> Stephen K. Park and Keith W. Miller. </author> <title> Random number generators: Good ones are hard to find. </title> <journal> CACM, </journal> <volume> 31(10) </volume> <pages> 1192-1201, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: The first competing weight function we consider is based on the Unix system functions random and srandom in place of rand and srand, resulting in a weight function we denote W random 5 . The second function we consider uses the Minimal Standard random number generator <ref> [22, 23] </ref>, resulting in the weight function: W minstd (k; S i ) = (16807 ((16807 S i ) XOR D (k))) (mod (2 31 1)) Our third alternative is to modify the W rand function as follows: W rand2 (k; S i ) = (1103515245 ((1103515245 D (k) +12345) XOR <p> The choice of which is most appropriate for use with HRW depends on the characteristics of the domain of use. Finally, while we could have simulated many other types of pseudo-random functions, we note that finding a good pseudo-random function is hard <ref> [22] </ref>.
Reference: [23] <author> David G. Carta. </author> <title> Two fast implementations of the "minimal standard" random number generator. </title> <journal> CACM, </journal> <volume> 33(1), </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: The first competing weight function we consider is based on the Unix system functions random and srandom in place of rand and srand, resulting in a weight function we denote W random 5 . The second function we consider uses the Minimal Standard random number generator <ref> [22, 23] </ref>, resulting in the weight function: W minstd (k; S i ) = (16807 ((16807 S i ) XOR D (k))) (mod (2 31 1)) Our third alternative is to modify the W rand function as follows: W rand2 (k; S i ) = (1103515245 ((1103515245 D (k) +12345) XOR
Reference: [24] <author> Stephen Williams, Marc Abrams, Charles R. Standridge, Ghaleb Abdulla, and Edward A. Fox. </author> <title> Removal policies in network caches for world-wide web documents. </title> <booktitle> In Proceedings of ACM SIGCOMM'96, </booktitle> <pages> pages 293-305, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: One solution to this problem is to cache web pages at HTTP proxies <ref> [3, 4, 24] </ref>. Client requests then go through a local proxy server. If the proxy server has the page cached, the page is returned to the client without accessing the remote server. Otherwise, the page is retrieved and cached for future use.
Reference: [25] <author> Marc Abrams, Charles R. Standridge, Ghaleb Abdulla, Stephen Willians, and Edward A. Fox. </author> <title> Caching proxies: Limitations and potentials. </title> <booktitle> Proc. 4th International WorldWide Web Conference, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: Client requests then go through a local proxy server. If the proxy server has the page cached, the page is returned to the client without accessing the remote server. Otherwise, the page is retrieved and cached for future use. Various studies (e.g., <ref> [25, 26] </ref>) have found that a cache hit rate of up to 50% can be achieved. Thus, since the number of possible objects is large, and a significant concentration of requests exists, the conditions are appropriate for HRW. <p> Table 2 shows the characterization of the resulting data set used for 15 simulation. Note that about 50% of the URLs requested were unique, giving an upper bound on the cache hit rate of around 50%, which agrees with the bound observed by <ref> [25] </ref> and [26].
Reference: [26] <author> Steven Glassman. </author> <title> A caching relay for the world wide web. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 27(2), </volume> <month> November </month> <year> 1994. </year>
Reference-contexts: Client requests then go through a local proxy server. If the proxy server has the page cached, the page is returned to the client without accessing the remote server. Otherwise, the page is retrieved and cached for future use. Various studies (e.g., <ref> [25, 26] </ref>) have found that a cache hit rate of up to 50% can be achieved. Thus, since the number of possible objects is large, and a significant concentration of requests exists, the conditions are appropriate for HRW. <p> Table 2 shows the characterization of the resulting data set used for 15 simulation. Note that about 50% of the URLs requested were unique, giving an upper bound on the cache hit rate of around 50%, which agrees with the bound observed by [25] and <ref> [26] </ref>. <p> That is, when there is enough space at all servers combined to hold an object, but not at any single server, HRW must evict an object from a cache. requested object (which was zero if the object was cached). By comparison, Glassman <ref> [26] </ref> found the average response time t MISS seen by a client for an uncached page to be between 6 and 9 seconds, compared with t HIT = 1:5 seconds for a cached page, using a Digital Web relay.
Reference: [27] <institution> Netscape Communications Corp. </institution> <note> Netscape Navigator software. Available from http://www.netscape.com. </note>
Reference-contexts: Various studies (e.g., [25, 26]) have found that a cache hit rate of up to 50% can be achieved. Thus, since the number of possible objects is large, and a significant concentration of requests exists, the conditions are appropriate for HRW. Popular WWW browsers such as Netscape Navigator <ref> [27] </ref>, NCSA Mosaic, and lynx, now allow specifying one or more proxy servers through which requests for remote objects are sent. A single proxy, however, does not provide any fault tolerance. For a robust deployment, multiple proxies are required.
Reference: [28] <author> Carlos R. Cunha, Azer Bestavros, and Mark E. Crovella. </author> <title> Characteristics of WWW client-based traces. </title> <type> Technical Report BU-CS-95-010, </type> <institution> Boston University, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: This will allow the terminology to apply to the more general problem. In the following simulations, the objects and object sizes are taken from the publicly-available WWW client-based traces described in <ref> [28] </ref>, where all URLs accessed from 37 workstations at Boston University were logged over a period of five months.
Reference: [29] <author> Mark R. Nelson. </author> <title> File verification using CRC. </title> <journal> Dr. Dobb's Journal, </journal> <month> May </month> <year> 1992. </year>
Reference-contexts: Gbytes Table 2: Trace Summary Since a unique object name k can, in general, have arbitrary length, and we wish to obtain a digest with which we can do 32-bit arithmetic, our simulation defined D (k) to be the 31-bit digest of the object name obtained by computing its CRC-32 <ref> [29] </ref> checksum and discarding the most significant bit. 7.2.1 Simulation Our simulator implemented HRW, a round-robin scheme, and a random allocation scheme. In a fourth scheme, similar to least-loaded allocation, a request was sent to the server with the least number of objects currently being serviced (with ties broken randomly).
Reference: [30] <author> Donald Neal. </author> <title> The Harvest object cache in New Zealand. </title> <booktitle> In Fifth International World Wide Web Conference, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: The line shown is based on the ratio of HRW's latency to that seen by Random. We expect the improvement to be much more pronounced for sites with low bandwidth connectivity to 16 the outside world, such as New Zealand <ref> [30] </ref>, since t MISS will rise while t HIT remains constant. no limit exists on cache space. Again, since we assume that no objects are invalidated during the lifetime of the simulation, no time-based expirations were simulated, and hence no objects were evicted from any cache.
Reference: [31] <author> A. Ballardie. </author> <title> Core based trees (CBT version 2) multicast routing: Protocol specification. </title> <type> Internet Draft, </type> <month> May </month> <year> 1997. </year> <month> 19 </month>
Reference-contexts: HRW has already been applied to multicast routing, where it has been recently incorporated by both the PIM [17] and CBT <ref> [31] </ref> protocols. HRW is also applicable to the World Wide Web. WWW clients could improve response time by using HRW to select servers in a cluster, rather than simply using the order presented by DNS.
References-found: 31

