URL: http://www.cs.toronto.edu/~mackay/erice.ps.gz
Refering-URL: http://www.cs.toronto.edu/~mackay/README.html
Root-URL: http://www.cs.toronto.edu
Title: INTRODUCTION TO MONTE CARLO METHODS of Monte Carlo methods, theorems and proofs and a full
Author: D.J.C. MACKAY Neal (), Gilks, Richardson 
Note: For details  and Spiegelhalter (1996), and Tanner (1996).  
Address: Madingley Road, Cambridge, CB3 0HE. United Kingdom.  
Affiliation: Department of Physics, Cambridge University. Cavendish Laboratory,  
Abstract: This chapter describes a sequence of Monte Carlo methods: importance sampling, rejection sampling, the Metropolis method, and Gibbs sampling. For each method, we discuss whether the method is expected to be useful for high-dimensional problems such as arise in inference with graphical models. After the methods have been described, the terminology of Markov chain Monte Carlo methods is presented. The chapter concludes with a discussion of advanced methods, including methods for reducing random walk behaviour. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Adler, S. L.: </author> <year> 1981, </year> <title> Over-relaxation method for the Monte-Carlo evaluation of the partition function for multiquadratic actions, </title> <journal> Physical Review D-Particles and Fields 23(12), </journal> <pages> 2901-2904. </pages>
Reference: <author> Cowles, M. K. and Carlin, B. P.: </author> <year> 1996, </year> <title> Markov-chain Monte-Carlo convergence diagnostics | a comparative review, </title> <journal> Journal of the American Statistical Association 91(434), </journal> <pages> 883-904. </pages>
Reference-contexts: Can we diagnose or detect convergence in a running simulation? This is also a difficult problem. There are a few practical tools available, but none of them is perfect <ref> (Cowles and Carlin 1996) </ref>. Can we speed up the convergence time and time between independent samples of a Markov chain Monte Carlo method? Here, there is good news. 7.1. SPEEDING UP MONTE CARLO METHODS 7.1.1.
Reference: <author> Gilks, W. and Wild, P.: </author> <year> 1992, </year> <title> Adaptive rejection sampling for Gibbs sampling, </title> <journal> Applied Statistics 41, </journal> <pages> 337-348. </pages>
Reference-contexts: For many graphical models (but not all) these one-dimensional conditional distributions are straightforward to sample from. Conditional distributions that are not of standard form may still be sampled from by adaptive rejection sampling if the conditional distribution satisfies certain convexity properties <ref> (Gilks and Wild 1992) </ref>. Gibbs sampling is illustrated for a case with two variables (x 1 ; x 2 ) = x in figure 9. <p> An excellent software package, BUGS, is available which makes it easy to set up almost arbitrary probabilistic models and simulate them by Gibbs sampling <ref> (Thomas, Spiegelhalter and Gilks 1992) </ref>. 6. Terminology for Markov chain Monte Carlo methods We now spend a few moments sketching the theory on which the Metropolis method and Gibbs sampling are based.
Reference: <author> Gilks, W. R., Richardson, S. and Spiegelhalter, D. J.: </author> <year> 1996, </year> <title> Markov Chain Monte Carlo in Practice, </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Green, P. J.: </author> <year> 1995, </year> <title> Reversible jump Markov chain Monte Carlo computation and Bayesian model determination, </title> <journal> Biometrika 82, </journal> <pages> 711-732. </pages>
Reference-contexts: Techniques for evaluating Z include: 1. Importance sampling (reviewed by Neal (1993)). 2. `Thermodynamic integration' during simulated annealing, the `accep tance ratio' method, and `umbrella sampling' (reviewed by Neal (1993)). 3. `Reversible jump Markov chain Monte Carlo' <ref> (Green 1995) </ref>. Perhaps the best way of dealing with Z, however, is to find a solution to one's task that does not require that Z be evaluated.
Reference: <author> Marinari, E. and Parisi, G.: </author> <year> 1992, </year> <title> Simulated tempering anew Monte-Carlo scheme, </title> <journal> Europhysics Letters 19(6), </journal> <pages> 451-458. </pages>
Reference-contexts: As a Monte Carlo method, simulated 26 D.J.C. MACKAY annealing as described above doesn't sample exactly from the right distribution; the closely related `simulated tempering' methods <ref> (Marinari and Parisi 1992) </ref> correct the biases introduced by the annealing process by making the temperature itself a random variable that is updated in Metropolis fashion during the simulation. 7.2.
Reference: <author> Neal, R. M.: </author> <year> 1993, </year> <title> Probabilistic inference using Markov chain Monte Carlo methods, </title> <type> Technical Report CRG-TR-93-1, </type> <institution> Dept. of Computer Science, University of Toronto. </institution>
Reference: <author> Neal, R. M.: </author> <year> 1995, </year> <title> Suppressing random walks in Markov chain Monte Carlo using ordered overrelaxation, </title> <type> Technical Report 9508, </type> <institution> Dept. of Statistics, University of Toronto. </institution>
Reference: <author> Neal, R. M.: </author> <year> 1996, </year> <title> Bayesian Learning for Neural Networks, </title> <booktitle> number 118 in Lecture Notes in Statistics, </booktitle> <publisher> Springer, </publisher> <address> New York. </address>
Reference-contexts: Instead of using several models (differing in complexity, for example) and evaluating their relative posterior probabilities, one can make a single hierarchical model having, for example, various continuous hyperparameters which play a role similar to that played by the distinct models <ref> (Neal 1996) </ref>. 7.3. THE METROPOLIS METHOD FOR BIG MODELS Our original description of the Metropolis method involved a joint updating of all the variables using a proposal density Q (x 0 ; x).
Reference: <author> Propp, J. G. and Wilson, D. B.: </author> <year> 1996, </year> <title> Exact sampling with coupled Markov chains and applications to statistical mechanics, Random Structures and Algorithms 9(1-2), </title> <type> 223-252. </type>
Reference: <author> Tanner, M. A.: </author> <year> 1996, </year> <title> Tools for Statistical Inference: Methods for the Exploration of Posterior Distributions and Likelihood Functions, </title> <booktitle> Springer Series in Statistics, 3rd edn, </booktitle> <publisher> Springer Verlag. </publisher>
Reference: <author> Thomas, A., Spiegelhalter, D. J. and Gilks, W. R.: </author> <year> 1992, </year> <title> BUGS: A program to perform Bayesian inference using Gibbs sampling, </title> <editor> in J. M. Bernardo, J. O. Berger, A. </editor> <address> P. </address>
Reference-contexts: An excellent software package, BUGS, is available which makes it easy to set up almost arbitrary probabilistic models and simulate them by Gibbs sampling <ref> (Thomas, Spiegelhalter and Gilks 1992) </ref>. 6. Terminology for Markov chain Monte Carlo methods We now spend a few moments sketching the theory on which the Metropolis method and Gibbs sampling are based.
Reference: <author> Dawid and A. F. M. Smith (eds), </author> <title> Bayesian Statistics 4, </title> <publisher> Clarendon Press, Oxford, </publisher> <pages> pp. 837-842. </pages>
Reference: <author> Yeomans, J.: </author> <year> 1992, </year> <title> Statistical mechanics of phase transitions, </title> <publisher> Clarendon Press, </publisher> <address> Oxford. </address> <note> For a full bibliography and a more thorough review of Monte Carlo meth ods, the reader is encouraged to consult Neal (1993), Gilks et al. (1996), and Tanner (1996). </note>
Reference-contexts: One system with 2 1000 states is a collection of 1000 spins, for example, a 30 fi 30 fragment of an Ising model (or `Boltzmann machine' or `Markov field') <ref> (Yeomans 1992) </ref> whose probability distribution is proportional to P fl (x) = exp [fiE (x)] (9) where x n 2 f1g and E (x) = 1 X J mn x m x n + n # The energy function E (x) is readily evaluated for any x.
References-found: 14

