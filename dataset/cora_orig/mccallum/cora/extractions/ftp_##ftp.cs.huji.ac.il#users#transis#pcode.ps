URL: ftp://ftp.cs.huji.ac.il/users/transis/pcode.ps
Refering-URL: http://www.cs.huji.ac.il/labs/transis/abstracts94.html
Root-URL: http://www.cs.huji.ac.il
Email: bruck@systems.caltech.edu dolev@cs.huji.ac.il  fho,strongg@almaden.ibm.com rimon@umiacs.umd.edu  
Phone: 116-81  
Title: PCODE: An Efficient and Reliable Collective Communication Protocol for Unreliable Broadcast Domains  
Author: Jehoshua Bruck Danny Dolev Ching-Tien Ho Rimon Orni Ray Strong 
Address: Mail Code  Pasadena, CA 91125 Jerusalem, Israel  650 Harry Road  San Jose, CA 95120 College Park, MD 20742  
Affiliation: California Institute of Technology Institute of CS  Hebrew University  IBM Almaden Research Center University of Maryland  Institute of Advanced Computer Studies  
Abstract: Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. Parallel programming environments offer the user a convenient way for expressing parallel computation and communication. The communication part consists of the usual point-to-point communication as well as collective communication. However, existing parallel programming environments for clusters are built on top of a point-to-point communication layer (send and receive) over local area networks (LANs) and, as a result, suffer from poor performance in the collective communication part. For example, a broadcast that is implemented using a TCP/IP protocol (which is a point-to-point protocol) over a LAN is obviously inefficient as it is not utilizing the fact that the LAN is a broadcast medium. We have studied the requirements associated with collective communication for parallel computing. We have observed that the main difference between a distributed computing paradigm and a message passing parallel computing paradigm is that, in a distributed environment the activity of every processor is independent while in a parallel environment the collection of the user-communication layers in the processors can be modeled as a single global program. We have formalized the requirements by defining the notion of a correct global program. This notion provides a precise specification of the interface between the transport layer and the user-communication layer. We have developed PCODE, a new communication protocol that is driven by a global program, and proved its correctness. We have implemented the PCODE protocol on a collection of IBM RS/6000 workstations and on a collection of Silicon Graphics Indigo workstations, both communicating via UDP broadcast. The experimental results we obtained indicate that the performance advantage of PCODE over the current point-to-point approach (TCP) can be as high as an order of magnitude on a cluster of 16 workstations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Amir, D. Dolev, S. Kramer and D. Malki, "Transis: </author> <title> A communication subs-system for high availability," </title> <booktitle> Proceedings of the 22nd International Symposium on Fault-Tolerant Computing, IEEE, </booktitle> <pages> pp. 76-84, </pages> <year> 1992. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [6], ISIS [7], Psync [16], Amoeba [19], Trans [13], Transis <ref> [1] </ref> and Totem [2]. However, we have observed that the properties required from the user-communication layer associated with reliable broadcast protocols for distributed systems are different from the properties of the user-communication layer associated with parallel systems. <p> Therefore when the difference between the minimum and the maximum on gcv is greater than a FLOW WINDOW size, P myid will stop sending, until the difference decreases (Figure 12, Line 4 to 6). FLOW WINDOW is a tunable size (See <ref> [1] </ref> regarding flow windows). Note that the difference between the minimum and maximum will also be large when the user communication layer on a processor is not initiating the sending of messages.
Reference: [2] <author> Y. Amir, L.E. Moser, P.M. Melliar-Smith, D.A. Agarwal and P. Ciarfella, </author> <title> "Fast message ordering and membership using a logical token-passing ring", </title> <booktitle> Proceedings of the 13th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 551-560, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [6], ISIS [7], Psync [16], Amoeba [19], Trans [13], Transis [1] and Totem <ref> [2] </ref>. However, we have observed that the properties required from the user-communication layer associated with reliable broadcast protocols for distributed systems are different from the properties of the user-communication layer associated with parallel systems.
Reference: [3] <author> J. Backus, J. Williams, E. Wimmers, P. Lucas, and A. Aiken, </author> <title> "FL Language Manual," Parts 1 and 2, </title> <institution> IBM Research Report RJ7100, </institution> <year> 1989. </year>
Reference-contexts: The scaffolding provides a console interface, benchmark testing using a script from a text file, and simple statistical measurement. The scaffolding is written in a very high level subset of the functional language FL <ref> [3] </ref> and is intended for ease of use and debugging rather than high performance.
Reference: [4] <author> V. Bala, J. Bruck, R. Bryant, R. Cypher, P. de Jong, P. Elustondo, D. Frye, A. Ho, C.T. Ho, G. Irwin, S. Kipnis, R. Lawrence and M. Snir, </author> <title> "The IBM External User Interface for Scalable Parallel Systems", </title> <journal> Parallel Computing, </journal> <volume> Vol. 20, No. 4, </volume> <pages> pp. 445-462, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [4, 11, 15, 18, 20, 21, 22] </ref>. Parallel programming environments offer the user a convenient way to express parallel computation and communication. The communication part consists of the usual point-to-point communication as well as collective communication.
Reference: [5] <author> V. Bala, J. Bruck, R. Cypher, P. Elustondo, A. Ho, C.T. Ho, S. Kipnis, and M. Snir, </author> <title> "CCL: A portable and tunable collective communication library for scalable parallel computers", </title> <booktitle> International Parallel Processing Symposium, </booktitle> <pages> pp. 835-844, </pages> <address> Cancun, Mexico, </address> <month> April </month> <year> 1994. </year> <note> To appear in IEEE Trans. on Parallel and Distributed Computing. </note>
Reference-contexts: Collective communication routines can operate over the entire set of processes that are created at the beginning of an application or over user-specified groups of processes <ref> [5, 14] </ref>. However, existing parallel programming environments for clusters are built on top of a point-to-point communication layer (send and receive) over local area networks (LANs) and, as a result, suffer from poor communication performance.
Reference: [6] <author> D. R. Cheriton and W. Zwaenepoel, </author> <title> "Distributed process groups in the V kernel," </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 2(3), </volume> <pages> pp. 77-107, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: Reliable broadcast in distributed systems is a topic that has been studied extensively for more than a decade [12]. In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system <ref> [6] </ref>, ISIS [7], Psync [16], Amoeba [19], Trans [13], Transis [1] and Totem [2]. However, we have observed that the properties required from the user-communication layer associated with reliable broadcast protocols for distributed systems are different from the properties of the user-communication layer associated with parallel systems.
Reference: [7] <author> K. Birman, R. Cooper, T. A. Joseph, K. Marzullo, M. Makpangou, K. Kane, F. Schmuck and M. Wood, </author> <title> The ISIS System Manual, </title> <institution> Dept. of Computer Science, Cornell University, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [6], ISIS <ref> [7] </ref>, Psync [16], Amoeba [19], Trans [13], Transis [1] and Totem [2]. However, we have observed that the properties required from the user-communication layer associated with reliable broadcast protocols for distributed systems are different from the properties of the user-communication layer associated with parallel systems.
Reference: [8] <author> D. Dolev, R. Strong, and E. Wimmers, </author> <title> "RAPID: An environment for rapid prototyping of distributed protocols", IBM internal memo, </title> <year> 1993. </year>
Reference-contexts: This normalization enables us to compare the performance over a changing number of machines. 6.3 RAPID To facilitate debugging, testing, and measurement of the transport layer, we implemented a driver scaffolding in RAPID, an environment for rapid prototyping of distributed protocols <ref> [8, 9] </ref>. The scaffolding provides a console interface, benchmark testing using a script from a text file, and simple statistical measurement. The scaffolding is written in a very high level subset of the functional language FL [3] and is intended for ease of use and debugging rather than high performance.
Reference: [9] <author> D. Dolev, R. Strong, and E. Wimmers, </author> <title> "Experience with RAPID prototypes", </title> <booktitle> to appear in the Proceedings of the IEEE International Workshop on Rapid Systems Prototyping, </booktitle> <address> Grenoble, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: This normalization enables us to compare the performance over a changing number of machines. 6.3 RAPID To facilitate debugging, testing, and measurement of the transport layer, we implemented a driver scaffolding in RAPID, an environment for rapid prototyping of distributed protocols <ref> [8, 9] </ref>. The scaffolding provides a console interface, benchmark testing using a script from a text file, and simple statistical measurement. The scaffolding is written in a very high level subset of the functional language FL [3] and is intended for ease of use and debugging rather than high performance.
Reference: [10] <author> G. Fox, M. Johnson, G. Lyzenga, S. Otto, J. Salmon, and D. Walker, </author> <title> Solving Problems on Concurrent Processors, Volume I: General Techniques and Regular Problems, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: In particular, collective communication is extensively used in many scientific applications for which the interleaving of stages of local computations with stages of global communication is possible (see <ref> [10] </ref>). Collective communication routines can operate over the entire set of processes that are created at the beginning of an application or over user-specified groups of processes [5, 14].
Reference: [11] <author> G. A. Geist, M. T. Heath, B. W. Peyton, and P. H. Worley, </author> <title> "A user's guide to PICL: a Portable Instrumented Communication Library", </title> <type> ORNL Technical Report, </type> <institution> ORNL/TM-11616, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [4, 11, 15, 18, 20, 21, 22] </ref>. Parallel programming environments offer the user a convenient way to express parallel computation and communication. The communication part consists of the usual point-to-point communication as well as collective communication.
Reference: [12] <author> V. Hadzilacos and S. Toueg, </author> <title> "Fault-tolerant broadcasts and related problems", Chapter 5 in Distributed Systems, second edition, Edited by S. Mullender, </title> <publisher> ACM Press New York, </publisher> <year> 1993. </year> <month> 21 </month>
Reference-contexts: We make use of special properties of the parallel programming environment in order to save in communication cost, in code complexity, and in CPU overhead. Reliable broadcast in distributed systems is a topic that has been studied extensively for more than a decade <ref> [12] </ref>. In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [6], ISIS [7], Psync [16], Amoeba [19], Trans [13], Transis [1] and Totem [2].
Reference: [13] <author> P. M. Melliar-Smith, L. E. Moser and V. Agrawala, </author> <title> "Broadcast protocols for distributed systems", </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <month> January </month> <year> 1990. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [6], ISIS [7], Psync [16], Amoeba [19], Trans <ref> [13] </ref>, Transis [1] and Totem [2]. However, we have observed that the properties required from the user-communication layer associated with reliable broadcast protocols for distributed systems are different from the properties of the user-communication layer associated with parallel systems.
Reference: [14] <author> Message Passing Interface Forum, </author> <title> Document for a Standard Message-Passing Interface, </title> <institution> University of Tennessee, </institution> <type> Technical Report No. </type> <institution> CS-93-214, </institution> <month> November, </month> <year> 1993. </year>
Reference-contexts: Collective communication routines can operate over the entire set of processes that are created at the beginning of an application or over user-specified groups of processes <ref> [5, 14] </ref>. However, existing parallel programming environments for clusters are built on top of a point-to-point communication layer (send and receive) over local area networks (LANs) and, as a result, suffer from poor communication performance. <p> In Horus [17] the results refer to packing several short messages on a single UDP packet. We tried to bring the measurements to a common ground, for that we performed a few experiments in which we imitated the transmission patterns of MPI <ref> [14] </ref> over Transis and Horus. Our experiments show that PCODE's performance is comparable to that of the other distributed broadcast layers.
Reference: [15] <author> J. F. Palmer, </author> <title> "The NCUBE family of parallel supercomputers", </title> <booktitle> Proceedings of the International Conference on Computer Design, IEEE, </booktitle> <year> 1986. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [4, 11, 15, 18, 20, 21, 22] </ref>. Parallel programming environments offer the user a convenient way to express parallel computation and communication. The communication part consists of the usual point-to-point communication as well as collective communication.
Reference: [16] <author> L. L. Peterson, N. C. Bucholtz and R. D. Schlichting, </author> <title> "Preserving and using context information in interprocess communication," </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 7 (3), </volume> <pages> pp. 217-246, </pages> <year> 1989. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [6], ISIS [7], Psync <ref> [16] </ref>, Amoeba [19], Trans [13], Transis [1] and Totem [2]. However, we have observed that the properties required from the user-communication layer associated with reliable broadcast protocols for distributed systems are different from the properties of the user-communication layer associated with parallel systems.
Reference: [17] <author> R. van Renesse, K. P. Birman, R. Cooper, B. Glade, and P. Stephenson, </author> <title> "Reliable Mul-ticast between Microkernels", </title> <booktitle> Proceedings of the USENIX workshop on Micro-Kernels and Other Kernel Architectures, </booktitle> <pages> pp. 27-28, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Moreover, in a typical distributed broadcast layer a slow machine hardly influences the throughput measured, whereas in a synchronous mode it slows down all the other machines. In Transis the reported measurements are for maximum flooding of the network, and do not measure latency. In Horus <ref> [17] </ref> the results refer to packing several short messages on a single UDP packet. We tried to bring the measurements to a common ground, for that we performed a few experiments in which we imitated the transmission patterns of MPI [14] over Transis and Horus.
Reference: [18] <author> A. Skjellum and A. P. Leung, </author> <title> "Zipcode: a portable multicomputer communication library atop the reactive kernel", </title> <booktitle> Proceedings of the 5th Distributed Memory Computing Conference, IEEE, </booktitle> <pages> pp. 328-337, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [4, 11, 15, 18, 20, 21, 22] </ref>. Parallel programming environments offer the user a convenient way to express parallel computation and communication. The communication part consists of the usual point-to-point communication as well as collective communication.
Reference: [19] <author> A. S. Tanenbaum, M. F. Kaashoek and H. E. Bal, </author> <title> "Parallel programming using shared objects and broadcasting," </title> <journal> IEEE Computer, </journal> <volume> vol. 25, </volume> <year> 1992. </year>
Reference-contexts: In fact, there are a number of existing projects and systems that provide a reliable transport layer as well as other services for distributed computing. Examples are the V system [6], ISIS [7], Psync [16], Amoeba <ref> [19] </ref>, Trans [13], Transis [1] and Totem [2]. However, we have observed that the properties required from the user-communication layer associated with reliable broadcast protocols for distributed systems are different from the properties of the user-communication layer associated with parallel systems.
Reference: [20] <institution> Connection Machine CM-5 Technical Summary, Thinking Machines Corporation, </institution> <year> 1991. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [4, 11, 15, 18, 20, 21, 22] </ref>. Parallel programming environments offer the user a convenient way to express parallel computation and communication. The communication part consists of the usual point-to-point communication as well as collective communication.
Reference: [21] <institution> Express 3.0 Introductory Guide, Parasoft Corporation, </institution> <year> 1990. </year>
Reference-contexts: 1 Introduction Parallel computing on clusters of workstations and personal computers has very high potential, since it leverages existing hardware and software. In fact, there are a number of existing commercial parallel programming environments that can run on top of clusters of workstations <ref> [4, 11, 15, 18, 20, 21, 22] </ref>. Parallel programming environments offer the user a convenient way to express parallel computation and communication. The communication part consists of the usual point-to-point communication as well as collective communication.

References-found: 21

