URL: ftp://ftp.cs.rochester.edu/pub/u/rosca/gp/96.gp.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/rosca/research.html
Root-URL: 
Email: E-mail: rosca@cs.rochester.edu  
Title: Generality versus Size in Genetic Programming  
Author: Justinian P. Rosca 
Address: Rochester, NY 14627  
Affiliation: Computer Science Department University of Rochester  
Date: 1996  
Note: In Proceedings of the Genetic Programming 1996 Conference (GP-96) The MIT Press,  
Abstract: Genetic Programming (GP) uses variable size representations as programs. Size becomes an important and interesting emergent property of the structures evolved by GP. The size of programs can be both a controlling and a controlled factor in GP search. Size influences the efficiency of the search process and is related to the generality of solutions. This paper analyzes the size and generality issues in standard GP and GP using subroutines and addresses the question whether such an analysis can help control the search process. We relate the size, generalization and modularity issues for programs evolved to control an agent in a dynamic and non-deterministic environment, as exemplified by the Pac-Man game.
Abstract-found: 1
Intro-found: 1
Reference: <author> Angeline, P. J. </author> <year> (1994). </year> <title> Evolutionary Algorithms and Emergent Intelligence. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Ohio State University. </institution>
Reference-contexts: In contrast to the two hybrid approaches above, there are two main problems with directly applying a parsimony pressure in standard GP. First, introns may be useful (see also <ref> (Angeline, 1994) </ref>). Second, the program space is much more rough and larger programs are not necessarily better. Iba outlined that the MDLP-based fitness measure can be applied problems satisfying the "size-based performance" criterion (Iba et al., 1994), where the more the tree structure grows the better its performance becomes.
Reference: <author> Boyan, J. A. and Moore, A. W. </author> <year> (1995). </year> <title> Generalization in reinforcement learning: Safely approximating the value function. </title> <editor> In Tesauro, G., D.S.Touretzky, and T.K.Leen, editors, </editor> <booktitle> NIPS 7. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Geman, S., E.Bienenstock, </author> <title> and R.Doursat (1992). Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> (4):1-58. 
Reference-contexts: Intuitively, we want small solutions that are also general, according to Ockham's razor principle. Biasing search towards smaller programs intuitively corresponds to biasing search towards an inductive model of lower dimensionality. A biased model has fewer degrees of freedom and lower variance <ref> (Geman et al., 1992) </ref>. In statistics, this issue has been discussed as the bias-variance tradeoff. One aims for a low-bias, low-variance model but has to trade off one for another.
Reference: <author> Iba, H., de Garis, H., and Sato, T. </author> <year> (1994). </year> <title> Genetic programming using a minimum description length principle. </title> <editor> In Kinnear, K., editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: First, introns may be useful (see also (Angeline, 1994)). Second, the program space is much more rough and larger programs are not necessarily better. Iba outlined that the MDLP-based fitness measure can be applied problems satisfying the "size-based performance" criterion <ref> (Iba et al., 1994) </ref>, where the more the tree structure grows the better its performance becomes. Along the size perspective, GP research has focused on the intron issue and the bloating phenomenon. In-trons are pieces of code with no effect on the output.
Reference: <author> Iba, H., Kurita, T., de Garis, H., and Sato, T. </author> <year> (1993). </year> <title> System identification using structured genetic algorithms. </title> <booktitle> In Proceedings of the Fifth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kauf-mann Publishers, Inc. </publisher>
Reference-contexts: A theoretically grounded method to balance the dimensionality of a model and its error is Rissanen's minimum description length principle (MDLP) (Li and Vi-tanyi, 1992). MDLP has been applied in GP to extend the fitness function of hybrid classification models (see <ref> (Iba et al., 1993) </ref> for a GP-regression tree hybrid and (Zhang and Muhlenbein, 1995) for a GP-neural net hybrid; in both cases GP manipulates tree structures, not programs). (Rosca and Ballard, 1994) has used MDLP to assess the suitability of an extension of GP with sub 6 a run of GP
Reference: <author> Johnson, M. P., Maes, P., and Darrel, T. </author> <year> (1994). </year> <title> Evolving visual routines. </title> <journal> Artificial Life, </journal> <volume> 1(4) </volume> <pages> 373-389. </pages>
Reference-contexts: Resampling techniques such as crossvalidation or bootstrapping (Weiss and Kulikowski, 1991) are used to better estimate performance for limited sample sets. For example <ref> (Johnson et al., 1994) </ref> used such techniques to evaluate the quality of GP evolved routines for detecting the left and right hand position in a person's bitmap silhouette. In addition to the generalization analysis, further post processing can offer more confidence in the performance figures obtained.
Reference: <editor> Kinnear, Jr., K. E. </editor> <booktitle> (1994). Advances in Genetic Programming. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Koza, J. R. </author> <year> (1992). </year> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction Genetic Programming <ref> (Koza, 1992) </ref> has been applied to a variety of machine learning applications formulated mostly as classification or prediction problems. <p> For example the obstacle avoiding agent or the crawling agent are "rewarded" proportional to the life of their collision-free walk. 2.2 The Pac-Man Game We consider the problem of controlling an agent in a dynamic environment, similar to the well known Pac-Man game (see <ref> (Koza, 1992) </ref>). The problem is to learn a controller to drive the Pac-Man agent in order to acquire as many points as possible and to avoid being eaten by the monsters. 2.3 GP Representation Programs that define agent controllers will be built based on perception, action and program control primitives. <p> If the result of its first argument is true then it evaluates its second argument, otherwise it evaluates its third argument. Representation (A) is taken from <ref> (Koza, 1992) </ref> with one change: all primitives return distances, as opposed to a mix of distances (senses) and directions (actions). In the latter alternative distances would be compared with actions without making much sense. In representation (B) primitives are typed.
Reference: <author> Koza, J. R. </author> <year> (1994). </year> <title> Genetic Programming II. </title> <publisher> MIT Press. </publisher>
Reference-contexts: A larger number of fitness cases would offer better results but is very expensive to use (see also (Reynolds, 1994)). 3.2 Generalization in the Pac-Man Domain Generality of the best solutions obtained with standard GP (SGP), GP with automatically defined functions (ADF) <ref> (Koza, 1994) </ref>, the adaptive representation Table 2: Generalization performance of Pac-Man solutions: average fitness of solutions evolved through training on one or three cases. Averages for each approach are computed from the same 100 random test cases.
Reference: <author> Li, M. and Vitanyi, P. M. B. </author> <year> (1992). </year> <title> Inductive reasonong and kolmogorov complexity. </title> <journal> Journal of Computer and Systems Sciences, </journal> <volume> 44 </volume> <pages> 343-384. </pages>
Reference-contexts: As reported, the disassortative mating algorithm improves convergence to a better optimum while maintaining speed. A theoretically grounded method to balance the dimensionality of a model and its error is Rissanen's minimum description length principle (MDLP) <ref> (Li and Vi-tanyi, 1992) </ref>.
Reference: <author> Nordin, P., Francone, F., and Banzhaf, W. </author> <year> (1995). </year> <title> Explicitly defined introns and destructive crossover in genetic programming. </title> <editor> In Rosca, J. P., editor, </editor> <booktitle> Pro-ceeedings of the Workshop on Genetic Programming: From Theory to Real-World Applications (NRL TR 95.2, University of Rochester), </booktitle> <pages> pages 6-22. </pages>
Reference-contexts: An analysis of introns goes hand in hand with an analysis of bloating. Bloating is the phenomenon of size increase over time. It has been conjectured that the increase in size is a "defense against crossover." This hypothesis was analyzed in detail in <ref> (Nordin et al., 1995) </ref> only for linear genome representations. The noticed increase in the size of programs was attributed to introns. The authors suggested that a representation which generates introns leads to better search effectiveness based on experiments with controlled crossover or mutation rate within intron fragments. <p> Thus, introns may have a positive role in GP search protecting against destructive genetic operations. However, the conclusion above is not warranted in the case of GP using tree representations. The overhead introduced by exponentially increasing tree sizes may offset the protective effects of introns. Moreover in <ref> (Nordin et al., 1995) </ref>, the detection of introns is computationally expensive. In order to determine introns, each instruction has to be replaced with a no-op and the effect of this change is observed on the output of the program.
Reference: <author> Reynolds, C. W. </author> <year> (1994). </year> <title> Evolution of obstacle avoidance behaviour:using noise to promote robust solutions. </title>
Reference-contexts: The task in RL is to learn a policy maximizing the expected future rewards. Formally, this corresponds to learning a function representing a good satisficing policy that maps perceptions and internal states to actions. Several instances of RL-like problems in the GP literature are the obstacle avoiding robot <ref> (Reynolds, 1994) </ref>, Pac-Man game (Koza, 1992; Rosca and Ballard, 1996), crawling and walking robots (Spencer, 1994). A reactive agent, embodied as a robot in a simulated world, pursues a task in the world. <p> We applied this method to analyze Pac-Man solutions. Note that the choice of the number of GP fitness cases is a balance in the accuracy-efficiency tradeoff. A larger number of fitness cases would offer better results but is very expensive to use (see also <ref> (Reynolds, 1994) </ref>). 3.2 Generalization in the Pac-Man Domain Generality of the best solutions obtained with standard GP (SGP), GP with automatically defined functions (ADF) (Koza, 1994), the adaptive representation Table 2: Generalization performance of Pac-Man solutions: average fitness of solutions evolved through training on one or three cases.
Reference: <editor> In Kinnear, Jr., K. E., editor, </editor> <booktitle> Advances in Genetic Programming, chapter 10. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Rosca, J. P. and Ballard, D. H. </author> <year> (1994). </year> <title> Hierarchical self-organization in genetic programming. </title> <booktitle> In 11th ICML, </booktitle> <pages> pages 251-258. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For standard GP, the size of a program is simply the number of nodes in the tree representation. For GP using subroutines, structural complexity is computed by adding up the sizes of all subroutines (or ADFs) <ref> (Rosca and Ballard, 1994) </ref>. Next we present a new type of size analysis and show some experimental results. 4.1 How Size Varies We present the "average path length" perspective on size change. This method focuses on the average path length variation of an individual after a genetic operation. <p> MDLP has been applied in GP to extend the fitness function of hybrid classification models (see (Iba et al., 1993) for a GP-regression tree hybrid and (Zhang and Muhlenbein, 1995) for a GP-neural net hybrid; in both cases GP manipulates tree structures, not programs). <ref> (Rosca and Ballard, 1994) </ref> has used MDLP to assess the suitability of an extension of GP with sub 6 a run of GP with ADF for the Pac-Man problem (representation A).
Reference: <author> Rosca, J. P. and Ballard, D. H. </author> <year> (1995). </year> <title> Causality in genetic programming. </title> <editor> In Eshelman, L., editor, </editor> <booktitle> ICGA95, </booktitle> <pages> pages 256-263, </pages> <address> San Francisco, CA., USA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In turn, internal/leaf nodes are uniformly chosen. This results in an expected height of pivot nodes of approximately 2 <ref> (Rosca and Ballard, 1995) </ref>.
Reference: <author> Rosca, J. P. and Ballard, D. H. </author> <year> (1996). </year> <title> Discovery of subroutines in genetic programming. </title> <editor> In Angeline, P. and Kinnear, Jr., K. E., editors, </editor> <booktitle> Advances in Genetic Programming 2, chapter 9. </booktitle> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, USA. </address>
Reference-contexts: Averages for each approach are computed from the same 100 random test cases. SGP ADF ARL Hand Rep. 1 3 1 3 1 3 coded A 3095 2906 1011 1569 3594 3611 1798 through learning (ARL) GP extension <ref> (Rosca and Bal-lard, 1996) </ref>, and hand-coded solutions, is summarized in Table 2. The ADF approach uses two subroutines of two arguments each, while the ARL approach creates a library of subroutines on-the-fly by generalizing useful blocks of code. We tested all solutions on the same 100 random test cases. <p> The size of effective code from an individual is the individual's effective size. We disregard here information about which pieces of code contribute to useful computations, although differential behavior of code is a useful source of information that could be used for improving GP search too <ref> (Rosca and Ballard, 1996) </ref>. The effective size of a program is greater or equal than the difference between the size of the program and the total size of introns. In our experiments, instead of analyzing introns we track effective size. <p> Thus, as an alternative to the use of introns to increase GP effectiveness we suggest to directly evolve modular programs. A direct way to evolve programs of smaller complexity is to discover subroutines as in ARL <ref> (Rosca and Ballard, 1996) </ref>. As discussed before, evolved modular programs seem to have better generality indeed. 6 Conclusions GP was used to learn a Pac-Man policy expressed as a program. Such an implicit representation of the agent policy satisfies two important properties discussed in this paper: compressibility and generalization. <p> The paper also discusses the size problem in GP from the new perspective of size attractors and effective code. Effective size offers insights into the properties of the search space for a given problem and also indicates size attractors. More importantly, effective code can be used for modularization purposes <ref> (Rosca and Ballard, 1996) </ref> leading to a smaller complexity and increased generalization. Monitoring size and effective size can be done almost without overhead in GP, as no additional program evaluations are needed.
Reference: <author> Ryan, C. O. </author> <year> (1994). </year> <editor> Pygmies and civil servants. In Kin-near, Jr., K. E., editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: Parsimony pressure is often added into the GP fitness function to limit the size increase and improve efficiency and understandability of solutions. Adding the right size pressure component to fitness remains however, an art. One example is "disassortative mating" <ref> (Ryan, 1994) </ref>. This GP algorithm selects parents for crossover from two different lists of individuals. One list of individuals is ranked based on fitness while the other is ranked based on the sum of size and weighted fitness.
Reference: <author> Spencer, G. </author> <year> (1994). </year> <title> Automatic generation of programs for crawling and walking. </title> <editor> In Kinnear, Jr., K. E., editor, </editor> <booktitle> Advances in Genetic Programming, chapter 15. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: Formally, this corresponds to learning a function representing a good satisficing policy that maps perceptions and internal states to actions. Several instances of RL-like problems in the GP literature are the obstacle avoiding robot (Reynolds, 1994), Pac-Man game (Koza, 1992; Rosca and Ballard, 1996), crawling and walking robots <ref> (Spencer, 1994) </ref>. A reactive agent, embodied as a robot in a simulated world, pursues a task in the world.
Reference: <author> Sutton, R. S. </author> <year> (1996). </year> <title> Generalization in reinforcement learning: Successful examples using sparse coarse coding. </title> <booktitle> In NIPS 8. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Tackett, W. A. </author> <year> (1994). </year> <title> Recombination, Selection and the Genetic Construction of Computer Programs. </title> <type> PhD thesis, </type> <institution> University of Southern California. </institution>
Reference-contexts: Count ing which instructions of a sequential program are introns takes time proportional to the product of the length of the program and the average time of an execution. Tackett correctly pointed out that bloating cannot be selection-neutral <ref> (Tackett, 1994) </ref>. He showed that the average growth in size is proportional to the selection pressure. We argue that this may not be the case in general and that the particular results obtained only analyzed a small number of generations with a small initial program size.
Reference: <author> Weiss, S. M. and Kulikowski, C. A. </author> <year> (1991). </year> <title> Computer Systems that Learn. </title> <publisher> Morgan Maufmann. </publisher>
Reference-contexts: The true performance (or true error rate in a classification problem) of the learning system is evaluated based on the performance of induced solutions on cases not used for training but kept aside for testing. Resampling techniques such as crossvalidation or bootstrapping <ref> (Weiss and Kulikowski, 1991) </ref> are used to better estimate performance for limited sample sets. For example (Johnson et al., 1994) used such techniques to evaluate the quality of GP evolved routines for detecting the left and right hand position in a person's bitmap silhouette. <p> the increase in total size indicates the undesirable self protection against changes and the reach of a local optimum. 5 Putting It All Together When learning a fixed size model that explains given data, a complexity fit is a method to make a good model choice with respect to generalization <ref> (Weiss and Ku-likowski, 1991) </ref>. Such a procedure is not relevant for GP, as GP simultaneously searches the space of all models given by the set of problem primitives using variable size structures. Generality of solutions can be taken as a guiding prin SGP run for the Pac-Man problem (representation A).
Reference: <author> Zhang, B.-T. and Muhlenbein, H. </author> <year> (1995). </year> <title> Balancing accuracy and parsimony in genetic programming. </title> <journal> Evolutionary Computation, </journal> <volume> 3(1) </volume> <pages> 17-38. </pages>
Reference-contexts: MDLP has been applied in GP to extend the fitness function of hybrid classification models (see (Iba et al., 1993) for a GP-regression tree hybrid and <ref> (Zhang and Muhlenbein, 1995) </ref> for a GP-neural net hybrid; in both cases GP manipulates tree structures, not programs). (Rosca and Ballard, 1994) has used MDLP to assess the suitability of an extension of GP with sub 6 a run of GP with ADF for the Pac-Man problem (representation A).
References-found: 22

