URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1994/GIT-CC-94-23.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.94.html
Root-URL: 
Title: Rapid A Multiprocessor Scheduler for Dynamic Real-Time Applications  
Author: Harold Forbes Karsten Schwan 
Date: April 30, 1994  
Address: Atlanta, GA 30332  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: This paper describes and evaluates operating system support for on-line scheduling of real-time tasks on shared memory multiprocessors. The contributions of this work include: (1) the design and implementation of an efficient on-line scheduler that can execute a variety of policies addressing both the assignment of real-time tasks to processors and the scheduling of tasks on individual processors, (2) performance improvements in multiprocessor scheduling due to the separation of task schedulability analysis from actual task scheduling and due to the use of parallelism internal to the scheduler, and (3) the scheduling of individual as well as sets and groups of tasks. Performance measurements on a multiprocessor machine describe the costs and benefits attained from (2) and (3), based on experiences with a multiprocessor robot navigation and planning program being implemented as part of this research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <type> Technical report, </type> <institution> Department of Computer Science and Engineering, University of Washington, TR 90-04-02, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: Performance advantages derived from the resulting asynchrony among steps (1)-(3) are evaluated in Section 4. In future work, alternative implementations of internal interactions among different scheduler components will be evaluated to address the general topic of suitable operating system interfaces for real-time operating systems' resource managers <ref> [1] </ref>. The remainder of this paper is structured as follows. First, a sample multiprocessor application is shown to require on-line real-time scheduling. This robot planning and navigation code motivates the functionality and demonstrates the interfaces offered by Rapid. <p> It also allows a requesting thread to wait on and make decisions based on its reservation, and it can indicate in each reservation multiple, potentially suitable time slots on different processors. Therefore, in contrast to previous work on scheduler activations described in <ref> [1] </ref>, the role of a reservation in Rapid is to provide a vehicle for maintaining information about specific scheduling requests, for single or sets of tasks, and to permit application threads and the different components of the Rapid scheduler to cooperate (synchronize) and communicate (exchange information) to satisfy such requests.
Reference: [2] <author> R.C. Arkin. </author> <title> Motor schema-based mobile robot navigation. </title> <journal> International Journal of Robotics Research, </journal> <volume> 8(4) </volume> <pages> 92-112, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Moreover, real-time systems are inherently dynamic when they operate in complex external environments or consist of many interoperating, asynchronous, and potentially distributed code modules. External events causing dynamic system behavior include: (1) unforeseen events, like the detection of new obstacles in robot navigation <ref> [2] </ref>, (2) actions by human operators, and (3) unexpected system loads due to excessive levels of inputs in certain sensors, such as the arrival of threats in military applications [15].
Reference: [3] <author> R.C. Arkin. </author> <title> The impact of cybernetics on the design of a mobile robot system: A case study. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 20(6) </volume> <pages> 1245-1257, </pages> <month> Nov/Dec </month> <year> 1990. </year>
Reference-contexts: Navigation is performed across an un-mapped world potentially cluttered with obstacles. The parallel code is based on the reactive component of the Autonomous Robot Architecture (AuRA) <ref> [3] </ref>, in which motor schemas are the basic unit of behavioral control of the physical system. Concurrency of execution is possible because several schemas may be active simultaneously as the robot moves.
Reference: [4] <author> T. Balch, H. Forbes, and K. Schwan. </author> <title> Dynamic scheduling for mobile robots. </title> <booktitle> In 6th EuroMicro Workshop, </booktitle> <month> June </month> <year> 1994. </year> <note> to appear. </note>
Reference-contexts: In fact, experimentation with a prototype of the concurrent robot code described in <ref> [4] </ref> demonstrate both the importance of concurrency in thread execution and the need for dynamic control of thread scheduling: * `best effort' thread scheduling disregarding thread timing constraints demonstrates the existence of parallelism in the robot code, but * also shows that the dynamic variation of threads' timing constraints can significantly
Reference: [5] <author> T. Bihari and K. Schwan. </author> <title> Dynamic adaptation of real-time software. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(2) </volume> <pages> 143-147, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In addition, internal characteristics of real-time computer systems leading to dynamic system behavior include software and/or hardware faults due to the system's inherent complexity <ref> [5] </ref> and temporary actions required by specific system components, to avoid component damage, to trade off component performance vs. reliability, etc. The Rapid scheduler. This paper presents the Rapid scheduler for dynamic real-time, multiprocessor systems.
Reference: [6] <author> Tomas E Bihari, Thomas M Walliser, and Mark R Patterson. </author> <title> Controlling the adaptive suspension vehicle. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 59-64, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: This corresponds to an emergency reaction and may take other forms in different real-time applications, such as increases in altitude in autonomous guided missiles, the reversion to human intervention in the ASV walker <ref> [6] </ref> or in other semi-autonomous vehicles, etc. Sporadic schemas.
Reference: [7] <author> Ben Blake. </author> <title> A Fast, Effective Scheduling Framework for Parallel Computing Systems. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, Ohio State University, </institution> <year> 1990. </year> <month> C-128-B. </month>
Reference-contexts: In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [24]. Multiprocessor implementations of internally concurrent schedulers were first described in <ref> [7] </ref>, then generalized and evaluated rigorously and experimentally in [23, 30]. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines.
Reference: [8] <author> Christian Clemencon, Bodhisattwa Mukherjee, and Karsten Schwan. </author> <title> Distributed shared abstractions (dsa) on large-scale multiprocessors. </title> <booktitle> In Proc. of the Fourth USENIX Symposium on Experiences with Distributed and Multiprocessor Systems, </booktitle> <pages> pages 227-246. </pages> <publisher> USENIX, </publisher> <month> September </month> <year> 1993. </year>
Reference-contexts: Reservation list fragmentation vs. the use of a central list can result in significant execution time reductions due to decreases in caching and/or remote memory access on the underlying parallel machine, as shown in <ref> [8] </ref>. While the results presented in this paper address the efficient scheduling of single or sets of tasks, Rapid already contains support for groups of tasks that must be co-scheduled with `all or none' semantics, or must be partially scheduled separating essential from non-essential tasks, etc. <p> an alternative to the real-time threads implementation described in [22], and (2) increased configurability for inclusion of resource scheduling algorithms and of different models of timing constraints, and for experimentation with scaling Rapid to larger parallel machines, where alternative scheduling groups and communication structures among those groups must be considered <ref> [8] </ref>. In essence, Rapid will be the basis for a flexible framework for implementation of schedulers for embedded systems. Last, we will experiment with task groups that require the co-scheduling of related tasks or that require the allocation of both CPU and other resources for task execution.
Reference: [9] <author> Ahmed Gheith and Karsten Schwan. </author> <title> Chaos-arc kernel support for multi-weight objects, invocations, and atomicity in real-time applications. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(1) </volume> <pages> 33-72, </pages> <month> April </month> <year> 1993. </year>
Reference: [10] <author> Ahmed Gheith and Karsten Schwan. </author> <title> Chaos-arc kernel support for multi-weight objects, invocations, and atomicity in real-time applications. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(1) </volume> <pages> 33-72, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: This separation permits the rapid recognition of failures regarding task scheduling, so that the application program or higher-level operating system software <ref> [10, 12] </ref> can deal with such failures in a timely manner (e.g., by submission of alternate tasks, by reduction of execution time using alternate algorithms, etc.). Schedulability algorithm. Rapid uses Zhou's slot list algorithm to perform schedulability analysis of a task on each processor. <p> In addition, Rapid permits users to specify failure functions executed by scheduling threads in reaction to scheduling failures. Our motivation for not including additional functionality to address exception handling is the conviction that such functionality ought to reside at higher levels of the real-time operating system, as described in <ref> [10] </ref>, or at user level where application semantics may be used in making recovery decisions. For example, in the robot navigation code described in Section 2, planning is performed continuously during robot movement so that partially generated alternate plans are continuously available.
Reference: [11] <author> Ahmed M. Gheith. </author> <title> Support for Multi-Weight Objects, Invocations and Atomicity in Real-Time Systems. </title> <type> PhD thesis, </type> <institution> Georgia Institute of Technology, </institution> <address> Atlanta, GA 30332-0280, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Additional support for handling scheduling failures must either be part of higher level real-time operating system functionality or must be supplied by application programs. One approach to implementing such support is taken by the CHAOS arc is an object-based, real-time operating system kernel <ref> [11] </ref>, where related groups of object invocations may be scheduled individually but can then be grouped together into an atomic computation, which is viewed by the operating system as a single schedulable unit with guaranteed scheduling, consistency and failure recovery attributes. 3 The Rapid Scheduler 3.1 A Scalable Implementation NUMA machines.
Reference: [12] <author> Prabha Gopinath and Karsten Schwan. </author> <title> Chaos: Why one cannot have only an operating system for real-time applications. </title> <journal> SIGOPS Notices, </journal> <pages> pages 106-125, </pages> <month> July </month> <year> 1989. </year> <note> Also availble as Philips Technical Note TN-89-006. </note>
Reference-contexts: This separation permits the rapid recognition of failures regarding task scheduling, so that the application program or higher-level operating system software <ref> [10, 12] </ref> can deal with such failures in a timely manner (e.g., by submission of alternate tasks, by reduction of execution time using alternate algorithms, etc.). Schedulability algorithm. Rapid uses Zhou's slot list algorithm to perform schedulability analysis of a task on each processor.
Reference: [13] <author> Dilip D. Kandlur, Daniel L. Kiskis, and Kang G. Shin. HARTOS: </author> <title> A distributed real-time operating system. </title> <booktitle> In Operating Systems Review of ACM SIGOPS, </booktitle> <pages> pages 72-89. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1989. </year> <month> 20 </month>
Reference: [14] <author> Kwei-Jay Lin, Swaminathan Natarajan, and Jane W S Liu. </author> <title> Imprecise results: Utilizing partial computation in real-time systems. </title> <booktitle> In Proceedings Real-Time Systems Symposium, </booktitle> <pages> pages 210-217, </pages> <address> 1730 Massachusetts Avenue, N.W., Washington, DC 20036-1903, 1987. </address> <publisher> IEEE Computer Society, IEEE Computer Society Press. </publisher>
Reference-contexts: Rapid offers no higher-level support for ease of implementation of such forward recovery. Note that the use of pre-scheduling or even imprecise computation <ref> [14] </ref> may be indicated in this context system loads are sufficiently high to result in a high probability of failure for dynamic re-scheduling. Future research. The immediate next steps in this research concern experimentation with task groups, where different tasks in the same group must be co-scheduled.
Reference: [15] <author> Jim McDonald and Karsten Schwan. </author> <title> Ada dynamic load control mechanisms for distributed embedded battle management systems. </title> <booktitle> In First Workshop on Real-time Applications, </booktitle> <address> New York, </address> <pages> pages 156-160. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: External events causing dynamic system behavior include: (1) unforeseen events, like the detection of new obstacles in robot navigation [2], (2) actions by human operators, and (3) unexpected system loads due to excessive levels of inputs in certain sensors, such as the arrival of threats in military applications <ref> [15] </ref>. In addition, internal characteristics of real-time computer systems leading to dynamic system behavior include software and/or hardware faults due to the system's inherent complexity [5] and temporary actions required by specific system components, to avoid component damage, to trade off component performance vs. reliability, etc. The Rapid scheduler.
Reference: [16] <author> Douglas Niehaus, Krithi Ramamritham, John A. Stankovic, Gary Wallace, and Charles Weems. </author> <title> The spring scheduling co-processor: Design, use and performance. </title> <booktitle> In Proceedings of the Real-Time Systems Symposium, </booktitle> <pages> pages 106-111. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: On-line real-time scheduling. On-line real-time schedulers have been constructed in many past and several recent research efforts. The Spring operating system designers have implemented and evaluated multiprocessor sched-ulers running on single, dedicated nodes of small-scale parallel embedded systems [25], with recent work addressing hardware support for on-line scheduling <ref> [16] </ref>, and past work addressing distributed real-time systems [18]. Shin et al.[13] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling.
Reference: [17] <author> David W. Payton and Thomas E. Bihari. </author> <title> Intelligent real-time control of robotic vehicles. </title> <journal> Communications of the ACM, </journal> <volume> 34(8) </volume> <pages> 48-63, </pages> <month> August </month> <year> 1991. </year>
Reference: [18] <author> K. Ramamritham, J. Stankovic, and Wl Zhao. </author> <title> Distributed scheduling of tasks with deadlines and resource requirements. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 1,110-1,123, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: The Spring operating system designers have implemented and evaluated multiprocessor sched-ulers running on single, dedicated nodes of small-scale parallel embedded systems [25], with recent work addressing hardware support for on-line scheduling [16], and past work addressing distributed real-time systems <ref> [18] </ref>. Shin et al.[13] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling. In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [24].
Reference: [19] <author> Krithi Ramamritham, John A. Stankovic, and Perng-Fei Shiah. </author> <title> Efficient scheduling algorithms for real-time multiprocessor systems. </title> <journal> In IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> volume 1(2), </volume> <pages> pages 184-194, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: This indicates that concurrency in scheduling is essential for larger scale parallel system or that hardware support is required for scheduling as described in <ref> [19] </ref>. 4.2 Effects of Concurrency on Scheduler Performance Scheduling throughput. Performance improvements due to the use of concurrency are shown in Figure 3, where scheduling throughput is demonstrated as the total time required to schedule a remote fixed set of feasible tasks already available when schedulability analysis is initiated.
Reference: [20] <author> Karsten Schwan, Tom Bihari, Bruce W. Weide, and Gregor Taulbee. </author> <title> High-performance operating system primitives for robotics and real-time control systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(3) </volume> <pages> 189-231, </pages> <month> Aug. </month> <year> 1987. </year>
Reference: [21] <author> Karsten Schwan, Harold Forbes, Ahmed Gheith, Bodhisattwa Mukherjee, and Yiannis Samiotakis. </author> <title> A c thread library for multiprocessors. </title> <type> Technical Report TR-91/02, </type> <institution> Georgia Institute of Technology, </institution> <address> Atlanta, GA 30332-0280, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Additional schemas are responsible for planning, using a parallel implementation of a planning algorithm similar to the D* algorithm by Stentz [27]. 3 Motor, perceptual, and planning schemas are implemented as concurrent execution threads with the Cthreads library for parallel programming <ref> [21] </ref>.
Reference: [22] <author> Karsten Schwan, Ahmed Gheith, and Hongyi Zhou. </author> <title> Dynamic scheduling for hard real-time systems: Toward real-time threads. </title> <booktitle> In Joint IEEE Workshop on Real-Time Operating Systems and Software and IFAC Workshop on Real-Time Programming, </booktitle> <address> Atlanta, GA, </address> <pages> pages 13-21. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1991. </year> <journal> Also in IEEE Real-Time Systems Newsletter, </journal> <volume> Vol. 7, No. 4, </volume> <month> Fall </month> <year> 1991, </year> <pages> pp. 14-22. </pages>
Reference-contexts: Orthogonally, thread creation itself can also be decoupled from its scheduling, by using the RT-thread-prefork calls described in <ref> [22] </ref> (not used in this example), or by first creating a thread with a non-real-time fork instruction and then scheduling it using RTasynch-schedule (). The primary mechanism supplied by Rapid for attaining asynchrony and to permit thread creation separately from thread scheduling is the reservation. <p> More importantly, we will generalize the current Rapid scheduler to provide: (1) application interfaces to support the robotics applications described in this paper and additional real-time applications, resulting in an alternative to the real-time threads implementation described in <ref> [22] </ref>, and (2) increased configurability for inclusion of resource scheduling algorithms and of different models of timing constraints, and for experimentation with scaling Rapid to larger parallel machines, where alternative scheduling groups and communication structures among those groups must be considered [8].
Reference: [23] <author> Karsten Schwan and Hongyi Zhou. </author> <title> Dynamic scheduling of hard real-time tasks and real-time threads. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(8) </volume> <pages> 736-748, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [24]. Multiprocessor implementations of internally concurrent schedulers were first described in [7], then generalized and evaluated rigorously and experimentally in <ref> [23, 30] </ref>. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines. Also, higher level mechanisms for managing soft real-time parallel applications are being at the University of Rochester [28]. Scheduler performance and concurrency. <p> This algorithm takes O (n log n) steps to determine the schedulability of any new task, where n is the number of slots in the slot list. Detailed studies of average slot list lengths indicate that algorithm performance remains good and even improves with increasing system loads <ref> [23] </ref>. However, in contrast to Rapid, the multiprocessor slot list-based algorithm described in [30] only allows a single scheduler to be active at a time.
Reference: [24] <author> Brinkley Sprunt, Lui Sha, and John Lehoczky. </author> <title> Aperiodic task scheduling for hard-real-time systems. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 1 </volume> <pages> 27-60, </pages> <year> 1989. </year>
Reference-contexts: Shin et al.[13] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling. In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms <ref> [24] </ref>. Multiprocessor implementations of internally concurrent schedulers were first described in [7], then generalized and evaluated rigorously and experimentally in [23, 30]. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines.
Reference: [25] <author> J. A. Stankovic and K. Ramamritham. </author> <title> The spring kernel: A new paradigm for real-time systems. </title> <journal> IEEE Software, </journal> <volume> 8(3) </volume> <pages> 62-72, </pages> <month> May </month> <year> 1991. </year> <month> 21 </month>
Reference-contexts: On-line real-time scheduling. On-line real-time schedulers have been constructed in many past and several recent research efforts. The Spring operating system designers have implemented and evaluated multiprocessor sched-ulers running on single, dedicated nodes of small-scale parallel embedded systems <ref> [25] </ref>, with recent work addressing hardware support for on-line scheduling [16], and past work addressing distributed real-time systems [18]. Shin et al.[13] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling.
Reference: [26] <author> Anthony Stentz. </author> <title> The NAVLAB System for Mobile Robot Navigation. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> March </month> <year> 1990. </year>
Reference: [27] <author> Anthony Stentz. </author> <title> Optimal and efficient path planning for partially-known iguanas. </title> <booktitle> In International Conference on Robotics and Automation. IEEE, </booktitle> <month> May </month> <year> 1994. </year> <note> to appear. </note>
Reference-contexts: Additional schemas are responsible for planning, using a parallel implementation of a planning algorithm similar to the D* algorithm by Stentz <ref> [27] </ref>. 3 Motor, perceptual, and planning schemas are implemented as concurrent execution threads with the Cthreads library for parallel programming [21].
Reference: [28] <author> R. W. Wisniewski and C. M. Brown. Ephor, </author> <title> a run-time environment for parallel intelligent applications. </title> <booktitle> In Proceedings of the Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <pages> pages 51-60, </pages> <address> April 1993. Newport Beach, CA. </address>
Reference-contexts: The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines. Also, higher level mechanisms for managing soft real-time parallel applications are being at the University of Rochester <ref> [28] </ref>. Scheduler performance and concurrency. The Rapid scheduler builds on our previous research in real-time, 2 multiprocessor threads [30], but focusses on two topics not explored to date: (1) the use of concurrency during schedul-ing and (2) the efficient implementation of concurrent multiprocessor schedulers on large scale parallel machines.
Reference: [29] <author> Hongyi Zhou. </author> <title> Task Scheduling and Synchronization for Multiprocessor Real-Time Systems. </title> <type> PhD thesis, </type> <institution> Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Reservations are inspected by threads performing schedulability analysis, and are removed from reservation lists only when schedulability analysis is completed. Schedulability analysis is performed using Zhou's <ref> [29] </ref> slot list algorithm, where successful analysis results in the generation of a reservation entry by the scheduler into the reservation maintained for this task. <p> In addition to knowledge about the frequencies of scheduler execution, processor load information can also be made available to the fork procedure, thereby permitting it to decide where schedulability analysis is most likely to succeed <ref> [29] </ref>. The operational description of scheduling in Figure 2 permits us to define several terms precisely. First, scheduling latency is defined as the total elapsed time from generation of a scheduling request (reservation generation) to insertion of the task into a designated task list.
Reference: [30] <author> Hongyi Zhou, Karsten Schwan, and Ian F Akyildiz. </author> <title> Performance effects of information sharing in a distributed multiprocessor real-time scheduler. </title> <booktitle> In Real-Time Systems Symposium. IEEE, IEEE, </booktitle> <year> 1992. </year> <note> Also available as GIT-CC-91/40 from Ga. Tech. 22 </note>
Reference-contexts: In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [24]. Multiprocessor implementations of internally concurrent schedulers were first described in [7], then generalized and evaluated rigorously and experimentally in <ref> [23, 30] </ref>. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines. Also, higher level mechanisms for managing soft real-time parallel applications are being at the University of Rochester [28]. Scheduler performance and concurrency. <p> Also, higher level mechanisms for managing soft real-time parallel applications are being at the University of Rochester [28]. Scheduler performance and concurrency. The Rapid scheduler builds on our previous research in real-time, 2 multiprocessor threads <ref> [30] </ref>, but focusses on two topics not explored to date: (1) the use of concurrency during schedul-ing and (2) the efficient implementation of concurrent multiprocessor schedulers on large scale parallel machines. <p> This research currently uses a 64-node shared memory KSR-1 multiprocessor; its primary contributions are: * Scheduler concurrency in contrast to <ref> [30] </ref>, schedulability analysis and scheduling are performed by multiple, concurrently executed threads, thereby enabling us to vary both the latency of scheduling for individual requests and scheduling throughput, by variation of internal scheduler concurrency. Presentation of performance gains due to parallelism appear in Section 4. <p> Detailed studies of average slot list lengths indicate that algorithm performance remains good and even improves with increasing system loads [23]. However, in contrast to Rapid, the multiprocessor slot list-based algorithm described in <ref> [30] </ref> only allows a single scheduler to be active at a time. Therefore, although actual scheduling overhead is comparatively low, overall scheduling latency could become unacceptable in the presence of a large queue of tasks to be scheduled. <p> The Rapid concurrent scheduler allows multiple scheduling threads to be active simultaneously thereby, increasing throughput and decreasing latency. The execution of Rapid. The Rapid scheduler is not simply run as independently scheduled threads with fixed execution periods staggered across different processors, as the non-concurrent multiprocessor scheduler described in <ref> [30] </ref>. Instead, whenever a schema finishes its execution, the low-level task dispatcher within Rapid can choose to run either a thread executing the scheduler or the next available application task. <p> However, for reasons of system predictability under high system loads, Rapid schedulers will also be scheduled conservatively 8 using a dynamic variant of the staggered scheme described in <ref> [30] </ref>. 2.4 Rapid Concurrent Scheduling To attain concurrency in task scheduling, Rapid must decouple (1) the generation of scheduling requests, from (2) schedulability analysis for requests, from (3) the decision concerning thread scheduling. <p> Second, in contrast to our previous work described in <ref> [30] </ref>, Rapid supports concurrency in scheduling by decoupling (1) the generation of scheduling requests (generating a reservation), from (2) their processing (schedulability analysis by slot list inspection), from (3) task scheduling (task insertion into some TL). <p> This permits processors to be dynamically added to or removed from scheduling groups, and processors can simultaneously belong to more than one scheduling group. The size of scheduling groups results in tradeoffs in scheduler performance vs. the quality of scheduling exposed in part by our past work <ref> [30] </ref> and to be investigated further in our future research. Similarly, communication between processors and the scheduler is via the per-processor reservation list (RL) part of each scheduler's state. <p> Such issues may be addressed by proper scheduling of scheduling threads, such as the staggered schedule suggested by Zhou <ref> [30] </ref>. In order to evaluate scheduling overheads and latencies without considering this issue, we also define scheduling effort as the total amount of execution time spent on performing scheduling actions on behalf of a single task. <p> Significant variations in execution times only exist for list (RL, SL, and TL) manipulation, with total execution time dominated by SL manipulation. Details on the effects of task laxities, execution times, and system load on SL execution times are not reported below; they are described in a previous publication <ref> [30] </ref>. For purposes of this paper, it is sufficient to state that SL execution time strictly depends on the number of slots in the list, which tends to remain constant and/or grow smaller with increasing system load due to the merging of adjacent slots. Conclusions from these results are straightforward. <p> Such increases outweigh the costs of additional mechanisms required for asynchronous task generation, schedulability analysis, and decision-making. Furthermore, increased performance is shown not to 16 degrade the quality of on-line multiprocessor scheduling significantly compared to our past results attained with synchronous scheduling methods <ref> [30] </ref>. The primary Rapid concept and mechanism supporting such asynchrony is the notion of reservation, which defines an application interface containing scheduling information to end users and permits concurrent scheduling components to share information concerning single or groups of tasks being scheduled, thereby also defining interfaces between those components. <p> Acknowledgements. Tucker Balch is contributing the robot navigation and planning code used in this research. Hongyi Zhou has provided some assistance in comparing the quality of Rapid scheduling to her previous results published in <ref> [30] </ref>. 19
References-found: 30

