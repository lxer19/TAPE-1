URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94529-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Email: e-mail: rshankar, kaalsabt, ranka@top.cis.syr.edu  
Title: The Transportation Primitive  
Author: Ravi V. Shankar Khaled A. Alsabti Sanjay Ranka 
Date: August 1994  
Address: Syracuse, NY 13244-4100  
Affiliation: School of Computer and Information Science Syracuse University,  
Abstract: This paper presents algorithms for implementing the transportation primitive on a distributed memory parallel architecture. The transportation primitive performs many-to-many personalized communication with bounded incoming and outgoing traffic. We present a two-stage deterministic algorithm that decomposes the communication with possibly high variance in message size into two communication stages with low message size variance. If the maximum outgoing or incoming traffic at any processor is t, transportation can be done in 2t time (+ lower order terms) when t O(p 2 + pt =) ( is the inverse of the data transfer rate, t is the startup overhead). If the maximum outgoing and incoming traffic are r and c respectively, transportation can be done in (r + c) time when either r O(p 2 ) or c O(p 2 ). Optimality and scalability are thus achieved when the traffic is large, a condition that is usually satisfied in practice. The algorithm was implemented on the Connection Machine CM-5. The implementation used the low latency communication primitives (active messages) available on the CM-5, but the algorithm as such is architecture-independent. An alternate single-stage algorithm using distributed random scheduling was implemented on the CM-5 and the performance of the two algorithms were compared. fl A preliminary version of this paper titled Many-to-many Personalized Communication with Bounded Traffic is to presented at Frontiers '95,Mclean, Virginia, February 1995. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shahid H. Bokhari. </author> <title> Complete Exchange on the iPSC/860. </title> <type> ICASE Technical Report No. 91-4, </type> <institution> NASA Langley Research Center, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: This is all-to-all personalized communication with uniform messages. Under these conditions, a linear permutation algorithm <ref> [1] </ref> can be used to perform the communication.
Reference: [2] <author> Zeki Bozkus, Sanjay Ranka, Geoffrey C. Fox. </author> <title> Benchmarking the CM-5 Multicomputer, </title> <booktitle> Proceedings of the Frontiers of Massively Parallel Computation, </booktitle> <pages> pp. 100-107, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: The resultant vector R [0 n p 1] is stored in all the processors. R [j] = i=0 This operation can be completed in O ( 2 n p ) time on the CM-5, where 2 is a small constant <ref> [2] </ref>. * Global Vector Scan Let each processor contain a vector V i [0 n p 1]. The global vector prefix-sum-scan operation computes an element-wise prefix-sum-scan of the local list in each processor.
Reference: [3] <author> Eric A. Brewer and Robert Blumofe, Strata: </author> <title> A Multi-Layer Communications Library, </title> <institution> MIT Laboratory of Computer Science Technical Report, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: We used the CMMD message passing library and CMAML (the CMMD active messages layer) [14]. Two other implementations of active messages on the CM-5 exist: the original CMAM library [6] from UC Berkeley and the Strata library from MIT <ref> [3] </ref>. 4.2 Modeling the CM-5 * Sending a Message The time taken to send a message from one node on the CM-5 to another can be modeled as O (t + M ), where t is the startup overhead, is the inverse of the data transfer rate and M is the
Reference: [4] <author> Eric A. Brewer, Bradley C. Kuszmaul, </author> <title> How to Get Good Performance from the CM-5 Data Network, </title> <booktitle> Proceedings of the 8th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: The barrier also prevents the communication network from getting congested and this has been shown to improve performance <ref> [4] </ref>. This is the algorithm referred to when "linear permutation" is mentioned in the rest of this paper. 6 Collective Communication with High Message Size Variance Dealing with communication in which message sizes show a large variation is a difficult problem.
Reference: [5] <author> Herbert A. David, </author> <title> Order Statistics, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1981. </year>
Reference: [6] <author> T. von Eicken, D.E. Culler, S.C. Goldstein, K.E.Schauser. </author> <title> Active Messages: a mechanism for integrated communication and computation. </title> <booktitle> Proceedings of the ISCA '92, </booktitle> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Our implementations were performed on a 32-node CM-5 using active messages for low latency communication. Each 20-byte active message packet can carry up to 16 bytes of payload. Sending and receiving a single-packet active message on the CM-5 takes 1.6 s and 1.7 s respectively <ref> [6] </ref>. We used the CMMD message passing library and CMAML (the CMMD active messages layer) [14]. Two other implementations of active messages on the CM-5 exist: the original CMAM library [6] from UC Berkeley and the Strata library from MIT [3]. 4.2 Modeling the CM-5 * Sending a Message The time <p> Sending and receiving a single-packet active message on the CM-5 takes 1.6 s and 1.7 s respectively <ref> [6] </ref>. We used the CMMD message passing library and CMAML (the CMMD active messages layer) [14]. Two other implementations of active messages on the CM-5 exist: the original CMAM library [6] from UC Berkeley and the Strata library from MIT [3]. 4.2 Modeling the CM-5 * Sending a Message The time taken to send a message from one node on the CM-5 to another can be modeled as O (t + M ), where t is the startup overhead, is the
Reference: [7] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms, </title> <address> Benjamin-Cummings, </address> <year> 1994. </year>
Reference-contexts: This classification is fairly standard in the literature. See, for instance, <ref> [7] </ref>. Algorithms for performing broadcasts are comparatively easier than those for performing personalized communication. All further discussion in this paper deals with personalized communication.
Reference: [8] <author> J. Marberg, E.Gafni. </author> <title> Sorting in Constant Number of Row and Column Phases on a Mesh. Algo-rithmica, </title> <type> Vol.3, </type> <institution> pp.561-572, </institution> <year> 1988. </year>
Reference-contexts: Since the destination processors are numbers from a fixed range, local sorting done using a radix-sort takes just O (t) time. Data movement between processors can be achieved using an adaptation of rotate-sort <ref> [8] </ref>. All communication between processors can be done as fixed (or static) permutations. Such a combination was used to perform sorting for geometric hashing in [10]. This rotate-sort and radix-sort combination performs transportation in O (t) time, but requires nine local radix-sorts, six rotates (fixed permutations), and three row-wise sorts.
Reference: [9] <author> K. Mehrotra, S. Ranka, J.C. Wang. </author> <title> A Probabilistic Analysis of a Locality Maintaining Load Balancing Algorithm, </title> <booktitle> Proc. 7th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1993. </year> <month> 20 </month>
Reference: [10] <author> Victor K. Prasanna, Cho-Li Wang, </author> <title> Scalable Data Parallel Object Recognition using Geometric Hashing on the CM-5. </title> <booktitle> Scalable High Performance Computing Conference, </booktitle> <address> SHPCC, </address> <year> 1994. </year>
Reference-contexts: Data movement between processors can be achieved using an adaptation of rotate-sort [8]. All communication between processors can be done as fixed (or static) permutations. Such a combination was used to perform sorting for geometric hashing in <ref> [10] </ref>. This rotate-sort and radix-sort combination performs transportation in O (t) time, but requires nine local radix-sorts, six rotates (fixed permutations), and three row-wise sorts.
Reference: [11] <author> Ravi V. Shankar, Sanjay Ranka. </author> <title> Random Data Accesses on a Coarse-Grained Parallel Machine - I. One-to-one Mappings, </title> <type> CIS Technical Report, </type> <institution> Syracuse University, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: We are using them for performing dynamic permutations <ref> [11] </ref> and for dealing with highly irregular data accesses involving hot-spots [12] on coarse-grained parallel machines. 4 CM-5 System Overview 4.1 Node/Network Architecture The Connection Machine Model CM-5 [13] is a synchronized MIMD distributed-memory parallel machine available in configurations of 32 to 1024 processing nodes.
Reference: [12] <author> Ravi V. Shankar, Sanjay Ranka. </author> <title> Random Data Accesses on a Coarse-Grained Parallel Machine - II. One-to-many and Many-to-one Mappings, </title> <type> CIS Technical Report, </type> <institution> Syracuse University, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: We are using them for performing dynamic permutations [11] and for dealing with highly irregular data accesses involving hot-spots <ref> [12] </ref> on coarse-grained parallel machines. 4 CM-5 System Overview 4.1 Node/Network Architecture The Connection Machine Model CM-5 [13] is a synchronized MIMD distributed-memory parallel machine available in configurations of 32 to 1024 processing nodes.
Reference: [13] <author> Thinking Machines Corporation. </author> <title> The Connection Machine CM-5 Technical Summary, </title> <month> October </month> <year> 1991. </year>
Reference-contexts: We are using them for performing dynamic permutations [11] and for dealing with highly irregular data accesses involving hot-spots [12] on coarse-grained parallel machines. 4 CM-5 System Overview 4.1 Node/Network Architecture The Connection Machine Model CM-5 <ref> [13] </ref> is a synchronized MIMD distributed-memory parallel machine available in configurations of 32 to 1024 processing nodes. Each node contains a 33 MHz SPARC microprocessor with 32 megabytes of memory, and is rated at 22 Mips and 5 Mflops. <p> However, if the destination is within the same same cluster of 4 or 16 nodes in the fat-tree, a peak bandwidth of 20 megabytes per second and 10 megabytes per second, respectively, can be achieved <ref> [13] </ref>. The control network handles operations requiring the cooperation of many or all processors. This includes broadcasting, combining, and global operations. The diagnostic network helps in the detection and isolation of errors throughout the system. 3 4 Both, the control network and the diagnostic network, have a binary tree topology.
Reference: [14] <institution> Thinking Machines Corporation. </institution> <note> CMMD Reference Manual Version 3.0, </note> <month> October </month> <year> 1991. </year>
Reference-contexts: Each 20-byte active message packet can carry up to 16 bytes of payload. Sending and receiving a single-packet active message on the CM-5 takes 1.6 s and 1.7 s respectively [6]. We used the CMMD message passing library and CMAML (the CMMD active messages layer) <ref> [14] </ref>.
Reference: [15] <author> Jhy-chun Wang, Tseng-Hui Lin, Sanjay Ranka. </author> <title> Distributed Scheduling of Unstructured Collective Communication on the CM-5. </title> <booktitle> Hawaii International Conference on System Sciences, </booktitle> <year> 1993. </year>
Reference-contexts: A linear permutation algorithm could take as much as O (tp) time. Sorting messages by size is not guaranteed to improve performance either. We use a distributed random scheduling algorithm using spin locks to deal with such a situation. The distributed scheduling algorithm <ref> [15] </ref> was chosen over other graph based techniques because its low overhead enables scheduling to be done dynamically. The algorithm is presented in figure 5. Each processor maintains a status bit that indicates whether the processor is busy or free.
References-found: 15

