URL: http://www.isi.edu/~frank/Theses/phdthesis.ps
Refering-URL: http://www.isi.edu/~frank/Theses/theses.html
Root-URL: http://www.isi.edu
Title: Model-Based User Interface Design By Demonstration and By Interview  
Author: Martin Robert Frank Martin R. Frank 
Degree: A Thesis Presented to The Academic Faculty by  In Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy in Computer Science  
Note: Copyright (c) 1995 by  
Date: December 1995  
Affiliation: Georgia Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [Astr75] <author> M. M. Astrahan and D. D. Chamberlin. </author> <title> Implementation of a structured English query language. </title> <journal> Communications of the ACM, </journal> <volume> 18(10):580587, </volume> <month> October </month> <year> 1975. </year>
Reference-contexts: Comparison of the EET Model and the Relational Model There is a rough analogy between the Elements, Events & T ransitions model for user interfaces and the relational model for databases [Codd70], and there is a similar analogy between the EET behavior description language and the SQL database query language <ref> [Astr75] </ref>. Both the relational database model and the EET user interface model impose more structure on their data than general-purpose programming languages. The relational database model imposes a tabular structure, and also imposes some restrictions on the content of the data (it has to comply with some normal form [e.g.
Reference: [Byrn94] <author> Michael D. Byrne, Scott D. Wood, Piyawadee Noi Sukaviriya, James D. Foley, and David E. Kieras. </author> <title> Automating interface evaluation. </title> <booktitle> In Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 232237, </pages> <address> (Boston, Massachusetts, </address> <month> April 24-28) </month> <year> 1994. </year>
Reference-contexts: These transformations are especially valuable in the early design phases, where designers can quickly explore alternative interaction paradigms via transformation of a design prototype. USAGE <ref> [Byrn94] </ref> can translate a high-level declarative user interface model into an NGOMSL model [Kier88] that is suitable for subsequent automated interface evaluation. This automated evaluation capability comes for free assuming that such a higher-level model has already been constructed for other purposes, such as driving the user interface at run-time.
Reference: [Codd70] <author> Edgar F. Codd. </author> <title> A relational model for large shared data banks. </title> <journal> Communications of the ACM, </journal> <volume> 13(6):377387, </volume> <month> June </month> <year> 1970. </year>
Reference-contexts: III.5.5 Comparison of the EET Model and the Relational Model There is a rough analogy between the Elements, Events & T ransitions model for user interfaces and the relational model for databases <ref> [Codd70] </ref>, and there is a similar analogy between the EET behavior description language and the SQL database query language [Astr75]. Both the relational database model and the EET user interface model impose more structure on their data than general-purpose programming languages.
Reference: [Cyph91] <author> Allen Cypher. EAGER: </author> <title> Programming repetitive tasks by example. </title> <booktitle> In Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 3339, </pages> <address> (New Orleans, Louisiana, </address> <month> April 28-May 2) </month> <year> 1991. </year>
Reference-contexts: However, it is generally not possible to demonstrate a parameterized interaction with a single demonstration. In conclusion, the macro recording approach works best for parameterless interactions and quickly becomes arkward for more complex interactions. Eager <ref> [Cyph91] </ref> watches users perform operations and detects and automates repetition. Eager differs significantly from the other demonstrational systems discussed in this section. It does not synthesize a program but rather just automates repetition. Eager does not have to be explicitly invoked, it is rather constantly running in the background.
Reference: [Cyph93] <author> Allen Cypher, </author> <title> editor. Watch What I Do: Programming by Demonstration. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: VII.1.3 Textual Languages as the Basis of PBD Systems Programming By Demonstration (PBD) systems intended for a non-programming audience often include a graphical language for the representation of 225 demonstrated behavior, like e.g. Pygmalion and Mondrian (both in <ref> [Cyph93] </ref>) and KidSim [Cyph95]. We have deliberately put all our effort into an inferencing mechanism at the expense of a visual language (primarily because another student at our institution has in turn put all her effort into a visual language for PBD systems, see Appendix B).
Reference: [Cyph95] <author> Allen Cypher and David Canfield Smith. KidSim: </author> <title> End user programming of simulations. </title> <booktitle> In Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 2734, </pages> <address> (Denver, Colorado, </address> <month> May 7-11) </month> <year> 1995. </year>
Reference-contexts: Or, consider that any non-trivial program cannot be exhaustively tested for correctness. Is is consequently also impossible to construct such a program from 2. For example, KidSim <ref> [Cyph95] </ref> combines Programming By Demonstration with a visual language to enable children as young as eight years old to interactively specify the behavior of animated characters - a task they could typically not accomplish with a conventional programming or scripting language. 6 a finite set of examples (because this example set <p> VII.1.3 Textual Languages as the Basis of PBD Systems Programming By Demonstration (PBD) systems intended for a non-programming audience often include a graphical language for the representation of 225 demonstrated behavior, like e.g. Pygmalion and Mondrian (both in [Cyph93]) and KidSim <ref> [Cyph95] </ref>. We have deliberately put all our effort into an inferencing mechanism at the expense of a visual language (primarily because another student at our institution has in turn put all her effort into a visual language for PBD systems, see Appendix B). <p> The most obvious extension to this research is to present the output of demonstrations in an editable visual language (similar to the graphical rewrite rules used in KidSim <ref> [Cyph95] </ref>). Appendix B presents a visual language that we feel is especially well-suited for integration with Grizzly Bear. 228 Another desirable extension to the design environment is a single-stepping tool for debugging purposes.
Reference: [Fish92] <author> Gene L. Fisher, Dale E. Busse, and David A. Wolber. </author> <title> Adding rule-based reasoning to a demonstrational interface builder. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 8997, </pages> <address> (Monterey, California, </address> <month> November 15-18) </month> <year> 1992. </year>
Reference-contexts: DEMO does some linear generalization similar to Peridot, so that it is possible to link an angle of a gauge to a numeric text field. DEMO II <ref> [Fish92] </ref> is a successor of the DEMO system which has been augmented by a rule base. Some of the rules try to automatically recognize the stimulus for a demonstrated behavior. Other rules try to infer nonlinear relationships. <p> At least one existing demonstrational system has used such a hybrid approach <ref> [Fish92] </ref>. Our inferencing engine also already provides a number of hooks (C++ function calls) which let one tune the inferencing based on domain knowledge. For example, one such hook provides for sorting source variables by domain-specific criteria.
Reference: [Fole89] <author> James D. Foley, Won Chul Kim, Srdjan Kovacevic, and Kevin Murray. </author> <title> Defining user interfaces at a high level of abstraction. </title> <journal> IEEE Software, </journal> <volume> 6(1):2532, </volume> <month> January </month> <year> 1989. </year> <month> 261 </month>
Reference-contexts: This formal description can then be used to drive the user interface at run time, and it can also serve additional purposes. Humanoid [Szek92, Szek93] and UIDE <ref> [Fole89, Suka93] </ref> are typical model-based systems. I.1.1 Strengths The primary strength of user interface models is in their descriptive power and in their high level of abstraction. <p> Application objects group commands and simple objects (variables) into a semantically meaningful entity. The data ow constraints are the control element in the model, they specify the dependencies between inputs, variables and objects. UIDE <ref> [Fole89] </ref> is a set of model-based tools. The original model consisted of actions, attributes, and an object hierarchy. Actions have parameters, pre and postconditions. The pre and postconditions capture part of an application actions semantics. <p> However , the text has been updated to reect our current views. The underlying modelling language is a precursor of the Elements, Events & Transitions (EET) model that was inspired by UIDE <ref> [Fole89] </ref>. From a computational standpoint, the EET model is a superset of that earlier version: actions were replaced by transitions, pre-conditions were subsumed by transition headers, and post-conditions were subsumed by transition bodies. 72. The systems were developed independently.
Reference: [Fran93] <author> Martin R. Frank and James D. Foley. </author> <title> Model-based user interface design by example and by interview. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 129137, </pages> <address> (Atlanta, Georgia, </address> <month> November 3-5) </month> <year> 1993. </year>
Reference-contexts: It is just that an interview approach can never present a general design methodology for any non-trivial application domain. 73 The remainder of this chapter contains the original design of the interview component as presented in <ref> [Fran93] </ref>. However , the text has been updated to reect our current views. The underlying modelling language is a precursor of the Elements, Events & Transitions (EET) model that was inspired by UIDE [Fole89].
Reference: [Hart90] <author> H. Rex Hartson, Antonio C. Siochi, and Deborah Hix. </author> <title> The UAN: A user-oriented representation for direct manipulation interface designs. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(3):181203, </volume> <month> July </month> <year> 1990. </year>
Reference-contexts: The techniques capture user interface functionality at a much lower level than in the previous model, mainly to support the animation component. Table 2-1 gives an overview of the specif ication languages presented in this section. The User-Action Notation (UAN) <ref> [Hart90] </ref> is another well-known specif ica-tion language f or user interf ace behavior . However, it is intended for human-human communication rather than machine interpretation. 3 We will limit 13 our discussion of previous work to machine-readable specif ications here. <p> However, their generality often incurs a cost in terms of storage overhead and runtime performance that can preclude their use in interactive software. 3. Citing from <ref> [Hart90] </ref>, page 184: Because UAN is in the behavioral domain, it should not be confused with, for example, specif ication languages for program behavior. ...
Reference: [Hill86] <author> Ralph D. Hill. </author> <title> Supporting concurrency, communication and synchronization in human-computer interaction - the Sassafras UIMS. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 5(3):179210, </volume> <month> July </month> <year> 1986. </year>
Reference-contexts: We feel that the special-purpose languages are justified because they greatly simplify the management of the domains to which they are applicable. 31 III.5.6 Comparison of the EET and Event-Response Languages Ralph Hills Sassafras user interface management system <ref> [Hill86] </ref> includes a behavioral description language called the Event-Response Language (ERL). This language models the system s reaction to user actions as responses to 31. <p> Sche86] solve the multiple input stream problem by simply serializing the events into a single input queue. This solution appears superior because it facilitates multiple input devices for the user without exposing the system implementer to the dif ficulties inherent in parallelism (deadlock, race conditions). 33. Citing from <ref> [Hill86] </ref>, page 194: Sassafras ... relies heavily on the tools provided by the Interlisp-D environment.
Reference: [Huds88] <author> Scott E. Hudson and Roger King. </author> <title> Semantic feedback in the Higgens UIMS. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14(8):11881206, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: However, this simple model did not support defining what an applicationspecif ic object is. For example, it is not possible to state that a wire is an object which connects two other objects. 10 Higgens <ref> [Huds88] </ref> uses an application data model which was inspired by semantic database models. The model contains application entities and relationships. For example, musical notation can be modelled as consisting of the entities Instrument, Piece, Measure and Note. These entities have relationships to each other.
Reference: [Huds93] <author> Scott E. Hudson. </author> <title> A system for efficient and exible one-way constraint evaluation in C++. </title> <type> Technical Report 93-15, </type> <institution> Graphics, Visualization & Usability Center, Georgia Institute of Technology, </institution> <address> Atlanta, GA 30332-0280, </address> <year> 1993. </year>
Reference: [Kier88] <author> David E. Kieras. </author> <title> Towards a practical GOMS model methodology for user interface design. </title> <editor> In Martin Helander, editor, </editor> <booktitle> Handbook of Human-Computer Interaction, </booktitle> <pages> pages 135157. </pages> <publisher> Elsevier (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: These transformations are especially valuable in the early design phases, where designers can quickly explore alternative interaction paradigms via transformation of a design prototype. USAGE [Byrn94] can translate a high-level declarative user interface model into an NGOMSL model <ref> [Kier88] </ref> that is suitable for subsequent automated interface evaluation. This automated evaluation capability comes for free assuming that such a higher-level model has already been constructed for other purposes, such as driving the user interface at run-time.
Reference: [Kim90] <author> Won Chul Kim and James D. Foley. DON: </author> <title> User interface presentation design assistant. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 1020, </pages> <address> (Snowbird, Utah, </address> <month> October 3-5) </month> <year> 1990. </year>
Reference-contexts: This required much more detailed knowledge about the elements of an user interface, like the placement of objects on the screen. Another driving force was a new user interface generator <ref> [Kim90] </ref> which had its own requirements like logical grouping of application actions. One of the most important model additions was the has-a relationship (aggregation) in addition to the existing is-a relationship (specialization). <p> Cartoonist probably presents the visually most compelling case for declarative user interface models. DON <ref> [Kim90] </ref> is a user interface generator that also makes use of a comprehensive declarative model. Its model includes a class hierarchy of application objects that are to be presented to the user.
Reference: [Kodr88] <author> Yves Kodratoff. </author> <title> Introduction to Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: The one-comparison seed expressions are originally ordered alphabetically, so that there is a bias towards variables that rank lower in the alphabet. Finally, let us note that this algorithm is closely related to work in machine learning, more specifically to work on learning by similarity detection (see e.g. <ref> [Kodr88] </ref>, chapter 8). Some of these algorithms exhibit a better running time for certain special cases of the problem of f inding set expressions. (Our algorithm is exponential in the number of set source variables in the worst case. <p> An algorithm by Michalski (also in <ref> [Kodr88] </ref>, chapter 8) seems to be the one most closely related to ours. We may try to build on it in the future if the performance of the set expression finder becomes an issue.
Reference: [Koos85] <author> Donald J. Koosis. </author> <title> Statistics. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, third edition, </address> <year> 1985. </year>
Reference-contexts: The two variables are contained in rows eight and ten of Table E-1. 79. The correlation is r=0.117, well below the critical value for signif icance r&gt;0.549. (The table of critical values we used is from <ref> [Koos85] </ref>, page 275.) 80. The two variables are contained in rows five and ten of Table E-1. 81. The correlation is r=0.625 (greater than the critical value r&gt;0.549). 213 VI.2 Testing on Programmers This section describes an experiment we performed on subjects with substantial programming experience.
Reference: [Kosb94] <author> David S. Kosbie and Brad A. Myers. </author> <title> Extending programming by demonstration with hierarchical event histories. </title> <booktitle> In Fourth International East-West Conference on Human-Computer Interaction, </booktitle> <pages> pages 147157, </pages> <address> (St. Petersburg, Russia, </address> <month> August 2-5) </month> <year> 1994. </year> <month> 262 </month>
Reference-contexts: This way , the PBD system can generate output that reads if the trashcan is entered then.... 88. This section will not discuss the potential benefits of placing high-level events into the input stream (e.g. f ile selection task complete), which is the topic of a separate dissertation <ref> [Kosb94] </ref>. 224 Contrast this with an event that e.g. states mouse was moved from (123,37) to (129,43).
Reference: [Kova92] <author> Srdjan Kovacevic. </author> <title> A Compositional Model of Human-Computer Interaction. </title> <type> PhD thesis, </type> <institution> Dept. of EE&CS, The George Washington University, </institution> <year> 1992. </year>
Reference-contexts: An issue that we 229 have not addressed is how to use programming by demonstration to input high-level model constructs. For example, a higher-level model may specify that commands throughout the interface are invoked first, before their arguments are supplied (pre-fix), or that their parameters are supplied first (post-fix) <ref> [Kova92] </ref>. It is an issue of future research if the definition of behavior at such an abstract level lends itself to a PBD approach.
Reference: [Kueh92] <author> Thomas Kuehme and Matthias Schneider-Hufschmidt. </author> <title> SX/Tools - An open design environment for adaptable multimedia user interfaces. </title> <journal> Computer Graphics Forum, </journal> <volume> 11(3):93105, </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: It instead relies on a translator to fill in the elements from the toolkit at run-time, and to propagate changes to the elements back to the actual toolkit. The toolkit we used for our prototype implementation (SX/Tools <ref> [Kueh92] </ref>) uses an integer-valued attribute called mapped to control visibility. 42 III.3.1 Statements that Operate on Sets of Elements The transitions shown in the introductory section use statements that operate on one element at a time. <p> This is not to say that runtime inheritance may not be useful in some cases, or that it could not be incorporated into the EET model as a future extension. 19. This is not dif ferent from other prototype-instance schemes like e.g. the ones used in SX/Tools <ref> [Kueh92] </ref>, SUIT [Paus91], and Garnet [Myer90b]. 51 from which a new element is copied can change at run time, and that it is marked with an iAmTheCurrentPrototype attribute. element e := create (*.iAmTheCurrentPrototype=="true"); Note that a set expression in a create statement must yield exactly one element. <p> This chapter makes extensive use of snapshots from our prototype implementation in C++, which runs on Sun SP ARC stations running the Motif window manager on top of the X window system [Sche86]. The prototype implementation additionally makes use of an existing user interface builder , SX/Tools <ref> [Kueh92] </ref>. We have also implemented our own text editor based on the Motif text editing widget (so that we could seamlessly integrate a text editor with the rest of the system). <p> The user interface is edited using an existing interface building tool, SX/Tools <ref> [Kueh92] </ref>, which supports designing custom objects in addition to providing predefined standard objects. The application model and the glue are edited in text editors under control of Interactive UIDE so that switching from design mode to run mode is instantaneous. <p> Our Elements, Events & 86. For example, the SX/Tools interface builder takes this approach <ref> [Kueh92] </ref>. 221 Transitions language can also serve as such a scripting language when used at a single level of abstraction (as was done throughout Chapter IV). This approach seems most appropriate for rapidly prototyping user interfaces. <p> Finally, the pseudo-parallelism discussed in Section III.5.1 supports our snapshot-based PBD approach well. 227 The user interface builder that is the basis for our prototype implementation, SX/Tools <ref> [Kueh92] </ref>, runs as a separate process from its client code, requiring inter-process communication to access and change the state of its user interface elements. This turned out to be a major performance bottleneck in the interpretation of Elements, Events & T ransition (EET) models.
Reference: [Kurl93] <author> David Kurlander and Steven Feiner. </author> <title> Inferring constraints from multiple snapshots. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 12(4):277304, </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: W e have also used a dual approach: The Interview Tool of Chapter V is our heuristic component, while the demonstrational tools of Chapter IV use mathematically-thorough reasoning. In a nutshell, heuristic components can be more forgiving while the mathematics-based components can make more general inferences. Chimera <ref> [Kurl93] </ref> infers constraints between graphical objects given multiple snapshots 7 . For example, it can infer that buttons should be distributed evenly when their window is resized.
Reference: [Lint89] <author> Mark A. Linton, John M. Vlissides, and Paul R. Calder. </author> <title> Composing user interfaces with interviews. </title> <journal> IEEE Computer, </journal> <volume> 22(2):822, </volume> <month> February </month> <year> 1989. </year>
Reference-contexts: already invested considerable time in learning a general-purpose programming language - so why invest even more time in learning another language which has no more overall expressive power, and likely less? And there will normally also be a run-time cost because these special-purpose languages tend to be interpreted! Mark Linton <ref> [Lint89, page 20] </ref> provides a good summary of these criticisms. For example, he writes: The special-purpose language used ... is likely to be unfamiliar to programmers and user interface designers alike.
Reference: [Luo93] <author> Ping Luo, Pedro Szekely, and Robert Neches. </author> <booktitle> Management of interface design in HUMANOID. In Proceedings of INTERCHI, ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 107114, </pages> <address> (Amsterdam, The Netherlands, </address> <month> April 24-29) </month> <year> 1993. </year>
Reference: [MacG91] <author> Robert M. MacGregor. </author> <title> Using a description classifier to enhance deductive inference. </title> <booktitle> In Proceedings of the Seventh IEEE Conference on AI Applications, </booktitle> <pages> pages 141147, </pages> <address> (Miami, Florida, </address> <month> February) </month> <year> 1991. </year>
Reference-contexts: However, pushing UAN too hard into this direction risks creating a language which could be too formal for human-human communication while still not being formal enough for machine interpretation. Finally, it is worth noting that there are many related modelling languages outside the user interface domain. For example, LOOM <ref> [MacG91] </ref> is a general-purpose knowledge representation language that is widely used in the Artif i-cial Intelligence community. It provides concepts and relations (a data model in our terminology) as well as actions and productions (a control model in our terminology).
Reference: [Maul89] <author> David L. Maulsby, Ian H. Witten, and Kenneth A. Kittlitz. Metamouse: </author> <title> Specifying graphical procedures by example. </title> <booktitle> In Proceedings of Siggraph, </booktitle> <pages> pages 127136, </pages> <address> (Boston, Massachusetts, </address> <month> July 31-August 4) </month> <year> 1989. </year>
Reference-contexts: The designer initiates two system snapshots, before and after the change to the object (for example to make its text italic). The system then creates a constraint which makes the text of highlighted objects italic. Metamouse <ref> [Maul89] </ref> learns graphical procedures by example. The user first invokes a special teaching mode. Metamouse then watches the user perform graphical editing operations and uses generalization to identify the steps, loops, and branches in this procedure. <p> Metamouse used the proximity of objects to reduce the amount of computation required for its inferencing. Metamouse is nearsighted but touch sensitive. The user understands that relations at a dis 19 tance must be constructed, for example by using a line to demonstrate alignment <ref> [Maul89, page 128, end of first paragraph] </ref>. 5 Druid [Sing90] lets users attach simple functionality such as enabling, disabling, hiding and showing buttons. It is a user interface management system with demonstrational capabilities.
Reference: [Myer88] <author> Brad A. Myers. </author> <title> Creating User Interfaces by Demonstration. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: That is, the designers give concrete examples of the desired behavior rather than having to deal wit h an abstract sequencing specif icat ion direct ly. Peridot <ref> [Myer88] </ref> and DEMO [Wolb91] are typical demonstrational systems for user interface design. <p> II.3 Previous Work on Demonstrational User Interface Tools A number of demonstrational user interface tools have been built during the last ten years. We will first describe relevant systems individually in chronological order, and then provide a summary of their key characteristics. Peridot <ref> [Myer88] </ref> supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. It was the f irst user interface tool to provide for the interactive specification of behavior in addition to layout. The primitives of Peridots inference mechanism are rectangles, circles, text lines and icons. <p> How will Inference Bear know which event is the one that triggers the behavior to be demonstrated? There are several solutions to this problem. Peridot <ref> [Myer88] </ref> uses a simulated mouse which is an icon depicting a mouse and the state of its buttons. The user can then use the state and position of the simulated mouse to demonstrate mousedependent behavior, freeing the real mouse for metalevel commands. <p> Similarly, another rule can check if a new object is left-aligned by checking if the values of their attributes named x-pos are similar. For example, Peridot <ref> [Myer88] </ref> and Druid [Sing90] have taken this approach. 179 A possible domain-independent approach is to instead check if the attributes of the new object can be computed from a linear combination of existing variables. This was our approach. Other systems of a similar nature are Demo [Wolb91] and GITS [Olse90]. <p> It has no capabilities in natural language generation or understanding. Instead, the designer provides answers through selecting interface objects and filling out forms. 204 When used to infer an application model, our system starts from a user interface example but it is not a by-example approach such as Peridot <ref> [Myer88] </ref> in a strict sense because a user interface example alone is not sufficient for inferring a semantic application model. However, our approach still shares a similar philosophy. Examples are inherently easier to understand than abstract concepts, and our system makes use of this fact. <p> However, our approach still shares a similar philosophy. Examples are inherently easier to understand than abstract concepts, and our system makes use of this fact. Our system is not a with-example approach either. In Myers and Halberts definition <ref> [Myer88] </ref>, programming with example is a generalized macro recording approach, following the philosophy of do what I did rather than the do what I mean philosophy of by-example programming.
Reference: [Myer89] <author> Brad A. Myers, Brad Vander Zanden, and Roger B. Dannenberg. </author> <title> Creating graphical interactive application objects by demonstration. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 95104, </pages> <address> (Williamsburg, Virginia, </address> <month> November 13-15) </month> <year> 1989. </year>
Reference-contexts: We encountered the same limitations with our rule-based tool, the interview component (Chapter V). Lapidary <ref> [Myer89] </ref> focused on creating applicationspecif ic objects. It also used constraints but replaced Peridot s active values with interactors [Myer90a] as its way of handling user input.
Reference: [Myer90a] <author> Brad A. Myers. </author> <title> A new model for handling input. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(3):289320, </volume> <month> July </month> <year> 1990. </year> <month> 263 </month>
Reference-contexts: We encountered the same limitations with our rule-based tool, the interview component (Chapter V). Lapidary [Myer89] focused on creating applicationspecif ic objects. It also used constraints but replaced Peridot s active values with interactors <ref> [Myer90a] </ref> as its way of handling user input. T o specify a constraint by demonstration, the user first selects the user interface event which triggers the constraint, such as object selection with the mouse.
Reference: [Myer90b] <author> Brad A. Myers, Dario A. Giuse, Roger B. Dannenberg, Brad Vander Zanden, David S. Kosbie, Ed Pervin, Andrew Mickish, and Philippe Marchal. Garnet: </author> <title> Comprehensive support for graphical, highly-interactive user interfaces. </title> <journal> IEEE Computer, </journal> <volume> 23(11):7185, </volume> <month> November </month> <year> 1990. </year>
Reference-contexts: This is not dif ferent from other prototype-instance schemes like e.g. the ones used in SX/Tools [Kueh92], SUIT [Paus91], and Garnet <ref> [Myer90b] </ref>. 51 from which a new element is copied can change at run time, and that it is marked with an iAmTheCurrentPrototype attribute. element e := create (*.iAmTheCurrentPrototype=="true"); Note that a set expression in a create statement must yield exactly one element. <p> Grizzly-Bear can of course already tie behavior to double-clicks if double-click events are built into the underlying toolkit (as done in Garnet <ref> [Myer90b] </ref>, for example). 244 APPENDIX E Material and Data from the Non-Programmer Study E.1 Questionnaire 1. What is your major school? (circle one) Psychology Other: ____________________ 2. What is your year in school? (circle one) Freshman Sophomore Junior Senior Grad Student 3.
Reference: [Myer93] <author> Brad A. Myers, Richard G. McDaniel, and David S. Kosbie. Marquise: </author> <title> Creating complete user interfaces by demonstration. </title> <booktitle> In Proceedings of INTERCHI, ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 293300, </pages> <address> (Amsterdam, The Netherlands, </address> <month> April 24-29) </month> <year> 1993. </year>
Reference-contexts: The primitives of Chimera s inferencing mechanism are lines and other elements of a simple drawing editor . Chimera does not reason about objects that are dynamically instantiated and deleted at run-time. Finally, Marquise <ref> [Myer93] </ref> uses domain knowledge to support building graphical editors. It is a by-demonstration system for creating MacDraw-style graphical editors. It contains built-in knowledge about editorspecif ic behaviors 8. <p> DEMO [Wolb91] always records a press event and then asks the user whether she really meant a press event, or whether she meant one of three other event types (release, enter and leave in our terminology). Marquise <ref> [Myer93] </ref> uses the keyboard to start and stop the recording. W e use an alternative technique which uses time to distinguish the triggering event from the other events. Snapshot button has been clicked. <p> She holds the left mouse button pressed over the Properties button until Inference Bears event recording timer runs out. A small iconic cursor is shown which indicates the type and position of the click (borrowed from Marquise <ref> [Myer93] </ref>). 5. She clicks the Stop Recording Button which switches the interface design back into editing mode Inference Bear shows the recorded event in its status line. 6. She edits the interface design for the after snapshot by disabling the Properties button and by showing the Properties window. 7. <p> L i k e i n Marquise <ref> [Myer93] </ref>, the designer can use the icon dropped by the press event to Canvas Line (This element will serve as a prototype for the lines to be created.
Reference: [Nard93] <author> Bonnie A. Nardi. </author> <title> A Small Matter of Programming: Perspectives on End-User Computing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: We also believe that a textual programming language can sometimes be suitable even for a nonprogramming audience if the language is specif ic to their needs (as is also argued in <ref> [Nard93] </ref>, especially in its third chapter). Apple Computers HyperTalk language (part of the HyperCard prototyping environment) is a good example of a successful textual behavior specif ication language for end-users. 226 VII.2 Contributions The thesis contributes to the state of the art in three dimensions.
Reference: [Olse86] <author> Dan R. Olsen, Jr. MIKE: </author> <title> The menu interaction kontrol environment. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 5(4):318344, </volume> <month> October </month> <year> 1986. </year>
Reference-contexts: Our interest is in specification languages that operate at a higher level of abstraction than programming language code that calls subroutines of a user interface library. MIKE <ref> [Olse86] </ref> is one of the oldest user interface management systems supporting graphical user interfaces. Its specif ication consists of possible end-user actions.
Reference: [Olse90] <author> Dan R. Olsen, Jr. and Kirk Allan. </author> <title> Creating interactive techniques by symbolically solving geometric constraints. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 102107, </pages> <address> (Snowbird, Utah, </address> <month> October 3-5) </month> <year> 1990. </year>
Reference-contexts: This was our approach. Other systems of a similar nature are Demo [Wolb91] and GITS <ref> [Olse90] </ref>. We will discuss the advantages and disadvantages of the two approaches using the two main characteristics of PBD systems: how much they can infer, and how easy they are to use.
Reference: [Paus91] <author> Randy Pausch, Nathaniel R. Young II, and Robert DeLine. SUIT: </author> <title> The Pascal of user interface toolkits. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 117125, </pages> <address> (Hilton Head, South Carolina, </address> <month> November 11-13) </month> <year> 1991. </year>
Reference-contexts: This is not to say that runtime inheritance may not be useful in some cases, or that it could not be incorporated into the EET model as a future extension. 19. This is not dif ferent from other prototype-instance schemes like e.g. the ones used in SX/Tools [Kueh92], SUIT <ref> [Paus91] </ref>, and Garnet [Myer90b]. 51 from which a new element is copied can change at run time, and that it is marked with an iAmTheCurrentPrototype attribute. element e := create (*.iAmTheCurrentPrototype=="true"); Note that a set expression in a create statement must yield exactly one element.
Reference: [Sadu96] <author> Erica L. Sadun. </author> <title> DJASA - An Interactive Graphical Notation. </title> <type> PhD thesis, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1996. </year> <note> (in progress). </note>
Reference-contexts: | &lt; | &gt; | eetDottedNames ::= . eetSpec | eetDottedNames . eetSpec eetStringSpec ::= name eetListSpec ::= name [ cardinal ] eetSpec ::= eetListSpec | eetStringSpec 235 APPENDIX B A Visual Language for Grizzly Bear Erica Sadun is developing a new visual specif ication language for user interface behavior <ref> [Sadu96] </ref>. Figure B-1 contains an example specification.
Reference: [Sche86] <author> Robert W. Scheier and Jim Gettys. </author> <title> The X window system. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 5(2):79109, </volume> <month> April </month> <year> 1986. </year>
Reference-contexts: This chapter makes extensive use of snapshots from our prototype implementation in C++, which runs on Sun SP ARC stations running the Motif window manager on top of the X window system <ref> [Sche86] </ref>. The prototype implementation additionally makes use of an existing user interface builder , SX/Tools [Kueh92]. We have also implemented our own text editor based on the Motif text editing widget (so that we could seamlessly integrate a text editor with the rest of the system).
Reference: [Sing89] <author> Gurminder Singh and Mark Green. </author> <title> A high-level user interface management system. </title> <booktitle> In Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 133138, </pages> <address> (Austin, Texas, </address> <month> April 30-May 4) </month> <year> 1989. </year>
Reference-contexts: In this way, the application need only be concerned with updating application data. It does not need to be involved in presenting data to the user. UofA*s application model <ref> [Sing89] </ref> consists of actions and parameters and is similar in spirit to MIKE s model. The user can def ine applicationspecific types only in a very limited sense by specifying ranges. For example, an Angle type can be defined as Angle=[0:360];.
Reference: [Sing90] <author> Gurminder Singh, Chun Hong Kok, and Teng Ye Ngan. Druid: </author> <title> A system for demonstrational rapid user interface development. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 167177, </pages> <address> (Snowbird, Utah, </address> <month> October 3-5) </month> <year> 1990. </year> <month> 264 </month>
Reference-contexts: Metamouse is nearsighted but touch sensitive. The user understands that relations at a dis 19 tance must be constructed, for example by using a line to demonstrate alignment [Maul89, page 128, end of first paragraph]. 5 Druid <ref> [Sing90] </ref> lets users attach simple functionality such as enabling, disabling, hiding and showing buttons. It is a user interface management system with demonstrational capabilities. <p> Similarly, another rule can check if a new object is left-aligned by checking if the values of their attributes named x-pos are similar. For example, Peridot [Myer88] and Druid <ref> [Sing90] </ref> have taken this approach. 179 A possible domain-independent approach is to instead check if the attributes of the new object can be computed from a linear combination of existing variables. This was our approach. Other systems of a similar nature are Demo [Wolb91] and GITS [Olse90].
Reference: [Suka90] <author> Piyawadee Noi Sukaviriya and James D. Foley. </author> <title> Coupling a user interface framework with automatic generation of context-sensitive animated help. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 152166, </pages> <address> (Snowbird, Utah, </address> <month> October 3-5) </month> <year> 1990. </year>
Reference-contexts: Objects declare attributes and actions, they would be called classes in todays terminology. 12 The UIDE knowledge base has since been ref ined several times. A major driving force for the new model was its use for automatic generation of con-textsensitive procedural animated help <ref> [Suka90] </ref>. This required much more detailed knowledge about the elements of an user interface, like the placement of objects on the screen. Another driving force was a new user interface generator [Kim90] which had its own requirements like logical grouping of application actions. <p> This section describes tools that take advantage of such a model. Cartoonist <ref> [Suka90] </ref> automatically generates animated and contextsensi-tive help for the end user . The generation is based on a sequencing model that consists of user interface actions.
Reference: [Suka93] <author> Piyawadee Noi Sukaviriya, James D. Foley, and Todd Griffith. </author> <title> A second generation user interface design environment: The model and the runtime architecture. </title> <booktitle> In Proceedings of INTERCHI, ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 375382, </pages> <address> (Amsterdam, The Netherlands, </address> <month> April 24-29) </month> <year> 1993. </year>
Reference-contexts: This formal description can then be used to drive the user interface at run time, and it can also serve additional purposes. Humanoid [Szek92, Szek93] and UIDE <ref> [Fole89, Suka93] </ref> are typical model-based systems. I.1.1 Strengths The primary strength of user interface models is in their descriptive power and in their high level of abstraction. <p> For example, the higher 27. In a previous system, user interface tasks served as a lower-level user interface model while application tasks were used at a higher level <ref> [Suka93] </ref>. There is a rough but not perfect correspondence to using two EET models at dif ferent levels of abstraction. 77 level model of a f ile management application may have a command to delete a group of files. <p> For example, a mousedown event on an object may be translated into a selection event. The higher-level will in turn send events to the lower-level model such as deselect all objects. This scheme is similar to one used in the second-generation UIDE <ref> [Suka93] </ref>. The higher-level EET model will then communicate with the application as discussed above. This form of organization ensures that both the higher-level EET model and its attached application code can be moved to a different platform by replacing the lower-level, platform-specific model. <p> W e are not aware of any user interface tools using this approach. VII.1.1.6 Many Modelling Languages, Multiple Levels of Abstraction In this approach, the user interface design environment supplies a number of modelling languages that are each geared towards describing dialog-related information at a particular level of abstraction <ref> [Suka93, Szek95] </ref>. For example, there can be a special-purpose language for describing the tasks that the user is accomplishing, another language for describing the interaction techniques used, a language for describing the characteristics of the computing platform, and so on.
Reference: [Szek92] <author> Pedro Szekely, Ping Luo, and Robert Neches. </author> <title> Facilitating the exploration of interface design alternatives: The HUMANOID model of interface design. </title> <booktitle> In Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 507515, </pages> <address> (Monterey, California, </address> <month> May 3-7) </month> <year> 1992. </year>
Reference-contexts: I.1 Model-Based User Interface Design The discipline of model-based user interface design advocates the explicit denotation of the conceptual abstractions that underlie a user interface. This formal description can then be used to drive the user interface at run time, and it can also serve additional purposes. Humanoid <ref> [Szek92, Szek93] </ref> and UIDE [Fole89, Suka93] are typical model-based systems. I.1.1 Strengths The primary strength of user interface models is in their descriptive power and in their high level of abstraction.
Reference: [Szek93] <author> Pedro Szekely, Ping Luo, and Robert Neches. </author> <title> Beyond interface builders: Model-based interface tools. </title> <booktitle> In Proceedings of INTERCHI, ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 383390, </pages> <address> (Amsterdam, The Netherlands, </address> <month> April 24-29) </month> <year> 1993. </year>
Reference-contexts: I.1 Model-Based User Interface Design The discipline of model-based user interface design advocates the explicit denotation of the conceptual abstractions that underlie a user interface. This formal description can then be used to drive the user interface at run time, and it can also serve additional purposes. Humanoid <ref> [Szek92, Szek93] </ref> and UIDE [Fole89, Suka93] are typical model-based systems. I.1.1 Strengths The primary strength of user interface models is in their descriptive power and in their high level of abstraction.
Reference: [Szek95] <author> Pedro Szekely, Piyawadee Noi Sukaviriya, Pablo Castells, Jayakumar Muthukumarasamy, and Ewald Sacher. </author> <title> Declarative interface models for user interface construction tools. </title> <booktitle> In IFIP Working Conference on Engineering for Human-Computer Interaction, </booktitle> <institution> (Grand Targhee Resort, Wyoming, </institution> <month> August 14-18) </month> <year> 1995. </year>
Reference-contexts: It is currently an open research question if a universal modelling 17 language exists that can support all of these tools, and that can ef ficiently drive the user interface at runtime as well. The Mastermind project <ref> [Szek95] </ref> currently is the most ambitious attempt of providing a comprehensive and detailed user interface model. II.3 Previous Work on Demonstrational User Interface Tools A number of demonstrational user interface tools have been built during the last ten years. <p> W e are not aware of any user interface tools using this approach. VII.1.1.6 Many Modelling Languages, Multiple Levels of Abstraction In this approach, the user interface design environment supplies a number of modelling languages that are each geared towards describing dialog-related information at a particular level of abstraction <ref> [Suka93, Szek95] </ref>. For example, there can be a special-purpose language for describing the tasks that the user is accomplishing, another language for describing the interaction techniques used, a language for describing the characteristics of the computing platform, and so on.
Reference: [Ullm83] <author> Jeffrey D. Ullman. </author> <title> Principles of Database Systems. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, Maryland, </address> <note> second edition, </note> <year> 1983. </year>
Reference: [Wiec89] <author> Charles Wiecha, William Bennett, Stephen Boies, and John Gould. </author> <title> Generating highly interactive user interfaces. </title> <booktitle> In Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 277282, </pages> <address> (Austin, Texas, </address> <month> April 30-May 4) </month> <year> 1989. </year>
Reference-contexts: For example, standard user interface design knowledge can be encoded in our questions so that this knowledge can be accessed and applied by people other than user interface designers. This is similar in spirit to ITS style rules <ref> [Wiec89] </ref> but augmented with the interactive interface to the knowledge. In this way, interface design knowledge is not only automatically applied, but the process is also visible and understandable to the designers so that they learn about interface design themselves while using the system.
Reference: [Wiec90] <author> Charles Wiecha and Stephen Boies. </author> <title> Generating user interfaces: Principles and use of ITS style rules. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 2130, </pages> <address> (Snowbird, Utah, </address> <month> October 3-5) </month> <year> 1990. </year> <month> 265 </month>
Reference: [Wolb91] <author> David Wolber and Gene Fisher. </author> <title> A demonstrational technique for developing interfaces with dynamically created objects. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 221230, </pages> <address> (Hilton Head, South Carolina, </address> <month> November 11-13) </month> <year> 1991. </year> <note> 266 VITA Martin Frank was born in Mannheim, Germany , on August 4, 1966. He received his Abitur from the Carl-Benz Gymnasium Ladenburg in 1985, his V or-Diplom in Informatik from the Universit t Karlsruhe in 1988, </note> <institution> and his Master s degree in Computer Science from the Georgia Institute of Technology in 1991. </institution>
Reference-contexts: That is, the designers give concrete examples of the desired behavior rather than having to deal wit h an abstract sequencing specif icat ion direct ly. Peridot [Myer88] and DEMO <ref> [Wolb91] </ref> are typical demonstrational systems for user interface design. <p> The users thus get a subtle, unobtrusive hint that they can use Eager to automate repetition. Eager presented a usability breakthrough for by-demonstration systems because it did not require any special skills from its users. 6 DEMO <ref> [Wolb91] </ref> uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. The designer specifies a triggering event, the stimulus, and then demonstrates the intended behavior , the response. This paradigm 6. <p> Peridot [Myer88] uses a simulated mouse which is an icon depicting a mouse and the state of its buttons. The user can then use the state and position of the simulated mouse to demonstrate mousedependent behavior, freeing the real mouse for metalevel commands. DEMO <ref> [Wolb91] </ref> always records a press event and then asks the user whether she really meant a press event, or whether she meant one of three other event types (release, enter and leave in our terminology). Marquise [Myer93] uses the keyboard to start and stop the recording. <p> For example, Peridot [Myer88] and Druid [Sing90] have taken this approach. 179 A possible domain-independent approach is to instead check if the attributes of the new object can be computed from a linear combination of existing variables. This was our approach. Other systems of a similar nature are Demo <ref> [Wolb91] </ref> and GITS [Olse90]. We will discuss the advantages and disadvantages of the two approaches using the two main characteristics of PBD systems: how much they can infer, and how easy they are to use.
References-found: 47

