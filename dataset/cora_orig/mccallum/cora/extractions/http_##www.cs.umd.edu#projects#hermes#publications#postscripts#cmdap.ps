URL: http://www.cs.umd.edu/projects/hermes/publications/postscripts/cmdap.ps
Refering-URL: http://www.cs.umd.edu/projects/hermes/publications/abstracts/cmdap.html
Root-URL: 
Title: Collaborative Multimedia Documents: Authoring and Presentation  
Author: Kasm S. Candan B. Prabhakaran V.S. Subrahmanian 
Abstract: Multimedia documents are composed of different data types such as video, audio, text and images. Authoring a multimedia document is a creative exercise. Unlike traditional computer supported collaborative work where documents are composed of static objects, multimedia documents have temporal, spatial and quality of service (QoS) requirements that must be supported by any collaborative multimedia platform. In this paper, we show that most requirements (including temporal, spatial, and QoS requirements) for collaborative multimedia systems can be expressed in terms of a highly-structured class of linear constraints called difference constraints that have been well-studied in the operations research literature. As a consequence, well known algorithms for solving difference constraints may be used as a starting point for creating multimedia documents. Based on our difference-constraint based characterization, we develop efficient, incremental algorithms for creating and modifying multimedia documents so as to satisfy the required temporal, spatial and QoS constraints. We further develop methods to identify inconsistent requirements, and show how such inconsistencies may be removed through constraint relaxation techniques.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.F. Allen. </author> <title> (1984) Towards a General Theory of Time and Action, </title> <journal> Artificial Intelligence, </journal> <volume> 23, </volume> <pages> pps 123-154. </pages>
Reference-contexts: This requirement can be described using the following constraints: ST (o 1 ) ST (o 2 ) 0 ET (o 1 ) ET (o 2 ) 0 Note that using these constraints, not only we can specify Allen's 13 temporal relationships <ref> [1] </ref> between events (cf. Figure 6), but also specify more complex quantitative relationships that cannot be expressed in Allen's framework. For instance, in Allen's approach, it is possible to state that event A occurs before event B.
Reference: [2] <author> K.S. Candan, V.S. Subrahmanian, and P. Venkat Rangan. </author> <title> (1995) Collaborative Multimedia Systems: Synthesis of Media Objects, </title> <note> Submitted for publication, </note> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: We will develop an incremental algorithm for this purpose. 2 This paper is part of a long term project on developing support for collaborative multimedia systems, jointly between University of Maryland and University of California, San Diego. In our first paper on this topic <ref> [2] </ref>, we developed techniques whereby objects could be routed across a network (and possibly transformed along the way) in such a way that the person (i.e. author) requesting the object received it at the lowest possible cost and at the desired quality. <p> Question (3) above was recently studied in detail by Candan, Subrahmanian and Venkat Rangan <ref> [2] </ref>. The primary aim of this paper is to study question (4) above. In order to have a solution to this problem, the properties and the structure of the COMS environment needs to be identified. <p> Wolf et al [24] show how an application can be shared among heterogeneous systems. They compare two methods for heterogeneous sharing: one optimizes transmission in the system and other optimizes conversions between objects. Candan et. al. <ref> [2] </ref> develop a formal framework within which objects may be routed and transformed from one network node to the site of an author in such a way that the desired quality is maintained and the author's host machine capabilities are adequate to process the object. <p> Furthermore, these algorithms work independently of whether temporal constraints, spatial constraints, or QoS constraints are being considered. This paper is part of a joint effort between the University of California, San Diego. In our first paper on this topic <ref> [2] </ref>, we developed techniques whereby objects could be routed across a network (and possibly transformed along the way) in such a way that the person (I.e. author) requesting the object received it at the lowest possible cost and at the desired quality.
Reference: [3] <author> T.H. Cormen, C.E. Leiserson and R.L. Rivest, </author> <title> "Introduction to Algorithms", </title> <publisher> McGraw Hill Publishers. </publisher>
Reference-contexts: Optimal algorithms for this purpose were developed by Bellman and Ford <ref> [3] </ref>. We may use a single unified data structure for difference constraints to handle temporal, spatial and QoS constraints. This data structure is shown in Figure 9. We now describe the basic intuition underlying this data structure: 1. <p> If no solution exists, then find a way of relaxing these constraints minimally so as to make the original unsolvable set of constraints solvable. It is well known that solving a set of difference constraints is equivalent to finding the shortest path in the graph associated with those constraints <ref> [3] </ref> in the manner described earlier on. <p> Note that, the negative cycles in the graph correspond to the set of conflicts given in example 7.1. Though most graph algorithms for computing shortest paths cannot handle negative cycles, the well known Bellman-Ford shortest path algorithm can deal with negative cycles in the graph <ref> [3] </ref>. This algorithm also detects the presence of a negative cycle that is reachable from the start of multimedia document presentation. If there is no cycle, the algorithm produces the shortest paths and their weights.
Reference: [4] <author> D. Ferrari, </author> <title> `Client Requirements For Real-Time Communication Services', </title> <journal> IEEE Communication Magazine, </journal> <volume> Vol. 28, No. 11, Nov. '90, </volume> <pages> pp. 65-72. </pages>
Reference-contexts: Delay Jitter Constraints: Delay jitter constraints are specified as the maximum tolerable variations in the delay suffered by an object or a network packet <ref> [4, 5] </ref>. <p> Cell Loss Probability Constraints: The cell loss probability constraints describe the maximum percentage of cells (or the network packets) that can be lost during an object transfer <ref> [4, 5] </ref>.
Reference: [5] <author> D. Ferrari, J. Ramaekers and G. Ventre, </author> <title> `Client-Network Interactions in Quality of Service Communication Environments', </title> <booktitle> Proc. of High Performance Networking, 4th IFIP Conf. on High Performance Networking, Liege, </booktitle> <address> Belgium, 14-18, </address> <month> December '92. </month>
Reference-contexts: Delay Jitter Constraints: Delay jitter constraints are specified as the maximum tolerable variations in the delay suffered by an object or a network packet <ref> [4, 5] </ref>. <p> Cell Loss Probability Constraints: The cell loss probability constraints describe the maximum percentage of cells (or the network packets) that can be lost during an object transfer <ref> [4, 5] </ref>.
Reference: [6] <author> H. Gajewska, "Argo: </author> <title> A System for Distributed Collaboration", </title> <booktitle> ACM Multimedia 94, </booktitle> <pages> Pages 433-440. </pages>
Reference-contexts: Gong [8] studies some of the important issues in multimedia conferencing over packet switched networks, and provides solutions to the problems that arise in multipoint audio and video control. The Argo system <ref> [6] </ref> on the other hand, is built to let users collaborate remotely using video, audio, shared applications, and whiteboards. Wolf et al [24] show how an application can be shared among heterogeneous systems.
Reference: [7] <author> A. Ginsberg and S. Ahuja, </author> <title> "Automating envisionment of virtual meeting room histories", </title> <booktitle> ACM Multimedia 95, </booktitle> <pages> Pages 65-76. </pages>
Reference-contexts: Furthermore, these algorithms are provably correct and their complexity has been analyzed and proved to be always polynomial-time. Ahuja's group at AT&T <ref> [7] </ref> also has had significant contributions in collaborative services. They propose a method for generating visual representations of recorded histories of distributed collaborations, so that remote collaborators can easily access information that will let them understand how the collaborative environment evolved to a particular state.
Reference: [8] <author> F. Gong, </author> <title> "Multipoint Audio and Video Control for Packet-Based Multimedia Conferencing", </title> <booktitle> ACM Multimedia 94, </booktitle> <pages> Pages 425-432. </pages>
Reference-contexts: Using our work in conjunction with these two works to maintain versions of documents as they are altered over a period of time. Gong <ref> [8] </ref> studies some of the important issues in multimedia conferencing over packet switched networks, and provides solutions to the problems that arise in multipoint audio and video control. The Argo system [6] on the other hand, is built to let users collaborate remotely using video, audio, shared applications, and whiteboards.
Reference: [9] <author> F. Hillier and G. Lieberman. </author> <note> (1974) Operations Research, Holden-Day. 33 </note>
Reference-contexts: We show that spatial, temporal, and QoS constraints can all be uniformly described within a small class of the language of real valued linear constraints. This class of constraints are referred to in the Operations Research literature as difference constraints. While generalized linear constraints <ref> [9] </ref> have the form a 1 x 1 + a 2 x 2 + + a n x n b (1) where a 1 ; : : : ; a n ; b are rational numbers (positive and negative), and x 1 ; : : : ; x n range over <p> In the next few sections, we will study the precise structure of these constraints. 4 Specification of Temporal Constraints Associated with each object O in a multimedia document D, we associate a set, T O , of temporal constraints. As is customary in operations research <ref> [9] </ref>, constraints are constructed from variables.
Reference: [10] <author> T. Imai, K. Yamaguchi, T. Muranaga, </author> <title> "Hypermedia Conversation Recording to Preserve Informal Artifacts in Realtime", </title> <booktitle> ACM Multimedia 94, </booktitle> <pages> Pages 417-424. </pages>
Reference-contexts: They propose a method for generating visual representations of recorded histories of distributed collaborations, so that remote collaborators can easily access information that will let them understand how the collaborative environment evolved to a particular state. In <ref> [10] </ref>, Imai et al. show how to record the artifacts of a realtime collaboration so that when the collaboration is concluded, the collaborators have access not only to the final document, but also to the artifacts (handwritten notes, voice annotations etc.) that led them to this document.
Reference: [11] <author> H. Korth and A. Silberschatz. </author> <title> (1986) "Database System Concepts", </title> <publisher> McGraw Hill. </publisher>
Reference-contexts: Furthermore, the authors may have priorities to resolve conflicts generated by the simultaneous editing of shared objects. The modifications performed on the original copy is immediately available to all users. Methods to study concurrent read-write accesses have been extensively studied in the operating systems community and database community <ref> [11] </ref>, and hence we do not address these issues within the framework of this paper. 3 Multimedia Objects: Formal Definition A multimedia document comprises of objects of different types such as video, audio, image and text. Each media object is presented in accordance with certain spatial and temporal constraints.
Reference: [12] <author> L. Li, A. Karmouch and N.D. Georganas, </author> <title> "Multimedia Teleorchestra With Independent Sources : Part 1 and Part 2", </title> <journal> ACM/Springer-Verlag Journal of Multimedia Systems, </journal> <volume> vol. 1, no. 4, </volume> <month> February </month> <year> 1994, </year> <month> pp.143-165. </month>
Reference-contexts: Also, the specifications of the requirements are fixed in nature. Synchronization has also been studied by Manohar [14]. They study methods to enable the faithful replay of multimedia objects under varying system parameters. To accomplish synchronization of different session objects, they provide an adaptive scheduling algorithm. In <ref> [12] </ref>, a Time-flow Graph (TFG) model has been proposed to represent "fuzzy" or imprecise temporal relationships. Multimedia objects are described by their presentation intervals. Given any two time intervals, there are thirteen ways in which they can be related.
Reference: [13] <author> T.D.C. Little and A Ghafoor, </author> <title> `Synchronization and Storage Models for Multimedia Objects', </title> <journal> IEEE J. on Selected Areas of Communication, </journal> <volume> vol. 8, no. 3, </volume> <month> April </month> <year> 1990, </year> <pages> pp. 413-427. </pages>
Reference-contexts: Their formalization captures the requirements of various types of interactive and non-interactive collaborations. They also implemented a prototype collaboration management system based on their formalism. Significant contributions have been made in the area of temporal specification of multimedia 31 presentations. Petri nets based models have been suggested in <ref> [13, 16, 19, 17] </ref> for specifying the tem-poral and synchronization characteristics of a multimedia presentation. Concurrent programming language based approach has been suggested in [21].
Reference: [14] <author> N.R. Manohar and A. Prakash, </author> <title> "Dealing with synchronization and timing variability in the playback of interactive session recordings", </title> <booktitle> ACM Multimedia 95, </booktitle> <pages> Pages 45-56. </pages>
Reference-contexts: However, these works do not address the issues that arise in an collaborative environment. Also, the specifications of the requirements are fixed in nature. Synchronization has also been studied by Manohar <ref> [14] </ref>. They study methods to enable the faithful replay of multimedia objects under varying system parameters. To accomplish synchronization of different session objects, they provide an adaptive scheduling algorithm. In [12], a Time-flow Graph (TFG) model has been proposed to represent "fuzzy" or imprecise temporal relationships.
Reference: [15] <author> N. Pahuja, B.N. Jain and G.M. Shroff, </author> <title> `Multimedia Information Objects: A Conceptual Model for Representing Synchronization', </title> <booktitle> to appear in International Conference on Computer Networks, </booktitle> <address> Networks'96, Bombay, India, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: Concurrent programming language based approach has been suggested in [21]. A Context Free Grammar based approach has been proposed in [19] for describing the synchronization characteristics of an orchestrated presentation and for translating the characteristics into the network traffic that might be generated by an orchestrated presentation. In <ref> [15] </ref> user views of a document are represented by means of attribute based selection of a Petri nets based specification. However, these works do not address the issues that arise in an collaborative environment. Also, the specifications of the requirements are fixed in nature.
Reference: [16] <author> B. Prabhakaran and S.V. Raghavan, </author> <title> `Synchronization Models For Multimedia Presentation With User Participation', </title> <journal> ACM/Springer-Verlag Journal of Multimedia Systems, vol.2, </journal> <volume> no. 2, </volume> <month> August </month> <year> 1994, </year> <pages> pp. 53-62. </pages> <booktitle> Also in the Proceedings of the First ACM Conference on MultiMedia Systems, </booktitle> <address> Anaheim, California, </address> <month> August </month> <year> 1993, </year> <month> pp.157-166. </month>
Reference-contexts: Their formalization captures the requirements of various types of interactive and non-interactive collaborations. They also implemented a prototype collaboration management system based on their formalism. Significant contributions have been made in the area of temporal specification of multimedia 31 presentations. Petri nets based models have been suggested in <ref> [13, 16, 19, 17] </ref> for specifying the tem-poral and synchronization characteristics of a multimedia presentation. Concurrent programming language based approach has been suggested in [21].
Reference: [17] <author> S.V. Raghavan, B. Prabhakaran and Satish K. </author> <title> Tripathi - `Synchronization Representation and Traffic Source Modeling in Orchestrated Presentation', to appear in the special issue on Multimedia Synchronization, </title> <journal> IEEE Journal on Selected Areas in Communication. </journal>
Reference-contexts: The QoS required for viewing (or editing) a multimedia document depends on the size of the various media objects and the time available for retrieving the objects i.e., their temporal constraints. Methodologies have been proposed in <ref> [17, 19] </ref> to identify the QoS requirements of a multimedia document. For a typical stream i in a multimedia document, the objects may be stored in different servers. <p> It should be noted that the same methodology can be adopted for describing other QoS parameters such as delay, delay jitter and packet (or cell) loss probabilities. Let us consider the throughput requirements for presenting the multimedia document. <ref> [17, 18, 19] </ref> presents methodologies to identify the throughput requirements for an orchestrated presentation. A similar methodology can be used to derive the throughput requirement of a multimedia document presentation. <p> Their formalization captures the requirements of various types of interactive and non-interactive collaborations. They also implemented a prototype collaboration management system based on their formalism. Significant contributions have been made in the area of temporal specification of multimedia 31 presentations. Petri nets based models have been suggested in <ref> [13, 16, 19, 17] </ref> for specifying the tem-poral and synchronization characteristics of a multimedia presentation. Concurrent programming language based approach has been suggested in [21].
Reference: [18] <author> S.V. Raghavan, B. Prabhakaran and Satish K. </author> <title> Tripathi - `Quality of Service Considerations For Distributed, Orchestrated Multimedia Presentation', </title> <booktitle> Proceedings of High Performance Networking 94 (HPN'94), </booktitle> <address> Paris, France, </address> <month> July </month> <year> 1994, </year> <pages> pp. 217-238. </pages> <note> Also available as Technical Report : CS-TR-3167, </note> <institution> UMIACS-TR-93-113, University of Maryland, College Park, Computer Science Technical Report Series, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: It should be noted that the same methodology can be adopted for describing other QoS parameters such as delay, delay jitter and packet (or cell) loss probabilities. Let us consider the throughput requirements for presenting the multimedia document. <ref> [17, 18, 19] </ref> presents methodologies to identify the throughput requirements for an orchestrated presentation. A similar methodology can be used to derive the throughput requirement of a multimedia document presentation.
Reference: [19] <author> S.V. Raghavan, B. Prabhakaran and Satish K. </author> <note> Tripathi - `Handling QoS Negotiations in Distributed Orchestrated Presentation', to be published in Journal of High Speed Networking. </note>
Reference-contexts: The QoS required for viewing (or editing) a multimedia document depends on the size of the various media objects and the time available for retrieving the objects i.e., their temporal constraints. Methodologies have been proposed in <ref> [17, 19] </ref> to identify the QoS requirements of a multimedia document. For a typical stream i in a multimedia document, the objects may be stored in different servers. <p> It should be noted that the same methodology can be adopted for describing other QoS parameters such as delay, delay jitter and packet (or cell) loss probabilities. Let us consider the throughput requirements for presenting the multimedia document. <ref> [17, 18, 19] </ref> presents methodologies to identify the throughput requirements for an orchestrated presentation. A similar methodology can be used to derive the throughput requirement of a multimedia document presentation. <p> Their formalization captures the requirements of various types of interactive and non-interactive collaborations. They also implemented a prototype collaboration management system based on their formalism. Significant contributions have been made in the area of temporal specification of multimedia 31 presentations. Petri nets based models have been suggested in <ref> [13, 16, 19, 17] </ref> for specifying the tem-poral and synchronization characteristics of a multimedia presentation. Concurrent programming language based approach has been suggested in [21]. <p> Petri nets based models have been suggested in [13, 16, 19, 17] for specifying the tem-poral and synchronization characteristics of a multimedia presentation. Concurrent programming language based approach has been suggested in [21]. A Context Free Grammar based approach has been proposed in <ref> [19] </ref> for describing the synchronization characteristics of an orchestrated presentation and for translating the characteristics into the network traffic that might be generated by an orchestrated presentation. In [15] user views of a document are represented by means of attribute based selection of a Petri nets based specification.
Reference: [20] <author> S. Rajan, P.V. Rangan, and H.M. Vin, </author> <title> "A Formal Basis for Structured Multimedia Collaborations", </title> <booktitle> IEEE Intl. Conf. on Multimedia Computing and Systems, </booktitle> <year> 1995. </year>
Reference-contexts: Wray et al. [25] have built an experimental collaborative environment called Medusa which integrates data from heterogeneous hardware devices. Medusa provides an environment which facilitates rapid pro-totyping of new applications. Rajan, Vin et al. <ref> [20] </ref> started some work on formalizing the notion of multimedia collaboration. They provide a basis which can support a wide spectrum of structured multimedia collaborations. Their formalization captures the requirements of various types of interactive and non-interactive collaborations. They also implemented a prototype collaboration management system based on their formalism.
Reference: [21] <author> R. Steinmetz, </author> <title> `Synchronization Properties in Multimedia Systems', </title> <journal> IEEE J. on Selected Areas of Communication, </journal> <volume> vol. 8, no. 3, </volume> <month> April </month> <year> 1990, </year> <pages> pp. 401-412. </pages>
Reference-contexts: Significant contributions have been made in the area of temporal specification of multimedia 31 presentations. Petri nets based models have been suggested in [13, 16, 19, 17] for specifying the tem-poral and synchronization characteristics of a multimedia presentation. Concurrent programming language based approach has been suggested in <ref> [21] </ref>. A Context Free Grammar based approach has been proposed in [19] for describing the synchronization characteristics of an orchestrated presentation and for translating the characteristics into the network traffic that might be generated by an orchestrated presentation.
Reference: [22] <author> P.D. Stotts and R. Furuta, </author> <title> `Temporal Hyperprogramming', </title> <journal> Journal of Visual Languages and Computing, </journal> <month> Sept. </month> <year> 1990, </year> <pages> pp. 237-253. </pages>
Reference: [23] <author> T.M. Wittenburg and T.D.C. Little, </author> <title> "An Adaptive Document Management System for Shared Multimedia Data", </title> <booktitle> IEEE Intl. Conf. on Multimedia Computing and Systems, </booktitle> <year> 1994, </year> <pages> Pages 245-254. </pages>
Reference-contexts: Furthermore, we develop techniques that will optimally relax the presentation constraints in the event that these constraints are inconsistent. Finally, our framework applies uniformly not just to temporal aspects of multimedia systems, but to spatial and QoS as well. Little <ref> [23] </ref> has presented an elegant document management system for shared data and provided a data model (P OM ) which permits dynamic compositions of mixed-media documents. Wray et al. [25] have built an experimental collaborative environment called Medusa which integrates data from heterogeneous hardware devices.
Reference: [24] <author> K.H. Wolf, K. Froitzheim and P. Schulthess, </author> <title> "Multimedia Application Sharing in a Hetero--geneous Environment", </title> <booktitle> ACM Multimedia 95, </booktitle> <pages> Pages 57-64. </pages>
Reference-contexts: The Argo system [6] on the other hand, is built to let users collaborate remotely using video, audio, shared applications, and whiteboards. Wolf et al <ref> [24] </ref> show how an application can be shared among heterogeneous systems. They compare two methods for heterogeneous sharing: one optimizes transmission in the system and other optimizes conversions between objects.

References-found: 24

