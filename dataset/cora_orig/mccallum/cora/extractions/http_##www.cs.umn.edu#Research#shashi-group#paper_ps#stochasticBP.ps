URL: http://www.cs.umn.edu/Research/shashi-group/paper_ps/stochasticBP.ps
Refering-URL: http://www.cs.umn.edu/Research/shashi-group/paper_list.html
Root-URL: http://www.cs.umn.edu
Title: Generalization by Neural Networks  
Author: Shashi Shekhar Minesh B. Amin 
Address: Minneapolis, MN 55455.  
Affiliation: Department of Computer Science University of Minnesota  
Abstract: Neural networks have traditionally been applied to recognition problems, and most learning algorithms are tailored to those problems. We discuss the requirements of learning for generalization, where the traditional methods based on gradient descent have limited success. We present a new stochastic learning algorithm based on simulated annealing in weight space. We verify the convergence properties and feasibility of the algorithm. We also describe an implementation of the algorithm and validation experiments. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Sejnowski, T.J. and Wasserman,P.D., </author> <title> Neural Networks, Part 2, </title> <journal> IEEE Expert Magazine, </journal> <volume> 3(1)(spring 1988.). </volume> <publisher> John Hopkins Univ., </publisher> <address> Baltimore, MD. </address>
Reference-contexts: 1. Introduction Neural networks are being applied to a wide variety of applications from speech generation <ref> [1] </ref>, to handwriting recognition [2]. Last decade has seen great advances in design of neural networks for a class of problems called recognition problems, and in design of learning algorithms [3-5, 5-7]. The learning of weights for neural network for many recognition problem is no longer a difficult task. <p> The learning of weights for neural network for many recognition problem is no longer a difficult task. However, designing a neural network for generalization problem is not well understood. Domains of neural network applications can be classified into two broad categories-- recognition and generalization <ref> [1, 8] </ref>. For both classes, we first train the neural network on a set of input-output pairs (I 1 , O 1 ), (I 2 , O 2 ),...,(I n , O n ).
Reference: 2. <author> K. Yamada, H. Kami, J. Tsukumo, and T. Temma, </author> <title> Handwritten numeral recognition by multi-layered neural network with improved learning algorithm, </title> <booktitle> Proc. Intl Conf. on Neural Networks, IEEE and ICNN, </booktitle> <month> (June </month> <year> 1989). </year>
Reference-contexts: 1. Introduction Neural networks are being applied to a wide variety of applications from speech generation [1], to handwriting recognition <ref> [2] </ref>. Last decade has seen great advances in design of neural networks for a class of problems called recognition problems, and in design of learning algorithms [3-5, 5-7]. The learning of weights for neural network for many recognition problem is no longer a difficult task. <p> The trained network is expected to reproduce the output O j corresponding to I j , in spite of the noise. Shape recognition [9, 10], and handwriting recognition <ref> [2] </ref> are examples of recognition prob lems. On the other hand, in generalization problems, the trained neural network is tested with input I n+1 , which is distinct from the inputs I 1 , I 2 ,...,I n used for training the network, as shown in Fig.1.
Reference: 3. <author> M. A. Fanty, </author> <title> Learning in Neural Networks, </title> <type> Ph.D. Thesis TR252, </type> <institution> C.S.Dept., Univ. of Rochester, </institution> <year> (1988). </year>
Reference: 4. <author> D.E.Rumelhart, G.E.Hinton, and R.J.Williams, </author> <title> Learning Internal Representations by Back Propagating Errors, </title> <note> Nature 323 pp. </note> <month> 533-536 </month> <year> (1986). </year>
Reference-contexts: The neural network used in generalization problems tend to be simpler with small number of hidden nodes, layers, and interconnection edges and weights, enabling one to use computationally sophisticated algorithms. Most of the earlier work in neural networks <ref> [4, 9] </ref> is related to recognition problems. There has been little research towards developing neural network models for generalization problems [16, 17]. - 3 - We present a new learning algorithm, stochastic backpropagation for generalization problems. <p> The outer loop changes the control parameter slowly to the final value near 0. This corresponds to slow cooling to achieve configurations with globally minimum error. The steps inside the innermost loop combine backpropagation with transitions for simulated annealing.. We use the BACKPROP, the backpropagation algorithm, <ref> [4] </ref> as a subroutine to compute the error derivatives E /w lm with respect to various weights. These deriva tives help us to estimate the change in error function, when a particular weight is changed by d. PERTURB produces a neighboring configuration by changing a randomly chosen weight by d.
Reference: 5. <author> D. H.Ackley, G.E.Hinton, and T.J. Sejnowski, </author> <title> A Learning Algorithm for Boltzman Machine, </title> <journal> Cognitive Science 9 pp. </journal> <month> 147-169 </month> <year> (1985). </year>
Reference-contexts: One may change the weights simul taneously to avoid conflicting local weight adjustments. The boltzman machine is stochastic in nature and the aim of learning the weights is to achieve a probability distribution of input-output mapping. The boltzman machine learning <ref> [5] </ref> is based on a series of simulated annealing on the state space of network. State space for the network can be characterized by defining the state of the network.
Reference: 6. <author> S. E. Hampsin and D. J. Volper, </author> <title> Linear Function Neurons: Structure and Training, </title> <journal> Biological Cybernetics 53 pp. </journal> <month> 203-217 </month> <year> (1986). </year>
Reference: 7. <author> G. Carpenter and S. Grossberg, </author> <title> The ART of adaptive pattern recognition by a self-organizing neural network, </title> <note> Computer 21 pp. </note> <month> 77-88 </month> <year> (1988). </year>
Reference: 8. <author> D. E. Rumelhart, </author> <title> Brain Style Computation: Learning and Generalization, An introduction to neural and electronic networks, </title> <publisher> Acadmemic Press, </publisher> <year> (1990). </year>
Reference-contexts: The learning of weights for neural network for many recognition problem is no longer a difficult task. However, designing a neural network for generalization problem is not well understood. Domains of neural network applications can be classified into two broad categories-- recognition and generalization <ref> [1, 8] </ref>. For both classes, we first train the neural network on a set of input-output pairs (I 1 , O 1 ), (I 2 , O 2 ),...,(I n , O n ). <p> We also describe an implementation of the algorithm and our experience with the algorithms in solving generalization problems. 2. Problem Formulation Generalization problems for neural networks have been formulated in three different ways: (a) analytical formalism [18-24], (b) constructive function learning [25-27], and (c) symbolic semantic network <ref> [8] </ref>. The analytical formalism focuses on the existence of networks with a capability to generalize. It also provide worst case time complexity to discover such networks to solve arbitrary generalization problems. It does not provide a way to discover the networks.
Reference: 9. <author> G.E.Hinton, </author> <title> Learning to Recognize Shapes in a Parallel Network, </title> <booktitle> Proc. 1986 Fyssen Conference, (1987). </booktitle> <publisher> Oxford University Press, Oxford. </publisher>
Reference-contexts: In recognition problems, the trained network is tested with a previously seen input I j (1 j n ) corrupted by noise as shown in Fig.1. The trained network is expected to reproduce the output O j corresponding to I j , in spite of the noise. Shape recognition <ref> [9, 10] </ref>, and handwriting recognition [2] are examples of recognition prob lems. <p> The neural network used in generalization problems tend to be simpler with small number of hidden nodes, layers, and interconnection edges and weights, enabling one to use computationally sophisticated algorithms. Most of the earlier work in neural networks <ref> [4, 9] </ref> is related to recognition problems. There has been little research towards developing neural network models for generalization problems [16, 17]. - 3 - We present a new learning algorithm, stochastic backpropagation for generalization problems. <p> Comparison with Existing Algorithms: Some of the existing learning algorithms, e.g. in Hopfield networks [30, 31], are based on memorizing the learning examples accurately. These cannot be used for prediction in generalization problems. Two of the more flexible learning methods include backpropagation <ref> [9, 32] </ref> and boltzman machine learning [33]. Both are iterative algorithms based on gradient descent on the error surface. In backpropagation the error of fit for a given set of weights is defined by Eq.
Reference: 10. <author> G.E. Hinton, </author> <title> Learning Translation Invariant Recognition in Massively Parallel Network, </title> <booktitle> Lecture Notes in Computer Science # 258, </booktitle> <pages> pp. </pages> <publisher> 1-13 Springer Verlag, </publisher> <year> (1987). </year>
Reference-contexts: In recognition problems, the trained network is tested with a previously seen input I j (1 j n ) corrupted by noise as shown in Fig.1. The trained network is expected to reproduce the output O j corresponding to I j , in spite of the noise. Shape recognition <ref> [9, 10] </ref>, and handwriting recognition [2] are examples of recognition prob lems.
Reference: 11. <author> S. Shekhar and S. Dutta, </author> <title> Bond Rating: A Non-Conservative Application of Neural Network, </title> <booktitle> Proc. IEEE Intl. Conf. on Neural Networks, </booktitle> <address> (July, 1988). San Diego. </address>
Reference-contexts: The network is expected to correctly predict the output O n+1 for the input I n+1 from the model it has learned through training. Typical examples of generalization problems are Bond Rating <ref> [11] </ref> and Robotics [12]. Neural networks for generalization problems are important, since there are many applications, of enormous importance in the real world [13-15] which would benefit from this work. <p> In many of these applications it is difficult to successfully apply either conventional mathematical techniques (e.g., statistical regression) or standard AI approaches (e.g., rule based systems). A neural network with generalization ability will be useful for such domains <ref> [11] </ref>, because it does not require an a priori specification of a functional domain model; rather it attempts to learn the underlying domain model from the training input-output examples. - 2 - T e s t i n g N e t w o r k o f N e t
Reference: 12. <author> R. </author> <title> Eckmiller, The design of intelligent robot as a federation of geometric mchines, An introduction to neural and electronic networks, </title> <publisher> Acadmemic Press, </publisher> <year> (1990). </year>
Reference-contexts: The network is expected to correctly predict the output O n+1 for the input I n+1 from the model it has learned through training. Typical examples of generalization problems are Bond Rating [11] and Robotics <ref> [12] </ref>. Neural networks for generalization problems are important, since there are many applications, of enormous importance in the real world [13-15] which would benefit from this work.
Reference: 13. <author> Hecht Nielsen, </author> <title> Neurocomputer Applications, </title> <editor> Neural Computers (Ed R. Eckmiller & Malsburg) F41Springer-Verlag Ber-lin Heidelberg, </editor> <year> (1988). </year>
Reference: 14. <author> A. Irani, J. P. Matts, J.M.Long, and J. R. Slagle, </author> <title> Using Artificial Neural Nets for Statistical Discovery: Observations after using Back-Propagation, Expert Systems, and Multiple-Linear Regression on Clinical Trial Data, </title> <institution> University of Min-nesota Technical Report, (1989.). </institution>
Reference: 15. <author> P. Werbs, </author> <title> Beyond Regression: New Tools for Prediction and Analysis in the Behaviorial Sciences, </title> <type> Ph.D. thesis, </type> <month> (Nov. </month> <year> 1974). </year> <institution> Applied math., Harvard University </institution>
Reference: 16. <author> Gallant,S.I., </author> <title> Connectionist Expert Systems, </title> <journal> Comm. of the ACM, 31(2)(Feb. 1988.). </journal>
Reference-contexts: Most of the earlier work in neural networks [4, 9] is related to recognition problems. There has been little research towards developing neural network models for generalization problems <ref> [16, 17] </ref>. - 3 - We present a new learning algorithm, stochastic backpropagation for generalization problems. We verify the convergence of the algorithm and provide theoretical arguments towards the capability of the proposed algorithm to discover optimal weights.
Reference: 17. <author> Parunak,H.V., </author> <title> Material Handling: A Conservative Domain for Neural Connectivity and Propagation, </title> <booktitle> Proc. AAAI Conf., </booktitle> <pages> pp. 307-311. </pages> <year> (1987). </year>
Reference-contexts: Most of the earlier work in neural networks [4, 9] is related to recognition problems. There has been little research towards developing neural network models for generalization problems <ref> [16, 17] </ref>. - 3 - We present a new learning algorithm, stochastic backpropagation for generalization problems. We verify the convergence of the algorithm and provide theoretical arguments towards the capability of the proposed algorithm to discover optimal weights.
Reference: 18. <author> M. Minsky and S. Papert, </author> <title> Perceptrons, </title> <note> MIT Press (1968). reprinted in 1988 </note>
Reference: 19. <author> A. K. </author> <title> Kolmogorov, On the representation of continuous functions of several variablesby superposition of continuous functions of one variable and addition, </title> <journal> Doklady Akademii Nauk 114 pp. </journal> <pages> 369-373 SSSR, </pages> <year> (1957). </year>
Reference: 20. <author> S. Patarnello and P. Carnevali, </author> <title> Meaning of Generalization (ch. 4 of Learning Capabilities of Boolean Networks), Neural Computing Architectures (Ed. </title> <editor> I. Aleksander), </editor> <publisher> The MIT Press, </publisher> <year> (1989). </year>
Reference: 21. <author> M. Arai, </author> <title> Mapping Abilities of Three Layered Neural Networks, </title> <booktitle> Proc. Intl. Jt. Conf. on Neural Network, IEEE and INNS, </booktitle> <month> (June </month> <year> 1989). </year> <month> - 16 </month> - 
Reference: 22. <author> A. Blum and R. L. Rivest, </author> <title> Training a 3-node neural net is NP-complete, </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <pages> pp. </pages> <publisher> 494-501 Morgan Kaufmann, </publisher> <year> (1989). </year>
Reference: 23. <author> S. Judd, </author> <title> On Complexity of Loading Shallow Networks, Journal of Complexity 4 pp. </title> <publisher> 177-182 Academic Press, </publisher> <year> (1988). </year>
Reference: 24. <author> J. Stephen Judd, </author> <title> Neural Network Design and the Complexity of Learning, </title> <publisher> MIT Press (1990). </publisher>
Reference: 25. <author> S. Ahmad and G. Tesauro, </author> <title> Scaling and Generalization in Neural Networks: A case study, </title> <booktitle> Intl Conf. Neural Info. Processing Systems (1988). </booktitle>
Reference-contexts: Usually more than one function can fit the given set of learning samples of input-output pairs. It makes the generalization problem harder. For example, learning a specific boolean function from a subset of domain is difficult <ref> [25] </ref> since several boolean functions over the domain can fit the learning samples. There is little consensus on a criteria to prefer one of the candidate boolean functions over the rest to break the tie. We restrict our attention to the functions over the set of real numbers.
Reference: 26. <author> C.V. Ramamoorthy and S. Shekhar, </author> <title> Stochastic Backproagation: A Learning Algorithm for Generalization Problems, </title> <booktitle> Proc. IEEE COMPSAC Conf., </booktitle> <address> (1989.). Orlando, FL. </address>
Reference: 27. <author> J. Stephen Judd, </author> <title> Memorization and Generalization (Ch. 7), Neural Network Design and the Complexity of Learning, </title> <publisher> MIT Press, </publisher> <year> (1990). </year>
Reference: 28. <author> J. Sietsma and R. J. F. Dow, </author> <title> Creating Artificial Neural Networks That Generalize, Neural Networks 4 pp. </title> <publisher> 67-69 Per-gamon Press, </publisher> <year> (1991). </year>
Reference-contexts: The task in signal detection problem is to learn to recognize a parameter of the function f: I -&gt; O, rather than learn the function. Recognizing the frequency of given sinusoidal function is an example of signal detection problem. Backpropagation neural networks has been applied successfully to this problem <ref> [28] </ref>. We focus on the constructive function learning formulation in terms of learning a numeric function. A simple neural network can be described as a directed graph G = (V, E).
Reference: 29. <author> N. A. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller, </author> <title> Equation of State Calculations by Fast Computing Machines, </title> <journal> J. of Chem. Physics 21 pp. </journal> <month> 1087-1092 </month> <year> (1953). </year>
Reference-contexts: The simulated annealing procedure searches the weight space for the configuration W opt to minimizes the error-to-fit function E (W i ). The search procedure is based on the Monte Carlo method <ref> [29] </ref>. Given the current configuration W i of the network, characterized by the values of its weights, a small, randomly generated, perturbation is applied by a small change in a randomly chosen weight.
Reference: 30. <author> J. J. </author> <title> Hopfield, Neural networks and physical systems with emergent collective computing abilities, </title> <booktitle> Proc. </booktitle> <institution> of the Natl Academy of Sciences USA 79(8) pp. </institution> <month> 2554-2558 </month> <year> (1982). </year>
Reference-contexts: It is better to modify the backpropagation algorithm to compute only one derivative, which is required. Comparison with Existing Algorithms: Some of the existing learning algorithms, e.g. in Hopfield networks <ref> [30, 31] </ref>, are based on memorizing the learning examples accurately. These cannot be used for prediction in generalization problems. Two of the more flexible learning methods include backpropagation [9, 32] and boltzman machine learning [33]. Both are iterative algorithms based on gradient descent on the error surface.
Reference: 31. <author> J. J. Hopfield and D. W. Tank, </author> <title> Neural computation of decisions in optimization problems, </title> <journal> Biological Cybernetics 52(3) pp. </journal> <month> 141-152 </month> <year> (1985). </year>
Reference-contexts: It is better to modify the backpropagation algorithm to compute only one derivative, which is required. Comparison with Existing Algorithms: Some of the existing learning algorithms, e.g. in Hopfield networks <ref> [30, 31] </ref>, are based on memorizing the learning examples accurately. These cannot be used for prediction in generalization problems. Two of the more flexible learning methods include backpropagation [9, 32] and boltzman machine learning [33]. Both are iterative algorithms based on gradient descent on the error surface.
Reference: 32. <author> D.E.Rumelhart and J.LMcClelland, </author> <title> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </title> <publisher> Bradford Books, </publisher> <address> Cambridge, MA. </address> <year> 1(1986). </year>
Reference-contexts: Comparison with Existing Algorithms: Some of the existing learning algorithms, e.g. in Hopfield networks [30, 31], are based on memorizing the learning examples accurately. These cannot be used for prediction in generalization problems. Two of the more flexible learning methods include backpropagation <ref> [9, 32] </ref> and boltzman machine learning [33]. Both are iterative algorithms based on gradient descent on the error surface. In backpropagation the error of fit for a given set of weights is defined by Eq.
Reference: 33. <author> G.E. Hinton, T.J. Sejnowski, and D.H. Ackley, </author> <title> Boltzman Machines: Constraint Stisfaction Machines That Learn, </title> <institution> Tech.Rep. CMU-CS-84-119, Carnegie Mellon University, </institution> <year> (1984). </year>
Reference-contexts: Comparison with Existing Algorithms: Some of the existing learning algorithms, e.g. in Hopfield networks [30, 31], are based on memorizing the learning examples accurately. These cannot be used for prediction in generalization problems. Two of the more flexible learning methods include backpropagation [9, 32] and boltzman machine learning <ref> [33] </ref>. Both are iterative algorithms based on gradient descent on the error surface. In backpropagation the error of fit for a given set of weights is defined by Eq. <p> The learning algorithm aims to achieve a certain probability distribution over the states, and does a gradient descent to minimize the error in probability distribution. Our use of simulated annealing in weight space is quite different from the boltzman machine <ref> [33] </ref>, where simulated annealing is carried out in the state space of the network. These learning methods work only when the cost/error surface is concave. Since these algorithms are based on a simple heuristic of gradient descent, these can get stuck in local minima.
Reference: 34. <author> S. Judd, </author> <title> Complexity of Connectionist Learning with Various Node Functions, </title> <type> Tech. Rep. 87-60, </type> <institution> Univ. </institution> <address> of Mass., Amherst, MA, </address> <year> (1987). </year>
Reference-contexts: Furthermore these can get stuck at plateaus, where the gradient is very small, as shown in Fig.4. These algorithms cannot guarantee the optimality of discovered weights. The learning problem is NP-complete in general <ref> [34] </ref> and remains NP-complete under several restrictions. it is not surprising that heuristic learning algorithms like backpropagation do not always work, and can not be trusted to find the globally optimal weights for generalization problems.
Reference: 35. <author> M.R.Garey and D.S.Johnson, </author> <title> Computers and Interactability: A Guide to the Theory of NP-Completeness, </title> <publisher> Freeman, </publisher> <year> (1979). </year>
Reference-contexts: There are two ways of approaching NP-complete problems: (a) approximation methods <ref> [35] </ref>, and (b) stochastic enumeration method such as simulated annealing [36]. Since it is difficult to formulate a general approximation method for neural network learning, we use the simulated annealing method. We extend the backpropagation algorithm with stochastic weight changes for learning the weights.
Reference: 36. <author> S. Kirkpatrick, </author> <title> Optimization by simulated annealing, </title> <note> Science 220 pp. 671-680 (May 13, </note> <year> 1983). </year>
Reference-contexts: There are two ways of approaching NP-complete problems: (a) approximation methods [35], and (b) stochastic enumeration method such as simulated annealing <ref> [36] </ref>. Since it is difficult to formulate a general approximation method for neural network learning, we use the simulated annealing method. We extend the backpropagation algorithm with stochastic weight changes for learning the weights.
Reference: 37. <author> W. Feller, </author> <title> An Introduction to Probability Theory and Applications, </title> <publisher> Wiley, </publisher> <address> New York 1950. </address>
Reference-contexts: This mechanisms can mathematically be described by means of a Markov Chain: a sequence of trials, where the outcome of each trial depends only on the outcome of the previous one <ref> [37] </ref>. In the case of stochastic backpropagation, the trials correspond to transitions and it is clear that the outcome of a transition depends only on the outcome of the previous one (i.e. the current configuration). <p> The proof for last step is contingent on the cooling rate and provides us with a bound on the rate. 4.1. Existence of Stationary Distribution The following theorem establishes the existence of the stationary distribution. Theorem 1 (Feller, <ref> [37] </ref> ): The stationary distribution q of a finite homogeneous Markov chain exists if the Markov chain is irreducible and aperiodic.
Reference: 38. <author> F. Romeo and A.L Sangiovanni-Vincentelli, </author> <title> Probabilistic Hill Climbing Algorithms: Properties and Applications, </title> <booktitle> Proc. 1985 Chapel Hill Conf. on VLSI, </booktitle> <pages> pp. </pages> <month> 393-417 (May </month> <year> 1985). </year>
Reference-contexts: In the case of stochastic backpropagation, the matrix P is defined by Eq. C.4. Since the definition of A guarantee that forall i,j,c &gt; 0 : A ij (T) &gt; 0 , it is sufficient for irreducibility to check that the Markov chain induced by G (T) is irreducible <ref> [38] </ref>, i.e. forall i ,j R , exists p 1, and l 0 ,l 1 ,....,l p R (l 0 =i and l p = j): - 10 - To establish aperiodicity, one uses the fact that an irreducible Markov chain is aperiodic if the following condition is satisfied [38]: forall <p> irreducible <ref> [38] </ref>, i.e. forall i ,j R , exists p 1, and l 0 ,l 1 ,....,l p R (l 0 =i and l p = j): - 10 - To establish aperiodicity, one uses the fact that an irreducible Markov chain is aperiodic if the following condition is satisfied [38]: forall T&gt;0, exists i T R : P i T i T (T)&gt;0. (C.11) Thus for aperiodicity it is sufficient to assume that forall T &gt; 0, exists i T , j T R : A i T j T (T) &lt; 1, (C.12) Using the inequality of Eq. <p> Convergence of the Stationary Distribution We now impose further conditions on the matrices A (T) and G (T) to ensure convergence of q (T) to the distribution p, as given by Eq. C.5. Theorem 2 <ref> [38] </ref>: if the two argument function y (E (i ) - E opt ,T) is taken as A i 0 ,i (T) (for an arbitrary configura tion i 0 R opt and if G (T) does not depend on T, then the stationary distribution q (T) is given by forall i <p> C.5, the following condition is sufficient <ref> [38] </ref>: (a5) forall i,j R : E (i )&lt;E ( j ) fi T fi 0 limA ij (T)=0, (C.21) Thus the conditions (C.19)-(C.23) guarantee the convergence. It can be easily checked that the matrices G (T) and A (T) for stochastic backpropagation meet all these conditions. 4.3. <p> Convergence Results We have listed the conditions under which simulated annealing converges to globally optimal configurations. Our formulation of stochastic backpropagation uses similar acceptance probabilities, generation probabilities, and cooling schedule, as the simulated annealing algorithm <ref> [38] </ref>. That is we use Metropolis criteria as acceptance criteria. We have a configuration generating mechanism, which has uniform distribution over neighbors. The generation mechanism across two neighboring configuration is symmetric. One can generate any arbitrary configuration from a given configuration in finite number of steps.
Reference: 39. <author> P.J.M. van Laarhoven, </author> <title> Simulated Annealing: Theory and Applications, </title> <address> D. </address> <publisher> Reidel Publishing Co., </publisher> <address> Boston 1987. </address>
Reference-contexts: ij (T)A jk (T); (C.18) (a3) forall i,j e R: E (i) E (j) fi A ij (T) = 1; (C.19) (a4) forall i,j e R, c &gt; 0: E (i) &lt; E (j) 0 &lt; A ij (T) &lt; 1, (C.20) The proof of this theorem is discussed elsewhere <ref> [ 39] </ref>. It is implicitly assumed that the acceptance probabilities depend only on the cost values of the configuration and not on the configurations itself.
Reference: 40. <author> B. Hajek, </author> <title> Cooling Schedules for Optimal Annealing, </title> <journal> Math. </journal> <note> of Operations Research (submitted), </note> <year> (1986). </year>
Reference-contexts: In particular, if T k is of the form T k = logk G then one can guarantee the convergence to the globally optimal configurations <ref> [40] </ref>. 4.4. Convergence Results We have listed the conditions under which simulated annealing converges to globally optimal configurations. Our formulation of stochastic backpropagation uses similar acceptance probabilities, generation probabilities, and cooling schedule, as the simulated annealing algorithm [38]. That is we use Metropolis criteria as acceptance criteria.
Reference: 41. <author> L. McClelland and D. E. Rumelhart, </author> <title> Explorations in Parallel Distributed Processing -- A Handbook of Models, Programs, and Exercises, </title> <publisher> Bradford MIT Press (1989). </publisher>
Reference-contexts: SUN 3/60). Since generaliza tion often takes large amounts of computation, we plan to reimplement the algorithm on a vector processor (e.g. Cray XMP) for speed-up. The current prototype is based on the source code of a public domain software implementing backpropagation algorithm <ref> [41] </ref>. We studied the software to reuse pertinent modules to implement stochastic backpropagation. The implementation comprises of 5000 lines of C code. It required approximately seven man months to design, code and debug. <p> The code was Provided G &gt;= D, the maximal depth of any local minima in the error surface. - 12 - verified by walkthrough method and by extensive usage. The prototype has been used in seminar courses and research. The backpropagation package <ref> [41] </ref> has three modules: user interface, learning module and testing module. User interface implements the commands by associating the commands to internal functions via a table. <p> One needs to further tune the parameters of the implementation of stochastic backpropagation to get better results. - 15 - 8. Acknowledgements We acknowledge useful help from the CS 8199 class of spring 1991, UROP at the University of Minnesota, and the backpropagation package <ref> [41] </ref>
Reference: 42. <author> E.H.L.Aarts and J.H.M. Korst, </author> <title> Simulated Annealing and Boltzman Machines, </title> <publisher> John Wiley & Sons (1989). </publisher>
Reference-contexts: We implemented the stochastic backpropagation in C with a simplified cooling schedule. The cooling schedule is based on expotential cooling T k = l * T k-1 for simplicity and efficiency. This cooling schedule has been used in many applications <ref> [42] </ref>. The main routine in the learning module, namely trial (), was modified to adjust weight based weight by randomly choosing a neighbor and accepting it by metropolis criteria. Testing module was not altered for the implementation. 6.
References-found: 42

