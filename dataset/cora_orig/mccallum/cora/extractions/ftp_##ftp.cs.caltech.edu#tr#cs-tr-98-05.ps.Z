URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-98-05.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Title: CS-TR-98-05 Creating Generative Models from Range Images  
Degree: Thesis by Ravi Ramamoorthi In Partial Fulfillment of the Requirements for the Degree of Master of Science  
Date: 1998 (Submitted March 2, 1998)  
Address: Pasadena, California  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A.H. Barr. </author> <title> Superquadrics and angle preserving transformations. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 1(1) </volume> <pages> 11-23, </pages> <year> 1981. </year>
Reference-contexts: The curves are maps from the real line to 2-dimensional space; i.e. c i : &lt; ! &lt; 2 . u and v are parameters to the curves (and hence, the surface). By convention, we usually use u; v 2 <ref> [1; 1] </ref> It can be seen that the three-dimensional shape is built from two-dimensional curves|that may for instance, control cross-sections or scaling relationships. Thus, the shape is specified in a modular way, being built from lower-dimensional components that are easier to manipulate and visualize. <p> The affine transform is composed of a rotation, translation and scaling. Each component could be represented with a different curve, each parameterized by v. fl represents the cross-section parameterized by u. It is also possible to easily represent simpler models such as profile products <ref> [1] </ref>: S (u; v) = B fl 1 (u)ffi 1 (v) ffi 2 (v) C where fl (u) = [fl 1 (u); fl 2 (u)] is the cross-section curve and the profile curve is ffi (v) = [ffi 1 (v); ffi 2 (v)]. <p> The curves are maps from the real line to 2-dimensional space; i.e. c i : &lt; ! &lt; 2 . u and v are parameters to the curves (and hence, the surface). By convention, we usually use u; v 2 <ref> [1; 1] </ref> It can be seen that the three-dimensional shape is built from two-dimensional curves|that may for instance, control cross-sections or scaling relationships. Thus, the shape is specified in a modular way, being built from lower-dimensional components that are easier to manipulate and visualize. <p> The affine transform is composed of a rotation, translation and scaling. Each component could be represented with a different curve, each parameterized by v. fl represents the cross-section parameterized by u. It is also possible to easily represent simpler models such as profile products <ref> [1] </ref>: S (u; v) = B fl 1 (u)ffi 1 (v) ffi 2 (v) C where fl (u) = [fl 1 (u); fl 2 (u)] is the cross-section curve and the profile curve is ffi (v) = [ffi 1 (v); ffi 2 (v)]. <p> Fractional Mapping: For simplicity, let us first assume that z m is a single-valued function of (x m ; y m ). We first map a range data point onto the unit square <ref> [0; 1] </ref> 2 (the inverse mapping): ff (x r ) = min max X r fi (x r ; y r ) = min (x r ) max (x r ) Y r (4.8) We then map (ff; fi) onto the model (the forward mapping) where we assume that z m <p> A mathematical representation is then given by (where the shape is denoted by P ): GEN CY L = B P (v)[0] ST (P (v)<ref> [1] </ref>; d; u)[1] C There are a few special restrictions on P . We assume that P [1] goes to 0 at the end-points and is perpendicular to the X-axis there to ensure derivative continuity of the shape (which is implicitly reflected about the X-axis as a result of the symmetry in the cross-sections). We implement this by placing a triple knot at the end-points with P [1] <p> <ref> [1] </ref> goes to 0 at the end-points and is perpendicular to the X-axis there to ensure derivative continuity of the shape (which is implicitly reflected about the X-axis as a result of the symmetry in the cross-sections). We implement this by placing a triple knot at the end-points with P [1] = 0, and also ensuring that the next control point at both ends has P [0] the same as the previous 3 to ensure the curve is perpendicular to the X-axis at the extremes. <p> The depth is estimated by considering the silhouette in the X-Z plane. Calling the depth curve "H", we obtain: V ARDEP T H = 0 @ ST ( w ST ( w 1 A (5:3) Similar to the generalized cylinder, we want H <ref> [1] </ref> to go to 0 at the end-points. Also, as shown in figure 5.4, H may go from negative to positive.
Reference: [2] <author> P.J. Besl and R.C. Jain. </author> <title> Three dimensional object recognition. </title> <journal> ACM Computing Surveys, </journal> <volume> 17(1) </volume> <pages> 75-145, </pages> <year> 1985. </year>
Reference-contexts: While there has been some research on such methods (for instance, [29]), use of stereo requires solving a correspondence problem, for which sufficiently robust algorithms have not yet been developed. Jarvis gives a good introduction and survey of range data acquisition [18]. Besl and Jain <ref> [2] </ref> survey three-dimensional object recognition and include a discussion 8 of range data acquisition. Parthasarathy et al.[24] give a classification of methods to acquire range data. To acquire a seamless 3-dimensional representation of the object being modeled, we must align multiple range images obtained from different angles. <p> While there has been some research on such methods (for instance, [29]), use of stereo requires solving a correspondence problem, for which sufficiently robust algorithms have not yet been developed. Jarvis gives a good introduction and survey of range data acquisition [18]. Besl and Jain <ref> [2] </ref> survey three-dimensional object recognition and include a discussion 8 of range data acquisition. Parthasarathy et al.[24] give a classification of methods to acquire range data. To acquire a seamless 3-dimensional representation of the object being modeled, we must align multiple range images obtained from different angles.
Reference: [3] <author> Ruud M. Bolle and Baba C. Vemuri. </author> <title> On three-dimensional surface reconstruction methods. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(1) </volume> <pages> 1-13, </pages> <month> Jan </month> <year> 1991. </year>
Reference-contexts: See the survey by Bolle and Vemuri <ref> [3] </ref> for instance. In some cases, the parametric model may be represented by an implicit function that depends on some parameters: f (x; y; z) = 0 where x, y and z are the co-ordinates. <p> See the survey by Bolle and Vemuri <ref> [3] </ref> for instance. In some cases, the parametric model may be represented by an implicit function that depends on some parameters: f (x; y; z) = 0 where x, y and z are the co-ordinates.
Reference: [4] <author> Jean-Yves Bouguet and Pietro Perona. </author> <title> 3D photography on your desk. </title> <booktitle> In International Conference on Computer Vision 98 proceedings, </booktitle> <pages> pages 43-50, </pages> <year> 1998. </year>
Reference-contexts: There has also been much interest recently in simple methods for range data acquisition using structured light. In this thesis, we use two of these techniques, due to Bouguet and Perona <ref> [4] </ref> and Trobina [30]. In the first approach, 3-dimensional shape is inferred from the deformation of the shadow of a hand-held rod rolled over a plane on which the object is placed. The second method [30] involves the projection of alternating black-and-white stripes onto the object to be scanned. <p> Assume we have a collection of objects such as cylinders, bowls, and spoons that we wish to represent, and which are effectively modeled by our chosen hierarchy. By using the range data acquisition techniques in <ref> [4] </ref> or [30], and the algorithms described in this thesis, we may automatically obtain accurate parametric models of the input objects. <p> different class of models, the user must define the appropriate generative model hierarchy or extend our hierarchy to model the desired objects. 1.2 Benefits of the Proposed Method Simplicity: To acquire the range data, we use simple techniques based on structured light due to Trobina [30] and Bouguet and Perona <ref> [4] </ref>. The latter approach requires only a desk-lamp, pencil and checkerboard apart from the camera. Using input from these approaches, we output a simple and intuitive object description in the form of a compact generative model. Bottom: Recovered generative model with the same bounding box. <p> resulting point cloud (which has been made sparser to show the individual points clearly) is found in figure 2.3. 10 different resolutions and project a gray code onto the object. 2 sparser in the figure to show the individual points clearly. 2 2.1.2 Desktop Range Imaging Recently, Bouguet and Perona <ref> [4] </ref> proposed an approach designed to use minimal hardware. They observe the deformation of the shadow cast by a hand-moved rod over a plane on which the object is cast after calibration of the camera and point light-source. This approach is very easy to set up. <p> Check for possible simplifications. 3.2 Algorithm Description Step 1. Acquire Range Data: We use simple and portable techniques based on structured lighting to acquire range data. Trobina [30] describes a method using a projector where alternating patterns of dark and light are projected onto an object. Bouguet and Perona <ref> [4] </ref> infer shape from the shadow of a rod moved over a plane on which the object is placed. Both techniques are simple, portable, and require minimal hardware. Step 2. <p> resulting point cloud (which has been made sparser to show the individual points clearly) is found in figure 2.3. 10 different resolutions and project a gray code onto the object. 2 sparser in the figure to show the individual points clearly. 2 2.1.2 Desktop Range Imaging Recently, Bouguet and Perona <ref> [4] </ref> proposed an approach designed to use minimal hardware. They observe the deformation of the shadow cast by a hand-moved rod over a plane on which the object is cast after calibration of the camera and point light-source. This approach is very easy to set up. <p> Check for possible simplifications. 3.2 Algorithm Description Step 1. Acquire Range Data: We use simple and portable techniques based on structured lighting to acquire range data. Trobina [30] describes a method using a projector where alternating patterns of dark and light are projected onto an object. Bouguet and Perona <ref> [4] </ref> infer shape from the shadow of a rod moved over a plane on which the object is placed. Both techniques are simple, portable, and require minimal hardware. Step 2. <p> Links exist between nodes either when the cross-section is changed or a single curve is refined using the same cross-section. Ladle: In figure 6.4, we show the fitting of a generative model to a single range image of a ladle obtained using the method of Bouguet and Perona <ref> [4] </ref>. The algorithm does well even when the data is incomplete or noisy. Cup: Figure 6.5 demonstrates the robustness of our approach even when the model does not match the range data well. We took 6 aligned range images of a cup (shown in different colors).
Reference: [5] <author> Liang-Hua Chen, Wei-Chung Lin, and Hong-Yuan Mark Liao. </author> <title> Recovery of superquadric primitive from stereo images. </title> <journal> Image and Vision Computing, </journal> <volume> 12(5) </volume> <pages> 285-296, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Representative references are <ref> [5, 14, 20] </ref>. While these methods are useful within our framework for estimating model parameters, our major contribution is not in parametric recovery for specific models, but in selecting an appropriate model and presenting general techniques for optimizing the curves constituting this representation. <p> Representative references are <ref> [5, 14, 20] </ref>. While these methods are useful within our framework for estimating model parameters, our major contribution is not in parametric recovery for specific models, but in selecting an appropriate model and presenting general techniques for optimizing the curves constituting this representation.
Reference: [6] <author> Brian Curless and Marc Levoy. </author> <title> A volumetric method for building complex models from range images. </title> <booktitle> In SIGGRAPH 96 proceedings, </booktitle> <pages> pages 303-312, </pages> <year> 1996. </year>
Reference-contexts: In this way, 3D objects may be scanned in much the same way as a 2D photograph. Reasonably accurate point-clouds or range data|a collection of 3-dimensional points on the surface of the object to be scanned in|from 3D objects <ref> [6, 31] </ref> can be obtained. There has also been much interest recently in simple methods for range data acquisition using structured light. In this thesis, we use two of these techniques, due to Bouguet and Perona [4] and Trobina [30]. <p> The second method [30] involves the projection of alternating black-and-white stripes onto the object to be scanned. Both approaches use off-the-shelf hardware and are portable and easy to set up. For use in graphical applications, these point-clouds are usually transformed into polygonal meshes <ref> [6, 15] </ref>, or spline patches [9, 19]. However, these approaches often provide an unintuitive representation of the object and are difficult to manipulate. In addition, a huge amount of data is required since the meshes usually contain many thousands of triangles. <p> This is analogous to composing photographs taken from different angles to get a better idea of shape. Alignment of range images is an interesting topic. A volumetric method of merging scans is detailed in <ref> [6] </ref> along with an arrangement that allows for full motion around the object. In case the precise transformation between the different range images is not known, computing a correct alignment can be extremely difficult. <p> This is analogous to composing photographs taken from different angles to get a better idea of shape. Alignment of range images is an interesting topic. A volumetric method of merging scans is detailed in <ref> [6] </ref> along with an arrangement that allows for full motion around the object. In case the precise transformation between the different range images is not known, computing a correct alignment can be extremely difficult.
Reference: [7] <author> Paul E. Debevec, Camillo J. Taylor, and Jitendra Malik. </author> <title> Modeling and rendering architecture from photographs: A hybrid geometry- and image-based approach. </title> <booktitle> In SIGGRAPH 96 proceedings, </booktitle> <pages> pages 11-20, </pages> <year> 1996. </year>
Reference: [8] <author> J.E. Dennis, Jr. and R.B. Schnabel. </author> <title> Numerical Methods for Unconstrained Optimization and Nonlinear Equations. </title> <publisher> Prentice Hall, </publisher> <year> 1983. </year>
Reference-contexts: A straightforward gradient descent can then be performed. The Hessian is updated using Broyden-Fletcher-Garb-Shapiro quasi-Newton update (see <ref> [8] </ref> for a reference). A good general reference is Gill et al.[12]. Differentiability: In order to compute the gradients and the Hessian, most numerical routines require the objective function to be continuously twice differentiable. The gradients may either be computed analytically, or by using a finite difference approximation. <p> A straightforward gradient descent can then be performed. The Hessian is updated using Broyden-Fletcher-Garb-Shapiro quasi-Newton update (see <ref> [8] </ref> for a reference). A good general reference is Gill et al.[12]. Differentiability: In order to compute the gradients and the Hessian, most numerical routines require the objective function to be continuously twice differentiable. The gradients may either be computed analytically, or by using a finite difference approximation.
Reference: [9] <author> Matthias Eck and Hugues Hoppe. </author> <title> Automatic reconstruction of B-Spline surfaces of arbitrary topological type. </title> <booktitle> In SIGGRAPH 96 proceedings, </booktitle> <pages> pages 325-334, </pages> <year> 1996. </year> <month> 49 </month>
Reference-contexts: The second method [30] involves the projection of alternating black-and-white stripes onto the object to be scanned. Both approaches use off-the-shelf hardware and are portable and easy to set up. For use in graphical applications, these point-clouds are usually transformed into polygonal meshes [6, 15], or spline patches <ref> [9, 19] </ref>. However, these approaches often provide an unintuitive representation of the object and are difficult to manipulate. In addition, a huge amount of data is required since the meshes usually contain many thousands of triangles.
Reference: [10] <author> O.D. Faugeras, M. Herbert, and E. Pauchon. </author> <title> Segmentation of planar and quadratic patches from range data. </title> <booktitle> In IEEE Conference on Pattern Recognition and Image Processing, </booktitle> <year> 1983. </year>
Reference-contexts: Further, most of the representations used in previous work have a small number of parameters instead of curves, and research has largely been restricted to recovery of a specific type of model such as quadrics <ref> [10] </ref> or generalized cones [26] instead of a model within a more general hierarchy. In a similar spirit as our work, Debevec et al.[7] propose a way to recover polyhedral models from photographs of architectural scenes. <p> Further, most of the representations used in previous work have a small number of parameters instead of curves, and research has largely been restricted to recovery of a specific type of model such as quadrics <ref> [10] </ref> or generalized cones [26] instead of a model within a more general hierarchy. In a similar spirit as our work, Debevec et al.[7] propose a way to recover polyhedral models from photographs of architectural scenes.
Reference: [11] <author> J. </author> <title> Feder. </title> <journal> Plex languages. Inform. Sci., </journal> <volume> 3 </volume> <pages> 225-247, </pages> <year> 1971. </year>
Reference-contexts: However, we require range data instead of photographs and use a pre-defined model hierarchy. Grammars: Lin and Fu [22] discuss the use of plex grammars <ref> [11] </ref> to describe composition of objects, which is analogous to our use of a hierarchical tree structure as a model representation. An object is represented as a composition of primitive objects. These primitives can be joined together via translations, rotations and connection at curves or surfaces. <p> However, we require range data instead of photographs and use a pre-defined model hierarchy. Grammars: Lin and Fu [22] discuss the use of plex grammars <ref> [11] </ref> to describe composition of objects, which is analogous to our use of a hierarchical tree structure as a model representation. An object is represented as a composition of primitive objects. These primitives can be joined together via translations, rotations and connection at curves or surfaces.
Reference: [12] <author> P.E. Gill, W. Murray, and M.H. Wright. </author> <title> Practical Optimization. </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference: [13] <author> Stefan Gottschalk, Ming Lin, and Dinesh Manocha. </author> <title> A hierarchical structure for rapid interference detection. </title> <booktitle> In SIGGRAPH 96 proceedings, </booktitle> <pages> pages 171-180, </pages> <year> 1996. </year>
Reference-contexts: Co-ordinate Axes: We find the co-ordinate axis directions by computing the principal axes of the data using the eigenvectors of the covariance matrix as done to compute bounding boxes in <ref> [13] </ref>, or by considering the axes along which the range data has greatest extent|in this approach, we first find the longest axis using optimization, and then the longest axis orthogonal to the first one.
Reference: [14] <author> Ari D. Gross and Terrance E. Boult. </author> <title> Recovery of SHGCs from a single intensity view. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 18(2) </volume> <pages> 161-180, </pages> <month> Feb </month> <year> 1996. </year>
Reference-contexts: Representative references are <ref> [5, 14, 20] </ref>. While these methods are useful within our framework for estimating model parameters, our major contribution is not in parametric recovery for specific models, but in selecting an appropriate model and presenting general techniques for optimizing the curves constituting this representation. <p> Representative references are <ref> [5, 14, 20] </ref>. While these methods are useful within our framework for estimating model parameters, our major contribution is not in parametric recovery for specific models, but in selecting an appropriate model and presenting general techniques for optimizing the curves constituting this representation.
Reference: [15] <author> Hugues Hoppe, Tony DeRose, Tom Duchamp, John McDonald, and Werner Stuetzle. </author> <title> Surface reconstruction from unorganized points. </title> <booktitle> In SIGGRAPH 92 proceedings, </booktitle> <pages> pages 71-78, </pages> <year> 1992. </year>
Reference-contexts: The second method [30] involves the projection of alternating black-and-white stripes onto the object to be scanned. Both approaches use off-the-shelf hardware and are portable and easy to set up. For use in graphical applications, these point-clouds are usually transformed into polygonal meshes <ref> [6, 15] </ref>, or spline patches [9, 19]. However, these approaches often provide an unintuitive representation of the object and are difficult to manipulate. In addition, a huge amount of data is required since the meshes usually contain many thousands of triangles.
Reference: [16] <author> Hugues Hoppe, Tony DeRose, Tom Duchamp, John McDonald, and Werner Stuetzle. </author> <title> Mesh optimization. </title> <booktitle> In SIGGRAPH 93 proceedings, </booktitle> <pages> pages 19-26, </pages> <year> 1993. </year>
Reference: [17] <author> S. Inokuchi, K. Sato, and F. Matsuda. </author> <title> Range imaging system for 3d object recognition. </title> <booktitle> In Proceedings of the 7 th International Conference on Pattern Recognition, </booktitle> <pages> pages 806-808, </pages> <year> 1984. </year>
Reference: [18] <author> R. A. Jarvis. </author> <title> A perspective on range finding techniques for computer vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(2) </volume> <pages> 122-139, </pages> <year> 1983. </year>
Reference-contexts: While there has been some research on such methods (for instance, [29]), use of stereo requires solving a correspondence problem, for which sufficiently robust algorithms have not yet been developed. Jarvis gives a good introduction and survey of range data acquisition <ref> [18] </ref>. Besl and Jain [2] survey three-dimensional object recognition and include a discussion 8 of range data acquisition. Parthasarathy et al.[24] give a classification of methods to acquire range data. <p> While there has been some research on such methods (for instance, [29]), use of stereo requires solving a correspondence problem, for which sufficiently robust algorithms have not yet been developed. Jarvis gives a good introduction and survey of range data acquisition <ref> [18] </ref>. Besl and Jain [2] survey three-dimensional object recognition and include a discussion 8 of range data acquisition. Parthasarathy et al.[24] give a classification of methods to acquire range data.
Reference: [19] <author> Venkat Krishnamurthy and Marc Levoy. </author> <title> Fitting smooth surfaces to dense polygon meshes. </title> <booktitle> In SIGGRAPH 96 proceedings, </booktitle> <pages> pages 313-324, </pages> <year> 1996. </year>
Reference-contexts: The second method [30] involves the projection of alternating black-and-white stripes onto the object to be scanned. Both approaches use off-the-shelf hardware and are portable and easy to set up. For use in graphical applications, these point-clouds are usually transformed into polygonal meshes [6, 15], or spline patches <ref> [9, 19] </ref>. However, these approaches often provide an unintuitive representation of the object and are difficult to manipulate. In addition, a huge amount of data is required since the meshes usually contain many thousands of triangles. <p> For instance, in the cup example before segmentation, a large number of control points are needed because the system does not recognize the discontinuities in the cup profile. Also, a future system would probably use displacement maps <ref> [19] </ref> 47 to keep the full complexity of the range data and have the ability to compose generative models to represent more complex objects. In the future, we would also like the system to automate some tasks that currently require user interaction.
Reference: [20] <author> Senthil Kumar, Han Song, Dmitry Golgof, and Kevin Bowyer. </author> <title> On recovering hyperquadrics from range data. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(11) </volume> <pages> 1079-1083, </pages> <month> Nov </month> <year> 1995. </year>
Reference-contexts: Representative references are <ref> [5, 14, 20] </ref>. While these methods are useful within our framework for estimating model parameters, our major contribution is not in parametric recovery for specific models, but in selecting an appropriate model and presenting general techniques for optimizing the curves constituting this representation. <p> Representative references are <ref> [5, 14, 20] </ref>. While these methods are useful within our framework for estimating model parameters, our major contribution is not in parametric recovery for specific models, but in selecting an appropriate model and presenting general techniques for optimizing the curves constituting this representation.
Reference: [21] <author> R.A. Lewis and A.R. Johnston. </author> <title> A scanning laser rangefinder for a robotic vehicle. </title> <booktitle> In Proceedings of 5 th International Joint Conference on Artifical Intelligence IJCAI, </booktitle> <pages> pages 762-768. 50 </pages>
Reference-contexts: The ordinary intensity image can be useful for modeling the reflectance properties of the object to be scanned, but this thesis does not address issues of texture and reflectance modeling. The range image can be acquired in a variety of ways|by use of laser scanner <ref> [21] </ref>, triangulation [25], and with structured light. These are all active methods in that energy is projected onto the object, and range data is obtained from observing its reflection. Passive methods may also be used such as shape from properties such as shading and silhouettes. <p> The ordinary intensity image can be useful for modeling the reflectance properties of the object to be scanned, but this thesis does not address issues of texture and reflectance modeling. The range image can be acquired in a variety of ways|by use of laser scanner <ref> [21] </ref>, triangulation [25], and with structured light. These are all active methods in that energy is projected onto the object, and range data is obtained from observing its reflection. Passive methods may also be used such as shape from properties such as shading and silhouettes.
Reference: [22] <author> W.C. Lin and K.S. Fu. </author> <title> A syntactic approach to 3-D object representation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6(3) </volume> <pages> 351-364, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: While this research is similar to ours, we employ more complex shapes, and automate the recovery process further|the user need specify neither the specific model nor the particular edges of interest. However, we require range data instead of photographs and use a pre-defined model hierarchy. Grammars: Lin and Fu <ref> [22] </ref> discuss the use of plex grammars [11] to describe composition of objects, which is analogous to our use of a hierarchical tree structure as a model representation. An object is represented as a composition of primitive objects. <p> While this research is similar to ours, we employ more complex shapes, and automate the recovery process further|the user need specify neither the specific model nor the particular edges of interest. However, we require range data instead of photographs and use a pre-defined model hierarchy. Grammars: Lin and Fu <ref> [22] </ref> discuss the use of plex grammars [11] to describe composition of objects, which is analogous to our use of a hierarchical tree structure as a model representation. An object is represented as a composition of primitive objects.
Reference: [23] <institution> Numerical Algorithms Group, Ltd. NAG Fortran Library Document, </institution> <year> 1988. </year>
Reference-contexts: This is particularly challenging because most optimizers require objective functions that are twice-differentiable. Optimization In fitting of a parametric model, we will need to use an unconstrained nonlinear minimizer. We used the Sequential Quadratic Programming routine E04UCF in the NAG libraries <ref> [23] </ref>. Here, we briefly describe how this optimizer works. Let x denote the current best guess to minimize the objective function . <p> Since the model can be an arbitrary function of the parametric curves constituting it, we use a general unconstrained nonlinear minimizer. For example, we have used the Sequential Quadratic Programming routine in NAG <ref> [23] </ref> with numerical computation of the gradients. Because the optimization process is more robust when the objective function varies smoothly with the parameters, we use objective functions that are guaranteed to be C p continuous where p can be made arbitrarily large. <p> This is particularly challenging because most optimizers require objective functions that are twice-differentiable. Optimization In fitting of a parametric model, we will need to use an unconstrained nonlinear minimizer. We used the Sequential Quadratic Programming routine E04UCF in the NAG libraries <ref> [23] </ref>. Here, we briefly describe how this optimizer works. Let x denote the current best guess to minimize the objective function . <p> Since the model can be an arbitrary function of the parametric curves constituting it, we use a general unconstrained nonlinear minimizer. For example, we have used the Sequential Quadratic Programming routine in NAG <ref> [23] </ref> with numerical computation of the gradients. Because the optimization process is more robust when the objective function varies smoothly with the parameters, we use objective functions that are guaranteed to be C p continuous where p can be made arbitrarily large.
Reference: [24] <author> S. Parthasarathy, J. Burk, and J. Dessimoz. </author> <title> Laser rangefinder for robot control and inspection. </title> <booktitle> In Proceedings of the Society for Photo-Optical Instrumentation Engineers Conference on Robot Vision, </booktitle> <volume> volume 336, </volume> <pages> pages 2-11, </pages> <year> 1982. </year>
Reference: [25] <author> F.J. Pipitone and T.G. Marshall. </author> <title> A wide-field scanning triangulation rangefinder for machine vision. </title> <journal> International Journal of Robotic Research, </journal> <volume> 2(1) </volume> <pages> 39-49, </pages> <year> 1983. </year>
Reference-contexts: The ordinary intensity image can be useful for modeling the reflectance properties of the object to be scanned, but this thesis does not address issues of texture and reflectance modeling. The range image can be acquired in a variety of ways|by use of laser scanner [21], triangulation <ref> [25] </ref>, and with structured light. These are all active methods in that energy is projected onto the object, and range data is obtained from observing its reflection. Passive methods may also be used such as shape from properties such as shading and silhouettes. <p> The ordinary intensity image can be useful for modeling the reflectance properties of the object to be scanned, but this thesis does not address issues of texture and reflectance modeling. The range image can be acquired in a variety of ways|by use of laser scanner [21], triangulation <ref> [25] </ref>, and with structured light. These are all active methods in that energy is projected onto the object, and range data is obtained from observing its reflection. Passive methods may also be used such as shape from properties such as shading and silhouettes.
Reference: [26] <author> S.A. Shafer and T. Kanade. </author> <title> The theory of straight homogeneous generalized cylinders and taxonomy of generalized cylinders. </title> <type> Technical Report CMU-CS-83-105, </type> <month> Jan </month> <year> 1983. </year>
Reference-contexts: Further, most of the representations used in previous work have a small number of parameters instead of curves, and research has largely been restricted to recovery of a specific type of model such as quadrics [10] or generalized cones <ref> [26] </ref> instead of a model within a more general hierarchy. In a similar spirit as our work, Debevec et al.[7] propose a way to recover polyhedral models from photographs of architectural scenes. <p> Further, most of the representations used in previous work have a small number of parameters instead of curves, and research has largely been restricted to recovery of a specific type of model such as quadrics [10] or generalized cones <ref> [26] </ref> instead of a model within a more general hierarchy. In a similar spirit as our work, Debevec et al.[7] propose a way to recover polyhedral models from photographs of architectural scenes.
Reference: [27] <author> John Snyder. </author> <title> Generative Modeling for Computer Graphics and CAD. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: However, these approaches often provide an unintuitive representation of the object and are difficult to manipulate. In addition, a huge amount of data is required since the meshes usually contain many thousands of triangles. For modeling many man-made objects, generative models proposed by Snyder <ref> [27, 28] </ref> provide an attractive alternative. The modeled object is represented by a hierarchical tree of operators that provides a logical description of the object's structure. Designers can intuitively specify, examine, and modify the model. In this paper, we describe methods to invert this modeling process. <p> We deal only with static scenes; dynamic scene descriptions are not modeled. The object to be scanned in must be rigid to allow it to be easily rotated for viewing from multiple viewpoints. Our current system makes it hard to scan in flexible objects. 12 2.2 Generative Modeling Snyder <ref> [27] </ref> gives a comprehensive description of generative modeling. Here, we briefly mention the important features that we use in our system. <p> Thus, the shape is specified in a modular way, being built from lower-dimensional components that are easier to manipulate and visualize. An example of a generative model that is simple to specify, and yet reasonably expressive is the banana model <ref> [27, p. 68,69] </ref> developed by Snyder. Here, the surface S is given by an affine transform: S (u; v) = M (v)fl (u) + T (v) (2:2) where M (v) is a linear transformation in 3D, and T (v) is a translation. <p> This hierarchy which is pictured on the lower left of figure 1.2 (a larger version is reproduced in figure 5.1) and in figure 6.1 is inspired by the spoon model created by Snyder <ref> [27, p. 83] </ref>. <p> We deal only with static scenes; dynamic scene descriptions are not modeled. The object to be scanned in must be rigid to allow it to be easily rotated for viewing from multiple viewpoints. Our current system makes it hard to scan in flexible objects. 12 2.2 Generative Modeling Snyder <ref> [27] </ref> gives a comprehensive description of generative modeling. Here, we briefly mention the important features that we use in our system. <p> Thus, the shape is specified in a modular way, being built from lower-dimensional components that are easier to manipulate and visualize. An example of a generative model that is simple to specify, and yet reasonably expressive is the banana model <ref> [27, p. 68,69] </ref> developed by Snyder. Here, the surface S is given by an affine transform: S (u; v) = M (v)fl (u) + T (v) (2:2) where M (v) is a linear transformation in 3D, and T (v) is a translation. <p> This hierarchy which is pictured on the lower left of figure 1.2 (a larger version is reproduced in figure 5.1) and in figure 6.1 is inspired by the spoon model created by Snyder <ref> [27, p. 83] </ref>. <p> For illustrative purposes, both the range images and the model were meshed to create the final images for display (colors are artificial). Internally, no meshing is done. Snyder <ref> [27] </ref> describes alternative methods to image generative models without mesh creation, but at the cost of loss of interactivity.
Reference: [28] <author> John M. Snyder and James T. Kajiya. </author> <title> Generative modeling: A symbolic system for geometric modeling. </title> <booktitle> In SIGGRAPH 92 proceedings, </booktitle> <pages> pages 369-378, </pages> <year> 1992. </year>
Reference-contexts: However, these approaches often provide an unintuitive representation of the object and are difficult to manipulate. In addition, a huge amount of data is required since the meshes usually contain many thousands of triangles. For modeling many man-made objects, generative models proposed by Snyder <ref> [27, 28] </ref> provide an attractive alternative. The modeled object is represented by a hierarchical tree of operators that provides a logical description of the object's structure. Designers can intuitively specify, examine, and modify the model. In this paper, we describe methods to invert this modeling process.
Reference: [29] <author> D. Terzopoulos. </author> <title> Multilevel computational processes for visual surface reconstruction. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 24 </volume> <pages> 52-96, </pages> <year> 1983. </year>
Reference-contexts: However, these algorithms are generally not as reliable as active range data acquisition. Humans acquire a sense of depth by stereoscopic vision as well as higher level cognitive processing. While there has been some research on such methods (for instance, <ref> [29] </ref>), use of stereo requires solving a correspondence problem, for which sufficiently robust algorithms have not yet been developed. Jarvis gives a good introduction and survey of range data acquisition [18]. Besl and Jain [2] survey three-dimensional object recognition and include a discussion 8 of range data acquisition. <p> However, these algorithms are generally not as reliable as active range data acquisition. Humans acquire a sense of depth by stereoscopic vision as well as higher level cognitive processing. While there has been some research on such methods (for instance, <ref> [29] </ref>), use of stereo requires solving a correspondence problem, for which sufficiently robust algorithms have not yet been developed. Jarvis gives a good introduction and survey of range data acquisition [18]. Besl and Jain [2] survey three-dimensional object recognition and include a discussion 8 of range data acquisition.
Reference: [30] <author> Marjan Trobina. </author> <title> Error model of a coded-light range sensor. </title> <type> Technical Report BIWI-TR-164, </type> <institution> ETH, </institution> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: There has also been much interest recently in simple methods for range data acquisition using structured light. In this thesis, we use two of these techniques, due to Bouguet and Perona [4] and Trobina <ref> [30] </ref>. In the first approach, 3-dimensional shape is inferred from the deformation of the shadow of a hand-held rod rolled over a plane on which the object is placed. The second method [30] involves the projection of alternating black-and-white stripes onto the object to be scanned. <p> In this thesis, we use two of these techniques, due to Bouguet and Perona [4] and Trobina <ref> [30] </ref>. In the first approach, 3-dimensional shape is inferred from the deformation of the shadow of a hand-held rod rolled over a plane on which the object is placed. The second method [30] involves the projection of alternating black-and-white stripes onto the object to be scanned. Both approaches use off-the-shelf hardware and are portable and easy to set up. For use in graphical applications, these point-clouds are usually transformed into polygonal meshes [6, 15], or spline patches [9, 19]. <p> Assume we have a collection of objects such as cylinders, bowls, and spoons that we wish to represent, and which are effectively modeled by our chosen hierarchy. By using the range data acquisition techniques in [4] or <ref> [30] </ref>, and the algorithms described in this thesis, we may automatically obtain accurate parametric models of the input objects. <p> we wish to represent a different class of models, the user must define the appropriate generative model hierarchy or extend our hierarchy to model the desired objects. 1.2 Benefits of the Proposed Method Simplicity: To acquire the range data, we use simple techniques based on structured light due to Trobina <ref> [30] </ref> and Bouguet and Perona [4]. The latter approach requires only a desk-lamp, pencil and checkerboard apart from the camera. Using input from these approaches, we output a simple and intuitive object description in the form of a compact generative model. Bottom: Recovered generative model with the same bounding box. <p> Below, we discuss two techniques for range data acquisition that require minimal hardware and can easily be constructed from off-the-shelf components. These were used to provide the range data input for our system. 9 2.1.1 Hierarchical Structured Light In this method <ref> [30] </ref>, we use a projector and a camera. First, the projector and camera are calibrated (a checkerboard pattern is used for this purpose), and the relative transformation between them is noted. <p> Optimize. 6. Check for possible simplifications. 3.2 Algorithm Description Step 1. Acquire Range Data: We use simple and portable techniques based on structured lighting to acquire range data. Trobina <ref> [30] </ref> describes a method using a projector where alternating patterns of dark and light are projected onto an object. Bouguet and Perona [4] infer shape from the shadow of a rod moved over a plane on which the object is placed. Both techniques are simple, portable, and require minimal hardware. <p> Below, we discuss two techniques for range data acquisition that require minimal hardware and can easily be constructed from off-the-shelf components. These were used to provide the range data input for our system. 9 2.1.1 Hierarchical Structured Light In this method <ref> [30] </ref>, we use a projector and a camera. First, the projector and camera are calibrated (a checkerboard pattern is used for this purpose), and the relative transformation between them is noted. <p> Optimize. 6. Check for possible simplifications. 3.2 Algorithm Description Step 1. Acquire Range Data: We use simple and portable techniques based on structured lighting to acquire range data. Trobina <ref> [30] </ref> describes a method using a projector where alternating patterns of dark and light are projected onto an object. Bouguet and Perona [4] infer shape from the shadow of a rod moved over a plane on which the object is placed. Both techniques are simple, portable, and require minimal hardware. <p> A single range image (shown in figure 1.1) obtained using the method of Trobina <ref> [30] </ref> was used. In figures 6.1 and 6.2, we show the entire process of recovery with reference to the tree of models pictured in figure 1.2. Bowl: Figure 6.3 shows the recovery of a bowl model from a single range image acquired using [30]. <p> 1.1) obtained using the method of Trobina <ref> [30] </ref> was used. In figures 6.1 and 6.2, we show the entire process of recovery with reference to the tree of models pictured in figure 1.2. Bowl: Figure 6.3 shows the recovery of a bowl model from a single range image acquired using [30]. In regions where data is missing, the depth curve yields poor results, but the system automatically 42 nodes were the best fit at some point, while nodes which are never reached (combination of shape and bend neither of which are ever best-guess) are not shown.
Reference: [31] <author> Greg Turk and Marc Levoy. </author> <title> Zippered polygon meshes from range images. </title> <booktitle> In SIGGRAPH 94 proceedings, </booktitle> <pages> pages 311-318, </pages> <year> 1994. </year>
Reference-contexts: In this way, 3D objects may be scanned in much the same way as a 2D photograph. Reasonably accurate point-clouds or range data|a collection of 3-dimensional points on the surface of the object to be scanned in|from 3D objects <ref> [6, 31] </ref> can be obtained. There has also been much interest recently in simple methods for range data acquisition using structured light. In this thesis, we use two of these techniques, due to Bouguet and Perona [4] and Trobina [30].
References-found: 31

