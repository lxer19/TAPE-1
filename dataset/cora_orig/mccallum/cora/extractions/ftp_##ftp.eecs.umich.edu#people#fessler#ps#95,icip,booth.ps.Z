URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/95,icip,booth.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/conf.html
Root-URL: http://www.cs.umich.edu
Title: COMBINED DIAGONAL/FOURIER PRECONDITIONING METHODS FOR IMAGE RECONSTRUCTION IN EMISSION TOMOGRAPHY  
Author: Scott D. Booth and Jeffrey A. Fessler 
Affiliation: Bioengineering Program and Dept. of Electrical Engineering and Computer Science University of Michigan  
Abstract: Iterative methods for tomographic image reconstruction often converge slowly. Preconditioning methods can often accelerate gradient-based iterations. Previous preconditioning methods for PET reconstruction have used either diagonal or Fourier-based preconditioners. Fourier-based pre-conditioners are well suited to problems with near-circulant Hessian matrices. However, due to the nonuniform Poisson noise variance in PET, the circulant approximation to the Hessian is suboptimal. This paper shows that a particular combined diagonal/Fourier preconditioner yields a more accurate approximation to the Hessian and gives significantly faster convergence rates than does either precon-ditioner used alone. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L Kaufman, </author> <title> "Maximum likelihood, least squares, and and CG algorithms with combined diagonal/Fourier preconditioning and without preconditioning. penalized least squares for PET", </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 12, no. 2, </volume> <pages> pp. 200-214, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Several authors have described conjugate gradient methods for PET and SPECT [1-4]. This paper describes a new preconditioning method for accelerating the convergence of the conjugate gradient iteration for penalized weighted least-squares image reconstruction in PET. Kaufman <ref> [1, 5] </ref> showed that the EM algorithm for emission tomography is equivalent to a gradient ascent iteration with an estimate-dependent diagonal preconditioner. Mumcuoglu et al [2] incorporated this diagonal precondi-tioner into a conjugate-gradient algorithm.
Reference: [2] <author> E U Mumcuoglu, R Leahy, S R Cherry, and Z Zhou, </author> <title> "Fast gradient-based methods for Bayesian reconstruction of transmission and emission PET images", </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 13, no. 3, </volume> <pages> pp. 687-701, </pages> <month> Dec. </month> <year> 1994. </year>
Reference-contexts: Kaufman [1, 5] showed that the EM algorithm for emission tomography is equivalent to a gradient ascent iteration with an estimate-dependent diagonal preconditioner. Mumcuoglu et al <ref> [2] </ref> incorporated this diagonal precondi-tioner into a conjugate-gradient algorithm. Clinthorne et al [6] proposed a Fourier-based preconditioner for iterative reconstruction in PET, which exploits the fact that A T A is approximately circulant-block-circulant (where A is the system matrix described below). <p> For simplicity, in this paper we ignore the nonnegativity constraint for x, although the methods could be extended to include a barrier function as described in <ref> [2] </ref>. <p> The method of conjugate gradients modifies the search direc tions d n to ensure that they are mutually orthogonal. This method minimizes quadratic objective functions in a finite number of steps, and converges faster than steepest-descent for both quadratic and nonquadratic objectives <ref> [2, 10] </ref>. A preconditioned form of the Polak-Ribiere Conjugate Gradient (CG) method [2, 10] is summarized below: ^x = ^x + ff n d d n = p n + fl n d n1 fl n = r (^x n ) r ^x n1 fl r (^x n1 ) p n1 <p> This method minimizes quadratic objective functions in a finite number of steps, and converges faster than steepest-descent for both quadratic and nonquadratic objectives <ref> [2, 10] </ref>. A preconditioned form of the Polak-Ribiere Conjugate Gradient (CG) method [2, 10] is summarized below: ^x = ^x + ff n d d n = p n + fl n d n1 fl n = r (^x n ) r ^x n1 fl r (^x n1 ) p n1 The positive-definite matrix M determines the precondi tioner, and the step size <p> Applying this preconditioner to the CG algorithm is trivial: p n = D 1 r T (^x n ) : Note that this diagonal preconditioner differs from the EM-based diagonal preconditioner used in <ref> [2, 5] </ref>. 2.3. Fourier Preconditioning Since A T A and R u are approximately block-circulant 2 , the Fourier basis is a natural choice for a preconditioner [3]. The Fourier preconditioner is derived from the point-spread function of the A T A (projection-backprojection) operation.
Reference: [3] <author> D S Lalush and B M W Tsui, </author> <title> "A fast and stable maximum a posteriori conjugate gradient reconstruction algorithm", </title> <institution> Med. Phys., </institution> <year> 1994, </year> <note> Submitted. </note>
Reference-contexts: Fourier Preconditioning Since A T A and R u are approximately block-circulant 2 , the Fourier basis is a natural choice for a preconditioner <ref> [3] </ref>. The Fourier preconditioner is derived from the point-spread function of the A T A (projection-backprojection) operation. A single pixel at the center of the image field (a delta function) is projected and then backprojected.
Reference: [4] <author> A H Delaney and Y Bresler, </author> <title> "A fast iterative to-mographic reconstruction algorithm", </title> <booktitle> in Proc. IEEE Conf. Acoust. Speech Sig. Proc., 1995, </booktitle> <volume> vol. 4, </volume> <pages> pp. 2295-2298. </pages>
Reference: [5] <author> L Kaufman, </author> <title> "Implementing and accelerating the EM algorithm for positron emission tomography", </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 6, no. 1, </volume> <pages> pp. 37-51, </pages> <month> Mar. </month> <year> 1987. </year>
Reference-contexts: Several authors have described conjugate gradient methods for PET and SPECT [1-4]. This paper describes a new preconditioning method for accelerating the convergence of the conjugate gradient iteration for penalized weighted least-squares image reconstruction in PET. Kaufman <ref> [1, 5] </ref> showed that the EM algorithm for emission tomography is equivalent to a gradient ascent iteration with an estimate-dependent diagonal preconditioner. Mumcuoglu et al [2] incorporated this diagonal precondi-tioner into a conjugate-gradient algorithm. <p> Applying this preconditioner to the CG algorithm is trivial: p n = D 1 r T (^x n ) : Note that this diagonal preconditioner differs from the EM-based diagonal preconditioner used in <ref> [2, 5] </ref>. 2.3. Fourier Preconditioning Since A T A and R u are approximately block-circulant 2 , the Fourier basis is a natural choice for a preconditioner [3]. The Fourier preconditioner is derived from the point-spread function of the A T A (projection-backprojection) operation.
Reference: [6] <author> N H Clinthorne, </author> <title> T S Pan, P C Chiao, W L Rogers, and J A Stamos, "Preconditioning methods for improved convergence rates in iterative reconstructions", </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 12, no. 1, </volume> <pages> pp. 78-83, </pages> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: Kaufman [1, 5] showed that the EM algorithm for emission tomography is equivalent to a gradient ascent iteration with an estimate-dependent diagonal preconditioner. Mumcuoglu et al [2] incorporated this diagonal precondi-tioner into a conjugate-gradient algorithm. Clinthorne et al <ref> [6] </ref> proposed a Fourier-based preconditioner for iterative reconstruction in PET, which exploits the fact that A T A is approximately circulant-block-circulant (where A is the system matrix described below). Both diagonal and Fourier preconditioners increase the convergence rate of gradient-based iterations. <p> Therefore the term A T K 1 A within the Hessian (see (2) below) is not particularly well approximated by a circulant-block-circulant preconditioner (see Fig. 1). (Clinthorne et al used K = I in their simulations <ref> [6] </ref>.) Further, A T A is not particularly well approxi This work was supported in part by DOE grant DE-FG02-87ER60561 and NIH grants CA-60711 and CA-54362. mated by any diagonal matrix, since the 1=r characteristics of tomographic systems give significant off-diagonal content.
Reference: [7] <author> J A Fessler, </author> <title> "Penalized weighted least-squares image reconstruction for positron emission tomography", </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 13, no. 2, </volume> <pages> pp. 290-300, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Both diagonal and Fourier preconditioners increase the convergence rate of gradient-based iterations. Unfortunately, the Poisson measurement noise in PET imaging has a covariance matrix K with a very nonuniform diagonal, due to the effects of attenuation, detector efficiency, etc. <ref> [7] </ref>. <p> One useful statistical criterion for estimating x from y is the penalized weighted least-squares objective: (x) = 2 p X X w jk (x j x k ) ; where K is the covariance matrix of y (or the data-based approximate covariance <ref> [7] </ref>) and the term on the right is a roughness penalty. The unregularized estimate (with fi=0) is poorly conditioned, so some regularization is required to ensure a stable solution. <p> The diagonal covariance matrix K of the projection data y is estimated using the noisy data based on the Poisson statistics <ref> [7] </ref> K ii = maxf10; y i g: The iterations were initialized with a zero image. We used the modified roughness penalty (1) with fi = 0:001. 4.
Reference: [8] <author> J A Fessler and W L Rogers, </author> <title> "Uniform quadratic penalties cause nonuniform image resolution (and sometimes vice versa)", </title> <booktitle> in Conf. Rec. of the IEEE Nuc. Sci. Symp. Med. Im. Conf., 1994, </booktitle> <volume> vol. 4, </volume> <pages> pp. 1915-1919. </pages>
Reference-contexts: Thus, neither the Fourier or diagonal preconditioner is optimal for PET image reconstruction. In related work, we have shown that A T K 1 A can be reasonably well approximated by a matrix of the form flA T Afl, where fl is a particular diagonal matrix <ref> [8, 9] </ref>. This property suggests that a combined diagonal/Fourier preconditioner should yield faster convergence than is realized by the use of either preconditioner alone. In the following we summarize the development of the combined diagonal/Fourier preconditioner, and present empirical results demonstrating significantly improved convergence rates. 2. <p> The regularization parameter fi controls the resolution/noise tradeoff. Methods for choosing fi to specify a desired resolution are described in <ref> [8, 9] </ref>. For a quadratic penalty, the objective simplifies to (x) = 2 1 fix T Rx; where the matrix R is the (symmetric) Hessian of the penalty. <p> The usual "uniform" roughness penalty matrix R u has 4's along its diagonal and 1's in the off-diagonal positions corresponding to each pixel's neighbors. Surpris--ingly, this uniform penalty leads to nonuniform spatial resolution <ref> [8, 9] </ref>. Thus, here we follow [8, 9] and use a modified penalty in which we replace w jk above with w jk j k , where j = X A 2 ii = i ij : In this case one can show that the penalty Hessian satisfies R flR u <p> The usual "uniform" roughness penalty matrix R u has 4's along its diagonal and 1's in the off-diagonal positions corresponding to each pixel's neighbors. Surpris--ingly, this uniform penalty leads to nonuniform spatial resolution <ref> [8, 9] </ref>. Thus, here we follow [8, 9] and use a modified penalty in which we replace w jk above with w jk j k , where j = X A 2 ii = i ij : In this case one can show that the penalty Hessian satisfies R flR u fl; (1) where fl = diag <p> with w jk j k , where j = X A 2 ii = i ij : In this case one can show that the penalty Hessian satisfies R flR u fl; (1) where fl = diag f j g : This modified penalty leads to nearly uniform spatial resolution <ref> [8, 9] </ref>, and also fortuitously leads to a Hessian that is more amenable to preconditioning. For simplicity, in this paper we ignore the nonnegativity constraint for x, although the methods could be extended to include a barrier function as described in [2].
Reference: [9] <author> J A Fessler et al., </author> <title> "Spatial resolution properties of penalized maximum-likelihood image reconstruction methods", </title> <note> 1994, In preparation. </note>
Reference-contexts: Thus, neither the Fourier or diagonal preconditioner is optimal for PET image reconstruction. In related work, we have shown that A T K 1 A can be reasonably well approximated by a matrix of the form flA T Afl, where fl is a particular diagonal matrix <ref> [8, 9] </ref>. This property suggests that a combined diagonal/Fourier preconditioner should yield faster convergence than is realized by the use of either preconditioner alone. In the following we summarize the development of the combined diagonal/Fourier preconditioner, and present empirical results demonstrating significantly improved convergence rates. 2. <p> The regularization parameter fi controls the resolution/noise tradeoff. Methods for choosing fi to specify a desired resolution are described in <ref> [8, 9] </ref>. For a quadratic penalty, the objective simplifies to (x) = 2 1 fix T Rx; where the matrix R is the (symmetric) Hessian of the penalty. <p> The usual "uniform" roughness penalty matrix R u has 4's along its diagonal and 1's in the off-diagonal positions corresponding to each pixel's neighbors. Surpris--ingly, this uniform penalty leads to nonuniform spatial resolution <ref> [8, 9] </ref>. Thus, here we follow [8, 9] and use a modified penalty in which we replace w jk above with w jk j k , where j = X A 2 ii = i ij : In this case one can show that the penalty Hessian satisfies R flR u <p> The usual "uniform" roughness penalty matrix R u has 4's along its diagonal and 1's in the off-diagonal positions corresponding to each pixel's neighbors. Surpris--ingly, this uniform penalty leads to nonuniform spatial resolution <ref> [8, 9] </ref>. Thus, here we follow [8, 9] and use a modified penalty in which we replace w jk above with w jk j k , where j = X A 2 ii = i ij : In this case one can show that the penalty Hessian satisfies R flR u fl; (1) where fl = diag <p> with w jk j k , where j = X A 2 ii = i ij : In this case one can show that the penalty Hessian satisfies R flR u fl; (1) where fl = diag f j g : This modified penalty leads to nearly uniform spatial resolution <ref> [8, 9] </ref>, and also fortuitously leads to a Hessian that is more amenable to preconditioning. For simplicity, in this paper we ignore the nonnegativity constraint for x, although the methods could be extended to include a barrier function as described in [2]. <p> This ensures that the direction vector p n is a real vector. 2.4. A Combined Diagonal/Fourier Method Since the utility of the Fourier preconditioning method hinges on the assumption that the Hessian is approximately circulant-block-circulant, making this assumption more accurate should make the Fourier preconditioner more effective. In <ref> [9] </ref> the approximation A T K 1 A flA T Afl is dis cussed in more detail, where fl was defined above.
Reference: [10] <author> W H Press, B P Flannery, </author> <title> S A Teukolsky, and W T Vetterling, Numerical recipes in C, </title> <publisher> Cambridge Univ. Press, </publisher> <year> 1988. </year>
Reference-contexts: of iterative function minimization, in cluding the steepest-descent (SD) method, use the gradient of the objective function r (^x) to determine a series of direction vectors d n over which is minimized: ^x = ^x + ffd ; where ff is chosen to minimize (^x n + ffd n ) <ref> [10] </ref>. The method of conjugate gradients modifies the search direc tions d n to ensure that they are mutually orthogonal. This method minimizes quadratic objective functions in a finite number of steps, and converges faster than steepest-descent for both quadratic and nonquadratic objectives [2, 10]. <p> The method of conjugate gradients modifies the search direc tions d n to ensure that they are mutually orthogonal. This method minimizes quadratic objective functions in a finite number of steps, and converges faster than steepest-descent for both quadratic and nonquadratic objectives <ref> [2, 10] </ref>. A preconditioned form of the Polak-Ribiere Conjugate Gradient (CG) method [2, 10] is summarized below: ^x = ^x + ff n d d n = p n + fl n d n1 fl n = r (^x n ) r ^x n1 fl r (^x n1 ) p n1 <p> This method minimizes quadratic objective functions in a finite number of steps, and converges faster than steepest-descent for both quadratic and nonquadratic objectives <ref> [2, 10] </ref>. A preconditioned form of the Polak-Ribiere Conjugate Gradient (CG) method [2, 10] is summarized below: ^x = ^x + ff n d d n = p n + fl n d n1 fl n = r (^x n ) r ^x n1 fl r (^x n1 ) p n1 The positive-definite matrix M determines the precondi tioner, and the step size
References-found: 10

