URL: http://charm.cs.uiuc.edu/version2/papers/ChareKernelICPP91.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/ChareKernelICPP91.html
Root-URL: http://www.cs.uiuc.edu
Title: Supporting Machine Independent Parallel Programming on Diverse Architectures  
Author: W. Fenton B. Ramkumar V. A. Saletore A. B. Sinha L. V. Kale 
Address: Urbana, Illinois 61801  
Affiliation: Department of Computer Science, University Of Illinois at Urbana-Champaign,  
Abstract: The Chare kernel is a run time support system that permits users to write machine independent parallel programs on MIMD multiprocessors without losing efficiency. It supports an explicitly parallel language which helps control the complexity of parallel program design by imposing a separation of concerns between the user program and the system. The programmer is responsible for the dynamic creation of processes and exchanging messages between processes. The kernel assumes responsibility for when and where to execute the processes, dynamic load balancing, and other "low" level features. The language also provides machine-independent abstractions for information sharing which are implemented differently on different types of machines. The language has been implemented on both shared and nonshared memory machines including Sequent Balance and Symmetry, Encore Multimax, Alliant FX/8, Intel iPSC/2, iPSC/860 and NCUBE/2, and is being ported to NUMA (Non Uniform Memory Access) machines like the BBN TC2000. It is also being ported to a network of Sun workstations. We discuss the salient features of the implementation of the kernel on the three different types of architectures.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agha G.A. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT press, </publisher> <year> 1986. </year>
Reference-contexts: There are other efforts aimed at machine independence. Strand [8] is a language based on asynchronous processes and streams, and is portable across many parallel machines. Linda [4] is another language based on the notion of a shared tuple-space. Actors <ref> [1] </ref> and concurrent object-based languages are comprised of processes which communicate by depositing and/or removing tuples with specific patterns. The language described by us differs from these mainly in its rich set of diverse information sharing modes, and on its reliance on implicit dynamic load balancing for scheduling work.
Reference: [2] <author> Athas W.C., Seitz C.L. </author> <title> Multicomputers: Message-Passing Concurrent Computers. </title> <booktitle> Computer, </booktitle> <pages> 9-24, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The language we described is different from the distributed system kernels such as the V kernel [5], or the Amoeba system [14] which essentially provide support for communicating processes. The Reactive Kernel/Cosmic Environment <ref> [2] </ref> also supports machine independent programming by providing communication mechanisms. The recently proposed Concurrent Aggregates (CA) language [6] bears some similarities with the branch-office chares in our language, although CA is aimed at a fine-grained machine (The J-machine) [7] being built at MIT.
Reference: [3] <author> Boyce J., Butler R. et al. </author> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart & Winston, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: 0.99 1.97 3.92 7.78 13.92 (367.4) (371.8) iPSC/2 0.99 1.93 3.72 6.77 12.60 (379.3) (385.0) Table 1: Performance of parallel IDA* algorithm on a 15 puzzle problem that explores 1.4 million nodes. 7 Related Work One of the early attempts at machine independence was the development of the "Argonne macros" <ref> [3] </ref> aimed at porting compilers for parallel Prolog across shared memory machines. This attempt, although significant in the direction it chose to take, did not go far enough, restricting its attention to a single type of architecture.
Reference: [4] <author> Carriero N., Gelernter D. </author> <title> How to Write Parallel Programs: A Guide to the Perplexed. </title> <journal> ACM Computing Surveys, </journal> <pages> 323-357, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Also important is that there is no context switching between explicit processes in our model and hence no associated overheads are incurred. There are other efforts aimed at machine independence. Strand [8] is a language based on asynchronous processes and streams, and is portable across many parallel machines. Linda <ref> [4] </ref> is another language based on the notion of a shared tuple-space. Actors [1] and concurrent object-based languages are comprised of processes which communicate by depositing and/or removing tuples with specific patterns.
Reference: [5] <author> Cheriton D.R. </author> <title> The V Distributed System. </title> <journal> Communications of the ACM, </journal> <pages> 314-333, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: The language described by us differs from these mainly in its rich set of diverse information sharing modes, and on its reliance on implicit dynamic load balancing for scheduling work. The language we described is different from the distributed system kernels such as the V kernel <ref> [5] </ref>, or the Amoeba system [14] which essentially provide support for communicating processes. The Reactive Kernel/Cosmic Environment [2] also supports machine independent programming by providing communication mechanisms.
Reference: [6] <author> Chien A., Dally W.J. </author> <title> Concurrent Aggregates (CA). </title> <booktitle> In ACM SIGPLAN Principles and Practice of Parallel Programming, </booktitle> <address> Seattle, Washington, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: The Reactive Kernel/Cosmic Environment [2] also supports machine independent programming by providing communication mechanisms. The recently proposed Concurrent Aggregates (CA) language <ref> [6] </ref> bears some similarities with the branch-office chares in our language, although CA is aimed at a fine-grained machine (The J-machine) [7] being built at MIT. Implicitly parallel higher level languages such as Functional or Logic languages constitute another approach to machine independence.
Reference: [7] <author> Dally W.J. </author> <title> Fine-Grain Message-Passing Concurrent Computers. </title> <booktitle> In The Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <address> Pasadena, California, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: The Reactive Kernel/Cosmic Environment [2] also supports machine independent programming by providing communication mechanisms. The recently proposed Concurrent Aggregates (CA) language [6] bears some similarities with the branch-office chares in our language, although CA is aimed at a fine-grained machine (The J-machine) <ref> [7] </ref> being built at MIT. Implicitly parallel higher level languages such as Functional or Logic languages constitute another approach to machine independence.
Reference: [8] <author> Foster I., Taylor S. Strand: </author> <title> New Concepts in Parallel Programming. </title> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: Also important is that there is no context switching between explicit processes in our model and hence no associated overheads are incurred. There are other efforts aimed at machine independence. Strand <ref> [8] </ref> is a language based on asynchronous processes and streams, and is portable across many parallel machines. Linda [4] is another language based on the notion of a shared tuple-space. Actors [1] and concurrent object-based languages are comprised of processes which communicate by depositing and/or removing tuples with specific patterns.
Reference: [9] <author> Gabber E. </author> <title> VMMP: A Practical Tool for the Development for Portable and Efficient Programs for Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <pages> 304-317, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: This attempt, although significant in the direction it chose to take, did not go far enough, restricting its attention to a single type of architecture. A project with similar objectives as ours is the recently published VMMP project <ref> [9] </ref>. Like the Chare kernel, it too is designed for developing portable and efficient software on both shared and nonshared memory machines. One of the primary differences appears in the implementation of different information sharing abstractions in the two systems.
Reference: [10] <author> Kale L.V. </author> <title> Comparing the Performance of Two Dynamic Load Distribution Methods. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1988. </year>
Reference: [11] <author> Kale L.V. </author> <title> The Chare Kernel Parallel Programming System Programming System. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: For example, one may call Find (key, entryPoint, chareID); The call immediately returns, and eventually a message containing the data associated with the given key is sent to the specified chare at the specified entryPoint. The language description above is necessarily sketchy. See <ref> [11, 12] </ref> for a complete description of the language. <p> The execution times (in seconds) of the Sequential C program and the Chare Kernel program (1 processor) occur in parentheses. Additional performance data can be found in <ref> [11] </ref>. A parallel Prolog compiler which exploits both AND and OR parallelism has been written using the Chare kernel system [15], and is one of the first such systems to run efficiently on both shared and non-shared memory system. A state-space search package was also developed using the Chare kernel.
Reference: [12] <author> Kale L.V., et. al. </author> <title> The Chare Kernel Programming Language Manual. </title> <type> internal report. </type>
Reference-contexts: For example, one may call Find (key, entryPoint, chareID); The call immediately returns, and eventually a message containing the data associated with the given key is sent to the specified chare at the specified entryPoint. The language description above is necessarily sketchy. See <ref> [11, 12] </ref> for a complete description of the language.
Reference: [13] <author> Lin F.C.H, Keller R. </author> <title> Gradient Model: A Demand Driven Load Balancing Scheme. </title> <booktitle> In International Conference on Distributed Systems, </booktitle> <pages> pages 329-336, </pages> <year> 1986. </year>
Reference-contexts: Processors also exchange explicit load status messages periodically to keep their status information updated on their neighbors. An entry point is provided for this purpose. For a different load balancing scheme such as gradient model <ref> [13] </ref> the load balancing process may be awakened periodically to balance loads whenever the pressure gradient falls or rises above a certain threshold. Additional entry points may be added as desired for implementing different schemes.
Reference: [14] <author> Mullender S.J., Tanenbaum A. </author> <title> The Design of a Capability-Based Operating System. </title> <booktitle> Computer, </booktitle> <pages> 289-300, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: The language we described is different from the distributed system kernels such as the V kernel [5], or the Amoeba system <ref> [14] </ref> which essentially provide support for communicating processes. The Reactive Kernel/Cosmic Environment [2] also supports machine independent programming by providing communication mechanisms.
Reference: [15] <author> Ramkumar B., Kale L.V. </author> <title> A Chare Kernel Implementation of a Parallel Prolog Compiler. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Principles and Practice of Parallel Programming, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: The execution times (in seconds) of the Sequential C program and the Chare Kernel program (1 processor) occur in parentheses. Additional performance data can be found in [11]. A parallel Prolog compiler which exploits both AND and OR parallelism has been written using the Chare kernel system <ref> [15] </ref>, and is one of the first such systems to run efficiently on both shared and non-shared memory system. A state-space search package was also developed using the Chare kernel. Many other parallel applications are being developed using this system.

References-found: 15

