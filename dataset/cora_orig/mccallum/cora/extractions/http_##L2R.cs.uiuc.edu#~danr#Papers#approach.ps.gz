URL: http://L2R.cs.uiuc.edu/~danr/Papers/approach.ps.gz
Refering-URL: http://L2R.cs.uiuc.edu/~danr/publications.html
Root-URL: http://www.cs.uiuc.edu
Email: danr@wisdom.weizmann.ac.il  
Title: Learning in Order to Reason: The Approach framework suggests an "operational" approach to reasoning, that
Author: Dan Roth 
Web: http://www.wisdom.weizmann.ac.il/~danr  
Address: Rehovot 76100 Israel  
Affiliation: Dept. of Appl. Math. CS, Weizmann Institute of Science  
Note: Invited presentation at SOFSEM'96; appeared in LNCS 1175  Overall, this  Supported by a grant from the Israeli Ministry of Science veys further developments made within this frame work more recently.  
Abstract: Any theory aimed at understanding commonsense reasoning, the process that humans use to cope with the mundane but complex aspects of the world in evaluating everyday situations, should account for its flexibility, its adaptability, and the speed with which it is performed. Current theories of reasoning, however, do not satisfy these requirements, a fact we attribute, at least partly, to their separation from learning. While the central role of learning in cognition is widely acknowledged, most lines of research nevertheless study the phenomenon of "learning" separately from that of "reasoning". The work presented here is motivated by the belief that learning is at the core of any attempt at understanding high level cognitive tasks. A formal model for the study of reasoning is developed in which a learning component has a principal role, and its advantages over traditional formalisms for the study of reasoning are shown. This paper presents an integrated theory of learning, knowledge representation and reasoning within a unified framework called Learning to Reason. The Learning to Reason framework combines the interfaces to the world used by known learning models with a reasoning task and a performance criterion suitable for it. It is shown that the framework efficiently supports "more reasoning" than traditional approaches and at the same time matches our expectations of plausible patterns of reasoning. Several results are presented to substantiate this claim, presenting cases where learning to reason about the world is feasible but either reasoning from a given representation of the world or learning representations of the world do not have efficient solutions. The paper presents work originally introduced by Khardon and Roth (Khardon & Roth 1994a) and sur 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baum, E. </author> <year> 1996. </year> <title> Toward a model of mind as a laissez-faire economy of idiots. </title> <booktitle> In Proceedings of the International Conference on Machine Learning. </booktitle>
Reference-contexts: The most significant addition to the framework developed there is that the agent acts in the world, and there by changes it. Other works in planning which can be viewed within the Learning to Reason framework include, for example, <ref> (Baum 1996) </ref>. Learning Active Classifiers Many classification algorithms are "passive", in that they assign a class-label to each instance based only on the description given, even if that description is incomplete.
Reference: <author> Brooks, R. A. </author> <year> 1991. </year> <title> Intelligence without representation. </title> <booktitle> Artificial Intelligence 47 </booktitle> <pages> 139-159. </pages>
Reference-contexts: These results show that neither a traditional reasoning algorithm (from the CNF representation) nor a traditional learning algorithm (that can "classify" the world) is necessary for Learning to Reason. Moreover, the results exemplify the phrase "intelligence is in the eye of the beholder" <ref> (Brooks 1991) </ref>, since our agent seems to behave logically, even though its knowledge representation need not be a logical formula and it does not use any logic or "theorem proving".
Reference: <author> Bshouty, N. H. </author> <year> 1995. </year> <title> Exact learning via the monotone theory. </title> <booktitle> Information and Computation 123(1) </booktitle> <pages> 146-153. </pages>
Reference-contexts: The following results are shown for Learning to Reason algorithms that use a set of models (satisfying assignments) as their knowledge representation. The results build on a characterization of reasoning with models developed in (Khardon & Roth 1994b) (based on ideas from <ref> (Bshouty 1995) </ref>). * Learning to Reason without Reasoning: Consider the reasoning problem W j= ff, where W is some CNF formula and ff is a log nCNF (i.e., a CNF formula with at most log n literals in each clause).
Reference: <author> Cadoli, M. </author> <year> 1995. </year> <booktitle> Tractable Reasoning in Artificial Intelligence. Springer-verlag. Lecture notes in Artificial Intelligence, </booktitle> <volume> vol. </volume> <pages> 941. </pages>
Reference: <author> Doyle, J., and Patil, R. </author> <year> 1991. </year> <title> Two theses of knowledge representation: language restrictions, taxonomic classification, and the utility of representation services. </title> <booktitle> Artificial Intelligence 48 </booktitle> <pages> 261-297. </pages>
Reference-contexts: However, none of these works meet the strong tractability requirements for common-sense reasoning (as described, for example, in (Shastri 1993)), even though, (as argued, for example, in <ref> (Doyle & Patil 1991) </ref>) the inference is sometimes restricted in implausible ways. Very few works have considered the question of integrating theories of reasoning and learning in any formal way. In fact, results in these two fields are in a fairly disconnected state.
Reference: <author> Frazier, M., and Pitt, L. </author> <year> 1993. </year> <title> Learning from entailment: An application to propositional Horn sentences. </title> <booktitle> In Proceedings of the International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Golding, A. R., and Roth, D. </author> <year> 1996. </year> <title> Applying winnow to context-sensitive spelling correction. </title> <booktitle> In Proceedings of the International Conference on Machine Learning. </booktitle>
Reference-contexts: We briefly point to results which have be recently developed for other, related, reasoning tasks within this framework. We discuss in the following only theoretical results within this framework, and do not consider more applied work that is influenced by this framework <ref> (Golding & Roth 1996) </ref>. Abductive Reasoning The results cited above are based on learnability results for model-based representations.
Reference: <author> Greiner, R.; Grove, A.; and Roth, D. </author> <year> 1996. </year> <title> Learning active classifiers. </title> <booktitle> In Proceedings of the International Conference on Machine Learning, </booktitle> <pages> 207-215. </pages>
Reference-contexts: In contrast, an active classifier can, at some cost, obtain the values of missing attributes, before deciding upon a class label. The problem of learning active classifiers is formalized and studied in <ref> (Greiner, Grove, & Roth 1996) </ref>. It is shown there that while the "learn then optimize" approach to this problem is certainly sufficient (in principle) to determine active classifiers, it can fail (for complexity reasons) in various ways.
Reference: <author> Khardon, R., and Roth, D. </author> <year> 1994a. </year> <title> Learning to reason. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 682-687. </pages>
Reference-contexts: In this paper we present a high level survey of the theoretical work within the Learning to Reason framework. The work on this framework started by Khardon and Roth in <ref> (Khardon & Roth 1994a) </ref>, and many of the works discussed here are extensions of this paper in various directions. No technical details are given here. Rather, we motivate the framework, describe its high level principles and briefly discuss how they can be implemented and what results they yield. <p> No technical details are given here. Rather, we motivate the framework, describe its high level principles and briefly discuss how they can be implemented and what results they yield. For preliminaries on reasoning, learning and rigorous definitions for the material presented here, consult <ref> (Khardon & Roth 1994a) </ref>. Motivation The generally accepted framework for the study of reasoning in intelligent systems is the knowledge-based system approach (McCarthy 1958; Nilsson 1991). <p> Consult the relevant papers for those. General Framework Several general questions regarding the relation of the Learning to Reason (L2R) framework to the two existing ones, the traditional reasoning framework and the traditional learning framework have been considered <ref> (Khardon & Roth 1994a) </ref>. Most of these were considered for the task of deductive reasoning. First, it was shown that when the class of queries is not restricted, L2R implies L2C.
Reference: <author> Khardon, R., and Roth, D. </author> <year> 1994b. </year> <title> Reasoning with models. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 1148-1153. </pages> <note> To appear in Artificial Intelligence Journal. </note>
Reference-contexts: The following results are shown for Learning to Reason algorithms that use a set of models (satisfying assignments) as their knowledge representation. The results build on a characterization of reasoning with models developed in <ref> (Khardon & Roth 1994b) </ref> (based on ideas from (Bshouty 1995)). * Learning to Reason without Reasoning: Consider the reasoning problem W j= ff, where W is some CNF formula and ff is a log nCNF (i.e., a CNF formula with at most log n literals in each clause). <p> We discuss in the following only theoretical results within this framework, and do not consider more applied work that is influenced by this framework (Golding & Roth 1996). Abductive Reasoning The results cited above are based on learnability results for model-based representations. Together with the results in <ref> (Khardon & Roth 1994b) </ref>, which show how model-based representations can be used for efficient abductive reasoning (see there for details on the abduction formalisms used) this yields an algorithm for Learning to Reason abductively.
Reference: <author> Khardon, R., and Roth, D. </author> <year> 1995a. </year> <title> Default-reasoning with models. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> 319-325. </pages> <note> To appear in Artificial Intelligence. </note>
Reference-contexts: Default Reasoning As in the case of abductive reasoning, learnability results for model-based representations, together with the results in <ref> (Khardon & Roth 1995a) </ref>, which show how model-based representations can be used for efficient default reasoning, yield an algorithm for Learning to Reason with defaults. In particular, the results provide a "Learning to Reason without Reasoning" result to fragments of Reiter's default logic.
Reference: <author> Khardon, R., and Roth, D. </author> <year> 1995b. </year> <title> Learning to reason with a restricted view. </title> <booktitle> In Workshop on Computational Learning Theory, </booktitle> <pages> 301-310. </pages>
Reference-contexts: In particular, the results provide a "Learning to Reason without Reasoning" result to fragments of Reiter's default logic. Reasoning with Partial Assignments The deductive reasoning approach presented above has been extended in <ref> (Khardon & Roth 1995b) </ref> to handle partial assignments in the input. Several interpretations for partial information in the interface with the environment are discussed there and the work on model-based representations is extended to deal with partially observable worlds.
Reference: <author> Khardon, R. </author> <year> 1996. </year> <title> Learning to take actions. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 787-792. </pages>
Reference-contexts: It is then demonstrated that these have concise representations over the generalized domain and it is shown that these representations can be learned efficiently, yielding Learning to Reason algorithm that learn to reason non-monotonically. Learning to Take Action <ref> (Khardon 1996) </ref> extends the framework in another direction and studies planning problems. As in other instances of the Learning to Reason framework, the problem of learning to take actions is viewed as a supervised learning problem.
Reference: <author> Kirsh, D. </author> <year> 1991. </year> <title> Foundations of AI: the big issues. </title> <booktitle> Artificial Intelligence 47 </booktitle> <pages> 3-30. </pages>
Reference-contexts: While the central role of learning in cognition is widely acknowledged, early theories of intelligent systems have assumed that cognition (namely, computational processes such as reasoning, language understanding, object recognition and other "high level" cognitive tasks) can be studied separately from learning, or as phrased by Kirsh <ref> (Kirsh 1991) </ref>, that "learning can be added later". This paper presents a new framework for the study of Reasoning.
Reference: <author> Levesque, H., and Brachman, R. </author> <year> 1985. </year> <title> A fundamental tradeoff in knowledge representation and reasoning. </title>
Reference: <editor> In Brachman, R., and Levesque, H., eds., </editor> <booktitle> Readings in Knowledge Representation. </booktitle> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Levesque, H. </author> <year> 1992. </year> <title> Is reasoning too hard ? In Proceeding of the 3rd NEC research Symposium. </title>
Reference: <author> McCarthy, J. </author> <year> 1958. </year> <title> Programs with common sense. </title>
Reference: <editor> In Brachman, R., and Levesque, H., eds., </editor> <booktitle> Readings in Knowledge Representation, 1985. </booktitle> <publisher> Morgan-Kaufmann. </publisher>
Reference: <author> Moses, Y., and Tennenholtz, M. </author> <year> 1993. </year> <title> Off-line reasoning for on-line efficiency. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> 490-495. </pages>
Reference: <author> Nilsson, N. J. </author> <year> 1991. </year> <booktitle> Logic and artificial intelligence. Artificial Intelligence 47 </booktitle> <pages> 31-56. </pages>
Reference: <author> Papadimitriou, C. H. </author> <year> 1991. </year> <title> On selecting a satisfying truth assignment. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> 163-169. </pages>
Reference: <author> Roth, D. </author> <year> 1995. </year> <title> Learning to reason: The non-monotonic case. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> 1178-1184. </pages>
Reference-contexts: This is used to formalize the intuition that incomplete information may actually help to support efficient and plausible reasoning; the underlying assumption is that missing information in the interaction of the agent with its environment may be as informative for future interactions as observed information. Formally, <ref> (Roth 1995) </ref> shows that the problem of reasoning from incomplete information can be presented as a problem of learning attribute functions over a generalized domain.
Reference: <author> Roth, D. </author> <year> 1996. </year> <title> On the hardness of approximate reasoning. </title> <journal> Artificial Intelligence 82(1-2):273-302. </journal>
Reference-contexts: We briefly point to results which have be recently developed for other, related, reasoning tasks within this framework. We discuss in the following only theoretical results within this framework, and do not consider more applied work that is influenced by this framework <ref> (Golding & Roth 1996) </ref>. Abductive Reasoning The results cited above are based on learnability results for model-based representations. <p> In contrast, an active classifier can, at some cost, obtain the values of missing attributes, before deciding upon a class label. The problem of learning active classifiers is formalized and studied in <ref> (Greiner, Grove, & Roth 1996) </ref>. It is shown there that while the "learn then optimize" approach to this problem is certainly sufficient (in principle) to determine active classifiers, it can fail (for complexity reasons) in various ways.
Reference: <author> Selman, B., and Kautz, H. </author> <year> 1991. </year> <title> Knowledge compilation using Horn approximations. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 904-909. </pages>
Reference: <author> Selman, B., and Kautz, H. </author> <year> 1996. </year> <title> Knowledge compilation and theory approximation. </title> <journal> Journal of the ACM 43(2) </journal> <pages> 193-224. </pages>
Reference: <author> Selman, B. </author> <year> 1990. </year> <title> Tractable Default Reasoning. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Toronto. </institution>
Reference: <author> Shastri, L. </author> <year> 1993. </year> <title> A computational model of tractable reasoning taking inspiration from cognition. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> 202-207. </pages>
Reference-contexts: However, none of these works meet the strong tractability requirements for common-sense reasoning (as described, for example, in <ref> (Shastri 1993) </ref>), even though, (as argued, for example, in (Doyle & Patil 1991)) the inference is sometimes restricted in implausible ways. Very few works have considered the question of integrating theories of reasoning and learning in any formal way.
Reference: <author> Valiant, L. G. </author> <year> 1994. </year> <title> Circuits of the Mind. </title> <publisher> Oxford University Press. </publisher>
Reference-contexts: This work is similar in nature to the Neuroidal model developed by Valiant <ref> (Valiant 1994) </ref>. The model developed there provides a more comprehensive approach to cognition, and akin to our approach it views learning as an integral and crucial part of the process. There, the agent reasons from a learned knowledge base, a complex circuit, and thus can be modeled by our framework.
Reference: <author> Valiant, L. G. </author> <year> 1995. </year> <title> Rationality. </title> <booktitle> In Workshop on Computational Learning Theory, </booktitle> <pages> 3-14. </pages>
References-found: 30

