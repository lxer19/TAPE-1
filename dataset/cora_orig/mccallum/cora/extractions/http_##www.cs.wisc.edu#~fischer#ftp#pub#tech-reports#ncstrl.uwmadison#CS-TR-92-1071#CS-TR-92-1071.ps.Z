URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1071/CS-TR-92-1071.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1071/
Root-URL: http://www.cs.wisc.edu
Note: c copyright by Venkatachary Srinivasan 1992 All Rights Reserved  
Abstract-found: 0
Intro-found: 1
Reference: [Agra89] <author> Agrawal, D. and Sengupta, S., </author> <title> "Modular Synchronization in Multiver-sion Databases: Version Control and Concurrency Control", </title> <booktitle> Proceedings of the ACM SIGMOD Conference, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: This is quite similar to the way that queries execute in the compensation-based model in order to generate transaction-consistent answers. Concurrency control algorithms based on transient versioning (e.g., <ref> [Chan82, Agra89, Bobe92] </ref>) are also related to compensation-based query processing. In transient versioning algorithms, prior versions of data are retained to allow queries to see slightly outdated but transaction-consistent database snapshots.
Reference: [Agra87] <author> Agrawal, R., Carey, M., and Livny, M., </author> <title> "Concurrency Control Performance Modeling: Alternatives and Implications", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(4), </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: In addition to concrete performance measures such as transaction throughput, it would be nice if the level of concurrency provided by the protocols could be somehow characterized. For this study, we have adopted the throughput of the protocols under infinite resources <ref> [Fran85, Tay84, Agra87] </ref> as a measure of the level of concurrency that they provide. The resource manager simulates such a condition by replacing the CPU and disk scheduling code with pure time delays.
Reference: [Baye72] <author> Bayer, R. and McCreight, </author> <title> E.M., "Organization and Maintainance of Large Ordered Indices", </title> <journal> Acta Informatica, </journal> <volume> 1(3), </volume> <pages> 173-189, </pages> <year> 1972. </year>
Reference: [Baye77] <author> Bayer, R. and Schkolnick, M., </author> <title> "Concurrency of Operations on B-trees", </title> <journal> Acta Informatica, </journal> <volume> 9, </volume> <pages> 173-189, </pages> <year> 1977. </year>
Reference-contexts: A number of algorithms have been proposed for accessing indices concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but no performance analyses existed until recently that compare all of these algorithms. The earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. As a result, the relative performance of these algorithms was still an open question when work began on this thesis 1 . <p> A number of algorithms have been proposed for accessing B-trees concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but few performance analyses exist that compare these algorithms. Most earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. <p> Updaters and readers whose scopes do not interfere can thus execute concurrently. However, a considerable number of conflicts may be caused at higher level nodes due to the use of X locks. A class of algorithms that improves on the above idea was proposed by Bayer and Schkolnick <ref> [Baye77] </ref>. Bayer-Schkolnick Algorithms In all Bayer-Schkolnick algorithms, searches always follow the same locking protocol. In particular, a search gets an S lock on the root and lock-couples to the leaf using S locks. The various algorithms differ in the locking strategy used by updaters. <p> operations; the ARIES/IM algorithm also describes how to hold extended locks on records (to allow serializability of transactions that perform more than one B-tree operation) as well as how to perform recovery using write-ahead logging. 2.6 Comparison with Related Work An approximate analysis of the Bayer-Schkolnick algorithms was included in <ref> [Baye77] </ref>. The formulas provided there calculate quantities like the number of locks held by tree operations and the maximum MPL that can be handled without creating a bottleneck at the root. This is a static analysis, so it does not provide insight into the dynamic performance of the various algorithms.
Reference: [Bern81] <author> Bernstein, P., and Goodman, N., </author> <title> "Concurrency Control in Distributed Database Systems", </title> <journal> ACM Computing Surveys, </journal> <volume> 13(2), </volume> <month> June </month> <year> 1981. </year>
Reference: [Bili85] <author> Biliris, A., </author> <title> "A Model for the Evaluation of Concurrency Control Algorithms on B-trees", </title> <journal> Computer Science Technical Report, </journal> <volume> No. </volume> <pages> 85-015, </pages> <address> Boston University, </address> <year> 1985. </year>
Reference-contexts: A number of algorithms have been proposed for accessing indices concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but no performance analyses existed until recently that compare all of these algorithms. The earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. As a result, the relative performance of these algorithms was still an open question when work began on this thesis 1 . <p> A number of algorithms have been proposed for accessing B-trees concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but few performance analyses exist that compare these algorithms. Most earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. <p> It should be noted that the phenomenon of a bottleneck at the root for pessimistic algorithms has been mentioned in earlier papers <ref> [Bili85, John90a] </ref>; our contribution is to the understanding of how bottlenecks affect the response times of different operation types. <p> This is a static analysis, so it does not provide insight into the dynamic performance of the various algorithms. Biliris <ref> [Bili85] </ref> described a simulation model for the evaluation of B-tree algorithms and presented a set of experiments comparing four algorithms that included the Samadi algorithm [Sama76], the B-SIX algorithm, the side-branching algorithm [Kwon82], and the mU algorithm [Bili87].
Reference: [Bili87] <author> Biliris, A., </author> <title> "Operation Specific Locking in B-trees", </title> <booktitle> Proceedings of the Sixth ACM Symposium on Principles of Database Systems, </booktitle> <address> San Diego, California, 159-169, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: A restarted updater 4 repeatedly tries the protocol until it succeeds; starvation is avoided by assigning priorities to operations based on their first start time. Apart from the algorithms described above, several other B-tree concurrency control algorithms have been proposed as well <ref> [Kwon82, Bili87, Moha89] </ref>. <p> an effect on performance since, due to updaters experiencing a bottleneck at the root, there is already little interference (as evidenced by the almost constant search response times in Figure 2.9 for the SIX-LC algorithm class). 2.5.2 The mU Protocol An interesting algorithm called the mU protocol was proposed in <ref> [Bili87] </ref>. An important feature of this algorithm is that the compatibility graph for locks on a node is dependent on the occupancy of the node. <p> Biliris [Bili85] described a simulation model for the evaluation of B-tree algorithms and presented a set of experiments comparing four algorithms that included the Samadi algorithm [Sama76], the B-SIX algorithm, the side-branching algorithm [Kwon82], and the mU algorithm <ref> [Bili87] </ref>. This study found that the pessimistic algorithms bottleneck at the root and that the mU algorithm performed better in the situations considered. The side-branching technique was found not to give any improvement over B-SIX.
Reference: [Blak86a] <author> Blakeley, J., Larson, P. and Tompa, F., </author> <title> "Efficiently Updating Materialized Views", </title> <booktitle> Proceedings of the ACM SIGMOD Conference, </booktitle> <month> May </month> <year> 1986. </year>
Reference-contexts: In the compensation phase, one would then try to get a transaction-consistent answer by applying the update-list to the intermediate answer. This third strategy has characteristics similar to keeping materialized views up-to-date when the base relations are updated <ref> [Blak86a, Blak86b] </ref>; this is a hard problem for arbitrary join queries, even when an initial transaction-consistent copy of the view exists, so we will not consider the third strategy further. 5.5.1 Optimizing Compensation-Based Queries While executing complex queries in a compensation-based manner, certain query optimization techniques carry through with minor modifications
Reference: [Blak86b] <author> Blakeley, J., Coburn, N. and Larson, P., </author> <title> "Updating Derived Relations: Detecting Irrelevant and Autonomously Computable Updates", </title> <booktitle> Proceedings of the 191 192 Twelfth International Conference on Very Large Data Bases, </booktitle> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: In the compensation phase, one would then try to get a transaction-consistent answer by applying the update-list to the intermediate answer. This third strategy has characteristics similar to keeping materialized views up-to-date when the base relations are updated <ref> [Blak86a, Blak86b] </ref>; this is a hard problem for arbitrary join queries, even when an initial transaction-consistent copy of the view exists, so we will not consider the third strategy further. 5.5.1 Optimizing Compensation-Based Queries While executing complex queries in a compensation-based manner, certain query optimization techniques carry through with minor modifications
Reference: [Bobe92] <author> Bober, P. and Carey, M., </author> <title> "On Mixing Queries and Transactions Via Multiversion Locking", </title> <booktitle> Proceedings of the Eighth IEEE Conference on Data Engineering, </booktitle> <month> February </month> <year> 1992, </year> <note> to appear. </note>
Reference-contexts: This is quite similar to the way that queries execute in the compensation-based model in order to generate transaction-consistent answers. Concurrency control algorithms based on transient versioning (e.g., <ref> [Chan82, Agra89, Bobe92] </ref>) are also related to compensation-based query processing. In transient versioning algorithms, prior versions of data are retained to allow queries to see slightly outdated but transaction-consistent database snapshots.
Reference: [Care84a] <author> Carey, M., and Stonebraker, M., </author> <title> "The Performance of Concurrency Control Algorithms for Database Management Systems", </title> <booktitle> Proceedings of the Tenth International Conference on Very Large Data Bases, </booktitle> <address> Singapore, </address> <month> August </month> <year> 1984. </year>
Reference: [Care84b] <author> Carey, M., and Thompson, C., </author> <title> "An Efficient Implementation of Search Trees on dlg N + 1e Processors", </title> <journal> IEEE Transactions on Computer Systems, </journal> <volume> 11(2), </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: Several alternative algorithms have been proposed that instead split the updating of the scope into several smaller, atomic operations. We consider two of these next, the top-down and B-link algorithms. Top-down Algorithms In top-down algorithms <ref> [Guib78, Care84b, Mond85, Lani86] </ref>, updaters perform what are known as preparatory splits and merges. If an inserter encounters a full node during its descent, it performs a preparatory page split and inserts an appropriate index entry in the parent of the newly split node.
Reference: [Chan82] <author> Chan, A. et al, </author> <title> "The Implementation of an Integrated Concurrency Control and Recovery Scheme", </title> <booktitle> Proceedings of the ACM SIGMOD Conference, </booktitle> <month> June </month> <year> 1982. </year>
Reference-contexts: This is quite similar to the way that queries execute in the compensation-based model in order to generate transaction-consistent answers. Concurrency control algorithms based on transient versioning (e.g., <ref> [Chan82, Agra89, Bobe92] </ref>) are also related to compensation-based query processing. In transient versioning algorithms, prior versions of data are retained to allow queries to see slightly outdated but transaction-consistent database snapshots.
Reference: [Chen84] <author> Cheng, J.M., Loosley, C.R., Shibamiya, A. and Worthington, </author> <title> P.S., "IBM Database 2 Performance: Design, Implementation, and Tuning", </title> <journal> IBM Systems Journal,, </journal> <volume> 23(2), </volume> <pages> 189-210, </pages> <year> 1984. </year>
Reference: [Come79] <author> Comer, D., </author> <title> "The Ubiquitous B-Tree", </title> <journal> ACM Computing Surveys, </journal> <volume> 11(4), </volume> <year> 1979. </year>
Reference-contexts: Since B-trees 2 are the most common dynamic index structures in DBMSs, most earlier 2 By B-tree we mean the variant in which all keys are stored at the leaves, also called B + -trees and sometimes B fl -trees <ref> [Come79] </ref>. 7 work has concentrated on them, and our focus is also on B-tree concurrency control algorithms. However, many of our results will lend insight into concurrency control for other index structures also. <p> Thus, the relative performance of these 1 Again, by B-tree we mean the variant in which all keys are stored at the leaves, also called B + -trees and sometimes B fl -trees <ref> [Come79] </ref> 10 11 algorithms in more realistic situations was an open question when work began on this thesis. An extension of the work in [John90a] resulted in a more comprehensive study of B-tree concurrency control algorithms [John90b].
Reference: [Dewi90] <author> DeWitt, D. J. and Gray, J., </author> <title> "Parallel Database Systems: The Future of Database Processing or a Passing Fad?", </title> <booktitle> SIGMOD Record, </booktitle> <month> 19(4) December </month> <year> 1990. </year>
Reference-contexts: Examples of such 1 2 24fi7 systems include database management for multinational companies with a global reach, hospital management systems, round-the-clock shopping services, etc. In order to service such applications, next generation databases will be required to keep their data on-line all of the time <ref> [Dewi90, Silb90] </ref>. The above trends affect important aspects of database design and implementation, as discussed below. Under very high transaction rates, contention in heavily used auxiliary data structures like indices can increase tremendously, necessitating the use of highly concurrent algorithms for managing these data structures. <p> It is almost sure to be unacceptable 65 66 to exclude updates for such an extended period of time. In fact, leading researchers have identified the problem of on-line index construction for very large databases as an important open research problem <ref> [Dewi90, Silb90] </ref>. In this chapter, we present several algorithms for on-line index construction.
Reference: [Elli80a] <author> Ellis, C., </author> <title> "Concurrent Search and Insertion in 2-3 Trees", </title> <journal> Acta Infor-matica, </journal> <volume> 14(1), </volume> <year> 1980. </year>
Reference: [Elli80b] <author> Ellis, C., </author> <title> "Concurrent Search and Insertion in AVL Trees", </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29(9), </volume> <month> September </month> <year> 1980. </year>
Reference: [Elli83] <author> Ellis, C., </author> <title> "Extendible Hashing for Concurrent Operations and Distributed Data", </title> <booktitle> Proceedings of the 2nd ACM Symposium on Principles of Database Systems, </booktitle> <address> Atlanta, Georgia, </address> <month> March </month> <year> 1983. </year> <month> 193 </month>
Reference: [Epst79] <author> Epstein, R., </author> <title> "Techniques For Processing of Aggregates in Relational Database Systems", </title> <note> Memorandum No. </note> <institution> UCB/ERL M79/8, Electronics Research Laboratory, University of California-Berkeley, </institution> <year> 1979. </year>
Reference-contexts: Since the compensation-based model is particularly well suited to executing aggregate queries efficiently, we consider several examples of aggregate queries first. Techniques for processing aggregate queries in relational database systems have been discussed earlier <ref> [Epst79] </ref>; our work employs some of those techniques as well as extensions needed in the context of our compensation-based model. Aggregate queries come in two types, scalar aggregates and aggregate functions. Scalar aggregates compute a single scalar value, like the aggregate AVG in query Q1 of Section 5.1. <p> The following steps are needed for processing a general scalar aggregate <ref> [Epst79] </ref>: 1. Allocate two variables, one for storing the aggregate result and another for stor ing a count. Initialize both to zero. 2. For each tuple that satisfies the qualification, update the aggregate result and increment the counter. <p> This query computes the average of the salary values over all tuples of the EMPLOYEE relation. In each approach, the scan performed by the query can be either a relation scan or an index-only scan <ref> [Epst79] </ref>. One way to execute query Q1 is similar to the execution of the consistent-copy query of Figure 5.2, with minor differences. The query process first scans the EMPLOYEE relation collecting [SALARY, tuple-id] pairs. <p> SQL has a GROUP BY-clause for this purpose. Aggregate functions require the maintenance of an aggregate value, a count field, and the actual BY-list attribute value for each different value 152 of the BY-list attribute. There are two basic algorithms that are commonly used to compute aggregate functions <ref> [Epst79] </ref>: 1. The first technique scans the base relation, maintaining a temporary relation which has attributes for the count field, the aggregate value, and the BY-list attribute value. <p> Furthermore, given that the leaf page of the index stores [SALARY, rid] pairs, the relation does not have to be accessed at all; an index-only scan is sufficient <ref> [Epst79] </ref>. (Note that the rid will be used to lock the tuple while its SALARY attribute is being read from the index in this case.) Concurrent update transactions can either be required to apply the filter as well, 156 thereby restricting their appends to the update-list, or they can simply append
Reference: [Fran85] <author> Franaszek, P., and Robinson, J., </author> <title> "Limitations of Concurrency in Transaction Processing", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 10(1), </volume> <pages> 1-28, </pages> <month> March </month> <year> 1985. </year>
Reference-contexts: In addition to concrete performance measures such as transaction throughput, it would be nice if the level of concurrency provided by the protocols could be somehow characterized. For this study, we have adopted the throughput of the protocols under infinite resources <ref> [Fran85, Tay84, Agra87] </ref> as a measure of the level of concurrency that they provide. The resource manager simulates such a condition by replacing the CPU and disk scheduling code with pure time delays.
Reference: [Good85] <author> Goodman, N., and Shasha, D., </author> <title> "Semantically-based Concurrency Control for Search Structures", </title> <booktitle> Proceedings of the Fourth ACM Symposium on Principles of Database Systems, </booktitle> <month> March </month> <year> 1985. </year>
Reference: [Gray79] <author> Gray, J., </author> <title> "Notes On Database Operating Systems", in Operating Systems: An Advanced Course, </title> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: Under very high transaction rates, contention in heavily used auxiliary data structures like indices can increase tremendously, necessitating the use of highly concurrent algorithms for managing these data structures. Concurrency control techniques that work well for records or data pages, such as two-phase locking <ref> [Gray79] </ref>, are overly restrictive when naively applied to such items as index pages. Special techniques must be employed to prevent indices and system catalogs from becoming concurrency bottlenecks. <p> For example, IBM's System R and DB2 offer the concept of cursor stability <ref> [Gray79] </ref>, where a query like Q1 looks only at committed updates of other transactions, but holds locks on tuples only while their values are actually being read. <p> Updaters are assumed to hold an Intention-exclusive lock on the relation while modifying a page of the relation (a la the hierarchical locking scheme of <ref> [Gray79] </ref>) and would therefore be unable to execute concurrently with the index building process. On the other hand, readers (which only acquire an Intention-share lock on the relation) can access the relation's pages concurrently with the building process. The pseudo code for this algorithm is given in Figure 3.3. <p> SELECT AVG (SALARY) FROM EMPLOYEE We explained in Chapter 1 that the only on-line way of executing a query such as Q1 in a typical commercial DBMS is to use a lower degree of consistency (like cursor stability <ref> [Gray79] </ref>), therefore obtaining only an approximate (non-serializable) answer. Any attempt to obtain a serializable answer for such queries is likely to have an unacceptable impact on system performance. <p> During the scan, the query process locks a tuple in Share mode only while the tuple is being read, using the same mechanism that is used in cursor stability <ref> [Gray79] </ref>. For each tuple it encounters in the scan, the query process extracts the data that it needs for query execution. <p> In our discussions thus far, we have assumed that the query process executes under cursor stability (also called level 2 consistency) <ref> [Gray79] </ref>, in which case it reads only committed data from other transactions. This form of execution is sufficient for producing transaction-consistent answers, but is not strictly necessary. <p> Compared to that work, the method described here is more general and handles arbitrarily complex queries. The process of scanning the base relations in the compensation-based method is also akin to taking a fuzzy dump of the relations <ref> [Gray79] </ref>. After the dump is taken, the log generated during the fuzzy dump is merged with the fuzzy dump to produce a sharp dump. This is quite similar to the way that queries execute in the compensation-based model in order to generate transaction-consistent answers.
Reference: [Guib78] <author> Guibas, L., and Sedgewick, R., </author> <title> "A Dichromatic Framework for Balanced Trees", </title> <booktitle> Proceedings of the Nineteenth Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1978. </year>
Reference-contexts: Several alternative algorithms have been proposed that instead split the updating of the scope into several smaller, atomic operations. We consider two of these next, the top-down and B-link algorithms. Top-down Algorithms In top-down algorithms <ref> [Guib78, Care84b, Mond85, Lani86] </ref>, updaters perform what are known as preparatory splits and merges. If an inserter encounters a full node during its descent, it performs a preparatory page split and inserts an appropriate index entry in the parent of the newly split node.
Reference: [Haer83] <author> Haerder, T., and Reuter, A., </author> <title> "Principles of Transaction-Oriented Database Recovery", </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4), </volume> <month> December </month> <year> 1983. </year>
Reference: [John89] <author> Johnson, T. and Shasha, D., </author> <title> "Utilization of B-trees with Inserts, Deletes and Searches", </title> <booktitle> Proceedings of the Eighth ACM Symposium on Principles of Database Systems, </booktitle> <pages> 235-246, </pages> <year> 1989. </year>
Reference-contexts: B-trees in real database systems usually perform page merges only when pages becomes empty; nodes are not actually required to contain at least d entries, since this simplifies implementation and for practical workloads is not found to decrease occupancy by much <ref> [John89] </ref>. We employ this approach to B-tree merges in this study. A node is considered safe for an insert if it is not full and safe for a delete if it has more than one entry.
Reference: [John90a] <author> Johnson, T. and Shasha, D., </author> <title> "A Framework for the Performance Analysis of Concurrent B-Tree Algorithms", </title> <booktitle> Proceedings of the Ninth ACM Symposium on Principles of Database Systems, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: A number of algorithms have been proposed for accessing indices concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but no performance analyses existed until recently that compare all of these algorithms. The earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. As a result, the relative performance of these algorithms was still an open question when work began on this thesis 1 . <p> Utilities are typically used for re-organization of data and for construction and maintenance of hidden data 1 It should be noted that the work reported in <ref> [John90a] </ref> has been extended concurrently with this work, and another comprehensive study of B-tree concurrency control algorithms is now available in [John90b]. 3 structures like indices. <p> A number of algorithms have been proposed for accessing B-trees concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but few performance analyses exist that compare these algorithms. Most earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. <p> An extension of the work in <ref> [John90a] </ref> resulted in a more comprehensive study of B-tree concurrency control algorithms [John90b]. That work was done concurrently with our work, which first appeared as [Srin91], and we will compare our performance results with those of [John90b] at the end of this chapter. <p> It should be noted that the phenomenon of a bottleneck at the root for pessimistic algorithms has been mentioned in earlier papers <ref> [Bili85, John90a] </ref>; our contribution is to the understanding of how bottlenecks affect the response times of different operation types. <p> The most recently published performance analysis of B-tree concurrency control algorithms was based on analytic modeling of an open queuing system <ref> [John90a] </ref>. This study assumed infinite resource conditions and did not model buffer management. The algorithms compared in the study are a naive lock-coupling algorithm (B-X), an 61 optimistic algorithm (B-OPT modified with the second phase using X locks instead of SIX locks), and the LY version of the B-link algorithm. <p> Finally, their model allows only S and X locks, while we have considered more complicated algorithms that use SIX locks to enable certain tree operations to overtake others on their descent to the leaf. In parallel with the work reported in this thesis, the authors of <ref> [John90a] </ref> have extended their work. In their extended study [John90b], they now handle SIX locks and analyze four additional algorithms: TD-X, B-OPT, two-phase locking, and a parameterized optimistic descent algorithm (in which the number of levels X-locked during the first descent is a parameter). <p> In our low contention experiments (experiment Set 1), for example, searches in B-SIX were faster even than searches in the B-link algorithms, though the overall throughput of the B-link algorithms was much higher than that of the B-SIX algorithm (see Figures 2.6 and 2.9). The analytical model in <ref> [John90a, John90b] </ref> assumes that the proportion of inserts in the workload is always larger than that of deletes, i.e., they model only growing trees. Also, the workload model assumes that operations access leaf nodes uniformly. <p> Another alternative for an open system would be to analyze the various algorithms based on a loss metric constructed from the maximum throughput, which is defined as the maximum possible arrival rate that can be handled 114 stably by the open system <ref> [John90a, John90b] </ref>.
Reference: [John90b] <author> Johnson, T., </author> <title> "The Performance of Concurrent Data Structure Algorithms", </title> <type> Ph.D. Thesis, </type> <address> New York University, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Utilities are typically used for re-organization of data and for construction and maintenance of hidden data 1 It should be noted that the work reported in [John90a] has been extended concurrently with this work, and another comprehensive study of B-tree concurrency control algorithms is now available in <ref> [John90b] </ref>. 3 structures like indices. <p> An extension of the work in [John90a] resulted in a more comprehensive study of B-tree concurrency control algorithms <ref> [John90b] </ref>. That work was done concurrently with our work, which first appeared as [Srin91], and we will compare our performance results with those of [John90b] at the end of this chapter. <p> An extension of the work in [John90a] resulted in a more comprehensive study of B-tree concurrency control algorithms <ref> [John90b] </ref>. That work was done concurrently with our work, which first appeared as [Srin91], and we will compare our performance results with those of [John90b] at the end of this chapter. In this chapter, we analyze the performance of various B-tree concurrency control algorithms using a simulation model of B-tree operations in a centralized DBMS. Our study differs from earlier ones in several aspects: 1. <p> In parallel with the work reported in this thesis, the authors of [John90a] have extended their work. In their extended study <ref> [John90b] </ref>, they now handle SIX locks and analyze four additional algorithms: TD-X, B-OPT, two-phase locking, and a parameterized optimistic descent algorithm (in which the number of levels X-locked during the first descent is a parameter). <p> In our low contention experiments (experiment Set 1), for example, searches in B-SIX were faster even than searches in the B-link algorithms, though the overall throughput of the B-link algorithms was much higher than that of the B-SIX algorithm (see Figures 2.6 and 2.9). The analytical model in <ref> [John90a, John90b] </ref> assumes that the proportion of inserts in the workload is always larger than that of deletes, i.e., they model only growing trees. Also, the workload model assumes that operations access leaf nodes uniformly. <p> In addition, our append experiments model a situation with highly concurrent and skewed access to portions of the B-tree. In addition to extending their work to additional algorithms, <ref> [John90b] </ref> modeled resource contention using a service time dilation factor and found that (i) under very high resource contention there was no difference between the various algorithms and (ii) under moderate to light contention there was a significant difference between the algorithms. These conclusions essentially agree with our results. <p> In addition, we found that in high resource contention situations a highly skewed append workload causes 63 the B-link algorithms to exhibit a thrashing behavior; in fact, in such situations, the B-link algorithms performed worse than the exclusive lock-coupling algorithms at high MPLs (Figure 2.21). <ref> [John90b] </ref> also showed that LRU buffering will hold the highest levels of the tree in memory. While our results agree with theirs, we have also characterized the extra utilization of the buffer pool by variations of the B-link algorithms. <p> Another alternative for an open system would be to analyze the various algorithms based on a loss metric constructed from the maximum throughput, which is defined as the maximum possible arrival rate that can be handled 114 stably by the open system <ref> [John90a, John90b] </ref>.
Reference: [Kell88] <author> Keller, A. and Wiederhold, G., </author> <title> "Concurrent Use of B-trees with Variable-Length Entries", </title> <booktitle> SIGMOD Record, </booktitle> <volume> 17(2), </volume> <month> June </month> <year> 1988. </year>
Reference: [Kung80] <author> Kung, H., and Lehman, P., </author> <title> "A Concurrent Database Manipulation Problem: Binary Search Trees", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 5(3), </volume> <month> September </month> <year> 1980. </year> <month> 194 </month>
Reference: [Kwon82] <author> Kwong, Y., and Wood, D., </author> <title> "A New Method for Concurrency in B-trees", </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-8(3), </volume> <month> May </month> <year> 1982. </year>
Reference-contexts: A restarted updater 4 repeatedly tries the protocol until it succeeds; starvation is avoided by assigning priorities to operations based on their first start time. Apart from the algorithms described above, several other B-tree concurrency control algorithms have been proposed as well <ref> [Kwon82, Bili87, Moha89] </ref>. <p> Based on the above observations and the results of the previous section, we can also comment on the performance of algorithms that have not been explicitly simulated in our system relative to the performance of the B-link algorithms. 2.5.1 Side-Branching Technique The side-branching solution proposed in <ref> [Kwon82] </ref> is a modification to the SIX locking Bayer-Schkolnick algorithm, B-SIX. Updaters in this algorithm perform the allocation of new pages and the copying of keys from old pages to new ones while holding SIX locks on the scope of the update. <p> Biliris [Bili85] described a simulation model for the evaluation of B-tree algorithms and presented a set of experiments comparing four algorithms that included the Samadi algorithm [Sama76], the B-SIX algorithm, the side-branching algorithm <ref> [Kwon82] </ref>, and the mU algorithm [Bili87]. This study found that the pessimistic algorithms bottleneck at the root and that the mU algorithm performed better in the situations considered. The side-branching technique was found not to give any improvement over B-SIX.
Reference: [Lani86] <author> Lanin, V. and Shasha, D., </author> <title> "A Symmetric Concurrent B-tree Algorithm", </title> <booktitle> Proceedings of the Fall Joint Computer Conference, </booktitle> <pages> 380-389, </pages> <year> 1986. </year>
Reference-contexts: A number of algorithms have been proposed for accessing indices concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but no performance analyses existed until recently that compare all of these algorithms. The earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. As a result, the relative performance of these algorithms was still an open question when work began on this thesis 1 . <p> A number of algorithms have been proposed for accessing B-trees concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but few performance analyses exist that compare these algorithms. Most earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. <p> Several alternative algorithms have been proposed that instead split the updating of the scope into several smaller, atomic operations. We consider two of these next, the top-down and B-link algorithms. Top-down Algorithms In top-down algorithms <ref> [Guib78, Care84b, Mond85, Lani86] </ref>, updaters perform what are known as preparatory splits and merges. If an inserter encounters a full node during its descent, it performs a preparatory page split and inserts an appropriate index entry in the parent of the newly split node. <p> If the leaf is unsafe, the updater releases all locks and then restarts the operation, making a second descent a la TD-SIX <ref> [Lani86] </ref>. Readers use the same locking strategy as in the Bayer-Schkolnick algorithms. The top-down algorithms break down the updating of a scope into sub-operations that involve nodes at two adjacent levels of the tree. <p> The B-link algorithms go one step further and limit each sub-operation to nodes at a single tree level. They also differ from the top-down algorithms in that they do their updates in a bottom-up manner. B-link Tree Algorithms A B-link tree <ref> [Lehm81, Sagi85, Lani86] </ref> is a modification of the B-tree that uses links to chain all nodes at each level together. A page in a B-link tree contains a high key 19 (the highest key of the subtree rooted at this page) and a link to the right sibling. <p> Operations arriving at a newly split node with a search key greater than the high key use the right link to get to the appropriate page. Such a sideways traversal is termed a link-chase. Merges can also be done in two steps <ref> [Lani86] </ref>, via a half-merge followed by an entry deletion at the next higher tree level. The B-link algorithms that have been proposed [Lehm81, Sagi85, Lani86] differ from the Bayer-Schkolnick and top-down algorithms in that neither readers nor updaters lock-couple on their way down to a leaf. <p> Such a sideways traversal is termed a link-chase. Merges can also be done in two steps [Lani86], via a half-merge followed by an entry deletion at the next higher tree level. The B-link algorithms that have been proposed <ref> [Lehm81, Sagi85, Lani86] </ref> differ from the Bayer-Schkolnick and top-down algorithms in that neither readers nor updaters lock-couple on their way down to a leaf. We study three variations of the B-link algorithms: LY, LY-LC and LY-ABUF. <p> One way to take care of this problem is to force updaters that encounter such inconsistencies to restart repeatedly until they succeed <ref> [Lani86] </ref>. Our solution is different, however, and we modify the LY algorithm to hold locks more conservatively, thus eliminating inconsistent situations altogether.
Reference: [Lehm81] <author> Lehman, P., and Yao, S., </author> <title> "Efficient Locking for Concurrent Operations on B-trees", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6(4), </volume> <month> December </month> <year> 1981. </year>
Reference-contexts: The B-link algorithms go one step further and limit each sub-operation to nodes at a single tree level. They also differ from the top-down algorithms in that they do their updates in a bottom-up manner. B-link Tree Algorithms A B-link tree <ref> [Lehm81, Sagi85, Lani86] </ref> is a modification of the B-tree that uses links to chain all nodes at each level together. A page in a B-link tree contains a high key 19 (the highest key of the subtree rooted at this page) and a link to the right sibling. <p> Such a sideways traversal is termed a link-chase. Merges can also be done in two steps [Lani86], via a half-merge followed by an entry deletion at the next higher tree level. The B-link algorithms that have been proposed <ref> [Lehm81, Sagi85, Lani86] </ref> differ from the Bayer-Schkolnick and top-down algorithms in that neither readers nor updaters lock-couple on their way down to a leaf. We study three variations of the B-link algorithms: LY, LY-LC and LY-ABUF. <p> That is, the LY-LC algorithm differs from the LY algorithm in that updaters release their lock on a node that is half-split or half-merged only after getting an X lock on its current parent. In the B-link algorithm as it was first proposed in <ref> [Lehm81] </ref>, readers did not use locks at all. Instead, they relied on the atomic nature of disk I/Os and used their own consistent copies of pages.
Reference: [Livn90] <author> Livny, M., </author> <note> "DeNet User's Guide", version 1.5, </note> <year> 1990. </year>
Reference-contexts: The system on which tree transactions operate is modeled using the DeNet simulation language <ref> [Livn90] </ref>. The system can have one or more CPUs and disks and these are modeled using a module called the resource manager.
Reference: [Lome91] <author> Lomet, D. and Salzberg, B., </author> <title> "Concurrency and Recovery for Index Trees", </title> <type> Technical Report, No. CRL 91/8, </type> <institution> Cambridge Research Laboratory, Digital Equipment Corporation, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Before using Blink algorithms in real systems, however, recovery strategies have to be designed for them, and a way has to be found to handle variable length keys. Recovery strategies for B-link algorithms have been proposed recently <ref> [Lome91] </ref>. In this study we have considered only one aspect of concurrency control on B-tree indices, namely, transactions that perform single B-tree operations. When B-tree operations are part of larger transactions, there are several strategies available for holding long term locks for recovery purposes. <p> The relative performance of these alternative strategies is an open question. 2. The aforementioned lock holding strategies are closely linked to recovery strategies. Few comprehensive recovery strategies have been proposed for B-trees <ref> [Moha89, Lome91] </ref>, and the interaction of concurrency control and recovery in B-trees has not yet been satisfactorily studied. 3.
Reference: [Mill78] <author> Miller, R., and Snyder, L., </author> <title> "Multiple Access to B-trees", </title> <booktitle> Proceedings of the Conference on Information Science and Systems, </booktitle> <institution> Johns Hopkins University, Baltimore, MD, </institution> <month> March </month> <year> 1978. </year>
Reference: [Moha89] <author> Mohan, C. and Levine, F., "ARIES/IM: </author> <title> An Efficient and High Concur-rency Index Management Method Using Write-Ahead Logging", </title> <journal> IBM Research Report, </journal> <volume> RJ 6846, </volume> <year> 1989. </year>
Reference-contexts: Their lock compatibility relationships are given in Table 2.1. A naive B-tree concurrency control algorithm would treat the entire B-tree as a single data item and use locks (or latches 3 ) on just the root page to prevent conflicts. 3 Latches <ref> [Moha89] </ref> can be thought of as fast locks. <p> A restarted updater 4 repeatedly tries the protocol until it succeeds; starvation is avoided by assigning priorities to operations based on their first start time. Apart from the algorithms described above, several other B-tree concurrency control algorithms have been proposed as well <ref> [Kwon82, Bili87, Moha89] </ref>. <p> equal proportion of inserts and deletes, we can therefore expect this interference to cause a loss of throughput at sufficiently high MPLs due to a bottleneck forming at the root, much like in the TD-OPT and B-OPT algorithms. 2.5.3 ARIES/IM Algorithm An algorithm for high-concurrency index management was described in <ref> [Moha89] </ref>. We will not describe the details of this algorithm, except to state that it does not suffer from any of the performance drawbacks that are present in non-B-link algorithms and discussed at the beginning of this section. <p> The impact of waiting for the tree latch was much higher in the low fanout case due to an increased number of splits. A modification to the ARIES/IM algorithm to handle more than one page split at a time is suggested in <ref> [Moha89] </ref> and, if implemented, this should allow ARIES/IM 60 to perform comparably to the B-link algorithm. <p> The relative performance of these alternative strategies is an open question. 2. The aforementioned lock holding strategies are closely linked to recovery strategies. Few comprehensive recovery strategies have been proposed for B-trees <ref> [Moha89, Lome91] </ref>, and the interaction of concurrency control and recovery in B-trees has not yet been satisfactorily studied. 3.
Reference: [Moha90] <author> Mohan, C., "ARIES/KVL: </author> <title> A Key-Value Locking Method for Concur-rency Control of Multiaction Transactions Operating on B-tree Indexes", </title> <booktitle> Proceedings of the Sixteenth International Conference on Very Large Data Bases, </booktitle> <pages> 392-405, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Such selective locking of attributes may be possible, for example, in a system that uses key-value locking of the type described in <ref> [Moha90] </ref> if an index exists on the SALARY attribute.
Reference: [Moha91] <author> Mohan, C. and Narang, I., </author> <title> "Algorithms for Creating Indexes for Very Large Tables Without Quiescing Updates", </title> <journal> IBM Research Report, </journal> <volume> RJ 8016, </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: Multiple color bits per relation page would be needed to accommodate more than one 106 index construction process at a time. 3.8 Related Work In parallel with this work, two other on-line index construction algorithms have also been proposed by Mohan and Narang <ref> [Moha91] </ref>. Their first algorithm is index-based and allows updaters and the build process to share the same index throughout. In this algorithm, the build process first initializes a public index into which updaters concurrently insert their index updates. <p> Also, at the end of the index construction process, the new index may still contain superfluous pseudo-deleted entries. The second algorithm described in <ref> [Moha91] </ref> is list-based and does not have the above disadvantages. It uses an update-list, like the List-C-Basic strategy, but the index building process performs catch-up differently. <p> As we mentioned earlier, index construction for a terabyte relation may take days (due to the scan phase itself). This means that the index building process must be able to survive crashes and to complete without having to restart from scratch after every crash. Recovery strategies are presented in <ref> [Moha91] </ref> for their algorithms, and it should be straightforward to apply those recovery techniques to the algorithms described in this chapter. 3.9 Summary In this chapter, we have presented a range of solutions to the important problem of online index construction. <p> Finally, using the above results, we can now make informed projections about the performance of other on-line algorithms that have been proposed in the literature. Other Candidate Algorithms As we mentioned earlier in Section 3.8, Mohan and Narang have proposed two algorithms for on-line index construction <ref> [Moha91] </ref>. One of their algorithms is index-based 132 while the other is list-based. While we have not explicitly simulated the two algorithms from [Moha91] in our experiments, we believe that their performance can be inferred from that of the Index-C-Basic and List-C-Basic algorithms. <p> Other Candidate Algorithms As we mentioned earlier in Section 3.8, Mohan and Narang have proposed two algorithms for on-line index construction <ref> [Moha91] </ref>. One of their algorithms is index-based 132 while the other is list-based. While we have not explicitly simulated the two algorithms from [Moha91] in our experiments, we believe that their performance can be inferred from that of the Index-C-Basic and List-C-Basic algorithms. First, the performance of our Index-C-Basic algorithm should be comparable to (or better than) the performance of the index-based algorithm from [Moha91]. <p> we have not explicitly simulated the two algorithms from <ref> [Moha91] </ref> in our experiments, we believe that their performance can be inferred from that of the Index-C-Basic and List-C-Basic algorithms. First, the performance of our Index-C-Basic algorithm should be comparable to (or better than) the performance of the index-based algorithm from [Moha91]. This is because the set of concurrent updates is inserted into the index built with the scanned entries in the Index-C-Basic algorithm, while in their index-based algorithm the sorted scanned entries are inserted concurrently into an index built with concurrent updates. <p> In realistic situations, the list of concurrent updates is likely to be much smaller than the list of scanned entries, leading Index-C-Basic to perform better than their index-based algorithm. Turning to the list-based algorithm from <ref> [Moha91] </ref>, the performance of their list-based algorithm should be similar to that of our List-C-Basic algorithm. Their algorithm should perform better than List-C-Basic, in the best case having about half of the response time of List-C-Basic, since updaters selectively (rather than always) record updates to the update-list. <p> A similar optimization has been suggested for on-line index construction <ref> [Moha91] </ref> as well as for on-line checkpointing of databases [Pu85]. If updaters follow the approach just outlined, then the query process no longer has to store individual [SALARY, tuple-id] pairs; instead it can directly compute a count and a running average value in the scan phase itself. <p> query process can also perform some or all of any pre-processing that it needs to do on the scanned data. 172 5.8 Related Work The work that is most closely related to compensation-based query processing is the work on on-line index construction algorithms in Chapter 3 of this thesis and <ref> [Moha91] </ref>. In fact, it was our work on techniques for incrementally building an index that led us to discover the techniques described in this chapter. Compared to that work, the method described here is more general and handles arbitrarily complex queries.
Reference: [Mond85] <author> Mond, Y. and Raz, Y., </author> <title> "Concurrency Control in B + -trees Databases Using Preparatory Operations", </title> <booktitle> Proceedings of the Eleventh International Conference on Very Large Data Bases, </booktitle> <pages> 331-334, </pages> <year> 1985. </year>
Reference-contexts: Several alternative algorithms have been proposed that instead split the updating of the scope into several smaller, atomic operations. We consider two of these next, the top-down and B-link algorithms. Top-down Algorithms In top-down algorithms <ref> [Guib78, Care84b, Mond85, Lani86] </ref>, updaters perform what are known as preparatory splits and merges. If an inserter encounters a full node during its descent, it performs a preparatory page split and inserts an appropriate index entry in the parent of the newly split node.
Reference: [Omie89] <author> Omiecinski, E., </author> <title> "Concurrent File Conversion Between B+ Tree and Linear Hash Files", </title> <journal> Information Systems, </journal> <volume> 14(5), </volume> <year> 1989. </year> <month> 195 </month>
Reference: [Omie92] <author> Omiecinski, E., Lee, L. and Scheuermann, P., </author> <title> "Performance Analysis of a Concurrent File Reorganization Algorithm for Record Clustering", </title> <booktitle> Proceedings of the Eighth IEEE Conference on Data Engineering, </booktitle> <month> February </month> <year> 1992, </year> <note> to appear. </note>
Reference: [Pu85] <author> Pu, C., </author> <title> "On-the-Fly, Incremental, Consistent Reading of Entire Databases", </title> <booktitle> Proceedings of the Eleventh International Conference on Very Large Data Bases, </booktitle> <pages> 369-375, </pages> <year> 1985. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in <ref> [Rose78, Pu85, Pu88] </ref>, and concurrent database reorganization was addressed in [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88]. In this chapter, we address the open problem of on-line index construction. <p> It therefore appears that there is an even smaller chance of a concurrency problem arising here as compared to the list case. If the requirement of immediate index updates is considered undesirable, it can be relaxed by employing the page coloring technique of <ref> [Pu85] </ref>. In this strategy, all relation pages are colored "white" when the build process starts. <p> A similar optimization has been suggested for on-line index construction [Moha91] as well as for on-line checkpointing of databases <ref> [Pu85] </ref>. If updaters follow the approach just outlined, then the query process no longer has to store individual [SALARY, tuple-id] pairs; instead it can directly compute a count and a running average value in the scan phase itself.
Reference: [Pu88] <author> Pu, C., Hong, C. H. and Wha, J.M., </author> <title> "Performance Evaluation of Global Reading of Entire Databases", </title> <booktitle> Proceedings of the International Symposium on Databases in Parallel and Distributed Systems, </booktitle> <pages> 167-176, </pages> <year> 1988. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in <ref> [Rose78, Pu85, Pu88] </ref>, and concurrent database reorganization was addressed in [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88]. In this chapter, we address the open problem of on-line index construction.
Reference: [Rose78] <author> Rosenkrantz, D., </author> <title> "Dynamic Database Dumping", </title> <booktitle> Proceedings of the ACM SIGMOD Conference, </booktitle> <month> May </month> <year> 1978. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in <ref> [Rose78, Pu85, Pu88] </ref>, and concurrent database reorganization was addressed in [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88]. In this chapter, we address the open problem of on-line index construction.
Reference: [Sagi85] <author> Sagiv, Y., </author> <title> "Concurrent Operations on B fl -trees with Overtaking", </title> <booktitle> Proceedings of the Fourth ACM Symposium on Principles of Database Systems, </booktitle> <pages> 28-37, </pages> <year> 1985. </year>
Reference-contexts: The B-link algorithms go one step further and limit each sub-operation to nodes at a single tree level. They also differ from the top-down algorithms in that they do their updates in a bottom-up manner. B-link Tree Algorithms A B-link tree <ref> [Lehm81, Sagi85, Lani86] </ref> is a modification of the B-tree that uses links to chain all nodes at each level together. A page in a B-link tree contains a high key 19 (the highest key of the subtree rooted at this page) and a link to the right sibling. <p> Such a sideways traversal is termed a link-chase. Merges can also be done in two steps [Lani86], via a half-merge followed by an entry deletion at the next higher tree level. The B-link algorithms that have been proposed <ref> [Lehm81, Sagi85, Lani86] </ref> differ from the Bayer-Schkolnick and top-down algorithms in that neither readers nor updaters lock-couple on their way down to a leaf. We study three variations of the B-link algorithms: LY, LY-LC and LY-ABUF.
Reference: [Salz91] <author> Salzberg, B. and Dimock, A., </author> <title> "Record Level Concurrent Reorganization", </title> <type> Technical Report, </type> <institution> No. NU-CCS-91-6, College of Computer Science, Northeastern University, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in [Rose78, Pu85, Pu88], and concurrent database reorganization was addressed in <ref> [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88] </ref>. In this chapter, we address the open problem of on-line index construction.
Reference: [Sama76] <author> Samadi, B., </author> <title> "B-trees in a System With Multiple Users", </title> <journal> Information Processing Letters, </journal> <volume> 5(4), </volume> <year> 1976. </year>
Reference-contexts: An operation is said to lock-couple when it requests a lock on an index page while already holding a lock on the page's parent, releasing the parent lock only after the child lock is granted. In a simple algorithm proposed in <ref> [Sama76] </ref>, all operations get an X lock on the root and then lock-couple their way to the leaf using X locks, releasing locks at higher levels whenever a safe node is encountered. <p> This is a static analysis, so it does not provide insight into the dynamic performance of the various algorithms. Biliris [Bili85] described a simulation model for the evaluation of B-tree algorithms and presented a set of experiments comparing four algorithms that included the Samadi algorithm <ref> [Sama76] </ref>, the B-SIX algorithm, the side-branching algorithm [Kwon82], and the mU algorithm [Bili87]. This study found that the pessimistic algorithms bottleneck at the root and that the mU algorithm performed better in the situations considered. The side-branching technique was found not to give any improvement over B-SIX.
Reference: [Seli79] <author> Selinger, P., et al, </author> <title> "Access Path Selection in a Relational Database Management System", </title> <booktitle> Proceedings of the ACM SIGMOD Conference, </booktitle> <month> June </month> <year> 1979. </year>
Reference-contexts: For example, if a suitable index exists that matches a predicate in the query <ref> [Seli79] </ref>, an index scan can be used to efficiently retrieve only those tuples from the relation that actually satisfy the predicate. 143 Update Transaction . . . . . . Time Time Update-List . . . Scan Relation Merge Append SortSort . . . <p> This filter only lets through those tuples that satisfy the condition (s) specified in the WHERE-clause. Of course, further optimizations can be applied in the initial scan if an index that matches a predicate <ref> [Seli79] </ref> exists on an attribute. For example, an index on the SALARY attribute matches the predicate (SALARY &gt; 40,000), and in the presence of such a predicate in the WHERE-clause, an index on SALARY can be used to scan the data efficiently.
Reference: [Shap86] <author> Shapiro, L., </author> <title> "Join Processing in Database Systems with Large Main Memories", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(3), </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: The appropriate (key, rid) entries from a page are copied into a heap file which is the output of this function. Sort: This procedure sorts a heap file of (key, rid) entries into increasing key order using a method like the (two-phase) sort-merge algorithm described in <ref> [Shap86] </ref>. A heap file is first scanned, producing runs of size p N pages where N is the number of pages in the heap file. Next, these runs are concurrently merged. <p> Next, these runs are concurrently merged. This causes at most 4N I/Os (2N I/Os more than an in-memory sort), and it works as long as p pages of memory are available for use by the sort <ref> [Shap86] </ref>. If the file to be sorted is actually a sequence of updates of the form (key, rid, insert/delete) then only the last entry in the input determines the state of a particular (key, rid) pair and needs to be retained. <p> This ratio depends only on the size of an index entry relative to the size of a tuple (assuming there is enough memory for an efficient sort <ref> [Shap86] </ref>), and not on the absolute size of the relation itself. Finally, using the above results, we can now make informed projections about the performance of other on-line algorithms that have been proposed in the literature. <p> The merging logic ensures that if an entry for a particular 3 Typically, one can optimize this strategy by concurrently merging several runs in parallel instead of completely sorting down to two runs before merging <ref> [Shap86] </ref>. We assume that this optimization will be done in any implementation, but retain the simpler description in our discussion for clarity. <p> As we will see next, we can do even better in case of sort-merge and hash joins, where the cost for compensation-based execution more closely approaches that of conventional execution. 5.5.3 Sort-Merge Join In order to execute a sort-merge join, we extend the efficient strategy described in <ref> [Shap86] </ref>. The first step is to scan R and S, creating sorted runs of size 2 fi M where M is the size of memory in pages. <p> is almost as efficient as the basic strategy, as the main extra work required is the creation of sorted runs from the (presumably small) update-lists. 165 5.5.4 Hash Join There are three common types of hash join: the simple hash join, the GRACE hash join, and the hybrid hash join <ref> [Shap86] </ref>. Here we demonstrate how to adapt the GRACE hash join algorithm to the compensation-based model. The GRACE algorithm first scans R and partitions it into roughly equal subsets such that the hash table for each partition of R will fit in memory.
Reference: [Shas84] <author> Shasha, D., </author> <title> "Concurrent Algorithms for Search Structures", </title> <type> Ph.D. Thesis, </type> <institution> Aiken Computation Laboratory, Harvard University, </institution> <month> June </month> <year> 1984. </year>
Reference: [Shas85] <author> Shasha, D., </author> <title> "What Good are Concurrent Search Structure Algorithms for Databases Anyway?", </title> <journal> Database Engineering, </journal> <volume> 8(2), </volume> <month> June </month> <year> 1985. </year> <month> 196 </month>
Reference-contexts: A number of algorithms have been proposed for accessing indices concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but no performance analyses existed until recently that compare all of these algorithms. The earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management. As a result, the relative performance of these algorithms was still an open question when work began on this thesis 1 . <p> A number of algorithms have been proposed for accessing B-trees concurrently [Sama76, Baye77, Mill78, Lehm81, Kwon82, Shas84, Good85, Mond85, Sagi85, Shas85, Lani86, Bili87, Moha89, Weih90], but few performance analyses exist that compare these algorithms. Most earlier studies <ref> [Baye77, Bili85, Shas85, Lani86, John90a] </ref> each compare only a few algorithms and have been based on simplified assumptions about resource contention and buffer management.
Reference: [Silb90] <author> Silberschatz, A., Stonebraker, M. and Ullman, J. D., </author> <title> "Database Systems: Achievements and Opportunities", </title> <booktitle> SIGMOD Record, </booktitle> <month> 19(4) December </month> <year> 1990. </year>
Reference-contexts: Database sizes are growing rapidly, and future databases are expected to be several orders of magnitude larger than the largest databases in operation today. Databases on the order of terabytes (10 12 bytes) will soon be in active use <ref> [Silb90] </ref>. 3. Next generation DBMSs are expected to gravitate more and more towards what is referred to as 24 (hour) fi 7 (day) operation. There exist important DBMS applications that have no significant off-peak time, which is time when it becomes acceptable to take the data off-line for maintenance purposes. <p> Examples of such 1 2 24fi7 systems include database management for multinational companies with a global reach, hospital management systems, round-the-clock shopping services, etc. In order to service such applications, next generation databases will be required to keep their data on-line all of the time <ref> [Dewi90, Silb90] </ref>. The above trends affect important aspects of database design and implementation, as discussed below. Under very high transaction rates, contention in heavily used auxiliary data structures like indices can increase tremendously, necessitating the use of highly concurrent algorithms for managing these data structures. <p> It is almost sure to be unacceptable 65 66 to exclude updates for such an extended period of time. In fact, leading researchers have identified the problem of on-line index construction for very large databases as an important open research problem <ref> [Dewi90, Silb90] </ref>. In this chapter, we present several algorithms for on-line index construction.
Reference: [Sock78] <author> Sockut, G. H., </author> <title> "A Performance Model for Computer Data-Base Reorganization Performed Concurrently with Usage", </title> <journal> Operations Research, </journal> <month> September-October </month> <year> 1978. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in [Rose78, Pu85, Pu88], and concurrent database reorganization was addressed in <ref> [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88] </ref>. In this chapter, we address the open problem of on-line index construction.
Reference: [Sock79] <author> Sockut, G. and Goldberg, R., </author> <title> "Database Reorganization Principles and Practice", </title> <journal> ACM Computing Surveys, </journal> <volume> 11(4), </volume> <month> December </month> <year> 1979. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in [Rose78, Pu85, Pu88], and concurrent database reorganization was addressed in <ref> [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88] </ref>. In this chapter, we address the open problem of on-line index construction.
Reference: [Sode81a] <author> Soderlund, L., </author> <title> "Concurrent Database Reorganization Assessment of a Powerful Technique through Modeling", </title> <booktitle> Proceedings of the Seventh Conference on Very Large Data Bases, </booktitle> <month> September </month> <year> 1981. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in [Rose78, Pu85, Pu88], and concurrent database reorganization was addressed in <ref> [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88] </ref>. In this chapter, we address the open problem of on-line index construction.
Reference: [Sode81b] <author> Soderlund, L., </author> <title> "Evaluation of Concurrent Physical Database Reorganization through Simulation Modeling", </title> <booktitle> Proceedings of the ACM SIGMETRICS Conference, </booktitle> <month> Sept. </month> <year> 1981. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in [Rose78, Pu85, Pu88], and concurrent database reorganization was addressed in <ref> [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88] </ref>. In this chapter, we address the open problem of on-line index construction.
Reference: [Srin91] <author> Srinivasan, V. and Carey, M. J., </author> <title> "Performance of B-tree Concurrency Control Algorithms", </title> <type> Technical Report, TR 999, </type> <institution> Computer Sciences Department, University of Wisconsin, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: An extension of the work in [John90a] resulted in a more comprehensive study of B-tree concurrency control algorithms [John90b]. That work was done concurrently with our work, which first appeared as <ref> [Srin91] </ref>, and we will compare our performance results with those of [John90b] at the end of this chapter. In this chapter, we analyze the performance of various B-tree concurrency control algorithms using a simulation model of B-tree operations in a centralized DBMS.
Reference: [Ston88] <author> Stonebraker, M., Katz, R., Patterson, D. and Ousterhout, J., </author> <booktitle> "The Design of XPRS", Proceedings of the Fourteenth Conference on Very Large Data Bases, </booktitle> <address> Los Angeles, CA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: These utilities are typically used for index construction, database reorganization, and checkpointing. On-line checkpointing has been discussed in [Rose78, Pu85, Pu88], and concurrent database reorganization was addressed in <ref> [Salz91, Sock78, Sock79, Sode81a, Sode81b, Ston88] </ref>. In this chapter, we address the open problem of on-line index construction.
Reference: [Tay84] <author> Tay, Y., </author> <title> "A Mean Value Performance Model For Locking in Databases", </title> <type> Ph.D. Thesis, </type> <institution> Computer Science Department, Harvard University, </institution> <month> February </month> <year> 1984. </year>
Reference-contexts: In addition to concrete performance measures such as transaction throughput, it would be nice if the level of concurrency provided by the protocols could be somehow characterized. For this study, we have adopted the throughput of the protocols under infinite resources <ref> [Fran85, Tay84, Agra87] </ref> as a measure of the level of concurrency that they provide. The resource manager simulates such a condition by replacing the CPU and disk scheduling code with pure time delays.
Reference: [Verh78] <author> Verhofstad, J., </author> <title> "Recovery Techniques for Database Systems", </title> <journal> ACM Computing Surveys, </journal> <volume> 10(2), </volume> <month> June </month> <year> 1978. </year>
Reference: [Weih90] <author> Weihl, W. E., Wang, Paul., </author> <title> "Multi-Version Memory: Software Cache Management for Concurrent B-trees", </title> <institution> MIT Laboratory of Computer Science Manuscript, </institution> <year> (1990). </year>
Reference: [Yao78] <author> Yao, A. C., </author> " <title> On Random 2-3 Trees", </title> <journal> Acta Informatica, </journal> <volume> 9, </volume> <pages> 159-170, </pages> <year> 1978. </year>
Reference-contexts: We found no significant performance 8 A strategy that causes the appends to be inserted in the increasing order of key values will attain a leaf page occupancy of only 50% for new pages, while a randomization of the appends will cause the page occupancy to be around 69% <ref> [Yao78] </ref>. Thus, randomization leads to fewer splits. 53 differences between the LY and LY-LC algorithms in situations where the buffer pool size was 600 pages (much less than the B-tree size). Even in heavily disk bound cases, link-chases did not significantly affect the hit rates of the buffer pool. <p> 3 This strategy could be further optimized by grouping together all inserts from the sorted list that can be accommodated in a leaf page before making the next index traversal from the root page. 4 The expected leaf page occupancy of a B-tree built with random inserts is about 69% <ref> [Yao78] </ref>. 77 Name How Updates Are Applied? After Scan Phase List-X-Basic Sequentially apply from unsorted list exclude concurrent updaters List-X-Sort Sequentially apply from sorted list exclude concurrent updaters List-X-Merge Merge sorted list and scanned entries exclude concurrent updaters List-C-Basic Sequentially apply from unsorted list allow concurrent updaters List-C-Sort Sequentially apply from
References-found: 63

