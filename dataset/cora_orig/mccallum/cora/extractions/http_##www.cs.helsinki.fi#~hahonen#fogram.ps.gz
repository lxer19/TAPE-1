URL: http://www.cs.helsinki.fi/~hahonen/fogram.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~hahonen/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Abstract-found: 0
Intro-found: 1
Reference: [AFQ89a] <author> J. Andr, R. Furuta, and V. Quint. </author> <title> By way of an introduction. Structured documents: </title> <editor> What and why? In J. Andr, R. Furuta, and V. Quint, editors, </editor> <title> Structured Documents, </title> <booktitle> The Cambridge Series on Electronic Publishing, </booktitle> <pages> pages 16. </pages> <publisher> Cambridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: The text body consists of a list of sections, every section consists of subsections or paragraphs, and so on. Other typical examples of structured documents are dictionaries, encyclopedias, user manuals, and annual reports. Recent surveys of the research concerning structured documents are <ref> [AFQ89a, AFQ89b, Qui89] </ref>. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96].
Reference: [AFQ89b] <author> J. Andr, R. Furuta, and V. Quint, </author> <title> editors. Structured Documents. The Cambridge Series on Electronic Publishing. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: The text body consists of a list of sections, every section consists of subsections or paragraphs, and so on. Other typical examples of structured documents are dictionaries, encyclopedias, user manuals, and annual reports. Recent surveys of the research concerning structured documents are <ref> [AFQ89a, AFQ89b, Qui89] </ref>. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96].
Reference: [AHH + 96] <author> H. Ahonen, B. Heikkinen, O. Heinonen, J. Jaakkola, P. Kilpeli-nen, G. Lindn, and H. Mannila. </author> <title> Intelligent assembly of structured documents. </title> <type> Report C199640, </type> <institution> Department of Computer Science, University of Helsinki, </institution> <year> 1996. </year>
Reference-contexts: One example of this kind of DTD is an author DTD [MA96]: a DTD that is given to the people who create documents. For instance, in our research project <ref> [AHH + 96] </ref> we have used ISO 12083 standard DTD for books [ISO94] as a DTD for engineering text books. <p> We can utilize the already converted tagged textbooks to generate a DTD automatically, and check the result against the standard DTD to make the obvious generalizations, like allowing more than one author. Online DTDs We have studied in our research project <ref> [AHH + 96] </ref> intelligent assembly of documents, which means that the user can contgure new, individualized documents from a collection of documents and possibly also from external information sources.
Reference: [Ang82] <author> D. Angluin. </author> <title> Inference of reversible languages. </title> <journal> Journal of the ACM, </journal> <volume> 29(3):741765, </volume> <year> 1982. </year>
Reference-contexts: This property states roughly that in the structure of 3 the document what can follow a certain element is completely determined by the k preceding elements at the same level. Steps 1 and 2 are based on the synthesis of tnite automata presented in <ref> [Ang82, Mug90] </ref>, specitcally (k; h)-contextuality is a moditcation of k-reversibility [Ang82] and k-contextuality [Mug90]. 4. The automata are disambiguated until their language is unambigu ous [BKW94]. 5. The resulting automata are transformed to unambiguous regular expressions, which form the right-hand sides of the productions for the corresponding elements. <p> Steps 1 and 2 are based on the synthesis of tnite automata presented in [Ang82, Mug90], specitcally (k; h)-contextuality is a moditcation of k-reversibility <ref> [Ang82] </ref> and k-contextuality [Mug90]. 4. The automata are disambiguated until their language is unambigu ous [BKW94]. 5. The resulting automata are transformed to unambiguous regular expressions, which form the right-hand sides of the productions for the corresponding elements. The rest of this thesis is organized as follows. <p> Some results are presented and evaluated in Chapter 6. Finally, Chapter 7 contains some concluding remarks. 4 1 Introduction Chapter 2 Basic detnitions In this chapter we present the basic detnitions and notations used in this thesis. The detnitions are mostly based on <ref> [Sal69, HU79, Ang82, Woo87] </ref>. 2.1 Sets, strings and languages If S is any tnite set, jSj denotes the cardinality of S. An alphabet is a tnite nonempty set of symbols. A string over an alphabet consists of zero or more symbols of . <p> some rule in I 2. construct a tnite-state automaton that accepts the structures of e; 3. generalize the automaton by merging states; 4. disambiguate the automaton; 5. convert the automaton into a content model for e; 24 3 Generating grammars for structured documents Generalization of automata applies grammatical inference methods <ref> [Ang82, Mug90] </ref>. Some background and general solutions of grammatical inference are presented in the next chapter. The solutions used in the method are detailly described in Chapter 5. Algorithm 3.2 produces the trst candidate for the DTD. <p> Garcia and Vidal [GV90] present also their own algorithm for inferring k-testable languages. In Section 5.1 we present three subclasses of regular languages: k-reversible languages <ref> [Ang82] </ref>, k-contextual languages [Mug90] and our generalization of them, (k,h)-contextual languages. The corresponding algorithms use the general schema: a pretx-tree automaton is generalized by merging states until the automaton is k-reversible (k-contextual, (k; h)- contextual, respectively). Actually, the class of k-contextual languages is equivalent to the class of k-testable languages. <p> We can formalize the process of merging states by considering the par titions of the states of the pretx-tree automaton <ref> [Ang82] </ref>. 38 5 Generation of content models Detnition 5.2 A partition of a set S is a set of pairwise disjoint nonempty subsets of S such that the union of the subsets is S. <p> If a suciently long sequence of 5.1 Generalizing the right-hand sides of productions 39 elements occurs in two places in the examples, the elements that can follow this sequence are independent of the position of the sequence in the document structure. The classes of k-reversible languages <ref> [Ang82] </ref>, k-contextual languages [Mug90], and (k,h)-contextual languages satisfy this condition in varying degrees. As the work presented is considerably based on the work of Angluin, we detne trst the property of k-reversibility, although in our experiments it has not proved to be suitable for the inference of document structures. <p> As for k-contextual languages, we have to show that Algorithm 5.12 works correctly, i.e., that it constructs an automaton accepting the smallest (k; h)-contextual language containing the given set of strings. The proof follows the corresponding proofs in <ref> [Ang82, Mug90] </ref>. Before stating the actual theorem, we have to present the following lemmas. First we show that a subautomaton of a (k; h)-contextual automaton is also (k; h)-contextual. <p> Let be the partition L restricted to the set P r (S) of pretxes of elements of S. Then M 0 = is isomorphic to a subautomaton of the canonical automaton M (L). Thus, L (M 0 =) is contained in L. Proof Angluin <ref> [Ang82] </ref>. Now we are ready to show that Algorithm 5.12 works correctly. Theorem 5.17 Let S be a nonempty positive sample, k and h positive integers, and let M f be the automaton output by Algorithm 5.12 on input S, k, and h. <p> Generally, the set of k-grams also grows for a while but since the examples usually have common substrings the size gradually converges. 56 5 Generation of content models The respective results of Angluin and Muggleton are the following. According to Angluin <ref> [Ang82] </ref>, a k-reversible automaton can be constructed in time O (kn 3 ), where n is the sum of the lengths of the input strings. Muggleton [Mug90] presents a more ecient O (n 2 )algorithm for the same problem.
Reference: [Ang87] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. Information and Computation, </title> <address> 75(2):87106, </address> <year> 1987. </year>
Reference-contexts: The answer is either yes or no. If it is no, then the user has to provide a counterexample. The algorithm is a moditcation of Angluin's algorithm for regular languages <ref> [Ang87] </ref>, and it outputs a grammar structurally equivalent to the target grammar. Sakakibara [Sak92] describes another approach to the same problem.
Reference: [AS83] <author> D. Angluin and C. H. Smith. </author> <title> Inductive inference: Theory and methods. </title> <journal> Computing Surveys, </journal> <volume> 15(3):237269, </volume> <year> 1983. </year>
Reference-contexts: Thus, one should be able to generalize the productions in some meaningful way. For the generalization, we use techniques from machine learning [Mug90, Nat91] and formulate our problem as a grammatical inference problem <ref> [AS83] </ref>. The basic ideas of grammatical inference are presented in Chapter 4. The automatic generalization method we have developed proceeds as follows. 1. The document instances, e.g. tagged SGML documents, are parsed to form a set of simple productions. 2. <p> show how grammatical inference problems can be specited (Section 4.1) and present some approaches for inferencing context-free languages (Section 4.2) and regular languages (Section 4.3). 25 26 4 Grammatical inference problem 4.1 Specitcation of grammatical inference prob lem A grammatical inference problem can be specited by giving the following items <ref> [AS83] </ref>: 1. the class of languages, 2. the hypothesis space, i.e., a set of representations for the languages, 3. for each language, its set of positive and negative examples, and the admissible sequences of examples, 4. the class of inference methods, 5. the criteria for a successful inference. <p> A large amount of inference methods has been introduced in the literature. In the following we consider some of them. 4.2 Inference of context-free languages 27 4.2 Inference of context-free languages The trivial inference method is called identitcation by enumeration <ref> [AS83] </ref>. It systematically searches the hypothesis space to tnd a representation that is consistent with all the examples seen so far.
Reference: [Bar89] <author> D. Barron. </author> <title> Why use SGML? Electronic Publishing, </title> <address> 2(1):324, </address> <year> 1989. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar.
Reference: [BBKF96] <author> A. Brown, A. Brggemann-Klein, and A. Feng, </author> <title> editors. </title> <booktitle> Proceedings of the International Conference on Electronic Publishing, Document Manipulation & Typography, </booktitle> <address> Palo Alto, USA, September 2426. </address> <publisher> Wiley Publishers, </publisher> <year> 1996. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar.
Reference: [BF72] <author> A. W. Biermann and J. A. Feldman. </author> <title> On the synthesis of tnite-state machines from samples of their behavior. </title> <journal> IEEE Transactions on Computers, 21(6):592597, 1972. </journal> <volume> 103 104 References </volume>
Reference-contexts: Some methods, however, are characteristic: they guarantee that the result belongs to some specited subclass of regular languages. In the following we trst look at some heuristic inference methods and then present some subclasses of regular languages that can be used as target classes. Biermann and Feldman <ref> [BF72] </ref> present a heuristic that constructs trst a so-called pretx-tree automaton that accepts exactly the given examples. Then it merges states having identical k-tail sets, that is, states that have similar paths to accepting states with a look-ahead of k. <p> With this approach also the merging conditions of <ref> [BF72] </ref> and [RV84] can be described. Levine [Lev82] proposes a heuristic that locates dierent substructures that seem to occur at the same position in the examples and infers that these substructures could be interchangeable. Compared to the heuristic of Biermann and Feldman [BF72] Levine constructs tail sets that are equivalent to <p> With this approach also the merging conditions of <ref> [BF72] </ref> and [RV84] can be described. Levine [Lev82] proposes a heuristic that locates dierent substructures that seem to occur at the same position in the examples and infers that these substructures could be interchangeable. Compared to the heuristic of Biermann and Feldman [BF72] Levine constructs tail sets that are equivalent to k-tail sets with k set to intnity. Additionally, inference process 32 4 Grammatical inference problem has a parameter the value of which determines the level of similarity that is needed for merging two states.
Reference: [BKW92] <author> A. Brggemann-Klein and D. Wood. </author> <title> Deterministic regular languages. </title> <editor> In A. Finkel and M. Jantzen, editors, </editor> <booktitle> STACS '92, Proceedings of the 9th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science 577, </booktitle> <pages> pages 173184. </pages> <address> SpringerVerlag, </address> <year> 1992. </year>
Reference-contexts: A content model is ambiguous if an element appearing in the document instance can be matched with more than one occurrence of the corresponding element in the content model without look-ahead, i.e., without scanning the text ahead to decide which occurrence should be chosen. Brggemann-Klein and Wood <ref> [BKW92, BKW94] </ref> have presented an algorithm that can decide whether a content model is unambiguous. We have developed their ideas further and present a disambiguation algorithm that transforms an ambiguous content model into an unambiguous one. The resulting content model generalizes the original, i.e., accepts more element structures.
Reference: [BKW94] <author> A. Brggemann-Klein and D. Wood. </author> <title> One-unambiguous regular languages. </title> <type> Technical report, </type> <institution> Institut fr Informatik, Universitt Freiburg, </institution> <month> May </month> <year> 1994. </year> <note> Accessible at URL: http://www.informatik.uni-freiburg.de/Personalia/Brueggemann-Klein.html. </note>
Reference-contexts: Steps 1 and 2 are based on the synthesis of tnite automata presented in [Ang82, Mug90], specitcally (k; h)-contextuality is a moditcation of k-reversibility [Ang82] and k-contextuality [Mug90]. 4. The automata are disambiguated until their language is unambigu ous <ref> [BKW94] </ref>. 5. The resulting automata are transformed to unambiguous regular expressions, which form the right-hand sides of the productions for the corresponding elements. The rest of this thesis is organized as follows. First, in Chapter 2, we give the basic detnitions and notations used throughout. <p> A content model is ambiguous if an element appearing in the document instance can be matched with more than one occurrence of the corresponding element in the content model without look-ahead, i.e., without scanning the text ahead to decide which occurrence should be chosen. Brggemann-Klein and Wood <ref> [BKW92, BKW94] </ref> have presented an algorithm that can decide whether a content model is unambiguous. We have developed their ideas further and present a disambiguation algorithm that transforms an ambiguous content model into an unambiguous one. The resulting content model generalizes the original, i.e., accepts more element structures. <p> The next section outlines the decision algorithm of Brggemann-Klein and Wood and the basic concepts needed. In Section 5.2.2 we present our disambiguation algorithm for automata, and in Section 5.2.3 the conversion into an unambiguous content model, as presented by Brggemann-Klein and Wood. 5.2.1 1-unambiguity Brggemann-Klein and Wood <ref> [BKW94] </ref> call the unambiguity required in the SGML standard 1-unambiguity, and give a detnition for it in terms of the pairs of positions that follow each other in a word. First, they detne the following sets. 5.2 Disambiguation 57 Detnition 5.30 Let be a set of elements. <p> In the following, we consider trst the structural properties of 1-unambiguous automata, as presented in <ref> [BKW94] </ref>. Major causes of ambiguities are iterations, i.e., cycles in automata. Therefore, we have to consider the strongly connected components, so-called orbits, of an automaton. 58 5 Generation of content models Detnition 5.32 Let M = (Q; ; ffi; I; F ) be a tnite automaton. <p> In Figure 5.12 we can see the orbit automaton when the Sand T -transitions have been removed, i.e., the fT; Sg-cut. Now we have three trivial orbits, and hence, (M 3 ) fS;T g and the whole automaton are 1-unambiguous. 5.2 Disambiguation 61 Theorem 5.42 <ref> [BKW94] </ref> Algorithm 5.40 can be implemented to run in time O (e 2 ). 5.2.2 Disambiguation of automata If the language of a content model is not 1-unambiguous, we have to disambiguate the corresponding automaton. <p> Now we can construct the expression for the automaton M by constructing the expression for the reduced automaton. Brggemann-Klein and Wood <ref> [BKW94] </ref> give the following method. First we assume that the 1-unambiguous regular expressions for the orbits can be constructed. We assume that M has more than one orbit and consider the orbit O (q 0 ) of the initial state q 0 .
Reference: [BR84] <author> F. Bancilhon and P. Richard. </author> <title> Managing texts and facts in a mixed data base environment. </title> <editor> In G. Gardarin and E. Gelenbe, editors, </editor> <booktitle> New Applications of Data Bases, </booktitle> <pages> pages 87107. </pages> <publisher> Academic Press, </publisher> <year> 1984. </year>
Reference-contexts: The common way to describe the structure of a set of similar documents is to use context-free grammars <ref> [GT87, BR84, CIV86, FQA88, QV86] </ref>. It is typical to use regular expressions on the right-hand sides of the productions of the grammar. For example, the following might describe the simplited structure of a dictionary entry: Entry ! Headword Sense fl .
Reference: [Bro89] <author> H. Brown. </author> <title> Standards for structured documents. </title> <journal> The Computer Journal, </journal> <volume> 32(6):505514, </volume> <year> 1989. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar.
Reference: [Che91] <author> J. Chen. </author> <title> Grammar generation and query processing for text databases. Research proposal, </title> <institution> University of Waterloo, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Take all the structures of the instances to be the DTD. This solution is also called the de-facto grammar <ref> [Che91] </ref>. &lt;!ELEMENT Entry ((Headword, Inflection, Sense, Example_block, Sense_structure) | (Headword, Example_block) | (Headword, Inflection, Example_block)) &gt; &lt;!ELEMENT Sense_structure (Technical_field, Example_block)&gt; &lt;!ELEMENT Example_block ((Example, Example, Example) | (Example, Example) | Example)&gt; Solutions 1 and 2 are usually overgeneralizing, while solution 3 is too restrictive. <p> Hence, we are going to study how the source DTD and the transformations can be used to generalize the target DTD in a suitable way. 3.4 Related work There have been several attempts to generate grammars automatically, mostly in practical contexts <ref> [Che91, FX94, Sol94, Sha95] </ref>. Online Computer Library Center (OCLC) receives several tagged data sources for its reference databases. While this tagged text appears to be SGML, it does not always have a DTD. Despite this, OCLC must build data transformations, databases, and interfaces for this tagged text. <p> The main part of the generation is to tnd the similar parts and combine them. The degree of similarity in the approaches varies. The parts may be required to be identical, or there can be a detnition of similarity or subsuming relation. For instance, Chen <ref> [Che91] </ref> detnes a rule ab (op)c ab (op 0 )c ! ab (op 00 )c; where op and op 0 can be , ?, + , or fl .
Reference: [CIV86] <author> G. Coray, R. Ingold, and C. Vanoirbeek. </author> <title> Formatting structured documents: Batch versus interactive. </title> <editor> In J. C. van Vliet, editor, </editor> <booktitle> Text Processing and Document Manipulation, </booktitle> <pages> pages 154170. </pages> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: The common way to describe the structure of a set of similar documents is to use context-free grammars <ref> [GT87, BR84, CIV86, FQA88, QV86] </ref>. It is typical to use regular expressions on the right-hand sides of the productions of the grammar. For example, the following might describe the simplited structure of a dictionary entry: Entry ! Headword Sense fl .
Reference: [FGHR69] <author> J. A. Feldman, J. Gips, J. J. Horning, and S. Reder. </author> <title> Grammatical complexity and inference. </title> <type> Report TR CS 125/1969, </type> <institution> Stanford University, </institution> <year> 1969. </year>
Reference-contexts: The inference method of [Sak92] uses the equivalence of context-free grammars and tree automata. It constructs trst a simple tree automaton and merges states until the language that the automaton accepts is reversible. A number of inference methods, especially for regular languages, use this schema trst introduced in <ref> [FGHR69] </ref>: Construct trst a grammar that generates exactly the examples, and generalize the grammar by merging nonterminals. The same idea applied to automata merges states. The inference method of Knuutila [Knu93] restricts the form of context-free grammars by inferring so-called k-testable tree languages.
Reference: [FQA88] <author> R. Furuta, V. Quint, and J. Andr. </author> <title> Interactively editing structured documents. </title> <publisher> Electronic Publishing, </publisher> <address> 1(1):1944, </address> <year> 1988. </year>
Reference-contexts: The common way to describe the structure of a set of similar documents is to use context-free grammars <ref> [GT87, BR84, CIV86, FQA88, QV86] </ref>. It is typical to use regular expressions on the right-hand sides of the productions of the grammar. For example, the following might describe the simplited structure of a dictionary entry: Entry ! Headword Sense fl .
Reference: [FX94] <author> P. Fankhauser and Y. Xu. </author> <title> Markitup! An incremental approach to document structure recognition. Electronic Publishing Origination, Dissemination and Design, </title> <address> 6(4):447456, </address> <year> 1994. </year>
Reference-contexts: Hence, we are going to study how the source DTD and the transformations can be used to generalize the target DTD in a suitable way. 3.4 Related work There have been several attempts to generate grammars automatically, mostly in practical contexts <ref> [Che91, FX94, Sol94, Sha95] </ref>. Online Computer Library Center (OCLC) receives several tagged data sources for its reference databases. While this tagged text appears to be SGML, it does not always have a DTD. Despite this, OCLC must build data transformations, databases, and interfaces for this tagged text. <p> The generation is intended to be run mainly in a batch processing. OCLC has even oered a free online service for anyone who needs to tnd a DTD for some documents. The primary goal of Fankhauser and Xu <ref> [FX94] </ref> is to recognize the logical structure of untagged electronic documents in order to transform them into structured SGML. The documents are mainly intended to be publicly available electronic information sources, such as public databases, bulletin boards, and electronic mail. <p> Fankhauser and Xu <ref> [FX94] </ref> use the partial ordering on regular expressions and Solstrand [Sol94] gives a certain similarity detnition. Fred Grammar Builder [Sha95] contains the following heuristics: * Identical Bases: combines all subrules that have identical base ele ments.
Reference: [GH67] <author> S. Ginsburg and M. A. Harrison. </author> <title> Bracketed context-free languages. </title> <journal> Journal of Computer and System Sciences, </journal> <note> 1(1):123, 1967. References 105 </note>
Reference-contexts: Document types in SGML are detned by bracketed, extended context-free grammars <ref> [GH67] </ref>, while the content models are essentially regular expressions. 3.1.1 Document type detnition in SGML We concentrate here on the parts of a document type detnition that are crucial for our study, i.e., on the element declarations.
Reference: [Gol67] <author> E. M. Gold. </author> <title> Language identitcation in the limit. </title> <journal> Information and Control, </journal> <volume> 10(5):447474, </volume> <year> 1967. </year>
Reference-contexts: The most important criterion of success is identitcation in the limit, which is detned as follows <ref> [Gol67] </ref>: Detnition 4.1 Method M identites language L in the limit if, after a tnite number of examples, M makes a correct guess and does not alter its guess thereafter. <p> That is, the user gives no examples of illegal document structures. This is natural for the user, but it causes problems, not only for version space strategy, but also in general, since it can make the learning task undecidable: Theorem 4.5 (Gold <ref> [Gol67] </ref>) Any class of languages containing all the tnite languages and at least one intnite language cannot be identited in the limit from positive samples. Thus the class of context-free languages and even the class of regular languages cannot be learned from positive samples.
Reference: [Gol90a] <author> C. F. Goldfarb. </author> <title> The SGML Handbook. </title> <publisher> Oxford University Press, </publisher> <year> 1990. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar.
Reference: [Gol90b] <author> C. F. Goldfarb. </author> <title> The SGML Handbook. </title> <publisher> Oxford University Press, </publisher> <year> 1990. </year>
Reference-contexts: Then it is useful to group documents with similar properties and purposes into document classes and detne constraints that the markup of all the documents of the class should satisfy. That is, these constraints specify the markup language for the document class. ISO standard SGML (Standard Generalized Markup Language) <ref> [SGM86, Gol90b, vH94] </ref> is a metalanguage that is used to detne markup languages. SGML markup languages are descriptive: every part has a start tag and an end tag, and the name of the tag tries to describe the logical meaning of the part.
Reference: [GT87] <author> G. Gonnet and F. Tompa. </author> <title> Mind your grammar: A new approach to modelling text. </title> <editor> In P. Hammersley, editor, </editor> <booktitle> VLDB '87, Proceedings of the Conference on Very Large Data Bases, </booktitle> <pages> pages 339346. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1987. </year>
Reference-contexts: The common way to describe the structure of a set of similar documents is to use context-free grammars <ref> [GT87, BR84, CIV86, FQA88, QV86] </ref>. It is typical to use regular expressions on the right-hand sides of the productions of the grammar. For example, the following might describe the simplited structure of a dictionary entry: Entry ! Headword Sense fl .
Reference: [GV90] <author> P. Garcia and E. Vidal. </author> <title> Inference of k-testable languages in the strict sense and application to syntactic pattern recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(9):920925, </volume> <year> 1990. </year>
Reference-contexts: The inference is made by considering the patterns of the sample and constructing a tree automaton that accepts the smallest k-testable 4.3 Inference of regular languages 31 tree language detned by those patterns. This approach is a generalization of the method described in <ref> [GV90] </ref> for k-testable string languages. The methods of [Sak92, Knu93] are inappropriate for our applications. First, our examples contain labelled derivation trees, i.e., we have more background information. Additionally, we want to generate extended context-free grammars, that is, grammars in which the right-hand sides of productions are regular expressions. <p> Although the above approaches do not mention any language (sub)classes and are in that sense heuristic the successor method of [RV84] results in a language that is a so-called local language [MP71, GVC87], and the predecessor and successor method of [KS88] can result, for instance, in a k-testable language <ref> [GV90] </ref>. Actually, a local language is a k-testable language with k having a value 2. A k-testable language is detned by a tnite set of substrings of length k that are permitted to appear in the strings of the language. Garcia and Vidal [GV90] present also their own algorithm for inferring <p> result, for instance, in a k-testable language <ref> [GV90] </ref>. Actually, a local language is a k-testable language with k having a value 2. A k-testable language is detned by a tnite set of substrings of length k that are permitted to appear in the strings of the language. Garcia and Vidal [GV90] present also their own algorithm for inferring k-testable languages. In Section 5.1 we present three subclasses of regular languages: k-reversible languages [Ang82], k-contextual languages [Mug90] and our generalization of them, (k,h)-contextual languages. <p> We prove this shortly. As mentioned in Chapter 4, the family of k-contextual languages is also known as the family of k-testable languages. Garcia and Vidal <ref> [GV90] </ref> detne a k-testable language by a regular expression of the form L = (I fl " fl F ) n fl T fl ; where is the alphabet, and I [ k1 i=1 i and F [ k1 i=1 i are sets of initial and tnal substrings, respectively, while T
Reference: [GVC87] <author> P. Garcia, E. Vidal, and F. Casacuberta. </author> <title> Local languages, the successor method, and a step towards a general methodology for the inference of regular grammars. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(1):841845, </volume> <year> 1987. </year>
Reference-contexts: Although the above approaches do not mention any language (sub)classes and are in that sense heuristic the successor method of [RV84] results in a language that is a so-called local language <ref> [MP71, GVC87] </ref>, and the predecessor and successor method of [KS88] can result, for instance, in a k-testable language [GV90]. Actually, a local language is a k-testable language with k having a value 2.
Reference: [HU79] <author> J. E. Hopcroft and J. D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1979. </year>
Reference-contexts: Some results are presented and evaluated in Chapter 6. Finally, Chapter 7 contains some concluding remarks. 4 1 Introduction Chapter 2 Basic detnitions In this chapter we present the basic detnitions and notations used in this thesis. The detnitions are mostly based on <ref> [Sal69, HU79, Ang82, Woo87] </ref>. 2.1 Sets, strings and languages If S is any tnite set, jSj denotes the cardinality of S. An alphabet is a tnite nonempty set of symbols. A string over an alphabet consists of zero or more symbols of . <p> Second, checking whether some grammar G generalizes another grammar G 0 is equivalent to testing whether the language generated by G includes the language generated by G 0 . This problem is known to be undecidable for context-free grammars <ref> [HU79] </ref>. To reduce the complexity of the problem [VB87] detnes restrictions for context-free grammars. <p> If L is regular, the set of blocks B is tnite (Myhill-Nerode theorem <ref> [HU79] </ref>). Therefore we can detne the canonical automaton for L, the states of which are the blocks detned by L . <p> Assume, for instance, that L 1 = fabcd; ebcdg and L 2 = fabgg. Then L 1 [ L 2 is not (2; 1)-contextual while both the languages are (2; 1)- contextual. 2. L 1 " L 2 is regular because L 1 and L 2 are regular <ref> [HU79] </ref>.
Reference: [ISO94] <author> ISO. </author> <title> Information and documentation Electronic manuscript preparation and markup, </title> <type> ISO 12083, </type> <year> 1994. </year>
Reference-contexts: One example of this kind of DTD is an author DTD [MA96]: a DTD that is given to the people who create documents. For instance, in our research project [AHH + 96] we have used ISO 12083 standard DTD for books <ref> [ISO94] </ref> as a DTD for engineering text books. By now we have converted existing non-SGML books to this DTD, but since the conversion process is very tedious, the authors are recommended to use an SGML editor to create the new books. <p> presented. 6.1 Two applications In this section we present some experiments that illustrate how our method can be used to satisfy needs of varying applications. 6.1.1 Textbook As mentioned earlier, we have converted one textbook on control engineering into SGML and structured it according to our ISO 12083 -based DTD <ref> [ISO94] </ref>. As we need a simpler DTD for the authors of new books, we generated a DTD for the book we already have, and now we can use this DTD as a basis for the author DTD.
Reference: [Jol89] <author> V. Jolobo. </author> <title> Document representation: Concepts and standards. </title> <editor> In J. Andr, R. Furuta, and V. Quint, editors, </editor> <title> Structured Documents, </title> <booktitle> The Cambridge Series on Electronic Publishing, </booktitle> <pages> pages 75105. </pages> <publisher> Cambridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar.
Reference: [Knu93] <author> T. Knuutila. </author> <title> Inference of k-testable tree languages. </title> <editor> In H. Bunke, editor, </editor> <booktitle> Proceedings of the International Workshop on Structural and Syntactic Pattern Recognition, </booktitle> <pages> pages 109120, </pages> <year> 1993. </year>
Reference-contexts: A number of inference methods, especially for regular languages, use this schema trst introduced in [FGHR69]: Construct trst a grammar that generates exactly the examples, and generalize the grammar by merging nonterminals. The same idea applied to automata merges states. The inference method of Knuutila <ref> [Knu93] </ref> restricts the form of context-free grammars by inferring so-called k-testable tree languages. Any k-testable tree language can be detned by a tnite set of patterns that can appear in the trees of that language. The size of the patterns is bound by constant k. <p> This approach is a generalization of the method described in [GV90] for k-testable string languages. The methods of <ref> [Sak92, Knu93] </ref> are inappropriate for our applications. First, our examples contain labelled derivation trees, i.e., we have more background information. Additionally, we want to generate extended context-free grammars, that is, grammars in which the right-hand sides of productions are regular expressions.
Reference: [KS88] <author> M. Kudo and M. Shimbo. </author> <title> Ecient regular grammatical inference techniques by the use of partial similarities and their logical relationships. </title> <journal> Pattern Recognition, </journal> <note> 21(4):401409, 1988. 106 References </note>
Reference-contexts: The algorithm of Richetin and Vernadat [RV84] take into account one successor only: an input symbol a is b's successor if there is at least one example in which a occurs immediately after b. Kudo and Shimbo <ref> [KS88] </ref> generalize this idea further and let the user construct various merging conditions using both predecessors and successors. <p> Although the above approaches do not mention any language (sub)classes and are in that sense heuristic the successor method of [RV84] results in a language that is a so-called local language [MP71, GVC87], and the predecessor and successor method of <ref> [KS88] </ref> can result, for instance, in a k-testable language [GV90]. Actually, a local language is a k-testable language with k having a value 2. A k-testable language is detned by a tnite set of substrings of length k that are permitted to appear in the strings of the language.
Reference: [Lev82] <author> B. Levine. </author> <title> The use of tree derivatives and a sample support parameter for inferring tree systems. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 4(1):2534, </volume> <year> 1982. </year>
Reference-contexts: With this approach also the merging conditions of [BF72] and [RV84] can be described. Levine <ref> [Lev82] </ref> proposes a heuristic that locates dierent substructures that seem to occur at the same position in the examples and infers that these substructures could be interchangeable.
Reference: [MA96] <author> E. Maler and J. E. Andaloussi. </author> <title> Developing SGML DTDs from text to model to markup. </title> <publisher> Prentice Hall PTR, </publisher> <year> 1996. </year>
Reference-contexts: If we then need a simpler DTD for some task, or a DTD for some subdocument, we can use automatic generation to tnd a DTD that accepts the selected documents. One example of this kind of DTD is an author DTD <ref> [MA96] </ref>: a DTD that is given to the people who create documents. For instance, in our research project [AHH + 96] we have used ISO 12083 standard DTD for books [ISO94] as a DTD for engineering text books.
Reference: [Mit77] <author> T. M. Mitchell. </author> <title> Version spaces: a candidate elimination approach to rule learning. </title> <booktitle> In IJCAI '77, Proceedings of the Fifth International Conference on Artitcial Intelligence, </booktitle> <pages> pages 305 310, </pages> <year> 1977. </year>
Reference-contexts: One inference method that avoids exhaustive search and backtracking necessary in identitcation by enumeration is the version space strategy. Mitchell <ref> [Mit77] </ref> detnes the version space to be a set of all generalizations that are consistent with the sample. In case of grammars, and if there are positive examples only, the version space contains all the grammars that generate the sample strings.
Reference: [Moo56] <author> E. F. Moore. </author> <title> Gedanken-experiments on sequential machines. </title> <editor> In C. Shannon and J. McCarthy, editors, </editor> <booktitle> Automata Studies, number 34 in Annals of Mathematics Studies, </booktitle> <pages> pages 129153, </pages> <address> Princeton, NJ, 1956. </address> <publisher> Princeton University Press. </publisher>
Reference-contexts: (u) : u 2 P r (L)g; I = T L (*); if L 6= ;; otherwise I = ;; F = fT L (w) : w 2 Lg; The automaton M (L) accepts the language L and has the minimum possible number of states among all automata of L <ref> [Moo56] </ref>. Additionally, M (L) has useful states only. An automaton M is called canonical if and only if M is isomorphic to the canonical automaton for the language of M . Let M = (Q; ; ffi; I; F ) be any automaton.
Reference: [MP71] <author> R. McNaughton and S. Papert. </author> <title> Counter-Free Automata. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA and London, England, </address> <year> 1971. </year>
Reference-contexts: Although the above approaches do not mention any language (sub)classes and are in that sense heuristic the successor method of [RV84] results in a language that is a so-called local language <ref> [MP71, GVC87] </ref>, and the predecessor and successor method of [KS88] can result, for instance, in a k-testable language [GV90]. Actually, a local language is a k-testable language with k having a value 2.
Reference: [Mug90] <author> S. Muggleton. </author> <title> Inductive Acquisition of Expert Knowledge. </title> <publisher> Ad-dison Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference-contexts: Thus, one should be able to generalize the productions in some meaningful way. For the generalization, we use techniques from machine learning <ref> [Mug90, Nat91] </ref> and formulate our problem as a grammatical inference problem [AS83]. The basic ideas of grammatical inference are presented in Chapter 4. The automatic generalization method we have developed proceeds as follows. 1. <p> This property states roughly that in the structure of 3 the document what can follow a certain element is completely determined by the k preceding elements at the same level. Steps 1 and 2 are based on the synthesis of tnite automata presented in <ref> [Ang82, Mug90] </ref>, specitcally (k; h)-contextuality is a moditcation of k-reversibility [Ang82] and k-contextuality [Mug90]. 4. The automata are disambiguated until their language is unambigu ous [BKW94]. 5. The resulting automata are transformed to unambiguous regular expressions, which form the right-hand sides of the productions for the corresponding elements. <p> Steps 1 and 2 are based on the synthesis of tnite automata presented in [Ang82, Mug90], specitcally (k; h)-contextuality is a moditcation of k-reversibility [Ang82] and k-contextuality <ref> [Mug90] </ref>. 4. The automata are disambiguated until their language is unambigu ous [BKW94]. 5. The resulting automata are transformed to unambiguous regular expressions, which form the right-hand sides of the productions for the corresponding elements. The rest of this thesis is organized as follows. <p> some rule in I 2. construct a tnite-state automaton that accepts the structures of e; 3. generalize the automaton by merging states; 4. disambiguate the automaton; 5. convert the automaton into a content model for e; 24 3 Generating grammars for structured documents Generalization of automata applies grammatical inference methods <ref> [Ang82, Mug90] </ref>. Some background and general solutions of grammatical inference are presented in the next chapter. The solutions used in the method are detailly described in Chapter 5. Algorithm 3.2 produces the trst candidate for the DTD. <p> Garcia and Vidal [GV90] present also their own algorithm for inferring k-testable languages. In Section 5.1 we present three subclasses of regular languages: k-reversible languages [Ang82], k-contextual languages <ref> [Mug90] </ref> and our generalization of them, (k,h)-contextual languages. The corresponding algorithms use the general schema: a pretx-tree automaton is generalized by merging states until the automaton is k-reversible (k-contextual, (k; h)- contextual, respectively). Actually, the class of k-contextual languages is equivalent to the class of k-testable languages. <p> Actually, the class of k-contextual languages is equivalent to the class of k-testable languages. We use the name k-contextual since we utilize also the detnitions and algorithm of Muggle-ton <ref> [Mug90] </ref>. Now we can specify our grammatical inference problem, or actually the subproblem of generalizing the right-hand sides of productions. The class of languages is the class of (k; h)-contextual languages over some alphabet. The hypothesis space is the set of (k; h)-contextual automata. <p> If a suciently long sequence of 5.1 Generalizing the right-hand sides of productions 39 elements occurs in two places in the examples, the elements that can follow this sequence are independent of the position of the sequence in the document structure. The classes of k-reversible languages [Ang82], k-contextual languages <ref> [Mug90] </ref>, and (k,h)-contextual languages satisfy this condition in varying degrees. As the work presented is considerably based on the work of Angluin, we detne trst the property of k-reversibility, although in our experiments it has not proved to be suitable for the inference of document structures. <p> Proof Can be found in <ref> [Mug90] </ref>. The corresponding proof for (k; h)- contextuality (Theorem 5.17 below) follows the idea of the proof of Mug-gleton. (k; h)-contextual languages The intuition in using k-contextuality is that two occurrences of a sequence of length k imply that the subsequent elements are the same in both cases. <p> As for k-contextual languages, we have to show that Algorithm 5.12 works correctly, i.e., that it constructs an automaton accepting the smallest (k; h)-contextual language containing the given set of strings. The proof follows the corresponding proofs in <ref> [Ang82, Mug90] </ref>. Before stating the actual theorem, we have to present the following lemmas. First we show that a subautomaton of a (k; h)-contextual automaton is also (k; h)-contextual. <p> According to Angluin [Ang82], a k-reversible automaton can be constructed in time O (kn 3 ), where n is the sum of the lengths of the input strings. Muggleton <ref> [Mug90] </ref> presents a more ecient O (n 2 )algorithm for the same problem. His implementation of the inference of k-contextual languages needs linear time. 5.2 Disambiguation A context-free grammar G such that some word w in L (G) has two parse trees is said to be ambiguous.
Reference: [Nat91] <author> B. K. Natarajan. </author> <title> Machine Learning: A Theoretical Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Thus, one should be able to generalize the productions in some meaningful way. For the generalization, we use techniques from machine learning <ref> [Mug90, Nat91] </ref> and formulate our problem as a grammatical inference problem [AS83]. The basic ideas of grammatical inference are presented in Chapter 4. The automatic generalization method we have developed proceeds as follows. 1.
Reference: [ODA89] <institution> Information Processing Text and Oce Systems Oce Document Architecture (ODA) and Interchange Format. </institution> <type> Technical Report ISO/IEC 8613, </type> <institution> International Organization for Standardization ISO/IEC, </institution> <address> Geneva/New York, </address> <year> 1989. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar.
Reference: [PC78] <author> T.-W. Pao and J. W. Carr. </author> <title> A solution of the syntactical induction-inference problem for regular languages. </title> <booktitle> Computer languages, </booktitle> <address> 3(1):5364, </address> <year> 1978. </year>
Reference-contexts: Additionally, inference process 32 4 Grammatical inference problem has a parameter the value of which determines the level of similarity that is needed for merging two states. The method of Pao and Carr <ref> [PC78] </ref> constructs trst a pretx-tree automaton, considers all the partitions of the states, and then tries to infer which of these partitions is the right one. Inference process compares every pair of partitions to check if they correspond to automata that accept the same language.
Reference: [PR87] <author> L. Pitt and R. E. Reinke. </author> <title> Polynomial-time solvability of clustering and conceptual clustering problems: The agglomerative-hierarchical algorithm. </title> <type> Technical Report UIUCDCS-R-87-1371, </type> <institution> University of Illinois, Dept. of Computer Science, </institution> <year> 1987. </year>
Reference-contexts: In our method we apply the clustering schema of <ref> [PR87] </ref> to our application domain.
Reference: [Qui89] <author> V. Quint. </author> <title> Systems for the manipulation of structured documents. </title> <editor> In J. Andr, R. Furuta, and V. Quint, editors, </editor> <title> Structured Documents, </title> <booktitle> The Cambridge Series on Electronic Publishing, </booktitle> <pages> pages 3974. </pages> <publisher> Cambridge University Press, </publisher> <year> 1989. </year> <note> References 107 </note>
Reference-contexts: The text body consists of a list of sections, every section consists of subsections or paragraphs, and so on. Other typical examples of structured documents are dictionaries, encyclopedias, user manuals, and annual reports. Recent surveys of the research concerning structured documents are <ref> [AFQ89a, AFQ89b, Qui89] </ref>. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96].
Reference: [QV86] <author> V. Quint and I. Vatton. Grif: </author> <title> An interactive system for structured document manipulation. </title> <editor> In J. C. van Vliet, editor, </editor> <booktitle> Text Processing and Document Manipulation, pages 200213, Cam-bridge, 1986. </booktitle> <publisher> Cambridge University Press. </publisher>
Reference-contexts: The common way to describe the structure of a set of similar documents is to use context-free grammars <ref> [GT87, BR84, CIV86, FQA88, QV86] </ref>. It is typical to use regular expressions on the right-hand sides of the productions of the grammar. For example, the following might describe the simplited structure of a dictionary entry: Entry ! Headword Sense fl .
Reference: [RV84] <author> M. Richetin and F. Vernadat. </author> <title> Ecient regular grammatical inference for pattern recognition. </title> <journal> Pattern Recognition, </journal> <volume> 17(2):245 250, </volume> <year> 1984. </year>
Reference-contexts: Biermann and Feldman [BF72] present a heuristic that constructs trst a so-called pretx-tree automaton that accepts exactly the given examples. Then it merges states having identical k-tail sets, that is, states that have similar paths to accepting states with a look-ahead of k. The algorithm of Richetin and Vernadat <ref> [RV84] </ref> take into account one successor only: an input symbol a is b's successor if there is at least one example in which a occurs immediately after b. Kudo and Shimbo [KS88] generalize this idea further and let the user construct various merging conditions using both predecessors and successors. <p> With this approach also the merging conditions of [BF72] and <ref> [RV84] </ref> can be described. Levine [Lev82] proposes a heuristic that locates dierent substructures that seem to occur at the same position in the examples and infers that these substructures could be interchangeable. <p> If it belongs, one of the partitions can be removed since it corresponds to an automaton that does not accept that string. Although the above approaches do not mention any language (sub)classes and are in that sense heuristic the successor method of <ref> [RV84] </ref> results in a language that is a so-called local language [MP71, GVC87], and the predecessor and successor method of [KS88] can result, for instance, in a k-testable language [GV90]. Actually, a local language is a k-testable language with k having a value 2.
Reference: [Sak88] <author> Y. Sakakibara. </author> <title> Learning context-free grammars from structural data in polynomial time. </title> <editor> In D. Haussler and L. Pitt, editors, </editor> <booktitle> Proceedings of the 1988 Workshop on Computational Learning Theory, </booktitle> <pages> pages 330344. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1988. </year>
Reference-contexts: The user can give derivation trees for grammars, the maximum number of states for automata, or restrict the subclass of the target class. The algorithm can also ask queries. In the following we look at some methods that utilize background knowledge. 30 4 Grammatical inference problem Sakakibara <ref> [Sak88] </ref> presents a polynomial time algorithm that uses structural data and queries for learning context free grammars. The user gives structural descriptions of the sample in the form of derivation trees without labels. Additionally, the user has to answer structural membership queries and equivalence queries.
Reference: [Sak92] <author> Y. Sakakibara. </author> <title> Ecient learning of context-free grammars from positive structural examples. Information and Computation, </title> <address> 97(1):2360, </address> <year> 1992. </year>
Reference-contexts: The answer is either yes or no. If it is no, then the user has to provide a counterexample. The algorithm is a moditcation of Angluin's algorithm for regular languages [Ang87], and it outputs a grammar structurally equivalent to the target grammar. Sakakibara <ref> [Sak92] </ref> describes another approach to the same problem. <p> Reversibility is a normal form, i.e., any context-free language can be generated by some reversible context-free grammar. The inference method of <ref> [Sak92] </ref> uses the equivalence of context-free grammars and tree automata. It constructs trst a simple tree automaton and merges states until the language that the automaton accepts is reversible. <p> This approach is a generalization of the method described in [GV90] for k-testable string languages. The methods of <ref> [Sak92, Knu93] </ref> are inappropriate for our applications. First, our examples contain labelled derivation trees, i.e., we have more background information. Additionally, we want to generate extended context-free grammars, that is, grammars in which the right-hand sides of productions are regular expressions.
Reference: [Sal69] <author> A. Salomaa. </author> <title> Theory of Automata. </title> <publisher> Pergamon Press, </publisher> <year> 1969. </year>
Reference-contexts: Some results are presented and evaluated in Chapter 6. Finally, Chapter 7 contains some concluding remarks. 4 1 Introduction Chapter 2 Basic detnitions In this chapter we present the basic detnitions and notations used in this thesis. The detnitions are mostly based on <ref> [Sal69, HU79, Ang82, Woo87] </ref>. 2.1 Sets, strings and languages If S is any tnite set, jSj denotes the cardinality of S. An alphabet is a tnite nonempty set of symbols. A string over an alphabet consists of zero or more symbols of .
Reference: [SGM86] <institution> Information Processing Text and Oce Systems Standard Generalized Markup Language (SGML). </institution> <type> Technical Report ISO/IEC 8879, </type> <institution> International Organization for Standardization ISO/IEC, </institution> <address> Geneva/New York, </address> <year> 1986. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar. <p> Then it is useful to group documents with similar properties and purposes into document classes and detne constraints that the markup of all the documents of the class should satisfy. That is, these constraints specify the markup language for the document class. ISO standard SGML (Standard Generalized Markup Language) <ref> [SGM86, Gol90b, vH94] </ref> is a metalanguage that is used to detne markup languages. SGML markup languages are descriptive: every part has a start tag and an end tag, and the name of the tag tries to describe the logical meaning of the part.
Reference: [Sha95] <author> K. Shafer. </author> <title> Automatic DTD creation via the GB-Engine and Fred. </title> <type> Technical report, </type> <institution> OCLC Online Computer Library Center, Inc., </institution> <address> 6565 Frantz Road, Dublin, Ohio 43017-3395, </address> <year> 1995. </year> <note> Accessible at URL: http://www.oclc.org/fred/docs/papers/. </note>
Reference-contexts: Hence, we are going to study how the source DTD and the transformations can be used to generalize the target DTD in a suitable way. 3.4 Related work There have been several attempts to generate grammars automatically, mostly in practical contexts <ref> [Che91, FX94, Sol94, Sha95] </ref>. Online Computer Library Center (OCLC) receives several tagged data sources for its reference databases. While this tagged text appears to be SGML, it does not always have a DTD. Despite this, OCLC must build data transformations, databases, and interfaces for this tagged text. <p> While this tagged text appears to be SGML, it does not always have a DTD. Despite this, OCLC must build data transformations, databases, and interfaces for this tagged text. Therefore they have built FRED Grammar Builder <ref> [Sha95] </ref> to generate the necessary DTDs. The generation is intended to be run mainly in a batch processing. OCLC has even oered a free online service for anyone who needs to tnd a DTD for some documents. <p> Fankhauser and Xu [FX94] use the partial ordering on regular expressions and Solstrand [Sol94] gives a certain similarity detnition. Fred Grammar Builder <ref> [Sha95] </ref> contains the following heuristics: * Identical Bases: combines all subrules that have identical base ele ments. E.g. ((ab) fl (a?b?) ab) is transformed to ((a?b?) fl ). 3.5 Overview of the method 23 * O by One: tnds all subrules that dier by at most one place.
Reference: [Sol94] <author> S. M. K. Solstrand. Automatisk generering av DTD fra SGML-kodet materiale. M.Sc.thesis, Institutt for informasjonsviten-skap, Universitetet i Bergen, </author> <month> September </month> <year> 1994. </year>
Reference-contexts: Hence, we are going to study how the source DTD and the transformations can be used to generalize the target DTD in a suitable way. 3.4 Related work There have been several attempts to generate grammars automatically, mostly in practical contexts <ref> [Che91, FX94, Sol94, Sha95] </ref>. Online Computer Library Center (OCLC) receives several tagged data sources for its reference databases. While this tagged text appears to be SGML, it does not always have a DTD. Despite this, OCLC must build data transformations, databases, and interfaces for this tagged text. <p> Both parts contain a set of rules that are used for the unitcation and abstraction, respectively. The basic goal of Solstrand <ref> [Sol94] </ref> is to tnd DTDs for documents in the Wittgenstein archive in Bergen, Norway. The documents were originally marked up with particular coding, and also the methods to convert the codes into SGML markup were available. Only the DTDs were missing. <p> Fankhauser and Xu [FX94] use the partial ordering on regular expressions and Solstrand <ref> [Sol94] </ref> gives a certain similarity detnition. Fred Grammar Builder [Sha95] contains the following heuristics: * Identical Bases: combines all subrules that have identical base ele ments. <p> If we also would have a structure M N R S, the model group would be (M, N, (R S? | S)). If there are many such structures, the model groups tend to become complicated (See Section 6.2.3). The sample in Figure 6.3 <ref> [Sol94] </ref> is another example of a reasonably well-behaving input. The content model produced by our method is: &lt;!ELEMENT PERSON - ((STILLING)*, FNAVN, ENAVN, STATUS?, ((TLF | BYGN | ROMNR)*, (EMAIL | TREFFTID, EMAIL? | FAX | INTEROMR)? )? &gt; The content model produced by the method in [Sol94] does not dier <p> in Figure 6.3 <ref> [Sol94] </ref> is another example of a reasonably well-behaving input. The content model produced by our method is: &lt;!ELEMENT PERSON - ((STILLING)*, FNAVN, ENAVN, STATUS?, ((TLF | BYGN | ROMNR)*, (EMAIL | TREFFTID, EMAIL? | FAX | INTEROMR)? )? &gt; The content model produced by the method in [Sol94] does not dier much from this: &lt;!ELEMENT PERSON - (STILLING*, FNAVN, ENAVN, STATUS?, (TLF | BYGN | ROMNR)*, (INTEROMR | FAX | TREFFTID?)?, EMAIL?) &gt; 96 6 Experimental results PERSON -&gt; STILLING FNAVN ENAVN ROMNR TLF EMAIL PERSON -&gt; STILLING FNAVN ENAVN ROMNR TLF TREFFTID EMAIL PERSON -&gt; STILLING FNAVN <p> - (A, (B, C, D, E, F, G, H | C, E, (G | H) | D, G | E | F | G | H ) | C, E, ( G | H ) | D, H ) &gt; A real example of this feature can be found in <ref> [Sol94] </ref>: UNFELLES -&gt; AVSN UNFELLES -&gt; NAVN UNFELLES -&gt; NAVN NAVN START UNFELLES -&gt; NAVN VARIGHET UNFELLES -&gt; NAVN NAVN NAVN START VARIGHET UNFELLES -&gt; NAVN START UNFELLES -&gt; START UNFELLES -&gt; AVSN STED NAVN UNFELLES -&gt; AVSN NAVN UNFELLES -&gt; NAVN TID DAG STED VARIGHET AVSN UNFELLES -&gt; TID STED <p> -&gt; TID STED NAVN UNFELLES -&gt; STED NAVN The content model produced is: &lt;!ELEMENT UNFELLES - ( (AVSN, (STED?, NAVN)? | (NAVN)*, (START, VARIGHET? | VARIGHET | TID, DAG, STED, VARIGHET, AVSN)? | START | TID, STED, NAVN | STED, NAVN)? ) &gt; and, again, the corresponding content model of <ref> [Sol94] </ref> is: &lt;!ELEMENT UNFELLES - (AVSN?, TID?, STED?, NAVN*, (START? | TID?), DAG?, STED?, VARIGHET?, AVSN?) &gt; Chapter 7 Conclusion In this study we have presented a method for generating a context-free grammar for a set of documents from the examples of document structures.
Reference: [Suo90] <editor> Suomen kielen perussanakirja. Ensimminen osa (AK). Val-tion painatuskeskus, </editor> <address> Helsinki, </address> <year> 1990. </year>
Reference-contexts: (TBODY) &gt; &lt;!ELEMENT TBODY - (ROW)* &gt; &lt;!ELEMENT TITLE - ( #PCDATA | (SUBSCR)*) &gt; &lt;!ELEMENT TITLEGRP - (TITLE) &gt; &lt;!ELEMENT TSTUB - (P) &gt; 6.2 Evaluation of the method 93 6.1.2 Dictionary data Most challenging of our test cases has been the part A K of a Finnish dictionary <ref> [Suo90] </ref>. We converted the typographical tags of the dictionary, which consists of about 16000 entries, to structural tags, and obtained a set of 468 distinct structures. Every structure also received a frequency, i.e., the number of entries that the structure covers.
Reference: [VB87] <author> K. Vanlehn and W. Ball. </author> <title> A version space approach to learning context-free grammars. </title> <booktitle> Machine Learning, </booktitle> <address> 2(1):3974, </address> <year> 1987. </year>
Reference-contexts: If the sets of maximally general and maximally specitc versions become equal, no further examples can change the tnal solution. This success criterion is a great advantage of the strategy. The version space strategy cannot be applied to grammatical inference 28 4 Grammatical inference problem as such <ref> [VB87] </ref>. First, if the version space contains all the grammars that generate the sample strings, the version space is certainly intnite. An intnite version space would not be a problem for the version space strategy, if the boundaries, i.e., the sets of maximally general and maximally specitc versions, were tnite. <p> Second, checking whether some grammar G generalizes another grammar G 0 is equivalent to testing whether the language generated by G includes the language generated by G 0 . This problem is known to be undecidable for context-free grammars [HU79]. To reduce the complexity of the problem <ref> [VB87] </ref> detnes restrictions for context-free grammars. These restrictions, which state that the grammars have to be simple and reduced , are quite natural: they exclude grammars that also common-sense would exclude, for instance grammars that have nonterminals not used to derive any string. <p> Given a tnite sample, there are tnitely many reduced simple context-free grammars consistent with the sample. Hence, the reduced sets of maximally general and maximally specitc versions are also tnite. This solves the trst problem. However, partial ordering of grammars is still undecidable. To solve the second problem <ref> [VB87] </ref> detnes a concept of derivational version space that is a superset of the reduced version space and a subset of the version space. <p> Given a set of positive and negative strings, the derivational version space is the derivational version space for the positive strings minus those grammars that generate any of the negative strings. The derivational version space is tnite. Additionally, <ref> [VB87] </ref> detnes a predicate that implements the partial ordering in derivational version space. The inference method described constructs the set of unlabelled simple derivation trees for the sample. The method then considers all derivations and all labelings, and gives as a solution all grammars consistent with the sample. <p> In our setting only one solution is needed, since even a single solution can be very complicated. Besides, the number of solutions can be huge. The version space strategy of <ref> [VB87] </ref> behaves especially poor in practice if there are no negative examples. The example productions of our application, however, are all positive examples. That is, the user gives no examples of illegal document structures.
Reference: [vH94] <author> E. van Herwijnen. </author> <title> Practical SGML, 2. </title> <editor> ed. </editor> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Dordrect, London, </address> <year> 1994. </year>
Reference-contexts: Recent surveys of the research concerning structured documents are [AFQ89a, AFQ89b, Qui89]. The interest in the area has led to the creation of several document standards, of which the best known are Open Document Architecture (ODA) and Standard Generalized Markup Language (SGML) <ref> [ODA89, SGM86, Jol89, Bar89, Bro89, Gol90a, vH94, BBKF96] </ref>. The common way to describe the structure of a set of similar documents is to use context-free grammars [GT87, BR84, CIV86, FQA88, QV86]. It is typical to use regular expressions on the right-hand sides of the productions of the grammar. <p> Then it is useful to group documents with similar properties and purposes into document classes and detne constraints that the markup of all the documents of the class should satisfy. That is, these constraints specify the markup language for the document class. ISO standard SGML (Standard Generalized Markup Language) <ref> [SGM86, Gol90b, vH94] </ref> is a metalanguage that is used to detne markup languages. SGML markup languages are descriptive: every part has a start tag and an end tag, and the name of the tag tries to describe the logical meaning of the part.
Reference: [Woo87] <author> D. Wood. </author> <title> Theory of computation. </title> <publisher> Harper & Row Publishers, </publisher> <address> New York, </address> <year> 1987. </year> <title> ISSN 1238-8645 ISBN 951-45-7532-6 Helsinki 1996 Helsinki University Printing House Helena Ahonen: Generating Gramm ars for Structured Do cumen ts Using Gramm atical Inference Metho ds </title>
Reference-contexts: Some results are presented and evaluated in Chapter 6. Finally, Chapter 7 contains some concluding remarks. 4 1 Introduction Chapter 2 Basic detnitions In this chapter we present the basic detnitions and notations used in this thesis. The detnitions are mostly based on <ref> [Sal69, HU79, Ang82, Woo87] </ref>. 2.1 Sets, strings and languages If S is any tnite set, jSj denotes the cardinality of S. An alphabet is a tnite nonempty set of symbols. A string over an alphabet consists of zero or more symbols of . <p> We call these grammars extended context-free grammars. For each extended context-free grammar G there is a context-free grammar G 0 such that L (G) = L (G 0 ) <ref> [Woo87] </ref>. Chapter 3 Generating grammars for structured documents In this chapter we introduce some basic concepts of structured documents (Section 3.1). We also formulate the problem of automatic generation of document type detnitions and motivate the need for it (Section 3.2).
References-found: 53

