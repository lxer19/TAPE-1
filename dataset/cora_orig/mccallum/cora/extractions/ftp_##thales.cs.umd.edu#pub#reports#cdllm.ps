URL: ftp://thales.cs.umd.edu/pub/reports/cdllm.ps
Refering-URL: ftp://thales.cs.umd.edu/pub/reports/Contents.html
Root-URL: 
Title: Continuity in Degenerate Log-linear Models  
Author: G. W. Stewart 
Abstract: Degeneracy in a log-linear model occurs when a configuration of zero counts causes the likelihood function to fail to attain its supremum. This problem is sometimes treated computationally by replacing the offending zero counts with suitably small numbers. However, to justify this procedure it must be shown that the estimates of the nonzero cells are not greatly altered. In this paper we establish a such a continuity theorem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yvonne M. M. Bishop, Stephen E. Fienberg, and Paul W. Holland. </author> <title> Discrete Multivariate Analysis. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1975. </year>
Reference-contexts: The problem is to compute the maximum likelihood estimate ^m of m. The above model is called log-linear because the logarithms of the cell means are assumed to lie in a linear manifold. The model is most frequently encountered in the analysis of contingency tables (see, e.g., <ref> [1] </ref>); the general formulation given here is due to Haberman [3].
Reference: [2] <author> J. E. Dennis and R. B. Schnabel. </author> <title> Numerical Methods for Unconstrained Optimization and Nonlinear Equations. </title> <publisher> Prentice-Hall, </publisher> <address> Englewook Cliffs, New Jersey, </address> <year> 1983. </year>
Reference-contexts: When maximum likelihood estimates of u exist, they may be computed by any of a number of standard optimization methods; for example, by Newton's method [4], by quasi-Newton methods <ref> [2] </ref>, or in contingency tables by iterative proportional scaling, which is a variant of coordinate ascent [3, p.64]. However, it may happen that the likelihood function fails to attain its supremum. This phenomenon, which we will call degeneracy, is always associate with zero counts in some of the cells.
Reference: [3] <author> S. J. Haberman. </author> <title> The Analysis of Frequency Data. </title> <publisher> The University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1974. </year>
Reference-contexts: The above model is called log-linear because the logarithms of the cell means are assumed to lie in a linear manifold. The model is most frequently encountered in the analysis of contingency tables (see, e.g., [1]); the general formulation given here is due to Haberman <ref> [3] </ref>. When maximum likelihood estimates of u exist, they may be computed by any of a number of standard optimization methods; for example, by Newton's method [4], by quasi-Newton methods [2], or in contingency tables by iterative proportional scaling, which is a variant of coordinate ascent [3, p.64]. <p> When maximum likelihood estimates of u exist, they may be computed by any of a number of standard optimization methods; for example, by Newton's method [4], by quasi-Newton methods [2], or in contingency tables by iterative proportional scaling, which is a variant of coordinate ascent <ref> [3, p.64] </ref>. However, it may happen that the likelihood function fails to attain its supremum. This phenomenon, which we will call degeneracy, is always associate with zero counts in some of the cells. <p> Since this infimum is "attained" when u 2 = 1, so that m 2 = e u 2 = 0, we can say that the model yields an extended maximum likelihood estimate with ^m 2 = 0. This nomenclature is due to Haberman <ref> [3, pp. 402-404] </ref>. It is possible for a model to be partially degenerate in the sense that the nonzero vector s = U 22 r of (2.8) must have zero components.
Reference: [4] <author> J. M. Ortega and W. C. Rheinboldt. </author> <title> Iterative Solution of Nonlinear Equations in Several Variables. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year> <note> Draft 10 September 10, 1987 GWS Log-Linear Continuity </note>
Reference-contexts: When maximum likelihood estimates of u exist, they may be computed by any of a number of standard optimization methods; for example, by Newton's method <ref> [4] </ref>, by quasi-Newton methods [2], or in contingency tables by iterative proportional scaling, which is a variant of coordinate ascent [3, p.64]. However, it may happen that the likelihood function fails to attain its supremum. <p> Thus is a contraction in S ff , and it follows from the contractive mapping theorem <ref> [4] </ref> that if the iterates x k all remain in S ff then they converge to a unique fixed point ~x of ; i.e., a zero of f + g.
Reference: [5] <author> G. W. Stewart. </author> <title> Introductin to Matrix Computations. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: When f (x) = Ax b and g (x) = Ex e, so that the concern is with the perturbation of linear systems, this condition reduces to kA 1 Ek &lt; 1, which is a well known sufficient condition that A + E be nonsingular (see, for example, <ref> [5] </ref>). The condition (3.5) requires that g (^x) be sufficiently small. The analog for linear equations is that kA 1 ek be small, although this condition is not required for the linear theory.
Reference: [6] <author> G. W. Stewart. </author> <title> An Iterative Method for Solving Linear Inequalities. </title> <type> Technical Report TR-1833, </type> <institution> Computer Science Department, University of Maryland, </institution> <year> 1987. </year> <note> Draft 11 September 10, </note> <year> 1987 </year>
Reference-contexts: Then sup k (U T DU ) 1 U T Dk &lt; 1: A proof of this surprising result, which does not hold when D is replaced by a nondiagonal, positive definite matrix, may be found in <ref> [6] </ref>.
References-found: 6

