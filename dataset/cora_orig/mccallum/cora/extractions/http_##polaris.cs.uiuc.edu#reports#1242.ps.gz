URL: http://polaris.cs.uiuc.edu/reports/1242.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Iterative Method for Nonsymmetric Systems with Multiple Right-Hand Sides  
Author: V. Simoncini and E. Gallopoulos IMGA-CNR 
Address: 1308 West Main Street Urbana, Illinois 61801  
Affiliation: Modena, Italy Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Note: An  
Abstract: SIAM J. Sci. Comput., 16(4):917-933, July 1995 (Replaces CSRD Report 1242.) 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. T. Chronopoulos, </author> <title> On the squared unsymmetric Lanczos method, </title> <journal> J. Comput. Appl. Math, </journal> <volume> 54 (1994), </volume> <pages> pp. 65-78. </pages>
Reference-contexts: The right-hand sides were chosen as B 1 = [e 1 ; : : : ; e s ] and B 2 = rand (n; s), where function rand creates a random matrix of dimension n fi s with values uniformly distributed in <ref> [0; 1] </ref>. In all examples the starting guess X (0) was taken to be zero. The stopping test for iteration index i is kr (i) (0) j k 10 7 for j = 1; : : : ; s. <p> Block methods deserve further research: For example, a study of the influence of the block size on stability, the use of restarting to improve performance, and the building of solvers based on recent developments in transpose free, nonsymmetric Lanczos methods <ref> [1, 6] </ref>. Appendix. Block gmres. ([41]). U i (i = 1; : : : ; m + 1) is of dimension n fi s and denotes the i th block of the orthogonal basis of the block Krylov subspace K m (A; R).
Reference: [2] <author> I. S. Duff, R. G. Grimes, and J. G. Lewis, </author> <title> User's guide for the Harwell-Boeing sparse matrix collection (release I), </title> <type> Tech. Report TR/PA/92/86, </type> <institution> CERFACS, </institution> <address> Toulouse Cedex, France, </address> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: As fi grew larger than 10 6 , compared to other methods, mhgmres suffered a milder performance degradation, while bbicg failed to converge (compare with Table 6.) Experiments with matrices from the Harwell-Boeing collection <ref> [2] </ref>. We present results from experiments with matrices pde 9511, orsreg 1 and sherman4. It was observed in studies [16, 37] that for these matrices bicg had better overall performance than restarted gmres.
Reference: [3] <author> S. C. Eisenstat, H. C. Elman, and M. H. Schultz, </author> <title> Variational iterative methods for nonsymmetric systems of linear equations, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 20 (April </month> <year> 1983), </year> <pages> pp. 345-357. </pages>
Reference-contexts: If the polynomial constructed by the gmres (m) step is such that kp (A)k &lt; 1, the residuals k~r (i+1) j k obtained in Eq. (3) will decrease after the Richardson phase. This is guaranteed irrespective of the value of m when A has definite symmetric part <ref> [3] </ref>. Even then, however, kp (A)k might be very near 1 unless m is taken very large, thus making the method impractical. Then other methods might be preferable; see [12, 17, 27].
Reference: [4] <author> R. Fletcher, </author> <title> Conjugate gradient methods for indefinite linear systems, </title> <note> in Proc. Dundee Biennial Conf. Numer. Anal., </note> <editor> G. A. Watson, ed., </editor> <volume> vol. </volume> <booktitle> 506 of Lect. </booktitle> <publisher> Notes Math., Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1976, </year> <pages> pp. 73-89. </pages>
Reference-contexts: Block bicg. The bbicg algorithm, proposed and described in [19], is a block generalization of bicg <ref> [4] </ref>. In exact arithmetic, if bbicg does not terminate before k = dn=se steps, then the solution becomes available at step k [19, Th. 1]. <p> In our experiments these selections produced better results than ~ R = R; also compare with <ref> [4, 31] </ref>. We have also used orthogonalization of the search direction blocks but no restarting. Experiments with a partial differential operator.
Reference: [5] <author> R. Freund, G. Golub, and N. Nachtigal, </author> <title> Iterative solution of linear systems, </title> <journal> Acta Numer-ica, </journal> <volume> 1 (1992), </volume> <pages> pp. </pages> <month> 57-100. </month> <title> [6] , Recent advances in Lanczos-based iterative methods for nonsymmetric linear systems, in Algorithmic Trends in Computational Fluid Dynamics, </title> <editor> M. Hussaini, A. Kumar, and M. Salas, eds., </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993, </year> <pages> pp. 137-162. </pages>
Reference-contexts: These are erratic convergence behavior, possible division by zero, and sensitivity to the choice of the auxiliary starting vector. An organizational drawback is the use of the transpose of A. Recent research has been attempting to design methods which overcome some of these drawbacks <ref> [5, 10] </ref>. One problem due to the block nature of bbicg is the possible rank deficiency or near rank deficiency of the search direction blocks. One suggested remedy is to restart bbicg with deflated right-hand sides.
Reference: [7] <author> R. W. Freund, </author> <title> Quasi-kernel polynomials and their use in non-Hermitian matrix iterations, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 43 (1992), </volume> <pages> pp. 135-158. </pages>
Reference-contexts: ] = richardson (A; b j ; x j ; ) j = 1; : : : ; s 13. [; r ] = seed (R) 14. fi = kr k choice of this approach for computing the roots is motivated by its good stability properties; see the discussion in <ref> [7] </ref>. Note that the procedure can be simplified by using the QR decomposition of H, which is already available.
Reference: [8] <author> D. Y. Hu and L. Reichel, </author> <title> Krylov subspace methods for the Sylvester equation, </title> <journal> Lin. Alg. Appl., </journal> <volume> 172 (1992), </volume> <pages> pp. 283-313. </pages>
Reference-contexts: There are, however, practical disadvantages such as high memory requirements; see [30] for comments on memory difficulties with block methods. It is also worth noting that similar memory difficulties arise in gmres-like methods for the Sylvester equation <ref> [8] </ref> 1 . The memory problem is handled by applying restarts. We denote by gmres (m) and bgmres (m; s) the restarted standard and block gmres algorithms. Restarting entails, however, loss of the properties of finite termination and minimization over the entire Krylov subspace [27]. <p> Overall, good seed selection merits further research, especially when application-dependent information is available. A similar problem, in connection with the Sylvester equation, was discussed in <ref> [8, Section 5] </ref>. We also note that a new seed system is selected whenever the current seed does not contain enough information to make the remaining systems converge.
Reference: [9] <author> P. Joly, </author> <title> Resolution de systemes lineaires avec plusieurs seconds membres par la methode du gradient conjugue, </title> <type> Tech. Report R-91012, </type> <institution> Publications du Laboratoire d'Analyse Numerique, Universite Pierre et Marie Curie, Paris, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Smith [34] used a single seed system to solve multiple systems in electromagnetic scattering. Smith, Peterson, and Mittra also considered these methods [35] and Joly <ref> [9] </ref> extended the discussion. The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) [9, 34], and a preconditioned generalized conjugate residual method [9]. If A is such that normal equations or bicg approaches are successful, then the methods of [9, 35] can be effective. <p> Smith [34] used a single seed system to solve multiple systems in electromagnetic scattering. Smith, Peterson, and Mittra also considered these methods [35] and Joly [9] extended the discussion. The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) <ref> [9, 34] </ref>, and a preconditioned generalized conjugate residual method [9]. If A is such that normal equations or bicg approaches are successful, then the methods of [9, 35] can be effective. We present one such method in Section 2.3. <p> Smith, Peterson, and Mittra also considered these methods [35] and Joly <ref> [9] </ref> extended the discussion. The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) [9, 34], and a preconditioned generalized conjugate residual method [9]. If A is such that normal equations or bicg approaches are successful, then the methods of [9, 35] can be effective. We present one such method in Section 2.3. <p> The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) [9, 34], and a preconditioned generalized conjugate residual method [9]. If A is such that normal equations or bicg approaches are successful, then the methods of <ref> [9, 35] </ref> can be effective. We present one such method in Section 2.3. In this paper we propose an alternative scheme for the solution of Eq. (1) and compare its performance with existing schemes. <p> Other methods. The electromagnetics literature describes alternatives to the block approach that share common features with our method <ref> [9, 35] </ref>. The success of these methods is usually measured by their effectiveness for complex symmetric matrices encountered in scattering. The method we describe is based on bicg and was recently proposed by Joly [9]. We refer to the method as mj3 2 . <p> The success of these methods is usually measured by their effectiveness for complex symmetric matrices encountered in scattering. The method we describe is based on bicg and was recently proposed by Joly <ref> [9] </ref>. We refer to the method as mj3 2 . The full algorithm is presented in the Appendix. <p> The seed system is solved completely, while the remaining systems are suitably updated. Once converged, a new seed is chosen, namely the system with the maximum residual norm. Joly <ref> [9] </ref> shows that after starting with a new seed system, several orthogonality properties between old and new direction vectors are maintained, which permits information obtained during the solution of one system to be used for the next one; in exact arithmetic, this leads to finite termination in n steps, irrespective of <p> Unfortunately, except for special cases, there is no guarantee a priori for the quality of the approximation. Thus we consider additional methods 2 Postfix 3 acknowledges that this is the third of the algorithms proposed in <ref> [9] </ref>. ITERATIVE METHOD FOR SYSTEM WITH SEVERAL RIGHT-HAND SIDES 5 to accomplish sharing of information among the systems. <p> In all examples the starting guess X (0) was taken to be zero. The stopping test for iteration index i is kr (i) (0) j k 10 7 for j = 1; : : : ; s. Matrix R in mj3 was chosen as suggested in <ref> [9] </ref>, namely R = R, where R is the initial residual matrix. A maximum number of 500 and 5000 iterations was allowed for bbicg and mj3, respectively. A dash signifies that the maximum allowed number of iterations was reached before convergence. <p> We thank Miloud Sadkane for providing us with the bgm-res programs, Jacques Laminie for drawing our attention to <ref> [9] </ref>, Dianne O'Leary for her explanations on [19], Randall Bramley for his criticism and suggestions, and Merle Levy for her editorial comments. We thank Gene Golub, Youcef Saad, Paul Saylor, and David Schneider for several discussions, Raj Mittra for readily providing us [34] and Qasim Seikh for [13].
Reference: [10] <author> W. D. Joubert, </author> <title> Lanczos methods for the solution of nonsymmetric systems of linear equations, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 (1992), </volume> <pages> pp. </pages> <month> 926-943. </month> <title> [11] , A robust GMRES-based adaptive polynomial preconditioning alorithm for nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 15 (1994), </volume> <pages> pp. </pages> <month> 427-439. </month> <title> [12] , On the convergence behavior of the restarted GMRES algorithm for solving nonsymmetric linear systems, </title> <journal> J. Numer. Linear Algebra with Appl., </journal> <volume> 1 (1994), </volume> <pages> pp. 427-448. </pages>
Reference-contexts: In exact arithmetic, if bbicg does not terminate before k = dn=se steps, then the solution becomes available at step k [19, Th. 1]. Even though the underlying bicg method can be effective in several cases <ref> [10, 16, 17, 37] </ref>, there are some drawbacks that seem to be inherited by the block version. These are erratic convergence behavior, possible division by zero, and sensitivity to the choice of the auxiliary starting vector. An organizational drawback is the use of the transpose of A. <p> These are erratic convergence behavior, possible division by zero, and sensitivity to the choice of the auxiliary starting vector. An organizational drawback is the use of the transpose of A. Recent research has been attempting to design methods which overcome some of these drawbacks <ref> [5, 10] </ref>. One problem due to the block nature of bbicg is the possible rank deficiency or near rank deficiency of the search direction blocks. One suggested remedy is to restart bbicg with deflated right-hand sides. <p> It is worth observing that orsreg 1 and sherman4 have indefinite symmetric parts. In general, for such matrices, convergence of restarted gmres for fixed m cannot be guaranteed a priori (cf. comments following Corollary 3.3). Thus bicg and other Lanczos type methods might be more suitable (see experiments in <ref> [10, 17] </ref>). It would also be worth exploring adaptive versions of mhgmres as suggested at the end of Section 3.1. As it stands, the indefinite problem merits further investigation. 6. Conclusions. mhgmres seems to be an attractive method for solving nonsymmetric systems with multiple right-hand sides.
Reference: [13] <author> S. Kharchenko, P. Kolesnikov, A. Nikishin, A. Yeremin, M. Heroux, and Q. Seikh, </author> <title> Iterative solution methods on the Cray YMP/C90. Part II: Dense linear systems. </title> <booktitle> Presented at 1993 Simulation Conference: High Performance Computing Symposium, </booktitle> <address> Washington D.C. </address>
Reference-contexts: We also note the recent communication by Kharchenko et al. on the use of restarted bgmres for dense complex systems <ref> [13] </ref>. An alternative idea to block methods, suggested in the context of radar scattering applications and applied mostly to complex symmetric matrices, is to use a single "seed" system and some cg-type method as a generator of approximations for several right-hand sides. <p> We thank Gene Golub, Youcef Saad, Paul Saylor, and David Schneider for several discussions, Raj Mittra for readily providing us [34] and Qasim Seikh for <ref> [13] </ref>. We also thank the referees and Howard Elman for criticism that helped us improve the paper.
Reference: [14] <author> C. </author> <title> Lanczos, Solution of systems of linear equations by minimized iterations, </title> <institution> J. Res. Natl. Bur. Stand., </institution> <month> 49 </month> <year> (1952), </year> <pages> pp. 33-53. </pages>
Reference-contexts: We would also like these methods to be applicable when all the right-hand sides b j are not available simultaneously. It is worth noting that Lanczos in <ref> [14, Sections 4 and 8] </ref> devoted several paragraphs to (1), commenting on the merits of reusing basis vectors obtained from the iterative solution for one right-hand side in order to solve for the remaining ones, and comparing with the direct computation of the inverse as well as to repeated application of
Reference: [15] <author> T. A. Manteuffel, </author> <title> Adaptive procedure for estimating parameters for the nonsymmetric Tchebychev iteration, </title> <journal> Numer. Math., </journal> <volume> 31 (1978), </volume> <pages> pp. 183-208. </pages>
Reference-contexts: The discretization was performed using a grid size of h = 1=51, yielding a matrix of size n = 2500. The matrices were scaled by multiplication with h 2 . Such matrices were used in <ref> [15] </ref>. They are unsymmetric and have positive definite symmetric part. The Krylov subspace for gmres-based methods was of maximum dimension m = 20. Tables 6 and 7 show the number of iterations to convergence for each method for fi = 1 and 100 respectively.
Reference: [16] <author> U. Meier-Yang, </author> <title> Preconditioned Conjugate Gradient-Like Methods for Nonsymmetric Linear Systems, </title> <type> Tech. Report 1210, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: In exact arithmetic, if bbicg does not terminate before k = dn=se steps, then the solution becomes available at step k [19, Th. 1]. Even though the underlying bicg method can be effective in several cases <ref> [10, 16, 17, 37] </ref>, there are some drawbacks that seem to be inherited by the block version. These are erratic convergence behavior, possible division by zero, and sensitivity to the choice of the auxiliary starting vector. An organizational drawback is the use of the transpose of A. <p> We present results from experiments with matrices pde 9511, orsreg 1 and sherman4. It was observed in studies <ref> [16, 37] </ref> that for these matrices bicg had better overall performance than restarted gmres.
Reference: [17] <author> N. M. Nachtigal, S. C. Reddy, and L. N. Trefethen, </author> <title> How fast are nonsymmetric matrix iterations?, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <month> 13 (July </month> <year> 1992), </year> <pages> pp. 778-795. </pages>
Reference-contexts: In exact arithmetic, if bbicg does not terminate before k = dn=se steps, then the solution becomes available at step k [19, Th. 1]. Even though the underlying bicg method can be effective in several cases <ref> [10, 16, 17, 37] </ref>, there are some drawbacks that seem to be inherited by the block version. These are erratic convergence behavior, possible division by zero, and sensitivity to the choice of the auxiliary starting vector. An organizational drawback is the use of the transpose of A. <p> Error estimates for mhgmres. We seek bounds for the residual norms at each iteration of the method to restart, both before and after the application of the Richardson phase. During every iteration, the seed system is approximated essentially by gmres, for which error bounds are known <ref> [17] </ref>. We first bound the residual norms, in terms of information we have from the seed. Let m be the space of polynomials of degree less or equal to m. For a set S, and polynomial p on S, we define kpk S as sup z2S jp (z)j. <p> This is guaranteed irrespective of the value of m when A has definite symmetric part [3]. Even then, however, kp (A)k might be very near 1 unless m is taken very large, thus making the method impractical. Then other methods might be preferable; see <ref> [12, 17, 27] </ref>. Theorem 3.2 and its corollary show how the approximation is governed by the effectiveness of the projections and the underlying gmres procedure, compounded by the application of the gmres polynomial. We also note that solving (2) for ~z j 's is straighforward. <p> It is worth observing that orsreg 1 and sherman4 have indefinite symmetric parts. In general, for such matrices, convergence of restarted gmres for fixed m cannot be guaranteed a priori (cf. comments following Corollary 3.3). Thus bicg and other Lanczos type methods might be more suitable (see experiments in <ref> [10, 17] </ref>). It would also be worth exploring adaptive versions of mhgmres as suggested at the end of Section 3.1. As it stands, the indefinite problem merits further investigation. 6. Conclusions. mhgmres seems to be an attractive method for solving nonsymmetric systems with multiple right-hand sides.
Reference: [18] <author> N. M. Nachtigal, L. Reichel, and L. N. Trefethen, </author> <title> A hybrid GMRES algorithm for nonsymmetric matrix iterations, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <month> 13 (July </month> <year> 1992), </year> <pages> pp. 796-825. </pages>
Reference-contexts: The method uses one subspace as a generator of approximations and accomplishes information sharing by means of a projection process and Richardson acceleration, thus utilizing some advantages of the hybrid method of Nachtigal, Reichel, and Trefethen <ref> [18] </ref>. Compared to bbicg this method is transpose-free while compared to bgmres, the method needs substantially less memory and gives better overall performance. Furthermore, it does not exhibit the problems encountered when normal equations are used. <p> Furthermore, the disadvantages of bicg (use of the transpose and erratic behavior) are still present. 3. mhgmres: A hybrid algorithm for multiple right-hand sides. The aforementioned considerations together with recent advances in hybrid methods <ref> [18, 29, 36] </ref> led us to investigate alternatives for economical information sharing to solve Eq. (1). <p> ITERATIVE METHOD FOR SYSTEM WITH SEVERAL RIGHT-HAND SIDES 5 to accomplish sharing of information among the systems. In particular we use a hybrid scheme based on the method of Nachtigal, Reichel, and Trefethen <ref> [18] </ref>, which allows us to exploit the generated gmres residual polynomial in order to improve the approximation of all the systems. The method described in [18] starts with an initial guess, runs gmres until the residual has become small enough, constructs the gmres residual polynomial, and applies it on the residual <p> In particular we use a hybrid scheme based on the method of Nachtigal, Reichel, and Trefethen <ref> [18] </ref>, which allows us to exploit the generated gmres residual polynomial in order to improve the approximation of all the systems. The method described in [18] starts with an initial guess, runs gmres until the residual has become small enough, constructs the gmres residual polynomial, and applies it on the residual cyclically until convergence. As shown in [18], using the gmres residual polynomial for the Richardson step for non-normal matrices is more effective than using a <p> The method described in <ref> [18] </ref> starts with an initial guess, runs gmres until the residual has become small enough, constructs the gmres residual polynomial, and applies it on the residual cyclically until convergence. As shown in [18], using the gmres residual polynomial for the Richardson step for non-normal matrices is more effective than using a polynomial built to be small in a domain determined by eigenvalue estimates. The desire to have an effective method for multiple right-hand sides led us to modify the method of [18] to <p> in <ref> [18] </ref>, using the gmres residual polynomial for the Richardson step for non-normal matrices is more effective than using a polynomial built to be small in a domain determined by eigenvalue estimates. The desire to have an effective method for multiple right-hand sides led us to modify the method of [18] to use restarting instead of either repeatedly applying the Richardson steps or continuing the gmres process where it left off. As we make clear in the next section, by restarting, the method builds the solutions by appropriately using any information that can be shared between the right-hand sides. <p> is to generate a triangular matrix C m such that V m = [v 1 ; Av 1 ; A 2 v 1 ; : : : ; A m1 v 1 ]C m , compute the coefficients C m y of the residual polynomial, and then use a rootfinder <ref> [18] </ref>. This approach suffers from the potential ill-conditioning of C m , even though in some cases it can be cheaper and more effective than the qz-based approach; see [32] for experiments. <p> The reciprocals of the zeros of the minimal residual polynomial are used as coefficients of the Richardson acceleration procedure. We use Leja ordering, which is accomplished by means of function leja and is known to have several advantages <ref> [18, 23] </ref>. Reordered parameters are stored in vector and complex values are avoided by pairing complex roots and their conjugates [20]. <p> This is because adding a new residual with the current approach delays the convergence of the current set of residuals and makes the overall solution time slower than if the systems were to be solved in strict sequence. We also note a suggestion made in <ref> [18, Section 7] </ref> for handling multiple right-hand sides: to apply the gmres component of the algorithm to all the residuals and then to select a polynomial for the hybrid method based on the cumulative information. However, this involves the application of the costly gmres process s times. <p> It is also possible to make mhgmres more flexible, e.g. by varying m, or the number of times the Richardson phase is applied or monitoring the application of the polynomial on non-seed residuals and stopping when the behavior is unsatisfactory. In light of results in <ref> [11, 12, 18] </ref> such flexibility is expected to enhance the performance of the algorithm; however, a full investigation remains to be done. 3.2. Error estimates for mhgmres. <p> Corollary 3.3. The residual after the Richardson phase will satisfy kr j k kp (A)k k (I P m+1 )r j k + jff j;0 j 2* i Note that Richardson acceleration is most advantageous when kp (A)k k~r (i+1) (i) is of order O (ffi m;* ) <ref> [18] </ref>. If the polynomial constructed by the gmres (m) step is such that kp (A)k &lt; 1, the residuals k~r (i+1) j k obtained in Eq. (3) will decrease after the Richardson phase. This is guaranteed irrespective of the value of m when A has definite symmetric part [3].
Reference: [19] <author> D. P. O'Leary, </author> <title> The block conjugate gradient algorithm and related methods, </title> <journal> Lin. Alg. Appl., </journal> <volume> 29 (1980), </volume> <pages> pp. 293-322. </pages>
Reference-contexts: When matrix A is symmetric, block versions of the conjugate gradient (cg) and minimum residual algorithms of O'Leary <ref> [19] </ref> as well as the block Davidson method by Sadkane and Vital [28] are appropriate for handling the problem (1), whereas the Lanczos schemes proposed by Parlett [22] and extended by Saad [25] and Papadrakakis and Smerou in [21], and the method of van der Vorst [40] are mostly suitable when <p> E-mail stratis@csrd.uiuc.edu. This research was supported by the National Science Foundation grant No. NSF CCR-91-20105. 1 2 V. SIMONCINI AND E. GALLOPOULOS not all b j 's are simultaneously available. Reference [21] is of particular interest as it contains numerical experiments from actual applications. See also <ref> [19] </ref> for useful references. The literature for nonsymmetric systems with multiple right-hand sides is less well developed. Two methods that have been proposed are block generalizations of solvers for nonsymmetric systems: the block biconjugate gradient algorithm (bbicg) of O'Leary [19], and block gmres (bgmres) described by Vital [41]. <p> See also <ref> [19] </ref> for useful references. The literature for nonsymmetric systems with multiple right-hand sides is less well developed. Two methods that have been proposed are block generalizations of solvers for nonsymmetric systems: the block biconjugate gradient algorithm (bbicg) of O'Leary [19], and block gmres (bgmres) described by Vital [41]. We also note the recent communication by Kharchenko et al. on the use of restarted bgmres for dense complex systems [13]. <p> Block bicg. The bbicg algorithm, proposed and described in <ref> [19] </ref>, is a block generalization of bicg [4]. In exact arithmetic, if bbicg does not terminate before k = dn=se steps, then the solution becomes available at step k [19, Th. 1]. <p> Block bicg. The bbicg algorithm, proposed and described in [19], is a block generalization of bicg [4]. In exact arithmetic, if bbicg does not terminate before k = dn=se steps, then the solution becomes available at step k <ref> [19, Th. 1] </ref>. Even though the underlying bicg method can be effective in several cases [10, 16, 17, 37], there are some drawbacks that seem to be inherited by the block version. <p> One suggested remedy is to restart bbicg with deflated right-hand sides. Another remedy proposed to mitigate when possible the propagation of roundoff is to orthogonalize the direction matrices at each iteration <ref> [19] </ref>. The major computational costs during bbicg are as shown in Table 1. We denote by MxV the cost for performing one matrix-vector multiplication with the (sparse) matrices A or A T . Function mgs orthogonalizes a set of columns using modified Gram-Schmidt. 2.2. Block gmres. <p> The leading term, 5ns, for bbicg, is due to computations with rectangular iteration matrices of size n fi s <ref> [19] </ref>, while the cost for mj3 is due to the matrices R and R of residuals and auxiliary residuals r j and r j respectively. All methods handling all right-hand sides simultaneously need to store the matrix of the residuals R. <p> We recall that for gmres-based methods the number of iterations refers to the number of restarts. All algorithms were implemented using early-stopping; that is, as soon as any of the systems would converge, these systems were marked and did not participate in any further iterations. Reference <ref> [19] </ref> leaves several options open in the implementation of bbicg. We list our choices next. <p> One instance where bbicg is effective is shown in Table 6: the number of iterations for bbicg decreases as the number of right-hand sides increases, corroborating theoretical results in <ref> [19] </ref>. <p> We thank Miloud Sadkane for providing us with the bgm-res programs, Jacques Laminie for drawing our attention to [9], Dianne O'Leary for her explanations on <ref> [19] </ref>, Randall Bramley for his criticism and suggestions, and Merle Levy for her editorial comments. We thank Gene Golub, Youcef Saad, Paul Saylor, and David Schneider for several discussions, Raj Mittra for readily providing us [34] and Qasim Seikh for [13].
Reference: [20] <author> G. Opfer and G. Schober, </author> <title> Richardson's iteration for nonsymmetric matrices, </title> <journal> Lin. Alg. Appl., </journal> <volume> 58 (1984), </volume> <pages> pp. 343-361. </pages>
Reference-contexts: We use Leja ordering, which is accomplished by means of function leja and is known to have several advantages [18, 23]. Reordered parameters are stored in vector and complex values are avoided by pairing complex roots and their conjugates <ref> [20] </ref>. Function richardson applies the GMRES polynomial to each residual r j ; j = 1; : : : ; s using the following scheme: R = B AX X = X + 1 R = B AX It is worth noticing that qz is called once for each restart.
Reference: [21] <author> M. Papadrakakis and S. Smerou, </author> <title> A new implementation of the Lanczos method in linear problems, </title> <journal> Int'l. J. Numer. Meth. Engng., </journal> <volume> 29 (1990), </volume> <pages> pp. 141-159. </pages>
Reference-contexts: versions of the conjugate gradient (cg) and minimum residual algorithms of O'Leary [19] as well as the block Davidson method by Sadkane and Vital [28] are appropriate for handling the problem (1), whereas the Lanczos schemes proposed by Parlett [22] and extended by Saad [25] and Papadrakakis and Smerou in <ref> [21] </ref>, and the method of van der Vorst [40] are mostly suitable when fl IMGA-CNR, Modena, Italy. E-mail valeria@bora.bo.cnr.it. <p> E-mail stratis@csrd.uiuc.edu. This research was supported by the National Science Foundation grant No. NSF CCR-91-20105. 1 2 V. SIMONCINI AND E. GALLOPOULOS not all b j 's are simultaneously available. Reference <ref> [21] </ref> is of particular interest as it contains numerical experiments from actual applications. See also [19] for useful references. The literature for nonsymmetric systems with multiple right-hand sides is less well developed.
Reference: [22] <author> B. N. Parlett, </author> <title> A new look at the Lanczos algorithm for solving symmetric systems of linear 18 V. SIMONCINI AND E. GALLOPOULOS equations, </title> <journal> Lin. Alg. Appl., </journal> <volume> 29 (1980), </volume> <pages> pp. 323-346. </pages>
Reference-contexts: When matrix A is symmetric, block versions of the conjugate gradient (cg) and minimum residual algorithms of O'Leary [19] as well as the block Davidson method by Sadkane and Vital [28] are appropriate for handling the problem (1), whereas the Lanczos schemes proposed by Parlett <ref> [22] </ref> and extended by Saad [25] and Papadrakakis and Smerou in [21], and the method of van der Vorst [40] are mostly suitable when fl IMGA-CNR, Modena, Italy. E-mail valeria@bora.bo.cnr.it.
Reference: [23] <author> L. Reichel, </author> <title> The application of Leja points to Richardson iteration and polynomial preconditioning, </title> <journal> Lin. Alg. Appl., </journal> <month> 154-156 </month> <year> (1991), </year> <pages> pp. 389-414. </pages>
Reference-contexts: The reciprocals of the zeros of the minimal residual polynomial are used as coefficients of the Richardson acceleration procedure. We use Leja ordering, which is accomplished by means of function leja and is known to have several advantages <ref> [18, 23] </ref>. Reordered parameters are stored in vector and complex values are avoided by pairing complex roots and their conjugates [20].
Reference: [24] <author> Y. Saad, </author> <title> Numerical Methods for Large Eigenvalue Problems, </title> <publisher> Halstead Press, </publisher> <address> New York, </address> <year> 1992. </year> <title> [25] , On the Lanczos method for solving symmetric systems with several right hand sides, </title> <journal> Math. Comp., </journal> <month> 48 (Apr. </month> <year> 1987), </year> <pages> pp. 651-662. </pages> <month> [26] , SPARSKIT: </month> <title> A basic tool kit for sparse matrix computation, </title> <type> Tech. Report 1029, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Central to each iteration of the algorithm is a block Arnoldi process to produce an orthogonal basis for K m (A; R) := fR; AR; : : :; A m1 Rg, where R is an n fi s residual block (see also <ref> [24] </ref>), followed by a (block) minimization problem defined on that subspace. In exact arithmetic and under certain conditions on R and A bgmres achieves finite termination in dn=se iterations.
Reference: [27] <author> Y. Saad and M. H. Schultz, </author> <title> GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <month> 7 (July </month> <year> 1986), </year> <pages> pp. 856-869. </pages>
Reference-contexts: The memory problem is handled by applying restarts. We denote by gmres (m) and bgmres (m; s) the restarted standard and block gmres algorithms. Restarting entails, however, loss of the properties of finite termination and minimization over the entire Krylov subspace <ref> [27] </ref>. Experiments reported in [31] and Section 5 indicate that restarting has a deleterious effect on the purported nice convergence properties of bgmres. <p> This is guaranteed irrespective of the value of m when A has definite symmetric part [3]. Even then, however, kp (A)k might be very near 1 unless m is taken very large, thus making the method impractical. Then other methods might be preferable; see <ref> [12, 17, 27] </ref>. Theorem 3.2 and its corollary show how the approximation is governed by the effectiveness of the projections and the underlying gmres procedure, compounded by the application of the gmres polynomial. We also note that solving (2) for ~z j 's is straighforward.
Reference: [28] <author> M. Sadkane and B. </author> <title> Vital, Davidson's method for linear systems of equations. Implementation of a block algorithm on a multi-processor, </title> <type> Tech. Report TR/PA/91/60, </type> <institution> CERFACS, Toulouse, </institution> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: When matrix A is symmetric, block versions of the conjugate gradient (cg) and minimum residual algorithms of O'Leary [19] as well as the block Davidson method by Sadkane and Vital <ref> [28] </ref> are appropriate for handling the problem (1), whereas the Lanczos schemes proposed by Parlett [22] and extended by Saad [25] and Papadrakakis and Smerou in [21], and the method of van der Vorst [40] are mostly suitable when fl IMGA-CNR, Modena, Italy. E-mail valeria@bora.bo.cnr.it.
Reference: [29] <author> P. E. Saylor and D. C. Smolarski, </author> <title> Implementation of an adaptive algorithm for Richardson's method, </title> <journal> Lin. Alg. Appl., </journal> <month> 154-156 </month> <year> (1991), </year> <pages> pp. 615-646. </pages>
Reference-contexts: Furthermore, the disadvantages of bicg (use of the transpose and erratic behavior) are still present. 3. mhgmres: A hybrid algorithm for multiple right-hand sides. The aforementioned considerations together with recent advances in hybrid methods <ref> [18, 29, 36] </ref> led us to investigate alternatives for economical information sharing to solve Eq. (1).
Reference: [30] <author> B. I. Schneider and L. A. Collins, </author> <title> The linear algebraic method for the scattering of electrons from atoms and molecules: Computational techniques, </title> <journal> Computer Physics Reports, </journal> <month> 10 (Aug. </month> <year> 1991), </year> <pages> pp. 51-75. </pages>
Reference-contexts: This property, combined with the built-in minimization of the block residual make bgmres mathematically attractive. There are, however, practical disadvantages such as high memory requirements; see <ref> [30] </ref> for comments on memory difficulties with block methods. It is also worth noting that similar memory difficulties arise in gmres-like methods for the Sylvester equation [8] 1 . The memory problem is handled by applying restarts.

Reference: [34] <author> C. F. Smith, </author> <title> The performance of preconditioned iterative methods in computational electromag-netics, </title> <type> PhD thesis, </type> <institution> Dept. of Electrical Engineering, Univ. of Illinois at Urbana-Champaign, </institution> <year> 1987. </year>
Reference-contexts: An alternative idea to block methods, suggested in the context of radar scattering applications and applied mostly to complex symmetric matrices, is to use a single "seed" system and some cg-type method as a generator of approximations for several right-hand sides. Smith <ref> [34] </ref> used a single seed system to solve multiple systems in electromagnetic scattering. Smith, Peterson, and Mittra also considered these methods [35] and Joly [9] extended the discussion. The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) [9, 34], and a preconditioned generalized conjugate residual method [9]. <p> Smith [34] used a single seed system to solve multiple systems in electromagnetic scattering. Smith, Peterson, and Mittra also considered these methods [35] and Joly [9] extended the discussion. The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) <ref> [9, 34] </ref>, and a preconditioned generalized conjugate residual method [9]. If A is such that normal equations or bicg approaches are successful, then the methods of [9, 35] can be effective. We present one such method in Section 2.3. <p> One possible way to minimize that distance, suggested in <ref> [34] </ref>, is to choose as seed a linear combination of the current residuals, in order to increase the spectral content of the underlying subspace. However, this causes the gmres step to solve an artificial system, which causes extra work. We thus restrict the seed to one of the current residuals. <p> We thank Gene Golub, Youcef Saad, Paul Saylor, and David Schneider for several discussions, Raj Mittra for readily providing us <ref> [34] </ref> and Qasim Seikh for [13]. We also thank the referees and Howard Elman for criticism that helped us improve the paper.
Reference: [35] <author> C. F. Smith, A. F. Peterson, and R. Mittra, </author> <title> A conjugate gradient algorithm for the treatment of multiple incident electromagnetic fields, </title> <journal> IEEE Trans. Ant. Prop., </journal> <volume> 37 (Nov. </volume> <year> 1989), </year> <pages> pp. 1490-1493. </pages>
Reference-contexts: Smith [34] used a single seed system to solve multiple systems in electromagnetic scattering. Smith, Peterson, and Mittra also considered these methods <ref> [35] </ref> and Joly [9] extended the discussion. The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) [9, 34], and a preconditioned generalized conjugate residual method [9]. If A is such that normal equations or bicg approaches are successful, then the methods of [9, 35] can be effective. <p> The underlying cg-like schemes are cg on normal equations, biconjugate gradients (bicg) [9, 34], and a preconditioned generalized conjugate residual method [9]. If A is such that normal equations or bicg approaches are successful, then the methods of <ref> [9, 35] </ref> can be effective. We present one such method in Section 2.3. In this paper we propose an alternative scheme for the solution of Eq. (1) and compare its performance with existing schemes. <p> Other methods. The electromagnetics literature describes alternatives to the block approach that share common features with our method <ref> [9, 35] </ref>. The success of these methods is usually measured by their effectiveness for complex symmetric matrices encountered in scattering. The method we describe is based on bicg and was recently proposed by Joly [9]. We refer to the method as mj3 2 .
Reference: [36] <author> G. Starke and R. S. Varga, </author> <title> A hybrid Arnoldi-Faber iterative method for nonsymmetric systems of linear equations, </title> <journal> Numer. Math., </journal> <volume> 64 (1993), </volume> <pages> pp. 213-240. </pages>
Reference-contexts: Furthermore, the disadvantages of bicg (use of the transpose and erratic behavior) are still present. 3. mhgmres: A hybrid algorithm for multiple right-hand sides. The aforementioned considerations together with recent advances in hybrid methods <ref> [18, 29, 36] </ref> led us to investigate alternatives for economical information sharing to solve Eq. (1).
Reference: [37] <author> C. H. Tong, </author> <title> A comparative study of preconditioned Lanczos methods for nonsymmetric linear systems, </title> <type> Tech. </type> <institution> Report SAND91-8240 UC404, Sandia National Laboratories, </institution> <address> Albuquerque, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: In exact arithmetic, if bbicg does not terminate before k = dn=se steps, then the solution becomes available at step k [19, Th. 1]. Even though the underlying bicg method can be effective in several cases <ref> [10, 16, 17, 37] </ref>, there are some drawbacks that seem to be inherited by the block version. These are erratic convergence behavior, possible division by zero, and sensitivity to the choice of the auxiliary starting vector. An organizational drawback is the use of the transpose of A. <p> We present results from experiments with matrices pde 9511, orsreg 1 and sherman4. It was observed in studies <ref> [16, 37] </ref> that for these matrices bicg had better overall performance than restarted gmres.
Reference: [38] <author> L. N. Trefethen, </author> <title> Approximation theory and numerical linear algebra, in Algorithms for Approximation II, </title> <editor> J. C. Mason and M. G. Cox, eds., </editor> <publisher> Chapman and Hall, </publisher> <year> 1990, </year> <pages> pp. 336-360. </pages>
Reference-contexts: Let m be the space of polynomials of degree less or equal to m. For a set S, and polynomial p on S, we define kpk S as sup z2S jp (z)j. Since we deal with possibly non-normal matrices, we use the notion of *-pseudospectrum <ref> [38] </ref>. To simplify the notation, let = 1 be the index of the seed system. At each restart i, let r (i) j denote the residual of the j th system, and ~r (i+1) j the intermediate residual obtained after the gmres phase.
Reference: [39] <author> H. A. van der Vorst, </author> <title> Iterative solution methods for certain sparse linear systems with a nonsymmetric matrix arising from PDE-problems, </title> <journal> J. Comput. Phys., </journal> <volume> 44 (1981), </volume> <pages> pp. </pages> <month> 1-19. </month> <title> [40] , An iterative solution method for solving f(A)x = b using Krylov subspace information obtained for the symmetric positive definite matrix A, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 18 (1987), </volume> <pages> pp. 249-263. </pages>
Reference-contexts: In particular, when s is large, expensive but effective forms of preconditioning may be justified because their cost is amortized over a large number of right-hand sides. We also point to <ref> [39] </ref> for preconditioners applied to methods having a polynomial component. The structure of the paper is as follows. Section 2 reviews existing algorithms. Section 3 describes the new method, its implementation, and its convergence properties. The complexity of the methods is discussed in Section 4.
Reference: [41] <author> B. </author> <title> Vital, Etude de quelques methodes de resolution de problemes lineaires de grande taille sur multiprocesseur, </title> <type> PhD thesis, </type> <institution> Universite de Rennes I, Rennes, </institution> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: See also [19] for useful references. The literature for nonsymmetric systems with multiple right-hand sides is less well developed. Two methods that have been proposed are block generalizations of solvers for nonsymmetric systems: the block biconjugate gradient algorithm (bbicg) of O'Leary [19], and block gmres (bgmres) described by Vital <ref> [41] </ref>. We also note the recent communication by Kharchenko et al. on the use of restarted bgmres for dense complex systems [13]. <p> We denote by MxV the cost for performing one matrix-vector multiplication with the (sparse) matrices A or A T . Function mgs orthogonalizes a set of columns using modified Gram-Schmidt. 2.2. Block gmres. The bgmres algorithm was described in <ref> [41] </ref> and is repeated in the Appendix. <p> in addition to the (order n) matrix by vector multiplications, there is significant overhead arising from block Arnoldi and modified Gram-Schmidt, which are used to obtain a block basis [U 1 ; : : : ; U m ] for K m (A; R); for a detailed complexity analysis, see <ref> [41] </ref>. 2.3. Other methods. The electromagnetics literature describes alternatives to the block approach that share common features with our method [9, 35]. The success of these methods is usually measured by their effectiveness for complex symmetric matrices encountered in scattering. <p> Matrix T is triangular of dimension s (m + 1) fi s m. newrot computes and applies the s 2 rotations necessary to update 16 V. SIMONCINI AND E. GALLOPOULOS the qr decomposition of T <ref> [41] </ref>. T is not stored; instead all computed rotations and the triangular matrix of the qr decomposition are saved.
References-found: 32

