URL: http://www.cs.colostate.edu/~ftppub/TechReports/1996/tr96-117.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Email: ross@cs.colostate.edu  riseman@cs.umass.edu  
Phone: Phone: (970) 491-5862 Fax: (970) 491-2466  
Title: How Easy is Matching 2D Line Models Using Local Search?  
Author: J. Ross Beveridge Edward M. Riseman 
Note: Updated 9/04/97 to match manuscript published in IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol 19, No 6, June 1997. c fl1997 IEEE Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes of for creating new collective works for resale is redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE.  
Web: WWW: http://www.cs.colostate.edu  
Address: Fort Collins, CO 80523-1873  
Date: September 11, 1997  
Affiliation: Computer Science  Colorado State University  University of Massachusetts  Computer Science Department Colorado State University  
Pubnum: Technical Report  Technical Report CS-96-117  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> B. W. Kernighan and S. Lin, </author> <title> "An efficient heuristic procedure for partitioning graphs," </title> <journal> Bell Systems Tech. Journal, </journal> <volume> vol. 49, </volume> <pages> pp. 291 - 307, </pages> <year> 1972. </year>
Reference-contexts: Since E I is average squared perpendicular distance, the fit error E fit (c) reaches 1:0 when the average perpendicular distance reaches . Practically speaking, since the omission error is normalized to the range <ref> [0; 1] </ref>, is the largest amount of integrated perpendicular distance allowed in a match. This is because if E fit (c) exceeds 1:0, the match error will favor removal of those segments causing the poor fit. <p> Second, as increasingly large portions fail to be found, the penalty should begin to grow substantially. The following non-linear function of p captures this relationship: E om (p) = e fl 1 if fl 6= 0 p otherwise : (19) Since p lies in the range <ref> [0; 1] </ref>, the omission error also lies in this range. The degree of non-linearity is controlled by fl. However, the exact manner in which changing fl changes the form of E om (p) is less than obvious.
Reference: [2] <author> S. Lin and B. Kernighan, </author> <title> "An effective heuristic algorithm for the traveling salesman problem," </title> <journal> Operations Research, </journal> <volume> vol. 21, </volume> <pages> pp. 498 - 516, </pages> <year> 1973. </year>
Reference: [3] <author> Christos H. Papadimitriou and Kenneth Steiglitz, </author> <title> Combinatorial Optimization: Algorithms and Complexity, chapter Local Search, </title> <journal> pp. </journal> <volume> 454 - 480, </volume> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: A.1 Biased Random Sampling The choice of initial random starting matches need not be uniform, and it is common <ref> [3] </ref>, [29] to bias random selection of starting states in order to improve the likelihood that the state is in the tree leading to the global optima.
Reference: [4] <author> J. Ross Beveridge, Rich Weiss, and Edward M. Riseman, </author> <title> "Combinatorial Optimization Applied to Variable Scale 2D Model Matching," </title> <booktitle> in Proceedings of the IEEE International Conference on Pattern Recognition 1990, </booktitle> <address> Atlantic City. </address> <month> June </month> <year> 1990, </year> <pages> pp. 18 - 23, </pages> <publisher> IEEE. </publisher>
Reference-contexts: Our experience <ref> [4] </ref>, [5], [6], [12] suggests E match (c) induces reasonable rankings over matches for a given model. It is not intended for comparing matches to different models. Developing measures to compare complex versus simple models is itself a subtle problem [20]. <p> Extending a fragmented segment amplifies orientation errors and in turns skews the overall resulting fit. We have developed closed-form solutions with the role of data and model reversed so that the inherently more stable model segments are infinitely extended [24], <ref> [4] </ref>. In another improvement to least-squares fitting of line models, the perpendicular distance is integrated along the data line segment rather than being allowed to concentrate at the ends. Consequently, the optimal least-squares fit is completely invariant with respect to breakpoints in data line segments.
Reference: [5] <author> J. Ross Beveridge, Rich Weiss, and Edward M. Riseman, </author> <title> "Optimization of 2-Dimensional Model Matching," </title> <booktitle> in Selected Papers on Automatic Object Recognition (originally appeared in DARPA Image Understanding Workshop, </booktitle> <year> 1989), </year> <editor> Hatem Nasr, Ed., </editor> <booktitle> SPIE Milestone Series. SPIE, </booktitle> <address> Bellingham, WA, </address> <year> 1991. </year>
Reference-contexts: Our experience [4], <ref> [5] </ref>, [6], [12] suggests E match (c) induces reasonable rankings over matches for a given model. It is not intended for comparing matches to different models. Developing measures to compare complex versus simple models is itself a subtle problem [20].
Reference: [6] <author> J. Ross Beveridge, </author> <title> Local Search Algorithms for Geometric Object Recognition: Optimal Correspondence and Pose, </title> <type> Ph.D. thesis, </type> <institution> University of Massachusetts at Amherst, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Our experience [4], [5], <ref> [6] </ref>, [12] suggests E match (c) induces reasonable rankings over matches for a given model. It is not intended for comparing matches to different models. Developing measures to compare complex versus simple models is itself a subtle problem [20]. <p> In a somewhat counter-intuitive discovery, we have found that least-squares fitting of line models for the rigid case is harder than for the variable scale case. Variable scale requires the solution of a quadratic equation, while fixing scale leads to a quartic equation <ref> [6] </ref>. C.1 Minimizing Perpendicular Distance Models are fit to data so as to minimize the sum of the integrated squared perpendicular distance (ISPD) between h corresponding pairs of segments in c. <p> In principle, for every neighbor tested, the model must be completely fit to the corresponding data and the associated omission over the entire model computed. However, the change in fit error can be more efficiently computed incrementally relative to the current match <ref> [6] </ref>. The incremental computation of E fit requires about 20 floating point additions and multiplications and the finding 8 of 1 square root. A useful heuristic is therefore to see if the change in fit error appears to preclude improvement. <p> This means that the maximum likeli hood estimate for P s is the ratio: ^ P s = k It is also possible to predict the degree of uncertainty in the estimate ^ P s and these bounds for different combinations of trials and ^ P s appear in <ref> [6] </ref>. A good rule of thumb is that the best match must be seen some reasonable number of times: perhaps more than 10 times. While all the problems presented in this paper may be studied in this fashion, clearly there are limits. <p> Test data, a) random clutter, b) multiple instances. used this test suite in the past to benchmark local search matching algorithms <ref> [6] </ref>, [14] and to compare local search with genetic algorithms [28]. The test suite as well as our optimal matches are available through our website: http://www.cs.colostate.edu/~vision. Each model is defined by a set of 2D straight line segments.
Reference: [7] <author> Robert T. Collins and J. Ross Beveridge, </author> <title> "Matching perspective views of coplanar structures using projective unwarping and 15 similarity matching.," </title> <booktitle> in Proceedings: 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <address> New York, NY, </address> <month> June </month> <year> 1993, </year> <pages> pp. 240 - 245. </pages>
Reference-contexts: In these examples, models have been hand built. However, while these examples are hand built, local search has been used with real building models on the RADIUS calibrated terrain board imagery [18]. It has also been used with aerial photgraphs to register ortho-rectified images <ref> [7] </ref>. The data line segments for these examples are produced using the Burns algorithm [19]. For the match in Figure 2d, the model is rotated by 120 ffi , illustrating that the original orientation of the model does not matter.
Reference: [8] <author> Claude Fennema, Allen Hanson, Edward Riseman, J. R. Bev-eridge, and R. Kumar, </author> <title> "Model-directed mobile robot navigation," </title> <journal> IEEE Trans. on Syst., Man, Cybern., </journal> <volume> vol. 20, no. 6, </volume> <pages> pp. 1352 - 1369, </pages> <month> November/December </month> <year> 1990. </year>
Reference: [9] <author> Edward M. Riseman and Allen R. Hanson and J. Ross Beveridge and Rakesh Kumar and Harpreet Sawhney, </author> <title> "Landmark-based navigation and the acquisition of environmental models," in Visual Navigation: From Biological Systems to Unmanned Ground Vehicles, </title> <editor> Yiannis Aloimonos, Ed., pp. </editor> <volume> 317 - 374. </volume> <publisher> Lawrence Erl-baum Associates, Inc., </publisher> <year> 1997. </year>
Reference: [10] <author> J. Ross Beveridge and Christopher Graves and Christopher E. Lesher, </author> <title> "Local Search as a Tool for Horizon Line Matching," </title> <booktitle> in Proceedings: Image Understanding Workshop, </booktitle> <address> Los Altos, CA, </address> <month> February </month> <year> 1996, </year> <booktitle> ARPA, </booktitle> <pages> pp. 683 - 686, </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: [11] <author> Bruce A. Draper, </author> <title> Learning Object Recognition Strategies, </title> <type> Ph.D. thesis, </type> <institution> University of Massachusetts, Amherst, </institution> <month> May </month> <year> 1993. </year>
Reference: [12] <author> J. Ross Beveridge and Edward M. Riseman, </author> <title> "Optimal Geometric Model Matching Under Full 3D Perspective," </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> vol. 61, no. 3, </volume> <pages> pp. 351 - 364, </pages> <year> 1995, </year> <note> (short version in IEEE Second CAD-Based Vision Workshop). </note>
Reference-contexts: Our experience [4], [5], [6], <ref> [12] </ref> suggests E match (c) induces reasonable rankings over matches for a given model. It is not intended for comparing matches to different models. Developing measures to compare complex versus simple models is itself a subtle problem [20]. <p> B. Conclusion Our work adds a new tool to the relatively small set of general matching techniques. Past work has shown our algorithm performs well in several application domains where rough placement constraints derived from other sources are available. This is true for both 2D and 3D <ref> [12] </ref> recognition problems. The empirical tests presented in this paper suggest local search does well on a wide range of 2D line matching problems even when no initial estimate of model placement is available.
Reference: [13] <author> David S. Johnson, Christos H. Papadimitriou, and Mihalis Yan-nakakis, </author> <title> "How easy is local search," </title> <journal> Journal of Computer and System Sciences, </journal> <volume> vol. 37, </volume> <pages> pp. 79 - 100, </pages> <year> 1988. </year>
Reference-contexts: 1 Johnson and Papadimitriou <ref> [13] </ref> are thanked for inspiring the title to this paper with their own title: 'How Easy is Local Search?' 2 (b) Fig. 1. Illustration of local search matching. a) a model, imperfect data, and an optimal match, b) Successive rows show local search improving upon an initial random match.
Reference: [14] <author> J. Ross Beveridge, Edward M. Riseman, and Christopher Graves, </author> <title> "Demonstrating Polynomial Run-Time Growth for Local Search Matching," </title> <booktitle> in Proceedings: International Symposium on Computer Vision, Coral Gables, </booktitle> <address> Florida, </address> <month> November </month> <year> 1995, </year> <journal> IEEE PAMI TC, pp. </journal> <volume> 533 - 538, </volume> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Test data, a) random clutter, b) multiple instances. used this test suite in the past to benchmark local search matching algorithms [6], <ref> [14] </ref> and to compare local search with genetic algorithms [28]. The test suite as well as our optimal matches are available through our website: http://www.cs.colostate.edu/~vision. Each model is defined by a set of 2D straight line segments.
Reference: [15] <author> W. E. L. </author> <title> Grimson, "The Combinatorics of Object Recognition in Cluttered Environments Using Constrained Search," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 44, no. 1, </volume> <pages> pp. 121 - 165, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The exponents fi for the polynomial model are also shown in Table II. For the random clutter cases, these empirical estimates are surprisingly close to the n 2 average case bounds derived for tree search by Grimson <ref> [15] </ref>, [16]. However, note that our random clutter data includes the Dandelion model, which because of its near symmetry would cause tree search great difficulty. For the multiple-instance problems, the growth rate is higher, tending up toward 2:5 rather than 2:0. C.
Reference: [16] <author> W. Eric L. </author> <title> Grimson, Object Recognition by Computer: The Role of Geometric Constraints, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: More precisely, if a single data segment is broken into two adjacent segments at any position along the segment, the resulting fit will not change. As an aside, the case of rigid 2D fitting deserves comment. For many matching techniques, such as tree search <ref> [16] </ref> and Hough transforms [25], forcing scale to remain constant makes problems easier to solve. In a somewhat counter-intuitive discovery, we have found that least-squares fitting of line models for the rigid case is harder than for the variable scale case. <p> The models have been selected to be simple enough to permit study yet varied enough to test for possible weaknesses in a matching algorithm. For example, the Dandelion exhibits a 16 fold near symmetry. Symmetries in models complicate matching for many well established techniques <ref> [16] </ref>. The Leaf presents an example where model and data line segments approximate a curved contour. In this case, a many-to-many mapping between model and image segments is needed to account for breakpoints falling at different positions along the curve. A Monte Carlo simulator produces corrupted image data. <p> The exponents fi for the polynomial model are also shown in Table II. For the random clutter cases, these empirical estimates are surprisingly close to the n 2 average case bounds derived for tree search by Grimson [15], <ref> [16] </ref>. However, note that our random clutter data includes the Dandelion model, which because of its near symmetry would cause tree search great difficulty. For the multiple-instance problems, the growth rate is higher, tending up toward 2:5 rather than 2:0. C. <p> VIII. Some Observations The performance of local search as a general method for finding matches appears as good or better than any of the known alternative general methods [32], <ref> [16] </ref>, [17]. However, there are some important caveats. First, while local search probabilistically finds optimal matches, these other techniques deterministically find acceptable (not optimal) matches. Comparison at a coarse level is informative but also somewhat problematic.
Reference: [17] <author> Todd A. Cass, </author> <title> "Polynomial-time object recognition in the presence of clutter, occlusion, and uncertainty," </title> <booktitle> in Proceedings: Image Understanding Workshop, </booktitle> <address> San Mateo, CA, </address> <month> January </month> <year> 1992, </year> <title> DARPA, </title> <journal> pp. </journal> <volume> 693 - 704, </volume> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: VIII. Some Observations The performance of local search as a general method for finding matches appears as good or better than any of the known alternative general methods [32], [16], <ref> [17] </ref>. However, there are some important caveats. First, while local search probabilistically finds optimal matches, these other techniques deterministically find acceptable (not optimal) matches. Comparison at a coarse level is informative but also somewhat problematic.
Reference: [18] <author> R. Collins, A. Hanson, R. Riseman, and Y. Cheng, </author> <title> "Model Matching and Extension for Automated 3D Site Modeling," </title> <booktitle> in Proceedings: Image Understanding Workshop, </booktitle> <address> Los Altos, CA, </address> <month> April </month> <year> 1993, </year> <booktitle> ARPA, </booktitle> <pages> pp. 197 - 203, </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In these examples, models have been hand built. However, while these examples are hand built, local search has been used with real building models on the RADIUS calibrated terrain board imagery <ref> [18] </ref>. It has also been used with aerial photgraphs to register ortho-rectified images [7]. The data line segments for these examples are produced using the Burns algorithm [19].
Reference: [19] <author> J. B. Burns, A. R. Hanson, and E. M. Riseman, </author> <title> "Extracting straight lines," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. PAMI-8, no. 4, </volume> <pages> pp. 425 - 456, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: It has also been used with aerial photgraphs to register ortho-rectified images [7]. The data line segments for these examples are produced using the Burns algorithm <ref> [19] </ref>. For the match in Figure 2d, the model is rotated by 120 ffi , illustrating that the original orientation of the model does not matter. In this example, there is little clutter and the building has a distinctive form.
Reference: [20] <author> Mark R. Stevens and J. Ross Beveridge, </author> <title> "Precise Matching of 3-D Target Models to Multisensor Data," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 6, no. 1, </volume> <pages> pp. 126-142, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: Our experience [4], [5], [6], [12] suggests E match (c) induces reasonable rankings over matches for a given model. It is not intended for comparing matches to different models. Developing measures to compare complex versus simple models is itself a subtle problem <ref> [20] </ref>. In part inspired by Wells [21], we have experimented with a data omission term penalizing matches that leave data unmatched. On problems of the type presented here data omission hurts rather than helps. Consider what happens when two instances of a model appear in one image. <p> Making the quality of a match to one instance dependent upon the size of the other instance leads to unpredictable and undesirable behavior. However, in the context of matching laser range data we have found a data omission term to be helpful <ref> [20] </ref>. To evaluate E match , first a global alignment of model to data must be determined based upon the correspondence c. Next, the model must be transformed to this configuration and omission measured.
Reference: [21] <author> William M. Wells III, </author> <title> "Map model matching," </title> <booktitle> in CVPR-91, </booktitle> <year> 1991, </year> <pages> pp. 486-492. </pages>
Reference-contexts: Our experience [4], [5], [6], [12] suggests E match (c) induces reasonable rankings over matches for a given model. It is not intended for comparing matches to different models. Developing measures to compare complex versus simple models is itself a subtle problem [20]. In part inspired by Wells <ref> [21] </ref>, we have experimented with a data omission term penalizing matches that leave data unmatched. On problems of the type presented here data omission hurts rather than helps. Consider what happens when two instances of a model appear in one image.
Reference: [22] <author> David G. Lowe, </author> <title> Perceptual Organization and Visual Recognition, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1985. </year>
Reference-contexts: Point-to-point fitting has problems when line segments are fragmented or overextended. Both Lowe and Ayache <ref> [22] </ref>, [23] appropriately suggested it is better to minimize a perpendicular point-to-line distance measure. Ayache [23] developed a closed-form solution for the rotation, translation and scale which minimizes squared perpendicular distance from endpoints of model line segments to infinitely extended data lines. <p> Going back to Roberts [33], there has been a rich tradition of work that says essentially: to find an object first find a small subset of features that predict the presence of the object. This general approach to recognition can be traced through many works including [34], <ref> [22] </ref>, work on geometric hashing schemes [35] and on through a collection of excellent recent works [36], [37], [38], [39], [40]. Grimson et al. provide a nice general analysis of the problem [41]. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features.
Reference: [23] <author> N. Ayache and O. D. Faugeras, </author> <title> "Hyper: A new approach for the recognition and positioning of 2-d objects," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 8, no. 1, </volume> <pages> pp. 44 - 54, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Point-to-point fitting has problems when line segments are fragmented or overextended. Both Lowe and Ayache [22], <ref> [23] </ref> appropriately suggested it is better to minimize a perpendicular point-to-line distance measure. Ayache [23] developed a closed-form solution for the rotation, translation and scale which minimizes squared perpendicular distance from endpoints of model line segments to infinitely extended data lines. <p> Point-to-point fitting has problems when line segments are fragmented or overextended. Both Lowe and Ayache [22], <ref> [23] </ref> appropriately suggested it is better to minimize a perpendicular point-to-line distance measure. Ayache [23] developed a closed-form solution for the rotation, translation and scale which minimizes squared perpendicular distance from endpoints of model line segments to infinitely extended data lines. The weakness of this approach is that often line segments extracted from imagery fragment [24].
Reference: [24] <author> J. Ross Beveridge, Rich Weiss, and Edward M. Riseman, </author> <title> "Optimization of 2-dimensional model matching," </title> <booktitle> in Proceedings: Image Understanding Workshop, </booktitle> <address> Los Altos, CA, </address> <month> June </month> <year> 1989, </year> <title> DARPA, </title> <journal> pp. </journal> <volume> 815 - 830, </volume> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Ayache [23] developed a closed-form solution for the rotation, translation and scale which minimizes squared perpendicular distance from endpoints of model line segments to infinitely extended data lines. The weakness of this approach is that often line segments extracted from imagery fragment <ref> [24] </ref>. Extending a fragmented segment amplifies orientation errors and in turns skews the overall resulting fit. We have developed closed-form solutions with the role of data and model reversed so that the inherently more stable model segments are infinitely extended [24], [4]. <p> approach is that often line segments extracted from imagery fragment <ref> [24] </ref>. Extending a fragmented segment amplifies orientation errors and in turns skews the overall resulting fit. We have developed closed-form solutions with the role of data and model reversed so that the inherently more stable model segments are infinitely extended [24], [4]. In another improvement to least-squares fitting of line models, the perpendicular distance is integrated along the data line segment rather than being allowed to concentrate at the ends. Consequently, the optimal least-squares fit is completely invariant with respect to breakpoints in data line segments. <p> This algorithm has already been illustrated in pair of model-data segments in one move: it cannot swap one data segment for another. A Hamming-distance-2 neighborhood permits swapping of segments. However, the size of the Hamming-distance-2 neighborhood is n 2 . Early experiments were made with this neighborhood <ref> [24] </ref>, but the n 2 growth in neighborhood size makes this an unattractive alternative for even medium sized problems. Results using the Hamming-distance-1 neighborhood show run-times to solve complete problems appear to grow as a function of n 2 .
Reference: [25] <author> Larry S. Davis, </author> <title> "Hierarchical generalized Hough transforms and line-segment based generalized Hough transforms," </title> <journal> Pattern Recognition, </journal> <volume> vol. 15, no. 4, </volume> <pages> pp. 277 - 285, </pages> <year> 1982. </year>
Reference-contexts: More precisely, if a single data segment is broken into two adjacent segments at any position along the segment, the resulting fit will not change. As an aside, the case of rigid 2D fitting deserves comment. For many matching techniques, such as tree search [16] and Hough transforms <ref> [25] </ref>, forcing scale to remain constant makes problems easier to solve. In a somewhat counter-intuitive discovery, we have found that least-squares fitting of line models for the rigid case is harder than for the variable scale case.
Reference: [26] <author> Ben Noble and James W. Daniel, </author> <title> Applied Linear Algebra, </title> <publisher> Prentice-Hall, Inc, </publisher> <address> Englewood Cliffs, N.J., 2 edition, </address> <year> 1977. </year>
Reference: [27] <author> Visvanathan Ramesh, </author> <title> Performance Characterization of Image Understanding Algorithms, </title> <type> Ph.D. thesis, </type> <institution> University of Wash-ington, </institution> <year> 1995. </year>
Reference-contexts: While the connection is not rigorous, one may think informally of as the standard deviation of a noise process which skews data line segments relative to their `true' position. For an excellent treatment on noise process models and straight line extraction, see <ref> [27] </ref>. C.3 Omission Error is Non-linear Function of Coverage The omission error for a model segment M is defined as a non-linear function of the percent p of the model line unaccounted for by data.
Reference: [28] <author> D. Whitley, J. Ross Beveridge, C. Graves and K. Mathias, </author> <title> "Test Driving Three 1995 Genetic Algorithms: New Test Functions and Geometric Matching," </title> <journal> Journal of Heuristics, </journal> <volume> vol. 1, </volume> <pages> pp. 77 - 104, </pages> <year> 1996. </year>
Reference-contexts: Applying this heuristic reduces required computation by nearly an order of magnitude <ref> [28] </ref>. It is a heuristic because it neglects subtle interaction effects in which a small match change might drop omission error for many model line segments. Such cases exist but are rare. B. <p> Test data, a) random clutter, b) multiple instances. used this test suite in the past to benchmark local search matching algorithms [6], [14] and to compare local search with genetic algorithms <ref> [28] </ref>. The test suite as well as our optimal matches are available through our website: http://www.cs.colostate.edu/~vision. Each model is defined by a set of 2D straight line segments. In matching, these models may be rotated and translated to lie anywhere in the image.
Reference: [29] <author> Craig A. Tovey, </author> <title> "Hill climbing with multiple local optima," </title> <journal> SIAM J. Alg. Disc. Meth., </journal> <volume> vol. 6, no. 3, </volume> <pages> pp. 384 - 393, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: As one might expect, for all but trivial problems, there are a tremendous number of local optima in the space C. Often this fact causes people to prematurely dismiss local search as a useful technique. Tovey <ref> [29] </ref> makes several very insightful observations about local search and local optima. The first is that a deterministic local search algorithm imposes a `forest structure' upon the search space. <p> The shape of this forest, the number of trees and their relative size, are the combined product of the local search neighborhood definition, the criterion function and the specific problem instance. 5 Tovey <ref> [29] </ref> proves that for several classes of NP-complete problems the expected number trees in the forest grows exponentially. He further expresses a belief that all NP-complete problems have exponentially many local optima, but stops short of offering a proof (a proof would amount to a proof that P 6= NP). <p> P s for a given problem is known, then the probability of failing to see the global optima over t independent trials is 4 For simplicity, ties for `best' are ignored. 5 This interplay between the neighborhood definition and the evaluation function which makes formal analysis of local search difficult <ref> [29] </ref> 9 simply Q f = (P f ) ; where P f = 1 P s : (24) From equation 24 it is possible to compute the number of trials t s required to find the optimal match with probability Q s = 1 Q f : t s = <p> A.1 Biased Random Sampling The choice of initial random starting matches need not be uniform, and it is common [3], <ref> [29] </ref> to bias random selection of starting states in order to improve the likelihood that the state is in the tree leading to the global optima.
Reference: [30] <author> Chris Loader, </author> <title> "Local Search Algorithms for 2D Geometric Object Recognition," M.S. </title> <type> thesis, </type> <institution> University of Western Australia, </institution> <year> 1995. </year>
Reference-contexts: VI. Characterizing Performance A test suite of 48 distinct matching problems is used in this study. They are derived from the 6 `stick figure' models shown in Figure 7. We and others <ref> [30] </ref> have 10 Fig. 6. Local optima: a) Model shifted up with E match = 0:395, b) Model shifted down with E match = 0:340, c) E match = 0:523, d) E match = 0:575 (a) (b) Fig. 8.
Reference: [31] <author> Jay L. Devore, </author> <title> Probability and Statistics for Engineering and the Sciences, chapter Nonlinear and Multiple Regression, </title> <journal> pp. </journal> <pages> 459-520, </pages> <publisher> Brooks/Color Publishing Company, </publisher> <address> Monterey, CA, </address> <year> 1982. </year>
Reference-contexts: Within these two problem classes, problems deriving from the six different models have not been distinguished. Also shown in Figure 9 are two non-linear regression curves. These are derived using standard non-linear regression techniques as described in <ref> [31] </ref>.
Reference: [32] <author> Henry S. Baird, </author> <title> Model-Based Image Matching Using Location, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: VIII. Some Observations The performance of local search as a general method for finding matches appears as good or better than any of the known alternative general methods <ref> [32] </ref>, [16], [17]. However, there are some important caveats. First, while local search probabilistically finds optimal matches, these other techniques deterministically find acceptable (not optimal) matches. Comparison at a coarse level is informative but also somewhat problematic.
Reference: [33] <author> L. G. Roberts, </author> <title> "Machine perception of three-dimensional solids," in Optical and Electro-Optical Information Processing, </title> <editor> James T. Tippett, Ed., </editor> <volume> chapter 9, </volume> <pages> pp. 159 - 197. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1965. </year>
Reference-contexts: This lack of reliance upon indexing sets our approach apart from much of the prior work on geometric object recognition and makes our algorithm robust across a wide range of problem types. However, it also places limits on what problems can be solved. Going back to Roberts <ref> [33] </ref>, there has been a rich tradition of work that says essentially: to find an object first find a small subset of features that predict the presence of the object.
Reference: [34] <author> R. C. Bolles and R. A. Cain, </author> <title> "Recognizing and Locating Partially Visible Objects: The Local-Feature-Focus Method," </title> <journal> International Journal of Robotics Research, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 57 - 82, </pages> <year> 1982. </year>
Reference-contexts: Going back to Roberts [33], there has been a rich tradition of work that says essentially: to find an object first find a small subset of features that predict the presence of the object. This general approach to recognition can be traced through many works including <ref> [34] </ref>, [22], work on geometric hashing schemes [35] and on through a collection of excellent recent works [36], [37], [38], [39], [40]. Grimson et al. provide a nice general analysis of the problem [41].
Reference: [35] <author> Yehezkel Lamdan, Jacob T. Schwartz, and Haim J. Wolfson, </author> <title> "Affine invariant model-based object recognition," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 6, no. 5, </volume> <pages> pp. 578 - 589, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: This general approach to recognition can be traced through many works including [34], [22], work on geometric hashing schemes <ref> [35] </ref> and on through a collection of excellent recent works [36], [37], [38], [39], [40]. Grimson et al. provide a nice general analysis of the problem [41]. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features.
Reference: [36] <author> Fridtjof Stein and Gerard Medioni, </author> <title> "Recognition of 3-d objects from 2-d groupings," </title> <booktitle> in Proceedings: Image Understanding Workshop, </booktitle> <address> San Mateo, </address> <month> January </month> <year> 1992, </year> <title> DARPA, </title> <journal> pp. </journal> <volume> 667 - 674, </volume> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This general approach to recognition can be traced through many works including [34], [22], work on geometric hashing schemes [35] and on through a collection of excellent recent works <ref> [36] </ref>, [37], [38], [39], [40]. Grimson et al. provide a nice general analysis of the problem [41]. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features. Hence, indexing is frequently solved using domain specific heuristics.
Reference: [37] <author> A.R. Pope and D.G. Lowe, </author> <title> "Learning object recognition models from images," </title> <booktitle> in ICCV, </booktitle> <year> 1993, </year> <pages> pp. 296-301. </pages>
Reference-contexts: This general approach to recognition can be traced through many works including [34], [22], work on geometric hashing schemes [35] and on through a collection of excellent recent works [36], <ref> [37] </ref>, [38], [39], [40]. Grimson et al. provide a nice general analysis of the problem [41]. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features. Hence, indexing is frequently solved using domain specific heuristics.
Reference: [38] <author> Arthur R. Pope, </author> <title> "Model-based object recognition," </title> <type> Tech. Rep., </type> <institution> University of British Columbia, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: This general approach to recognition can be traced through many works including [34], [22], work on geometric hashing schemes [35] and on through a collection of excellent recent works [36], [37], <ref> [38] </ref>, [39], [40]. Grimson et al. provide a nice general analysis of the problem [41]. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features. Hence, indexing is frequently solved using domain specific heuristics.
Reference: [39] <author> C.F. Olson, </author> <title> "Time and space efficient pose clustering," </title> <booktitle> in CVPR94, </booktitle> <year> 1994, </year> <pages> pp. 251-258. </pages>
Reference-contexts: This general approach to recognition can be traced through many works including [34], [22], work on geometric hashing schemes [35] and on through a collection of excellent recent works [36], [37], [38], <ref> [39] </ref>, [40]. Grimson et al. provide a nice general analysis of the problem [41]. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features. Hence, indexing is frequently solved using domain specific heuristics.
Reference: [40] <author> C.F. Olson, </author> <title> "On the speed and accuracy of object recognition when using imperfect grouping," </title> <booktitle> in SCV95, </booktitle> <year> 1995, </year> <pages> pp. 449-454, </pages> <address> http://www.cs.cornell.edu/Info/People/clarko/papers.html. </address>
Reference-contexts: This general approach to recognition can be traced through many works including [34], [22], work on geometric hashing schemes [35] and on through a collection of excellent recent works [36], [37], [38], [39], <ref> [40] </ref>. Grimson et al. provide a nice general analysis of the problem [41]. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features. Hence, indexing is frequently solved using domain specific heuristics.
Reference: [41] <author> Grimson, W.E.L. and Huttenlocher, D.P. and Jacobs, D.W., </author> <title> "A Study of Affine Matching With Bounded Sensor Error," </title> <journal> IJCV, </journal> <volume> vol. 13, no. 1, </volume> <pages> pp. 7-32, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: This general approach to recognition can be traced through many works including [34], [22], work on geometric hashing schemes [35] and on through a collection of excellent recent works [36], [37], [38], [39], [40]. Grimson et al. provide a nice general analysis of the problem <ref> [41] </ref>. The fundamental difficulty in designing indexing algorithms is efficiently finding reliable sets of domain independent indexing features. Hence, indexing is frequently solved using domain specific heuristics. In some application domains, such as 2D part recognition, these heuristics are easily developed.
Reference: [42] <author> Martin A. Fischler and Robert C. Bolles, </author> " <title> A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography (reprinted in Readings in Computer Vision, </title> <editor> ed. M. A. </editor> <title> Fischler," </title> <journal> Comm. ACM, </journal> <volume> vol. 24, no. 6, </volume> <pages> pp. 381 - 395, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: Random sampling plays such a key role in our approach that it is worth understanding that random sampling alone is not a good way of selecting consistent indexing features. Random sampling to find small subsets of consistent features has been suggested and put to good use under some conditions <ref> [42] </ref>, [43], [44].
Reference: [43] <author> Gerhard Roth, </author> <title> "Extracting geometric primitives," Computer Vision, Graphics, </title> <booktitle> and Image Processing Image Understanding, </booktitle> <volume> vol. 58, no. 1, </volume> <pages> pp. 1 - 22, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Random sampling to find small subsets of consistent features has been suggested and put to good use under some conditions [42], <ref> [43] </ref>, [44].

References-found: 43

