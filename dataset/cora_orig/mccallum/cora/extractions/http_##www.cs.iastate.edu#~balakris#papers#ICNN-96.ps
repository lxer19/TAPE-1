URL: http://www.cs.iastate.edu/~balakris/papers/ICNN-96.ps
Refering-URL: http://www.cs.iastate.edu/~balakris/publications.html
Root-URL: http://www.cs.iastate.edu
Email: balakris@cs.iastate.edu, honavar@cs.iastate.edu  
Phone: (515)-294-1098, Fax (515)-294-0258  
Title: Analysis of Neurocontrollers Designed by Simulated Evolution  
Author: Karthik Balakrishnan and Vasant Honavar 
Address: Ames, IA 50011  
Affiliation: Artificial Intelligence Research Group Iowa State University,  
Abstract: Randomized adaptive greedy search, using evolutionary algorithms, offers a powerful and versatile approach to the automated design of neural network architectures for a variety of tasks in artificial intelligence and robotics. In this paper we present results from the evolutionary design of a neuro-controller for a robotic bulldozer. This robot is given the task of clearing an arena littered with boxes by pushing boxes to the sides. Through a careful analysis of the evolved networks we show how evolution exploits the design constraints and properties of the environment to produce network structures of high fitness. We conclude with a brief summary of related ongoing research examining the intricate interplay between environment and evolutionary processes in determining the structure and function of the resulting neural architectures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Balakrishnan and V. Honavar, </author> <title> "Analysis of neurocontrollers designed by simulated evolution," </title> <type> Tech. Rep. CS TR 95-25, </type> <institution> Department of Computer Science, Iowa State University, Ames, </institution> <address> IA - 50011, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: 1. Introduction Artificial neural networks offer an attractive paradigm for the design of behavior and control systems in robots and autonomous agents for a variety of reasons <ref> [7, 5, 2, 1] </ref> including: ability to adapt and learn, potential for resistance to noise, faults and component failures, potential for real-time performance in dynamic environments (through massive parallelism and suitable hardware realization) etc. <p> Implementation Details In our simulations we use Genetic Algorithms (GA) [8, 6] to evolve neuro-controller designs. We used a genetic representation that codes for the input connectivity of each of the units of the network as shown in Figure 2 (ref <ref> [1] </ref> for details). This encoding scheme was chosen primarily for its simplicity and certain representational properties [3]. Since the emphasis of this paper is on the analysis of the evolution of network architectures that produce specific behaviors, exploration of more expressive genetic representations (e.g., grammars), have not been undertaken.
Reference: [2] <author> K. Balakrishnan and V. Honavar, </author> <title> "Evolutionary design of neural architectures | a preliminary taxonomy and guide to literature," </title> <type> Tech. Rep. CS TR 95-01, </type> <institution> Department of Computer Science, Iowa State University, Ames, </institution> <address> IA - 50011, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: 1. Introduction Artificial neural networks offer an attractive paradigm for the design of behavior and control systems in robots and autonomous agents for a variety of reasons <ref> [7, 5, 2, 1] </ref> including: ability to adapt and learn, potential for resistance to noise, faults and component failures, potential for real-time performance in dynamic environments (through massive parallelism and suitable hardware realization) etc.
Reference: [3] <author> K. Balakrishnan and V. Honavar, </author> <title> "Properties of genetic representations of neural architectures," </title> <booktitle> in Proceedings of the World Congress on Neural Networks, </booktitle> <address> (Washington D.C), </address> <pages> pp. 807-813, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: We used a genetic representation that codes for the input connectivity of each of the units of the network as shown in Figure 2 (ref [1] for details). This encoding scheme was chosen primarily for its simplicity and certain representational properties <ref> [3] </ref>. Since the emphasis of this paper is on the analysis of the evolution of network architectures that produce specific behaviors, exploration of more expressive genetic representations (e.g., grammars), have not been undertaken.
Reference: [4] <author> V. </author> <title> Braitenberg, Vehicles: Experiments in Synthetic Psychology. </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1984. </year>
Reference-contexts: Table 2 shows a different mapping of the neural network outputs to actions, inspired by Braitenberg's thought experiments with vehicles <ref> [4] </ref>.
Reference: [5] <author> D. Floreano and F. Mondada, </author> <title> "Automatic creation of an autonomous agent: Genetic evolution of a neural-network driven robot," </title> <booktitle> in From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> (D. Cliff, P. Husbands, J.-A. Meyer, and S. Wilson, eds.), </editor> <address> (Cambridge, MA), </address> <pages> pp. 421-430, </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: 1. Introduction Artificial neural networks offer an attractive paradigm for the design of behavior and control systems in robots and autonomous agents for a variety of reasons <ref> [7, 5, 2, 1] </ref> including: ability to adapt and learn, potential for resistance to noise, faults and component failures, potential for real-time performance in dynamic environments (through massive parallelism and suitable hardware realization) etc.
Reference: [6] <author> D. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization, </title> <booktitle> and Machine Learning. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Evolutionary Algorithms (EA) that are loosely inspired models of natural evolution, offer a particularly attractive tool for the design of neuro-controllers for a number of reasons. They have been shown to be effective in searching several vast, complex, multi-modal and deceptive search spaces <ref> [8, 6] </ref>. In addition, EA constitute a form of population-based reinforcement learning and hence can deal with problems where precise knowledge of the desired actions in response to particular sensory inputs is lacking (and hence it is difficult to use conventional supervised neural network learning algorithms). <p> For reasons mentioned in section 1, we use an EA to search for such a neuro-controller in a suitably chosen space of neural architectures. 3. Implementation Details In our simulations we use Genetic Algorithms (GA) <ref> [8, 6] </ref> to evolve neuro-controller designs. We used a genetic representation that codes for the input connectivity of each of the units of the network as shown in Figure 2 (ref [1] for details). This encoding scheme was chosen primarily for its simplicity and certain representational properties [3].
Reference: [7] <author> I. Harvey, P. Husbands, and D. Cliff, </author> <booktitle> "Issues in evolutionary robotics," in From Animals to Animats II: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <editor> (J. Meyer, H. Roitblat, and S. Wilson, eds.), </editor> <address> (Cambridge, MA), </address> <pages> pp. 364-373, </pages> <publisher> MIT Press-Bradford Books, </publisher> <year> 1992. </year>
Reference-contexts: 1. Introduction Artificial neural networks offer an attractive paradigm for the design of behavior and control systems in robots and autonomous agents for a variety of reasons <ref> [7, 5, 2, 1] </ref> including: ability to adapt and learn, potential for resistance to noise, faults and component failures, potential for real-time performance in dynamic environments (through massive parallelism and suitable hardware realization) etc.
Reference: [8] <author> J. Holland, </author> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <address> Ann Arbor: </address> <publisher> The University of Michigan Press, </publisher> <year> 1975. </year>
Reference-contexts: Evolutionary Algorithms (EA) that are loosely inspired models of natural evolution, offer a particularly attractive tool for the design of neuro-controllers for a number of reasons. They have been shown to be effective in searching several vast, complex, multi-modal and deceptive search spaces <ref> [8, 6] </ref>. In addition, EA constitute a form of population-based reinforcement learning and hence can deal with problems where precise knowledge of the desired actions in response to particular sensory inputs is lacking (and hence it is difficult to use conventional supervised neural network learning algorithms). <p> For reasons mentioned in section 1, we use an EA to search for such a neuro-controller in a suitably chosen space of neural architectures. 3. Implementation Details In our simulations we use Genetic Algorithms (GA) <ref> [8, 6] </ref> to evolve neuro-controller designs. We used a genetic representation that codes for the input connectivity of each of the units of the network as shown in Figure 2 (ref [1] for details). This encoding scheme was chosen primarily for its simplicity and certain representational properties [3].
Reference: [9] <author> A. Teller, </author> <title> "The evolution of mental models," </title> <booktitle> in Advances in Genetic Programming, </booktitle> <editor> (K. Kinnear, </editor> <publisher> ed.), </publisher> <pages> pp. 199-219, </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The Task Domain The task environment, proposed by Teller <ref> [9] </ref>, consists of an arena of N fi N squares strewn with M boxes in the inner (N 2) fi (N 2) grid. The arena is enclosed by impenetrable walls. Fig. 1: The operating environment. <p> With integer weights and threshold functions, the computational power of such networks is equivalent to that of finite state automata. This simplifies the analysis of the resulting behaviors. The general framework for the simulation experiments was borrowed from <ref> [9] </ref>. Thus we used 6 fi 6 arenas, with 6 boxes randomly distributed in the inner 4 fi 4 grid. <p> This choice was based on an O (N 2 ) simulation time proposed by Teller <ref> [9] </ref>. However, a little deliberation shows that even under idealistic circumstances the robot needs O (N ) time for each of the M = O (N 2 ) boxes, leading to an O (N 3 ) time requirement.
References-found: 9

