URL: http://www.isi.edu/natural-language/mt/amta94-integrating.ps
Refering-URL: http://www.isi.edu/natural-language/people/knight.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Integrating Knowledge Bases and Statistics in MT  
Author: f g Kevin Knight, Ishwar Chander, Matthew Haines, Vasileios Hatzivassiloglou, Eduard Hovy, Masayo Iida, Steve K. Luk, Akitoshi Okumura, Richard Whitney, Kenji Yamada 
Note: et al.  
Abstract: et al.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bateman, J. </author> <year> 1990. </year> <title> Upper modeling: Organizing knowledge for natural language processing. </title> <booktitle> In </booktitle> . 
Reference: <author> Berger, A.; Brown, P.; Della-Pietra, S.; Della-Pietra, V.; Gillett, J.; Lafferty, J.; Mercer, R.; Printz, H.; and Ures, L. </author> <year> 1994. </year> <title> The Candide system for machine translation. </title> <booktitle> In </booktitle> . 
Reference: <author> Brown, P. F.; Della-Pietra, S. A.; Della-Pietra, V. J.; and Mercer, R. L. </author> <year> 1993. </year> <title> The mathematics of statistical machine translation: Parameter estimation. </title> <type> 19(2). </type>
Reference-contexts: An R-component takes a set of structures of the same type, assigns each structure a score, then prunes away some number of low-scoring structures. For example, the statistical MT system Candide <ref> (Brown 1993) </ref> operates in a T-R-R fashion. A French string is transformed into many thousands of French-English string pairs. These translations are ranked and pruned first by a translation model, then by an English-only language model. Both rankers are "soft", never assigning a zero score.
Reference: <author> Carlson, L., and Nirenburg, S. </author> <year> 1990. </year> <title> World modeling for NLP. </title> <type> Technical Report CMU-CMT-90-121, </type> <institution> Center for Machine Translation, Carnegie Mellon University. </institution>
Reference-contexts: Semantic analysis has now given us a set of candidate meanings, in terms of concepts and relations from our knowledge base. This inventory of concepts is a synthesis of resources like the PENMAN Upper Model (Bate-man 1990), ONTOS <ref> (Carlson & Nirenburg 1990) </ref>, the WordNet thesaurus (Miller 1990), and the Longman Dictionary of Contemporary English (Longman-Group 1978). It contains roughly 70,000 terms organized into inheritance networks; (Knight & Luk 1994) describe its construction. The concept inventory and its functional interface are part of a system called SENSUS. <p> Again, we are pursuing both manual and automatic approaches. We have developed a constraint language for manually entered world knowledge. This language takes advantage of the SENSUS hierarchy, so that a single rule can cover a very large number of cases. The language allows for relaxed constraints <ref> (Carlson & Nirenburg 1990) </ref>, giving us a softer measure of violation. We are looking at ways to automatically identify semantic constraints using machine learning techniques. We are using untagged and concept-tagged corpora (single and dual-language) and the prior knowledge of SENSUS to learn which concepts co-occur in which configurations.
Reference: <author> Church, K. W., and Gale, W. A. </author> <year> 1991. </year> <title> A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams. </title> <booktitle> 5 </booktitle> <pages> 19-54. </pages>
Reference-contexts: The main runtime program accepts a word lattice from the generator (or glosser|see Section 3.10) and extracts the most likely path through that lattice. Likelihood is based on a word trigram model we built from online Wall Street Journal text. We use a version of enhanced Good-Turing smoothing <ref> (Church & Gale 1991) </ref> to assign non-zero probabilities to previously unseen trigrams. This form of smoothing is detailed enough to distinguish "good" unseen trigrams (e.g., ) from "bad" ones, even those composed of popular unigrams (e.g., ).
Reference: <editor> Dowty, D. R.; Wall, R.; and Peters, S. </editor> <address> 1981. . Dordrecht: </address> <publisher> Reidel. </publisher>
Reference-contexts: Moving up the parse trees, meanings of constituents are computed compositionally from the meanings of their children, according to a database of semantic combination rules. Semantic rules have the same format as syntactic rules; they are keyed to one another via their context-free parts, in the style of <ref> (Dowty, Wall, & Peters 1981) </ref> and (Moore 1989). Semantic rules look like: The current semantic rule base contains at least one rule for every syntactic rule in the grammar. The output of semantic analysis is represented in a number of ways.
Reference: <author> Hobbs, J. </author> <year> 1985. </year> <note> Ontological promiscuity. In </note> . 
Reference-contexts: The output of semantic analysis is represented in a number of ways. Inside the analyzer, semantic information takes the form of directed acyclic graphs. For semantic ranking, we view the graphs as lists of assertions, as in <ref> (Hobbs 1985) </ref>. We also use the SPL format of the PENMAN generation system (Penman 1989). Here is a sample output, representing the sentence "the new company plans to launch in February": : : : 3.5 Inference 3.6 Semantic Ranking (SENSUS) &lt;EAT-2, PATIENT, WORM-1&gt; &lt;EAT-2, AGENT, PERSON-1&gt; Ongoing research project.
Reference: <author> Knight, K., and Chander, I. </author> <year> 1994. </year> <title> Automated postediting of documents. </title> <booktitle> In </booktitle> . 
Reference-contexts: Ongoing research project. The acquisition of a large Japanese semantic lexicon is a difficult task. We are tackling this problem with a combination of automatic and manual techniques. (Okumura & Hovy 1994) and <ref> (Knight & Luk 1994) </ref> describe algorithms for using bilingual dictionaries to propose links between non-English words and concepts in a knowledge base. We have also built an interface called the Acquisitor, which allows a person to identify word-concept links by conceptually tagging words in context. <p> This inventory of concepts is a synthesis of resources like the PENMAN Upper Model (Bate-man 1990), ONTOS (Carlson & Nirenburg 1990), the WordNet thesaurus (Miller 1990), and the Longman Dictionary of Contemporary English (Longman-Group 1978). It contains roughly 70,000 terms organized into inheritance networks; <ref> (Knight & Luk 1994) </ref> describe its construction. The concept inventory and its functional interface are part of a system called SENSUS. The other part is a set of constraints on which concepts are naturally related to which others in our world. <p> The posteditor's knowledge is statistical, but its model is deeper than that of the trigram model discussed above. It organizes its knowledge into automatically generated decision trees that insert articles based on features of the surrounding context; <ref> (Knight & Chander 1994) </ref> has details.
Reference: <author> Knight, K., and Luk, S. K. </author> <year> 1994. </year> <title> Building a large-scale knowledge base for machine translation. </title> <booktitle> In </booktitle> . 
Reference-contexts: Ongoing research project. The acquisition of a large Japanese semantic lexicon is a difficult task. We are tackling this problem with a combination of automatic and manual techniques. (Okumura & Hovy 1994) and <ref> (Knight & Luk 1994) </ref> describe algorithms for using bilingual dictionaries to propose links between non-English words and concepts in a knowledge base. We have also built an interface called the Acquisitor, which allows a person to identify word-concept links by conceptually tagging words in context. <p> This inventory of concepts is a synthesis of resources like the PENMAN Upper Model (Bate-man 1990), ONTOS (Carlson & Nirenburg 1990), the WordNet thesaurus (Miller 1990), and the Longman Dictionary of Contemporary English (Longman-Group 1978). It contains roughly 70,000 terms organized into inheritance networks; <ref> (Knight & Luk 1994) </ref> describe its construction. The concept inventory and its functional interface are part of a system called SENSUS. The other part is a set of constraints on which concepts are naturally related to which others in our world. <p> The posteditor's knowledge is statistical, but its model is deeper than that of the trigram model discussed above. It organizes its knowledge into automatically generated decision trees that insert articles based on features of the surrounding context; <ref> (Knight & Chander 1994) </ref> has details.
Reference: <author> Lavie, A. </author> <year> 1994. </year> <title> An integrated heuristic scheme for partial parse evaluation. </title> <editor> In . Longman-Group., ed. </editor> <booktitle> 1978. </booktitle> . <publisher> Essex, UK: Longman. </publisher>
Reference-contexts: We strive for full parses whenever possible, because we cannot rely on deep semantics to patch everything up. Since one unanticipated word or punctuation mark may splinter the input into four or five pieces, we are working on techniques for word-skipping, inspired in part by <ref> (Lavie 1994) </ref>. We are investigating methods to repair trouble spots in grammatical analysis. In particular, we are looking at statistical differences between fully-parsed and not-fully-parsed sentences. These differences include relative distributions of part-of-speech bigrams.
Reference: <author> Miller, G. </author> <year> 1990. </year> <title> Wordnet: An on-line lexical database. </title> <type> 3(4). </type> <note> (Special Issue). </note>
Reference-contexts: Semantic analysis has now given us a set of candidate meanings, in terms of concepts and relations from our knowledge base. This inventory of concepts is a synthesis of resources like the PENMAN Upper Model (Bate-man 1990), ONTOS (Carlson & Nirenburg 1990), the WordNet thesaurus <ref> (Miller 1990) </ref>, and the Longman Dictionary of Contemporary English (Longman-Group 1978). It contains roughly 70,000 terms organized into inheritance networks; (Knight & Luk 1994) describe its construction. The concept inventory and its functional interface are part of a system called SENSUS.
Reference: <author> Moore, R. </author> <year> 1989. </year> <title> Unification-based semantic interpretation. </title> <booktitle> In </booktitle> . 
Reference-contexts: Semantic rules have the same format as syntactic rules; they are keyed to one another via their context-free parts, in the style of (Dowty, Wall, & Peters 1981) and <ref> (Moore 1989) </ref>. Semantic rules look like: The current semantic rule base contains at least one rule for every syntactic rule in the grammar. The output of semantic analysis is represented in a number of ways. Inside the analyzer, semantic information takes the form of directed acyclic graphs.
Reference: <author> Nirenburg, S., and Frederking, R. </author> <year> 1994. </year> <title> Toward multi-engine machine translation. </title> <booktitle> In </booktitle> . 
Reference: <author> Nirenburg, S.; Carbonell, J.; Tomita, M.; and Goodman, K. </author> <booktitle> 1992. </booktitle> . <address> San Mateo, Calif.: </address> <publisher> Morgan Kaufmann. </publisher> <editor> NMSU/CRL; USC/ISI; and CMU/CMT. </editor> <year> 1994. </year> <title> The Pangloss Mark III machine translation system. </title> <type> Technical report, </type> <institution> Carnegie Mellon University. </institution>
Reference: <author> Nyberg, E., and Mitamura, T. </author> <year> 1992. </year> <title> The KANT system: Fast, accurate, high-quality translation in practical domains. </title> <booktitle> In </booktitle> . 
Reference: <author> Okumura, A., and Hovy, E. </author> <year> 1994. </year> <title> Ontology concept association using a bilingual dictionary. </title> <booktitle> In . Penman. </booktitle> <year> 1989. </year> <title> The Penman documentation. </title> <type> Technical report, </type> <institution> USC/Information Sciences Institute. </institution>
Reference-contexts: Ongoing research project. The acquisition of a large Japanese semantic lexicon is a difficult task. We are tackling this problem with a combination of automatic and manual techniques. <ref> (Okumura & Hovy 1994) </ref> and (Knight & Luk 1994) describe algorithms for using bilingual dictionaries to propose links between non-English words and concepts in a knowledge base. We have also built an interface called the Acquisitor, which allows a person to identify word-concept links by conceptually tagging words in context.
Reference: <author> Shieber, S. </author> <year> 1986. </year> . <institution> University of Chicago. </institution> <note> Also, CSLI Lecture Notes Series. </note>
Reference-contexts: (((X1 map object-role) =c X2)) (((X1 map object2-role) =c X2)))) (|h-709| / |have as a goal| :SENSER (|c-710| / |company/business| :Q-MOD (|n-711| / |new~virgin|)) :PHENOMENON (|f-712| / |found, launch| :TEMPORAL-LOCATING (|c-713| / |calendar month| :MONTH-INDEX 2) :AGENT |c-710|) :THEME |c-710|) grammar augmented with unification feature equations, in the style of <ref> (Shieber 1986) </ref>. HAX grammars may contain complex disjunctions of equations, exclusive-or disjunctions, feature existence checking, and simple negation. Our current grammar of Japanese contains 71 unary rules, 32 binary rules, and 15 n-ary rules.
Reference: <author> Yamron, J.; Cant, J.; Demedts, A.; Dietzel, T.; and Ito, Y. </author> <year> 1994. </year> <title> The automatic component of the LINGSTAT machine-aided translation system. </title> <booktitle> In </booktitle> . 
Reference-contexts: A French string is transformed into many thousands of French-English string pairs. These translations are ranked and pruned first by a translation model, then by an English-only language model. Both rankers are "soft", never assigning a zero score. The final pruning leaves only a single translation. The LINGSTAT system <ref> (Yamron 1994) </ref>, works with a T-R-T-R design. The first T-component transforms a Japanese sentence into many possible parse trees, as stipulated by a context-free grammar. A statistical ranker chooses one "best" tree and prunes the rest.
References-found: 18

