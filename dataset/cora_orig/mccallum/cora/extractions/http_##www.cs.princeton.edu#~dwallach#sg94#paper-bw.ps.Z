URL: http://www.cs.princeton.edu/~dwallach/sg94/paper-bw.ps.Z
Refering-URL: http://www.cs.princeton.edu/~dwallach/sg94/
Root-URL: http://www.cs.princeton.edu
Email: dwallach@cs.princeton.edu sgk@cs.princeton.edu mfc@cs.princeton.edu  
Title: Accelerated MPEG Compression of Dynamic Polygonal Scenes  
Author: Dan S. Wallach Sharma Kunapalli Michael F. Cohen 
Keyword: CR Categories and Subject Descriptors: I.2.10 [Artificial Intelligence]: Vision and Scene Understanding; I.3.3 [Computer Graphics]: Picture/Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism; I.4.2 [Image Processing]: Compression (coding) Additional Key Words: MPEG; optical flow; motion prediction.  
Affiliation: Department of Computer Science Princeton University  
Abstract: This paper describes a methodology for using the matrix-vector multiply and scan conversion hardware present in many graphics workstations to rapidly approximate the optical flow in a scene. The optical flow is a 2-dimensional vector field describing the on-screen motion of each pixel. An application of the optical flow to MPEG compression is described which results in improved compression with minimal overhead. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Akeley, K. </author> <title> RealityEngine Graphics. </title> <booktitle> In Computer Graphics (Aug. </booktitle> <year> 1993), </year> <pages> pp. 109-116. </pages>
Reference-contexts: We can modify this process to encode the pixel's previous location as its texture value. The optical flow vector will then simply be the difference between this value and the new pixel location. This process can be accomplished using current texture mapping hardware <ref> [1] </ref> in real-time. The algorithm runs as follows: the polygon's previous and current homogeneous coordinates are used to derive a texture matrix which maps between them.
Reference: [2] <author> Chen, S. E., and Williams, L. </author> <title> View Interpolation for Image Synthesis. </title> <booktitle> In Computer Graphics (Aug. </booktitle> <year> 1993), </year> <pages> pp. 279-288. </pages>
Reference-contexts: Optical flow has been used in computer vision [5, 8] and video compression [6]. It could also be useful for temporal anti-aliasing, providing information for the temporal sampling pattern [12] and for computing the morph map as discussed in <ref> [2] </ref>. After a short discussion of the optical flow computation itself, this paper outlines experiments using the motion information to enhance MPEG compression 2 .
Reference: [3] <author> Guenter, B. K., Yun, H. C., and Mersereau, R. M. </author> <title> Motion Compensated Compression of Computer Animation Frames. </title> <booktitle> In Computer Graphics (Aug. </booktitle> <year> 1993), </year> <pages> pp. 297-304. </pages>
Reference-contexts: shading then rapidly 1 The term motion field is sometimes used to distinguish actual motion from apparent motion, e.g., a smooth shiny ball spinning in place in an otherwise static environment is moving but the motion won't be visible. 2 CAD-based geometrical information has been used in other compression methods <ref> [3] </ref>, however, with the increasing acceptance of the MPEG standard, there is interest in improving MPEG encoding itself. produces an approximate rendering of the optical flow of each pixel. Workstations equipped with texture mapping hardware can create a more accurate optical flow image.
Reference: [4] <author> Heckbert, P. S. </author> <title> Fundamentals of Texture Mapping and Image Warping. </title> <type> Master's thesis, </type> <institution> University of California, Berkeley, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: To be more precise, each pixel would need to be transformed from the current frame to the previous frame, rather than just the vertices. The function to compute this transformation is a projective mapping <ref> [4] </ref>. Projective texture mapping normally utilizes an affine transformation from homogeneous coordinates to texture coordinates. For each polygon, the texture coordinates of the vertices are trans formed by the texture matrix resulting in the indices into the texture map.
Reference: [5] <author> Horn, B. K. P. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Another use is described here, that of "rendering" an optical flow image 1 , that is, an image in which the color of each pixel represents the motion occurring at that location in the image. Optical flow has been used in computer vision <ref> [5, 8] </ref> and video compression [6]. It could also be useful for temporal anti-aliasing, providing information for the temporal sampling pattern [12] and for computing the morph map as discussed in [2].
Reference: [6] <institution> Coded Representation of Picture, </institution> <note> Audio and Multimedia/Hypermedia Information. Committee Draft of Standard ISO/IEC 11172, </note> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Another use is described here, that of "rendering" an optical flow image 1 , that is, an image in which the color of each pixel represents the motion occurring at that location in the image. Optical flow has been used in computer vision [5, 8] and video compression <ref> [6] </ref>. It could also be useful for temporal anti-aliasing, providing information for the temporal sampling pattern [12] and for computing the morph map as discussed in [2]. <p> For introductory information on MPEG, see <ref> [6, 7, 10] </ref>. MPEG exploits the general similarity of adjacent picture frames by using motion vectors for each 16fi16 pixel macroblock to point to another 16fi16 block in a previous or future frame. The MPEG coder records the motion vector itself and the differences between previous and current pixels. <p> The literature on motion searching [9] discusses methods to reduce the number and/or cost of comparisons between blocks. Some well-known search techniques are: * Exhaustive select the best motion vector within a 2N fi2N pixel square of pixels (best compression, but slow) * Logarithmic <ref> [6] </ref> first check the corners, sides, and center of a 2N fi2N pixel square range, and recursively (until N = 0) repeat the procedure with the best result as the new center and N decremented (fast, but may overlook good solutions) * Subsample [13] rather than comparing whole macroblocks, only a
Reference: [7] <author> Legall, D. </author> <title> MPEG A Video Compression Standard for Multimedia Applications. </title> <type> CACM 34, </type> <month> 4 (Apr. </month> <year> 1991), </year> <pages> 46-58. </pages>
Reference-contexts: For introductory information on MPEG, see <ref> [6, 7, 10] </ref>. MPEG exploits the general similarity of adjacent picture frames by using motion vectors for each 16fi16 pixel macroblock to point to another 16fi16 block in a previous or future frame. The MPEG coder records the motion vector itself and the differences between previous and current pixels.
Reference: [8] <author> Nagel, H. </author> <title> On the Estimation of Optical Flow: Relations Between Different Approaches And Some New Results. </title> <booktitle> In Artificial Intelligence (1987), </booktitle> <volume> vol. 33, </volume> <pages> pp. 299-324. </pages>
Reference-contexts: Another use is described here, that of "rendering" an optical flow image 1 , that is, an image in which the color of each pixel represents the motion occurring at that location in the image. Optical flow has been used in computer vision <ref> [5, 8] </ref> and video compression [6]. It could also be useful for temporal anti-aliasing, providing information for the temporal sampling pattern [12] and for computing the morph map as discussed in [2].
Reference: [9] <author> Orchard, M. </author> <title> A Comparison of Techniques for Estimating Block Motion in Image Sequence Coding. </title> <booktitle> In Proceedings SPIE, Visual Comm. and Image Proc. I (1989), </booktitle> <volume> vol. 1199, </volume> <pages> pp. 248-258. </pages>
Reference-contexts: I B PB B B I... The literature on motion searching <ref> [9] </ref> discusses methods to reduce the number and/or cost of comparisons between blocks.
Reference: [10] <author> Patel, K., Smith, B. C., and Rowe, L. A. </author> <title> Performance of a Software MPEG Video Decoder. </title> <booktitle> In Multimedia '93 Proceedings (Aug. 1993), ACM, </booktitle> <publisher> Addison-Wesley, </publisher> <pages> pp. 75-82. </pages>
Reference-contexts: For introductory information on MPEG, see <ref> [6, 7, 10] </ref>. MPEG exploits the general similarity of adjacent picture frames by using motion vectors for each 16fi16 pixel macroblock to point to another 16fi16 block in a previous or future frame. The MPEG coder records the motion vector itself and the differences between previous and current pixels.
Reference: [11] <author> Rowe, L. A., Gong, K., Patel, K., and Wallach, D. </author> <note> MPEG-1 Video Software Encoder. Anonymous ftp mm-ftp.cs.berkeley.edu:/pub/multimedia/mpeg/ mpeg encode-1.3.tar.Z, </note> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: This technique should improve any block matching scheme with limited search range. Modifications to the Berkeley MPEG encoder's <ref> [11] </ref> exhaustive search algorithm were made to measure the effects of shifting the center of the search range. The motion prediction for a mac-roblock is taken as the mode of the associated 16fi16 array of optical flow data.
Reference: [12] <author> Shinya, M. </author> <title> Spatial Anti-aliasing for Animation Sequences with Spatio-temporal Filtering. </title> <booktitle> In Computer Graphics (Aug. </booktitle> <year> 1993), </year> <pages> pp. 289-296. </pages>
Reference-contexts: Optical flow has been used in computer vision [5, 8] and video compression [6]. It could also be useful for temporal anti-aliasing, providing information for the temporal sampling pattern <ref> [12] </ref> and for computing the morph map as discussed in [2]. After a short discussion of the optical flow computation itself, this paper outlines experiments using the motion information to enhance MPEG compression 2 .
Reference: [13] <author> Zaccarin, A., and Liu, B. </author> <title> Fast Algorithms for Block Motion Estimation. </title> <booktitle> In Proceedings ICASSP'92 (Mar. </booktitle> <year> 1992), </year> <pages> pp. </pages> <address> III-449 - III-452. </address>
Reference-contexts: pixels (best compression, but slow) * Logarithmic [6] first check the corners, sides, and center of a 2N fi2N pixel square range, and recursively (until N = 0) repeat the procedure with the best result as the new center and N decremented (fast, but may overlook good solutions) * Subsample <ref> [13] </ref> rather than comparing whole macroblocks, only a fraction of the pixels in each macroblock are com pared (fast, but may mistake a bad match as a good one) Under normal circumstances, each algorithm centers its search range on the origin, assuming equal likelihood of motion in any direction. 4 Optical
References-found: 13

