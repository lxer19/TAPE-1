URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1991/tr-91-048.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1991.html
Root-URL: http://www.icsi.berkeley.edu
Title: ICSIM: An Object-Oriented Connectionist Simulator gives an overview of the simulator. Its main concepts, the
Author: Heinz W. Schmidt Ben Gomes 
Note: The report  are defined.  
Affiliation: ICSI, Berkeley, California  
Abstract: ICSIM is a connectionist net simulator being developed at ICSI and written in Sather. It is object-oriented to meet the requirements for flexibility and reuse of homogeneous and structured connectionist nets and to allow the user to encapsulate efficient customized implementations perhaps running on dedicated hardware. Nets are composed by combining off-the-shelf library classes and if necessary by specializing some of their behaviour. General user interface classes allow a uniform or customized graphic presentation of the nets being modeled. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Alexander, I (ed.): </editor> <booktitle> Neural Computing Architectures: The design of brain-like machines. </booktitle> <address> Cambridge: </address> <publisher> MIT Press, </publisher> <year> 1989 </year>
Reference-contexts: Flexibility is essential, due to the different mathematical models underlying neural nets, the different network architectures and applications and also due to the experimental character of most research projects (cf. e.g. <ref> [12, 15, 9, 1, 16] </ref>). Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. [8, 11, 3]).
Reference: [2] <author> Coss, R.G., and Perkel, D.H.: </author> <title> The function of dendritic spines: a review of theoretical issues. </title> <journal> Behavioural and Neural Biology, </journal> <volume> 44, </volume> <pages> pp. </pages> <month> 151-185 </month> <year> (1985) </year>
Reference-contexts: In this way users can customize interconnection structure on a high level amore 2 Physiologically, many neurons have multiple connections with adjacent neurons and the activation of these synaptic connections depends on learning such that there is the possibility of many different non-linear interactions between the same two neurons <ref> [2] </ref>. 8 Skipped psfile= ps/output-object.ps convenient way than programming in terms of the internal connection primitives of the different net classes. To interpret a connection request at the various levels in the hierarchy, ICSIM supports general routines Any Model::connectp, Inputs::which site, and Any Link::initial weight.
Reference: [3] <author> D'Autrechy, C.L. et al: </author> <title> A general-purpose simulation environment for develping connectionist models. </title> <booktitle> Simulation 51, </booktitle> <volume> 1, </volume> <pages> pp. 5-19 </pages>
Reference-contexts: Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. <ref> [8, 11, 3] </ref>). Efficiency is equally important; the simulation of the massively parallel nets, for instance in real-time speech recognition, may take hours on sequential machines. <p> Finally the abstract data type paradigm embodied in object-oriented languages provides acceptable high-level mechanisms that have advantages over special purpose languages for declaring net topology and interconnections (e.g. <ref> [10, 3] </ref>). In the near future, we expect network sizes in the range of some hundreds of thousands of units. Although larger nets are conceivable theoretically and, as nature suggests, realistic, the technology to deal with heterogeneous nets of such size does not yet exist.
Reference: [4] <author> Fahlman, S. and Lebiere, C. </author> <title> "The Cascade-Correlation Learning Architecture". </title> <type> Carnegie-Mellon Report CMU-CS-90-100, </type> <year> 1990 </year>
Reference: [5] <author> Fahlman, S. </author> <title> "Faster-Learning Variations on Back-Propagation: An Empirical Study". </title> <booktitle> In: Proc. of the 1988 Connectionist Models Summer School, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988 </year>
Reference-contexts: The input layer is fully connected to the output layer. The connections to the output layer are trained using some form of gradient descent - quickprop <ref> [5] </ref> is a fast second order method to achieve this. <p> As pointed out above, sometimes computation can be expressed in either a local or a global form. The cascade correlation example defines three main classes of units the Qp Unit, the Corr Unit and the Corr Output Unit. Qp Unit implements the quickprop algorithm <ref> [5] </ref>, by inheriting from backprop and modifying the weight update method. The create routine must also be modified in order to take into account the extra parameters and arrays that the quickprop unit requires.
Reference: [6] <author> Feldman, J.A. and Ballard, D.H.: </author> <title> Connectionist models and their properties. </title> <journal> Cognitive Science, </journal> <volume> 6, </volume> <pages> pp. 205-254 </pages>
Reference-contexts: For instance, for many of our instantiable library units the potential is the weighted sum of inputs. Different types of units may have different additional attributes to model more complex states and state transitions. In some models <ref> [6, 14] </ref>, a unit has a mode represented by a value in a small range of integers that represent different phases of computation. We subsume all the related accessor functionality of classes under the general term state.
Reference: [7] <author> Feldman, J.A. et al: </author> <title> Computing with Structured Connectionist Networks, </title> <journal> CACM 31, </journal> <volume> 2, </volume> <pages> pp. 170-187, </pages> <year> (1988) </year>
Reference-contexts: A specific choice of a compact data representation on the subnet level will typically require a specific way to implement the computation of the net. Also, modeling a specific computation mode of a net may require departure from a pure compositional semantics. For instance, structured connectionist nets <ref> [7, 14, 11] </ref>, that model semantic networks, will usually require special computation modes to implement mechanisms like variable-binding, token passing or inference steps. Our hierarchy of net classes is designed to allow the user to form subclasses in such a situation.
Reference: [8] <author> Goddard, N.: </author> <title> The Rochester Connectionist Simulator: User Manual, </title> <type> TR, </type> <institution> Univ. Rochester, </institution> <year> 1987 </year>
Reference-contexts: Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. <ref> [8, 11, 3] </ref>). Efficiency is equally important; the simulation of the massively parallel nets, for instance in real-time speech recognition, may take hours on sequential machines. <p> Efficiency is equally important; the simulation of the massively parallel nets, for instance in real-time speech recognition, may take hours on sequential machines. Existing simulators like the Rochester simulator <ref> [8] </ref> or Genesis [17] lack the ability to deal with nets in a modular fashion supporting the partial reuse of existing prototype nets.
Reference: [9] <author> Hecht-Nielson, R.: </author> <title> Neurocomputing: Picking the Human Brain. </title> <journal> IEEE Spectrum, </journal> <month> March </month> <year> 1988, </year> <pages> pp. 36-41 </pages>
Reference-contexts: Flexibility is essential, due to the different mathematical models underlying neural nets, the different network architectures and applications and also due to the experimental character of most research projects (cf. e.g. <ref> [12, 15, 9, 1, 16] </ref>). Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. [8, 11, 3]).
Reference: [10] <author> Korb, T., Zell, A.: </author> <title> A declarative neural network decription language. Microprocessing and Microprogramming 27, </title> <publisher> North-Holland, </publisher> <pages> pp. </pages> <month> 181-188 </month> <year> (1989) </year>
Reference-contexts: Finally the abstract data type paradigm embodied in object-oriented languages provides acceptable high-level mechanisms that have advantages over special purpose languages for declaring net topology and interconnections (e.g. <ref> [10, 3] </ref>). In the near future, we expect network sizes in the range of some hundreds of thousands of units. Although larger nets are conceivable theoretically and, as nature suggests, realistic, the technology to deal with heterogeneous nets of such size does not yet exist.
Reference: [11] <author> Lange, T.E. et al.: </author> <title> DESCARTES: Development Environment for Simulating Hybrid Connectionist Architectures. </title> <type> TR UCLA-AI-89-16, </type> <institution> Los Angelos: UCLA, </institution> <year> 1989 </year> <month> 27 </month>
Reference-contexts: Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. <ref> [8, 11, 3] </ref>). Efficiency is equally important; the simulation of the massively parallel nets, for instance in real-time speech recognition, may take hours on sequential machines. <p> A specific choice of a compact data representation on the subnet level will typically require a specific way to implement the computation of the net. Also, modeling a specific computation mode of a net may require departure from a pure compositional semantics. For instance, structured connectionist nets <ref> [7, 14, 11] </ref>, that model semantic networks, will usually require special computation modes to implement mechanisms like variable-binding, token passing or inference steps. Our hierarchy of net classes is designed to allow the user to form subclasses in such a situation.
Reference: [12] <author> McClelland, J. L., Rumelhart, D. E., </author> <title> and the PDP research group: </title> <booktitle> Parallel distributed processing: Foundations. </booktitle> <address> Cambridge, MA: </address> <publisher> Bradford Books, </publisher> <year> 1986 </year>
Reference-contexts: Flexibility is essential, due to the different mathematical models underlying neural nets, the different network architectures and applications and also due to the experimental character of most research projects (cf. e.g. <ref> [12, 15, 9, 1, 16] </ref>). Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. [8, 11, 3]).
Reference: [13] <author> Omohundro, S.: </author> <title> The Sather Language. </title> <type> TR, </type> <institution> Berkeley: ICSI, </institution> <note> to appear, </note> <year> 1990. </year>
Reference-contexts: The current focus of the design is on the structure of the class libraries and, to some extent, on the separation and interaction between the simulator proper and the user interface objects. The simulator is written in Sather <ref> [13] </ref>, after initial prototype implementations in Common Lisp and Eiffel. The design tries to assist the specialist scientific community in teaching and research in artificial neural networks. We envisage three types of `users' to ICSIM that possess increasing programming skills: 1.
Reference: [14] <author> Shastri, L. and Ajjanagadde, V.: </author> <title> From associations to systematic reasoning. </title> <type> TR, </type> <institution> Philadelphia: Univ. of Pennsylvania, </institution> <year> 1989 </year>
Reference-contexts: A specific choice of a compact data representation on the subnet level will typically require a specific way to implement the computation of the net. Also, modeling a specific computation mode of a net may require departure from a pure compositional semantics. For instance, structured connectionist nets <ref> [7, 14, 11] </ref>, that model semantic networks, will usually require special computation modes to implement mechanisms like variable-binding, token passing or inference steps. Our hierarchy of net classes is designed to allow the user to form subclasses in such a situation. <p> For instance, for many of our instantiable library units the potential is the weighted sum of inputs. Different types of units may have different additional attributes to model more complex states and state transitions. In some models <ref> [6, 14] </ref>, a unit has a mode represented by a value in a small range of integers that represent different phases of computation. We subsume all the related accessor functionality of classes under the general term state.
Reference: [15] <author> Waltz, D., Feldman J.A. (eds): </author> <title> Connectionist models and their implications: </title> <booktitle> readings from cognitive science. </booktitle> <address> Norwood, N.J.: </address> <publisher> Ablex Pub. Corp., </publisher> <year> 1988. </year>
Reference-contexts: Flexibility is essential, due to the different mathematical models underlying neural nets, the different network architectures and applications and also due to the experimental character of most research projects (cf. e.g. <ref> [12, 15, 9, 1, 16] </ref>). Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. [8, 11, 3]).
Reference: [16] <author> Wassermann, </author> <title> P.D.: </title> <booktitle> Neural Computing: Theory and Praxis. </booktitle> <address> New York: </address> <publisher> Van Nostrand Reinhold, </publisher> <year> 1989 </year>
Reference-contexts: Flexibility is essential, due to the different mathematical models underlying neural nets, the different network architectures and applications and also due to the experimental character of most research projects (cf. e.g. <ref> [12, 15, 9, 1, 16] </ref>). Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. [17]) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. [8, 11, 3]).
Reference: [17] <author> Wilson, M.A. et al.: </author> <title> Genesis: A system for simulating neural networks. </title> <note> Proc. of '89 NIPS conf., also TR: </note> <institution> Pasadena: Cal. Inst. of Tech., </institution> <year> 1989 </year>
Reference-contexts: Different simulators serve different purposes ranging from modeling bio-chemical processes in the human brain (e.g. <ref> [17] </ref>) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. [8, 11, 3]). Efficiency is equally important; the simulation of the massively parallel nets, for instance in real-time speech recognition, may take hours on sequential machines. Existing simulators like the Rochester simulator [8] or Genesis [17] lack <p> (e.g. <ref> [17] </ref>) to developing structured connectionist models of artificial memory, recognition and reasoning processes (e.g. [8, 11, 3]). Efficiency is equally important; the simulation of the massively parallel nets, for instance in real-time speech recognition, may take hours on sequential machines. Existing simulators like the Rochester simulator [8] or Genesis [17] lack the ability to deal with nets in a modular fashion supporting the partial reuse of existing prototype nets.
Reference: [18] <author> Wilson, M.A. et al.: Genesis&XODUS: </author> <title> General Purpose Neural Network Simulation Tool. </title> <booktitle> Proc. of '89 USENIX conf., </booktitle> <institution> also TR: Pasadena: Cal. Inst. of Tech., </institution> <year> 1989 </year> <month> 28 </month>
Reference-contexts: Otherwise, in a non-incremental environment, these long runs tend to repeat essentially the same problems as the edit-compile-debug cycle in the batch-orieted style of programming in the seventieth. For instance, in the development of the Genesis simulator this need was specifically addressed by an intermediate shell language interpreter <ref> [18] </ref> and in the Rochester simulator a special linker/loader was developed to support a kind of dynamic binding of binary code for the same reason. We believe that most of the above requirements related to extensibility, reuse and in-crementality can be met by an object-oriented design of the simulator.
References-found: 18

