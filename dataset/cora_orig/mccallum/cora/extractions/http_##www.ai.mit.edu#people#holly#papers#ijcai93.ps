URL: http://www.ai.mit.edu/people/holly/papers/ijcai93.ps
Refering-URL: http://www.ai.mit.edu/people/holly/papers/papers.html
Root-URL: 
Email: holly@ai.mit.edu  
Phone: (617)253-7884  
Title: Development of a Context Dependent Robot Language:  
Note: lation of the experiment are presented.  
Address: 545 Technology Square, Room 741 Cambridge, MA 02139  
Affiliation: Artificial Intelligence Laboratory Massachusetts Institute of Technology  
Abstract: Preliminary Results Abstract The meaning of a word in a context dependent language is determined using the context in which it is spoken. In this paper, we will describe how a group of autonomous agents can develop a context dependent language by using their sensor readings to provide context. Results from a computer simu 
Abstract-found: 1
Intro-found: 1
Reference: [Kaelbling, 1990] <author> Leslie Pack Kaelbling. </author> <title> Learning in em-bedded systems. </title> <type> Technical Report TR-90-04, </type> <institution> Teleos Research, Palo Alto, California, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: The followers need to learn the appropriate action to perform according to the leader's signal. The instructor provides task based reinforcement; all robots must perform the appropriate action in order for the group to receive positive reinforcement. The reinforcement learning algorithm we are using is Kaelbling's Interval Estimation <ref> [Kaelbling, 1990] </ref>. In the context dependent extension to the experiment, the agents take into account a sensor-reading vector when considering the meaning of a signal (either from the trainer or the leader). Once again, the agents need to map signals (or words) to actions (or meanings for the words).
Reference: [Yanco and Stein, 1993] <author> Holly Yanco and Lynn Andrea Stein. </author> <title> An adaptive communication protocol for coop-erating mobile robots. </title> <booktitle> In From Animals to Animats: Proceedings of the Second International Conference on the Simulation of Adaptive Behavior, </booktitle> <pages> pages 478-485. </pages> <publisher> The MIT Press/Bradford Books, </publisher> <year> 1993. </year>
Reference-contexts: number of signals that the robots can send, sensor i is one of the sensors being used to determne context, and values i is the number of values that sensor i can have. 2 Simulation The experiments performed in this paper are based upon a language learning experiment described in <ref> [Yanco and Stein, 1993] </ref>. Two agents learn to communicate with each other in the presence of a trainer. A signal given by the trainer, which we call the human signal, is heard by one of the agents who is acting as the leader. <p> Convergence Basic Num of Iterations to Convergence - CD Actions Average Minimum Maximum Average Minimum Maximum 4 340.48 53 990 219.34 68 555 20 232267.82 44196 1241767 51860.30 21853 105632 Table 2: Comparison between learning times for basic language learning (where each signal maps to one action as described in <ref> [Yanco and Stein, 1993] </ref>) and learning times for context dependent language learning. Each experiment was run 100 times using two agents. signals for the robots to create a one-to-one mapping between signals and actions. <p> In this experiment, the agents are learning the optimal language, which we define to use the fewest number of words to encode the number of actions. A comparison between learning times for a basic language experiment <ref> [Yanco and Stein, 1993] </ref> and for the context dependent language experiment is given in Ta- ble 2. Note that learning times for the context dependent language are significantly shorter than for the basic language (where each signal maps to one meaning). <p> When the sensor data is irrelevant, the robots will still converge upon the solution. However, it takes longer than the case where no sensor data is given; a two robot, two signal, two action experiment described in <ref> [Yanco and Stein, 1993] </ref> has an average convergence time of 15:24. In an experiment with two agents, two signals, two actions and two sensor values, the average convergence time is 91:26. <p> The sensor values are paired with the signals and used as the input. Later experiments will test the abilities of the robots to learn this capability. The experiments have only been performed in simulation. The next step is moving them to the robots. The robot hardware is described in <ref> [Yanco and Stein, 1993] </ref>. Context is provided by actual sensor readings on the robots rather than from a simulated sensor vector. Dif- ferent areas in the world have various characteristics that the robots are able to detect with their sensors.
References-found: 2

