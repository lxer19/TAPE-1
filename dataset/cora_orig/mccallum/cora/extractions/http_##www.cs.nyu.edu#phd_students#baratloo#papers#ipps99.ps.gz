URL: http://www.cs.nyu.edu/phd_students/baratloo/papers/ipps99.ps.gz
Refering-URL: http://www.cs.nyu.edu/phd_students/baratloo/html/publications.html
Root-URL: http://www.cs.nyu.edu
Email: fbaratloo,ayali,kedem,yuanyuang@cs.nyu.edu  
Title: Mechanisms for Just-in-Time Allocation of Resources to Adaptive Parallel Programs  
Author: Arash Baratloo Ayal Itzkovitz Zvi M. Kedem Yuanyuan Zhao 
Address: New York University 251 Mercer Street New York, NY 10012-1185, USA  
Affiliation: Department of Computer Science Courant Institute of Mathematical Sciences  
Abstract: Adaptive parallel computationscomputations that can adapt to changes in resource availability and requirementcan effectively use networked machines because they dynamically expand as machines become available and dynamically acquire machines as needed. While most parallel programming systems provide the means to develop adaptive programs, they do not provide any functional interface to external resource management systems. Thus, no existing resource management system has the capability to manage resources on COTS system software, arbitrating the demands of multiple adaptive computations written using diverse programming environments. Indeed, systems such as DRMS require that programs be modified and tightly integrated with the operating system; others, such as Piranha, Condor/CARMI, and MPVM, are tightly integrated with the programming system they support. Their inability to support more than one programming system severely limits their applicability. This paper presents a set of novel mechanisms that facilitate dynamic allocation of resources to adaptive parallel computations. The mechanisms are built on low-level features common to many programming systems, and unique in their ability to transparently manage adaptive parallel programs that were not developed to have their resources managed by external systems. We also describe the design and the implementation of the initial prototype of ResourceBroker, a resource management system built to validate these mechanisms. This prototype is the first system that can support adaptive programs written in more than one programming system, and has been tested using a mix of programs written in PVM, MPI, Calypso, and PLinda. Performance results show that the prototype's runtime overhead is negligible. fl New York University & Technion
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal and E. Ezzat. </author> <title> Location independent remote execution in NEST. </title> <journal> IEEE Transactions on Software Engineering, </journal> <year> 1987. </year> <month> 18 </month>
Reference-contexts: To use their services, users submit programs to the underlying system for execution. The system then selects the machines to execute those programs. Executing programs' terminal IO are generally redirected to provide the user with the output of the remotely executing program. Systems like NEST <ref> [1] </ref>, V [34], Sprite [11], MOSIX [3], and Remote Unix [25] provide such a service at the operating system level. Coshell [16] provides a similar service, not as a part of the operating system but as a Unix shell. The only privilege Coshell requires is rsh access to remote hosts.
Reference: [2] <author> R. Arpaci, A. Dusseau, L. Vahdat, L. Liu, T. Anderson, and D. Patterson. </author> <title> The interaction of parallel and sequential workloads on a network of workstations. </title> <booktitle> In SIGMETRICS, </booktitle> <year> 1995. </year>
Reference-contexts: Hence, we were anticipating that excess resources would eliminate contention. Our findings indicate that in order to achieve the 2:1 rule reported by Arpaci et al. <ref> [2] </ref>, that a NOW [Networks Of Workstations] cluster of approximately 60 machines can easily sustain a 32-node parallel workload in addition to the sequential load placed upon it by interactive users, intelligent allocation of resources is necessary. <p> An overview of selected resource management systems, with an emphasis on resource allocation for adaptive jobs, is given in Secion 8. Section 9 concludes the paper. 2 Background On networks of machines that support both parallel jobs and interactive users, machine loads change over time. A number of studies <ref> [30, 34, 11, 28, 2, 9] </ref> indicate that in most institutions up to 60% of machines are idle at any given time. <p> The performance of parallel programs is very sensitive to machine loads and availability. Parallel programs with interdependent components cannot make progress if some of the participating machines become unavailable or heavily loaded during a computation. In the experiments conducted by Arpaci et al. <ref> [2] </ref>, when machines were shared by two parallel jobs, the jobs were slowed 2 down by at least a factor of eight, and for some by a factor of 50. <p> Under such systems, when a machine becomes busy, process executing on that machine are migrated to a remote underloaded remote machine. Although it has been argued that process checkpointing and migration is not effective for parallel jobs <ref> [2, 24] </ref>, the literature is still undecided on this subject [12]. A dynamic allocation of machines to jobs is more effective if machine-loads, as well as the job resource requirements, can change over time.
Reference: [3] <author> A. Barak, S. Guday, and R. Wheller. </author> <title> The MOSIX distributed operating system load balancing for Unix. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The system then selects the machines to execute those programs. Executing programs' terminal IO are generally redirected to provide the user with the output of the remotely executing program. Systems like NEST [1], V [34], Sprite [11], MOSIX <ref> [3] </ref>, and Remote Unix [25] provide such a service at the operating system level. Coshell [16] provides a similar service, not as a part of the operating system but as a Unix shell. The only privilege Coshell requires is rsh access to remote hosts.
Reference: [4] <author> A. Baratloo, P. Dasgupta, and Z. M. Kedem. Calypso: </author> <title> A novel software system for fault-tolerant parallel processing on distributed platforms. </title> <booktitle> In Proceedings of IEEE International Symposium on High-Performance Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: Second, they can acquire machines as their requirements grow, rather than reserving the largest pool of machines required at any single instance during their execution. Most master-slave PVM [17] programs, self-scheduling MPI [19] programs, bag-of-tasks Linda [5] programs, and all Calypso <ref> [4] </ref> programs are adaptive. For PVM, MPI, and Linda, programs must be written so that they are able to tolerate machine removals; whereas for Calypso, this service is provided by the runtime layer.
Reference: [5] <author> N. Carriero and D. Gelernter. </author> <title> Linda in context. </title> <journal> Communication of ACM, </journal> <year> 1989. </year>
Reference-contexts: Second, they can acquire machines as their requirements grow, rather than reserving the largest pool of machines required at any single instance during their execution. Most master-slave PVM [17] programs, self-scheduling MPI [19] programs, bag-of-tasks Linda <ref> [5] </ref> programs, and all Calypso [4] programs are adaptive. For PVM, MPI, and Linda, programs must be written so that they are able to tolerate machine removals; whereas for Calypso, this service is provided by the runtime layer.
Reference: [6] <author> N. Carriero, D. Gelernter, D. Kaminsky, and J. Westbrook. </author> <title> Adaptive parallelism with piranha. </title> <type> Technical report, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1993. </year>
Reference-contexts: In contrast to ResourceBroker, previously mentioned resource managers can not dynamically allocate resources to jobs, and hence, do not support adaptive programs. 8.3 Dynamic Allocation for Adaptive Jobs Systems such as Piranha <ref> [6] </ref>, MPVM [7], Condor/CARMI [33], and DRMS [27] specifically target adaptive parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere.
Reference: [7] <author> J. Casas, D. Clark, R. Konuru, S. Otto, R. Prouty, and J. Walope. MPVM: </author> <title> A migration transparent version of PVM. </title> <booktitle> Computing Systems, </booktitle> <year> 1995. </year>
Reference-contexts: In contrast to ResourceBroker, previously mentioned resource managers can not dynamically allocate resources to jobs, and hence, do not support adaptive programs. 8.3 Dynamic Allocation for Adaptive Jobs Systems such as Piranha [6], MPVM <ref> [7] </ref>, Condor/CARMI [33], and DRMS [27] specifically target adaptive parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere.
Reference: [8] <author> S. Chapin, D. Katramatos, J. Karpovich, and A. Grimshaw. </author> <title> Resource management in legion. </title> <booktitle> To applear in International Journal on Future Generation Computer Systems, </booktitle> <year> 1999. </year>
Reference-contexts: These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs. With the increased popularity of parallel programming systems such as PVM and MPI, they extended their support to parallel interactive jobs. Globus [15] and Legion <ref> [8] </ref> are large-scale resource managers designed to unite machines from multiple administrative domains. While well-suited to what they do, previously mentioned systems are, in some sense batch-like, and limited to static allocation of resources.
Reference: [9] <author> E. Chung, Y. Huang, and S. Yajnik. </author> <title> Checkpointing in CosMic: A user-level process migration environment. </title> <booktitle> In Proceedings of Pacific Rim Symposium on Fault-Tolerant Computing, </booktitle> <year> 1997. </year>
Reference-contexts: An overview of selected resource management systems, with an emphasis on resource allocation for adaptive jobs, is given in Secion 8. Section 9 concludes the paper. 2 Background On networks of machines that support both parallel jobs and interactive users, machine loads change over time. A number of studies <ref> [30, 34, 11, 28, 2, 9] </ref> indicate that in most institutions up to 60% of machines are idle at any given time. <p> The only privilege Coshell requires is rsh access to remote hosts. To manage the transient availability of machines, systems such as Remote Unix, Sprite, and MOSIX utilize checkpointing and process migration to move processes once machines become unavailable. Coshell provides user-level process migration through CosMiC <ref> [9] </ref>.
Reference: [10] <author> L. Dikken, F. van Der Linden, J. Vesseur, and P. Sloot. DynamicPVM: </author> <title> Dynamic load balancing on parallel systems. </title> <booktitle> In Proceedings High-Performance Computing and Networking, </booktitle> <year> 1994. </year>
Reference-contexts: Attempts have been made to dynamically load-balance parallel jobs using techniques employed for sequential jobs: process checkpointing and migration. Resource managers such as GLU-nix [35], PRM [29], and DynamicPVM <ref> [10] </ref> were designed to use this technique. Under such systems, when a machine becomes busy, process executing on that machine are migrated to a remote underloaded remote machine.
Reference: [11] <author> F. Douglis and J. Ousterhout. </author> <title> Transparent process migration: Design alternatives and the Sprite implementation. </title> <journal> Software Practice and Experience, </journal> <year> 1991. </year>
Reference-contexts: An overview of selected resource management systems, with an emphasis on resource allocation for adaptive jobs, is given in Secion 8. Section 9 concludes the paper. 2 Background On networks of machines that support both parallel jobs and interactive users, machine loads change over time. A number of studies <ref> [30, 34, 11, 28, 2, 9] </ref> indicate that in most institutions up to 60% of machines are idle at any given time. <p> To use their services, users submit programs to the underlying system for execution. The system then selects the machines to execute those programs. Executing programs' terminal IO are generally redirected to provide the user with the output of the remotely executing program. Systems like NEST [1], V [34], Sprite <ref> [11] </ref>, MOSIX [3], and Remote Unix [25] provide such a service at the operating system level. Coshell [16] provides a similar service, not as a part of the operating system but as a Unix shell. The only privilege Coshell requires is rsh access to remote hosts.
Reference: [12] <author> A. Downey and M. Harchol-Balter. </author> <title> A note on the limited performance benefits of migrating active processes for load sharing. </title> <type> Technical report, </type> <institution> University of California at Berkeley, </institution> <year> 1995. </year>
Reference-contexts: Under such systems, when a machine becomes busy, process executing on that machine are migrated to a remote underloaded remote machine. Although it has been argued that process checkpointing and migration is not effective for parallel jobs [2, 24], the literature is still undecided on this subject <ref> [12] </ref>. A dynamic allocation of machines to jobs is more effective if machine-loads, as well as the job resource requirements, can change over time.
Reference: [13] <author> D. Duke, T. Green, and J. Pasko. </author> <title> Research toward a heterogeneous networked computer cluster: The Distributed Queuing System version 3.0. </title> <institution> Supercomputer Computations Research Institute, Florida State University, </institution> <year> 1994. </year>
Reference-contexts: In contrast to ResourceBroker, focus of these systems is to support sequential computations and they do not make any special provision for parallel programs. 8.2 Static Allocation for Parallel Jobs A number of research and commercial products such as Condor [26], Utopia [36] (now LSF [32]), DQS <ref> [13] </ref> (now CODINE [18]), PBS [20], and IBM's LoadLever [21] were developed for managing heterogenous resources of networks of workstations. These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs.
Reference: [14] <author> R. Felderman, E. Schooler, and L. Kleinrock. </author> <title> The benevolent bandit laboratory: A testbed for distributed algorithms. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <year> 1989. </year>
Reference-contexts: The concept of separating these two types of managers was first discussed in the work on the Benevolent Bandit Laboratory <ref> [14] </ref>. Dynamic allocation and reallocation of machines to jobs requires communication between multiple inter-job resource managers and the intra-job resource manager.
Reference: [15] <author> I. Foster and C. Kesselman. </author> <title> The globus project: A status report. </title> <booktitle> In Proceedings IPPS/SPDP '98 Heterogeneous Computing Workshop, </booktitle> <year> 1998. </year>
Reference-contexts: to start the job 5.1 Users' Interaction with the ResourceBroker Users communicate with the resource manager to query the availability of machines, to learn the status of queued jobs, to submit jobs for execution, and to specify a job's resource requirements. 6 ResourceBroker adopted the Resource Specification Language of Globus <ref> [15] </ref>, and extended it to support adaptive programs. Specifically, adaptive, start script, and module parameters were added to describe adaptive jobs. The supported specification grammar is presented in +(count&lt;=8)(adaptive=1)(start script="my script") is a request to execute an adaptive program (as specified by adaptive=1) on up to eight machines. <p> These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs. With the increased popularity of parallel programming systems such as PVM and MPI, they extended their support to parallel interactive jobs. Globus <ref> [15] </ref> and Legion [8] are large-scale resource managers designed to unite machines from multiple administrative domains. While well-suited to what they do, previously mentioned systems are, in some sense batch-like, and limited to static allocation of resources.
Reference: [16] <author> G. Fowler. </author> <title> The shell as a service. </title> <booktitle> In Cincinnati USENIX Conf. Proceedings, </booktitle> <year> 1993. </year>
Reference-contexts: Executing programs' terminal IO are generally redirected to provide the user with the output of the remotely executing program. Systems like NEST [1], V [34], Sprite [11], MOSIX [3], and Remote Unix [25] provide such a service at the operating system level. Coshell <ref> [16] </ref> provides a similar service, not as a part of the operating system but as a Unix shell. The only privilege Coshell requires is rsh access to remote hosts.
Reference: [17] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM: Parallel virtual machine. </title> <publisher> MIT Press, </publisher> <year> 1994. </year> <month> 19 </month>
Reference-contexts: First, they can expand to execute parts of the computation on machines that, otherwise, would be left unused. Second, they can acquire machines as their requirements grow, rather than reserving the largest pool of machines required at any single instance during their execution. Most master-slave PVM <ref> [17] </ref> programs, self-scheduling MPI [19] programs, bag-of-tasks Linda [5] programs, and all Calypso [4] programs are adaptive. For PVM, MPI, and Linda, programs must be written so that they are able to tolerate machine removals; whereas for Calypso, this service is provided by the runtime layer.
Reference: [18] <institution> GENIS Software GmbH. Codine 4.1.1, </institution> <note> technical description. http://www.genias. de/products/codine/tech_desc.html. </note>
Reference-contexts: In contrast to ResourceBroker, focus of these systems is to support sequential computations and they do not make any special provision for parallel programs. 8.2 Static Allocation for Parallel Jobs A number of research and commercial products such as Condor [26], Utopia [36] (now LSF [32]), DQS [13] (now CODINE <ref> [18] </ref>), PBS [20], and IBM's LoadLever [21] were developed for managing heterogenous resources of networks of workstations. These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs.
Reference: [19] <author> W. Gropp, E. Lust, and A. Skjellum. </author> <title> Using MPI: Portable parallel programming with the message-passing interface. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Second, they can acquire machines as their requirements grow, rather than reserving the largest pool of machines required at any single instance during their execution. Most master-slave PVM [17] programs, self-scheduling MPI <ref> [19] </ref> programs, bag-of-tasks Linda [5] programs, and all Calypso [4] programs are adaptive. For PVM, MPI, and Linda, programs must be written so that they are able to tolerate machine removals; whereas for Calypso, this service is provided by the runtime layer.
Reference: [20] <author> R. Henderson and D. Tweten. </author> <title> Portable batch system. NAS Scientific Computing Branch, </title> <institution> NASA Ames Research Center, </institution> <year> 1995. </year>
Reference-contexts: In a broader sense, it acts as a broker between the resource management layer and the running jobs, and is able to coerce programs to achieve the allocation policy determined by the resource management layer. Many existing resource managers <ref> [26, 36, 29, 20] </ref> employ a single-level architecture, where the monitoring daemon processes also carry out the responsibilities of agent and subagent processes. The purpose behind a two-level architecture is to allow ResourceBroker to run with user-level privileges only. <p> to ResourceBroker, focus of these systems is to support sequential computations and they do not make any special provision for parallel programs. 8.2 Static Allocation for Parallel Jobs A number of research and commercial products such as Condor [26], Utopia [36] (now LSF [32]), DQS [13] (now CODINE [18]), PBS <ref> [20] </ref>, and IBM's LoadLever [21] were developed for managing heterogenous resources of networks of workstations. These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs.
Reference: [21] <institution> IBM. IBM LoadLeveler: General information, </institution> <year> 1993. </year>
Reference-contexts: these systems is to support sequential computations and they do not make any special provision for parallel programs. 8.2 Static Allocation for Parallel Jobs A number of research and commercial products such as Condor [26], Utopia [36] (now LSF [32]), DQS [13] (now CODINE [18]), PBS [20], and IBM's LoadLever <ref> [21] </ref> were developed for managing heterogenous resources of networks of workstations. These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs. With the increased popularity of parallel programming systems such as PVM and MPI, they extended their support to parallel interactive jobs.
Reference: [22] <author> K. Jeong, D. Shasha, S. Talla, and P. Wyckoff. </author> <title> An approach to fault tolerant parallel processing on intermittently idle, heterogeneous workstations. </title> <booktitle> In Proceedings of the IEEE Twenty-Seventh International Symposium on Fault-Tolerant Computing (FTCS), </booktitle> <year> 1997. </year>
Reference-contexts: machines can also be reallocated to meet specified policies and constraints. * Support for diverse programming systems: Supports a collection of unmodified parallel programming systems; ResourceBroker is the first resource manager that can simultaneously manage programs written in PVM, LAM [31] (an implementation of the MPI standard), Calypso, and PLinda <ref> [22] </ref> (an implementation of Linda with atomic transactions). Sequential and non-adaptive parallel programs are also supported. * System independence: Parallel programming systems are treated as Commercial Off The Shelf (COTS) components.
Reference: [23] <author> J. Jones and C. Brickell. </author> <title> Second evaluation of job queuing/scheduling software: Phase i report. </title> <type> Technical report, NAS Technical Report NAS-97-013, </type> <year> 1997. </year>
Reference-contexts: An important characteristic of such resource managers is the inherently static allocation of machines to jobs: machines are allocated only once and before the jobs starts executing. This is a limiting factor. In a recent study at the NASA Ames Research Center <ref> [23] </ref>, six commercial and research resource managers were evaluated. According to this study, it was reported that the bad news is the confirmation of a continuing lack of JMS [Job Management System] support for parallel applications, parallel systems, and clusters of workstations.
Reference: [24] <author> E. Lazowska, L. Eager, and J Zahorjan. </author> <title> The limited performance benefits of migrating active processes for load sharing. In Performance Evaluation Review, </title> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: Under such systems, when a machine becomes busy, process executing on that machine are migrated to a remote underloaded remote machine. Although it has been argued that process checkpointing and migration is not effective for parallel jobs <ref> [2, 24] </ref>, the literature is still undecided on this subject [12]. A dynamic allocation of machines to jobs is more effective if machine-loads, as well as the job resource requirements, can change over time.
Reference: [25] <author> M. Litzkow. </author> <title> UNIX: Turning idle workstations into cycle servers. </title> <booktitle> In Proceedings Summer 1987 USENIX Conference, </booktitle> <year> 1987. </year>
Reference-contexts: The system then selects the machines to execute those programs. Executing programs' terminal IO are generally redirected to provide the user with the output of the remotely executing program. Systems like NEST [1], V [34], Sprite [11], MOSIX [3], and Remote Unix <ref> [25] </ref> provide such a service at the operating system level. Coshell [16] provides a similar service, not as a part of the operating system but as a Unix shell. The only privilege Coshell requires is rsh access to remote hosts.
Reference: [26] <author> M. Lizkow, M. Livny, , and M. </author> <title> Mutka. Condor: A hunter of idle workstations. </title> <booktitle> In Proceedings International Conference on Distributed Computing Systems, </booktitle> <year> 1988. </year>
Reference-contexts: In a broader sense, it acts as a broker between the resource management layer and the running jobs, and is able to coerce programs to achieve the allocation policy determined by the resource management layer. Many existing resource managers <ref> [26, 36, 29, 20] </ref> employ a single-level architecture, where the monitoring daemon processes also carry out the responsibilities of agent and subagent processes. The purpose behind a two-level architecture is to allow ResourceBroker to run with user-level privileges only. <p> Coshell provides user-level process migration through CosMiC [9]. In contrast to ResourceBroker, focus of these systems is to support sequential computations and they do not make any special provision for parallel programs. 8.2 Static Allocation for Parallel Jobs A number of research and commercial products such as Condor <ref> [26] </ref>, Utopia [36] (now LSF [32]), DQS [13] (now CODINE [18]), PBS [20], and IBM's LoadLever [21] were developed for managing heterogenous resources of networks of workstations. These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs.
Reference: [27] <author> J. Moreira, V. Naik, and R. Konuru. </author> <title> A programming environment for dynamic resource allocation and data distribution. </title> <booktitle> In Proceedings 9th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <year> 1996. </year>
Reference-contexts: In contrast to ResourceBroker, previously mentioned resource managers can not dynamically allocate resources to jobs, and hence, do not support adaptive programs. 8.3 Dynamic Allocation for Adaptive Jobs Systems such as Piranha [6], MPVM [7], Condor/CARMI [33], and DRMS <ref> [27] </ref> specifically target adaptive parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere.
Reference: [28] <author> M. Mutka and M. Livny. </author> <title> The available capacity of a privately owned workstation environment. In Performance Evaluation, </title> <year> 1991. </year>
Reference-contexts: An overview of selected resource management systems, with an emphasis on resource allocation for adaptive jobs, is given in Secion 8. Section 9 concludes the paper. 2 Background On networks of machines that support both parallel jobs and interactive users, machine loads change over time. A number of studies <ref> [30, 34, 11, 28, 2, 9] </ref> indicate that in most institutions up to 60% of machines are idle at any given time.
Reference: [29] <author> C. Neuman and S. Rao. </author> <title> The prospero resource manager: A scalable framework for processor allocation in distributed systems. </title> <journal> Concurrency: Practice and Experience, </journal> <year> 1994. </year>
Reference-contexts: In a broader sense, it acts as a broker between the resource management layer and the running jobs, and is able to coerce programs to achieve the allocation policy determined by the resource management layer. Many existing resource managers <ref> [26, 36, 29, 20] </ref> employ a single-level architecture, where the monitoring daemon processes also carry out the responsibilities of agent and subagent processes. The purpose behind a two-level architecture is to allow ResourceBroker to run with user-level privileges only. <p> Attempts have been made to dynamically load-balance parallel jobs using techniques employed for sequential jobs: process checkpointing and migration. Resource managers such as GLU-nix [35], PRM <ref> [29] </ref>, and DynamicPVM [10] were designed to use this technique. Under such systems, when a machine becomes busy, process executing on that machine are migrated to a remote underloaded remote machine.
Reference: [30] <author> D. Nichols. </author> <title> Using idle workstations in a shared computing environment. </title> <booktitle> In Proceedings of SOSP, </booktitle> <year> 1987. </year>
Reference-contexts: An overview of selected resource management systems, with an emphasis on resource allocation for adaptive jobs, is given in Secion 8. Section 9 concludes the paper. 2 Background On networks of machines that support both parallel jobs and interactive users, machine loads change over time. A number of studies <ref> [30, 34, 11, 28, 2, 9] </ref> indicate that in most institutions up to 60% of machines are idle at any given time.
Reference: [31] <institution> Ohio Supercomputer Center, Ohio State University. MPI primer/developing with LAM, </institution> <year> 1996. </year>
Reference-contexts: Further more, machines can also be reallocated to meet specified policies and constraints. * Support for diverse programming systems: Supports a collection of unmodified parallel programming systems; ResourceBroker is the first resource manager that can simultaneously manage programs written in PVM, LAM <ref> [31] </ref> (an implementation of the MPI standard), Calypso, and PLinda [22] (an implementation of Linda with atomic transactions). Sequential and non-adaptive parallel programs are also supported. * System independence: Parallel programming systems are treated as Commercial Off The Shelf (COTS) components.
Reference: [32] <institution> Platform Computing Corporation, Toronto, Canada. </institution> <note> LSF User's and administrator's guide, </note> <year> 1993. </year>
Reference-contexts: In contrast to ResourceBroker, focus of these systems is to support sequential computations and they do not make any special provision for parallel programs. 8.2 Static Allocation for Parallel Jobs A number of research and commercial products such as Condor [26], Utopia [36] (now LSF <ref> [32] </ref>), DQS [13] (now CODINE [18]), PBS [20], and IBM's LoadLever [21] were developed for managing heterogenous resources of networks of workstations. These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs.
Reference: [33] <author> J. Pruyne and M. Livny. </author> <title> Parallel processing on dynamic resources with CARMI. In Job Scheduling Strategies for Parallel ProcessingIPPS'95 Workshop Proceedings, </title> <booktitle> 1995. </booktitle> <pages> 20 </pages>
Reference-contexts: In contrast to ResourceBroker, previously mentioned resource managers can not dynamically allocate resources to jobs, and hence, do not support adaptive programs. 8.3 Dynamic Allocation for Adaptive Jobs Systems such as Piranha [6], MPVM [7], Condor/CARMI <ref> [33] </ref>, and DRMS [27] specifically target adaptive parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere. <p> While this was a great step towards providing an adaptive resource manager, Piranha required modifications to the Linda system, and only supported Linda programs that had been modified to use Piranha. Condor/CARMI <ref> [33] </ref> proposed that all RM [resource management] functionality be removed from PPE [parallel programming environments] code, and migrated into one or more processes which are dedicated to handling resource management requests.
Reference: [34] <author> M. Theimer and K. Lantz. </author> <title> Finding idle machines in a workstation-based distributed system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <year> 1989. </year>
Reference-contexts: An overview of selected resource management systems, with an emphasis on resource allocation for adaptive jobs, is given in Secion 8. Section 9 concludes the paper. 2 Background On networks of machines that support both parallel jobs and interactive users, machine loads change over time. A number of studies <ref> [30, 34, 11, 28, 2, 9] </ref> indicate that in most institutions up to 60% of machines are idle at any given time. <p> To use their services, users submit programs to the underlying system for execution. The system then selects the machines to execute those programs. Executing programs' terminal IO are generally redirected to provide the user with the output of the remotely executing program. Systems like NEST [1], V <ref> [34] </ref>, Sprite [11], MOSIX [3], and Remote Unix [25] provide such a service at the operating system level. Coshell [16] provides a similar service, not as a part of the operating system but as a Unix shell. The only privilege Coshell requires is rsh access to remote hosts.
Reference: [35] <author> A. Vahdat, D. Ghormley, and T. Anderson. </author> <title> Efficient, portable, and robust extension of operating system functionality. </title> <type> Technical Report Technical Report CS-94-842, </type> <institution> UC Berkeley, </institution> <year> 1994. </year>
Reference-contexts: Attempts have been made to dynamically load-balance parallel jobs using techniques employed for sequential jobs: process checkpointing and migration. Resource managers such as GLU-nix <ref> [35] </ref>, PRM [29], and DynamicPVM [10] were designed to use this technique. Under such systems, when a machine becomes busy, process executing on that machine are migrated to a remote underloaded remote machine.
Reference: [36] <author> S. Zhou, J. Wang, X. Zheng, and P. Delisle. </author> <title> Utopia: A load sharing facility for large, heterogeneous distributed computing systems. </title> <institution> Computer Systems Research Institute, University of Toronto, </institution> <year> 1992. </year> <month> 21 </month>
Reference-contexts: In a broader sense, it acts as a broker between the resource management layer and the running jobs, and is able to coerce programs to achieve the allocation policy determined by the resource management layer. Many existing resource managers <ref> [26, 36, 29, 20] </ref> employ a single-level architecture, where the monitoring daemon processes also carry out the responsibilities of agent and subagent processes. The purpose behind a two-level architecture is to allow ResourceBroker to run with user-level privileges only. <p> In contrast to ResourceBroker, focus of these systems is to support sequential computations and they do not make any special provision for parallel programs. 8.2 Static Allocation for Parallel Jobs A number of research and commercial products such as Condor [26], Utopia <ref> [36] </ref> (now LSF [32]), DQS [13] (now CODINE [18]), PBS [20], and IBM's LoadLever [21] were developed for managing heterogenous resources of networks of workstations. These systems are typically Queue Management Systems and were originally intended to be use with batch sequential jobs.
References-found: 36

