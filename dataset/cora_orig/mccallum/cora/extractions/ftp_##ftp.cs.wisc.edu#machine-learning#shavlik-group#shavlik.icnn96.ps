URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/shavlik.icnn96.ps
Refering-URL: http://www.cs.wisc.edu/~shavlik/abstracts/shavlik.icnn96.ps.abstract.html
Root-URL: 
Email: shavlik@cs.wisc.edu  
Title: An Overview of Research at Wisconsin on Knowledge-Based Neural Networks  
Author: Jude W. Shavlik 
Address: 1210 W. Dayton Street Madison, WI 53706 USA  
Affiliation: Department of Computer Sciences University of Wisconsin  
Abstract: Recent research at the University of Wisconsin on knowledge-based neural networks is surveyed. This work has focused on (a) using symbolically represented background knowledge to improve neural-network learning and (b) extracting comprehensible sym bolic representations from trained networks. Important open issues are discussed.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Craven and J. Shavlik, </author> <title> "Learning symbolic rules using artificial neural networks," </title> <booktitle> in Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <address> (Amherst, MA), </address> <pages> pp. 73-80, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Our experiments demonstrated that this approach results in better performance from fewer training examples. 3. Understanding what a Neural Network Learned The second major focus of our research program has been to develop algorithms for extracting comprehensible, symbolic knowledge from trained neural networks <ref> [1, 2, 3, 4, 18] </ref>. A current limitation of neural networks is that their concept representations are extremely difficult for humans to understand because they are represented using large numbers of real-valued parameters. The goal of this research is to enable comprehensible concept descriptions to be extracted from trained networks. <p> Our network-extracted rules are more accurate than the rules produced by a decision-tree induction algorithm (called C4.5), and are comparable in terms of comprehensibility. We initially designed rule-extraction techniques tailored for knowledge-based networks [18] and, more recently, for "standard" neural networks <ref> [1, 2, 4] </ref>. <p> Instead, the learning system periodically gets rewards (or penalties) from its environment and it must decide how to allocate credit/blame to previous actions that it took. 4 also be successfully applied to ordinary networks by using a training procedure that encouraged the weights to cluster during training <ref> [1] </ref>. This training procedure is a variant of Nowlan and Hinton's soft weight-sharing technique. Although their method was motivated by the desire for better generalization, we employed it to facilitate rule extraction. We next developed a new rule-extraction approach that does not require a special training procedure [2].
Reference: [2] <author> M. Craven and J. Shavlik, </author> <title> "Using sampling and queries to extract rules from trained neural networks," </title> <booktitle> in Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <address> (New Brunswick, NJ), </address> <pages> pp. 37-45, </pages> <year> 1994. </year>
Reference-contexts: Our experiments demonstrated that this approach results in better performance from fewer training examples. 3. Understanding what a Neural Network Learned The second major focus of our research program has been to develop algorithms for extracting comprehensible, symbolic knowledge from trained neural networks <ref> [1, 2, 3, 4, 18] </ref>. A current limitation of neural networks is that their concept representations are extremely difficult for humans to understand because they are represented using large numbers of real-valued parameters. The goal of this research is to enable comprehensible concept descriptions to be extracted from trained networks. <p> Our network-extracted rules are more accurate than the rules produced by a decision-tree induction algorithm (called C4.5), and are comparable in terms of comprehensibility. We initially designed rule-extraction techniques tailored for knowledge-based networks [18] and, more recently, for "standard" neural networks <ref> [1, 2, 4] </ref>. <p> This training procedure is a variant of Nowlan and Hinton's soft weight-sharing technique. Although their method was motivated by the desire for better generalization, we employed it to facilitate rule extraction. We next developed a new rule-extraction approach that does not require a special training procedure <ref> [2] </ref>. It uses a rule-learning algorithm to find a set of rules that is approximately equivalent to the concept represented by a trained network. The target concept, in this learning task, is the function computed by the network.
Reference: [3] <author> M. Craven and J. Shavlik, </author> <title> "Extracting comprehensible concept representations from trained neural networks," </title> <booktitle> in Presented at the IJCAI Workshop on Comprehensibility in Machine Learning, </booktitle> <address> (Montreal, Quebec, Canada), </address> <year> 1995. </year>
Reference-contexts: Our experiments demonstrated that this approach results in better performance from fewer training examples. 3. Understanding what a Neural Network Learned The second major focus of our research program has been to develop algorithms for extracting comprehensible, symbolic knowledge from trained neural networks <ref> [1, 2, 3, 4, 18] </ref>. A current limitation of neural networks is that their concept representations are extremely difficult for humans to understand because they are represented using large numbers of real-valued parameters. The goal of this research is to enable comprehensible concept descriptions to be extracted from trained networks.
Reference: [4] <author> M. Craven and J. Shavlik, </author> <title> "Extracting tree-structured representations of trained networks," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 8, </volume> <year> 1996. </year>
Reference-contexts: Our experiments demonstrated that this approach results in better performance from fewer training examples. 3. Understanding what a Neural Network Learned The second major focus of our research program has been to develop algorithms for extracting comprehensible, symbolic knowledge from trained neural networks <ref> [1, 2, 3, 4, 18] </ref>. A current limitation of neural networks is that their concept representations are extremely difficult for humans to understand because they are represented using large numbers of real-valued parameters. The goal of this research is to enable comprehensible concept descriptions to be extracted from trained networks. <p> Our network-extracted rules are more accurate than the rules produced by a decision-tree induction algorithm (called C4.5), and are comparable in terms of comprehensibility. We initially designed rule-extraction techniques tailored for knowledge-based networks [18] and, more recently, for "standard" neural networks <ref> [1, 2, 4] </ref>. <p> The target concept, in this learning task, is the function computed by the network. In addition to learning from training examples, our method exploits the property that networks can be efficiently queried. Our most recent algorithm, Trepan <ref> [4] </ref>, uses queries to induce a decision tree that approximates the concept represented by a given network. Experiments demonstrate that Trepan is able to produce decision trees that maintain a high level of fidelity to their respective networks, while being comprehensible and accurate.
Reference: [5] <author> R. Maclin, </author> <title> Learning from Instruction and Experience: Methods for Incorporating Procedural Domain Theories into Knowledge-Based Neural Networks. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Wisconsin-Madison, </institution> <year> 1995. </year>
Reference-contexts: Finally, we found it useful to create a set of knowledge-based networks whose outputs are averaged (weighted) when 3 categorizing new examples [13]; we search for a set of highly accurate networks whose errors are not highly correlated. Recently, we extended our approach to the reinforcement learning paradigm <ref> [5, 7, 8] </ref>. 1 The approach we developed allows a connectionist reinforcement learner to accept advice, provided at any time during the learning process, by an external observer. In this approach, the advice-giver watches the learner and occasionally makes suggestions, expressed as instructions in a simple programming language. <p> In general, we should think of a continual dialog between the human user and the machine learner. Maclin's thesis work <ref> [5] </ref> provides an initial approach to this task. Finally, in most domains it is important to understand what a trained network has learned.
Reference: [6] <author> R. Maclin and J. Shavlik, </author> <title> "Using knowledge-based neural networks to improve algorithms: Refining the Chou-Fasman algorithm for protein folding," </title> <journal> Machine Learning, </journal> <volume> vol. 11, no. 2,3, </volume> <pages> pp. 195-215, </pages> <year> 1993. </year>
Reference-contexts: Our initial Kbann algorithm required that existing knowledge be expressed in the form of non-recursive, propositional rules. Subsequent work extended the types of representations supported by Kbann. Our FSkbann algorithm allows domain knowledge expressed as generalized finite-state automata to be mapped into recurrent neural networks <ref> [6] </ref>. This representation enabled us to consider state-dependent domain theories. We tested FSkbann by using it to refine the Chou-Fasman algorithm for predicting how proteins fold. The resulting networks outperformed both the Chou-Fasman algorithm (a standard in the biological community), as well as previous neural-network approaches.
Reference: [7] <author> R. Maclin and J. Shavlik, </author> <title> "Incorporating advice into agents that learn from reinforcements," </title> <booktitle> in Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <address> (Seattle, WA), </address> <pages> pp. 694-699, </pages> <publisher> AAAI/MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Finally, we found it useful to create a set of knowledge-based networks whose outputs are averaged (weighted) when 3 categorizing new examples [13]; we search for a set of highly accurate networks whose errors are not highly correlated. Recently, we extended our approach to the reinforcement learning paradigm <ref> [5, 7, 8] </ref>. 1 The approach we developed allows a connectionist reinforcement learner to accept advice, provided at any time during the learning process, by an external observer. In this approach, the advice-giver watches the learner and occasionally makes suggestions, expressed as instructions in a simple programming language.
Reference: [8] <author> R. Maclin and J. Shavlik, </author> <title> "Creating advice-taking reinforcement learners," </title> <journal> Machine Learning, </journal> <volume> vol. 22, </volume> <pages> pp. 251-281, </pages> <year> 1995. </year>
Reference-contexts: Finally, we found it useful to create a set of knowledge-based networks whose outputs are averaged (weighted) when 3 categorizing new examples [13]; we search for a set of highly accurate networks whose errors are not highly correlated. Recently, we extended our approach to the reinforcement learning paradigm <ref> [5, 7, 8] </ref>. 1 The approach we developed allows a connectionist reinforcement learner to accept advice, provided at any time during the learning process, by an external observer. In this approach, the advice-giver watches the learner and occasionally makes suggestions, expressed as instructions in a simple programming language.
Reference: [9] <author> D. Opitz, </author> <title> An Anytime Approach to Connectionist Theory Refinement: Refining the Topologies of Knowledge-Based Neural Networks. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Wisconsin-Madison, </institution> <year> 1995. </year>
Reference-contexts: Again, the Kbann network outperformed the standard algorithm from the chemical engineering literature and an ordinary neural-network approach. The basic Kbann algorithm determines the initial network topology, then only alters the network's weights. However, if the domain theory is sparse, the network Kbann produces can be too small <ref> [9, 10] </ref>. To overcome this limitation, we developed a heuristic-search technique that suggested where additional hidden units should be added to a Kbann-produced network [10, 12].
Reference: [10] <author> D. Opitz and J. Shavlik, </author> <title> "Heuristically expanding knowledge-based neural networks," </title> <booktitle> in Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> (Chambery, France), </address> <pages> pp. 1360-1365, </pages> <publisher> Mor-gan Kaufmann, </publisher> <month> September </month> <year> 1993. </year>
Reference-contexts: Figure 1 shows an example of the Kbann process for a set of simple propositional rules. We have tested Kbann on a number of difficult, real-world tasks, including four DNA problems, the diagnosis of telephone-line faults, and a chess-like game <ref> [10, 13, 19] </ref>. Kbann was compared to other learning algorithms by measuring generalization performance. Generalization refers to how well a learning system is able to correctly classify previously unseen instances. <p> Again, the Kbann network outperformed the standard algorithm from the chemical engineering literature and an ordinary neural-network approach. The basic Kbann algorithm determines the initial network topology, then only alters the network's weights. However, if the domain theory is sparse, the network Kbann produces can be too small <ref> [9, 10] </ref>. To overcome this limitation, we developed a heuristic-search technique that suggested where additional hidden units should be added to a Kbann-produced network [10, 12]. <p> However, if the domain theory is sparse, the network Kbann produces can be too small [9, 10]. To overcome this limitation, we developed a heuristic-search technique that suggested where additional hidden units should be added to a Kbann-produced network <ref> [10, 12] </ref>. The basic approach is: train the initial Kbann-produced network, use a set of "tuning" examples to locate poorly performing hidden units, add additional hidden units to the weak portions of the network, then repeat as long as improvement is detected.
Reference: [11] <author> D. Opitz and J. Shavlik, </author> <title> "Using genetic search to refine knowledge-based neural networks," </title> <booktitle> in Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <address> (New Brunswick, NJ), </address> <pages> pp. 208-216, </pages> <publisher> Morgan Kaufmann, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: We successfully extended this idea by using genetic operators (specialized versions of crossover and mutation) to create new networks from the current population of candidate network topologies <ref> [11] </ref>. Finally, we found it useful to create a set of knowledge-based networks whose outputs are averaged (weighted) when 3 categorizing new examples [13]; we search for a set of highly accurate networks whose errors are not highly correlated.
Reference: [12] <author> D. Opitz and J. Shavlik, </author> <title> "Dynamically adding symbolically meaningful nodes to knowledge-based neural networks," </title> <booktitle> Knowledge-Based Systems, </booktitle> <pages> pp. 301-311, </pages> <year> 1996. </year>
Reference-contexts: However, if the domain theory is sparse, the network Kbann produces can be too small [9, 10]. To overcome this limitation, we developed a heuristic-search technique that suggested where additional hidden units should be added to a Kbann-produced network <ref> [10, 12] </ref>. The basic approach is: train the initial Kbann-produced network, use a set of "tuning" examples to locate poorly performing hidden units, add additional hidden units to the weak portions of the network, then repeat as long as improvement is detected.
Reference: [13] <author> D. Opitz and J. Shavlik, </author> <title> "Generating accurate and diverse members of a neural-network ensemble," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 8, </volume> <year> 1996. </year>
Reference-contexts: Figure 1 shows an example of the Kbann process for a set of simple propositional rules. We have tested Kbann on a number of difficult, real-world tasks, including four DNA problems, the diagnosis of telephone-line faults, and a chess-like game <ref> [10, 13, 19] </ref>. Kbann was compared to other learning algorithms by measuring generalization performance. Generalization refers to how well a learning system is able to correctly classify previously unseen instances. <p> Finally, we found it useful to create a set of knowledge-based networks whose outputs are averaged (weighted) when 3 categorizing new examples <ref> [13] </ref>; we search for a set of highly accurate networks whose errors are not highly correlated.
Reference: [14] <author> G. Scott, J. Shavlik, and W. Ray, </author> <title> "Refining PID controllers using neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 5, no. 4, </volume> <pages> pp. 746-757, </pages> <year> 1992. </year>
Reference-contexts: The resulting networks outperformed both the Chou-Fasman algorithm (a standard in the biological community), as well as previous neural-network approaches. We also extended Kbann to handle numeric knowledge pertaining to the control of a chemical plant <ref> [14] </ref>. Again, the Kbann network outperformed the standard algorithm from the chemical engineering literature and an ordinary neural-network approach. The basic Kbann algorithm determines the initial network topology, then only alters the network's weights.
Reference: [15] <author> J. Shavlik, </author> <title> "Combining symbolic and neural learning," </title> <journal> Machine Learning, </journal> <volume> vol. 14, no. 2, </volume> <pages> pp. 321-331, </pages> <year> 1994. </year>
Reference-contexts: 1. Introduction We have been developing algorithms that integrate symbolic and neural-network approaches to supervised learning <ref> [15] </ref>. Our research program has had two main thrusts: using symbolically represented background knowledge to improve neural-network learning, and extracting comprehensible symbolic representations from trained networks. <p> Conclusion The value of using prior, symbolic knowledge in combination with neural training methods has been demonstrated on a variety of tasks involving comparison to alternate learning methods. The set of knowledge representations mappable into networks is growing (see <ref> [15] </ref> for a review), though an open issue is the use of prior knowledge expressed in first-order predicate calculus, a topic addressed in the field of inductive logic programming. While knowledge-based neural networks have been applied to several real-world tasks, these have generally involved small amounts of prior knowledge.
Reference: [16] <author> J. Shavlik and G. Towell, </author> <title> "An approach to combining explanation-based and neural learning algorithms," </title> <journal> Connection Science, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 233-255, </pages> <year> 1989. </year>
Reference-contexts: One major focus of our research has been to investigate how to make effective use of some types of prior knowledge about f . The first significant results of our research program were the Ebl-Ann <ref> [16] </ref> and Kbann [17, 19, 20] algorithms. Kbann enables a neural network to be initialized with a domain theory (i.e., a task-specific collection of inference rules), which need not be correct nor complete. It maps the domain theory into a neural network, determining its topology and initial weights.
Reference: [17] <author> G. Towell, </author> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement and Extraction. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Wisconsin-Madison, </institution> <year> 1991. </year>
Reference-contexts: One major focus of our research has been to investigate how to make effective use of some types of prior knowledge about f . The first significant results of our research program were the Ebl-Ann [16] and Kbann <ref> [17, 19, 20] </ref> algorithms. Kbann enables a neural network to be initialized with a domain theory (i.e., a task-specific collection of inference rules), which need not be correct nor complete. It maps the domain theory into a neural network, determining its topology and initial weights.
Reference: [18] <author> G. Towell and J. Shavlik, </author> <title> "Extracting refined rules from knowledge-based neural networks," </title> <journal> Machine Learning, </journal> <volume> vol. 13, no. 1, </volume> <pages> pp. 71-101, </pages> <year> 1993. </year>
Reference-contexts: Our experiments demonstrated that this approach results in better performance from fewer training examples. 3. Understanding what a Neural Network Learned The second major focus of our research program has been to develop algorithms for extracting comprehensible, symbolic knowledge from trained neural networks <ref> [1, 2, 3, 4, 18] </ref>. A current limitation of neural networks is that their concept representations are extremely difficult for humans to understand because they are represented using large numbers of real-valued parameters. The goal of this research is to enable comprehensible concept descriptions to be extracted from trained networks. <p> Our network-extracted rules are more accurate than the rules produced by a decision-tree induction algorithm (called C4.5), and are comparable in terms of comprehensibility. We initially designed rule-extraction techniques tailored for knowledge-based networks <ref> [18] </ref> and, more recently, for "standard" neural networks [1, 2, 4]. <p> We initially developed the MofN algorithm <ref> [18] </ref> that extracts m-of-n rules from trained Kbann networks. An m-of-n rule is satisfied when at least m of its n antecedents are true. Our studies showed that we can extract comprehensible rules while still maintaining the accuracy of the trained network.
Reference: [19] <author> G. Towell and J. Shavlik, </author> <title> "Knowledge-based artificial neural networks," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 70, no. 1,2, </volume> <pages> pp. 119-165, </pages> <year> 1994. </year>
Reference-contexts: One major focus of our research has been to investigate how to make effective use of some types of prior knowledge about f . The first significant results of our research program were the Ebl-Ann [16] and Kbann <ref> [17, 19, 20] </ref> algorithms. Kbann enables a neural network to be initialized with a domain theory (i.e., a task-specific collection of inference rules), which need not be correct nor complete. It maps the domain theory into a neural network, determining its topology and initial weights. <p> Figure 1 shows an example of the Kbann process for a set of simple propositional rules. We have tested Kbann on a number of difficult, real-world tasks, including four DNA problems, the diagnosis of telephone-line faults, and a chess-like game <ref> [10, 13, 19] </ref>. Kbann was compared to other learning algorithms by measuring generalization performance. Generalization refers to how well a learning system is able to correctly classify previously unseen instances.
Reference: [20] <author> G. Towell, J. Shavlik, and M. Noordewier, </author> <title> "Refinement of approximate domain theories by knowledge-based neural networks," </title> <booktitle> in Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> (Boston, MA), </address> <pages> pp. 861-866, </pages> <publisher> AAAI/MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: One major focus of our research has been to investigate how to make effective use of some types of prior knowledge about f . The first significant results of our research program were the Ebl-Ann [16] and Kbann <ref> [17, 19, 20] </ref> algorithms. Kbann enables a neural network to be initialized with a domain theory (i.e., a task-specific collection of inference rules), which need not be correct nor complete. It maps the domain theory into a neural network, determining its topology and initial weights.
References-found: 20

