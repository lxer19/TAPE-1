URL: http://www.cs.colorado.edu/homes/msarkis/public_html/papers/dd10.ps.gz
Refering-URL: http://www.cs.colorado.edu/homes/msarkis/public_html/papers.html
Root-URL: http://www.cs.colorado.edu
Title: Contemporary Mathematics A Minimum Overlap Restricted Additive Schwarz Preconditioner and Applications in 3D Flow Simulations  
Author: Xiao-Chuan Cai, Charbel Farhat, and Marcus Sarkis 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> X.-C. Cai, M. Dryja, and M. Sarkis, </author> <title> A convergence theory for restricted additive Schwarz methods, </title> <note> in preparation, </note> <year> 1998. </year>
Reference-contexts: Because of the page limit, we shall restrict our discussion to this particular precon-ditioner. Other issues can be found in the papers <ref> [1, 2] </ref>. We remark that the action of R 0 i to a vector does not involve any communication in a parallel implementation, but R i does. As a result, RAS is cheaper than AS in terms of the communication cost.
Reference: [2] <author> X.-C. Cai, C. Farhat, B. Koobus, and M. Sarkis, </author> <title> Parallel restricted additive Schwarz based iterative methods for general aerodynamic simulations, </title> <note> in preparation, </note> <year> 1998. </year>
Reference-contexts: In this paper, we focus on the study of a parallel restricted additive Schwarz preconditioned iterative method for solving (2.4) with various ffi. More discussions and computational experience with the selection of the nonlinear and linear stopping tolerance t and ffi can be found in <ref> [2] </ref>. 3. RAS with minimum overlap We now describe a version of the RAS preconditioner, which was recently in troduced in [3], with the smallest possible non-zero overlap. <p> Because of the page limit, we shall restrict our discussion to this particular precon-ditioner. Other issues can be found in the papers <ref> [1, 2] </ref>. We remark that the action of R 0 i to a vector does not involve any communication in a parallel implementation, but R i does. As a result, RAS is cheaper than AS in terms of the communication cost.
Reference: [3] <author> X.-C. Cai and M. Sarkis, </author> <title> A restricted additive Schwarz preconditioner for general sparse linear systems, </title> <type> Tech. Report CU-CS-843-97, </type> <institution> Department of Computer Science, University of Colorado at Boulder, </institution> <year> 1997. </year>
Reference-contexts: More discussions and computational experience with the selection of the nonlinear and linear stopping tolerance t and ffi can be found in [2]. 3. RAS with minimum overlap We now describe a version of the RAS preconditioner, which was recently in troduced in <ref> [3] </ref>, with the smallest possible non-zero overlap.
Reference: [4] <author> M. Dryja and O. B. Widlund, </author> <title> Domain decomposition algorithms with small overlap, </title> <journal> SIAM J. Sci. Comput. </journal> <volume> 15 (1994), </volume> <pages> 604-620. </pages> <note> RESTRICTED ADDITIVE SCHWARZ 7 </note>
Reference: [5] <author> C. Farhat, S. Lanteri, and H. Simon, TOP/DOMDEC: </author> <title> A software tool for mesh partitioning and parallel processing and applications to CSM and CFD computations, </title> <journal> Comput. Sys. Engrg. </journal> <volume> 6 (1995), </volume> <pages> 13-26. </pages>
Reference-contexts: Other recent development in the application of RAS in CFD can be found in [6, 9]. 4.1. Parallel implementation issues. We implemented the algorithm on a number of parallel machines, and the top-level message-passing calls are implemented through MPI [7]. We partition the mesh by using the TOP/DOMDEC package <ref> [5] </ref>. We require that all subdomains have more or less the same number of mesh points. An effort is made to reduce the number of mesh points along the interfaces of subdomains to reduce the communication cost.
Reference: [6] <author> W. Gropp, D. Keyes, L. McInnes, and M. Tidriri, </author> <title> Parallel implicit PDE computations: </title> <booktitle> Algorithms and software, Proceedings of Parallel CFD'97, </booktitle> <editor> A. Ecer, et al., edt., </editor> <address> Manchester, UK, </address> <year> 1997., 1997, </year> <note> to appear. </note>
Reference-contexts: We also include some comparisons with the regular additive Schwarz method and the simple pointwise Jacobi method (JAC). Note that a point in the mesh represents an 5 fi 5 block matrix. Other recent development in the application of RAS in CFD can be found in <ref> [6, 9] </ref>. 4.1. Parallel implementation issues. We implemented the algorithm on a number of parallel machines, and the top-level message-passing calls are implemented through MPI [7]. We partition the mesh by using the TOP/DOMDEC package [5].
Reference: [7] <author> W. Gropp, E. Lusk, and A. Skjellum, </author> <title> Using MPI Portable Parallel Programming with the Message-Passing Interface, </title> <publisher> The MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: Other recent development in the application of RAS in CFD can be found in [6, 9]. 4.1. Parallel implementation issues. We implemented the algorithm on a number of parallel machines, and the top-level message-passing calls are implemented through MPI <ref> [7] </ref>. We partition the mesh by using the TOP/DOMDEC package [5]. We require that all subdomains have more or less the same number of mesh points. An effort is made to reduce the number of mesh points along the interfaces of subdomains to reduce the communication cost.
Reference: [8] <author> C. Hirsch, </author> <title> Numerical Computation of Internal and External Flows, Vol I, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: interested in applying the method of DeC-Krylov-RAS to the system of Euler's equation: @W + @x @ F 2 (W ) + @z where W = (; u; v; w; E) T and (F 1 ; F 2 ; F 3 ) T is the convective flux as defined in <ref> [8] </ref>. Here and in the rest of the paper is the density, U = (u; v; w) T is the velocity vector, E is the total energy per unit volume, and p is the pressure.
Reference: [9] <author> D. Keyes, D. Kaushik, and B. Smith, </author> <title> Prospects for CFD on petaflops systems, CFD Review 1997, </title> <editor> M. Hafez et al., edt., </editor> <year> 1997, </year> <note> to appear. </note>
Reference-contexts: We also include some comparisons with the regular additive Schwarz method and the simple pointwise Jacobi method (JAC). Note that a point in the mesh represents an 5 fi 5 block matrix. Other recent development in the application of RAS in CFD can be found in <ref> [6, 9] </ref>. 4.1. Parallel implementation issues. We implemented the algorithm on a number of parallel machines, and the top-level message-passing calls are implemented through MPI [7]. We partition the mesh by using the TOP/DOMDEC package [5].
Reference: [10] <author> B. Koobus and C. Farhat, </author> <title> Time-accurate schemes for computing two- and three-dimensional viscous fluxes on unstructured dynamic meshes, </title> <address> AIAA-96-2384, </address> <year> 1996. </year>
Reference-contexts: We locate the variables at the vertices of the grid, which gives rise to a cell-vertex scheme. The space of solutions is taken to be the space of piecewise linear continuous functions. The discrete system is obtained via a finite volume formulation; see e.g., Koobus and Farhat <ref> [10] </ref>. We determine the nth time step size t n in the following way. Let CFL be a pre-selected positive number.
Reference: [11] <author> R. Martin and H. Guillard, </author> <title> A second order defect correction scheme for unsteady problems, </title> <booktitle> Computers and Fluids 25 (1996), </booktitle> <pages> 9-27. </pages>
Reference: [12] <author> Y. Saad and M. Schultz, </author> <title> GMRES: A generalized minimum residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 7 (1986), </volume> <pages> 856-869. </pages>
Reference: [13] <author> B. Smith, P. Bjtrstad, and W. Gropp, </author> <title> Domain Decomposition: Parallel Multilevel Methods for Elliptic Partial Differential Equations, </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year> <institution> Department of Computer Science, University of Colorado at Boulder, Boulder, CO 80309. E-mail address: cai@cs.colorado.edu Department of Aerospace Engineering, University of Colorado at Boulder, Boulder, CO 80309. E-mail address: charbel@alexandra.colorado.edu Department of Computer Science, University of Colorado at Boulder, Boulder, </institution> <address> CO 80309. </address> <publisher> E-mail address: msarkis@cs.colorado.edu </publisher>
References-found: 13

