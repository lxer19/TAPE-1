URL: ftp://speech.cse.ogi.edu/pub/docs/langid_euro95.ps.Z
Refering-URL: http://www.cse.ogi.edu/~berkling/vitae.html
Root-URL: http://www.cse.ogi.edu
Email: berkling,barnard)@cse.ogi.edu  
Title: Theoretical Error Prediction for a Language Identification System using Optimal Phoneme Clustering  
Author: Kay M. Berkling, Etienne Barnard 
Affiliation: Oregon Graduate Institute of Science and Technology  
Note: Center for Spoken Language Understanding,  
Abstract: A neural network based language identification system is described, which uses language independent phoneme clusters as speech units to recognize the language spoken by native speakers over the telephone. We extend our previous work comparing phoneme-cluster and phoneme based approaches to language identification [1]. By creating a new speech unit valid across all languages in a theoretically motivated manner, we circumvent problems that are associated with fine phonemic modelling such as high complexity [4], extensive training requirements [2], and the linguistically arbitrary reduction to subsets of phonemes [4]. A common set of speech units across languages allows us to automatically derive discriminating sequences of any length and theoretically estimate the language identification error. We demonstrate our implemented system for German vs. English on the OGI-TS database. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. M. Berkling and E. Barnard. </author> <title> Language identification with multilingual phoneme clusters. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing 94, </booktitle> <volume> volume 4, </volume> <pages> pages 1891-1894, </pages> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Thus, adding a word to a given list results in the following distributions for the language pair i = 1,2 (assuming independence of sequence occurrences): List ' N (u i <ref> [1] </ref>+ffu i [2]; s i [1] 2 +ff 2 s i [2] 2 ) = N ( i ; i ) ff is chosen to minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect to ff, yielding: <p> [2] f 2 [2] f 1 [2] )( s 2 [2] 2 + s 1 [2] 2 ) Given the optimal ff, a word is added to the list iff 1 e 4 [ ( 2 1) 2 1 + 2 ] 1 e 4 [ (u 2 <ref> [1] </ref>u 1 [1]) 2 ; that is, if the estimated error rate after adding the word is smaller or equal to the error rate before adding the word. Phoneme-Cluster Derivation This next step consists of repeating the above procedures by iteratively merging the two closest phoneme clusters.
Reference: [2] <author> S. Kadambe and J. L. Hieronymus. </author> <title> Spontaneous speech language identification with a knowledge of linguistics. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing 94, </booktitle> <volume> volume 4, </volume> <pages> pages 1879-1882, </pages> <address> Yoko-hama, Japan, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Thus, adding a word to a given list results in the following distributions for the language pair i = 1,2 (assuming independence of sequence occurrences): List ' N (u i [1]+ffu i <ref> [2] </ref>; s i [1] 2 +ff 2 s i [2] 2 ) = N ( i ; i ) ff is chosen to minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect <p> Thus, adding a word to a given list results in the following distributions for the language pair i = 1,2 (assuming independence of sequence occurrences): List ' N (u i [1]+ffu i <ref> [2] </ref>; s i [1] 2 +ff 2 s i [2] 2 ) = N ( i ; i ) ff is chosen to minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect to ff, yielding: () ff ( p [2] f <p> i <ref> [2] </ref> 2 ) = N ( i ; i ) ff is chosen to minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect to ff, yielding: () ff ( p [2] f 2 [2] f 1 [2] )( s 2 [2] 2 + s 1 [2] 2 ) Given the optimal ff, a word is added to the list iff 1 e 4 [ ( 2 1) 2 1 + 2 ] 1 e 4 [ (u 2 [1]u 1 [1]) <p> ) = N ( i ; i ) ff is chosen to minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect to ff, yielding: () ff ( p <ref> [2] </ref> f 2 [2] f 1 [2] )( s 2 [2] 2 + s 1 [2] 2 ) Given the optimal ff, a word is added to the list iff 1 e 4 [ ( 2 1) 2 1 + 2 ] 1 e 4 [ (u 2 [1]u 1 [1]) 2 ; that <p> ( i ; i ) ff is chosen to minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect to ff, yielding: () ff ( p <ref> [2] </ref> f 2 [2] f 1 [2] )( s 2 [2] 2 + s 1 [2] 2 ) Given the optimal ff, a word is added to the list iff 1 e 4 [ ( 2 1) 2 1 + 2 ] 1 e 4 [ (u 2 [1]u 1 [1]) 2 ; that is, if the <p> ) ff is chosen to minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect to ff, yielding: () ff ( p <ref> [2] </ref> f 2 [2] f 1 [2] )( s 2 [2] 2 + s 1 [2] 2 ) Given the optimal ff, a word is added to the list iff 1 e 4 [ ( 2 1) 2 1 + 2 ] 1 e 4 [ (u 2 [1]u 1 [1]) 2 ; that is, if the estimated error rate after <p> minimize the classification error, i.e. the overlap between N ( 1 ; 1 ) and N ( 2 ; 2 ) by differentiating the Mahalanobis distance with respect to ff, yielding: () ff ( p <ref> [2] </ref> f 2 [2] f 1 [2] )( s 2 [2] 2 + s 1 [2] 2 ) Given the optimal ff, a word is added to the list iff 1 e 4 [ ( 2 1) 2 1 + 2 ] 1 e 4 [ (u 2 [1]u 1 [1]) 2 ; that is, if the estimated error rate after adding the word is smaller
Reference: [3] <author> Y. K. Muthusamy. </author> <title> A Segmental Approach to Automatic Language Identification. </title> <type> PhD thesis, </type> <institution> Oregon Graduate Institute, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: We exploit the tradeoff between the accuracy of the rec-ognizer and the imprecision of the phoneme model, by progressively merging phonemes into broader language-independent speech units. At the extremes we obtain either a phoneme-based system or a broad-category-based system <ref> [3] </ref>. Because sequences in both languages can now be expressed in terms of these derived speech units, we have gained the capability to automatically select discriminating features consisting of the occurrence frequencies of sequences of speech units.
Reference: [4] <author> M. A. Zissman and E. Singer. </author> <title> Automatic language identification of telephone speech messages using phoneme recognition and n-gram modelling. </title> <booktitle> In Proceedings 1994 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> pages I-305 - I-308, Adelaide, Australia, </address> <month> April </month> <year> 1994. </year>
References-found: 4

