URL: ftp://ftp.aic.nrl.navy.mil/pub/papers/1992/AIC-92-009.ps
Refering-URL: http://www.aic.nrl.navy.mil/~schultz/papers.html
Root-URL: 
Email: EMAIL: schultz@aic.nrl.navy.mil  
Phone: (202) 767-2684  
Title: USING A GENETIC ALGORITHM TO LEARN BEHAVIORS FOR AUTONOMOUS VEHICLES  
Author: Alan C. Schultz and John J. Grefenstette 
Address: (Code 5514),  DC 20375-5000, U.S.A.  
Affiliation: Navy Center for Applied Research in Artificial Intelligence  Naval Research Laboratory, Washington,  
Abstract: Truly autonomous vehicles will require both projec - tive planning and reactive components in order to perform robustly. Projective components are needed for long-term planning and replanning where explicit reasoning about future states is required. Reactive components allow the system to always have some action available in real-time, and themselves can exhibit robust behavior, but lack the ability to expli - citly reason about future states over a long time period. This work addresses the problem of creating reactive components for autonomous vehicles. Creating reactive behaviors (stimulus-response rules) is generally difficult, requiring the acquisition of much knowledge from domain experts, a problem referred to as the knowledge acquisition bottleneck. SAMUEL is a system that learns reactive behaviors for autonomous agents. SAMUEL learns these behaviors under simulation, automating the process of creating stimulus-response rules and therefore reducing the bottleneck. The learning algorithm was designed to learn useful behaviors from simulations of limited fidelity. Current work is investigating how well behaviors learned under simulation environments work in real world environments. In this paper, we describe SAMUEL, and describe behaviors that have been learned for simulated autonomous aircraft, autonomous underwater vehicles, and robots. These behaviors include dog fighting, missile evasion, track - ing, navigation, and obstacle avoidance. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Arkin, R. C. </author> <year> (1989). </year> <title> Motor schema-based mobile robot navigation. </title> <journal> The International Journal of Robotics Research (pp. </journal> <pages> 92-112). </pages>
Reference: <author> Brooks, R. A. </author> <year> (1991). </year> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47, </volume> <publisher> Elsevier, </publisher> <pages> (pp. 139-159). </pages>
Reference-contexts: 1. Introduction As hardware issues are being resolved, and as competent low-level controllers are being designed, attention in autonomous vehicle design is now focusing more on the higher level autonomic functions of these vehicles. Historically, many researchers have examined either projective planning (e.g. Kanade, 1990) or reactive systems <ref> (e.g. Brooks, 1991) </ref> in isolation for control of an autonomous vehicle.
Reference: <author> Davis, L. </author> <year> (1991). </year> <title> Handbook of Genetic Algorithms New York: </title> <publisher> Van Nostrand Reinhold. </publisher>
Reference: <author> De Jong, K. A. </author> <year> (1975). </year> <title> Analysis of the behavior of a class of genetic adaptive systems. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer and Communications Sciences, University of Michigan, </institution> <address> Ann Arbor. </address>
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic algorithms in search, optimization, </title> <booktitle> and machine learning. </booktitle> <address> Reading: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Grefenstette, J. J. </author> <year> (1986). </year> <title> Optimization of control parameters for genetic algorithms. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, SMC-16(1). </journal>
Reference-contexts: Goldberg (1989) and Davis (1991) provide a detailed discussion of genetic algorithms. The learning level of SAMUEL is a specialized version of a standard genetic algorithm, GENESIS <ref> (Grefenstette, 1986) </ref>. In SAMUEL, the knowledge structures that make up the population are behaviors, or sets of reactive rules, that represent a strategy for solving the problem. The remainder of this section outlines the differences between GENESIS and the genetic algorithm in SAMUEL. 2.3.2.1.
Reference: <author> Grefenstette, J. J. </author> <year> (1988). </year> <title> Credit assignment in rule discovery system based on genetic algorithms. </title> <journal> Machine Learning, </journal> <volume> 3(2/3), </volume> <pages> (pp. 225-245). </pages>
Reference: <author> Grefenstette, J. J. </author> <year> (1989). </year> <title> A system for learning control plans with genetic algorithms. </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms. </booktitle> <address> Fairfax, VA: </address> <publisher> Morgan Kaufmann. </publisher> <pages> (pp. 183-190). </pages>
Reference: <author> Grefenstette, J. J., C. L. Ramsey, and A. C. </author> <title> Schultz (1990). Learning sequential decision rules using simulation models and competition. </title> <journal> Machine Learning, </journal> <volume> 5(4), </volume> <pages> (pp. 355-381). </pages>
Reference-contexts: Previous studies have illustrated that knowledge learned under simulation is robust and might be applicable to the real world if the simulation is more general (i.e. has more noise, more varied conditions, etc.) than the real world environment <ref> (Ramsey, Schultz and Grefenstette, 1990) </ref>, and work continues in this area. The approach described here reflects a particular methodology for learning via a simulation model. The motivation is that making mistakes on real systems may be costly or dangerous. <p> Earlier work indicated that it is important for the simulation model to include more variability and noise that the actual environment <ref> (Grefenstette, Ramsey and Schultz, 1990) </ref>. In this study, noise is included in the sensors, and each initial environment is comprised of a random mine field. 2.3.2.3. Selection Plans are selected for reproduction on the basis of their overall fitness scores returned by CPS.
Reference: <author> Holland, J. H. </author> <year> (1975). </year> <booktitle> Adaptation in natural and artificial systems. </booktitle> <address> Ann Arbor: </address> <publisher> University Michigan Press. </publisher>
Reference-contexts: Creating reactive behaviors (stimulus-response rules) is generally difficult, requiring the acquisition of knowledge from domain experts, a problem referred to as the knowledge acquisition bottleneck. This paper presents work on SAMUEL, a system that learns reactive behaviors for autonomous agents. SAMUEL, based on genetic algorithms <ref> (Holland, 1975) </ref>, learns these behaviors under simulation, automating the pro cess of creating stimulus-response rules and therefore 1 TARGET ENVIRONMENT RULE INTERPRETER ACTIVE BEHAVIOR SIMULATION MODEL RULE INTERPRETER LEARNING MODULE TEST BEHAVIOR ON-LINE SYSTEM OFF-LINE SYSTEM Fig. 1. A Model for Learning from a Simulation Model. reducing the bottleneck. <p> As a result, the settings for different control variables may be recommended by distinct rules. 5 of heredity and evolution in the field of population genetics, and embody abstractions of the mechanisms of adaptation present in natural systems <ref> (Holland, 1975) </ref>. Briefly, a genetic algorithm simulates the dynamics of population genetics by maintaining a knowledge base of knowledge structures that evolves over time in response to the observed performance of its knowledge structures in their training environment.
Reference: <author> Laird, J. E., E. S. Yager, M. Hucka, and C. M. </author> <title> Tuck (1991). Robo-Soar: An integration of external interaction, planning, and learning using Soar. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <pages> 8(1-2), (pp. 113-129) Ramsey, </pages> <editor> C. L., Alan C. Schultz and J. J. Grefenstette (1990). </editor> <title> Simulation-assisted learning by competition: Effects of noise differences between training model and target environment. </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning. </booktitle> <address> Austin, TX: </address> <publisher> Morgan Kaufmann (pp. </publisher> <pages> 211-215). </pages>
Reference: <author> Schultz, A. C. and J. J. </author> <title> Grefenstette (1990). Improving tactical plans with genetic algorithms. </title> <booktitle> Proceeding of IEEE Conference on Tools for AI 90, </booktitle> <address> Washington, DC: </address> <note> IEEE (pp. </note> <month> 328-334). </month> <title> 11 This paper is declared a work of the U.S. Government and is not subject to copyright protection in the United States. </title> <type> 12 </type>
Reference-contexts: Previous studies have illustrated that knowledge learned under simulation is robust and might be applicable to the real world if the simulation is more general (i.e. has more noise, more varied conditions, etc.) than the real world environment <ref> (Ramsey, Schultz and Grefenstette, 1990) </ref>, and work continues in this area. The approach described here reflects a particular methodology for learning via a simulation model. The motivation is that making mistakes on real systems may be costly or dangerous. <p> Of course, the new rule is likely to need further modification, and is subject to further competition with the other rules. A third approach is to seed the initial population with existing knowledge <ref> (Schultz and Grefen-stette, 1990) </ref>. The rule language of SAMUEL was designed to facilitate the inclusion of available knowledge. <p> Earlier work indicated that it is important for the simulation model to include more variability and noise that the actual environment <ref> (Grefenstette, Ramsey and Schultz, 1990) </ref>. In this study, noise is included in the sensors, and each initial environment is comprised of a random mine field. 2.3.2.3. Selection Plans are selected for reproduction on the basis of their overall fitness scores returned by CPS.
References-found: 12

