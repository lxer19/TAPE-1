URL: ftp://speech.cse.ogi.edu/pub/docs/langid_icassp96.ps.gz
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Email: yan@cse.ogi.edu barnard@cse.ogi.edu  
Title: EXPERIMENTS FOR AN APPROACH TO LANGUAGE IDENTIFICATION WITH CONVERSATIONAL TELEPHONE SPEECH for Spoken Language Understanding
Author: Yonghong Yan Etienne Barnard 
Note: Without the  
Address: 20000 N.W.Walker Road, Portland, OR 97291-1000  
Affiliation: Center  Oregon Graduate Institute of Science and Technology  
Abstract: This paper presents our recent work on language identification research using conversational speech (the LDC Conversational Telephone Speech Database). The baseline system used in this study was developed recently ([4, 5]). It is based on language-dependent phone recognition and phonotactic constraints. The system was trained using monologue data and obtained an error rate of around 9% on a commonly used nine-language monologue test set. While the system was used to process conversational speech from the same nine-language task, dramatic performance degradation (with an error rate of 40%) was observed. Based on our analysis of conversational speech, two methods: (1) pre-processing and, (2) post-processing, were proposed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y.K. Muthusamy, E. Barnard, and R. A. Cole. </author> <title> Reviewing automatic language identification. </title> <journal> IEEE Signal Processing Magazine, </journal> <volume> 11(4) </volume> <pages> 33-41, </pages> <month> October </month> <year> 1994. </year>
Reference: [2] <author> Y. Yan and E. Barnard. </author> <title> A comparison of neural net and linear classifier as the pattern recognizer in automatic language identification. In International Conference on Neural Networks and Signal Processing (ICNNSP95), </title> <note> page To Appear, Nanjing, P.R.China, </note> <month> December, </month> <year> 1995. </year>
Reference: [3] <author> Y. Yan and E. Barnard. </author> <title> Recent improvements to a phonotactic approach to language identification. </title> <booktitle> In the Fifteenth Annual Speech Research Symposium XV, </booktitle> <pages> pages 212-219, </pages> <address> Baltimore, Maryland, </address> <month> June, </month> <year> 1995. </year>
Reference-contexts: Front End Six (M = 6) language-dependent phone recognizers were implemented; they are for English, German, Hindi, Japanese, Mandarin and Spanish. The phone accuracies for these six phone recognizers are approxiately 45% to 55%. Details can be found in <ref> [4, 3] </ref>. The recognizers run in parallel, and independently decode the input speech vectors into phone strings. The output of the recognizer is the time-aligned phone string with an acoustic probability attached to each phone in the string. 2.2.
Reference: [4] <author> Y. Yan and E. Barnard. </author> <title> An approach to automatic language identification based on language-dependent phone recognition. </title> <booktitle> In Proceedings 1995 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> pages V-3511 V-3514, Detroit, Michigan, USA, </address> <month> May, </month> <year> 1995. </year>
Reference-contexts: Front End Six (M = 6) language-dependent phone recognizers were implemented; they are for English, German, Hindi, Japanese, Mandarin and Spanish. The phone accuracies for these six phone recognizers are approxiately 45% to 55%. Details can be found in <ref> [4, 3] </ref>. The recognizers run in parallel, and independently decode the input speech vectors into phone strings. The output of the recognizer is the time-aligned phone string with an acoustic probability attached to each phone in the string. 2.2.
Reference: [5] <author> Y. Yan and E. Barnard. </author> <title> An approach to automatic language identification with enhanced language model. </title> <booktitle> In Eurospeech Proceedings, </booktitle> <pages> pages 1351 - 1354, </pages> <address> Madrid, Spain, </address> <month> September, </month> <year> 1995. </year>
Reference-contexts: P (O i jO i ) is the original context-independent mono-phone duration model, which is used here as a smoothing factor with weight ff. The language models were optimized by the method proposed in <ref> [5] </ref>. 2.3. Final Classifier A feed-forward neural network with one hidden layer and full connections between successive layers is used to learn the relations among these scores in our system. The output of the neural network is the final LID result of the input utterance. 3.
Reference: [6] <author> M.A. Zissman and A. Martin. </author> <title> Language identification overview. </title> <booktitle> In Proceedings of the Fifteenth Annual Speech Research Symposium, </booktitle> <pages> pages 2 - 14, </pages> <address> Baltimore, USA, </address> <month> June </month> <year> 1995. </year>
References-found: 6

