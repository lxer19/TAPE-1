URL: http://http.cs.berkeley.edu/~yyz/publication/rerend.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~yyz/publication/publication.html
Root-URL: 
Title: Recovering Photometric Properties Of Architectural Scenes From Photographs  
Author: Yizhou Yu Jitendra Malik 
Keyword: CR Categories: I.2.10 [Artificial Intelligence]: Vision and Scene Understandingmodeling and recovery of physical attributes I.3.7 [Computer Graphics]: Three-dimensional Graphics and Realismcolor, shading, shadowing, and texture visible line/surface algorithms I.4.8 [Image Processing]: Scene Analysiscolor, photometry, shading Keywords: Photometric Properties, Image-based Rendering, Illumination, Sky Model, Reflectance, BRDF, Photometric Stereo  
Address: Berkeley  
Affiliation: Computer Science Division University Of California At  
Abstract: In this paper, we present a new approach to producing photoreal-istic computer renderings of real architectural scenes under novel lighting conditions, such as at different times of day, starting from a small set of photographs of the real scene. Traditional texture mapping approaches to image-based modeling and rendering are unable to do this because texture maps are the product of the interaction between lighting and surface reflectance and one cannot deal with novel lighting without dissecting their respective contributions. To obtain this decomposition into lighting and reflectance, our basic approach is to solve a series of optimization problems to find the parameters of appropriate lighting and reflectance models that best explain the measured values in the various photographs of the scene. The lighting models include the radiance distributions from the sun and the sky, as well as the landscape to consider the effect of secondary illumination from the environment. The reflectance models are for the surfaces of the architecture. Photographs are taken for the sun, the sky, the landscape, as well as the architecture at a few different times of day to collect enough data for recovering the various lighting and reflectance models. We can predict novel illumination conditions with the recovered lighting models and use these together with the recovered reflectance values to produce renderings of the scene. Our results show that our goal of generating photore-alistic renderings of real architectural scenes under novel lighting conditions has been achieved. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> BRUNGER, A., AND HOOPER, F. </author> <title> Anisotropic sky radiance model based on narrow field of view measurements of shortwave radiance. Solar Energy 51, </title> <booktitle> 1 (1993), </booktitle> <pages> 53-64. </pages>
Reference-contexts: Furthermore, physical models often give the spectral distribution of any point in the sky. It is very hard to fit these models to RGB data taken from photographs. On the other hand, there are also many empirical models for sky luminance or radiance distribution <ref> [16, 1, 13, 8] </ref>. All CIE standard sky formulae are fixed sky luminance distributions. They can not be used for the purpose of data-fitting. The all-weather sky luminance model proposed in [16] is a generalization of the CIE standard clear sky formula.
Reference: [2] <author> DANA, K., VAN GINNEKEN, B., NAYAR, S., AND KOEN DERINK, J. </author> <title> Reflectance and texture of real-world surfaces. </title> <booktitle> In proceedings of CVPR (1997), </booktitle> <pages> pp. 151-157. </pages>
Reference-contexts: Note the dependence on wavelength . There has been some some previous work using a spectrophotometer to carefully measure spectral BRDFs <ref> [2] </ref>. However, we concluded that it is impractical to use such a technique to measure the BRDFs of complex, outdoor scenes. Our philosophy is to work with whatever information can be extracted from photographs, and we will use just an ordinary handheld digital video camcorder to acquire these photographs. <p> There has been a lot of previous work <ref> [24, 19, 20, 11, 2] </ref> trying to fit empirical or physics-based models to measured data and then using the obtained model into illumination calculation.
Reference: [3] <author> DEBEVEC, P., AND MALIK, J. </author> <title> Recovering high dynamic range radiance maps from photographs. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1997), </booktitle> <pages> pp. 369-378. </pages>
Reference-contexts: We highlight a few of them here: 1. The photographs do not directly give us radiance measurements-there is a nonlinear mapping which relates the digital values from the photograph to the radiance in the direction of that image pixel. This can be estimated using the technique from <ref> [3] </ref>, and subsequent processing performed using radiance images. 2. Any measurements that we make from photographs cannot be used to recover the full spectral BRDF. We need to define a new concept, the pseudo-BRDF associated with a particular spectral distribution of the illuminant. This is done in Section 2. <p> To accurately measure the radiance, we need to convert the photographs into radiance images by inverting the nonlinear mapping between the incident radiance of the camera and its digital output. To recover this nonlinear mapping, we use the technique described in <ref> [3] </ref>. 3.1 The Sun We can measure the radiance of the sun with a camera and a couple of neutral density filters (Figure 2 (a)) to make it unsaturated so that we can recover its dynamic radiance using the nonlinear mapping introduced before. <p> Alternatively, we could use any standard mosaicing technique for the environment photographs. Exterior orientation is calibrated with a compass map or the solar position. Photometric calibration of the camera is done using the technique in <ref> [3] </ref>. Once we have recovered the nonlinear mapping between incident radiance and camera output, we can use it to further recover the radiance at each pixel. To extend the dynamic range, it is necessary to take photographs at different shutter speeds. The technique from [3] enables the combined use of these <p> is done using the technique in <ref> [3] </ref>. Once we have recovered the nonlinear mapping between incident radiance and camera output, we can use it to further recover the radiance at each pixel. To extend the dynamic range, it is necessary to take photographs at different shutter speeds. The technique from [3] enables the combined use of these to recover a high dynamic range radiance image. All subsequent processing in the system uses radiance values.
Reference: [4] <author> DEBEVEC, P., TAYLOR, C., AND MALIK, J. </author> <title> Modeling and rendering architecture from photographs: A hybrid geometry-and image-based approach. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1996), </booktitle> <pages> pp. 11-20. </pages>
Reference-contexts: Previous work on the FACADE system <ref> [4] </ref> has shown that it is possible to use a combination of geometric models recovered from photographs, and projective texture mapping with textures derived from the same photographs, to generate extremely photorealistic renderings of the scene from novel viewpoints. <p> We also took photographs at a fifth time. Those photographs are used for comparison with re-rendered images. They can be considered as testing data. Relative positions and orientations of the cameras are currently calibrated by using the FACADE system in <ref> [4] </ref>. Alternatively, we could use any standard mosaicing technique for the environment photographs. Exterior orientation is calibrated with a compass map or the solar position. Photometric calibration of the camera is done using the technique in [3]. <p> In Figure 13, we give a resulting image from this kind of re-rendering. A low-resolution image from previously recovered reflectance is also given for comparison. By taking zoom-in photographs at various camera positions, we can combine this technique with view-dependent texture mapping <ref> [4] </ref>. 7 CONCLUSIONS AND FUTURE WORK In this paper, we proposed a method to extend image-based modeling and rendering techniques to deal with producing renderings under novel lighting conditions.
Reference: [5] <author> DEBEVEC, P., YU, Y., AND BORSHUKOV, G. </author> <title> Efficient view dependent image-based rendering with projective texture-mapping. </title> <type> UC Berkeley technical report #UCB//CSD-98-1003. </type>
Reference: [6] <author> GORTLER, S., GRZESZCZUK, R., SZELISKI, R., AND CO HEN, M. </author> <booktitle> The lumigraph. In Computer Graphics Proceedings, Annual Conference Series (1996), </booktitle> <pages> pp. </pages> <month> 43-54. </month> <title> (a) (b) (c) the bell tower at different times(solar positions) on a sunny day close to the end of August at a location with latitude 37.8 and longitude -122.3. (a) 7am, </title> <editor> (b) 1pm, (c) 4pm, (d) 6pm, (e) 6:30pm. blocked sunlight(PBS). (a) PBS=0.0, (b) PBS=0.5, (c) PBS=0.9, </editor> <address> (d) PBS=0.95. </address>
Reference-contexts: Other approaches to image-based rendering <ref> [14, 12, 6, 21] </ref> share the same general difficulty.
Reference: [7] <author> HAMPEL, F., ROUSSEEUW, P., RONCHETTI, E., AND STA HEL, W. </author> <title> Robust Statistics. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: This means it is possible to apply better but more expensive global optimization techniques. We use the downhill simplex method with simulated annealing [17], which allows us to apply some techniques <ref> [17, 7] </ref> for robust parameter estimation. Robust estimation tries to minimize N X %( i where %(z) is a nonlinear function of a single variable z [y i y (x i )]= i , in order to estimate , the vector of parameters. <p> Classic least squares corresponds to using %(z) = z 2 , and is very sensitive to outliers. By a suitable choice of %(z), in our experiments %(z) = 1exp (jzj=2) 1+exp (jzj=2) , one can suppress the influence of outliers in the data. We refer the reader to <ref> [7] </ref> for extensive discussion on this topic, as well as a technique for estimating i .
Reference: [8] <author> INEICHEN, P., MOLINEAUX, B., AND PEREZ, R. </author> <title> Sky lumi nance data validation: Comparison of seven models with four data banks. Solar Energy 52, </title> <booktitle> 4 (1994), </booktitle> <pages> 337-346. </pages>
Reference-contexts: Furthermore, physical models often give the spectral distribution of any point in the sky. It is very hard to fit these models to RGB data taken from photographs. On the other hand, there are also many empirical models for sky luminance or radiance distribution <ref> [16, 1, 13, 8] </ref>. All CIE standard sky formulae are fixed sky luminance distributions. They can not be used for the purpose of data-fitting. The all-weather sky luminance model proposed in [16] is a generalization of the CIE standard clear sky formula.
Reference: [9] <author> KLASSEN, R. </author> <title> Modeling the effect of the atmosphere on light. </title> <journal> ACM Transactions on Graphics 6, </journal> <volume> 3 (1987), </volume> <pages> 215-237. </pages>
Reference-contexts: To solve the last problem, we use a set of different shutter speeds for the solar aureole with each speed capturing the radiance inside a circular band centered at the solar position (Figure 2 (b)). Several papers present physical models of sky radiance <ref> [22, 9, 23] </ref>. However, we do not know how closely they approximate the real sky. Furthermore, physical models often give the spectral distribution of any point in the sky. It is very hard to fit these models to RGB data taken from photographs. <p> During sunrise or sunset, there is less light from short wavelengths. So the sun and solar aureole appear more red. The whole sky is darker. But the color of the rest of the sky only changes a little. It is well known, e.g. <ref> [9] </ref>, that the color of the sky and sun is caused by scattering in the atmosphere. If a light beam travels a distance d in a medium with scattering particles, its intensity will be decreased by a factor of exp (fid) where fi is a constant coefficient. <p> The optical depth of the atmosphere at the horizon is about 38 times that at the zenith. A formula to compute d for any solar position can be found in <ref> [9] </ref> which tries to get the color of the sun and sky from physics-based models. However, we want to fit the above scattering model to real measurements. We measured solar radiance during the day and sunset and fit a distinct fi for each color channel.
Reference: [10] <author> KOENDERINK, J., AND VAN DOORN, A. </author> <title> Illuminance texture due to surface mesostructure. </title> <journal> J. Opt. Soc. </journal> <volume> Am.A 13, 3 (1996), </volume> <pages> 452-463. </pages>
Reference: [11] <author> LAFORTUNE, E., FOO, S., TORRANCE, K., AND GREEN BERG, D. </author> <title> Non-linear approximation of reflectance functions. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1997), </booktitle> <pages> pp. 117-126. </pages>
Reference-contexts: There has been a lot of previous work <ref> [24, 19, 20, 11, 2] </ref> trying to fit empirical or physics-based models to measured data and then using the obtained model into illumination calculation. <p> A solution to this difficulty might be to fill in reflectance values from adjacent faces. 4.2 Recovering The Specular Lobes Of The Pseudo-BRDFs We adopt the empirical model in <ref> [11] </ref> to recover specular lobes because this model can effectively simulate effects such as specularity at grazing angles, off-specular reflections and etc.
Reference: [12] <author> LEVOY, M., AND HANRAHAN, P. </author> <title> Light field rendering. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1996), </booktitle> <pages> pp. 31-42. </pages>
Reference-contexts: Other approaches to image-based rendering <ref> [14, 12, 6, 21] </ref> share the same general difficulty.
Reference: [13] <author> LITTLEFAIR, P. </author> <title> A comparison of sky luminance models with measured data from garston, united kingdom. Solar Energy 53, </title> <booktitle> 4 (1994), </booktitle> <pages> 315-322. </pages>
Reference-contexts: Furthermore, physical models often give the spectral distribution of any point in the sky. It is very hard to fit these models to RGB data taken from photographs. On the other hand, there are also many empirical models for sky luminance or radiance distribution <ref> [16, 1, 13, 8] </ref>. All CIE standard sky formulae are fixed sky luminance distributions. They can not be used for the purpose of data-fitting. The all-weather sky luminance model proposed in [16] is a generalization of the CIE standard clear sky formula. <p> Then the color at a point in the sky is simply a linear interpolation between the color of a clear sky and the color of the overcast sky. Actually some sky luminance models reviewed in <ref> [13] </ref> really use this kind of interpolation between two extreme sky models. A sequence of images are shown in Figure 12. It gives re-rendering results with various sky interpolation coefficients.
Reference: [14] <author> MCMILLAN, L., AND BISHOP, G. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1995), </booktitle> <pages> pp. 39-46. </pages>
Reference-contexts: Other approaches to image-based rendering <ref> [14, 12, 6, 21] </ref> share the same general difficulty.
Reference: [15] <author> NISHITA, T., AND NAKAMAE, E. </author> <title> Continuous tone represen tation of three-dimensional objects illuminated by sky light. </title> <booktitle> Computer Graphics 20, 4 (1986), </booktitle> <pages> 125-132. </pages>
Reference-contexts: We will discuss gathering light from the sky and environment in Appendix A. Gathering light from occluding faces can be done using the method in <ref> [15] </ref>. We use one-bounce reflection to approximate the interreflection among different faces. Multiple photographs are taken for the considered building at different viewing directions and times (Figure 5).
Reference: [16] <author> PEREZ, R., SEALS, R., AND MICHALSKY, J. </author> <title> All-weather model for sky luminance distribution-preliminary configuration and validation. Solar Energy 50, </title> <booktitle> 3 (1993), </booktitle> <pages> 235-245. </pages>
Reference-contexts: Furthermore, physical models often give the spectral distribution of any point in the sky. It is very hard to fit these models to RGB data taken from photographs. On the other hand, there are also many empirical models for sky luminance or radiance distribution <ref> [16, 1, 13, 8] </ref>. All CIE standard sky formulae are fixed sky luminance distributions. They can not be used for the purpose of data-fitting. The all-weather sky luminance model proposed in [16] is a generalization of the CIE standard clear sky formula. <p> On the other hand, there are also many empirical models for sky luminance or radiance distribution [16, 1, 13, 8]. All CIE standard sky formulae are fixed sky luminance distributions. They can not be used for the purpose of data-fitting. The all-weather sky luminance model proposed in <ref> [16] </ref> is a generalization of the CIE standard clear sky formula.
Reference: [17] <author> PRESS, W., FLANNERY, B., TEUKOLSKY, S., AND VETTER LING, W. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge Univ. Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Skies thus obtained have convincing colors. Since there might be trees, buildings or mountains in photographs, we interactively pick some sky regions from each photograph and fit the revised sky model to the chosen sky radiance data by using Levenberg-Marquardt method <ref> [17] </ref> to minimize the weighted least-square N X [ i 2 where y i 's are the chosen sky radiance data from photographs and i 's are weights. <p> This means it is possible to apply better but more expensive global optimization techniques. We use the downhill simplex method with simulated annealing <ref> [17] </ref>, which allows us to apply some techniques [17, 7] for robust parameter estimation. <p> This means it is possible to apply better but more expensive global optimization techniques. We use the downhill simplex method with simulated annealing [17], which allows us to apply some techniques <ref> [17, 7] </ref> for robust parameter estimation. Robust estimation tries to minimize N X %( i where %(z) is a nonlinear function of a single variable z [y i y (x i )]= i , in order to estimate , the vector of parameters.
Reference: [18] <author> REES, W. </author> <title> Physical Principles of Remote Sensing. </title> <publisher> Cambridge Univ. Press, </publisher> <year> 1990. </year>
Reference-contexts: The solid angle subtended by the sun can be obtained from the diameter of the sun and the distance between the sun and the earth. The solar position (altitude and azimuth) can be obtained from formula given in the appendix of <ref> [18] </ref>, provided that the latitude and longitude of the site on the earth's surface, and the time and date are known. We model the sun as a parallel light source. 3.2 The Sky We can take photographs of the sky in order to measure its radiance distribution. <p> illumination models for a few times of day where we took the initial photographs, recovered using the techniques introduced in Section 3. 5.1 The Sun And Sky Given the local time of day, the solar position (altitude and azimuth) can be obtained directly from formula given in the appendix of <ref> [18] </ref>, provided that the latitude and longitude of the site on the earth's surface and the day number in a year are all known. Finding the appropriate sky model requires more work. First we consider sky interpolation during the main part of the day, ignoring sunrise and sunset.
Reference: [19] <author> SATO, Y., AND IKEUCHI, K. </author> <title> Reflectance analysis for 3d com puter graphics model generation. Graphical Models and Image Processing 58, </title> <booktitle> 5 (1996), </booktitle> <pages> 437-451. </pages>
Reference-contexts: There has been a lot of previous work <ref> [24, 19, 20, 11, 2] </ref> trying to fit empirical or physics-based models to measured data and then using the obtained model into illumination calculation.
Reference: [20] <author> SATO, Y., WHEELER, M., AND IKEUCHI, K. </author> <title> Object shape and reflectance modeling from observation. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1997), </booktitle> <pages> pp. 379-388. </pages>
Reference-contexts: There has been a lot of previous work <ref> [24, 19, 20, 11, 2] </ref> trying to fit empirical or physics-based models to measured data and then using the obtained model into illumination calculation. <p> Each polygon in the geometric model is first triangulated and a dense grid is set up on each triangle in order to capture the variations. This step is similar to that introduced in <ref> [20] </ref>. Each grid point is projected onto the photographs to which it is visible and a radiance value is taken from each photograph. The diffuse pseudo-albedo at the grid point is obtained by dividing the average radiance by the irradiance.
Reference: [21] <author> SZELISKI, R., AND SHUM, H. </author> <title> Creating full view panoramic mosaics and environment maps. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1997), </booktitle> <pages> pp. 251-258. </pages>
Reference-contexts: Other approaches to image-based rendering <ref> [14, 12, 6, 21] </ref> share the same general difficulty.
Reference: [22] <author> TADAMURA, K., NAKAMAE, E., KANEDA, K., BABA, M., YAMASHITA, H., AND NISHITA, T. </author> <title> Modeling of skylight and rendering of outdoor scenes. </title> <booktitle> Proceedings of EUROGRAPH-ICS'93, Computer Graphics Forum 12, 3 (1993), </booktitle> <pages> 189-200. </pages>
Reference-contexts: To solve the last problem, we use a set of different shutter speeds for the solar aureole with each speed capturing the radiance inside a circular band centered at the solar position (Figure 2 (b)). Several papers present physical models of sky radiance <ref> [22, 9, 23] </ref>. However, we do not know how closely they approximate the real sky. Furthermore, physical models often give the spectral distribution of any point in the sky. It is very hard to fit these models to RGB data taken from photographs.
Reference: [23] <author> TAKAGI, A., TAKAOKA, H., OSHIMA, T., AND OGATA, Y. </author> <title> Accurate rendering technique based on colorimetric conception. </title> <booktitle> Computer Graphics 24, </booktitle> <month> 4 </month> <year> (1990), 1990. </year>
Reference-contexts: To solve the last problem, we use a set of different shutter speeds for the solar aureole with each speed capturing the radiance inside a circular band centered at the solar position (Figure 2 (b)). Several papers present physical models of sky radiance <ref> [22, 9, 23] </ref>. However, we do not know how closely they approximate the real sky. Furthermore, physical models often give the spectral distribution of any point in the sky. It is very hard to fit these models to RGB data taken from photographs. <p> Up to now, we still only have a sky luminance model which does not have colors. We have not seen in the literature any approach converting sky luminance models to RGB color distributions. The method proposed in <ref> [23] </ref> converts luminance data to color temperatures and then to spectral distributions. The relationship they use between luminance and color temperatures is not necessarily accurate for different weather conditions.
Reference: [24] <author> WARD, G. </author> <title> Measuring and modeling anisotropic reflection. </title> <booktitle> Computer Graphics 26, 2 (1992), </booktitle> <pages> 265-272. </pages>
Reference-contexts: There has been a lot of previous work <ref> [24, 19, 20, 11, 2] </ref> trying to fit empirical or physics-based models to measured data and then using the obtained model into illumination calculation.
Reference: [25] <author> WOODHAM, R. </author> <title> Photometric method for determining surface orientation from multiple images. In Shape from Shading, </title> <editor> B. Horn and M. Brooks, Eds. </editor> <publisher> MIT Press, </publisher> <year> 1989, </year> <pages> pp. 513-532. </pages>
Reference-contexts: We use the technique of photometric stereo for shape-from-shading in computer vision <ref> [25] </ref> to recover the average reflectance, assumed lambertian, and surface normal for each region of the environment.
References-found: 25

