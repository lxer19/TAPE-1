URL: http://www.ai.mit.edu/people/cohn/SAL95/Contributions/asker.ps
Refering-URL: http://www.ai.mit.edu/people/cohn/SAL95/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: asker@dsv.su.se  gamback@sics.se  
Title: Acquiring a Lexicon by Actively Querying the User  
Author: Lars Asker Bjorn Gamback 
Keyword: Natural Language Processing Group,  
Address: Electrum 230, S 164 40 Kista, Sweden  Box 1263, S 164 28 Kista, Sweden  
Affiliation: Dept. of Computer and Systems Sciences, Stockholm University,  Swedish Institute of Computer Science,  
Abstract: We present a semi-automatic approach to lexical acquisition which utilizes experiences from earlier systems by the authors and others. The hybrid system combines the subsystems in the following way: a fully automatic approach (EBL 2 ) is extended with grammatical constraints (SWECG) which filters output hypotheses, thus improving on the accuracy of the automatic paradigm assignments. Candidate sentences are generated using paradigm patterns from a semiautomatic lexical acquistion tool (VEX). These are presented to and judged for grammaticality by the user. This hybrid approach has several advantages compared to using either of the subsystems in isolation. It does not require any linguistic knowledge on the part of the user. Possible extensions to an existing lexicon are automatically selected by the system. Due to the strength of the combined strategy a 100% accuracy guarantee should be quite feasible. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Asker, L.; Gamback, B.; and Samuelsson, C. </author> <year> 1992. </year> <title> EBL 2 : An approach to automatic lexical acquisition. </title> <booktitle> In Proceedings of the 14th International Conference on Computational Linguistics, </booktitle> <volume> volume 4, </volume> <pages> 1172-1176. </pages>
Reference-contexts: The subsystems "Explanation-Based Lexical Learning"(EBL 2 ) is an automatic method to acquire new lexical entries by using EBL in combination with statistical methods <ref> (Asker, Gamback, & Samuelsson 1992) </ref>. A lexicon which, in addition to ordinary lexical entries, contains prototypical entries for various non-exclusive equivalence classes (paradigms) of open-class words, is extended by inferring new lexical entries from texts con taining unknown words.
Reference: <author> Asker, L. </author> <year> 1994. </year> <title> Partial Explanations as a Basis for Learning. </title> <institution> Doctor of Philosophy Thesis, Department of Computer and Systems Sciences, Stockholm University, Stockholm, Sweden. </institution>
Reference-contexts: The system had an overall accuracy of 63.5% in mapping unknown words to the correct one out of the 62 syntactic/semantic paradigms which are known by the present S-CLE grammar; 5 for Swedish nouns (including names), 10 for adjectives, and all the others for verbs <ref> (Asker 1994) </ref>. The system had difficulties in distinguishing between subclasses of nouns and adjectives, while it had a much better accuracy for common subclasses of verbs (79% as a total for all subclasses of verbs). Most of these un known words only occurred in a single sentence.
Reference: <author> Carter, D. </author> <year> 1989. </year> <title> Lexical acquisition in the Core Language Engine. </title> <booktitle> In Proceedings of the 4th Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <pages> 137-144. </pages>
Reference: <author> Gamback, B., and Rayner, M. </author> <year> 1992. </year> <title> The Swedish Core Language Engine. </title> <booktitle> In Papers from the 3rd Nordic Conference on Text Comprehension in Man and Machine, </booktitle> <pages> 71-85. </pages>
Reference-contexts: The grammatical properties of the unknown words are inferred by using example sentences from the VEX system. A typical situation where we think that this method is well suited is when a general purpose NL system with a core lexicon (such as the Swedish Core Language Engine, S-CLE <ref> (Gamback & Rayner 1992) </ref>) is to be customized to a specific application domain. The vocabulary used in the domain will include for example technical terms which are not present in the core lexicon. Also, the use of the words in the core lexicon may differ between domains. <p> The subsystems "Explanation-Based Lexical Learning"(EBL 2 ) is an automatic method to acquire new lexical entries by using EBL in combination with statistical methods <ref> (Asker, Gamback, & Samuelsson 1992) </ref>. A lexicon which, in addition to ordinary lexical entries, contains prototypical entries for various non-exclusive equivalence classes (paradigms) of open-class words, is extended by inferring new lexical entries from texts con taining unknown words.
Reference: <author> Gamback, B. </author> <year> 1992. </year> <title> Lexical acquisition: the Swedish VEX system. </title> <booktitle> In Papers from the 3rd Nordic Conference on Text Comprehension in Man and Machine, </booktitle> <pages> 59-70. </pages>
Reference-contexts: The grammatical properties of the unknown words are inferred by using example sentences from the VEX system. A typical situation where we think that this method is well suited is when a general purpose NL system with a core lexicon (such as the Swedish Core Language Engine, S-CLE <ref> (Gamback & Rayner 1992) </ref>) is to be customized to a specific application domain. The vocabulary used in the domain will include for example technical terms which are not present in the core lexicon. Also, the use of the words in the core lexicon may differ between domains. <p> The subsystems "Explanation-Based Lexical Learning"(EBL 2 ) is an automatic method to acquire new lexical entries by using EBL in combination with statistical methods <ref> (Asker, Gamback, & Samuelsson 1992) </ref>. A lexicon which, in addition to ordinary lexical entries, contains prototypical entries for various non-exclusive equivalence classes (paradigms) of open-class words, is extended by inferring new lexical entries from texts con taining unknown words.
Reference: <author> Kallgren, G. </author> <year> 1990. </year> <title> `The first million is hardest to get': Building a large tagged corpus as automatically as possible. </title> <booktitle> In Proceedings of the 13th International Conference on Computational Linguistics, </booktitle> <volume> volume 3, </volume> <pages> 400-404. </pages>
Reference-contexts: It builds on the paradigm lexicon and declarative knowledge of the range of sentential contexts in which the word usages in that lexicon can occur. Experimental evaluation Initial experiments have been performed with EBL 2 on an untagged part of the "SUC" <ref> (Kallgren 1990) </ref> Swedish corpus consisting of about 359; 500 words in approximately 52; 000 sentences.
Reference: <editor> Karlsson, F.; Voutilainen, A.; Heikkila, J.; and Anttila, A., eds. </editor> <year> 1995. </year> <title> Constraint Grammar: </title>
Reference-contexts: In cases where the tag assignments may be ambiguous, contraints on allowed structures are used to resolve most ambiguities, the unsolvable ones being left as they are. This rule-based strategy has proven surprisingly successful: the English version (ENGCG) <ref> (Karlsson et al. 1995) </ref> currently outperforms all competing approaches (statistical, connectionist, etc.) (Voutilainen 1995). A Swedish Constraint Grammar (SWECG) is currently being de veloped by the University of Helsinki.
References-found: 7

