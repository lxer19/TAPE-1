URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/fox/mosaic/people/cokasaki/icfp96.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/fox/mosaic/people/cokasaki/papers.html
Root-URL: 
Email: (e-mail: cokasaki@cs.cmu.edu)  
Title: The Role of Lazy Evaluation in Amortized Data Structures  
Author: Chris Okasaki 
Address: 5000 Forbes Avenue, Pittsburgh, Pennsylvania, USA 15213  
Affiliation: School of Computer Science, Carnegie Mellon University  
Abstract: Traditional techniques for designing and analyzing amortized data structures in an imperative setting are of limited use in a functional setting because they apply only to single-threaded data structures, yet functional data structures can be non-single-threaded. In earlier work, we showed how lazy evaluation supports functional amortized data structures and described a technique (the banker's method) for analyzing such data structures. In this paper, we present a new analysis technique (the physicist's method) and show how one can sometimes derive a worst-case data structure from an amortized data structure by appropriately scheduling the premature execution of delayed components. We use these techniques to develop new implementations of FIFO queues and binomial queues. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bror Bjerner and Soren Holmstrom. </author> <title> A compositional approach to time analysis of first order lazy functional programs. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 157-165, </pages> <year> 1989. </year>
Reference-contexts: We explore one class of such algorithms | amortized data structures | and describe techniques for reasoning about their complexity. Several researchers have developed theoretical frameworks for analyzing the time complexity of lazy programs <ref> [1, 19, 20, 25] </ref>. However, these frameworks are not yet mature enough to be useful in practice. One difficulty is that these frameworks are, in some ways, too general.
Reference: [2] <author> Gerth Sttlting Brodal and Chris Okasaki. </author> <title> Optimal purely functional priority queues. </title> <note> Submitted for publication. </note>
Reference-contexts: becomes the single completed zero between r 0 and r 1 . 2 Once we have an implementation of binomial queues supporting insert in O (1) worst-case time, we can improve the bounds of findMin and merge to O (1) worst-case time using the bootstrapping transformation of Brodal and Okasaki <ref> [2] </ref>. The O (log n) bound for deleteMin is unaffected by this transformation. 6 Related Work There has been very little previous work on amortized functional data structures. Schoenmakers [22] used functional notation to aid in deriving bounds for many amortized data structures, but considered only single-threaded data structures. <p> For every amortized functional data structure currently known, there is a competing worst-case data structure that does not depend on lazy evaluation. Examples include queues [8], double-ended queues [7, 4], catenable lists [12], and skew binomial queues <ref> [2] </ref>. In every case, the amortized data structure is significantly simpler than the worst-case version. However, the amortized data structure is usually slightly slower in practice, mostly because of overheads associated with lazy evaluation. Memoization, in particular, causes problems for many garbage collectors.
Reference: [3] <author> F. Warren Burton. </author> <title> An efficient functional implementation of FIFO queues. </title> <journal> Information Processing Letters, </journal> <volume> 14(5) </volume> <pages> 205-206, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: Schoenmakers [22] used functional notation to aid in deriving bounds for many amortized data structures, but considered only single-threaded data structures. Gries [6], Burton <ref> [3] </ref>, and Hoogerwoord [9] described purely functional queues and double-ended queues with amortized bounds, but, again, supported only single-threaded queues. We first described unrestricted amortized queues in [17] as an intermediate step in the development of worst-case queues based on lazy evaluation.
Reference: [4] <author> Tyng-Ruey Chuang and Benjamin Goldberg. </author> <title> Real-time deques, multihead Turing machines, and purely functional programming. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 289-298, </pages> <year> 1993. </year>
Reference-contexts: In addition, we introduce several new data structures, which may be useful in their own right. For every amortized functional data structure currently known, there is a competing worst-case data structure that does not depend on lazy evaluation. Examples include queues [8], double-ended queues <ref> [7, 4] </ref>, catenable lists [12], and skew binomial queues [2]. In every case, the amortized data structure is significantly simpler than the worst-case version. However, the amortized data structure is usually slightly slower in practice, mostly because of overheads associated with lazy evaluation.
Reference: [5] <author> James R. Driscoll, Neil Sarnak, Daniel D. K. Sleator, and Robert E. Tarjan. </author> <title> Making data structures persistent. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 38(1) </volume> <pages> 86-124, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: Instead, we develop ad hoc, but pragmatically useful, techniques for reasoning about the time complexity of lazy amortized data structures without regard to the contexts in which the data structures will be used. A data structure is called persistent <ref> [5] </ref> if, after an update, the old version of the data structure is still accessible. A data structure that is not persistent is called ephemeral. <p> In that case, the amortized data structure should usually be faster as well as simpler. Our research is also related to earlier studies in the im 67 perative community. Driscoll, Sarnak, Sleator, and Tar--jan <ref> [5] </ref> described several techniques for implementing persistent imperative data structures, and Raman [18] explored techniques for eliminating amortization from imperative data structures. 7 Discussion We have shown how lazy evaluation is essential to the design of amortized functional data structures, and given several techniques for analyzing such data structures.
Reference: [6] <editor> David Gries. </editor> <booktitle> The Science of Programming. Texts and Monographs in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: The O (log n) bound for deleteMin is unaffected by this transformation. 6 Related Work There has been very little previous work on amortized functional data structures. Schoenmakers [22] used functional notation to aid in deriving bounds for many amortized data structures, but considered only single-threaded data structures. Gries <ref> [6] </ref>, Burton [3], and Hoogerwoord [9] described purely functional queues and double-ended queues with amortized bounds, but, again, supported only single-threaded queues. We first described unrestricted amortized queues in [17] as an intermediate step in the development of worst-case queues based on lazy evaluation.
Reference: [7] <author> Robert Hood. </author> <title> The Efficient Implementation of Very-High-Level Programming Language Constructs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1982. </year>
Reference-contexts: In addition, we introduce several new data structures, which may be useful in their own right. For every amortized functional data structure currently known, there is a competing worst-case data structure that does not depend on lazy evaluation. Examples include queues [8], double-ended queues <ref> [7, 4] </ref>, catenable lists [12], and skew binomial queues [2]. In every case, the amortized data structure is significantly simpler than the worst-case version. However, the amortized data structure is usually slightly slower in practice, mostly because of overheads associated with lazy evaluation.
Reference: [8] <author> Robert Hood and Robert Melville. </author> <title> Real-time queue operations in pure Lisp. </title> <journal> Information Processing Letters, </journal> <volume> 13(2) </volume> <pages> 50-53, </pages> <month> November </month> <year> 1981. </year>
Reference-contexts: In addition, we introduce several new data structures, which may be useful in their own right. For every amortized functional data structure currently known, there is a competing worst-case data structure that does not depend on lazy evaluation. Examples include queues <ref> [8] </ref>, double-ended queues [7, 4], catenable lists [12], and skew binomial queues [2]. In every case, the amortized data structure is significantly simpler than the worst-case version. However, the amortized data structure is usually slightly slower in practice, mostly because of overheads associated with lazy evaluation.
Reference: [9] <author> Rob R. Hoogerwoord. </author> <title> A symmetric set of efficient list operations. </title> <journal> Journal of Functional Programming, </journal> <volume> 2(4) </volume> <pages> 505-513, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Schoenmakers [22] used functional notation to aid in deriving bounds for many amortized data structures, but considered only single-threaded data structures. Gries [6], Burton [3], and Hoogerwoord <ref> [9] </ref> described purely functional queues and double-ended queues with amortized bounds, but, again, supported only single-threaded queues. We first described unrestricted amortized queues in [17] as an intermediate step in the development of worst-case queues based on lazy evaluation.
Reference: [10] <author> Paul Hudak, Simon Peyton Jones, Philip Wadler, Brian Boutel, Jon Fairbairn, Joseph Fasel, Mar ia M. Guzman, Kevin Hammond, John Hughes, Thomas Johnsson, Dick Kieburtz, Rishiyur Nikhil, Will Partain, and John Peterson. </author> <title> Report on the functional programming language Haskell, Version 1.2. </title> <journal> SIGPLAN Notices, </journal> <volume> 27(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: In Section 4, we show that binomial queues implemented with lazy evaluation support insertion in only O (1) amortized time. Finally, in Section 5, we adapt this implementation of binomial queues to support insertion in O (1) worst-case time. We present some source code in Haskell <ref> [10] </ref>, and some in Standard ML [15].
Reference: [11] <author> John Hughes. </author> <title> Why functional programming matters. </title> <journal> The Computer Journal, </journal> <volume> 32(2) </volume> <pages> 98-107, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Functional programmers have long debated the relative merits of strict versus lazy evaluation. Although lazy evaluation has many benefits <ref> [11] </ref>, strict evaluation is clearly superior in at least one area: ease of reasoning about asymptotic complexity. Because of the unpredictable nature of lazy evaluation, it is notoriously difficult to reason about the complexity of algorithms in such a language.
Reference: [12] <author> Haim Kaplan and Robert E. Tarjan. </author> <title> Persistent lists with catenation via recursive slow-down. </title> <booktitle> In ACM Symposium on Theory of Computing, </booktitle> <pages> pages 93-102, </pages> <year> 1995. </year>
Reference-contexts: In addition, we introduce several new data structures, which may be useful in their own right. For every amortized functional data structure currently known, there is a competing worst-case data structure that does not depend on lazy evaluation. Examples include queues [8], double-ended queues [7, 4], catenable lists <ref> [12] </ref>, and skew binomial queues [2]. In every case, the amortized data structure is significantly simpler than the worst-case version. However, the amortized data structure is usually slightly slower in practice, mostly because of overheads associated with lazy evaluation. Memoization, in particular, causes problems for many garbage collectors.
Reference: [13] <author> Chan Meng Khoong and Hon Wai Leong. </author> <title> Double-ended binomial queues. </title> <booktitle> In International Symposium on Algorithms and Computation, volume 762 of LNCS, </booktitle> <pages> pages 128-137. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Example: Amortized Binomial Queues Binomial queues are an elegant form of priority queue invented by Vuillemin [24]. Inserting an element into a binomial queue requires O (log n) worst-case time, but it is well known that imperative (i.e., ephemeral) binomial queues support insertion in O (1) amortized time <ref> [13] </ref>. We now show, using the physicist's method, that persistent binomial queues implemented with lazy evaluation also support insertion in O (1) amortized time. A binomial queue is a forest of heap-ordered trees.
Reference: [14] <author> David J. King. </author> <title> Functional binomial queues. </title> <booktitle> In Glasgow Workshop on Functional Programming, </booktitle> <pages> pages 141-150, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: To insert an element into the queue, we create a new singleton tree and repeatedly link trees of equal size until all sizes are unique. This process is analogous to adding one to a binary number. See <ref> [14] </ref> for more details about binomial queues. binomial queues. In this implementation, we use a sparse representation of binomial queues, meaning we do not explicitly represent the zeros in the binary representation of the size of the queue. This requires that we tag each tree with its size. <p> This implementation appears in Figure 3. In addition to modifying the representation, we have also changed the source language from Haskell to Standard ML (extended with primitives for lazy evaluation). Other than the choice of language, this implementation of binomial queues is very similar to that of King <ref> [14] </ref>. Note that this change in representation does not affect the amortized analysis from the previous section. In particular, the amortized analysis also holds for King's implementation. Now, we extend binomial queues with a schedule of delayed computations. The only delayed computations in this implementation are calls to addUnique.
Reference: [15] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Finally, in Section 5, we adapt this implementation of binomial queues to support insertion in O (1) worst-case time. We present some source code in Haskell [10], and some in Standard ML <ref> [15] </ref>.
Reference: [16] <author> Chris Okasaki. Amortization, </author> <title> lazy evaluation, and persistence. </title> <booktitle> In IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 646-654, </pages> <year> 1995. </year>
Reference-contexts: Functional data structures are automatically persistent, whereas imperative data structures are almost always ephemeral. Traditional techniques for designing and analyzing amortized data structures were developed for imperative data structures and apply only in the ephemeral case. Functional (and therefore persistent) amortized data structures require different techniques. In <ref> [16] </ref>, we showed how lazy evaluation can be used to support persistent amortized data structures, and described the banker's method, a technique for analyzing the time complexity of such data structures. In this paper, we begin by reviewing these previous results in a functional setting. <p> The banker's method was first adapted to a persistent setting in <ref> [16] </ref>. 63 Example: Amortized FIFO Queues As an example of the banker's method, we next give an implementation of persistent FIFO queues that supports all standard operations in O (1) amortized time. This implementation is similar to, but simpler than, that presented in [17]. <p> However, because of the concern with worst-case bounds, that implementation is more complicated than the implementation in Section 3. We derived the worst-case queues from the amortized queues using techniques similar to those in Section 5. In <ref> [16] </ref>, we recognized the importance of lazy evaluation to non-single-threaded amortized data structures in general, and adapted the banker's method to analyze such data structures. We then used the banker's method to describe an implementation of lists supporting catenation and all other usual list primitives in O (1) amortized time.
Reference: [17] <author> Chris Okasaki. </author> <title> Simple and efficient purely functional queues and deques. </title> <journal> Journal of Functional Programming, </journal> <volume> 5(4), </volume> <month> October </month> <year> 1995. </year> <month> 68 </month>
Reference-contexts: This implementation is similar to, but simpler than, that presented in <ref> [17] </ref>. We represent a queue as a pair of lists hf; ri, where f is the front segment of the queue, and r is the rear segment of the queue in reverse order. Elements are enqueued at the head of r and dequeued from the head of f . <p> The exact number of jobs executed is governed by the (previously) amortized cost of the operation. For this technique to apply, maintaining the schedule cannot require more time than the desired worst-case bounds. A special case of this general technique was first used to implement worst-case FIFO queues in <ref> [17] </ref>. Example: Worst-Case Binomial Queues We now return to the example of binomial queues, and modify the earlier implementation to support insertions in O (1) worst-case time. Recall that, in our earlier implementation, insert was monolithic. <p> Gries [6], Burton [3], and Hoogerwoord [9] described purely functional queues and double-ended queues with amortized bounds, but, again, supported only single-threaded queues. We first described unrestricted amortized queues in <ref> [17] </ref> as an intermediate step in the development of worst-case queues based on lazy evaluation. However, because of the concern with worst-case bounds, that implementation is more complicated than the implementation in Section 3.
Reference: [18] <author> Rajeev Raman. </author> <title> Eliminating Amortization: On Data Structures with Guaranteed Response Times. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Rochester, </institution> <year> 1992. </year>
Reference-contexts: In that case, the amortized data structure should usually be faster as well as simpler. Our research is also related to earlier studies in the im 67 perative community. Driscoll, Sarnak, Sleator, and Tar--jan [5] described several techniques for implementing persistent imperative data structures, and Raman <ref> [18] </ref> explored techniques for eliminating amortization from imperative data structures. 7 Discussion We have shown how lazy evaluation is essential to the design of amortized functional data structures, and given several techniques for analyzing such data structures.
Reference: [19] <author> David Sands. </author> <title> Complexity analysis for a lazy higher-order language. </title> <booktitle> In European Symposium on Programming, volume 432 of LNCS, </booktitle> <pages> pages 361-376. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: We explore one class of such algorithms | amortized data structures | and describe techniques for reasoning about their complexity. Several researchers have developed theoretical frameworks for analyzing the time complexity of lazy programs <ref> [1, 19, 20, 25] </ref>. However, these frameworks are not yet mature enough to be useful in practice. One difficulty is that these frameworks are, in some ways, too general.
Reference: [20] <author> David Sands. </author> <title> A nave time analysis and its theory of cost equivalence. </title> <journal> Journal of Logic and Computation, </journal> <volume> 5(4) </volume> <pages> 495-541, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: We explore one class of such algorithms | amortized data structures | and describe techniques for reasoning about their complexity. Several researchers have developed theoretical frameworks for analyzing the time complexity of lazy programs <ref> [1, 19, 20, 25] </ref>. However, these frameworks are not yet mature enough to be useful in practice. One difficulty is that these frameworks are, in some ways, too general.
Reference: [21] <author> David A. Schmidt. </author> <title> Detecting global variables in de-notational specifications. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(2) </volume> <pages> 299-310, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: A data structure is called persistent [5] if, after an update, the old version of the data structure is still accessible. A data structure that is not persistent is called ephemeral. In functional programming terminology, an ephemeral data structure is one that must be single-threaded <ref> [21] </ref> and a persistent data structure is one that may be non-single-threaded. Aside from the obvious distinction regarding assignments, persistence is the fundamental difference between functional and imperative data structures. Functional data structures are automatically persistent, whereas imperative data structures are almost always ephemeral.
Reference: [22] <author> Berry Schoenmakers. </author> <title> Data Structures and Amortized Complexity in a Functional Setting. </title> <type> PhD thesis, </type> <institution> Eind-hoven University of Technology, </institution> <year> 1992. </year>
Reference-contexts: The O (log n) bound for deleteMin is unaffected by this transformation. 6 Related Work There has been very little previous work on amortized functional data structures. Schoenmakers <ref> [22] </ref> used functional notation to aid in deriving bounds for many amortized data structures, but considered only single-threaded data structures. Gries [6], Burton [3], and Hoogerwoord [9] described purely functional queues and double-ended queues with amortized bounds, but, again, supported only single-threaded queues.
Reference: [23] <author> Robert E. Tarjan. </author> <title> Amortized computational complexity. </title> <journal> SIAM Journal on Algebraic and Discrete Methods, </journal> <volume> 6(2) </volume> <pages> 306-318, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: The complete implementations are included in Appendix A. 2 Amortization and Lazy Evaluation Amortization is a method of accounting for the cost of sequences of operations <ref> [23] </ref>. The amortized cost of an individual operation is obtained by averaging the total cost of a worst-case sequence over all the operations in the sequence. <p> If x contains some delayed component that is demanded by f , then the first application of f to x will force the (potentially expensive) evaluation of that component and memoize the result. Subsequent applications may then access the memoized result directly. Tarjan <ref> [23] </ref> describes two techniques for analyzing ephemeral amortized data structures: the banker's method and the physicist's method. Both of these techniques account for future expensive operations by prepaying. Whenever the amortized cost of an operation is greater than the actual cost, the excess is saved to pay for future operations.
Reference: [24] <author> Jean Vuillemin. </author> <title> A data structure for manipulating priority queues. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 309-315, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: However, when applicable, the physicist's method tends to yield much simpler proofs than the banker's method. Example: Amortized Binomial Queues Binomial queues are an elegant form of priority queue invented by Vuillemin <ref> [24] </ref>. Inserting an element into a binomial queue requires O (log n) worst-case time, but it is well known that imperative (i.e., ephemeral) binomial queues support insertion in O (1) amortized time [13].
Reference: [25] <author> Philip Wadler. </author> <title> Strictness analysis aids time analysis. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 119-132, </pages> <year> 1988. </year>
Reference-contexts: We explore one class of such algorithms | amortized data structures | and describe techniques for reasoning about their complexity. Several researchers have developed theoretical frameworks for analyzing the time complexity of lazy programs <ref> [1, 19, 20, 25] </ref>. However, these frameworks are not yet mature enough to be useful in practice. One difficulty is that these frameworks are, in some ways, too general.
References-found: 25

