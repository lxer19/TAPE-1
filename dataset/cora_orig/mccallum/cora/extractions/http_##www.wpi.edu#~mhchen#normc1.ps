URL: http://www.wpi.edu/~mhchen/normc1.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Estimating Ratios of Normalizing Constants for Densities with Different Dimensions  
Author: Ming-Hui Chen and Qi-Man Shao 
Keyword: and Phrases: Bayesian computation; Bayes factor; Bridge sampling; Gibbs sampler; Importance sampling; Markov chain Monte Carlo; Metropolis algorithm; Ratio importance sampling.  
Web: 62A99.  
Note: 1997, Statistica Sinica, to appear AMS 1991 subject classifications: Primary 62A15; Secondary  
Abstract: In Bayesian inference, a Bayes factor is defined as the ratio of posterior odds versus prior odds where posterior odds is simply a ratio of the normalizing constants of two posterior densities. In many practical problems, the two posteriors have different dimensions. For such cases, the current Monte Carlo methods such as the bridge sampling method (Meng and Wong 1996), the path sampling method (Gelman and Meng 1994), and the ratio importance sampling method (Chen and Shao 1994) cannot directly be applied. In this article, we extend importance sampling, bridge sampling, and ratio importance sampling to problems of different dimensions. Then we find global optimal importance sampling, bridge sampling, and ratio importance sampling in the sense of minimizing asymptotic relative mean-square errors of estimators. Implementation algorithms, which can asymptotically achieve the optimal simulation errors, are developed and two illustrative examples are also provided. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Albert, J.H. and Chib, S. </author> <year> (1993). </year> <title> Bayesian analysis of binary and polychotomous response data. </title>
Reference-contexts: Sampling from 1 is straightforward. To sample from 2 , instead of using an independence chain sampling scheme in Verdinelli and Wasserman (1995), we use Gibbs sampling by introducing auxiliary variables (latent variables). Note that a t distribution is a scale mixture of normal distributions <ref> (e.g., see Albert and Chib 1993) </ref>.
Reference: <author> J. </author> <title> Amer. </title> <journal> Statist. Assoc. </journal> <volume> 88, </volume> <pages> 669-679. </pages>
Reference: <author> Berger, J.O. </author> <title> and Pericchi (1996). The intrinsic Bayes factor for model selection and prediction. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 91, </volume> <pages> 109-122. </pages>
Reference-contexts: As our algorithms can asymptotically or approximately achieve the optimal simulation errors and they can be programmed in a routine manner, our methodology developed in this paper will be useful in computing Bayes factors (Kass and Raftery 1995) or intrinsic Bayes factors <ref> (Berger and Pericchi 1996) </ref> and in Bayesian comparisons (Geweke, 1994) or model selection.
Reference: <author> Besag, J. and Green, P.J. </author> <year> (1993). </year> <title> Spatial statistics and Bayesian computation. </title> <journal> J. Roy. Statist. Soc. Ser. </journal> <volume> B 55, </volume> <pages> 25-37. </pages>
Reference: <author> Carlin, B.P. and Chib, S. </author> <year> (1995). </year> <title> Bayesian model choice via Markov chain Monte Carlo methods. </title>
Reference: <author> J. Roy. </author> <title> Statist. </title> <journal> Soc., Ser. </journal> <volume> B 57, </volume> <pages> 473-484. </pages>
Reference: <author> Chen. M.-H. </author> <year> (1994). </year> <title> Importance-weighted marginal Bayesian posterior density estimation. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 89, </volume> <pages> 818-824. </pages>
Reference-contexts: In order to compute the Bayes factor given in (1.1), Newton and Raftery (1994) proposed several Monte Carlo methods to estimate m (xjH 1 ) and m (xjH 2 ) individually and then to estimate the Bayes factor. Their methods are essentially the special cases of ratio importance sampling <ref> (Chen and Shao 1994) </ref>. If the main interest is to compute the Bayes factor, their methods might not be efficient. The problems of different dimensions were also considered by Carlin and Chib (1995) in the context of Bayesian model choice. <p> follows ^r BS (w; ff) = 2 i=1 p 1 ( 2i )w ( 2i j 2i )ff ( 2i ; 2i ) 1 i=1 p 2 ( 1i ; 1i )ff ( 1i ; 1i ) 6 Ratio Importance Sampling Using the RIS identity on the (; ) space <ref> (Chen and Shao 1994) </ref>, we have r = c 2 E fp 1 ()w ( j)=(; )g ; (2.6) where is an arbitrary density over fi such that (; ) &gt; 0 for (; ) 2 fi = fi 1 [ fi 2 . <p> Following the proof of Theorem 3.3 of Chen and Shao (1994), we have ARE 2 ^r RIS (w RIS opt ; ff opt ) : From Section 3 of Chen and Shao, we also have ARE 2 ^r RIS (w RIS opt ) : Remark 3.3. Under certain conditions <ref> (c.f., Theorem 3.1 of Chen and Shao 1994) </ref>, the central limit theorem holds for all ^r IS (w), ^r BS (w; ff) and ^r RIS (w; ). <p> with this optimal weight density w fl opt , equality in (3.14) still does not hold in general unless and are independent. 4 Implementation Issues In many practical problems, the closed form of the conditional density 2 ( j) is not available especially when () is a constrained parameter space <ref> (Chen 1994) </ref>. (Also see Gelfand, Smith and 12 Lee (1992) for the Bayesian analysis of constrained parameter problems.) Therefore, evaluating ratios of normalizing constants for densities with different dimensions is an important problem. <p> The most expensive/difficult part of Algorithm GORIS is Step 2. There are two possible approaches to draw (# i ; ' i ) from fl n 1 . The first approach is the random-direction interior-point (RDIP) sampler <ref> (Chen and Schmeiser 1994) </ref>. RDIP requires only that jp 1 () 2 ( j) t n 1 p 2 (; )j can be computed at any point (; ). Another approach is Metropolis sampling. <p> For example, if the support of the conditional density of (1) given is a finite interval, then one can use a beta density as w fl ( (1) j) whose mean, variance as well as two endpoints of the interval are determined by posterior moments of (1) and <ref> (see Chen 1994 for the detailed illustration) </ref>. When a good w fl ( j) is chosen, we simply replace ^ 2 by w fl ( j) in (4.7), (4.8), (4.9), and (4.10) and then Algorithms OIS, GOBS and GORIS give approximate ^r OIS , ^r GOBS and ^r GORIS .
Reference: <author> Chen, M.-H. and Schmeiser, B.W. </author> <year> (1994). </year> <title> Random-direction interior-point Markov chains: a family of black-box samplers. </title> <booktitle> Proceedings of the Section on Bayesian Statistical Science, American Statistical Association, </booktitle> <address> Toronto, Canada, </address> <pages> 1-6. </pages>
Reference-contexts: In order to compute the Bayes factor given in (1.1), Newton and Raftery (1994) proposed several Monte Carlo methods to estimate m (xjH 1 ) and m (xjH 2 ) individually and then to estimate the Bayes factor. Their methods are essentially the special cases of ratio importance sampling <ref> (Chen and Shao 1994) </ref>. If the main interest is to compute the Bayes factor, their methods might not be efficient. The problems of different dimensions were also considered by Carlin and Chib (1995) in the context of Bayesian model choice. <p> follows ^r BS (w; ff) = 2 i=1 p 1 ( 2i )w ( 2i j 2i )ff ( 2i ; 2i ) 1 i=1 p 2 ( 1i ; 1i )ff ( 1i ; 1i ) 6 Ratio Importance Sampling Using the RIS identity on the (; ) space <ref> (Chen and Shao 1994) </ref>, we have r = c 2 E fp 1 ()w ( j)=(; )g ; (2.6) where is an arbitrary density over fi such that (; ) &gt; 0 for (; ) 2 fi = fi 1 [ fi 2 . <p> Following the proof of Theorem 3.3 of Chen and Shao (1994), we have ARE 2 ^r RIS (w RIS opt ; ff opt ) : From Section 3 of Chen and Shao, we also have ARE 2 ^r RIS (w RIS opt ) : Remark 3.3. Under certain conditions <ref> (c.f., Theorem 3.1 of Chen and Shao 1994) </ref>, the central limit theorem holds for all ^r IS (w), ^r BS (w; ff) and ^r RIS (w; ). <p> with this optimal weight density w fl opt , equality in (3.14) still does not hold in general unless and are independent. 4 Implementation Issues In many practical problems, the closed form of the conditional density 2 ( j) is not available especially when () is a constrained parameter space <ref> (Chen 1994) </ref>. (Also see Gelfand, Smith and 12 Lee (1992) for the Bayesian analysis of constrained parameter problems.) Therefore, evaluating ratios of normalizing constants for densities with different dimensions is an important problem. <p> The most expensive/difficult part of Algorithm GORIS is Step 2. There are two possible approaches to draw (# i ; ' i ) from fl n 1 . The first approach is the random-direction interior-point (RDIP) sampler <ref> (Chen and Schmeiser 1994) </ref>. RDIP requires only that jp 1 () 2 ( j) t n 1 p 2 (; )j can be computed at any point (; ). Another approach is Metropolis sampling. <p> For example, if the support of the conditional density of (1) given is a finite interval, then one can use a beta density as w fl ( (1) j) whose mean, variance as well as two endpoints of the interval are determined by posterior moments of (1) and <ref> (see Chen 1994 for the detailed illustration) </ref>. When a good w fl ( j) is chosen, we simply replace ^ 2 by w fl ( j) in (4.7), (4.8), (4.9), and (4.10) and then Algorithms OIS, GOBS and GORIS give approximate ^r OIS , ^r GOBS and ^r GORIS .
Reference: <author> Chen, M.-H. and Schmeiser, B.W. </author> <year> (1993). </year> <title> Performance of the Gibbs, </title> <journal> hit-and-run, and Metropolis samplers. The J. Comput. Graph. Statist. </journal> <volume> 2, </volume> <pages> 251-272. </pages>
Reference: <author> Chen, M.-H. and Shao, Q.M. </author> <year> (1994). </year> <title> On Monte Carlo methods for estimating ratios of normalizing constants. Research Report No. </title> <type> 627, </type> <institution> Department of Mathematics, National University of Singapore. </institution>
Reference-contexts: In order to compute the Bayes factor given in (1.1), Newton and Raftery (1994) proposed several Monte Carlo methods to estimate m (xjH 1 ) and m (xjH 2 ) individually and then to estimate the Bayes factor. Their methods are essentially the special cases of ratio importance sampling <ref> (Chen and Shao 1994) </ref>. If the main interest is to compute the Bayes factor, their methods might not be efficient. The problems of different dimensions were also considered by Carlin and Chib (1995) in the context of Bayesian model choice. <p> follows ^r BS (w; ff) = 2 i=1 p 1 ( 2i )w ( 2i j 2i )ff ( 2i ; 2i ) 1 i=1 p 2 ( 1i ; 1i )ff ( 1i ; 1i ) 6 Ratio Importance Sampling Using the RIS identity on the (; ) space <ref> (Chen and Shao 1994) </ref>, we have r = c 2 E fp 1 ()w ( j)=(; )g ; (2.6) where is an arbitrary density over fi such that (; ) &gt; 0 for (; ) 2 fi = fi 1 [ fi 2 . <p> Following the proof of Theorem 3.3 of Chen and Shao (1994), we have ARE 2 ^r RIS (w RIS opt ; ff opt ) : From Section 3 of Chen and Shao, we also have ARE 2 ^r RIS (w RIS opt ) : Remark 3.3. Under certain conditions <ref> (c.f., Theorem 3.1 of Chen and Shao 1994) </ref>, the central limit theorem holds for all ^r IS (w), ^r BS (w; ff) and ^r RIS (w; ). <p> with this optimal weight density w fl opt , equality in (3.14) still does not hold in general unless and are independent. 4 Implementation Issues In many practical problems, the closed form of the conditional density 2 ( j) is not available especially when () is a constrained parameter space <ref> (Chen 1994) </ref>. (Also see Gelfand, Smith and 12 Lee (1992) for the Bayesian analysis of constrained parameter problems.) Therefore, evaluating ratios of normalizing constants for densities with different dimensions is an important problem. <p> The most expensive/difficult part of Algorithm GORIS is Step 2. There are two possible approaches to draw (# i ; ' i ) from fl n 1 . The first approach is the random-direction interior-point (RDIP) sampler <ref> (Chen and Schmeiser 1994) </ref>. RDIP requires only that jp 1 () 2 ( j) t n 1 p 2 (; )j can be computed at any point (; ). Another approach is Metropolis sampling. <p> For example, if the support of the conditional density of (1) given is a finite interval, then one can use a beta density as w fl ( (1) j) whose mean, variance as well as two endpoints of the interval are determined by posterior moments of (1) and <ref> (see Chen 1994 for the detailed illustration) </ref>. When a good w fl ( j) is chosen, we simply replace ^ 2 by w fl ( j) in (4.7), (4.8), (4.9), and (4.10) and then Algorithms OIS, GOBS and GORIS give approximate ^r OIS , ^r GOBS and ^r GORIS .
Reference: <author> Chib, S. </author> <year> (1995). </year> <title> Marginal likelihood from the Gibbs output. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 90, </volume> <pages> 1313-1321. </pages>
Reference: <editor> Cowles, M.K. and Carlin, B.P. </editor> <year> (1996). </year> <title> Markov chain Monte Carlo convergence diagnostics: a comparative review. </title> <journal> J. Amer. Statist. Assoc. </journal> <note> 91, to appear. 24 Dey, </note> <author> D.K. and Chen, M.-H. </author> <year> (1996). </year> <title> Bayesian analysis of correlated binary data models. </title> <type> Technical report 96-02, </type> <institution> Department of Statistics, University of Connecticut. </institution>
Reference: <author> Gelfand, A. E. and Smith, A.F.M. </author> <year> (1990). </year> <title> Sampling based approaches to calculating marginal densities. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 85, </volume> <pages> 398-409. </pages>
Reference: <author> Gelfand, A.E., Smith, A.F.M. and Lee, T.M. </author> <year> (1992). </year> <title> Bayesian analysis of constrained parameter and truncated data problems using Gibbs sampling. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 87, </volume> <pages> 523-532. </pages>
Reference: <author> Gelman, A. and Meng, X.-L. </author> <year> (1994). </year> <title> Path sampling for computing normalizing constants: identities and theory. </title> <type> Technical Report 377, </type> <institution> Department of Statistics, The University of Chicago. </institution>
Reference: <author> Geman, S. and Geman, D. </author> <year> (1984). </year> <title> Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images. </title> <journal> IEEE Trans. Pattern Anal. Machine Intelligence 6, </journal> <pages> 721-741. </pages>
Reference: <author> Geweke, J. </author> <year> (1989). </year> <title> Bayesian inference in econometrics models using Monte Carlo integration. </title> <type> Econometrica 57, </type> <pages> 1317-1340. </pages>
Reference-contexts: Chen (1994) presented the detailed guidelines for choosing a good w fl ( j). His guidelines are essentially similar to the ones for choosing a good importance sampling density <ref> (e.g., see Geweke 1989) </ref> and they can be directly applied to this problem. We use few lines to summarize these guidelines.
Reference: <author> Geweke, J. </author> <year> (1994). </year> <title> Bayesian comparison of econometric models. </title> <type> Technical Report 532, </type> <institution> Federal Reserve Bank of Minneapolis and University of Minnesota. </institution>
Reference-contexts: As our algorithms can asymptotically or approximately achieve the optimal simulation errors and they can be programmed in a routine manner, our methodology developed in this paper will be useful in computing Bayes factors (Kass and Raftery 1995) or intrinsic Bayes factors (Berger and Pericchi 1996) and in Bayesian comparisons <ref> (Geweke, 1994) </ref> or model selection.
Reference: <author> Geyer, C.J. </author> <year> (1994). </year> <title> Estimating normalizing constants and reweighting mixtures in Markov chain Monte Carlo. Revision of Technical Report No. </title> <type> 568, </type> <institution> School of Statistics, University of Minnesota. </institution>
Reference: <author> Gilks, W.R. and Wild, P. </author> <year> (1992). </year> <title> Adaptive rejection sampling for Gibbs sampling. </title> <journal> Appl. Statist. </journal> <volume> 41, </volume> <pages> 337-348. </pages>
Reference: <author> Hastings, W.K. </author> <year> (1970). </year> <title> Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrika 57, </journal> <pages> 97-109. </pages>
Reference: <author> Ibrahim, J.G., Chen, M.-H., and MacEachern, S.N. </author> <year> (1996). </year> <title> Bayesian variable selection for proportional hazards models. </title> <type> Technical Report, </type> <institution> Department of Biostatistics, Harvard School of Public Health. </institution>
Reference-contexts: are determined by ba = u 1 and ba 1=4 = u 2 : In order to complete prior elicitation, we need to specify values of D and 0 &lt; u 1 &lt; u 2 &lt; 1 where D, u 1 and u 2 reflect sharp or vague prior beliefs <ref> (see, e.g., Laud and Ibrahim 1996) </ref>. <p> In fact, our methods have been successfully applied to Bayesian variable selection for proportional hazards models <ref> (Ibrahim, Chen, and MacEachern 1996) </ref> and Bayesian analysis of correlated Binary data models (Dey and Chen 1996). 23 Acknowledgements The work of the second-named author was partially supported by a National University of Singapore Research Project. The authors thank Professors James O. Berger and Bradley P.
Reference: <author> Jeffreys, H. </author> <year> (1961). </year> <title> Theory of Probability. Third Edition. </title> <publisher> Clarendon Press: Oxford. </publisher>
Reference-contexts: Then they obtain the Bayes factor B = m 0 =m where m 0 = R m = L (xj; )(; )dd <ref> (Jeffreys 1961, chap. 5) </ref>. Here L (xj; ) is the likelihood function given data x and ( 0 ) and (; ) are the priors. Therefore, the Bayes factor B is a ratio of two normalizing constants again.
Reference: <author> Kass, R.E. and Raftery, A.E. </author> <year> (1995). </year> <title> Bayes factor. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 90, </volume> <pages> 773-795. </pages> <note> 25 Laud, </note> <author> P.W. and Ibrahim, J.G. </author> <year> (1996). </year> <title> Predictive specification of prior model probabilities in variable selection. </title> <journal> Biometrika 83, </journal> <note> to appear. </note>
Reference-contexts: As our algorithms can asymptotically or approximately achieve the optimal simulation errors and they can be programmed in a routine manner, our methodology developed in this paper will be useful in computing Bayes factors <ref> (Kass and Raftery 1995) </ref> or intrinsic Bayes factors (Berger and Pericchi 1996) and in Bayesian comparisons (Geweke, 1994) or model selection.
Reference: <author> Meng, X.L. and Wong, W.H. </author> <year> (1996). </year> <title> Simulating ratios of normalizing constants via a simple identity: a theoretical exploration. </title> <note> Statistica Sinica 6, to appear. </note>
Reference-contexts: Thus, we can view r = c 1 =c 2 as the ratio of the two normalizing constants of fl 1 (; ) and 2 (; ) and henceforth, we can directly apply the IS, BS, and RIS identities <ref> (Meng and Wong 1996 and Chen and Shao 1994) </ref> on the (; ) space for estimating r. We summarize the IS, BS and RIS estimators of r as follows. Importance Sampling Assume 1 2 . <p> on the (; ) space, using the IS identity r = c 2 p 2 (; ) ; (2.2) the ratio r can be estimated by ^r IS (w) = n i=1 p 2 ( 2i ; 2i ) Bridge Sampling Using the BS identity on the (; ) space <ref> (Meng and Wong 1996) </ref>, we have r = c 2 E 2 fp 1 ()w ( j)ff (; )g 1 fp 2 (; )ff (; )g where fl 1 (; ) is defined by (2.1) with the support of fi 1 = f (; ) : 2 1 (); 2 1
Reference: <author> Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H. and Teller, E. </author> <year> (1953). </year> <title> Equations of state calculations by fast computing machines. </title> <journal> J. Chem. Phys. </journal> <volume> 21, </volume> <pages> 1087-1091. </pages>
Reference: <author> Muller, P. </author> <year> (1991). </year> <title> A generic approach to posterior integration and Gibbs sampling. </title> <type> Technical Report #91-09, </type> <institution> Department of Statistics, Purdue University. </institution>
Reference: <author> Newton, M.A. and Raftery, A.E. </author> <year> (1994). </year> <title> Approximate Bayesian inference by the weighted likelihood bootstrap (with discussion). </title> <journal> J. Roy. Statist. Soc., Ser. </journal> <volume> B 56, </volume> <pages> 1-48. </pages>
Reference: <author> Polson, N.G. </author> <year> (1996). </year> <title> Convergence of Markov chain Monte Carlo algorithms. In Bayesian Statistics 5, </title> <editor> J.M. Bernado, J.O. Berger, A.P. Dawid and A.F.M. Smith (Eds.), </editor> <publisher> Oxford University Press, </publisher> <pages> 297-322. </pages>
Reference: <author> Ritter, C. and Tanner, T.A. </author> <year> (1992). </year> <title> Facilitation the Gibbs sampler: the Gibbs stopper and the griddy-Gibbs sampler. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 87, </volume> <pages> 861-868. </pages>
Reference: <author> Schervish, M.J. and Carlin, B.P. </author> <year> (1992). </year> <title> On the convergence of successive substitution sampling. </title>
Reference: <author> J. </author> <title> Comput. </title> <journal> Graphical Statist. </journal> <volume> 1, </volume> <pages> 111-127. </pages>
Reference: <author> Tanner, T.A. and Wong, W. H. </author> <year> (1987). </year> <title> The calculation of posterior distributions by data augmentation. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 82, </volume> <pages> 528-549. </pages>
Reference: <author> Tierney, L. </author> <year> (1994). </year> <title> Markov chains for exploring posterior distributions (with discussion). </title> <journal> Ann. Statist. </journal> <volume> 22, </volume> <pages> 1701-1762. </pages>
Reference-contexts: RDIP requires only that jp 1 () 2 ( j) t n 1 p 2 (; )j can be computed at any point (; ). Another approach is Metropolis sampling. In Metropolis sampling, one needs to choose a good proposal density that should be spread out enough <ref> (Tierney 1994) </ref>. For example, if 2 (; ) has a tail as heavy as the one of p 1 () 2 ( j), then one can simply choose 2 (; ) as a proposal density.
Reference: <author> Verdinelli, I. and Wasserman, L. </author> <year> (1995). </year> <title> Computing Bayes factors using a generalization of the Savage-Dickey density ratio. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 90, </volume> <pages> 614-618. </pages>
Reference: <author> Verdinelli, I. and Wasserman, L. </author> <year> (1996). </year> <title> Bayes factors, nuisance parameters and imprecise tests. </title>
Reference: <editor> In Bayesian Statistics 5, J.M. Bernado, J.O. Berger, A.P. Dawid and A.F.M. Smith (Eds.), </editor> <publisher> Oxford University Press, </publisher> <pages> 765-772. 26 </pages>
References-found: 37

