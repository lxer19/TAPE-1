URL: http://www.cs.ucsb.edu/~tyang/papers/jpdc97client.ps
Refering-URL: http://www.cs.ucsb.edu/Research/rapid_sweb/SWEB.html
Root-URL: http://www.cs.ucsb.edu
Email: omerg@cs.ucsb.edu  
Title: Adaptive Partitioning and Scheduling for Enhancing WWW Application Performance  
Author: Daniel Andresen, Tao Yang, Oscar H. Ibarra, Omer Egecioglu fdandrese, tyang, ibarra, 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: This paper studies runtime partitioning, scheduling and load balancing techniques for improving performance of on-line WWW-based information systems such as digital libraries. The main performance bottlenecks of such a system are caused by the server computing capability and Internet bandwidth. Our observations and solutions are based on our experience with the Alexandria Digital Library (ADL) testbed at UCSB, which provides on-line browsing and processing of documents, digitized maps and other geo-spatially mapped data via WWW. A proper partitioning and scheduling of computation and communication in processing a user request on a multi-processor server and transferring some computation to client-site machines can reduce network traffic and substantially improve system response time. We propose a partitioning and scheduling mechanism that adapts to resource changes and optimizes resource utilization, and demonstrate the application of this mechanism for on-line information browsing. We also provide a performance analysis and experimental results to study impact of resource availability and the effectiveness of our scheduling techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> The AltaVista Main Page, </institution> <note> http://altavista.digital.com/. </note>
Reference: [2] <author> E. Anderson, D. Patterson, E. Brewer, </author> <title> "The Magicrouter, an Application of Fast Packet Interposing", </title> <booktitle> submitted to the Second Symposium on Operating System Design and Implementation (OSDI96), </booktitle> <year> 1996. </year> <note> Also available at http://HTTP.CS.Berkeley.EDU/~eanders/262/262paper.ps. </note>
Reference-contexts: DLs) involve intensive I/O and computation in the server and a study on the necessity of re-balancing after DNS rotation is in [4]. Another approach for implementing re-assignment is socket forwarding, which avoids the overhead of re-connection, but requires significant changes in the OS kernel or network interface drivers <ref> [2] </ref>. We have not used it for compatibility reasons. 3.1 A cost model for processing task chains For each request, we predict the processing time and assign this request to an appropriate processor.
Reference: [3] <author> D.Andresen, L.Carver, R.Dolin, C.Fischer, J.Frew, M.Goodchild, O.Ibarra, R.Kothuri, M.Larsgaard, B.Manjunath, D.Nebert, J.Simpson, T.Smith, T.Yang, Q.Zheng, </author> <title> "The WWW Prototype of the Alexan-dria Digital Library", </title> <booktitle> Proc. of ISDL'95: International Symposium on Digital Libraries, </booktitle> <address> Japan, </address> <year> 1995. </year>
Reference-contexts: 1 Motivations The number of digital library (DL) projects is increasing rapidly at both the national and the international levels (see, for example, <ref> [3, 16] </ref>) and they are moving rapidly towards supporting on-line retrieval and processing of major collections of digitized documents over the Internet via the WWW. Performance and scalability issues are especially important for DLs. <p> The ADL has adopted progressive multi-resolution image delivery and subregion browsing as strategies to reduce Internet traffic when accessing map images <ref> [3, 21] </ref>. This approach is based on the idea that users often browse large images via a thumbnail (coarse resolution), and desire to rapidly view higher-resolution versions and subregions of those images already being viewed. We briefly describe the techniques of wavelet image data retrieval and transformation for multi-resolution browsing.
Reference: [4] <author> D.Andresen, T.Yang, V.Holmedahl, O.Ibarra, "SWEB: </author> <title> Towards a Scalable World Wide Web Server on Multicomputers", </title> <booktitle> Proc. of 10th IEEE International Symp. on Parallel Processing (IPPS'96), </booktitle> <pages> pp. 850-856. </pages> <month> April, </month> <year> 1996. </year>
Reference-contexts: Our research is motivated by the above situation and develops solutions addressing performance issues of WWW-based applications. In <ref> [4, 5] </ref>, we have studied issues in developing multiprocessor WWW servers dealing with this bottleneck using networked workstations connected with inexpensive disks. As the WWW develops and Web browsers achieve the ability to download executable content (e.g. <p> Our WWW server model consists of a set of nodes connected with a fast network as shown in Figure 1 and 2 presented as a single logical server to the Internet. User requests are first evenly routed to processors via DNS rotation <ref> [4, 18] </ref>. Each server node may have its local disk, which is accessible to other nodes via remote file service in the OS. <p> We first present a cost model for predicting the response time in processing a request, then we discuss a strategy to select a server node and decide a good split point. In our scheme request re-assignment is implemented using the HTTP "URL redirection" <ref> [4] </ref>. When client C sends a request to server S 0 , S 0 returns a rewritten URL r 0 and a response code indicating the information is located at r 0 . C then follows r 0 to retrieve the resulting data. <p> DNS rotation is used to provide an initial load distribution [18]. Load re-balancing is effective under the assumption that our targeted WWW applications (e.g. DLs) involve intensive I/O and computation in the server and a study on the necessity of re-balancing after DNS rotation is in <ref> [4] </ref>. Another approach for implementing re-assignment is socket forwarding, which avoids the overhead of re-connection, but requires significant changes in the OS kernel or network interface drivers [2]. <p> Clients are located within the campus network to avoid Internet bandwidth fluctuations over multiple experiments. The overhead for monitoring and scheduling is quite small for all experiments. Analyzing a request takes about 2-4ms, and monitoring takes about 0.1% of CPU resources. These results are consistent with those in <ref> [4] </ref>. 5.1 The impact of adding multiple servers (a) (b) (c) subimage retrieval. (c) Mixed wavelet and postscript text extraction. The period is 30 seconds. <p> Addressing client configuration variation is discussed in [15] for filtering multi-media data but it does not consider the use of client resources for integrated computing. Compared to the previous SWEB work <ref> [4] </ref>, the main contributions of this work are an adaptive partitioning and scheduling scheme for processing requests by utilizing both client and multiprocessor server resources, and analytic results for supporting our scheduling scheme.
Reference: [5] <author> D. Andresen, T. Yang, O. Egecioglu, O.H. Ibarra, T.R. Smith, </author> <title> "Scalability Issues for High Performance Digital Libraries on the World Wide Web", </title> <booktitle> Proc. of the 3rd IEEE Forum on Research and Tech. Advances in Digital Libraries (ADL96), </booktitle> <pages> pp. 139-148, </pages> <month> May, </month> <year> 1996. </year> <month> 24 </month>
Reference-contexts: Our research is motivated by the above situation and develops solutions addressing performance issues of WWW-based applications. In <ref> [4, 5] </ref>, we have studied issues in developing multiprocessor WWW servers dealing with this bottleneck using networked workstations connected with inexpensive disks. As the WWW develops and Web browsers achieve the ability to download executable content (e.g.
Reference: [6] <author> D. Andresen, T. Yang, D. Watson, A. Poulakidas, </author> <title> Dynamic Processor Scheduling with Client Resources for Fast Multi-resolution WWW Image Browsing, </title> <booktitle> in Proc. of the 11th IEEE International Parallel Processing Symposium (IPPS'97), Geneva, </booktitle> <pages> pp. 167-173, </pages> <month> April, </month> <year> 1997. </year>
Reference-contexts: The computation involved in multi-resolution image construction can be partially executed at a server and at a client also. The model of computation and communication described in <ref> [6, 21] </ref> uses the chain of tasks depicted in Figure 5: 1) Fetching compressed wavelet data and extracting the subregion. The wavelet image data is stored in a combined quad-tree/Huffman encoded form on a disk. These compressed files must be fetched.
Reference: [7] <author> M. Arlitt, C. Williamson, </author> <title> "Web Server Workload Characterization: The Search for Invariants", </title> <booktitle> Proc. SIGMETRICS Conference, </booktitle> <address> Philadelphia, PA, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: We denote this as model (r; L). Two instances of this model are considered. * (r; 1). This reflects the system performance in responding to a burst in user requests, which occurs frequently in many WWW sites <ref> [7, 13] </ref>. All requests are assumed completed in the same length of time and each server processor is dealing with the same number of requests until all finish. All task chains are partitioned uniformly on the same edge. * (r; 1).
Reference: [8] <author> T. Bemers-Lee and D. Connolly, </author> <title> "Hypertext Markup Language - 2.0", </title> <address> http://www.w3.org/hypertext/WWW/MarkUp/html-spec/html-spec toc.html, </address> <month> June, </month> <year> 1995. </year>
Reference-contexts: The URL defines which resource the user wishes to access, the HTML language allows the information to be presented in a platform-independent but still well-formatted manner, and the HTTP protocol is the application-level mechanism for achieving the transfer of information <ref> [8, 9, 17] </ref>. An HTTP request would typically activate the following sequence of events from initiation to completion. First, the client determines the host name from the URL, and uses the local Domain Name System (DNS) server to determine its IP address.
Reference: [9] <author> T. Bemers-Lee, </author> <title> "Uniform Resource Locators", </title> <note> http://www.w3.org/hypertext/WWW/Addressing/URL/, 1996. </note>
Reference-contexts: The URL defines which resource the user wishes to access, the HTML language allows the information to be presented in a platform-independent but still well-formatted manner, and the HTTP protocol is the application-level mechanism for achieving the transfer of information <ref> [8, 9, 17] </ref>. An HTTP request would typically activate the following sequence of events from initiation to completion. First, the client determines the host name from the URL, and uses the local Domain Name System (DNS) server to determine its IP address.
Reference: [10] <author> F. Berman, R. Wolski, S. Figueira, J. Schopf, G. Shao, </author> <title> "Application-Level Scheduling on Distributed Heterogeneous Networks", </title> <booktitle> Proc. of Supercomputing '96, </booktitle> <address> ACM/IEEE, </address> <month> Nov., </month> <year> 1996. </year>
Reference-contexts: Projects in [12, 14] are working on global computing software infrastructures. Scheduling issues in heterogeneous computing using network bandwidth and load information are addressed in <ref> [10] </ref>. The above work deals with an integration of different machines as one server and does not have the division of client and server.
Reference: [11] <author> E.C.K. Chui, </author> <title> Wavelets: A Tutorial in Theory and Applications, </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: We model such a process as follows. subregion (I 1 ) = Inverse W avelet (subregion (I 2 ); subregion (C 1 ); subregion (C 2 ); subregion (C 3 )): A detailed definition of forward and inverse wavelet functions can be found in <ref> [11] </ref>. The time complexity of wavelet transforms is proportional to the image size. The wavelet transform can be applied recursively, namely thumbnail I 2 can be decomposed further to produce smaller thumbnails. computation partitioning between client and server.
Reference: [12] <author> H. Casanova, J. Dongarra, "NetSolve: </author> <title> A network server for solving computation science problems", </title> <booktitle> Proc. of Supercomputing'96, </booktitle> <address> ACM/IEEE, </address> <month> Nov., </month> <year> 1996. </year>
Reference-contexts: But when client-server bandwidth decreases, the scheduler increases 23 the percentage of client involvement for data decompression and image reconstruction (D 2 ), to minimize the size of data sent over the network. 6 Related work and conclusions Several projects are related to our work. Projects in <ref> [12, 14] </ref> are working on global computing software infrastructures. Scheduling issues in heterogeneous computing using network bandwidth and load information are addressed in [10]. The above work deals with an integration of different machines as one server and does not have the division of client and server.
Reference: [13] <author> M. Crovella, A. Bestavros, </author> <title> "Self-Similarity in World Wide Web Traffic Evidence and Possible Causes", </title> <booktitle> Proc. </booktitle> <address> SIGMETRICS96, Philadelphia, PA, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: We denote this as model (r; L). Two instances of this model are considered. * (r; 1). This reflects the system performance in responding to a burst in user requests, which occurs frequently in many WWW sites <ref> [7, 13] </ref>. All requests are assumed completed in the same length of time and each server processor is dealing with the same number of requests until all finish. All task chains are partitioned uniformly on the same edge. * (r; 1). <p> We ran experiments to determine the actual MRPS by testing for a period of 120 seconds and choosing the highest RPS such that the server response times are reasonable and no requests are dropped. We chose the period of 120 seconds based on <ref> [13, 19] </ref>, which indicate most "long" bursts on the Internet are actually relatively short. Thus the sustained RPS required in practice are for a period shorter than 1. For this experiment, the clients are simulated within the Meiko machine.
Reference: [14] <author> K. Dincer, and G. C. Fox, </author> <title> "Building a world-wide virtual machine based on Web and HPCC technologies", </title> <booktitle> Proc. of Supercomputing'96, </booktitle> <address> ACM/IEEE, </address> <month> Nov., </month> <year> 1996. </year>
Reference-contexts: But when client-server bandwidth decreases, the scheduler increases 23 the percentage of client involvement for data decompression and image reconstruction (D 2 ), to minimize the size of data sent over the network. 6 Related work and conclusions Several projects are related to our work. Projects in <ref> [12, 14] </ref> are working on global computing software infrastructures. Scheduling issues in heterogeneous computing using network bandwidth and load information are addressed in [10]. The above work deals with an integration of different machines as one server and does not have the division of client and server.
Reference: [15] <author> A. Fox, E. Brewer, </author> <title> "Reducing WWW Latency and Bandwidth Requirements by Real-Time Distillation", </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> Volume 28, issues 711, </volume> <editor> p. </editor> <volume> 1445. </volume> <month> May, </month> <year> 1996. </year>
Reference-contexts: Many small WWW clients, such as personal digital assistants (PDAs) or NetPCs, do not have the capability to display Postscript files. Viewing the text can be the only available option to examine the content of a Postscript document <ref> [15] </ref>. pages. The chain has two tasks that can be performed either at server or at client. 1) Select the pages needed. Eliminating unnecessary postscript pages reduces the computation needed for Step 2. <p> Our current project focuses on the optimization between a server and clients and currently uses tightly coupled server nodes for a WWW server, but results could be generalized for loosely coupled server nodes. Addressing client configuration variation is discussed in <ref> [15] </ref> for filtering multi-media data but it does not consider the use of client resources for integrated computing.
Reference: [16] <author> E. Fox, Akscyn, R., Furuta, R. and Leggett, J. </author> <title> (Eds), </title> <journal> Special issue on digital libraries, CACM, </journal> <month> April </month> <year> 1995. </year>
Reference-contexts: 1 Motivations The number of digital library (DL) projects is increasing rapidly at both the national and the international levels (see, for example, <ref> [3, 16] </ref>) and they are moving rapidly towards supporting on-line retrieval and processing of major collections of digitized documents over the Internet via the WWW. Performance and scalability issues are especially important for DLs.
Reference: [17] <institution> Hypertext Transfer Protocol (HTTP): A protocol for networked information, </institution> <address> http://www.w3.org/hypertext/WWW/Protocols/HTTP/HTTP2.html, June 26, </address> <year> 1995. </year>
Reference-contexts: The URL defines which resource the user wishes to access, the HTML language allows the information to be presented in a platform-independent but still well-formatted manner, and the HTTP protocol is the application-level mechanism for achieving the transfer of information <ref> [8, 9, 17] </ref>. An HTTP request would typically activate the following sequence of events from initiation to completion. First, the client determines the host name from the URL, and uses the local Domain Name System (DNS) server to determine its IP address. <p> This response code could indicate the request service can be performed, or might redirect the request to another server. After the contents of the request are sent to the client, the connection is closed by either the client or the server <ref> [17] </ref>. The results of the request are normally described by HTML, which the client displays on its local machine.
Reference: [18] <author> E.D. Katz, M. Butler, R. McGrath, </author> <title> A Scalable HTTP Server: the NCSA Prototype, </title> <journal> Computer Networks and ISDN Systems. </journal> <volume> vol. 27, </volume> <year> 1994, </year> <pages> pp. 155-164. </pages>
Reference-contexts: Our WWW server model consists of a set of nodes connected with a fast network as shown in Figure 1 and 2 presented as a single logical server to the Internet. User requests are first evenly routed to processors via DNS rotation <ref> [4, 18] </ref>. Each server node may have its local disk, which is accessible to other nodes via remote file service in the OS. <p> For example, if a request involves a small file retrieval, typically no redirection occurs. DNS rotation is used to provide an initial load distribution <ref> [18] </ref>. Load re-balancing is effective under the assumption that our targeted WWW applications (e.g. DLs) involve intensive I/O and computation in the server and a study on the necessity of re-balancing after DNS rotation is in [4]. <p> Various authors have noted that DNS rotation seems to inevitably lead to load imbalances <ref> [18, 19] </ref>. We examine how our system deals with hot-spots by sending a fixed number of requests to a subset of nodes in our server cluster, giving a wide range of load disparities. Without our scheduler, the selected nodes would have to process all of those requests.
Reference: [19] <author> D. Mosedale, W. Foss, R. McCool, </author> <title> "Administering Very High Volume Internet Services", </title> <booktitle> 1995 LISA IX, </booktitle> <address> Monterey, CA, </address> <year> 1995. </year>
Reference-contexts: Various authors have noted that DNS rotation seems to inevitably lead to load imbalances <ref> [18, 19] </ref>. We examine how our system deals with hot-spots by sending a fixed number of requests to a subset of nodes in our server cluster, giving a wide range of load disparities. Without our scheduler, the selected nodes would have to process all of those requests. <p> We ran experiments to determine the actual MRPS by testing for a period of 120 seconds and choosing the highest RPS such that the server response times are reasonable and no requests are dropped. We chose the period of 120 seconds based on <ref> [13, 19] </ref>, which indicate most "long" bursts on the Internet are actually relatively short. Thus the sustained RPS required in practice are for a period shorter than 1. For this experiment, the clients are simulated within the Meiko machine.
Reference: [20] <author> NCSA development team, </author> <title> "The Common Gateway Interface", </title> <address> http://hoohoo.ncsa.uiuc.edu/cgi/, June, </address> <year> 1995. </year>
Reference-contexts: WWW applications such DLs involve extensive client-server interaction, and some of computation can be shifted to the client. In this paper we model the interaction between client and server using a task chain which is partially executed at the server (possibly as a CGI program <ref> [20] </ref>) and partially executed at the client (as a Java applet if applicable). A task consists of a segment of the request fulfillment, with its associated computation and communication.
Reference: [21] <author> A. Poulakidas, A. Srinivasan, O. Egecioglu, O. Ibarra, and T. Yang, </author> <title> "A Compact Storage Scheme for Fast Wavelet-based Subregion Retrieval", </title> <note> To appear in the Proceedings of COCOON '97, </note> <institution> Shanghai, China, </institution> <month> August, </month> <year> 1997. </year>
Reference-contexts: The ADL has adopted progressive multi-resolution image delivery and subregion browsing as strategies to reduce Internet traffic when accessing map images <ref> [3, 21] </ref>. This approach is based on the idea that users often browse large images via a thumbnail (coarse resolution), and desire to rapidly view higher-resolution versions and subregions of those images already being viewed. We briefly describe the techniques of wavelet image data retrieval and transformation for multi-resolution browsing. <p> The computation involved in multi-resolution image construction can be partially executed at a server and at a client also. The model of computation and communication described in <ref> [6, 21] </ref> uses the chain of tasks depicted in Figure 5: 1) Fetching compressed wavelet data and extracting the subregion. The wavelet image data is stored in a combined quad-tree/Huffman encoded form on a disk. These compressed files must be fetched. <p> For our purposes, we assume the viewing of the image takes no computation time, and must be done on the client. for the server and client. We discuss the possible computation and communication scenarios for four partitioning points below <ref> [21] </ref>. Notice that we also need to consider that the data sent from the server to the client may be compressed first for transmission, then decompressed at the client site. D 1 : The client starts from subregion extraction.
Reference: [22] <author> B. A. Shirazi, A. R. Hurson, and K. M. Kavi (Eds), </author> <title> Scheduling and Load Balancing in Parallel and Distributed Systems, </title> <publisher> IEEE CS Press, </publisher> <year> 1995. </year> <month> 25 </month>
Reference-contexts: To avoid this unsynchronized overloading, we conservatively increase the CPU load of p x by . This strategy is found to be effective in <ref> [22] </ref>. * t client = No. of client operations required CP U client speed : The number of client operations required depends on how a task chain is partitioned. <p> Still, the overall accuracy of prediction is very reasonable. It should be noted that the previous load balancing research <ref> [22] </ref> normally use simulations to verify performance analysis and it is quite difficult to predict and match actual performance in a real experimental setting. Expected redirection ratio. Experiments in Section 5.3 already indicate that the trend of redirection matches the theoretical prediction for the 512 fi 512 wavelet extraction.
References-found: 22

