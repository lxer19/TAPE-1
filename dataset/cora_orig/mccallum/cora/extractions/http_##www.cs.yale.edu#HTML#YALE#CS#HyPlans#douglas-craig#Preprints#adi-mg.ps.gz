URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/Preprints/adi-mg.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/ccd-preprints.html
Root-URL: http://www.cs.yale.edu
Phone: 3  
Title: Parallel Multigrid with ADI-like Smoothers in Two Dimensions  
Author: Craig C. Douglas Sachit Malhotra and Martin H. Schultz 
Address: Tower, Lexington, KY 40506-0027, USA 2 One Century Tower, 265 Church Street, New Haven, CT 06510-7010, USA  New Haven, CT 06520-8285, USA  
Affiliation: 1 Department of Mathematics, University of Kentucky, 715 Patterson Office  Department of Computer Science, Yale University,  
Abstract: Alternating direction iterative (ADI) methods do not usually work well on parallel computers due to having to do parallel rather than serial tridiagonal solves in all but one dimension. An ADI-like iteration is developed and analyzed which does not require parallel tridiagonal solves in any direction, has at least as good of a convergence rate as ADI, and has almost no communication when imbedded as a smoother inside of a multigrid solver. Numerical experiments on a network of workstations and a parallel computer are included. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Bank, R. E., Douglas, C. C.: </author> <title> Sharp estimates for multigrid rates of convergence with general smoothing and acceleration. </title> <journal> SIAM J. Numer. Anal., </journal> <month> 22 </month> <year> (1985) </year> <month> 617-633 </month>
Reference-contexts: Although the analysis in this section is for the model problem (2) numerical experience suggests that the ADG (,k) method works well in practice as a preconditioner for non constant coefficient problems. Theorem 4. For the model problem defined by (2), the two grid method <ref> [1] </ref>, using s smoothing steps of ADG (,k) at the finer level, converges with ke n+1 k r s;;k ke n k with r s;;k given in Table 1. <p> The theorem can be extended to more than 2 levels easily using the technique in <ref> [1] </ref>. 6 Craig Douglas et al. Fig. 1. <p> Poisson's Equation on a Square Domain The experiments in this section relate to the solution of (1) on the unit square. The problem was discretized using centered finite differences on a uniform grid. A nested iteration V cycle <ref> [1] </ref> was used for the solution of the problem. The code was based on [2] with the appropriate communication and computation routines added for the solution of the resulting tridiagonal systems. MPI [6] was used as the communication library.
Reference: 2. <author> Douglas, C. C.: </author> <title> MPI multigrid codes for 2D and 3D elliptic problems. </title> <note> MGNet (1995). Available electronically at http://casper.cs.yale.edu/mgnet/www/Codes/douglas </note>
Reference-contexts: The problem was discretized using centered finite differences on a uniform grid. A nested iteration V cycle [1] was used for the solution of the problem. The code was based on <ref> [2] </ref> with the appropriate communication and computation routines added for the solution of the resulting tridiagonal systems. MPI [6] was used as the communication library. The codes were executed on an IBM SP2 at the IBM T.J. Watson Research Center at Yorktown Heights, NY.
Reference: 3. <author> Douglas, C. C.: </author> <title> Private communication (August 1996) Fast ADI-like Smoothers and Multigrid 11 </title>
Reference-contexts: At this stage, we point out that ADI smoothers are not best for the solution of the model problem (2). For the constant coefficient problem, full Gauss-Seidel is probably the most efficient smoother due to its low arithmetic costs per iteration <ref> [3] </ref>. From our own experiments on RISC based architectures, we have observed that a single ADG (,1) iteration has arithmetic costs which are approximately between two and three times those for a single full Gauss-Seidel iteration.
Reference: 4. <author> Douglas, J. and Rachford, H. R.: </author> <title> On the numerical solution of heat conduction problems in two or three space variables. </title> <journal> Trans. Amer. Math. Soc., </journal> <month> 82 </month> <year> (1956) </year> <month> 421-439 </month>
Reference-contexts: In particular, they are reducible to the direct sum of irreducible Stieltjes matrices [10]. For the rest of the discussion we shall ignore the matrix , which can be incorporated into the discussion by defining the modified matrices <ref> [4] </ref> H 0 = H + =2 and V 0 = V + =2: The ADI method proceeds by converting (2) to a pair of matrix equations (H + I)u = k (V I)u (3) for some positive scalar .
Reference: 5. <author> Duff, I. S., Grimes, R. G., Lewis, J. G.: </author> <title> User's guide for the Harwell-Boeing sparse matrix collection (Release I). </title> <type> Tech. Rep. </type> <institution> TR/PA/92/86, CERFACS, Toulouse (1992) </institution>
Reference-contexts: The ideas of this chapter can also be applied to alternating direction line SOR methods with little or no modification. Alternating direction line SOR methods are often used as smoothers for multigrid methods since their smoothing properties are slightly better than the corresponding pointwise smoothers <ref> [5] </ref> (a smoothing rate of 0:2 for line SOR vs a smoothing rate of 0:25 for point SOR).
Reference: 6. <author> Gropp, W., Lusk, E., Skjellum, A.: </author> <title> Using MPI: Portable Parallel Programming with the Message Passing Interface. </title> <publisher> The MIT Press (1994) </publisher>
Reference-contexts: The problem was discretized using centered finite differences on a uniform grid. A nested iteration V cycle [1] was used for the solution of the problem. The code was based on [2] with the appropriate communication and computation routines added for the solution of the resulting tridiagonal systems. MPI <ref> [6] </ref> was used as the communication library. The codes were executed on an IBM SP2 at the IBM T.J. Watson Research Center at Yorktown Heights, NY.
Reference: 7. <author> Hackbush, W.: </author> <title> On the multi-grid method applied to difference equations, </title> <booktitle> Computing, </booktitle> <month> 20 </month> <year> (1978) </year> <month> 291-306 </month>
Reference-contexts: Proof: Note that (8) is a restatement of a well known result <ref> [7] </ref> and that (10) is derived from repeated applications of the matrix in (8). ut Corollary 2.
Reference: 8. <author> Malhotra, S.: </author> <title> Topics in Mutigrid Methods. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, CT, USA (1996). </address> <note> Available electronically through MGNet, http://casper.cs.yale.edu/mgnet/www/mgnet-papers.html </note>
Reference-contexts: Lemma 3 can be proved by considering the effect of each half step of ADG (,k) on the eigenvectors of the matrix A (see <ref> [8] </ref>). Note that (13) measures the difference in the iterates produced by the ADG (,k) and ADI meth ods. 4.1 ADG (,k) as a Multigrid Smoother As can be seen from Figure 1 ADI methods reduce the error for the high frequency components of the error substantially every iteration. <p> Table 1. r s;;k for multigrid using ADG (,k) as a smoother s ADI ( ADG ( 8, 1)) ADG ( 8, 1) ADG ( 8, 2) ADG ( 8, 3) 2 0.0923 0.1039 0.0898 0.0920 The proof of Theorem 4 can be found in <ref> [8] </ref>. The theorem can be extended to more than 2 levels easily using the technique in [1]. 6 Craig Douglas et al. Fig. 1.
Reference: 9. <author> Saied, F.: </author> <title> Numerical Techniques for the Solution of the Time-dependent Schrodinger Equation and their Parallel Implementation. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, CT, USA (1990). </address> <note> Available as YALEU/DCS/tr811, </note> <institution> Department of Computer Science, Yale University </institution>
Reference-contexts: On parallel processors, where the cost of substructuring effectively doubles the cost arithmetic costs of the tridiagonal solves in one direction <ref> [9] </ref>, the saving in the arithmetic costs is even higher (approximately 17n 2 flops for the ADG (; 1) compared to 31n 2 flops for ADI on a n fi n grid on multiple processors).
Reference: 10. <author> Varga, R. S.: </author> <title> Matrix Iterative Analysis. </title> <publisher> Prentice-Hall, Inc, </publisher> <address> Englewood Ciffs, NJ, USA (1962) </address>
Reference-contexts: (x; y); (x; y) 2 R; (1) on the unit square, R : 0 &lt; x; y &lt; 1 of the x-y plane, where 0 and u (x; y) = fl (x; y); (x; y) 2 ; where fl (x; y) is a prescribed function on the boundary of R <ref> [10] </ref>. The problem is discretized by imposing a uniform N fiN grid on the unit square with a grid spacing given by h1=(N + 1). <p> The matrix is a non-negative diagonal matrix. Each of the matrices H and V are each completely reducible <ref> [10] </ref>. In particular, they are reducible to the direct sum of irreducible Stieltjes matrices [10]. <p> The matrix is a non-negative diagonal matrix. Each of the matrices H and V are each completely reducible <ref> [10] </ref>. In particular, they are reducible to the direct sum of irreducible Stieltjes matrices [10]. <p> is defined by e m u m u fl ; it follows that e m+1 = T e m Fast ADI-like Smoothers and Multigrid 3 where T = (V + I) 1 (H I)(H + I) 1 (V I): (7) The above method converges to the solution for any positive <ref> [10, Theorem 7.1] </ref>. <p> In this section, we restate some of the properties of the Gauss-Seidel method as applied to the matrices obtained by the discretization of H and V in (2). The Gauss-Seidel method is preferred to the Jacobi method since it converges twice as fast as the Jacobi method <ref> [10] </ref>. Furthermore, it does not require any auxiliary storage unlike the Jacobi method.
References-found: 10

