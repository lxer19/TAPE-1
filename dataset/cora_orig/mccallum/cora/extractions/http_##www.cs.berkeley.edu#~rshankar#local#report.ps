URL: http://www.cs.berkeley.edu/~rshankar/local/report.ps
Refering-URL: http://www.cs.berkeley.edu/~rshankar/local/
Root-URL: 
Title: Locality-preserving dictionaries  
Author: Vijayshankar Raman 
Date: April 7, 1998  
Affiliation: UC Berkeley  
Pubnum: CS270 Project Report 1  
Abstract: In this report we discuss strategies for building locality-preserving (LP) dictionaries in which items 1 within a certain range 2 , are constrained to lie in memory within a space that is a small function of range size. We describe an approach where the memory space is partitioned so that items can be placed in sorted order in the memory, with spaces between them, resulting in efficient insert, delete, and search operations. We describe two variants of this strategy which give different time complexities for the operations and space constraints for locality, with a tradeoff between them. We also briefly discuss some related work on LP hashing, where better bounds are possible by assuming that the domain is that of distinct integers and using a different notion of locality. We discuss several applications of LP dictionaries for databases, mainly based on their reduced disk-seek needs, and their amenability to sequential pre-fetching. We also look at some implementation tricks that can be used to speed up our algorithms, and reduce the space needed. 
Abstract-found: 1
Intro-found: 1
Reference: [ADADC + 97] <author> A. Arpaci-Dusseau, R. Arpaci-Dusseau, D. Culler, J. Hellerstein, and D. Patterson. </author> <title> High performance sorting on networks of workstations. </title> <booktitle> In Proc. SIGMOD, </booktitle> <pages> pages 243-254, </pages> <year> 1997. </year>
Reference-contexts: The arguments for how LP data-structures give cache locality are the same as those for how they give better clustering on disk. Cache locality is increasingly important in many applications like sorting. For example, Alpha Sort [NBC + 95] and Now Sort <ref> [ADADC + 97] </ref>, which is a world record holding sorting program, take great care to achieve cache locality for their algorithms. Another important application of LP dictionaries is in searching noisy data [LS96] and near neighbor searches [IMRV97].
Reference: [CLR90] <author> T. Cormen, C. Leiserson, and R. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: There is a well known randomized cursor based linked list <ref> [CLR90] </ref> for performing O (n 1=2 ) insert, delete, and search in an array with n items and no extra spaces.
Reference: [Com79] <author> D. Comer. </author> <title> The ubiquitous b-tree. </title> <journal> ACM Computing Surveys, </journal> <volume> 11(2) </volume> <pages> 121-137, </pages> <year> 1979. </year>
Reference-contexts: The I/O cost from secondary storage like disks has a large per-request component 3 This work was not done this semester; it is from my undergraduate days 2 although the raw read/write bandwidth is quite good [GK97]. Moreover, random I/O imposes a high seek time. Traditionally, B-Trees <ref> [Com79] </ref> are used to index data on the disk, and this data is clustered at a page granularity to minimize I/O. A locality-preserving data-structure will allow for a much stronger notion of clustering.
Reference: [DNO98] <author> S. Dasgupta, A. Nayak, and R. Ostrovsky. </author> <type> Personal Communication, </type> <year> 1998. </year>
Reference-contexts: The advantage with their scheme is that insert, delete, and search can be done in amortized O (log (1=*)) time. Recently, Dasgupta, Nayak and Ostrovsky <ref> [DNO98] </ref> have found a scheme where the space needed is only O (n) and all operations take only O (1) time, but the locality is only in the expected case. Indyk et. al. [IMRV97] extend the results of [LS96] to multiple dimensions, but their structure is static.
Reference: [GK97] <author> G. Ganger and M. Kaashoek. </author> <title> Embedded inodes and explicit grouping: exploiting disk bandwidth for small files. </title> <booktitle> In Proceedings of the USENIX Technical Conference, </booktitle> <year> 1997. </year>
Reference-contexts: The I/O cost from secondary storage like disks has a large per-request component 3 This work was not done this semester; it is from my undergraduate days 2 although the raw read/write bandwidth is quite good <ref> [GK97] </ref>. Moreover, random I/O imposes a high seek time. Traditionally, B-Trees [Com79] are used to index data on the disk, and this data is clustered at a page granularity to minimize I/O. A locality-preserving data-structure will allow for a much stronger notion of clustering.
Reference: [HU69] <author> J. Hopcroft and J. Ullman. </author> <title> Formal languages and their relation to automata, </title> <booktitle> chapter 10, </booktitle> <pages> pages 141-142. </pages> <publisher> Addison-Wesley, </publisher> <year> 1969. </year>
Reference-contexts: As earlier, we can relax the fill factor restriction to get space = (1 + *) p fi (range size). However, insertion and deletion costs will now go up by a factor of 1=*. 9 7 Related work Hopcroft and Ullman <ref> [HU69] </ref> use a construction similar in spirit to our padding approach for bubbling, to prove a tape-reduction theorem.
Reference: [IMRV97] <author> P. Indyk, R. Motwani, P. Raghavan, and S. Vempala. </author> <title> Locality-preserving hashing in multidimensional spaces. </title> <booktitle> In Proc. 29th STOC, </booktitle> <pages> pages 618-625, </pages> <year> 1997. </year> <month> 11 </month>
Reference-contexts: For example, Alpha Sort [NBC + 95] and Now Sort [ADADC + 97], which is a world record holding sorting program, take great care to achieve cache locality for their algorithms. Another important application of LP dictionaries is in searching noisy data [LS96] and near neighbor searches <ref> [IMRV97] </ref>. However these are typically interesting only in higher dimensions. 3 A LP space-partitioning technique In this section we present a technique to partition space in an array, and place items in it with padding, so as to preserve locality and also support insert, search, and delete operations efficiently. <p> These results assume that the domain of the data is that of distinct integers. Linial and Sasson [LS96] give a family of hash functions using multifoldings <ref> [IMRV97] </ref> which ensure that any two integers p and q are mapped onto places f (p) and f (q) such that jf (p) f (q)j jp qj. Their scheme needs O (n 2 ) space where there are n integers to be hashed. <p> Recently, Dasgupta, Nayak and Ostrovsky [DNO98] have found a scheme where the space needed is only O (n) and all operations take only O (1) time, but the locality is only in the expected case. Indyk et. al. <ref> [IMRV97] </ref> extend the results of [LS96] to multiple dimensions, but their structure is static. They also prove lower bounds under the multifoldings framework.
Reference: [LS96] <author> N. Linial and O. Sasson. </author> <title> Non-expansive hashing. </title> <booktitle> In Proc. 28th STOC, </booktitle> <pages> pages 509--518, </pages> <year> 1996. </year>
Reference-contexts: It must be noted that the locality we obtain for a interval of r items is in terms of the number of items in the interval and not in terms of the size of the interval. <ref> [LS96] </ref> look at non-expansive hashing and treat locality in terms of the size of the interval. They posed supporting our idea of locality (in terms of the number of items in the interval) as an open problem. There, the motive was to support retrieval of noisy data, i.e. near-neighbor searches. <p> For example, Alpha Sort [NBC + 95] and Now Sort [ADADC + 97], which is a world record holding sorting program, take great care to achieve cache locality for their algorithms. Another important application of LP dictionaries is in searching noisy data <ref> [LS96] </ref> and near neighbor searches [IMRV97]. <p> These results assume that the domain of the data is that of distinct integers. Linial and Sasson <ref> [LS96] </ref> give a family of hash functions using multifoldings [IMRV97] which ensure that any two integers p and q are mapped onto places f (p) and f (q) such that jf (p) f (q)j jp qj. <p> Recently, Dasgupta, Nayak and Ostrovsky [DNO98] have found a scheme where the space needed is only O (n) and all operations take only O (1) time, but the locality is only in the expected case. Indyk et. al. [IMRV97] extend the results of <ref> [LS96] </ref> to multiple dimensions, but their structure is static. They also prove lower bounds under the multifoldings framework.
Reference: [NBC + 95] <author> C. Nyberg, T. Barclay, Z. Cvetanovic, J. Gray, and D. Lomet. </author> <title> Alphasort a cache-sensitive parallel external sort. </title> <journal> VLDB Journal, </journal> <volume> 4(4) </volume> <pages> 603-627, </pages> <year> 1995. </year>
Reference-contexts: The arguments for how LP data-structures give cache locality are the same as those for how they give better clustering on disk. Cache locality is increasingly important in many applications like sorting. For example, Alpha Sort <ref> [NBC + 95] </ref> and Now Sort [ADADC + 97], which is a world record holding sorting program, take great care to achieve cache locality for their algorithms. Another important application of LP dictionaries is in searching noisy data [LS96] and near neighbor searches [IMRV97].
Reference: [RP96] <author> V. Raman and C. Pandurangan. </author> <title> o(n 1=p ) amortized insert, search, and delete in array data structure. Unpublished, </title> <booktitle> 1996. </booktitle> <pages> 12 </pages>
Reference-contexts: this is that we bubble a whole batch of items at a time and so the cost of the random I/Os is amortized over the whole batch. 6 Another space-partitioning technique In this section, we briefly describe another space partitioning technique using the same paradigm discussed in Section 3.1 (see <ref> [RP96] </ref> for details). The algorithms are essentially the same as in the previous approach. The idea here is to build a hierarchy of LP dictionaries, each providing better and better bounds for various operations.
References-found: 10

