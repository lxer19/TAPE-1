URL: http://charm.cs.uiuc.edu/version2/papers/DivconSC91.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/DivconSC91.html
Root-URL: http://www.cs.uiuc.edu
Title: High Level Support For Divide-and-Conquer Parallelism  
Author: Attila Gursoy L. V. Kale 
Address: 1304 W.Springfield Ave., Urbana, IL 61801  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign  
Abstract: In this paper we present a simple language for expressing divide and conquer computations. The language allows for many variations in the standard divide and conquer paradigm. It is implemented using the Chare Kernel parallel programming system. The Chare Kernel supports dynamic creation of work with dynamic load balancing strategies, and machine independent execution. As a result, implementation of languages and systems such as that described in this paper is simplified significantly. A translator translates divide-and-conquer programs to Chare Kernel programs, handling details of synchronization and communication automatically. The design of the language is presented, followed by a description of its implementation, and performance results on many parallel machines, including NCUBE/two, iPSC/2, and the Sequent symmetry. User programs do not have to be changed to run on any of these machines.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.Aho, J.Hopcraft, and J.Ullman. </author> <title> The design and analysis of computer algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> (1974) </year> <month> pp230-232. </month>
Reference-contexts: version: Correct Version: /* a and b shared */ /* a and b shared */ when p : a=...- cond c [2]; when q : - b = ...- when p : a=..; set c [0];- when p,q : - f (a,b) ....- when q : - b=..; set c <ref> [1] </ref>;- when c [0,1] : -f (a,b) ...- (a) (b) 6 t t t t p [0] p [1] compute C11 compute C22 matrices. <p> a=...- cond c [2]; when q : - b = ...- when p : a=..; set c [0];- when p,q : - f (a,b) ....- when q : - b=..; set c <ref> [1] </ref>;- when c [0,1] : -f (a,b) ...- (a) (b) 6 t t t t p [0] p [1] compute C11 compute C22 matrices. <p> way. " A 21 A 22 B 11 B 12 # " C 21 C 22 C 11 = A 11 B 11 + A 12 B 21 C 21 = A 21 B 11 + A 22 B 21 The formulation can be optimized further to encode Strassen's algorithm <ref> [1] </ref>, which creates 7 (instead of 8) subproblems. As the purpose in this paper is to illustrate the language, we will stay with this simple formulation. is listed in Figure 7. Matrices A and B are declared as readonly so they are shared among nodes. <p> InitRootInput (root.in); /* fill row,column and size fields of root.in */ fire root; - when root:-PrintResult (root.out);- - node mult - in : - int rowA, colA, rowB, colB, n;- out: float c [in-&gt;n*in->n];- node mult : p [8]; /* p [0] computes A11xB11 */ cond c [4]; /* p <ref> [1] </ref> computes A12xB21 */ init : - /* .... */ if ( matrix-size &lt; grainsize) - /* p [7] computes A22xB22 */ seqentialmult (in,out); send result; - else - decompose (in,p); for (i=0;i&lt;8;i++) fire p [i]; - when p [0,1] : - add (p [0].out,p [1].out,out); set c [0];- /* compute <p> grainsize) - /* p [7] computes A22xB22 */ seqentialmult (in,out); send result; - else - decompose (in,p); for (i=0;i&lt;8;i++) fire p [i]; - when p [0,1] : - add (p [0].out,p <ref> [1] </ref>.out,out); set c [0];- /* compute C11 */ when p [2,3] : - add (p [2].out,p [3].out,out); set c [1];- /* compute C12 */ when p [4,5] : add p [4].out,p [5].out,out); set c [2];- /* compute C21 */ when p [6,7] : add p [6].out,p [7].out,out); set c [3];- /* compute C22 */ when c [0-3] : send result;- - decompose (in,pin) mult_IN *in,*pin; - /* fill fields of
Reference: [2] <author> J.L.Bentley, </author> <title> "Multidimensional divide-and-conquer," </title> <journal> Comm. ACM, </journal> <volume> vol. 23, no. 4., </volume> <month> April </month> <year> 1980. </year>
Reference-contexts: A simple divide-and-compose strategy for matrix multiplication: Let A and B be two n fi n Ambiguous version: Correct Version: /* a and b shared */ /* a and b shared */ when p : a=...- cond c <ref> [2] </ref>; when q : - b = ...- when p : a=..; set c [0];- when p,q : - f (a,b) ....- when q : - b=..; set c [1];- when c [0,1] : -f (a,b) ...- (a) (b) 6 t t t t p [0] p [1] compute C11 compute <p> decompose (in,p); for (i=0;i&lt;8;i++) fire p [i]; - when p [0,1] : - add (p [0].out,p [1].out,out); set c [0];- /* compute C11 */ when p [2,3] : - add (p <ref> [2] </ref>.out,p [3].out,out); set c [1];- /* compute C12 */ when p [4,5] : add p [4].out,p [5].out,out); set c [2];- /* compute C21 */ when p [6,7] : add p [6].out,p [7].out,out); set c [3];- /* compute C22 */ when c [0-3] : send result;- - decompose (in,pin) mult_IN *in,*pin; - /* fill fields of p [].in */- add (p1out,p2out,out) mult_OUT *p1out, *p2out, *out; - /* code for matrix addition
Reference: [3] <author> F.W. Burton, M.M.Huntbach, </author> <title> "Virtual Tree Machines," </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. C-33, no. 3, </volume> <pages> pp. 278-280, </pages> <month> Mar. </month> <year> 1984. </year>
Reference-contexts: [0].out,p [1].out,out); set c [0];- /* compute C11 */ when p [2,3] : - add (p [2].out,p <ref> [3] </ref>.out,out); set c [1];- /* compute C12 */ when p [4,5] : add p [4].out,p [5].out,out); set c [2];- /* compute C21 */ when p [6,7] : add p [6].out,p [7].out,out); set c [3];- /* compute C22 */ when c [0-3] : send result;- - decompose (in,pin) mult_IN *in,*pin; - /* fill fields of p [].in */- add (p1out,p2out,out) mult_OUT *p1out, *p2out, *out; - /* code for matrix addition : out-&gt;c = p1out-&gt;c+p2out->c*/ - sequentialmult (in,out) mult_IN *in; mult_OUT *out; - /* sequential matrix
Reference: [4] <author> F.W. Burton, </author> <title> "Storage management in virtual tree machines", </title> <journal> IEEE Trans. Comput., </journal> <volume> vol. 37, no. 3, </volume> <pages> pp. 321-328. </pages>
Reference-contexts: readonly matrices */ InitRootInput (root.in); /* fill row,column and size fields of root.in */ fire root; - when root:-PrintResult (root.out);- - node mult - in : - int rowA, colA, rowB, colB, n;- out: float c [in-&gt;n*in->n];- node mult : p [8]; /* p [0] computes A11xB11 */ cond c <ref> [4] </ref>; /* p [1] computes A12xB21 */ init : - /* .... */ if ( matrix-size &lt; grainsize) - /* p [7] computes A22xB22 */ seqentialmult (in,out); send result; - else - decompose (in,p); for (i=0;i&lt;8;i++) fire p [i]; - when p [0,1] : - add (p [0].out,p [1].out,out); set c
Reference: [5] <author> Conte and de Boor, </author> <title> Elementary Numerical Analysis, </title> <note> (1980) pp 328-332. </note>
Reference-contexts: when body 1 */| when1 () - /* when body 1 */ | | local-comp3 | local-comp3 | | send result; | send message out to parent | | - | Exit system | | | - | | Node definition | Chare Definition | ----------------------------------------------------------------------- 11 Adaptive Quadrature Integration <ref> [5] </ref> of the function sin x x 3=2 over the interval fi fl correct up to 10 14 . Interval is divided into two if the accuracy is not sufficient. If the difference between computed error and required error is less than 10 11 , computation continues sequentially.
Reference: [6] <author> J.B.Dennis, E.C.Van Horn, </author> <title> "Programming semantics for multiprogrammed computations," </title> <journal> Comm. ACM vol. </journal> <volume> 9, no. 3, pp.143-155, </volume> <year> 1966. </year>
Reference: [7] <author> R.Finkel, U.Manber, </author> <title> "DIB-A distributed implementation of Backtracking," </title> <journal> ACM TOPLAS 9(2) pp.235-256, </journal> <month> April </month> <year> 1987. </year>
Reference-contexts: node mult - in : - int rowA, colA, rowB, colB, n;- out: float c [in-&gt;n*in->n];- node mult : p [8]; /* p [0] computes A11xB11 */ cond c [4]; /* p [1] computes A12xB21 */ init : - /* .... */ if ( matrix-size &lt; grainsize) - /* p <ref> [7] </ref> computes A22xB22 */ seqentialmult (in,out); send result; - else - decompose (in,p); for (i=0;i&lt;8;i++) fire p [i]; - when p [0,1] : - add (p [0].out,p [1].out,out); set c [0];- /* compute C11 */ when p [2,3] : - add (p [2].out,p [3].out,out); set c [1];- /* compute C12 */
Reference: [8] <author> E.Gabber, "VMPP: </author> <title> A practical tool for the development of portable and efficient programs for multiprocessors", </title> <journal> IEEE Trans. Parallel and Distributed Sys., </journal> <volume> vol. 1, </volume> <pages> no.3, </pages> <address> pp304-316, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: init : - InitMatrix (); /* read and initialize readonly matrices */ InitRootInput (root.in); /* fill row,column and size fields of root.in */ fire root; - when root:-PrintResult (root.out);- - node mult - in : - int rowA, colA, rowB, colB, n;- out: float c [in-&gt;n*in->n];- node mult : p <ref> [8] </ref>; /* p [0] computes A11xB11 */ cond c [4]; /* p [1] computes A12xB21 */ init : - /* .... */ if ( matrix-size &lt; grainsize) - /* p [7] computes A22xB22 */ seqentialmult (in,out); send result; - else - decompose (in,p); for (i=0;i&lt;8;i++) fire p [i]; - when p
Reference: [9] <author> L.V.Kale, </author> <title> "The Chare Kernel parallel programming language and system", </title> <booktitle> Proceedings of the International Conference on Parallel Processing, </booktitle> <volume> Vol II, </volume> <month> Aug </month> <year> 1990, </year> <month> pp17-25. </month>
Reference-contexts: After the description of the language in section 2, we discuss a programming example to show how the system is used in section 3. The system is implemented on top of the Chare Kernel parallel programming system <ref> [9] </ref>. The Chare Kernel supports dynamic creation of medium grained tasks with dynamic load balancing strategies, and provides machine independence. It is a general purpose machine independent parallel programming system, which can be used to develop specific languages, such as the one discussed here, with relatively little effort. <p> A label may refer to a subcomputation or a condition. Node labels are allowed to be set in order to permit variable number of subcomputations to be activated. In Figure 4-b, the for-loop activates a subset of subcomputations p [0]...p <ref> [9] </ref>. Assume that it is not known at compile time which subset of p's will be activated. How one can specify conditions for a when-block that should be activated when all the fired instances of a node completed.
Reference: [10] <author> J.T.Kueth, H.J.Siegel, </author> <title> "Extensions to the C programming language for SIMD/MIMD parallelism," </title> <booktitle> Proceedings of the International Conference on Parallel Processing, </booktitle> <month> Aug. </month> <year> 1985, </year> <month> pp.232-235. </month>
Reference-contexts: In order to use the new value of b, the third when-block should wait for completion of the second one. Correct order of execution is achieved by utilizing condition variables as in Figure 5-b. 5 node f:p <ref> [10] </ref> node f:p [10]; .... .... fire p [i]; if (condition (i)) fire p [i]; else set p [i]; when p [0-9] :-...- (a) (b) 2.4 Main Node The source program should have one specially designated node named main. <p> In order to use the new value of b, the third when-block should wait for completion of the second one. Correct order of execution is achieved by utilizing condition variables as in Figure 5-b. 5 node f:p <ref> [10] </ref> node f:p [10]; .... .... fire p [i]; if (condition (i)) fire p [i]; else set p [i]; when p [0-9] :-...- (a) (b) 2.4 Main Node The source program should have one specially designated node named main.
Reference: [11] <author> V.Kumar, V.N.Rao, </author> <title> "Parallel depth first search,Part I:Implementation," </title>
Reference: [12] <author> C.Mead, L.Conway, </author> <title> Introduction to VLSI systems, </title> <publisher> Addison-Wesley, </publisher> <pages> (1980) pp 307-312. </pages>
Reference-contexts: Clique Finding the largest clique for a given undirected graph. All potential cliques are generated with a divide-and-conquer approach <ref> [12] </ref>. Matrix Multiplication Multiply two 160 fi 160 matrices as in explained in section 3. When size of the submatrices reaches below 20 fi 20, multiplication is done without further division. All programs achieved almost linear speedups on shared memory machines. This indicates that enough parallelism is available.
Reference: [13] <author> P.A. Nelson, L.Synder, </author> <title> "Programming paradigms for nonshared memory parallel computer," in The Characteristics of Parallel Algorithms, </title> <editor> L.H.Jamieson, D.B.Gannon, and R.J.Douglas, Eds. </editor> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1987, </year> <pages> pp. 3-20. </pages>
Reference: [14] <author> F.J.Peters, </author> <title> "Tree machines and divide-and-conquer algorithms," </title> <booktitle> Proc. Conf. Analyzing Problem-Classes Programming Parallel Computing, </booktitle> <address> Nuremburg, W.Germany, </address> <month> June </month> <year> 1981, </year> <pages> pp. 25-36. </pages>
Reference: [15] <author> V.N.Rao, V.Kumar, </author> <title> "Parallel depth first search, Part II: Analysis," </title>
Reference: [16] <author> V.M.Lo, S.Rajopadhye, </author> <title> "Mapping divide-and-conquer algorithms to parallel architectures," </title> <booktitle> Proceedings of the International Conference on Parallel Processing, </booktitle> <volume> vol. III, </volume> <pages> pp. 128-135, </pages> <month> Aug. </month> <year> 1990. </year>
Reference: [17] <author> W.Shu, L.V.Kale, </author> <title> "Dynamic scheduling of medium-grained processes on multicomputers", </title> <type> Tech. Rep. </type> <institution> UIUCDCS-R-89-1528, Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> July </month> <year> 1989. </year> <month> 14 </month>
Reference: [18] <author> T.L.Sterling, et al., </author> <title> "Effective implementation of a parallel language on a multiprocessor," </title> <journal> IEEE Micro, </journal> <volume> vol. 7, no. 6, </volume> <pages> pp. 27-36, </pages> <month> July </month> <year> 1984. </year>
Reference: [19] <author> Q.F.Stout, </author> <title> "Supporting divide-and-conquer algorithms for image processing," </title> <institution> J.Parallel Dis-trib. Comput. </institution> <month> 4 </month> <year> (1987), </year> <month> pp.95-115. </month>
Reference: [20] <author> Y.Wu, T.G., Lewis, </author> <title> "Parallelism Encapsulation in C++," </title> <booktitle> Processedings of the International Conference on Parallel Processing, </booktitle> <volume> vol. II, </volume> <pages> pp. 35-42, </pages> <month> Aug. </month> <year> 1990. </year>
Reference: [21] <author> Z.Xu, K.Hwang, </author> <title> "Molecule: A language construct for layered development of parallel programs", </title> <journal> IEEE Trans. Software, </journal> <volume> vol. 15, no. 5, </volume> <month> May </month> <year> 1989 </year> <month> 15 </month>
References-found: 21

