URL: http://www.cs.umd.edu/~tseng/papers/ics98.ps
Refering-URL: http://www.cs.umd.edu/projects/cosmic/papers.html
Root-URL: 
Email: frivera,tsengg@cs.umd.edu  
Title: Eliminating Conflict Misses for High Performance Architectures  
Author: Gabriel Rivera, Chau-Wen Tseng 
Address: College Park, MD 20742  
Affiliation: Department of Computer Science University of Maryland  
Abstract: Many cache misses in scientific programs are due to conflicts caused by limited set associativity. Two data-layout transformations, inter- and intra-variable padding, can eliminate many conflict misses at compile time. We present Group-Pad, an inter-variable padding heuristic to preserve group reuse in stencil computations frequently found in scientific computations. We show padding can also improve performance in parallel programs. Our optimizations have been implemented and tested on a collection of kernels and programs for different cache and data sizes. Preliminary results demonstrate GroupPad is able to consistently preserve group reuse among the programs evaluated, though execution time improvements are small for actual problem and cache sizes tested. Padding improves performance of parallel versions of programs approximately the same magnitude as sequential versions of the same program. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson, S. Amarasinghe, and M. Lam. </author> <title> Data and computation transformation for multiprocessors. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Researchers have examined data layout transformations, usually in the context of parallel programs. Techniques include changing the placement of variables in explicitly parallel programs [10], reshaping arrays to make local data contiguous <ref> [1] </ref>, and combining array transpose with loop permutation to improve parallelism and locality [4, 12, 19]. Man-jikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion [16].
Reference: [2] <author> B. Bershad, D. Lee, T. Romer, and B. Chen. </author> <title> Avoiding conflict misses dynamically in large direct-mapped caches. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: In particular, conflict misses can cause half of all cache misses and most intra-nest misses in scientific codes [18]. Conflicts may be eliminated with hardware [9, 11] or operating systems support <ref> [2, 3] </ref>. For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15].
Reference: [3] <author> E. Bugnion, J. Anderson, T. Mowry, M. Rosenblum, and M. Lam. </author> <title> Compiler-directed page coloring for multiprocessors. </title> <booktitle> In Proceedings of the Eighth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VIII), </booktitle> <address> Boston, MA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: We see padding transformations do improve parallel performance for both systems. The magnitude of the improvements are also similar to the improvements in sequential execution times. Recently, compiler-directed page coloring was proposed 5 6 as a method for reducing conflict misses in multiprocessors <ref> [3] </ref>. Two of the SPEC95 programs which benefited the most were swim and tomcatv. We find in our experiments that both also benefit from inter-variable padding. <p> In particular, conflict misses can cause half of all cache misses and most intra-nest misses in scientific codes [18]. Conflicts may be eliminated with hardware [9, 11] or operating systems support <ref> [2, 3] </ref>. For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15].
Reference: [4] <author> M. Cierniak and W. Li. </author> <title> Unifying data and control transformations for distributed shared-memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Researchers have examined data layout transformations, usually in the context of parallel programs. Techniques include changing the placement of variables in explicitly parallel programs [10], reshaping arrays to make local data contiguous [1], and combining array transpose with loop permutation to improve parallelism and locality <ref> [4, 12, 19] </ref>. Man-jikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion [16]. We improve on their algorithm in this paper.
Reference: [5] <author> S. Coleman and K. S. M c Kinley. </author> <title> Tile size selection using cache organization and data layout. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15]. Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation [7, 17, 23], and tiling <ref> [5, 14, 23] </ref>, though loop fission and fusion have also been found to be helpful [16, 17]. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23].
Reference: [6] <author> J. Ferrante, V. Sarkar, and W. Thrash. </author> <title> On estimating and enhancing cache effectiveness. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, Fourth International Workshop, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1991. </year> <note> Springer-Verlag. </note>
Reference-contexts: Many cache models have been designed for estimating cache misses to help guide data locality optimizations <ref> [6, 7, 17, 23] </ref>. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. present a method for detecting and counting the number of conflict misses [21].
Reference: [7] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: We refer to arrays which have equal element sizes and equal dimension sizes in all but their highest dimension as conforming. We also use uniformly-generated references <ref> [7] </ref> in this paper to refer to array references to conforming arrays where array subscripts match excluding constants. For instance, all array references in Figure 1 are uniformly generated. When we linearize uniformly-generated references to compute their conflict distance, loop index variable terms cancel. <p> For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15]. Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation <ref> [7, 17, 23] </ref>, and tiling [5, 14, 23], though loop fission and fusion have also been found to be helpful [16, 17]. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23]. <p> Many cache models have been designed for estimating cache misses to help guide data locality optimizations <ref> [6, 7, 17, 23] </ref>. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. present a method for detecting and counting the number of conflict misses [21].
Reference: [8] <author> S. Ghosh, M. Martonosi, and S. Malik. </author> <title> Cache miss equations: An analytical representation of cache misses. </title> <booktitle> In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Ghosh et al. calculate conflict misses accurately by counting the number of integer solutions to cache miss equations, linear Diophantine equations that exactly specify the cache line to which 7 each reference is mapped for every loop <ref> [8] </ref>. Our heuris-tics for detecting conflict misses are less accurate, but are inexpensive and allow us to optimize larger programs. Researchers have examined data layout transformations, usually in the context of parallel programs.
Reference: [9] <author> A. Gonzalez, M. Valero, N. Topham, and J. Parcerisa. </author> <title> Eliminating cache conflict misses through XOR-based placement functions. </title> <booktitle> In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: In particular, conflict misses can cause half of all cache misses and most intra-nest misses in scientific codes [18]. Conflicts may be eliminated with hardware <ref> [9, 11] </ref> or operating systems support [2, 3]. For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15].
Reference: [10] <author> T. Jeremiassen and S. Eggers. </author> <title> Reducing false sharing on shared memory multiprocessors through compile time data transformations. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Our heuris-tics for detecting conflict misses are less accurate, but are inexpensive and allow us to optimize larger programs. Researchers have examined data layout transformations, usually in the context of parallel programs. Techniques include changing the placement of variables in explicitly parallel programs <ref> [10] </ref>, reshaping arrays to make local data contiguous [1], and combining array transpose with loop permutation to improve parallelism and locality [4, 12, 19].
Reference: [11] <author> N. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: In particular, conflict misses can cause half of all cache misses and most intra-nest misses in scientific codes [18]. Conflicts may be eliminated with hardware <ref> [9, 11] </ref> or operating systems support [2, 3]. For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15].
Reference: [12] <author> M. Kandemir, J. Ramanujam, and A. Choudhary. </author> <title> A compiler algorithm for optimizing locality in loop nests. </title> <booktitle> In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Researchers have examined data layout transformations, usually in the context of parallel programs. Techniques include changing the placement of variables in explicitly parallel programs [10], reshaping arrays to make local data contiguous [1], and combining array transpose with loop permutation to improve parallelism and locality <ref> [4, 12, 19] </ref>. Man-jikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion [16]. We improve on their algorithm in this paper.
Reference: [13] <author> P. Keleher and C.-W. Tseng. </author> <title> Enhancing software DSM for compiler-parallelized applications. </title> <booktitle> In Proceedings of the 11th International Parallel Processing Symposium, </booktitle> <address> Geneva, Switzerland, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: We used SUIF to generate parallel programs for two systems, Pthreads on a 4-processor Alpha workstation (shared-memory) and CVM <ref> [13] </ref> on an 8-processor IBM SP-2 (software DSM). Results are displayed in Figure 8. Programs are listed on the X-axis, improvement (in %) relative to the execution time of the original parallel program is shown on the Y-axis. We see padding transformations do improve parallel performance for both systems.
Reference: [14] <author> M. Lam, E. Rothberg, and M. E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IV), </booktitle> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15]. Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation [7, 17, 23], and tiling <ref> [5, 14, 23] </ref>, though loop fission and fusion have also been found to be helpful [16, 17]. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23].
Reference: [15] <author> A. Lebeck and D. Wood. </author> <title> Cache profining and the SPEC benchmarks: A case study. </title> <journal> IEEE Computer, </journal> <volume> 27(10) </volume> <pages> 15-26, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Conflicts may be eliminated with hardware [9, 11] or operating systems support [2, 3]. For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks <ref> [15] </ref>. Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation [7, 17, 23], and tiling [5, 14, 23], though loop fission and fusion have also been found to be helpful [16, 17].
Reference: [16] <author> N. Manjikian and T. Abdelrahman. </author> <title> Fusion of loops for parallelism and locality. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 8(2) </volume> <pages> 193-209, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation [7, 17, 23], and tiling [5, 14, 23], though loop fission and fusion have also been found to be helpful <ref> [16, 17] </ref>. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23]. These models typically can predict only capacity misses because they assume a fully-associative cache. <p> Man-jikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion <ref> [16] </ref>. We improve on their algorithm in this paper. In previous research, we developed padding techniques for eliminating severe cache conflicts in stencils and linear algebra computations [20].
Reference: [17] <author> K. S. M c Kinley, S. Carr, and C.-W. Tseng. </author> <title> Improving data locality with loop transformations. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 18(4) </volume> <pages> 424-453, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15]. Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation <ref> [7, 17, 23] </ref>, and tiling [5, 14, 23], though loop fission and fusion have also been found to be helpful [16, 17]. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23]. <p> Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation [7, 17, 23], and tiling [5, 14, 23], though loop fission and fusion have also been found to be helpful <ref> [16, 17] </ref>. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23]. These models typically can predict only capacity misses because they assume a fully-associative cache. <p> Many cache models have been designed for estimating cache misses to help guide data locality optimizations <ref> [6, 7, 17, 23] </ref>. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. present a method for detecting and counting the number of conflict misses [21].
Reference: [18] <author> K. S. M c Kinley and O. Temam. </author> <title> A quantitative analysis of loop nest locality. </title> <booktitle> In Proceedings of the Eighth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VIII), </booktitle> <address> Boston, MA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Conflict misses have been found to be a significant source of poor performance in scientific programs, particularly within loop nests <ref> [18] </ref>. We previously presented inter- and intra-variable padding, two compiler transformations to eliminate severe conflicts, misses which occur on every loop iteration [20]. Unlike standard compiler transformations which restructure the computation performed by the program, these two techniques modify the program's data layout. <p> In particular, conflict misses can cause half of all cache misses and most intra-nest misses in scientific codes <ref> [18] </ref>. Conflicts may be eliminated with hardware [9, 11] or operating systems support [2, 3]. For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15].
Reference: [19] <author> M. O'Boyle and P. Knijnenburg. </author> <title> Non-singular data transformations: Definition, validity, </title> <booktitle> and applications. In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Researchers have examined data layout transformations, usually in the context of parallel programs. Techniques include changing the placement of variables in explicitly parallel programs [10], reshaping arrays to make local data contiguous [1], and combining array transpose with loop permutation to improve parallelism and locality <ref> [4, 12, 19] </ref>. Man-jikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion [16]. We improve on their algorithm in this paper.
Reference: [20] <author> G. Rivera and C.-W. Tseng. </author> <title> Data transformations for eliminating conflict misses. </title> <booktitle> In Proceedings of the SIGPLAN '98 Conference on Programming Language Design and Implementation, </booktitle> <address> Montreal, Canada, </address> <month> July </month> <year> 1998. </year>
Reference-contexts: Conflict misses have been found to be a significant source of poor performance in scientific programs, particularly within loop nests [18]. We previously presented inter- and intra-variable padding, two compiler transformations to eliminate severe conflicts, misses which occur on every loop iteration <ref> [20] </ref>. Unlike standard compiler transformations which restructure the computation performed by the program, these two techniques modify the program's data layout. To see how padding eliminates conflict misses, consider the program in Figure 1. The unit-stride references to A and B provide spatial locality, leading to cache reuse. <p> Later we present inter-variable padding heuristics to preserve such group reuse. We implemented inter- and intra-array padding in the SUIF compiler [22]. Preliminary experiments on a collection of kernels and benchmark programs showed padding can lower cache miss rates significantly for some programs <ref> [20] </ref>. In this paper, we make two new contributions: * improving padding heuristics to preserve group reuse across outer loop iterations * evaluating the impact of padding for parallel programs We begin by presenting previous algorithms for eliminating severe conflict misses, then discuss enhancements to preserve group reuse. <p> Increasingly larger pad sizes are used until no further severe conflicts are detected. We also apply previous techniques to pad array column sizes which can lead to frequent conflict misses in linear algebra codes <ref> [20] </ref>. 2.2 Algorithm Pad Pad performs inter-variable padding by assigning base addresses to variables, padding a variable A whenever conflict distances between uniformly-generated references to A and some previously assigned variable are less than L s [20]. Increasingly larger pad sizes are used until conflict distances are L s . <p> array column sizes which can lead to frequent conflict misses in linear algebra codes <ref> [20] </ref>. 2.2 Algorithm Pad Pad performs inter-variable padding by assigning base addresses to variables, padding a variable A whenever conflict distances between uniformly-generated references to A and some previously assigned variable are less than L s [20]. Increasingly larger pad sizes are used until conflict distances are L s . Since pads larger than C s are equivalent to smaller pads, the heuristic attempts only pads &lt; C s . <p> We improve on their algorithm in this paper. In previous research, we developed padding techniques for eliminating severe cache conflicts in stencils and linear algebra computations <ref> [20] </ref>. In this paper we improve our heuristic to preserve group reuse across outer loop iterations, as well as evaluate its impact on parallel applications. 6 Conclusions Padding transformations have been proven useful for eliminating cache conflict misses.
Reference: [21] <author> O. Temam, C. Fricker, and W. Jalby. </author> <title> Cache interference phenomena. </title> <booktitle> In Proceedings of the 1994 ACM SIGMET-RICS Conference on Measurement & Modeling Computer Systems, </booktitle> <address> Santa Clara, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23]. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. present a method for detecting and counting the number of conflict misses <ref> [21] </ref>. Ghosh et al. calculate conflict misses accurately by counting the number of integer solutions to cache miss equations, linear Diophantine equations that exactly specify the cache line to which 7 each reference is mapped for every loop [8].
Reference: [22] <author> R. Wilson et al. </author> <title> SUIF: An infrastructure for research on parallelizing and optimizing compilers. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 29(12) </volume> <pages> 31-37, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Later we present inter-variable padding heuristics to preserve such group reuse. We implemented inter- and intra-array padding in the SUIF compiler <ref> [22] </ref>. Preliminary experiments on a collection of kernels and benchmark programs showed padding can lower cache miss rates significantly for some programs [20]. <p> As a result, we expect data layout optimizations to be also effective in eliminating conflict misses on parallel programs. 4 Experimental Evaluation 4.1 Evaluation Framework We implemented our transformations in the Stanford SUIF compiler <ref> [22] </ref> and used it to optimize kernels and two applications from SPEC95 as shown in Table 1. The original and padded versions of each program were both timed and simulated for a number of cache configurations using Shade from Sun Microsystems.
Reference: [23] <author> M. E. Wolf and M. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year> <month> 8 </month>
Reference-contexts: For many scientific codes we can achieve similar or better results through inexpensive data layout transformations. Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15]. Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation <ref> [7, 17, 23] </ref>, and tiling [5, 14, 23], though loop fission and fusion have also been found to be helpful [16, 17]. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23]. <p> Data-layout transformations applied by hand has been shown to reduce conflict misses in the SPEC benchmarks [15]. Researchers working on compile-time data locality optimizations have concentrated on computation-reordering such as loop permutation [7, 17, 23], and tiling <ref> [5, 14, 23] </ref>, though loop fission and fusion have also been found to be helpful [16, 17]. Many cache models have been designed for estimating cache misses to help guide data locality optimizations [6, 7, 17, 23]. <p> Many cache models have been designed for estimating cache misses to help guide data locality optimizations <ref> [6, 7, 17, 23] </ref>. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. present a method for detecting and counting the number of conflict misses [21].
References-found: 23

