URL: http://www.stat.cmu.edu/www/cmu-stats/tr/tr659/tr659.ps
Refering-URL: 
Root-URL: 
Email: e-mail: mdaniels@stat.cmu.edu  
Phone: fax: (412) 268 7828  
Title: Nonconjugate Bayesian estimation of covariance matrices and its use in hierarchical models  Please send comments to:  
Author: Michael J. Daniels Robert E. Kass Michael J. Daniels 
Address: 232 Baker Hall Pittsburgh, PA 15213  
Note: PLEASE DO NOT QUOTE WITHOUT PERMISSION  
Affiliation: 1 Department of Statistics, Carnegie Mellon University  Department of Statistics Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Barnard J, McCulloch R, Meng X. </author> <title> (1996) A Natural Strategy for modeling covariance matrices with Application to shrinkage. </title> <institution> Harvard University Dept of Statistics technical report. </institution> <note> Bennet JE, </note> <editor> Racine-Poon A, </editor> <title> Wakefield JC (1995). MCMC for nonlinear hierarchical models. 17 in Markov Chain Monte Carlo in Practice, </title> <editor> eds. Gilks WR, Richardson S, Spiegelhalter DJ, </editor> <publisher> Chapman and Hall, </publisher> <pages> pp. 339-358. </pages>
Reference: <author> Berger J, </author> <title> Bernardo JM (1992). On the development of reference priors (with discussion). In Bayesian Statistics 4, </title> <editor> eds. JM Bernardo, JO Berger, AP Dawid, AFM Smith. </editor> <publisher> Oxford University Press, </publisher> <pages> pp. 35-60. </pages> <editor> Christiansen CL, Morris, </editor> <title> CN (1997) Hierarchical Poisson regression modeling. </title> <journal> Journal of the American Statistical Association. </journal> <volume> 92 </volume> <month> 618-632. </month> <title> Daniels, MJ (1996) A prior for the variance in hierarchical models. </title> <institution> Carnegie Mellon Dept of Statistics technical report. </institution>
Reference: <author> Daniels MJ, Gatsonis C. </author> <title> (1996) Multilevel hierarchical generalized linear models in the analysis of variations in health care utilization. </title> <journal> submitted to Journal of the American Statistical Association. </journal>
Reference: <author> Dey DK, Srinivasan C. </author> <title> (1985) Estimation of a covariance matrix under Stein's loss. </title> <journal> Annals of Statistics. </journal> <volume> 13 </volume> <month> 1581-1591. </month> <title> Genz A, Kass RE (1997) Subregion-adaptive integration of functions having a dominant peak. </title> <journal> Journal of Computational and Graphical Statistics. </journal> <volume> 6: </volume> <pages> 92-111. </pages>
Reference: <author> Gilks WR, Richardson S, </author> <title> Spiegelhalter DJ. (1995) Markov Chain Monte Carlo in Practice, </title> <publisher> Chap-man and Hall, London. </publisher>
Reference-contexts: We ran 2000 iterations of each method and computed the time to run the chain and the Monte Carlo standard errors of the posterior means for each method (Table 2). For the MCMC runs, we computed the Monte Carlo standard error using the method of batch means <ref> (e.g., Gilks et al, 1995, p. 50) </ref> and for the importance sampling run, we computed the approximate Monte Carlo standard error using an approximation to the variance of the importance ratio (e.g., O'Hagan, 1995, p. 224).
Reference: <author> Goldstein, H. </author> <title> (1962) Classical Mechanics, </title> <publisher> Addison-Wesley. </publisher>
Reference: <author> Haff, </author> <title> L.R. (1991) The variational form of certain Bayes estimators. </title> <journal> Annals of Statistics. </journal> <volume> 19 </volume> <pages> 1163-1190. </pages>
Reference: <author> Hobert, JP, Casella G. </author> <title> (1996) The effect of improper priors on Gibbs Sampling in hierarchical linear mixed models. </title> <journal> Journal of the American Statistical Association. </journal> <volume> 91 </volume> <pages> 1461-1474. </pages>
Reference: <author> Hoffman DK, Raffenetti RC, Ruedenberg K. </author> <title> (1972) Generalization of Euler angles to N-dimensional orthogonal matrices. </title> <journal> Journal of Mathematical Physics. </journal> <volume> 13 </volume> <pages> 528-533. </pages>
Reference: <author> Kass RE, Steffey D. </author> <title> (1989) Approximate Bayesian inference in conditionally independent hierarchical models (parametric empiricial Bayes models). </title> <journal> Journal of the American Statistical Association. </journal> <volume> 84 </volume> <month> 717-726. </month> <title> 18 Kass RE, Wasserman L (1995) A reference Bayesian test for nested hypotheses and its relationship to the Schwarz Criterion. </title> <journal> Journal of the American Statistical Association. </journal> 90:928-934. Ledoit, O (1996). A well-conditioned estimator for large dimensional covariance matrices. Working paper. Anderson Graduate School of Management, UCLA. 
Reference: <author> Leonard T, Hsu JS (1993). </author> <title> Bayesian inference for a covariance matrix. </title> <journal> Annals of Statistics. </journal> <volume> 21 </volume> <pages> 1-25. </pages>
Reference: <author> Lin SP, </author> <title> and Perlman MD (1985). A Monte Carlo comparison of four estimators for a covariance matrix. In Multivariate Analysis 6 P.R. Krishnaiah, </title> <editor> ed.) p.411-429. </editor> <title> North Holland. Natarajan R, McCulloch CE (1995) A note on the existence of the posterior distribution for a class of mixed models for binomial responses. </title> <journal> Biometrika, </journal> <volume> 82 </volume> <pages> 639-643. </pages>
Reference: <author> O'Hagan A. </author> <title> (1994) Kendall's Advanced Theory of Statistics, Volume 2B: Bayesian Inference, </title> <publisher> Halsted Press, </publisher> <address> New York. </address> <note> Pinheiro JC, </note> <author> Bates DM. </author> <title> (1996) Unconstrained parametrizations for variance-covariance matrices. </title> <journal> Statistics and Computing. </journal> <pages> 1-6. </pages>
Reference: <author> Schervish, M. J. </author> <booktitle> (1995) Theory of Statistics. </booktitle> <address> New York, </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For a discussion of other reference priors see Kass and Wasserman (1995). 2.1 Conjugate prior The conjugate prior is the inverse Wishart <ref> (Schervish, 1995) </ref> (i.e., the conjugate prior for D 1 is Wishart). However, this prior lacks flexibility, allowing only one precision parameter for all p (p + 1)=2 elements, and requires specification of a mean matrix.
Reference: <author> Smith AFM, </author> <title> Roberts GO. (1993) Bayesian Computation via the Gibbs Sampler and Related Markov Chain Monte Carlo Methods. </title> <journal> Journal of Royal Statistical Society B. </journal> <volume> 55 </volume> <pages> 3-23. </pages>
Reference-contexts: We focus on the model introduced in Section 1. The usual approach to posterior simulation in Bayesian hierarchical models is to apply Gibbs sampling, possibly using Metropolis steps to generate individual components <ref> (Smith and Roberts, 1993) </ref>. This works quite well when the full conditional distribution of D is distributed as inverse Wishart, which occurs when an inverse Wishart prior or a flat prior is placed on D.
Reference: <author> Stein C. </author> <title> (1975) Estimation of a covariance matrix. </title> <booktitle> Rietz Lecture, 39th Annual meeting IMS. </booktitle> <address> Atlanta, Georgia. </address>
Reference: <author> Sun L, Hsu JS, Guttman I, Leonard T. </author> <title> (1996) Bayesian Methods for variance component models. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 91 </volume> <pages> 743-752. </pages>
Reference: <author> Tanner MA. </author> <title> (1993) Tools for Statistical Inference: Methods for Exporation of Posterior Distributions and Likelihood Functions. New York, Springer-Verlag. Thisted (1988) Elements of Statistical Computing. </title> <publisher> Chapman and Hall. </publisher>
Reference-contexts: See the Appendix for a verification that these are the correct importance weights. The use of this importance sampling procedure will produce posterior means and variances. If we desire a 10 sample from the posterior distribution, we can obtain it by resampling <ref> (Tanner, 1993, section 5.7) </ref>. 4.2 Issues in computing Several issues and problems can arise with importance sampling. In our context, we can consider two distinct problems.

References-found: 18

