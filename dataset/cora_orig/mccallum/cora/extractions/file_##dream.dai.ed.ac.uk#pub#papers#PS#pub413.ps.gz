URL: file://dream.dai.ed.ac.uk/pub/papers/PS/pub413.ps.gz
Refering-URL: http://www.dai.ed.ac.uk:80/staff/personal_pages/bundy/projects/95-96/msc-project-diag-method.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Experiments with Proof Plans for Induction  
Author: Alan Bundy Frank van Harmelen Jane Hesketh Alan Smaill 
Keyword: Theorem proving, mathematical induction, search, combinatorial explosion, proof plans, tactics, planning, program synthesis. Acknowledgements  
Date: October 28, 1992  
Affiliation: Department of Artificial Intelligence, University of Edinburgh.  
Abstract: The technique of proof plans, is explained. This technique is used to guide automatic inference in order to avoid a combinatorial explosion. Empirical research is described to test this technique in the domain of theorem proving by mathematical induction. Heuristics, adapted from the work of Boyer and Moore, have been implemented as Prolog programs, called tactics, and used to guide an inductive proof checker, Oyster. These tactics have been partially specified in a meta-logic, and the plan formation program, clam, has been used to reason with these specifications and form plans. These plans are then executed by running their associated tactics and, hence, performing an Oyster proof. Results are presented of the use of this technique on a number of standard theorems from the literature. Searching in the planning space is shown to be considerably cheaper than searching directly in Oyster's The research reported in this paper was supported by SERC grant GR/E/44598, Alvey/SERC grant GR/D/44270, and an SERC Senior Fellowship to the first author. We are grateful to the other members of the mathematical reasoning group at Edinburgh for many useful discussions, and especially to Toby Walsh and an anonymous referee for feedback on earlier drafts. search space. The success rate on the standard theorems is high.
Abstract-found: 1
Intro-found: 1
Reference: [Aubin 75] <author> R. Aubin. </author> <title> Some generalization heuristics in proofs by induction. </title> <editor> In G. Huet and G. Kahn, editors, </editor> <booktitle> Actes du Colloque Construction: </booktitle> <institution> Amelioration et verification de Programmes. Institut de recherche d'informatique et d'automatique, </institution> <year> 1975. </year>
Reference-contexts: The three applications of wave raise the occurrences of the successor function, s, from their innermost positions around the x 0 s to being the outermost functions of the induction conclusion. Following <ref> [Aubin 75] </ref>, we call this process rippling-out. The two arguments of the successor functions are then identical to the two arguments of = in the induction hypothesis. The fertilize tactic then replaces the right hand of these two arguments by the left hand one in the induction conclusion. <p> Rippling-out is implemented as repeated applications of the wave tactic. Each application of wave applies a wave rule to rewrite the current goal into a new one. Our first version of wave was called unfold. It was based on earlier work by [Boyer & Moore 79], <ref> [Aubin 75] </ref> and [Burstall & Darlington 77] and was restricted to the application of rewrite rules based on the step cases of recursive definitions. Our current version is a generalization of unfold which can use previously proved lemmas with a similar structure to unfold rules.
Reference: [Boyer & Moore 79] <author> R.S. Boyer and J.S. Moore. </author> <title> A Computational Logic. </title> <publisher> Academic Press, </publisher> <address> 1979. </address> <publisher> ACM monograph series. </publisher>
Reference-contexts: These tactics need to be applied flexibly in order to maximise Oyster's chances of proving each theorem. The state of the art in inductive theorem proving is the Boyer-Moore Theorem Prover, <ref> [Boyer & Moore 79] </ref> (henceforth bmtp). It is, thus, natural for us to try and represent the heuristics embedded in the bmtp as Oyster tactics. [Bundy 88] contains an analysis of some of these heuristics. <p> We have used this analysis to implement a number of Oyster tactics for inductive proof and have tested them on some simple theorems, in the theories of natural numbers and lists, drawn from <ref> [Boyer & Moore 79] </ref> and [Kanamori & Fujita 86]. These tactics are outlined in x2. A theorem prover faithful to the spirit of the bmtp would apply these tactics, successively, to a series of sequents. <p> Rippling-out is implemented as repeated applications of the wave tactic. Each application of wave applies a wave rule to rewrite the current goal into a new one. Our first version of wave was called unfold. It was based on earlier work by <ref> [Boyer & Moore 79] </ref>, [Aubin 75] and [Burstall & Darlington 77] and was restricted to the application of rewrite rules based on the step cases of recursive definitions. Our current version is a generalization of unfold which can use previously proved lemmas with a similar structure to unfold rules. <p> x)) BM77 apprev app (rev (l); rev (m)) = rev (app (m; l)) BM09 applast n = last (app (x; n :: nil)) KF432 tailrev 3 rev (app (rev (a); n :: nil)) = n :: a KF51 Key to Source Column BMnn is theorem nn from appendix A of <ref> [Boyer & Moore 79] </ref>. KBnnn is example n.n.n from [Kanamori & Fujita 86]. <p> As mentioned in x1, the state of the art in inductive theorem proving is still the bmtp. We have yet to incorporate all the heuristics from the bmtp into our tactics or to test them on the full range of theorems in <ref> [Boyer & Moore 79] </ref>. However, even on the simple examples we have tried so far we have found some improvements over the bmtp. For instance, bmtp can only prove comfi if the lemma 3 u fi s (v) = u + u fi v has previously been proved.
Reference: [Bundy & Sterling 88] <author> A. Bundy and L.S. Sterling. </author> <title> Meta-level inference: two applications. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 4(1) </volume> <pages> 15-27, </pages> <year> 1988. </year> <note> Also available from Edinburgh as DAI Research Paper No. 273. </note>
Reference-contexts: We are unusual in using it to construct proof plans, i.e. outlines of the whole inference process. The only other use of proof plans we are aware of is earlier work in our own group, e.g. [Silver 85] and <ref> [Bundy & Sterling 88] </ref>, on which this work builds, and the use of abstraction to build proof plans, e.g. [Sacerdoti 74, ?]. Abstraction, in contrast to meta-level inference, works with a degenerate version of the object-level space in which some essential detail is thrown away.
Reference: [Bundy 88] <author> A. Bundy. </author> <title> The use of explicit plans to guide inductive proofs. </title> <editor> In R. Lusk and R. Overbeek, editors, </editor> <booktitle> 9th Conference on Automated Deduction, </booktitle> <pages> pages 111-120. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year> <note> Longer version available from Edinburgh as DAI Research Paper No. 349. </note>
Reference-contexts: The state of the art in inductive theorem proving is the Boyer-Moore Theorem Prover, [Boyer & Moore 79] (henceforth bmtp). It is, thus, natural for us to try and represent the heuristics embedded in the bmtp as Oyster tactics. <ref> [Bundy 88] </ref> contains an analysis of some of these heuristics. <p> We call this specification a method. It is expressed in a meta-logic, whose domain of discourse consists of logical expressions and tactics for manipulating them. More details of the advantages and use of proof plans can be found in <ref> [Bundy 88] </ref>. 2 Tactics for Guiding Inductive Proofs 2.1 Example Inductive Proofs Oyster tactics. It is the associativity of + over the natural numbers. <p> This success confirms the hypothesis proposed in <ref> [Bundy 88] </ref> that the proof structure captured in ind strat underlies a large number of inductive proofs. However, some theorems (e.g. comfi) do not yield to this straightforward combination of tactics and require ad hoc modifications, e.g. using base in the step case. <p> We include work on (a) building inductive theorem provers, (b) using tactics and (c) using meta-level inference. However, we start by comparing the clam and Oyster systems described here with the original proposal for proof plans in <ref> [Bundy 88] </ref>. The methods and tactics we proposed in [Bundy 88] required very little modification to prove the theorems listed in table 1. Since that paper was written there has been a steady, evolutionary process of improvement and extension, as our understanding of the induction strategy developed. <p> We include work on (a) building inductive theorem provers, (b) using tactics and (c) using meta-level inference. However, we start by comparing the clam and Oyster systems described here with the original proposal for proof plans in <ref> [Bundy 88] </ref>. The methods and tactics we proposed in [Bundy 88] required very little modification to prove the theorems listed in table 1. Since that paper was written there has been a steady, evolutionary process of improvement and extension, as our understanding of the induction strategy developed. <p> We also rationalised their names, e.g. ind strat used to be called basic plan. 14 Apart from this, the main changes were to the nature of the effects. The effects in <ref> [Bundy 88] </ref> were weak meta-level assertions about the relation between the input and the output of the tactic, which permitted only a partial prediction about the form of the output. <p> This cheapness is one major factor in making it cheaper to pre-plan proofs than to search directly in the object-level search space. The other factor is the grouping of object-level steps into bigger planning steps. Another difference from the methods proposed in <ref> [Bundy 88] </ref> is that the success of clam preconditions ensures the success if clam effects and hence of the Oyster tactics i.e. a clam method is a complete specification of its tactic. Thus clam proof plans never fail. <p> Thus clam proof plans never fail. However, this guarantee is bought at the price of building optional steps into the preconditions, effects and tactics using andpossibly, xor, etc., which makes them fairly messy. We are considering reverting to the proposal in <ref> [Bundy 88] </ref> of making methods be partial specifications of tactics, where the preconditions do not imply the effects. However, this will require much more flexibility in the planning and the tactic application mechanisms. As mentioned in x1, the state of the art in inductive theorem proving is still the bmtp. <p> For instance, it might only return a pattern, i.e. a formula containing meta-variables. The existential method already does this. Alternatively, the method application might return an abstraction of the output. Or, we might 16 revert to the proposal in <ref> [Bundy 88] </ref>, and return a meta-level description of the output. It will then be necessary to satisfy the preconditions of subsequent methods not by evaluating them on the current sequent, but by a process of bridging inference from the effects of previous methods. <p> We hope that proof plans will also be applicable in other domains. We intend to explore their use in other areas of mathematics and in knowledge-based systems. 7 Conclusion In this paper we have described empirical work to test the technique of proof plans, originally proposed in <ref> [Bundy 88] </ref>, in the domain of inductive theorem proving. We have built a series of tactics for the proof checker, Oyster, partially specified these tactics using methods, and built a series of planners to construct proof plans from these methods.
Reference: [Bundy et al 88] <author> A. Bundy, F. van Harmelen, J. Hesketh, A. Smaill, and A. Stevens. </author> <title> A rational reconstruction and extension of recursion analysis. </title> <type> Research Paper 419, </type> <institution> Dept. of Artificial Intelligence, Edinburgh, </institution> <year> 1988. </year> <note> Also in the proceedings of IJCAI-89. </note>
Reference-contexts: Our current version is a generalization of unfold which can use previously proved lemmas with a similar structure to unfold rules. See <ref> [Bundy et al 88] </ref> for details. The general form of a wave rule is: F (S (U ) ) ) T ( F (U )) where the wave term is indicated by the underbrace, the wave function is indicated by the overbrace and U is the wave argument. <p> This has the unfortunate side effects of making them hard to read and more brittle than desirable. For an extended discussion of the preconditions of the ind strat method, see <ref> [Bundy et al 88] </ref>. The output of the tactic will be a list of sequents corresponding to the remains of the base and step cases, (4). The effects of the tactic are calculated by considering the manipulations of the various subtactics, (5). <p> We call this process recursion analysis. We have yet to incorporate the full sophistication of this process into our proof plans, but a simple form of recursion analysis occurs as a side effect of fitting the ind strat to the theorem during plan formation. For more details see <ref> [Bundy et al 88] </ref>. This is sufficient, for example, to deal with the various induction possibilities in the even+ example above. Our version of recursion analysis improves on the bmtp version in various ways. <p> This is beyond the bmtp in its current form. For more details see <ref> [Bundy et al 88] </ref>. This theorem involves existential quantification, which again represents an extension to the bmtp. We deal with this by substituting a meta-variable for the existential variable when eliminating the existential quantifier during the planning process.
Reference: [Burstall & Darlington 77] <author> R.M. Burstall and J. Darlington. </author> <title> A transformation system for developing recursive programs. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 24(1) </volume> <pages> 44-67, </pages> <year> 1977. </year>
Reference-contexts: Rippling-out is implemented as repeated applications of the wave tactic. Each application of wave applies a wave rule to rewrite the current goal into a new one. Our first version of wave was called unfold. It was based on earlier work by [Boyer & Moore 79], [Aubin 75] and <ref> [Burstall & Darlington 77] </ref> and was restricted to the application of rewrite rules based on the step cases of recursive definitions. Our current version is a generalization of unfold which can use previously proved lemmas with a similar structure to unfold rules. See [Bundy et al 88] for details.
Reference: [Constable et al 86] <editor> R.L. Constable, S.F. Allen, H.M. Bromley, et al. </editor> <title> Implementing Mathematics with the Nuprl Proof Development System. </title> <publisher> Prentice Hall, </publisher> <year> 1986. </year>
Reference-contexts: Such inductive proofs are required in the domain of verification, transformation and synthesis of recursive computer programs. We have adopted this domain as a vehicle for the exploration of our ideas on automatic guidance. To enable us to do this the Nuprl program development system, <ref> [Constable et al 86] </ref>, has been reimplemented in Prolog by Christian Horn, a visitor to our group, [Horn 88]. This system, which we have christened Oyster, is a proof checker for a version of Intuitionistic Type Theory which is based on a system of Martin-Lof, [Martin-Lof 79].
Reference: [Desimone 86] <author> R.V. Desimone. </author> <title> Explanation-based learning of proof plans. </title> <editor> In Y. Kodratoff, editor, </editor> <booktitle> Proceedings of European Working Session on Learning, </booktitle> <address> EWSL-86, Orsay, France, </address> <month> February </month> <year> 1986. </year> <note> Longer version available from Edinburgh asDiscussion Paper 6. </note>
Reference-contexts: It would be nice to build a learning system that could remember such plans for future use. However, it would be necessary to weed out ad hoc plans that are not of general utility. Related work on learning plans from example proofs is being conducted within our group, <ref> [Desimone 86] </ref>. Our ideas on proof plans have been tested in the domain of inductive theorem proving because it is a challenging one in which there is a rich provision of heuristics. We have also done some earlier work in the domain of algebraic equation solving, [Silver 85].
Reference: [Gallaire & Lasserre 82] <author> H. Gallaire and C. Lasserre. </author> <title> Metalevel control for logic programs. In K.L. </title> <editor> Clark and S.-A. Tarnlund, editors, </editor> <booktitle> Logic Programming, </booktitle> <pages> pages 173-185. </pages> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference-contexts: Unlike Isabelle's tactics, proof plans are not limited to derived inference rules. The meta-language can describe classes of rules and lemmas and form tactics from arbitrary long sequences of these. Meta-level inference has been widely used in AI and logic programming to guide inference (see, for instance, <ref> [Gallaire & Lasserre 82] </ref>). However, most uses of meta-level inference have been to provide local control, e.g. to choose which subgoal to try to solve next or to choose which rule to solve it with.
Reference: [Gordon et al 79] <author> M.J. Gordon, A.J. Milner, </author> <title> and C.P. Wadsworth. Edinburgh LCF - A mechanised logic of computation, </title> <booktitle> volume 78 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1979. </year>
Reference-contexts: When the ind strat tactic is applied this object-level term is substituted for the existential variable at the time of existential quantifier elimination. Tactics were first introduced to theorem proving in the LCF program verification system, <ref> [Gordon et al 79] </ref>.
Reference: [Horn 88] <author> C. Horn. </author> <title> The Nurprl proof development system. </title> <type> Working paper 214, </type> <institution> Dept. of Artificial Intelligence, Edinburgh, </institution> <year> 1988. </year> <note> The Edinburgh version of Nurprl has been renamed Oyster. </note>
Reference-contexts: We have adopted this domain as a vehicle for the exploration of our ideas on automatic guidance. To enable us to do this the Nuprl program development system, [Constable et al 86], has been reimplemented in Prolog by Christian Horn, a visitor to our group, <ref> [Horn 88] </ref>. This system, which we have christened Oyster, is a proof checker for a version of Intuitionistic Type Theory which is based on a system of Martin-Lof, [Martin-Lof 79]. This logic is constructive, higher order and typed, and is especially suitable for the task of program synthesis.
Reference: [Kanamori & Fujita 86] <author> T. Kanamori and H. Fujita. </author> <title> Formulation of induction formulas in verification of Prolog programs. </title> <editor> In Joerg Siekmann, editor, </editor> <booktitle> 8th Conference on Automated Deduction, </booktitle> <pages> pages 281-299. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year> <note> Springer Lecture Notes in Computer Science No. 230. </note>
Reference-contexts: We have used this analysis to implement a number of Oyster tactics for inductive proof and have tested them on some simple theorems, in the theories of natural numbers and lists, drawn from [Boyer & Moore 79] and <ref> [Kanamori & Fujita 86] </ref>. These tactics are outlined in x2. A theorem prover faithful to the spirit of the bmtp would apply these tactics, successively, to a series of sequents. <p> KBnnn is example n.n.n from <ref> [Kanamori & Fujita 86] </ref>.
Reference: [Knoblock & Constable 86] <author> T. B. Knoblock and R.L. Constable. </author> <title> Formalized metareasoning in type theory. </title> <booktitle> In Proceedings of LICS, </booktitle> <pages> pages 237-248. </pages> <publisher> IEEE, </publisher> <year> 1986. </year> <month> 21 </month>
Reference-contexts: We are unique in using plan formation to construct a purpose-built tactic for a theorem, although <ref> [Knoblock & Constable 86] </ref> discusses the (meta-)use of Nuprl to construct a tautology checking tactic from its specification. The Isabelle theorem prover due to Paulson ([Paulson 88]) represents one extension of the LCF approach. It is a generic theorem prover incorporating unification (in this case higher-order) and supporting schematic assertion.
Reference: [Martin-Lof 79] <author> Per Martin-Lof. </author> <title> Constructive mathematics and computer program-ming. </title> <booktitle> In 6th International Congress for Logic, Methodology and Philosophy of Science, </booktitle> <pages> pages 153-175, </pages> <address> Hanover, </address> <month> August </month> <year> 1979. </year> <title> Published by North Holland, </title> <address> Amsterdam. </address> <year> 1982. </year>
Reference-contexts: This system, which we have christened Oyster, is a proof checker for a version of Intuitionistic Type Theory which is based on a system of Martin-Lof, <ref> [Martin-Lof 79] </ref>. This logic is constructive, higher order and typed, and is especially suitable for the task of program synthesis. Oyster reasons backwards from the theorem to be proved using a sequent calculus notation, which includes rules of inference for mathematical induction.
Reference: [Paulson 88] <author> L. Paulson. </author> <title> Experience with Isabelle: A generic theorem prover. </title> <booktitle> In COLOG 88. Institute of Cybernetics of the Estonian SSR, </booktitle> <year> 1988. </year>
Reference: [Sacerdoti 74] <author> E.D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: The only other use of proof plans we are aware of is earlier work in our own group, e.g. [Silver 85] and [Bundy & Sterling 88], on which this work builds, and the use of abstraction to build proof plans, e.g. <ref> [Sacerdoti 74, ?] </ref>. Abstraction, in contrast to meta-level inference, works with a degenerate version of the object-level space in which some essential detail is thrown away.
Reference: [Silver 85] <author> B. Silver. </author> <title> Meta-level inference: </title> <booktitle> Representing and Learning Control Information in Artificial Intelligence. </booktitle> <publisher> North Holland, </publisher> <year> 1985. </year> <note> Revised version of the author's PhD thesis, DAI 1984. 22 </note>
Reference-contexts: We are unusual in using it to construct proof plans, i.e. outlines of the whole inference process. The only other use of proof plans we are aware of is earlier work in our own group, e.g. <ref> [Silver 85] </ref> and [Bundy & Sterling 88], on which this work builds, and the use of abstraction to build proof plans, e.g. [Sacerdoti 74, ?]. Abstraction, in contrast to meta-level inference, works with a degenerate version of the object-level space in which some essential detail is thrown away. <p> Our ideas on proof plans have been tested in the domain of inductive theorem proving because it is a challenging one in which there is a rich provision of heuristics. We have also done some earlier work in the domain of algebraic equation solving, <ref> [Silver 85] </ref>. We hope that proof plans will also be applicable in other domains.
References-found: 17

