URL: http://www.cs.nyu.edu/vijayk/papers/iscope.ps
Refering-URL: http://www.cs.nyu.edu/vijayk/papers.html
Root-URL: http://www.cs.nyu.edu
Title: Evaluating High Level Parallel Programming Support for Irregular Applications in ICC++  
Author: Andrew A. Chien, Julian Dolby, Bishwaroop Ganguly, Vijay Karamcheti, and Xingbin Zhang 
Web: concert@red-herring.cs.uiuc.edu  
Affiliation: Department of Computer Science, University of Illinois at Urbana-Champaign  
Abstract: Object-oriented techniques have been proffered as aids for managing complexity, enhancing reuse, and improving readability of irregular parallel applications. Using a suite of seven challenging irregular applications and the mature Illinois Concert system (a high-level concurrent object-oriented programming model backed by an aggressive implementation), we evaluate what programming efforts are required to achieve high performance that is comparable to the best reported for low-level programming means on large-scale parallel systems. Our study indicates that procedure and computation granularity, names-pace management, and low-level concurrency management can be fully automated for these applications. Decoupling these concerns makes managing the remaining fundamental concerns data locality and load balance much easier. These two require programmer input, which our system integrates cleanly into the programming interface. Overall, only small changes to the sequential code (fewer than 5% of the source lines) were required to express concurrency and performance optimizations.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Chakrabarti and K. Yelick. </author> <title> Implementing an irregular application on a distributed memory multiprocessor. </title> <booktitle> In Proceedings of the Fourth ACM/SIGPLAN Symposium on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 169-179, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Applications Description Polyover [14] Overlay of two polygon maps (computer graphics) Barnes-hut [15] Barnes-Hut hierarchical N-body method (computational cosmology) FMM [15] Fast multipole method (computational cosmology) SAMR Structured adaptive mesh refinement (computational fluid dynamics) Grobner <ref> [1] </ref> Grobner basis (symbolic algebra) Phylogeny [7] Evolutionary history of species (molecular biology) Radiosity [15] Hierarchical radiosity method (computer graphics) Table 1. <p> The data placement and load balancing code consists of 37 line changes (out of 3951 lines). 3.2 Grobner The Grobner application computes the Grobner basis of a set of polynomials. Our algorithm is derived from a parallel implementation by Chakrabarti <ref> [1] </ref>. Concurrency and Synchronization Specification Parallelism in the application arises from parallel evaluation of polynomial pairs, and is naturally specified using a conc loop around the pair generation code in the sequential program. Pair evaluation tasks that produce irreducible terms invoke a method on the basis object to augment it. <p> The Radiosity speedup of 23 on 32 T3D processors compares well with a reported speedup of 26 on 32 processors of the DASH machine [10]. Speedups for both Grobner and Phylogeny compare favorably with implementations that explicitly manage data locality <ref> [7, 1] </ref>. The above competitive speedups were made possible by transformations that enhance data locality and load balance. To illustrate their performance advantages, Figure 1 (right) shows the speedup for three Radiosity versions: base, locality, and load-balance.
Reference: 2. <author> K. Mani Chandy and Carl Kesselman. </author> <title> Compositional C++: Compositional parallel programming. </title> <booktitle> In Proceedings of the Fifth Workshop on Compilers and Languages for Parallel Computing, </booktitle> <address> New Haven, Connecticut, </address> <year> 1992. </year> <note> YALEU/DCS/RR-915, Springer-Verlag Lecture Notes in Computer Science, </note> <year> 1993. </year>
Reference-contexts: Research efforts have largely focused on building libraries which provide runtime support for some dimensions of irregularity [6, 13, 9]. Most concurrent object-oriented programming systems have ignored support for fine-grained parallelism <ref> [8, 2, 5] </ref>, which forces programmers to map irregular concurrency into grains large enough to achieve efficiency. This study is the first systematic evaluation of programming effort for a significant range of irregular applications.
Reference: 3. <author> Andrew Chien, Julian Dolby, Bishwaroop Ganguly, Vijay Karamcheti, and Xingbin Zhang. </author> <title> Supporting high level programming with high performance: The Illinois Concert system. </title> <booktitle> In Proceedings of the Second International Workshop on High-level Parallel Programming Models and Supportive Environments, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Our application study is done in the context of the Illinois Concert system, a high performance compiler and run-time for parallel computers which has been the vehicle for extensive research on compiler optimization and runtime techniques over the past five years <ref> [3] </ref>. Using the mature Concert system, we evaluate programming effort for a rich suite of irregular parallel applications. Our results indicate that a high-level concurrent object-oriented programming model and a sophisticated implementation can eliminate many concerns, easing the programming of irregular parallel applications. <p> arg1 and is managed by a global priority scheduler: ( thread function ( arg1, ... ) !priority arg1 !scheduler PRIORITY ); Implementation Technology The Concert system contains a wide range of aggressive optimizations and has been used to demonstrate high performance in absolute terms on a wide range of applications <ref> [3] </ref>.
Reference: 4. <author> High Performance Fortran Forum. </author> <title> High performance Fortran language specification version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: All of these techniques pursue a library-based approach that considers irregularity in a single dimension and typically only support particular classes of algorithms (e.g., on sparse matrices or adaptive meshes [9]). While the best known parallel programming approaches | message passing [11] and data parallel <ref> [4] </ref> | can be used for programming irregular applications, neither provides adequate tools to manage the inherent complexity. 6 Summary Based on our application studies, we must conclude that while the development of irregular parallel applications remains challenging, the Concert System enables such programs to be written with a high level
Reference: 5. <author> A. Grimshaw. </author> <title> Easy-to-use object-oriented parallel processing with Mentat. </title> <journal> IEEE Computer, </journal> <volume> 5(26) </volume> <pages> 39-51, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Research efforts have largely focused on building libraries which provide runtime support for some dimensions of irregularity [6, 13, 9]. Most concurrent object-oriented programming systems have ignored support for fine-grained parallelism <ref> [8, 2, 5] </ref>, which forces programmers to map irregular concurrency into grains large enough to achieve efficiency. This study is the first systematic evaluation of programming effort for a significant range of irregular applications.
Reference: 6. <editor> J.H. Saltz, et al. </editor> <title> A manual for the CHAOS runtime library. </title> <type> Technical Report CS-TK-3437, </type> <institution> Department of Computer Science, University of Maryland, </institution> <year> 1995. </year>
Reference-contexts: Of the research on programming irregular parallel applications, none provides a single programming interface while supporting all three dimensions of irregularity data, control, and concurrency. Research efforts have largely focused on building libraries which provide runtime support for some dimensions of irregularity <ref> [6, 13, 9] </ref>. Most concurrent object-oriented programming systems have ignored support for fine-grained parallelism [8, 2, 5], which forces programmers to map irregular concurrency into grains large enough to achieve efficiency. This study is the first systematic evaluation of programming effort for a significant range of irregular applications.
Reference: 7. <author> Jeff A. Jones. </author> <title> Parallelizing the phylogeny problem. </title> <type> Master's thesis, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Applications Description Polyover [14] Overlay of two polygon maps (computer graphics) Barnes-hut [15] Barnes-Hut hierarchical N-body method (computational cosmology) FMM [15] Fast multipole method (computational cosmology) SAMR Structured adaptive mesh refinement (computational fluid dynamics) Grobner [1] Grobner basis (symbolic algebra) Phylogeny <ref> [7] </ref> Evolutionary history of species (molecular biology) Radiosity [15] Hierarchical radiosity method (computer graphics) Table 1. <p> The Radiosity speedup of 23 on 32 T3D processors compares well with a reported speedup of 26 on 32 processors of the DASH machine [10]. Speedups for both Grobner and Phylogeny compare favorably with implementations that explicitly manage data locality <ref> [7, 1] </ref>. The above competitive speedups were made possible by transformations that enhance data locality and load balance. To illustrate their performance advantages, Figure 1 (right) shows the speedup for three Radiosity versions: base, locality, and load-balance.
Reference: 8. <author> J. Lee and D. Gannon. </author> <title> Object oriented parallel programming. </title> <booktitle> In Proceedings of the ACM/IEEE Conference on Supercomputing. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: Research efforts have largely focused on building libraries which provide runtime support for some dimensions of irregularity [6, 13, 9]. Most concurrent object-oriented programming systems have ignored support for fine-grained parallelism <ref> [8, 2, 5] </ref>, which forces programmers to map irregular concurrency into grains large enough to achieve efficiency. This study is the first systematic evaluation of programming effort for a significant range of irregular applications.
Reference: 9. <author> R. Parsons and D. Quinlan. </author> <title> A++/P++ array classes for architecture independent finite difference computations. </title> <booktitle> In Proceedings of the Second Annual Object-Oriented Numerics Conference, </booktitle> <address> Sunriver, Oregon, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Of the research on programming irregular parallel applications, none provides a single programming interface while supporting all three dimensions of irregularity data, control, and concurrency. Research efforts have largely focused on building libraries which provide runtime support for some dimensions of irregularity <ref> [6, 13, 9] </ref>. Most concurrent object-oriented programming systems have ignored support for fine-grained parallelism [8, 2, 5], which forces programmers to map irregular concurrency into grains large enough to achieve efficiency. This study is the first systematic evaluation of programming effort for a significant range of irregular applications. <p> Programming techniques for irregular applications is an important body of related work. All of these techniques pursue a library-based approach that considers irregularity in a single dimension and typically only support particular classes of algorithms (e.g., on sparse matrices or adaptive meshes <ref> [9] </ref>).
Reference: 10. <author> Jaswinder Pal Singh. </author> <title> Parallel Hierarchical N-Body Methods and Their Implications For Multiprocessors. </title> <type> PhD thesis, </type> <institution> Stanford University Department of Computer Science, Stanford, </institution> <address> CA, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: In addition, the lengths of interaction lists are highly irregular across boxes, making both data locality and load balancing essential for good performance. We ensure data locality and load balance using a spatial partitioning of particles and boxes and a history-based load balancing algorithm, adopted from <ref> [10] </ref>. The spatial partitioning orders the particles by their position, and this ordering is blocked across the processors. <p> Both the Barnes speedup of 42 and FMM speedup of 54 on 64 nodes are competitive with shared-memory versions [15] and hand-optimized versions [12]. The Radiosity speedup of 23 on 32 T3D processors compares well with a reported speedup of 26 on 32 processors of the DASH machine <ref> [10] </ref>. Speedups for both Grobner and Phylogeny compare favorably with implementations that explicitly manage data locality [7, 1]. The above competitive speedups were made possible by transformations that enhance data locality and load balance.
Reference: 11. <author> Snir, et. al. </author> <title> MPI: The Complete Reference. </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: All of these techniques pursue a library-based approach that considers irregularity in a single dimension and typically only support particular classes of algorithms (e.g., on sparse matrices or adaptive meshes [9]). While the best known parallel programming approaches | message passing <ref> [11] </ref> and data parallel [4] | can be used for programming irregular applications, neither provides adequate tools to manage the inherent complexity. 6 Summary Based on our application studies, we must conclude that while the development of irregular parallel applications remains challenging, the Concert System enables such programs to be written
Reference: 12. <author> M. Warren and J. Salmon. </author> <title> A parallel hashed oct-tree N-body algorithm. </title> <booktitle> In Proceedings of Supercomputing Conference, </booktitle> <pages> pages 12-21, </pages> <year> 1993. </year>
Reference-contexts: Both the Barnes speedup of 42 and FMM speedup of 54 on 64 nodes are competitive with shared-memory versions [15] and hand-optimized versions <ref> [12] </ref>. The Radiosity speedup of 23 on 32 T3D processors compares well with a reported speedup of 26 on 32 processors of the DASH machine [10]. Speedups for both Grobner and Phylogeny compare favorably with implementations that explicitly manage data locality [7, 1].
Reference: 13. <author> Chih-Po Wen, Soumen Chakrabarti, Etienne Deprit, Arvind Krishnamurthy, and Katherine Yelick. </author> <title> Run-time support for portable distributed data structures. </title> <booktitle> In Third Workshop on Languages, Compilers, and Run-Time Systems for Scalable Computers, </booktitle> <pages> pages 111-120, </pages> <address> Boston, May 1995. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: Of the research on programming irregular parallel applications, none provides a single programming interface while supporting all three dimensions of irregularity data, control, and concurrency. Research efforts have largely focused on building libraries which provide runtime support for some dimensions of irregularity <ref> [6, 13, 9] </ref>. Most concurrent object-oriented programming systems have ignored support for fine-grained parallelism [8, 2, 5], which forces programmers to map irregular concurrency into grains large enough to achieve efficiency. This study is the first systematic evaluation of programming effort for a significant range of irregular applications.
Reference: 14. <author> Gregory V. Wilson and Paul Lu, </author> <title> editors. Parallel Programming Using C++. </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: 1 Overview Object-oriented techniques have been proffered as aids for managing complexity, enhancing reuse, and improving readability of parallel applications, and numerous variants have been explored (e.g. <ref> [14] </ref>). Such techniques appear most promising for irregular applications where modularity and encapsulation help manage complex data and parallelism structures. In this paper, we systematically evaluate a high level concurrent object system's programmability for achieving high performance on irregular applications. <p> We describe interfaces in the Concert system which aid in the management of these two concerns. 1 Basic Programming Interface Our programming interface is a basic object-oriented programming model augmented with simple extensions for concurrency. The basic model is based on C++ (ICC++ <ref> [14] </ref>), providing a single namespace, scalars and objects, and single inheritance. Simple extensions for concurrency include annotating standard blocks (i.e. compound statements) and loops with the conc keyword. A conc block defines a partial order amongst its statements, allowing non-binding concurrency while preserving local data dependences. <p> Each problem is challenging to express in parallel, exhibiting irregularity in one or more of data structure, parallel control structure, and concurrency. Applications Description Polyover <ref> [14] </ref> Overlay of two polygon maps (computer graphics) Barnes-hut [15] Barnes-Hut hierarchical N-body method (computational cosmology) FMM [15] Fast multipole method (computational cosmology) SAMR Structured adaptive mesh refinement (computational fluid dynamics) Grobner [1] Grobner basis (symbolic algebra) Phylogeny [7] Evolutionary history of species (molecular biology) Radiosity [15] Hierarchical radiosity method (computer <p> These speedups compare favorably with the best reported elsewhere for hand-optimized codes. Polyover's speedup 3 Except for the SAMR code, whose performance results are on the SGI Origin 2000. levels off because of insufficient work in the parallel algorithm but is compara-ble to other reported numbers <ref> [14] </ref>. Both the Barnes speedup of 42 and FMM speedup of 54 on 64 nodes are competitive with shared-memory versions [15] and hand-optimized versions [12]. The Radiosity speedup of 23 on 32 T3D processors compares well with a reported speedup of 26 on 32 processors of the DASH machine [10].
Reference: 15. <author> Steven Cameron Woo, Moriyoshi Ohara, Evan Torrie, Jaswinder Pal Singh, and Anoop Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <year> 1995. </year>
Reference-contexts: Each problem is challenging to express in parallel, exhibiting irregularity in one or more of data structure, parallel control structure, and concurrency. Applications Description Polyover [14] Overlay of two polygon maps (computer graphics) Barnes-hut <ref> [15] </ref> Barnes-Hut hierarchical N-body method (computational cosmology) FMM [15] Fast multipole method (computational cosmology) SAMR Structured adaptive mesh refinement (computational fluid dynamics) Grobner [1] Grobner basis (symbolic algebra) Phylogeny [7] Evolutionary history of species (molecular biology) Radiosity [15] Hierarchical radiosity method (computer graphics) Table 1. <p> Each problem is challenging to express in parallel, exhibiting irregularity in one or more of data structure, parallel control structure, and concurrency. Applications Description Polyover [14] Overlay of two polygon maps (computer graphics) Barnes-hut <ref> [15] </ref> Barnes-Hut hierarchical N-body method (computational cosmology) FMM [15] Fast multipole method (computational cosmology) SAMR Structured adaptive mesh refinement (computational fluid dynamics) Grobner [1] Grobner basis (symbolic algebra) Phylogeny [7] Evolutionary history of species (molecular biology) Radiosity [15] Hierarchical radiosity method (computer graphics) Table 1. <p> Applications Description Polyover [14] Overlay of two polygon maps (computer graphics) Barnes-hut <ref> [15] </ref> Barnes-Hut hierarchical N-body method (computational cosmology) FMM [15] Fast multipole method (computational cosmology) SAMR Structured adaptive mesh refinement (computational fluid dynamics) Grobner [1] Grobner basis (symbolic algebra) Phylogeny [7] Evolutionary history of species (molecular biology) Radiosity [15] Hierarchical radiosity method (computer graphics) Table 1. <p> Our parallel algorithm is derived from the FMM application in the SPLASH-2 suite <ref> [15] </ref>. Concurrency and Synchronization Specification There are three levels of parallelism in the dominant force computation phase: across interactions corresponding to separate boxes, across computations with different interaction lists for a single box (each box has four lists), and across interactions with boxes within the same interaction list. <p> Our parallel algorithm is derived from the radiosity application in the SPLASH-2 suite <ref> [15] </ref>. Concurrency and Synchronization Specification There are three levels of parallelism in each iteration | across all input patches, across children of a subdivided patch, and across neighbor patches in the interaction list | which are all naturally expressed using conc annotations. <p> Both the Barnes speedup of 42 and FMM speedup of 54 on 64 nodes are competitive with shared-memory versions <ref> [15] </ref> and hand-optimized versions [12]. The Radiosity speedup of 23 on 32 T3D processors compares well with a reported speedup of 26 on 32 processors of the DASH machine [10]. Speedups for both Grobner and Phylogeny compare favorably with implementations that explicitly manage data locality [7, 1].
References-found: 15

