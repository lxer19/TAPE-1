URL: http://www.cs.ucsb.edu/~neary/WORK/ijodl.ps
Refering-URL: http://www.cs.ucsb.edu/~neary/WORK/dir.html
Root-URL: http://www.cs.ucsb.edu
Email: amr@cs.ucsb.edu  
Title: Scalable Access within the Context of Digital Libraries  
Author: X. Cheng R. Dolin M. Neary S. Prabhakar K. V. Ravi Kanth D. Wu D. Agrawal A. El Abbadi M. Freeston A. Singh T. Smith J. Su 
Date: December 17, 1997  
Address: Library Project  Santa Barbara, CA 93106  
Affiliation: Alexandria Digital  Department of Computer Science University of California  
Abstract: This paper presents a summary of some of the work-in-progress within the Alexandria Digital Library Project. In particular, we present scalable methods for locating information at different levels within a distributed digital library environment. Starting at the high level, we show how queries can be routed to appropriate information sources. At a given source, efficient query processing is supported by using materialized views and multidimensional index structures. Finally, we propose solutions to the problem of storage and retrieval of large objects on both secondary and tertiary storage devices.
Abstract-found: 1
Intro-found: 1
Reference: [ABZ96] <author> M. Andrews, M. A. Bender, and L. Zhang. </author> <title> New algorithms for the disk scheduling problem. </title> <booktitle> In Foundations of Computer Science, </booktitle> <year> 1996. </year>
Reference-contexts: For disk scheduling, a number of requests need to be serviced on different locations. The drive has to seek between requests that are not contiguously located. Numerous algorithms have been proposed for efficiently servicing disk requests, such as C-SCAN [Teo72] and HEADSCHEDULE <ref> [ABZ96] </ref>. The major difference between disk scheduling and robotic library scheduling is that tertiary storage media such as tapes or optical disks are removable as opposed to fixed magnetic disks.
Reference: [ACD + 95] <author> D. Andresen, L. Carver, R. Dolin, C. Fischer, J. Frew, M. Goodchild, O. Ibarra, R. B. Kemp, R. Kothuri, M. Larsgaard, B. S. Manjunath, D. Nebert, J. Simpson, T. R. Smith, A. Wells, T. Yang, and Q. Zheng. </author> <title> The WWW Prototype of the Alexandria Digital Library. </title> <booktitle> In Proceedings of the International Symposium on Digital Libraries, </booktitle> <address> Tsukuba, Japan, </address> <year> 1995. </year> <note> Also appeared in IEEE Computer, </note> <month> 29(5): </month> <pages> 54-60, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: In this paper, we identify four primary scalability issues related to providing information access within the context of a digital library, and show how the Alexandria Digital Library (ADL) Project <ref> [ACD + 95] </ref> addresses them. First, the data itself is distributed on a scale that was not possible earlier. Instead of a single database or a handful of information sources, we now have information sources that are scattered throughout the Internet.
Reference: [BDH + 94] <author> C.M. Bowman, P.B. Danzig, D.R. Hardy, U. Manber, and M.F. Schwartz. </author> <title> The harvest information discovery and access system. </title> <booktitle> In Proceedings of the Second International World-Wide Web Conference, </booktitle> <pages> pages 763-771, </pages> <address> Chicago, Illinois, </address> <month> October </month> <year> 1994. </year> <note> http://harvest.cs.colorado.edu/. </note>
Reference-contexts: The gGlOSS text database discovery system [GGM95] represents sources by vectors of term frequencies. It is similar, in this regard, to the SMART automated text retrieval system [Sal89], replacing the two-dimensional term/document matrix by a term/collection matrix. Harvest <ref> [BDH + 94] </ref> automatically indexes documents within a source and distributes these indexes. Another system, STARTS [GCGMP96], is described in more detail below. 2.1 Network Models In [DAE97], we consider three general classes of network models that encompass the discovery and querying of information sources. <p> Each source registers with each mid-level server for which the source has relevant metadata, telling the server how often to update the source's 5 metadata. Harvest <ref> [BDH + 94] </ref> provides a suitable transport mechanism for distributing and storing mid-level metadata in Pharos [DAED97]. 2.3 Simulation Results In order to evaluate the expected performance of Pharos, we have tested it by generating simulated sources and queries and estimating the degree of success of finding the best sources.
Reference: [BKSS90] <author> N. Beckmann, H. Kriegel, R. Schneider, and B. Seeger. </author> <title> The R* tree: An efficient and robust access method for points and rectangles. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 322-331, </pages> <month> May 23-25 </month> <year> 1990. </year>
Reference-contexts: In [RS97], we show that the lower bound on time complexity of range queries on n d-dimensional objects (d &gt; 1) using conventional tree structures such as the R fl -trees <ref> [BKSS90] </ref> is (n 11=d ). In contrast, for 1-dimensional data, range queries can be answered in logarithmic time. Given this inherent complexity of multi-dimensional queries, we adopt the following three approaches to efficiently support arbitrary queries on multi-dimensional data. <p> To illustrate this situation, consider the following example. Figure 6 shows a set of 2-dimensional data objects and an R fl tree <ref> [BKSS90] </ref> indexing these data objects. Each index entry in the R fl tree represents a region multi-dimensional space. At the leaves, these entries correspond to the data rectangles. At higher levels, these entries are rectangles formed using the data in the corresponding subtrees. <p> This ensures that most queries can be processed in parallel. are evenly distributed among both the processors. Consequently, the query processing time is nearly halved. Using these ideas, we parallelized two index structures the R fl -tree <ref> [BKSS90] </ref> and the LIB structure [RAE + 95]. The R fl -tree is chosen because it is a versatile multi-dimensional index that caters to arbitrary 11 12 data. The LIB structure is chosen because it maintains separate index components that can be searched in parallel. <p> With this development, we are carrying out a new comparative performance study, specifically against R fl -trees <ref> [BKSS90] </ref> and Oracle's SDO. In addition, we are incorporating a new technique to improve the performance of conventional index structures for different types of queries on spatial data. <p> For a small number of images, a sequential browsing of images using their feature vectors may suffice. However, for large image databases such as in ADL, the problem of efficient browsing and retrieval of images has to be addressed. Multi-dimensional search structures like the R fl -tree <ref> [BKSS90] </ref> do not scale with the dimensionality of data [FRM94] and hence are not directly helpful. Our approach to solving this problem [WA + 96] is to first reduce the dimensionality of the image data and then use multi-dimensional index structures to support efficient retrieval.
Reference: [Bro66] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists & Designers. </title> <publisher> Dover, </publisher> <address> New York, New York, </address> <year> 1966. </year>
Reference-contexts: To compare whether truncated SVD components or DFT coefficients provide better retrieval performance, we simulate a series of queries on a collection of textures from the Brodatz album <ref> [Bro66] </ref>. The album consists of many different texture patterns. By applying an image processing technique known as the Gabor transform [MM96], 1856 48-dimnesional feature vectors are extracted from the album images. Every vector is processed at the time of insertion into the database with SVD or DFT.
Reference: [Cas96] <author> K. R. Castleman. </author> <title> Digital Image Processing. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1996. </year>
Reference-contexts: It is therefore important to provide the ability to browse items and view them at multiple levels of detail or resolution. For the purposes of ADL, which is designed to handle mostly image data, the technique of wavelet decomposition <ref> [Cas96] </ref> has been proposed for generating multi-resolution images. Using this technique, an image is decomposed into a low resolution copy or icon and several coefficients. The icon is the lowest resolution copy available. Higher resolution copies can be progressively reconstructed from the icon and other coefficients.
Reference: [CDK + 95] <author> L. T. Chen, R. Drach, M. Keating, S. Louise, D. Rotem, and A. Shoshani. </author> <title> Efficient organization and access of multi-dimensional datasets on tertiary storage systems. </title> <booktitle> In Information Systems, </booktitle> <pages> pages 155-83. </pages> <publisher> Elsevier Science, </publisher> <year> 1995. </year>
Reference-contexts: The feasibility of striping in tape based systems has been studied by Drapeau and Katz [DK93] and also by Golubchik and Muntz [GM95]. Other studies have looked at the problem of reorganization of data that is stored on tertiary media in order to improve retrieval performance <ref> [CDK + 95, SS94] </ref>. In contrast to other studies, we have explored the problem of scheduling requests for more than one medium [PAES97b]. Due to the great difference in speeds between the processors and tertiary storage, we expect that request traffic will be bursty.
Reference: [CF88] <author> S. Christodoulakis and D. A. Ford. </author> <title> Performance analysis and fundamental performance trade offs for clv optical disks. </title> <booktitle> In sigmod, </booktitle> <pages> pages 286-94, </pages> <address> Chicago, Illinois, U.S.A., </address> <month> June </month> <year> 1988. </year> <note> ACM. </note>
Reference-contexts: The algorithms developed for disks assume that all requests are located on the currently loaded medium which is not true for robotic libraries. Several other studies have investigated the performance of optical disks. In <ref> [CF88] </ref>, a model for retrieval from optical disks with constant linear velocity (CLV) is developed. Based upon the analysis, it is shown that data items that are accessed sequentially should be placed on the inside tracks of such disks and randomly accessed data on the outside tracks.
Reference: [CF89] <author> S. Christodoulakis and D. A. Ford. </author> <title> Retrieval performance versus disc space utilization on worm optical discs. </title> <booktitle> In sigmod, </booktitle> <pages> pages 306-14, </pages> <address> Protland, Oregon, U.S.A., </address> <month> June </month> <year> 1989. </year> <note> ACM. </note>
Reference-contexts: In [CF88], a model for retrieval from optical disks with constant linear velocity (CLV) is developed. Based upon the analysis, it is shown that data items that are accessed sequentially should be placed on the inside tracks of such disks and randomly accessed data on the outside tracks. In <ref> [CF89] </ref> the tradeoff between retrieval performance and disk space utilization for Write-Once-Read-Many (WORM) optical disks is investigated. The placement of data on CLV optical disks in order to improve random I/O based upon a hot-cold distribution of accesses is studied in [FC91].
Reference: [Che76] <author> P.P.-S. Chen. </author> <title> The entity-relationship model | toward a unified view of data. </title> <journal> Proc. ACM Symp. on Transactions of Database Systems, </journal> <volume> 1(1) </volume> <pages> 9-36, </pages> <year> 1976. </year> <month> 23 </month>
Reference-contexts: We have developed a general approach that addresses these issues in relational databases [Cod70] which are designed using entity-relationship models <ref> [Che76] </ref>. There had been some other work done on these two issues [Gup97, VH96, LMSS95]. Our approach is novel because we introduce query pattern into materialized view selection and translation which makes the solution more effective and efficient. The main idea is as follows. <p> In our approach, we assume that the original relational database schema is obtained from a schema in the Entity-Relationship (ER) model <ref> [Che76] </ref> which is a popular relational database design tool. The primary advantage of using the ER model is that we can easily separate the information concerning entities from that concerning relationships. Such a separation is natural in modeling the real world and useful in expressing the semantics of user queries.
Reference: [Cod70] <author> E. F. Codd. </author> <title> A relational model of data for large shared data banks. </title> <journal> Communications of the ACM, </journal> <volume> 13(6) </volume> <pages> 377-387, </pages> <year> 1970. </year>
Reference-contexts: We have developed a general approach that addresses these issues in relational databases <ref> [Cod70] </ref> which are designed using entity-relationship models [Che76]. There had been some other work done on these two issues [Gup97, VH96, LMSS95]. Our approach is novel because we introduce query pattern into materialized view selection and translation which makes the solution more effective and efficient.
Reference: [Com79] <author> D. Comer. </author> <title> The Ubiquitous B-tree. </title> <journal> ACM Computing Surveys, </journal> <volume> 11 </volume> <pages> 121-137, </pages> <year> 1979. </year>
Reference-contexts: In the original implementation [Fre87], which was restricted to point indexing, this partitioning was represented by a balanced, multiply-branched index tree structure similar to a B-tree <ref> [Com79] </ref>. Such an index organization exhibited an important feature of multi-dimensional indexing: it is not necessary to represent the whole data space in the index, if the data is not uniformly distributed.
Reference: [DAE97] <author> R. Dolin, D. Agrawal, and A. El Abbadi. </author> <title> Classifying network architectures for locating information sources. </title> <booktitle> In Proceedings of the 5th International Conference on Database Systems for Advanced Applications (DASFAA '97), </booktitle> <pages> pages 31-40, </pages> <address> Melbourne, Australia, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: Harvest [BDH + 94] automatically indexes documents within a source and distributes these indexes. Another system, STARTS [GCGMP96], is described in more detail below. 2.1 Network Models In <ref> [DAE97] </ref>, we consider three general classes of network models that encompass the discovery and querying of information sources. The first class of models uses no intermediate servers; the only communication is directly between users and information sources. <p> These servers supply more detailed information about this filtered list of sources, thus further reducing the number of potentially relevant sources (say from ~10 3 to ~10 1 ). These sources are then queried directly. Pharos is presented in more detail below. The analysis of these models in <ref> [DAE97] </ref> indicates that Pharos scales well by comparison. The BF Model requires that all intermediate servers pull over the actual documents of all sources, causing problems as the number of sources and documents per source increase.
Reference: [DAED97] <author> R. Dolin, D. Agrawal, A. El Abbadi, and L. Dillon. Pharos: </author> <title> A scalable distributed architecture for locating heterogeneous information sources. </title> <booktitle> In Proceedings of the 6th International Conference on Information and Knowledge Management (CIKM '97), </booktitle> <address> Las Vegas, Nevada, </address> <month> November </month> <year> 1997. </year>
Reference-contexts: Each source registers with each mid-level server for which the source has relevant metadata, telling the server how often to update the source's 5 metadata. Harvest [BDH + 94] provides a suitable transport mechanism for distributing and storing mid-level metadata in Pharos <ref> [DAED97] </ref>. 2.3 Simulation Results In order to evaluate the expected performance of Pharos, we have tested it by generating simulated sources and queries and estimating the degree of success of finding the best sources. <p> The numerator becomes 1=1 + 1=3 + 1=4 + + 1=103 = 2:06. The source precision is then 2:06=2:93 = 0:70. The first definition would have yielded 0.50 instead, and the second definition would have yielded 0.27. Using the performance measures developed in <ref> [DAED97] </ref>, we ran experiments with 1000 simulated sources. The sources were generated with 3 taxonomies per source, 8 children per node, and a taxonomy depth of 4 (i.e. 4681 nodes per taxonomy). High-level (mid-level) metadata were considered to be the level-1 (level-2) nodes in the taxonomies.
Reference: [Dig96] <institution> Digital Equipment Corporation. Altavista. </institution> <note> http://www.altavista.digital.com/, 1996. </note>
Reference-contexts: The existence of thousands of newsgroups, World-Wide Web (WWW) sites, FTP archives, and digital libraries renders traditional methods of locating good information sources infeasible. Current WWW indexes such as AltaVista <ref> [Dig96] </ref>, Lycos [Lyc96], and Yahoo [Yah96], which are designed for locating information on the Internet, are limited in several ways. For example, they are limited to on-line, text documents, and they give no control to the sources of the documents to determine the frequency with which they are indexed.
Reference: [DK93] <author> A. L. Drapeau and R. H. Katz. </author> <title> Striping in large tape libraries. </title> <booktitle> In Proc. of Supercomputing, </booktitle> <pages> pages 378-387, </pages> <address> Portland, Oregon, 1993. </address> <publisher> ACM. </publisher>
Reference-contexts: Myllymaki and Livny have investigated the benefits of executing tape and disk I/O in parallel [ML96]. In [FM96], a log structured file system for tertiary media has been proposed. The feasibility of striping in tape based systems has been studied by Drapeau and Katz <ref> [DK93] </ref> and also by Golubchik and Muntz [GM95]. Other studies have looked at the problem of reorganization of data that is stored on tertiary media in order to improve retrieval performance [CDK + 95, SS94].
Reference: [Dum91] <author> S. Dumais. </author> <title> Improving the retrieval of information from external sources. Behavior Research Methods, Instruments, </title> & <journal> Computers, </journal> <volume> 23(2) </volume> <pages> 229-236, </pages> <year> 1991. </year>
Reference-contexts: Instead, we are interested in a measure that is higher for sources which contain a relatively larger number of relevant documents. For simulation simplicity, we consider measures similar to the weights associated with documents based on vector analysis <ref> [Dum91, Sal89] </ref>, which lead to a ranked list of documents. Assuming that we have a weighting system which will lead to a ranked list of sources, we have several options for defining the precision of the results.
Reference: [FC91] <author> D. A. Ford and S. Christodoulakis. </author> <title> Optimizing random reterievals from clv format optical disks. </title> <booktitle> In vldb, </booktitle> <pages> pages 413-22, </pages> <address> Barcelona, Spain, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: In [CF89] the tradeoff between retrieval performance and disk space utilization for Write-Once-Read-Many (WORM) optical disks is investigated. The placement of data on CLV optical disks in order to improve random I/O based upon a hot-cold distribution of accesses is studied in <ref> [FC91] </ref>. More recent work on tape scheduling [HS96, LO96] has studied efficient processing schedules for I/O requests for single tapes. In [HS96] Hillyer and Silberschatz have analyzed algorithms for scheduling batched requests for a single serpentine tape that is loaded on the drive.
Reference: [FM96] <author> D. A. Ford and J. Myllymaki. </author> <title> A log-structured organization for tertiary storage. </title> <booktitle> In Proceedings of the Twelfth International Conference on Data Engineering, </booktitle> <pages> pages 20-7, </pages> <address> New Orleans, Louisiana, </address> <year> 1996. </year>
Reference-contexts: Work has also been done on optimizing the performance of relational database management systems that incorporate tertiary storage [SS93, ML95, Sar95a, Sar95b]. Myllymaki and Livny have investigated the benefits of executing tape and disk I/O in parallel [ML96]. In <ref> [FM96] </ref>, a log structured file system for tertiary media has been proposed. The feasibility of striping in tape based systems has been studied by Drapeau and Katz [DK93] and also by Golubchik and Muntz [GM95].
Reference: [Fre87] <author> M. W. Freeston. </author> <title> The bang file: a new kind of grid file. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 260-269, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: We observe that both R fl -tree and LIB-structure register a speedup of approximately 3 on 5 processors. Similar performance improvements are also obtained for Catalog data. These parallelizing techniques can also be applied to other index structures such as BANG files <ref> [Fre87] </ref> and BV-trees [Fre95] to improve their query performance. 4.2 Indexing Low Dimensional Data In this subsection, we examine different ways of structuring multi-dimensional data to support efficient location of data using different types of queries. <p> As part of this study, we are developing a new, generalized implementation of BANG indexing <ref> [Fre87] </ref>. BANG indexing was originally developed as a first step in a research effort to overcome the problem of indexing rules in large scale deductive database systems. Over the years, it evolved into an efficient multi-dimensional index [Fre95] with broad applicability to different types of data. <p> In its current form, BANG indexing combines the indexing of points (n-tuples) and spatial objects (n-dimensional bounding boxes) through a dual recursive partitioning of an n-dimensional space. In the original implementation <ref> [Fre87] </ref>, which was restricted to point indexing, this partitioning was represented by a balanced, multiply-branched index tree structure similar to a B-tree [Com79].
Reference: [Fre95] <author> M. W. Freeston. </author> <title> A general solution of the n-dimensional b-tree problem. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: We observe that both R fl -tree and LIB-structure register a speedup of approximately 3 on 5 processors. Similar performance improvements are also obtained for Catalog data. These parallelizing techniques can also be applied to other index structures such as BANG files [Fre87] and BV-trees <ref> [Fre95] </ref> to improve their query performance. 4.2 Indexing Low Dimensional Data In this subsection, we examine different ways of structuring multi-dimensional data to support efficient location of data using different types of queries. As part of this study, we are developing a new, generalized implementation of BANG indexing [Fre87]. <p> BANG indexing was originally developed as a first step in a research effort to overcome the problem of indexing rules in large scale deductive database systems. Over the years, it evolved into an efficient multi-dimensional index <ref> [Fre95] </ref> with broad applicability to different types of data. In its current form, BANG indexing combines the indexing of points (n-tuples) and spatial objects (n-dimensional bounding boxes) through a dual recursive partitioning of an n-dimensional space. <p> However, such performance could not be guaranteed, and pathological cases could be devised which would give much worse and uncontrolled performance. The new version preserves all the principles of BANG indexing, but is implemented as a BV-tree <ref> [Fre95] </ref>. The properties of this structure make it possible to guarantee logarithmic single-entry access and update, and a minimum 33% index and data node occupancy, for both point and spatial object indexing.
Reference: [FRM94] <author> C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. </author> <title> Fast subsequence matching in time-series databases. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 419-429, </pages> <address> Minneapolis, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: First, we explore the impact of parallelism on query processing in multi-dimensional index structures. Next, we devise new indexing strategies to improve the performance of queries on low dimensional data. Finally, for high dimensional data we note that the query overheads increase with the dimensionality of the data <ref> [FRM94] </ref>. Hence we examine several techniques to reduce the dimensionality of such data. 4.1 Parallelism in Indexing For range and intersection queries, multiple portions of a multi-dimensional index structure can be searched in parallel. To illustrate this situation, consider the following example. <p> The features are chosen so that proximity in the d-dimensional space reflects some type of similarity of images. To effectively capture this similarity, a large value of d is usually selected. However this leads to a problem known as the "dimensionality curse" <ref> [FRM94] </ref>: the larger the dimensionality d, the more difficult to index and retrieve these feature vectors. For a small number of images, a sequential browsing of images using their feature vectors may suffice. <p> However, for large image databases such as in ADL, the problem of efficient browsing and retrieval of images has to be addressed. Multi-dimensional search structures like the R fl -tree [BKSS90] do not scale with the dimensionality of data <ref> [FRM94] </ref> and hence are not directly helpful. Our approach to solving this problem [WA + 96] is to first reduce the dimensionality of the image data and then use multi-dimensional index structures to support efficient retrieval. <p> Each feature vector is first processed using DFT and SVD; then the resulting vector is truncated to a fewer number of components. These techniques have been used to reduce the dimensionality of information in several other projects <ref> [FRM94] </ref>. Both these methods have their relative strengths and weaknesses. SVD is computationally expensive, requiring O (md 2 ) time to process m d-dimensional feature vectors. By using Fast Fourier Transform techniques, the DFT can be calculated in O (md log d) time. <p> In SVD processing, truncation is performed by selecting the first few components (which SVD processing ensures to be the largest singular values). For the DFT, we can truncate by retaining the first few Fourier coefficients as shown in <ref> [FRM94] </ref>. This approach works well when the data is very smooth and dominated by low-order coefficients, however as our experiments on texture image data indicates, better results can be obtained by taking the first few dominant Fourier coefficients [WA + 96].
Reference: [GCGMP96] <author> L. Gravano, K. Chang, H. Garca-Molina, and A. Paepcke. </author> <title> STARTS: Stanford Protocol Proposal for Internet Retrieval and Search. </title> <note> http://www-db.stanford.edu/~gravano/starts.html, 1996. </note>
Reference-contexts: It is similar, in this regard, to the SMART automated text retrieval system [Sal89], replacing the two-dimensional term/document matrix by a term/collection matrix. Harvest [BDH + 94] automatically indexes documents within a source and distributes these indexes. Another system, STARTS <ref> [GCGMP96] </ref>, is described in more detail below. 2.1 Network Models In [DAE97], we consider three general classes of network models that encompass the discovery and querying of information sources. The first class of models uses no intermediate servers; the only communication is directly between users and information sources. <p> Lycos, AltaVista, etc.). In this model, shown in are sent to the intermediary, which returns a result set to the user; queries are not propagated to the sources. Figure 2b shows a more sophisticated approach, the STARTS Model <ref> [GCGMP96] </ref>, built on a gGlOSS [GGM95] framework. Here, each source extracts its own metadata; the intermediary then gathers this metadata rather than extracting its own. When an intermediary receives a query, it analyzes its pre-collected metadata and chooses a set of what it considers to be the best sources.
Reference: [GGM95] <author> L. Gravano and H. Garca-Molina. </author> <title> Generalizing GlOSS to vector-space databases and broker hierarchies. </title> <booktitle> In Proceedings of the 21st VLDB Conference, </booktitle> <address> Zurich, Switzerland, </address> <year> 1995. </year>
Reference-contexts: For example, they are limited to on-line, text documents, and they give no control to the sources of the documents to determine the frequency with which they are indexed. The gGlOSS text database discovery system <ref> [GGM95] </ref> represents sources by vectors of term frequencies. It is similar, in this regard, to the SMART automated text retrieval system [Sal89], replacing the two-dimensional term/document matrix by a term/collection matrix. Harvest [BDH + 94] automatically indexes documents within a source and distributes these indexes. <p> Lycos, AltaVista, etc.). In this model, shown in are sent to the intermediary, which returns a result set to the user; queries are not propagated to the sources. Figure 2b shows a more sophisticated approach, the STARTS Model [GCGMP96], built on a gGlOSS <ref> [GGM95] </ref> framework. Here, each source extracts its own metadata; the intermediary then gathers this metadata rather than extracting its own. When an intermediary receives a query, it analyzes its pre-collected metadata and chooses a set of what it considers to be the best sources.
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability A guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Note that when we generalize the problem to include D and V as a part of input [LMSS95], the problem is essentially the minimum cover problem that is known to be NP-complete <ref> [GJ79] </ref>. Fortunately the query Q is the only input to deal with, which permits an efficient solution to our problem. <p> Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in [PAES96, PAES97a]. The related problem of task or job scheduling has been extensively studied <ref> [Pin95, MP93, Par95, GJ79] </ref>. The problem of robotic library scheduling however, is not addressed by any of the existing studies due to the dependence of the latency upon the order of requests. <p> Therefore, any efficient scheduling policy for a single medium may be used. For multiple drives, the problem of finding an optimal solution is shown to be NP-complete by a from the Minimum Weighted Completion Time <ref> [GJ79] </ref> problem. In the absence of an efficient optimal solution, we have shown that the policy that achieves optimal solutions for the single drive case, OP T , is an effective heuristic for the multiple drive case also.
Reference: [GM95] <author> L. Golubchik and R. Muntz. </author> <title> Analysis of striping techniques in robotic storage libraries. </title> <booktitle> In Proceedings of the Fourteenth IEEE Symposium on Mass Storage Systems, </booktitle> <pages> pages 225-38, </pages> <address> Mon-terey, CA, </address> <year> 1995. </year>
Reference-contexts: In [FM96], a log structured file system for tertiary media has been proposed. The feasibility of striping in tape based systems has been studied by Drapeau and Katz [DK93] and also by Golubchik and Muntz <ref> [GM95] </ref>. Other studies have looked at the problem of reorganization of data that is stored on tertiary media in order to improve retrieval performance [CDK + 95, SS94]. In contrast to other studies, we have explored the problem of scheduling requests for more than one medium [PAES97b].
Reference: [Gup97] <author> H. Gupta. </author> <title> Selection of views to materialize in a data warehouse. </title> <booktitle> In Proc. Int Conf on Database Theory, </booktitle> <year> 1997. </year>
Reference-contexts: We have developed a general approach that addresses these issues in relational databases [Cod70] which are designed using entity-relationship models [Che76]. There had been some other work done on these two issues <ref> [Gup97, VH96, LMSS95] </ref>. Our approach is novel because we introduce query pattern into materialized view selection and translation which makes the solution more effective and efficient. The main idea is as follows.
Reference: [Har96] <author> D. </author> <title> Harman. </title> <booktitle> Overview of the Fourth Text REtrieval Conference (TREC-4). </booktitle> <address> Gaithersburg, MD, </address> <year> 1996. </year> <note> http://potomac.ncsl.nist.gov/TREC/. </note>
Reference-contexts: When dealing with a standard, single text document database, precision usually gives a measure of how many of the returned documents are considered to be relevant to the query <ref> [Har96] </ref>. This definition does not extend naturally to the problem of locating sources. A source could be considered relevant if it contains even a single relevant document, resulting in a relevance test that is too broad and unintuitive. <p> For proper perspective, precision measurements generally must be compared to their corresponding recall values, which we have not yet defined. While work from the NIST Text REtrieval Conferences (TREC) <ref> [Har96] </ref> generally shows the state-of-the-art of document retrieval to be around 50% precision for 50% recall, these values are for document query results from single collections.
Reference: [HS96] <author> B. K. Hillyer and A. Silberschatz. </author> <title> Random I/O scheduling in online tertiary storage. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <address> Canada, </address> <year> 1996. </year> <month> 24 </month>
Reference-contexts: In [CF89] the tradeoff between retrieval performance and disk space utilization for Write-Once-Read-Many (WORM) optical disks is investigated. The placement of data on CLV optical disks in order to improve random I/O based upon a hot-cold distribution of accesses is studied in [FC91]. More recent work on tape scheduling <ref> [HS96, LO96] </ref> has studied efficient processing schedules for I/O requests for single tapes. In [HS96] Hillyer and Silberschatz have analyzed algorithms for scheduling batched requests for a single serpentine tape that is loaded on the drive. Li and Orji [LO96] have studied efficient scheduling policies for linear tapes. <p> The placement of data on CLV optical disks in order to improve random I/O based upon a hot-cold distribution of accesses is studied in [FC91]. More recent work on tape scheduling [HS96, LO96] has studied efficient processing schedules for I/O requests for single tapes. In <ref> [HS96] </ref> Hillyer and Silberschatz have analyzed algorithms for scheduling batched requests for a single serpentine tape that is loaded on the drive. Li and Orji [LO96] have studied efficient scheduling policies for linear tapes. Both these studies do not consider scheduling requests for more than one medium.
Reference: [KF92] <author> I. Kamel and C. Faloutsos. </author> <title> Parallel R-trees. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 195-204, </pages> <year> 1992. </year>
Reference-contexts: These techniques estimate the proximity (likelihood of being retrieved in the same query) of every pair of nodes and assign nodes with high proximity to different processors <ref> [KF92] </ref>. This ensures that most queries can be processed in parallel. are evenly distributed among both the processors. Consequently, the query processing time is nearly halved. Using these ideas, we parallelized two index structures the R fl -tree [BKSS90] and the LIB structure [RAE + 95].
Reference: [Lib86] <institution> Library of Congress, </institution> <address> Washington, D.C. LC Classification Outline, fifth edition, </address> <year> 1986. </year>
Reference-contexts: For example, Figure 4 shows part of a geographic information hierarchy based on political regions, and a subject hierarchy can be modeled after the Library of Congress's LC Classification system <ref> [Lib86] </ref>, which has a fixed list of categories. Similarly, a simplistic geographical information hierarchy can be formed by tiling the Earth's surface into progressively smaller, hierarchical, longitude/latitude squares. A taxonomy is defined as a static hierarchy within which documents can be classified, usually according to their content.
Reference: [LMSS95] <author> Alon Y. Levy, Alberto O. Mendelzon, Yehoshua Sagiv, and Divesh Srivastava. </author> <title> Answering queries using views. </title> <booktitle> In Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 95-104, </pages> <year> 1995. </year>
Reference-contexts: We have developed a general approach that addresses these issues in relational databases [Cod70] which are designed using entity-relationship models [Che76]. There had been some other work done on these two issues <ref> [Gup97, VH96, LMSS95] </ref>. Our approach is novel because we introduce query pattern into materialized view selection and translation which makes the solution more effective and efficient. The main idea is as follows. <p> Since our main concern here is the number of joins, we measure the complexity of a query by the number of joins it uses in our model. Note that when we generalize the problem to include D and V as a part of input <ref> [LMSS95] </ref>, the problem is essentially the minimum cover problem that is known to be NP-complete [GJ79]. Fortunately the query Q is the only input to deal with, which permits an efficient solution to our problem.
Reference: [LO96] <author> J. Li and C. Orji. </author> <title> I/O scheduling in tape-based tertiary systems. </title> <journal> Journal of Mathematical Modelling and Scientific Computing, </journal> <volume> 6, </volume> <year> 1996. </year>
Reference-contexts: In [CF89] the tradeoff between retrieval performance and disk space utilization for Write-Once-Read-Many (WORM) optical disks is investigated. The placement of data on CLV optical disks in order to improve random I/O based upon a hot-cold distribution of accesses is studied in [FC91]. More recent work on tape scheduling <ref> [HS96, LO96] </ref> has studied efficient processing schedules for I/O requests for single tapes. In [HS96] Hillyer and Silberschatz have analyzed algorithms for scheduling batched requests for a single serpentine tape that is loaded on the drive. Li and Orji [LO96] have studied efficient scheduling policies for linear tapes. <p> More recent work on tape scheduling [HS96, LO96] has studied efficient processing schedules for I/O requests for single tapes. In [HS96] Hillyer and Silberschatz have analyzed algorithms for scheduling batched requests for a single serpentine tape that is loaded on the drive. Li and Orji <ref> [LO96] </ref> have studied efficient scheduling policies for linear tapes. Both these studies do not consider scheduling requests for more than one medium. Work has also been done on optimizing the performance of relational database management systems that incorporate tertiary storage [SS93, ML95, Sar95a, Sar95b].
Reference: [Lyc96] <author> Lycos. Lycos. </author> <note> http://www.lycos.com/, 1996. </note>
Reference-contexts: The existence of thousands of newsgroups, World-Wide Web (WWW) sites, FTP archives, and digital libraries renders traditional methods of locating good information sources infeasible. Current WWW indexes such as AltaVista [Dig96], Lycos <ref> [Lyc96] </ref>, and Yahoo [Yah96], which are designed for locating information on the Internet, are limited in several ways. For example, they are limited to on-line, text documents, and they give no control to the sources of the documents to determine the frequency with which they are indexed.
Reference: [ML95] <author> J. Myllymaki and M. Livny. </author> <title> Disk-tape joins: Synchronizing disk and tape access. </title> <booktitle> In Joint International Conference on Measurement and Modeling of ComputerSystems. SIGMETRICS '95/PERFORMANCE '95, </booktitle> <pages> pages 279-90, </pages> <address> Ottawa, Canada, </address> <year> 1995. </year>
Reference-contexts: Li and Orji [LO96] have studied efficient scheduling policies for linear tapes. Both these studies do not consider scheduling requests for more than one medium. Work has also been done on optimizing the performance of relational database management systems that incorporate tertiary storage <ref> [SS93, ML95, Sar95a, Sar95b] </ref>. Myllymaki and Livny have investigated the benefits of executing tape and disk I/O in parallel [ML96]. In [FM96], a log structured file system for tertiary media has been proposed.
Reference: [ML96] <author> J. Myllymaki and M. Livny. </author> <title> Efficient buffering for concurrent disk and tape I/O. </title> <booktitle> In Proceedings of Performance '96, Int. Conf. on Performance Theory, Measurement and Evaluation of Computer Communication Systems, </booktitle> <address> Lausanne, Switzerland, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Work has also been done on optimizing the performance of relational database management systems that incorporate tertiary storage [SS93, ML95, Sar95a, Sar95b]. Myllymaki and Livny have investigated the benefits of executing tape and disk I/O in parallel <ref> [ML96] </ref>. In [FM96], a log structured file system for tertiary media has been proposed. The feasibility of striping in tape based systems has been studied by Drapeau and Katz [DK93] and also by Golubchik and Muntz [GM95].
Reference: [MM96] <author> B. S. Manjunath and W. Y. Ma. </author> <title> Texture features for browsing and retrieval of image data. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <month> November </month> <year> 1996. </year>
Reference-contexts: To compare whether truncated SVD components or DFT coefficients provide better retrieval performance, we simulate a series of queries on a collection of textures from the Brodatz album [Bro66]. The album consists of many different texture patterns. By applying an image processing technique known as the Gabor transform <ref> [MM96] </ref>, 1856 48-dimnesional feature vectors are extracted from the album images. Every vector is processed at the time of insertion into the database with SVD or DFT. <p> The main benefit of extracting feature vectors from images using the Gabor transform is that this transform has the unique capability of producing features that are adept at comparing different textures for similarity <ref> [MM96] </ref>. Rather than involve a human in making this determination, we utilize the Gabor transform as an automated means of determining similarity of texture patterns; two images are relevant if their corresponding Gabor feature vectors are close in distance. <p> The latency of multiple disk access is reduced by fetching data in parallel from multiple disks. The study focuses on browsing access patterns when images are retrieved by similarity matching, where similarity is based on the content of the images. Image processing techniques <ref> [MM96] </ref> have been applied to quantify the content of images and to determine similarity. Two orthogonal declustering schemes have been evaluated. The first scheme declusters the image icons based on their similarity.
Reference: [Mos85] <author> P. </author> <title> Mosher. The nature and uses of the RLG verification studies. </title> <journal> C&RL News, </journal> <pages> pages 336-338, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: One study by the Research Libraries Group (RLG) of top research libraries in the U.S.A. indicated that the best source can alone provide well over 70% source recall, and that a few sufficient sources can provide a source recall of over 90% <ref> [Mos85] </ref>. It is difficult to know how these RLG values, derived from tens of research libraries, might be extrapolated to our work involving potentially tens of thousands of digital information sources; they do, however, help put the simulation results in some perspective.
Reference: [MP93] <author> T. E. Morton and D. W. Pentico. </author> <title> Heuristic Scheduling Systems with applications to Production Systems and Project Management. </title> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1993. </year>
Reference-contexts: Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in [PAES96, PAES97a]. The related problem of task or job scheduling has been extensively studied <ref> [Pin95, MP93, Par95, GJ79] </ref>. The problem of robotic library scheduling however, is not addressed by any of the existing studies due to the dependence of the latency upon the order of requests.
Reference: [PAE + 97a] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, A. Singh, and T. Smith. </author> <title> Browsing and placement of images on secondary storage. </title> <booktitle> In IEEE International Conference on Multimedia Computing and Systems (ICMCS'97), </booktitle> <pages> pages 636-7, </pages> <address> Ottawa, Canada, </address> <year> 1997. </year>
Reference-contexts: Higher resolution copies can be progressively reconstructed from the icon and other coefficients. The original image can be reconstructed from the icon and all the coefficients. In order to improve the I/O performance of browsing, we have investigated efficient placement techniques on magnetic disks <ref> [PAE + 97a, PAE + 97b] </ref>. The latency of multiple disk access is reduced by fetching data in parallel from multiple disks. The study focuses on browsing access patterns when images are retrieved by similarity matching, where similarity is based on the content of the images.
Reference: [PAE + 97b] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, A. Singh, and T. Smith. </author> <title> Browsing and placement of multiresolution images on parallel disks. </title> <booktitle> In 5th Annual Workshop on I/O in Parallel and Distributed Systems, (IOPADS'97), </booktitle> <pages> pages 102-113, </pages> <address> San Jose, U.S.A., </address> <month> November </month> <year> 1997. </year>
Reference-contexts: Higher resolution copies can be progressively reconstructed from the icon and other coefficients. The original image can be reconstructed from the icon and all the coefficients. In order to improve the I/O performance of browsing, we have investigated efficient placement techniques on magnetic disks <ref> [PAE + 97a, PAE + 97b] </ref>. The latency of multiple disk access is reduced by fetching data in parallel from multiple disks. The study focuses on browsing access patterns when images are retrieved by similarity matching, where similarity is based on the content of the images.
Reference: [PAES96] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, and A. Singh. </author> <title> Tertiary storage: Current status and future trends. </title> <type> Technical Report TRCS96-21, </type> <institution> Dept. of Computer Science, Univ. of Calilfornia, Santa Barbara, </institution> <year> 1996. </year> <note> http://www.cs.ucsb.edu/TRs/TRCS96-21.ps. </note>
Reference-contexts: It can take up to a few minutes to seek to the desired location on a tape. Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in <ref> [PAES96, PAES97a] </ref>. The related problem of task or job scheduling has been extensively studied [Pin95, MP93, Par95, GJ79]. The problem of robotic library scheduling however, is not addressed by any of the existing studies due to the dependence of the latency upon the order of requests.
Reference: [PAES97a] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, and A. Singh. </author> <title> A brief survey of tertiary storage systems and research. </title> <booktitle> In Proceedings of the 1997 ACM Symposium on Applied Computing, </booktitle> <pages> pages 155-157, </pages> <address> San Jose, CA, </address> <year> 1997. </year>
Reference-contexts: It can take up to a few minutes to seek to the desired location on a tape. Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in <ref> [PAES96, PAES97a] </ref>. The related problem of task or job scheduling has been extensively studied [Pin95, MP93, Par95, GJ79]. The problem of robotic library scheduling however, is not addressed by any of the existing studies due to the dependence of the latency upon the order of requests.
Reference: [PAES97b] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, and A. Singh. </author> <title> Scheduling tertiary I/O in database applications. </title> <booktitle> In 8th International Workshop on Database and Expert Systems Applications, </booktitle> <pages> pages 722-727, </pages> <address> Toulouse, France, </address> <month> September </month> <year> 1997. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: Other studies have looked at the problem of reorganization of data that is stored on tertiary media in order to improve retrieval performance [CDK + 95, SS94]. In contrast to other studies, we have explored the problem of scheduling requests for more than one medium <ref> [PAES97b] </ref>. Due to the great difference in speeds between the processors and tertiary storage, we expect that request traffic will be bursty. Consequently, we have studied the problem of scheduling bursty I/O requests.
Reference: [Par95] <author> G. R. Parker. </author> <title> Deterministic Scheduling Theory. </title> <publisher> Chapman & Hall, 2-6 Boundary Row, </publisher> <address> London SE1 8HN, UK, </address> <year> 1995. </year>
Reference-contexts: Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in [PAES96, PAES97a]. The related problem of task or job scheduling has been extensively studied <ref> [Pin95, MP93, Par95, GJ79] </ref>. The problem of robotic library scheduling however, is not addressed by any of the existing studies due to the dependence of the latency upon the order of requests.
Reference: [Pin95] <author> M. Pinedo. </author> <title> Scheduling Theory, </title> <booktitle> Algorithms and Systems. Prentice-Hall International Series in Industrial and Systems Engineering. </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in [PAES96, PAES97a]. The related problem of task or job scheduling has been extensively studied <ref> [Pin95, MP93, Par95, GJ79] </ref>. The problem of robotic library scheduling however, is not addressed by any of the existing studies due to the dependence of the latency upon the order of requests.
Reference: [RAE + 95] <author> K. V. Ravi Kanth, D. Agrawal, A. El Abbadi, A. Singh, and T. R. Smith. </author> <title> Indexing hierarchical data. </title> <type> Technical Report TRCS95-14, </type> <year> 1995. </year> <note> http://www.cs.ucsb.edu/TRs/TRCS95-15.html. 25 </note>
Reference-contexts: This ensures that most queries can be processed in parallel. are evenly distributed among both the processors. Consequently, the query processing time is nearly halved. Using these ideas, we parallelized two index structures the R fl -tree [BKSS90] and the LIB structure <ref> [RAE + 95] </ref>. The R fl -tree is chosen because it is a versatile multi-dimensional index that caters to arbitrary 11 12 data. The LIB structure is chosen because it maintains separate index components that can be searched in parallel.
Reference: [RAE + 96] <author> K. V. Ravi Kanth, D. Agrawal, A. El Abbadi, A. Singh, and T. R. Smith. </author> <title> Parallelizing multidimensional index structures. </title> <booktitle> IEEE Symposium on Parallel and Distributed Processing, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Nevertheless, the query is processed in the R fl tree from the root to the leaves by searching down all index nodes (that intersect the query rectangle). Let us now illustrate how parallelism can help. Using the techniques proposed in <ref> [RAE + 96] </ref>, we partition the R fl -tree into two components, each assigned to a separate processor. These techniques estimate the proximity (likelihood of being retrieved in the same query) of every pair of nodes and assign nodes with high proximity to different processors [KF92].
Reference: [RAES97] <author> K. V. Ravi Kanth, D. Agrawal, A. El Abbadi, and A. Singh. </author> <title> Indexing non-uniform spatial data. </title> <booktitle> International Database Engineering and Application Symposium (IDEAS 97), </booktitle> <year> 1997. </year> <note> http://www.cs.ucsb.edu/ ~ kravi/SpatialIndx.html. </note>
Reference-contexts: Indexing such dead space entails accessing irrelevant parts of the tree that may not contribute to the result of a query in any way. To reduce the effect of these two anomalies in current index structures, we proposed a promotion strategy in <ref> [RAES97] </ref>. This is explained using the following example. Consider the non-uniform data of Figure 9. Data object A contains data object B and overlaps with data objects C; D and E as shown in Figure 9 (a). <p> This index organization solves both the problems of non-uniformity - (1) it reduces the overlaps in index entries, and (2) it reduces the dead space that is indexed (region k is excluded). Based on this simple idea, we have devised two different criteria for data object promotion <ref> [RAES97] </ref>. 5 Structures such as R + -trees take explicit actions to remove such overlaps. 14 The first, called nesting-based promotion, uses spatial nesting of objects to identify possible candidates for promotion.
Reference: [RS97] <author> K. V. Ravi Kanth and A. Singh. </author> <title> Optimal dynamic range searching in non-replicating index structures. </title> <type> Technical Report TRCS97-13, </type> <institution> Comp. Sci. Dept., University of California, Santa Barbara, </institution> <year> 1997. </year> <note> http://www.cs.ucsb.edu/TRs/TRCS97-13.html. </note>
Reference-contexts: Image objects are characterized by high dimensional feature vectors and queries retrieve images similar to user-specified patterns (similarity queries). In <ref> [RS97] </ref>, we show that the lower bound on time complexity of range queries on n d-dimensional objects (d &gt; 1) using conventional tree structures such as the R fl -trees [BKSS90] is (n 11=d ). In contrast, for 1-dimensional data, range queries can be answered in logarithmic time.
Reference: [Sal89] <author> G. Salton. </author> <title> Automatic Text Processing. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: The gGlOSS text database discovery system [GGM95] represents sources by vectors of term frequencies. It is similar, in this regard, to the SMART automated text retrieval system <ref> [Sal89] </ref>, replacing the two-dimensional term/document matrix by a term/collection matrix. Harvest [BDH + 94] automatically indexes documents within a source and distributes these indexes. <p> Instead, we are interested in a measure that is higher for sources which contain a relatively larger number of relevant documents. For simulation simplicity, we consider measures similar to the weights associated with documents based on vector analysis <ref> [Dum91, Sal89] </ref>, which lead to a ranked list of documents. Assuming that we have a weighting system which will lead to a ranked list of sources, we have several options for defining the precision of the results. <p> In our experiments, we measure the quality of the two transformations by evaluating the recall and precision <ref> [Sal89] </ref> for different types of queries on the reduced-dimension data. Suppose a user issues a similarity query and retrieves q images from the database. The number of relevant images stored in the database is r; of these only p are returned in the query.
Reference: [Sar95a] <author> S. Sarawagi. </author> <title> Database systems for efficient access to tertiary memory. </title> <booktitle> In Proceedings of the Fourteenth IEEE Symposium on Mass Storage Systems, </booktitle> <pages> pages 120-6, </pages> <address> Monterey, California, 1995. </address> <publisher> IEEE Comput. Soc. Press. </publisher>
Reference-contexts: Li and Orji [LO96] have studied efficient scheduling policies for linear tapes. Both these studies do not consider scheduling requests for more than one medium. Work has also been done on optimizing the performance of relational database management systems that incorporate tertiary storage <ref> [SS93, ML95, Sar95a, Sar95b] </ref>. Myllymaki and Livny have investigated the benefits of executing tape and disk I/O in parallel [ML96]. In [FM96], a log structured file system for tertiary media has been proposed.
Reference: [Sar95b] <author> S. Sarawagi. </author> <title> Query processing in tertiary memory databases. </title> <booktitle> In Proc. of the 21st Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 585-596, </pages> <address> San Francisco, California, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Li and Orji [LO96] have studied efficient scheduling policies for linear tapes. Both these studies do not consider scheduling requests for more than one medium. Work has also been done on optimizing the performance of relational database management systems that incorporate tertiary storage <ref> [SS93, ML95, Sar95a, Sar95b] </ref>. Myllymaki and Livny have investigated the benefits of executing tape and disk I/O in parallel [ML96]. In [FM96], a log structured file system for tertiary media has been proposed.
Reference: [SS93] <author> S. Sarawagi and M. Stonebraker. </author> <title> Single query opimization for tertiary memory. </title> <type> Technical Report s2k-94-45, </type> <institution> Computer Science Div. U.C. Berkeley, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Li and Orji [LO96] have studied efficient scheduling policies for linear tapes. Both these studies do not consider scheduling requests for more than one medium. Work has also been done on optimizing the performance of relational database management systems that incorporate tertiary storage <ref> [SS93, ML95, Sar95a, Sar95b] </ref>. Myllymaki and Livny have investigated the benefits of executing tape and disk I/O in parallel [ML96]. In [FM96], a log structured file system for tertiary media has been proposed.
Reference: [SS94] <author> S. Sarawagi and M. Stonebraker. </author> <title> Efficient organization of large multidimensional arrays. </title> <booktitle> In IEEE Int. Conf. on Data Engineering, </booktitle> <pages> pages 328-336, </pages> <address> Houston, TX, USA, Feb. 1994. </address> <publisher> IEEE Comput. Soc. Press. </publisher>
Reference-contexts: The feasibility of striping in tape based systems has been studied by Drapeau and Katz [DK93] and also by Golubchik and Muntz [GM95]. Other studies have looked at the problem of reorganization of data that is stored on tertiary media in order to improve retrieval performance <ref> [CDK + 95, SS94] </ref>. In contrast to other studies, we have explored the problem of scheduling requests for more than one medium [PAES97b]. Due to the great difference in speeds between the processors and tertiary storage, we expect that request traffic will be bursty.
Reference: [Teo72] <author> T. J. Teorey. </author> <title> Properties of disk scheduling policies in multiprogrammed computer systems. </title> <booktitle> In Proceedings of the AFIPS Fall Joint Computer Conference, </booktitle> <pages> pages 1-11, </pages> <year> 1972. </year>
Reference-contexts: For disk scheduling, a number of requests need to be serviced on different locations. The drive has to seek between requests that are not contiguously located. Numerous algorithms have been proposed for efficiently servicing disk requests, such as C-SCAN <ref> [Teo72] </ref> and HEADSCHEDULE [ABZ96]. The major difference between disk scheduling and robotic library scheduling is that tertiary storage media such as tapes or optical disks are removable as opposed to fixed magnetic disks.
Reference: [VH96] <author> Jeffrey D. Ullman Venky Harinarayan, Anand Rajaraman. </author> <title> Implementing data cubes efficiently. </title> <booktitle> In Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 205-216, </pages> <year> 1996. </year>
Reference-contexts: We have developed a general approach that addresses these issues in relational databases [Cod70] which are designed using entity-relationship models [Che76]. There had been some other work done on these two issues <ref> [Gup97, VH96, LMSS95] </ref>. Our approach is novel because we introduce query pattern into materialized view selection and translation which makes the solution more effective and efficient. The main idea is as follows.
Reference: [WA + 96] <author> D. Wu, D. Agrawal, , A. El Abbadi, A. Singh, and T. R. Smith. </author> <title> Efficient retrieval for browsing large image databases. </title> <booktitle> Proc. Conf. on Information and Knowledge Management, </booktitle> <pages> pages 11-18, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: Multi-dimensional search structures like the R fl -tree [BKSS90] do not scale with the dimensionality of data [FRM94] and hence are not directly helpful. Our approach to solving this problem <ref> [WA + 96] </ref> is to first reduce the dimensionality of the image data and then use multi-dimensional index structures to support efficient retrieval. <p> <ref> [WA + 96] </ref> is to first reduce the dimensionality of the image data and then use multi-dimensional index structures to support efficient retrieval. To reduce the dimensionality of the feature vector data, we consider two different techniques based on the Discrete Fourier Transform (DFT) and Singular Value Decomposition (SVD) in [WA + 96]. Each feature vector is first processed using DFT and SVD; then the resulting vector is truncated to a fewer number of components. These techniques have been used to reduce the dimensionality of information in several other projects [FRM94]. Both these methods have their relative strengths and weaknesses. <p> This approach works well when the data is very smooth and dominated by low-order coefficients, however as our experiments on texture image data indicates, better results can be obtained by taking the first few dominant Fourier coefficients <ref> [WA + 96] </ref>. In our experiments, we measure the quality of the two transformations by evaluating the recall and precision [Sal89] for different types of queries on the reduced-dimension data. Suppose a user issues a similarity query and retrieves q images from the database. <p> Using the feature vector for I, the range query retrieves all other images lying in a neighborhood of radius R about I. Alternatively, a nearest-neighbor query retrieves the M images closest to the reference image I. As explained in <ref> [WA + 96] </ref>, 17 range queries provide 100% recall, while in nearest-neighbor queries recall and precision are the same.
Reference: [Yah96] <author> Yahoo. </author> <note> Yahoo FAQ. http://www.yahoo.com/docs/info/faq.html, 1996. 26 </note>
Reference-contexts: The existence of thousands of newsgroups, World-Wide Web (WWW) sites, FTP archives, and digital libraries renders traditional methods of locating good information sources infeasible. Current WWW indexes such as AltaVista [Dig96], Lycos [Lyc96], and Yahoo <ref> [Yah96] </ref>, which are designed for locating information on the Internet, are limited in several ways. For example, they are limited to on-line, text documents, and they give no control to the sources of the documents to determine the frequency with which they are indexed.
References-found: 59

