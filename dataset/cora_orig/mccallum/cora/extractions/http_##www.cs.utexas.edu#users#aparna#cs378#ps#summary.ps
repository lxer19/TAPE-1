URL: http://www.cs.utexas.edu/users/aparna/cs378/ps/summary.ps
Refering-URL: http://www.cs.utexas.edu/users/aparna/cs378/
Root-URL: 
Title: Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol  
Abstract: The sharing of caches among Web proxies is an important technique to reduce Web traffic and alleviate network bottlenecks. Nevertheless it is not widely deployed due to the overhead of existing protocols. In this paper we demonstrate the benefits of cache sharing, measure the overhead of the existing protocols, and propose a new protocol called "Summary Cache". In this new protocol, each proxy keeps a summary of the cache directory of each participating proxy, and checks these summaries for potential hits before sending any queries. Two factors contribute to our protocol's low overhead: the summaries are updated only periodically, and the directory representations are very economical, as low as 8 bits per entry. Using trace-driven simulations and a prototype implementation, we show that, compared to existing protocols such as the Internet Cache Protocol (ICP), Summary Cache reduces the number of inter-cache protocol messages by a factor of 40 to 65, reduces the bandwidth consumption by over 50%, eliminates 75% and 95% of the protocol CPU overhead, all while maintaining almost the same cache hit ratio as ICP. Hence Summary Cache scales to a large number of proxies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Thomas E. Anderson, Michael D. Dahlin, Jeanna M. Neefe, David A. Patterson, Drew S. Roselli, and Ran-dolph Y. Wang. </author> <title> Serverless network file systems. </title> <booktitle> In Proceedings of 15th ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: In the operating system context, there have been a lot of studies on cooperative file caching <ref> [10, 1] </ref> and the global memory system (GMS) [14]. The underlying assumption in these systems is that the high-speed local area networks are faster than disks, and workstations should use each other's idle memory to cache file pages or virtual memory pages to avoid traffic to disks.
Reference: [2] <author> M. Arlitt and C. Williamson. </author> <title> Web server workload characterization. </title> <booktitle> In Proceedings of the 1996 Page 15 ACM SIGMETRICS International Conference on Measurement and Modelling of Computer Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [9, 2, 13, 30, 20] </ref>, web caching algorithms [46, 32, 7] as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [3] <author> Aline Baggio and Guillaume Pierre. Oleron: </author> <title> Supporting information sharing in large-scale mobile environments. </title> <booktitle> In Proceedings of the ERSADS Workshop, </booktitle> <month> March </month> <year> 1997. </year> <note> Available from http://www-sor.inria.fr/projects/relais/. </note>
Reference-contexts: The idea is similar to summary cache. However, the project does not seem to address the problem of the linearly growing memory requirements of the local directories. From the publications on Relais that we can find and read <ref> [3] </ref>, it is also not clear to us whether the project addresses the issue of directory update frequencies.
Reference: [4] <author> Kirby Beck. </author> <title> Tennessee cache box project. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [15] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [22, 27, 39, 4, 13] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [5] <author> Burton Bloom. </author> <title> Space/time trade-offs in hash coding with allowable errors. </title> <journal> Communications of ACM, </journal> <pages> pages 13(7) 422-426, </pages> <month> July </month> <year> 1970. </year>
Reference-contexts: To reduce the memory requirements, we store each summary as a "Bloom filter" <ref> [5] </ref>. This is a computa-tionally very efficient hash-based probabilistic scheme that can represent a set of keys (in our case, a cache directory) with minimal memory requirements while answering membership queries with 0 probability for false negatives and low probability for false positives. <p> It was invented by Burton Bloom in 1970 <ref> [5] </ref> and was proposed for use in the web context by Marais and Bharat [34] as a mechanism for identifying which pages have associated comments stored within a CommonKnowledge server.
Reference: [6] <author> Andrei Z. Broder. </author> <title> Some applications of Rabin's fingerprinting method. </title> <editor> In Renato Capocelli, Alfredo De Santis, and Ugo Vaccaro, editors, </editor> <title> Sequences II: Methods in Communications, Security, </title> <booktitle> and Computer Science, </booktitle> <pages> pages 143-152. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The only drawback is the MD5 calculation, which must be performed every time a document is added to or deleted from the cache. However, faster hashing methods are available, for instance hash functions can be based on polynomial arithmetic as in Rabin's fingerprinting method (See <ref> [40, 6] </ref>), or a simple hash function (e.g. [19, p. 48]) can be used to generate, say 32 bits, and further bits can be obtained by taking random linear transformations of these 32 bits viewed as an integer.
Reference: [7] <author> Pei Cao and Sandy Irani. </author> <title> Cost-aware WWW proxy caching algorithms. </title> <booktitle> In Proceedings of the 1997 USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio <ref> [46, 7, 32] </ref>. <p> We also performed simulations with cache sizes being 5% of the inifinite cache size and the results are very similar. 3 Benefits of Cache Sharing Recent studies <ref> [7, 20, 13] </ref> have shown that under infinite cache capacity, Web cache hit ratio appears to grow logarithmically with the size of the user population served by the cache. <p> However, if the resource planning for each proxy is done properly, there is no need to perform load-balancing and incur the overhead of more tightly coordinating schemes. Finally, note that the results are obtained under the LRU replacement algorithm explained in Section 2. Different replacement algorithms <ref> [7] </ref> may give Page 4 different results. <p> We experiment with two different cache hit ratios, 25% and 45%, as the overhead of ICP varies with the cache miss ratio in each proxy. In the benchmark, the client issues requests following the temporal locality patterns observed in <ref> [32, 7] </ref>, and the inherent cache hit ratio in the request stream can be adjusted. In an experiment, each client process issues 200 requests, for a total of 24000 requests. Using the benchmark, we compare two configurations: no-ICP, where proxies do not collaborate, and ICP, where proxies collaborate via ICP. <p> Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics [9, 2, 13, 30, 20], web caching algorithms <ref> [46, 32, 7] </ref> as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [8] <author> M. Crovella and A. Bestavros. </author> <title> Self-similiarity in world wide web traffic: Evidence and possible causes. </title> <booktitle> In Proc of the 1996 Sigmetrics Conference on Measurment and Modeling of Computer systems Philadelphia, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: The client processes on each workstation connect to one of the proxies. Client processes issue requests with no thinking time in between, and the requested document size follow the Pareto distribution with ff = 1:1 and k = 3:0 <ref> [8] </ref>. Finally, two workstations act as servers, each with 15 servers listing on different ports. The Web server forks off a process when handling an 3 The cache size is artificially small so that cache replacement occurs during the short duration of the experiments.
Reference: [9] <author> Carlos R. Cunba, Azer Bestavros, and Mark E. Crov-ella. </author> <title> Characteristics of WWW client-based traces. </title> <type> Technical report, </type> <institution> BU-CS-96-010, Boston University, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [9, 2, 13, 30, 20] </ref>, web caching algorithms [46, 32, 7] as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [10] <author> Michael D. Dahlin, Randolph Y. Wang, Thomas E. Anderson, and David A. Patterson. </author> <title> Cooperative caching: Using remote client memory to improve file system performance. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 267-280, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: In the operating system context, there have been a lot of studies on cooperative file caching <ref> [10, 1] </ref> and the global memory system (GMS) [14]. The underlying assumption in these systems is that the high-speed local area networks are faster than disks, and workstations should use each other's idle memory to cache file pages or virtual memory pages to avoid traffic to disks.
Reference: [11] <author> P. B. Danzig, R. S. Hall, and M. F. Schwartz. </author> <title> A case for caching file objects inside internetworks. </title> <booktitle> In Proceedings of SIGCOMM '93, </booktitle> <pages> pages 239-248, </pages> <year> 1993. </year>
Reference-contexts: To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing bottleneck traffic. We call this cooperation "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project <ref> [23, 11] </ref>. The Harvest group designed the Internet Cache Protocol (ICP) [15] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet [22, 27, 39, 4, 13]. <p> Thus, in our simulations we ignore the cache consistency issues that arise in practice. There are many other protocols <ref> [11, 31, 25] </ref> that address the cache consistency issue in real life. Most of our simulations assume a cache size that is 10% of the "infinite" cache size. <p> There have also been a lot of studies on Web cache hierarchies and cache sharing. Hierarchical Web caching is first proposed in the Harvest project <ref> [23, 11] </ref>, which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol [45], upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching [47] proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web.
Reference: [12] <author> Fred Douglis, Anja Feldmann, Balachander Krish-namurthy, and Jeffrey Mogul. </author> <title> Rate of change and other metrics: A live study of the world wide web. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: There are many studies on Web client access characteristics [9, 2, 13, 30, 20], web caching algorithms [46, 32, 7] as well as Web cache consistency <ref> [25, 28, 31, 12] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. There have also been a lot of studies on Web cache hierarchies and cache sharing.
Reference: [13] <author> Bradley M. Duska, David Marwood, and Michael J. Feeley. </author> <title> The measured access characteristics of worldwide-web client proxy caches. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: 1 Introduction As the tremendous growth of the World-Wide Web continues to strain the Internet, caching has been recognized as one of the most important techniques to reduce bandwidth consumption [26]. In particular, caching within Web proxies has been shown to be very effective <ref> [13, 30] </ref>. To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing bottleneck traffic. We call this cooperation "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project [23, 11]. <p> The Harvest group designed the Internet Cache Protocol (ICP) [15] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [22, 27, 39, 4, 13] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs. <p> We also performed simulations with cache sizes being 5% of the inifinite cache size and the results are very similar. 3 Benefits of Cache Sharing Recent studies <ref> [7, 20, 13] </ref> have shown that under infinite cache capacity, Web cache hit ratio appears to grow logarithmically with the size of the user population served by the cache. <p> Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [9, 2, 13, 30, 20] </ref>, web caching algorithms [46, 32, 7] as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [14] <author> Michael J. Feeley, William E. Morgan, Frederic H. Pighin, Anna R. Karlin, Henry M. Levy, and Chan-dramohan A. Thekkath. </author> <title> Implementing global memory management in a workstation cluster. </title> <booktitle> In To appear in Proceedings of 15th ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: In the operating system context, there have been a lot of studies on cooperative file caching [10, 1] and the global memory system (GMS) <ref> [14] </ref>. The underlying assumption in these systems is that the high-speed local area networks are faster than disks, and workstations should use each other's idle memory to cache file pages or virtual memory pages to avoid traffic to disks. <p> Most cooperative file caching and GMS systems try to emulate the global LRU replacement algorithm, sometimes also using hints in doing so [42]. It is interesting to note that we arrive at quite different conclusions on whether global replacement algorithm is necessary <ref> [14] </ref>. The reason is that in the OS context, the global replacement algorithm is used for stealing memory from idle workstations (i.e. load-balancing the caches), while in Web cache sharing, every proxy is busy all the time.
Reference: [15] <institution> National Lab for Applied Network Research. Icp working group. </institution> <note> http://ircache.nlanr.net/Cache/ICP/, 1998. </note>
Reference-contexts: We call this cooperation "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project [23, 11]. The Harvest group designed the Internet Cache Protocol (ICP) <ref> [15] </ref> that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet [22, 27, 39, 4, 13]. <p> con-firmed that in case of severe load imbalance, the global cache will have a better cache hit ratio, and therefore it is important to allocate the cache size of each proxy in proportion to its user population size and anticipated use. 4 Overhead of ICP The Internet Cache Protocol (ICP) <ref> [15] </ref> has been very successful at encouraging the practice of Web cache sharing around the world. It requires loose coordinations among the proxies, and is built on top of UDP for efficiency.
Reference: [16] <institution> National Lab for Applied Network Research. Squid internet object cache. </institution> <note> http://squid.nlanr.net/Squid/, 1998. </note>
Reference-contexts: It requires loose coordinations among the proxies, and is built on top of UDP for efficiency. It was designed by the Harvest research group [23] and supported by both the public-domain Squid <ref> [16] </ref> proxy software and some commercial products today. With the deployment of Squid proxies around the globe, ICP is widely used by international countries to reduce traffic over trans-Atlantic and trans-Pacific links. Despite its success, ICP is not a scalable protocol.
Reference: [17] <author> Armando Fox, Steven D. Gribble, Yatin Chawathe, Eric A. Brewer, and Paul Gauthier. </author> <title> Cluster-based scalable network service. </title> <booktitle> In Proceedings of SOSP'16, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: Finally, proxies built out of tightly-coupled clustered workstations also use various hashing and partitioning approaches to utilize the memory and disks in the cluster <ref> [17] </ref>, but the approaches are not appropriate in wide-area networks. In the operating system context, there have been a lot of studies on cooperative file caching [10, 1] and the global memory system (GMS) [14].
Reference: [18] <author> S. Gadde, M. Rabinovich, and J. Chase. </author> <title> Reduce, reuse, recycle: An approach to building large internet caches. </title> <booktitle> In Proceedings of the Sixth Workshop on Hot Topics in Operating Systems (HotOS VI), </booktitle> <month> May </month> <year> 1997. </year> <note> Available from http://www.research.att.com/ misha/. </note>
Reference-contexts: Our inspection of the Questnet traces shows that the child-to-parent ICP queries can be a significant portion (over 2=3) of the messages that the parent has to process. Recently, there have been a number of new cache sharing approaches proposed in the literature. The Page 14 directory server approach <ref> [18] </ref> use a central server to keep track of the cache directories of all proxies, and all proxies query the server for cache hits in other proxies.
Reference: [19] <author> G. Gonnet and R. Baeza-Yates. </author> <title> Handbook of Algorithms and Data Structures. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: We first investigated two naive summary representations: exact-directory and server-name. In the Page 7 exact-directory approach, the summary is essentially the cache directory, with each URL represented by its 16-byte MD5 signature <ref> [19] </ref>. In the server-name approach, the summary is the list of the server name component of the URLs in cache. <p> Since we must allocate memory for the counters it is important to know how large they can become. The asymptotic expected maximum count after inserting n keys with k hash functions into a bit array of size m is (see <ref> [19, p. 72] </ref>) 1 (m) 1 + ln 1 (m) ln 2 1 (m) ; and the probability that any count is greater or equal i is i 1 im : As already mentioned the optimum value for k (over reals) is ln 2m=n so assuming that the number of hash <p> However, faster hashing methods are available, for instance hash functions can be based on polynomial arithmetic as in Rabin's fingerprinting method (See [40, 6]), or a simple hash function (e.g. <ref> [19, p. 48] </ref>) can be used to generate, say 32 bits, and further bits can be obtained by taking random linear transformations of these 32 bits viewed as an integer. We are still exploring whether any degradation happens if we use the faster approaches.
Reference: [20] <author> Steve Gribble and Eric Brewer. </author> <title> System design issues for internet middleware service: Deduction from a large client trace. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: Of the traces, we only simulate GET requests, and only those whose URLs do not include query strings, since most proxies do not cache query requests. 1 The change may have contributed to the difference between our hit ratio results on UCB and those reported in <ref> [20] </ref>. <p> We also performed simulations with cache sizes being 5% of the inifinite cache size and the results are very similar. 3 Benefits of Cache Sharing Recent studies <ref> [7, 20, 13] </ref> have shown that under infinite cache capacity, Web cache hit ratio appears to grow logarithmically with the size of the user population served by the cache. <p> Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [9, 2, 13, 30, 20] </ref>, web caching algorithms [46, 32, 7] as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [21] <author> Steven Gribble and Eric Brewer. </author> <note> Ucb home IP HTTP traces. Available at http://www.cs.berkeley.edu/ grib-ble/traces/index.html, </note> <month> June </month> <year> 1997. </year>
Reference-contexts: Our simulator can only simulate the subtraces due to swap-space limitations. In this paper, we present the results on the trace of the week of Aug. 29 to Sep. 4, 1996. Results on other traces are very similar. * UCB traces <ref> [21] </ref>: traces of HTTP requests gath ered from the Home IP service offered by UC Berkeley to its students, faculty, and staff.
Reference: [22] <author> Christian Grimm. </author> <title> The dfn cache service in B-WiN. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://www-cache.dfn.de/CacheEN/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [15] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [22, 27, 39, 4, 13] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [23] <institution> The Harvest Group. </institution> <note> Harvest information discovery and access system. http://excalibur.usc.edu/, 1994. </note>
Reference-contexts: To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing bottleneck traffic. We call this cooperation "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project <ref> [23, 11] </ref>. The Harvest group designed the Internet Cache Protocol (ICP) [15] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet [22, 27, 39, 4, 13]. <p> It requires loose coordinations among the proxies, and is built on top of UDP for efficiency. It was designed by the Harvest research group <ref> [23] </ref> and supported by both the public-domain Squid [16] proxy software and some commercial products today. With the deployment of Squid proxies around the globe, ICP is widely used by international countries to reduce traffic over trans-Atlantic and trans-Pacific links. Despite its success, ICP is not a scalable protocol. <p> There have also been a lot of studies on Web cache hierarchies and cache sharing. Hierarchical Web caching is first proposed in the Harvest project <ref> [23, 11] </ref>, which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol [45], upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching [47] proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web.
Reference: [24] <author> The Relais Group. Relais: </author> <title> cooperative caches for the worldwide web. </title> <note> http://www-sor.inria.fr/projects/relais/, 1998. </note>
Reference-contexts: An advantage of the approach is that it eliminates duplicate copies of documents. However, it is not clear how well the approach performs for wide-area cache sharing, where proxies maybe distributed over a regional network. The Relais project <ref> [24] </ref> also proposes using local directories to facilitate finding documents in other caches, and updating the directories asynchronously. The idea is similar to summary cache. However, the project does not seem to address the problem of the linearly growing memory requirements of the local directories.
Reference: [25] <author> James Gwertzman and Margo Seltzer. </author> <title> World-wide web cache consistency. </title> <booktitle> In Proceedings of the 1996 USENIX Technical Conference, </booktitle> <address> San Diego, CA, </address> <month> Jan-uary </month> <year> 1996. </year>
Reference-contexts: Thus, in our simulations we ignore the cache consistency issues that arise in practice. There are many other protocols <ref> [11, 31, 25] </ref> that address the cache consistency issue in real life. Most of our simulations assume a cache size that is 10% of the "infinite" cache size. <p> There are many studies on Web client access characteristics [9, 2, 13, 30, 20], web caching algorithms [46, 32, 7] as well as Web cache consistency <ref> [25, 28, 31, 12] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. There have also been a lot of studies on Web cache hierarchies and cache sharing.
Reference: [26] <author> Van Jacobson. </author> <title> How to kill the internet. </title> <booktitle> In SIGCOMM'95 Middleware Workshop, </booktitle> <month> August </month> <year> 1995. </year> <note> URL ftp://ftp.ee.lhl.gov/talks/vj-webflame.ps.Z. </note>
Reference-contexts: 1 Introduction As the tremendous growth of the World-Wide Web continues to strain the Internet, caching has been recognized as one of the most important techniques to reduce bandwidth consumption <ref> [26] </ref>. In particular, caching within Web proxies has been shown to be very effective [13, 30]. To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing bottleneck traffic.
Reference: [27] <author> Jaeyeon. </author> <title> Nation-wide caching project in korea. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [15] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [22, 27, 39, 4, 13] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [28] <author> Balachander Krishnamurthy and Craig E. Ellis. </author> <title> Study of piggyback cache validation for proxy caches in the world wide web. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> De-cember </month> <year> 1997. </year>
Reference-contexts: There are many studies on Web client access characteristics [9, 2, 13, 30, 20], web caching algorithms [46, 32, 7] as well as Web cache consistency <ref> [25, 28, 31, 12] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. There have also been a lot of studies on Web cache hierarchies and cache sharing.
Reference: [29] <author> T. M. Kroeger, J. Mogul, and C. Maltzahn. </author> <title> Digital's web proxy traces. </title> <note> Available at URL: ftp://ftp.digital.com/pub/DEC/traces/proxy/webtraces.html, August 1996. Page 16 </note>
Reference-contexts: In particular, Table 1 lists the "infinite" cache size for each trace, which is the total size in bytes of unique documents in the trace (i.e. the size of the "infinite" cache which incurs no cache replacement). * DEC traces <ref> [29] </ref>: Digital Equipment Corporation Web Proxy server traces, servicing about 17,000 workstations. The trace is for a period of 25 days (Aug. 29 to Sep. 21, 1996). We partitioned the trace into three one-week traces and one half-week traces. Our simulator can only simulate the subtraces due to swap-space limitations.
Reference: [30] <author> Thomas M. Kroeger, Darrell D. E. Long, and Jef--frey C. Mogul. </author> <title> Exploring the bounds of web latency reduction from caching and prefetching. </title> <booktitle> In Proceedings of USENIX Symposium on Internet Technology and Systems, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: 1 Introduction As the tremendous growth of the World-Wide Web continues to strain the Internet, caching has been recognized as one of the most important techniques to reduce bandwidth consumption [26]. In particular, caching within Web proxies has been shown to be very effective <ref> [13, 30] </ref>. To gain the full benefits of caching, proxy caches behind a common bottleneck link should cooperate and serve each other's misses, thus further reducing bottleneck traffic. We call this cooperation "Web cache sharing." Web cache sharing was first proposed in the context of the Harvest project [23, 11]. <p> Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics <ref> [9, 2, 13, 30, 20] </ref>, web caching algorithms [46, 32, 7] as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [31] <author> Chengjie Liu and Pei Cao. </author> <title> Maintaining strong cache consistency for the world-wide web. </title> <booktitle> In The 17th International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: Thus, in our simulations we ignore the cache consistency issues that arise in practice. There are many other protocols <ref> [11, 31, 25] </ref> that address the cache consistency issue in real life. Most of our simulations assume a cache size that is 10% of the "infinite" cache size. <p> There are many studies on Web client access characteristics [9, 2, 13, 30, 20], web caching algorithms [46, 32, 7] as well as Web cache consistency <ref> [25, 28, 31, 12] </ref>. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing. There have also been a lot of studies on Web cache hierarchies and cache sharing.
Reference: [32] <author> P. Lorenzetti, L. Rizzo, and L. Vicisano. </author> <title> Replacement policies for a proxy cache. </title> <type> Technical report, </type> <institution> Universita di Pisa, Italy, </institution> <month> October </month> <year> 1996. </year> <note> URL http://www.iet.unipi.it/ luigi/caching.ps.gz. </note>
Reference-contexts: Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio <ref> [46, 7, 32] </ref>. <p> We experiment with two different cache hit ratios, 25% and 45%, as the overhead of ICP varies with the cache miss ratio in each proxy. In the benchmark, the client issues requests following the temporal locality patterns observed in <ref> [32, 7] </ref>, and the inherent cache hit ratio in the request stream can be adjusted. In an experiment, each client process issues 200 requests, for a total of 24000 requests. Using the benchmark, we compare two configurations: no-ICP, where proxies do not collaborate, and ICP, where proxies collaborate via ICP. <p> Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics [9, 2, 13, 30, 20], web caching algorithms <ref> [46, 32, 7] </ref> as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [33] <author> Carlos Maltzahn, Kathy Richardson, and Dirk Grun-wald. </author> <title> Performance issues of enterprise level web proxies. </title> <booktitle> In Proceedings of the 1997 ACM SIGMET-RICS International Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 13-23, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Summaries need to be stored in the main memory not only because memory lookups are much faster, but also because disk arms are typically the bottlenecks in proxy caches <ref> [33] </ref>. Although DRAM prices continue to drop, we still need a careful design, since the memory requirement grows linearly with the number of proxies. Summaries also take DRAM away from the in-memory cache of hot documents, affecting the proxy performance. Thus, it is important to keep the summaries small.
Reference: [34] <author> J. Marais and K. Bharat. </author> <title> Supporting cooperative and personal surfing with a desktop assistant. </title> <booktitle> In Proceedings of ACM UIST'97, </booktitle> <month> October </month> <year> 1997. </year> <note> Available on-line at ftp://ftp.digital.com/pub/DEC/SRC /publications/marais/uist97paper.pdf. </note>
Reference-contexts: It was invented by Burton Bloom in 1970 [5] and was proposed for use in the web context by Marais and Bharat <ref> [34] </ref> as a mechanism for identifying which pages have associated comments stored within a CommonKnowledge server.
Reference: [35] <institution> National Lab of Applied Network Research. </institution> <note> Sanitized access log. Available at ftp://ircache.nlanr.net/Traces/, </note> <month> July </month> <year> 1997. </year>
Reference-contexts: We extract successful GET requests seen by the parent proxies. Thus, the trace is only a subset of user requests going to the ten proxies. Unfortuantely, the full set of user requests to the proxies are not avail able. * NLANR traces <ref> [35] </ref>: one-day log (Dec. 22, 1997) of HTTP requests to four major parent proxy caches in the National Caching hierarchy by NLANR (National Lab of Applied Network Research). <p> Thus, we believe that the sharp drop in hit ratio is due to the anomaly in the NLANR trace. Unfortunately, we cannot pin down the offending clients because the client IDs are not consistent across NLANR traces <ref> [35] </ref>. The results demonstrate that in practice, a summary update delay threshold of 1% to 5% results in a tolerable degradation of the cache hit ratios.
Reference: [36] <institution> Reference omitted for Anonymous Review. </institution>
Reference-contexts: Thus, it has the potential to significantly increase the deployment of Web cache sharing and reduce Web traffic on the Internet. Toward this end, we are making our implementation publicly available <ref> [36] </ref> and are in the process of transferring it to the Squid users community. 2 Traces and Simulations For our study we have collected five sets of traces of HTTP requests. The number of requests in each trace, the number of clients, and other statistics are listed in Table 1.
Reference: [37] <institution> Reference omitted for Anonymous Review. </institution>
Reference-contexts: As the number of collaborating proxies increases, the overhead quickly becomes prohibitive. To measure the overhead of ICP and its impact on proxy performance, we run experiments using a proxy benchmark designed by us <ref> [37] </ref>. (The benchmark has been submitted to SPEC as a candidate for the industry standard benchmark and is currently in-use at a number of proxy system vendors.) The benchmark consists of a collection of client processes that issue requests following patterns observed in real traces, including request size distribution and temporal
Reference: [38] <institution> Reference omitted for Anonymous Review. </institution>
Reference-contexts: The protocol has been implemented in a prototype build on top of Squid 1.1.14 and the prototype is available for public domain <ref> [38] </ref>. We added a new opcode in ICP version 2 [45], ICP OP DIRUPDATE (= 20), which stands for directory update messages.
Reference: [39] <author> Pietsch. </author> <title> Caching in the washington state k-20 network. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/. </note>
Reference-contexts: The Harvest group designed the Internet Cache Protocol (ICP) [15] that supports discovery and retrieval of documents from neighboring caches. Today, many institutions and many countries have established hierarchies of proxy caches that cooperate via ICP to reduce traffic to the Internet <ref> [22, 27, 39, 4, 13] </ref>. Nevertheless, the wide deployment of web cache sharing is currently hindered by the overhead of the ICP protocol. ICP discovers cache hits in other proxies by having the proxy multicast a query message to all other proxies whenever a cache miss occurs.
Reference: [40] <author> Michael O. Rabin. </author> <title> Fingerprinting by random polynomials. </title> <type> Technical Report TR-15-81, </type> <institution> Center for Research in Computing Technology, Harvard University, </institution> <year> 1981. </year>
Reference-contexts: The only drawback is the MD5 calculation, which must be performed every time a document is added to or deleted from the cache. However, faster hashing methods are available, for instance hash functions can be based on polynomial arithmetic as in Rabin's fingerprinting method (See <ref> [40, 6] </ref>), or a simple hash function (e.g. [19, p. 48]) can be used to generate, say 32 bits, and further bits can be obtained by taking random linear transformations of these 32 bits viewed as an integer.
Reference: [41] <author> Luigi Rizzo. </author> <title> Web proxy traces. </title> <note> Available at URL: http://info.iet.unipi.it/ luigi/proxy-traces/, </note> <month> May </month> <year> 1997. </year>
Reference-contexts: Again, we have run the simulations on other traces in the UCB collections, and the results are similar to what are presented here. * UPisa traces <ref> [41] </ref>: traces of HTTP requests made by the users in Computer Science Department in Universita di Pisa, Italy, for a period of three months from January to March, 1997.
Reference: [42] <author> P. Sarkar and J. Hartman. </author> <title> Efficient cooperative caching using hints. </title> <booktitle> In Proceedings of the USENIX Conference on Operating System Design and Implementations, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: On the other hand, in both context there is the issue of how tightly coordinated the caches should be. Most cooperative file caching and GMS systems try to emulate the global LRU replacement algorithm, sometimes also using hints in doing so <ref> [42] </ref>. It is interesting to note that we arrive at quite different conclusions on whether global replacement algorithm is necessary [14].
Reference: [43] <author> Vinod Valloppillil and Keith W. Ross. </author> <title> Cache array routing protocol v1.0. </title> <note> http://ircache.nlanr.net/Cache/ICP/draft-vinod-carp-v1-02.txt, 1997. </note>
Reference-contexts: Thus, as the number of proxies increases, both the communication and the CPU processing overhead increase quadratically. A number of alternative protocols have been proposed to address the problem, for example, a cache array routing protocol that partitions the URL space among proxies <ref> [43] </ref>. However, such solutions are often not appropriate for wide-area cache sharing, which is characterized by limited network bandwidth among proxies and non-uniform network distances between proxies and their users (for example, each proxy might be much closer to one user group than to others). <p> The drawback of the approach is that the central server can easily become a bottleneck with the query and update messages from the proxies. Another approach is the Cache Array Routing Protocol <ref> [43] </ref>, which divides URL-space among an array of loosely coupled proxy servers, and lets each proxy cache only the documents whose URLs are hashed to it. An advantage of the approach is that it eliminates duplicate copies of documents.
Reference: [44] <author> Julianne Weekers. </author> <type> Personal communication. </type> <month> January </month> <year> 1998. </year>
Reference-contexts: The hit ratio and byte hit ratio are achieved under infinite cache. * Questnet traces <ref> [44] </ref>: 7-days worth of logs of HTTP requests seen by the parent proxies at Questnet, which is a regional network in Aus-tralia, from Jan. 15 to Jan. 21, 1998. The proxies are parent proxies serving about 12 child proxies in the regional network.
Reference: [45] <author> Duane Wessels and Kim Claffy. </author> <title> Internet cache protocol (ICP), </title> <note> version 2. http://ds.internic.net/rfc/rfc2186.txt, 1998. </note>
Reference-contexts: The protocol has been implemented in a prototype build on top of Squid 1.1.14 and the prototype is available for public domain [38]. We added a new opcode in ICP version 2 <ref> [45] </ref>, ICP OP DIRUPDATE (= 20), which stands for directory update messages. In an update message, an additional header follows the regular ICP header and consists of: 16 bits of Function Num, 16 bits of Function Bits, 32 bits of BitArray Size InBits, and 32 bits of Number of Updates. <p> There have also been a lot of studies on Web cache hierarchies and cache sharing. Hierarchical Web caching is first proposed in the Harvest project [23, 11], which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol <ref> [45] </ref>, upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching [47] proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web. In particular, the scheme seeks to position the documents at the right caches along the routes to the servers.
Reference: [46] <author> S. Williams, M. Abrams, C.R. Stanbridge, G. Ab-dulla, and E.A. Fox. </author> <title> Removal policies in network caches for world-wide web documents. </title> <booktitle> In Proceedings of the ACM Sigcomm96, </booktitle> <month> August </month> <year> 1996. </year> <note> URL http://ei.cs.vt.edu/ succeed/96sigcomm/. </note>
Reference-contexts: Most of our simulations assume a cache size that is 10% of the "infinite" cache size. Studies have shown that 10% of the "infinite" cache size typically achieves about 90% of the maximum cache hit ratio <ref> [46, 7, 32] </ref>. <p> Toward this end, we are actively pushing the adoption of the new protocol in the Squid user community. 8 Related Work Web caching is an active research area. There are many studies on Web client access characteristics [9, 2, 13, 30, 20], web caching algorithms <ref> [46, 32, 7] </ref> as well as Web cache consistency [25, 28, 31, 12]. Our study does not address caching algorithms or cache consistency maintanence, but overlaps some of client traffic studies in our investigation of the benefits of Web cache sharing.
Reference: [47] <author> Lixia Zhang, Sally Floyd, and Van Jacob-son. </author> <title> Adaptive web caching. In the 2nd Web Caching Workshop, </title> <address> Boulder, Colorado, </address> <month> June </month> <year> 1997. </year> <note> http://ircache.nlanr.net/Cache/Workshop97/Papers/Floyd/floyd.ps. Page 17 </note>
Reference-contexts: Hierarchical Web caching is first proposed in the Harvest project [23, 11], which also introduces the ICP protocol. Currently, the Squid proxy server implements version 2 of the ICP protocol [45], upon which our Summary-Cached enhanced ICP is based. Adaptive Web caching <ref> [47] </ref> proposes a multicast-based adaptive caching infrastructure for document dissemination in the Web. In particular, the scheme seeks to position the documents at the right caches along the routes to the servers. Our study does not address the positioning issues.
References-found: 47

