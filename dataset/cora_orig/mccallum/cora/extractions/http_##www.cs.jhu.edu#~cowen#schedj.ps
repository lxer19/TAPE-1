URL: http://www.cs.jhu.edu/~cowen/schedj.ps
Refering-URL: http://www.cs.jhu.edu/~cowen/
Root-URL: http://www.cs.jhu.edu
Title: Scheduling with Concurrency-Based Constraints  
Author: Bonnie Berger Lenore Cowen 
Note: an approximation algorithm. Supported in part by a Graduate Fellowship from ARO Grant DAAL03-86-K-0171 and by a NSF postdoctoral fellowship. Supported in part by NSF Grant CCR-86-57527  
Date: August 30, 1995  
Address: Cambridge, MA 02139  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: This paper considers scheduling problems with timing constraints of the forms: &lt; (precedence), (no later than), and : = (concurrence). Scheduling unit-time jobs subject to &lt; and = constraints, and scheduling unit-time jobs subject to constraints, are proved NP-complete for fixed k 3 processors. (This contrasts with the case of just &lt; constraints, which is a famous open problem.) We then show that a modified version of Gabow's linear time 2-processor scheduling algorithm can optimally handle all three types of constraints. Linear time and NC algorithms for optimally scheduling with any subset of f&lt;; ; : =g constraints are thus obtained for k = 2 processors. Approximation results for k 3 processors are also obtained. Finally, we consider a problem that arises in practice on the Tera architecture, proving an NP-Completeness result and providing 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Anderson, P. Beame, and W. Ruzzo. </author> <title> Low overhead parallel schedules for task graphs. </title> <booktitle> In Proceedings of the 1990 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 66-75, </pages> <month> July </month> <year> 1990. </year> <month> 18 </month>
Reference-contexts: Papadimitriou and Yannakakis [17] looked at scheduling, considering also communication delay between processors, as a parameter of the architecture. This allows them to adjust for communication latencies inherent in the machine. Anderson, Beame, and Ruzzo <ref> [1] </ref>, introduced a scheduling model with applications to the architectures of small parallel machines. In this paper, we suggest f&lt;; ; : =g constraints as a way to more precisely model concurrency, in order to take advantage of the synchronous capability of synchronous parallel machines.
Reference: [2] <author> D. Buell. </author> <type> Personal communication. </type>
Reference-contexts: Therefore we have forced the same scheduling problem, and the theorem is proved. 2 Horizontal scheduling on just one processor, was the problem originally considered by <ref> [15, 2] </ref>. They assume that the scheduling problem is already solved off-line, and then for each processor, a post-processor "packager" is then employed to horizontalize the code on each processor.
Reference: [3] <author> W. F. de la Vega and G. S. Lueker. </author> <title> Bin packing can be solved within 1 + * in linear time. </title> <journal> Combinatorica, </journal> <volume> 1 </volume> <pages> 349-355, </pages> <year> 1981. </year>
Reference-contexts: The problem is also known to be NP-complete for non-constant k [10], and there are approximation algorithms that perform within 1 + * of optimal <ref> [3, 14] </ref>.
Reference: [4] <author> J. M. Draper. </author> <title> Compiling in horizon. </title> <booktitle> In Proceedings Supercomputing '88, </booktitle> <pages> pages 51-52, </pages> <address> Orlando, Florida, </address> <month> November </month> <year> 1988. </year> <note> IEEE. </note>
Reference-contexts: So the most accurate representation of this constraint would be j i, which can allow the exploitation of more parallelism (see <ref> [4] </ref> for an example of exactly this type on the Tera architecture.) An initial version of this paper appeared in the proceedings of the Second ACM-SIAM Symposium on Discrete Algorithms (SODA91), under the title Complexity Results and Algorithms for f&lt;; ; =g Constrained Scheduling. 1.1 Previous Results For the special case <p> We apply the developed techniques to a scheduling problem required for efficient parallel processing on the Horizon architecture, now also commonly referred to as the Tera architecture. This is a novel parallel architecture, which has received a lot of recent attention <ref> [4, 15, 19, 11] </ref>. Our new results include the following 1. Scheduling with f&lt;; : =g constraints is NP-complete for constant k 3 processors. <p> We show for any k, a heuristic that produces a schedule of length at most four times optimal; this leads us to suggest a method to exploit more parallelism in Tera than was previously intended <ref> [4] </ref>.
Reference: [5] <author> Jesse M. Draper. </author> <title> Extending dependence analysis to accomodate synchronous machines. </title> <type> Technical Report SRC-TR-89-004, </type> <institution> Supercomputer Research Center, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: This variety of constraints allows us to better model data dependencies in architectures with synchronous capabilities, such as the Tera architecture [18] (previously known also as the Horizon architecture- see Section 5). Draper <ref> [5] </ref> gives examples when both and : = constraints might be needed, in addition to strict precedence constraints, when drawing a data dependency graph.
Reference: [6] <author> Jr. E. G. Coffman and R. L. Graham. </author> <title> Optimal scheduling for two-processor systems. </title> <journal> Acta Informatica, </journal> <volume> 1(3) </volume> <pages> 200-213, </pages> <year> 1972. </year>
Reference-contexts: For the special case where f&lt;g is the only type of constraint relation allowed between tasks, a polynomial time algorithm that finds the optimal schedule on k = 2 processors was known <ref> [7, 6, 8] </ref>. 1 It was also known that the problem is NP-complete for an arbitrary number of processors [20], and the complexity of the problem for constant k 3 processors is a famous open question in the theory of NP-completeness [10] which we do not address in this paper. <p> Coffman and Graham <ref> [6] </ref> reduced the running time by proving a certain lexicographic ordering yields the optimal schedule.
Reference: [7] <author> M. Fujii, T. Kasami, and K. Ninomiya. </author> <title> Bounds on multiprocessing timing anomalies. </title> <journal> SIAM Journal of Applied Mathematics, </journal> <volume> 17(4) </volume> <pages> 784-789, </pages> <month> July </month> <year> 1969. </year>
Reference-contexts: For the special case where f&lt;g is the only type of constraint relation allowed between tasks, a polynomial time algorithm that finds the optimal schedule on k = 2 processors was known <ref> [7, 6, 8] </ref>. 1 It was also known that the problem is NP-complete for an arbitrary number of processors [20], and the complexity of the problem for constant k 3 processors is a famous open question in the theory of NP-completeness [10] which we do not address in this paper. <p> we define levels at the beginning of Section 3.2), we will have to go deep into the structure of the algorithm to prove optimality. 3.1 Background and Notation The first polynomial time algorithm for optimal 2-processor scheduling, in the classical model, where only precedence constraints are considered, was given in <ref> [7] </ref>. Coffman and Graham [6] reduced the running time by proving a certain lexicographic ordering yields the optimal schedule.
Reference: [8] <author> H. M. Gabow. </author> <title> An almost linear algorithm for two-processor scheduling. </title> <journal> Journal of the ACM, </journal> <volume> 29(3) </volume> <pages> 766-780, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: For the special case where f&lt;g is the only type of constraint relation allowed between tasks, a polynomial time algorithm that finds the optimal schedule on k = 2 processors was known <ref> [7, 6, 8] </ref>. 1 It was also known that the problem is NP-complete for an arbitrary number of processors [20], and the complexity of the problem for constant k 3 processors is a famous open question in the theory of NP-completeness [10] which we do not address in this paper. <p> Lam and Sethi [16] also give an approximation algorithm for k-processor scheduling with precedence constraints, where the length of the schedule produced is at most (2 2=k) times the length of the optimal schedule, thereby improving on Graham's <ref> [8] </ref> bound of (2 1=k). For the special case where just fg constraints are allowed, this problem is equivalent to the assembly line balancing problem considered first by [12]. <p> Our algorithm is a modification of Gabow's linear time algorithm for 2-processor scheduling with just f&lt;g constraints <ref> [8] </ref>. Though the way we modify Gabow's algorithm to handle fg and f : =g constraints is easy to describe, the proof that the modifications result in an optimal schedule is fairly involved- as is Gabow's proof that f&lt;g-constrained 2-processor scheduling is solvable in linear time. <p> Coffman and Graham [6] reduced the running time by proving a certain lexicographic ordering yields the optimal schedule. Gabow, in <ref> [8] </ref>, introduced new techniques to reduce the running time for computing a lexicographic ordering to almost linear; when, with Tarjan, he showed in a subsequent paper how to reduce the running time of the set merging operations to linear [9], his algorithm could then be implemented in O (n + e) <p> Such a schedule is called highest level first or HLF, if compared to all legal level schedules, its jump sequence is lexicographically highest. (Jumps are always made to the highest level possible.) Gabow <ref> [8] </ref> proves that for 2-processor scheduling with only strict precedence constraints, any HLF schedule is optimal. <p> Then l can jump to w instead of z. So z is free, again contradicting our assumption. 2 Theorem 3.8 The schedule produced by the algorithm above is optimal and runs in O (n + e) time. Proof. Follows immediately from Gabow's analysis <ref> [8] </ref>, now that we have shown strict precedence in Lemma 3.7. For implementing the data structures in linear time, see also [9]. 2 Theorem 3.9 The schedule produced by the algorithm is HLF, and in fact, any HLF schedule for 2-processor scheduling with f&lt;; g constraints is optimal. Proof.
Reference: [9] <author> H. N. Gabow and R. E. Tarjan. </author> <title> A linear time algorithm for a special case of disjoint set union. </title> <booktitle> In Proceedings of the 15th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 48-50, </pages> <address> Orlando, Florida, </address> <month> May </month> <year> 1983. </year> <note> IEEE. </note>
Reference-contexts: Gabow, in [8], introduced new techniques to reduce the running time for computing a lexicographic ordering to almost linear; when, with Tarjan, he showed in a subsequent paper how to reduce the running time of the set merging operations to linear <ref> [9] </ref>, his algorithm could then be implemented in O (n + e) time. We modify Gabow's linear time algorithm for 2-processor scheduling subject to precedence constraints, to find an optimal 2-processor schedule subject to both f&lt;; g constraints. We then show how to handle f : =g constraints as well. <p> Proof. Follows immediately from Gabow's analysis [8], now that we have shown strict precedence in Lemma 3.7. For implementing the data structures in linear time, see also <ref> [9] </ref>. 2 Theorem 3.9 The schedule produced by the algorithm is HLF, and in fact, any HLF schedule for 2-processor scheduling with f&lt;; g constraints is optimal. Proof.
Reference: [10] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-completeness. </title> <publisher> Freeman, </publisher> <address> San Francisco, CA, </address> <year> 1981. </year>
Reference-contexts: The goal of such scheduling algorithms is to achieve a small makespan, or total length of the schedule. Good scheduling algorithms are essential to exploit the full parallelism of these machines. The classical scheduling problem, precedence constrained scheduling, captures one type of data dependency <ref> [10] </ref>. For precedence constrained scheduling, n unit-length tasks are given to schedule on k identical processors, subject to precedence constraints given by a partial order, &lt;, on the tasks. In practice, however, other types of data dependencies between tasks can arise. <p> = is the only type of constraint relation allowed between tasks, the problem is just integer bin packing, where a set of m mutually concurrent unit time tasks becomes a block of size m, and there is a polynomial time algorithm to find the optimal schedule for all constant k <ref> [10] </ref>. The problem is also known to be NP-complete for non-constant k [10], and there are approximation algorithms that perform within 1 + * of optimal [3, 14]. <p> problem is just integer bin packing, where a set of m mutually concurrent unit time tasks becomes a block of size m, and there is a polynomial time algorithm to find the optimal schedule for all constant k <ref> [10] </ref>. The problem is also known to be NP-complete for non-constant k [10], and there are approximation algorithms that perform within 1 + * of optimal [3, 14]. <p> optimal schedule on k = 2 processors was known [7, 6, 8]. 1 It was also known that the problem is NP-complete for an arbitrary number of processors [20], and the complexity of the problem for constant k 3 processors is a famous open question in the theory of NP-completeness <ref> [10] </ref> which we do not address in this paper. <p> It is interesting that we can determine the complexity of these scheduling problems, because the complexity of f&lt;g, for any constant k 3 is one of the original NP-completeness open problems first posed by Garey and Johnson <ref> [10] </ref>, and one of the few whose complexity is still unknown. <p> In Section 3 we present a linear time algorithm which finds the optimal schedule for k = 2 processors. Theorem 2.1 Scheduling with &lt; and : = constraints is an NP-complete problem for k = 3 proces sors. 3 Proof. The reduction is from exact cover by 3-sets <ref> [10] </ref>.
Reference: [11] <author> R. R. Glenn. </author> <title> Performance prediction for the Horizon super computer. </title> <booktitle> In Proceedings Supercomputing '88, </booktitle> <pages> pages 246-251, </pages> <month> November </month> <year> 1983. </year>
Reference-contexts: We apply the developed techniques to a scheduling problem required for efficient parallel processing on the Horizon architecture, now also commonly referred to as the Tera architecture. This is a novel parallel architecture, which has received a lot of recent attention <ref> [4, 15, 19, 11] </ref>. Our new results include the following 1. Scheduling with f&lt;; : =g constraints is NP-complete for constant k 3 processors. <p> Its performance target is 100 giga (10 11 ) floating point operations per second <ref> [15, 11] </ref>. The architecture is a fixed network consisting of a few hundred identical scalar processors with fixed communication delay.
Reference: [12] <author> A. L. Gutjahr and G. L. Nemhauser. </author> <title> An algorithm for the line balancing problem. </title> <journal> Management Science, </journal> <volume> 11(2) </volume> <pages> 308-315, </pages> <year> 1964. </year>
Reference-contexts: For the special case where just fg constraints are allowed, this problem is equivalent to the assembly line balancing problem considered first by <ref> [12] </ref>.
Reference: [13] <author> David Hembold and Ernst Mayr. </author> <title> Two processor scheduling is in NC. </title> <booktitle> In AWOC 88, </booktitle> <pages> pages 12-25, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: We can also show the following: Theorem 3.13 There is an NC algorithm for optimal 2-processor scheduling subject to f&lt;; ; : constraints. Proof. Follows from Theorem 3.9, coupled with the NC algorithm for optimal 2-processor schedul ing subject to only precedence constraints, given by Helmbold and Mayr <ref> [13] </ref>. 2 4 Approximation Algorithms for k-Processor Scheduling We are interested in finding good approximation algorithms for all subsets of possible constraint relations. Through a careful analysis, we show that a greedy heuristic actually performs quite well.
Reference: [14] <author> R. M. Karp and N. Karmarkar. </author> <title> An efficient approximation scheme for the one-dimensional bin packing problem. </title> <booktitle> In Proceedings of the 23th Annual Symposium on Foundations of Computer Science, </booktitle> <month> May </month> <year> 1982. </year>
Reference-contexts: The problem is also known to be NP-complete for non-constant k [10], and there are approximation algorithms that perform within 1 + * of optimal <ref> [3, 14] </ref>.
Reference: [15] <author> J. T. Kuehn and B. J. Smith. </author> <title> The Horizon supercomputing system: </title> <booktitle> architecture and software. In Proceedings Supercomputing '88, </booktitle> <pages> pages 28-34, </pages> <address> Orlando, Florida, </address> <month> November </month> <year> 1988. </year> <note> IEEE. </note>
Reference-contexts: We apply the developed techniques to a scheduling problem required for efficient parallel processing on the Horizon architecture, now also commonly referred to as the Tera architecture. This is a novel parallel architecture, which has received a lot of recent attention <ref> [4, 15, 19, 11] </ref>. Our new results include the following 1. Scheduling with f&lt;; : =g constraints is NP-complete for constant k 3 processors. <p> Its performance target is 100 giga (10 11 ) floating point operations per second <ref> [15, 11] </ref>. The architecture is a fixed network consisting of a few hundred identical scalar processors with fixed communication delay. <p> The advantage of horizontal code is that it allows the exploitation of more parallelism in algorithms by allowing independent scheduling of each functional unit. The problem, however, is that constructing horizontal code is very hard in practice <ref> [15] </ref>. So suppose we represent the data-dependency digraph of a program as if it were a dataflow program. <p> Therefore we have forced the same scheduling problem, and the theorem is proved. 2 Horizontal scheduling on just one processor, was the problem originally considered by <ref> [15, 2] </ref>. They assume that the scheduling problem is already solved off-line, and then for each processor, a post-processor "packager" is then employed to horizontalize the code on each processor. <p> Concurrency becomes an important option only when one is dealing with a machine like Tera, that hides latencies <ref> [15, 19] </ref>. 7 Acknowledgments Thanks to Duncan Buell for getting us started on scheduling by posing the Horizon scheduling problem. Many many thanks to Daniel Kleitman, Tom Leighton, and the anonymous referee for very helpful discussions. Thanks to David Johnson and David Shmoys for helpful references.
Reference: [16] <author> S. Lam and R. Sethi. </author> <title> Worst case analysis of two scheduling algorithms. </title> <journal> SIAM Journal on Computing, </journal> <volume> 6(3) </volume> <pages> 518-536, </pages> <month> September </month> <year> 1977. </year>
Reference-contexts: Lam and Sethi <ref> [16] </ref> also give an approximation algorithm for k-processor scheduling with precedence constraints, where the length of the schedule produced is at most (2 2=k) times the length of the optimal schedule, thereby improving on Graham's [8] bound of (2 1=k).
Reference: [17] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> Toward an architecture-independent analysis of parallel algorithms. </title> <booktitle> In Proceedings of the 20th Annual ACM Symposium on Theory of Computing, </booktitle> <month> May </month> <year> 1988. </year>
Reference-contexts: The goal of research of this type is to tightly couple the actual scheduling problems we model to specific real-world architectures. Papadimitriou and Yannakakis <ref> [17] </ref> looked at scheduling, considering also communication delay between processors, as a parameter of the architecture. This allows them to adjust for communication latencies inherent in the machine. Anderson, Beame, and Ruzzo [1], introduced a scheduling model with applications to the architectures of small parallel machines. <p> Finally, we remark that models where one would want to differentiate between weak and strict precedence constraints, and allow concurrency, are entirely orthogonal to those models where one would want to consider the costs of latencies as in <ref> [17] </ref>. Concurrency becomes an important option only when one is dealing with a machine like Tera, that hides latencies [15, 19]. 7 Acknowledgments Thanks to Duncan Buell for getting us started on scheduling by posing the Horizon scheduling problem.
Reference: [18] <author> Burton Smith. </author> <title> A massively parallel shared memory computer. </title> <booktitle> In Proceedings of the 1991 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1991. </year>
Reference-contexts: This variety of constraints allows us to better model data dependencies in architectures with synchronous capabilities, such as the Tera architecture <ref> [18] </ref> (previously known also as the Horizon architecture- see Section 5). Draper [5] gives examples when both and : = constraints might be needed, in addition to strict precedence constraints, when drawing a data dependency graph.
Reference: [19] <author> M. M. Thistle and B. J. Smith. </author> <title> A processor architecture for Horizon. </title> <booktitle> In Proceedings Supercomputing '88, </booktitle> <pages> pages 35-41, </pages> <address> Orlando, Florida, </address> <month> November </month> <year> 1988. </year> <journal> IEEE. </journal> <volume> 19 </volume>
Reference-contexts: We apply the developed techniques to a scheduling problem required for efficient parallel processing on the Horizon architecture, now also commonly referred to as the Tera architecture. This is a novel parallel architecture, which has received a lot of recent attention <ref> [4, 15, 19, 11] </ref>. Our new results include the following 1. Scheduling with f&lt;; : =g constraints is NP-complete for constant k 3 processors. <p> Concurrency becomes an important option only when one is dealing with a machine like Tera, that hides latencies <ref> [15, 19] </ref>. 7 Acknowledgments Thanks to Duncan Buell for getting us started on scheduling by posing the Horizon scheduling problem. Many many thanks to Daniel Kleitman, Tom Leighton, and the anonymous referee for very helpful discussions. Thanks to David Johnson and David Shmoys for helpful references.
Reference: [20] <author> J. D. Ullman. </author> <title> NP-complete scheduling problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 10(3) </volume> <pages> 384-393, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: the special case where f&lt;g is the only type of constraint relation allowed between tasks, a polynomial time algorithm that finds the optimal schedule on k = 2 processors was known [7, 6, 8]. 1 It was also known that the problem is NP-complete for an arbitrary number of processors <ref> [20] </ref>, and the complexity of the problem for constant k 3 processors is a famous open question in the theory of NP-completeness [10] which we do not address in this paper.
Reference: [21] <author> T.S. Wee and M.J. </author> <title> Magazine. Assembly line balancing as generalized bin packing. </title> <journal> Operations Research Letters, </journal> <volume> 1(2) </volume> <pages> 56-58, </pages> <year> 1982. </year> <month> 20 </month>
Reference-contexts: For the special case where just fg constraints are allowed, this problem is equivalent to the assembly line balancing problem considered first by [12]. While the complexity of this problem for k processors was undetermined prior to this paper, Wee and Magazine <ref> [21] </ref> gave approximation algorithms that achieve twice the length of the optimal schedule. 1.2 Our Results In this paper, we obtain complexity results and approximation algorithms for all other subsets of allowable constraint relations between tasks. <p> For the special case of scheduling with fg constraints, we show that this algorithm yields a schedule which is at most 2 2=(k+1) times optimal, thereby improving on Wee and Magazine's <ref> [21] </ref> bound of twice optimal. 4. We also show a particular scheduling problem that arises when taking advantage of the "hor izontal" parallel capabilities of the Tera architecture is very closely related to the abstract 2 Complexity Results Approx.
References-found: 21

