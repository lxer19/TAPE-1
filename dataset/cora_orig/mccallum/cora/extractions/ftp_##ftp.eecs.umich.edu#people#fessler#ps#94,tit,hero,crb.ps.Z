URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/94,tit,hero,crb.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/jour.html
Root-URL: http://www.cs.umich.edu
Phone: Tel: (313)-763-0564 Tel:  
Title: A Recursive Algorithm for Computing CR-Type Bounds on Estimator Covariance 1  
Author: Alfred Hero Jeffrey A. Fessler 
Keyword: Multi-dimensional parameter estimation, estimator covariance bounds, complete-incomplete data problem, image reconstruction.  
Address: Ann Arbor, MI 48109-2122 Ann Arbor, MI 48109-0028  (313)-763-1434  
Affiliation: Dept. of EECS Division of Nuclear Medicine The University of Michigan The University of Michigan  
Note: (Corresponding Author)  
Abstract: We derive an iterative algorithm that calculates submatrices of the Cramer-Rao (CR) matrix bound on the covariance of any unbiased estimator of a vector parameter . Our algorithm computes a sequence of lower bounds that converges monotonically to the CR bound with exponential speed of convergence. The recursive algorithm uses an invertable "splitting matrix," and we present a statistical approach to selecting this matrix based on a "complete data incomplete data" formulation similar to that of the well known EM parameter estimation algorithm. As a concrete illustration we consider image reconstruction from projections for emission computed tomography. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. </author> <title> Blahut, </title> <booktitle> Principles and Practice of Information Theory, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Specifically, we formulate the parameter estimation problem in a complete data incomplete data setting and apply a version of the "data processing theorem" <ref> [1] </ref> for Fisher information matrices. This setting is similar to that which underlies the classical formulation of the Maximum Likelihood Expectation Maximization (ML-EM) parameter estimation algorithm. <p> the lemma. 2 Since the Fisher information matrix F XjY is non-negative definite, an important consequence of the decomposition of Lemma 1 is the matrix inequality: F X () F Y (): (15) The inequality (15) can be interpreted as a version of the "data processing theorem" of information theory <ref> [1] </ref> which asserts that any irreversible processing of data X entails a loss in information in the resulting data Y. 3.2 Remarks 1. The inequality (15) is precisely the condition required of the splitting matrix F by the recursive CR bound algorithm (10).
Reference: [2] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin, </author> <title> "Maximum likelihood from incomplete data via the EM algorithm," </title> <journal> J. Royal Statistical Society, Ser. B, </journal> <volume> vol. 39, </volume> <pages> pp. 1-38, </pages> <year> 1977. </year>
Reference-contexts: This definition of incomplete complete data is equivalent to defining Y as the output of a -independent possibly noisy channel having input X. Note that our definition contains as a special case the standard definition <ref> [2] </ref> whereby X and Y must be related via a deterministic functional transformation Y = h (X), where h : X ! Y is many-to-one. Assume that a complete data set X has been specified. <p> A = I F 1 On the other hand, if the Fisher matrix F Y is not available, the matrix A in the recursion (8) can be computed directly from Q (u; v) = Eflog f (X; )jY; g arising from the E step of the EM parameter estimation algorithm <ref> [2] </ref>. Note that, under the assumption that exchange of order of differentiation and expectation is justified [10, Sec. 2.6]: F XjY () = E r 2 fi fl i fi fl where H (u; v) def = E v flog f XjY (XjY; u)jY = yg. <p> We can make use of an identity <ref> [2, Lemma 2] </ref>: r 20 H (; ) = r 11 H (; ) Furthermore, r 11 H (; ) = r 11 Q (; ): This gives the identity: F XjY () = E [r 11 Q (; )]: Giving an alternative expression to (16) for precomputing A: A =
Reference: [3] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations (2nd Edition), </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1989. </year>
Reference-contexts: Equivalently, the first p columns of F 1 Y provide this CR bound. The method of sequential partitioning [11] for computing the upper left p fi p submatrix of F 1 Y and Cholesky based Gaussian elimination techniques <ref> [3] </ref> for computing the p first columns of F 1 Y are efficient direct methods for obtaining the CR bound but require O (n 3 ) floating point operations. <p> In this correspondence we give an iterative algorithm for computing columns of the CR bound which requires only O (pn 2 ) per iteration. This algorithm falls into the class of "splitting matrix iterations" <ref> [3] </ref> with the imposition of an additional requirement: the splitting matrix must be chosen to ensure that a valid lower bound results at each iteration of the algorithm. <p> E = [e 1 ; : : : ; e p ] and e j is the j-th unit column vector in IR n . Using a standard identity for the partitioned matrix inverse <ref> [3] </ref> this submatrix can be expressed in terms of the partition elements of F Y yielding the following equivalent form for the unbiased CR bound: cov ( ^ ) F 11 F T 22 F 12 : (6) By using the method of sequential partitioning [11], the right hand side of <p> The topmost p fi p block E T U of U is equal to the right hand side of the CR bound inequality (5). By using the Cholesky decomposition of F Y and Gaussian elimination <ref> [3] </ref> the solution U to F Y U = E could be computed with O (n 3 ) floating point operations. <p> This recursion can be implemented alongside of the bound recursion (10). 3. For p = 1 the iteration of Corollary 1 is related to the "matrix splitting" method <ref> [3] </ref> for iteratively approximating the solution u to a linear equation Cu = c. In this method, a decomposition C = F N is found for the non-singular matrix C such that F is non-singular and (F 1 N ) &lt; 1.
Reference: [4] <author> J. Gorman and A. O. Hero, </author> <title> "Lower bounds for parametric estimation with constraints," </title> <journal> IEEE Trans. on Inform. Theory, </journal> <month> Nov. </month> <year> 1990. </year>
Reference: [5] <author> A. O. Hero and L. Shao, </author> <title> "Information analysis of single photon computed tomography with count losses," </title> <journal> IEEE Trans. on Medical Imaging, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 117-127, </pages> <month> June </month> <year> 1990. </year>
Reference: [6] <author> A. O. Hero and J. A. Fessler, </author> <title> "On the convergence of the EM algorithm," </title> <note> Technical Report in prep., Comm. and Sig. Proc. </note> <institution> Lab. (CSPL), Dept. EECS, University of Michigan, </institution> <address> Ann Arbor, </address> <month> April </month> <year> 1992. </year>
Reference: [7] <author> A. O. Hero, </author> <title> "A Cramer-Rao type lower bound for essentially unbiased parameter estimation," </title> <institution> MIT Lincoln Laboratory, Lexington, Mass., </institution> <type> Technical Rep. 890, </type> <note> (3 January 1992). DTIC AD-A246666. </note>
Reference-contexts: We are also developing analogous recursive algorithms to sucessively approximate generalized matrix CR bounds, such as those developed in <ref> [7] </ref>, for biased estimation. 11
Reference: [8] <author> R. A. Horn and C. R. Johnson, </author> <title> Matrix Analysis, </title> <address> Cambridge, </address> <year> 1985. </year>
Reference-contexts: Since I F 1 2 F Y F 1 2 is similar to I F 1 F Y , it follows that the eigenvalues of I F 1 F Y lie in [0; 1) <ref> [8, Corollary 1.3.4] </ref>. <p> Since I F 1 2 F Y F 1 2 is similar to I F 1 F Y , it follows that the eigenvalues of I F 1 F Y lie in [0; 1) [8, Corollary 1.3.4]. Thus, applying the matrix form of the geometric series <ref> [8, Corollary 5.6.16] </ref>: B = [F Y ] 1 = [F (F F Y )] 1 = k=0 ! This infinite series expression for the unbiased n fi n CR bound B is the basis for the matrix recursion given in the following theorem.
Reference: [9] <author> I. A. Ibragimov and R. Z. Has'minskii, </author> <title> Statistical estimation: Asymptotic theory, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Assume that for each 2 fi, P is absolutely continuous with respect to a dominating measure so that for each there exists a density function f (y; ) = dP (y)=d for Y. The family of densities ff Y (y; )g 2fi is said to be a regular family <ref> [9] </ref> if fi is an open subset of IR p and: 1) f Y (y; ) is a continuous function on fi for -almost all y; 2) ln f (Y; ) is mean-square differentiable in ; and 3) r ln f (Y; ) is mean-square continuous in . <p> Then the covariance matrix of ^ satisfies the matrix CR lower bound <ref> [9] </ref>: cov ( ^ ) B () = F 1 In (1) F Y () is the assumed non-singular n fi n Fisher information matrix associated with the measurements Y: def Under the additional assumption that the mixed partials @ 2 i j f Y (Y; ), i; j = 1
Reference: [10] <author> S. Kullback, </author> <title> Information Theory and Statistics, </title> <publisher> Dover, </publisher> <year> 1978. </year>
Reference-contexts: Note that, under the assumption that exchange of order of differentiation and expectation is justified <ref> [10, Sec. 2.6] </ref>: F XjY () = E r 2 fi fl i fi fl where H (u; v) def = E v flog f XjY (XjY; u)jY = yg.
Reference: [11] <author> A. R. Kuruc, </author> <title> "Lower bounds on multiple-source direction finding in the presence of direction-dependent antenna-array-calibration errors," </title> <type> Technical Report 799, </type> <institution> M.I.T. Lincoln Laboratory, </institution> <month> Oct., </month> <year> 1989. </year>
Reference-contexts: The upper left hand p fi p submatrix of the n fi n inverse Fisher information matrix F 1 Y provides the CR lower bound for these parameter estimates. Equivalently, the first p columns of F 1 Y provide this CR bound. The method of sequential partitioning <ref> [11] </ref> for computing the upper left p fi p submatrix of F 1 Y and Cholesky based Gaussian elimination techniques [3] for computing the p first columns of F 1 Y are efficient direct methods for obtaining the CR bound but require O (n 3 ) floating point operations. <p> for the partitioned matrix inverse [3] this submatrix can be expressed in terms of the partition elements of F Y yielding the following equivalent form for the unbiased CR bound: cov ( ^ ) F 11 F T 22 F 12 : (6) By using the method of sequential partitioning <ref> [11] </ref>, the right hand side of (6) could be computed with O (n 3 ) floating point operations.
Reference: [12] <author> T. A. Louis, </author> <title> "Finding the observed information matrix when using the EM algorithm," </title> <journal> J. Royal Statistical Society, Ser. B, </journal> <volume> vol. 44, no. 2, </volume> <pages> pp. 226-233, </pages> <year> 1982. </year>
Reference-contexts: The basis for the matrix recursion of Theorem 1 is the geometric series (7). A geometric series approach was also employed in <ref> [12, Section 5] </ref> to develop a method to speed up the asymptotic convergence of the EM parameter estimation algorithm.
Reference: [13] <author> M. I. Miller, D. L. Snyder, and T. R. Miller, </author> <title> "Maximum-likelihood reconstruction for single photon emission computed tomography," </title> <journal> IEEE Trans. Nuclear Science, </journal> <volume> vol. 32, </volume> <pages> pp. 769-778, </pages> <month> Feb. </month> <year> 1985. </year>
Reference: [14] <author> J. M. Ortega and W. C. Rheinboldt, </author> <title> Iterative Solution of Nonlinear Equations in Several Variables, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Let (A) denote the spectral radius, i.e. the maximum magnitude eigenvalue, of A. If (A) &lt; 1 then v i converges to zero and the asymptotic rate of convergence increases as the root convergence factor (A) decreases <ref> [14] </ref>. 2.2 The CR Lower Bound Let ^ = ^ (Y) be an unbiased estimator of 2 fi, and assume that the densities ff Y (y; g 2fi are a regular family.
Reference: [15] <author> L. A. Shepp and Y. Vardi, </author> <title> "Maximum likelihood reconstruction for emission tomography," </title> <journal> IEEE Trans. on Medical Imaging, </journal> <volume> vol. MI-1, No. 2, </volume> <pages> pp. 113-122, </pages> <month> Oct. </month> <year> 1982. </year>
Reference-contexts: The paper concludes with an implementation of the recursive algorithm for bounding the minimum achievable error of reconstruction for a small region of interest (ROI) in an image reconstruction problem arising in emission computed tomography. By using the complete data of the standard EM algorithm for PET reconstruction <ref> [15] </ref>, F X is diagonal and the implementation of the CR bound algorithm is very simple.
Reference: [16] <author> M. Usman and A. O. Hero, </author> <title> "Algebraic versus statistical optimization of convergence rates for recursive CR bound algorithms," </title> <type> Technical Report 298, </type> <institution> Communications and Signal Processing Laboratory, Dept. of EECS, The University of Michigan, </institution> <address> Ann Arbor, 48109-2122, </address> <month> Jan. </month> <year> 1993. </year> <month> 12 </month>
Reference-contexts: While a purely algebraic approach to this restricted class of iterations can easily be adopted <ref> [16] </ref>, the CR bound setting allows us to exploit additional properties of Fisher information matrices arising from the statistical model. Specifically, we formulate the parameter estimation problem in a complete data incomplete data setting and apply a version of the "data processing theorem" [1] for Fisher information matrices.
References-found: 16

