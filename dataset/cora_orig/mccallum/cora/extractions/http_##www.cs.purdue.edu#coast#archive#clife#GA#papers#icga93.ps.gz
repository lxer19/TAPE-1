URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/icga93.ps.gz
Refering-URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/
Root-URL: http://www.cs.purdue.edu
Title: Optimal Mutation Rates in Genetic Search  
Author: Thomas Back 
Address: D-44221 Dortmund Germany  
Affiliation: Department of Computer Science University of Dortmund  
Abstract: The optimization of a single bit string by means of iterated mutation and selection of the best (a (1+1)-Genetic Algorithm) is discussed with respect to three simple fitness functions: The counting ones problem, a standard binary encoded integer, and a Gray coded integer optimization problem. A mutation rate schedule that is optimal with respect to the success probability of mutation is presented for each of the objective functions, and it turns out that the standard binary code can hamper the search process even in case of unimodal objective functions. While normally a mutation rate of 1=l (where l denotes the bit string length) is recommendable, our results indicate that a variation of the mutation rate is useful in cases where the fitness function is a multimodal pseudo-boolean function, where multimodality may be caused by the objective function as well as the encoding mechanism.
Abstract-found: 1
Intro-found: 1
Reference: <author> Antamoshkin, A. N., V. N. Saraev, and E. S. </author> <month> Se-menkin </month> <year> (1990). </year> <title> Optimization of unimodal monotone pseudoboolean functions. </title> <type> Kybernetika 26 (5), </type> <pages> 432-442. </pages>
Reference: <author> Back, T. </author> <year> (1992a). </year> <title> The interaction of mutation rate, selection, and self-adaptation within a genetic algorithm. </title> <booktitle> In Manner and Manderick (1992), </booktitle> <pages> pp. 85-94. </pages>
Reference-contexts: In the former case, maximizing the success probability also maximizes the convergence velocity, i.e. the expectation value of the improvement per generation (see <ref> (Back 1992a) </ref> for an in-depth analysis of convergence velocity). <p> i=1 was analyzed independently by Muhlenbein and Back, resulting in the approximation p + presented by Muhlenbein (see (Muhlenbein 1992)) and the exact expression p + f (a) X i p i (1 p) f (a)i lf (a) X j p j (1 p) lf (a)j presented by Back (see <ref> (Back 1992a) </ref>). The optimal mutation rate p fl , such that p + f (a) (p) is maximized for p = p fl , is approximated by Muhlenbein to a value of p fl (f (a)) 1 (f (a)=l) 1=(lf (a)) 1=l (8) (denoted Appr. (A) in figure 1).
Reference: <author> Back, T. </author> <year> (1992b). </year> <title> Self-Adaptation in Genetic Algorithms. </title> <editor> In F. J. Varela and P. Bourgine (Eds.), </editor> <booktitle> Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> pp. 263-271. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: For the hard case of a multimodal fitness function (where multimodality may be caused by either the de coding function, the objective function, or both) the results reported here may be interpreted as an explanation of the usefulness of a self-adaptation mechanism for mutation rates as described in <ref> (Back 1992b) </ref>, where a remarkable diversity of mutation rates exists in a population of individuals. Further investigations on this mechanism are necessary in order to evaluate its general usefulness. Acknowledgements The author gratefully acknowledges support by the DFG (Deutsche Forschungsgemeinschaft), grant Schw 361/5-1.
Reference: <author> Back, T. and H.-P. </author> <title> Schwefel (1993). An overview of evolutionary algorithms for parameter optimization. </title> <booktitle> Evolutionary Computation 1 (1), </booktitle> <pages> 1-23. </pages>
Reference-contexts: 1 INTRODUCTION Genetic Algorithms (GAs) (Holland 1975) are the most prominent, widely used representatives of Evolutionary Algorithms, a class of probabilistic search algorithms based on the model of organic evolution (see <ref> (Back and Schwefel 1993) </ref> for an overview of Evolutionary Algorithms). Basic components of all Evolutionary Algorithms are a population of individuals, each of which represents a search point in the space of potential solutions to a given optimization problem, and random operators that are intended to model mutation and selection.
Reference: <author> Bethke, A. D. </author> <year> (1981). </year> <title> Genetic algorithms as function optimizers. </title> <type> Ph. D. thesis, </type> <institution> University of Michigan. Diss. Abstr. </institution> <note> Int. 41(9), 3503B, University Microfilms No. 8106101. </note>
Reference-contexts: b i = a i ; if i = 1 (3) Indicated by several researchers, the main advantage of a Gray code is seen in the fact that it maps Eu-clidean neighborhoods into Hamming neighborhoods due to the representation of adjacent integers by bit strings of Hamming distance one (see <ref> (Bethke 1981) </ref>, pp. 100-104). This was supported by empirical comparisons between standard code and Gray code, indicating statistically significant advantages for the latter (see e.g. (Caruna and Schaffer 1988)). Gray code is the default mechanism in the important public domain im plementation of (Grefenstette 1987).
Reference: <author> Caruna, R. A. and J. D. </author> <title> Schaffer (1988). Representation and hidden bias: Gray vs. binary coding for genetic algorithms. </title> <editor> In J. Laird (Ed.), </editor> <booktitle> Proceedings of the 5th International Conference on Machine Learning, </booktitle> <pages> pp. 153-161. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: This was supported by empirical comparisons between standard code and Gray code, indicating statistically significant advantages for the latter (see e.g. <ref> (Caruna and Schaffer 1988) </ref>). Gray code is the default mechanism in the important public domain im plementation of (Grefenstette 1987). The impact of the highly nonlinear binary representation on the search process, however, was not investigated in a systematical way after the general acceptance of a Gray code.
Reference: <author> Fogarty, T. C. </author> <year> (1989). </year> <title> Varying the probability of mutation in the genetic algorithm. </title> <booktitle> In Schaffer (1989), </booktitle> <pages> pp. 104-109. </pages>
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: a binary alphabet is supported by the fact that this maximizes the total number of schemata available for processing, i.e. consideration of the schema theorem, the building block hypothesis, and a minimal alpha bet are seen as the main design criteria for applying a GA to an optimization problem (see <ref> (Goldberg 1989) </ref>, pp. 28-42, pp. 80-82).
Reference: <author> Goodman, R. </author> <year> (1988). </year> <title> Introduction to Stochastic Models. </title> <publisher> The Benjamin/Cummings Publishing Company, </publisher> <address> Menlo Park, CA. </address>
Reference-contexts: The expected time resulting from the alternative approximation by Back can only be calculated numerically by means of Markov chain methods (see <ref> (Goodman 1988) </ref>, pp. 157-162). For l 100 the resulting time to absorption (i.e. un til the algorithm has found the optimum) is shown for both approximations in the right part of figure 1.
Reference: <author> Grefenstette, J. J. </author> <year> (1986). </year> <title> Optimization of control parameters for genetic algorithms. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics SMC-16 (1), </journal> <pages> 122-128. </pages>
Reference-contexts: fixed length l, i.e. a 2 IB l where IB = f0; 1g. (2) Mutation is a bit reversal event that occurs with small probability p m per bit (common settings are p m 0:001 (De Jong 1975), p m 2 [0:005; 0:01] (Schaffer et al. 1989), p m 0:01 <ref> (Grefenstette 1986) </ref>). (3) The algorithm uses a recombination (crossover ) operator that exchanges arbitrary substrings between two individuals with probability p c (e.g., p c 0:6 (De Jong 1975), p c 2 [0:75; 0:95] (Schaf-fer et al. 1989), p c 0:95 (Grefenstette 1986)). <p> [0:005; 0:01] (Schaffer et al. 1989), p m 0:01 <ref> (Grefenstette 1986) </ref>). (3) The algorithm uses a recombination (crossover ) operator that exchanges arbitrary substrings between two individuals with probability p c (e.g., p c 0:6 (De Jong 1975), p c 2 [0:75; 0:95] (Schaf-fer et al. 1989), p c 0:95 (Grefenstette 1986)).
Reference: <author> Grefenstette, J. J. </author> <year> (1987). </year> <title> A User's Guide to GENESIS. </title> <address> Washington, D. C.: </address> <note> Navy Center for Applied Research in Artificial Intelligence. </note>
Reference-contexts: This was supported by empirical comparisons between standard code and Gray code, indicating statistically significant advantages for the latter (see e.g. (Caruna and Schaffer 1988)). Gray code is the default mechanism in the important public domain im plementation of <ref> (Grefenstette 1987) </ref>. The impact of the highly nonlinear binary representation on the search process, however, was not investigated in a systematical way after the general acceptance of a Gray code.
Reference: <author> Hesser, J. and R. </author> <title> Manner (1991). Towards an optimal mutation probability in genetic algorithms. </title> <editor> In H.-P. Schwefel and R. Manner (Eds.), </editor> <booktitle> Parallel Problem Solving from Nature | Proceedings 1st Workshop PPSN I, Volume 496 of Lecture Notes in Computer Science, </booktitle> <pages> pp. 23-32. </pages> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference: <author> Hoffmeister, F. and T. </author> <title> Back (1992). Genetic algorithms and evolution strategies: Similarities and differences. Report of the Systems Analysis Research Group SYS-1/92, </title> <institution> University of Dortmund, Department of Computer Science. </institution>
Reference-contexts: If the number of crossover points is much smaller than the dimension of the objective function (which is quite usual), the effect of crossover is expected to be small. Preliminary experimental investigations seem to confirm this suspicion (see <ref> (Hoffmeister and Back 1992) </ref>, pp. 64-66).
Reference: <author> Holland, J. H. </author> <year> (1975). </year> <booktitle> Adaptation in natural and artificial systems. </booktitle> <address> Ann Arbor, MI: </address> <publisher> The University of Michigan Press. </publisher>
Reference-contexts: 1 INTRODUCTION Genetic Algorithms (GAs) <ref> (Holland 1975) </ref> are the most prominent, widely used representatives of Evolutionary Algorithms, a class of probabilistic search algorithms based on the model of organic evolution (see (Back and Schwefel 1993) for an overview of Evolutionary Algorithms). <p> The fundamental Schema Theorem explains the power of GAs by an exponential growth of relatively short, useful substrings | so-called building blocks | and their accumulation and concatenation to useful substrings of increasing length <ref> (Holland 1975) </ref>. <p> Second, the formal description helps to identify and characterize special mappings which are needed in the remainder of this paper. While Holland pointed out how to apply the GA to parameter optimization problems of the form f : IR n ! IR (see <ref> (Holland 1975) </ref>, pp. 54-58), K. De Jong was the first who realized this important application as an optimization algorithm (De Jong 1975).
Reference: <author> De Jong, K. A. </author> <year> (1975). </year> <title> An analysis of the behaviour of a class of genetic adaptive systems. </title> <type> Ph. D. thesis, </type> <institution> University of Michigan. Diss. Abstr. </institution> <note> Int. 36(10), 5140B, University Microfilms No. 76-9381. </note>
Reference-contexts: (see e.g. (Holland 1975; Goldberg 1989)): (1) Individuals a are represented as bit strings of fixed length l, i.e. a 2 IB l where IB = f0; 1g. (2) Mutation is a bit reversal event that occurs with small probability p m per bit (common settings are p m 0:001 <ref> (De Jong 1975) </ref>, p m 2 [0:005; 0:01] (Schaffer et al. 1989), p m 0:01 (Grefenstette 1986)). (3) The algorithm uses a recombination (crossover ) operator that exchanges arbitrary substrings between two individuals with probability p c (e.g., p c 0:6 (De Jong 1975), p c 2 [0:75; 0:95] (Schaf-fer et <p> m per bit (common settings are p m 0:001 <ref> (De Jong 1975) </ref>, p m 2 [0:005; 0:01] (Schaffer et al. 1989), p m 0:01 (Grefenstette 1986)). (3) The algorithm uses a recombination (crossover ) operator that exchanges arbitrary substrings between two individuals with probability p c (e.g., p c 0:6 (De Jong 1975), p c 2 [0:75; 0:95] (Schaf-fer et al. 1989), p c 0:95 (Grefenstette 1986)). <p> While Holland pointed out how to apply the GA to parameter optimization problems of the form f : IR n ! IR (see (Holland 1975), pp. 54-58), K. De Jong was the first who realized this important application as an optimization algorithm <ref> (De Jong 1975) </ref>.
Reference: <editor> Manner, R. and B. Manderick (Eds.) </editor> <year> (1992). </year> <title> Parallel Problem Solving from Nature 2. </title> <publisher> Elsevier, Amster-dam. </publisher>
Reference: <author> Muhlenbein, H. </author> <year> (1992). </year> <title> How genetic algorithms really work: I. mutation and hillclimbing. </title> <booktitle> In Manner and Manderick (1992), </booktitle> <pages> pp. 15-25. </pages>
Reference-contexts: objective functions as indicated above. 2.1 COUNTING ONES The simple counting problem f : IB l ! f0; : : :; lg: f (a 1 : : : a l ) = i=1 was analyzed independently by Muhlenbein and Back, resulting in the approximation p + presented by Muhlenbein (see <ref> (Muhlenbein 1992) </ref>) and the exact expression p + f (a) X i p i (1 p) f (a)i lf (a) X j p j (1 p) lf (a)j presented by Back (see (Back 1992a)). <p> Assuming an initial string with f (a) = bl=2c, Muhlen-bein derives an expected time hT (p fl )i e l ln (l=2) for p fl = 1=l, and he indicates that the O (l ln l) estimate is valid for any unimodal pseudoboolean function <ref> (Muhlenbein 1992) </ref>. The expected time resulting from the alternative approximation by Back can only be calculated numerically by means of Markov chain methods (see (Goodman 1988), pp. 157-162).
Reference: <editor> Schaffer, J. D. (Ed.) </editor> <booktitle> (1989). Proceedings of the 3rd International Conference on Genetic Algorithms and Their Applications. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: a are represented as bit strings of fixed length l, i.e. a 2 IB l where IB = f0; 1g. (2) Mutation is a bit reversal event that occurs with small probability p m per bit (common settings are p m 0:001 (De Jong 1975), p m 2 [0:005; 0:01] <ref> (Schaffer et al. 1989) </ref>, p m 0:01 (Grefenstette 1986)). (3) The algorithm uses a recombination (crossover ) operator that exchanges arbitrary substrings between two individuals with probability p c (e.g., p c 0:6 (De Jong 1975), p c 2 [0:75; 0:95] (Schaf-fer et al. 1989), p c 0:95 (Grefenstette 1986)).
Reference: <author> Schaffer, J. D., R. A. Caruana, L. J. Eshelman, and R. </author> <title> Das (1989). A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <booktitle> In Schaffer (1989), </booktitle> <pages> pp. 51-60. </pages>
Reference-contexts: a are represented as bit strings of fixed length l, i.e. a 2 IB l where IB = f0; 1g. (2) Mutation is a bit reversal event that occurs with small probability p m per bit (common settings are p m 0:001 (De Jong 1975), p m 2 [0:005; 0:01] <ref> (Schaffer et al. 1989) </ref>, p m 0:01 (Grefenstette 1986)). (3) The algorithm uses a recombination (crossover ) operator that exchanges arbitrary substrings between two individuals with probability p c (e.g., p c 0:6 (De Jong 1975), p c 2 [0:75; 0:95] (Schaf-fer et al. 1989), p c 0:95 (Grefenstette 1986)).
Reference: <author> Wright, A. H. </author> <year> (1991). </year> <title> Genetic algorithms for real parameter optimization. </title> <editor> In G. J. E. Rawlins (Ed.), </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pp. 205-218. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: simplicity we omit the index which denotes the segment number) to the simple code (a 1 : : : a l x ) by means of a mapping fl 1 : IB l x ! IB l x such that 8i 2 f1; : : :; l x g (see <ref> (Wright 1991) </ref>): a i = j=1 where denotes addition modulo 2. Conversely, the standard binary code can be converted to Gray code by the mapping fl, where 8i 2 f1; : : : ; l x g (Wright 1991): b i = a i ; if i = 1 (3) Indicated <p> x such that 8i 2 f1; : : :; l x g (see <ref> (Wright 1991) </ref>): a i = j=1 where denotes addition modulo 2. Conversely, the standard binary code can be converted to Gray code by the mapping fl, where 8i 2 f1; : : : ; l x g (Wright 1991): b i = a i ; if i = 1 (3) Indicated by several researchers, the main advantage of a Gray code is seen in the fact that it maps Eu-clidean neighborhoods into Hamming neighborhoods due to the representation of adjacent integers by bit strings of Hamming distance one <p> This is likely to be still valid when crossover is introduced, since one-point crossover in case of an encoded parameter optimization problem corresponds to a crossover at a segment boundary plus a mutation-like perturbation of the parameter within whose segment the crossover position is located <ref> (Wright 1991) </ref>. If the number of crossover points is much smaller than the dimension of the objective function (which is quite usual), the effect of crossover is expected to be small. Preliminary experimental investigations seem to confirm this suspicion (see (Hoffmeister and Back 1992), pp. 64-66).
References-found: 20

