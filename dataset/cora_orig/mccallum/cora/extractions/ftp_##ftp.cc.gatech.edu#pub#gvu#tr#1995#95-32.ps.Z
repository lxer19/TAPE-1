URL: ftp://ftp.cc.gatech.edu/pub/gvu/tr/1995/95-32.ps.Z
Refering-URL: http://www.cs.gatech.edu/gvu/reports/1995/
Root-URL: 
Title: Interactive Model-Based Image Understanding  
Author: Daryl T. Lawton Warren F. Gardner 
Abstract: This paper describes a general architecture for an interactive model-based vision system. A human specifies a limited amount of information which establishes a context for autonomous interpretation of images. Object models are described by constraints specifying necessary geometrical properties and relationships between objects. The use of constraints allows for flexible object in-stantiation. A user can indicate an object in a scene and this directs perceptual processing routines as well as constraining future object instantiations. This interactive model-based concept has been applied to the domain of vehicle tracking, and this paper concludes with several processing examples from this domain.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Borning, </author> <title> "The programming language aspects of thinglab, a constraint oriented simulation laboratory," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 3, no. 4, </volume> <editor> p. 353ff, </editor> <year> 1981. </year>
Reference-contexts: Thus, in addition to describing its shape, the model of a car needs to include that a car is acted on by gravity and will have a preferred type of orientation and attachment with respect to the ground surface. Object models are described by sets of constraints <ref> [1, 3, 6, 8] </ref> which must be satisfied. A simple constraint is that the value of some parameter associated with an object model is bounded. More complicated constraints deal with relations between objects.
Reference: [2] <author> W. F. Gardner and D. T. Lawton, </author> <title> "Interactive model-based vehicle tracking," </title> <type> Tech. Rep. </type> <institution> GIT-GVU-95-33, Graphics, Visualization, and Usability Center, Georgia Institute of Technology, </institution> <address> At-lanta, GA, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: The information derived from this tracker can be used to determine a 3D road model, as well as refine the attributes of the instantiated vehicle model through temporal modeling with the Kalman Filter. This tracker is discussed in more detail in <ref> [2] </ref>. 5.1 Feature Extraction from a Model The local translation tracker requires features which can be matched in successive images. The type of features used are conventional masks of image pixels, extracted from distinct areas of the image. <p> The additional edge error 11 sums are added to the error sum for each possible position, and the maximum value is chosen as the position of the vehicle. A more detailed discussion of the vehicle motion model is given in <ref> [2] </ref>. 5.2 Locally Planar Motion Often the motion of a vehicle is restricted to a plane determined by the local road or surface orientation. In this case, it is possible to associate 3D information with extracted image features.
Reference: [3] <author> D. T. Lawton, </author> <title> "Constraint-based inference from image motion," </title> <booktitle> in Proceedings of AAAI-80, 1980. </booktitle> <address> Stanford, CA. </address>
Reference-contexts: Thus, in addition to describing its shape, the model of a car needs to include that a car is acted on by gravity and will have a preferred type of orientation and attachment with respect to the ground surface. Object models are described by sets of constraints <ref> [1, 3, 6, 8] </ref> which must be satisfied. A simple constraint is that the value of some parameter associated with an object model is bounded. More complicated constraints deal with relations between objects.
Reference: [4] <author> D. T. Lawton and W. F. Gardner, </author> <title> "Translational decomposition of flow fields," </title> <booktitle> in Proceedings of the DARPA Image Understanding Workshop, </booktitle> <pages> pp. 697-705, </pages> <address> April 1993. Washington, D.C. </address>
Reference-contexts: A vehicle tracker was constructed based upon this constraint and using the concepts presented 8 9 in <ref> [4] </ref>. A vehicle is subdivided into local regions and each region is treated as if it had undergone purely translational motion. The extraction and grouping of features can be done automatically, but is more efficient and reliable when directed by a vehicle model.
Reference: [5] <author> D. T. Lawton, W. F. Gardner, and J. Kim, </author> <title> "An interactive model based vision system for vehicle tracking," </title> <booktitle> in Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <volume> vol. 3, </volume> <pages> pp. 403-409, </pages> <month> May </month> <year> 1993. </year> <institution> Atlanta, </institution> <address> GA. </address>
Reference-contexts: The approach described here is to develop a model-based vision system that a human can interactively control. The inspiration for this system comes from the interactive vehicle tracking system described in <ref> [5] </ref>. The human is responsible for building a 3D model of the world by instantiating object models. These models are maintained by the vision system and used to constrain future processing.
Reference: [6] <author> W. Leler, </author> <title> Constraint Programming Languages: Their Specification and Generation. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: Thus, in addition to describing its shape, the model of a car needs to include that a car is acted on by gravity and will have a preferred type of orientation and attachment with respect to the ground surface. Object models are described by sets of constraints <ref> [1, 3, 6, 8] </ref> which must be satisfied. A simple constraint is that the value of some parameter associated with an object model is bounded. More complicated constraints deal with relations between objects.
Reference: [7] <author> H. P. Moravec, </author> <title> "Towards automatic visual obstacle avoidance," </title> <booktitle> in Proceedings of the 5th International Joint Conference on Artificial Intelligence, </booktitle> <address> p. 584, </address> <month> August </month> <year> 1977. </year> <month> 17 </month>
Reference-contexts: The type of features used are conventional masks of image pixels, extracted from distinct areas of the image. In the examples shown in this paper, the masks are 9x9 pixel arrays. These features are extracted through the use of the Moravec interest operator <ref> [7] </ref>. The information provided by models is used to direct feature extraction. The local translation tracker estimates the local translation of different portions of the vehicle, thus each portion requires a certain density of features for this estimation.
Reference: [8] <author> J. Mundy, P. Vrobel, and R. Joynson, </author> <title> "Constraint-based modeling," </title> <booktitle> in Proceedings of the DARPA Image Understanding Workshop, </booktitle> <month> May </month> <year> 1989. </year> <institution> Stanford, </institution> <address> CA. </address>
Reference-contexts: Thus, in addition to describing its shape, the model of a car needs to include that a car is acted on by gravity and will have a preferred type of orientation and attachment with respect to the ground surface. Object models are described by sets of constraints <ref> [1, 3, 6, 8] </ref> which must be satisfied. A simple constraint is that the value of some parameter associated with an object model is bounded. More complicated constraints deal with relations between objects.
Reference: [9] <author> C. Ruoff, J. Bowyer, T. Brooks, J. Hanson, K. Holmes, and B. Wilcox, </author> <title> "Autonomous ground vehicles: Control system technology development," </title> <type> tech. rep., </type> <institution> Jet Propulsion Laboratory, Pasadena, </institution> <address> CA, </address> <month> October </month> <year> 1984. </year>
Reference-contexts: Previous work has addressed many of these problems by stressing the importance of telerobotic and interactive systems <ref> [9, 11] </ref>. This is a realistic approach to fielding advanced technology in the short term, and also provides a long term framework for developing autonomous systems.
Reference: [10] <author> M. Sannella, J. Maloney, B. Freeman-Benson, and A. Borning, </author> <title> "Multi-way versus one-way constraints in user interfaces: Experience with the deltablue algorithm," </title> <type> Tech. Rep. </type> <institution> 92-07-05a, Department of Computer Science and Engineering, University of Washington, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: One way this could be accomplished is through the use of an existing constraint satisfaction algorithm such as DeltaBlue <ref> [10] </ref>. The use of multiple cameras would provide valuable 3D information that is unavailable from a single camera. However, the model instantiation and manipulation processes become more involved when dealing with multiple input sources. Multiple input sources also raises problems of camera calibration.
Reference: [11] <author> R. Steeb, S. Cammarata, S. Narain, J. Rothenberg, and W. Giuarla, </author> <title> "Cooperative intelligence for remotely piloted vehicle fleet control, analysis, and simulation," </title> <type> tech. rep., </type> <institution> Rand Corporation, </institution> <address> Santa Monica, CA, </address> <year> 1986. </year> <month> 18 </month>
Reference-contexts: Previous work has addressed many of these problems by stressing the importance of telerobotic and interactive systems <ref> [9, 11] </ref>. This is a realistic approach to fielding advanced technology in the short term, and also provides a long term framework for developing autonomous systems.
References-found: 11

