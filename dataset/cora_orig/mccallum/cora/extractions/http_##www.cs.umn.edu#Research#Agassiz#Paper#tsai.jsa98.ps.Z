URL: http://www.cs.umn.edu/Research/Agassiz/Paper/tsai.jsa98.ps.Z
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/agassiz_pubs.html
Root-URL: http://www.cs.umn.edu
Email: j-tsai1@uiuc.edu yew@cs.umn.edu  
Title: Enhancing Multiple-Path Speculative Execution with Predicate Window Shifting  
Author: Jenn-Yuan Tsai Pen-Chung Yew 
Keyword: instruction level parallelism, speculative execution, predicated execution, VLIW pro cessor architecture.  
Address: Urbana, IL 61801 USA Minneapolis, MN 55455 USA  
Affiliation: Department of Computer Science Department of Computer Science University of Illinois University of Minnesota  
Abstract: Speculative execution has long been used as an approach to exploit instruction level parallelism across basic block boundaries. Most existing speculative execution techniques only support speculating along single control path, and heavily rely on branch prediction to choose the right control path. In this paper, we propose an extended predicated execution mechanism, called predicate shifting, to support speculating along multiple control paths. The predicate shifting mechanism maintains a condition/predicate window for each basic block. With the condition/predicate window, instructions can be guarded by predicates related to current or future branch conditions. The predicate shifting mechanism can reduce the number of required tag bits by shifting conditions/predicates out of the condition/predicate window whenever they are no longer in use. To incorporate the predicate shifting mechanism into a VLIW processor, a new result-buffering structure, call future buffer, is used to buffer uncommitted results and to evaluate predicates. The FIFO structure of the future buffer not only simplifies exception handling but also allows multiple uncommitted writes to the same register. Experimental results show that the predicate shifting mechanism can use predicate tag effectively and achieve 24% performance improvement over the previous predicating mechanism [2] using a small predicate tag. fl This work is supported in part by the National Science Foundation under Grant No. MIP 93-07910, MIP 94-96320, and CDA 9502979; by the U.S. Army Intelligence Center and Fort Huachuca under Contract DABT63-95-C-0127 and ARPA order No. D 346; and by a gift from Intel Corporation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Weslay Publishing Company, </publisher> <address> Massachusetts, </address> <year> 1986. </year>
Reference-contexts: must also be legal to avoid writing to a register or a memory location whose value may be used by instructions on other control paths [18]. 1 A region is a set of basic blocks that includes a entry basic block, which dominates all other basic blocks in the region <ref> [1] </ref>. 2 These restrictions can severely limit the exploitable ILP. Hardware mechanisms to buffer uncommitted results and to handle speculative exceptions can relax such restrictions. To allow speculative instruction movement along multiple control paths, additional hardware is needed to handle future conditions and control dependences. <p> A region is a set of basic blocks that includes an entry basic block which dominates all other basic blocks in the region <ref> [1] </ref>. Similar to [2], tail duplication is performed to make every basic block in a region, except the entry block, having only one predecessor in the control flow graph. To simplify global scheduling and tail duplication, our region formation algorithm will not include loops or function calls inside a region.
Reference: [2] <author> H. Ando, C. Nakanishi, T. Hara, and M. Nakaya. </author> <title> Unconstrained Speculative Execution with Predicated State Buffering. </title> <booktitle> In Proceedings of the 22th International Symposium on Computer Architecture, </booktitle> <pages> pages 126-137, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Without any hardware support, a compiler can only perform limited speculative movement in order to maintain safety and legality of the program execution. To support speculative execution, some result-buffering mechanism for uncommitted results is usually needed. Reordering buffers [7, 16] in superscalar processors and shadow register files <ref> [2, 19, 18] </ref> in VLIW processor provide such result-buffering mechanism for speculative execution. Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. <p> In other words, the control dependences are 1 merely converted to data dependences rather than avoided as in the case of speculative execution. Speculative execution and predicated execution can be used together to support multiple-path speculative execution <ref> [2, 20] </ref>. Predicated execution provides a good mechanism to represent control dependences in different control paths. With the support of result buffering mechanisms, instructions can be speculatively moved and executed before their predicate defining instructions. <p> Predicated execution provides a good mechanism to represent control dependences in different control paths. With the support of result buffering mechanisms, instructions can be speculatively moved and executed before their predicate defining instructions. Recently, Ando et al. <ref> [2] </ref> proposed a predicated state buffering mechanism called predicating which can support multiple-path speculative execution. They show that predicating can gain more speedup than single-path speculative execution. The mechanism, however, requires a unique condition name for each conditional branch in a region 1 . <p> In addition, we present a new result-buffering structure, called future buffer, for VLIW architectures. The future buffer can evaluate the predicate states of uncommitted results according to the run time conditions. Differing from the shadow register files used in <ref> [2, 19, 18] </ref>, the future buffer adopts a first-in, first-out (FIFO) structure to simplify the handling of speculative exceptions and allow multiple uncommitted writes to the same register. In the rest of this paper, we review some previous works in section 2. <p> To support n levels of branch speculation, the processor must provide n shadow register files. This mechanism allows unconstrained speculative execution in a single control path. The predicating mechanism <ref> [2] </ref> uses a similar shadow structure to buffer speculative results from multiple control paths. Each entry of the register file contains a predicate field and two data fileds, one for sequential (committed) value and the other one for speculative value. <p> With the excepting address stored in the source register, the processor can accurately locate the speculative instruction which causes the exception. Boosting [19, 18] and predicating <ref> [2] </ref> also postpone speculative exceptions until the commit point. Instead of saving the excepting address in the destination register, they mark the exception flag in the corresponding shadow register when an exception occurs. <p> The representation of control dependences in boosting is very simple and efficient, but it also restricts the opportunities of exploiting ILP from other control paths. Predicating <ref> [2] </ref> supports speculative execution along multiple control paths. In this scheduling model, instructions from both directions of a conditional branch can be moved above the branch instruction. Predicating mechanism gives each conditional branch in a region a unique condition name. <p> A region is a set of basic blocks that includes an entry basic block which dominates all other basic blocks in the region [1]. Similar to <ref> [2] </ref>, tail duplication is performed to make every basic block in a region, except the entry block, having only one predecessor in the control flow graph. To simplify global scheduling and tail duplication, our region formation algorithm will not include loops or function calls inside a region. <p> Since the condition window can contain both current conditions and future conditions, the compiler can encode the control dependencies of an instruction on future conditions (for speculative execution) as well as on current conditions (for predicated execution). In this mechanism, unlike predicating <ref> [2] </ref>, the predicate tag only contains control dependencies on conditions in current use instead of on all conditions in a region. The width of predicate tag only limits the levels of branch predication and speculation instead of the size of a region. <p> Some basic blocks in the original code have disappeared because all of their instructions have been moved to the predecessor blocks. Also, note some SETC instructions have been moved to the last instruction of their predecessor blocks. 4 Performance Evaluation Ando et al. <ref> [2] </ref> have shown that multiple-path speculative execution through predicating outperforms traditional global scheduling techniques and single-path speculative execution techniques such as boosting [19, 18]. Hence, we only compare the performance of the predicate shifting model with the predicating model. <p> With the support of predicate shifting mechanism, the compiler can fully predicate basic blocks or speculatively move instructions from multiple control paths above the conditional branches they are dependent on. Unlike the previous predicating mechanism <ref> [2] </ref>, this mechanism will not limit the number of conditions in a region and thus can achieve good 24 performance with a small predicate tag.
Reference: [3] <author> P. O. Chang, S. A. Mahlke, W. Y. Chen, N. J. Warter, and W. W. Hwu. </author> <title> IMPACT: An Architectural Framework for Multiple-Instruction-Issue Processors. </title> <booktitle> In Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <pages> pages 266-275, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. In VLIW architectures, compilers use profile information <ref> [5, 3] </ref> to identify the most-frequently executed trace. With branch prediction, compilers or processors can speculatively move or execute instructions along the most-frequently taken control path. <p> The experimental results also shows that, with the support for multiple-path speculative execution, the compiler can effectively exploit ILP across basic block boundaries without relying on profile information. This is a significant improvement over other schemes <ref> [5, 3, 18] </ref>, which can only speculate along one selected control path. This paper also presents a structure, called future buffer, to buffer uncommitted results and to evaluate the predicate state associated with each result.
Reference: [4] <author> R. P. Colwell, R. P. Nix, J. J. O'Donnell, D. B. Papworth, and P. K. Rodman. </author> <title> A VLIW Architecture for a Trace Scheduling Compiler. </title> <booktitle> In Proceedings of Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 180-192, </pages> <month> October </month> <year> 1987. </year> <month> 25 </month>
Reference-contexts: The continuing execution of the program may lead some later non-speculative instruction to read the polluted value. The non-speculative instruction will signal the exception when it reads the polluted value. Colwell et al <ref> [4] </ref> use a NaN (i.e. Not-A-Number in the IEEE floating point standard) to represent the polluted result of a speculative instruction which causes exception. The use of a NaN by a non-speculative instruction will signal the exception. There are several shortcomings with this method.
Reference: [5] <author> J. A. Fisher. </author> <title> Trace Scheduling: A Technique for Global Microcode Compaction. </title> <journal> IEEE Trans--actions on Computers, </journal> <volume> C-30(7):478-490, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. In VLIW architectures, compilers use profile information <ref> [5, 3] </ref> to identify the most-frequently executed trace. With branch prediction, compilers or processors can speculatively move or execute instructions along the most-frequently taken control path. <p> Profiling information is very important in traditional global instruction scheduling techniques such as trace scheduling <ref> [5] </ref>, and in single-path speculative execution supported by boosting. They rely on the profile information to select the most-frequently executed control path for performing speculative instruction movement. Optimizing one control path, however, may affect the performance of the other control paths. <p> The experimental results also shows that, with the support for multiple-path speculative execution, the compiler can effectively exploit ILP across basic block boundaries without relying on profile information. This is a significant improvement over other schemes <ref> [5, 3, 18] </ref>, which can only speculate along one selected control path. This paper also presents a structure, called future buffer, to buffer uncommitted results and to evaluate the predicate state associated with each result.
Reference: [6] <author> P. Y. T. Hsu and E. S. Davidson. </author> <title> Highly Concurrent Scalar Processing. </title> <booktitle> In Proceedings of the 13th International Symposium on Computer Architecture, </booktitle> <pages> pages 386-395, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: To improve performance for processors with a high issue rate on programs with a low prediction accuracy, one may consider using multiple-path speculative execution to exploit ILP from all control paths. Predicated execution [11, 12, 15] or guarded execution <ref> [6, 13] </ref> has been used as a way to eliminate branches from instruction streams. In predicated execution, a conditional branch is converted into a predicate defining instruction. Instructions which are control dependent on the conditional branch are then guarded by the predicate.
Reference: [7] <author> Mike Johnson. </author> <title> Superscalar Microprocessor Design. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1991. </year>
Reference-contexts: Without any hardware support, a compiler can only perform limited speculative movement in order to maintain safety and legality of the program execution. To support speculative execution, some result-buffering mechanism for uncommitted results is usually needed. Reordering buffers <ref> [7, 16] </ref> in superscalar processors and shadow register files [2, 19, 18] in VLIW processor provide such result-buffering mechanism for speculative execution. Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. <p> Reordering buffers [7, 16] in superscalar processors and shadow register files [2, 19, 18] in VLIW processor provide such result-buffering mechanism for speculative execution. Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table <ref> [7] </ref> is often used to predict branch results dynamically. In VLIW architectures, compilers use profile information [5, 3] to identify the most-frequently executed trace. With branch prediction, compilers or processors can speculatively move or execute instructions along the most-frequently taken control path. <p> In other words, the maximum distance of the speculative execution is limited by the size of the future buffer. The FIFO mechanism of the future buffer is very similar to the reorder buffer <ref> [7, 16] </ref> used in superscalar processors. The main disadvantage of a reorder buffer is that it requires associative hardware to provide later instructions with the uncommitted results produced by earlier instructions. The hardware complexity and its associated latency often limit the size of a reorder buffer in superscalar processors [7]. <p> The main disadvantage of a reorder buffer is that it requires associative hardware to provide later instructions with the uncommitted results produced by earlier instructions. The hardware complexity and its associated latency often limit the size of a reorder buffer in superscalar processors <ref> [7] </ref>. The design of the future buffer eliminates the need of the associative hardware with the assistance of the compiler. Since instruction scheduling is done at compile time, the compiler knows the register dependency and the distance between instructions.
Reference: [8] <author> M. S. Lam and R. P. Wilson. </author> <title> Limits of Control Flow on Parallelism. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 46-57, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Superscalar and VLIW architectures have become dominant in high performance processor design. They both provide multiple instruction decoders and functional units to exploit instruction level parallelism (ILP). Previous studies <ref> [21, 8] </ref> have shown that the ILP within a basic block is very limited. Thus, exploiting ILP across basic block boundaries is essential to achieve higher performance.
Reference: [9] <author> J. K. F. Lee and A. J. Smith. </author> <title> Branch Prediction Strategies and Branch Target Buffer Design. </title> <journal> IEEE Computer, </journal> <volume> 17(1) </volume> <pages> 6-22, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: To support speculative execution, some result-buffering mechanism for uncommitted results is usually needed. Reordering buffers [7, 16] in superscalar processors and shadow register files [2, 19, 18] in VLIW processor provide such result-buffering mechanism for speculative execution. Besides result-buffering, most existing speculative execution techniques also adopt branch prediction <ref> [9] </ref>. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. In VLIW architectures, compilers use profile information [5, 3] to identify the most-frequently executed trace. With branch prediction, compilers or processors can speculatively move or execute instructions along the most-frequently taken control path. <p> All instructions, except branch instructions, have the same latencies as those of R4000. For branch instructions, we assume a branch target buffer <ref> [9] </ref> is used and all branch targets except indirect jumps will hit the branch target buffer. Note that branch prediction is not essentialin our model because a conditional branch instruction is always executed at least one cycle after the SETC instruction that defines the branch condition.
Reference: [10] <author> S. A. Mahlke, W. Y. Chen, B. R. Rau W. W. Hwu, and M. S. Schlansker. </author> <title> Sentinel Scheduling for VLIW and Superscalar Processors. </title> <booktitle> In Proceedings of Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 238-247, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: There are several shortcomings with this method. First, it is not guaranteed to signal an exception if the polluted result is conditionally used. Also, it is very difficult to locate and re-execute the original instruction which causes the exception. Mahlke et al. proposed a sentinel scheduling model <ref> [10] </ref> to accurately detect and report all exceptions caused by speculative instructions. Sentinel scheduling model divides each speculative instruction into two parts, the non-excepting part that performs the actual speculative operation, and the sentinel part that signals an exception, if necessary.
Reference: [11] <author> S. A. Mahlke, R. E. Hank D. C. Lin, W. Y. Chen, and R. A. Bringmann. </author> <title> Effective Compiler Support for Predicated Execution Using the Hyperblock. </title> <booktitle> In Proceedings of MICRO-25, </booktitle> <pages> pages 45-54, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: To improve performance for processors with a high issue rate on programs with a low prediction accuracy, one may consider using multiple-path speculative execution to exploit ILP from all control paths. Predicated execution <ref> [11, 12, 15] </ref> or guarded execution [6, 13] has been used as a way to eliminate branches from instruction streams. In predicated execution, a conditional branch is converted into a predicate defining instruction. Instructions which are control dependent on the conditional branch are then guarded by the predicate.
Reference: [12] <author> S. A. Mahlke, R. E. Hank, J. E. McCormick, D. I. August, and W. W. Hwu. </author> <title> A Comparison of Full and Partial Predicated Execution Support for ILP Processors. </title> <booktitle> In Proceedings of the 22th International Symposium on Computer Architecture, </booktitle> <pages> pages 138-149, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: To improve performance for processors with a high issue rate on programs with a low prediction accuracy, one may consider using multiple-path speculative execution to exploit ILP from all control paths. Predicated execution <ref> [11, 12, 15] </ref> or guarded execution [6, 13] has been used as a way to eliminate branches from instruction streams. In predicated execution, a conditional branch is converted into a predicate defining instruction. Instructions which are control dependent on the conditional branch are then guarded by the predicate.
Reference: [13] <author> D. N. Pnevmatikatos and G. S. Sohi. </author> <title> Guarded Execution and Branch Prediction in Dynamic ILP Processors. </title> <booktitle> In Proceedings of the 21th International Symposium on Computer Architecture, </booktitle> <pages> pages 120-129, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: To improve performance for processors with a high issue rate on programs with a low prediction accuracy, one may consider using multiple-path speculative execution to exploit ILP from all control paths. Predicated execution [11, 12, 15] or guarded execution <ref> [6, 13] </ref> has been used as a way to eliminate branches from instruction streams. In predicated execution, a conditional branch is converted into a predicate defining instruction. Instructions which are control dependent on the conditional branch are then guarded by the predicate.
Reference: [14] <author> J. Ferrante R. Cytron and B. K. Rosen. </author> <title> Efficiently Computing Static Single assignment Form and the Control Dependence Graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: The store data can be committed and 5 We name this instruction PHI because it performs a similar function of the OE-function used in the Static Single Assignment (SSA) form <ref> [14] </ref> 14 written back to the data cache only when the corresponding entry in the future buffer is committed. Another difference between the store buffer and the future buffer is that the store buffer uses associative hardware to check the data dependencies between load and store instructions.
Reference: [15] <author> B. Ramakrishna Rau, D. W. L. Yen, W. Yen, and R. A. Towle. </author> <title> The Cydra 5 departmental Supercomputer. </title> <journal> IEEE Computer, </journal> <volume> 22(1) </volume> <pages> 12-35, </pages> <month> January </month> <year> 1989. </year> <month> 26 </month>
Reference-contexts: To improve performance for processors with a high issue rate on programs with a low prediction accuracy, one may consider using multiple-path speculative execution to exploit ILP from all control paths. Predicated execution <ref> [11, 12, 15] </ref> or guarded execution [6, 13] has been used as a way to eliminate branches from instruction streams. In predicated execution, a conditional branch is converted into a predicate defining instruction. Instructions which are control dependent on the conditional branch are then guarded by the predicate.
Reference: [16] <author> J. E. Smith and A. R. Pleszkun. </author> <title> Implementation of Precise Interrupts in Pipelined Processors. </title> <booktitle> In Proceedings of the 12th International Symposium on Computer Architecture, </booktitle> <pages> pages 36-44, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: Without any hardware support, a compiler can only perform limited speculative movement in order to maintain safety and legality of the program execution. To support speculative execution, some result-buffering mechanism for uncommitted results is usually needed. Reordering buffers <ref> [7, 16] </ref> in superscalar processors and shadow register files [2, 19, 18] in VLIW processor provide such result-buffering mechanism for speculative execution. Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. <p> In other words, the maximum distance of the speculative execution is limited by the size of the future buffer. The FIFO mechanism of the future buffer is very similar to the reorder buffer <ref> [7, 16] </ref> used in superscalar processors. The main disadvantage of a reorder buffer is that it requires associative hardware to provide later instructions with the uncommitted results produced by earlier instructions. The hardware complexity and its associated latency often limit the size of a reorder buffer in superscalar processors [7].
Reference: [17] <author> M. D. Smith. </author> <title> Tracing with pixie. </title> <type> Technical report, </type> <institution> Stanford University, Stanford, </institution> <address> California 94305, </address> <month> November </month> <year> 1991. </year> <note> Technical Report CSL-TR-91-497. </note>
Reference-contexts: Some performance-related issues, which include the size of the future buffer, instruction scheduling with or without profiling, and code expansion rate, are also studied in this section. 18 4.1 Methodology We implement the instruction scheduler and simulator based on pixie and xsim <ref> [17] </ref>. Pixie is used to partition an executable program into basic blocks and generate dynamic basic block trace for simulation. Xsim is used to construct the global control flow graph. Xsim also provides a disassembler for decoding instructions with given addresses.
Reference: [18] <author> M. D. Smith, M. A. Horowitz, and M. S. Lam. </author> <title> Efficient Superscalar Performance Through Boosting. </title> <booktitle> In Proceedings of Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 248-259, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Without any hardware support, a compiler can only perform limited speculative movement in order to maintain safety and legality of the program execution. To support speculative execution, some result-buffering mechanism for uncommitted results is usually needed. Reordering buffers [7, 16] in superscalar processors and shadow register files <ref> [2, 19, 18] </ref> in VLIW processor provide such result-buffering mechanism for speculative execution. Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. <p> In addition, we present a new result-buffering structure, called future buffer, for VLIW architectures. The future buffer can evaluate the predicate states of uncommitted results according to the run time conditions. Differing from the shadow register files used in <ref> [2, 19, 18] </ref>, the future buffer adopts a first-in, first-out (FIFO) structure to simplify the handling of speculative exceptions and allow multiple uncommitted writes to the same register. In the rest of this paper, we review some previous works in section 2. <p> A speculative instruction movement must be safe to avoid speculative exceptions that may alter the result of the program execution. A speculative instruction movement must also be legal to avoid writing to a register or a memory location whose value may be used by instructions on other control paths <ref> [18] </ref>. 1 A region is a set of basic blocks that includes a entry basic block, which dominates all other basic blocks in the region [1]. 2 These restrictions can severely limit the exploitable ILP. Hardware mechanisms to buffer uncommitted results and to handle speculative exceptions can relax such restrictions. <p> This method, however, requires additional instructions to copy the new values to the original registers if the control paths containing the renamed registers are taken. The performance of such register renaming is limited by the availability of free registers. Smith et al. <ref> [19, 18] </ref> propose boosting which uses a shadow register file and a shadow store buffer to store the results of the speculative instructions until the branch instructions they are control dependent on become committed. <p> With the excepting address stored in the source register, the processor can accurately locate the speculative instruction which causes the exception. Boosting <ref> [19, 18] </ref> and predicating [2] also postpone speculative exceptions until the commit point. Instead of saving the excepting address in the destination register, they mark the exception flag in the corresponding shadow register when an exception occurs. <p> By encoding the control dependences in instructions, the compiler can inform the hardware in what conditions to commit or to squash the results of the instructions. The representation of future conditions and control dependences must be easy to manipulate and to encode. Boosting <ref> [19, 18] </ref> supports speculative execution along a single control path, that is, only instructions in the most-frequently taken direction of each conditional branch can be speculatively moved above the branch instruction. <p> Also, note some SETC instructions have been moved to the last instruction of their predecessor blocks. 4 Performance Evaluation Ando et al. [2] have shown that multiple-path speculative execution through predicating outperforms traditional global scheduling techniques and single-path speculative execution techniques such as boosting <ref> [19, 18] </ref>. Hence, we only compare the performance of the predicate shifting model with the predicating model. <p> The experimental results also shows that, with the support for multiple-path speculative execution, the compiler can effectively exploit ILP across basic block boundaries without relying on profile information. This is a significant improvement over other schemes <ref> [5, 3, 18] </ref>, which can only speculate along one selected control path. This paper also presents a structure, called future buffer, to buffer uncommitted results and to evaluate the predicate state associated with each result.
Reference: [19] <author> M. D. Smith, M. S. Lam, and M. A. Horowitz. </author> <title> Boosting Beyond Static Scheduling in a Superscalar Processor. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 344-455, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Without any hardware support, a compiler can only perform limited speculative movement in order to maintain safety and legality of the program execution. To support speculative execution, some result-buffering mechanism for uncommitted results is usually needed. Reordering buffers [7, 16] in superscalar processors and shadow register files <ref> [2, 19, 18] </ref> in VLIW processor provide such result-buffering mechanism for speculative execution. Besides result-buffering, most existing speculative execution techniques also adopt branch prediction [9]. In superscalar architectures, branch history table [7] is often used to predict branch results dynamically. <p> In addition, we present a new result-buffering structure, called future buffer, for VLIW architectures. The future buffer can evaluate the predicate states of uncommitted results according to the run time conditions. Differing from the shadow register files used in <ref> [2, 19, 18] </ref>, the future buffer adopts a first-in, first-out (FIFO) structure to simplify the handling of speculative exceptions and allow multiple uncommitted writes to the same register. In the rest of this paper, we review some previous works in section 2. <p> This method, however, requires additional instructions to copy the new values to the original registers if the control paths containing the renamed registers are taken. The performance of such register renaming is limited by the availability of free registers. Smith et al. <ref> [19, 18] </ref> propose boosting which uses a shadow register file and a shadow store buffer to store the results of the speculative instructions until the branch instructions they are control dependent on become committed. <p> With the excepting address stored in the source register, the processor can accurately locate the speculative instruction which causes the exception. Boosting <ref> [19, 18] </ref> and predicating [2] also postpone speculative exceptions until the commit point. Instead of saving the excepting address in the destination register, they mark the exception flag in the corresponding shadow register when an exception occurs. <p> By encoding the control dependences in instructions, the compiler can inform the hardware in what conditions to commit or to squash the results of the instructions. The representation of future conditions and control dependences must be easy to manipulate and to encode. Boosting <ref> [19, 18] </ref> supports speculative execution along a single control path, that is, only instructions in the most-frequently taken direction of each conditional branch can be speculatively moved above the branch instruction. <p> Also, note some SETC instructions have been moved to the last instruction of their predecessor blocks. 4 Performance Evaluation Ando et al. [2] have shown that multiple-path speculative execution through predicating outperforms traditional global scheduling techniques and single-path speculative execution techniques such as boosting <ref> [19, 18] </ref>. Hence, we only compare the performance of the predicate shifting model with the predicating model.
Reference: [20] <author> M. Srinivas, A. Nicolau, and V. H. Allan. </author> <title> An Approach to Combine Predicated/Speculative Execution for Programs with Unpredictable Branches. </title> <booktitle> In Proceedings of the IFIP WG10.3 Working Conference on Parallel Architectures and Compilation Techniques, </booktitle> <pages> pages 147-156, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: In other words, the control dependences are 1 merely converted to data dependences rather than avoided as in the case of speculative execution. Speculative execution and predicated execution can be used together to support multiple-path speculative execution <ref> [2, 20] </ref>. Predicated execution provides a good mechanism to represent control dependences in different control paths. With the support of result buffering mechanisms, instructions can be speculatively moved and executed before their predicate defining instructions.
Reference: [21] <author> D. W. Wall. </author> <title> Limits of Instruction-Level parallelism. </title> <booktitle> In Proceedings of Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188, </pages> <month> April </month> <year> 1991. </year> <month> 27 </month>
Reference-contexts: 1 Introduction Superscalar and VLIW architectures have become dominant in high performance processor design. They both provide multiple instruction decoders and functional units to exploit instruction level parallelism (ILP). Previous studies <ref> [21, 8] </ref> have shown that the ILP within a basic block is very limited. Thus, exploiting ILP across basic block boundaries is essential to achieve higher performance.
References-found: 21

