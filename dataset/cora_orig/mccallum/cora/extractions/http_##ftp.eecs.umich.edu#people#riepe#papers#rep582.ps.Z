URL: http://ftp.eecs.umich.edu/people/riepe/papers/rep582.ps.Z
Refering-URL: http://ftp.eecs.umich.edu/people/riepe/papers/
Root-URL: http://www.eecs.umich.edu
Title: On the Study of Novel Modern High-Speed Distributed Object-Oriented Fault-Tolerant Real-Time State Machine Testable Shared-Memory
Author: Tse Hao Hsing, Michael A. Riepe, Carlos V. Rozas 
Note: This document was created with FrameMaker 4.0.2  
Address: Ann Arbor, Michigan 48109-2122fl USA  
Affiliation: THE UNIVERSITY OF MICHIGAN Computer Science and Engineering Divisionfl Department of Electrical Engineering and Computer Sciencefl  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Agarwal, J. Hennessy, M. Horowitz. </author> <title> Cache Performance of Operating System and Multiprogramming Workloads, </title> <journal> ACM Transactions on Computer Systems , Vol. </journal> <volume> 6, No. 4, </volume> <month> Nov. </month> <year> 1988, </year> <pages> pp. 393431. </pages>
Reference-contexts: This motivates a thorough study of the differences between system and application code and how they behave and interact with each other and with the memory system. Several recent studies have begun to address this issue. The first was the Ph. D. Thesis of Anant Agarwal <ref> [1, 2] </ref>, which performed a re-analysis of many classical issues in the design of caches, such as the effects of associativity and block length, in the presence of complete address traces including the system code and under multiprogramming workloads.
Reference: [2] <author> A. Agarwal. </author> <title> Analysis of Cache Performance for Operating Systems and Multiprogramming, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1989. </year>
Reference-contexts: This motivates a thorough study of the differences between system and application code and how they behave and interact with each other and with the memory system. Several recent studies have begun to address this issue. The first was the Ph. D. Thesis of Anant Agarwal <ref> [1, 2] </ref>, which performed a re-analysis of many classical issues in the design of caches, such as the effects of associativity and block length, in the presence of complete address traces including the system code and under multiprogramming workloads.
Reference: [3] <author> T. Anderson, H. Levy, B. Bershad, E. Lazowska. </author> <title> The Interaction of Architecture and Operating System Design, </title> <booktitle> in proc. Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV), </booktitle> <year> 1991, </year> <pages> pp. 108120. </pages>
Reference-contexts: In particular, we would like to examine the effect of system calls on users cache hit ratio to gain some insight on the true cost of a system call. 2 Background and Related Work 2.1 Interactions Between the Architecture and the Operating System Anderson et al <ref> [3] </ref> examine the new trends in architecture and operating systems as well as the implications of changes in the two competing domains. Anderson concentrates on three major components of the operating system: enterprises communication (IPC), virtual memory, and threads and multiprocessing, discussing the functional and performance needs of each component. <p> At the low end, this is comparable to the other costs of a context switch, and dominates at the high end. Ousterhout [10] estimated the penalty for a context switch, plus the cost of echoing one byte through a pipe, at about 90 micro-seconds. Anderson <ref> [3] </ref> estimated the cost for the simplest null system call at about 9 micro-seconds. The authors point out that in comparison to the cost of the aggregate cache misses, the cost of saving and restoring even very large register sets would be negligible.
Reference: [4] <author> B. Bershad. </author> <title> The Increasing Irrelevance of IPC Performance for Microkernel-Based Operating Systems, USENIX, Micro-Kernels and Other Kernel Architectures, </title> <booktitle> 1992, </booktitle> <pages> pp. </pages> <year> 205211. </year>
Reference-contexts: Thus, IPC could represent a significant additional overhead in microkernel system calls as compared to monolithic kernels system calls. Bershad <ref> [4] </ref> examines IPC implementation in the next generation microkernel-based operating systems with the following observations: IPC has gotten faster than the rest of the operating system Performance is dominated by caches, not by address spaces All services do not need a hardware firewall.
Reference: [5] <author> J. Chen, B. Bershad. </author> <title> The Impact of Operating System Structure on Memory System Performance, </title> <booktitle> To appear in The Fourteenth Symposium on Operating System Principles </booktitle>
Reference-contexts: They were not able to study the effects of kernel code directly, but one can extrapolate some of the effects of frequent system calls from the behavior of ordinary context switches. Finally, Bradley Chen and Brian Bershad <ref> [5] </ref> have attempted to unify this work with detailed studies of the characteristics of the system code and how it behaves in the cache. We will survey the techniques and findings of these authors in the following section. <p> And more seriously, he has no method for capturing traces of system calls. Many tracing methods have since evolved to counter some of these inaccuracies. Traces are often obtained by annotating the application executable itself with extra instructions to capture all memory reference addresses <ref> [5, 7, 12] </ref>, allowing the program to be run in a normal execution environment at a near real-time speed. Multi-programming behavior can be traced if the entire workload has been annotated, and if the system code is annotated one can capture full traces of the system calls. <p> However, the overhead introduced by many schemes can introduce second-order effects which will distort the results of the simulation. The hardware monitoring methodology is the only one completely free of this problem. Chen and Bershad <ref> [5] </ref> list three sources of distortion seen in their code annotation strategy: the traced program is both larger (by about a factor of two) and slower (by about a factor of 15), leading to what they call memory dilation time dilation , respectively. <p> On the Study of Novel Modern High-Speed Distributed Object-Oriented Fault-Tolerant Real-Time State Machine Testable Shared Memory Disconnected and Secure Operating System/Memory Interactions 7 The recent paper by Chen & Bershad <ref> [5] </ref> studied the memory system behavior of the operating system by comparing two different implementation of UNIX: DECs Ultrix, a monolithic kernel O.S., and Mach3.0, a micro-kernel O.S. <p> Another interesting aspect observed is that the interference component of the total miss rate reduces gradually. This confirms Chen and Bershards claim that collisions between user and kernel references do not lead to significant performance degradation in caches <ref> [5] </ref>. Also, we note that cold miss component is very small compared to the other components.The major part of total miss rate is due to the non-stationary component.
Reference: [6] <author> N. Jouppi. </author> <title> Cache Write Policies and Performance, </title> <booktitle> in proc. 1993 International Symposium on Computer Architecture (ISCA), </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. </pages> <year> 191201. </year>
Reference: [7] <author> J. Mogul, A. Borg. </author> <title> The Effect of Context Switches on Cache Performance, </title> <booktitle> in proc. Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV), </booktitle> <year> 1991, </year> <pages> pp. 7584. </pages>
Reference-contexts: And more seriously, he has no method for capturing traces of system calls. Many tracing methods have since evolved to counter some of these inaccuracies. Traces are often obtained by annotating the application executable itself with extra instructions to capture all memory reference addresses <ref> [5, 7, 12] </ref>, allowing the program to be run in a normal execution environment at a near real-time speed. Multi-programming behavior can be traced if the entire workload has been annotated, and if the system code is annotated one can capture full traces of the system calls. <p> Regions of code with these traits could be identified with the tracing techniques. While Agarwal concentrated on the long-term average behavior of the cache under system code and multi-programming loads, Mogul & Borg <ref> [7] </ref> studies the fine-grained behavior of processes following context switches in a multi-programming environment. After a context switch, the application will have to spend some time reloading some portion of its working set that were lost due to interference, resulting in an increase in the miss rate.
Reference: [8] <author> D. Nagle, R. Uhlig, T. Mudge, S. Sechrest. </author> <title> Optimal Allocation of On-chip Memory for Multiple-API Operating Systems, </title> <booktitle> To Appear in the 21st International Conference on Computer Architecture (ISCA), </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: Measurements found in <ref> [8] </ref> indicate that the round-trip call and return path is less than 100 instructions in Ultrix, but approximately 1850 instructions in Mach. System calls are therefore much more expensive in micro-kernels. <p> However, data cache dynamic miss rate are much lower then instruction cache dynamic miss rate. Therefore, the size of data cache has less impact on system performance than that of instruction cache on a microkernel-based operating system such as Mach, as suggested by Nagle <ref> [8] </ref>. We also ran a trace for under Mach shown in Figure 6, captured at the beginning of the program execution. In this trace, kernel trace segment time-slices are much larger than user trace segment time-slices (the maximum user trace segment time-slice has approximately 7000 instructions). <p> In order to maker further investigation, more ultrix traces will be needed. Considering that more than 95% of the user trace segment time-slices has fewer than 1000 instructions, Figure 10 and Figure 11 have very similar behaviors. Note that, in contradiction with the common knowledge <ref> [8] </ref>, the VideoPlay ultrix trace has a higher instruction cache miss rate after context switches, and also takes longer to recover its working set in the instruction cache.
Reference: [9] <author> D. Nagle. R. Uhlig, T. Mudge, S. Sechrest. </author> <title> Monster: A Tool for Analyzing the interaction between Operating Systems and Architectures. </title> <institution> University of Michigan Technical Report CSE-TR-147-92, </institution> <year> 1992. </year>
Reference: [10] <author> J. Ousterhout. </author> <title> Why Arent Operating Systems Getting Faster as Fast as Hardware?, </title> <booktitle> USENIX Summer Conference, </booktitle> <month> June </month> <year> 1990. </year> <pages> pp. 110. </pages>
Reference-contexts: Modern architectures which have considered the needs of operating systems have usually used a monolithic model to drive the design. The question then arises as to how these new trends in operating systems and architecture have affected operating system performance. John Ousterhout <ref> [10] </ref> assembled various operating system micro-benchmarks that measured specific features of the hardware or operating system like kernel entry-exit and context switching as well as a macro-benchmark to measure the operating system performance as a whole. <p> John Ousterhout <ref> [10] </ref> assembled various operating system micro-benchmarks that measured specific features of the hardware or operating system like kernel entry-exit and context switching as well as a macro-benchmark to measure the operating system performance as a whole. <p> Given the clock speed of the DECstation 5000/200 (25 MHz) the penalty is about 8 micro-seconds in the best case, and 400 micro-seconds in the worst case. At the low end, this is comparable to the other costs of a context switch, and dominates at the high end. Ousterhout <ref> [10] </ref> estimated the penalty for a context switch, plus the cost of echoing one byte through a pipe, at about 90 micro-seconds. Anderson [3] estimated the cost for the simplest null system call at about 9 micro-seconds. <p> X X IOzone A sequential file I/O benchmark that writes and then reads a 10 Megabyte file. Written by Bill Norcott. X X jpeg_play The xloadimage program written by Jim Frost. Displays four jpeg images. X mab John Ousterhouts Modified Andrew Benchmark <ref> [10] </ref>. X mpeg_play mpeg_play V2.0 from Berkeley Plateau Research Group. Displays 610 frames from a compressed video file. X ousterhout John Ousterhouts benchmark suite (excluding mab) [10]. <p> X X jpeg_play The xloadimage program written by Jim Frost. Displays four jpeg images. X mab John Ousterhouts Modified Andrew Benchmark <ref> [10] </ref>. X mpeg_play mpeg_play V2.0 from Berkeley Plateau Research Group. Displays 610 frames from a compressed video file. X ousterhout John Ousterhouts benchmark suite (excluding mab) [10]. X On the Study of Novel Modern High-Speed Distributed Object-Oriented Fault-Tolerant Real-Time State Machine Testable Shared Memory Disconnected and Secure Operating System/Memory Interactions 9 It is well known that the approach taken by Mach results in system calls that have much longer invocation paths than traditional monolithic kernels.
Reference: [11] <author> A. Smith. </author> <title> Cache Memories, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 14, No. 3, </volume> <month> Sept. </month> <year> 1982. </year> <pages> pp. </pages> <month> 473530.M. </month> <title> Smith. Tracing with Pixie, </title> <institution> Stanford University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: It has long been recognized that the study of real program workloads is an indispensable aid in the design and optimization of the memory system. In his seminal paper on cache memories, Alan Smith <ref> [11] </ref> studied many aspects of cache design using cache simulations driven by address traces from real programs. However, it has not been until recently that such studies could include the effects of system code. Many memory systems have been designed based on the behavior of application code alone. <p> This would eliminate interference between the system and user code, preventing portions of the application working sets from being ushed from the cache during system calls. Agarwal performed several experiments to test this hypothesis, but they verified the opinion of Smith <ref> [11] </ref> that the inherently high miss rates of the system code would be harmed more by having its available cache size cut in half, than the elimination of the interference misses would cost.
Reference: [12] <author> M. Smith. </author> <title> Tracing with pixie , Center for Integrated Systems, </title> <institution> Stanford University, </institution> <month> April, </month> <year> 1991. </year>
Reference-contexts: And more seriously, he has no method for capturing traces of system calls. Many tracing methods have since evolved to counter some of these inaccuracies. Traces are often obtained by annotating the application executable itself with extra instructions to capture all memory reference addresses <ref> [5, 7, 12] </ref>, allowing the program to be run in a normal execution environment at a near real-time speed. Multi-programming behavior can be traced if the entire workload has been annotated, and if the system code is annotated one can capture full traces of the system calls. <p> Therefore, the results showing the relative numbers of kernel and user instructions, misses, etc. may appear contradictory, showing Ultrix system calls as being more expensive. Cache simulations were performed using a simulator which we added into the xsim simulator, a C++ simulation environment written by Mike Smith of Stanford <ref> [12] </ref>, and meant to be used with traces obtained with the DEC pixie code annotation system.
Reference: [13] <author> D. Thiebaut, H. Stone. </author> <title> Footprints in the Cache, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 5, No. 4, </volume> <pages> pp. 305-329. </pages> <month> Nov. </month> <year> 1987. </year>
Reference: [14] <author> R. Uhlig, D. Nagle, T. Mudge, S. Sechrest. Tapeworm II: </author> <title> A New Method for Measuring OS Effects on Memory Architecture Performance. </title> <booktitle> Submitted for review to the Sixth International Conference on Architectural Support for Programming On the Study of Novel Modern High-Speed Distributed Object-Oriented Fault-Tolerant Real-Time State Machine Testable Shared Memory Disconnected and Secure Operating System/Memory Interactions 19 Languages and Operating Systems (ASPLOS VI), </booktitle> <year> 1994. </year>
Reference: [15] <author> R. Uhlig, D. Nagle, T. Mudge, S. Sechrest. </author> <title> Kernel Based Memory Simulation, </title> <institution> University of Michigan Technical Report CSE-TR-185-93, </institution> <month> November </month> <year> 1993. </year> <title> On the Study of Novel Modern High-Speed Distributed Object-Oriented Fault-Tolerant Real-Time State Machine Testable Shared Memory Disconnected and Secure Operating System/Memory Interactions 20 </title>
References-found: 15

