URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1997/umsi-97-95.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1997/
Root-URL: http://www.cs.umn.edu
Title: Experimental Study of ILU Preconditioners for Indefinite Matrices  
Author: Edmond Chow and Yousef Saad 
Date: August 3, 1997  
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science, and Minnesota Supercomputer Institute University of Minnesota  
Abstract: Incomplete LU factorization preconditioners have been surprisingly successful for many cases of general nonsymmetric and indefinite matrices. However, their failure rate is still too high for them to be useful as black-box library software for general matrices. Besides fatal breakdowns due to zero pivots, the major causes of failure are inaccuracy, and instability of the triangular solves. When there are small pivots, both these problems can occur, but these problems can also occur without small pivots. Through examples from actual problems, this paper shows how these problems evince themselves, how these problems can be detected, and how these problems can sometimes be circumvented through pivoting, reordering, scaling, perturbing diagonal elements, and preserving symmetric structure. The goal of this paper is to gain a better practical understanding of ILU preconditioners and help improve their reliability.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Axelsson and L. Yu. </author> <title> Kolotilina. Diagonally compensated reduction and related preconditioning methods. </title> <journal> Num. Lin. Alg. Appl., </journal> <volume> 1, </volume> <year> 1995. </year>
Reference-contexts: Elman [17] used this as part of his criteria to modify certain rows and not others, in his stabilized factorization based on RILU. Recently, the method of diagonal compensation <ref> [1] </ref> has been developed for preconditioning positive definite matrices with incomplete factorizations. Essentially, the SPD matrix is modified into an M-matrix, for example, by dropping positive off-diagonal elements and adding them to the diagonal.
Reference: [2] <author> O. Axelsson and G. Lindskog. </author> <title> On the eigenvalue distribution of a class of preconditioning methods. </title> <journal> Numer. Math., </journal> <volume> 48 </volume> <pages> 479-498, </pages> <year> 1986. </year>
Reference-contexts: Experimental Study of ILU 13 These methods apply to elliptic problems in one variable, where they lower the order of the spectral condition number of the preconditioned matrix. Relaxed ILU (RILU) <ref> [2, 3] </ref> parameterizes the fraction of the modification to perform, giving it the same effect as the perturbation. Negative relaxation factors in RILU have a stabilizing effect for M-matrices. They were used for multigrid smoothing by Wittum [42] in his ILU fi method.
Reference: [3] <author> O. Axelsson and G. Lindskog. </author> <title> On the rate of convergence of the preconditioned conjugate gradient method. </title> <journal> Numer. Math., </journal> <volume> 48 </volume> <pages> 499-523, </pages> <year> 1986. </year>
Reference-contexts: Experimental Study of ILU 13 These methods apply to elliptic problems in one variable, where they lower the order of the spectral condition number of the preconditioned matrix. Relaxed ILU (RILU) <ref> [2, 3] </ref> parameterizes the fraction of the modification to perform, giving it the same effect as the perturbation. Negative relaxation factors in RILU have a stabilizing effect for M-matrices. They were used for multigrid smoothing by Wittum [42] in his ILU fi method.
Reference: [4] <author> Owe Axelsson. </author> <title> Iterative Solution Methods. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1994. </year>
Reference-contexts: For M-matrices, the modification actually decreases the size of the pivots, making the factorization less stable. Perturbed factorizations that add a small value to the diagonal opposite in direction to the modification, help guarantee a bound on the largest eigenvalue of the preconditioned system; see <ref> [4, Ch. 10] </ref> for a review. Experimental Study of ILU 13 These methods apply to elliptic problems in one variable, where they lower the order of the spectral condition number of the preconditioned matrix.
Reference: [5] <author> E. F. F. Botta, A. van der Ploeg, and F. W. Wubs. </author> <title> Nested grids ilu-decomposition (ngilu). </title> <journal> J. Comp. Appl. Math., </journal> <volume> 66 </volume> <pages> 515-526, </pages> <year> 1996. </year>
Reference-contexts: A full-length work vector is used to hold the current row or column that is being computed, which helps minimize searching for nonzero entries. The `submatrix' form is more expensive to use, but it is more flexible and makes it possible to perform symmetric pivoting <ref> [5, 12] </ref>. The `bordered' form will be introduced in Section 4. Experimental Study of ILU 7 Algorithm 2.1 illustrates the row-wise incomplete factorization of a matrix A. This form is suitable for sparse matrices stored in row-contiguous data structures.
Reference: [6] <author> A. M. Bruaset, A. Tveito, and R. Winther. </author> <title> On the stability of relaxed incomplete LU factorizations. </title> <journal> Math. Comp., </journal> <volume> 54 </volume> <pages> 701-719, </pages> <year> 1990. </year>
Reference-contexts: In the nonsymmetric case, there may be another problem: the incomplete factors L and U may be much worsely conditioned than the original matrix A. A coupled effect is that the long recurrences associated with solving with these factors are unstable <ref> [6, 16] </ref>.
Reference: [7] <author> N. I. Buleev. </author> <title> A numerical method for the solution of two-dimensional and three-dimensional equations of diffusion. </title> <journal> Math. Sb., </journal> <volume> 51 </volume> <pages> 227-238, </pages> <year> 1960. </year> <title> English transl.: </title> <type> Rep. </type> <institution> BNL-TR-551, Brookhaven National Laboratory, Upton, </institution> <address> New York, </address> <year> 1973. </year>
Reference-contexts: For these problems, the structure of the incomplete triangular factors was chosen based on the structure of the gridpoint operators <ref> [7, 28, 29, 39] </ref> (see also the review [9]) and the resulting structure of the error matrix E.
Reference: [8] <author> J. R. Bunch and L. Kaufman. </author> <title> Some stable methods for calculating inertia and solving symmetric linear systems. </title> <journal> Math. Comp., </journal> <volume> 31 </volume> <pages> 162-179, </pages> <year> 1977. </year>
Reference-contexts: ILUTP can be used to simulate this type of pivoting by only searching for pivots within the current block. The idea of blocking is similar to the idea of diagonal pivoting for complete factorizations of symmetric indefinite matrices <ref> [8, 13] </ref>, where 2 by 2 pivot blocks are allowed.
Reference: [9] <author> T. F. Chan and H. A. Van der Vorst. </author> <title> Approximate and incomplete factorizations. </title> <type> Technical Report 871, </type> <institution> Department of Mathematics, University of Utrecht, </institution> <year> 1994. </year>
Reference-contexts: For these problems, the structure of the incomplete triangular factors was chosen based on the structure of the gridpoint operators [7, 28, 29, 39] (see also the review <ref> [9] </ref>) and the resulting structure of the error matrix E. In most cases, the gridpoint operator was a five-point stencil, and the stencil for the lower (upper) triangular factor was chosen to have the same pattern as the lower (upper) triangular part of the original stencil.
Reference: [10] <author> A. Chapman, Y. Saad, and L. Wigton. </author> <title> High-order ILU preconditioners for CFD problems. </title> <type> Technical Report UMSI 96/14, </type> <institution> Minnesota Supercomputer Institute, University of Minnesota, Minneapolis, Minnesota, </institution> <year> 1996. </year>
Reference-contexts: This destroys the accuracy of the factorization, and usually, increasing the fill-in is done in vain. For these problems, the last resort seems to be to use very large amounts of fill-in <ref> [10] </ref>, for example, as we did for the PULLIAM1 and BBMAT problems. General-purpose software for incomplete factorizations should include options for pivoting and perturbing pivots. The latter should be a particularly simple addition to any incomplete factorization code.
Reference: [11] <author> E. Chow and Y. Saad. ILUS: </author> <title> an incomplete LU factorization for matrices in sparse skyline format. </title> <journal> Intl. J. Num. Meth. Fluids, </journal> <volume> 24, </volume> <year> 1997. </year>
Reference-contexts: However, the symmetric structure can be preserved with an incomplete form of LDU Gaussian elimination based on bordering <ref> [11, 30, 35] </ref>. Let A k+1 be the (k + 1)-st leading principal submatrix of A and assume we have the decomposition A k = L k D k U k . <p> However, in this case, the lower triangular matrices are only available by rows, not by columns. A companion data structure that gives access to the columns is needed. For details, see <ref> [11] </ref>, which also describes how sparse approximate solutions to the triangular systems can be found using approximate inverse techniques. In order for z k and y k to have the same sparsity pattern, the systems (6) and (7) are solved simultaneously.
Reference: [12] <author> E. F. D'Azevdo, P. A. Forsyth, and W.-P. Tang. </author> <title> Towards a cost-effective ILU preconditioner with high level fill. </title> <journal> BIT, </journal> <volume> 32 </volume> <pages> 442-463, </pages> <year> 1992. </year>
Reference-contexts: The ILU (k) factorization is thus defined as a factorization that retains all elements with level up to k. ILU (0) retains only the original nonzeros of the matrix. There is also a characterization of level-of-fill based on the graph of the original matrix <ref> [12] </ref>. To illustrate this, consider the graph of Figure 4 from [20] and the elimination of the nodes in the numbered order. In the complete factorization of the associated matrix, there will be a fill-in between nodes 4 and 6, from the successive eliminations of nodes 1 and 2 [31]. <p> A full-length work vector is used to hold the current row or column that is being computed, which helps minimize searching for nonzero entries. The `submatrix' form is more expensive to use, but it is more flexible and makes it possible to perform symmetric pivoting <ref> [5, 12] </ref>. The `bordered' form will be introduced in Section 4. Experimental Study of ILU 7 Algorithm 2.1 illustrates the row-wise incomplete factorization of a matrix A. This form is suitable for sparse matrices stored in row-contiguous data structures.
Reference: [13] <author> I. S. Duff, N. I. M. Gould, J. K. Reid, and J. A. Scott. </author> <title> The factorization of sparse indefinite matrices. </title> <journal> IMA J. Num. Anal., </journal> <volume> 11 </volume> <pages> 181-204, </pages> <year> 1991. </year>
Reference-contexts: ILUTP can be used to simulate this type of pivoting by only searching for pivots within the current block. The idea of blocking is similar to the idea of diagonal pivoting for complete factorizations of symmetric indefinite matrices <ref> [8, 13] </ref>, where 2 by 2 pivot blocks are allowed.
Reference: [14] <author> I. S. Duff and G. A. Meurant. </author> <title> The effect of ordering on preconditioned conjugate gradients. </title> <journal> BIT, </journal> <volume> 29 </volume> <pages> 635-657, </pages> <year> 1989. </year>
Reference-contexts: This is important because, for symmetric linear systems, the size of E is very strongly related to the convergence rate of an ILU-preconditioned iteration <ref> [14] </ref>. However, for nonsymmetric and for indefinite problems the performance is much less predictable. <p> The solution, keeping all other parameters the same, was found in 37 steps in this case. In general, reordering has a large effect on the accuracy of ILU preconditioners <ref> [14, 15] </ref>. Consider now LNS3937. If no pivoting is used, the problem is small pivots. We thresholded the pivots for ILU (30). This decreases condest and helps the residual be reduced further, but there is still no convergence.
Reference: [15] <author> L. C. Dutto. </author> <title> The effect of ordering on preconditioned GMRES algorithms, for solving the compressible Navier-Stokes equations. </title> <journal> Int. J. Numer. Methods Engrg., </journal> <volume> 36 </volume> <pages> 457-497, </pages> <year> 1993. </year>
Reference-contexts: The solution, keeping all other parameters the same, was found in 37 steps in this case. In general, reordering has a large effect on the accuracy of ILU preconditioners <ref> [14, 15] </ref>. Consider now LNS3937. If no pivoting is used, the problem is small pivots. We thresholded the pivots for ILU (30). This decreases condest and helps the residual be reduced further, but there is still no convergence.
Reference: [16] <author> H. C. Elman. </author> <title> A stability analysis of incomplete LU factorizations. </title> <journal> Math. Comp., </journal> <volume> 47 </volume> <pages> 191-217, </pages> <year> 1986. </year> <title> Experimental Study of ILU 31 </title>
Reference-contexts: In the nonsymmetric case, there may be another problem: the incomplete factors L and U may be much worsely conditioned than the original matrix A. A coupled effect is that the long recurrences associated with solving with these factors are unstable <ref> [6, 16] </ref>.
Reference: [17] <author> H. C. Elman. </author> <title> Relaxed and stabilized incomplete factorizations for non-self-adjoint linear systems. </title> <journal> BIT, </journal> <volume> 29 </volume> <pages> 890-915, </pages> <year> 1989. </year>
Reference-contexts: A coupled effect is that the long recurrences associated with solving with these factors are unstable [6, 16]. A remedy is also to use diagonal perturbations, this time to make the factors diagonally dominant <ref> [27, 37, 17] </ref>, but the perturbations in this case may need to be very large. fl Work supported in part by the National Science Foundation under grant NSF/CCR-9618827 and in part by NASA under grant NAG2-904. <p> ILU 0 corresponds to the regular, unmodified factorization, ILU 1 corresponds to MILU, and ILU 1 corresponds to the modification of Jennings and Malik [22]. For elliptic problems that are not M-matrices, modification may also have a stabilizing effect if it increases the value on the diagonal. Elman <ref> [17] </ref> used this as part of his criteria to modify certain rows and not others, in his stabilized factorization based on RILU. Recently, the method of diagonal compensation [1] has been developed for preconditioning positive definite matrices with incomplete factorizations.
Reference: [18] <author> M. Engelman. FIDAP: </author> <title> Examples Manual, Revision 6.0. </title> <booktitle> Fluid Dynamics International, </booktitle> <address> Evanston, IL, </address> <year> 1991. </year>
Reference-contexts: Besides this breadth of test problems, we also examined in depth a set of test problems in SPARSKIT from the solution of the incompressible Navier-Stokes equations. We generated this test set with the FIDAP fluid dynamics analysis package <ref> [18, 19] </ref>. The example problems provided by FIDAP were solved using the fully-coupled solution method, and we extracted the first linear systems in the nonlinear iterations. The incompressibility condition gives these matrices zeros on their diagonals. The FIDAP matrices have a symmetric pattern.
Reference: [19] <author> M. S. Engelman and I. Hasbani. </author> <title> Matrix-free solution algorithms in a finite element context. </title> <type> Technical Report 88-1, </type> <institution> Fluid Dynamics International, Evanston, Illinois, </institution> <year> 1988. </year>
Reference-contexts: Besides this breadth of test problems, we also examined in depth a set of test problems in SPARSKIT from the solution of the incompressible Navier-Stokes equations. We generated this test set with the FIDAP fluid dynamics analysis package <ref> [18, 19] </ref>. The example problems provided by FIDAP were solved using the fully-coupled solution method, and we extracted the first linear systems in the nonlinear iterations. The incompressibility condition gives these matrices zeros on their diagonals. The FIDAP matrices have a symmetric pattern.
Reference: [20] <author> Alan George and Joseph W. Liu. </author> <title> Computer Solution of Large Sparse Positive Definite Systems. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: ILU (0) retains only the original nonzeros of the matrix. There is also a characterization of level-of-fill based on the graph of the original matrix [12]. To illustrate this, consider the graph of Figure 4 from <ref> [20] </ref> and the elimination of the nodes in the numbered order. In the complete factorization of the associated matrix, there will be a fill-in between nodes 4 and 6, from the successive eliminations of nodes 1 and 2 [31].
Reference: [21] <author> I. Gustafsson. </author> <title> A class of first-order factorization methods. </title> <journal> BIT, </journal> <volume> 18 </volume> <pages> 142-156, </pages> <year> 1978. </year>
Reference-contexts: To get a more accurate factorization, a larger stencil for the factors can be chosen, for example, by attempting to reduce the error A LU . This can be done by considering the stencil of LU as the new stencil to be approximated <ref> [21] </ref>. Successively larger stencils for the lower-triangular factor defined this way are shown in Figure 3. Incomplete factorizations were named as such when an approximate Gaussian elimination process was defined that gives sparse factors of any given pattern [25]. <p> Numerical experiments for positive definite matrices show that convergence improves sharply as ff is increased toward the optimal ff, and then deteriorates slowly [24, 35]. Shifted or stabilized factorizations are not to be confused with modified ILU (MILU) factorizations <ref> [21] </ref> where the row-sum criteria Ae = LU e; e = (1; 1; ; 1) T is satisfied by modifying the diagonal of L or U . For M-matrices, the modification actually decreases the size of the pivots, making the factorization less stable.
Reference: [22] <author> A. Jennings and G. M. Malik. </author> <title> Partial elimination. </title> <journal> J. Inst. Maths Applics, </journal> <volume> 20 </volume> <pages> 307-316, </pages> <year> 1977. </year>
Reference-contexts: Robert [32] later extended this result to positive real matrices. Even before incomplete factorizations were used widely, Jennings and Malik <ref> [22] </ref> augmented the entries on the diagonal of a sparsified matrix to guarantee it is positive definite for a complete factorization. <p> The diagonal is augmented with fi times the sum of the magnitudes of the dropped elements. ILU 0 corresponds to the regular, unmodified factorization, ILU 1 corresponds to MILU, and ILU 1 corresponds to the modification of Jennings and Malik <ref> [22] </ref>. For elliptic problems that are not M-matrices, modification may also have a stabilizing effect if it increases the value on the diagonal. Elman [17] used this as part of his criteria to modify certain rows and not others, in his stabilized factorization based on RILU.
Reference: [23] <author> D. S. Kershaw. </author> <title> The incomplete Cholesky-conjugate gradient method for the iterative solution of systems of linear equations. </title> <journal> J. Comput. Phys., </journal> <volume> 26 </volume> <pages> 43-65, </pages> <year> 1978. </year>
Reference-contexts: However, ILU preconditioners have been successfully applied in much more general situations. In the general symmetric case, diagonal perturbations of the matrix are required to help guarantee the existence of a symmetric factorization <ref> [23, 24, 27] </ref>. These perturbations may be applied before the factorization, or during the factorization when a small or negative pivot is encountered. In the nonsymmetric case, there may be another problem: the incomplete factors L and U may be much worsely conditioned than the original matrix A. <p> It is obvious that a successful balance between these two may not always be found, in which case some other technique must be brought into play. For positive definite matrices, Kershaw <ref> [23] </ref> suggested replacing negative or zero pivots with small positive values, and continuing with the factorization. For symmetric incomplete factorizations by threshold, Munksgaard [27] proposed the same kind of modification, making the pivot element comparable to the sum of the magnitudes of the off-diagonal elements in a row.
Reference: [24] <author> T. A. Manteuffel. </author> <title> An incomplete factorization technique for positive definite linear systems. </title> <journal> Math. Comp., </journal> <volume> 34 </volume> <pages> 473-497, </pages> <year> 1980. </year>
Reference-contexts: However, ILU preconditioners have been successfully applied in much more general situations. In the general symmetric case, diagonal perturbations of the matrix are required to help guarantee the existence of a symmetric factorization <ref> [23, 24, 27] </ref>. These perturbations may be applied before the factorization, or during the factorization when a small or negative pivot is encountered. In the nonsymmetric case, there may be another problem: the incomplete factors L and U may be much worsely conditioned than the original matrix A. <p> For symmetric incomplete factorizations by threshold, Munksgaard [27] proposed the same kind of modification, making the pivot element comparable to the sum of the magnitudes of the off-diagonal elements in a row. Manteuffel <ref> [24] </ref> proposed the factorization of a shifted matrix A + ffI, and when A is symmetric, proved that there exists a scalar ff&gt;0 such that the factorization for any sparsity pattern exists. Robert [32] later extended this result to positive real matrices. <p> Robert [32] later extended this result to positive real matrices. Even before incomplete factorizations were used widely, Jennings and Malik [22] augmented the entries on the diagonal of a sparsified matrix to guarantee it is positive definite for a complete factorization. Besides guaranteeing existence, Manteuffel <ref> [24] </ref> noticed that the shift ff that gave the best convergence of the iterative method was not the smallest one that makes the factorization exist, but one slightly larger. The shift should make the pivots large enough so that the matrix is not too poorly conditioned. <p> Numerical experiments for positive definite matrices show that convergence improves sharply as ff is increased toward the optimal ff, and then deteriorates slowly <ref> [24, 35] </ref>. Shifted or stabilized factorizations are not to be confused with modified ILU (MILU) factorizations [21] where the row-sum criteria Ae = LU e; e = (1; 1; ; 1) T is satisfied by modifying the diagonal of L or U . <p> The larger shift has the effect of making the problem much better conditioned. Stabilization essentially amounts to the factorization of a better conditioned matrix. This is an important effect of stabilization that was discovered experimentally <ref> [24, 37] </ref>. For block incomplete factorizations, the pivot is a block. The equivalent of a small pivot in this case is a block that is very poorly conditioned, with an inverse that has very large entries.
Reference: [25] <author> J. A. Meijerink and H. A. Van der Vorst. </author> <title> An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix. </title> <journal> Math. Comp., </journal> <volume> 31(137) </volume> <pages> 148-162, </pages> <year> 1977. </year>
Reference-contexts: 1 Introduction The incomplete LU factorization preconditioners were originally developed for M-matrices, for which properties such as existence and a form of stability can be proved <ref> [25] </ref> (see also [40]). However, ILU preconditioners have been successfully applied in much more general situations. In the general symmetric case, diagonal perturbations of the matrix are required to help guarantee the existence of a symmetric factorization [23, 24, 27]. <p> Successively larger stencils for the lower-triangular factor defined this way are shown in Figure 3. Incomplete factorizations were named as such when an approximate Gaussian elimination process was defined that gives sparse factors of any given pattern <ref> [25] </ref>. This generalized the earlier Experimental Study of ILU 6 work on stencils to arbitrarily structured M-matrices. Choices of effective sparsity patterns for the factors were given for five- and seven-point matrices [26].
Reference: [26] <author> J. A. Meijerink and H. A. Van der Vorst. </author> <title> Guidelines for the usage of incomplete decompositions in solving sets of linear equations as they occur in practical problems. </title> <journal> J. Computational Physics, </journal> <volume> 44(1) </volume> <pages> 134-155, </pages> <year> 1981. </year>
Reference-contexts: This generalized the earlier Experimental Study of ILU 6 work on stencils to arbitrarily structured M-matrices. Choices of effective sparsity patterns for the factors were given for five- and seven-point matrices <ref> [26] </ref>. Note that the sparsity pattern should include the full diagonal, even if there are zeros on the diagonal, as in the case of some indefinite matrices. To get more accurate factorizations for general sparse matrices, the concept of level-of-fill was introduced [41].
Reference: [27] <author> N. Munksgaard. </author> <title> Solving sparse symmetric sets of linear equations by preconditioned conjugate gradients. </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 6 </volume> <pages> 206-219, </pages> <year> 1980. </year>
Reference-contexts: However, ILU preconditioners have been successfully applied in much more general situations. In the general symmetric case, diagonal perturbations of the matrix are required to help guarantee the existence of a symmetric factorization <ref> [23, 24, 27] </ref>. These perturbations may be applied before the factorization, or during the factorization when a small or negative pivot is encountered. In the nonsymmetric case, there may be another problem: the incomplete factors L and U may be much worsely conditioned than the original matrix A. <p> A coupled effect is that the long recurrences associated with solving with these factors are unstable [6, 16]. A remedy is also to use diagonal perturbations, this time to make the factors diagonally dominant <ref> [27, 37, 17] </ref>, but the perturbations in this case may need to be very large. fl Work supported in part by the National Science Foundation under grant NSF/CCR-9618827 and in part by NASA under grant NAG2-904. <p> For these matrices, level-of-fill may be less effective at predicting the locations of the largest entries in the factorization. As an alternative to dropping techniques based on structure, fill-in can be dropped during the factorization, based on their numerical size <ref> [27, 34, 36, 44] </ref>. This is a kind of greedy approach to minimizing E in (1). Numerical dropping strategies generally yield more accurate factorizations with the same amount of fill-in than level-of-fill methods. This is true even for some diagonally dominant M-matrices. <p> For positive definite matrices, Kershaw [23] suggested replacing negative or zero pivots with small positive values, and continuing with the factorization. For symmetric incomplete factorizations by threshold, Munksgaard <ref> [27] </ref> proposed the same kind of modification, making the pivot element comparable to the sum of the magnitudes of the off-diagonal elements in a row.
Reference: [28] <author> T. A. Oliphant. </author> <title> An implicit numerical method for solving two-dimensional time-dependent diffusion problems. </title> <journal> Quart. Appl. Math., </journal> <volume> 19 </volume> <pages> 221-229, </pages> <year> 1961. </year>
Reference-contexts: For these problems, the structure of the incomplete triangular factors was chosen based on the structure of the gridpoint operators <ref> [7, 28, 29, 39] </ref> (see also the review [9]) and the resulting structure of the error matrix E.
Reference: [29] <author> T. A. Oliphant. </author> <title> An extrapolation process for solving linear systems. </title> <journal> Quart. Appl. Math., </journal> <volume> 20 </volume> <pages> 257-267, </pages> <year> 1962. </year>
Reference-contexts: For these problems, the structure of the incomplete triangular factors was chosen based on the structure of the gridpoint operators <ref> [7, 28, 29, 39] </ref> (see also the review [9]) and the resulting structure of the error matrix E.
Reference: [30] <author> J. M. Ortega. </author> <title> Introduction to Parallel and Vector Solution of Linear Systems. </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: However, the symmetric structure can be preserved with an incomplete form of LDU Gaussian elimination based on bordering <ref> [11, 30, 35] </ref>. Let A k+1 be the (k + 1)-st leading principal submatrix of A and assume we have the decomposition A k = L k D k U k .
Reference: [31] <author> S. V. Parter. </author> <title> The use of linear graphs in Gauss elimination. </title> <journal> SIAM Rev., </journal> <volume> 3 </volume> <pages> 119-130, </pages> <year> 1961. </year>
Reference-contexts: To illustrate this, consider the graph of Figure 4 from [20] and the elimination of the nodes in the numbered order. In the complete factorization of the associated matrix, there will be a fill-in between nodes 4 and 6, from the successive eliminations of nodes 1 and 2 <ref> [31] </ref>. This is because there exists a path (4, 2, 1, 6) in the graph. The level of the fill-in is one less than the length of the shortest path between nodes 4 and 6 through the eliminated nodes 1 and 2. In this case, the level is 2.
Reference: [32] <author> Y. Robert. </author> <title> Regular incomplete factorizations of real positive definite matrices. </title> <journal> Lin. Alg. Appl., </journal> <volume> 48 </volume> <pages> 105-117, </pages> <year> 1982. </year>
Reference-contexts: Manteuffel [24] proposed the factorization of a shifted matrix A + ffI, and when A is symmetric, proved that there exists a scalar ff&gt;0 such that the factorization for any sparsity pattern exists. Robert <ref> [32] </ref> later extended this result to positive real matrices. Even before incomplete factorizations were used widely, Jennings and Malik [22] augmented the entries on the diagonal of a sparsified matrix to guarantee it is positive definite for a complete factorization.
Reference: [33] <author> Y. Saad. </author> <title> Preconditioning techniques for indefinite and nonsymmetric linear systems. </title> <journal> J. Comp. Appl. Math., </journal> <volume> 24 </volume> <pages> 89-105, </pages> <year> 1988. </year> <title> Experimental Study of ILU 32 </title>
Reference-contexts: In the implementation of column pivoting, no actual column exchanges are made, and the new row indices are determined through permutation vectors. The permutation vectors are updated with each column exchange. This variant of incomplete factorization combined with the dropping strategy of ILUT is called ILUTP. See <ref> [33] </ref> for more details. Unlike the case with complete factorizations, pivoting for incomplete factorizations cannot guarantee that a nonzero pivot can always be found, i.e., z may be all zero and failures due to zero pivots can still occur.
Reference: [34] <author> Y. Saad. ILUT: </author> <title> A dual threshold incomplete ILU factorization. </title> <journal> Num. Lin. Alg. Appl., </journal> <volume> 1 </volume> <pages> 387-402, </pages> <year> 1994. </year>
Reference-contexts: For these matrices, level-of-fill may be less effective at predicting the locations of the largest entries in the factorization. As an alternative to dropping techniques based on structure, fill-in can be dropped during the factorization, based on their numerical size <ref> [27, 34, 36, 44] </ref>. This is a kind of greedy approach to minimizing E in (1). Numerical dropping strategies generally yield more accurate factorizations with the same amount of fill-in than level-of-fill methods. This is true even for some diagonally dominant M-matrices. <p> This is the maximum number of nonzeros in each row y and z when a row of the factorization is computed, i.e., the largest lfil entries are retained in each of y and z. This implementation is called ILUT (droptol, lfil) <ref> [34] </ref>. The lfil parameter makes the storage requirements for the preconditioner known beforehand. However, by limiting the fill-in in each row but not each column, a very nonsymmetric preconditioner may be produced.
Reference: [35] <author> Y. Saad. </author> <title> Preconditioned Krylov subspace methods for CFD applications. </title> <editor> In W. G. Habashi, editor, </editor> <booktitle> Proceedings of the International Workshop on Solution Techniques for Large-Scale CFD Problems, </booktitle> <pages> pages 179-195, </pages> <address> Montreal, Quebec, </address> <year> 1994. </year>
Reference-contexts: However, the symmetric structure can be preserved with an incomplete form of LDU Gaussian elimination based on bordering <ref> [11, 30, 35] </ref>. Let A k+1 be the (k + 1)-st leading principal submatrix of A and assume we have the decomposition A k = L k D k U k . <p> He called this a `stabilized' incomplete factorization. In general, a major difficulty is the determination of the threshold value for the pivots, or the shift ff. For irregularly structured symmetric matrices, Saad <ref> [35] </ref> gave a heuristic formula for the shift to help ensure that each pivot will be greater than some small positive value. Numerical experiments for positive definite matrices show that convergence improves sharply as ff is increased toward the optimal ff, and then deteriorates slowly [24, 35]. <p> Numerical experiments for positive definite matrices show that convergence improves sharply as ff is increased toward the optimal ff, and then deteriorates slowly <ref> [24, 35] </ref>. Shifted or stabilized factorizations are not to be confused with modified ILU (MILU) factorizations [21] where the row-sum criteria Ae = LU e; e = (1; 1; ; 1) T is satisfied by modifying the diagonal of L or U .
Reference: [36] <author> O. sterby and Z. Zlatev. </author> <title> Direct Methods for Sparse Matrices, </title> <booktitle> volume 157 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1983. </year>
Reference-contexts: For these matrices, level-of-fill may be less effective at predicting the locations of the largest entries in the factorization. As an alternative to dropping techniques based on structure, fill-in can be dropped during the factorization, based on their numerical size <ref> [27, 34, 36, 44] </ref>. This is a kind of greedy approach to minimizing E in (1). Numerical dropping strategies generally yield more accurate factorizations with the same amount of fill-in than level-of-fill methods. This is true even for some diagonally dominant M-matrices.
Reference: [37] <author> H. A. Van der Vorst. </author> <title> Iterative solution methods for certain sparse linear systems with a non-symmetric matrix arising from PDE-problems. </title> <journal> J. Computational Physics, </journal> <volume> 44(1) </volume> <pages> 1-19, </pages> <year> 1981. </year>
Reference-contexts: A coupled effect is that the long recurrences associated with solving with these factors are unstable [6, 16]. A remedy is also to use diagonal perturbations, this time to make the factors diagonally dominant <ref> [27, 37, 17] </ref>, but the perturbations in this case may need to be very large. fl Work supported in part by the National Science Foundation under grant NSF/CCR-9618827 and in part by NASA under grant NAG2-904. <p> The shift should make the pivots large enough so that the matrix is not too poorly conditioned. Van der Vorst <ref> [37] </ref> found the same result for nonsymmetric matrices, and suggested modifications to the diagonal to make the resulting factors diagonally dominant. He called this a `stabilized' incomplete factorization. In general, a major difficulty is the determination of the threshold value for the pivots, or the shift ff. <p> The larger shift has the effect of making the problem much better conditioned. Stabilization essentially amounts to the factorization of a better conditioned matrix. This is an important effect of stabilization that was discovered experimentally <ref> [24, 37] </ref>. For block incomplete factorizations, the pivot is a block. The equivalent of a small pivot in this case is a block that is very poorly conditioned, with an inverse that has very large entries.
Reference: [38] <author> H. A. Van der Vorst. </author> <title> Stabilized incomplete LU-decompositions as preconditionings for the Tchebycheff iteration. </title> <editor> In D. J. Evans, editor, </editor> <title> Preconditioning methods: Analysis and Applications, </title> <address> New York, 1983. </address> <publisher> Gordon and Breach. </publisher>
Reference-contexts: For low amounts of fill-in, there are not enough nonzeros to make very large values of `condest.' BILUK (0) corresponds to lfil of approximately 4. BILUT is successful in this case for lfil approximately 23. Van der Vorst <ref> [38] </ref> briefly investigated the effect that increasing fill-in has on stability in the nonsymmetric case. His conclusion also was that increasing the accuracy does not seem to help, unless of course, the accuracy approaches that of a direct solve.
Reference: [39] <author> R. S. Varga. </author> <title> Factorization and normalized iterative methods. </title> <editor> In R. E. Langer, editor, </editor> <title> Boundary Problems in Differential Equations, </title> <type> pages 121-142, </type> <institution> Santa Barbara, California, 1960. University of Wisconsin Press. </institution>
Reference-contexts: For these problems, the structure of the incomplete triangular factors was chosen based on the structure of the gridpoint operators <ref> [7, 28, 29, 39] </ref> (see also the review [9]) and the resulting structure of the error matrix E.
Reference: [40] <author> R. S. Varga, E. B. Saff, and V. Mehrman. </author> <title> Incomplete factorizations of matrices and connections with h-matrices. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 17 </volume> <pages> 787-793, </pages> <year> 1980. </year>
Reference-contexts: 1 Introduction The incomplete LU factorization preconditioners were originally developed for M-matrices, for which properties such as existence and a form of stability can be proved [25] (see also <ref> [40] </ref>). However, ILU preconditioners have been successfully applied in much more general situations. In the general symmetric case, diagonal perturbations of the matrix are required to help guarantee the existence of a symmetric factorization [23, 24, 27].
Reference: [41] <author> J. W. Watts-III. </author> <title> A conjugate gradient truncated direct method for the iterative solution of the reservoir simulation pressure equation. </title> <journal> Soc. Pet. Eng. J., </journal> <volume> 21 </volume> <pages> 345-353, </pages> <year> 1981. </year>
Reference-contexts: Note that the sparsity pattern should include the full diagonal, even if there are zeros on the diagonal, as in the case of some indefinite matrices. To get more accurate factorizations for general sparse matrices, the concept of level-of-fill was introduced <ref> [41] </ref>. Suppose a matrix A has diagonal elements of size O (* 0 ) and off-diagonal elements of size O (* 1 ), with *&lt;1, and the exponent on * indicating the level of the nonzero element.
Reference: [42] <author> G. Wittum. </author> <title> On the robustness of ILU-smoothing. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 10 </volume> <pages> 699-717, </pages> <year> 1989. </year>
Reference-contexts: Relaxed ILU (RILU) [2, 3] parameterizes the fraction of the modification to perform, giving it the same effect as the perturbation. Negative relaxation factors in RILU have a stabilizing effect for M-matrices. They were used for multigrid smoothing by Wittum <ref> [42] </ref> in his ILU fi method. The diagonal is augmented with fi times the sum of the magnitudes of the dropped elements. ILU 0 corresponds to the regular, unmodified factorization, ILU 1 corresponds to MILU, and ILU 1 corresponds to the modification of Jennings and Malik [22].
Reference: [43] <author> A. Yu. </author> <title> Yeremin. </title> <type> Private communication, </type> <year> 1995. </year>
Reference-contexts: The equivalent of a small pivot in this case is a block that is very poorly conditioned, with an inverse that has very large entries. It is possible to perform a shift for a block by shifting its singular values away from zero <ref> [43] </ref>.
Reference: [44] <author> Z. Zlatev, V. A. Barker, and P. G. Thomsen. SLEST: </author> <title> A Fortran IV subroutine for solving sparse systems of linear equations. User's guide. </title> <type> Technical Report NI-78-01, </type> <institution> Numerisk Institut, Lyngby, Denmark, </institution> <year> 1978. </year>
Reference-contexts: For these matrices, level-of-fill may be less effective at predicting the locations of the largest entries in the factorization. As an alternative to dropping techniques based on structure, fill-in can be dropped during the factorization, based on their numerical size <ref> [27, 34, 36, 44] </ref>. This is a kind of greedy approach to minimizing E in (1). Numerical dropping strategies generally yield more accurate factorizations with the same amount of fill-in than level-of-fill methods. This is true even for some diagonally dominant M-matrices.
References-found: 44

