URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-455.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: pinhanez bobick@media.mit.edu  
Title: an Autonomous Computer Graphics Character  
Author: Claudio Pinhanez Aaron Bobick 
Address: Ames St. Cambridge, MA 02139  
Affiliation: 20  
Note: "It/I": A Theater Play Featuring  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 455 (submitted to SIGGRAPH'98) - January 1998 Abstract "It/I" is a two-character theater play where the human character I is taunted and played by an autonomous computer-graphics character It. We believe that "It/I" is the first play ever produced involving a character reactively controlled by a computer. Autonomous characters can bring a new dimension to the theater experience by enabling the audience to go up on stage after the performance and interact directly with the characters, re-enacting the story of the play. This paper reports the experience and examines technical developments needed for the successful production of "It/I". In particular we describe the interval script paradigm used to program the CG-character, the proposed SCD-architecture for story-based interactive systems, and the ActScript language for communication of actions and goals.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James F. Allen. </author> <title> Towards a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 123-154, </pages> <year> 1984. </year>
Reference-contexts: In other words, actions | and thus, interaction | can not be fully described neither by events (as Director does), nor by simple tree-forking structures as proposed by Perlin's or Bates' works, nor by straight encapsulation such as suggested by structured programming. We adopted Allen's interval algebra <ref> [1] </ref> as the temporal model of interval scripts. According to this algebra the temporal relationship between two intervals is defined as a disjunction of 13 basic primitives.
Reference: [2] <author> Joseph Bates, A. Bryan Loyall, and W. Scott Reilly. </author> <title> An architecture for action, emotion, and social behavior. </title> <booktitle> In Proceedings of the Fourth European Workshop on Modeling Autonomous Agents in a Multi-Agent World, </booktitle> <editor> S. Martino al Cimino, </editor> <address> Italy, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Unlike previous work involving automated characters <ref> [16, 2] </ref>, our work addresses the situation where the actor or user's body is the body of one of characters, and 1 Examples of use of electronic puppets are more common in the context of performance animation. <p> It is arguable whether story control should be centralized. Perlin & Goldberg [16] and Bates et. al. <ref> [2] </ref> built (semi-) autonomous computer-actors with such characteristics. However, in both cases, the story was distributed among the characters, or seen as the natural result of the interaction between the characters and the user.
Reference: [3] <author> Aaron F. Bobick and James W. Davis. </author> <title> An appearance-based representation of action. </title> <type> Technical Report 369, </type> <institution> M.I.T. Media Laboratory Perceptual Computing Section, </institution> <month> February </month> <year> 1996. </year> <note> To appear in ICPR'96. </note>
Reference-contexts: Besides that, the 30-minute performance was completely autonomous, even during the audience part. Since the recognition of this kind of gesture has been demonstrated in computer vision (see <ref> [3] </ref>) and in real-time environments [4], we believe that there are no technical obstacles for a fully autonomous run of the play. 9 Conclusion "It/I" is part of a continuing work of understanding and developing technology for story-based, interactive, immer-sive environments.
Reference: [4] <author> Aaron F. Bobick, Jim Davis, Stephen Intille, Freedom Baird, Lee Campbell, Yuri Ivanov, Claudio Pinhanez, Arjan Schutte, and Andy Wilson. Kidsroom: </author> <title> Action recognition in an interactive story environment. </title> <type> Technical Report 398, </type> <institution> M.I.T. Media Laboratory Perceptual Computing Section, </institution> <year> 1996. </year>
Reference-contexts: of response, It brings the switch to the screen and turns it off, leaving I in an empty, silent, lightless world. 4 Control Architecture The production of "It/I" is part of our continuing research on developing technology for interactive, immersive environments which started with SingSong [21], followed by The KidsRoom <ref> [4] </ref>, and after "It/I", by PAT, a virtual aerobics personal trainer [7]. is a 3-layer architecture where the upper layer contains the story control module, followed by a layer of systems to control each individual character, and a final layer of modules to deal with the actual input and output devices. <p> Besides that, the 30-minute performance was completely autonomous, even during the audience part. Since the recognition of this kind of gesture has been demonstrated in computer vision (see [3]) and in real-time environments <ref> [4] </ref>, we believe that there are no technical obstacles for a fully autonomous run of the play. 9 Conclusion "It/I" is part of a continuing work of understanding and developing technology for story-based, interactive, immer-sive environments.
Reference: [5] <author> M. Cecelia Buchanan and Polle T. Zellweger. </author> <title> Automatic temporal layout mechanisms. </title> <booktitle> In Proc. of ACM Multimedia'93, </booktitle> <pages> pages 341-350, </pages> <address> Ahaheim, California, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: In these cases, the emphasis is on realistic-looking ways of describing human motion with little provision for scripting interaction and sensory input. The other type corresponds to languages for description of interaction as for example Director [12] and the works of Buchanan & Zelllweger <ref> [5] </ref> and Hamakawa & Rekimoto [8].
Reference: [6] <author> James W. Davis and A. Bobick. </author> <title> The representation and recognition of human movement using temporal templates. </title> <booktitle> In Proc. of CVPR'97, </booktitle> <pages> pages 928-934, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: In many ways, It's understanding of the world reflects the state-of-art of real-time automatic vision: the character's reaction is mostly based on tracking I's movements and position and on the recognition of some specific gestures (using <ref> [6] </ref>). on the stage interacting with the tv-like object projected in the screen behind him. Figure 2 depicts a diagram of the different components of the physical setup of "It/I". <p> Smaller blobs are labeled as blocks. The vision system is also trained to recognize 5 different static gestures. For this, we employed a simplification of the technique described in <ref> [6] </ref>. 7.2 The Computer Graphics Modules The computer graphics modules control the generation and movement of the different objects and flat images which appear on the stage screens. Each CG module basically processes requests similar to the one displayed in fig. 5 translating them into Inventor commands.
Reference: [7] <author> James W. Davis and Aaron F. Bobick. </author> <title> Virtual PAT: a virtual personal aerobics trainer. </title> <type> Technical Report 436, </type> <institution> M.I.T. Media Laboratory Perceptual Computing Section, </institution> <month> January </month> <year> 1998. </year>
Reference-contexts: it off, leaving I in an empty, silent, lightless world. 4 Control Architecture The production of "It/I" is part of our continuing research on developing technology for interactive, immersive environments which started with SingSong [21], followed by The KidsRoom [4], and after "It/I", by PAT, a virtual aerobics personal trainer <ref> [7] </ref>. is a 3-layer architecture where the upper layer contains the story control module, followed by a layer of systems to control each individual character, and a final layer of modules to deal with the actual input and output devices.
Reference: [8] <author> Rei Hamakawa and Jun Rekimoto. </author> <title> Object composition and playback models for handling multimedia data. </title> <booktitle> In Proc. of ACM Multimedia'93, </booktitle> <pages> pages 273-281, </pages> <address> Ahaheim, California, </address> <month> August </month> <year> 1993. </year> <month> 7 </month>
Reference-contexts: In these cases, the emphasis is on realistic-looking ways of describing human motion with little provision for scripting interaction and sensory input. The other type corresponds to languages for description of interaction as for example Director [12] and the works of Buchanan & Zelllweger [5] and Hamakawa & Rekimoto <ref> [8] </ref>.
Reference: [9] <author> Yuri Ivanov, Aaron Bobick, and John Liu. </author> <title> Fast lighting independent background subtraction. </title> <booktitle> In IEEE Workshop on Visual Surveillance - VS'98, </booktitle> <pages> pages 49-55, </pages> <address> Bombay, India, </address> <month> January </month> <year> 1998. </year>
Reference-contexts: In the performance setup we employed a frontal 3-camera stereo system that is able to segment the actor and the blocks, computing a silhouette image that is used to track and recognize gestures. The stereo system, based on <ref> [9] </ref>, constructs off-line a depth map of the background | stage, backdrops, and screens. Based on the depth map, it is possible to determine in real-time whether a pixel in the central camera image belongs to the background or to the foreground, in spite of lighting or screen changes.
Reference: [10] <author> Jugal Kumar Kalita. </author> <title> Natural Language Control of Animation of Task Performance in a Physical Domain. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, Pennsylvania, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Previous work on scripting languages can be divided into two types. The first deals with languages for scripting movements and reactions of characters, like the work of Perlin [15], Kalita <ref> [10] </ref>, and Thalman [24]. In these cases, the emphasis is on realistic-looking ways of describing human motion with little provision for scripting interaction and sensory input. <p> We are currently developing this work further into a language, ActScript, able to represent actions, requests, queries, and goals in a physical environment. Unlike previous work in languages for CG characters (for example, <ref> [16, 10, 24] </ref>), ActScript allows recursive decomposition of actions, specification of complex temporal relationships, and translation to/from (request (action "left-cg-module" (move (object "camera") (direction to (location (0.0 0.4 0.5)) from (location (0.0 3.0 -1.0))) (path (location (0.0 -0.03 0.0))) (when NOW) (velocity (special "crescendo")) (interval (timed duration 5.0))))) in ActScript. (request
Reference: [11] <author> Susanne K. Langer. </author> <title> Feeling and Form. </title> <publisher> Charles Scrib-ner's Sons, </publisher> <address> New York, New York, </address> <year> 1953. </year>
Reference-contexts: However, in both cases, the story was distributed among the characters, or seen as the natural result of the interaction between the characters and the user. We believe that centralized story control is very important for an interactive system to achieve successful story development. As pointed by Langer <ref> [11] </ref> and Mur-ray [14], well-constructed stories require coordination and synchronicity of events and coincidences; also, dramatic actions have to forecast the future, especially in the context of theatrical stories 4 . Such coordination, in our view, is only possible with centralized story control. <p> An interval script is a computer file containing the description of each action and statements about how the intervals are related temporally. A complete description of the syntax and semantics of interval scripts is beyond the 4 See Langer <ref> [11] </ref>, chapter 7, for a complex but insightful argumentation about how in theater it is fundamental that actions in the present are determined by the happenings in the future. 3 scope of this paper.
Reference: [12] <author> MacroMind Inc. Director's User Manual. </author> <year> 1990. </year>
Reference-contexts: In these cases, the emphasis is on realistic-looking ways of describing human motion with little provision for scripting interaction and sensory input. The other type corresponds to languages for description of interaction as for example Director <ref> [12] </ref> and the works of Buchanan & Zelllweger [5] and Hamakawa & Rekimoto [8].
Reference: [13] <author> Pattie Maes, Trevor Darrell, Bruce Blumberg, and Alex Pentland. </author> <title> The ALIVE system: Full-body interaction with autonomous agents. </title> <booktitle> In Proc. of the Computer Animation '95 Conference, </booktitle> <address> Geneva, Switzer-land, </address> <month> April </month> <year> 1995. </year>
Reference: [14] <author> Janet Murray. </author> <title> Hamlet on the Holodeck: the Future of Narrative in Cyberspace. </title> <publisher> The Free Press, Simon & Schuster, </publisher> <year> 1997. </year>
Reference-contexts: We believe that centralized story control is very important for an interactive system to achieve successful story development. As pointed by Langer [11] and Mur-ray <ref> [14] </ref>, well-constructed stories require coordination and synchronicity of events and coincidences; also, dramatic actions have to forecast the future, especially in the context of theatrical stories 4 . Such coordination, in our view, is only possible with centralized story control.
Reference: [15] <author> Ken Perlin. </author> <title> Real time responsive animation with personality. </title> <journal> IEEE Transactions on Visualization and Computer Graphics, </journal> <volume> 1(1) </volume> <pages> 5-15, </pages> <year> 1995. </year>
Reference-contexts: Previous work on scripting languages can be divided into two types. The first deals with languages for scripting movements and reactions of characters, like the work of Perlin <ref> [15] </ref>, Kalita [10], and Thalman [24]. In these cases, the emphasis is on realistic-looking ways of describing human motion with little provision for scripting interaction and sensory input.
Reference: [16] <author> Ken Perlin and Athomas Goldberg. Improv: </author> <title> A system for scripting interactive actors in virtual worlds. </title> <booktitle> In Proc. of SIGGRAPH'96, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Unlike previous work involving automated characters <ref> [16, 2] </ref>, our work addresses the situation where the actor or user's body is the body of one of characters, and 1 Examples of use of electronic puppets are more common in the context of performance animation. <p> It is arguable whether story control should be centralized. Perlin & Goldberg <ref> [16] </ref> and Bates et. al. [2] built (semi-) autonomous computer-actors with such characteristics. However, in both cases, the story was distributed among the characters, or seen as the natural result of the interaction between the characters and the user. <p> We are currently developing this work further into a language, ActScript, able to represent actions, requests, queries, and goals in a physical environment. Unlike previous work in languages for CG characters (for example, <ref> [16, 10, 24] </ref>), ActScript allows recursive decomposition of actions, specification of complex temporal relationships, and translation to/from (request (action "left-cg-module" (move (object "camera") (direction to (location (0.0 0.4 0.5)) from (location (0.0 3.0 -1.0))) (path (location (0.0 -0.03 0.0))) (when NOW) (velocity (special "crescendo")) (interval (timed duration 5.0))))) in ActScript. (request
Reference: [17] <author> Claudio S. Pinhanez. </author> <booktitle> Computer theater. In Proc. of the Eighth International Symposium on Electronic Arts (ISEA'97), </booktitle> <address> Chicago, Illinois, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: We end by describing the performances and the future developments in the play and in the technology. 2 Computer Theater Computer theater is a term referring to live theatrical performances involving the active use of computers in the artistic process. Pinhanez <ref> [17] </ref> contains a detailed exposition about computer theater, the origins of the term, and related works. Our research has been concentrated in building automatic, semi-autonomous computer-actors able to interact with human actors on camera-monitored stages.
Reference: [18] <author> Claudio S. Pinhanez and Aaron F. Bobick. </author> <title> Approximate world models: Incorporating qualitative and linguistic information into vision systems. </title> <booktitle> In AAAI'96, </booktitle> <pages> pages 1116-1123, </pages> <address> Portland, Oregon, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: In this situation those three modules have to exchange information concerning actions to be and being executed, and characters' goals. This is accomplished using the communication language described in the next section. 6 Communicating Actions In <ref> [18] </ref>, Pinhanez & Bobick revitalized Roger Schank's conceptualizations [22] as a formalism to represent action that enables shallow reasoning. We are currently developing this work further into a language, ActScript, able to represent actions, requests, queries, and goals in a physical environment.
Reference: [19] <author> Claudio S. Pinhanez and Aaron F. Bobick. </author> <title> Computer theater: Stage for action understanding. </title> <booktitle> In Proc. of the AAAI'96 Workshop on Entertainment and AI/A-Life, </booktitle> <pages> pages 28-33, </pages> <address> Portland, Oregon, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: The performance context brings two simplifying factors to the construction of interactive, immersive systems (see also <ref> [19] </ref>). First, the human actor knows how to interact with the computer character within the limitations of the sensory apparatus. Second, after watching the performance, the members of the audience transformed in actors have probably learned the basic structure and interaction modes of the play.
Reference: [20] <author> Claudio S. Pinhanez and Aaron F. Bobick. </author> <title> Fast constraint propagation on specialized Allen networks and its application to action recognition and control. </title> <type> Technical Report 456, </type> <institution> M.I.T. Media Laboratory Perceptual Computing Section, </institution> <month> January </month> <year> 1998. </year>
Reference-contexts: According to this algebra the temporal relationship between two intervals is defined as a disjunction of 13 basic primitives. It is beyond the scope of this paper to detail how the algebra works, our approach for fast temporal reasoning, or how the interval script is actually computed (see <ref> [20] </ref>). Our objective here is to exemplify how temporal constraints can be incorporated into interval scripts allowing a significant increase in script expressiveness.
Reference: [21] <author> Claudio S. Pinhanez, Kenji Mase, and Aaron F. Bo-bick. </author> <title> Interval scripts: A design paradigm for story-based interactive systems. </title> <booktitle> In CHI'97, </booktitle> <pages> pages 287-294, </pages> <address> Atlanta, Georgia, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: We begin by discussing the advantages and disadvantages of having centralized control of story as used in the story-character-device (SCD) architecture employed in "It/I". The two main technical developments proportioned by "It/I" were the interval script paradigm used for character and story scripting (based on <ref> [21] </ref>); and the language for communication between characters, story, and physical devices called ActScript. The description of both paradigms stresses the burden brought into interactive, immersive systems by the the need to recognize human action in a physical environment. <p> Finally, given the lack of response, It brings the switch to the screen and turns it off, leaving I in an empty, silent, lightless world. 4 Control Architecture The production of "It/I" is part of our continuing research on developing technology for interactive, immersive environments which started with SingSong <ref> [21] </ref>, followed by The KidsRoom [4], and after "It/I", by PAT, a virtual aerobics personal trainer [7]. is a 3-layer architecture where the upper layer contains the story control module, followed by a layer of systems to control each individual character, and a final layer of modules to deal with the
Reference: [22] <author> Roger C. Schank. </author> <title> Conceptual dependency theory. </title> <booktitle> In Conceptual Information Processing, chapter 3, </booktitle> <pages> pages 22-82. </pages> <publisher> North-Holland, </publisher> <year> 1975. </year>
Reference-contexts: In this situation those three modules have to exchange information concerning actions to be and being executed, and characters' goals. This is accomplished using the communication language described in the next section. 6 Communicating Actions In [18], Pinhanez & Bobick revitalized Roger Schank's conceptualizations <ref> [22] </ref> as a formalism to represent action that enables shallow reasoning. We are currently developing this work further into a language, ActScript, able to represent actions, requests, queries, and goals in a physical environment.
Reference: [23] <author> Christa Sommerer and Laurent Mignonneau. </author> <title> Art as a living system. </title> <journal> Leonardo, </journal> <volume> 30(5), </volume> <month> October </month> <year> 1997. </year>
Reference: [24] <author> Nadia Magnetat Thalmann and Daniel Thalmann. </author> <title> Synthetic Actors in Computer Generated 3D Films. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1990. </year> <month> 8 </month>
Reference-contexts: Previous work on scripting languages can be divided into two types. The first deals with languages for scripting movements and reactions of characters, like the work of Perlin [15], Kalita [10], and Thalman <ref> [24] </ref>. In these cases, the emphasis is on realistic-looking ways of describing human motion with little provision for scripting interaction and sensory input. <p> We are currently developing this work further into a language, ActScript, able to represent actions, requests, queries, and goals in a physical environment. Unlike previous work in languages for CG characters (for example, <ref> [16, 10, 24] </ref>), ActScript allows recursive decomposition of actions, specification of complex temporal relationships, and translation to/from (request (action "left-cg-module" (move (object "camera") (direction to (location (0.0 0.4 0.5)) from (location (0.0 3.0 -1.0))) (path (location (0.0 -0.03 0.0))) (when NOW) (velocity (special "crescendo")) (interval (timed duration 5.0))))) in ActScript. (request
References-found: 24

