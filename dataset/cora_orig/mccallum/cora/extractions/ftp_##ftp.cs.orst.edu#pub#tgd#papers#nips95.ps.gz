URL: ftp://ftp.cs.orst.edu/pub/tgd/papers/nips95.ps.gz
Refering-URL: http://www.cs.orst.edu/~tgd/cv/pubs.html
Root-URL: 
Email: fzhangw, tgdg@research.cs.orst.edu  
Title: High-Performance Job-Shop Scheduling With A Time-Delay TD() Network  
Author: Wei Zhang and Thomas G. Dietterich 
Keyword: Category: Control, Navigation, and Planning: Reinforcement Learning Presentation Preference: Poster.  
Address: Corvallis, Oregon 97331-3202  
Affiliation: Department of Computer Science Oregon State University  
Abstract: Job-shop scheduling is an important task for manufacturing industries. We are interested in the particular task of scheduling payload processing for NASA's space shuttle program. This paper summarizes our previous work on formulating this task for solution by the reinforcement learning algorithm T D(). A shortcoming of this previous work was its reliance on hand-engineered input features. This paper shows how to extend the time-delay neural network (TDNN) architecture to apply it to irregular-length schedules. Experimental tests show that this TDNN-T D() network can match the performance of our previous hand-engineered system. The tests also show that both neural network approaches significantly outperform the best previous (non-learning) solution to this problem in terms of the quality of the resulting schedules and the number of search steps required to construct them.
Abstract-found: 1
Intro-found: 1
Reference: [ Lang et al., 1990 ] <author> K. J. Lang, A. H. Waibel, and G. E. Hinton. </author> <title> A time-dalay neural network architecture for isolated word recognition. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 33-43, </pages> <year> 1990. </year>
Reference-contexts: To obtain those results, we hand-engineered a set of input features. An advantage of neural network algorithms, however, is that they can often learn good "features" (i.e., hidden units) from more primitive, raw features. The work described in this paper shows how to apply the time-delay neural network architecture <ref> [ Lang et al., 1990, LeCun et al., 1989 ] </ref> to this task to learn from raw features and thereby eliminate hand-engineering. In the following sections, we first describe the scheduling task and show how this task can be formulated for TD (). <p> However, hand-engineering increases the cost of creating a new application and reduces the autonomy of the learning system. Therefore, we wish to develop a method that can automatically learn good input features. The time-delay neural network <ref> [ Lang et al., 1990 ] </ref> has proved to be very effective in learning good position-independent features in visual- and speech-recognition tasks. In speech recognition, it is applied to convert an input sequence of speech frames into a "hidden sequence" of extracted features.
Reference: [ LeCun et al., 1989 ] <author> Y. LeCun, B. Boser, J. S. Deniker, and D. Henderson et al. </author> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> neural computation, </journal> <volume> 1 </volume> <pages> 541-551, </pages> <year> 1989. </year>
Reference-contexts: To obtain those results, we hand-engineered a set of input features. An advantage of neural network algorithms, however, is that they can often learn good "features" (i.e., hidden units) from more primitive, raw features. The work described in this paper shows how to apply the time-delay neural network architecture <ref> [ Lang et al., 1990, LeCun et al., 1989 ] </ref> to this task to learn from raw features and thereby eliminate hand-engineering. In the following sections, we first describe the scheduling task and show how this task can be formulated for TD ().
Reference: [ Pomerleau, 1991 ] <author> D. A. Pomerleau. </author> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <journal> Neural Computation, </journal> <volume> 3(1) </volume> <pages> 88-97, </pages> <year> 1991. </year>
Reference-contexts: H2 has no adjustable parameters. H3 has 40 hidden units fully connected to H2, for a total of 720 parameters. The output layer has 8 units fully connected to H3 and encoding the predicted RDF using the technique of overlapping gaussian ranges <ref> [ Pomerleau, 1991 ] </ref> . The output layer has 328 (= 8 (40 + 1)) parameters. Therefore, this net has a total of 1123 parameters.
Reference: [ Sutton, 1988 ] <author> R. S. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3(1) </volume> <pages> 9-44, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: 1 Introduction In Tesauro's 1992 landmark work on TD-gammon, he showed that the temporal difference algorithm T D () <ref> [ Sutton, 1988 ] </ref> can learn an excellent evaluation function for the game of backgammon. This is probably the most successful application of reinforcement learning to date. The goal of our research is to determine whether this success can be duplicated in an application of industrial importance: Job-shop scheduling.
Reference: [ Tesauro, 1992 ] <author> G. J. Tesauro. </author> <title> Practical issues in temporal difference learning. </title> <journal> Machine Learning, </journal> 8(3/4):257-277, 1992. 
Reference: [ Zhang and Dietterich, 1995 ] <author> W. Zhang and T. Dietterich. </author> <title> A reinforcement learning approach to job-shop scheduling. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year> <note> (to appear). </note>
Reference-contexts: The best existing method for this task is an iterative repair scheduler that combines heuristics with simulated annealing [ Zweben et al., 1994 ] . In <ref> [ Zhang and Dietterich, 1995 ] </ref> , we report initial results showing that a neural network-based T D () scheduler can out-perform this iterative repair algorithm. To obtain those results, we hand-engineered a set of input features. <p> All units in H1, H3, and the output layer use sigmoidal transfer functions. 4 Experiments We constructed an artificial problem set based on specifications for the NASA SSPP problem. Space constraints do not permit a complete description of the problems or the training procedure (see <ref> [ Zhang and Dietterich, 1995 ] </ref> for full details). 100 scheduling problems were generated. These were subdivided into 50 problems for final testing, 20 problems for validation testing, and three training sets of 10 problems bars show 95% confidence intervals.
Reference: [ Zweben et al., 1994 ] <author> M. Zweben, B. Daun, and M. Deale. </author> <title> Scheduling and rescheduling with iterative repair. </title> <editor> In M. Zweben and M. S. Fox, editors, </editor> <title> Intelligent Scheduling, </title> <booktitle> chapter 8, </booktitle> <pages> pages 241-255. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1994. </year>
Reference-contexts: The goal is to schedule a set of tasks to satisfy a set of temporal and resource constraints while also seeking to minimize the total duration (makespan) of the schedule. The best existing method for this task is an iterative repair scheduler that combines heuristics with simulated annealing <ref> [ Zweben et al., 1994 ] </ref> . In [ Zhang and Dietterich, 1995 ] , we report initial results showing that a neural network-based T D () scheduler can out-perform this iterative repair algorithm. To obtain those results, we hand-engineered a set of input features.
References-found: 7

