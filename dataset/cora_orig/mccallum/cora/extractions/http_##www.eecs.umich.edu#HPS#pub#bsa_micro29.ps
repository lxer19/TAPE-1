URL: http://www.eecs.umich.edu/HPS/pub/bsa_micro29.ps
Refering-URL: http://www.eecs.umich.edu/HPS/hps_micro.html
Root-URL: http://www.cs.umich.edu
Email: ehao@eecs.umich.edu  
Title: Increasing the Instruction Fetch Rate via Block-Structured Instruction Set Architectures  
Author: Eric Hao, Po-Yung Chang, Marius Evers, and Yale N. Patt 
Address: Ann Arbor, MI 48109-2122  
Affiliation: Advanced Computer Architecture Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Web: accessible.  
Note: This work has been submitted to the IEEE for possible publication in the Proceedings of the 29th Annual International Symposium on Microarchitecture, December 2-4, 1996, Paris, France. Copyright may be transferred without notice, after which this version may no longer be  
Abstract: To exploit larger amounts of instruction level parallelism, processors are being built with wider issue widths and larger numbers of functional units. Instruction fetch rate must also be increased in order to effectively exploit the performance potential of such processors. Block-structured ISAs provide an effective means of increasing the instruction fetch rate. We define an optimization, called block enlargement, that can be applied to a block-structured ISA to increase the instruction fetch rate of a processor that implements that ISA. We have constructed a compiler that generates block-structured ISA code, and a simulator that models the execution of that code on a block-structured ISA processor. We show that for the SPECint95 benchmarks, the block-structured ISA processor executing enlarged atomic blocks outperforms a conventional ISA processor by 12% while using simpler microarchitectural mechanisms to support wide-issue and dynamic scheduling. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. M. Conte, K. N. Menezes, P. M. Mills, and B. Patel. </author> <title> Optimization of instruction fetch mechanisms for high issue rates. </title> <booktitle> In Proceedings of the 22st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 333-344, </pages> <year> 1995. </year>
Reference-contexts: Various approaches have been proposed for increasing instruction fetch rate from that of a single basic block per cycle. Some approaches <ref> [24, 1, 2, 20] </ref> extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple, non-consecutive cache lines can be fetched each cycle. However, this extra hardware requires extra stages in the pipeline which will increase the branch misprediction penalty, decreasing performance. <p> The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. They include the branch address cache [24], the collapsing buffer <ref> [1] </ref>, the subgraph-level predictor [2], the multiple-block ahead branch predictor [20], and the trace cache [19]. Trace scheduling [5] and superblock scheduling [8] are compiler optimizations that enlarge the scope in which the compiler can schedule instructions. <p> The compiler may have to delay the scheduling of certain operations in order to meet these requirements, lowering the instruction fetch rate of the processor. The branch address cache [24], the collapsing buffer <ref> [1] </ref>, the subgraph-level predictor [2], and the multiple-block ahead branch predictor [20] are hardware schemes that propose different ways to extend the dynamic branch predictor so that it can make multiple branch predictions each cycle.
Reference: [2] <author> S. Dutta and M. Franklin. </author> <title> Control flow prediction with treelike subgraphs for superscalar processors. </title> <booktitle> In Proceedings of the 28th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pages 258-263, </pages> <year> 1995. </year>
Reference-contexts: Various approaches have been proposed for increasing instruction fetch rate from that of a single basic block per cycle. Some approaches <ref> [24, 1, 2, 20] </ref> extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple, non-consecutive cache lines can be fetched each cycle. However, this extra hardware requires extra stages in the pipeline which will increase the branch misprediction penalty, decreasing performance. <p> The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. They include the branch address cache [24], the collapsing buffer [1], the subgraph-level predictor <ref> [2] </ref>, the multiple-block ahead branch predictor [20], and the trace cache [19]. Trace scheduling [5] and superblock scheduling [8] are compiler optimizations that enlarge the scope in which the compiler can schedule instructions. <p> The compiler may have to delay the scheduling of certain operations in order to meet these requirements, lowering the instruction fetch rate of the processor. The branch address cache [24], the collapsing buffer [1], the subgraph-level predictor <ref> [2] </ref>, and the multiple-block ahead branch predictor [20] are hardware schemes that propose different ways to extend the dynamic branch predictor so that it can make multiple branch predictions each cycle.
Reference: [3] <author> K. Ebcioglu. </author> <title> Some design ideas for a VLIW architecture for sequential natured software. </title> <booktitle> Parallel Processing (Proceedings of IFIP WG 10.3 Working Conference on Parallel Processing, </booktitle> <pages> pages 3-21, </pages> <month> Apr. </month> <year> 1988. </year>
Reference-contexts: The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling [5, 8], predicated execution [7, 12, 18], and the VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref>. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> While predicated execution by itself may not be an effective mechanism for increasing instruction fetch rate, it can provide a significant performance benefit when used in conjunction with speculative execution [11] and other schemes for increasing fetch rate. The VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref> combines multiple branches from multiple paths in the control flow graph into a single branch. Using this mechanism, basic blocks which form a rooted subgraph in the control flow graph can be combined into a single VLIW instruction.
Reference: [4] <author> J. A. Fisher. </author> <title> 2 n -way jump microinstruction hardware and an effective instruction binding method. </title> <booktitle> In Proceedings of the 13th Annual Microprogramming Workshop, </booktitle> <pages> pages 64-75, </pages> <year> 1980. </year>
Reference-contexts: The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling [5, 8], predicated execution [7, 12, 18], and the VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref>. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> While predicated execution by itself may not be an effective mechanism for increasing instruction fetch rate, it can provide a significant performance benefit when used in conjunction with speculative execution [11] and other schemes for increasing fetch rate. The VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref> combines multiple branches from multiple paths in the control flow graph into a single branch. Using this mechanism, basic blocks which form a rooted subgraph in the control flow graph can be combined into a single VLIW instruction.
Reference: [5] <author> J. A. Fisher. </author> <title> Trace scheduling: A technique for global microcode compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(7):478-490, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: However, this extra hardware requires extra stages in the pipeline which will increase the branch misprediction penalty, decreasing performance. Other approaches <ref> [5, 8] </ref> statically predict the direction to be taken by a program's branches and then based on those predictions, use the compiler to arrange the blocks so that the multiple blocks to be fetched are always placed in consecutive cache lines. <p> The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling <ref> [5, 8] </ref>, predicated execution [7, 12, 18], and the VLIW multi-way jump mechanism [4, 10, 3, 15]. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> They include the branch address cache [24], the collapsing buffer [1], the subgraph-level predictor [2], the multiple-block ahead branch predictor [20], and the trace cache [19]. Trace scheduling <ref> [5] </ref> and superblock scheduling [8] are compiler optimizations that enlarge the scope in which the compiler can schedule instructions. They use static branch prediction to determine the frequently executed program paths and place the basic blocks along these paths into consecutive locations, forming a superblock.
Reference: [6] <author> M. Franklin and G. S. Sohi. </author> <title> The expandable split window paradigm for exploiting fine-grain parallelism. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 58-67, </pages> <year> 1992. </year>
Reference-contexts: By combining the blocks at compile-time, the block enlargement optimization has the advantage of being able to use the entire icache to store its enlarged blocks instead of the small cache used in the trace cache approach. Multiscalar processors <ref> [6, 21] </ref> are a new processing paradigm that does not fall into either the compiler-based or hardware-based categories. Multiscalar processors consist of a set of processing elements connected in a ring. Each processing element executes a task, a set of basic blocks specified by the compiler.
Reference: [7] <author> P. Hsu and E. Davidson. </author> <title> Highly concurrent scalar processing. </title> <booktitle> In Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <year> 1986. </year>
Reference-contexts: The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling [5, 8], predicated execution <ref> [7, 12, 18] </ref>, and the VLIW multi-way jump mechanism [4, 10, 3, 15]. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> This extra degree of freedom provides a performance advantage for the block enlargement optimization over superblock scheduling because dynamic branch predictors usually achieve significantly higher prediction accuracies than static branch predictors. Predicated execution <ref> [7, 12, 18] </ref> eliminates program branches by converting their control dependencies into data dependencies. Once a basic block's branch has been eliminated, it can be combined with its control flow successors to form a single basic block. Predicated execution has two disadvantages.
Reference: [8] <author> W. W. Hwu, S. A. Mahlke, W. Y. Chen, P. P. Chang, N. J. Warter, R. A. Bringmann, R. G. Ouellette, R. E. Hank, T. Kiy-ohara, G. E. Haab, J. G. Holm, and D. M. Lavery. </author> <title> The su-perblock: An effective technique for VLIW and superscalar compilation. </title> <journal> Journal of Supercomputing, </journal> <pages> 7(9-50), </pages> <year> 1993. </year>
Reference-contexts: However, this extra hardware requires extra stages in the pipeline which will increase the branch misprediction penalty, decreasing performance. Other approaches <ref> [5, 8] </ref> statically predict the direction to be taken by a program's branches and then based on those predictions, use the compiler to arrange the blocks so that the multiple blocks to be fetched are always placed in consecutive cache lines. <p> The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling <ref> [5, 8] </ref>, predicated execution [7, 12, 18], and the VLIW multi-way jump mechanism [4, 10, 3, 15]. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> They include the branch address cache [24], the collapsing buffer [1], the subgraph-level predictor [2], the multiple-block ahead branch predictor [20], and the trace cache [19]. Trace scheduling [5] and superblock scheduling <ref> [8] </ref> are compiler optimizations that enlarge the scope in which the compiler can schedule instructions. They use static branch prediction to determine the frequently executed program paths and place the basic blocks along these paths into consecutive locations, forming a superblock.
Reference: [9] <author> Intel Corporation. </author> <title> Intel Reference C Compiler User's Guide for UNIX Systems, </title> <year> 1993. </year>
Reference-contexts: The Block-Structured ISA Compiler We implemented a compiler that is targeted for the block-structured ISA described above. This compiler is based on the Intel Reference C Compiler <ref> [9] </ref> with the back end appropriately retargeted. The Intel Reference C Compiler generates an intermediate representation of the program being compiled and applies the standard set of optimizations to that representation.
Reference: [10] <author> K. Karplus and A. Nicolau. </author> <title> Efficient hardware for multi-way jumps and prefetches. </title> <booktitle> In Proceedings of the 18th Annual Microprogramming Workshop, </booktitle> <pages> pages 11-18, </pages> <year> 1985. </year>
Reference-contexts: The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling [5, 8], predicated execution [7, 12, 18], and the VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref>. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> While predicated execution by itself may not be an effective mechanism for increasing instruction fetch rate, it can provide a significant performance benefit when used in conjunction with speculative execution [11] and other schemes for increasing fetch rate. The VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref> combines multiple branches from multiple paths in the control flow graph into a single branch. Using this mechanism, basic blocks which form a rooted subgraph in the control flow graph can be combined into a single VLIW instruction.
Reference: [11] <author> S. A. Mahlke, R. E. Hank, R. A. Bringmann, J. C. Gyllenhaal, D. M. Gallagher, and W. W. Hwu. </author> <title> Characterizing the impact of predicated execution on branch prediction. </title> <booktitle> In Proceedings of the 27th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pages 217-227, </pages> <year> 1994. </year>
Reference-contexts: While predicated execution by itself may not be an effective mechanism for increasing instruction fetch rate, it can provide a significant performance benefit when used in conjunction with speculative execution <ref> [11] </ref> and other schemes for increasing fetch rate. The VLIW multi-way jump mechanism [4, 10, 3, 15] combines multiple branches from multiple paths in the control flow graph into a single branch.
Reference: [12] <author> S. A. Mahlke, D. C. Lin, W. Y. Chen, R. E. Hank, and R. A. Bringmann. </author> <title> Effective compiler support for predicated execution using the hyperblock. </title> <booktitle> In Proceedings of the 25th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pages 45-54, </pages> <year> 1992. </year>
Reference-contexts: The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling [5, 8], predicated execution <ref> [7, 12, 18] </ref>, and the VLIW multi-way jump mechanism [4, 10, 3, 15]. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> This extra degree of freedom provides a performance advantage for the block enlargement optimization over superblock scheduling because dynamic branch predictors usually achieve significantly higher prediction accuracies than static branch predictors. Predicated execution <ref> [7, 12, 18] </ref> eliminates program branches by converting their control dependencies into data dependencies. Once a basic block's branch has been eliminated, it can be combined with its control flow successors to form a single basic block. Predicated execution has two disadvantages.
Reference: [13] <author> S. Melvin and Y. Patt. </author> <title> Enhancing instruction scheduling with a block-structured ISA. </title> <journal> International Journal on Parallel Processing, </journal> <volume> 23(3) </volume> <pages> 221-243, </pages> <year> 1995. </year>
Reference-contexts: This paper presents a solution using block-structured ISAs that exploits the advantages of both compiler-based and hardware-based solutions by merging basic blocks together statically and providing support for dynamic branch prediction. Block-structured ISAs <ref> [14, 13, 22] </ref> are a new class of instruction set architectures that were designed to address the performance obstacles faced by processors attempting to exploit high levels of instruction level parallelism. <p> Section 4 describes our block-structured ISA and the compiler and microarchi-tectural support needed to implement that ISA. Section 5 presents experimental results comparing the performance of our block-structured ISA to that of a conventional ISA. Concluding remarks are given in section 6. 2. Block-Structured ISAs Block-structured ISAs <ref> [14, 13, 22] </ref> were designed to help solve the performance obstacles faced by wide-issue processors. Their major distinguishing feature is that the architectural atomic unit is defined to be a group of operations. These groups, known as atomic blocks, are specified by the compiler.
Reference: [14] <author> S. Melvin and Y. N. Patt. </author> <title> Exploiting fine-grained parallelism through a combination of hardware and software techniques. </title> <booktitle> In Proceedings of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 287-297, </pages> <year> 1991. </year>
Reference-contexts: This paper presents a solution using block-structured ISAs that exploits the advantages of both compiler-based and hardware-based solutions by merging basic blocks together statically and providing support for dynamic branch prediction. Block-structured ISAs <ref> [14, 13, 22] </ref> are a new class of instruction set architectures that were designed to address the performance obstacles faced by processors attempting to exploit high levels of instruction level parallelism. <p> Section 4 describes our block-structured ISA and the compiler and microarchi-tectural support needed to implement that ISA. Section 5 presents experimental results comparing the performance of our block-structured ISA to that of a conventional ISA. Concluding remarks are given in section 6. 2. Block-Structured ISAs Block-structured ISAs <ref> [14, 13, 22] </ref> were designed to help solve the performance obstacles faced by wide-issue processors. Their major distinguishing feature is that the architectural atomic unit is defined to be a group of operations. These groups, known as atomic blocks, are specified by the compiler.
Reference: [15] <author> S.-M. Moon and K. Ebcioglu. </author> <title> An efficient resource-constrained global scheduling technique for superscalar and VLIW processors. </title> <booktitle> In Proceedings of the 25th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pages 55-71, </pages> <year> 1992. </year>
Reference-contexts: The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling [5, 8], predicated execution [7, 12, 18], and the VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref>. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> While predicated execution by itself may not be an effective mechanism for increasing instruction fetch rate, it can provide a significant performance benefit when used in conjunction with speculative execution [11] and other schemes for increasing fetch rate. The VLIW multi-way jump mechanism <ref> [4, 10, 3, 15] </ref> combines multiple branches from multiple paths in the control flow graph into a single branch. Using this mechanism, basic blocks which form a rooted subgraph in the control flow graph can be combined into a single VLIW instruction.
Reference: [16] <author> Y. Patt, W. Hwu, and M. Shebanow. HPS, </author> <title> a new microarchi-tecture: Rationale and introduction. </title> <booktitle> In Proceedings of the 18th Annual Microprogramming Workshop, </booktitle> <pages> pages 103-107, </pages> <year> 1985. </year>
Reference-contexts: The Block-Structured ISA Processor The block-structured ISA processor modeled in our experiments is a sixteen-wide issue, dynamically scheduled processor that implements the HPS execution model <ref> [16, 17] </ref>. The processor supports speculative execution as required by block-structured ISAs (see section 2). It can fetch and issue one atomic block each cycle. Each atomic block can contain up to sixteen operations. Dynamic register renaming removes any anti and output dependencies in the dynamic instruction stream.
Reference: [17] <author> Y. N. Patt, S. W. Melvin, W. Hwu, and M. C. Shebanow. </author> <title> Critical issues regarding HPS, a high performance microarchitec-ture. </title> <booktitle> In Proceedings of the 18th Annual Microprogramming Workshop, </booktitle> <pages> pages 109-116, </pages> <year> 1985. </year>
Reference-contexts: The Block-Structured ISA Processor The block-structured ISA processor modeled in our experiments is a sixteen-wide issue, dynamically scheduled processor that implements the HPS execution model <ref> [16, 17] </ref>. The processor supports speculative execution as required by block-structured ISAs (see section 2). It can fetch and issue one atomic block each cycle. Each atomic block can contain up to sixteen operations. Dynamic register renaming removes any anti and output dependencies in the dynamic instruction stream.
Reference: [18] <author> D. N. Pnevmatikatos and G. S. Sohi. </author> <title> Guarded execution and dynamic branch prediction in dynamic ILP processors. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 120-129, </pages> <year> 1994. </year>
Reference-contexts: The compiler-based schemes place the basic blocks to be fetched next to each other in the icache, eliminating the need for extra hardware. These schemes include trace and superblock scheduling [5, 8], predicated execution <ref> [7, 12, 18] </ref>, and the VLIW multi-way jump mechanism [4, 10, 3, 15]. The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. <p> This extra degree of freedom provides a performance advantage for the block enlargement optimization over superblock scheduling because dynamic branch predictors usually achieve significantly higher prediction accuracies than static branch predictors. Predicated execution <ref> [7, 12, 18] </ref> eliminates program branches by converting their control dependencies into data dependencies. Once a basic block's branch has been eliminated, it can be combined with its control flow successors to form a single basic block. Predicated execution has two disadvantages.
Reference: [19] <author> E. Rotenberg, S. Bennett, and J. E. Smith. </author> <title> Trace cache: A low latency approach to high bandwidth instruction fetching. </title> <type> Technical Report 1310, </type> <institution> University of Wisconsin - Madison, </institution> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: They include the branch address cache [24], the collapsing buffer [1], the subgraph-level predictor [2], the multiple-block ahead branch predictor [20], and the trace cache <ref> [19] </ref>. Trace scheduling [5] and superblock scheduling [8] are compiler optimizations that enlarge the scope in which the compiler can schedule instructions. They use static branch prediction to determine the frequently executed program paths and place the basic blocks along these paths into consecutive locations, forming a superblock. <p> The processor will require at least one additional stage in the pipeline in order to accomplish these tasks. This additional stage will increase the branch misprediction penalty, decreasing overall performance. The trace cache <ref> [19] </ref> is a hardware-based scheme that does not require fetching non-consecutive blocks from the icache. Its fetch unit consists of two parts, a core fetch unit and a trace cache. The core fetch unit fetches one basic block each cycle from the icache. <p> In-lining can increase the fetch bandwidth used by eliminating procedure calls and returns, allowing the block enlargement optimization to combine blocks that previously could not be combined. In addition, using block-structured ISAs in conjunction with another fetch rate enhancing mechanism, such as the trace cache <ref> [19] </ref>, may lead to even higher fetch rates without sacrificing icache performance. We also plan to measure the performance gains that can be achieved by block-structured ISAs for scientific code.
Reference: [20] <author> A. Seznec, S. Jourdan, P. Sainrat, and P. Michaud. </author> <title> Multiple-block ahead branch predictors. </title> <booktitle> In Proceedings of the 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Various approaches have been proposed for increasing instruction fetch rate from that of a single basic block per cycle. Some approaches <ref> [24, 1, 2, 20] </ref> extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple, non-consecutive cache lines can be fetched each cycle. However, this extra hardware requires extra stages in the pipeline which will increase the branch misprediction penalty, decreasing performance. <p> The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. They include the branch address cache [24], the collapsing buffer [1], the subgraph-level predictor [2], the multiple-block ahead branch predictor <ref> [20] </ref>, and the trace cache [19]. Trace scheduling [5] and superblock scheduling [8] are compiler optimizations that enlarge the scope in which the compiler can schedule instructions. <p> The compiler may have to delay the scheduling of certain operations in order to meet these requirements, lowering the instruction fetch rate of the processor. The branch address cache [24], the collapsing buffer [1], the subgraph-level predictor [2], and the multiple-block ahead branch predictor <ref> [20] </ref> are hardware schemes that propose different ways to extend the dynamic branch predictor so that it can make multiple branch predictions each cycle.
Reference: [21] <author> G. S. Sohi, S. E. Breach, and T. N. Vijaykumar. </author> <title> Multiscalar processors. </title> <booktitle> In Proceedings of the 22st Annual International Symposium on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: By combining the blocks at compile-time, the block enlargement optimization has the advantage of being able to use the entire icache to store its enlarged blocks instead of the small cache used in the trace cache approach. Multiscalar processors <ref> [6, 21] </ref> are a new processing paradigm that does not fall into either the compiler-based or hardware-based categories. Multiscalar processors consist of a set of processing elements connected in a ring. Each processing element executes a task, a set of basic blocks specified by the compiler.
Reference: [22] <author> E. Sprangle and Y. Patt. </author> <title> Facilitating superscalar processing via a combined static/dynamic register renaming scheme. </title> <booktitle> In Proceedings of the 27th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pages 143-147, </pages> <year> 1994. </year>
Reference-contexts: This paper presents a solution using block-structured ISAs that exploits the advantages of both compiler-based and hardware-based solutions by merging basic blocks together statically and providing support for dynamic branch prediction. Block-structured ISAs <ref> [14, 13, 22] </ref> are a new class of instruction set architectures that were designed to address the performance obstacles faced by processors attempting to exploit high levels of instruction level parallelism. <p> Section 4 describes our block-structured ISA and the compiler and microarchi-tectural support needed to implement that ISA. Section 5 presents experimental results comparing the performance of our block-structured ISA to that of a conventional ISA. Concluding remarks are given in section 6. 2. Block-Structured ISAs Block-structured ISAs <ref> [14, 13, 22] </ref> were designed to help solve the performance obstacles faced by wide-issue processors. Their major distinguishing feature is that the architectural atomic unit is defined to be a group of operations. These groups, known as atomic blocks, are specified by the compiler.
Reference: [23] <author> R. Uhlig, D. Nagle, T. Mudge, S. Sechrest, and J. Emer. </author> <title> Instruction fetching: Coping with code bloat. </title> <booktitle> In Proceedings of the 22st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 345-356, </pages> <year> 1995. </year>
Reference-contexts: This study did not model the icache effects due to operating system code. These effects may further decrease icache performance <ref> [23] </ref>. Figures 6 and 7 show the results of these comparisons for icache sizes from 16KB to 64KB. With the exception of the small benchmarks (compress, li, and ijpeg), the block-structured ISA executables show much larger performance decreases due to icache misses than the conventional ISA executables.
Reference: [24] <author> T.-Y. Yeh, D. Marr, and Y. N. Patt. </author> <title> Increasing the instruction fetch rate via multiple branch prediction and branch address cache. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 67-76, </pages> <year> 1993. </year>
Reference-contexts: Various approaches have been proposed for increasing instruction fetch rate from that of a single basic block per cycle. Some approaches <ref> [24, 1, 2, 20] </ref> extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple, non-consecutive cache lines can be fetched each cycle. However, this extra hardware requires extra stages in the pipeline which will increase the branch misprediction penalty, decreasing performance. <p> The hardware-based schemes extend the branch predictor and icache so that multiple branch predictions can be made each cycle and multiple non-consecutive cache lines can be fetched each cycle. They include the branch address cache <ref> [24] </ref>, the collapsing buffer [1], the subgraph-level predictor [2], the multiple-block ahead branch predictor [20], and the trace cache [19]. Trace scheduling [5] and superblock scheduling [8] are compiler optimizations that enlarge the scope in which the compiler can schedule instructions. <p> The compiler may have to delay the scheduling of certain operations in order to meet these requirements, lowering the instruction fetch rate of the processor. The branch address cache <ref> [24] </ref>, the collapsing buffer [1], the subgraph-level predictor [2], and the multiple-block ahead branch predictor [20] are hardware schemes that propose different ways to extend the dynamic branch predictor so that it can make multiple branch predictions each cycle.
Reference: [25] <author> T.-Y. Yeh and Y. N. Patt. </author> <title> Two-level adaptive branch prediction. </title> <booktitle> In Proceedings of the 24th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pages 51-61, </pages> <year> 1991. </year>
Reference-contexts: Instruction classes and latencies icache is always modeled as perfect with a six cycle access time. To predict the next atomic block to be fetched, the block-structured ISA processor uses a predictor based on the Two-Level Adaptive Branch Predictor <ref> [25] </ref>. Because each atomic block may contain multiple branches, the block-structured ISA predictor must be able to implicitly make multiple branch predictions each cycle. To do this, the Two-Level Adaptive Branch Predictor must be modified in three ways: 1.
References-found: 25

