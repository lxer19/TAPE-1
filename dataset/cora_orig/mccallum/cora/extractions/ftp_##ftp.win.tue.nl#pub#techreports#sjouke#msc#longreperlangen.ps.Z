URL: ftp://ftp.win.tue.nl/pub/techreports/sjouke/msc/longreperlangen.ps.Z
Refering-URL: http://www.win.tue.nl/win/cs/fm/sjouke/mscwhatsnew.html
Root-URL: http://www.win.tue.nl
Email: Email: mitsch@informatik.uni-erlangen.de  Email: bmc@informatik.uni-essen.de  
Title: Extension of SDL and MSC to Support Performance Engineering: A Discussion of Design Issues  
Author: Andreas Mitschele-Thiel Bruno Muller-Clostermann 
Affiliation: Universitat Erlangen-Nurnberg  Universitat GH Essen  
Abstract: Formal description techniques allow to formally reason about the functional aspects of systems under development. This allows to detect and remedy functional errors in early stages of the development cycle. In order to also support performance engineering activities in the early development stages, a study of the integration of performance aspects into the standardized formal description techniques SDL and MSC has been launched within the ITU-T study group 10 in 1997. The integration of performance aspects into the standards is important to promote the wide-spread use of performance tools. The paper reports on the results of the study reached so far and discusses the issues involved with the integration of performance aspects into SDL and MSC. 
Abstract-found: 1
Intro-found: 1
Reference: [Bra93] <author> R. Braek, O. Haugen. </author> <title> Engineering Real Time Systems An object-oriented methodology using SDL. BCS Practitioner Series, </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: Another related issue is the automatic derivation of efficient and responsive systems (see <ref> [Hen97, Bra93] </ref> for a discussion). In the paper, we concentrate on the issues involved with the integration of information needed for a performance evaluation.
Reference: [Bue96] <author> M. Butow, M. Mestern, C. Schapiro, </author> <title> P.S. Kritzinger. Performance Modelling with the Formal Specification Language SDL. Joint Int. Conf. on Formal Description Techniques for Distributed Systems and Communication Protocols (IX) and Protocol Specification, Testing and Verification (XVI) (FORTE/PSTV'96), </title> <editor> R. Gotzhein, J. Bredereke (eds.), </editor> <publisher> Chapman & Hall, </publisher> <year> 1996. </year>
Reference-contexts: The paper summarizes the major issues involved in the integration of performance and time aspects in the formal description techniques SDL and MSC and the results of the discussion so far. The important tools that integrate performance aspects into SDL are SPECS <ref> [Bue96] </ref>, QUEST and the language QSDL [Die95, Que98], EasySim-II [Ger97], DNAsty and SDLnet [Kab97], and SPEET [Ste97]. <p> For an early evaluation, a coarse model may be sufficient. The known approaches range from the simple specification of delays to a precise model of the underlying hardware. In <ref> [Bue96, Rou98] </ref>, delays are specified from which the response times are derived considering concurrency within a set of processes. In [Die95, Ger97], queuing models with various service strategies and priorities are employed. A detailed emulation of the underlying processor hardware is used in [Ste97].
Reference: [Die95] <author> M. Diefenbruch, E. Heck, J. Hintelmann, B. Muller-Clostermann. </author> <title> Performance Evaluation of SDL Systems Adjunct by Queuing Models. </title> <booktitle> SDL '95 with MSC in CASE (Proc. Seventh SDL Forum), </booktitle> <editor> R. Braek, A. Sarma (Ed.), </editor> <publisher> Elsevier, </publisher> <year> 1995. </year> <month> 12 </month>
Reference-contexts: The paper summarizes the major issues involved in the integration of performance and time aspects in the formal description techniques SDL and MSC and the results of the discussion so far. The important tools that integrate performance aspects into SDL are SPECS [Bue96], QUEST and the language QSDL <ref> [Die95, Que98] </ref>, EasySim-II [Ger97], DNAsty and SDLnet [Kab97], and SPEET [Ste97]. Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool [Smi97], and the tool described in [ElS98]. <p> This includes questions as where to put the additional information and the exact syntax as well as semantics of the extra information. 2.3.1 System Stimuli Two basic concepts exist to specify the system stimuli. QSDL <ref> [Die95] </ref> uses SDL processes (extended to model time more precisely) to describe arrival processes. PMSC [Fal97] employs a special notation to describe system stimuli. Another approach is to have a separate workload generator linked to the SDL specification, implemented in an arbitrary (non-standardized) language or notation (e.g. [Ger97, Rou98]). <p> For an early evaluation, a coarse model may be sufficient. The known approaches range from the simple specification of delays to a precise model of the underlying hardware. In [Bue96, Rou98], delays are specified from which the response times are derived considering concurrency within a set of processes. In <ref> [Die95, Ger97] </ref>, queuing models with various service strategies and priorities are employed. A detailed emulation of the underlying processor hardware is used in [Ste97]. Multiple use of the resource/platform description The description of the resources or implementation platform may serve two very different purposes. <p> Level of detail of the resource demands The level of detail of the resource requests is an important issue. Alternatives are the association of a service request to actions or complete transitions in SDL [Rou98], or to add special service requests to arbitrary points in the SDL specification <ref> [Die95, Ger98] </ref>. It has been argued that service requests should be associated to SDL constructs, rather than introducing a new construct. In this context also the question of flexibility versus practicability and ease of use of the approach has been raised. <p> Several alternatives exist. The mapping can be specified implicitly by directly naming the resource within the resource requests. However, this considerably limits flexibility. Flexibility is supported by a separate description of the mapping of the resource requests on the available resources (e.g. <ref> [Die95, Ger98] </ref>). 2.3.5 Performance Metrics and Sensors Performance sensors are used to specify the performance metrics monitored and measured during the performance evaluation. QSDL provides sophisticated aggregated performance sensors [Die98, Que98] while others rely on rather simple probes.
Reference: [Die98] <author> M. Diefenbruch. </author> <title> Functional and quantitative Verification of time- and resource--enhanced SDL Systems with Model Checking. </title> <booktitle> In [Mit98]. </booktitle>
Reference-contexts: Flexibility is supported by a separate description of the mapping of the resource requests on the available resources (e.g. [Die95, Ger98]). 2.3.5 Performance Metrics and Sensors Performance sensors are used to specify the performance metrics monitored and measured during the performance evaluation. QSDL provides sophisticated aggregated performance sensors <ref> [Die98, Que98] </ref> while others rely on rather simple probes. Simple probes used in SPEET [Ste97] or PMSC [Fal97] focus on providing an interface to output performance data. With QSDL, aggregated performance sensors are special data types maintained by the underlying system during the system simulation. <p> However, it is not central for a typical performance evaluation. Basic approaches to specify performance requirements are * extended MSCs [Fal97, Sch98], * temporal logics used in conjunction with performance sensors <ref> [Die98, Que98] </ref>, and * the direct use of SDL to check performance requirements within the SDL specification during the system simulation. MSCs are especially appropriate to specify response time requirements. <p> On the other hand, temporal logics are not acceptable for end users. An idea is to enhance the expressiveness of MSCs and map these enhanced MSCs internally on a temporal logic to support the formal verification of functional and non-functional aspects by model checking techniques <ref> [Die98] </ref>. 3 Final Remarks Support for performance evaluation and performance engineering in general is an important issue in the software engineering process. This is increasingly acknowledged by the telecommunication industry and reflected by a growing demand in SDL tools that support performance engineering activities.
Reference: [ElS98] <author> H. El-Sayed, D. Cameron, M. Woodside. </author> <title> Automated performance modelling from scenarios and SDL designs of telecom systems. </title> <booktitle> Proc. of Intl. Symp. on Software Engineering for Parallel and Distributed Systems (PDSE'98), </booktitle> <publisher> IEEE Press, </publisher> <year> 1998. </year>
Reference-contexts: Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool [Smi97], and the tool described in <ref> [ElS98] </ref>. A survey and classification of the approaches employed by the tools can be found in [Mit97]. The different approaches to describe and associate the additional information needed for a performance evaluation to the SDL and MSC specification are described in [Mit98].
Reference: [Fal97] <author> N. Faltin, L. Lambert, A. Mitschele-Thiel, F. Slomka. </author> <title> An Annotational Extension of Message Sequence Charts to Support Performance Engineering. </title> <booktitle> Proc. of the Eighth SDL Forum, </booktitle> <address> Evry, France, </address> <publisher> Elsevier, </publisher> <year> 1997. </year>
Reference-contexts: QSDL [Die95] uses SDL processes (extended to model time more precisely) to describe arrival processes. PMSC <ref> [Fal97] </ref> employs a special notation to describe system stimuli. Another approach is to have a separate workload generator linked to the SDL specification, implemented in an arbitrary (non-standardized) language or notation (e.g. [Ger97, Rou98]). For a standardized approach only the first two approaches seem to be appropriate. <p> QSDL provides sophisticated aggregated performance sensors [Die98, Que98] while others rely on rather simple probes. Simple probes used in SPEET [Ste97] or PMSC <ref> [Fal97] </ref> focus on providing an interface to output performance data. With QSDL, aggregated performance sensors are special data types maintained by the underlying system during the system simulation. The sensors can be used also to dynamically influence the functional behavior of the SDL specification based on the load figures. <p> However, it is not central for a typical performance evaluation. Basic approaches to specify performance requirements are * extended MSCs <ref> [Fal97, Sch98] </ref>, * temporal logics used in conjunction with performance sensors [Die98, Que98], and * the direct use of SDL to check performance requirements within the SDL specification during the system simulation. MSCs are especially appropriate to specify response time requirements.
Reference: [Fer86] <author> D. Ferrari. </author> <title> Considerations on the Insularity of Performance Evaluation. </title> <journal> IEEE Trans. on Softw. Eng., </journal> <volume> 12(6), </volume> <year> 1986. </year>
Reference-contexts: Nevertheless, the integration of performance aspects in the system engineering process has not been well studied. Instead, systems engineering and performance evaluation are often being considered as two rather independent areas. Domenico Ferrari once coined the term `insularity of performance evaluation' <ref> [Fer86] </ref>, even the phrase `esoteric cult' is sometimes used in this context. As a result of this, each of the two worlds has its own specialists and uses its own models, methods and tools.
Reference: [Ger97] <author> R. Gerlich. </author> <title> Tuning Development of Distributed Real-Time Systems with SDL and MSC Current Experience and Future Issues. </title> <booktitle> Proc. of Eighth SDL Forum, </booktitle> <address> Evry, France, </address> <publisher> Elsevier, </publisher> <year> 1997. </year>
Reference-contexts: The important tools that integrate performance aspects into SDL are SPECS [Bue96], QUEST and the language QSDL [Die95, Que98], EasySim-II <ref> [Ger97] </ref>, DNAsty and SDLnet [Kab97], and SPEET [Ste97]. Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool [Smi97], and the tool described in [ElS98]. <p> QSDL [Die95] uses SDL processes (extended to model time more precisely) to describe arrival processes. PMSC [Fal97] employs a special notation to describe system stimuli. Another approach is to have a separate workload generator linked to the SDL specification, implemented in an arbitrary (non-standardized) language or notation (e.g. <ref> [Ger97, Rou98] </ref>). For a standardized approach only the first two approaches seem to be appropriate. Due to its similarities with the current SDL standard, the use of SDL processes to specify the system stimuli seems to be most appropriate. <p> For an early evaluation, a coarse model may be sufficient. The known approaches range from the simple specification of delays to a precise model of the underlying hardware. In [Bue96, Rou98], delays are specified from which the response times are derived considering concurrency within a set of processes. In <ref> [Die95, Ger97] </ref>, queuing models with various service strategies and priorities are employed. A detailed emulation of the underlying processor hardware is used in [Ste97]. Multiple use of the resource/platform description The description of the resources or implementation platform may serve two very different purposes.
Reference: [Ger98] <author> R. Gerlich. </author> <title> EaSySim II SDL Extensions for Performance Simulation. </title> <booktitle> In [Mit98]. </booktitle>
Reference-contexts: Level of detail of the resource demands The level of detail of the resource requests is an important issue. Alternatives are the association of a service request to actions or complete transitions in SDL [Rou98], or to add special service requests to arbitrary points in the SDL specification <ref> [Die95, Ger98] </ref>. It has been argued that service requests should be associated to SDL constructs, rather than introducing a new construct. In this context also the question of flexibility versus practicability and ease of use of the approach has been raised. <p> Blocking versus nonblocking resource demands Typical approaches support blocking resource requests similar to the semantics of procedure calls known from programming languages, i.e. the executing process is blocked until the given resource is acquired and the required service time has passed. In <ref> [Ger98] </ref> also nonblocking requests can be issued. This may be helpful to directly specify nonblocking resource demands, e.g. a signal output. On the other hand, non-blocking service requests are somehow less intuitive than blocking requests. <p> Several alternatives exist. The mapping can be specified implicitly by directly naming the resource within the resource requests. However, this considerably limits flexibility. Flexibility is supported by a separate description of the mapping of the resource requests on the available resources (e.g. <ref> [Die95, Ger98] </ref>). 2.3.5 Performance Metrics and Sensors Performance sensors are used to specify the performance metrics monitored and measured during the performance evaluation. QSDL provides sophisticated aggregated performance sensors [Die98, Que98] while others rely on rather simple probes.
Reference: [Hec91] <author> E. Heck, D. Hogrefe, B. Muller-Clostermann. </author> <title> Hierarchical Performance Evaluation Based on Formally Specified Communication Protocols. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 40(4), </volume> <year> 1991. </year>
Reference-contexts: An overview on the additional information is depicted in figure 1. References that have discussed these issues in the past are <ref> [Hec91, Hec96] </ref>. For a recent overview and tutorial information see [Mit97, Mit98]. System stimuli The system stimuli describes the load imposed on the system i.e. the different service requests (type and intensity) issued to the system.
Reference: [Hec96] <author> E. Heck. </author> <title> Performance Evaluation of Formally Specified Systems The Integration of SDL with HIT. </title> <type> Doctoral Thesis, </type> <institution> Informatik IV, </institution> <address> Universitat Dortmund, </address> <publisher> Krehl Verlag, </publisher> <year> 1996. </year>
Reference-contexts: An overview on the additional information is depicted in figure 1. References that have discussed these issues in the past are <ref> [Hec91, Hec96] </ref>. For a recent overview and tutorial information see [Mit97, Mit98]. System stimuli The system stimuli describes the load imposed on the system i.e. the different service requests (type and intensity) issued to the system.
Reference: [Hen97] <author> R. Henke, H. Konig, A. Mitschele-Thiel. </author> <title> Derivation of Efficient Implementations from SDL Specifications Employing Data Referencing, Integrated Packet Framing and Activity Threads. </title> <booktitle> Proc. of the Eighth SDL Forum, </booktitle> <address> Evry, France, </address> <publisher> Elsevier, </publisher> <year> 1997. </year>
Reference-contexts: Another related issue is the automatic derivation of efficient and responsive systems (see <ref> [Hen97, Bra93] </ref> for a discussion). In the paper, we concentrate on the issues involved with the integration of information needed for a performance evaluation. <p> Measurements have shown that the overhead in executing an SDL specification (i.e. the SDL transitions) may be much larger than the cost of the SDL transitions itself <ref> [Hen97] </ref>. Thus, the overhead of the underlying runtime system is an important issue and should be modeled appropriately. In performance evaluation, there are (at least) two basic approaches to include overhead.
Reference: [ITU93] <author> ITU-T. Z.100, </author> <title> Specification and Description Language (SDL). </title> <address> ITU, </address> <year> 1993. </year>
Reference: [ITU93a] <author> ITU-T. Z.100, Appendix I. ITU, </author> <title> SDL Methodology Guidelines. </title> <address> ITU, </address> <year> 1993. </year>
Reference: [ITU96] <author> ITU-T. Z.120, </author> <title> Message Sequence Charts (MSC). </title> <address> ITU, </address> <year> 1996. </year>
Reference: [ITU97] <author> ITU-T. </author> <title> SDL+ Methodology: Manual for the use of MSC and SDL (with ASN.1). Supplement 1 to Z.100, </title> <year> 1997. </year>
Reference: [Kab97] <author> H.M. Kabutz. </author> <title> Analytical performance evaluation of concurrent communicating systems using SDL and stochastic Petri nets. </title> <type> Doctoral Thesis, </type> <institution> Department of Computer Science, University of Cape Town, Republic of South Africa, </institution> <year> 1997. </year>
Reference-contexts: The important tools that integrate performance aspects into SDL are SPECS [Bue96], QUEST and the language QSDL [Die95, Que98], EasySim-II [Ger97], DNAsty and SDLnet <ref> [Kab97] </ref>, and SPEET [Ste97]. Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool [Smi97], and the tool described in [ElS98].
Reference: [Mit96] <author> A. Mitschele-Thiel, P. Langendorfer, R. Henke. </author> <title> Design and Optimization of High-Performance Protocols with the DO-IT Toolbox. Joint Int. Conf. on Formal Description Techniques for Distributed Systems and Communication Protocols (IX) and Protocol Specification, Testing and Verification (XVI) (FORTE/PSTV'96), </title> <editor> R. Gotzhein, J. Bredereke (eds.), p. </editor> <address> 45-60, </address> <publisher> Chapman & Hall, </publisher> <year> 1996. </year>
Reference-contexts: The important tools that integrate performance aspects into SDL are SPECS [Bue96], QUEST and the language QSDL [Die95, Que98], EasySim-II [Ger97], DNAsty and SDLnet [Kab97], and SPEET [Ste97]. Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox <ref> [Mit96] </ref>, the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool [Smi97], and the tool described in [ElS98]. A survey and classification of the approaches employed by the tools can be found in [Mit97].
Reference: [Mit97] <author> A. Mitschele-Thiel, B. Muller-Clostermann. </author> <title> Performance Engineering of SDL/MSC Systems. SDL `97 Time for Testing, </title> <booktitle> Tutorial Notes, (Eighth SDL Forum), </booktitle> <editor> A. Cav-alli, D. Vincent (Eds.), </editor> <booktitle> Institut National des Telecommunications, </booktitle> <address> Evry, France, </address> <year> 1997, </year> <title> (to appear in Computer Networks and ISDN Systems, </title> <publisher> Elsevier, </publisher> <year> 1998). </year>
Reference-contexts: A survey and classification of the approaches employed by the tools can be found in <ref> [Mit97] </ref>. The different approaches to describe and associate the additional information needed for a performance evaluation to the SDL and MSC specification are described in [Mit98]. <p> An overview on the additional information is depicted in figure 1. References that have discussed these issues in the past are [Hec91, Hec96]. For a recent overview and tutorial information see <ref> [Mit97, Mit98] </ref>. System stimuli The system stimuli describes the load imposed on the system i.e. the different service requests (type and intensity) issued to the system.
Reference: [Mit97a] <author> A. Mitschele-Thiel, F. Slomka. </author> <title> A Methodology for Hardware/Software Codesign of Real-Time Systems with SDL/MSC. </title> <booktitle> Intl. Workshop on Conjoint Systems Engineering (CONSYSE 97), </booktitle> <address> Bad Tolz, </address> <month> Sept. </month> <year> 1997, </year> <note> (to appear by IT Press). 13 </note>
Reference-contexts: Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen <ref> [Mit97a] </ref>, the SPEED tool [Smi97], and the tool described in [ElS98]. A survey and classification of the approaches employed by the tools can be found in [Mit97].
Reference: [Mit98] <editor> A. Mitschele-Thiel, B. Muller-Clostermann, R. Reed (Eds.). </editor> <booktitle> Proc. of Workshop on Performance and Time in SDL and MSC. </booktitle> <institution> Report IMMD VII-1/98, University of Er-langen, </institution> <year> 1998. </year>
Reference-contexts: In order to foster the integration of performance and time aspects into SDL and MSC, a workshop on the topic has been held 2 in conjunction with the ITU Q.6/10 (SDL) expert meeting in Erlangen, Germany, on February 17-19, 1998 <ref> [Mit98] </ref>. The paper summarizes the major issues involved in the integration of performance and time aspects in the formal description techniques SDL and MSC and the results of the discussion so far. <p> A survey and classification of the approaches employed by the tools can be found in [Mit97]. The different approaches to describe and associate the additional information needed for a performance evaluation to the SDL and MSC specification are described in <ref> [Mit98] </ref>. To our knowledge, SDL and MSC are the first formal description techniques for which the tight integration with performance aspects is pursued in such a concrete manner. <p> An overview on the additional information is depicted in figure 1. References that have discussed these issues in the past are [Hec91, Hec96]. For a recent overview and tutorial information see <ref> [Mit97, Mit98] </ref>. System stimuli The system stimuli describes the load imposed on the system i.e. the different service requests (type and intensity) issued to the system.
Reference: [Ols94] <author> A. Olsen, O. Faergemand, B. Moller-Pedersen, R. Reed, J.R.W. Smith. </author> <title> Systems Engineering Using SDL-92. </title> <publisher> North Holland, </publisher> <year> 1994. </year>
Reference: [Que98] <editor> QUEST and QSDL Homepage. </editor> <address> http://www.cs.uni-essen.de/Fachgebiete/SysMod/Forschung/QUEST/. 1998. </address>
Reference-contexts: The paper summarizes the major issues involved in the integration of performance and time aspects in the formal description techniques SDL and MSC and the results of the discussion so far. The important tools that integrate performance aspects into SDL are SPECS [Bue96], QUEST and the language QSDL <ref> [Die95, Que98] </ref>, EasySim-II [Ger97], DNAsty and SDLnet [Kab97], and SPEET [Ste97]. Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool [Smi97], and the tool described in [ElS98]. <p> Flexibility is supported by a separate description of the mapping of the resource requests on the available resources (e.g. [Die95, Ger98]). 2.3.5 Performance Metrics and Sensors Performance sensors are used to specify the performance metrics monitored and measured during the performance evaluation. QSDL provides sophisticated aggregated performance sensors <ref> [Die98, Que98] </ref> while others rely on rather simple probes. Simple probes used in SPEET [Ste97] or PMSC [Fal97] focus on providing an interface to output performance data. With QSDL, aggregated performance sensors are special data types maintained by the underlying system during the system simulation. <p> However, it is not central for a typical performance evaluation. Basic approaches to specify performance requirements are * extended MSCs [Fal97, Sch98], * temporal logics used in conjunction with performance sensors <ref> [Die98, Que98] </ref>, and * the direct use of SDL to check performance requirements within the SDL specification during the system simulation. MSCs are especially appropriate to specify response time requirements.
Reference: [Ree96] <author> R. Reed. </author> <title> Methodology for real time systems. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 28, </volume> <pages> pp 1685-1701, </pages> <year> 1996. </year>
Reference: [Rou98] <author> J.L. Roux. </author> <title> SDL Performance Analysis with ObjectGEODE. </title> <booktitle> In [Mit98]. </booktitle>
Reference-contexts: QSDL [Die95] uses SDL processes (extended to model time more precisely) to describe arrival processes. PMSC [Fal97] employs a special notation to describe system stimuli. Another approach is to have a separate workload generator linked to the SDL specification, implemented in an arbitrary (non-standardized) language or notation (e.g. <ref> [Ger97, Rou98] </ref>). For a standardized approach only the first two approaches seem to be appropriate. Due to its similarities with the current SDL standard, the use of SDL processes to specify the system stimuli seems to be most appropriate. <p> For an early evaluation, a coarse model may be sufficient. The known approaches range from the simple specification of delays to a precise model of the underlying hardware. In <ref> [Bue96, Rou98] </ref>, delays are specified from which the response times are derived considering concurrency within a set of processes. In [Die95, Ger97], queuing models with various service strategies and priorities are employed. A detailed emulation of the underlying processor hardware is used in [Ste97]. <p> Level of detail of the resource demands The level of detail of the resource requests is an important issue. Alternatives are the association of a service request to actions or complete transitions in SDL <ref> [Rou98] </ref>, or to add special service requests to arbitrary points in the SDL specification [Die95, Ger98]. It has been argued that service requests should be associated to SDL constructs, rather than introducing a new construct.
Reference: [Rud96] <author> E. Rudolph, P. Graubmann, J Grabowski. </author> <title> Tutorial on Message Sequence Charts. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 28, </volume> <pages> 1629-1641, </pages> <year> 1996. </year>
Reference: [Sch98] <author> I. Schieferdecker, A. Rennoch. </author> <title> Usage of Timed MSCs for Test Purpose Definition. </title> <booktitle> In [Mit98]. </booktitle>
Reference-contexts: However, it is not central for a typical performance evaluation. Basic approaches to specify performance requirements are * extended MSCs <ref> [Fal97, Sch98] </ref>, * temporal logics used in conjunction with performance sensors [Die98, Que98], and * the direct use of SDL to check performance requirements within the SDL specification during the system simulation. MSCs are especially appropriate to specify response time requirements.
Reference: [Smi90] <author> C.U. Smith. </author> <title> Performance Engineering of Software Systems. SEI Series in Software Engineering, </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: The extra effort necessary to derive and maintain a separate per-formance model in addition to the functional model is often shunned by putting off performance issues as long as possible in the engineering process. A survey of the risks of the `fix-it-later' approach is given in <ref> [Smi90] </ref>. The `fix-it-later' approach is especially dangerous in the major application area of SDL. In the telecommunication sector, product families are offered which evolve over many years and which have to be maintained and updated for a period of 20 years or more.
Reference: [Smi97] <author> C.U. Smith, L.G. Williams. </author> <title> Performance Engineering Evaluation of Object-Oriented Systems with SPEED. </title> <booktitle> Intl. Conf. on Computer Performance Evaluation: Modelling Techniques and Tools, Lecture Notes in Computer Science 1245, </booktitle> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool <ref> [Smi97] </ref>, and the tool described in [ElS98]. A survey and classification of the approaches employed by the tools can be found in [Mit97]. The different approaches to describe and associate the additional information needed for a performance evaluation to the SDL and MSC specification are described in [Mit98].
Reference: [Ste97] <author> M. Steppler, M. Lott. </author> <title> SPEET - SDL Performance Evaluation Tool. </title> <booktitle> Proc. of Eighth SDL Forum, </booktitle> <address> Evry, France, </address> <publisher> Elsevier, </publisher> <year> 1997. </year>
Reference-contexts: The important tools that integrate performance aspects into SDL are SPECS [Bue96], QUEST and the language QSDL [Die95, Que98], EasySim-II [Ger97], DNAsty and SDLnet [Kab97], and SPEET <ref> [Ste97] </ref>. Tools that base their performance evaluation on MSC rather than on SDL are the DO-IT Toolbox [Mit96], the rapid prototyping project conducted at the University of Erlangen [Mit97a], the SPEED tool [Smi97], and the tool described in [ElS98]. <p> In [Bue96, Rou98], delays are specified from which the response times are derived considering concurrency within a set of processes. In [Die95, Ger97], queuing models with various service strategies and priorities are employed. A detailed emulation of the underlying processor hardware is used in <ref> [Ste97] </ref>. Multiple use of the resource/platform description The description of the resources or implementation platform may serve two very different purposes. It is needed for a performance evaluation as well as to specify the platform for the implementation of the SDL specification. <p> QSDL provides sophisticated aggregated performance sensors [Die98, Que98] while others rely on rather simple probes. Simple probes used in SPEET <ref> [Ste97] </ref> or PMSC [Fal97] focus on providing an interface to output performance data. With QSDL, aggregated performance sensors are special data types maintained by the underlying system during the system simulation.
Reference: [Tel96] <institution> Telelogic Malmo AB: </institution> <note> SDT 3.1 User's Guide, SDT 3.1 Reference Manual. </note> <year> 1996. </year>
Reference-contexts: In the worst case, the system runs completely out of control due to its enormous complexity. A system specified with SDL may serve as a basis for verification, validation, functional simulation and animation, code generation, prototyping, and testing. Today there are SDL tools like SDT <ref> [Tel96] </ref> and ObjectGEODE [Ver96] supporting these activities. However, the integration of performance and time aspects into the SDL methodology and the SDL tools has not been fully established so far. Therefore, the usability of SDL for performance-critical applications is limited.
Reference: [Ver96] <author> Verilog. ObjectGEODE Technical Documentation, </author> <year> 1996. </year>
Reference-contexts: In the worst case, the system runs completely out of control due to its enormous complexity. A system specified with SDL may serve as a basis for verification, validation, functional simulation and animation, code generation, prototyping, and testing. Today there are SDL tools like SDT [Tel96] and ObjectGEODE <ref> [Ver96] </ref> supporting these activities. However, the integration of performance and time aspects into the SDL methodology and the SDL tools has not been fully established so far. Therefore, the usability of SDL for performance-critical applications is limited. <p> Currently, the time may or may not be advanced by an action or a transaction. A legal interpretation of this is to advance the time only when all queues of the system are empty (e.g. <ref> [Ver96] </ref>). As depicted in figure 3, this interpretation has the advantage of reducing the set of possible traces. Thus, the complexity of the (functional) simulation and validation is reduced. However, for a performance simulation, this interpretation is not appropriate. From the implementational viewpoint, time is advanced be every action.
Reference: [Wir98] <author> K. Wirth. </author> <title> Overload Control in GSM Handling the Problem in the Context of SDL. </title> <booktitle> In [Mit98]. </booktitle> <pages> 14 </pages>
Reference-contexts: There, load sensors are implemented by the underlying runtime system depending on the special needs of the application. The detection of specific load situations triggers SDL signals sent to the SDL processes in charge of dealing with the problems (e.g. see <ref> [Wir98] </ref>). 2.3.6 Performance Requirements This is an important issue for the automatic verification of performance requirements. However, it is not central for a typical performance evaluation.
References-found: 33

