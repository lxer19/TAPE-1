URL: http://www.ai.sri.com/~reddy/thesis/thesis.ps.gz
Refering-URL: http://www.ai.sri.com/~reddy/thesis/
Root-URL: 
Title: Perceptually Modulated Level of Detail for Virtual Environments  
Author: Martin Reddy 
Degree: Doctor of Philosophy  
Date: 1997  
Affiliation: University of Edinburgh  
Abstract-found: 0
Intro-found: 1
Reference: <author> Airey, J. M., Rohlf, J. H. and Frederick P. Brooks, J. </author> <year> (1990). </year> <title> Towards Image Realism with Interactive Update Rates in Complex Virtual Building Environments, </title> <booktitle> ACM SIGGRAPH Special Issue on 1990 Symposium on Interactive 3D Graphics, </booktitle> <volume> 24(2): </volume> <pages> 4150. </pages>
Reference-contexts: This technique is only of use if the VE is amenable to this sort of segmentation. For example, it is particularly applicable to architectural walkthroughs where the boundary of each room can be used as the boundary for the subdivision <ref> (Airey et al., 1990) </ref>: but it would be of little use for large, open spaces. [PROCESSING, RENDERING] * Employ Parallelism : as alluded to in Section 1.2.1, we can attempt to reduce lags by using multi-processor systems and parallelising the major processes.
Reference: <author> Aliaga, D. G. </author> <year> (1996). </year> <title> Dynamic Simplification Using Textures, </title> <type> UNC Technical Report No. </type> <institution> TR96-007, Deptartment of Computer Science, University of North Carolina, Chapel Hill, NC. </institution>
Reference-contexts: This optimisation can introduce visual artifacts if the model is viewed from a different viewpoint or distance. However, a number of solutions exist to combat this problem; including warping the texture image (McMillan and Bishop, 1995), warping the adjacent geometry <ref> (Aliaga, 1996) </ref>, and smoothly transforming between geometry and texture (Maciel and Shirley, 1995). 10 * Illumination Models : the particular illumination model which is used to render an object can influence the display time.
Reference: <author> Andrews, P. R. and Campbell, F. W. </author> <year> (1991). </year> <title> Images at the Blind Spot, </title> <journal> Nature, </journal> <volume> 353(6342): </volume> <pages> 308. </pages>
Reference-contexts: This therefore raises the question: could we reduce the detail of objects that fall onto a user's blind spot? The angular size of the blind spot is quite large: around 5 deg <ref> (Andrews and Campbell, 1991) </ref>. However, because LOD implies a per-object modulation, we would require all of an object to be projected onto the blind spot before we could degrade its detail (or perhaps even remove it completely from the scene).
Reference: <author> Anstis, S. M. and Cavanagh, P. </author> <year> (1983). </year> <title> A Minimum Motion Technique for Judging Equiluminance in Colour Vision, </title> <editor> in J. D. Mollon and L. T. Sharpe (eds), </editor> <title> Colour Vision: Physiology and Psychophysics, </title> <publisher> Academic Press, Lon-don, </publisher> <pages> pp. 156166. </pages>
Reference-contexts: We must therefore ask if we would lose any accuracy by employing achromatic threshold data to our task; and whether we should consider applying colour contrast data instead. We know that the achromatic channel is far more effective than the chromatic channels for processing shape (Mullen, 1985), motion <ref> (Anstis and Cavanagh, 1983) </ref>, and stereoscopic depth (Gregory, 1977).
Reference: <author> Astheimer, P. and Pche, M.-L. </author> <year> (1994). </year> <title> Level-Of-Detail Generation and its Application in Virtual Reality, </title> <booktitle> Proceedings of the VRST '94 conference, Singa-pore, </booktitle> <pages> pp. 299309. </pages>
Reference: <author> Atkin, P. J. </author> <year> (1993). </year> <title> Parallel Processing for Virtual Reality, Parallel Processing for Graphics and Scientific Visualization, </title> <institution> University of Edinburgh. </institution>
Reference-contexts: We shall refer to the cumulative effect of both of these delays as System Lag. There are a number of contributing factors which can affect the magnitude of the System Lag. These can be divided, in terms of the application program, into three fundamental components <ref> (Atkin, 1993) </ref>: 1. Sensor Delay : the delay incurred by the sensing of the real environment, e.g. the tracking of a user's body part such as their head or hand. <p> This of course does not actually reduce any of the component lags in a system; but it does reduce the combined effect of these, i.e. System Lag. This approach has been used in a number of successful systems such as Division Ltd.'s PROvision systems <ref> (Atkin, 1993) </ref>, Silicon Graphics Inc.'s IRIS Performer (Rohlf and Helman, 1994), and the freely-available MR-Toolkit package (Shaw et al., 1992). 1.2.3.1 Discussion of Solutions Each of the above solutions offer various advantages and disadvantages.
Reference: <author> Bahill, A. T., Adler, D. and Stark, L. </author> <year> (1975). </year> <title> Most Naturally Occuring Saccades Have Magnitudes of 15 Degrees or Less, </title> <journal> Investigative Ophthalmology and Visual Science, </journal> <volume> 14: </volume> <pages> 468. </pages>
Reference: <author> Banks, M. S. </author> <year> (1982). </year> <title> The Development of Spatial and Temporal Contrast Sensitivity, </title> <journal> Current Eye Research, </journal> <volume> 2: </volume> <year> 191198. </year>
Reference-contexts: Individual Considerations : * Age : contrast sensitivity varies as a function of age. For example, an infant's CSF is significantly displaced from an adult's CSF. Consequently we know that infants can only see large, high contrast objects <ref> (Banks, 1982) </ref>. Owsley et al. (1983) investigated the contrast sensitivity of adults over a range of ages (20 to 80 years).
Reference: <author> Barfield, W. and Hendrix, C. </author> <year> (1995). </year> <title> The Effect of Update Rate on the Sense of Presence within Virtual Environments, Virtual Reality: </title> <journal> Research, Development, Applications, </journal> <volume> 1(1): </volume> <pages> 316. </pages>
Reference-contexts: With respect to this, it has been reported that 5 reduced frame rates (less than 15 Hz) can significantly diminish a user's sense of presence within a VE <ref> (Barfield and Hendrix, 1995) </ref>. 1.2.3 Techniques to Reduce Lag Based upon the above discussion, it is clearly undesirable to produce VR systems with a high degree of lag. As a result, a number of techniques have been developed to reduce System Lag in VR systems.
Reference: <author> Barten, P. G. J. </author> <year> (1990). </year> <title> Evaluation of Subjective Image Quality with the Square-Root Integral Method, </title> <journal> Journal of the Optical Society of America A (Optics and Image Science), </journal> <volume> 7(10): 20242031. 209 Beck, </volume> <editor> J., Sutter, A. and Ivry, R. </editor> <year> (1987). </year> <title> Spatial Frequency Channels and Per--ceptual Grouping in Texture Segregation, Computer Vision, </title> <journal> Graphics, and Image Processing (CVGIP), </journal> <volume> 37: </volume> <pages> 299325. </pages>
Reference-contexts: is, what is the value of CIELUV colour difference (E fl uv ) below which the user cannot perceive any change between two colours? This topic is not tackled to any extent by the colour perception literature; although a few references talk about CIELUV units in the order of 310 <ref> (Barten, 1990) </ref>. We therefore decided to try and evaluate this threshold empirically. An experiment was devised in which an observer tried to match two different colours so that they could perceive no difference. The E fl uv value at this point was noted in each case.
Reference: <author> Biederman, I. </author> <year> (1987). </year> <title> Recognition by Components: A Theory of Human Image Understanding, </title> <journal> Psychological Review, </journal> <volume> 94(2): </volume> <pages> 115147. </pages>
Reference: <author> Billyard, A. </author> <year> (1993). </year> <title> Shifting the Software/Silicon Balance in High Performance 3D Graphics, </title> <booktitle> VR93 Virtual Reality International 93: Proceedings of the Third Annual Conference on Virtual Reality, Meckler, </booktitle> <address> London, UK, </address> <pages> pp. </pages> <year> 1923. </year>
Reference-contexts: For this to be possible, work is required into the development of 8 algorithmic solutions to combat the various latencies currently experienced in VR systems, as opposed to resorting to custom hardware solutions. This view is held by a number of other researchers <ref> (e.g. Billyard, 1993) </ref>. Arguably, the only solutions presented above which enable the application program to balance the load of the system in real-time are: update rates and level of detail. All of the others offer a single (meaningful) reduction in lag for any application.
Reference: <author> Bishop, G., Fuchs, H., McMillan, L. and Scher Zagier, E. J. </author> <year> (1994). </year> <title> Frameless Rendering: Double Buffering Considered Harmful, </title> <editor> in A. Glassner (ed.), </editor> <booktitle> Proceedings of SIGGRAPH '94, Computer Graphics Proceedings, Annual Conference Series, ACM SIGGRAPH, </booktitle> <pages> pp. </pages> <note> 175176. ISBN 0-89791-667-0. </note>
Reference-contexts: Obviously, if the scene were to be rendered in a systematic left!right, top!bottom fashion then the user would be aware of the progressive update of the screen. Instead, pixels are rendered in a pseudo-random order so that the effect is less visually distracting <ref> (Bishop et al., 1994) </ref>.
Reference: <author> Blakemore, C. and Campbell, F. W. </author> <year> (1969). </year> <title> On the Existence of Neurones in the Human Visual System Selectively Sensitive to the Orientation and Size of Retinal Images, </title> <journal> Journal of Physiology, </journal> <volume> 203: </volume> <pages> 237260. </pages>
Reference-contexts: Also, the cortical cells respond maximally to gradients of luminance across their receptive fields rather than ambient illumination levels. However, unlike the retinal and LGN cells, they are also selective on the orientation of a stimulus and the direction of moving stimuli <ref> (Blakemore and Campbell, 1969) </ref>. We can segregate the cortical cells into two classes (Hubel and Wiesel, 1962): the simple cells, which are orientation selective to stationary or slow moving stimuli, and the complex cells, which respond maximally to moving stimuli of a particular orientation.
Reference: <author> Borgefors, G. </author> <year> (1992). </year> <title> A Hierarchical Square Tessellation of the Sphere, </title> <journal> Pattern Recognition Letters, </journal> <volume> 13(3): </volume> <pages> 183188. </pages>
Reference: <author> Bracewell, R. </author> <year> (1965). </year> <title> The Fourier Transform and Its Applications, </title> <publisher> McGraw-Hill, inc., </publisher> <address> New York, NY. </address>
Reference-contexts: + (RSF () tan (90 )) 2 ; when 45 ffi ffi 3.1.7 What's Wrong with Fourier Analysis? 3.1.7.1 Introduction to Fourier Analysis The technique of Fourier analysis can be used to decompose an image function into the set of harmonic intensity functions which sum to give the original image <ref> (Bracewell, 1965) </ref>. This transformation is normally represented mathematically as F (u; v) = F ff (x; y)g, where f (x; y) represents the spatial domain of 79 the original image and F (u; v) represents the frequency domain of the Fourier transformed result.
Reference: <author> Brigham, E. O. </author> <year> (1974). </year> <title> The Fast Fourier Transform, </title> <publisher> Prentice-Hall, inc., </publisher> <address> Engle-wood Cliffs, NJ. ISBN 0-13-307496-X. </address>
Reference-contexts: The formula for the 2D DFT can be defined as follows: F (u; v) x=0 y=0 M + vy In practice however, computing this function directly is impractical. The most common method is to use the Fast Fourier Transform (FFT) which drastically reduces the complexity of the DFT calculation <ref> (Brigham, 1974) </ref>. 3.1.7.2 Problems with Fourier Analysis On first inspection, Fourier analysis sounds like a perfect solution to our problem: it takes a 2D source image and returns a frequency domain containing all of the relative spatial frequencies in that image. However, this is not actually what we require.
Reference: <author> Bryson, S. </author> <year> (1993). </year> <title> Effects of Lag and Frame Rate on Various Tracking Tasks, </title> <booktitle> Proceedings of the SPIE The International Society for Optical Engineering, Vol. 1915 of Stereoscopic Displays and Applications IV, </booktitle> <address> Bellingham, WA, </address> <pages> pp. 155166. </pages>
Reference-contexts: More precisely, it is the period of time between some change being effected on the VE, and that change being reflected on the display device (Bryson and Fisher, 1990). This can be broken down into two principal types of temporal degradation <ref> (Bryson, 1993) </ref>: 1. Update Rate : the rate at which the visual display is refreshed. This is also often referred to as the frame rate of an application. A low update rate implies a high degree of lag. 2.
Reference: <author> Bryson, S. and Fisher, S. S. </author> <year> (1990). </year> <title> Defining, Modeling, and Measuring System Lag in Virtual Environments, </title> <booktitle> Proceedings of the SPIE The International Society for Optical Engineering, </booktitle> <volume> Vol. 1256, </volume> <pages> Bellingham, </pages> <address> WA, </address> <pages> pp. 98109. </pages>
Reference-contexts: More precisely, it is the period of time between some change being effected on the VE, and that change being reflected on the display device <ref> (Bryson and Fisher, 1990) </ref>. This can be broken down into two principal types of temporal degradation (Bryson, 1993): 1. Update Rate : the rate at which the visual display is refreshed. This is also often referred to as the frame rate of an application.
Reference: <author> Burr, D. C. and Ross, J. </author> <year> (1982). </year> <title> Contrast Sensitivity at High Velocities, </title> <journal> Vision Research, </journal> <volume> 22: </volume> <pages> 479484. </pages>
Reference: <author> Caelli, T. M. and Moraglia, G. </author> <year> (1985). </year> <title> On the Detection of Gabor Signals and Discriminations of Gabor Textures, </title> <journal> Vision Research, </journal> <volume> 25: </volume> <pages> 671684. </pages>
Reference: <author> Campbell, F. W., Carpenter, R. H. S. and Levinson, J. Z. </author> <year> (1969). </year> <title> Visibility of Aperiodic Patterns Compared with that of Sinusoidal Gratings, </title> <journal> Journal of Physiology, </journal> <volume> 204: </volume> <pages> 283298. </pages>
Reference-contexts: Also, the cortical cells respond maximally to gradients of luminance across their receptive fields rather than ambient illumination levels. However, unlike the retinal and LGN cells, they are also selective on the orientation of a stimulus and the direction of moving stimuli <ref> (Blakemore and Campbell, 1969) </ref>. We can segregate the cortical cells into two classes (Hubel and Wiesel, 1962): the simple cells, which are orientation selective to stationary or slow moving stimuli, and the complex cells, which respond maximally to moving stimuli of a particular orientation.
Reference: <author> Campbell, F. W. and Green, D. G. </author> <year> (1965). </year> <title> Optical and Retinal Factors Affecting Visual Resolution, </title> <journal> Journal of Physiology, </journal> <volume> 181: 576593. 210 Campbell, </volume> <editor> F. W. and Gubisch, R. W. </editor> <year> (1966). </year> <title> Optical Quality of the Human Eye, </title> <journal> Journal of Physiology, </journal> <volume> 186: </volume> <pages> 558578. </pages>
Reference-contexts: A smaller pupil size implies that less light can reach the retina. This reduction of retinal illumination will cause a drop in the observer's visual acuity <ref> (Campbell and Green, 1965) </ref>. * Experience : Gregory (1990) suggests that our perception of objects may be influenced by a priori knowledge and past experience.
Reference: <author> Campbell, F. W., Hulikowski, J. J. and Levinson, J. </author> <year> (1966). </year> <title> The Effect of Orientation on the Visual Resolution of Gratings, </title> <journal> Journal of Physiology, </journal> <volume> 187: 427 436. </volume>
Reference-contexts: In this fashion, it has been empirically confirmed that our ability to resolve detail varies in relation to the orientation of a contrast grating <ref> (Campbell et al., 1966) </ref>, its velocity across the retina (Kelly, 1979), the degree to which it is placed in our peripheral field (Rovamo and Virsu, 1979), and the level of background illumination (Kelly, 1975). <p> A sufficiently large initial value for ff should be chosen so that the highest 123 root of H (ff; v; E)1 = 0 is always found, e.g. the highest spatial frequency that our visual system can resolve, ff = 60 c/deg <ref> (Campbell and Gubisch, 1966) </ref>. Naturally such an iterative calculation should be avoided during a real-time simulation for performance reasons. <p> In order to calculate the predicted threshold response, we used our cortical magnification factor, defined by Equation 3.20. This can be written in terms of spatial frequency (ff) as: where M 0 = 60 c/deg: the highest spatial frequency which can be resolved at the fovea <ref> (Campbell and Gubisch, 1966) </ref>. The experiment produced results which were in the correct order of magnitude, but somewhat displaced from our predicted curve. A best fit curve was therefore calculated which represented the data more closely.
Reference: <author> Campbell, F. W. and Robson, J. G. </author> <year> (1968). </year> <title> Application of Fourier Analysis to the Visibility of Gratings, </title> <journal> Journal of Physiology, </journal> <volume> 197: </volume> <pages> 551566. </pages>
Reference-contexts: predicts that information is analysed independently by a number of parallel channels, each of which is tuned to a particular level of detail. 2.3.2 Measuring Visual Acuity 2.3.2.1 Contrast Gratings and Spatial Frequency The human ability to perceive detail is determined by the relative size and contrast of a stimulus <ref> (Campbell and Robson, 1968) </ref>. This faculty has been extensively analysed by vision researchers for the past several decades. Since the pioneering work of Schade (1956), the most common experimental device for accurately measuring a subject's visual acuity is the contrast grating.
Reference: <author> Carpenter, R. H. S. </author> <year> (1992). </year> <title> Turning Vision Into Actions, </title> <booktitle> Current Biology, </booktitle> <volume> 2: 288 290. </volume>
Reference-contexts: The main sites of processing on the visual pathways are the superior colliculus and the lateral geniculate nucleus (LGN). The superior colliculus is believed to be responsible for determining the location of a stimulus and also initiating and controlling eye movements <ref> (Carpenter, 1992) </ref>. Of more interest to our discussion are the lateral geniculate nuclei (there are twoone on each side of the brain), which form a feedback loop with the visual cortex. The cells of each LGN have antagonistic, concentric receptive fields much like those of the retinal ganglion cells.
Reference: <author> Carter, R. </author> <year> (1996). </year> <type> Personal communication. </type>
Reference-contexts: Also, the CIELUV system is the most flexible because it is the only system which can incorporate size corrections <ref> (Carter, 1996) </ref>. All colour difference equations are based around the CIEXYZ system which is only defined for colours that occupy 2 degrees of the user's field of view. But our colour perception degrades as the stimulus size decreases (Wyszecki and Fielder, 1971).
Reference: <author> Carter, R. C. </author> <year> (1989). </year> <title> Calculate (Don't Guess) the Effect of Symbol Size on Usefulness of Color, </title> <booktitle> Proceedings of the Human Factors Society 33rd Annual Meeting, </booktitle> <pages> pp. 13681372. </pages>
Reference-contexts: Stimulus Size : colour differences vary in relation to the size of the two colours, but the CIE colour spaces are only defined for colours occupying 2 deg of visual arc. However, we have already noted that size correction formulae exist for the CIELUV colour difference equation <ref> (see Carter, 1989, for a review) </ref>. 2. Surrounding Colour (s) : the brightness of a colour can appear different for different surrounding colours. This effect is know as simultaneous contrast. Phillips (1986) reports that this can induce perceived colour 85 difference variations in the order of 1020%.
Reference: <author> Carter, R. C. and Carter, E. C. </author> <year> (1983). </year> <title> CIE L fl u fl v fl Color-Difference Equations for Self-Luminous Displays, Color Research and Application, </title> <type> 8: 252253. </type>
Reference: <author> Cavanagh, P. </author> <year> (1991). </year> <title> Vision at Equiluminance, </title> <editor> in J. R. Cronly-Dillon (ed.), </editor> <title> Vision and Visual Dysfunction: </title> <journal> Limits of Vision, </journal> <volume> Vol. 5, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 20, pp. </pages> <note> 234250. ISBN 0-333-52713-5. </note>
Reference-contexts: As an example, he notes that face perception is destroyed when only colour information available, i.e. at isoluminance (Gregory, 1993). Hubel and Wiesel (1962) also suggest that colour makes very little contribution to spatial and temporal vision. It is evident that colour is important for suprathreshold vision <ref> (Cavanagh, 1991) </ref>, however we can see that it plays a far inferior rle to luminance for threshold vision.
Reference: <author> Chrislip, C. A. and Ehlert Jr., J. F. </author> <year> (1995). </year> <title> Level of Detail Models for Dismounted Infantry in NPSNETIV.8.1, </title> <type> Master's thesis, </type> <institution> Naval Postgraduate School, </institution> <address> Monterey, CA. </address> <month> CIE </month> <year> (1979). </year> <title> Recommendations on Uniform Color Spaces: Color-Difference Equations, Supplement No. </title> <note> 2 to CIE Publication No. 15, </note> <institution> Vienna: Com-mision International de l'clairage, Central Bureau of the CIE. </institution>
Reference-contexts: These include: 11 a candlestick. Reproduced with kind permission from Wernecke (1993). (c) Silicon Graphics Inc., 1994. 1. There is currently no principled mechanism to select the optimal LOD at any point. As a result, most systems use trial and error judgements or ad hoc heuristics to decide this <ref> (Chrislip and Ehlert Jr., 1995) </ref>. While this may be satisfactory for the occasional distance LOD implementation, a general LOD paradigm must be based upon a more formal and tractable solution. 2.
Reference: <author> Ciuffreda, K. J. and Tannen, B. </author> <year> (1995). </year> <title> Eye Movement Basics for the Clinician, </title> <publisher> Mosby-Year Book, Inc., </publisher> <address> St. Louis, Missouri. ISBN 0-8016-6843-3. </address>
Reference: <author> Clark, J. H. </author> <year> (1976). </year> <title> Hierarchical Geometric Models for Visible Surface Algorithms, </title> <journal> Communications of the ACM, 19(10): </journal> <volume> 547554. </volume> <month> CMC </month> <year> (1989). </year> <title> CMC: Calculation of Small Color Differences for Acceptability, </title> <journal> Textile Chemist and Colorist, </journal> <volume> 21(11): </volume> <pages> 1821. </pages>
Reference: <author> Cohen, J., Varshney, A., Manocha, D., Turk, G., Weber, H., Agarwal, P., Brooks, F. and Wright, W. </author> <year> (1996). </year> <title> Simplification Envelopes, </title> <type> UNC Technical Report No. </type> <institution> TR96-017, Deptartment of Computer Science, University of North Car-olina, Chapel Hill, NC. </institution> <note> 211 Coltman, </note> <author> J. W. and Anderson, A. E. </author> <year> (1960). </year> <title> Noise Limitations to Resolving Power in Electronic Imaging, </title> <booktitle> Proceedings of the Institute of Radio Engineers, </booktitle> <volume> Vol. 48, </volume> <pages> pp. 858865. </pages>
Reference: <author> Cook, R. L., Porter, T. and Carpenter, L. </author> <year> (1984). </year> <title> Distributed Ray Tracing, </title> <journal> Computer Graphics, </journal> <volume> 18(3): </volume> <pages> 137144. </pages>
Reference-contexts: then merged together using a simple weighted sum averaging algorithm, e.g. a box filter (Korein and Badler, 1983). * Distributed Ray Tracing : the various reflected and transmitted rays of a ray tracer are distributed in time as well as space, taking into account any changes in visibility and shading <ref> (Cook et al., 1984) </ref>. * Fourier Techniques : a Fast Fourier Transform (FFT) is performed on the image and then convolved with a Point-Spread Function (PSF) which describes the image path of the projected motion.
Reference: <author> Corless, R. M., Gonnet, G. H., Hare, D. E. G. and Jeffrey, D. J. </author> <year> (1993). </year> <title> On Lam-bert's W Function, </title> <type> Technical Report CS-93-03, </type> <institution> Department of Computer Science, University of Waterloo, Canada. </institution>
Reference-contexts: An analytical solution to this problem would be overtly complicated; requiring the computation of Lambert's W function <ref> (Corless et al., 1993) </ref>, or equivalent, to resolve the combination ff 2 exp (ff) which arises.
Reference: <author> Costella, J. P. </author> <year> (1993). </year> <title> Motion Extrapolation at the Pixel Level. </title> <institution> School of Physics, The University of Melbourne. </institution>
Reference: <author> Cowan, W. B. and Ware, C. </author> <year> (1985). </year> <title> Elementary colour coding, </title> <booktitle> SIGGRAPH 1985 Course #3 Notes: Colour Perception, </booktitle> <pages> pp. 5595. </pages>
Reference-contexts: This is because the degree of photoreceptor pooling for ganglion cells varies with eccentricity. At the fovea, there is a 1:1 correspondence between cones and ganglion cells. This increases to a 7:1 mapping beyond the fovea <ref> (Cowan and Ware, 1985) </ref>. * There is a disproportionate number of cells in the visual cortex devoted to the foveal region of the retina. It has been estimated that 80% of all cortical cells are devoted to the central 10 degrees of the visual field (Drasdo, 1977). <p> However, the CIELUV system was specifically devised for viewing additive sources such as colour monitors (Travis, 1991; Carter and Carter, 1983) and is therefore the best colour system for our purposes <ref> (Cowan and Ware, 1985) </ref>. Also, the CIELUV system is the most flexible because it is the only system which can incorporate size corrections (Carter, 1996).
Reference: <author> Cutting, J. E. </author> <year> (1986). </year> <title> Perception with an Eye for Motion, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Cutting, J. E., Springer, K., Braren, P. A. and Johnson, S. H. </author> <year> (1992). </year> <title> Wayfind-ing on Foot From Information in Retinal, Not Optical, Flow, </title> <journal> Journal of Experimental Psychology: General, </journal> <volume> 121(1): </volume> <pages> 4172. </pages>
Reference: <author> Daly, S. </author> <year> (1993). </year> <title> The Visible Difference Predictor: An Algorithm for the Assessment of Image Fidelity, </title> <editor> in A. B. Watson (ed.), </editor> <title> Digital Images and Human Vision, </title> <publisher> MIT Press, </publisher> <pages> pp. 179206. </pages>
Reference: <author> Daniel, P. M. and Whitteridge, W. </author> <year> (1961). </year> <title> The Representation of the Visual Field on the Cerebral Cortex in Monkeys, </title> <journal> Journal of Physiology, </journal> <volume> 159: </volume> <year> 203221. </year>
Reference: <author> Daugman, J. G. </author> <year> (1984). </year> <title> Spatial Visual Channels in the Fourier Plane, </title> <journal> Vision Research, </journal> <volume> 24(9): </volume> <pages> 91910. </pages>
Reference: <author> Deering, M. F. </author> <year> (1994). </year> <title> Data Complexity for Virtual Reality: Where do all the Triangles Go?, </title> <booktitle> Proceedings of the VRST '94 conference, Singapore, </booktitle> <pages> pp. 357 363. </pages>
Reference-contexts: For example, a VE which is composed of a large number of polygons will take longer to process and render than a VE with fewer polygons <ref> (Deering, 1994) </ref>. This is not a simple relationship because, for example, the size and geometry of polygons can affect performance, and the use of texture maps can add visual detail to a VE which would otherwise require a large number of small polygons.
Reference: <author> Drasdo, N. </author> <year> (1977). </year> <title> The Neural Representation of Visual Space, </title> <journal> Nature, </journal> <volume> 266: </volume> <pages> 554556. </pages>
Reference-contexts: It has been estimated that 80% of all cortical cells are devoted to the central 10 degrees of the visual field <ref> (Drasdo, 1977) </ref>. The result of these characteristics is that our vision is maximally sensitive within a central region of approximately 5 deg of arc, and drops off smoothly towards the periphery (Zeki, 1993). <p> = M 0 =(1 + 0:29E + 0:000012E 3 ); 0 E 80 deg: (3.18) Inferior: M I = M 0 =(1 + 0:42E + 0:000055E 3 ); 0 E 60 deg: (3.19) 4 Where M 2 is directly proportional to the density of receptive fields of retinal ganglion cells <ref> (Drasdo, 1977) </ref>. 91 (a) (b) (lower curve) and with the cubic term ignored (upper curve). Where M 0 is the value of magnification for the most central point in the fovea; which we can simply instantiate as M 0 = 1.
Reference: <author> Eagle, R. A. and Rogers, B. J. </author> <year> (1991). </year> <title> Maximum Displacement (D max ) as a Function of Density, Patch Size, and Spatial-Filtering in Random-Dot Kin-ematograms, </title> <journal> Investigative Ophthalmology and Visual Science, </journal> <volume> 32(4): </volume> <pages> 893. </pages>
Reference-contexts: The term T max is the temporal equivalent of this spatial phenomenon. These values are therefore important in order to understand how we may preserve the illusion of apparent motion in a computer graphics system. It is known that D max is a function of stimulus size and density <ref> (Eagle and Rogers, 1991) </ref>, and that this value increases with retinal eccentricity. However, little work has been done to assess the values of D max and T max for complex, real-world images: most of the work in this field has been restricted to simple random dot displays.
Reference: <author> Eck, M., DeRose, T., Duchamp, T., Hoppe, H., Lounsbery, M. and Stuetzle, W. </author> <year> (1995). </year> <title> Multiresolution Analysis of Arbitrary Meshes, </title> <type> Technical Report 95-01-02, </type> <institution> University of Washington. </institution> <note> 212 Economy, </note> <author> R., Ferguson, R. L., Kelly, W. A. and Ramos, P. P. </author> <year> (1990). </year> <title> Continuous Terrain Level of Detail for Visual Simulation, </title> <booktitle> Proceedings of the IMAGE V Conference, Phoenix, Arizona, </booktitle> <pages> pp. 144151. </pages>
Reference: <author> Enroth-Cugell, C. and Robson, J. G. </author> <year> (1966). </year> <title> The Contrast Sensitivity of Retinal Ganglion Cells of the Cat, </title> <journal> Journal of Physiology, </journal> <volume> 187: </volume> <pages> 517552. </pages>
Reference: <author> Erikson, C. </author> <year> (1996). </year> <title> Polygonal Simplification: An Overview, </title> <type> UNC Technical Report No. </type> <institution> TR96-016, Deptartment of Computer Science, University of North Carolina, Chapel Hill, NC. </institution>
Reference: <author> Evans, R. </author> <year> (1990). </year> <title> Image Quality Metrics and Performance of Visual Display Systems, </title> <booktitle> Proceedings of the IMAGE V Conference, Phoenix, Arizona, </booktitle> <pages> pp. 115 122. </pages>
Reference-contexts: It may be instructive to note that our term, highest displayable spatial frequency, is merely a simplification of the display device's modulation transfer function (MTF). The MTF is a measure of a display's ability to maintain the contrast of a signal as a function of its spatial frequency <ref> (Evans, 1990) </ref>, i.e. in effect it is the electronic equivalent of our biological system's contrast sensitivity function (CSF). The general operation would therefore be to threshold the CSF using the MTF.
Reference: <author> Falby, J. S., Zyda, M. J., Pratt, D. R. and Mackey, R. L. </author> <year> (1993). </year> <title> NPSNET: Hierarchical Data Structures for Real-Time Three-Dimensional Visual Simulation, </title> <journal> Computer and Graphics, </journal> <volume> 17(1): 6569. </volume> <publisher> Pergamon Press, </publisher> <address> UK. </address>
Reference-contexts: Their NPSNET system uses a terrain dataset of 50fi50 km at a resolution of 125 m; employing a terrain paging algorithm in order to manage the swapping of visible terrain tiles <ref> (Falby et al., 1993) </ref>. Three different resolutions of this dataset were generated (at resolutions of 250, 500, and 1000 m) and the terrain resolution at any point was based upon a measure of its distance from the viewpoint.
Reference: <author> Foley, J. D., van Dam, A., Feiner, S. K. and Hughes, J. F. </author> <year> (1990). </year> <title> Computer Graphics: </title> <booktitle> Principles and Practice, second edn, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. ISBN 0-201-12110-7. </address>
Reference-contexts: For example, lighting models such as Phong or Gouraud (smooth-shading) produce more realistically shaded results than the Lambertian (flat-shading) model, but at the price of higher computational complexity <ref> (Foley et al., 1990) </ref>.
Reference: <author> Frank, L. H., Casali, J. G. and Wierwille, W. W. </author> <year> (1988). </year> <title> Effects of Visual Display and Motion System Delays on Operator Performance and Uneasiness in a Driving Simulator, </title> <booktitle> Human Factors, </booktitle> <volume> 30(2): </volume> <year> 201217. </year>
Reference: <author> Funkhouser, T. A. and Squin, C. H. </author> <year> (1993). </year> <title> Adaptive Display Algorithm for Interactive Frame Rates During Visualization of Complex Virtual Environments, </title> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> Vol. 27, </volume> <pages> pp. 247 254. </pages>
Reference-contexts: For example, lighting models such as Phong or Gouraud (smooth-shading) produce more realistically shaded results than the Lambertian (flat-shading) model, but at the price of higher computational complexity (Foley et al., 1990). Therefore, we can use different lighting models to render an object to introduce different levels of detail <ref> (Funkhouser and Squin, 1993) </ref>. 1.3.2 A Typical Implementation The normal way in which LOD is implemented is to base the model selection upon the distance of the object from the viewpoint. <p> This would imply that perceptually modulated LOD would be more suited to an immersive VR system where this situation is more generally true. 169 6.2.1.2 Rendering Consideration Some researchers have contemplated using different rendering models to produce various LODs, such as flat-shading or smooth-shading <ref> (e.g. Funkhouser and Squin, 1993) </ref>. However we should note the existence of a fundamental dichotomy in this case. That is, a smooth-shaded object will generally have a lower spatial frequency content than the corresponding flat-shaded object (because the interpolation removes sharp edges from the image).
Reference: <author> Gervais, M. J., L. O. Harvey, J. and Roberts, J. O. </author> <year> (1984). </year> <title> Identification Confusions Among Letters of the Alphabet, </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 10(5): </volume> <pages> 655666. </pages>
Reference: <author> Gonzalez, R. C. and Woods, R. E. </author> <year> (1992). </year> <title> Digital Image Processing, </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA. ISBN 0-201-50803-6. </address>
Reference-contexts: A number of techniques have therefore been developed to compensate for, or smooth over, noisy components within an image <ref> (Gonzalez and Woods, 1992) </ref>. <p> That is, Fourier analysis will only (accurately) extract perfectly harmonic variances in intensity 1 . 2. Fourier analysis will return values for all spatial frequencies at every point 1 There exist other transforms, such as the Walsh Transform <ref> (Gonzalez and Woods, 1992) </ref>, which can locate square-wave intensity components. However, these will then suffer from an inability to locate smooth intensity gradients, i.e. any such features will be recorded as a series of small square-waves instead of a more appropriate sine-wave coding. 81 in the image.
Reference: <author> Gregory, R. L. </author> <year> (1977). </year> <title> Vision with Isoluminant Colour Contrast: 1. a Projection Technique and Observations, </title> <journal> Perception, </journal> <volume> 6: </volume> <pages> 113119. </pages>
Reference-contexts: We know that the achromatic channel is far more effective than the chromatic channels for processing shape (Mullen, 1985), motion (Anstis and Cavanagh, 1983), and stereoscopic depth <ref> (Gregory, 1977) </ref>.
Reference: <author> Gregory, R. L. </author> <year> (1990). </year> <title> Eye and Brain: the Psychology of Seeing, </title> <booktitle> fourth edn, Weidenfeld and Nicolson, </booktitle> <address> London. </address>
Reference: <author> Gregory, R. L. </author> <year> (1993). </year> <title> Seeing by Exploring, </title> <editor> in S. R. Ellis, M. K. Kaiser and A. J. Grunwald (eds), </editor> <title> Pictorial Communication in Virtual and Real Environments, second edn, Taylor and Francis, </title> <note> chapter 21, pp. 328337. ISBN 0-74840-0082-6. </note>
Reference-contexts: As an example, he notes that face perception is destroyed when only colour information available, i.e. at isoluminance <ref> (Gregory, 1993) </ref>. Hubel and Wiesel (1962) also suggest that colour makes very little contribution to spatial and temporal vision. It is evident that colour is important for suprathreshold vision (Cavanagh, 1991), however we can see that it plays a far inferior rle to luminance for threshold vision.
Reference: <author> Hallett, P. E. </author> <year> (1991). </year> <title> Some Limitations to Human Peripheral Vision, </title> <editor> in J. R. Cronly-Dillon (ed.), </editor> <title> Vision and Visual Dysfunction: </title> <journal> Limits of Vision, </journal> <volume> Vol. 5, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 6, pp. </pages> <note> 4480. ISBN 0-333-52713-5. </note>
Reference-contexts: This roughly means that the width of your thumb in centimeters is its angular subtense in degrees at arm's length. (60 minutes of arc = 1 degree.) 21 the cone density <ref> (Hallett, 1991) </ref>. * The receptive field size of retinal ganglion cells increases linearly with eccentricity (Kelly, 1984). This is because the degree of photoreceptor pooling for ganglion cells varies with eccentricity. At the fovea, there is a 1:1 correspondence between cones and ganglion cells.
Reference: <author> Hamann, B. </author> <year> (1994). </year> <title> A Data Reduction Scheme for Triangulated Surfaces, </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 11(2): </volume> <year> 197214. </year>
Reference: <author> Hardin, C. L. </author> <year> (1988). </year> <title> Color For Philosophers, </title> <publisher> Hackett Publishing Company, </publisher> <address> In-dianapolis, CA. </address>
Reference: <author> Harvey, L. O. and Gervais, M. J. </author> <year> (1981). </year> <title> Internal Representation of Visual Texture as the Basis for the Judgement of Similarity, </title> <journal> Journal of Experimental Psychology: Human Perception Performance, </journal> <volume> 7(4): </volume> <pages> 741753. </pages>
Reference: <author> Hawkes, R., Rushton, S. and Smyth, M. </author> <year> (1995). </year> <title> Update Rates and Fidelity in Virtual Environments, Virtual Reality: </title> <booktitle> Research, Development and Application, </booktitle> <volume> 1(2): </volume> <pages> 99108. </pages>
Reference: <author> He, T., Hong, L., Kaufman, A., Varshney, A. and Wang, S. </author> <year> (1995). </year> <title> Voxel Based Object Simplification, </title> <booktitle> Proceedings of Visualization '95, </booktitle> <pages> pp. 296303. </pages>
Reference-contexts: With respect to this, it has been reported that 5 reduced frame rates (less than 15 Hz) can significantly diminish a user's sense of presence within a VE <ref> (Barfield and Hendrix, 1995) </ref>. 1.2.3 Techniques to Reduce Lag Based upon the above discussion, it is clearly undesirable to produce VR systems with a high degree of lag. As a result, a number of techniques have been developed to reduce System Lag in VR systems.
Reference: <author> Heeley, D. </author> <year> (1991). </year> <title> Spatial Frequency Difference Thresholds Depend on Stimulus Area, Spatial Vision, </title> <type> 5(3): </type> <institution> 205217. </institution>
Reference: <author> Held, R. and Durlach, N. </author> <year> (1993). </year> <title> Telepresence, Time Delay and Adaption, </title> <editor> in S. R. Ellis, M. K. Kaiser and A. J. Grunwald (eds), </editor> <title> Pictorial Communication in Virtual and Real Environments, second edn, Taylor and Francis, </title> <note> chapter 14, pp. 232246. ISBN 0-74840-0082-6. </note>
Reference-contexts: For example, lags of between 30120 ms have been shown to degrade user performance, depending upon the application <ref> (Held and Durlach, 1993) </ref>. Singhal and Cheriton (1995) state that humans can detect latencies of around 100 ms, and will only tolerate maximum inconsistencies in the order of 200 ms.
Reference: <author> Helman, J. </author> <year> (1994). </year> <title> Designing Real-Time Graphics for Entertainment, Architecture and Performance of Entertainment Systems, </title> <note> Vol. 14 of SIGGRAPH '94 Lecture Notes, ACM Press, chapter 1. </note>
Reference-contexts: System Lag. This approach has been used in a number of successful systems such as Division Ltd.'s PROvision systems (Atkin, 1993), Silicon Graphics Inc.'s IRIS Performer <ref> (Rohlf and Helman, 1994) </ref>, and the freely-available MR-Toolkit package (Shaw et al., 1992). 1.2.3.1 Discussion of Solutions Each of the above solutions offer various advantages and disadvantages. <p> systems which have used LOD to maintain a desired frame rate include Airey et al.'s (1990) architectural walkthrough system [reactive], Hitchner and McGreevy's (1993) VPE testbed [reactive], Wloka's (1993a) Up 34 date Rate system [predictive] (see Section 1.2.3), and also the IRIS Performer graphics library developed by Silicon Graphics, Inc. <ref> (Rohlf and Helman, 1994) </ref> [reactive]. 2.1.6 Discussion of LOD Applications From the above, we can observe that LOD techniques have been used in a vast array of real-time applications. We have seen implementations in flight simulators, vehicle simulators, architectural walkthroughs, visualisations, digital terrain modeling, etc.
Reference: <author> Hinker, P. and Hansen, C. </author> <year> (1993). </year> <title> Geometric Optimization, </title> <booktitle> Proceedings of Visualization '93, </booktitle> <pages> pp. 189195. </pages>
Reference: <author> Hitchner, L. E. and McGreevy, M. W. </author> <year> (1993). </year> <title> Methods for User-Based Reduction of Model Complexity for Virtual Planetary Exploration, </title> <booktitle> Proceedings of the SPIE The International Society for Optical Engineering, </booktitle> <volume> Vol. </volume> <year> 1913, </year> <pages> pp. 622 36. </pages>
Reference: <author> Holloway, R. L. </author> <year> (1991). </year> <title> Viper: a Quasi-Real-Time Virtual-Worlds Application, </title> <type> UNC Technical Report No. </type> <institution> TR-92-004, Deptartment of Computer Science, University of North Carolina, Chapel Hill, NC. </institution>
Reference-contexts: This is particularly desirable because many users tend to feel disoriented when they move their heads rapidly and the system does not keep up with their movements <ref> (Holloway, 1991) </ref>. Therefore, by reducing detail during head movements we can improve the update rate of the system and thus make the simulation appear more smooth and interactive.
Reference: <author> Hoppe, H., DeRose, T., Duchamp, T., McDonald, J. and Stuetzle, W. </author> <year> (1992). </year> <title> Surface Reconstruction from Unorganised Points, </title> <journal> Computer Graphics (SIG-GRAPH'92 Proceedings), </journal> <volume> 26(2): </volume> <pages> 7178. </pages> <note> 214 Hoppe, </note> <author> H., DeRose, T., Duchamp, T., McDonald, J. and Stuetzle, W. </author> <year> (1993). </year> <title> Mesh Optimization, </title> <booktitle> Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pp. </pages> <year> 1925. </year>
Reference-contexts: Also, vertices that lie on the convex hull of the object can be preserved in an attempt to retain the general form of the object. 2.2.2.3 Mesh Optimisation (Hoppe et al.) Hoppe et al. (1993) present a triangular mesh simplification process which was based upon their surface reconstruction work <ref> (Hoppe et al., 1992) </ref>. This technique introduces the concept of an energy function to model the opposing factors of polygon reduction and similarity to the original topography. The energy function is used to provide a measure of deviance between the original mesh and the simplified version.
Reference: <author> Hubel, D. and Wiesel, T. </author> <year> (1962). </year> <title> Receptive Fields, Binocular Interaction, and Functional Architecture in the Cat's Visual Cortex, </title> <journal> Journal of Physiology, </journal> <volume> 160: </volume> <pages> 106154. </pages>
Reference-contexts: However, unlike the retinal and LGN cells, they are also selective on the orientation of a stimulus and the direction of moving stimuli (Blakemore and Campbell, 1969). We can segregate the cortical cells into two classes <ref> (Hubel and Wiesel, 1962) </ref>: the simple cells, which are orientation selective to stationary or slow moving stimuli, and the complex cells, which respond maximally to moving stimuli of a particular orientation.
Reference: <author> Humphreys, G. W. and Bruce, V. </author> <year> (1991). </year> <title> Visual Cognition: Computational, Experimental and Neuropsychological Perspectives, </title> <publisher> Hove Lawrence Erlbaum Associates. </publisher> <address> ISBN 0-863-77125-4. </address>
Reference-contexts: In the most densely packed region of the retina, photorecept-ors subtend around 0.5 min of arc. Not surprisingly therefore, we find that the eye can detect detail down to a size of about 0.5 min of arc <ref> (Humphreys and Bruce, 1991) </ref> 2 . 1.4.4.2 Retinal Inhomegenity The eye's sensitivity to the size of a stimulus is not uniform across the entire retina.
Reference: <author> Hurault, F. </author> <year> (1993). </year> <title> A Head Slaved Visual System for Flight Simulators, </title> <booktitle> Proceedings of the International Training Equipment Conference and Exhibition, </booktitle> <address> London, UK, </address> <pages> pp. 3742. </pages>
Reference-contexts: Also, Sogitec Electronique constructed a dome-housed projection screen flight simulator offering fovea enhanced rendering by using two projection channels: a large field of view background channel for peripheral imagery and a central eye-tracked high resolution channel for the AOI <ref> (Hurault, 1993) </ref>. 2.1.4 Velocity Level of Detail 2.1.4.1 Overview Velocity LOD is when an object's representation is selected based upon its velocity relative to the user's gaze.
Reference: <author> Hurvich, L. M. </author> <year> (1981). </year> <title> Color Vision, </title> <publisher> Sinauer Associates, </publisher> <address> Sunderland, Mass. </address>
Reference: <author> Hwang, S. C. and Yang, H. S. </author> <year> (1993). </year> <title> Efficient View Sphere Tessellation Method Based on Halfedge Data Structure and Quadtree, </title> <journal> Computers and Graphics, </journal> <volume> 17(5): </volume> <pages> 575581. </pages>
Reference: <author> Jacobson, R. E. </author> <year> (1995). </year> <title> Image Quality Metrics, </title> <journal> The Journal of Photographic Science, </journal> <volume> 43(2): </volume> <pages> 4243. </pages>
Reference-contexts: proceed any further, it would be useful at this point to briefly review some previous attempts which have been made to extract visual features from an image, or to otherwise assess its perceptual content. 69 There has been a large body of work in the area of image quality metrics <ref> (see Jacobson, 1995, for a recent review) </ref>. However this field is dedicated to the concise perceptual evaluation of display devices. As such, these metrics are not concerned with the quality of arbitrary images displayed on these devices; and hence are of little benefit to us here.
Reference: <author> Kalawsky, R. S. </author> <year> (1993). </year> <title> The Science of Virtual Reality and Virtual Environments, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. ISBN 0-201-63171-7. </address>
Reference: <author> Kalvin, A. D. and Taylor, R. H. </author> <year> (1994). </year> <title> Superfaces: Polygonal Mesh Simplification with Bounded Error, </title> <type> Technical Report RC 19808 (#87702), </type> <institution> IBM Research Division, T. J. Watson Research Centre, Yorktown Heights, NY. </institution>
Reference: <author> Katz, D. </author> <year> (1951). </year> <title> Gestalt Psychology, </title> <publisher> Methuen and Co. Ltd., London. </publisher>
Reference-contexts: Within the field of computer vision a number of image segmentation algorithms have been founded on perceptual models (see Reed and du Buf, 1993, for a review). Many of these have resorted to Gestalt rules of grouping <ref> (Katz, 1951) </ref> to resolve all of the perceptually disparate components (e.g. Khan and Giles, 1992). Other feature extraction techniques have included attempts to generate a number of feature maps to locate `meaningful wholes' in an image based upon a number perceptual criteria (e.g.
Reference: <author> Kelly, D. H. </author> <year> (1975). </year> <title> Spatial Frequency Selectivity in the Retina, </title> <journal> Vision Research, </journal> <volume> 15: </volume> <pages> 665672. </pages>
Reference-contexts: empirically confirmed that our ability to resolve detail varies in relation to the orientation of a contrast grating (Campbell et al., 1966), its velocity across the retina (Kelly, 1979), the degree to which it is placed in our peripheral field (Rovamo and Virsu, 1979), and the level of background illumination <ref> (Kelly, 1975) </ref>. The phase of a contrast grating has no effect on its detectability (Lamming, 1991c). 2.3.2.2 The Contrast Sensitivity Function The contrast sensitivity function (CSF) is essentially a graph of the results from a series of contrast grating tests. <p> We know that our ability to perceive detail varies with respect to the background illumination; with our resolving ability degrading in darker surrounds <ref> (Kelly, 1975) </ref>. However, Kelly's (1979) model was formulated for high background illumination. This is therefore a worst-case model, and so implicitly handles the case of low background illumination.
Reference: <author> Kelly, D. H. </author> <year> (1979). </year> <title> Motion and Vision. II. Stabilized Spatio-Temporal Threshold Surface, </title> <journal> Journal of the Optical Society of America, </journal> <volume> 69(10): </volume> <pages> 13401349. </pages>
Reference-contexts: In this fashion, it has been empirically confirmed that our ability to resolve detail varies in relation to the orientation of a contrast grating (Campbell et al., 1966), its velocity across the retina <ref> (Kelly, 1979) </ref>, the degree to which it is placed in our peripheral field (Rovamo and Virsu, 1979), and the level of background illumination (Kelly, 1975).
Reference: <author> Kelly, D. H. </author> <year> (1984). </year> <title> Retinal Inhomogenity: I. Spatiotemporal Contrast Sensitivity, </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 1(1): </volume> <pages> 107113. </pages>
Reference-contexts: This roughly means that the width of your thumb in centimeters is its angular subtense in degrees at arm's length. (60 minutes of arc = 1 degree.) 21 the cone density (Hallett, 1991). * The receptive field size of retinal ganglion cells increases linearly with eccentricity <ref> (Kelly, 1984) </ref>. This is because the degree of photoreceptor pooling for ganglion cells varies with eccentricity. At the fovea, there is a 1:1 correspondence between cones and ganglion cells.
Reference: <author> Kemeny, A. </author> <year> (1993). </year> <title> A Cooperative Driving Simulator, </title> <booktitle> Proceedings of the International Training Equipment Conference (ITEC), </booktitle> <address> London, UK, </address> <pages> pp. 6771. </pages>
Reference: <author> Khan, G. N. and Giles, D. F. </author> <year> (1992). </year> <title> Extracting Contours by Perceptual Grouping, </title> <journal> Image and Vision Computing, </journal> <volume> 10(2): 7788. 215 Kingslake, </volume> <editor> R. </editor> <year> (1991). </year> <note> An Introductory Course in Computer Graphics, second edn, Chartwell-Bratt. ISBN 0-86238-284-X. </note>
Reference-contexts: Within the field of computer vision a number of image segmentation algorithms have been founded on perceptual models (see Reed and du Buf, 1993, for a review). Many of these have resorted to Gestalt rules of grouping (Katz, 1951) to resolve all of the perceptually disparate components <ref> (e.g. Khan and Giles, 1992) </ref>. Other feature extraction techniques have included attempts to generate a number of feature maps to locate `meaningful wholes' in an image based upon a number perceptual criteria (e.g. Soufi and Scrivener, 1992), or the use of localised frequency domain techniques to categorise object groupings (e.g.
Reference: <author> Koenderink, J. J., Bouman, M. A., de Mesquita, A. E. B. and Slappendel, S. </author> <year> (1978a). </year> <title> Perimetry of Contrast Detection Thresholds of Moving Spatial Sine Wave Patterns. II. The Far Peripheral Visual Field (Eccentricity 0 ffi ffi ), Journal of the Optical Society of America, </title> <type> 68(6): 850854. </type>
Reference: <author> Koenderink, J. J., Bouman, M. A., de Mesquita, A. E. B. and Slappendel, S. </author> <year> (1978b). </year> <title> Perimetry of Contrast Detection Thresholds of Moving Spatial Sine Wave Patterns. I. The Near Peripheral Visual Field (Eccentricity 0 ffi ffi ), Journal of the Optical Society of America, </title> <type> 68(6): 845849. </type>
Reference: <author> Korein, J. and Badler, N. </author> <year> (1983). </year> <title> Temporal Anti-Aliasing in Computer Generated Animation, </title> <journal> Computer Graphics, </journal> <volume> 17(3): </volume> <pages> 377388. </pages>
Reference-contexts: The following list presents a few of the techniques that have been developed thus far: * Super-Sampling : for each frame, multiple images are generated over time and then merged together using a simple weighted sum averaging algorithm, e.g. a box filter <ref> (Korein and Badler, 1983) </ref>. * Distributed Ray Tracing : the various reflected and transmitted rays of a ray tracer are distributed in time as well as space, taking into account any changes in visibility and shading (Cook et al., 1984). * Fourier Techniques : a Fast Fourier Transform (FFT) is performed
Reference: <author> Lamming, D. </author> <year> (1991a). </year> <title> On the Limits of Visual Detection, </title> <editor> in J. R. Cronly-Dillon (ed.), </editor> <title> Vision and Visual Dysfunction: </title> <journal> Limits of Vision, </journal> <volume> Vol. 5, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 2, pp. </pages> <note> 614. ISBN 0-333-52713-5. </note>
Reference-contexts: This is normally done by allowing the subject to vary the contrast of a grating until it is deemed to be at threshold, i.e. they can no longer resolve discrete bars <ref> (Lamming, 1991a) </ref>. Much of this initial work was performed by the late Fergus Campbell and his colleagues (e.g. Campbell and Green, 1965; Campbell and Gubisch, 1966; Camp 53 (a) (b) and, (b) a higher spatial frequency. <p> It has been shown that presenting a single stimulus to a subject and asking whether they can see itreplying `yes' or `no'is a flawed approach. This is because most subjects appear to have a predisposed readiness to report positive responses <ref> (Lamming, 1991a) </ref>. Therefore, the generally recommended method for determining signal detection thresholds is the 2 Alternative Forced Choice (2AFC) method.
Reference: <author> Lamming, D. </author> <year> (1991b). </year> <title> Signal Detection Theory, </title> <editor> in J. R. Cronly-Dillon (ed.), </editor> <title> Vision and Visual Dysfunction: </title> <journal> Limits of Vision, </journal> <volume> Vol. 5, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 3, pp. </pages> <note> 1522. ISBN 0-333-52713-5. </note>
Reference-contexts: Therefore, the generally recommended method for determining signal detection thresholds is the 2 Alternative Forced Choice (2AFC) method. This involves presenting the subject with the test stimulus in one of two successive observation intervals and asking them to decide which interval it occurred in, guessing if necessary <ref> (Lamming, 1991b) </ref>. For example, presenting the stimulus to the left or to the right of the user's gaze. When the stimulus is above threshold then the user will always identify the stimulus interval correctly.
Reference: <author> Lamming, D. </author> <year> (1991c). </year> <title> Spatial Frequency Channels, </title> <editor> in J. R. Cronly-Dillon (ed.), </editor> <title> Vision and Visual Dysfunction: </title> <journal> Limits of Vision, </journal> <volume> Vol. 5, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 8, pp. </pages> <note> 97105. ISBN 0-333-52713-5. </note>
Reference-contexts: The phase of a contrast grating has no effect on its detectability <ref> (Lamming, 1991c) </ref>. 2.3.2.2 The Contrast Sensitivity Function The contrast sensitivity function (CSF) is essentially a graph of the results from a series of contrast grating tests. It illustrates the threshold of vision for a single observer at a number of spatial frequencies. <p> Campbell and Robson noted that a square-wave grating is indistinguishable from a sine-wave grating until the third harmonic reaches its own threshold). That is, for the upper regions of the CSF we can analyse a stimulus by only referring to its fundamental component <ref> (Lamming, 1991c) </ref>. 2.3.3.2 Complexity Effects on Feature Detection Campbell and Robson also performed experiments with compound contrast gratings in order to investigate how the visibility of these is related to that of their component harmonic gratings (Sekuler and Blake, 1994).
Reference: <author> Levi, D. M., Klein, S. A. and Aitsebaomo, A. P. </author> <year> (1985). </year> <title> Vernier Acuity, Crowding and Cortical Magnification, </title> <journal> Vision Research, </journal> <volume> 25: </volume> <pages> 963971. </pages>
Reference: <author> Levitt, H. </author> <year> (1971). </year> <title> Transformed UpDown Methods in Psychoacoustics, </title> <journal> The Journal of the Acoustical Society of America, </journal> <volume> 49(2): </volume> <pages> 467477. </pages>
Reference-contexts: Alternatively, the staircase method adaptively selects new eccentricities to analyse based upon the subject's previous responses; eventually converging around the threshold value. The staircase methodology is often considered the more efficient and robust approach <ref> (Levitt, 1971) </ref>, and so we will adopt this technique. The operation of the staircase method (also known as the Transformed Up Down method) can be described as follows (Wetherill and Levitt, 1965): 1. Choose an initial eccentricity (our best a priori estimate, e.g. the predicted result from our model). 2.
Reference: <author> Levoy, M. and Whitaker, R. </author> <year> (1990). </year> <title> GazeDirected Volume Rendering, </title> <booktitle> ACM SIGGRAPH Special Issue on 1990 Symposium on Interactive 3D Graphics, </booktitle> <volume> 24(2): </volume> <pages> 217223. </pages>
Reference: <author> Liang, J., Shaw, C. and Green, M. </author> <year> (1991). </year> <title> On Temporal-Spatial Realism in the Virtual Reality Environment, </title> <booktitle> Proceedings of the 4th Annual Symposium on User Interface Software and Technology, </booktitle> <address> Hilton Head SC, </address> <pages> pp. </pages> <year> 1925. </year>
Reference-contexts: The underlying principle is to pre-empt the tracking system by calculating estimated intermediate values and then using these approximations until a new reading is available from the sensor. As Kalawsky (1993) notes, simple extrapolation schemes are generally unsatisfactory, so most successful systems have been based upon Kalman filtering techniques <ref> (e.g. Liang et al., 1991) </ref>. [SENSOR] * Update Rates : the notion of update rates 1 can be used to define the rate at which an object's state is recomputed (Wloka, 1993b).
Reference: <author> Lindstrom, P., Koller, D., Hodges, L. F., Ribarsky, W., Faust, N. and Turner, G. </author> <year> (1995). </year> <title> Level-of-Detail Management for Real-Time Rendering of Phototex-tured Terrain, </title> <type> Technical Report No. </type> <institution> TR95-06, Graphics, Visualization and Usability Centre, Georgia Institute of Technology, Altanta, GA. </institution> <note> 216 Lindstrom, </note> <author> P., Koller, D., Ribarsky, W., Hodges, L. F., Faust, N. and Turner, G. </author> <year> (1996). </year> <title> Real-Time, Continuous Level of Detail Rendering of Height Fields, </title> <type> Technical Report No. </type> <institution> TR96-02, Graphics, Visualization and Usability Centre, Georgia Institute of Technology, </institution> <address> Altanta, GA. </address>
Reference: <author> Livingstone, M. S. </author> <year> (1988). </year> <title> Art, Illusion and the Visual System, </title> <journal> Scientific American, </journal> <volume> 258(1): </volume> <pages> 6875. </pages>
Reference-contexts: However, M cells respond vigorously to the rapid motion of a stimulus within the visual field. This provides evidence for the widely-held theory that the various components of visionform, colour, movement, and depthare transmitted independently via separate channels to the visual cortex <ref> (Livingstone and Hubel, 1988) </ref>. 1.4.3 The Visual Cortex The visual cortex (also referred to as the striate cortex, Area 17, and V1) is the major centre of vision. It is located in the occipital lobe, towards the rear of the brain. <p> Instead we perceive a single wash of colour which exhibits the average contrast of the two component colours <ref> (Livingstone, 1988) </ref>. This phenomenon is used to great effect in the newspaper industry where halftoned patterns can be used to portray a wide range of greyscale levels with only a single black pigment on white paper.
Reference: <author> Livingstone, M. S. and Hubel, D. H. </author> <year> (1988). </year> <title> Segregation of Form, Color, Movement, and Depth: Anatomy, </title> <journal> Physiology, and Perception, Science, </journal> <volume> 240: 740 749. </volume>
Reference-contexts: However, M cells respond vigorously to the rapid motion of a stimulus within the visual field. This provides evidence for the widely-held theory that the various components of visionform, colour, movement, and depthare transmitted independently via separate channels to the visual cortex <ref> (Livingstone and Hubel, 1988) </ref>. 1.4.3 The Visual Cortex The visual cortex (also referred to as the striate cortex, Area 17, and V1) is the major centre of vision. It is located in the occipital lobe, towards the rear of the brain. <p> Instead we perceive a single wash of colour which exhibits the average contrast of the two component colours <ref> (Livingstone, 1988) </ref>. This phenomenon is used to great effect in the newspaper industry where halftoned patterns can be used to portray a wide range of greyscale levels with only a single black pigment on white paper.
Reference: <author> Lorensen, W. E. and Cline, H. E. </author> <year> (1987). </year> <title> Marching Cubes: a High Resolution 3D Surface Construction Algorithm, </title> <booktitle> Computer Graphics (SIGGRAPH '87 Proceedings), </booktitle> <volume> Vol. 21, </volume> <pages> pp. 163169. </pages>
Reference-contexts: Schroeder et al. illustrate the decimation algorithm on a number of terrain and volume data. They state that the technique performs particularly well on polygon models converted from volume data using the Marching Cubes algorithm <ref> (Lorensen and Cline, 1987) </ref>. 2.2.1.4 Hierarchical Geometric Approximations (Varshney) The geometry removal algorithm devised by Varshney (1994) introduces the notion of `offset surfaces'. These are surfaces which are formed by extending the position of each vertex in the mesh by its normal scaled by a user supplied error tolerance.
Reference: <author> Lounsbery, M., DeRose, T. and Warren, J. </author> <year> (1994). </year> <title> Multiresolution Analysis for Surfaces of Arbitrary Topological Type, </title> <type> Technical Report No. </type> <institution> 93-10-05b, Deptartment of Computer Science and Engineering, University of Wash-ington. </institution>
Reference: <author> Luebke, D. </author> <year> (1996). </year> <title> Hierarchical Structures for Dynamic Polygonal Simplification, </title> <type> UNC Technical Report No. </type> <institution> TR96-006, Deptartment of Computer Science, University of North Carolina, Chapel Hill, NC. </institution>
Reference: <author> Luo, M. R. and Rigg, B. </author> <year> (1987). </year> <title> BFD(l:c) Colour-Difference Formula, Part 1: Development of the Formula, </title> <journal> Journal of the Society of Dyers and Colourists, </journal> <volume> 103(2): </volume> <pages> 8694. </pages>
Reference-contexts: These two systems managed to improve the perceptual nonuniformity of the CIEXYZ system to around 6:1. Since that time, a number of other systems have been proposed which try to improve upon the CIE's standard, e.g. the CMC formula (CMC, 1989), the BFD formula <ref> (Luo and Rigg, 1987) </ref>, the FMC1 formula (MacAdam, 1985), etc. The most relevant colour difference formula for our purposes is the CIELUV 73 system. Most formulae were developed for use in the colourant industry as a product tolerance measure.
Reference: <author> MacAdam, D. L. </author> <year> (1985). </year> <title> Evaluation of Color Differences, </title> <journal> Journal of the Optical Society of America A (Optics and Image Science), </journal> <volume> 2(13): </volume> <pages> 11. </pages>
Reference-contexts: Since that time, a number of other systems have been proposed which try to improve upon the CIE's standard, e.g. the CMC formula (CMC, 1989), the BFD formula (Luo and Rigg, 1987), the FMC1 formula <ref> (MacAdam, 1985) </ref>, etc. The most relevant colour difference formula for our purposes is the CIELUV 73 system. Most formulae were developed for use in the colourant industry as a product tolerance measure.
Reference: <author> MacDonald, L. W., Luo, M. R. and Scrivener, S. A. R. </author> <year> (1990). </year> <title> Factors Affecting the Appearance of Coloured Images on a Video Display Monitor, </title> <journal> Journal of Photographic Science, </journal> <volume> 38(45): </volume> <pages> 177186. </pages>
Reference: <author> Maciel, P. and Shirley, P. </author> <year> (1995). </year> <title> Visual Navigation of Large Environments Using Textured Clusters, </title> <booktitle> Symposium on Interactive 3D Graphics, </booktitle> <pages> pp. 95102. </pages>
Reference-contexts: This optimisation can introduce visual artifacts if the model is viewed from a different viewpoint or distance. However, a number of solutions exist to combat this problem; including warping the texture image (McMillan and Bishop, 1995), warping the adjacent geometry (Aliaga, 1996), and smoothly transforming between geometry and texture <ref> (Maciel and Shirley, 1995) </ref>. 10 * Illumination Models : the particular illumination model which is used to render an object can influence the display time.
Reference: <author> Mannos, J. L. and Sakrison, D. J. </author> <year> (1974). </year> <title> The Effects of a Visual Fidelity Criterion on the Encoding of Images, </title> <journal> IEEE Transactions on Information Theory, IT-20(4): </journal> <volume> 525536. </volume>
Reference: <author> Marr, D. </author> <year> (1982). </year> <title> Vision: a Computational Investigation into the Human Representation and Processing of Visual Information, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> New York, NY. </address>
Reference: <author> DeHaemer, Jr., M. J. and Zyda, M. J. </author> <year> (1991). </year> <title> Simplification of Objects Rendered by Polygonal Approximations, </title> <journal> Computer and Graphics, </journal> <volume> 15(2): 175184. </volume> <publisher> Pergamon Press, </publisher> <address> UK. </address> <note> 217 VR News (1995). Headmounted displays, VR News, 4(4): </note> <year> 2029. </year>
Reference: <author> McMillan, L. and Bishop, G. </author> <year> (1995). </year> <title> Plenoptic Modeling: An Image-Based Rendering System, </title> <editor> in R. Cook (ed.), </editor> <booktitle> SIGGRAPH '95 Conference Proceedings, </booktitle> <pages> pp. 3946. </pages>
Reference-contexts: The polygon's texture is simply a rendered image of that section, from a certain viewpoint and distance. This optimisation can introduce visual artifacts if the model is viewed from a different viewpoint or distance. However, a number of solutions exist to combat this problem; including warping the texture image <ref> (McMillan and Bishop, 1995) </ref>, warping the adjacent geometry (Aliaga, 1996), and smoothly transforming between geometry and texture (Maciel and Shirley, 1995). 10 * Illumination Models : the particular illumination model which is used to render an object can influence the display time.
Reference: <author> Meyer, G. W. and Greenberg, D. P. </author> <year> (1980). </year> <title> Perceptual Color Spaces for Computer Graphics, </title> <journal> Computer Graphics, </journal> <volume> 14: </volume> <pages> 254261. </pages>
Reference: <author> Money, K. </author> <year> (1970). </year> <title> Motion Sickness, </title> <journal> Physiological Reviews, </journal> <volume> 50(1): </volume> <pages> 139. </pages>
Reference-contexts: was quantitatively similar, and that the user's performance degraded linearly with respect to lag between 0 and 0.5 seconds. * Motion Sickness : delays in the update of visual information have also been reported to cause effects of motion sickness, the symptoms of which include nausea, pallor, and cold sweating <ref> (Money, 1970) </ref>. This is thought to be due principally to the conflict between the user's visual and ves-tibular senses (Oman, 1993), often referred to as the Vestibular Ocular Response (VOR).
Reference: <author> Morgan, M. J. </author> <year> (1991). </year> <editor> Hyperacuity, in D. Regan (ed.), </editor> <booktitle> Vision and Visual Dysfunction: Spatial Vision, </booktitle> <volume> Vol. 10, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 4, pp. </pages> <note> 87110. ISBN 0-333-52713-5. </note>
Reference-contexts: We must therefore ask ourselves: are we being over simplistic by 183 only using contrast sensitivity to measure perceived detail? Hyperacuity is thought to be caused by differences in the mean distribution of light sampled over a number of photoreceptors <ref> (Morgan, 1991) </ref>. The effect is therefore dependent upon the large spatial spread over which two adjacent features extends, i.e. any isolated feature which is smaller than a single receptor will still remain undetectable.
Reference: <author> Mullen, K. T. </author> <year> (1985). </year> <title> The Contrast Sensitivity of Human Color Vision to Red-Green and Blue-Yellow Chromatic Gratings, </title> <journal> Journal of Physiology, </journal> <volume> 359: </volume> <pages> 381400. </pages>
Reference-contexts: We must therefore ask if we would lose any accuracy by employing achromatic threshold data to our task; and whether we should consider applying colour contrast data instead. We know that the achromatic channel is far more effective than the chromatic channels for processing shape <ref> (Mullen, 1985) </ref>, motion (Anstis and Cavanagh, 1983), and stereoscopic depth (Gregory, 1977).
Reference: <author> Mullen, K. T. and Kingdom, F. A. A. </author> <year> (1991). </year> <title> Colour Contrast in Form Perception, </title> <editor> in J. Cronly-Dillon (ed.), </editor> <title> Vision and Visual Dysfunction: </title> <journal> The Perception of Colour, </journal> <volume> Vol. 6, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 12, pp. </pages> <address> 198217. MultiGen, </address> <publisher> Inc. </publisher> <year> (1994). </year> <title> ModelGen2 Modeler's Guide, </title> <publisher> MultiGen Inc., </publisher> <address> San Jose, CA. Revision 14.1. </address>
Reference: <author> Murphy, B. J. </author> <year> (1978). </year> <title> Pattern Thresholds for Moving and Stationary Gratings During Smooth Eye Movement, </title> <journal> Vision Research, </journal> <volume> 18: </volume> <pages> 521530. </pages>
Reference-contexts: The reason for this effect is thought to be due, in part, to the eye's inability to track rapidly moving targets accurately, thus causing a slippage in the retinal image <ref> (Murphy, 1978) </ref>. However, based upon the more recent studies of Tyler (1985), it has been suggested that the photoreceptors themselves are also responsible for limiting our temporal frequency sensitivity (Nakayama, 1990). That is, the process of detecting motion implies an integration of a moving object's stimulus energy over time.
Reference: <author> Nachmias, J. </author> <year> (1968). </year> <title> Visual Resolution of Two-Bar Patterns and Square-Wave Gratings, </title> <journal> Journal of the Optical Society of America, </journal> <volume> 58(1): </volume> <pages> 913. </pages>
Reference: <author> Nakayama, K. </author> <year> (1990). </year> <title> Properties of Early Motion Processing: Implications for the Sensing of Egomotion, </title> <editor> in R. Warren and A. H. Wertheim (eds), </editor> <title> The Perception and Control of Self Motion, </title> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. </pages> <month> 6980. </month> <title> NSF (1992). Research Directions in Virtual Environments: Report of an NSF Invitational Workshop, </title> <journal> Computer Graphics, </journal> <volume> 26(3): </volume> <pages> 153177. </pages>
Reference-contexts: This reduction in visual acuity across the retina is significant, with around a 35-fold difference existing between the fovea and the periphery <ref> (Nakayama, 1990) </ref>. 1.4.4.3 Temporal Sensitivity The human vision system cannot resolve as much detail in an object which is moving across the retina as it can in an object which is stabilised on the fovea. <p> However, based upon the more recent studies of Tyler (1985), it has been suggested that the photoreceptors themselves are also responsible for limiting our temporal frequency sensitivity <ref> (Nakayama, 1990) </ref>. That is, the process of detecting motion implies an integration of a moving object's stimulus energy over time. Therefore the visual information for precise features in that object are destroyed by this integration process. 22 1.5 Thesis Content We have now completed the presentation of required background knowledge.
Reference: <author> Ohshima, T., Yamamoto, H. and Tamura, H. </author> <year> (1996). </year> <title> Gaze-Directed Adaptive Rendering for Interacting with Virtual Space, </title> <booktitle> Proceedings of the IEEE Virtual Reality Annual International Symposium (VRAIS), </booktitle> <address> Santa Clara, CA, </address> <pages> pp. 103110. </pages>
Reference: <author> Oman, C. M. </author> <year> (1993). </year> <title> Sensory Conflict in Motion Sickness: an Observer Theory approach, </title> <editor> in S. R. Ellis, M. K. Kaiser and A. J. Grunwald (eds), </editor> <title> Pictorial Communication in Virtual and Real Environments, second edn, Taylor and Francis, </title> <note> chapter 24, pp. 362376. ISBN 0-74840-0082-6. 218 Owsley, </note> <author> C. J., Sekuler, R. and Siemsen, D. </author> <year> (1983). </year> <title> Contrast Sensitivity Throughout Adulthood, </title> <journal> Vision Research, </journal> <volume> 23: </volume> <pages> 689699. </pages>
Reference-contexts: This is thought to be due principally to the conflict between the user's visual and ves-tibular senses <ref> (Oman, 1993) </ref>, often referred to as the Vestibular Ocular Response (VOR). Frank et al. (1988) have shown that humans can detect head tracking lags of greater than 5 ms and that delays of more than 30 ms can produce effects of motion sickness.
Reference: <author> Peli, E. </author> <year> (1990). </year> <title> Contrast in Complex Images, </title> <journal> Journal of the Optical Society of America A (Optics and Image Science), </journal> <volume> 7(10): </volume> <year> 20322040. </year>
Reference-contexts: The feature bitmap therefore need only contain binary information (e.g. a monochrome bitmap). The contrast of the feature can be calculated by finding the ratio of the average luminance of each pixel in the feature, to the average luminance of the pixels immediately surrounding the feature <ref> (Peli, 1990) </ref>. 74 In summary, a single iteration of the feature extraction stage produces the de-scription of a single visual feature (e.g. a binary feature bitmap containing only those pixels which exist in the feature), and a value of contrast for that feature.
Reference: <author> Phillips, P. L. </author> <year> (1986). </year> <title> Minimum Colour Differences Required to Recognize Small Objects on a Colour CRT, </title> <journal> Journal of the Institution of Electronic and Radio Engineers, </journal> <volume> 56(3): </volume> <pages> 123129. </pages>
Reference-contexts: This effect is know as simultaneous contrast. Phillips (1986) reports that this can induce perceived colour 85 difference variations in the order of 1020%. However, when compared with the variability of a typical observer, this error does not appear to be significant <ref> (Phillips, 1986) </ref>. More critically, this effect is of course the result of our human perceptual processing (the wavelength of light reflected by an object does not physically change due to juxtaposition with another object).
Reference: <author> Pokorny, J., Shevell, S. K. and Smith, V. C. </author> <year> (1991). </year> <title> Colour Appearance and Colour Constancy, </title> <editor> in J. Cronly-Dillon (ed.), </editor> <title> Vision and Visual Dysfunction: </title> <journal> The Perception of Colour, </journal> <volume> Vol. 6, </volume> <publisher> MacMillan Press, Ltd., </publisher> <pages> chapter 4, pp. 43 61. </pages>
Reference: <author> Potmesil, M. and Chakravarty, I. </author> <year> (1983). </year> <title> Modeling Motion Blur in Computer-Generated Images, </title> <journal> Computer Graphics, </journal> <volume> 17(3): </volume> <pages> 389399. </pages>
Reference-contexts: The inverse FFT is then calculated to produce the blurred image <ref> (Potmesil and Chakravarty, 1983) </ref>. * Practically Frameless Rendering : only a fraction (e.g. a quarter) of all pixels are updated each frame. By distributing these pixels uniformly, the entire image appears to update progressively over a number of frames; producing a `dissolving' effect.
Reference: <author> Poynton, C. A. </author> <year> (1993). </year> <title> Gamma and its Disguises: The Nonlinear Mappings of Intensity in Perception, CRTs, Film and Video, </title> <journal> SMPTE Journal (Society of Motion Picture and Television Engineers), </journal> <volume> 102(12): </volume> <pages> 10991108. </pages>
Reference-contexts: This provided an accurate and convenient means of specifying an absolute col-our, but it did not consider the perceptual relationship between points in the colour space. In fact, the perceptual non-uniformity of the CIEXYZ colour space is about 80:1 <ref> (Poynton, 1993) </ref>, i.e. the discrepancy between the perceptual distance and the numerical distance of two CIEXYZ colours can vary at points by up to about 8,000%. <p> We therefore do not need to compensate for this phenomenon in our application. 3. Display Factors : a number of monitor characteristics can affect the perceived colour of a stimulus. For example, a monitor's black level (or brightness) and its gamma value <ref> (Poynton, 1993) </ref>. Care should therefore be taken to ensure that the display's brightness control is set so that dark elements are reproduced correctly, and that all colours are gamma corrected (see Reddy, 1996a).
Reference: <author> Reddy, M. </author> <year> (1994). </year> <title> Reducing Lags in Virtual Reality Systems using Motion-Sensitive Level of Detail, </title> <booktitle> Proceedings of the 2nd UK VR-SIG Conference, </booktitle> <address> Theale, Reading, UK, </address> <pages> pp. 2531. </pages>
Reference: <author> Reddy, M. </author> <year> (1995a). </year> <title> A Perceptual Framework for Optimising Visual Detail in Virtual Environments, </title> <booktitle> Proceedings of the FIVE '95 Conference, </booktitle> <address> QMW, University of London, UK, </address> <pages> pp. 189201. </pages>
Reference: <author> Reddy, M. </author> <year> (1995b). </year> <title> A Survey of Level of Detail Support in Current Virtual Reality Solutions, Virtual Reality: </title> <booktitle> Research, Development and Application, </booktitle> <volume> 1(2): </volume> <pages> 9598. </pages>
Reference-contexts: However, only a few simplistic attempts have been made to integrate all of these into a single, generic, and orthogonal framework. 4. There is very little support in currently available VR packages to actually generate different levels of detail for an arbitrary object <ref> (Reddy, 1995b) </ref>. 12 Without the ability to produce various LOD models, the effectiveness of LOD is obviated. This thesis will attempt to address each of these issues by investigating theories of visual perception. <p> There are however certain logistical difficulties associated with hierarchical LOD. Firstly, there may be a large development effort required to implement this technique: not all image generators may provide the ability to easily implement this; whereas most, if not all, renderers support a mechanism to implement traditional LOD <ref> (Reddy, 1995b) </ref>. There is also the question of how to hierarchically decompose an arbitrary polygon mesh, and to do so in such a manner that there are no discontinuities when different parts of the model are displayed at a different detail level.
Reference: <author> Reddy, M. </author> <year> (1995c). </year> <title> Musings on Volumetric Level of Detail for Virtual Environments, Virtual Reality: </title> <booktitle> Research, Development and Application, </booktitle> <volume> 1(1): 49 56. </volume>
Reference: <author> Reddy, M. </author> <year> (1996a). </year> <title> A Measure for Perceived Detail in Computer-Generated Images, </title> <type> Technical Report ECS-CSG-19-96, </type> <institution> Department of Computer Science, University of Edinburgh. </institution>
Reference-contexts: For example, a monitor's black level (or brightness) and its gamma value (Poynton, 1993). Care should therefore be taken to ensure that the display's brightness control is set so that dark elements are reproduced correctly, and that all colours are gamma corrected <ref> (see Reddy, 1996a) </ref>. It is therefore evident that any colour difference formulae which we employ will not give us a consistent and reliable estimate for a user's ability to discern between two colours.
Reference: <author> Reddy, M. </author> <year> (1996b). </year> <title> SCROOGE: Perceptually-Driven Polygon Reduction, </title> <journal> Computer Graphics Forum, </journal> <volume> 15(4): </volume> <year> 191203. </year>
Reference: <author> Reddy, M. </author> <year> (1997). </year> <title> The Development and Evaluation of a Model of Visual Acuity for Computer-Generated Imagery, </title> <type> Technical Report ECS-CSG-30-97, </type> <institution> Department of Computer Science, University of Edinburgh. </institution> <note> 219 Reed, </note> <author> T. R. and du Buf, J. M. H. </author> <year> (1993). </year> <title> A Review of Recent Texture Segment--ation and Feature Extraction Techniques, Computer Vision, Graphics, and Image Processing (CVGIP): </title> <booktitle> Image Understanding, </booktitle> <volume> 57(3): </volume> <pages> 359372. </pages>
Reference: <author> Reed, T. R. and Wechsler, H. </author> <year> (1990). </year> <title> Segmentation of Textured Images and Gestalt Organisation Using Spatial/Spatial-Frequency Representations, </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(1): 1 12. </volume>
Reference-contexts: Khan and Giles, 1992). Other feature extraction techniques have included attempts to generate a number of feature maps to locate `meaningful wholes' in an image based upon a number perceptual criteria (e.g. Soufi and Scrivener, 1992), or the use of localised frequency domain techniques to categorise object groupings <ref> (e.g. Reed and Wechsler, 1990) </ref>.
Reference: <author> Regan, C. </author> <year> (1995). </year> <title> An Investigation into Nausea and Other Side-effects of Head-coupled Immersive Virtual Reality, Virtual Reality: </title> <journal> Research, Development, Applications, </journal> <volume> 1(1): </volume> <pages> 1732. </pages>
Reference: <author> Regan, D. and Beverley, K. I. </author> <year> (1983). </year> <title> Visual Field Described by Contrast Sensitivity, by Acuity and by Relative Sensitivity to Different Orientations, </title> <journal> Investigative Ophthalmology and Visual Science, </journal> <volume> 24: </volume> <pages> 754759. </pages>
Reference-contexts: Therefore, in order to incorporate eccentricity into our model of spatiotemporal contrast sensitivity, we simply need to apply this cortical magnification factor to Equation 3.15. The eye's peripheral sensitivity is not circular symmetric <ref> (e.g. Regan and Bever-ley, 1983) </ref>. For example, there are marked asymmetries between the nasal and temporal retina beyond 20 degrees (Sutter and Tran, 1991). Taking this into consideration, Rovamo and Virsu produced four equations to characterise M for each principal half-meridian of the retina.
Reference: <author> Renka, R. J. </author> <year> (1984). </year> <title> Interpolation of Data on the Surface of a Sphere, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 10: </volume> <pages> 417436. </pages>
Reference-contexts: This tells us the orientation of the object as perceived by the user. We then estimate the transition spatial frequencies of the object at that orientation by interpolating between the closest sampled viewpoints around the view sphere <ref> (e.g. Renka, 1984) </ref>. For example, if we used a triangular tessellation of the sphere to generate the viewpoints, then we could find the three closest sampled viewpoints and interpolate between these to find the correct value of transition spatial frequency.
Reference: <author> Rieger, J. H. and Toet, L. </author> <year> (1985). </year> <title> Human Visual Navigation in the Presence of 3-D Motions, </title> <journal> Biological Cybernetics, </journal> <volume> 52: </volume> <pages> 354360. </pages>
Reference: <author> Ritter, J. </author> <year> (1990). </year> <title> A Fast Approximation to 3D Euclidean Distance, </title> <editor> in A. </editor> <publisher> S. </publisher>
Reference-contexts: Secondly, it is efficient: the only computationally expensive procedure is the calculation of the 3D Euclidean distance between two points; and a number of fast approximations already exist for this <ref> (e.g. Ritter, 1990) </ref>. However, there are some problems with distance LOD techniques. Principally, we have to chose an arbitrary point within the 3D volume of the object to use for all distance calculations.
Reference: <editor> Glassner (ed.), </editor> <booktitle> Graphics Gems, </booktitle> <volume> Vol. 1, </volume> <publisher> Academic Press, inc, </publisher> <pages> pp. </pages> <note> 432433. ISBN 0-12-286165-5. </note>
Reference: <author> Robinson, D. A. </author> <year> (1964). </year> <title> The Mechanics of Human Saccadic Eye Movements, </title> <journal> Journal of Physiology, </journal> <volume> 180: </volume> <pages> 569590. </pages>
Reference-contexts: Saccades can occur at velocities of up to 800 deg/s and last for periods of many milliseconds 3 . The term saccadic suppression is used to 3 A good rule of thumb for the duration (ms) of a saccade is: 20 plus twice the angular distance travelled <ref> (Robinson, 1964) </ref>, e.g. a 10 deg saccade will last about 40 ms. 181 describe the phenomenon that during a saccade we do not experience blurred vision, even though our eyes are moving at very high velocities; that is, we do not appear to perceive detail during a saccade.
Reference: <author> Roehl, B. </author> <year> (1995). </year> <type> Personal communication. </type>
Reference-contexts: The REND386 package, originally written by Bernie Roehl and Dave Stampe of the University of Waterloo, provides a real-time 3D graphics library for the IBMPC compatible platform. The system implements a size LOD system by calculating the projected radius of an object's bounding sphere <ref> (Roehl, 1995) </ref>. This provides a very lightweight and effective mechanism for representing the size of an object in screen space. It also provides an orientation invariant method because the projected radius will be the same length for all object orientations.
Reference: <author> Rohlf, J. and Helman, J. </author> <year> (1994). </year> <title> IRIS Performer: a High Performance Multiprocessing Toolkit for Real-Time 3D Graphics, </title> <booktitle> Computer Graphics (SIGGRAPH '94 Proceedings), </booktitle> <pages> pp. 381394. </pages>
Reference-contexts: System Lag. This approach has been used in a number of successful systems such as Division Ltd.'s PROvision systems (Atkin, 1993), Silicon Graphics Inc.'s IRIS Performer <ref> (Rohlf and Helman, 1994) </ref>, and the freely-available MR-Toolkit package (Shaw et al., 1992). 1.2.3.1 Discussion of Solutions Each of the above solutions offer various advantages and disadvantages. <p> systems which have used LOD to maintain a desired frame rate include Airey et al.'s (1990) architectural walkthrough system [reactive], Hitchner and McGreevy's (1993) VPE testbed [reactive], Wloka's (1993a) Up 34 date Rate system [predictive] (see Section 1.2.3), and also the IRIS Performer graphics library developed by Silicon Graphics, Inc. <ref> (Rohlf and Helman, 1994) </ref> [reactive]. 2.1.6 Discussion of LOD Applications From the above, we can observe that LOD techniques have been used in a vast array of real-time applications. We have seen implementations in flight simulators, vehicle simulators, architectural walkthroughs, visualisations, digital terrain modeling, etc.
Reference: <author> Rossignac, J. R. and Borrel, P. </author> <year> (1992). </year> <title> Multi-Resolution 3D Approximations for Rendering Complex Scenes, </title> <type> Technical Report RC 17697 (#77951), </type> <institution> IBM Research Division, T. J. Watson Research Centre, Yorktown Heights, NY. </institution>
Reference: <author> Rovamo, J. and Virsu, V. </author> <year> (1979). </year> <title> An Estimation and Application of the Human Cortical Magnification Factor, </title> <journal> Experimental Brain Research, </journal> <volume> 37: </volume> <pages> 495510. </pages>
Reference-contexts: In this fashion, it has been empirically confirmed that our ability to resolve detail varies in relation to the orientation of a contrast grating (Campbell et al., 1966), its velocity across the retina (Kelly, 1979), the degree to which it is placed in our peripheral field <ref> (Rovamo and Virsu, 1979) </ref>, and the level of background illumination (Kelly, 1975). The phase of a contrast grating has no effect on its detectability (Lamming, 1991c). 2.3.2.2 The Contrast Sensitivity Function The contrast sensitivity function (CSF) is essentially a graph of the results from a series of contrast grating tests.
Reference: <author> Rushmeier, H., Ward, G., Piatko, C., Sanders, P. and Rust, B. </author> <year> (1995). </year> <title> Comparing Real and Synthetic Images: Some Ideas About Metrics, </title> <booktitle> Proceedings of the 6th Eurographics Workshop on Rendering, Dublin, </booktitle> <pages> pp. 8291. </pages>
Reference: <author> Scarlatos, L. L. </author> <year> (1990). </year> <title> A Refined Triangulation Hierarchy for Multiple Levels of Terrain Detail, </title> <booktitle> Proceedings of the IMAGE V Conference, Phoenix, Arizona, </booktitle> <pages> pp. 115122. </pages>
Reference: <author> Schachter, B. J. </author> <year> (1981). </year> <title> Computer Image Generation for Flight Simulation, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 1: </volume> <pages> 2968. </pages>
Reference: <author> Schade, O. H. </author> <year> (1956). </year> <title> Optical and Photoelectric Analog of the Eye, </title> <journal> Journal of the Optical Society of America, </journal> <volume> 46: </volume> <pages> 721739. </pages>
Reference: <author> Schmitt, F. J. M., Barsky, B. A. and Du, W.-H. </author> <year> (1986). </year> <title> An Adaptive Subdivision Method for Surface-Fitting from Sample Data, </title> <journal> Computer Graphics, </journal> <volume> 20(4): </volume> <pages> 179188. </pages>
Reference: <author> Schor, C. M. and Badcock, D. R. </author> <year> (1985). </year> <title> A Comparison of Stereo and Vernier Acuity with Spatial Channels as a Function of Distance from Fixation, </title> <journal> Vision Research, </journal> <volume> 25: </volume> <pages> 11131119. </pages>
Reference: <author> Schroeder, W. J., Zarge, J. A. and Lorensen, W. E. </author> <year> (1992). </year> <title> Decimation of Triangle Meshes, </title> <booktitle> Computer Graphics (SIGGRAPH '92 Proceedings), </booktitle> <volume> Vol. 26, </volume> <pages> pp. 65 70. </pages>
Reference: <author> Sekuler, R. and Blake, R. </author> <year> (1994). </year> <title> Perception, third edn, </title> <publisher> McGraw-Hill, Inc., </publisher> <address> New York, NY. ISBN 0-07-113683-5. </address>
Reference-contexts: For example, Figure 1.8 (b) will be maximally sensitive to a vertical edge and least sensitive to a horizontal edge. In general, a deviation of 19 around 15 ffi from a cell's preferred orientation is sufficient to render a feature undetectable to that cell <ref> (Sekuler and Blake, 1994) </ref>. illustrating the orientation selective nature of these cells. Similarly, complex cells are also sensitive to the orientation of a contrast gradient. <p> the CSF we can analyse a stimulus by only referring to its fundamental component (Lamming, 1991c). 2.3.3.2 Complexity Effects on Feature Detection Campbell and Robson also performed experiments with compound contrast gratings in order to investigate how the visibility of these is related to that of their component harmonic gratings <ref> (Sekuler and Blake, 1994) </ref>. They found that the appearance of a compound grating is characterised by the independent contributions from each of the harmonic components.
Reference: <author> Sen, R., Yates, R. B. and Thacker, N. A. </author> <year> (1995). </year> <title> Virtual Reality Based on Cost/Benefit Analysis, </title> <booktitle> Proceedings of the FIVE '95 Conference, </booktitle> <address> QMW, University of London, UK, </address> <pages> pp. 213221. </pages>
Reference-contexts: From our perspective this would mean that if a large object is displayed on screen, then any parts of the object that are within the user's peripheral field could potentially be degraded whilst retaining high detail for those parts of the object which the user is focussing upon <ref> (Sen et al., 1995) </ref>. This would be most useful in the situation where the VE contains a small number of large objects: a situation in which traditionally implemented eccentricity LOD would not cope well. There are however certain logistical difficulties associated with hierarchical LOD.
Reference: <author> Sewell, J. </author> <year> (1995). </year> <title> Automatic Generation of Simple Replacements for Groups of Objects. </title> <institution> The University of Cambridge Computer Laboratory, UK. </institution>
Reference: <author> Shaw, C., Liang, J., Green, M. and Sun, Y. </author> <year> (1992). </year> <title> The Decoupled Simulation Model for Virtual Reality Systems, </title> <booktitle> Proceedings of the CHI'92, </booktitle> <pages> pp. 321328. </pages>
Reference-contexts: System Lag. This approach has been used in a number of successful systems such as Division Ltd.'s PROvision systems (Atkin, 1993), Silicon Graphics Inc.'s IRIS Performer (Rohlf and Helman, 1994), and the freely-available MR-Toolkit package <ref> (Shaw et al., 1992) </ref>. 1.2.3.1 Discussion of Solutions Each of the above solutions offer various advantages and disadvantages.
Reference: <author> Sheridan, T. B. </author> <year> (1992). </year> <title> Musings on Telepresence and Virtual Presence, Presence: Teleoperators and Virtual Environments, </title> <type> 1(1): 120126. </type>
Reference: <author> Silverstein, L. D. and Merrifield, R. M. </author> <year> (1985). </year> <title> The Development and Evaluation of Color Systems for Airborne Applications, </title> <type> Technical Report DOT/FAA/PM8519, </type> <institution> Federal Aviation Administration, </institution> <address> Washington, DC. </address>
Reference: <author> Simpson, W. A. </author> <year> (1989). </year> <title> The Step Method: A New Adaptive Psychophysical Procedure, </title> <journal> Perceptual Psychology, </journal> <volume> 45: </volume> <pages> 572576. </pages>
Reference-contexts: Again, when guessing, the observer may exhibit a predisposed tendency to choose the first (i.e. left) interval. It has been shown that this can be countered by randomly varying the stimulus interval <ref> (Simpson, 1989) </ref>. 138 The Staircase Method There are two principal procedures for executing a 2AFC experiment. These are the constant stimuli method and the staircase method. In our present context, the former would mean selecting a number of eccentricities (normally five) and only testing the subject with these values.
Reference: <author> Singhal, S. K. and Cheriton, D. R. </author> <year> (1995). </year> <title> Exploiting Position History for Efficient Remote Rendering in Networked Virtual Reality, Presence: Teleoperators and Virtual Environments, </title> <type> 4(2): 169193. </type>
Reference: <author> Slater, M. and Usoh, M. </author> <year> (1993). </year> <title> Presence in Immersive Virtual Environments, </title> <booktitle> Proceedings of VRAIS '93 (IEEE Virtual Reality International Symposium), </booktitle> <address> Seattle, Washington, </address> <pages> pp. </pages> <note> 9096. 221 Slater, </note> <author> M., Usoh, M. and Chrysanthou, Y. </author> <year> (1995). </year> <title> The Influence of Dynamic Shadows on Presence in Immersive Virtual Environments. </title> <institution> Department of Computer Science, Queen Mary Westfield College, University of London. </institution>
Reference: <author> Smets, G. J. and Overbeeke, K. J. </author> <year> (1995). </year> <title> Trade-Off Between Resolution and Interactivity in Spatial Task Performance, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 15(5): </volume> <pages> 4651. </pages>
Reference-contexts: This is a valid trade-off for a real-time, interactive graphics system because it has been shown that humans are far more tolerant to reductions in image quality than to delays in visual update <ref> (Smets and Overbeeke, 1995) </ref>. 9 (a) (b) where (a) contains 6,048 polygons and (b) contains 278 polygons.
Reference: <author> Soufi, B. and Scrivener, S. A. R. </author> <year> (1992). </year> <title> Perceptual Grouping Algorithms and Object Identification, </title> <type> Technical Report 92/C/LUTCHI/0148, </type> <institution> Loughborough University of Technology, LUTCHI Research Centre. </institution>
Reference-contexts: Khan and Giles, 1992). Other feature extraction techniques have included attempts to generate a number of feature maps to locate `meaningful wholes' in an image based upon a number perceptual criteria <ref> (e.g. Soufi and Scrivener, 1992) </ref>, or the use of localised frequency domain techniques to categorise object groupings (e.g. Reed and Wechsler, 1990).
Reference: <author> Stampe, D. M., Reingold, E. M. and Grodski, Julius, J. </author> <year> (1993). </year> <title> Operator Gaze Position Control Interfaces: Investigation of Psychophysical and Operational Parameters, </title> <journal> AGARD CP-541, </journal> . <note> (NATO publication). </note>
Reference: <author> Stollnitz, E. J., DeRose, T. D. and Salesin, D. H. </author> <year> (1995a). </year> <title> Wavelets for Computer Graphics: a Primer, Part 1, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 15(3): </volume> <pages> 7684. </pages>
Reference: <author> Stollnitz, E. J., DeRose, T. D. and Salesin, D. H. </author> <year> (1995b). </year> <title> Wavelets for Computer Graphics: a Primer, Part 2, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 15(4): </volume> <pages> 7585. </pages>
Reference: <author> Stork, D. G. and Wilson, H. R. </author> <year> (1990). </year> <title> Do Gabor Functions Provide Appropriate Descriptions of Visual Cortical Receptive Fields?, </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 7(8): </volume> <pages> 13621373. </pages>
Reference-contexts: These channels can be modeled using 2D Gabor functions <ref> (Stork and Wilson, 1990) </ref> which are simply the product of a 2D sinusoid and a 2D Gaussian. Some researchers have therefore tried convolving an image using these Gabor functions in an attempt to develop and validate computational models of human vision (e.g. Watson, 1987; Beck et al., 1987).
Reference: <author> Sutherland, I. E. </author> <year> (1965). </year> <title> The Ultimate Display, </title> <booktitle> Proceedings of the IFIP Congress, </booktitle> <pages> pp. 506508. </pages>
Reference-contexts: A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal.' <ref> (Sutherland, 1965) </ref> Clearly we are far from attaining this considerable and provocative goal. Nevertheless, the field of computer graphics has advanced considerably over the past three decades. This has seen a progression from simple, monochrome, wire-frame figures to full-colour, lit, shaded, and textured representations.
Reference: <author> Sutter, E. E. and Tran, D. </author> <year> (1991). </year> <title> The Field Topography of ERG Components in ManI. The Photopic Luminance Response, </title> <journal> Vision Reseach, </journal> <volume> 32(3): 433 446. </volume>
Reference-contexts: The eye's peripheral sensitivity is not circular symmetric (e.g. Regan and Bever-ley, 1983). For example, there are marked asymmetries between the nasal and temporal retina beyond 20 degrees <ref> (Sutter and Tran, 1991) </ref>. Taking this into consideration, Rovamo and Virsu produced four equations to characterise M for each principal half-meridian of the retina. These are replicated below, and plotted in Figure 3.9 (a).
Reference: <author> Swartz, M., Wallace, D. and Tkacz, S. </author> <year> (1992). </year> <title> The Influence of Frame Rate and Resolution Reduction on Human Performance, </title> <booktitle> Proceedings of the Human Factors Society 36th Annual Meeting, </booktitle> <address> Santa Monica, CA, </address> <pages> pp. 14401444. </pages>
Reference: <author> Tipton, D. A. </author> <year> (1984). </year> <title> A Review of Vision Physiology, Aviation, </title> <journal> Space and Environmental Medicine, </journal> <volume> 55(2): </volume> <pages> 145149. </pages>
Reference-contexts: A Snellen fraction of 20/n is defined as the acuity at which two objects, which subtend 1 min of arc at n ft, can be perceived as separate at 20 ft <ref> (Tipton, 1984) </ref>. Therefore a person with 20/20 vision is classed as normal, and a person with 20/40 vision can only see a stimulus from 20 ft that a normal person can see from 40 ft.
Reference: <author> Travis, D. </author> <year> (1991). </year> <title> Effective Color Displays: Theory and Practice, </title> <publisher> Academic Press Ltd., </publisher> <address> London, UK. ISBN 012-697690-2. </address>
Reference: <author> Turk, G. </author> <year> (1992). </year> <title> Re-tiling Polygonal Surfaces, </title> <editor> in E. E. Catmull (ed.), </editor> <booktitle> Computer Graphics (SIGGRAPH '92 Proceedings), </booktitle> <volume> Vol. 26, </volume> <pages> pp. </pages> <note> 5564. 222 Tyler, </note> <author> C. W. </author> <year> (1985). </year> <title> Analysis of Visual Modulation Sensitivity. II. Peripheral Retina and the Role of Photoreceptor Dimensions, </title> <journal> Journal of the Optical Society of America, A2(3): </journal> <volume> 393398. </volume>
Reference: <author> Uliano, K., Kennedy, R. and Lambert, E. </author> <year> (1986). </year> <title> Asynchronous Visual Delays and the Development of Simulator Sickness, </title> <booktitle> Proceedings of the Human Factors Society (30th Annual Meeting), Human Factors Society, </booktitle> <address> Dayton, OH, </address> <pages> pp. </pages> <note> 422426. </note> <author> van Dam, A. </author> <year> (1993). </year> <title> Virtual Reality as a Forcing Function: Software Implications of a New Paradigm, </title> <booktitle> IEEE Symposium on Research Frontiers in Virtual Reality. </booktitle>
Reference: <author> Varshney, A. </author> <year> (1994). </year> <title> Hierarchical Geometric Approximations, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of North Carolina at Chapel Hill. </institution>
Reference: <author> Vince, J. </author> <year> (1993). </year> <title> Virtual Reality Techniques in Flight Simulation, </title> <editor> in R. A. Earn-shaw, M. A. Gigante and H. Jones (eds), </editor> <title> Virtual Reality Systems, </title> <publisher> Academic Press Ltd. </publisher> <address> ISBN 0-12-227748-1. </address>
Reference: <author> Virsu, V., Rovamo, J., Laurinen, P. and Nsnen, R. </author> <year> (1982). </year> <title> Temporal Contrast Sensitivity and Cortical Magnification, </title> <journal> Vision Research, </journal> <volume> 33: </volume> <pages> 12111217. </pages>
Reference: <author> Wann, J. P., Rushton, S. K. and Lee, D. N. </author> <year> (1995). </year> <title> Can You Control Where You Are Heading When You Are Looking At Where You Want To Go?, </title> <editor> in B. Bardy, R. Bootsma and Y. Guiard (eds), </editor> <booktitle> Proceedings of the 8th International Conference on Event Perception and Action, </booktitle> <pages> pp. 171174. </pages>
Reference-contexts: This type of experiment, as well as having been used by numerous vision scientists in the past, has also been used by various researchers in the field of VR to assess the performance of subjects within a VE <ref> (e.g. Wann et al., 1995) </ref>. The technique is therefore an accepted and stable metric for assessing user performance. 5.2.2 Method Stimuli.
Reference: <author> Ware, C. and Knight, W. </author> <year> (1995). </year> <title> Using Visual Texture for Information Display, </title> <journal> ACM Transactions on Graphics, </journal> <volume> 14(1): </volume> <pages> 320. </pages>
Reference: <author> Warren, W. H. and Hannon, D. J. </author> <year> (1990). </year> <title> Eye Movements and Optical Flow, </title> <journal> Journal of the Optical Society of America, A(7): </journal> <volume> 160169. </volume>
Reference: <author> Watson, A. B. </author> <year> (1983). </year> <title> Detection and Recognition of Simple Spatial Forms, </title> <editor> in O. J. Braddick and A. C. Sleigh (eds), </editor> <title> Physical and Biological Processing of Images, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <pages> pp. 100114. </pages>
Reference: <author> Watson, A. B. </author> <year> (1987). </year> <title> The Cortex Transform: Rapid Computation of Simulated Neural Images, Computer Vision, </title> <journal> Graphics, and Image Processing (CVGIP), </journal> <volume> 39: </volume> <pages> 311327. </pages>
Reference: <author> Watson, B., Walker, N. and Hodges, L. F. </author> <year> (1995). </year> <title> A User Study Evaluating Level of Detail Degradation in the Periphery of Head-Mounted Displays, </title> <booktitle> Proceedings of the FIVE '95 Conference, </booktitle> <address> QMW, University of London, UK, </address> <pages> pp. </pages> <year> 203212. </year>
Reference: <author> Wernecke, J. </author> <year> (1993). </year> <title> The Inventor Mentor: Programming Object-Oriented 3D Graphics with Open Inventor(TM), Release 2, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address> <note> ISBN 0-201-62495-8. 223 Wetherill, </note> <author> G. B. and Levitt, H. </author> <year> (1965). </year> <title> Sequential Estimation of Points on a Psychometric Function, </title> <journal> The British Journal of Mathematical and Statistical Psychology, </journal> <volume> 18(1): </volume> <pages> 110. </pages>
Reference-contexts: The screen area is calculated by projecting the 3D bounding box for a model onto the viewport and then computing the area of the screen-aligned rectangle surrounding that bounding box <ref> (Wernecke, 1993) </ref>. The REND386 package, originally written by Bernie Roehl and Dave Stampe of the University of Waterloo, provides a real-time 3D graphics library for the IBMPC compatible platform. The system implements a size LOD system by calculating the projected radius of an object's bounding sphere (Roehl, 1995).
Reference: <author> Williams, M. </author> <year> (1993). </year> <title> Immersive Virtual Environments Some Implications for Computer Graphics, Report on the One Day Immersive Virtual Environments Workshop, </title> <institution> Queen Mary and Westfield College, </institution> <address> London. </address>
Reference-contexts: by blurring the image of an object, and velocity LOD does this by using less complex geometry for the object. 184 Historically, most temporal antialiasing techniques have been developed for non real-time applications (such as ray tracing) and are therefore too computation-ally expensive for use in a real-time VR system <ref> (Williams, 1993) </ref>; however, a number of real-time techniques are beginning to emerge.
Reference: <author> Wilson, H. R. and Bergen, J. R. </author> <year> (1979). </year> <title> A Four Mechanism Model for Threshold Spatial Vision, </title> <journal> Vision Research, </journal> <volume> 19: </volume> <year> 1932. </year>
Reference: <author> Witmer, B. G. and Singer, M. J. </author> <year> (1994). </year> <title> Measuring Presence in Virtual Environments, </title> <type> Technical Report 1014, U.S. </type> <institution> Army Research Institute for the Behavioral and Social Sciences, Alexandria, VA. </institution>
Reference: <author> Wloka, M. M. </author> <year> (1993a). </year> <title> Incorporating Update Rates into Today's Graphics Systems, </title> <type> Technical Report CS-93-56, </type> <institution> Department of Computer Science, Brown University, Providence, RI. </institution>
Reference: <author> Wloka, M. M. </author> <year> (1993b). </year> <type> Thesis Proposal: Time-Critical Graphics, Technical Report CS-93-50, </type> <institution> Department of Computer Science, Brown University, Providence, RI. </institution>
Reference-contexts: Liang et al., 1991). [SENSOR] * Update Rates : the notion of update rates 1 can be used to define the rate at which an object's state is recomputed <ref> (Wloka, 1993b) </ref>. <p> this. 2.1.6.4 Discussion of Fixed Frame Rate LOD Fixed frame rate techniques have evolved significantly over the past few years; particularly with the growth of immersive environments which necessitate a high and consistent update rate in order to maintain the illusion of immersion, and to avoid effects of motion sickness <ref> (Wloka, 1993b) </ref>. Most currently available systems use a reactive scheduler to provide fixed frame rates because these are simpler to implement.
Reference: <author> Wloka, M. M. </author> <year> (1995). </year> <title> Lag in Multiprocessor Virtual Reality, Presence: Teleoperators and Virtual Environments, </title> <type> 4(1): 5063. </type>
Reference-contexts: Suffice to say however that the same components are relevant to both classes of VR systems; although normally a multi-processor system will incur an additional Synchronisation Delay to coordinate the activity of each processor <ref> (Wloka, 1995) </ref>. 1.2.2 Effects of Lag The degree of lag which a VR system exhibits can manifestly affect the user in a number of adverse ways. <p> Instead, pixels are rendered in a pseudo-random order so that the effect is less visually distracting (Bishop et al., 1994). The applicability of this technique to polygon renderers (as commonly used in VR applications) has been demonstrated <ref> (Wloka et al., 1995) </ref> and shown to increase the frame rate of the graphics system. [RENDERING] * Galilean Antialiasing : Costella (1993) has proposed a hardware-based motion extrapolation system which operates at a pixel level.
Reference: <author> Wloka, M. M., Zeleznik, R. C. and Miller, T. </author> <year> (1995). </year> <title> Practically Frameless Rendering, </title> <type> Technical Report CS-95-06, </type> <institution> Department of Computer Science, Brown University, Providence, RI. </institution>
Reference-contexts: Suffice to say however that the same components are relevant to both classes of VR systems; although normally a multi-processor system will incur an additional Synchronisation Delay to coordinate the activity of each processor <ref> (Wloka, 1995) </ref>. 1.2.2 Effects of Lag The degree of lag which a VR system exhibits can manifestly affect the user in a number of adverse ways. <p> Instead, pixels are rendered in a pseudo-random order so that the effect is less visually distracting (Bishop et al., 1994). The applicability of this technique to polygon renderers (as commonly used in VR applications) has been demonstrated <ref> (Wloka et al., 1995) </ref> and shown to increase the frame rate of the graphics system. [RENDERING] * Galilean Antialiasing : Costella (1993) has proposed a hardware-based motion extrapolation system which operates at a pixel level.
Reference: <author> Wyszecki, G. and Fielder, G. H. </author> <year> (1971). </year> <title> New Color-Matching Ellipses, </title> <journal> Journal of the Optical Society of America, </journal> <volume> 61(9): </volume> <pages> 11351152. </pages>
Reference-contexts: All colour difference equations are based around the CIEXYZ system which is only defined for colours that occupy 2 degrees of the user's field of view. But our colour perception degrades as the stimulus size decreases <ref> (Wyszecki and Fielder, 1971) </ref>. Silverstein and Mer-rifield (1985) therefore produced scaling factors for the CIELUV colour space to model the effect of stimulus size on colour perception.
Reference: <author> Yan, J. K. </author> <year> (1985). </year> <title> Advances in Computer Generated Imagery for Flight Simulation, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 5: </volume> <pages> 3751. </pages>
Reference: <author> Young, L. R. and Sheena, D. </author> <year> (1975). </year> <title> Survey of Eye Movement Recording Methods, Behaviour Research Methods and Instrumentation, </title> <type> 7(5): 397429. </type>
Reference: <author> Zeki, S. </author> <year> (1993). </year> <title> A Vision of the Brain, </title> <publisher> Blackwell Scientific Publications, Inc., Oxford, </publisher> <address> UK. ISBN 0-632-03054-2. </address> <month> 224 </month>
Reference-contexts: The result of these characteristics is that our vision is maximally sensitive within a central region of approximately 5 deg of arc, and drops off smoothly towards the periphery <ref> (Zeki, 1993) </ref>.
References-found: 194

