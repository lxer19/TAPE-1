URL: http://www.daimi.aau.dk/~tamtoft/Papers/WSA93.ps.Z
Refering-URL: http://www.daimi.aau.dk/~tamtoft/papers.html
Root-URL: http://www.daimi.aau.dk
Email: internet: tamtoft@daimi.aau.dk  
Title: Minimal Thunkification  
Author: Torben Amtoft 
Address: Ny Munkegade, DK-8000 Arhus C, Denmark  
Affiliation: Computer Science Department, Aarhus University  
Abstract: By "thunkifying" the arguments to function applications and "dethunkifying" variables one can translate a -expression e into a - expression e 0 , such that call-by-value evaluation of e 0 gives the same result as call-by-name evaluation of e. By using the result of a strictness analysis, some of these thunkifications can be avoided. In this paper we present a type system for strictness analysis; present a translation algorithm which exploits the strictness proof tree; and give a combined proof of the correctness of the analysis/translation. 
Abstract-found: 1
Intro-found: 1
Reference: [Amt93] <author> Torben Amtoft. </author> <title> Strictness types: An inference algorithm and an application. </title> <type> Technical Report PB-448, DAIMI, </type> <institution> University of Aarhus, Denmark, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: Section 4 gives a translation algorithm (which exploits the proof tree generated by the strictness analysis). In Sect. 5 we formulate predicates expressing the correctness of the translation/analysis, and we briefly outline a correctness proof for a full proof, see <ref> [Amt93] </ref>. 2 The -Calculus with Constants Expressions. <p> On the other hand, it is possible to develop a type inference algorithm which for each assignment to the arrows occurring in contravariant position finds a least assignment to the arrows in covariant position. The algorithm works by solving constraints "on the fly" and is fully described in <ref> [Amt93] </ref>; below we shall give a brief outline: The first step is to reformulate the inference system from Fig. 4 by employing the notion of strictness variables, ranging over 0,1. A pre-strictness type is now a strictness type where the 0/1's have been replaced by strictness variables. <p> : : : x n g] t The first part of 4 resembles the standard way of extending relations from closed terms to open terms; the second part of 4 expresses that the variables in W are "needed". 5.1 Correctness Theorems We have the following theorem, to be proved in <ref> [Amt93] </ref>: Theorem 6. Suppose ; T ` sa e : t; W , suppose e contains no unbounded recursion (i.e. only rec n 's and no rec's) and suppose e (by means of the corresponding proof tree) translates into e 0 .
Reference: [BHA86] <author> Geoffrey L. Burn, Chris Hankin, and Samson Abramsky. </author> <title> Strictness analysis for higher-order functions. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 7 </volume> <pages> 249-278, </pages> <year> 1986. </year>
Reference-contexts: Also thanks to Jens Palsberg for useful feedback. Strictness analysis for higher-order functions is treated in <ref> [BHA86] </ref> and proved correct in the following sense: if e # 1 is the abstract denotation of e 1 , and if e 1 (?) =? (in the abstract domain), then e 1 (?) =? (in the concrete domain) that is, e 1 will not terminate if its argument does not
Reference: [DH92] <author> Olivier Danvy and John Hatcliff. </author> <title> Thunks (continued). </title> <editor> In M. Billaud et al., editor, Analyse statique, </editor> <booktitle> Bordeaux 92 (WSA '92), </booktitle> <pages> pages 3-11, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The standard technique to solve the problem is to introduce "thunks" everywhere (thus simulating how one would naively implement call-by-name), as done e.g. in <ref> [DH92] </ref>.
Reference: [DH93] <author> Olivier Danvy and John Hatcliff. </author> <title> CPS transformation after strictness analysis. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(3), </volume> <year> 1993. </year>
Reference-contexts: A thunkification algorithm exploiting strictness information is presented in <ref> [DH93] </ref>. ? Supported by the DART-project funded by the Danish Research Council. ?? The work reported here evolved from numerous discussions with Hanne Riis Nielson and Flemming Nielson. Also thanks to Jens Palsberg for useful feedback. <p> Then e translates into rec f e 0 1 (resp. rec n f e 0 1 ). This is similar to the translation produced by the thunkification algorithm from <ref> [DH93] </ref>. Example 4. <p> Notice that twice also has strictness type (Int! 0 Int)! 0 (Int! 0 Int). Using the corresponding proof tree, twice just translates into itself. 5 Correctness Predicates We now embark on expressing the correctness of the translation something not addressed in <ref> [DH93] </ref>.
Reference: [Hug89] <author> John Hughes. </author> <title> Why functional programming matters. </title> <journal> Computer Journal, </journal> <volume> 32(2) </volume> <pages> 98-107, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction We shall consider the following problem: given -expression e, find a -expression e 0 such that e when evaluated using a call-by-name strategy yields the same result as e 0 when evaluated using a call-by-value strategy. The reason why this is interesting is that it is more convenient <ref> [Hug89] </ref> to program in a lazy language than in an eager (the former also enjoys the nice property of referential transparency); and that CBV traditionally is considered more efficient than CBN.
Reference: [Jen91] <author> Thomas P. Jensen. </author> <title> Strictness analysis in logical form. </title> <editor> In John Hughes, editor, </editor> <booktitle> International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 352-366. </pages> <publisher> Springer Verlag, LNCS 523, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: Other type-based approaches to strictness analysis includes [KM89], where the base types (not the arrows) are annotated with strictness information. An attempt to clarify the relation between strictness analysis based on abstract interpretation resp. type inference is presented in <ref> [Jen91] </ref> however, the relationship is in no way fully understood. Neither is the relative power of the various approaches in the literature, and accordingly the strength of our analysis will not be compared formally with other analyses.
Reference: [KM89] <author> Tsung-Min Kuo and Prateek Mishra. </author> <title> Strictness analysis: A new perspective based on type inference. </title> <booktitle> In International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 260-272. </pages> <publisher> ACM Press, </publisher> <month> September </month> <year> 1989. </year>
Reference-contexts: This is inspired by the method of Wright [Wri91] in [Wri92] he proves the correctness of his analysis (by means of a model for the -calculus), but does not consider any transformation based on the result of the analysis. Other type-based approaches to strictness analysis includes <ref> [KM89] </ref>, where the base types (not the arrows) are annotated with strictness information. An attempt to clarify the relation between strictness analysis based on abstract interpretation resp. type inference is presented in [Jen91] however, the relationship is in no way fully understood. <p> Consider the function f defined by rec f x:y:z:e where e = if (z = 0) (x + y) (f y x (z 1)). f is strict in all its arguments, but this cannot be inferred by the type system from <ref> [KM89] </ref> (due to the lack of conjunction types).
Reference: [Lan92] <author> Torben Poort Lange. </author> <title> The correctness of an optimized code generation. </title> <type> Technical Report PB-427, DAIMI, </type> <institution> University of Aarhus, Denmark, </institution> <month> November </month> <year> 1992. </year> <note> Also in the proceedings of PEPM '93, Copenhagen, ACM press. </note>
Reference-contexts: This can be seen as following the trend of [Wan93] who proves the combined correctness of a binding time analysis and a partial evaluation based on the result of this analysis. Also something similar can be found in <ref> [Lan92] </ref> where the correctness of a code generation exploiting strictness information is proved.
Reference: [Myc80] <author> Alan Mycroft. </author> <title> The theory of transforming call-by-need to call-by-value. </title> <editor> In B. Robinet, editor, </editor> <booktitle> International Symposium on Programming, Paris, </booktitle> <pages> pages 269-281. </pages> <publisher> Springer Verlag, LNCS 83, </publisher> <month> April </month> <year> 1980. </year>
Reference-contexts: Clearly, this is far from optimal since many expressions may become thunki-fied only to become dethunkified soon after. This kind of observation motivated Mycroft <ref> [Myc80] </ref> to introduce strictness analysis by means of abstract interpretation: if e # 1 is the denotation of e 1 in the abstract domain, and if e # then it is safe to omit thunkification of the argument to e 1 .
Reference: [NN90] <author> Hanne Riis Nielson and Flemming Nielson. </author> <title> Context information for lazy code generation. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 251-263. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: It may be of interest to investigate closer the power of our strictness analysis, relative to other approaches. And in order to avoid the kind of superfluous dethunkification/thunkification we encountered in Example 4, one may consider keeping track of context somewhat similar to what is done in <ref> [NN90] </ref>.
Reference: [Wan93] <author> Mitchell Wand. </author> <title> Specifying the correctness of binding-time analysis. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 137-143. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: However, no attention is given to proving the correctness of a translation using this information. This is a quite general phenomenon, cf. the claims made in <ref> [Wan93] </ref>: The goal of flow analysis is to annotate a program with certain propositions about the behavior of that program. One can then apply optimizations to the program that are justified by those propositions. <p> The main contribution of this paper is to give a combined proof of the correctness of a strictness analysis and of the resulting transformation. This can be seen as following the trend of <ref> [Wan93] </ref> who proves the combined correctness of a binding time analysis and a partial evaluation based on the result of this analysis. Also something similar can be found in [Lan92] where the correctness of a code generation exploiting strictness information is proved. <p> Thus the predicate closely reflects how expressions are to be translated, cf. the claim in <ref> [Wan93] </ref>: This work suggests that the proposition associated with a flow anal ysis can simply be that "the optimization works". Now we are ready to consider arbitrary (non-closed) expressions.
Reference: [Wri91] <author> David A. Wright. </author> <title> A new technique for strictness analysis. </title> <booktitle> In TAPSOFT 91, </booktitle> <pages> pages 235-258. </pages> <publisher> Springer Verlag, LNCS 494, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: This is inspired by the method of Wright <ref> [Wri91] </ref> in [Wri92] he proves the correctness of his analysis (by means of a model for the -calculus), but does not consider any transformation based on the result of the analysis. <p> We use that CT sa (c) is a strict iterated base type and hence is least among all types t with E (t) = E (CT sa (c)). ut The type system is rather similar to the one of Wright <ref> [Wri91] </ref> where function arrows are marked by boolean expressions amajor difference is that he imposes a "substitution ordering" (which hence is monotone in both "arrow positions") among types.
Reference: [Wri92] <author> David A. Wright. </author> <title> An intensional type discipline. </title> <journal> Australian Computer Science Communications, </journal> <volume> 14, </volume> <month> January </month> <year> 1992. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: This is inspired by the method of Wright [Wri91] in <ref> [Wri92] </ref> he proves the correctness of his analysis (by means of a model for the -calculus), but does not consider any transformation based on the result of the analysis. Other type-based approaches to strictness analysis includes [KM89], where the base types (not the arrows) are annotated with strictness information.
References-found: 13

