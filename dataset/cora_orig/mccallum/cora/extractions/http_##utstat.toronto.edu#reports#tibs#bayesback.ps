URL: http://utstat.toronto.edu/reports/tibs/bayesback.ps
Refering-URL: http://utstat.toronto.edu/reports/tibs/
Root-URL: 
Title: Bayesian Backfitting  
Author: Trevor Hastie and Robert Tibshirani 
Keyword: generalization of the backfitting algorithm for fitting additive models. Keywords: additive models, backfitting, Bayes, Gibbs sampling, random effects, Metropolis-Hastings procedure  
Abstract: We propose general procedures for posterior sampling from additive and generalized additive models, with applications to non-parametric, semi-parametric and mixed models. One chooses a linear operator S j for each predictor, and the algorithm requires only the application of S j and S j . Both of these can be done applied efficiently (O(n) operations) for many popular operators. The procedure is a stochastic
Abstract-found: 1
Intro-found: 1
Reference: <author> Ansley, C. & Kohn, R. </author> <year> (1996), </year> <title> `Estimation, filtering and smoothing in state space models with diffuse initial conditions.', </title> <journal> Annals of Statistics 13, </journal> <pages> 1286-1316. </pages>
Reference: <author> Buja, A., Hastie, T. & Tibshirani, R. </author> <year> (1989), </year> <title> `Linear smoothers and additive models (with discussion)', </title> <journal> Annals of Statistics 17, </journal> <pages> 453-555. </pages>
Reference-contexts: Convergence has only been proven for a certain class of fixed, non-adaptive operators <ref> (Buja et al. 1989) </ref>, such as smoothing splines, but the algorithm seems well-behaved in general.
Reference: <author> Carter, C. & Kohn, R. </author> <year> (1994), </year> <title> `On gibbs sampling for state space models', </title> <journal> Biometrika 81, </journal> <pages> 541-553. </pages>
Reference: <author> Chambers, J. & Hastie, T. </author> <year> (1991), </year> <title> Statistical Models in S, </title> <publisher> Wadsworth/Brooks Cole, </publisher> <address> Pacific Grove. de Boor, C. </address> <year> (1978), </year> <title> A Practical Guide to Splines, </title> <publisher> Applied Mathematical Sciences, Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: We have written several functions in the Splus language for implementing the ideas in this paper. In particular, a function gibbs.gam () takes as input a fitted gam object <ref> (Chambers & Hastie 1991) </ref>, and samples from the posterior distribution.
Reference: <author> Gelfand, A. E. & Smith, A. F. M. </author> <year> (1990), </year> <title> `Sampling based approaches to calculating marginal densities', </title> <journal> J. Amer. Statist. Assoc. </journal> <pages> pp. 398-409. </pages>
Reference: <author> Geman, S. & Geman, D. </author> <year> (1984), </year> <title> `Stochastic relaxation, gibbs distributions and the bayesian restoration of images', </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence pp. </journal> <pages> 721-741. </pages>
Reference-contexts: Gibbs sampling <ref> (Geman & Geman 1984, Gelfand & Smith 1990) </ref> for 7 general random variables A 1 ; A 2 ; : : : A p operates by successive sampling of each A j conditional on the other A k .
Reference: <author> Green, P. & Silverman, B. </author> <year> (1994), </year> <title> Nonparametric regression and generalized linear models: a roughness peanlty approach, </title> <publisher> Chapman and Hall. </publisher>
Reference-contexts: It is often convenient to parametrize the smoothing spline in terms of this fitted vector f rather than in (3). This is an equivalent representation <ref> (Green & Silverman 1994) </ref>, since f = B, where B is the full-rank nfiM basis matrix evaluated at the n values of x i . An advantage is that one obtains expressions that immediately suggest generalizations to other smoothing methods. There is a Bayesian characterization of ^ f .
Reference: <author> Hastie, T. </author> <year> (1995), </year> <title> `Pseudosplines', </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> Series B 58, </volume> <pages> 379-396. </pages>
Reference: <author> Hastie, T. & Tibshirani, R. </author> <year> (1986), </year> <title> `Generalized additive models', </title> <booktitle> Statistical Science 1, </booktitle> <pages> 295-318. </pages>
Reference: <author> Hastie, T. & Tibshirani, R. </author> <year> (1990), </year> <title> Generalized Additive Models, </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Hastings, W. K. </author> <year> (1970), </year> <title> `Monte carlo sampling methods using markov chains and their applications', </title> <journal> Biometrika 57, </journal> <pages> 97-109. </pages>
Reference-contexts: How can we simulate from the posterior density exp (J (; ))? The Metropolis-Hastings procedure <ref> (Hastings 1970) </ref> is a convenient approach here. In general this method works as follows. Given a posterior density (u) from which we wish to generate realizations u, we define a proposal distribution q (u; v) that specifies the probability of moving from state u to v.
Reference: <author> Laird, N. M. & Ware, J. H. </author> <year> (1982), </year> <title> `Random-effects models for longitudinal data', </title> <type> Biometrics 38, </type> <pages> 963-974. </pages> <note> 24 Lin, </note> <author> X. & Zhang, D. </author> <year> (1997), </year> <title> Inference in generalized additive mixed models, </title> <type> Technical report, </type> <institution> Department of Biostatistics, University of Michigan. </institution>
Reference-contexts: Typically one assumes the V i ~ N (0; 2 V ) independently across girls, and " ij ~ N (0; 2 ) independently across all measurements. Estimation of these mixed-effects models is typically done by maximum-likelihood <ref> (Laird & Ware 1982) </ref>, and focusses on : * the parameters of the fixed effects and their standard errors, * the variance components 2 V and 2 , * the posterior mean or BLUP estimates of the V i . 11 are connected. <p> The function f is random at level "0" (a single coefficient vector), while the V i are random at level "1" (a coefficient per cluster). Mixed effects models are typically fit by maximum likelihood or REML <ref> (Laird & Ware 1982) </ref>, and the popular packages such as SAS and Splus have routines for fitting them. <p> It turns out, that if the "fixed effects" are given a flat prior, then empirical Bayes is equivalent to REML <ref> (Laird & Ware 1982) </ref> Treating smoothing splines as random effects and estimating t 2 by REML is not a new idea (Speed 1991), also known as GML in the spline literature (Wahba 1990).
Reference: <author> Liu, J. S., Wong, W. H. & Kong, A. </author> <year> (1994), </year> <title> `Covariance structure of the Gibbs sampler with applications to the comparisons of estimators and augmentation schemes', </title> <journal> Biometrika 81, </journal> <pages> 27-40. </pages>
Reference: <author> Neal, R. M. </author> <year> (1996), </year> <title> Bayesian learning for neural networks, </title> <publisher> Springer-Verlag. </publisher>
Reference: <author> O'Hagan, A. </author> <year> (1978), </year> <title> `Curve fitting and optimal design for regression (with discussion)', </title> <journal> J. Royal Statist. Soc. </journal> <volume> B 40, </volume> <pages> 1-42. </pages>
Reference: <author> Silverman, B. </author> <year> (1984), </year> <title> `Spline smoothing: the equivalent kernel method', </title> <journal> Annals of Statistics 12, </journal> <pages> 898-9164. </pages>
Reference: <author> Speed, T. </author> <year> (1991), </year> <title> `Comment on "That BLUP is a good thing: the estimation of random effects"', </title> <booktitle> Statistical Science 6(1), </booktitle> <pages> 42-44. </pages>
Reference-contexts: It turns out, that if the "fixed effects" are given a flat prior, then empirical Bayes is equivalent to REML (Laird & Ware 1982) Treating smoothing splines as random effects and estimating t 2 by REML is not a new idea <ref> (Speed 1991) </ref>, also known as GML in the spline literature (Wahba 1990). Lin & Zhang (1997) in fact use REML in this way to estimate the smoothing parameters for additive spline models.
Reference: <author> Spiegelhalter, D., Best, N., Gilks, W. & Inskip, H. </author> <year> (1996), </year> <title> Hepatitis B: a case study in mcmc methods, </title> <editor> in W. Gilks, S. Richardson & D. Spegel-halter, eds, </editor> <title> `Markov Chain Monte Carlo in Practice', Interdisciplinary Statistics, </title> <publisher> Chapman and Hall. </publisher>
Reference-contexts: This prior is still improper, but the presence of = 10 10 appears to prevent the absorptions at the two extreme states. * In the right panel, we use IG (0:01; 0:01), considered to be reasonably flat proper priors in the MCMC literature <ref> (Spiegelhalter, Best, Gilks & Inskip 1996) </ref>. The histogram was obtained by simulating 10; 000 values from these priors. It exhibits very similar behavior to the first, although it appears there is support everywhere.
Reference: <author> Tierney, L. </author> <year> (1994), </year> <title> `Markov chains for exploring posterior distributions (with discussion)', </title> <journal> Annals of Statistics 22, </journal> <pages> 1701-1762. </pages> <month> Wahba </month> <year> (1980), </year> <title> Spline bases, regularization, and generalized cross-validation for solving approximation problems with large quantities of noisy data, </title> <booktitle> in `Proceedings of the International Conference on Approximation theory in honour of George Lorenz', </booktitle> <publisher> Academic Press, </publisher> <address> Austin, Texas. </address>
Reference: <author> Wahba, G. </author> <year> (1990), </year> <title> Spline Models for Observational Data, </title> <publisher> SIAM, Philadel-phia. </publisher>
Reference-contexts: All the parameters are the estimated by cross-validation, GCV <ref> (Wahba 1990) </ref>, or related methods aimed at minimizing prediction error on future ob servations. We give more details on the first two of these (in reverse order). 4.1 REML, ML and Empirical Bayes Model (19) can be regarded as an hierarchical mixed effects model. <p> turns out, that if the "fixed effects" are given a flat prior, then empirical Bayes is equivalent to REML (Laird & Ware 1982) Treating smoothing splines as random effects and estimating t 2 by REML is not a new idea (Speed 1991), also known as GML in the spline literature <ref> (Wahba 1990) </ref>. Lin & Zhang (1997) in fact use REML in this way to estimate the smoothing parameters for additive spline models.
Reference: <author> Williams, C. & Rasmussen, C. </author> <year> (1996), </year> <title> Gaussian processes for regression, </title> <booktitle> in `Neural Information Processing Systems 8. </booktitle> <editor> Editor: D. S. Touretzky and M. C. Mozer and M. E. Hasselmo.', </editor> <publisher> MIT Press. </publisher>
Reference: <author> Wong, C. & Kohn, R. </author> <year> (1996), </year> <title> `A bayesian approach to estimating and forecasting additive nonparametric autoregressive models', Journal of Time Series Analysis 17, </title> <type> 203-220. </type> <note> 25 Zeger, </note> <author> S. & Karim, M. </author> <year> (1991), </year> <title> `Generalized linear models with random ef-fects: a gibbs sampling approach', </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 86, </volume> <pages> 79-86. </pages>
References-found: 22

