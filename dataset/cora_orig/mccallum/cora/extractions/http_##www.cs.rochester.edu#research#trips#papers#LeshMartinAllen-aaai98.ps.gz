URL: http://www.cs.rochester.edu/research/trips/papers/LeshMartinAllen-aaai98.ps.gz
Refering-URL: http://www.cs.rochester.edu/stats/oldmonths/1998.05/docs-name.html
Root-URL: 
Email: flesh,martin,jamesg@cs.rochester.edu  
Title: Improving Big Plans  
Author: Neal Lesh, Nathaniel Martin, James Allen 
Address: Rochester NY 14627  
Affiliation: Computer Science Department University of Rochester  
Abstract: Past research on assessing and improving plans in domains that contain uncertainty has focused on analytic techniques that are exponential in the length of the plan. Little work has been done on choosing from among the many ways in which a plan can be improved. We present the Improve algorithm which simulates the execution of large, probabilistic plans. Improve runs a data mining algorithm on the execution traces to pinpoint defects in the plan that most often lead to plan failure. Finally, Improve applies qualitative reasoning and plan adaptation algorithms to modify the plan to correct these defects. We have tested Improve on plans containing over 250 steps in an evacuation domain, produced by a domain-specific scheduling routine. In these experiments, the modified plans have over a 15% higher probability of achieving their goal than the original plan. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agrawal, R., and Srikant, R. </author> <year> 1995. </year> <title> Mining sequential patterns. </title> <booktitle> In Intl. Conf. on Data Engg. </booktitle>
Reference-contexts: Introduction Large, complex domains call for large, robust plans. However, today's state-of-the-art planning algorithms cannot efficiently generate large or robust plans from first principles. We have combined work on data mining <ref> (Agrawal & Srikant 1995) </ref>, qualitative reasoning (Wellman 1990), planning (Nebel & Koehler 1995), and simulation to construct the Improve algorithm which modifies a given plan so that it has a higher probability of achieving its goal. <p> The objective is a function which outputs expressions of the form Prevent (a i ; o i;k ) which translates to "Try to prevent action a i from having outcome o i;k ." This process is more completely described in (Zaki, Lesh, & Ogihara 1997). Sequential discovery <ref> (Agrawal & Srikant 1995) </ref> is the problem of mining patterns from sequences of unordered sets of items, such as ABC 7! DE 7! EF 7! GHI AB 7! E 7! IJ 1 Values for z can be found in any statistics textbook.
Reference: <author> Alterman, R. </author> <year> 1988. </year> <title> Adaptive planning. </title> <booktitle> Cognitive Science 12 </booktitle> <pages> 393-421. </pages>
Reference-contexts: Furthermore, we focus on repairing a large, non-reactive plan to avoid the trouble, whereas Drummond and Bresnia enhance a reactive plan to get itself out of trouble once it has occurred. <ref> (Alterman 1988) </ref> describes run-time repair of plans by, for example, replacing a step that just failed with a similar action. This is rather different that our approach of repairing plans in advance. We believe both techniques are necessary.
Reference: <author> Boutilier, C.; Dean, T.; and Hanks, S. </author> <year> 1995. </year> <title> Planning under uncertainty: Structural assumptions and computational leverage. </title> <booktitle> In Proc. 2nd European Planning Workshop. </booktitle>
Reference-contexts: Formulation In this section, we define our terms and specify the input and output of the plan improvement problem. The problem of planning under uncertainty has recently been addressed by a variety of researchers. See (Goldman & Boddy 1996) and <ref> (Boutilier, Dean, & Hanks 1995) </ref> for comparisons of various approaches. We use the representation of actions used by the Buri-dan planner (Kushmerick, Hanks, & Weld 1995), which allows for probabilistic and conditional effects, but not for exogenous events or for actions to be executed in parallel or have varying durations.
Reference: <author> Draper, D.; Hanks, S.; and Weld, D. </author> <year> 1994. </year> <title> Probabilistic planning with information gathering and contingent execution. </title> <booktitle> In Proc. 2nd Intl. Conf. AI Planning Systems. </booktitle>
Reference: <author> Drummond, M., and Bresina, J. </author> <year> 1990. </year> <title> Anytime Synthetic Projection: Maximizing the Probability of Goal Satisfaction. </title> <booktitle> In Proc. 8th Nat. Conf. AI, </booktitle> <pages> 138-144. </pages>
Reference-contexts: One limitation of GORDIUS is that it can only resolve flaws that arise from a single mistaken assumption. We find problems that arise from sequences of defects that cause the problem. The overall spirit of our approach resembles robusti-fication in <ref> (Drummond & Bresina 1990) </ref>. Here, a reactive plan is incrementally refined by detecting the state in which it is most likely to fail and then producing new instructions for that state. We use very different techniques than theirs.
Reference: <author> Ferguson, G.; Allen, J. F.; and Miller, B. </author> <year> 1996. </year> <title> TRAINS-95: Towards a mixed-initiative planning assistant. </title> <booktitle> In Proceedings of the Third International Conference on AI Planning Systems (AIPS-96). </booktitle>
Reference-contexts: An algorithm for improving big plans is useful only if big, but not especially robust, plans can be generated to begin with. We believe domain specific and collaborative planning algorithms (e.g. <ref> (Ferguson, Allen, & Miller 1996) </ref>) will produce such plans. In our experiments, we use a greedy, domain specific algorithm to produce plans with 250 to 300 steps in an evacuation domain.
Reference: <author> Goldman, R. P., and Boddy, M. S. </author> <year> 1994. </year> <title> Epsilon-safe planning. </title> <booktitle> In Proc. 10th Conf. Uncertainty in Artifical Intelligence. </booktitle>
Reference: <author> Goldman, R. P., and Boddy, M. S. </author> <year> 1996. </year> <title> Expressive Planning And Explicit Knowledge. </title> <booktitle> In Proc. 3rd Intl. Conf. AI Planning Systems. </booktitle>
Reference-contexts: We then present our improvement algorithm, describe our experiments, and then conclude. Formulation In this section, we define our terms and specify the input and output of the plan improvement problem. The problem of planning under uncertainty has recently been addressed by a variety of researchers. See <ref> (Goldman & Boddy 1996) </ref> and (Boutilier, Dean, & Hanks 1995) for comparisons of various approaches.
Reference: <author> Hammond, K. </author> <year> 1989. </year> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <publisher> Academic Press. </publisher>
Reference: <author> Hammond, K. </author> <year> 1990. </year> <title> Explaining and repairing plans that fail. </title> <journal> J. Artificial Intelligence 45 </journal> <pages> 173-228. </pages>
Reference-contexts: This contrasts to our work, in which each simulation contains a great number of undesirable effects, such as buses getting flat tires or overheating, and our analysis attempts to discover important trends that distinguish successful from unsuccessful executions. Plan repair CHEF <ref> (Hammond 1990) </ref> is a case-based planning system addresses many issues. We focus on those most related to our work. CHEF composes a plan from plans in its memory, simulates it, and then analyzes the execution trace to improve the plan.
Reference: <author> Hanks, S., and Weld, D. S. </author> <year> 1995. </year> <title> A domain-independent algorithm for plan adaptation. </title> <journal> J. Artificial Intelligence Research 319-360. </journal>
Reference-contexts: Formulation In this section, we define our terms and specify the input and output of the plan improvement problem. The problem of planning under uncertainty has recently been addressed by a variety of researchers. See (Goldman & Boddy 1996) and <ref> (Boutilier, Dean, & Hanks 1995) </ref> for comparisons of various approaches. We use the representation of actions used by the Buri-dan planner (Kushmerick, Hanks, & Weld 1995), which allows for probabilistic and conditional effects, but not for exogenous events or for actions to be executed in parallel or have varying durations. <p> The problem of planning under uncertainty has recently been addressed by a variety of researchers. See (Goldman & Boddy 1996) and (Boutilier, Dean, & Hanks 1995) for comparisons of various approaches. We use the representation of actions used by the Buri-dan planner <ref> (Kushmerick, Hanks, & Weld 1995) </ref>, which allows for probabilistic and conditional effects, but not for exogenous events or for actions to be executed in parallel or have varying durations. In our actual system, we allow for limited forms of all of these factors. <p> Let P [G j I; A] be the probability of goal G holding in the state resulting from executing action sequence A from state I. See <ref> (Kushmerick, Hanks, & Weld 1995) </ref> for an exact description of how to compute the probability of a plan achieving a goal, as well as the probability of a state resulting from executing a given action from a given state. <p> Since simulation explores only one possible execution path at a time, the complexity of simulation is linear in the length of the plan. Previous analytic techniques for assessing plans are exponential in the length of the plan (e.g. <ref> (Kushmerick, Hanks, & Weld 1995) </ref>). We now briefly discuss the advantages of using simulation in probabilistic planning. <p> In each case, a plan that almost solves a given goal is modified, or repaired, to solve the goal. In particular our problem, can be mapped into a plan-reuse or plan adaptation problem (Nebel & Koehler 1995), for which there are several domain-independent algorithms including SPA <ref> (Hanks & Weld 1995) </ref>, PRIAR (Kambhampati & Hendler 1992), and NOLIMIT (Veloso 1994). We focus on SPA, which is based on the SNLP partial-order planner (McAllester & Rosenblitt 1991). Planning by adaptation is similar to planning from first principles.
Reference: <author> Kambhampati, S., and Hendler, J. </author> <year> 1992. </year> <title> A validation structure based theory of plan modification and reuse. </title> <journal> J. Artificial Intelligence 55 </journal> <pages> 193-258. </pages>
Reference-contexts: In particular our problem, can be mapped into a plan-reuse or plan adaptation problem (Nebel & Koehler 1995), for which there are several domain-independent algorithms including SPA (Hanks & Weld 1995), PRIAR <ref> (Kambhampati & Hendler 1992) </ref>, and NOLIMIT (Veloso 1994). We focus on SPA, which is based on the SNLP partial-order planner (McAllester & Rosenblitt 1991). Planning by adaptation is similar to planning from first principles.
Reference: <author> Kushmerick, N.; Hanks, S.; and Weld, D. </author> <year> 1995. </year> <title> An Algorithm for Probabilistic Planning. </title> <journal> J. Artificial Intelligence 76 </journal> <pages> 239-286. </pages>
Reference-contexts: The problem of planning under uncertainty has recently been addressed by a variety of researchers. See (Goldman & Boddy 1996) and (Boutilier, Dean, & Hanks 1995) for comparisons of various approaches. We use the representation of actions used by the Buri-dan planner <ref> (Kushmerick, Hanks, & Weld 1995) </ref>, which allows for probabilistic and conditional effects, but not for exogenous events or for actions to be executed in parallel or have varying durations. In our actual system, we allow for limited forms of all of these factors. <p> Let P [G j I; A] be the probability of goal G holding in the state resulting from executing action sequence A from state I. See <ref> (Kushmerick, Hanks, & Weld 1995) </ref> for an exact description of how to compute the probability of a plan achieving a goal, as well as the probability of a state resulting from executing a given action from a given state. <p> Since simulation explores only one possible execution path at a time, the complexity of simulation is linear in the length of the plan. Previous analytic techniques for assessing plans are exponential in the length of the plan (e.g. <ref> (Kushmerick, Hanks, & Weld 1995) </ref>). We now briefly discuss the advantages of using simulation in probabilistic planning.
Reference: <author> McAllester, D., and Rosenblitt, D. </author> <year> 1991. </year> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. 9th Nat. Conf. AI, </booktitle> <pages> 634-639. </pages>
Reference-contexts: We focus on SPA, which is based on the SNLP partial-order planner <ref> (McAllester & Rosenblitt 1991) </ref>. Planning by adaptation is similar to planning from first principles. The primary difference is that search begins from the plan to be adapted rather than from a null plan.
Reference: <author> McClave, J. T., and II, F. H. D. </author> <year> 1982. </year> <institution> Statistics. </institution> <address> San Francisco: </address> <publisher> Dellen Publishing Company. </publisher>
Reference-contexts: Previous analytic techniques for assessing plans are exponential in the length of the plan (e.g. (Kushmerick, Hanks, & Weld 1995)). We now briefly discuss the advantages of using simulation in probabilistic planning. Standard statistical arguments <ref> (McClave & II 1982) </ref> show that simulation converges in the sense that one can guarantee there is a high probability that the estimate returned by simulation is within some * of the true probability.
Reference: <author> McDermott, D. </author> <year> 1994. </year> <title> Improving robot plans during execution. </title> <booktitle> In Proc. 2nd Intl. Conf. AI Planning Systems, </booktitle> <pages> 7-12. </pages>
Reference-contexts: Both types of techniques can be used in conjunction. But note that our approach is relevant only in domains with uncertainty, in which multiple executions of the same plan might differ from each other. <ref> (McDermott 1994) </ref> describes a system in which a robot repeatedly simulates the execution of a plan while executing the plan, with hopes of finding a more robust alternative. Each error in the simulations is considered a bug and categorized into an extensive taxonomy of plan failure modes.
Reference: <author> Minton, S. </author> <year> 1990. </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence 42(2-3). </journal>
Reference-contexts: Related work We now discuses several areas of related work. Analyzing execution traces Much work has been done on analyzing planning episodes, i.e. invocations of the planner, to improve future planning performance in terms of efficiency or quality. (e.g. <ref> (Minton 1990) </ref>). In contrast, we analyze execution traces to improve the quality of the plan at hand, not the planning process. Both types of techniques can be used in conjunction.
Reference: <author> Nebel, B., and Koehler, J. </author> <year> 1995. </year> <title> Plan reuse versus plan generation: a theoretical and emperical analysis. </title> <journal> J. Artificial Intelligence 76 </journal> <pages> 427-454. </pages>
Reference-contexts: Introduction Large, complex domains call for large, robust plans. However, today's state-of-the-art planning algorithms cannot efficiently generate large or robust plans from first principles. We have combined work on data mining (Agrawal & Srikant 1995), qualitative reasoning (Wellman 1990), planning <ref> (Nebel & Koehler 1995) </ref>, and simulation to construct the Improve algorithm which modifies a given plan so that it has a higher probability of achieving its goal. An algorithm for improving big plans is useful only if big, but not especially robust, plans can be generated to begin with. <p> Finally, plan modifications can necessitate further planning. For example, adding an action to a plan requires that the preconditions of the action be satisfied, perhaps by adding more actions. We show how this problem is closely related to the problem of plan re-use or adaptation <ref> (Nebel & Koehler 1995) </ref>. Below, we first formulate the plan improvement problem. We then describe our four components: sim ulation, data mining, qualitative reasoning, planning. We then present our improvement algorithm, describe our experiments, and then conclude. <p> For example, the new action may have unsatisfied preconditions. We now address the problem of further modifying the plan to accommodate the new changes. Variations of this problem arise in case-based planning (Hammond 1989; 1990), transformational planning (Simmons 1988), or plan re-use or plan adaptation <ref> (Nebel & Koehler 1995) </ref>. In each case, a plan that almost solves a given goal is modified, or repaired, to solve the goal. In particular our problem, can be mapped into a plan-reuse or plan adaptation problem (Nebel & Koehler 1995), for which there are several domain-independent algorithms including SPA (Hanks <p> (Hammond 1989; 1990), transformational planning (Simmons 1988), or plan re-use or plan adaptation <ref> (Nebel & Koehler 1995) </ref>. In each case, a plan that almost solves a given goal is modified, or repaired, to solve the goal. In particular our problem, can be mapped into a plan-reuse or plan adaptation problem (Nebel & Koehler 1995), for which there are several domain-independent algorithms including SPA (Hanks & Weld 1995), PRIAR (Kambhampati & Hendler 1992), and NOLIMIT (Veloso 1994). We focus on SPA, which is based on the SNLP partial-order planner (McAllester & Rosenblitt 1991).
Reference: <author> Simmons, R. </author> <year> 1988. </year> <title> A theory of debugging plans and interpretations. </title> <booktitle> In Proc. 7th Nat. Conf. AI, </booktitle> <pages> 94-99. </pages>
Reference-contexts: However, these modifications might result in an unexecutable plan. For example, the new action may have unsatisfied preconditions. We now address the problem of further modifying the plan to accommodate the new changes. Variations of this problem arise in case-based planning (Hammond 1989; 1990), transformational planning <ref> (Simmons 1988) </ref>, or plan re-use or plan adaptation (Nebel & Koehler 1995). In each case, a plan that almost solves a given goal is modified, or repaired, to solve the goal.
Reference: <author> Simmons, R. </author> <year> 1992. </year> <title> The roles of associational and causal reasoning in problem solving. </title> <journal> J. Artificial Intelligence 159-208. </journal>
Reference-contexts: In contrast we simulate our plans hundreds of times and apply shallow, statistical methods to pinpoint defects and apply general plan adaptation techniques to repair plans. The GORDIUS system <ref> (Simmons 1992) </ref> also applies repair strategies to a plan, by replacing an incorrect assumption which gave rise to the flaw.
Reference: <author> Veloso, M. </author> <year> 1994. </year> <title> Flexible strategy learning: Analogical replay of problem solving episodes. </title> <booktitle> In Proc. 12th Nat. Conf. AI, </booktitle> <pages> 595-600. </pages>
Reference-contexts: In particular our problem, can be mapped into a plan-reuse or plan adaptation problem (Nebel & Koehler 1995), for which there are several domain-independent algorithms including SPA (Hanks & Weld 1995), PRIAR (Kambhampati & Hendler 1992), and NOLIMIT <ref> (Veloso 1994) </ref>. We focus on SPA, which is based on the SNLP partial-order planner (McAllester & Rosenblitt 1991). Planning by adaptation is similar to planning from first principles. The primary difference is that search begins from the plan to be adapted rather than from a null plan.
Reference: <author> Wellman, M. P. </author> <year> 1990. </year> <title> Fundamental concepts of qualitative probabilistic networks. </title> <journal> AI Magazine 44 </journal> <pages> 257-303. </pages>
Reference-contexts: Introduction Large, complex domains call for large, robust plans. However, today's state-of-the-art planning algorithms cannot efficiently generate large or robust plans from first principles. We have combined work on data mining (Agrawal & Srikant 1995), qualitative reasoning <ref> (Wellman 1990) </ref>, planning (Nebel & Koehler 1995), and simulation to construct the Improve algorithm which modifies a given plan so that it has a higher probability of achieving its goal. <p> The patterns are used to determine what to fix in the plan. For example, if the plan often fails when Bus1 gets a flat tire and overheats, then Improve attempts to prevent at least one of those problems from occurring. In the third step, we apply qualitative reasoning techniques <ref> (Wellman 1990) </ref> to modify the plan to avoid the problems that arose in simulation. For example, if the problem is that a bus is getting a flat tire then this step might suggest changing its tires. Finally, plan modifications can necessitate further planning. <p> Currently, we hand code a set of qualitative rules QR for the domain. Our approach can be described as a simple case of a qualitative probabilistic network (QPN) <ref> (Wellman 1990) </ref>. QPNs are used to perform inference over qualitative influences. The complexity of determining if one node positively or negatively influences another is O (jVj 2 ) where V is the number of nodes. These techniques are thus suitable for large domains.
Reference: <author> Zaki, M. J.; Lesh, N.; and Ogihara, M. </author> <year> 1997. </year> <title> Sequence mining for plan failuresk. </title> <type> Technical Report URCS TR 671, </type> <institution> University of Rochester. </institution>
Reference-contexts: Simulation is linear in the length of the plan and fast in practice. Further, the estimate produced by simulation converges, as more simulations are performed, to the true probability that a plan will achieve its goal. In the second step, we use SPADE <ref> (Zaki 1997) </ref>, a sequential discovery data mining algorithm to extract patterns of events that are common in traces of plan failures but uncommon in traces of plan successes. The patterns are used to determine what to fix in the plan. <p> The objective is a function which outputs expressions of the form Prevent (a i ; o i;k ) which translates to "Try to prevent action a i from having outcome o i;k ." This process is more completely described in <ref> (Zaki, Lesh, & Ogihara 1997) </ref>. Sequential discovery (Agrawal & Srikant 1995) is the problem of mining patterns from sequences of unordered sets of items, such as ABC 7! DE 7! EF 7! GHI AB 7! E 7! IJ 1 Values for z can be found in any statistics textbook. <p> The algorithms find pat-terns that occur with high frequency. For example, the sequence A 7! I occurs in all three of the above sequences, and AB 7! E 7! I occurs in two of them. We have applied the SPADE algorithm <ref> (Zaki 1997) </ref> to the execution traces produced by the simulator. <p> A second problem is that the existence of one rule that predicts failure, say (Bus1 Flat) 7! (Bus1 Overheat), implies the existence of many related, equally predictive rules, such as (Move Bus1) 7! (Move Bus1) 7! (Bus1 Flat) 7! (Bus1 Overheat), since the Move action is so common. <ref> (Zaki, Lesh, & Ogihara 1997) </ref> discusses these problems and describes pruning stratagies for addressing them.
Reference: <author> Zaki, M. J. </author> <year> 1997. </year> <title> Fast mining of sequential patterns in very large databases. </title> <type> Technical Report URCS TR 668, </type> <institution> University of Rochester. </institution>
Reference-contexts: Simulation is linear in the length of the plan and fast in practice. Further, the estimate produced by simulation converges, as more simulations are performed, to the true probability that a plan will achieve its goal. In the second step, we use SPADE <ref> (Zaki 1997) </ref>, a sequential discovery data mining algorithm to extract patterns of events that are common in traces of plan failures but uncommon in traces of plan successes. The patterns are used to determine what to fix in the plan. <p> The objective is a function which outputs expressions of the form Prevent (a i ; o i;k ) which translates to "Try to prevent action a i from having outcome o i;k ." This process is more completely described in <ref> (Zaki, Lesh, & Ogihara 1997) </ref>. Sequential discovery (Agrawal & Srikant 1995) is the problem of mining patterns from sequences of unordered sets of items, such as ABC 7! DE 7! EF 7! GHI AB 7! E 7! IJ 1 Values for z can be found in any statistics textbook. <p> The algorithms find pat-terns that occur with high frequency. For example, the sequence A 7! I occurs in all three of the above sequences, and AB 7! E 7! I occurs in two of them. We have applied the SPADE algorithm <ref> (Zaki 1997) </ref> to the execution traces produced by the simulator. <p> A second problem is that the existence of one rule that predicts failure, say (Bus1 Flat) 7! (Bus1 Overheat), implies the existence of many related, equally predictive rules, such as (Move Bus1) 7! (Move Bus1) 7! (Bus1 Flat) 7! (Bus1 Overheat), since the Move action is so common. <ref> (Zaki, Lesh, & Ogihara 1997) </ref> discusses these problems and describes pruning stratagies for addressing them.
References-found: 24

