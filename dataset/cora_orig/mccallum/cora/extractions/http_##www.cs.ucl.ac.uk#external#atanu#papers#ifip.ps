URL: http://www.cs.ucl.ac.uk/external/atanu/papers/ifip.ps
Refering-URL: http://www.cs.ucl.ac.uk/external/atanu/papers/papers.html
Root-URL: http://www.cs.ucl.ac.uk
Email: mike@socs.uts.edu.au  a.ghosh@cs.ucl.ac.uk  
Phone: +612 330 1821  +44 171 380 3670  
Title: Integrated Layer Processing of Complex Presentation  
Author: Michael Fry Atanu Ghosh 
Address: Sydney PO Box 123, Broadway, NSW 2007 Australia  Gower Street, London WC1E 6BT England  
Affiliation: School of Computing Sciences University of Technology,  Department of Computer Science University College London  
Abstract: Application Level Framing (ALF) and Integrated Layer Processing (ILP) have been proposed as strategies for solving the end system bottleneck problem for modern, distributed applications. Distributed multimedia applications that employ software intensive coding and compression techniques appear to be likely performance beneficiaries of an ALF/ILP implementation approach. However, there is a widely held view that the computational complexity of such presentation protocol processing dwarfs any performance benefits that may be derived from ILP. This paper investigates the potential for ILP in a non-trivial distributed application: a JPEG photo server. We measure some of the potential benefits of ILP by instrumentation of the application and by some hand-coded integration experiments. Our results show that an ILP approach will be worthwhile for this application. Nonetheless, we also show that certain transformation stages may impose limits on the extent of loop integration. One of the drawbacks of ILP is its hand-coded approach and lack of modularity. We propose a strategy to further investigate ILP for complex applications that will utilise re-useable "filter" components. This strategy will realise optimal performance, while also enabling automatic synthesis of communication modules to meet particular application requirements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David Clark, David Tennenhouse. </author> <title> Architectural Considerations for a New Generation Protocols. </title> <journal> Computer Communication Review, </journal> <volume> Vol. 20, No. 4, SIGCOMM '90, </volume> <month> September </month> <year> 1990, </year> <pages> pp. 200-208. </pages>
Reference-contexts: Application and presentation protocol processing functions are widely recognised as some of the most heavyweight aspects of end-to-end communication. Consideration of the general problem of optimal protocol design and implementation has lead to the development of two significant principles: Application Level Framing (ALF) and Integrated Layer Processing (ILP) <ref> [1] </ref>. ALF and ILP are concise and powerful principles. They have been used experimentally in the construction of fairly simple communications modules, but have not so far been applied to more complex, "production strength" applications. There has been rapid growth in multimedia applications and information services based on the Internet.
Reference: [2] <author> Mark Abbott, Larry Peterson. </author> <title> Increasing Network Throughput by Integrating Protocol Layers. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> Vol. 1, No. 5, </volume> <month> October </month> <year> 1993, </year> <pages> pp. 600-610. </pages>
Reference-contexts: In [4] the benefits of ILP are indicated by applying integration to an isolated pipeline of checksum, encryption and and file (FTP protocol) processing. Further development of the ILP concept has occurred in <ref> [2] </ref>. This study explores some problems in the application of ILP such as dependencies between headers and data parts at different protocol layers, other ordering constraints in data manipulations, and the modularity of ILP implementations. Abbot and Peterson propose some implementation techniques to overcome these problems. <p> Our results show that data manipulations performed on uncompressed data are just as significant. Furthermore, with the advent of modern processor architectures such as the DEC Alpha, the cost of complex computation vis-a-vis data movement is a widely discussed issue. We have investigated this balance for our application. In <ref> [2] </ref> all data manipulation tasks in protocols are characterised to consist of: * for loops (iteration) * data read/write * computation An ILP implementation attempts to minimise the costs of the first two. <p> However (as discussed below) it is likely that a checksum failure would be detected prior to the reverse DCT stage, which would then inhibit further processing. Care must also be taken to defer acknowledge-ments until the checksum result is known. The strategy of a common "final stage" <ref> [2] </ref>, which we have described previously, addresses this control dependency. A simple approach to integration is to perform all layers of protocol processing in a simple "for loop", representing a single read-process-write cycle. This is the approach used in [4]. <p> Unfortunately, the kind of hand integration that we have performed in our experiment has many drawbacks. Most significantly, modularity is lost: the integrated code becomes very complicated and difficult to maintain. A way forward would be to have automated loop integration. Word filters <ref> [2] </ref> point to such a way forward. In this case, each stage of a pipeline is executed for each 32 bit machine word of the input stream. However, different stages may operate on different data widths. In [2] the example of DES is given, which manipulates 64 bit quanta (in block <p> A way forward would be to have automated loop integration. Word filters <ref> [2] </ref> point to such a way forward. In this case, each stage of a pipeline is executed for each 32 bit machine word of the input stream. However, different stages may operate on different data widths. In [2] the example of DES is given, which manipulates 64 bit quanta (in block mode). A DES word filter will maintain state such that it will only perform its manipulation on pairs of words. When the first word is input from the pipeline it is simply saved.
Reference: [3] <author> Isabelle Chrisment. </author> <title> Impact of ALF on Communication Subsystems Design and Performance. </title> <booktitle> 1st HIPPARCH Workshop, </booktitle> <institution> Sophia Antipolis, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: all performed in software at the client. 2 This view has been expressed in discussion during the HIPPARCH project, and is also suggested in [4] 3 The photo server has been developed under a parallel Task of the HIPPARCH project, which is primarily investigating the network efficiency benefits of ALF <ref> [3] </ref>. Thus, the application executes an Application Layer Framed transport protocol in user space, which utilises the basic (unreliable) delivery service of UDP. The sequence of events is as follows. The client specifies a JPEG picture file on the server. <p> Therefore, by appropriate choice of ADU, there is nothing in principle preventing this receiver from processing each incoming ADU to completion. This is an essential precondition for effective ILP. We next consider the protocol processing steps in isolation. Description of the ALF transport protocol can be found elsewhere <ref> [3] </ref>.
Reference: [4] <author> Per Gunningberg, Craig Partridge, Teet Sirotkin, Bjorn Victor. </author> <title> Delayed Evaluation of Gigabit Protocols. </title> <booktitle> 2nd MultiG Workshop, </booktitle> <address> Stockholm, </address> <year> 1991. </year>
Reference-contexts: This is facilitated by revealing all essential constraints (such as demultiplex-ing and reassembly) and identifying "atomic" processing loops. 1 Sponsored by CEC DG XIII 2 2.2 Application of ALF/ILP Since the ALF/ILP ideas were proposed, there have been a number of applied experiments. In <ref> [4] </ref> the benefits of ILP are indicated by applying integration to an isolated pipeline of checksum, encryption and and file (FTP protocol) processing. Further development of the ILP concept has occurred in [2]. <p> The client/server interactions are at the transport, presentation and application levels. This entails packet processing, decompression and display, which is all performed in software at the client. 2 This view has been expressed in discussion during the HIPPARCH project, and is also suggested in <ref> [4] </ref> 3 The photo server has been developed under a parallel Task of the HIPPARCH project, which is primarily investigating the network efficiency benefits of ALF [3]. Thus, the application executes an Application Layer Framed transport protocol in user space, which utilises the basic (unreliable) delivery service of UDP. <p> The strategy of a common "final stage" [2], which we have described previously, addresses this control dependency. A simple approach to integration is to perform all layers of protocol processing in a simple "for loop", representing a single read-process-write cycle. This is the approach used in <ref> [4] </ref>. In our case, there are some major transformations performed on the data at certain stages, notably the huffman decode and reverse DCT. Intuitively, these transformations present barriers to a simple "for loop" style of integration. These transformations change the width of the data. They also require non-sequential access patterns.
Reference: [5] <author> Eric Hamilton. </author> <title> JPEG File Interchange Format Version 1.02. </title> <publisher> C-Cube Microsystems, </publisher> <month> Septem-ber </month> <year> 1992. </year>
Reference-contexts: These are transformed into six DCT coefficient blocks, which are in turn quantized and huffman encoded for additional compression <ref> [6, 5] </ref>. The essential encoding/decoding and display steps have been taken from the XV software [7]. XV is structured to decode and display an entire image.
Reference: [6] <author> Gregory Wallace. </author> <title> The JPEG Still Picture Compression Standard Communications of the ACM, </title> <journal> Vol. </journal> <volume> 34, No. 4, </volume> <month> April </month> <year> 1991. </year> <month> 9 </month>
Reference-contexts: These are transformed into six DCT coefficient blocks, which are in turn quantized and huffman encoded for additional compression <ref> [6, 5] </ref>. The essential encoding/decoding and display steps have been taken from the XV software [7]. XV is structured to decode and display an entire image. <p> They are presented in Table 1. We present these steps somewhat mechanistically, i.e. as a sequence of data movements and manipulations. For detailed understanding of the various stages of JPEG compression/decompression the reader is referred to <ref> [6] </ref>. We note in passing that most of these processing steps are generic protocol functions, which may be found individually and/or in various combinations in other application protocol stacks. For example, huffman decoding and reverse DCT are stages in some video decoders [8].
Reference: [7] <author> John Bradley. </author> <title> XV Interactive Image Display for the X Window Systems Version 3.00, </title> <month> April </month> <year> 1993. </year>
Reference-contexts: These are transformed into six DCT coefficient blocks, which are in turn quantized and huffman encoded for additional compression [6, 5]. The essential encoding/decoding and display steps have been taken from the XV software <ref> [7] </ref>. XV is structured to decode and display an entire image. We have modified the software such that the atomic unit of decode and display is the MCU, i.e. each MCU is displayed immediately it is decoded. The MCU is therefore the ADU.
Reference: [8] <author> Atanu Ghosh, Jon Crowcroft, Mark Handley and Michael Fry. </author> <title> Integrated Layer Video Decoding and Application Level Framed Secure Login: General Lessons from Two or Three Very Different Applications. </title> <booktitle> 1st HIPPARCH Workshop, </booktitle> <institution> Sophia Antipolis, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: We note in passing that most of these processing steps are generic protocol functions, which may be found individually and/or in various combinations in other application protocol stacks. For example, huffman decoding and reverse DCT are stages in some video decoders <ref> [8] </ref>. Pixel conversion and dithering are likewise found in other distributed applications, and are therefore generic functions. Each step involves at least one physical read/write of the data. Those steps marked * also transform the data, while steps with ** transform and alter the width of the data unit.
Reference: [9] <author> Sean O'Malley. </author> <title> High Performance Protocol Implementations in the Scout Operating System. </title> <booktitle> 1st HIPPARCH Workshop, </booktitle> <institution> Sophia Antipolis, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Again, the volume of data transfer in the post DCT stage dominates the processing costs. It has been argued that, for modern architectures, the most significant overhead by far is the cost of reading and writing data <ref> [9] </ref>. Our results support a generalisation of that hypothesis to distributed multimedia applications. Nonetheless the abstraction of "computation" that we have used is simplistic. Transformations such as DCT and huffman compression employ a mix of pure processor operations and table lookups.
Reference: [10] <author> Peter Druschel and Larry Peterson. </author> <title> High-Performance Cross-Domain Data Transfers. </title> <type> Report TR-92-11, </type> <institution> University of Arizona, Tucson, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: This prevents the processing of each ADU, from network entry to the top of the protocol stack, in a single loop. To solve this problem requires an integrated buffer management scheme such as proposed in <ref> [10] </ref>, and a system environment to support user-level protocol stacks. Other barriers to integration may include ordering constraints between control and data processing at different layers, and between different layers of data processing. We are able, for example, to inhibit the execution of UDP checksum processing within the operating system.
Reference: [11] <author> Hans Anderson, Anders Linbeck, and Dick Zetterbeg. </author> <title> Video Conferencing: A Study. </title> <type> UTS Report, </type> <month> February </month> <year> 1995. </year> <month> 10 </month>
Reference-contexts: A good example is video encoding and decoding (especially where compression is used) which is commonly performed in software. In this case the end system can be the most critical factor in performance, as measured by throughput and latency <ref> [11] </ref>. This is so 1 for the current generation of high speed networks and processors, and seems likely to remain so for the foreseeable future.
References-found: 11

