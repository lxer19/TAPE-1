URL: http://www.cs.huji.ac.il/papers/IP/CVPR97/gilad-sh.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/CVPR97/index.html
Root-URL: http://www.cs.huji.ac.il
Title: Motion of disturbances: detection and tracking of multi-body non rigid motion  
Author: Gilad Halevy and Daphna Weinshall 
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science, The Hebrew University of Jerusalem  
Abstract: We present a new approach to the tracking of very non rigid patterns of motion, such as water flowing down a stream. The algorithm is based on a "disturbance map," which is obtained by linearly subtracting the temporal average of the previous frames from the new frame. Every local motion creates a disturbance having the form of a wave, with a "head" at the present position of the motion and a historical "tail" that indicates the previous locations of that motion. These disturbances serve as loci of attraction for "tracking particles" that are scattered throughout the image. The algorithm is very fast and can be performed in real time. We provide excellent tracking results on various complex sequences, using both stabilized and moving cameras, showing: a busy ant convoy, waterfalls, rapids and flowing streams, shoppers in a mall, and cars in a traffic intersection. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. H. Nagel, </author> <title> "Formation of an Object Concept by Analysis of Systematic Time Variation in the Optically Perceptible Environment", </title> <journal> CVIP, </journal> <volume> Vol. 7, </volume> <pages> pp. 149-194, </pages> <year> 1978. </year>
Reference-contexts: The basic structure of the disturbance does not depend on the changes in shading or shape that the object undergoes, but only on its motion. (Cf. to <ref> [1] </ref> where such changes were used for figure/ground segmentation.) A disturbance is an abrupt change in grey-levels that appears (and disappears) in a certain region and at a certain time.
Reference: [2] <author> A. Kass, A. Witkin and D. Terzopoulos, "Snakes: </author> <title> Active Contour Modes", </title> <journal> IJCV, </journal> <volume> vol 1(3), </volume> <pages> pp. 321-331, </pages> <year> 1988. </year>
Reference-contexts: The basic assumption is almost always that the shape of the object changes slowly (small deformation), as in the methods based on the occluding contours of objects <ref> [2] </ref>, or methods based on extreme points in the object [3]. Clearly, these approaches are not suitable to handle flowing water (what are 5 the "objects" in this case?), or camouflaged ants where occluding contours cannot be discerned reliably.
Reference: [3] <author> I. Cohen, N. Ayache and P. Sulger, </author> <title> "Tracking Points on Deformable Objects, Using Curvature Information", </title> <booktitle> ECCV 92, </booktitle> <pages> pp. 458-465, </pages> <year> 1992. </year>
Reference-contexts: The basic assumption is almost always that the shape of the object changes slowly (small deformation), as in the methods based on the occluding contours of objects [2], or methods based on extreme points in the object <ref> [3] </ref>. Clearly, these approaches are not suitable to handle flowing water (what are 5 the "objects" in this case?), or camouflaged ants where occluding contours cannot be discerned reliably.
Reference: [4] <author> J. P. Berroir, I. Herlin and I. Cohen,. </author> <title> "Non-Rigid Motion Without Relying on Local Features: </title> ...", <journal> INRIA Repport, </journal> <volume> No. 2684, </volume> <year> 1995. </year>
Reference-contexts: The only methods that are not based on the assumption of slow changes, such as the method described in <ref> [4] </ref>, require a geometric model that is confined to very specific cases.
Reference: [5] <author> D. P. Huttenlocher, J. J. Noh and W. J. Rucklidge, </author> <title> "Tracking Non-Rigid Objects in Complex Scenes", </title> <booktitle> ICCV 93, </booktitle> <pages> pp. 93-101, </pages> <year> 1993. </year>
Reference-contexts: Clearly, these approaches are not suitable to handle flowing water (what are 5 the "objects" in this case?), or camouflaged ants where occluding contours cannot be discerned reliably. Also, an approach like that described in <ref> [5] </ref>, in which the minimum of the Hausdorff distance between prominent points sampled from the frame is sought, requires that the shape of the object changes slowly between consecutive frames, and thus it does not meet our needs.
Reference: [6] <author> H. Applebaum, M. Werman, </author> <title> "The detection of motion in noisy environments using a 3D f* algorithm", </title> <type> PhD thesis, </type> <institution> Hebrew University, </institution> <year> 1995. </year>
Reference-contexts: The basic assumption of such algorithms is that interest points at each frame are provided by an external process (which in many cases includes manual identification or marked points), and the task is to match and follow the points in time. For comparison, we used the algorithm described in <ref> [6] </ref>, which was designed to identify and track the motion of vesicles. The vesicles are interesting objects for tracking: they move at different velocities, some upward and some downward; they appear and vanish, stop, or change direction. The algorithm described in [6] assumes that a list of positions of the vesicles <p> For comparison, we used the algorithm described in <ref> [6] </ref>, which was designed to identify and track the motion of vesicles. The vesicles are interesting objects for tracking: they move at different velocities, some upward and some downward; they appear and vanish, stop, or change direction. The algorithm described in [6] assumes that a list of positions of the vesicles is given in each frame in the sequence, and its purpose is to find trajectories that will connect the points is the best way from the standpoint of least energy (which is a function of inter-point distances in this case). <p> Fig. 7a shows one of the frames from the original movie. The output of <ref> [6] </ref> is shown in Fig. 7b. As far as the eye can see, the results are not so good. For example, we see many cases of transverse motion, which is not observed in the original movie. Moreover, only slow vesicles are tracked, whereas the rapidly moving vesicles are completely ignored. <p> When seen as a movie, the results appear smoother and in better agreement with the visually observed motion. Note that the particles preferred to cling to the rapidly moving vesicles, since the faster the object moves the stronger is its disturbance. a) b) c) points (taken from <ref> [6] </ref>). (c): results using our tracking algorithm: the trajectories seem to be smooth and in the right direction.
Reference: [7] <author> P. J. Burt, R. Hingorani and R. J. Kolezyn-ski, </author> <title> "Mechanism for isolating component patterns in the sequential analysis of multiple motion", </title> <booktitle> IEEE Workshop on Visual Motion, </booktitle> <pages> pp. 187-193, </pages> <year> 1991. </year>
Reference-contexts: In this way maximum overlap between the average and the new frame is always maintained, cf. [9]. The stabilization process is based on a search for affine correspondence between the frames. In <ref> [7] </ref> it was proved that this computation always converges to a result that correctly reflects the most dominant motion in the scene. In most cases it is the motion of the background.
Reference: [8] <author> B. K. P. Horn and B.G. Schunck, </author> <title> "Determining Optical Flow", </title> <booktitle> Art. Intel. </booktitle> <volume> 17, </volume> <pages> pp. 185-203, </pages> <year> 1981. </year>
Reference-contexts: In the following experiments we used the algorithm of Lucas and Kanade [10], which is based on the optical flow equation <ref> [8] </ref>: I x U + I y V + I t = 0. Our algorithm exploits temporal continuity. Conversely, the optical flow computation is instantaneous, and relies only on spatial information within a frame, which is the gradient (I x ; I y ; I t ) at the point.
Reference: [9] <author> M. Irani, B. Rousso and S. Peleg, </author> <title> "Computing Occluding and Transparent Motion", </title> <journal> International Journal of Computer Vision, </journal> <year> 1993. </year>
Reference-contexts: For this reason we employ the opposite approach of repeated registration of the background to the last frame. In this way maximum overlap between the average and the new frame is always maintained, cf. <ref> [9] </ref>. The stabilization process is based on a search for affine correspondence between the frames. In [7] it was proved that this computation always converges to a result that correctly reflects the most dominant motion in the scene. In most cases it is the motion of the background.

References-found: 9

