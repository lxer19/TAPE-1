URL: http://www.isi.edu/~crago/multi.ps
Refering-URL: http://www.isi.edu/~crago/
Root-URL: http://www.isi.edu
Email: carlton@isi.edu  crago@isi.edu  despain@isi.edu  
Title: Application-Architecture Interaction on Shared-Memory Multiprocessors  
Author: Michael Carlton Stephen P. Crago Alvin M. Despain 
Keyword: Performance Evaluation, Shared Memory, Multiprocessor, Multiple-Bus  
Date: January 15, 1996  
Address: 4676 Admiralty Way Marina del Rey, CA 90292-6695 310-822-1511  
Affiliation: USC/Information Sciences Institute  
Abstract: Programmers who need to obtain high performance on their shared-memory multiprocessor applications are already required to modify and sometimes re-write applications. Running low-level simulations allows the programmer to more easily see performance bottlenecks and to measure more characteristics of an application running on an architecture, including characteristics that are impractical for hardware to measure. Low-level simulation is more accurate than high-level simulation and helps prevent unrealistic assumptions from being made and allows characterizations to be made that cannot be made by existing multiprocessor hardware. We describe the Multi-multi shared-memory multiprocessor architecture and show several examples where we determined the bottleneck of an application running on the architecture by using low-level simulation. Performance bottlenecks discovered in simulation of an application on a specific shared-memory multiprocessor are often generalizable to achieve high performance of the application on a wide variety of shared-memory multiprocessors. 
Abstract-found: 1
Intro-found: 1
Reference: [ABC + 95] <author> A. Agarwal, R. Bianchini, D. Chaiken, K. Johnson, D. Kranz, J. Kubiatowicz, B-H. Lim, K. Mackenzie, and D. Yeung. </author> <title> The MIT Alewife Machine: Architecture and Performance. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: The SPLASH-2 paper ignores many artifacts of architecture in the interests of time and space and with the assumption that architects will run their own more detailed simulations. Many shared-memory multiprocessor architectural studies have used the SPLASH benchmark suite, e.g. [LLG + 92], <ref> [ABC + 95] </ref>. Some of these studies modify the benchmarks to improve performance either because they found a bottleneck of the application running on the architecture being evaluated or take advantage of a feature of the architecture.
Reference: [Bel85] <author> C. G. Bell. Multis: </author> <title> A New Class of Multiprocessor Computers. </title> <journal> Science, </journal> <volume> 228 </volume> <pages> 462-467, </pages> <month> April 16 </month> <year> 1985. </year>
Reference-contexts: The buses and the cache coherency protocol are optimized for sharing along one dimension, acting like traditional multis <ref> [Bel85] </ref> in this dimension. By convention, we refer to this dimension as the X dimension and draw it horizontally. Implicit in the assumption that the entire system is cache coherent is the guarantee that cache coherency is provided between buses.
Reference: [Car95] <author> M. Carlton. </author> <title> Multiple-Bus, Scalable, Shared-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: The architecture of the system simulated consists of processing nodes connected through a multidimensional grid of buses. The architecture, called a Multi-multi [CD90], and its associated cache coherency protocol are explained in detail in <ref> [Car95] </ref>; we will summarize them here. 2.1 System Architecture Each node of the multiprocessor consists of a processor, cache and a portion of the global memory, which includes a directory. Each processor node is connected to D buses, where D is the dimensionality of the system. <p> We also ported the ANL macros to work with our system calls. The Multi-multi memory consistency model requires the support of the compiler and programmer <ref> [Car95] </ref>. In particular, the consistency model requires that shared data be locked before being written to, that shared data be allocated in separate cache lines and that locks be allocated in the same memory module as the data they are protecting.
Reference: [CD90] <author> M. Carlton and A. M. Despain. </author> <title> Cache Coherency for a Multi-Multi. </title> <journal> Computer, </journal> <volume> 23(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: The architecture of the system simulated consists of processing nodes connected through a multidimensional grid of buses. The architecture, called a Multi-multi <ref> [CD90] </ref>, and its associated cache coherency protocol are explained in detail in [Car95]; we will summarize them here. 2.1 System Architecture Each node of the multiprocessor consists of a processor, cache and a portion of the global memory, which includes a directory.
Reference: [LLG + 92] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> The Stanford DASH Multiprocessor. </title> <journal> Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The SPLASH-2 paper ignores many artifacts of architecture in the interests of time and space and with the assumption that architects will run their own more detailed simulations. Many shared-memory multiprocessor architectural studies have used the SPLASH benchmark suite, e.g. <ref> [LLG + 92] </ref>, [ABC + 95]. Some of these studies modify the benchmarks to improve performance either because they found a bottleneck of the application running on the architecture being evaluated or take advantage of a feature of the architecture.
Reference: [LO87] <author> E. L. Lusk and R. A. Overbeek. </author> <title> Use of Monitors in FORTRAN: A Tutorial on the Barrier, Self-scheduling DO-Loop, and Askfor Monitors. </title> <type> Technical Report ANL-84-51, Rev. 1, </type> <institution> Argonne National Laboratory, </institution> <month> June </month> <year> 1987. </year>
Reference-contexts: The SPLASH programs used for this study are summarized in Table 1. Each of these are written in C with the Argonne National Labs (ANL) parmacs parallel macros package <ref> [LO87] </ref>. The ANL parmacs package, which must be ported to the architecture being evaluated, provides operations such as spawning a parallel process, allocating global shared memory, locking and unlocking a lock variable, and barrier synchronization.
Reference: [SWG91] <author> J. S. Singh, W-D. Weber, and A. Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared Memory. </title> <type> Technical report, </type> <institution> Stanford University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: Low-level simulations allow us to identify bottlenecks and provide insight into the characteristics of the benchmarks and of our architecture. We've run low-level simulations of several applications from the SPLASH suite <ref> [SWG91] </ref> on a novel multiprocessor architecture built around a multidimensional grid of buses. Our experience simulating benchmarks on an architecture other than the one they were tuned for shows the need for specifically tuning for the given architecture. 1.1 Applications The SPLASH benchmark suite [SWG91] is a well-known set of numeric <p> several applications from the SPLASH suite <ref> [SWG91] </ref> on a novel multiprocessor architecture built around a multidimensional grid of buses. Our experience simulating benchmarks on an architecture other than the one they were tuned for shows the need for specifically tuning for the given architecture. 1.1 Applications The SPLASH benchmark suite [SWG91] is a well-known set of numeric and non-numeric parallel applications commonly used by researchers to evaluate parallel architectures. The SPLASH programs used for this study are summarized in Table 1. Each of these are written in C with the Argonne National Labs (ANL) parmacs parallel macros package [LO87]. <p> Finally, Cholesky executes a Cholesky factorization of a sparse positive definite matrix. We ran Choleksy on an 1806-by-1806 matrix with 30824 non-zero elements in the matrix and 110461 in the factor. 1.2 Related Work The SPLASH benchmark report <ref> [SWG91] </ref> provides descriptions of the applications and describes the performance of the applications on two platforms: the Encore Multimax, a shared-bus multiprocessor with 12 nodes, and a simulator that has a perfect memory system (infinite cache and zero-overhead memory accesses) with short cache lines (4 bytes) to avoid false sharing and
Reference: [WOT + 95] <author> S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. </author> <title> SPLASH-2 Programs: Characterization and Methodological Considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> June </month> <year> 1995. </year> <month> 19 </month>
Reference-contexts: However, we show that a lower level architecture model is necessary to determine key characteristics of the applications which can cause a significant performance degradation on a shared-memory multiprocessor architecture. The SPLASH-2 benchmark report <ref> [WOT + 95] </ref> provides a similar characterization of the SPLASH-2 bench 4 mark suite, which modifies and adds to the SPLASH benchmark suite.
References-found: 8

