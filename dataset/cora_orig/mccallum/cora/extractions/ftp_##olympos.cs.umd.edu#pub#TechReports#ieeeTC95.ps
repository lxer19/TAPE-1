URL: ftp://olympos.cs.umd.edu/pub/TechReports/ieeeTC95.ps
Refering-URL: http://www.cs.umd.edu/~christos/selpapers.html
Root-URL: 
Title: Flexible and Adaptable Buffer Management Techniques for Database Management Systems  
Author: Christos Faloutsos Raymond Ng Timos Sellis 
Note: This research was partially sponsored by the National Science Foundation under Grants DCR-86-16833, IRI- 8719458, IRI-8958546 and IRI-9057573, by DEC, IBM and Bellcore, by NASA under Grant NAS5-31351, by NSERC under Grants STR0134419 and OGPO138055, and by the  Work performed while the author was with the  
Address: College Park, MD 20742  Vancouver, B.C. Canada V6T 1Z2  Zographou 157 73, Athens, Greece  
Affiliation: Department of Computer Science and Institute for Systems Research (ISR) University of Maryland  Department of Computer Science University of British Columbia  Department of Electrical and Computer Engineering Computer Science Division National Technical University of Athens  University of Maryland Institute for Advanced Computer Studies (UMIACS).  Dept. of Comp. Science, Univ. of Maryland.  
Abstract: The problem of buffer management in database management systems is concerned with the efficient main memory allocation and management for answering database queries. Previous works on buffer allocation are based either exclusively on the availability of buffers at runtime or on the access patterns of queries. In this paper, we first propose a unified approach for buffer allocation in which both of these considerations are taken into account. Our approach is based on the notion of marginal gains which specify the expected reduction in page faults by allocating extra buffers to a query. Then, we extend this approach to support adaptable buffer allocation. An adaptable buffer allocation algorithm automatically optimizes itself for the specific query workload. To achieve this adaptability, we propose using run-time information, such as the load of the system, in buffer allocation decisions. Our approach is to use a simple queueing model to predict whether a buffer allocation will improve the performance of the system. Thus, this paper provides a more theoretical basis for buffer allocation. Simulation results show that our methods based on marginal gains and our predictive methods consistently outperform existing allocation strategies. In addition, the predictive methods have the added advantage of adjusting their allocation to changing workloads. Keywords: buffer management, performance analysis, relational databases 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.F. Cardenas. </author> <title> Analysis and Performance of Inverted Data Base Structures, </title> <booktitle> Communications of the ACM (18) 5 (1975). </booktitle>
Reference-contexts: Intuitively, k 0 is the expected number of page accesses that fill all the s buffers. Thus, the top row of the formula corresponds to the case where none of the buffers that have been filled needs to be replaced. This first case uses Cardenas' formula <ref> [1] </ref> which calculates the expected number of distinct pages accessed after k random pages have been selected out of N possible ones with replacement. More accurate results may be obtained with Yao's formula [18], which assumes no replacement.
Reference: [2] <author> H. Chou. </author> <title> Buffer Management of Database Systems, </title> <institution> Computer Sciences Techincal Report 597, University of Wisconsin, Madison (1985). </institution>
Reference-contexts: They propose the DBMIN algorithm that makes allocation equal to the size of the locality set. DBMIN also allows different local replacement policies. Simulation results in <ref> [2, 3] </ref> show that DBMIN outperforms the Hot-Set strategy and the algorithms referred to in the first group. <p> Finally, we present in Section 5 simulation results that compare the performance of 3 our algorithms with DBMIN. 2 Mathematical Models for Relational Database References In this section we first review the taxonomy proposed by Chou and DeWitt <ref> [2, 3] </ref> for classifying reference patterns exhibited by relational database queries. We analyze in detail the major types of references, and present mathematical models and formulas calculating the expected number of page faults using a given number of buffers. <p> These models help to provide formulas for computing marginal gains and predictive estimates in Sections 3 and 4. 2.1 Types of Reference Patterns In <ref> [2, 3] </ref> Chou and DeWitt show how page references of relational database queries can be decomposed into sequences of simple and regular access patterns. Here we focus on three major types of references: random, sequential and looping. A random reference consists of a sequence of random page accesses. <p> The allocation to each relation is determined by the reference pattern as described in the previous section, and each relation uses its own allocated buffers throughout. See <ref> [2] </ref> for a more detailed discussion. In ongoing work, we study how to allocate buffers on a per query basis. Before we describe DBMIN using the general framework outlined in Algorithm 1, let us define a few symbols that are used throughout the rest of this paper. <p> As for the allocation policy, it depends on the type of the reference. For a looping reference, the locality set size is the total number of pages of the loop <ref> [2, pp. 52] </ref>. Since DBMIN requires the entire locality set be allocated [2, pp. 50], i.e. s min = s max = t, where t is the length of the loop 1 . <p> As for the allocation policy, it depends on the type of the reference. For a looping reference, the locality set size is the total number of pages of the loop [2, pp. 52]. Since DBMIN requires the entire locality set be allocated <ref> [2, pp. 50] </ref>, i.e. s min = s max = t, where t is the length of the loop 1 . <p> Since DBMIN requires the entire locality set be allocated [2, pp. 50], i.e. s min = s max = t, where t is the length of the loop 1 . As for a random reference, it is proposed in <ref> [2, 3] </ref> that a random reference may be allocated 1 or b yao buffers where b yao is the Yao estimate on the average number of pages referenced in a series of random record accesses [18]. In practice, the Yao estimates are usually too high for allocation. <p> As a preview, some of our algorithms may also make use of the Yao estimate. But a very important difference is that unlike DBMIN which allocates either 1 or 82 buffers in this example, our algorithms may allocate any buffer within the 1 In <ref> [2] </ref>, Chou remarks that MRU is the best replacement policy for a looping reference under sub-optimal allocation. However, as far as we know, no method is proposed in [2, 3] to allocate sub-optimally. 8 range 1 and 82, depending on conditions such as buffer availability and dynamic workload. <p> However, as far as we know, no method is proposed in <ref> [2, 3] </ref> to allocate sub-optimally. 8 range 1 and 82, depending on conditions such as buffer availability and dynamic workload. Finally, for a sequential reference, DBMIN specifies s min = s max = 1. <p> For instance, EDU-o stands for the algorithm adopting the EDU admission policy and the optimistic allocation policy. 5 Simulation Results In this section we present simulation results on the performance of MG-x-y and the adaptable methods in a multiuser environment. As Chou and DeWitt have shown in <ref> [2, 3] </ref> that DBMIN performs better than the Hot-Set algorithm, First-In-First-Out, Clock, Least-Recently-Used and Working-Set, we only compare our algorithms with DBMIN. 5.1 Details of Simulation In order to make direct comparison with DBMIN, we use the simulation program Chou and DeWitt used for DBMIN, and we experiment with the same <p> Table 5 summarizes the details of the queries that are chosen to represent varying degrees of demand on CPU, disk and memory <ref> [2, 3] </ref>. Table 6 and Table 7 show respectively the details of the relations and the query mixes we used. In the simulation, the number of concurrent queries varies from 2 to 16 or 24. <p> See <ref> [2, 3] </ref> for more details. 5.2 Effectiveness of Allocations to Looping References The first mix of queries consists of 70% of queries of type VI (looping references) and 10% each of queries of types I, II and IV (sequential, random and random references respectively). <p> Figure 5 shows the throughputs of DBMIN, MG-100-12, MG-50-y's and the adaptable algorithms running with 4 Besides buffer management, concurrency control and transaction management is another important factor affecting the performance of the whole database system. While the simulation package does not consider transaction management, see <ref> [2] </ref> for a discussion on how the transaction and lock manager can be integrated with a buffer manager using DBMIN. <p> The major reason why the pessimistic approach gives poor performance is that the approach is being too aggressive in allowing too many queries to get into the system. Note that to obtain the throughput values, we run our simulation package repeatedly until the values stabilized. <ref> [2] </ref> discusses how the simulation package can be used to obtain results within a specified confidence interval. Figure 5 also includes the throughputs of the "ideal" algorithm that has infinitely many buffers and can therefore support any number of concurrent queries requiring any number of buffers. <p> If the page is found, the page is given to the query, without changing the original ownership of the page. See <ref> [2, 3] </ref> for more details. To examine the effect of data sharing on the relative performance of our algorithms relative to DBMIN, we also run simulations with varying degrees of data sharing.
Reference: [3] <author> H. Chou and D. DeWitt. </author> <title> An Evaluation of Buffer Management Strategies for Relational Database Systems, </title> <booktitle> Proc. of the 11th Intern. Conference on Very Large Data Bases (1985). </booktitle>
Reference-contexts: However, as they focus on adapting memory management techniques used in operating systems to database systems, they fail to take advantage of the specific access patterns exhibited by relational database queries, and their performance is not satisfactory <ref> [3] </ref>. Allocation strategies in the second group consider exclusively the demand factor, or more specifically the access patterns of queries. <p> This approach of buffer allocation is culminated in the work of Chou and DeWitt <ref> [3] </ref>. <p> They propose the DBMIN algorithm that makes allocation equal to the size of the locality set. DBMIN also allows different local replacement policies. Simulation results in <ref> [2, 3] </ref> show that DBMIN outperforms the Hot-Set strategy and the algorithms referred to in the first group. <p> Finally, we present in Section 5 simulation results that compare the performance of 3 our algorithms with DBMIN. 2 Mathematical Models for Relational Database References In this section we first review the taxonomy proposed by Chou and DeWitt <ref> [2, 3] </ref> for classifying reference patterns exhibited by relational database queries. We analyze in detail the major types of references, and present mathematical models and formulas calculating the expected number of page faults using a given number of buffers. <p> These models help to provide formulas for computing marginal gains and predictive estimates in Sections 3 and 4. 2.1 Types of Reference Patterns In <ref> [2, 3] </ref> Chou and DeWitt show how page references of relational database queries can be decomposed into sequences of simple and regular access patterns. Here we focus on three major types of references: random, sequential and looping. A random reference consists of a sequence of random page accesses. <p> Since DBMIN requires the entire locality set be allocated [2, pp. 50], i.e. s min = s max = t, where t is the length of the loop 1 . As for a random reference, it is proposed in <ref> [2, 3] </ref> that a random reference may be allocated 1 or b yao buffers where b yao is the Yao estimate on the average number of pages referenced in a series of random record accesses [18]. In practice, the Yao estimates are usually too high for allocation. <p> However, as far as we know, no method is proposed in <ref> [2, 3] </ref> to allocate sub-optimally. 8 range 1 and 82, depending on conditions such as buffer availability and dynamic workload. Finally, for a sequential reference, DBMIN specifies s min = s max = 1. <p> For instance, EDU-o stands for the algorithm adopting the EDU admission policy and the optimistic allocation policy. 5 Simulation Results In this section we present simulation results on the performance of MG-x-y and the adaptable methods in a multiuser environment. As Chou and DeWitt have shown in <ref> [2, 3] </ref> that DBMIN performs better than the Hot-Set algorithm, First-In-First-Out, Clock, Least-Recently-Used and Working-Set, we only compare our algorithms with DBMIN. 5.1 Details of Simulation In order to make direct comparison with DBMIN, we use the simulation program Chou and DeWitt used for DBMIN, and we experiment with the same <p> Table 5 summarizes the details of the queries that are chosen to represent varying degrees of demand on CPU, disk and memory <ref> [2, 3] </ref>. Table 6 and Table 7 show respectively the details of the relations and the query mixes we used. In the simulation, the number of concurrent queries varies from 2 to 16 or 24. <p> See <ref> [2, 3] </ref> for more details. 5.2 Effectiveness of Allocations to Looping References The first mix of queries consists of 70% of queries of type VI (looping references) and 10% each of queries of types I, II and IV (sequential, random and random references respectively). <p> If the page is found, the page is given to the query, without changing the original ownership of the page. See <ref> [2, 3] </ref> for more details. To examine the effect of data sharing on the relative performance of our algorithms relative to DBMIN, we also run simulations with varying degrees of data sharing.
Reference: [4] <author> S. Christodoulakis. </author> <title> Implication of Certain Assumptions in Data Base Performance Evaluation, </title> <booktitle> ACM Transactions on Database Systems (9) 2 (1984). </booktitle>
Reference-contexts: More accurate results may be obtained with Yao's formula [18], which assumes no replacement. All these formulas make the uniformity assumption; its effects are discussed in <ref> [4] </ref>. The second row corresponds to the case when local replacement has occurred.
Reference: [5] <author> D. Cornell and P. Yu. </author> <title> Integration of Buffer Management and Query Optimization in Relational Database Environment, </title> <booktitle> Proc. 15th Intern. Conference on Very Large Data Bases (1989). </booktitle>
Reference-contexts: They include the proposal by Kaplan [8] on the implementation of INGRES [16], the Hot-Set model designed by Sacca and Schkolnick [13, 14], and the strategy used by Cornell and Yu <ref> [5] </ref> in the integration of buffer management with query optimization. This approach of buffer allocation is culminated in the work of Chou and DeWitt [3]. <p> In ongoing research, we are investigating how to extend our predictors to systems with multiple disks, and how to set up analytic models for references with data sharing. We are also studying whether the flexible and predictor approach can be incorporated into the framework proposed by Cornell and Yu <ref> [5] </ref>, in order to improve the quality of query plans generated by a query optimizer. Finally, we are interested in deriving formulas for computing marginal gains of more complex queries like sort-merge joins. Acknowledgements. We would like to thank H. Chou and D.
Reference: [6] <author> W. Effelsberg and T. Haerder. </author> <title> Principles of Database Buffer Management, </title> <booktitle> ACM Transactions on Database Systems (9) 4 (1984). </booktitle>
Reference-contexts: Based on these factors, previous proposals on buffer allocation can be classified into the following groups, as summarized in Table 1. Allocation algorithms in the first group consider only the buffer availability factor. They include variations of First-In-First-Out (FIFO), Random, Least-Recently-Used (LRU), Clock, and Working-Set <ref> [6, 10, 15] </ref>. However, as they focus on adapting memory management techniques used in operating systems to database systems, they fail to take advantage of the specific access patterns exhibited by relational database queries, and their performance is not satisfactory [3].
Reference: [7] <author> C. Faloutsos, R. Ng and T. Sellis. </author> <title> Predictive Load Control for Flexible Buffer Allocation, </title> <booktitle> Proc. 17th Intern. Conference on Very Large Data Bases, </booktitle> <pages> pp 265-274 (1991). </pages>
Reference: [8] <author> J. Kaplan. </author> <title> Buffer Management Policies in a Database Environment, </title> <type> Master Thesis, </type> <institution> University of California, Berkeley (1980). </institution>
Reference-contexts: Allocation strategies in the second group consider exclusively the demand factor, or more specifically the access patterns of queries. They include the proposal by Kaplan <ref> [8] </ref> on the implementation of INGRES [16], the Hot-Set model designed by Sacca and Schkolnick [13, 14], and the strategy used by Cornell and Yu [5] in the integration of buffer management with query optimization. This approach of buffer allocation is culminated in the work of Chou and DeWitt [3].
Reference: [9] <author> E. Kauder. </author> <title> History of Marginal Utility Theory, </title> <publisher> Princeton University Press (1965). </publisher>
Reference-contexts: These problems lead us to the development of the notion of marginal gains and flexible buffer allocation algorithms MG-x-y to be discussed next. 3.2 Marginal Gains The concepts of marginal gain and marginal utility have been widely used in ecomonics theory since the 18th century <ref> [9] </ref>. Here we apply the approach to database buffer allocation.
Reference: [10] <author> T. Lang, C. Wood and E. Fernandez. </author> <title> Database Buffer Paging in Virtual Storage Systems, </title> <booktitle> ACM Transactions on Database Systems (2) 4 (1977). </booktitle>
Reference-contexts: Based on these factors, previous proposals on buffer allocation can be classified into the following groups, as summarized in Table 1. Allocation algorithms in the first group consider only the buffer availability factor. They include variations of First-In-First-Out (FIFO), Random, Least-Recently-Used (LRU), Clock, and Working-Set <ref> [6, 10, 15] </ref>. However, as they focus on adapting memory management techniques used in operating systems to database systems, they fail to take advantage of the specific access patterns exhibited by relational database queries, and their performance is not satisfactory [3].
Reference: [11] <author> R. Mattson, J. Gecsei, D. Slutz and I. Traiger. </author> <title> Evaluation Techniques for Storage Hierarchies, </title> <journal> IBM Systems Journal (9) 2 (1970). </journal> <volume> 28 </volume>
Reference-contexts: The key observation is that for a looping reference, MRU is identical to the policy which looks ahead and keeps the pages that 6 will be used in the most immediate future (cf. the table in the example below). Then a well-known result by Mattson et al <ref> [11] </ref> for optimal page replacement in operating systems can be applied to show the optimality of MRU. Thus, in this paper we only present the analysis for MRU, which is best explained by an example.
Reference: [12] <author> R. Ng, C. Faloutsos and T. Sellis. </author> <title> Flexible Buffer Allocation based on Marginal Gains, </title> <booktitle> Proc. ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pp 387-396 (1991). </pages>
Reference: [13] <author> G. Sacca and M. Schkolnick. </author> <title> A Mechanism for Managing the Buffer Pool in a Relational Database System using the Hot Set Model, </title> <booktitle> Proc. 8th Intern. Conference on Very Large Data Bases (1982). </booktitle>
Reference-contexts: Allocation strategies in the second group consider exclusively the demand factor, or more specifically the access patterns of queries. They include the proposal by Kaplan [8] on the implementation of INGRES [16], the Hot-Set model designed by Sacca and Schkolnick <ref> [13, 14] </ref>, and the strategy used by Cornell and Yu [5] in the integration of buffer management with query optimization. This approach of buffer allocation is culminated in the work of Chou and DeWitt [3].
Reference: [14] <author> G. Sacca and M. Schkolnick. </author> <title> Buffer Management in Relational Database Systems, </title> <booktitle> ACM Transactions on Database Systems (11) 4 (1986). </booktitle>
Reference-contexts: Allocation strategies in the second group consider exclusively the demand factor, or more specifically the access patterns of queries. They include the proposal by Kaplan [8] on the implementation of INGRES [16], the Hot-Set model designed by Sacca and Schkolnick <ref> [13, 14] </ref>, and the strategy used by Cornell and Yu [5] in the integration of buffer management with query optimization. This approach of buffer allocation is culminated in the work of Chou and DeWitt [3].
Reference: [15] <author> S. Sherman and R. Brice. </author> <title> Performance of a Database Manager in a Virtual Memory System, </title> <booktitle> ACM Transactions on Database Systems (1) 4 (1976). </booktitle>
Reference-contexts: Based on these factors, previous proposals on buffer allocation can be classified into the following groups, as summarized in Table 1. Allocation algorithms in the first group consider only the buffer availability factor. They include variations of First-In-First-Out (FIFO), Random, Least-Recently-Used (LRU), Clock, and Working-Set <ref> [6, 10, 15] </ref>. However, as they focus on adapting memory management techniques used in operating systems to database systems, they fail to take advantage of the specific access patterns exhibited by relational database queries, and their performance is not satisfactory [3].
Reference: [16] <author> M. Stonebraker, E. Wong and P. Kreps. </author> <title> The Design and Implementation of INGRES, </title> <booktitle> ACM Transactions on Database Systems (1) 3 (1976). </booktitle>
Reference-contexts: Allocation strategies in the second group consider exclusively the demand factor, or more specifically the access patterns of queries. They include the proposal by Kaplan [8] on the implementation of INGRES <ref> [16] </ref>, the Hot-Set model designed by Sacca and Schkolnick [13, 14], and the strategy used by Cornell and Yu [5] in the integration of buffer management with query optimization. This approach of buffer allocation is culminated in the work of Chou and DeWitt [3].
Reference: [17] <author> K.S. Trivedi. </author> <title> Probability and Statistics with Reliability, Queuing and Computer Science Applications, </title> <publisher> Prentice Hall, Inc., </publisher> <address> Englewood Cliffs, NJ (1982). </address>
Reference-contexts: The general solution to such a network can be calculated; see for example <ref> [17, pp. 451-452] </ref>. It involves an n-class model with each job being in a class of its own. But while it gives accurate performance measures such as throughput and utilizations, this solution is expensive to compute, since it requires exponential time on the number of classes. <p> A multiple disk system would introduce the issue of data placement; once this has been decided, we could extend our queueing model to have multiple disks. Queueing systems with multiple servers are studied in <ref> [17] </ref>. 4.3 Predictor TP Since our ultimate performance measure is the throughput of the system, a natural predictor is to estimate the throughput directly. <p> To implement the above policy, we provide formulas to compute the throughput. The solution to the single class model is given in <ref> [17] </ref>: T P = U D =T D : (9) U D is the utilization of the disk given by: U D = n+1 1 where is the ratio of the disk load versus the CPU load = T D =T C : (11) To derive the average loads T C <p> We only need this approximation to calculate the disk utilization U D . Using the exact n-class model <ref> [17] </ref>, we find out that the geometric averages give a better approximation to the the disk utilization. Thus, the average CPU and disk loads are given by: T C = n q Q n q Q n i=1 T D;i .
Reference: [18] <author> S. Yao. </author> <title> Approximating Block Accesses in Database Organizations, </title> <booktitle> Communications of the ACM (20) 4 (1977). </booktitle> <pages> 29 </pages>
Reference-contexts: This first case uses Cardenas' formula [1] which calculates the expected number of distinct pages accessed after k random pages have been selected out of N possible ones with replacement. More accurate results may be obtained with Yao's formula <ref> [18] </ref>, which assumes no replacement. All these formulas make the uniformity assumption; its effects are discussed in [4]. The second row corresponds to the case when local replacement has occurred. <p> As for a random reference, it is proposed in [2, 3] that a random reference may be allocated 1 or b yao buffers where b yao is the Yao estimate on the average number of pages referenced in a series of random record accesses <ref> [18] </ref>. In practice, the Yao estimates are usually too high for allocation. For example, for a blocking factor of 5, the Yao estimate of accessing 100 records of a 1000-record relation is 82 pages.
References-found: 18

