URL: http://www.cs.unc.edu/~anderson/papers/rtss97.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: Wait-free Object-Sharing Schemes for Real-Time Uniprocessors and Multiprocessors  
Author: James H. Anderson, Rohit Jain, and Srikanth Ramamurthy 
Address: Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science, University of North Carolina,  
Abstract: Several new wait-free object-sharing schemes for real-time uniprocessors and multiprocessors are presented. These schemes have characteristics in common with the priority inheritance and priority ceiling protocols, but are nonblocking and implemented at the user level. In total, six new object-sharing schemes are proposed: two for unipro-cessors and four for multiprocessors. Breakdown utilization experiments are presented that show that the multiprocessor schemes entail less overhead than lock-based schemes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> Universal Constructions for Multi-Object Operations, </title> <booktitle> Proc. of the 14th ACM Symp. on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 184-193. </pages>
Reference-contexts: Par [tid]&gt;subop := NIL; 29: Par [tid]&gt;rv := 0; 20: Phase [tid] := 0 procedure Insert (key: keytype; val: valtype) 44: new := nodealloc (); 45: fl new := (key; val; NIL) ; 46: Initialize (i); 47: Par [tid]&gt;node := new; 48: Par [tid]&gt;subop [0] := Findpos; 49: Par [tid]&gt;subop <ref> [1] </ref> := Ins; 50: Par [tid]&gt;key := key; 51: Access Obj () procedure Help (tid: 1::N ) 10: ph := Phase [tid]; 11: while ph 6= DONE do 12: nextph := Par [tid]&gt;subop [ph](tid; ph); 13: CAS (&Phase [tid];ph; nextph); 14: ph := Phase [tid] od procedure Search (key: keytype) returns <p> (tid: 1::N ) 10: ph := Phase [tid]; 11: while ph 6= DONE do 12: nextph := Par [tid]&gt;subop [ph](tid; ph); 13: CAS (&Phase [tid];ph; nextph); 14: ph := Phase [tid] od procedure Search (key: keytype) returns phtype 31: Initialize (i); 32: Par [tid]&gt;subop [0] := Findpos; 33: Par [tid]&gt;subop <ref> [1] </ref> := Sch; 34: Par [tid]&gt;key := key; 35: Access Obj (); 36: return (Par [tid]&gt;rv) procedure Ins (tid: 1::N ; ph: phtype) returns phtype 52: pred := Par [tid]&gt;pred; 53: nextp := pred&gt;next; 54: new := Par [tid]&gt;node; 55: nextkey := nextp&gt;key; 56: if nextkey 6= Par [tid]&gt;key then 57: <p> Par [tid]&gt;key; 39: nextkey := pred&gt;next&gt;key; 40: if key = nextkey then 41: CCAS (&Phase [tid]; ph; &(Par [tid]&gt;rv); 0; 1) 42: else CCAS (&Phase [tid]; ph; &(Par [tid]&gt;rv); 0; 2) 43: return DONE procedure Delete (key: keytype) 60: Initialize (i); 61: Par [tid]&gt;subop [0] := Findpos; 62: Par [tid]&gt;subop <ref> [1] </ref> := Del 1; 63: Par [tid]&gt;subop [2] := Del 2; 64: Par [tid]&gt;key := key; 65: Access Obj () procedure Del 1 (tid: 1::N ; ph: phtype) returns phtype 66: pred := Par [tid]&gt;pred; 67: key := Par [tid]&gt;key; 68: nextp := pred&gt;next; 69: nextkey := nextp&gt;key; 70: nextnextp :=
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> Universal Constructions for Large Objects, </title> <booktitle> Proc. of the Ninth International Workshop on Distributed Algorithms, Lecture Notes in Computer Science 972, </booktitle> <year> 1995, </year> <pages> pp. 168-182. </pages>
Reference-contexts: if key = nextkey then 41: CCAS (&Phase [tid]; ph; &(Par [tid]&gt;rv); 0; 1) 42: else CCAS (&Phase [tid]; ph; &(Par [tid]&gt;rv); 0; 2) 43: return DONE procedure Delete (key: keytype) 60: Initialize (i); 61: Par [tid]&gt;subop [0] := Findpos; 62: Par [tid]&gt;subop [1] := Del 1; 63: Par [tid]&gt;subop <ref> [2] </ref> := Del 2; 64: Par [tid]&gt;key := key; 65: Access Obj () procedure Del 1 (tid: 1::N ; ph: phtype) returns phtype 66: pred := Par [tid]&gt;pred; 67: key := Par [tid]&gt;key; 68: nextp := pred&gt;next; 69: nextkey := nextp&gt;key; 70: nextnextp := nextp&gt;next; 71: if nextkey = key then
Reference: [3] <author> J. Anderson and S. Ramamurthy, </author> <title> A Framework for Implementing Objects and Scheduling Tasks in Lock-Free Real-Time Systems, </title> <booktitle> Proc. of the 17th IEEE Real-Time Systems Symp., </booktitle> <year> 1996, </year> <pages> pp. 94-105. </pages>
Reference-contexts: the interval [1; t). (The interval [0; 1) is excluded because work cannot be wasted unless some task has executed for at least one time unit.) A much tighter bound on this term (in both this and later theorems) can be obtained by means of linear programming, as described in <ref> [3] </ref>.
Reference: [4] <author> J. Anderson, S. Ramamurthy, M. Moir, and K. Jef-fay, </author> <title> Lock-Free Transactions for Real-Time Systems, </title> <booktitle> Proc. of the First International Workshop on Real-Time Databases: Issues & Applications, </booktitle> <year> 1996, </year> <pages> pp. 107-114. </pages>
Reference: [5] <author> J. Anderson, S. Ramamurthy, and R. </author> <title> Jain Implementing Wait-Free Objects on Priority-Based Systems, </title> <booktitle> Proc. of the 16th ACM Symp. on Principles of Distributed Computing, </booktitle> <year> 1997, </year> <pages> pp. 229-238. </pages>
Reference-contexts: In practice, it is important to apply object-specific optimizations to improve performance. For example, the list implementation just presented can be optimized to remove many of the CCAS operations. Such an implementation was recently presented by us in <ref> [5] </ref>. Although counting lines of code is a very crude way of measuring performance, the optimized list implementation requires only 51 lines of code, compared to 80 lines of code in the implementation presented above.
Reference: [6] <author> J. Anderson, S. Ramamurthy, and K. Jeffay, </author> <title> Real-Time Computing with Lock-Free Shared Objects, </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 15(2), </volume> <month> May </month> <year> 1997, </year> <pages> pp. 134-165. </pages>
Reference-contexts: In previous experimental work we have done, we have found that lock-free and wait-free object implementations that do not rely on state-copying give rise to sequential operation costs that are comparable to sequential operation costs in lock-based schemes <ref> [6] </ref>. The wait-free schemes considered in this paper do not rely on state-copying, and with suitable optimizations should perform very well. In our experiments, object-access costs were randomly generated assuming a normal distribution with mean and standard deviation of 50 and 30 time units, respectively. Only single-object accesses were considered.
Reference: [7] <author> R. Bettati, </author> <title> End-to-End Scheduling to Meet Deadlines in Distributed Systems, </title> <type> Ph.D. Thesis, </type> <institution> Computer Science Department, University of Illinois, </institution> <month> March </month> <year> 1994. </year>
Reference: [8] <author> M. Herlihy, </author> <title> A Methodology for Implementing Highly Concurrent Data Objects, </title> <journal> ACM Trans. on Progam. Languages and Systems, </journal> <volume> 15(5), </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference: [9] <author> G. Peterson, </author> <title> Concurrent Reading While Writing, </title> <journal> ACM Trans. on Progam. Languages and Systems, </journal> <volume> 5(1), </volume> <year> 1983, </year> <pages> pp. 46-55. </pages>
Reference: [10] <author> R. Rajkumar, </author> <title> Real-Time Synchronization Protocols for Shared Memory Multiprocessors, </title> <booktitle> Proc. of the International Conference on Distributed Computing Systems, </booktitle> <year> 1990, </year> <pages> pp. 116-123. </pages>
Reference-contexts: This is why G i is used in the third term. 4. Experimental Results In this section, we present results from experiments conducted to compare the performance of the multiprocessor priority ceiling protocol (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. <p> Results In this section, we present results from experiments conducted to compare the performance of the multiprocessor priority ceiling protocol (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. We have also conducted similar experiments to compare our schemes with the distributed priority ceiling protocol (DPCP) [10, 11, 12], and the results from those experiments are similar to those reported here for the MPCP. <p> (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. We have also conducted similar experiments to compare our schemes with the distributed priority ceiling protocol (DPCP) [10, 11, 12], and the results from those experiments are similar to those reported here for the MPCP.
Reference: [11] <author> R. Rajkumar, </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach, </title> <publisher> Kluwer Academic Publications, </publisher> <year> 1991. </year>
Reference-contexts: a set of tasks is schedulable if the following condition holds for each task T i . h9t : 0 &lt; t p i : j=1 t m P i1 l p j w ti It is interesting to compare the condition above with that given for the PCP in <ref> [11, 13] </ref>. The first term in the condition in Theorem 1 is also present in the PCP condition. The second term is replaced by a blocking term in the PCP condition. (In fact, these terms arise for precisely the same reasons.) The main difference lies in the third term. <p> scheme with RM scheduling, a set of tasks is schedulable if the following condition holds for each task T i . h9t : 0 &lt; t p i : j=1 t m P + j=1 t1 m The above condition is very similar to that given for the PIP in <ref> [11, 13] </ref>. As mentioned before, the main difference lies in the fact that in the IHI scheme, wasted computation may result from repeated helping, whereas in the PIP, costs associated with kernel calls are incurred. 3. <p> Otherwise, if there are other announced operations on other processors with priority greater than T j 's but less than T i 's, then T i may be delayed unnecessarily. This is very similar to priority inheritance in lock-based object-sharing schemes <ref> [11] </ref>. When using priority helping to implement an object shared across P processors, advancing the help counter requires an O (P ) scan of all announce variables. <p> This is why G i is used in the third term. 4. Experimental Results In this section, we present results from experiments conducted to compare the performance of the multiprocessor priority ceiling protocol (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. <p> Results In this section, we present results from experiments conducted to compare the performance of the multiprocessor priority ceiling protocol (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. We have also conducted similar experiments to compare our schemes with the distributed priority ceiling protocol (DPCP) [10, 11, 12], and the results from those experiments are similar to those reported here for the MPCP. <p> (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. We have also conducted similar experiments to compare our schemes with the distributed priority ceiling protocol (DPCP) [10, 11, 12], and the results from those experiments are similar to those reported here for the MPCP.
Reference: [12] <author> R. Rajkumar, L. Sha, and J. Lehoczky, </author> <title> Real-Time Synchronization Protocols for Multiprocessors, </title> <booktitle> Proc. of the Nineth IEEE Real-Time Systems Symp., </booktitle> <year> 1988, </year> <pages> pp. 259-269. </pages>
Reference-contexts: This is why G i is used in the third term. 4. Experimental Results In this section, we present results from experiments conducted to compare the performance of the multiprocessor priority ceiling protocol (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. <p> Results In this section, we present results from experiments conducted to compare the performance of the multiprocessor priority ceiling protocol (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. We have also conducted similar experiments to compare our schemes with the distributed priority ceiling protocol (DPCP) [10, 11, 12], and the results from those experiments are similar to those reported here for the MPCP. <p> (MPCP) <ref> [10, 11, 12] </ref> with that of the four wait-free multiprocessor schemes presented in this paper. The comparison is based on RM scheduling conditions given in this paper and in [10, 11, 12]. We have also conducted similar experiments to compare our schemes with the distributed priority ceiling protocol (DPCP) [10, 11, 12], and the results from those experiments are similar to those reported here for the MPCP.
Reference: [13] <author> L. Sha, R. Rajkumar, and J. Lehoczky, </author> <title> Priority Inheritance Protocols: An Approach to Real-Time System Synchronization, </title> <journal> IEEE Trans. on Computers, </journal> <volume> 39(9), </volume> <year> 1990, </year> <pages> pp. 1175-1185. </pages>
Reference-contexts: However, as discussed in Section 5, the algorithms that we present can be used to implement multi-object operations. If all operations are single-object operations, then the priority ceiling of an operation on an object is simply the priority of the highest-priority task that accesses that object <ref> [13] </ref>. In the IHC scheme, one Ann variable is used for all implemented objects. <p> a set of tasks is schedulable if the following condition holds for each task T i . h9t : 0 &lt; t p i : j=1 t m P i1 l p j w ti It is interesting to compare the condition above with that given for the PCP in <ref> [11, 13] </ref>. The first term in the condition in Theorem 1 is also present in the PCP condition. The second term is replaced by a blocking term in the PCP condition. (In fact, these terms arise for precisely the same reasons.) The main difference lies in the third term. <p> scheme with RM scheduling, a set of tasks is schedulable if the following condition holds for each task T i . h9t : 0 &lt; t p i : j=1 t m P + j=1 t1 m The above condition is very similar to that given for the PIP in <ref> [11, 13] </ref>. As mentioned before, the main difference lies in the fact that in the IHI scheme, wasted computation may result from repeated helping, whereas in the PIP, costs associated with kernel calls are incurred. 3.
Reference: [14] <author> J. Sun, R. Bettati, and J. W.-S. Liu, </author> <title> Using End-to-End Scheduling Approach to Schedule Tasks with Shared Resources in Multiprocessor Systems, </title> <booktitle> Proc. of the 11th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <year> 1994. </year>
References-found: 14

