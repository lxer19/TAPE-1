URL: http://www.dcs.ex.ac.uk/research/neural/pub/paper14.ps
Refering-URL: http://www.dcs.ex.ac.uk/research/neural/pub/pub.htm
Root-URL: http://www.dcs.ex.ac.uk
Title: Distinct Failure Diversity in Multiversion Software  
Author: Derek Partridge Wojtek Krzanowski 
Keyword: Index Terms Coincident failure, software diversity, distinct-failure diversity, multiversion programming, software faults, software reliability, N  
Note: version programming  
Date: August 8, 1997  
Address: Exeter, U.K.  
Affiliation: University of  
Abstract: In earlier studies of multiversion programming, both empirical and analytical, emphasis switched from notions of independence to one of minimization of coincident failure. We show that neither independence of failure, nor lack of coincident failure are the single important properties. Indeed, an N-version system may deliver an optimal performance (under some voting strategy) even when the incidence of coincident failure is arbitrarily high. The key notion that this study contributes is one of distinct different failure, and hence distinct-failure diversity. The important property is not whether versions fail on the same input so much as whether they fail in the same way. If the failures of an N-version system (on some input) are dispersed over a set of distinct alternative outcomes, then this (hitherto unacknowledged) aspect of diversity may be exploited to substantially enhance system reliability. We propose measures for the traditional coincident-failure diversity (CFD), for the new distinct failure-diversity (DFD), and for an integrated overall diversity (OD). We show how the DFD property of an N-version system may permit substantial performance enhancement despite maximum coincident failure. We demonstrate the extra practical benefits that accrue from an exploitation of this new treatment of multiversion software systems by application to previously published examples. Finally, we suggest how this new aspect of diversity (as well as several others) can be exploited to cast the potential for multiversion software engineering in a much more positive light than was produced by the previous studies which demonstrated the necessary absence of independent failure behaviour. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. M. Adams and A. Taha, </author> <title> "An experiment in software redundancy with diverse methodologies", </title> <booktitle> Proc. 25th Hawaii Internat. Conf. on System Sciences, </booktitle> <month> January, </month> <pages> pp. 83-90, </pages> <year> 1992. </year> <month> 25 </month>
Reference-contexts: But the results of several experiments <ref> [4, 1, 2] </ref> do not provide support for this negative prognostication. In this paper we develop an argument to reconcile these conflicting results. <p> n c ! 6 Empirical studies We illustrate the significance of distinct-failure diversity by drawing on results from two, rather different, previously published studies of multiversion software systems. 6.1 Previous results on the LI problem As part of an empirical study of the Littlewood and Miller model, Adams and Taha <ref> [1] </ref> used the LI problem (specified in, and previously studied by Knight and Leveson [8,5]). They arranged for the independent development of implementations of this problem using two implementation target languages, Prolog and Modula2.
Reference: 2. <author> A. Avizienis, M. R. Lyu and W. Schutz, </author> <title> "In search of effective di-versity: a six-language study of fault-tolerant flight control software", </title> <booktitle> Dig. 18th Ann. Int. Symp. Fault-Tolerant Computing, </booktitle> <month> June, </month> <pages> pp. 15-22, </pages> <year> 1988. </year>
Reference-contexts: But the results of several experiments <ref> [4, 1, 2] </ref> do not provide support for this negative prognostication. In this paper we develop an argument to reconcile these conflicting results.
Reference: 3. <author> A. Bhattacharyya, </author> <title> "On a measure of divergence between two multinomial populations," </title> <journal> Sankhya A, </journal> <volume> vol. 7, </volume> <pages> pp. 401-406, </pages> <year> 1946. </year>
Reference-contexts: These are both just frequency distributions, and a useful measure of similarity (or `affinity') between them <ref> [3] </ref> is d = i=1 a i fi n c X r m 14 Providing the a i are arranged appropriately, the `most diverse' frequency distribution will always have the value d max = 1, while the `least diverse' (0; : : : ; 0; n n ) will always have
Reference: 4. <author> P. G. Bishop, D. G. Esp, M. Barnes, P. Humphreys, G. Dahll and J. Lahti, </author> <title> "PODS | A project on diverse software," </title> <journal> IEEE Trans. on Software Eng., </journal> <volume> vol. SE-12, no. 9, </volume> <pages> pp. 929-940, </pages> <year> 1986. </year>
Reference-contexts: But the results of several experiments <ref> [4, 1, 2] </ref> do not provide support for this negative prognostication. In this paper we develop an argument to reconcile these conflicting results.
Reference: 5. <author> S. S. Brilliant, J. C. Knight and N. G. Leveson, </author> <title> "Analysis of faults in an N-version software experiment," </title> <journal> IEEE Trans. on Software Eng., </journal> <volume> vol. 16, no. 2, </volume> <pages> pp. 238-247, </pages> <year> 1990. </year>
Reference-contexts: However, the basis on which this redundancy is expected to provide enhanced reliability has been consistently oversimplified. It is not simply independence of failure (as <ref> [5] </ref> assert), nor diversity with low probability of simultaneous version failure (as [10] imply) that is the basis for system reliability improvement. It is a more complex property, which may involve these simpler properties, whose exact composition is dependent upon the particular decision strategy employed. <p> This outcome is due to variation in difficulty of the inputs. If some inputs are harder than others (as is inevitably the case), then more failures are likely to occur on these inputs, no matter what version (or versions) are chosen. Brilliant, Knight and Leveson <ref> [5] </ref> similarly work from the standpoint that "The amount of reliability improvement achieved [by majority voting in an N-version system] is determined by the degree of independence of the failures of the versions" (p. 238 citing [7] as the source | our emphasis). <p> But they then test for, and base their conclusions on notions of lack of independence or coincident failure (i.e. failure in the same input) only. And a follow-up study focuses exclusively on the minimization of coincident failure <ref> [5] </ref>, "which means that both versions failed and includes failures with both identical and non-identical outputs"(p. 240). Taking a broader view, this work diverts the quest for reliable software even further away from the dominant path which aims for total error elimination.
Reference: 6. <author> D. E. Eckhardt and L. D. Lee, </author> <title> "A theoretical basis for the analysis of redundant software subject to coincident errors," </title> <type> NASA Tech. Memo. 86369, </type> <month> Jan. </month> <year> 1985. </year>
Reference-contexts: Thus the probability of two or more versions failing on the same input is very small"[8] p. 96. However, the precise meaning of central concepts, such as `independence', initially received little attention. Eckhardt and Lee <ref> [6] </ref>, [7] began the task of formalizing some of these concepts and their interrelationships. An important outcome of their study was that truly independently prepared versions (where `independence' is precisely defined) will necessarily fail dependently. This outcome is due to variation in difficulty of the inputs.
Reference: 7. <author> D. E. Eckhardt and L. D. Lee, </author> <title> "A theoretical basis for the analysis of multiversion software subject to coincident errors," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. SE-11, no. 12, </volume> <pages> pp. 1511-1517, </pages> <year> 1985. </year>
Reference-contexts: Thus the probability of two or more versions failing on the same input is very small"[8] p. 96. However, the precise meaning of central concepts, such as `independence', initially received little attention. Eckhardt and Lee [6], <ref> [7] </ref> began the task of formalizing some of these concepts and their interrelationships. An important outcome of their study was that truly independently prepared versions (where `independence' is precisely defined) will necessarily fail dependently. This outcome is due to variation in difficulty of the inputs. <p> Brilliant, Knight and Leveson [5] similarly work from the standpoint that "The amount of reliability improvement achieved [by majority voting in an N-version system] is determined by the degree of independence of the failures of the versions" (p. 238 citing <ref> [7] </ref> as the source | our emphasis). <p> Many of the earlier studies may therefore be seriously underestimating the potential reliability of the systems tested. 2 Littlewood & Miller model Littlewood and Miller [10] developed a thorough conceptual model to underpin the multiversion approach to software engineering. In agreement with Eckhardt and Lee <ref> [7] </ref>, the new model is surprising in that it relegates independence to a position of relative unimportance. Littlewood and Miller's model shows that, in theory, it is possible to produce better than independent failure behaviour: it is possible to have a multiversion system with negatively correlated failure.
Reference: 8. <author> J. C. Knight and N. G. Leveson, </author> <title> "An experimental evaluation of the assumption of independence in multiversion programming," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. SE-12, </volume> <pages> pp. 96-109, </pages> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: They analyse faults in their large study <ref> [8] </ref> of the Launch Interceptor (LI) problem, and conclude pessimistically: "we do not expect that changing 2 development tools or methods, or any other simple technique, would reduce significantly the incidence of correlated failures in N-version software" (p. 245). <p> While it is, of course, necessary to obtain sufficient successes within the version set, it is also permissable to have coincident failures provided they are distinct. It relegates lack of coincident failure to be merely one, non-definitive, indicator of system reliability potential. 24 Curiously, one earlier study <ref> [8] </ref> appears to indicate the importance of distinct failures when the authors write that "the basic assumption [is] that the probability of common mode failure (identical incorrect output given the same input) is very low" (p. 97, our emphasis).
Reference: 9. <author> W. J. Krzanowski and D. Partridge, </author> <title> "Software diversity: practical statistics for its measurement and exploitation," Res. </title> <type> Rep. 324, </type> <institution> Dept. Computer Science, </institution> <note> University of Exeter (submitted to Information & Software Technology). </note>
Reference-contexts: Necessarily finite input test spaces and small finite numbers of versions need to be accommodated in any practical application. 3 The Krzanowski & Partridge model Krzanowski and Partridge <ref> [9] </ref> have provided a development of the Littlewood and Miller model which makes no pretence to emulate the completeness of 6 the precursor conceptual model, but concentrates instead on a framework for practical application. <p> Hence CF D can be written CF D = n=1 (N 1) This diversity measure, which supercedes an earlier one [11], is (under certain conditions) a useful indicator of the potential for reliability enhancement in a multiversion system under majority voting strategies. The model <ref> [9] </ref> also generalizes this measure to the multiset case such that the relative potential of alternative system structures (such as a diverse 2-out-of-3 system or a homogeneous 2-out-of-3 system) can also be effectively assessed. <p> Notice also that use of the (more accurate) p (2) values, which we have added, reduces the apparent lack of independent failure behaviour. Using the above data, and applying our model <ref> [9] </ref>, estimates of the reliability of multiversion systems based on the eleven versions can be computed. Table 8 gives some informative values.
Reference: 10. <author> B. Littlewood and D. R. Miller, </author> <title> "Conceptual modelling of coincident failures in multiversion software," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. SE-15, no. 12, </volume> <pages> pp. 1596-1614, </pages> <month> Dec. </month> <year> 1989. </year> <month> 26 </month>
Reference-contexts: However, the basis on which this redundancy is expected to provide enhanced reliability has been consistently oversimplified. It is not simply independence of failure (as [5] assert), nor diversity with low probability of simultaneous version failure (as <ref> [10] </ref> imply) that is the basis for system reliability improvement. It is a more complex property, which may involve these simpler properties, whose exact composition is dependent upon the particular decision strategy employed. Put another way: useful software diversity is not a simple, context-free property of an N-version system. <p> Proper consideration of this property can raise dramatically the estimated N-version system reliability. Many of the earlier studies may therefore be seriously underestimating the potential reliability of the systems tested. 2 Littlewood & Miller model Littlewood and Miller <ref> [10] </ref> developed a thorough conceptual model to underpin the multiversion approach to software engineering. In agreement with Eckhardt and Lee [7], the new model is surprising in that it relegates independence to a position of relative unimportance. <p> under conditions of extreme DFD, which supports total system reliability, the coincident-failure diversity approaches zero and probability of two-version failure approaches unity as the number of versions increases. 12 In addition, independence of failure, measured in terms of the agreement between E ( 2 ) and E () 2 (as <ref> [10] </ref> propose), is achieved in all sets! This is because, under this particular distribution of failure, both quantities reduce to (N 2) 2 =N 2 . <p> The estimate p (2) P ro barely changes but E ( 2 P ro ) increases by an order of magnitude. This latter result might be taken to indicate that coincident failure is much higher in the altered set. Consequently, diversity is lower (as per <ref> [10] </ref>, p. 1609) and thus system 21 reliability should be much worse.
Reference: 11. <author> D. Partridge, </author> <title> "Neural network differences quantified," </title> <journal> Neural Net--works, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 263-271, </pages> <year> 1996. </year>
Reference-contexts: Hence CF D can be written CF D = n=1 (N 1) This diversity measure, which supercedes an earlier one <ref> [11] </ref>, is (under certain conditions) a useful indicator of the potential for reliability enhancement in a multiversion system under majority voting strategies.
Reference: 12. <author> D. Partridge and W. B. Yates, </author> <title> "Engineering multiversion neural-net systems," </title> <journal> Neural Computation, </journal> <volume> vol. 8, no. 4, </volume> <pages> pp. 869-893, </pages> <year> 1996. </year>
Reference-contexts: As Littlewood and Miller's analysis shows "the diverse design is not always superior to the homogeneous design"(p. 1605). The multiset diversity indicators permit assessment of the relative merits of these two options which have, in fact, been examined <ref> [12] </ref>. 8 4 Distinct failure diversity In all of the previous work on multiversion software, the focus has been on version success and version failure with an emergent concentration upon minimizing the likelihood of coincident failure between any two versions.
Reference: 13. <author> D. Partridge and W. B. Yates, </author> <title> "Data-defined problems and multiver-sion neural-net systems," </title> <journal> Journal of Intelligent Systems, </journal> <note> (in press). </note>
Reference-contexts: Consequently, diversity is lower (as per [10], p. 1609) and thus system 21 reliability should be much worse. But, as we know, under majority-vote, at least, nothing has changed concerning overall system reliability. 6.2 Inductive programming and N-version systems In a previous study <ref> [13] </ref> an N-version system was constructed to classify images as one of the 26 upper case letters, A to Z. The versions were neural networks, each differently trained on example data, to produce a nine-version system.
References-found: 13

