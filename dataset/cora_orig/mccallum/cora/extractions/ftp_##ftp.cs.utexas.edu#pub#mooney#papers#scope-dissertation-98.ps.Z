URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/scope-dissertation-98.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/ilp.html
Root-URL: http://www.cs.utexas.edu
Title: Using Multi-Strategy Learning to Improve Planning Efficiency and Quality  
Author: Tara Adrienne Estlin 
Address: Austin, TX 78712  
Affiliation: Artificial Intelligence Laboratory The University of Texas at Austin  
Web: http://www.cs.utexas.edu/users/estlin/  
Note: estlin@cs.utexas.edu  
Date: May 1998  
Pubnum: Report AI98-269  
Abstract-found: 0
Intro-found: 1
Reference: <author> Agosa, J. M., & Wilkins, D. E. </author> <year> (1996). </year> <title> Using SIPE-2 to plan emergency response to marine oil spills. </title> <journal> IEEE Expert, </journal> <volume> 11, </volume> <pages> 6-8. </pages>
Reference-contexts: Another option is to give the plan to a computer execution agent which performs the task with little or no human intervention. Planning systems have become a powerful and popular tool for performing a range of activities, from manufacturing semiconductors (Fargher & Smith, 1994), to cleaning up oil-spills <ref> (Agosa & Wilkins, 1996) </ref>, to scheduling antenna communications with orbiting spacecraft (Chien, Govindjee, Estlin, Wang, & Jr., 1997).
Reference: <author> Andrews, S., Kettler, B., Erol, K., & Hendler, J. </author> <year> (1995). </year> <title> UM Translog: A planning domain for the development and benchmarking of planning systems. </title> <type> Tech. rep. </type> <institution> CS-TR-3487, Institute for Advanced Computer Studies, University of Maryland. </institution>
Reference-contexts: Also, holes in a part can be further refined such as tapping a hole to produce a thread inside or countersinking a hole to cut an angular opening into the top. A number of other domains could also to test Scope. For instance, the UM Translog domain <ref> (Andrews et al., 1995) </ref> is an extended version of logistics transportation domain, which it is an order of magnitude larger in size (41 actions vs. 6) and which provides more complex features and goal interactions.
Reference: <author> Barrett, A., & Weld, D. </author> <year> (1994). </year> <title> Partial order planning: Evaluating possible efficiency gains. </title> <journal> Artificial Intelligence, </journal> <volume> 67, </volume> <pages> 71-112. </pages>
Reference: <author> Barrett, A., & et al. </author> <year> (1995). </year> <title> UCPOP: User's manual (version 4.0). </title> <type> Tech. rep. </type> <institution> 93-09-06d, Department of Computer Science and Engineering, University of Washington. </institution>
Reference-contexts: For comparison purposes, one other search method was used to solve the test problems. Best-first search was also evaluated at solving the test problems. These tests were done using the standard Lisp implementation of UCPOP <ref> (Barrett & et al., 1995) </ref>, thus some results could be partially due to implementation difference between Prolog and Lisp. 1 These solutions are not guaranteed to be optimal since it is possible the rules are too specialized and could miss an optimal solution. <p> For comparison purposes, best-first search was also evaluated at solving the test problems. Again, these tests were done using the standard Lisp implementation of UCPOP <ref> (Barrett & et al., 1995) </ref>, thus some results could be partially due to implementation difference between Prolog and Lisp. 64 7.5 Efficiency Results tests Scope was able to greatly improve planner efficiency. <p> strategy. (All other experiments up to this point have employed a LIFO goal-selection strategy.) Both learning systems run UCPOP in a depth-first search mode, however, it should be noted that Scope was run used a Prolog version of UCPOP as a base planner, while UCPOP+EBL uses the standard LISP implementation <ref> (Barrett & et al., 1995) </ref>. Also, these experiments were run on different machines. Thus some differences in results could be due to these factors.
Reference: <author> Barrett, A., Golden, K., Penberthy, S., & Weld, D. </author> <year> (1993). </year> <title> UCPOP: User's manual (version 2.0). </title> <type> Tech. rep. </type> <institution> 93-09-06, Department of Computer Science and Engineering, University of Washington. </institution>
Reference-contexts: This system is discussed further in related work and to the author's knowledge, is the only other system besides SCOPE that can learn control rules for UCPOP. To evaluate the efficiency of the Prolog planner as compared to the standard Lisp implementation of UCPOP (v2.0) <ref> (Barrett et al., 1993) </ref>, several experiments were run using problem sets from three domains, which are also used for testing the learning algorithm. In these tests, which are discussed in Sections 6 and 7, the Prolog planner performed comparably to UCPOP and in some cases performed better.
Reference: <author> Bhatnagar, N., & Mostow, J. </author> <year> (1994). </year> <title> On-line learning from search failure. </title> <journal> Machine Learning, </journal> <volume> 15, </volume> <pages> 69-117. </pages>
Reference-contexts: Static (Etzioni, 1993) acquires control rules by analyzing the problem domain theory. This system uses EBL to analyze a graph struc 77 ture that captures the precondition/effect dependencies between the actions in the domain. This analysis is then used to derive goal-ordering rules for the Prodigy state-based planner. Failsafe <ref> (Bhatnagar & Mostow, 1994) </ref> was designed to learn control rules in domains where the underlying domain theory was recursive. This system uses a forward-searching state-based planner and learns by building incomplete explanations of its execution time failures. Not all learning approaches have relied on EBL.
Reference: <author> Blum, A., & Furst, M. </author> <year> (1997). </year> <title> Fast planning through planning graph analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 90, </volume> <pages> 281-300. </pages>
Reference-contexts: These types of planners operator very differently from more traditional planning styles, where planning is viewed as a state-based or plan-based search. For instance, Graphplan converts a planning problem into a structure called a planning graph, and then systematically searches the graph for a solution <ref> (Blum & Furst, 1997) </ref>. Kautz and Selman (1996) describe a method for reducing planning problems into SAT encodings, and then employing either a satisfiability algorithm or a stochastic algorithm to produce solutions.
Reference: <author> Borrajo, D., & Veloso, M. </author> <year> (1994). </year> <title> Incremental learning of control knowledge for nonlinear problem solving. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, ECML-94, </booktitle> <pages> pp. </pages> <publisher> 64-82 Springer Verlag. </publisher>
Reference: <author> Borrajo, D., & Veloso, M. </author> <year> (1997). </year> <title> Lazy incremental learning of control knowledge for efficiently obtaining quality plans. </title> <journal> Artificial Intelligence Review, </journal> <volume> 11, </volume> <pages> 371-405. </pages>
Reference-contexts: Removing the linearity assumption adds further complications for learning search-control not addressed by these early systems, since many more search paths must be considered in generating an explanation. Unfortunately, very few learning systems have been built to acquire control knowledge for other styles of planning. Hamlet <ref> (Borrajo & Veloso, 1997) </ref> is one more recent system, which learns control knowledge for the nonlinear planner Prodigy4.0 (Carbonell & et al., 1992). Similar to Scope, Hamlet uses a combination of EBL with induction to acquire control rules.
Reference: <author> Cameron-Jones, R. M., & Quinlan, J. R. </author> <year> (1994). </year> <title> Efficient top-down induction of logic programs. </title> <journal> SIGART Bulletin, </journal> <volume> 1 (5), </volume> <pages> 33-42. </pages>
Reference: <author> Carbonell, J., & et al. </author> <year> (1992). </year> <title> PRODIGY4.0: The manual and tutorial. </title> <type> Tech. rep. </type> <institution> CMU-CS-92-150, School of Computer Science, Carnegie Mellon University, Pittsburg, </institution> <address> PA. </address>
Reference-contexts: Additionally, providing solutions to the training problems that are high quality is even more difficult. The approach used to generate high-quality solutions for training problems was the following. First, in order to solve all of the training problems, the Prodigy4.0 planner <ref> (Carbonell & et al., 1992) </ref> was utilized, which contains a large set of hand-coded control rules for the process planning domain. These rules enable the Prodigy planner to solve problems in this domain much quicker than with the base planner used in this dissertation. <p> Unfortunately, very few learning systems have been built to acquire control knowledge for other styles of planning. Hamlet (Borrajo & Veloso, 1997) is one more recent system, which learns control knowledge for the nonlinear planner Prodigy4.0 <ref> (Carbonell & et al., 1992) </ref>. Similar to Scope, Hamlet uses a combination of EBL with induction to acquire control rules. First, optimal solutions are gathered for each training example by performing an exhaustive search of the problem search space.
Reference: <author> Chase, M., Zweben, M., Piazza, R., Burger, J., Maglio, P., & Hirsh, H. </author> <year> (1989). </year> <title> Approximating learned search control knowledge. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 40-42 Ithaca, NY. </address> <note> 111 Chien, </note> <author> S. </author> <year> (1989). </year> <title> Using and refining simplifications: Explanation-based learning of plans in in-tractable domains. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 590-595 Detroit, MI. </address>
Reference-contexts: Scope, on the other hand, uses induction to select the most useful pieces of EBG generalizations. Some work has also been done on learning approximations to EBL rules. The ULS system <ref> (Chase et al., 1989) </ref> acquired conservative approximations to EBL rules by simply dropping one or two conditions. ULS was very limited in the rules it could generate, unlike Scope, which uses an inductive learning mechanism to build rules from scratch.
Reference: <author> Chien, S., & DeJong, G. </author> <year> (1994). </year> <title> Incremental reasoning in explanation-based learning of plans. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems Chicago. </booktitle>
Reference: <author> Chien, S., Govindjee, A., Estlin, T., Wang, X., & Jr., R. H. </author> <year> (1997). </year> <title> Automated generation of antenna operation procedures: A knowledge-based approach. </title> <journal> Telecommunications and Data Acquisition, </journal> <volume> 142. </volume>
Reference-contexts: Planning systems have become a powerful and popular tool for performing a range of activities, from manufacturing semiconductors (Fargher & Smith, 1994), to cleaning up oil-spills (Agosa & Wilkins, 1996), to scheduling antenna communications with orbiting spacecraft <ref> (Chien, Govindjee, Estlin, Wang, & Jr., 1997) </ref>.
Reference: <author> Cohen, W. W. </author> <year> (1990). </year> <title> Learning approximate control rules of high utility. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 268-276 Austin, TX. </address>
Reference-contexts: More information on Foil can be found in (Quinlan, 1990; Quinlan & Cameron-Jones, 1993; Cameron-Jones & Quinlan, 1994). 3.2.3 ILP for Control It has also been argued that ILP techniques can be a useful tool for acquiring control information <ref> (Cohen, 1990) </ref>. Many different problem solving strategies can be easily coded as logic programs and learning mechanisms are also easily implemented in this framework. Logic programming also provides a well-understood representational and computational platform upon which to build. <p> In Prolog, depth-first search with backtracking is used to search for a proof. If during execution the current search path fails, then the last non-deterministic decision point is backtracked upon and a new path explored. Search control in a Prolog program can be viewed as a clause-selection problem <ref> (Cohen, 1990) </ref>, where clause selection is the process of deciding what program clause should be used to reduce a particular subgoal during program execution. Different options in a program are represented using separate clauses which have unifiable heads but different clause bodies. <p> ULS was very limited in the rules it could generate, unlike Scope, which uses an inductive learning mechanism to build rules from scratch. A more closely related system is AxA-EBL <ref> (Cohen, 1990) </ref>, which integrates an induction mechanism to learn approximate EBL rules. AxA-EBL first learns a control rule by applying EBG to the proof of a correct control decision.
Reference: <author> DeJong, G. F., & Mooney, R. J. </author> <year> (1986). </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1 (2), </volume> <pages> 145-176. </pages> <note> Reprinted in Readings in Machine Learning, </note> <editor> J. W. </editor> <booktitle> Shavlik and T. </booktitle>
Reference: <editor> G. Dietterich (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: <author> Descotte, Y., & Latombe, J.-C. </author> <year> (1985). </year> <title> Making compromises among antagonist constraints in a planner. </title> <journal> Artificial Intelligence, </journal> <volume> 27, </volume> <pages> 183-217. </pages>
Reference-contexts: There have also been some domain-dependent approaches to generate high quality plans. The Machinist program (Hayes, 1990) generates plans for a machine process domain and has embedded knowledge about feature interaction which helps it to generate minimal length plans. The GARI <ref> (Descotte & Latombe, 1985) </ref> planner generates plans for metal cutting by using a constraint satisfaction algorithm, where domain control knowledge is encoded with more general domain information in the form of preference rules. 82 Chapter 10 Future Work There are a number of issues that would be interesting to pursue in
Reference: <author> Erol, K., Nau, D., & Hendler, J. </author> <year> (1994a). </year> <title> HTN planning: Complexity and expressivity. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1123-1128 Seattle. </address>
Reference-contexts: There are several other types of planners besides partial-order that are prominent in the planning community today. One is an hierarchical-task network (HTN) planner <ref> (Erol et al., 1994a) </ref>. As opposed to most operator-based planners, HTN planners specify plan modifications in terms of task reduction rules. These reduction rules are then used to decompose abstract goals into lower level tasks.
Reference: <author> Erol, K., Nau, D., & Hendler, J. </author> <year> (1994b). </year> <title> UMCP: A sound and complete planning procedure for hierarchical task-network planning. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems Chicago. </booktitle>
Reference-contexts: HTN planners are argued by some researchers to be more useful for real-world applications since they offer more flexibility in expressing domain knowledge. There are several well-developed HTN algorithms that would be good testbeds for Scope. These include UMCP <ref> (Erol et al., 1994b) </ref>, developed at the University of Maryland, and COLLAGE (Lansky & Getoor, 1995), developed at the NASA Ames Research Center. Another breed of planners that could be considered are those that use a combination of 86 plan-space and state-space techniques.
Reference: <author> Estlin, T. A., & Mooney, R. J. </author> <year> (1996). </year> <title> Multi-strategy learning of search control for partial-order planning. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 843-848 Portland, OR. </address>
Reference-contexts: while Scope, which uses a combination of EBL and induction, is shown to be much more robust at applying to different domain representations. 5.5 Improving Upon Different Planning Metrics By learning rules that avoid search paths that lead to backtracking, Scope can significantly improve the efficiency of of a planner <ref> (Estlin & Mooney, 1996) </ref>. Scope can also be used simultaneously to improve the quality of plans by using a particular method to collect training data. In order to improve plan quality, as well as efficiency, Scope is trained on only high-quality solutions.
Reference: <author> Etzioni, O. </author> <year> (1993). </year> <title> Acquiring search control knowledge via static analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 60 (2). </volume>
Reference-contexts: Rules are learned in response to both planning failures and successes and also from unforeseen goal interactions. Learned control rules can select, reject, or prefer plan-refinement candidates for several different decision types. A number of other systems have also applied EBL to learn search-control for planning. Static <ref> (Etzioni, 1993) </ref> acquires control rules by analyzing the problem domain theory. This system uses EBL to analyze a graph struc 77 ture that captures the precondition/effect dependencies between the actions in the domain. This analysis is then used to derive goal-ordering rules for the Prodigy state-based planner.
Reference: <author> Etzioni, O., & Etzioni, R. </author> <year> (1994). </year> <title> Statistical methods for analyzing speedup learning experiments. </title> <journal> Machine Learning, </journal> <volume> 14, </volume> <pages> 337-347. </pages>
Reference-contexts: On the 50 package problems, solution coverage actually slightly decreased from 24% to 22%. This decrease is most likely caused by the use of a time limit. As discussed in <ref> (Etzioni & Etzioni, 1994) </ref>, using a time limit can decrease speedup, especially when solution times are close to the limit. In these problems, solution times were often very close to the time limit (of 500 seconds). <p> Though employing a time limit is often necessary when running experiments such as the one presented in this dissertation, it can often underplay the true speedup achieved by a learning system <ref> (Etzioni & Etzioni, 1994) </ref>. For these experiments, it is unclear how long it would take the base planner (without control knowledge) to solve all of the test problems. The planner was run for several days without a time limit and could only solve a few problems.
Reference: <author> Fargher, H., & Smith, R. </author> <year> (1994). </year> <title> Planning in a flexible semiconductor manufacturing environment. </title>
Reference-contexts: Another option is to give the plan to a computer execution agent which performs the task with little or no human intervention. Planning systems have become a powerful and popular tool for performing a range of activities, from manufacturing semiconductors <ref> (Fargher & Smith, 1994) </ref>, to cleaning up oil-spills (Agosa & Wilkins, 1996), to scheduling antenna communications with orbiting spacecraft (Chien, Govindjee, Estlin, Wang, & Jr., 1997).
Reference: <editor> In Zweben, M., & Fox, M. (Eds.), </editor> <booktitle> Intelligent Scheduling, </booktitle> <pages> pp. 545-580. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA. </address>
Reference: <author> Fikes, R., & Nilsson, N. </author> <year> (1971). </year> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 (3/4). </volume>
Reference-contexts: In many standard approaches to planning, domain actions are represented in a STRIPS operator format <ref> (Fikes & Nilsson, 1971) </ref>, which consists of a list of preconditions, an add list and a delete list. Definitions for several actions from the logistics transportation domain (Veloso, 1992) are shown in Figure 2.1. <p> Operators are specified using Pednault's Action Description Language (ADL) (Pendault, 1989), which was discussed in Section 2.1 and is an extension of the well-known STRIPS format <ref> (Fikes & Nilsson, 1971) </ref>. Operators contain precondition, add and delete lists, and they can also contain constructs such as conditional effects, disjunctive preconditions, and universal quantification. UCPOP searches for a solution in a space of partial plans, where each plan consists of a partial-ordering of actions.
Reference: <author> Fikes, R. E., Hart, P. E., & Nilsson, N. J. </author> <year> (1972). </year> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 (4), </volume> <pages> 251-288. </pages>
Reference-contexts: X-Learn has been shown to produce significant speedup in several planning domains, including a variant of the STRIPS world domain <ref> (Fikes, Hart, & Nilsson, 1972) </ref> and an air-traffic control domain. Unfortunately, even though X-Learn can produce significant speedup on these domains, it is not guaranteed to produce a complete planner and thus sometimes the final planner cannot produce a solution for all test problems.
Reference: <author> Foulser, D., Li, M., & Yang, Q. </author> <year> (1992). </year> <title> Theory and algorithms for plan merging. </title> <journal> Artificial Intelligence, </journal> <volume> 52, </volume> <pages> 143-181. </pages> <note> 112 Gerevini, </note> <author> A., & Schubert, L. </author> <year> (1996). </year> <title> Accelerating partial-order planners: Some techniques for effective search control and pruning. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 5, </volume> <pages> 95-137. </pages>
Reference: <author> Gil, Y. </author> <year> (1991). </year> <title> A specification of manufacturing processes for planning. </title> <type> Tech. rep. </type> <institution> CMU-CS-91-179, School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: These constructs allow the domain writer to create more complicated and expressive operator definitions. For an example of a domain that uses these additional constructs, see the definition of the process planning domain <ref> (Gil, 1991) </ref> in Appendix A. 2.2 Search Methods Given a planning problem, many different search methods have been developed for finding a correct plan. Most classical planners, including the original STRIPS planner, employ a state-based search. <p> A.4 Process Planning Domain The process planning definition <ref> (Gil, 1991) </ref> that was used in this dissertation is listed below. This domain contains definitions for operators, axioms and functions. Axioms can be used to easily define extra operator effects so that domain operators can be structured in a concise format.
Reference: <author> Gratch, J., & DeJong, G. </author> <year> (1992). </year> <title> COMPOSER: A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 235-240 San Jose, CA. </address>
Reference: <author> Greiner, R., & Likuski, J. </author> <year> (1989). </year> <title> Incorporating redundant learned rules: A preliminary formal analysis of ebl. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 744-749 Detroit, MI. </address>
Reference: <author> Hart, P. E., Nilsson, N. J., & Raphael, B. </author> <year> (1968). </year> <title> A formal basis for the heuristic determination of minimum cost parts. </title> <journal> IEEE transactions on SSC, </journal> <volume> 4, </volume> <pages> 100-107. </pages>
Reference-contexts: For other metrics, such as plan execution time or cost, a branch and bound search can be used that focuses on finding low-cost plans for that metric. Or, it may be possible to use an A fl star search <ref> (Hart, Nilsson, & Raphael, 1968) </ref> if there exists an admissible heuristic for that quality metric. Another technique is to employ a human domain expert to solve the training problems. When presented with a problem, a domain expert can often easily provide a high-quality solution.
Reference: <author> Hayes, C. </author> <year> (1990). </year> <title> Machining Planning: A Model of an Expert Level Planning Process. </title> <type> Ph.D. thesis, </type> <institution> The Robotics Institue, Carnegie Mellon University. </institution>
Reference-contexts: Some work has concentrated on examining goal interactions and how they related to solution quality. One technique is to analyze the different types of goal interactions and then develop strategies to deal them (Wilensky, 1983; Pollack, 1992). The LCOS (Least Commitment to Operator Selection) planning strategy <ref> (Hayes, 1990) </ref> takes a global view of the plan and only makes operator selections that can maximize a given plan quality criteria. Foulser, Li, and Yang (1992) promotes plan merging as a technique for minimizing plan cost, where certain operators in a plan are grouped together. <p> The Pyrrhus planning system (Williamson & Hanks, 1994) is an extension to UCPOP that finds optimal plans by using utility models to measure the quality of a partial plan. There have also been some domain-dependent approaches to generate high quality plans. The Machinist program <ref> (Hayes, 1990) </ref> generates plans for a machine process domain and has embedded knowledge about feature interaction which helps it to generate minimal length plans.
Reference: <author> Iwamoto, M. </author> <year> (1994). </year> <title> A planner with quality goal and its speedup learning for optimization problem. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems Chicago. </booktitle>
Reference-contexts: There are two other learning systems for improving quality which also run on the PRODIGY nonlinear planner. One technique was developed by <ref> (Iwamoto, 1994) </ref> and uses EBL to acquire control rules for near-optimal solutions in LSI design.
Reference: <author> Kambhampati, S., & Chen, J. </author> <year> (1993). </year> <title> Relative utility of EBG based plan reuse in partial ordering vs. total ordering. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 514-519 Washington, D.C. </address>
Reference: <author> Kambhampati, S., Katukam, S., & Qu, Y. </author> <year> (1996). </year> <title> Failure driven search control for partial order planners: An explanation based approach. </title> <journal> Artificial Intelligence, </journal> <volume> 88. </volume>
Reference-contexts: UCPOP+EBL is a learning system that learns control rules for planning by utilizing EBL to explain planning failures <ref> (Kambhampati et al., 1996) </ref>, and is discussed in more detail in Chapter 9. This learning system has been successfully used to acquire rules that improve the performance of UCPOP. <p> For 72 Problem A Problem B Plan A Plan B stack (d,c) putdown (d) pickup (b) pickup (c) stack (b,d) stack (c,b) unstack (b,d) * pickup (d) stack (d,c) pickup (b) stack (b,d) unstack (b,d) * instance, the UCPOP+EBL system <ref> (Kambhampati et al., 1996) </ref>, which is discussed in Chapter 9, utilizes extra domain axioms to help it reason about depth-limit failures. 8.3 Quality Results Changes in plan quality for these experiments are shown in Figure 8.5 and Figure 8.6. <p> In quality improvements, Scope was able to more significantly decrease solution lengths in blocksworld and both systems achieved equivalent improvements in the logistics domain. 9.2.2 Systems Applied to Partial-Order Planners The only system besides Scope to learn control information for partial-order planning is UCPOP+EBL <ref> (Kambhampati et al., 1996) </ref>. This system also learns search control rules to improve the performance of UCPOP, but uses a purely explanation-based approach. Specifically, UCPOP+EBL employs the standard EBL techniques of regression, explanation propagation and rule generation to acquire search-control rules, which are learned in response to past planning failures.
Reference: <author> Kambhampati, S., & Srivastava, B. </author> <year> (1996). </year> <title> Universal classical planner: An algorithm for unifying state-space and plan-space planning. </title> <editor> In Ghallab, M., & Milani, A. (Eds.), </editor> <booktitle> New Directions in AI Planning, </booktitle> <pages> pp. </pages> <address> 61-75 Amsterdam. </address> <publisher> IOS Press. </publisher>
Reference-contexts: UCPOP+EBL is a learning system that learns control rules for planning by utilizing EBL to explain planning failures <ref> (Kambhampati et al., 1996) </ref>, and is discussed in more detail in Chapter 9. This learning system has been successfully used to acquire rules that improve the performance of UCPOP. <p> For 72 Problem A Problem B Plan A Plan B stack (d,c) putdown (d) pickup (b) pickup (c) stack (b,d) stack (c,b) unstack (b,d) * pickup (d) stack (d,c) pickup (b) stack (b,d) unstack (b,d) * instance, the UCPOP+EBL system <ref> (Kambhampati et al., 1996) </ref>, which is discussed in Chapter 9, utilizes extra domain axioms to help it reason about depth-limit failures. 8.3 Quality Results Changes in plan quality for these experiments are shown in Figure 8.5 and Figure 8.6. <p> In quality improvements, Scope was able to more significantly decrease solution lengths in blocksworld and both systems achieved equivalent improvements in the logistics domain. 9.2.2 Systems Applied to Partial-Order Planners The only system besides Scope to learn control information for partial-order planning is UCPOP+EBL <ref> (Kambhampati et al., 1996) </ref>. This system also learns search control rules to improve the performance of UCPOP, but uses a purely explanation-based approach. Specifically, UCPOP+EBL employs the standard EBL techniques of regression, explanation propagation and rule generation to acquire search-control rules, which are learned in response to past planning failures.
Reference: <author> Kautz, H., & Selman, B. </author> <year> (1996). </year> <title> Pushing the envelope: Planning, propositional logic, and stochastic search. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Ariticial Intelligence, </booktitle> <pages> pp. </pages> <address> 1194-1200 Portland, OR. </address>
Reference: <author> Keller, R. </author> <year> (1987). </year> <title> The Role of Explicit Contextual Knowledge in Learning Concepts to Improve Performance. </title> <type> Ph.D. thesis, </type> <institution> Rutgers University, </institution> <address> New Brunswick, N. </address> <note> Also appears as tech. report ML-TR-7. </note>
Reference-contexts: Several early approaches also used a combination of induction and EBL to learn control information. The LEX-2 (Mitchell et al., 1983) and MetaLEX <ref> (Keller, 1987) </ref> systems constructed rules by inducing over complete explanation-based generalizations of problem-solving traces. Scope, on the other hand, uses induction to select the most useful pieces of EBG generalizations. Some work has also been done on learning approximations to EBL rules.
Reference: <author> Kijsirikul, B., Numao, M., & Shimura, M. </author> <year> (1992). </year> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 44-49 San Jose, CA. </address>
Reference: <author> Korf, R. </author> <year> (1985). </year> <title> Depth-first iterative-deepening: An optimal admissable tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 27 (1). 113 Langley, </volume> <editor> P. </editor> <year> (1985). </year> <title> Learning to search: From weak methods to domain specific heuristics. </title> <journal> Cognitive Science, </journal> <volume> 9 (2), </volume> <pages> 217-260. </pages>
Reference-contexts: In order to train Scope on high-quality solutions, several different techniques can be employed to generate training problem solutions. One is to allow the planner to simply search for optimal or high-quality solutions. For example, when plan length is the quality metric, the search method depth-first iterative deepening (DFID) <ref> (Korf, 1985) </ref> can often be used to guarantee optimal solutions. For other metrics, such as plan execution time or cost, a branch and bound search can be used that focuses on finding low-cost plans for that metric.
Reference: <author> Langley, P., & Allen, J. </author> <year> (1991). </year> <title> The acquisition of human planning expertise. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. 80-84 Evanston,IL. </pages>
Reference: <author> Lansky, A., & Getoor, L. </author> <year> (1995). </year> <title> Scope and abstraction: Two criteria for localized planning. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1612-1618 Montreal, CA. </address>
Reference-contexts: There are several well-developed HTN algorithms that would be good testbeds for Scope. These include UMCP (Erol et al., 1994b), developed at the University of Maryland, and COLLAGE <ref> (Lansky & Getoor, 1995) </ref>, developed at the NASA Ames Research Center. Another breed of planners that could be considered are those that use a combination of 86 plan-space and state-space techniques.
Reference: <author> Lavrac, N., & Dzeroski, S. </author> <year> (1994). </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood. </publisher>
Reference: <author> Leckie, C., & Zuckerman, I. </author> <year> (1993). </year> <title> An inductive approach to learning search control rules for planning. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1100-1105 Chamberry,France. </pages>
Reference-contexts: Also, the search space increases exponentially with the number of distinct variables in the clause. Most past approaches that have utilized a pure inductive search for acquiring control knowledge have only searched through a handful of simple predicates. For instance, Grasshoppper <ref> (Leckie & Zuckerman, 1993) </ref>, was applied to a state-based planner and does an inductive search on whether certain conditions are present in the current world state. Conversely, the operational planning predicates used by Scope can be much more complicated and often have a number of arguments (some up to ten). <p> Failsafe (Bhatnagar & Mostow, 1994) was designed to learn control rules in domains where the underlying domain theory was recursive. This system uses a forward-searching state-based planner and learns by building incomplete explanations of its execution time failures. Not all learning approaches have relied on EBL. Grasshopper <ref> (Leckie & Zuckerman, 1993) </ref> uses an inductive approach to learn planning control knowledge. This system learns control rules for goal, operator, and variable binding decisions. Given a set of training examples, Grasshopper looks for sets of similar decisions that could form the basis for control rules.
Reference: <author> Markovitch, S., & Scott, P. D. </author> <year> (1989). </year> <title> Utilization filtering: A method for reducing the inherent harmfulness of deductively learning knowledge. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 738-743 Detroit, MI. </address>
Reference: <author> McDermott, D. </author> <year> (1991). </year> <title> Regression planning. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 6, </volume> <pages> 357-416. </pages>
Reference: <author> Minton, S. </author> <year> (1988). </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 564-569 St. </address>
Reference-contexts: Unfortunately, due to its reliance on only a few examples, standard EBL can often produce complex, overly-specific control rules that do not generalize well to new planning situations <ref> (Minton, 1988) </ref>. This situation is commonly known as the utility problem (Minton, 1988; Mooney, 1989; Cohen, 1990), where even though the learned rules are correct, the cost of testing their applicability to new planning situations often outweighs their savings. <p> The utility of individual rules can often dramatically vary and too many rules of low utility can even lead to lower performance <ref> (Minton, 84 1988) </ref>. This occurrence, commonly known as the utility problem, can be lessened or prevented by only including the most useful control rules in the final planner.
Reference: <editor> Paul, </editor> <address> MN. </address>
Reference: <author> Minton, S. </author> <year> (1989). </year> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 63-118. </pages>
Reference-contexts: Most of this research has concentrated on linear, state-based planners. For instance, the Prodigy planning and learning system <ref> (Minton, 1989) </ref> employs a version of EBL, called explanation-based specialization, to learn domain-specific control rules for a linear, state-based planner. Rules are learned in response to both planning failures and successes and also from unforeseen goal interactions.
Reference: <author> Minton, S. N. </author> <year> (1988). </year> <title> Learning Effective Search Control Knowledge: An Explanantion-Based Approach. </title> <type> Ph.D. thesis, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference-contexts: Unfortunately, due to its reliance on only a few examples, standard EBL can often produce complex, overly-specific control rules that do not generalize well to new planning situations <ref> (Minton, 1988) </ref>. This situation is commonly known as the utility problem (Minton, 1988; Mooney, 1989; Cohen, 1990), where even though the learned rules are correct, the cost of testing their applicability to new planning situations often outweighs their savings. <p> The utility of individual rules can often dramatically vary and too many rules of low utility can even lead to lower performance <ref> (Minton, 84 1988) </ref>. This occurrence, commonly known as the utility problem, can be lessened or prevented by only including the most useful control rules in the final planner.
Reference: <author> Minton, S. </author> <year> (1985). </year> <title> Selectively generalizing plans for problem solving. </title> <booktitle> In Proceedings of the Ninth International Conference on Ariticial Intelligence, </booktitle> <pages> pp. </pages> <address> 569-599 Los Angeles, CA. </address>
Reference: <author> Minton, S., Drummond, M., Bresina, J. L., & Phillips, A. B. </author> <year> (1992). </year> <title> Total order vs. partial order planning: Factors influencing performance. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 83-92 Cambridge,CA. </pages>
Reference: <author> Mitchell, T., Utgoff, T., & Banerji, R. </author> <year> (1983). </year> <title> Learning problem solving heuristics by experimentation. </title> <editor> In Michalski, R., Mitchell, T., & Carbonell, J. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: Positive and negative examples of problem solver behavior are identified (Mitchell et al., 1983; Langley, 1985), and then control heuristics are learned to cover the positive examples and rule out the negatives. Several early approaches also used a combination of induction and EBL to learn control information. The LEX-2 <ref> (Mitchell et al., 1983) </ref> and MetaLEX (Keller, 1987) systems constructed rules by inducing over complete explanation-based generalizations of problem-solving traces. Scope, on the other hand, uses induction to select the most useful pieces of EBG generalizations. Some work has also been done on learning approximations to EBL rules.
Reference: <author> Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. </author> <year> (1986). </year> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 47-80. </pages> <note> 114 Mooney, </note> <author> R. J. </author> <year> (1989). </year> <title> The effect of rule use on the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 725-730 Detroit, MI. </address>
Reference: <author> Mooney, R. J., & Califf, M. E. </author> <year> (1995). </year> <title> Induction of first-order decision lists: Results on learning the past tense of English verbs. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 1-24. </pages>
Reference-contexts: have successfully induced small programs for simple tasks such as sorting and list manipulation (Muggleton & Buntine, 1988; Quinlan & Cameron-Jones, 1993); as well as performing well on more complicated tasks such as learning properties of organic molecules (Muggleton et al., 1992) and predicting the past tense of English verbs <ref> (Mooney & Califf, 1995) </ref>. The ILP algorithm used in this dissertation is a version of the Foil induction algorithm (Quinlan, 1990). Foil learns a function-free, first-order, Horn clause definition of a target concept. <p> The refinement-selection examples collected in the example analysis phase provide the sets of positive and negative examples for when each refinement should be applied. Scope uses an intensional version of Foil where background predicates can be defined as Prolog programs <ref> (Mooney & Califf, 1995) </ref> instead of requiring an extensional representation as in standard Foil.
Reference: <author> Muggleton, S., & Buntine, W. </author> <year> (1988). </year> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 339-352 Ann Arbor, MI. </address>
Reference: <author> Muggleton, S., King, R., & Sternberg, M. </author> <year> (1992). </year> <title> Protein secondary structure prediction using logic-based machine learning. </title> <journal> Protein Engineering, </journal> <volume> 5 (7), </volume> <pages> 647-657. </pages>
Reference-contexts: ILP systems have successfully induced small programs for simple tasks such as sorting and list manipulation (Muggleton & Buntine, 1988; Quinlan & Cameron-Jones, 1993); as well as performing well on more complicated tasks such as learning properties of organic molecules <ref> (Muggleton et al., 1992) </ref> and predicting the past tense of English verbs (Mooney & Califf, 1995). The ILP algorithm used in this dissertation is a version of the Foil induction algorithm (Quinlan, 1990). Foil learns a function-free, first-order, Horn clause definition of a target concept.
Reference: <author> Muggleton, S. H. (Ed.). </author> <year> (1992). </year> <title> Inductive Logic Programming. </title> <publisher> Academic Press, </publisher> <address> New York, NY. </address>
Reference-contexts: ILP systems have successfully induced small programs for simple tasks such as sorting and list manipulation (Muggleton & Buntine, 1988; Quinlan & Cameron-Jones, 1993); as well as performing well on more complicated tasks such as learning properties of organic molecules <ref> (Muggleton et al., 1992) </ref> and predicting the past tense of English verbs (Mooney & Califf, 1995). The ILP algorithm used in this dissertation is a version of the Foil induction algorithm (Quinlan, 1990). Foil learns a function-free, first-order, Horn clause definition of a target concept.
Reference: <author> Nilsson, N. </author> <year> (1980). </year> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: Most classical planners, including the original STRIPS planner, employ a state-based search. In this approach, the planner always maintains a representation of the current world state to help guides its search for a correct plan. An example of a state-based search in the blocksworld domain <ref> (Nilsson, 1980) </ref> is shown in Figure 2.2. Here the planner starts with the initial state and searches through new states until a state where all the goals are true is reached. New states are created by applying a domain action. <p> Domain operators are specified using the operator/3 predicate which is defined as: operator (Op, Preconditions, Postconditions) where Op corresponds to the operator name and arguments, Preconditions corresponds to a list of preconditions and Effects corresponds to a list of effects. A.1 Blocksworld Domain The main blocksworld domain definition <ref> (Nilsson, 1980) </ref> that was used in this dissertation is listed below. operator (putdown (X), [holding (X)], [on_table (X),clear (X),arm_empty,not (holding (X))]). operator (pickup (X), [on_table (X),clear (X),arm_empty], [holding (X),not (on_table (X)),not (clear (X)),not (arm_empty)]). operator (unstack (X,Y), [on (X,Y),clear (X),arm_empty], [clear (Y),holding (X),not (on (X,Y)),not (clear (X)),not (arm_empty)]). operator (stack (X,Y),
Reference: <author> Pazzani, M., & Kibler, D. </author> <year> (1992). </year> <title> The utility of background knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 57-94. </pages>
Reference-contexts: Second, Foil has a "most general" bias which tends to produce simple definitions. Such a bias is important for learning rules with a low match cost, which helps avoid the utility problem. Third, it is relatively easy to bias Foil with prior knowledge <ref> (Pazzani & Kibler, 1992) </ref>.
Reference: <author> Penberthy, J., & Weld, D. S. </author> <year> (1992). </year> <title> UCPOP: A sound, complete, partial order planner for ADL. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 113-114 Cambridge,MA. </pages>
Reference-contexts: This type of approach is widely used in many current planning systems and thus a partial-order planner was thus identified as a good testbed for the SCOPE control rule learning system. 4.1 The UCPOP Planner The base planner that was chosen for experimentation is UCPOP <ref> (Penberthy & Weld, 1992) </ref>, a partial-order planner whose step descriptions can include conditional effects and universal quantification. UCPOP has been proven sound and complete, and a significant amount of planning research has been based around its algorithm (e.g. <p> Scope also utilizes a combination of EBL and induction to learn very general control rules, whereas UCPOP+EBL uses only EBL to build rules. UCPOP+EBL has been shown to improve planning performance in two domains, the blocksworld domain and the briefcase domain <ref> (Penberthy & Weld, 1992) </ref>. To compare Scope to UCPOP+EBL, an experiment was replicated from Kambhampati et al. (1996). This experiment uses three different versions of the blocksworld domain in order to test whether the expressiveness of the domain representation influences the effectiveness of the learner.
Reference: <author> Pendault, E. </author> <year> (1989). </year> <title> ADL: Exploring the middle ground between strips and the situation calculus. </title> <booktitle> In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning. </booktitle>
Reference-contexts: Operators are specified using Pednault's Action Description Language (ADL) <ref> (Pendault, 1989) </ref>, which was discussed in Section 2.1 and is an extension of the well-known STRIPS format (Fikes & Nilsson, 1971). Operators contain precondition, add and delete lists, and they can also contain constructs such as conditional effects, disjunctive preconditions, and universal quantification.
Reference: <author> Perez, M. A. </author> <year> (1995). </year> <title> Learning Search Control Knowledge to Improve Plan Quality. </title> <type> Ph.D. thesis, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: Goals such as minimizing execution time or reducing the number of resources used can be a crucial part of production manufacturing. There are a number of different quality metrics that can be measured for this domain <ref> (Perez, 1995) </ref>, including: * The number of plan steps * The total execution time of the plan * The dollar cost of the plan * The number of resources used by the plan * The feasibility of executing the plan * The reliability of the plan Plan length is usually not <p> One rough measure of the plan execution time can be made by counting the number of set-up steps that exist in the plan <ref> (Perez, 1995) </ref>. Set-up steps usually prepare a machine or part for an operation. For instance, placing a part in a machine or rotating a part already held in a machine are operations that fit in to this category.
Reference: <author> Perez, M. A. </author> <year> (1996). </year> <title> Representing and learning quality-improving search control knowledge. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Machine Learning Bari,Italy. </booktitle>
Reference-contexts: However, some research has concentrated on improving the quality of plans produced by a planner. The most prominent of these systems is the Quality learning system <ref> (Perez, 1996) </ref> which is built on top of the Prodigy4.0 nonlinear planner. Quality inputs a set of planning domain operators, a domain-dependent metric that evaluates the quality of plans and a set of problems for that domain.
Reference: <author> Perez, M. A., & Carbonell, J. </author> <year> (1994). </year> <title> Control knowledge to improve the plan quality. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems Chicago, </booktitle> <address> IL. </address>
Reference-contexts: For instance, it may be vital in a manufacturing domain for a planner to produce plans with low resource consumption, or with least number of possible steps. There are a variety of notions about what makes a good plan. Some of the more common quality metrics are listed below <ref> (Perez & Carbonell, 1994) </ref>: * The length of the plan (or the total number of steps) * The execution time of the plan * The resource consumption required * The robustness of the plan Depending on the domain being used, different quality metrics will have varying importance.
Reference: <author> Poet, M. A., & Smith, D. E. </author> <year> (1993). </year> <title> Threat-removal strategies for partial-order planning. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 492-499 Washington, D.C. </address>
Reference: <author> Pollack, M. E. </author> <year> (1992). </year> <title> The uses of plans. </title> <journal> Artificial Intelligence, </journal> <volume> 57, </volume> <pages> 43-68. </pages>
Reference: <author> Porter, B. W., & Kibler, D. F. </author> <year> (1986). </year> <title> Experimental goal regression: A method for learning problem-solving. </title> <journal> Machine Learning, </journal> <volume> 1 (3), </volume> <pages> 249-285. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address> <note> 115 Quinlan, </note> <editor> J. R. </editor> <booktitle> (1991). Determinate literals in inductive logic programming. In Proceedings of the Eighth International Workshop on Machine Learning Evanston, </booktitle> <address> IL. </address>
Reference-contexts: The inductive search is usually guided by a domain-independent bias. For example, one commonly used bias is Occam's razor <ref> (Quinlan, 1983) </ref> which prefers simple rules over more complex ones. 15 A main advantage of inductive learning techniques over other learning methods such as EBL is that they tend to learn very general control knowledge since they examine a number of different examples.
Reference: <author> Quinlan, J. R., & Cameron-Jones, R. M. </author> <year> (1993). </year> <title> FOIL: A midterm report. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pp. 3-20 Vienna. </pages>
Reference: <author> Quinlan, J. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 (3), </volume> <pages> 239-266. </pages>
Reference-contexts: The ILP algorithm used in this dissertation is a version of the Foil induction algorithm <ref> (Quinlan, 1990) </ref>. Foil learns a function-free, first-order, Horn clause definition of a target concept. When learning control for planning systems, the target concept can correspond to concepts such as "when to apply a particular action" or "when to apply a particular ordering constraint".
Reference: <author> Reddy, C., & Tadepalli, P. </author> <year> (1997). </year> <title> Learning goal-decomposition rules using exercises. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Machine Learning, </booktitle> <pages> pp. 278-286 Nashville,TN. </pages>
Reference-contexts: 99% 124 (7.7x) BW-univ 81% 3126 94% 1699 (1.8x) 90% 1359 100% 5 (271.8x) Table 9.1: Comparison between Scope and UCPOP+EBL for improving the efficiency of UCPOP. systems. 9.2.3 Systems Applied to Decomposition Planners One other type of learning system that has been developed to increase planning efficiency is X-Learn <ref> (Reddy & Tadepalli, 1997) </ref>, which uses a very different approach to control-knowledge acquisition. Instead of learning separate control rules that are incorporated into an existing planning system, X-Learn builds a new decomposition-based problem solver based on a set of training examples.
Reference: <author> Silverstein, G., & Pazzani, M. J. </author> <year> (1991). </year> <title> Relational cliches: Constraining constructive induction during relational learning. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 203-207 Evanston, IL. </address>
Reference: <author> Subramanian, D., & Feldman, R. </author> <year> (1990). </year> <title> The utility of EBL in recursive domains. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 942-949 Boston, MA. </address>
Reference: <author> Tadepalli, P. </author> <year> (1989). </year> <title> Lazy explanation-based learning: A solution to the intractable theory problem. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence Detroit, </booktitle> <address> MI. </address>
Reference: <author> Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. </author> <year> (1995). </year> <title> Integrated planning and learning: The PRODIGY architecture. </title> <journal> Journal of Theoretical and Experimental Artificial Intelligence Research, </journal> <volume> 7 (1). </volume>
Reference: <author> Veloso, M., & Stone, P. </author> <year> (1995). </year> <title> FLECS: Planning with a flexible commitment strategy. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 25-52. </pages>
Reference: <author> Veloso, M. M. </author> <year> (1992). </year> <title> Learning by Analogical Reasoning in General Problem Solving. </title> <type> Ph.D. thesis, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: In many standard approaches to planning, domain actions are represented in a STRIPS operator format (Fikes & Nilsson, 1971), which consists of a list of preconditions, an add list and a delete list. Definitions for several actions from the logistics transportation domain <ref> (Veloso, 1992) </ref> are shown in Figure 2.1. In order for an action to be applied in a plan, its preconditions must be satisfied in the current state of the world. <p> In the absence of control information, the Prolog UCPOP will always select the first valid refinement it finds; other refinements may be tried later through backtracking. An example of a planning decision point from the logistics transportation domain <ref> (Veloso, 1992) </ref> is shown in Figure 4.2 and Figure 4.3. Figure 4.2 shows a simple problem from this domain where the goal is to deliver one package from the Austin airport to the Chicago airport. <p> A.2.3 BW-Univ This version contains universal quantification in its preconditions. operator (puton (X,Y,Z), [on (X,Z),neq (X,Y),neq (X,Z),neq (Y,Z), or ([tab (Y),and ([bloc (Y),forall (bloc (B),not (on (B,Y)))])]), forall (bloc (C),not (on (C,X)))], [on (X,Y),not (on (X,Z))]). A.3 Logistics Transportation Domain The logistics transportation definition <ref> (Veloso, 1992) </ref> that was used in this dissertation is listed below. operator (load_truck (Obj,Truck,Loc), [at_obj (Obj,Loc),at_truck (Truck,Loc)], [inside_truck (Obj,Truck),not (at_obj (Obj,Loc))]). operator (load_airplane (Obj,Airplane,Loc), [at_obj (Obj,Loc),at_airplane (Airplane,Loc)], [inside_airplane (Obj,Airplane),not (at_obj (Obj,Loc))]). operator (unload_truck (Obj,Truck,Loc), [inside_truck (Obj,Truck),at_truck (Truck,Loc)], [at_obj (Obj,Loc),not (inside_truck (Obj,Truck))]). operator (unload_airplane (Obj,Airplane,Loc), [inside_airplane (Obj,Airplane),at_airplane (Airplane,Loc)], [at_obj (Obj,Loc),not (inside_airplane (Obj,Airplane))]).
Reference: <author> Warren, D. </author> <year> (1974). </year> <title> WARPLAN: A system for generating plans. </title> <type> Tech. rep. Memo No. 76, </type> <institution> Department of Computational Logic, University of Edinburgh. </institution>
Reference: <author> Weld, D. </author> <year> (1994). </year> <title> An introduction to least commitment planning. </title> <journal> AI Magazine, </journal> <volume> 15 (4), </volume> <pages> 27-61. </pages>
Reference: <author> Wilensky, R. W. </author> <year> (1983). </year> <title> Planning and Understanding: A Computational Approach to Human Reasoning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference: <author> Williamson, M., & Hanks, S. </author> <year> (1994). </year> <title> Optimal planning with a goal-directed utility model. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems, </booktitle> <pages> pp. </pages> <address> 176-181 Chicago. </address>
Reference-contexts: Foulser, Li, and Yang (1992) promotes plan merging as a technique for minimizing plan cost, where certain operators in a plan are grouped together. Other work has utilized decision theory to improve plan quality. The Pyrrhus planning system <ref> (Williamson & Hanks, 1994) </ref> is an extension to UCPOP that finds optimal plans by using utility models to measure the quality of a partial plan. There have also been some domain-dependent approaches to generate high quality plans. <p> The detailed set of operators in this domain provide for long plans with many possible solutions to the same problem. Scope could also be evaluated on different quality metrics. For instance in both the UM Translog domain and the Truckworld domain utilized by <ref> (Williamson & Hanks, 1994) </ref> resource consumption is an important quality measure. Also, further experiments should be done comparing the multi-strategy learning approach used by Scope to a pure explanation-based approach, such as that used by UCPOP+EBL.
Reference: <author> Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. </author> <year> (1983). </year> <title> Learning physical descriptions from functional definitions, examples, and precedents. </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 433-439 Washington, D.C. </address> <note> 116 Zelle, </note> <author> J. M., & Mooney, R. J. </author> <year> (1993). </year> <title> Combining FOIL and EBG to speed-up logic programs. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 1106-1111 Chambery, France. </address>
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1994a). </year> <title> Combining top-down and bottom-up methods in inductive logic programming. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 343-351 New Brunswick, NJ. </address>
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1994b). </year> <title> Inducing deterministic Prolog parsers from treebanks: A machine learning approach. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 748-753 Seattle, WA. </address>
Reference: <author> Zweben, M., Davis, E., Daun, B., Drascher, E., Deale, M., & Eskey, M. </author> <year> (1992). </year> <title> Learning to improve constraint-based scheduling. </title> <journal> Artificial Intelligence, </journal> <volume> 58, </volume> <pages> 271-296. 117 </pages>
Reference-contexts: The main goal of these methods is to retain the benefits of a domain theory while also having the flexibility to learn from the data. For example, instead of building a complete proof, plausible explanation-based learning (PEBL) <ref> (Zweben, Davis, Daun, Drascher, Deale, & Eskey, 1992) </ref> first conjectures an example is a member of the target concept, and then confirms the conjecture with empirical data.
References-found: 87

