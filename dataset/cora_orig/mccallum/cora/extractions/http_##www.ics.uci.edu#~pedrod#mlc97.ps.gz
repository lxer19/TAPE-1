URL: http://www.ics.uci.edu/~pedrod/mlc97.ps.gz
Refering-URL: http://www.ics.uci.edu/~mlearn/MLPapers.html
Root-URL: 
Email: pedrod@ics.uci.edu  
Title: Knowledge Acquisition from Examples Via Multiple Models  
Author: Pedro Domingos 
Web: http://www.ics.uci.edu/~pedrod  
Address: Irvine, California 92697, U.S.A.  
Affiliation: Dept. Information and Computer Science University of California, Irvine  
Abstract: If it is to qualify as knowledge, a learner's output should be accurate, stable and comprehensible. Learning multiple models can improve significantly on the accuracy and stability of single models, but at the cost of losing their comprehensibility (when they possess it, as do, for example, simple decision trees and rule sets). This paper proposes and evaluates CMM, a meta-learner that seeks to retain most of the accuracy gains of multiple model approaches, while still producing a single comprehensible model. CMM is based on reapplying the base learner to recover the frontiers implicit in the multiple model ensemble. This is done by giving the base learner a new training set, composed of a large number of examples generated and classified according to the ensemble, plus the original examples. CMM is evaluated using C4.5RULES as the base learner, and bagging as the multiple-model methodology. On 26 benchmark datasets, CMM retains on average 60% of the accuracy gains obtained by bagging relative to a single run of C4.5RULES, while producing a rule set whose complexity is typically a small multiple (2-6) of C4.5RULES's, and also improv ing stability.
Abstract-found: 1
Intro-found: 1
Reference: <author> Andrews, R., & Diederich, J. (Eds.) </author> <year> (1996). </year> <title> Proc. NIPS-96 Workshop on Rule Extraction from Trained Artificial Neural Networks. </title> <publisher> Snowmass, CO: The NIPS Foundation. </publisher>
Reference: <author> Angluin, D. </author> <year> (1988). </year> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 319-342. </pages>
Reference-contexts: Algorithms based on queries to an oracle are also relevant to this problem, and have been the object of much study in the theoretical community <ref> (e.g., Angluin, 1988) </ref>. Although oracle-based algorithms are generally of limited usefulness when learning directly from real data, they can be applied more easily in the meta-learning phase, using the previously-learned model (or model ensemble) as the oracle (e.g., Craven & Shavlik, 1994).
Reference: <author> Breiman, L. </author> <year> (1996). </year> <title> Bagging predictors. </title> <journal> Machine Learning, </journal> <volume> 24, </volume> <pages> 123-140. </pages>
Reference-contexts: It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions. Different forms of this "multiple models" approach include bagging <ref> ( Breiman, 1996 ) </ref> , boosting ( Freund & Schapire, 1996 ) , stacking ( Wolpert, 1992 ) , Bayesian averaging ( Buntine, 1990 ) , error-correcting output coding ( Kong & Dietterich, 1995 ) , combiner trees ( Chan & Stolfo, 1995 ) , and others. <p> C4.5RULES also has the advantage of being widely used, and thus constituting a good standard for empirical comparisons. In this system, rules are extracted from a previously-learned decision tree, and are ordered (i.e., if more than one rule applies, the one appearing first in the ordering prevails). Bagging <ref> ( Breiman, 1996 ) </ref> was used as the multiple-model methodology, on account of being perhaps the simplest one available, and of its effectiveness with decision trees being well established ( Breiman, 1996; Quinlan, 1996 ) . <p> This procedure is repeated m times, and the resulting m models are aggregated by uniform voting (i.e., when a test example is presented, the class that is predicted by the greatest number of models is predicted; if a tie occurs, the lowest-ordered class is chosen, as in <ref> ( Breiman, 1996 ) </ref> ). 4 Examples for meta-learning are generated using the probability distribution implicit in the rule sets produced by C4.5RULES. <p> Given that the randomly generated examples are added to the original ones, this implies that the training set size for meta-learning will always be at least twice the size of the original training set. An experimental methodology similar to that of <ref> ( Breiman, 1996 ) </ref> was followed, with 20 runs instead of 100, due to the large number of datasets used. In each run, 90% of the examples in the dataset were randomly chosen for training, and the remainder were used for testing.
Reference: <author> Buntine, W. L. </author> <year> (1990). </year> <title> A Theory of Learning Classification Rules. </title> <type> PhD thesis, </type> <institution> School of Computing Science, University of Technology, Sydney, Aus-tralia. </institution>
Reference-contexts: Different forms of this "multiple models" approach include bagging ( Breiman, 1996 ) , boosting ( Freund & Schapire, 1996 ) , stacking ( Wolpert, 1992 ) , Bayesian averaging <ref> ( Buntine, 1990 ) </ref> , error-correcting output coding ( Kong & Dietterich, 1995 ) , combiner trees ( Chan & Stolfo, 1995 ) , and others.
Reference: <author> Catlett, J. </author> <year> (1991). </year> <title> Megainduction: Machine Learning on Very Large Databases. </title> <type> PhD thesis, </type> <institution> Basser Department of Computer Science, University of Sydney, </institution> <address> Sydney, Australia. </address>
Reference: <author> Chan, P., Stolfo, S., & Wolpert, D. (Eds.) </author> <year> (1996). </year> <booktitle> Proc. AAAI-96 Workshop on Integrating Multiple Learned Models. </booktitle> <address> Portland, OR: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Other researchers have also noted the negative impact of instability on learners' ability to produce knowledge ( Dietterich, 1996 ) . Recently, an approach that mitigates this problem has been the object of much research (see, for example, <ref> ( Chan, Stolfo & Wolpert, 1996 ) </ref> ). It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions.
Reference: <author> Chan, P. K., & Stolfo, S. J. </author> <year> (1995). </year> <title> A comparative evaluation of voting and meta-learning on partitioned data. </title> <booktitle> Proc. Twelfth International Conference on Machine Learning (pp. </booktitle> <pages> 90-98). </pages> <address> Tahoe City, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Different forms of this "multiple models" approach include bagging ( Breiman, 1996 ) , boosting ( Freund & Schapire, 1996 ) , stacking ( Wolpert, 1992 ) , Bayesian averaging ( Buntine, 1990 ) , error-correcting output coding ( Kong & Dietterich, 1995 ) , combiner trees <ref> ( Chan & Stolfo, 1995 ) </ref> , and others. This approach has been found to be quite effective in practice (Drucker, Cortes, Jackel, LeCun & Vapnik, 1994; Quinlan, 1996; etc.), and also has substantial theoretical foundations ( Madigan, Raftery, Volinsky & Hoeting, 1996; Fried-man, 1996 ) .
Reference: <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-283. </pages>
Reference-contexts: This is as desired, and leads to CMM's complexity staying below 250 for almost all domains. Thus, by this measure, CMM can be considered to produce comprehensible output in almost all cases, assuming C4.5RULES does. As a further comparison, another widely-used rule learner, CN2 <ref> ( Clark & Niblett, 1989 ) </ref> , was run on these datasets. While being on average less accurate than C4.5RULES and CMM, CN2 has an output complexity that is often greater than CMM's.
Reference: <author> Cohn, D., Atlas, L., & Ladner, R. </author> <year> (1994). </year> <title> Improving generalization with active learning. </title> <journal> Machine Learning, </journal> <volume> 15, </volume> <pages> 201-221. </pages>
Reference-contexts: Although oracle-based algorithms are generally of limited usefulness when learning directly from real data, they can be applied more easily in the meta-learning phase, using the previously-learned model (or model ensemble) as the oracle (e.g., Craven & Shavlik, 1994). More generally, many forms of active learning <ref> ( Cohn, Atlas & Ladner, 1994 ) </ref> , where the learner has some degree of control over the information it obtains from the environment, are potentially applicable to this problem. 5 FUTURE WORK Several directions for future research are readily apparent, apart from those already mentioned in previous sections.
Reference: <author> Craven, M. W., & Shavlik, J. W. </author> <year> (1994). </year> <title> Using sampling and queries to extract rules from trained neural networks. </title> <booktitle> Proc. Eleventh International Conference on Machine Learning (pp. </booktitle> <pages> 37-45). </pages> <address> New Brunswick, NJ: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although oracle-based algorithms are generally of limited usefulness when learning directly from real data, they can be applied more easily in the meta-learning phase, using the previously-learned model (or model ensemble) as the oracle <ref> (e.g., Craven & Shavlik, 1994) </ref>.
Reference: <author> Datta, P., & Kibler, D. </author> <year> (1995). </year> <title> Learning prototypical concept descriptions. </title> <booktitle> Proc. Twelfth International Conference on Machine Learning (pp. </booktitle> <pages> 158-166). </pages> <address> Tahoe City, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Dietterich, T. G. </author> <year> (1996). </year> <title> Editorial. </title> <journal> Machine Learning, </journal> <volume> 24, </volume> <pages> 91-93. </pages>
Reference-contexts: The engineers lose confidence in the decision trees, even when we can demonstrate that the trees have high predictive accuracy." ( Turney, 1995 ) . Other researchers have also noted the negative impact of instability on learners' ability to produce knowledge <ref> ( Dietterich, 1996 ) </ref> . Recently, an approach that mitigates this problem has been the object of much research (see, for example, ( Chan, Stolfo & Wolpert, 1996 ) ).
Reference: <author> Domingos, P. </author> <year> (1996). </year> <title> Linear-time rule induction. </title> <booktitle> Proc. Second International Conference on Knowledge Discovery and Data Mining (pp. </booktitle> <pages> 96-101). </pages> <address> Port-land, OR: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Drucker, H., Cortes, C., Jackel, L. D., LeCun, Y., & Vapnik, V. </author> <year> (1994). </year> <title> Boosting and other machine learning algorithms. </title> <booktitle> Proc. Eleventh International Conference on Machine Learning (pp. </booktitle> <pages> 53-61). </pages> <address> New Brunswick, NJ: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Duda, R. O., & Hart, P. E. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <address> New York, NY: </address> <publisher> Wiley. </publisher>
Reference-contexts: More precisely, if x is an unclassified example and c its class, since the "true" probability distribution P r (x) is usually unknown, it should be estimated as closely as possible. While many general methods exist for approximately solving this problem (e.g., Parzen windows <ref> ( Duda & Hart, 1973 ) </ref> ), in the implementation described below the approach followed is one of replicating the way the learner L implicitly models P r (x). This avoids a mismatch between the bias of L and that of the probability estimation procedure.
Reference: <author> Evans, B., & Fisher, D. </author> <year> (1994). </year> <title> Process delay analysis using decision tree induction. </title> <journal> IEEE Expert, </journal> <volume> 9 (1), </volume> <pages> 60-66. </pages>
Reference: <author> Fayyad, U. M., Djorgovski, S. G., & Weir, N. </author> <year> (1996). </year> <title> From digitized images to online catalogs: Data mining a sky survey. </title> <journal> AI Magazine, </journal> <volume> 17 (2), </volume> <pages> 51-66. </pages>
Reference: <author> Freund, Y., & Schapire, R. E. </author> <year> (1996). </year> <title> Experiments with a new boosting algorithm. </title> <booktitle> Proc. Thirteenth International Conference on Machine Learning (pp. </booktitle> <pages> 148-156). </pages> <address> Bari, Italy: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions. Different forms of this "multiple models" approach include bagging ( Breiman, 1996 ) , boosting <ref> ( Freund & Schapire, 1996 ) </ref> , stacking ( Wolpert, 1992 ) , Bayesian averaging ( Buntine, 1990 ) , error-correcting output coding ( Kong & Dietterich, 1995 ) , combiner trees ( Chan & Stolfo, 1995 ) , and others. <p> The procedure just described, which will be called CMM (for "Combined Multiple Models"), is shown in pseudo-code in Table 1. 3 Two significant points should the same instances, but with different weights, as in boosting <ref> ( Freund & Schapire, 1996 ) </ref> . 2 Which, in the limit, can be m different learners, as is typically done in stacking ( Wolpert, 1992 ) . 3 Instead of variations of S, variations of L may be used.
Reference: <author> Friedman, J. H. </author> <year> (1996). </year> <title> On bias, variance, 0/1 loss, and the curse-of-dimensionality. </title> <type> Technical report, </type> <institution> Department of Statistics and Stanford Linear Accelerator Center, Stanford University, Stanford, </institution> <address> CA. </address>
Reference: <author> Jensen, D. </author> <year> (1997). </year> <title> Adjusting for multiple testing in decision tree pruning. </title> <booktitle> Proc. Sixth International Workshop on Artificial Intelligence and Statistics (pp. </booktitle> <pages> 295-302). </pages> <address> Fort Lauderdale, FL: </address> <booktitle> Society for Artificial Intelligence and Statistics. </booktitle>
Reference: <author> Kohavi, R., & Wolpert, D. H. </author> <year> (1996). </year> <title> Bias plus variance decomposition for zero-one loss functions. </title> <booktitle> Proc. Thirteenth International Conference on Machine Learning (pp. </booktitle> <pages> 275-283). </pages> <address> Bari, Italy: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, and crucially, because the accuracy and stability of learned models tend to increase with training set size (due to decreasing variance <ref> ( Kohavi & Wolpert, 1996 ) </ref> ), and the training set size for the meta-learning step can be made as large as desired, subject to computational resource constraints, it should be possible to obtain a meta-learned model that is more accurate and stable than the base models.
Reference: <author> Kong, E. B., & Dietterich, T. G. </author> <year> (1995). </year> <title> Error-correcting output coding corrects bias and variance. </title> <booktitle> Proc. Twelfth International Conference on Machine Learning (pp. </booktitle> <pages> 313-321). </pages> <address> Tahoe City, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Different forms of this "multiple models" approach include bagging ( Breiman, 1996 ) , boosting ( Freund & Schapire, 1996 ) , stacking ( Wolpert, 1992 ) , Bayesian averaging ( Buntine, 1990 ) , error-correcting output coding <ref> ( Kong & Dietterich, 1995 ) </ref> , combiner trees ( Chan & Stolfo, 1995 ) , and others.
Reference: <author> Madigan, D., Raftery, A. E., Volinsky, C. T., & Hoet-ing, J. A. </author> <year> (1996). </year> <title> Bayesian model averaging. </title> <booktitle> Proc. AAAI-96 Workshop on Integrating Multiple Learned Models (pp. </booktitle> <pages> 77-83). </pages> <address> Portland, OR: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Merz, C. J., Murphy, P. M., & Aha, D. W. </author> <year> (1997). </year> <title> UCI repository of machine learning databases. </title> <institution> Department of Information and Computer Science, University of California at Irvine, </institution> <address> Irvine, CA. </address>
Reference-contexts: To this end, experiments were carried out using a varied and representative sample of 26 datasets from the Irvine repository <ref> ( Merz, Murphy & Aha, 1997 ) </ref> .
Reference: <author> Oates, T., & Jensen, D. </author> <year> (1997). </year> <title> The effects of training set size on decision tree complexity. </title> <booktitle> Proc. Sixth International Workshop on Artificial Intelligence and Statistics (pp. </booktitle> <pages> 379-390). </pages> <address> Fort Lauderdale, FL: </address> <booktitle> Society for Artificial Intelligence and Statistics. </booktitle>
Reference: <author> Pazzani, P., Mani, M., & Shankle, W. R. </author> <year> (1997). </year> <title> Comprehensible knowledge discovery in databases. </title> <booktitle> Proc. Nineteenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Stanford, CA: </address> <note> Erlbaum. To appear. </note>
Reference-contexts: A limitation of the work described here is that it uses a somewhat naive notion of comprehensibility, equating it with simplicity. In reality, many other factors are involved, and will vary from one user group to another <ref> (e.g., Pazzani, Mani & Shankle, 1997) </ref>. Although arriving at a better definition of comprehensibility is a difficult task due to the subjective component involved, much progress should result from seeking a deeper understanding of what makes a model comprehensible, and using the results to guide algorithms like CMM.
Reference: <author> Quinlan, J. R. </author> <year> (1987). </year> <title> Generating production rules from decision trees. </title> <booktitle> Proc. Tenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 304-307). </pages> <address> Milan, Italy: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: C4.5RULES <ref> ( Quinlan, 1993 ) </ref> release 8 was used as the base learner. C4.5RULES produces propositional rule sets, which we believe to be the most easily understood of all representations currently in use. C4.5RULES also has the advantage of being widely used, and thus constituting a good standard for empirical comparisons.
Reference: <author> Quinlan, J. R. </author> <year> (1996). </year> <title> Bagging, boosting, </title> <booktitle> and C4.5. Proc. Thirteenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 725-730). </pages> <address> Portland, OR: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Shannon, W. D., & Banks, D. </author> <year> (1997). </year> <title> A distance metric for classification trees. </title> <booktitle> Proc. Sixth International Workshop on Artificial Intelligence and Statistics (pp. </booktitle> <pages> 457-464). </pages> <address> Fort Lauderdale, FL: </address> <booktitle> Society for Artificial Intelligence and Statistics. </booktitle>
Reference: <author> Towell, G. G., & Shavlik, J. W. </author> <year> (1993). </year> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13, </volume> <pages> 71-101. </pages>
Reference: <author> Turney, P. </author> <year> (1995). </year> <title> Bias and the quantification of stability. </title> <journal> Machine Learning, </journal> <volume> 20, </volume> <pages> 23-33. </pages>
Reference-contexts: The engineers lose confidence in the decision trees, even when we can demonstrate that the trees have high predictive accuracy." <ref> ( Turney, 1995 ) </ref> . Other researchers have also noted the negative impact of instability on learners' ability to produce knowledge ( Dietterich, 1996 ) . <p> It may thus be possible to substantially optimize CMM's complexity without seriously affecting accuracy by choosing n as a function of dataset size. This is a matter for future research. Stability was measured following the ideas contained in <ref> ( Turney, 1995 ) </ref> , and taking advantage of the models produced in the train-test runs carried out. The stability of a system is defined as the (estimated) probability that models generated by the system from different training sets will agree on an arbitrary example. <p> The use of a uniform distribution reflects a deeper notion of stability than that implicit in using some estimate of the dataset's distribution <ref> ( Turney, 1995 ) </ref> . Note that, because the different models are not generated from independent training sets, the empirical measure above will tend to overestimate stability. The results are shown in Table 2. On average, bagging is 6% more stable than a single run of C4.5RULES.
Reference: <author> Utans, J. </author> <year> (1996). </year> <title> Weight averaging for neural networks and local resampling schemes. </title> <booktitle> Proc. AAAI-96 Workshop on Integrating Multiple Learned Models (pp. </booktitle> <pages> 133-138). </pages> <address> Portland, OR: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Wolpert, D. </author> <year> (1992). </year> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5, </volume> <pages> 241-259. </pages>
Reference-contexts: Different forms of this "multiple models" approach include bagging ( Breiman, 1996 ) , boosting ( Freund & Schapire, 1996 ) , stacking <ref> ( Wolpert, 1992 ) </ref> , Bayesian averaging ( Buntine, 1990 ) , error-correcting output coding ( Kong & Dietterich, 1995 ) , combiner trees ( Chan & Stolfo, 1995 ) , and others. <p> CMM (for "Combined Multiple Models"), is shown in pseudo-code in Table 1. 3 Two significant points should the same instances, but with different weights, as in boosting ( Freund & Schapire, 1996 ) . 2 Which, in the limit, can be m different learners, as is typically done in stacking <ref> ( Wolpert, 1992 ) </ref> . 3 Instead of variations of S, variations of L may be used. <p> Note that this procedure is quite different from stacking <ref> (Wolpert, 1992) </ref>, where the final output is a two-level classifier that explicitly includes all the models produced, plus a meta-classifier to combine their predictions at performance time. Table 1. The CMM meta-learning algorithm.
References-found: 34

