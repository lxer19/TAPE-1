URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3636.1/3636.1.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: pugh@cs.umd.edu ejr@cs.umd.edu murka@cs.umd.edu  
Title: Exploiting Monotone Convergence Functions in Parallel Programs  
Author: William Pugh Evan Rosser Tatiana Shpeisman 
Note: This work is supported by an NSF PYI grant CCR-9157384 and by a Packard Fellowship.  
Address: College Park, MD 20742  
Affiliation: Inst. for Advanced Computer Studies Dept. of Computer Science Dept. of Computer Science Dept. of Computer Science Univ. of Maryland,  
Date: October, 1996  
Pubnum: UMIACS-TR-96-31.1  CS-TR-3636.1  
Abstract: Scientific codes which use iterative methods are often difficult to parallelize well. Such codes usually contain while loops which iterate until they converge upon the solution. Problems arise since the number of iterations cannot be determined at compile time, and tests for termination usually require a global reduction and an associated barrier. We present a method which allows us avoid performing global barriers and exploit pipelined parallelism when processors can detect non-convergence from local information. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.-F. Collard. </author> <title> Space-time transformation of while-loops using speculative execution. </title> <booktitle> In Proc. of the 1994 Scalable High Performance Computing Conf., </booktitle> <pages> pages 429-436, </pages> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year> <note> IEEE. </note>
Reference: 2. <author> J.-F. Collard. </author> <title> Automatic parallelization of while-loops using speculative execution. </title> <journal> Int. J. of Parallel Programming, </journal> <volume> 23(2) </volume> <pages> 191-219, </pages> <month> April </month> <year> 1995. </year>
Reference: 3. <author> M. Griebl and J.-F. Collard. </author> <title> Generation of synchronous code for automatic paral-lelization of while loops. In N.N., editor, </title> <booktitle> EuroPar 95, Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: 4. <author> M. Griebl and C. Lengauer. </author> <title> On scanning space-time mapped while loops. </title> <editor> In B. Buchberger and J. Volkert, editors, </editor> <booktitle> Parallel Processing: CONPAR 94 - VAPP VI, Lecture Notes in Computer Science 854, </booktitle> <pages> pages 677-688. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: 5. <author> M. Griebl and C. Lengauer. </author> <title> On the space-time mapping of WHILE-loops. </title> <journal> Parallel Processing Letters, </journal> <volume> 4(3) </volume> <pages> 221-232, </pages> <month> September </month> <year> 1994. </year>
Reference: 6. <author> David Kincaid and Ward Cheney. </author> <title> Numerical Analysis. </title> <publisher> Brooks/Cole Publishing Company, </publisher> <year> 1991. </year>
Reference-contexts: Laplace's equation @u 2 =@x 2 + @u 2 =@y 2 = 0 on the region = f (x; y) : 0 &lt; x &lt; 1; 0 &lt; y &lt; 1g with the Dirichlet boundary conditions defined by function g (x; y) = sinh (3y) sinh (3y) fl 10 3 <ref> [6] </ref>. // Set the initial guess for u j;l for l = 1 to N do if j = 1 or j = N or l = 1 or l = N then u j;l = g ( j1 N ) else u j;l = 0 endfor endfor // Iterate until
Reference: 7. <author> C. Lengauer and M. Griebl. </author> <title> On the parallelization of loop nests containing while loops. </title> <editor> In N. N. Mirenkov, Q.-P. Gu, S. Peng, and S. Sedukhin, editors, </editor> <booktitle> Proc. 1st Aizu Int. Symp. on Parallel Algorithm/Architecture Synthesis (pAs'95), </booktitle> <pages> pages 10-18. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference: 8. <author> William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> second edition, </address> <year> 1992. </year>
Reference-contexts: At each iteration, a processor probes to see if such a message from the master processor has arrived. Communication between individual processors is not affected by this optimization. An example of the transformed code appears in Figure 2. The code is adapted from <ref> [8] </ref>. 3 Example: SOR In this section we present an example program that can be parallelized using our method. The major program class arises from solving partial differential equation (PDE) boundary value problems using finite-difference methods [8,6]. <p> This problem can be solved iteratively using one of the relaxation methods. We shall consider solving it using Successive Over-relaxation (SOR) with Chebyshev acceleration <ref> [8] </ref>. The algorithm is shown in Figure 3. At each iteration the new values u i+1 j;l are computed from the old values u i j+1;l ,u i j;l+1 and u i j;l1 .
References-found: 8

