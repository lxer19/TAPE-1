URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/MP-TR-94-08/MP-TR-94-08.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/MP-TR-94-08/
Root-URL: http://www.cs.wisc.edu
Title: Projected Gradient Methods for NCP 57 Recent Advances in Nonsmooth Optimization, pp. 57-86 Projected Gradient
Author: Eds. D.-Z. Du, L. Qi and R.S. Womersley Michael C. Ferris Daniel Ralph 
Address: Madison, WI 53706, USA  Melbourne, Australia  
Affiliation: University of Wisconsin-Madison, Computer Sciences Department,  University of Melbourne, Department of Mathematics,  
Note: c fl1995 World Scientific Publishers  
Abstract: We present a new approach to solving nonlinear complementarity problems based on the normal map and adaptations of the projected gradient algorithm. We characterize a Gauss-Newton point for nonlinear complementarity problems and show that it is sufficient to check at most two cells of the related normal manifold to determine such points. Our algorithm uses the projected gradient method on one cell and n rays to reduce the normed residual at the current point. Global convergence is shown under very weak assumptions using a property called nonstationary repulsion. A hybrid algorithm maintains global convergence, with quadratic local convergence under appropriate assumptions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. V. Burke and M. C. Ferris, </author> <title> A Gauss-Newton method for convex composite optimization, </title> <type> Technical Report, 1176, </type> <institution> Computer Sciences Department, University of Wisconsin (Madison, Wisconsin 53706, </institution> <year> 1993). </year>
Reference-contexts: However singularities occur in many problems, for instance see [12], causing numerical difficulties for, or outright failure of these methods. To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references <ref> [1, 9, 19, 23, 22, 24] </ref>. Alternative techniques can be found in [8, 10, 14, 17, 18, 36]. Most of the notation in this paper is standard. <p> To make comparisons easy, we use the general notion of a Newton path [28] which, given the iterate x k , is some function p k : <ref> [0; 1] </ref> ! IR n with p k (0) = x k ; the next iterate x k+1 is defined as p k (ff) for some ff 2 [0; 1] (details are given below). <p> use the general notion of a Newton path [28] which, given the iterate x k , is some function p k : <ref> [0; 1] </ref> ! IR n with p k (0) = x k ; the next iterate x k+1 is defined as p k (ff) for some ff 2 [0; 1] (details are given below). We say a Newton iterate or Newton step is taken if x k+1 = p k (1). We may not take a Newton step, however, if it does not yield "sufficient progress".
Reference: [2] <author> P. H. Calamai and J. J. </author> <title> More, Projected gradient methods for linearly constrained problems, </title> <note> Mathematical Programming 39 (1987) 93-116. </note>
Reference-contexts: The second key idea, motivated by the characterizations above, is to apply variants of the projected gradient method <ref> [2] </ref> simultaneously to a single cell and n rays, to reduce . <p> of the Pro jected Gradient Method Let be a nonempty closed convex set in IR n and : ! IR be C 1 . (We are thinking of being an orthant and = j .) We paraphrase the description of the projected gradient (PG) algorithm given by Calamai and More <ref> [2] </ref> for the problem min (x): (6) For any ff &gt; 0, the first-order necessary condition for x to be a local minimizer of this problem is that (x ffr (x)) = x: When x k 2 is nonstationary, a step length ff k &gt; 0 is chosen by searching the <p> According to <ref> [2, (2.4)] </ref>, hr (x); x (ff) xi kx (ff) xk =ff; 8x 2 ; ff &gt; 0: Moreover, [2, Lemma 2.2] says that, as a function of ff &gt; 0, kx (ff) xk =ff is antitone (nonincreasing); in particular for any ff &gt; 0, kx (ff) xk =ff kx ( ff) <p> According to [2, (2.4)], hr (x); x (ff) xi kx (ff) xk =ff; 8x 2 ; ff &gt; 0: Moreover, <ref> [2, Lemma 2.2] </ref> says that, as a function of ff &gt; 0, kx (ff) xk =ff is antitone (nonincreasing); in particular for any ff &gt; 0, kx (ff) xk =ff kx ( ff) xk =ff; 8ff 2 (0; ff): Using this with the previous inequality, we deduce for any ff &gt; <p> Using the well known antitone property of hr (x); x (ff) xi in ff 0, see <ref> [2, (2.6)] </ref>, we see that (12) also holds for ff &gt; *. The following result gives some technical properties of the PG method that will be important for our main algorithm. <p> If such a limit point x fl is in fact a point of attraction of a Newton method, and a Newton step is taken every `th iteration, then convergence will be `-step superlinear, or `-step quadratic if rf is Lipschitz. See <ref> [2] </ref> for details on a related hybrid algorithm in the context of quadratic programming. We briefly sketch three popular Newton methods for solving the nonsmooth equation f + (x) = 0; which often produce Q-quadratically convergent sequences of iterates.
Reference: [3] <author> R. W. Cottle, J. S. Pang and R. E. Stone, </author> <title> The Linear Complementarity Problem (Academic Press, </title> <address> Boston, </address> <year> 1992). </year>
Reference-contexts: Note that ~z i = 0 when i =2 D. The results we now give impose conditions of J (x) to guarantee regularity. We note that A 2 IR nfin is an S-matrix if there is an x &gt; 0 with Ax &gt; 0, see <ref> [3] </ref>. Theorem 2.6 Let J (x) = T 1 rf (x + )T 1 . If [J (x)] EE is an S-matrix for some index set E with D E fi: x i 0g, then x is regular. <p> A is a P -matrix if all its principal minors are positive. P -matrices are S-matrices <ref> [3, Corollary 3.3.5] </ref>. The following corollary is now immediate. Corollary 2.7 If [rf (x + )] DD is a P -matrix, then x is regular. Proof The hypotheses imply that [J (x)] DD is a P -matrix and hence an S-matrix. <p> Using the invertibility assumption from (5) and z 2 K again, we see that EE [rf (x + ) T ] EM z M 0; z M 0: The Schur complement is a P -matrix and hence z = 0 follows from <ref> [3, Theorem 3.3.4] </ref>. 3 Nonstationary Repulsion (NSR) of the Pro jected Gradient Method Let be a nonempty closed convex set in IR n and : ! IR be C 1 . (We are thinking of being an orthant and = j .) We paraphrase the description of the projected gradient (PG)
Reference: [4] <author> S. P. Dirkse and M. C. Ferris, </author> <title> A pathsearch damped Newton method for computing general equilibria, </title> <type> Mathematical Programming Technical Report 94-03, </type> <institution> Computer Sciences Department, University of Wisconsin (Madison, Wisconsin 53706, </institution> <year> 1994). </year>
Reference-contexts: For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise. This has proven to be the case as demonstrated by recent advances on nonsmooth Newton-like algorithms for (NE) in <ref> [5, 4, 12, 28, 34] </ref>. Nonsmoothness of the normal map, however, is the difficulty assumed. In fact, normal maps such as f + can be cast in a more general framework, where x + is replaced by (x), the projection of x onto a nonempty closed convex set . <p> In <ref> [5, 4, 28, 34] </ref> these approximation properties have been exploited to give strong convergence results for Newton methods applied to nonsmooth equations like f + (x) = 0. Our main algorithm, below, and its extremely robust convergence behavior also rely on these approximation properties. <p> Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9). Further work on Newton 2 is given in [12, 20, 27] and on Newton 3 in <ref> [5, 4] </ref>. We define a hybrid algorithm involving Algorithm 2, for global convergence properties under no regularity assumptions, and Newton's method for fast local convergence under one of the regularity assumptions (A) or (B). Hybrid.
Reference: [5] <author> S. P. Dirkse and M. C. Ferris, </author> <title> The PATH solver: A non-monotone stabilization scheme for mixed complementarity problems, Optimization Methods & Software (1994, </title> <publisher> forthcoming). </publisher>
Reference-contexts: For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise. This has proven to be the case as demonstrated by recent advances on nonsmooth Newton-like algorithms for (NE) in <ref> [5, 4, 12, 28, 34] </ref>. Nonsmoothness of the normal map, however, is the difficulty assumed. In fact, normal maps such as f + can be cast in a more general framework, where x + is replaced by (x), the projection of x onto a nonempty closed convex set . <p> Then it is easy to see that ~p 2 T K, see (3). Furthermore, ~z T J (x)~p = ~z T D [J (x)~p] D &gt; 0. Hence x is regular. Note that <ref> [5, 12, 28] </ref> all assume that [rf (x + )] EE is nonsingular and ([rf (x + )] LL n [rf (x + )] EE ) is a P -matrix. (5) Here E def = fi: x i &gt; 0g contains N and L def = fi: x i 0g contains <p> In <ref> [5, 4, 28, 34] </ref> these approximation properties have been exploited to give strong convergence results for Newton methods applied to nonsmooth equations like f + (x) = 0. Our main algorithm, below, and its extremely robust convergence behavior also rely on these approximation properties. <p> Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9). Further work on Newton 2 is given in [12, 20, 27] and on Newton 3 in <ref> [5, 4] </ref>. We define a hybrid algorithm involving Algorithm 2, for global convergence properties under no regularity assumptions, and Newton's method for fast local convergence under one of the regularity assumptions (A) or (B). Hybrid.
Reference: [6] <author> M. C. Ferris and S. Lucidi, </author> <title> Nonmonotone stabilization methods for nonlinear equations, </title> <note> Journal of Optimization Theory and Applications 81 (1994) 53-74. </note>
Reference: [7] <author> R. Fletcher, </author> <title> Practical Methods of Optimization (John Wiley & Sons, </title> <address> New York, </address> <note> second edn., </note> <year> 1987). </year>
Reference-contexts: Condition (8) forces ff k not to be too small; in the case that ff k &lt; fl 1 , this requirement is the analogue of the standard Wolfe-Goldstein <ref> [7] </ref> condition from unconstrained optimization. The PG method is a feasible point algorithm in that it requires a starting point x 0 in and produces a sequence of iterates fx k g .
Reference: [8] <author> M. Fukushima, </author> <title> Equivalent differentiable optimization problems and descent methods for asymmetric variational inequality problems, </title> <note> Mathematical Programming 53 (1992) 99-110. </note>
Reference-contexts: To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references [1, 9, 19, 23, 22, 24]. Alternative techniques can be found in <ref> [8, 10, 14, 17, 18, 36] </ref>. Most of the notation in this paper is standard.
Reference: [9] <author> S. A. Gabriel and J. S. Pang, </author> <title> An inexact NE/SQP method for solving the nonlinear complementarity problem, </title> <note> Computational Optimization and Applications 1 (1992) 67-91. Projected Gradient Methods for NCP 85 </note>
Reference-contexts: However singularities occur in many problems, for instance see [12], causing numerical difficulties for, or outright failure of these methods. To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references <ref> [1, 9, 19, 23, 22, 24] </ref>. Alternative techniques can be found in [8, 10, 14, 17, 18, 36]. Most of the notation in this paper is standard.
Reference: [10] <author> P. T. Harker, </author> <title> Lectures on Computation of Equilibria with Equation-Based Methods, CORE Lecture Series (CORE Foundation, </title> <institution> Louvain-la-Neuve, Universite Catholique de Louvain, </institution> <year> 1993). </year>
Reference-contexts: To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references [1, 9, 19, 23, 22, 24]. Alternative techniques can be found in <ref> [8, 10, 14, 17, 18, 36] </ref>. Most of the notation in this paper is standard.
Reference: [11] <author> P. T. Harker and J. S. Pang, </author> <title> Finite-dimensional variational inequality and nonlinear complementarity problems: A survey of theory, algorithms and applications, </title> <note> Mathematical Programming 48 (1990) 161-220. </note>
Reference-contexts: In this context, finding a zero of the normal map f (x) = f ( (x)) + x (x) is equivalent to a nonlinear variational inequality <ref> [11] </ref> defined by the set and the function f . In the special case where IR n + , f = f + . For polyhedral , the normal map [31, 33] f is intimately related to the normal manifold [32].
Reference: [12] <author> P. T. Harker and B. Xiao, </author> <title> Newton's method for the nonlinear complementarity problem: A B-differentiable equation approach, </title> <note> Mathematical Programming 48 (1990) 339-358. </note>
Reference-contexts: For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise. This has proven to be the case as demonstrated by recent advances on nonsmooth Newton-like algorithms for (NE) in <ref> [5, 4, 12, 28, 34] </ref>. Nonsmoothness of the normal map, however, is the difficulty assumed. In fact, normal maps such as f + can be cast in a more general framework, where x + is replaced by (x), the projection of x onto a nonempty closed convex set . <p> A feature shared by "pure" Newton methods is the need for an invertible model function at the current iteration; applying the inverse of this model yields the next iterate. However singularities occur in many problems, for instance see <ref> [12] </ref>, causing numerical difficulties for, or outright failure of these methods. To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references [1, 9, 19, 23, 22, 24]. <p> Then it is easy to see that ~p 2 T K, see (3). Furthermore, ~z T J (x)~p = ~z T D [J (x)~p] D &gt; 0. Hence x is regular. Note that <ref> [5, 12, 28] </ref> all assume that [rf (x + )] EE is nonsingular and ([rf (x + )] LL n [rf (x + )] EE ) is a P -matrix. (5) Here E def = fi: x i &gt; 0g contains N and L def = fi: x i 0g contains <p> This boundedness property holds in many cases, for instance if f is a uniform P-function, see Harker and Xiao <ref> [12] </ref>; hence if f is strongly monotone. However the uniform P-function property implies that f 0 + (x; ) is invertible for each x, a condition that we believe is too strong in general (c.f. Lemma 2.9). <p> Assumption (B) implies assumption (A) but not vice versa; assumption (A) is called BD-regularity [27]. Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9). Further work on Newton 2 is given in <ref> [12, 20, 27] </ref> and on Newton 3 in [5, 4]. We define a hybrid algorithm involving Algorithm 2, for global convergence properties under no regularity assumptions, and Newton's method for fast local convergence under one of the regularity assumptions (A) or (B). Hybrid.
Reference: [13] <author> N. H. Josephy, </author> <title> Newton's method for generalized equations, </title> <type> Technical Summary Report 1965, </type> <institution> Mathematics Research Center, University of Wisconsin (Madison, Wisconsin, </institution> <year> 1979). </year>
Reference: [14] <author> C. Kanzow, </author> <title> Some equation-based methods for the nonlinear complementarity problem, </title> <note> Optimization Methods and Software 3 (1994) 327-340. </note>
Reference-contexts: To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references [1, 9, 19, 23, 22, 24]. Alternative techniques can be found in <ref> [8, 10, 14, 17, 18, 36] </ref>. Most of the notation in this paper is standard.
Reference: [15] <author> M. Kojima and S. Shindo, </author> <title> Extensions of Newton and quasi-Newton methods to systems of PC 1 equations, </title> <journal> Journal of Operations Research Society of Japan 29 (1986) 352-374. </journal>
Reference-contexts: Suppose f + (x) = 0. Assumption (A) is sufficient for Newton 1 to produce a sequence fx k g such that the Newton step is taken at each iteration k 0 k, if some x k is near enough to x <ref> [15, 26] </ref>. Furthermore, fx k g converges Q-quadratically to x. However (A) may not be sufficient for Newton 2 and Newton 3 to be well-defined, even though some x k is arbitrarily close to x.
Reference: [16] <author> B. Kummer, </author> <title> Newton's method for non-differentiable functions, </title> <booktitle> in: Advances in Mathematical Optimization (Akademie-Verlag, </booktitle> <address> Berlin, </address> <note> 1988) pp. 114-125. </note>
Reference-contexts: Algorithm 2 now proceeds from this point by relinearizing. Applying the Hybrid algorithm in the new cell would lead to the solution in very few iterations. Acknowledgement. We thank an anonymous referee for drawing our attention to reference <ref> [16] </ref>.
Reference: [17] <author> O. L. Mangasarian, </author> <title> Equivalence of the complementarity problem to a system of nonlinear equations, </title> <note> SIAM Journal on Applied Mathematics 31 (1976) 89-92. </note>
Reference-contexts: To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references [1, 9, 19, 23, 22, 24]. Alternative techniques can be found in <ref> [8, 10, 14, 17, 18, 36] </ref>. Most of the notation in this paper is standard.
Reference: [18] <author> P. Marcotte and J.-P. Dussault, </author> <title> A note on a globally convergent Newton method for solving monotone variational inequalities, </title> <note> Operations Research Letters 6 (1987) 35-42. </note>
Reference-contexts: To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references [1, 9, 19, 23, 22, 24]. Alternative techniques can be found in <ref> [8, 10, 14, 17, 18, 36] </ref>. Most of the notation in this paper is standard.
Reference: [19] <author> J. J. </author> <title> More, Global methods for nonlinear complementarity problems, </title> <type> Technical Report, </type> <institution> MCS-P429-0494, Argonne National Laboratory (Argonne, Illinois, </institution> <year> 1994). </year>
Reference-contexts: However singularities occur in many problems, for instance see [12], causing numerical difficulties for, or outright failure of these methods. To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references <ref> [1, 9, 19, 23, 22, 24] </ref>. Alternative techniques can be found in [8, 10, 14, 17, 18, 36]. Most of the notation in this paper is standard. <p> In order to generate a more testable notion of regularity, we follow the development of More <ref> [19] </ref>. Here, f + (x) is replaced by a general vector z and extra conditions that Projected Gradient Methods for NCP 65 are satisfied by f + (x) are used to weaken the regularity assumption. <p> Definition 2.4 A point x 2 IR n is said to be regular if the only z satisfying z 2 K; rf (x + ) T z 2 K ffi ; z P 0; z N 0; z C = 0 This condition is closely related to <ref> [19, Definition 3.1] </ref>. <p> In contrast to <ref> [19, 22] </ref>, the point x is not constrained to be nonneg ative. Using Definition 2.4, we can prove the following result. Lemma 2.5 x is a regular stationary point for if and only if x solves (NE). <p> Conversely, if x is stationary, then Proposition 2.3 shows that z = f + (x) satisfies all the relations required in the definition of regularity, and hence f + (x) = 0. We turn to the question of testing whether a point x is regular. <ref> [19, 22, 28] </ref> give several conditions on the Jacobian of f to ensure that x is regular in the sense defined in the corresponding paper. For brevity we only discuss the s-regularity condition of Pang and Gabriel [22], and do not repeat definitions here. <p> For brevity we only discuss the s-regularity condition of Pang and Gabriel [22], and do not repeat definitions here. More <ref> [19] </ref> argues that s-regularity is stronger than his regularity condition; a similar comparison between Definition 2.4 and s-regularity can be made. Here we make a new observation about s-regularity. <p> So s-regularity is too strong in the context of this investigation. 66 M. C. Ferris and D. Ralph In what follows, we give conditions that ensure x to be regular in the sense of Definition 2.4. These results are proven by adapting arguments from More <ref> [19] </ref>. A key construct in the results is the matrix J (x) = T 1 rf (x + )T 1 where T = diag (t i ); t i = ( 1 if i =2 P. <p> The proof of the following result is modeled after <ref> [19, Corollary 4.6] </ref>. Projected Gradient Methods for NCP 67 Theorem 2.8 If [rf (x + )] N N is nonsingular and the Schur complement of [rf (x + )] N N in [J (x)] DD is an S-matrix, then x is regular.
Reference: [20] <author> J. S. Pang, </author> <title> Newton's method for B-differentiable equations, </title> <note> Mathematics of Operations Research 15 (1990) 311-341. </note>
Reference-contexts: Assumption (B) implies assumption (A) but not vice versa; assumption (A) is called BD-regularity [27]. Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9). Further work on Newton 2 is given in <ref> [12, 20, 27] </ref> and on Newton 3 in [5, 4]. We define a hybrid algorithm involving Algorithm 2, for global convergence properties under no regularity assumptions, and Newton's method for fast local convergence under one of the regularity assumptions (A) or (B). Hybrid.
Reference: [21] <author> J. S. Pang, </author> <title> A B-differentiable equation based, globally and locally quadratically convergent algorithm for nonlinear programs, complementarity and variational inequality problems, </title> <note> Mathematical Programming 51 (1991) 101-132. </note>
Reference: [22] <author> J. S. Pang and S. A. Gabriel, NE/SQP: </author> <title> A robust algorithm for the nonlinear complementarity problem, </title> <note> Mathematical Programming 60 (1993) 295-338. 86 M. </note> <editor> C. Ferris and D. </editor> <publisher> Ralph </publisher>
Reference-contexts: However singularities occur in many problems, for instance see [12], causing numerical difficulties for, or outright failure of these methods. To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references <ref> [1, 9, 19, 23, 22, 24] </ref>. Alternative techniques can be found in [8, 10, 14, 17, 18, 36]. Most of the notation in this paper is standard. <p> In contrast to <ref> [19, 22] </ref>, the point x is not constrained to be nonneg ative. Using Definition 2.4, we can prove the following result. Lemma 2.5 x is a regular stationary point for if and only if x solves (NE). <p> Conversely, if x is stationary, then Proposition 2.3 shows that z = f + (x) satisfies all the relations required in the definition of regularity, and hence f + (x) = 0. We turn to the question of testing whether a point x is regular. <ref> [19, 22, 28] </ref> give several conditions on the Jacobian of f to ensure that x is regular in the sense defined in the corresponding paper. For brevity we only discuss the s-regularity condition of Pang and Gabriel [22], and do not repeat definitions here. <p> For brevity we only discuss the s-regularity condition of Pang and Gabriel <ref> [22] </ref>, and do not repeat definitions here. More [19] argues that s-regularity is stronger than his regularity condition; a similar comparison between Definition 2.4 and s-regularity can be made. Here we make a new observation about s-regularity. To explain this, recall that the goal of [22] is to solve 0 = <p> condition of Pang and Gabriel <ref> [22] </ref>, and do not repeat definitions here. More [19] argues that s-regularity is stronger than his regularity condition; a similar comparison between Definition 2.4 and s-regularity can be made. Here we make a new observation about s-regularity. To explain this, recall that the goal of [22] is to solve 0 = fi (x) = (1=2) kminff (x); xgk 2 , where the min is taken component-wise; a solution of this equation solves (NCP) and vice versa. <p> If x is nonstationary for fi, then s-regularity of x ensures that for some direction y 2 IR n and all x near x, y is a (strict) descent direction for fi at x, i.e. fi 0 (x; y) &lt; 0; see <ref> [22, Lemmas 2, 6 and 7] </ref>. However fi (like ) is only piecewise smooth, and may have a nonstationary point which is a local minimum of some piece of smoothness of fi, contradicting the existence of such a direction y.
Reference: [23] <author> J. S. Pang, S.-P. Han and N. Rangaraj, </author> <title> Minimization of locally Lipschitzian functions, </title> <note> SIAM Journal on Optimization 1 (1991) 57-82. </note>
Reference-contexts: However singularities occur in many problems, for instance see [12], causing numerical difficulties for, or outright failure of these methods. To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references <ref> [1, 9, 19, 23, 22, 24] </ref>. Alternative techniques can be found in [8, 10, 14, 17, 18, 36]. Most of the notation in this paper is standard. <p> Pang, Han and Rangaraj <ref> [23, Corollary 1] </ref> give an additional smoothness assumption at a limit point that is required to prove stationarity.
Reference: [24] <author> J. S. Pang and L. Qi, </author> <title> Nonsmooth equations: Motivation and algorithms, </title> <note> SIAM Journal on Optimization 3 (1993) 443-465. </note>
Reference-contexts: However singularities occur in many problems, for instance see [12], causing numerical difficulties for, or outright failure of these methods. To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references <ref> [1, 9, 19, 23, 22, 24] </ref>. Alternative techniques can be found in [8, 10, 14, 17, 18, 36]. Most of the notation in this paper is standard.
Reference: [25] <author> E. Polak, </author> <title> Computational Methods in Optimization; A Unified Approach (Academic Press, </title> <address> New York, </address> <year> 1971). </year>
Reference-contexts: The fact that the steepest descent method, i.e. the PG method when = IR n , has NSR is easy to see. Also, Polak <ref> [25, Chapter 1] </ref> discusses a general descent property that is similar to NSR and provides convergence results like Theorem 3.2 below. It is trivial but important that NSR yields strong global convergence properties: Theorem 3.2 Suppose A is a monotonic feasible point algorithm for (6) with NSR.
Reference: [26] <author> L. Qi, </author> <title> Convergence analysis of some algorithms for solving nonsmooth equations, </title> <note> Mathematics of Operations Research 18 (1993) 227-244. </note>
Reference-contexts: Suppose f + (x) = 0. Assumption (A) is sufficient for Newton 1 to produce a sequence fx k g such that the Newton step is taken at each iteration k 0 k, if some x k is near enough to x <ref> [15, 26] </ref>. Furthermore, fx k g converges Q-quadratically to x. However (A) may not be sufficient for Newton 2 and Newton 3 to be well-defined, even though some x k is arbitrarily close to x. <p> However (A) may not be sufficient for Newton 2 and Newton 3 to be well-defined, even though some x k is arbitrarily close to x. We need condition (B): if some x k is near enough to x, then the same conclusion holds for Newton 2 <ref> [26] </ref> and Newton 3 [28, 34] as holds above for Newton 1. Assumption (B) implies assumption (A) but not vice versa; assumption (A) is called BD-regularity [27].
Reference: [27] <author> L. Qi and J. Sun, </author> <note> A nonsmooth version of Newton's method, Mathematical Programming 58 (1993) 353-368. </note>
Reference-contexts: We need condition (B): if some x k is near enough to x, then the same conclusion holds for Newton 2 [26] and Newton 3 [28, 34] as holds above for Newton 1. Assumption (B) implies assumption (A) but not vice versa; assumption (A) is called BD-regularity <ref> [27] </ref>. Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9). Further work on Newton 2 is given in [12, 20, 27] and on Newton 3 in [5, 4]. <p> Assumption (B) implies assumption (A) but not vice versa; assumption (A) is called BD-regularity [27]. Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9). Further work on Newton 2 is given in <ref> [12, 20, 27] </ref> and on Newton 3 in [5, 4]. We define a hybrid algorithm involving Algorithm 2, for global convergence properties under no regularity assumptions, and Newton's method for fast local convergence under one of the regularity assumptions (A) or (B). Hybrid.
Reference: [28] <author> D. Ralph, </author> <title> Global convergence of damped Newton's method for nonsmooth equations, via the path search, </title> <note> Mathematics of Operations Research 19 (1994) 352-389. </note>
Reference-contexts: For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise. This has proven to be the case as demonstrated by recent advances on nonsmooth Newton-like algorithms for (NE) in <ref> [5, 4, 12, 28, 34] </ref>. Nonsmoothness of the normal map, however, is the difficulty assumed. In fact, normal maps such as f + can be cast in a more general framework, where x + is replaced by (x), the projection of x onto a nonempty closed convex set . <p> Conversely, if x is stationary, then Proposition 2.3 shows that z = f + (x) satisfies all the relations required in the definition of regularity, and hence f + (x) = 0. We turn to the question of testing whether a point x is regular. <ref> [19, 22, 28] </ref> give several conditions on the Jacobian of f to ensure that x is regular in the sense defined in the corresponding paper. For brevity we only discuss the s-regularity condition of Pang and Gabriel [22], and do not repeat definitions here. <p> Then it is easy to see that ~p 2 T K, see (3). Furthermore, ~z T J (x)~p = ~z T D [J (x)~p] D &gt; 0. Hence x is regular. Note that <ref> [5, 12, 28] </ref> all assume that [rf (x + )] EE is nonsingular and ([rf (x + )] LL n [rf (x + )] EE ) is a P -matrix. (5) Here E def = fi: x i &gt; 0g contains N and L def = fi: x i 0g contains <p> C. Ferris and D. Ralph Proof The equivalence between (5) and the existence of a Lipschitz inverse of f 0 + (x; ) is given by <ref> [28, Proposition 12] </ref>. Since all piecewise linear functions are Lipschitz, the claimed equivalence holds. Suppose z 2 K and rf (x + ) T z 2 K ffi . It follows that z i = 0, i =2 L. <p> Let def 1 fl flL k fl fl where L k + (x) = f (x k + )(x + x k The "linearization" L k + is a local point-based approximation [34] when rf is locally Lipschitz, and more generally a uniform first-order approximation near x k <ref> [28] </ref>; such approximations are more powerful than directional derivatives in that they approximate f + uniformly well for all x near x k . <p> In <ref> [5, 4, 28, 34] </ref> these approximation properties have been exploited to give strong convergence results for Newton methods applied to nonsmooth equations like f + (x) = 0. Our main algorithm, below, and its extremely robust convergence behavior also rely on these approximation properties. <p> We briefly sketch three popular Newton methods for solving the nonsmooth equation f + (x) = 0; which often produce Q-quadratically convergent sequences of iterates. To make comparisons easy, we use the general notion of a Newton path <ref> [28] </ref> which, given the iterate x k , is some function p k : [0; 1] ! IR n with p k (0) = x k ; the next iterate x k+1 is defined as p k (ff) for some ff 2 [0; 1] (details are given below). <p> We need condition (B): if some x k is near enough to x, then the same conclusion holds for Newton 2 [26] and Newton 3 <ref> [28, 34] </ref> as holds above for Newton 1. Assumption (B) implies assumption (A) but not vice versa; assumption (A) is called BD-regularity [27]. Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9).
Reference: [29] <author> S. M. Robinson, </author> <title> Mathematical foundations of nonsmooth embedding methods, </title> <note> Mathematical Programming 48 (1990) 221-229. </note>
Reference-contexts: Note that z solves (NCP) if and only if z f (z) solves (NE), and x solves (NE) if and only if x + solves (NCP). Normal maps were introduced by Robinson in [32] (see also <ref> [29, 30] </ref>) and we note here simply that the formulation (NE) has some advantages over (NCP). For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise.
Reference: [30] <author> S. M. Robinson, </author> <title> An implicit-function theorem for a class of nonsmooth functions, </title> <note> Mathematics of Operations Research 16 (1991) 292-309. </note>
Reference-contexts: Note that z solves (NCP) if and only if z f (z) solves (NE), and x solves (NE) if and only if x + solves (NCP). Normal maps were introduced by Robinson in [32] (see also <ref> [29, 30] </ref>) and we note here simply that the formulation (NE) has some advantages over (NCP). For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise.
Reference: [31] <author> S. M. Robinson, </author> <title> Homeomorphism conditions for normal maps of polyhedra, </title> <editor> in: A. Ioffe, M. Marcus and S. Reich eds., </editor> <title> Optimization and Nonlinear Analysis, </title> <booktitle> Pitman Research Notes in Mathematics Series No. </booktitle> <publisher> 244 (Longman, Harlow, Essex, </publisher> <address> England, </address> <year> 1992) </year> <month> 240-248. </month>
Reference-contexts: In the special case where IR n + , f = f + . For polyhedral , the normal map <ref> [31, 33] </ref> f is intimately related to the normal manifold [32]. This manifold is constructed using the faces of the set ; it is a collection of n-dimensional polyhedral sets (called cells) which partition IR n .
Reference: [32] <author> S. M. Robinson, </author> <title> Normal maps induced by linear transformations, </title> <note> Mathematics of Operations Research 17 (1992) 691-714. </note>
Reference-contexts: Note that z solves (NCP) if and only if z f (z) solves (NE), and x solves (NE) if and only if x + solves (NCP). Normal maps were introduced by Robinson in <ref> [32] </ref> (see also [29, 30]) and we note here simply that the formulation (NE) has some advantages over (NCP). For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise. <p> In the special case where IR n + , f = f + . For polyhedral , the normal map [31, 33] f is intimately related to the normal manifold <ref> [32] </ref>. This manifold is constructed using the faces of the set ; it is a collection of n-dimensional polyhedral sets (called cells) which partition IR n . <p> If is a polyhedral convex set, and F is a face of then N (x) is the same set for every x in the relative interior of F <ref> [32] </ref>. We call this set N (F ). A facet of is a face that has dimension 1 less than . Further definitions from convex analysis can be found in [35].
Reference: [33] <author> S. M. Robinson, </author> <title> Nonsingularity and symmetry for linear normal maps, </title> <note> Mathematical Programming 62 (1993) 415-425. </note>
Reference-contexts: In the special case where IR n + , f = f + . For polyhedral , the normal map <ref> [31, 33] </ref> f is intimately related to the normal manifold [32]. This manifold is constructed using the faces of the set ; it is a collection of n-dimensional polyhedral sets (called cells) which partition IR n .
Reference: [34] <author> S. M. Robinson, </author> <title> Newton's method for a class of nonsmooth functions, Set Valued Analysis (1993, </title> <publisher> forthcoming). </publisher>
Reference-contexts: For example, it is an equation rather than a system of inequalities and equalities, hence its examination from the viewpoint of equations may yield insight difficult to obtain otherwise. This has proven to be the case as demonstrated by recent advances on nonsmooth Newton-like algorithms for (NE) in <ref> [5, 4, 12, 28, 34] </ref>. Nonsmoothness of the normal map, however, is the difficulty assumed. In fact, normal maps such as f + can be cast in a more general framework, where x + is replaced by (x), the projection of x onto a nonempty closed convex set . <p> Ferris and D. Ralph At each iteration, we approximate by linearizing f about x k + . Let def 1 fl flL k fl fl where L k + (x) = f (x k + )(x + x k The "linearization" L k + is a local point-based approximation <ref> [34] </ref> when rf is locally Lipschitz, and more generally a uniform first-order approximation near x k [28]; such approximations are more powerful than directional derivatives in that they approximate f + uniformly well for all x near x k . <p> In <ref> [5, 4, 28, 34] </ref> these approximation properties have been exploited to give strong convergence results for Newton methods applied to nonsmooth equations like f + (x) = 0. Our main algorithm, below, and its extremely robust convergence behavior also rely on these approximation properties. <p> We need condition (B): if some x k is near enough to x, then the same conclusion holds for Newton 2 [26] and Newton 3 <ref> [28, 34] </ref> as holds above for Newton 1. Assumption (B) implies assumption (A) but not vice versa; assumption (A) is called BD-regularity [27]. Also note that the condition f + (x) = 0 is implied, assuming (B) holds, by x being a Gauss-Newton point of f + (Lemma 2.9).
Reference: [35] <author> R. T. </author> <title> Rockafellar, </title> <publisher> Convex Analysis (Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1970). </year>
Reference-contexts: We call this set N (F ). A facet of is a face that has dimension 1 less than . Further definitions from convex analysis can be found in <ref> [35] </ref>. We may abuse notation, when there is no possibility of confusion, by writing O instead of j O to mean the restriction of to an orthant O (to be distinguished from a normal map involving O ).
Reference: [36] <author> P. K. Subramanian, </author> <title> Gauss-Newton methods for the complementarity problem, </title> <note> Journal of Optimization Theory and Applications 77 (1993) 467-482. </note>
Reference-contexts: To circumvent the singularity problem, several Gauss-Newton techniques for solving nonlinear complementarity problems have been proposed. These can be found in the following references [1, 9, 19, 23, 22, 24]. Alternative techniques can be found in <ref> [8, 10, 14, 17, 18, 36] </ref>. Most of the notation in this paper is standard.
References-found: 36

