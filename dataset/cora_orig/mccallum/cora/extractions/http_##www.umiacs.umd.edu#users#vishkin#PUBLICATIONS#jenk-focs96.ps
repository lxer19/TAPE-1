URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/jenk-focs96.ps
Refering-URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/papers.html
Root-URL: 
Title: Efficient Approximate and Dynamic Matching of Patterns Using a Labeling Paradigm (extended abstract) approximate string
Author: Suleyman Cenk S ahinalp Uzi Vishkin 
Note: The  are permitted. partially supported by NSF grant CCR-9416890  
Address: Murray Hill  Israel  
Affiliation: University of Maryland at College Park and Bell Laboratories,  University of Maryland at College Park and Tel Aviv University,  
Abstract: A key approach in string processing algorithmics has been the labeling paradigm [KMR72], which is based on assigning labels to some of the substrings of a given string. If these labels are chosen consistently, they can enable fast comparisons of substrings. Until the first optimal parallel algorithm for suffix tree construction was given in [SV94], the labeling paradigm was considered not to be competitive with other approaches. In this paper we show that, this general method is also useful for several central problems in the area of string processing: * Approximate String Matching, * Dynamic Dictionary Matching, * Dynamic Text Indexing. 
Abstract-found: 1
Intro-found: 1
Reference: [AC75] <author> A. Aho and M. Corasick, </author> <title> Efficient String Matching: An Aid to Bibliographic Search, </title> <journal> Communications of the ACM (CACM), </journal> <year> 1975 </year>
Reference-contexts: The first linear algorithm for this problem is given in <ref> [AC75] </ref>. This algorithm preprocesses the patterns in O (d = p (1) + p (2)+; : : : ; +p (n)) time, and runs in O (t + tocc) time. Here tocc is the total number of occurrences of all patterns in the text.
Reference: [AF91] <author> A. Amir and M. Farach, </author> <title> Adaptive Dictionary Matching, </title> <booktitle> IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <year> 1991 </year>
Reference-contexts: Here tocc is the total number of occurrences of all patterns in the text. In dynamic dictionary matching, updates to the patterns occurring in the form of deletions and insertions of patterns are allowed. Algorithms for this problem have been provided in <ref> [AF91] </ref>, [AFM92], [AFGGP94] and many others. Among known results, the best time is achieved in [AFILS93].
Reference: [AFGGP94] <author> A. Amir, M. Farach, Z. Galil, R. Giancarlo, K. Park, </author> <title> Dynamic Dictionary Matching, </title> <journal> Journal of Computer and System Sciences (JCSS), </journal> <year> 1994 </year>
Reference-contexts: Here tocc is the total number of occurrences of all patterns in the text. In dynamic dictionary matching, updates to the patterns occurring in the form of deletions and insertions of patterns are allowed. Algorithms for this problem have been provided in [AF91], [AFM92], <ref> [AFGGP94] </ref> and many others. Among known results, the best time is achieved in [AFILS93].
Reference: [AFILS93] <author> A. Amir, M. Farach, R. Idury, A. La Poutre and A. Schaffer, </author> <title> Improved Dynamic Dictionary Matching, </title> <booktitle> ACM-SIAM Symposium on Discrete Algorithms (SODA), </booktitle> <year> 1993 </year>
Reference-contexts: In dynamic dictionary matching, updates to the patterns occurring in the form of deletions and insertions of patterns are allowed. Algorithms for this problem have been provided in [AF91], [AFM92], [AFGGP94] and many others. Among known results, the best time is achieved in <ref> [AFILS93] </ref>. This algorithm preprocesses the patterns in O (d) time, performs an update (i.e., insertion or deletion) of a whole pattern of size p in O (p log d= log log d) time, and runs in O ((t + tocc) log d= log log d) time.
Reference: [AFM92] <author> A. Amir, M. Farach and Y. Matias, </author> <title> Efficient Randomized Dictionary Matching Algorithms, Symposium on Combinatorial Pattern Matching (CPM), </title> <year> 1992 </year>
Reference-contexts: Here tocc is the total number of occurrences of all patterns in the text. In dynamic dictionary matching, updates to the patterns occurring in the form of deletions and insertions of patterns are allowed. Algorithms for this problem have been provided in [AF91], <ref> [AFM92] </ref>, [AFGGP94] and many others. Among known results, the best time is achieved in [AFILS93]. <p> The second compact trie, denoted by Pre (l), is the compact trie of the compact representations of the reverses of the main prefixes of the patterns in this group. The construction of a compact trie takes O (p (1) + : : : + p (i)) time <ref> [AFM92] </ref>. Searching For each level of the fat-tree, for each core in that level: (1) Match it to the compact suffix trie of that level.
Reference: [AILSV88] <author> A. Apostolico, C. Iliopoulos, G. Landau, B. Schieber and U. Vishkin, </author> <title> Parallel Construction of a Suffix Tree with Applications, </title> <journal> Algorithmica, </journal> <year> 1988 </year>
Reference: [BM77] <author> R. Boyer and J. Moore, </author> <title> A Fast String Searching Algorithm, </title> <journal> Communications of the ACM (CACM), </journal> <year> 1977 </year>
Reference: [CL90] <author> W. Chang and E. Lawler, </author> <title> Approximate String Matching in Sublinear Expected Time, </title> <booktitle> IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <year> 1990 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in [Se80], [LV85], [LV86], [GG88], [LV88], [LV89], [GP90], and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in <ref> [CL90] </ref> runs in O (t) expected time if m = O (p= log p). In this paper, we provide a deterministic algorithm for the approximate string matching problem, which runs in O (poly (m)t log p=p + t), hence achieving linear time for poly (m) &lt; O (p= log p).
Reference: [CV86] <author> R. Cole and U. Vishkin, </author> <title> Deterministic Coin Tossing and Accelerating Cascades, Micro and Macro Techniques for Designing Parallel Algorithms, </title> <booktitle> ACM Symposium on Theory of Computing (STOC), </booktitle> <year> 1986 </year>
Reference: [FG95] <author> P. Ferragina and R. Grossi, </author> <title> Optimal On-Line Search and Sublinear Time Update in String Matching, </title> <booktitle> IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <year> 1995 </year>
Reference-contexts: It can perform searching in O (p + tocc log i + i log p) time, where i is the number of updated characters. A recent result, given in <ref> [FG95] </ref>, enables O (p + tocc) time searching, and is constructed in O (t) time. It performs updates in the form of deletion and insertion of a substring of size u in O ( p time.
Reference: [FM96] <author> M. Farach and M. Muthukrishnan, </author> <title> An optimal logarithmic time, randomized parallel string matching algorithm, </title> <booktitle> International Colloquium on Automata, Languages and Programming (ICALP), </booktitle> <year> 1996 </year>
Reference-contexts: Algorithms for constructing suffix trees were first provided in in [KMR72], and then in [We73], and [Mc76]. The latter two algorithms build the suffix tree in O (t) time. This running time is also achieved by the serial execution of three new parallel algorithms given in [SV94], [Ha94], <ref> [FM96] </ref>. Suffix trees have proven their use in several domains [Ko94], [Ja90]. Other data structures, including the suffix arrays [MM90], are considered not as efficient as the suffix trees. In the dynamic text indexing problem, updates to the text in the form of insertions and deletions of sub-strings are permitted.
Reference: [GG88] <author> Z. Galil and R. Giancarlo, </author> <title> Data Structures and Algorithms for Approximate String Matching, </title> <journal> Journal of Complexity (JComp), </journal> <year> 1988 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in [Se80], [LV85], [LV86], <ref> [GG88] </ref>, [LV88], [LV89], [GP90], and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in [CL90] runs in O (t) expected time if m = O (p= log p).
Reference: [GP90] <author> Z. Galil and K. Park, </author> <title> An Improved Algorithm for Approximate String Matching, </title> <journal> SIAM Journal on Computing (SIAMJC), </journal> <year> 1990 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in [Se80], [LV85], [LV86], [GG88], [LV88], [LV89], <ref> [GP90] </ref>, and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in [CL90] runs in O (t) expected time if m = O (p= log p).
Reference: [GFB94] <author> M. Gu, M. Farach and R. Beigel, </author> <title> An Efficient Algorithm for Dynamic Text Indexing, </title> <booktitle> ACM-SIAM Symposium on Discrete Algorithms (SODA), </booktitle> <year> 1994 </year>
Reference-contexts: In the dynamic text indexing problem, updates to the text in the form of insertions and deletions of sub-strings are permitted. Such updates can take O (t) time in a suffix tree; hence suffix trees are not suitable for this problem. The border tree <ref> [GFB94] </ref> is the first alternative to the suffix tree in this domain. It is constructed in O (t) time, and performs updates in terms of insertions and deletions of single characters in O (log t) time.
Reference: [Ha94] <author> R. Hariharan, </author> <title> Optimal Parallel Suffix Tree Construction, </title> <booktitle> ACM Symposium on Theory of Computing (STOC), </booktitle> <year> 1994 </year>
Reference-contexts: Algorithms for constructing suffix trees were first provided in in [KMR72], and then in [We73], and [Mc76]. The latter two algorithms build the suffix tree in O (t) time. This running time is also achieved by the serial execution of three new parallel algorithms given in [SV94], <ref> [Ha94] </ref>, [FM96]. Suffix trees have proven their use in several domains [Ko94], [Ja90]. Other data structures, including the suffix arrays [MM90], are considered not as efficient as the suffix trees.
Reference: [Ja90] <author> J. Ja'Ja', </author> <title> Introduction to Parallel Algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> 1990 </year>
Reference-contexts: The latter two algorithms build the suffix tree in O (t) time. This running time is also achieved by the serial execution of three new parallel algorithms given in [SV94], [Ha94], [FM96]. Suffix trees have proven their use in several domains [Ko94], <ref> [Ja90] </ref>. Other data structures, including the suffix arrays [MM90], are considered not as efficient as the suffix trees. In the dynamic text indexing problem, updates to the text in the form of insertions and deletions of sub-strings are permitted.
Reference: [KMR72] <author> R. Karp, R. Miller and A. Rosenberg, </author> <title> Rapid Identification of Repeated Patterns in Strings, Trees, and Arrays, </title> <booktitle> ACM Symposium on Theory of Computing (STOC), </booktitle> <year> 1972 </year>
Reference-contexts: The suffix tree data structure solves this problem in O (p + tocc) time, where tocc is the number of all occurrences of P in T . Algorithms for constructing suffix trees were first provided in in <ref> [KMR72] </ref>, and then in [We73], and [Mc76]. The latter two algorithms build the suffix tree in O (t) time. This running time is also achieved by the serial execution of three new parallel algorithms given in [SV94], [Ha94], [FM96]. Suffix trees have proven their use in several domains [Ko94], [Ja90].
Reference: [KMP77] <author> D. Knuth, J. Morris and V. Pratt, </author> <title> Fast Pattern Matching in Strings, </title> <journal> SIAM Journal on Computing (SIAMJC), </journal> <year> 1977 </year>
Reference: [Ko94] <author> S. Kosaraju, </author> <title> Real Time Pattern Matching and Quasi Real Time Construction of Suffix Trees, </title> <booktitle> ACM Symposium on Theory of Computing (STOC), </booktitle> <year> 1994 </year>
Reference-contexts: The latter two algorithms build the suffix tree in O (t) time. This running time is also achieved by the serial execution of three new parallel algorithms given in [SV94], [Ha94], [FM96]. Suffix trees have proven their use in several domains <ref> [Ko94] </ref>, [Ja90]. Other data structures, including the suffix arrays [MM90], are considered not as efficient as the suffix trees. In the dynamic text indexing problem, updates to the text in the form of insertions and deletions of sub-strings are permitted.
Reference: [LV85] <author> G. Landau and U. Vishkin, </author> <title> Efficient String Matching in the Presence of Errors, </title> <booktitle> IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <year> 1985 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in [Se80], <ref> [LV85] </ref>, [LV86], [GG88], [LV88], [LV89], [GP90], and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in [CL90] runs in O (t) expected time if m = O (p= log p).
Reference: [LV86] <author> G. Landau and U. Vishkin, </author> <title> Introducing Efficient Parallelism into Approximate String Matching and a New Serial Algorithm, </title> <booktitle> ACM Symposium on Theory of Computing (STOC), </booktitle> <year> 1986 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in [Se80], [LV85], <ref> [LV86] </ref>, [GG88], [LV88], [LV89], [GP90], and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in [CL90] runs in O (t) expected time if m = O (p= log p).
Reference: [LV88] <author> G. Landau and U. Vishkin, </author> <title> Fast String Matching with k Differences, </title> <journal> Journal of Computer and System Sciences (JCSS), </journal> <year> 1988 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in [Se80], [LV85], [LV86], [GG88], <ref> [LV88] </ref>, [LV89], [GP90], and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in [CL90] runs in O (t) expected time if m = O (p= log p).
Reference: [LV89] <author> G. Landau and U. Vishkin, </author> <title> Fast Parallel and Serial Approximate String Matching, </title> <journal> Journal of Algorithms (JAlg), </journal> <year> 1989 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in [Se80], [LV85], [LV86], [GG88], [LV88], <ref> [LV89] </ref>, [GP90], and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in [CL90] runs in O (t) expected time if m = O (p= log p). <p> Extending them to left and right will be done as follows. We will find additional nearest long enough exact matches by using the fat trees of P and T . We then will use the standard dynamic programing algorithms for approximate matching (e.g. <ref> [LV89] </ref>) to connect with them using the smallest possible number of differences.
Reference: [MM90] <author> U. Manber and G. Myers, </author> <title> Suffix Arrays: A New Method for On-Line String Searches, </title> <journal> SIAM Journal on Computing (SIAMJC), </journal> <year> 1993 </year>
Reference-contexts: This running time is also achieved by the serial execution of three new parallel algorithms given in [SV94], [Ha94], [FM96]. Suffix trees have proven their use in several domains [Ko94], [Ja90]. Other data structures, including the suffix arrays <ref> [MM90] </ref>, are considered not as efficient as the suffix trees. In the dynamic text indexing problem, updates to the text in the form of insertions and deletions of sub-strings are permitted.
Reference: [Mc76] <author> E. McCreight, </author> <title> A Space-Economical Suffix Tree Construction Algorithm, </title> <journal> Journal of the ACM (JACM), </journal> <year> 1976 </year>
Reference-contexts: The suffix tree data structure solves this problem in O (p + tocc) time, where tocc is the number of all occurrences of P in T . Algorithms for constructing suffix trees were first provided in in [KMR72], and then in [We73], and <ref> [Mc76] </ref>. The latter two algorithms build the suffix tree in O (t) time. This running time is also achieved by the serial execution of three new parallel algorithms given in [SV94], [Ha94], [FM96]. Suffix trees have proven their use in several domains [Ko94], [Ja90].
Reference: [Me83] <author> N. Meggido, </author> <title> Applying Parallel Computation Algorithms in the Design of Serial Algorithms Journal of the ACM (JACM), </title> <year> 1983 </year>
Reference: [SV94] <author> S. Sahinalp and U. Vishkin, </author> <title> Symmetry Breaking for Suffix Tree Construction, </title> <booktitle> ACM Symposium on Theory of Computing (STOC), </booktitle> <year> 1994 </year>
Reference-contexts: 1. Introduction As the size of electronically stored information grows rapidly, efficient methods for string processing are becoming critical. In this abstract and its full version [SV96], we extend our work on parallel construction of a suffix tree <ref> [SV94] </ref> in a nontrivial manner, to obtain efficient algorithms for three fundamentally important problems: (i) approximate string matching, (ii) dynamic dictionary matching, (iii) dynamic text indexing. We describe each of these problems, discuss the relevant literature, and summarize our contributions below. <p> Algorithms for constructing suffix trees were first provided in in [KMR72], and then in [We73], and [Mc76]. The latter two algorithms build the suffix tree in O (t) time. This running time is also achieved by the serial execution of three new parallel algorithms given in <ref> [SV94] </ref>, [Ha94], [FM96]. Suffix trees have proven their use in several domains [Ko94], [Ja90]. Other data structures, including the suffix arrays [MM90], are considered not as efficient as the suffix trees. <p> The labels of level-0 cores are their respective characters themselves. In iteration i, we designate the cores of level-i as follows: 1. Consider the sequence of level-(i 1) labels (of nodes). Using a variant of the "locally consistent parsing" (LCP) method of <ref> [SV94] </ref>, which we describe in Appendix A, we get (possibly overlapping) subsequences of O (log fl s) labels each. Each label may appear in at most d=2 = O (log fl s) subsequences and the number of subsequences will not exceed s=2 i . 2.
Reference: [SV96] <author> S. Sahinalp and U. Vishkin, </author> <title> Efficient Approximate and Dynamic Matching of Patterns Using a Labeling Paradigm, </title> <type> (Technical Report), </type> <note> http://www.umiacs.umd.edu/ jenk/Research/ds.tr.ps </note>
Reference-contexts: 1. Introduction As the size of electronically stored information grows rapidly, efficient methods for string processing are becoming critical. In this abstract and its full version <ref> [SV96] </ref>, we extend our work on parallel construction of a suffix tree [SV94] in a nontrivial manner, to obtain efficient algorithms for three fundamentally important problems: (i) approximate string matching, (ii) dynamic dictionary matching, (iii) dynamic text indexing. <p> Comment to the Reader For simplicity, most of our informal outlines of algorithmic ideas suppress the case of periodicity in any substring of the input. We provide the general versions of our algorithms which involve periodicities in the appendices and in <ref> [SV96] </ref>. 2. A New String Matching Algorithm In this section, we present a new linear time algorithm for the classical string matching problem. The algorithm runs in four stages. <p> Properties of Cores and the Compact Rep resentations of Strings Once the cores of P and T are computed consistently, they satisfy the following important properties that we give without proofs. We leave the proofs of these properties to the full version of the paper <ref> [SV96] </ref>. Property 1 (Consistency of the Cores) Suppose P is identical to a substring T k;k+p . If P i;j is a core at P of level-g, then T k+i1;k+j1 is also a core at level-g, and has the same label as P i;j . <p> In the approximate string matching problem, if T i;j matches P with, say, l &lt; m differences, then obviously the strings T i1;j ; T i+1;j and so on would match P . This difficulty could be overcome by the following property, whose proof is provided in <ref> [SV96] </ref>. <p> Similarly we assume that no main prefix of any pattern is a suffix of the main prefix of another pattern. We also assume that the fat-tree of the patterns and the input text have been constructed. We generalize this algorithm for any set of patterns in <ref> [SV96] </ref>. <p> We employ a standard lookup table for patterns whose size is smaller than log a p trie based approach, as used in the dynamic dictionary matching algorithm, for patterns whose size is larger than log a p t. Please see <ref> [SV96] </ref> for a description of how these data structures are built and how the search and update operations are performed. Acknowledgements We would like to thank A.Funda Ergun (Cornell U. and MIT), Martin Farach (Rutgers U.), and Yossi Matias (Bell Laboratories), for their suggestions and help.
Reference: [Se80] <author> P. Sellers, </author> <title> The Theory and Computation of Evolutionary Distances: </title> <journal> Pattern Recognition. Journal of Algorithms (JAlg), </journal> <year> 1980 </year>
Reference-contexts: The differences can be in the form of inserted, deleted or replaced characters. Several deterministic algorithms for solving this problem are given in <ref> [Se80] </ref>, [LV85], [LV86], [GG88], [LV88], [LV89], [GP90], and numerous others. All of these have worst case running time of (tm). A probabilistic algorithm, given in [CL90] runs in O (t) expected time if m = O (p= log p).

References-found: 29

