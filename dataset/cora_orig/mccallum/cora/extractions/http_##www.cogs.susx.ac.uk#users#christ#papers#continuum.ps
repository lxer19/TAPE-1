URL: http://www.cogs.susx.ac.uk/users/christ/papers/continuum.ps
Refering-URL: http://www.cogs.susx.ac.uk/users/christ/index-noframes.html
Root-URL: 
Email: Email: Chris.Thornton@cogs.susx.ac.uk  
Phone: Tel: (44)273 606755 3239  
Title: Tracking the Neuro-symbolic Continuum: Learning by Explicitation  
Author: Chris Thornton 
Date: June 15, 1994  
Address: Brighton BN1 9QN  
Affiliation: Cognitive and Computing Sciences University of Sussex  
Abstract: The widely-held perception that Connectionism and Classical AI (`symbolism') offer complementary advantages has naturally motivated the attempt to bring the two paradigms together. [1,2,3]. Much of the work on symbolic/connectionist integration (SCI) has been concerned with inferential tasks, e.g., [4]. However, given connectionism's significant contribution in the area of learning, there are good reasons for investigating ways of combining symbolic approaches to this task with the more statistically-oriented connectionist approaches. The present paper takes some steps in this direction. It begins by presenting a Bayesian reappraisal of the supervised learning problem and uses this to re-emphasize the fact that relational learning problems tend to be harder than statistical ones. It then goes on to suggest a generic method for dealing with relational problems and shows how this leads naturally to a view of SCI in which a connectionist level is seamlessly connected to a symbolic level via a continuum of abstraction networks.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Torrance, S. and Thornton, C. (Eds.) </author> <year> (1991). </year> <title> Special issue on hybrid models. </title> <journal> AISB Quarterly, </journal> <volume> No. 78, </volume> <publisher> AISB society. </publisher>
Reference: [2] <author> Thornton, C. </author> <year> (1991). </year> <title> Stirring shakes: introduction to the special issue on hybrid models. </title> <editor> In S. Torrance (Ed.), AISB Quarterly, </editor> <volume> No. 78 (p. </volume> <pages> 7). </pages>
Reference: [3] <author> Thornton, C. </author> <year> (1992). </year> <title> Hybridism: a paradigm too many?. </title> <editor> In S. Torrance (Ed.), AISB Quarterly, </editor> <volume> No. 79 (p. </volume> <pages> 9). </pages>
Reference: [4] <author> Sun, R. </author> <year> (1991). </year> <title> Connectionist models of rule-based reasoning. </title> <editor> In S. Torrance (Ed.), AISB Quarterly, </editor> <volume> No. </volume> <pages> 79 (pp. 21-24). </pages>
Reference: [5] <author> Dietterich, T., London, B., Clarkson, K. and Dromey, G. </author> <year> (1982). </year> <title> Learning and inductive inference. </title> <editor> In P. Cohen and E. Feigenbaum (Eds.), </editor> <booktitle> The Handbook of Artificial Intelligence: Vol III. </booktitle> <address> Los Altos: </address> <publisher> Kaufmann. </publisher>
Reference-contexts: Thus problems whose solution involves exploiting indirect justifications are simply problems whose solution involves testing relational properties of the input vector. This conclusion is, of course, simply a re-statement of the old AI adage that `learning relations is hard', cf. <ref> [5] </ref>. 2 A learning method for relational problems Close examination of the supervised learning task reinforces the long-standing notion that learning may involve capturing statistical or relational effects, and that the latter type of problem is harder to solve in general than the former.
Reference: [6] <author> Langley, P., Simon, H., Bradshaw, G. and Zytkow, J. </author> <year> (1987). </year> <title> Scientific Discovery: Computational Explorations of the Creative Processes. </title> <address> Cambridge, Mass.: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The desire for generality forbids placing arbitrary restrictions on g (i.e., on the range of relationships that might be involved in the solution), and thus rules out the use of methods related to, say, BACON <ref> [6] </ref>, or Backpropagation [7]. It also generates something of a dilemma. A learner capable of discovering indirect justifications of any form would seem to be necessarily committed to carrying out exhaustive searches in the space of possible computable functions (Turing machines), a strategy that seems implausible to say the least.
Reference: [7] <author> Rumelhart, D., Hinton, G. and Williams, R. </author> <year> (1986). </year> <title> Learning representations by back-propagating errors. </title> <booktitle> Nature, </booktitle> <pages> 323 (pp. 533-6). </pages>
Reference-contexts: The desire for generality forbids placing arbitrary restrictions on g (i.e., on the range of relationships that might be involved in the solution), and thus rules out the use of methods related to, say, BACON [6], or Backpropagation <ref> [7] </ref>. It also generates something of a dilemma. A learner capable of discovering indirect justifications of any form would seem to be necessarily committed to carrying out exhaustive searches in the space of possible computable functions (Turing machines), a strategy that seems implausible to say the least.
Reference: [8] <author> Fahlman, S. and Lebiere, C. </author> <year> (1990). </year> <title> The Cascade-Correlation Learning Architecture. </title> <institution> CMU-CS-90-100, School of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA 15213. </address>
Reference-contexts: Lack of space prevents a full description of the model being presented. However, the general flavour of the method is that of a constructive, connectionist regime, such as cascade-correlation <ref> [8] </ref> or Upstart [9]. The process starts by initializing a network containing an appropriate number of input nodes.
Reference: [9] <author> Frean, M. </author> <year> (1989). </year> <title> The Upstart Algorithm: A Method for Constructing and Training Feed-Forward Neural Networks. </title> <type> Edinburgh Physics Preprint 89/479, </type> <institution> Dept. of Physics, University of Edinburgh. </institution>
Reference-contexts: Lack of space prevents a full description of the model being presented. However, the general flavour of the method is that of a constructive, connectionist regime, such as cascade-correlation [8] or Upstart <ref> [9] </ref>. The process starts by initializing a network containing an appropriate number of input nodes.
References-found: 9

