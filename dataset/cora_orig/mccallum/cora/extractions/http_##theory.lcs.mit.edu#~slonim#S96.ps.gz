URL: http://theory.lcs.mit.edu/~slonim/S96.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~slonim/thesis.html
Root-URL: 
Title: Learning from Imperfect Data in Theory and Practice  
Author: by Donna Karen Slonim Ronald L. Rivest 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Doctor of Philosophy at the  c Donna Karen Slonim, 1996. All rights reserved. The author hereby grants to MIT permission to reproduce and to distribute publicly paper and electronic copies of this thesis document in whole or in part. Signature of Author  Certified by  Professor of Computer Science Thesis Supervisor Accepted by F. R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Note: B.S., Yale University  
Date: (1991)  (1990)  May 1996  May 3, 1996  
Address: Berkeley  
Affiliation: M.S., University of California at  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K.J. Abel, et al. </author> <title> A radiation hybrid map of the BRCA1 region of chromosome 17q12-q21. </title> <journal> Genomics, </journal> <volume> 17 </volume> <pages> 632-641, </pages> <year> 1993. </year>
Reference-contexts: We expect that this goal of a 30,000-marker map will be reached well ahead of schedule, in part due to the work described in this chapter. 4.2 Radiation Hybrid Mapping Radiation hybrid mapping [43] is a technique that has been used for small-scale mapping since 1990 <ref> [61, 1, 62] </ref>. The experimental method involves exposing human cells to gamma radiation, which breaks each chromosome into random fragments. The DNA fragments are then "rescued" by fusion with healthy hamster cells that incorporate or retain a random subset of the human DNA fragments.
Reference: [2] <author> Farid Alizadeh, Richard M. Karp, Lee A. Newberg, and Deborah K. Weisser. </author> <title> Physical mapping of chromosomes: A combinatorial problem in molecular biology. </title> <booktitle> In Proceedings of the 4th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 371-381, </pages> <year> 1993. </year>
Reference-contexts: Thus, the real matrix might look more like that in Figure 4.2c. Solving the "almost-consecutive-ones" problem that arises in the error-prone case is much harder. In fact, Alizadeh, Karp, Newberg and Weisser prove that a formalization of the almost-consecutive-ones problem is NP-complete <ref> [2] </ref>. They reduce the problem to a variant of the traveling salesman problem. The key concept behind their approach is the notion of gap minimization.
Reference: [3] <author> Farid Alizadeh, Richard M. Karp, Deborah K. Weisser, and Geoffrey Zweig. </author> <title> Phys ical mapping of chromosomes using unique probes. </title> <journal> Journal of Computational Biology, </journal> <volume> 2(2) </volume> <pages> 159-184, </pages> <year> 1995. </year>
Reference-contexts: They obtain fairly accurate maps for simulated data with a false-negative rate of 0.1% <ref> [3] </ref>. However, building large-scale maps by STS-content mapping alone has proven to be difficult in practice because of the high rate of false positives and the frequency of repeated DNA. <p> Gap Minimization Finally, we reinforce the conclusions of Boehnke [29] that gap-minimization produces worse results than maximum-likelihood methods for radiation hybrid mapping. We used the gap-minimization software that Karp's group has written and successfully applied to STS-content mapping <ref> [3] </ref>. However, gap-minimization is particularly sensitive to false-positive errors, since each such error produces an additional gap. The STS-content data in Karp's project were carefully filtered to remove as many false-positive errors as possible, at the expense of adding some false-negative errors.
Reference: [4] <author> Dana Angluin. </author> <title> A note on the number of queries needed to identify regular lan guages. </title> <journal> Information and Control, </journal> <volume> 51 </volume> <pages> 76-87, </pages> <year> 1981. </year>
Reference-contexts: It then runs several copies of Angluin's algorithm [5] for learning DFAs given a reset. Angluin has shown that any algorithm for actively learning DFAs requires an equivalence oracle <ref> [4] </ref>. In this chapter, we introduce a new type of homing sequence for two robots. Because of the strength of the homing sequence, our algorithm does not require an equivalence oracle. For any graph, the expected running time of our algorithm is O (d 2 n 5 ). <p> In fact, two robots on a graph define a DFA whose states are pairs of nodes in G and whose edges correspond to pairs of actions. Since the automata defined in this way form a restricted class of DFAs, our results are not inconsistent with Angluin's work <ref> [4] </ref> showing that a teacher is necessary for learning general DFAs. Theorem 6 Every strongly-connected directed graph has a two-robot homing sequence. Proof: The following algorithm (based on that of Kohavi [69, 93]) constructs a homing sequence: Initially, let h be empty.
Reference: [5] <author> Dana Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Informa tion and Computation, </journal> <volume> 75 </volume> <pages> 87-106, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: If such an object exists, it is a counterexample to h; otherwise, h is probably approximately correct. Thus, any class C that is learnable by equivalence queries alone is also PAC-learnable <ref> [5] </ref>, though the converse is not true [22]. We use PAC-memb to refer to the variation of the PAC model in which the learner can make membership queries. Likewise we say that a concept class is exactly learnable if it is learnable with membership and equivalence queries. <p> To address this problem, Goldman, Kearns, and Schapire [53] consider a model of persistent noise in membership queries that is related to the model we adopt here. Overview of the Model Our model relies on the definition of a minimally adequate teacher <ref> [5] </ref>, in which a learner tries to learn a target concept f from a known concept class C. In this (error-free) model, the learner is assisted by a teacher that answers two types of queries. <p> They present an algorithm for a single robot to learn minimal deterministic finite automata. With the help of an equivalence oracle, their algorithm learns a homing sequence, which it uses in place of a reset function. It then runs several copies of Angluin's algorithm <ref> [5] </ref> for learning DFAs given a reset. Angluin has shown that any algorithm for actively learning DFAs requires an equivalence oracle [4]. In this chapter, we introduce a new type of homing sequence for two robots.
Reference: [6] <author> Dana Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: The set of 2-descendants is the union of the set of 1-descendants with 0111's grandchildren: 0001, 0010, and 0100. Figure 2.2 shows the set of 2-descendants of the vector 0111. 2.2.3 Using Incomplete Membership Queries A key subprocedure in the monotone DNF algorithm of Angluin <ref> [6] </ref> takes a positive example v of the target concept f and uses membership queries to reduce v to a minimum positive example of f . The algorithm starts with the empty formula and uses equivalence queries to generate new positive counterexamples to reduce. <p> Finally, we extend these definitions to the exact learning model by requiring that counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled <ref> [6, 70, 101, 64] </ref> and additional work in models that allow attribute noise [99, 52, 75]. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [7] <author> Dana Angluin. </author> <title> Negative results for equivalence queries. </title> <journal> Machine Learning, </journal> <volume> 5:121 150, </volume> <year> 1990. </year>
Reference-contexts: However, the choice of counterexample may not depend on the answers to membership queries not yet made. This adversary is strong enough to generate the "worst-case" counterexamples used to provide lower bounds for equivalence queries <ref> [7] </ref>, but it cannot predict the blind spots of the incomplete membership oracle. Discussion of the Model It may at first seem odd to assume that membership queries are flawed while equivalence queries remain correct. <p> However, there is no algorithm that runs in time polynomial in n and m and exactly identifies any monotone DNF formula using equivalence queries only <ref> [7] </ref>. Thus, the quantification of "with high probability" is necessary in the statement of our main result. 2.2.2 Preliminaries The target concepts are monotone formulas in disjunctive normal form (DNF) over the variables x 1 ; : : : ; x n for some positive integer n.
Reference: [8] <author> Dana Angluin. </author> <title> Exact learning of -DNF formulas with malicious membership queries. </title> <type> Technical Report YALEU/DCS/TR-1020, </type> <institution> Yale University, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Angluin and Kri~kis [10] introduce a similar model of malicious membership queries in which the adversary may respond with incorrect answers instead of "don't know". Their paper proves that the class of monotone DNF formulas is learnable in this model. Angluin <ref> [8] </ref> has shown that read-once DNF formulas are also learnable with malicious membership queries. The main difference in motivation between our model and those above is that most previous work supposes that there is a clear boundary between the positive and negative examples with some noise included.
Reference: [9] <author> Dana Angluin and Michael Kharitonov. </author> <booktitle> When won't membership queries help? In Proceedings of the Twenty-Third Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 444-454, </pages> <address> New Orleans, Louisiana, </address> <month> May </month> <year> 1991. </year> <note> 167 168 Bibliography </note>
Reference-contexts: We may then derive some measure of the "importance" of membership queries to the learning algorithm as we vary the failure probability p from 0 (complete information from membership queries) to 1 (no information from membership queries.) Angluin and Kharitonov <ref> [9] </ref> explore a number of cryptographic limitations on the power of membership queries.
Reference: [10] <author> Dana Angluin and Marti~ns Kri~kis. </author> <title> Learning with malicious membership queries and exceptions. </title> <booktitle> In Proceedings of the 7th Annual ACM Workshop on Computational Learning Theory (COLT '94), </booktitle> <pages> pages 57-66. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: Sloan and Turan present algorithms in this model for learning the class of monotone k-term DNF formulas with membership queries alone and the class of monotone DNF formulas with membership and equivalence queries. Angluin and Kri~kis <ref> [10] </ref> introduce a similar model of malicious membership queries in which the adversary may respond with incorrect answers instead of "don't know". Their paper proves that the class of monotone DNF formulas is learnable in this model. <p> difficult than those above in the sense that the membership query errors or omissions are chosen by an adversary (unlike the random noise models [13]), and algorithms must run in time that is polynomial in the usual parameters regardless of the number of queries that might receive incorrect answers (unlike <ref> [103, 10] </ref>). For example, in the case of a 1-term monotone DNF formula with the boundary radius r = 1, there may be exponentially many (in n) instances in the 2.3 Unreliable Boundary Queries 43 boundary region. (Example: let x 4 x 7 x 9 be the target term.
Reference: [11] <author> Dana Angluin and Philip Laird. </author> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370, </pages> <year> 1988. </year>
Reference-contexts: Results are encouraging for the case of random misclassification errors. In this benign error model, the teacher produces labeled positive or negative examples, where the label for any example is incorrect independently with probability . Angluin and Laird <ref> [11] </ref> show that information-theoretically, as long as is less than 1 2 , a sequence of labeled examples of length polynomial in ( 1 * ; 1 12 ) is sufficient for PAC-learning.
Reference: [12] <author> Dana Angluin and Donna K. </author> <title> Slonim. Learning monotone DNF with an incom plete membership oracle. </title> <booktitle> In Proceedings of COLT '91, </booktitle> <pages> pages 139-146. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference: [13] <author> Dana Angluin and Donna K. </author> <title> Slonim. Randomly fallible teachers: Learning mono tone DNF with an incomplete membership oracle. </title> <journal> Machine Learning, </journal> <volume> 14(1) </volume> <pages> 7-26, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: It is clear that Reduce must eventually return a vector v 0 such that v 0 v, v 0 is a positive example of f , and membership queries for all the proper d-descendants of v 0 were answered either "no" or "I don't know." In Angluin and Slonim <ref> [13] </ref>, we determine the values of d for which the probability that there is NO 32 Learning With Imperfect Teachers Reduce (v; d): 1 D := fdjd is a proper d-descendant of v g 2 for each y 2 D in breadth-first order 3 do if membership-query (y) = "yes" 4 <p> (v = equivalence-query (h)) 6= ; 3 do if (h (v) = 1) 4 then remove from h all w j w v 5 else y; Q :=mod-Reduce (v; d; ;) 6 h := h [ fyg [ Q 7 Output h and halt The analysis in Angluin and Slonim <ref> [13] </ref> shows that this algorithm exactly identifies f and with high probability runs in time polynomial in n; m; and d. <p> Their work uses membership queries to simulate a particular distribution. Frazier and Pitt [49] show that CLASSIC sentences are learnable in this noise model, using the fact that many distinct membership queries can be formulated that redundantly yield the same information. Angluin and Slonim <ref> [13] </ref> introduce a model of incomplete membership queries (de 42 Learning With Imperfect Teachers scribed in Section 2.2), in which a membership query on a given instance may persistently generate a "don't know" response. <p> Our model is more difficult than those above in the sense that the membership query errors or omissions are chosen by an adversary (unlike the random noise models <ref> [13] </ref>), and algorithms must run in time that is polynomial in the usual parameters regardless of the number of queries that might receive incorrect answers (unlike [103, 10]). <p> One reason for studying the one-sided, false-positive error model is that the mono-tonicity of the target class provides some inherent ability to handle false-negative errors. In a related model, Angluin and Slonim <ref> [13] </ref> show how to learn monotone DNF with random false-negative answers to membership queries allowed anywhere in the domain (not just in the boundary region). However, it is not known how to extend their results to handle false positive errors.
Reference: [14] <author> Yonatan Aumann and Michael O. Rabin. </author> <title> Clock construction in fully asynchronous parallel systems and PRAM simulation. </title> <journal> Theoretical Computer Science, </journal> <volume> 128 </volume> <pages> 3-30, </pages> <year> 1994. </year>
Reference-contexts: However, the following corollary bounds the conditional probabilities. The proof of this corollary is exactly analogous to that of a similar corollary by Aumann and Rabin <ref> [14, Corollary 1] </ref>. Corollary 9 Let X 1 ; : : : ; X m be 0/1 random variables (not necessarily independent), and let b j 2 f0; 1g for 1 j m.
Reference: [15] <author> Baruch Awerbuch, Margrit Betke, Ronald L. Rivest, and Mona Singh. </author> <title> Piecemeal graph exploration by a mobile robot. </title> <booktitle> In Proceedings of COLT '95, </booktitle> <pages> pages 321-328. </pages> <publisher> ACM, </publisher> <year> 1995. </year>
Reference-contexts: In piecemeal learning, the learner must return to a fixed starting point from time to time during the learning process. Betke, Rivest, and Singh provide linear algorithms for learning grid graphs with rectangular obstacles [21], and with Awerbuch <ref> [15] </ref> extend this work to show nearly-linear algorithms for general graphs. Rivest and Schapire [92, 93] explore the problem of learning deterministic finite automata whose nodes are not distinguishable except by the observed output. We rely heavily on their results in this chapter.
Reference: [16] <author> Eric Baum. </author> <title> Polynomial time algorithms for learning neural nets. </title> <booktitle> In Proceedings of the 3rd Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 258-272, </pages> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Our algorithm is an extension of an algorithm of Baum <ref> [16, 17] </ref> for learning the simpler class of intersections of two homogeneous halfspaces in the standard PAC-with-queries model 2 .
Reference: [17] <author> Eric Baum. </author> <title> Neural net algorithms that learn in polynomial time from examples and queries. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 2 </volume> <pages> 5-19, </pages> <year> 1991. </year>
Reference-contexts: Our algorithm is an extension of an algorithm of Baum <ref> [16, 17] </ref> for learning the simpler class of intersections of two homogeneous halfspaces in the standard PAC-with-queries model 2 .
Reference: [18] <author> Paul Beame, Allan Borodin, Prabhakar Raghavan, Walter Ruzzo, and Martin Tompa. </author> <title> Time-space tradeoffs for undirected graph traversal. </title> <booktitle> In Proceedings of the 31st Annual Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 429-438. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1990. </year>
Reference-contexts: JAGs have been used primarily to prove space efficiency for st-connectivity algorithms, and they have recently resurfaced as a tool for analyzing time and space tradeoffs for graph traversal and connectivity problems (e.g. <ref> [18, 87, 46] </ref>). Universal traversal sequences have been used to provide upper and lower bounds for the exploration of undirected graphs. Certainly, a universal traversal sequence for the class of directed graphs could be used to learn individual graphs.
Reference: [19] <author> Michael A. Bender and Donna K. </author> <title> Slonim. The power of team exploration: two robots can learn unlabeled directed graphs. </title> <booktitle> In Proceedings of the Thirty-Fifth Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 75-85, </pages> <month> November </month> <year> 1994. </year>
Reference: [20] <author> Margrit Betke. </author> <title> Algorithms for exploring an unknown graph. </title> <type> Master's thesis, </type> <institution> MIT Department of Electrical Engineering and Computer Science, </institution> <month> February </month> <year> 1992. </year> <institution> (Pub-lished as MIT Laboratory for Computer Science Technical Report MIT/LCS/TR-536, </institution> <month> March, </month> <year> 1992). </year> <note> Bibliography 169 </note>
Reference-contexts: They provide a learning algorithm whose competitive ratio (versus the optimal time to traverse all edges in the graph) is exponential in the deficiency of the graph <ref> [45, 20] </ref>. Betke, Rivest, and Singh introduce the notion of piecemeal learning of undirected graphs with labeled nodes. In piecemeal learning, the learner must return to a fixed starting point from time to time during the learning process.
Reference: [21] <author> Margrit Betke, Ronald L. Rivest, and Mona Singh. </author> <title> Piecemeal learning of an unknown environment. </title> <booktitle> In Proceedings of the 1993 Conference on Computational Learning Theory, </booktitle> <pages> pages 277-286, </pages> <address> Santa Cruz, CA, </address> <month> July </month> <year> 1993. </year> <note> (Published as MIT AI-Memo 1474, CBCL-Memo 93; and in Machine Learning, Feb/Mar 1995.). </note>
Reference-contexts: In piecemeal learning, the learner must return to a fixed starting point from time to time during the learning process. Betke, Rivest, and Singh provide linear algorithms for learning grid graphs with rectangular obstacles <ref> [21] </ref>, and with Awerbuch [15] extend this work to show nearly-linear algorithms for general graphs. Rivest and Schapire [92, 93] explore the problem of learning deterministic finite automata whose nodes are not distinguishable except by the observed output. We rely heavily on their results in this chapter.
Reference: [22] <author> Avrim Blum. </author> <title> Separating distribution-free and mistake-bound learning models over the Boolean domain. </title> <journal> SIAM Journal on Computing, </journal> <volume> 23(5) </volume> <pages> 990-1000, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: If such an object exists, it is a counterexample to h; otherwise, h is probably approximately correct. Thus, any class C that is learnable by equivalence queries alone is also PAC-learnable [5], though the converse is not true <ref> [22] </ref>. We use PAC-memb to refer to the variation of the PAC model in which the learner can make membership queries. Likewise we say that a concept class is exactly learnable if it is learnable with membership and equivalence queries.
Reference: [23] <author> Avrim Blum, Prasad Chalasani, Sally Goldman, and Donna Slonim. </author> <title> Learning with unreliable boundary queries. </title> <booktitle> In Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 98-107, </pages> <month> July </month> <year> 1995. </year> <note> Submitted by invitation to Journal of Computer and System Sciences. </note>
Reference: [24] <author> Avrim Blum and Ronald L. Rivest. </author> <title> Training a 3-node neural net is NP-Complete. </title> <booktitle> In Advances in Neural Information Processing Systems I, </booktitle> <pages> pages 494-501. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: The idea of Baum's algorithm is to reduce the problem of learning an intersection of two homogeneous halfspaces to the problem of learning an XOR of halfspaces, for which a PAC algorithm exists <ref> [24] </ref>. (That algorithm produces a hypothesis that is 2 A halfspace is homogeneous if its bounding hyperplane passes through the origin. 44 Learning With Imperfect Teachers the threshold of a degree-2 polynomial.) The idea of the reduction is to notice that negative examples in the quadrant opposite from the positive quadrant|the <p> Then find a linear function P such that P (~x) &lt; 0 for all the marked (negative) examples and P (~x) 0 for all the positives. Finally, run the XOR-of-halfspaces learning algorithm of <ref> [24] </ref> to find a hypothesis H 0 that correctly classifies f~x 2 S : P (~x) 0g.
Reference: [25] <author> M. Blum and W. J. Sakoda. </author> <title> On the capability of finite automata in 2 and 3 di mensional space. </title> <booktitle> In 18th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 147-161. </pages> <publisher> IEEE, </publisher> <year> 1977. </year>
Reference-contexts: Rabin first proposed the idea of dropping pebbles to mark nodes [89]. This suggestion led to a body of work exploring the searching capabilities of a finite automaton supplied with pebbles. Blum and Sakoda <ref> [25] </ref> consider the question of whether a finite set of finite automata can search a 2 or 3-dimensional obstructed grid.
Reference: [26] <author> Manuel Blum and Dexter Kozen. </author> <title> On the power of the compass (or, why mazes are easier to search than graphs). </title> <booktitle> In 19th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 132-142. </pages> <publisher> IEEE, </publisher> <year> 1978. </year>
Reference-contexts: They also prove, however, that no collection of finite automata can search every 3-dimensional maze. Blum and Kozen <ref> [26] </ref> improve this result to show that a single automaton with 2 pebbles can search a finite, 2-dimensional maze. Their results imply that mazes are strictly easier to search than planar graphs, since they also show that no single automaton with pebbles can search all planar graphs.
Reference: [27] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: Sometimes it is difficult to specify the hypothesis h exactly and succinctly. However, one can use the PAC model to approximate an equivalence query without formally specifying the hypothesis h. Blumer, Ehrenfeucht, Haussler and Warmuth <ref> [27] </ref> proved that any hypothesis consistent with a labeled random sample of size log 1=ffi + * is a PAC-hypothesis; i.e., with probability at least 1 ffi, the hypothesis is *-good.
Reference: [28] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. </author> <title> War muth. Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: For each negative example ~x neg 2 S, query the example 2~x pos ~x neg , and if the response to 3 The VC-dimension [110] of the hypothesis class is O (n 2 ). Blumer, Ehrenfeucht, Haussler and Warmuth <ref> [28] </ref> have shown that a sample of size polynomial in the VC-dimension of the hypothesis class is sufficient for PAC-learning, so the number of examples needed is polynomial in n. 2.3 Unreliable Boundary Queries 45 that query is "positive", then mark ~x neg .
Reference: [29] <author> Michael Boehnke. </author> <title> Radiation hybrid mapping by minimization of the number of obligate chromosome breaks: Genetic analysis workshop 7. </title> <journal> Cytogenetic Cell Genetics, </journal> <volume> 59 </volume> <pages> 96-98, </pages> <year> 1992. </year>
Reference-contexts: This technique works quite well in practice; the algorithms described in the next two sections are examples of such approaches. Gap Minimization Finally, we reinforce the conclusions of Boehnke <ref> [29] </ref> that gap-minimization produces worse results than maximum-likelihood methods for radiation hybrid mapping. We used the gap-minimization software that Karp's group has written and successfully applied to STS-content mapping [3]. However, gap-minimization is particularly sensitive to false-positive errors, since each such error produces an additional gap.
Reference: [30] <author> Michael Boehnke, Elizabeth Hauser, Kenneth Lange, Kathryn L. Lunetta, Justine Uro, and Jill Vanderstoep. </author> <title> RHMAP version 2.01: Statistical package for multi-point radiation hybrid mapping, </title> <note> 1994. Software and documentation available from http://www.sph.umich.edu/group/statgen/software. </note>
Reference-contexts: Previous Work on Radiation Hybrid Mapping Analytical methods for constructing radiation hybrid maps have been published by Boehnke, et al. <ref> [30, 31, 73, 76] </ref>. Their software, RHMAP, was originally designed for building maps of small chromosomal regions near disease genes. The hybrid panels used for this purpose are derived from somatic cell hybrids containing only a single copy of the human chromosome of interest. <p> Thus, while software for handling the haploid case has been widely available for a number of years [32], software that handles the diploid panels used in genome-wide mapping has only recently become available <ref> [30, 73] </ref>. Boehnke solves the first computational problem, that of determining what makes a good map, by representing the data with a Markov model. Under this probabilistic model one can compute the likelihood of each map.
Reference: [31] <author> Michael Boehnke, Kenneth Lange, and David Cox. </author> <title> Statistical methods for multi point radiation hybrid mapping. </title> <journal> American Journal of Human Genetics, </journal> <volume> 49 </volume> <pages> 1174-1188, </pages> <year> 1991. </year> <note> 170 Bibliography </note>
Reference-contexts: We cannot distinguish the exact number of copies retained. We must account for this limitation when we attempt to determine accurate distances between adjacent markers in our maps. The unit of distance in radiation hybrid maps is the Ray <ref> [31, 43] </ref>. The distance is calculated with the Haldane [56] formula: log (1 ), where is the probability of a break between two markers. One centiRay (cR) corresponds roughly to a 1% chance of a break. <p> Previous Work on Radiation Hybrid Mapping Analytical methods for constructing radiation hybrid maps have been published by Boehnke, et al. <ref> [30, 31, 73, 76] </ref>. Their software, RHMAP, was originally designed for building maps of small chromosomal regions near disease genes. The hybrid panels used for this purpose are derived from somatic cell hybrids containing only a single copy of the human chromosome of interest.
Reference: [32] <author> Michael Boehnke, et al. </author> <title> RHMAP version 1.01: Statistical package for multipoint radiation hybrid mapping, 1991. Software and documentation received by personal communication. </title>
Reference-contexts: The hybrid panels used for this purpose are derived from somatic cell hybrids containing only a single copy of the human chromosome of interest. Thus, while software for handling the haploid case has been widely available for a number of years <ref> [32] </ref>, software that handles the diploid panels used in genome-wide mapping has only recently become available [30, 73]. Boehnke solves the first computational problem, that of determining what makes a good map, by representing the data with a Markov model. <p> The markers were screened by PCR assay against the Stanford radiation hybrid panel of 85 hybrid cell lines. All assays were duplicated and any discrepancies were treated as missing data, so the error rate for this data set is rather low. Cox used version 1.0 of RHMAP <ref> [32] </ref> to generate a maximum-likelihood order of the markers. Using the same data, we generated a map of their markers blindly (without reference to Cox's map) and then compared our ordering to theirs. It took our software about 3 hours to obtain the final order. <p> Comparison with RHMAP We also compared the efficiency of our algorithm with that of version 1 of RHMAP <ref> [32] </ref>. (Tests with version 2, performed later, yielded similar maps but ran even more slowly.) We used the maximum-likelihood option and compared our results to RHMAP's stepwise 4.5 Greedy Algorithms for Ordering Markers 137 markers.
Reference: [33] <author> K.S. Booth and G.S. Lueker. </author> <title> Testing for the consecutive ones property, interval graphs, and graph planarity using PQ-tree algorithms. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 13 </volume> <pages> 335-379, </pages> <year> 1976. </year>
Reference-contexts: Thus the goal is to find a permutation of the rows of the input matrix with the consecutive ones property. This problem has a polynomial-time solution in the error-free case, due to Booth and Lueker <ref> [33] </ref>. However, as in any mapping problem, there are several types of errors in the data: deletions, insertions, false-positive or false-negative experimental results, and chimeras. Thus, the real matrix might look more like that in Figure 4.2c. Solving the "almost-consecutive-ones" problem that arises in the error-prone case is much harder.
Reference: [34] <editor> Rodney Brooks, Pattie Maes, Maja Mataric, </editor> <title> and Grinell More. Lunar base con struction robots. </title> <booktitle> In Proceedings of the IEEE International Workshop on Robots and Systems, </booktitle> <pages> pages 389-392. </pages> <publisher> IEEE Press, </publisher> <year> 1990. </year>
Reference-contexts: There have been many projects studying the learning and behavior of robot swarms. 3.1 Introduction 69 Mataric [80] uses reinforcement learning [107] to teach "foraging" behavior to a team of twenty independently-controlled robots. Brooks, et al., <ref> [34] </ref> describe parallel algorithms for swarms of robots to select and clear a site for construction of a lunar research station. The robots in this system form a "herd;" each acts independently, following some simple rules that may involve the location and behavior of other nearby robots.
Reference: [35] <author> D. T. Burke, G. F. Carle, and M. V. Olson. </author> <title> Cloning of large exogenous DNA into yeast by means of artificial chromosomes. </title> <journal> Science, </journal> <volume> 236 </volume> <pages> 806-812, </pages> <year> 1987. </year>
Reference-contexts: Integrated Map The resolution of radiation hybrid mapping can be controlled by adjusting the amount of radiation used to create the hybrid panel. In particular, the method can generate maps intermediate in resolution between genetic linkage maps and fine-grain STS content maps on YACs <ref> [35, 60] </ref>. Thus, radiation hybrid maps may provide the cohesion necessary for integrating several different types of mapping data.
Reference: [36] <author> N. Cesa-Bianchi, Y. Freund, D. Helmbold, D. Haussler, R. Schapire, and M. </author> <title> War muth. How to use expert advice. </title> <booktitle> In Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 382-391, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Several team learning papers explore the problems of combining the abilities of a number of different learners. Cesa-Bianchi et al. <ref> [36] </ref> consider the task of learning a probabilistic binary sequence given the predictions of a set of experts on the same sequence. They show how to combine the prediction strategies of several experts to predict nearly as well as the best of the experts.
Reference: [37] <author> I. Chumakov, et al. </author> <title> A YAC contig map of the human genome. </title> <booktitle> Nature, </booktitle> <address> 377:S175 S297, </address> <year> 1995. </year>
Reference-contexts: Each YAC incorporates an approximately 1 megabase (Mb) DNA fragment from a random part of the human genome. Recently, a collaboration between CEPH, Genethon, and the Whitehead has produced a clone-based map that is estimated to cover 75% of the genome with YAC clones <ref> [37] </ref>. Clone-based maps rely heavily on the accuracy of the cloning technology. However, most cloning techniques are prone to a variety of errors.
Reference: [38] <author> Francis S. Collins. </author> <title> Ahead of schedule and under budget: The genome project passes its fifth birthday. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 92 </volume> <pages> 10821-10823, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: This information may be used to develop new treatments and therapies. Thus, the field of genetics plays an essential role in modern medical research. An intense effort by many teams of scientists worldwide is currently underway to determine the location, DNA sequence and function of human genes <ref> [38, 55] </ref>. Physical 4.1 Introduction 105 maps are an important part of this process. A physical map of a chromosome shows the relative locations and estimated distances between known markers along the chromosome.
Reference: [39] <author> Stephen A. Cook and Charles W. Rackoff. </author> <title> Space lower bounds for maze thread ability on restricted machines. </title> <journal> SIAM Journal on Computing, </journal> <volume> 9 </volume> <pages> 636-652, </pages> <year> 1980. </year>
Reference-contexts: Cook and Rackoff generalized the idea of pebbles to jumping automata for graphs (JAGs) <ref> [39] </ref>. A jumping automaton is equipped with pebbles that can be dropped to mark nodes and that can "jump" to the locations of other pebbles.
Reference: [40] <author> Thomas Cormen, Charles Leiserson, and Ronald Rivest. </author> <title> Introduction to Algo rithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Each of these algorithms creates a directed acyclic graph (DAG) based on the triples and then finds the longest path in that DAG. Finding the longest path in a DAG with V vertices and E edges requires O (V + E) steps <ref> [40] </ref>; in our case this is O (n) steps, where n is the number of good triples. In contrast, finding the longest path in a general graph is NP-complete. The first algorithm relies on all partial order information available from the triples to assemble a path.
Reference: [41] <author> A. Coulson, et al. </author> <title> Toward a physical map of the genome of the nematode C. </title> <booktitle> elegans. Proceedings of the National Academy of Sciences, USA, </booktitle> <volume> 83(20) </volume> <pages> 7821-7826, </pages> <year> 1986. </year>
Reference-contexts: We have validated our approach by using it to construct genome-wide radiation hybrid maps. Other Physical Mapping Strategies We also experimented briefly with algorithmic methods that have been applied successfully to other physical mapping problems. The earliest physical maps consisted of overlapping clone coverage of a region <ref> [84, 41, 68] </ref>. The clones most suitable for large-scale mapping are yeast artificial chromosomes (YACs). Each YAC incorporates an approximately 1 megabase (Mb) DNA fragment from a random part of the human genome.
Reference: [42] <author> D. Cox and R. Myers. </author> <title> Chromosome 4 and 12 radiation hybrid data realease, </title> <note> electronically published at http://shgc.stanford.edu/rhmap.html, 1996. </note>
Reference-contexts: A third RHMAP option uses simulated annealing to find a maximum-likelihood solution. In Section 4.4 we describe our preliminary attempts to apply similar techniques to large-scale mapping. Radiation hybrid mapping has been used successfully to create maps of human chromosomes 14 [111], 11 [63], 4 and 12 <ref> [42] </ref>. However, building maps of entire chromosomes using RHMAP is a slow and painful process.
Reference: [43] <author> D. R. Cox, M. Burmeister, E. R. Price, S. Kim, and R. M. Myers. </author> <title> Radiation hybrid mapping: A somatic cell genetic method for constructing high-resolution maps of mammalian chromosomes. </title> <journal> Science, </journal> <volume> 250 </volume> <pages> 245-250, </pages> <year> 1990. </year>
Reference-contexts: Physical mapping is also an excellent case study in handling noisy or imperfect data. Physical map data can be derived from a variety of experimental methods; radiation hybrid mapping is one such mapping technique <ref> [43] </ref>. The project described in this chapter involves a great deal of data developed in different labs and with different experimental methods. Each type of data is subject to different sorts of noise and corruption. <p> We expect that this goal of a 30,000-marker map will be reached well ahead of schedule, in part due to the work described in this chapter. 4.2 Radiation Hybrid Mapping Radiation hybrid mapping <ref> [43] </ref> is a technique that has been used for small-scale mapping since 1990 [61, 1, 62]. The experimental method involves exposing human cells to gamma radiation, which breaks each chromosome into random fragments. <p> We cannot distinguish the exact number of copies retained. We must account for this limitation when we attempt to determine accurate distances between adjacent markers in our maps. The unit of distance in radiation hybrid maps is the Ray <ref> [31, 43] </ref>. The distance is calculated with the Haldane [56] formula: log (1 ), where is the probability of a break between two markers. One centiRay (cR) corresponds roughly to a 1% chance of a break.
Reference: [44] <author> T. Dean, D. Angluin, K. Basye, S. Engelson, L. Kaelbling, E. Kokkevis, and O. Maron. </author> <title> Inferring finite automata with stochastic output functions and an application to map learning. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <pages> pages 208-214. </pages> <publisher> AAAI, </publisher> <year> 1992. </year> <note> Bibliography 171 </note>
Reference-contexts: Rivest and Schapire [92, 93] explore the problem of learning deterministic finite automata whose nodes are not distinguishable except by the observed output. We rely heavily on their results in this chapter. Their work has been extended by Freund et al. [50], and by Dean et al. <ref> [44] </ref>. Freund et al. analyze the problem of learning finite automata with average-case labelings by the observed output on a random string, while Dean et al. explore the problem of learning DFAs with a robot whose observations of the environment are not always reliable.
Reference: [45] <author> Xiaotie Deng and Christos H. Papadimitriou. </author> <title> Exploring an unknown graph. </title> <booktitle> In Proceedings of the 31st Symposium on Foundations of Computer Science, </booktitle> <volume> volume I, </volume> <pages> pages 355-361, </pages> <year> 1990. </year>
Reference-contexts: They provide a learning algorithm whose competitive ratio (versus the optimal time to traverse all edges in the graph) is exponential in the deficiency of the graph <ref> [45, 20] </ref>. Betke, Rivest, and Singh introduce the notion of piecemeal learning of undirected graphs with labeled nodes. In piecemeal learning, the learner must return to a fixed starting point from time to time during the learning process.
Reference: [46] <author> Jeff Edmonds. </author> <title> Time-space trade-offs for undirected st-connectivity on a JAG. </title> <booktitle> In Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 718-727, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: JAGs have been used primarily to prove space efficiency for st-connectivity algorithms, and they have recently resurfaced as a tool for analyzing time and space tradeoffs for graph traversal and connectivity problems (e.g. <ref> [18, 87, 46] </ref>). Universal traversal sequences have been used to provide upper and lower bounds for the exploration of undirected graphs. Certainly, a universal traversal sequence for the class of directed graphs could be used to learn individual graphs.
Reference: [47] <author> S. Foote, D. Vollrath, A. Hilton, and D. C. </author> <title> Page. The human Y chromosome: Overlapping DNA clones spanning the euchromatic region. </title> <journal> Science, </journal> <volume> 258 </volume> <pages> 60-66, </pages> <year> 1992. </year>
Reference-contexts: Since the Genebridge 4 Hybrid Panel allows us to detect RH linkage between markers 30 cR apart, we can conclude that there are no substantial 3 Chromosome Y was not mapped because a detailed physical map of Chromosome Y had already been published by a collaborating Whitehead team <ref> [47] </ref>. 154 Building Human Genome Maps with Radiation Hybrids Chr Framework Total Length Physical RH vs.
Reference: [48] <author> Michael Frazier, Sally Goldman, Nina Mishra, and Leonard Pitt. </author> <title> Learning from a consistently ignorant teacher. </title> <booktitle> In Proceedings of the 7th Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 328-339. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: In other related work, Frazier, Goldman, Mishra and Pitt <ref> [48] </ref> introduce a learning model in which there is incomplete information about the target function due to an ill-defined boundary. While the omissions in their model may be adversarially placed, all examples labeled with "?" (indicating unknown classification) must be consistent with knowledge about the concept class.
Reference: [49] <editor> Michael Frazier and Leonard Pitt. </editor> <booktitle> CLASSIC learning. In Proceedings of the 7th Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 23-34. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: Goldman, Kearns and Schapire [53] give a positive result for learning certain classes of read-once formulas under this noise model. Their work uses membership queries to simulate a particular distribution. Frazier and Pitt <ref> [49] </ref> show that CLASSIC sentences are learnable in this noise model, using the fact that many distinct membership queries can be formulated that redundantly yield the same information.
Reference: [50] <author> Yoav Freund, Michael Kearns, Dana Ron, Ronitt Rubenfeld, Robert Schapire, and Linda Sellie. </author> <title> Efficient learning of typical finite automata from random walks. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 315-324, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Rivest and Schapire [92, 93] explore the problem of learning deterministic finite automata whose nodes are not distinguishable except by the observed output. We rely heavily on their results in this chapter. Their work has been extended by Freund et al. <ref> [50] </ref>, and by Dean et al. [44]. Freund et al. analyze the problem of learning finite automata with average-case labelings by the observed output on a random string, while Dean et al. explore the problem of learning DFAs with a robot whose observations of the environment are not always reliable.
Reference: [51] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: We used the standard Metropolis algorithm to determine which 2 See Goldberg <ref> [51] </ref> for a general discussion of genetic algorithms. 126 Building Human Genome Maps with Radiation Hybrids candidate orders to accept. We experimented with several different cooling schemes and initial conditions, but in all of our attempts we sought maximum-likelihood permutations of the markers.
Reference: [52] <author> Sally Goldman and Robert Sloan. </author> <title> Can PAC learning algorithms tolerate random noise. </title> <journal> Algorithmica, </journal> <volume> 14(1) </volume> <pages> 70-84, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled [6, 70, 101, 64] and additional work in models that allow attribute noise <ref> [99, 52, 75] </ref>. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [53] <author> Sally A. Goldman, Michael J. Kearns, and Robert E. Schapire. </author> <title> Exact identifi cation of circuits using fixed points of amplification functions. </title> <journal> SIAM Journal on Computing, </journal> <volume> 22(4) </volume> <pages> 705-726, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: To address this problem, Goldman, Kearns, and Schapire <ref> [53] </ref> consider a model of persistent noise in membership queries that is related to the model we adopt here. <p> Since PAC-learning can tolerate a large degree of random misclassification errors, general (two-sided) random errors in membership queries might seem approachable. Indeed, the results of Goldman, Kearns, and Schapire <ref> [53] </ref> show that the classes of logarithmic-depth read-once majority formulas and logarithmic-depth positive NAND formulas can be learned with high probability using only membership queries, even if the membership queries are subject to persistent two-sided errors. <p> In models of persistent membership query noise, repeated queries to the same example receive the same answer as in the first call. Goldman, Kearns and Schapire <ref> [53] </ref> give a positive result for learning certain classes of read-once formulas under this noise model. Their work uses membership queries to simulate a particular distribution.
Reference: [54] <author> Sally A. Goldman and H. David Mathias. </author> <title> Learning k-term DNF formulas with an incomplete membership oracle. </title> <booktitle> In Proceedings of the Fifth Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 77-84, </pages> <address> Pittsburgh, PA, 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Exactly how much power does an adversary need to prevent learning in a malicious model? Another question is whether we can find polynomial time algorithms in this model for other learning problems known to have polynomial time algorithms using equivalence and membership oracles. Goldman and Mathias <ref> [54] </ref> show how to exactly identify k-term DNF formulas in this model, proving that the model can be successfully applied to non-monotone concept classes. It would be interesting to determine what other types of concept classes (geometric concepts?) can be learned in this model. <p> The "don't know" instances are chosen uniformly at random from the entire domain and may account for up to a constant fraction of the instances. Additional positive results in this model are obtained by Goldman and Math-ias <ref> [54] </ref>. This model allows for a large number of "don't know" instances, but positive results in this model are typically highly dependent on the precisely uniform nature of the noise. Sloan and Turan [103] introduce the limited membership query model . <p> However, there is much more work to be done. The algorithms described here learn fairly simple concept classes. While Goldman and Mathias <ref> [54] </ref> have shown that it is possible to learn non-monotonic concepts with an incomplete membership oracle, it has proven difficult to learn more complex concept classes in this model.
Reference: [55] <author> Mark S. Guyer and Francis S. Collins. </author> <title> How is the human genome project doing, </title> <booktitle> and what have we learned so far? Proceedings of the National Academy of Sciences, </booktitle> <volume> 92 </volume> <pages> 10841-10848, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: This information may be used to develop new treatments and therapies. Thus, the field of genetics plays an essential role in modern medical research. An intense effort by many teams of scientists worldwide is currently underway to determine the location, DNA sequence and function of human genes <ref> [38, 55] </ref>. Physical 4.1 Introduction 105 maps are an important part of this process. A physical map of a chromosome shows the relative locations and estimated distances between known markers along the chromosome.
Reference: [56] <author> J.B.S. Haldane. </author> <title> The combination of linkage values, and the calculation of distance between the loci of linked factors. </title> <journal> J. Genet., </journal> <volume> 8 </volume> <pages> 299-309, </pages> <year> 1919. </year> <note> 172 Bibliography </note>
Reference-contexts: We cannot distinguish the exact number of copies retained. We must account for this limitation when we attempt to determine accurate distances between adjacent markers in our maps. The unit of distance in radiation hybrid maps is the Ray [31, 43]. The distance is calculated with the Haldane <ref> [56] </ref> formula: log (1 ), where is the probability of a break between two markers. One centiRay (cR) corresponds roughly to a 1% chance of a break. Each centiRay also corresponds to a rough physical distance (in Mb) based on the radiation dosage used in creating the hybrid panel.
Reference: [57] <author> David Haussler, Michael Kearns, Nick Littlestone, and Manfred K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Information and Computation, </journal> <volume> 95(2) </volume> <pages> 129-161, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: On the other hand, we may allow a learning algorithm to output any polynomial-time algorithm as a hypothesis. This less constrained model is sometimes called "PAC-predictability" <ref> [58, 57] </ref>. Active learning is also known as "query learning," since the learner is allowed to ask queries of an omniscient oracle. Many types of queries are possible, but the two most commonly-studied questions are membership queries and equivalence queries.
Reference: [58] <author> David Haussler, Nick Littlestone, and Manfred K. Warmuth. </author> <title> Predicting f0,1g functions on randomly drawn points. </title> <journal> Information and Computation, </journal> <volume> 115(2) </volume> <pages> 284-293, </pages> <year> 1994. </year>
Reference-contexts: On the other hand, we may allow a learning algorithm to output any polynomial-time algorithm as a hypothesis. This less constrained model is sometimes called "PAC-predictability" <ref> [58, 57] </ref>. Active learning is also known as "query learning," since the learner is allowed to ask queries of an omniscient oracle. Many types of queries are possible, but the two most commonly-studied questions are membership queries and equivalence queries.
Reference: [59] <author> Ian Horswill. </author> <title> Specialization of Perceptual Processes. </title> <type> PhD dissertation, </type> <institution> MIT Ar tificial Intelligence Laboratory, </institution> <month> September </month> <year> 1994. </year> <note> Available as Technical Report MIT-AITR-1511. </note>
Reference-contexts: While this model may appear extreme, it provides upper bounds for practical cases in which robots fail to recognize familiar locations. An example of this problem is found in Horswill's thesis <ref> [59] </ref>. Horswill describes Polly, a robot that wanders the seventh floor of the MIT AI Laboratory and gives tours to visitors. Polly has a built-in map of her environment.
Reference: [60] <author> T. Hudson, et al. </author> <title> An STS-based map of the human genome. </title> <booktitle> Science, </booktitle> <year> 270:1945 1954, </year> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Integrated Map The resolution of radiation hybrid mapping can be controlled by adjusting the amount of radiation used to create the hybrid panel. In particular, the method can generate maps intermediate in resolution between genetic linkage maps and fine-grain STS content maps on YACs <ref> [35, 60] </ref>. Thus, radiation hybrid maps may provide the cohesion necessary for integrating several different types of mapping data. <p> Thus, radiation hybrid maps may provide the cohesion necessary for integrating several different types of mapping data. The radiation hybrid maps described here formed the basis for the construction of a 15,086-marker integrated map described in Hudson, et al. <ref> [60] </ref>, which has since been expanded to contain 20,186 markers. The integrated map shows the consistency of the RH map with other types of map data.
Reference: [61] <author> C.W. Richard III, et al. </author> <title> A radiation hybrid map of the proximal long arm of human chromosome 11, containing the multiple endocrine neoplasia type 1 (MEN-1) and bcl-1 disease loci. </title> <journal> Am. J. hum. Gen., </journal> <volume> 49 </volume> <pages> 1189-1196, </pages> <year> 1991. </year>
Reference-contexts: We expect that this goal of a 30,000-marker map will be reached well ahead of schedule, in part due to the work described in this chapter. 4.2 Radiation Hybrid Mapping Radiation hybrid mapping [43] is a technique that has been used for small-scale mapping since 1990 <ref> [61, 1, 62] </ref>. The experimental method involves exposing human cells to gamma radiation, which breaks each chromosome into random fragments. The DNA fragments are then "rescued" by fusion with healthy hamster cells that incorporate or retain a random subset of the human DNA fragments.
Reference: [62] <author> C.W. Richard III, et al. </author> <title> A radiation hybrid map of the distal short arm of human chromosome 11, containing the beckwith-weidemann and associated embryonal tumor disease loci. </title> <journal> Am. J. hum. Gen., </journal> <volume> 52 </volume> <pages> 915-921, </pages> <year> 1993. </year>
Reference-contexts: We expect that this goal of a 30,000-marker map will be reached well ahead of schedule, in part due to the work described in this chapter. 4.2 Radiation Hybrid Mapping Radiation hybrid mapping [43] is a technique that has been used for small-scale mapping since 1990 <ref> [61, 1, 62] </ref>. The experimental method involves exposing human cells to gamma radiation, which breaks each chromosome into random fragments. The DNA fragments are then "rescued" by fusion with healthy hamster cells that incorporate or retain a random subset of the human DNA fragments.
Reference: [63] <editor> M.R. James, et al. </editor> <title> A radiation hybrid map of 506 STS markers spanning human chromosome 11. </title> <journal> Nature Genetics, </journal> <volume> 8 </volume> <pages> 70-76, </pages> <year> 1994. </year>
Reference-contexts: A third RHMAP option uses simulated annealing to find a maximum-likelihood solution. In Section 4.4 we describe our preliminary attempts to apply similar techniques to large-scale mapping. Radiation hybrid mapping has been used successfully to create maps of human chromosomes 14 [111], 11 <ref> [63] </ref>, 4 and 12 [42]. However, building maps of entire chromosomes using RHMAP is a slow and painful process. <p> Centromeric Retention We have noticed two phenomena that occur at the centromeres of most chromosomes. First, markers near the centromeres tend to have a higher retention rate than markers from elsewhere along the chromosome. This finding has previously been noted by other researchers <ref> [63, 111] </ref>. Second, we see very low pairwise linkage between markers on opposite sides of the centromere whose genetic map positions are only a few cM apart (so that we would expect to see significant RH linkage). <p> One way to test this hypothesis is to try specifically to generate several markers in the centromere itself, as James' group did with microsatellite markers on Chromosome 11 <ref> [63] </ref>. One could then test to see whether satellite markers from opposite sides of the centromere show linkage to one another or not. <p> However, if there is some particular point in the centromere with an unusually high break probability, that break point would appear even in a map of intra-centromeric markers. A final possibility has to do with high centromeric retention rates. James' study of chromosome 11 <ref> [63] </ref> showed that the retention frequencies of several markers near the centromere were higher than 60%.
Reference: [64] <author> Michael Kearns and Ming Li. </author> <title> Learning in the presence of malicious errors. </title> <journal> SIAM Journal on Computing, </journal> <volume> 22 </volume> <pages> 807-837, </pages> <year> 1993. </year>
Reference-contexts: Valiant shows that a small rate of error can be tolerated in this model. Kearns and Li <ref> [64] </ref> show that Valiant's error bound is tight; they use an information-theoretic argument to prove that a malicious error rate of at most O (*) is tolerable when PAC-learning any distinct concept class C. <p> Finally, we extend these definitions to the exact learning model by requiring that counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled <ref> [6, 70, 101, 64] </ref> and additional work in models that allow attribute noise [99, 52, 75]. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [65] <author> Michael J. Kearns and Robert E. Schapire. </author> <title> Efficient distribution-free learning of probablistic concepts. </title> <booktitle> In Proceedings of the Thirty-First Annual Symposium on Foundations of Computer Science, </booktitle> <volume> volume I, </volume> <pages> pages 382-391. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: The p-concepts model of Kearns and Schapire <ref> [65] </ref> also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries. <p> The challenge then would be to find a meaningful definition of learning in which it is possible to learn complicated concepts (perhaps in an approximate, PAC-like way) given any non-pathological source of noise. Kearns and Schapire's work on learning P-concepts <ref> [65] </ref> is a good preliminary description of such a model; a probabilistic concept may simply be the learner's representation of a noise process that is not well understood. I believe that more work along these lines is needed to suggest practical approaches to learning from imperfect data.
Reference: [66] <author> Michael J. Kearns and H. Sebastian Seung. </author> <title> Learning from a population of hy potheses. </title> <booktitle> In Proceedings of COLT '93, </booktitle> <pages> pages 101-110, </pages> <year> 1993. </year>
Reference-contexts: They show how to combine the prediction strategies of several experts to predict nearly as well as the best of the experts. In a related paper, Kearns and Seung <ref> [66] </ref> explore the statistical problems of combining several independent hypotheses to learn a target concept from a known, restricted concept class.
Reference: [67] <author> John Kececioglu and Eugene Myers. </author> <title> Combinatorial algorithms for DNA sequence assembly. </title> <journal> Algorithmica, </journal> <volume> 13 </volume> <pages> 7-51, </pages> <year> 1995. </year>
Reference-contexts: It has been the subject of a great deal of research that is beyond the scope of this thesis; see <ref> [67] </ref> for a summary of current sequence assembly methods. 4.1 Introduction 107 Chapter Overview This chapter describes the practical problems of building genome-wide radiation hybrid maps from noisy data. The work is part of a collaborative effort with the physical mapping group at the Whitehead Institute Center for Genome Research.
Reference: [68] <author> Y. Kohara, K. Akiyama, and K. Isono. </author> <title> The physical map of the whole E. coli chromosome: application of a new strategy for rapid analysis and sorting of a large genomic library. </title> <journal> Cell, </journal> <volume> 50(3) </volume> <pages> 495-508, </pages> <year> 1987. </year>
Reference-contexts: We have validated our approach by using it to construct genome-wide radiation hybrid maps. Other Physical Mapping Strategies We also experimented briefly with algorithmic methods that have been applied successfully to other physical mapping problems. The earliest physical maps consisted of overlapping clone coverage of a region <ref> [84, 41, 68] </ref>. The clones most suitable for large-scale mapping are yeast artificial chromosomes (YACs). Each YAC incorporates an approximately 1 megabase (Mb) DNA fragment from a random part of the human genome.
Reference: [69] <author> Zvi Kohavi. </author> <title> Switching and Finite Automata Theory. </title> <type> McGraw-Hill, </type> <note> second edition, 1978. Bibliography 173 </note>
Reference-contexts: Theorem 6 Every strongly-connected directed graph has a two-robot homing sequence. Proof: The following algorithm (based on that of Kohavi <ref> [69, 93] </ref>) constructs a homing sequence: Initially, let h be empty. As long as there are two nodes u and v in G such that output (h,u) = output (h,v) but final (h,u) 6 final (h,v), let x be a lead-lag sequence whose output distinguishes final (h,u) from final (h,v).
Reference: [70] <author> Philip D. Laird. </author> <title> Learning from Good and Bad Data. </title> <booktitle> Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: A number of other papers further explore various models in which the examples themselves or their classifications are corrupted (see Laird <ref> [70] </ref>; Shackelford and Volper [99]; Sloan [101, 102]; among others). Less is known about errors in query models. Sakakibara [97] proposes a model of noise in queries, which assumes that every time a query is asked there is some independent probability of getting the wrong answer. <p> Finally, we extend these definitions to the exact learning model by requiring that counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled <ref> [6, 70, 101, 64] </ref> and additional work in models that allow attribute noise [99, 52, 75]. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [71] <author> Eric S. Lander and Philip Green. </author> <title> Construction of multilocus genetic linkage maps in humans. </title> <booktitle> Proceedings of the National Academy of Sciences, USA, </booktitle> <volume> 84 </volume> <pages> 2363-2367, </pages> <year> 1987. </year>
Reference-contexts: To determine the likelihood of a particular order we use the estimation-maximization (EM) algorithm, which efficiently estimates the most-likely distances between adjacent markers in the given order. (Lander and Green <ref> [71] </ref> describe a similar process for building maps from genetic linkage data.) Our hidden Markov model relies on several assumptions. (For a basic tutorial on hidden Markov models, see Rabiner [90].) We assume that the radiation-induced breaks occur randomly along a chromosome as a Poisson process, and that different fragments are
Reference: [72] <author> K.J. Lang and E.B. Baum. </author> <title> Query learning can work poorly when a human oracle is used. </title> <booktitle> In Proceedings of International Joint Conference on Neural Networks. IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: A problem with this type of approach 1 , as noticed by Lang and Baum <ref> [72] </ref>, is that questions of this sort that are near the concept boundary may result in unreliable answers.
Reference: [73] <author> Kenneth Lange, Michael Boehnke, David Cox, and Kathryn Lunetta. </author> <title> Statistical methods for polyploid radiation hybrid mapping. </title> <journal> Genome Research, </journal> <volume> 5 </volume> <pages> 136-150, </pages> <year> 1995. </year>
Reference-contexts: Previous Work on Radiation Hybrid Mapping Analytical methods for constructing radiation hybrid maps have been published by Boehnke, et al. <ref> [30, 31, 73, 76] </ref>. Their software, RHMAP, was originally designed for building maps of small chromosomal regions near disease genes. The hybrid panels used for this purpose are derived from somatic cell hybrids containing only a single copy of the human chromosome of interest. <p> Thus, while software for handling the haploid case has been widely available for a number of years [32], software that handles the diploid panels used in genome-wide mapping has only recently become available <ref> [30, 73] </ref>. Boehnke solves the first computational problem, that of determining what makes a good map, by representing the data with a Markov model. Under this probabilistic model one can compute the likelihood of each map.
Reference: [74] <author> Nick Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: examples (produced and classified by Nature) with the assistance of a teacher who can correctly classify some but not all of the possible examples (modeled by an incomplete membership oracle.) If we have an efficient learning algorithm using equivalence queries and an incomplete membership oracle, then by a general transformation <ref> [74] </ref> we can obtain an efficient algorithm for the prediction task in the mistake bounded model that uses an incomplete membership oracle. It may also seem unrealistic to consider a teacher whose failures occur uniformly at random.
Reference: [75] <author> Nick Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proceedings of the 4th Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 147-156, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled [6, 70, 101, 64] and additional work in models that allow attribute noise <ref> [99, 52, 75] </ref>. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [76] <author> Kathryn Lunetta, Michael Boehnke, Kenneth Lange, and David Cox. </author> <title> Experimen tal design and error detection for polyploid radiation hybrid mapping. </title> <journal> Genome Research, </journal> <volume> 5 </volume> <pages> 151-163, </pages> <year> 1995. </year>
Reference-contexts: Previous Work on Radiation Hybrid Mapping Analytical methods for constructing radiation hybrid maps have been published by Boehnke, et al. <ref> [30, 31, 73, 76] </ref>. Their software, RHMAP, was originally designed for building maps of small chromosomal regions near disease genes. The hybrid panels used for this purpose are derived from somatic cell hybrids containing only a single copy of the human chromosome of interest. <p> While errors create difficulties in mono-chromosomal mapping as well, the problem is even more pervasive in large-scale mapping efforts. RHMAP does not account for errors in the data at all. Lunetta, et al. <ref> [76] </ref> analyze the impact of such errors on map construction and conclude that even low error rates can significantly confound mapping efforts. To be practical, map software should accommodate noisy data and flag suspected laboratory errors for experimental verification.
Reference: [77] <author> Wolfgang Maass. </author> <title> On-line learning with an oblivious environment and the power of randomization. </title> <booktitle> In Proceedings of the 4th Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 167-175, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: still possible (since an 26 Learning With Imperfect Teachers algorithm could simply perform identification by enumeration using equivalence queries.) In this new model we must specify the type of adversary selecting the counterexamples. (This is also an issue in the standard model when randomized learning algorithms are considered, as Maass <ref> [77] </ref> has shown.) We assume that the adversary is "on-line." That is, the choice of a counterexample may depend on the target hypothesis and the history of the computation to the point at which the query is asked, including the hypothesis queried, all previous queries and their answers, and any previous
Reference: [78] <author> Melanie Mahtani. </author> <type> Personal communication, </type> <year> 1996. </year>
Reference-contexts: If this were the case, nearby markers on opposite sides of the centromere would be retained independently in almost all hybrids, yielding the low pairwise linkage that we see. Another possibility is that the gaps at the centromeres of our radiation hybrid maps might be real. It is known <ref> [78] </ref> that there is a low rate of recombination near the centromeres, so the genetic map distances in the region may correspond to much larger physical distances than expected.
Reference: [79] <editor> Maja Mataric. </editor> <title> A distributed model for mobile robot environment-learning and navigation. </title> <type> Master's thesis, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> May </month> <year> 1990. </year> <note> Available as Technical Report MIT-AITR-1228. </note>
Reference-contexts: However, most cooperative projects require the robots to achieve a goal in an already-known environment, rather than asking the robots to learn a map of their world. Some robotics projects do focus on environment learning. Mataric <ref> [79] </ref> shows how a single robot might learn a map of an unknown office environment. For her robot, whose navigation relies on sonar sensors and a compass, the ability to distinguish similarly-shaped landmarks is a key issue.
Reference: [80] <editor> Maja Mataric. </editor> <title> Interaction and Intelligent Behavior. </title> <type> PhD dissertation, </type> <institution> MIT Arti ficial Intelligence Laboratory, </institution> <month> August </month> <year> 1994. </year> <note> Available as Technical Report MIT-AITR-1495. </note>
Reference-contexts: A key property of a swarm is that no individual robot is essential for the completion of the task. There have been many projects studying the learning and behavior of robot swarms. 3.1 Introduction 69 Mataric <ref> [80] </ref> uses reinforcement learning [107] to teach "foraging" behavior to a team of twenty independently-controlled robots. Brooks, et al., [34] describe parallel algorithms for swarms of robots to select and clear a site for construction of a lunar research station.
Reference: [81] <author> Milena Mihail. </author> <title> Conductance and convergence of Markov chains a combinatorial treatment of expanders. </title> <booktitle> In Proceedings of the 30th Annual Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 526-531. </pages> <publisher> IEEE Press, </publisher> <year> 1989. </year>
Reference-contexts: Mihail <ref> [81] </ref> shows that after a walk of length 2 log (2n=* 2 ), the L 1 norm of the distance between the current distribution P and the stationary distribution is at most * (i.e. i jP i i j *).
Reference: [82] <author> Edward F. Moore. </author> <booktitle> Gedanken-Experiments on Sequential Machines, </booktitle> <pages> pages 129-153. </pages> <publisher> Princeton University Press, </publisher> <year> 1956. </year> <title> Edited by C. </title> <editor> E. Shannon and J. McCarthy. </editor> <publisher> 174 Bibliography </publisher>
Reference-contexts: If the pebble is dropped outside the lock, the robot will not see the pebble again until it has passed through the lock. A robot that cannot find its pebble 1 Graphs of this sort have been used in theoretical computer science for many years (see <ref> [82] </ref>, for example). More recently they have reemerged as tools to prove the hardness of learning problems. We are not sure who first coined the term "combination lock." 3.5 Learning a Homing Sequence 89 R 11 .
Reference: [83] <author> Rajeev Motwani and Prabhakar Raghavan. </author> <title> Randomized Algorithms. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1995. </year>
Reference: [84] <author> M. Olson, et al. </author> <title> Random-clone strategy for genomic restriction mapping in yeast. </title> <booktitle> Proceedings of the National Academy of Sciences, USA, </booktitle> <volume> 83(20) </volume> <pages> 7826-7830, </pages> <year> 1986. </year>
Reference-contexts: We have validated our approach by using it to construct genome-wide radiation hybrid maps. Other Physical Mapping Strategies We also experimented briefly with algorithmic methods that have been applied successfully to other physical mapping problems. The earliest physical maps consisted of overlapping clone coverage of a region <ref> [84, 41, 68] </ref>. The clones most suitable for large-scale mapping are yeast artificial chromosomes (YACs). Each YAC incorporates an approximately 1 megabase (Mb) DNA fragment from a random part of the human genome.
Reference: [85] <author> Lynne E. Parker. </author> <title> Heterogeneous Multi-Robot Cooperation. </title> <type> PhD dissertation, </type> <institution> MIT, Artificial Intelligence Laboratory, </institution> <month> February </month> <year> 1994. </year> <note> Available as Technical Report MIT-AITR-1465. </note>
Reference-contexts: Recently, Ron and Rubinfeld [94] have shown that a teacher is unnecessary for learning finite automata with small cover time. Teamwork and Learning in Robotics Team research in robotics tends to address issues of control. Parker <ref> [85] </ref> divides the results in this field into two camps: "swarm" cooperation and "intentional" cooperation. "Swarms" are teams of homogeneous robots that all independently perform the same task. For example, swarms of robots might be used for harvesting crops or for mine-sweeping fields in a war zone. <p> Often there is a single global controller and planner for the entire system. Rus, Donald and Jennings [96] explore team cooperation strategies for moving heavy furniture. They present several strategies, both with and without a global planner. Parker <ref> [85] </ref> describes fault-tolerant distributed cooperation methods for heterogeneous robot teams to solve complex tasks such as cleaning up a toxic spill. However, most cooperative projects require the robots to achieve a goal in an already-known environment, rather than asking the robots to learn a map of their world.
Reference: [86] <author> Leonard Pitt and Manfred K. Warmuth. </author> <title> Prediction preserving reducibility. </title> <journal> Jour nal of Computer and System Sciences, </journal> <volume> 41(3) </volume> <pages> 430-467, </pages> <month> December </month> <year> 1990. </year> <booktitle> Special issue on the Third Annual Conference of Structure in Complexity Theory (Wash-ington, </booktitle> <address> DC., </address> <month> June 88). </month>
Reference-contexts: While this is clearly a highly-restrictive class, it is not difficult to show, using standard prediction preserving reductions <ref> [86] </ref>, that it is as hard to learn as general DNF formulas in the passive PAC model. Thus our algorithm demonstrates that unreliable 50 Learning With Imperfect Teachers queries provide some power over the passive model in a boolean setting.
Reference: [87] <author> C. K. Poon. </author> <title> Space bounds for graph connectivity problems on node-named JAGs and node-ordered JAGs. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 218-227. </pages> <publisher> IEEE Press, </publisher> <year> 1993. </year>
Reference-contexts: JAGs have been used primarily to prove space efficiency for st-connectivity algorithms, and they have recently resurfaced as a tool for analyzing time and space tradeoffs for graph traversal and connectivity problems (e.g. <ref> [18, 87, 46] </ref>). Universal traversal sequences have been used to provide upper and lower bounds for the exploration of undirected graphs. Certainly, a universal traversal sequence for the class of directed graphs could be used to learn individual graphs.
Reference: [88] <author> W.H. Press, S. A. Teukolshy, W. T. Vettering, and B. P. Flannery. </author> <title> Minimization or maximization of functions. In Numerical Recipes in C, </title> <booktitle> 2nd Edition, </booktitle> <pages> pages 394-455, </pages> <address> Cambridge, UK, 1988. </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: We repeated this process until the set of the ten most-likely elements in the population remained stable for a large number of generations (generally at least 100). Our simulated annealing algorithm was based on the code in Numerical Recipes in C <ref> [88] </ref>. (The relevant chapter, by Press, et al., also contains a good overview of simulated annealing.) New orders were derived from old ones by either swapping or reversing random substrings.
Reference: [89] <author> Michael O. Rabin. </author> <title> Maze threading automata. </title> <institution> Seminar talk presented at the University of California at Berkeley, </institution> <month> October </month> <year> 1967. </year>
Reference-contexts: However, when equipped with a number of pebbles that can be used to mark nodes, the single robot's plight improves. Rabin first proposed the idea of dropping pebbles to mark nodes <ref> [89] </ref>. This suggestion led to a body of work exploring the searching capabilities of a finite automaton supplied with pebbles. Blum and Sakoda [25] consider the question of whether a finite set of finite automata can search a 2 or 3-dimensional obstructed grid.
Reference: [90] <author> Lawrence Rabiner. </author> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77 </volume> <pages> 257-286, </pages> <year> 1989. </year>
Reference-contexts: the estimation-maximization (EM) algorithm, which efficiently estimates the most-likely distances between adjacent markers in the given order. (Lander and Green [71] describe a similar process for building maps from genetic linkage data.) Our hidden Markov model relies on several assumptions. (For a basic tutorial on hidden Markov models, see Rabiner <ref> [90] </ref>.) We assume that the radiation-induced breaks occur randomly along a chromosome as a Poisson process, and that different fragments are retained independently in a given hybrid. The retention rate is taken to be a constant for each hybrid, but different hybrids may have different retention rates. <p> Hence we describe the method for computing the likelihood of a map for a single hybrid. Our goal is to determine Pr (DatajMap). We compute this quantity inductively using Baum's forward-backward algorithm (see Rabiner <ref> [90] </ref> for an introduction to this and other basic HMM algorithms). Let P r L (i; j), the left-conditioned probability of state j at marker i, represent the probability of being in state j at marker i and seeing the observed data at the first i markers, given the map.
Reference: [91] <author> Prabhakar Raghavan. </author> <title> Lecture notes on randomized algorithms. </title> <institution> Yale University Course CS661, </institution> <month> Fall, </month> <year> 1989. </year>
Reference-contexts: Before we can prove the correctness of our algorithm, we need one more set of tools. Consider the following statement of Chernoff bounds from Raghavan <ref> [91] </ref>. Lemma 12 Let X 1 ; : : : ; X m be independent Bernoulli trials with E [X j ] = p j . Let the random variable X = P m j=1 X j , where = E [X] 0.
Reference: [92] <author> Ronald L. Rivest and Robert E. Schapire. </author> <title> Diversity-based inference of finite au tomata. </title> <booktitle> In Proceeding of the Twenty-Eighth Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 78-87, </pages> <address> Los Angeles, California, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: Betke, Rivest, and Singh provide linear algorithms for learning grid graphs with rectangular obstacles [21], and with Awerbuch [15] extend this work to show nearly-linear algorithms for general graphs. Rivest and Schapire <ref> [92, 93] </ref> explore the problem of learning deterministic finite automata whose nodes are not distinguishable except by the observed output. We rely heavily on their results in this chapter. Their work has been extended by Freund et al. [50], and by Dean et al. [44].
Reference: [93] <author> Ronald L. Rivest and Robert E. Schapire. </author> <title> Inference of finite automata using homing sequences. </title> <journal> Information and Computation, </journal> <volume> 103(2) </volume> <pages> 299-347, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Betke, Rivest, and Singh provide linear algorithms for learning grid graphs with rectangular obstacles [21], and with Awerbuch [15] extend this work to show nearly-linear algorithms for general graphs. Rivest and Schapire <ref> [92, 93] </ref> explore the problem of learning deterministic finite automata whose nodes are not distinguishable except by the observed output. We rely heavily on their results in this chapter. Their work has been extended by Freund et al. [50], and by Dean et al. [44]. <p> Alternatively, the lagging robot can abandon its current node to catch up with the leader, but then it may not know how to return to that node. In spite of these difficulties, our algorithms successfully employ a lead-lag strategy. Our work also builds on techniques of Rivest and Schapire <ref> [93] </ref>. They present an algorithm for a single robot to learn minimal deterministic finite automata. With the help of an equivalence oracle, their algorithm learns a homing sequence, which it uses in place of a reset function. <p> In this section we suggest an alternative technique: we introduce a new type of homing sequence for two robots. Intuitively, a homing sequence is a sequence of actions whose observed output uniquely determines the final node reached in G. Rivest and Schapire <ref> [93] </ref> show how a single robot with a teacher can use homing sequences to learn strongly-connected minimal DFAs. The output at each node indicates whether that node is an accepting or rejecting state of the automaton. <p> Theorem 6 Every strongly-connected directed graph has a two-robot homing sequence. Proof: The following algorithm (based on that of Kohavi <ref> [69, 93] </ref>) constructs a homing sequence: Initially, let h be empty. As long as there are two nodes u and v in G such that output (h,u) = output (h,v) but final (h,u) 6 final (h,v), let x be a lead-lag sequence whose output distinguishes final (h,u) from final (h,v). <p> Thus, the total running time of the algorithm is O (d 2 n 6 ). 2 3.5.1 Improvements to the Algorithm The running time for Learn-Graph can be decreased significantly by using two-robot adaptive homing sequences. As in Rivest and Schapire <ref> [93] </ref>, an adaptive homing sequence is a decision tree, so the actions in later steps of the sequence depend on the output of earlier steps. With an adaptive homing sequence, only one map c needs to be discarded each time the homing sequence is improved.
Reference: [94] <author> Dana Ron and Ronitt Rubinfeld. </author> <title> Exactly learning automata with small cover time. </title> <booktitle> In Proceedings 8th Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 427-436. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: Ron and Rubinfeld [95] present algorithms for learning "fallible" DFAs, in which the data is subject to persistent random errors. Recently, Ron and Rubinfeld <ref> [94] </ref> have shown that a teacher is unnecessary for learning finite automata with small cover time. Teamwork and Learning in Robotics Team research in robotics tends to address issues of control.
Reference: [95] <author> Dana Ron and Ronitt Rubinfeld. </author> <title> Learning fallible deterministic finite automata. </title> <journal> Machine Learning, </journal> 18(2/3):149-185, 1995. Bibliography <volume> 175 </volume>
Reference-contexts: Freund et al. analyze the problem of learning finite automata with average-case labelings by the observed output on a random string, while Dean et al. explore the problem of learning DFAs with a robot whose observations of the environment are not always reliable. Ron and Rubinfeld <ref> [95] </ref> present algorithms for learning "fallible" DFAs, in which the data is subject to persistent random errors. Recently, Ron and Rubinfeld [94] have shown that a teacher is unnecessary for learning finite automata with small cover time.
Reference: [96] <author> Daniela Rus, Bruce Donald, and Jim Jennings. </author> <title> Moving furniture with teams of autonomous robots. </title> <booktitle> In Proceedings of the IEEE International Workshop on Robots and Systems. </booktitle> <publisher> IEEE Press, </publisher> <year> 1995. </year>
Reference-contexts: In contrast, intentional cooperation refers to cases in which several (perhaps heterogeneous) robots work together to achieve tasks that no one robot could complete alone. Often there is a single global controller and planner for the entire system. Rus, Donald and Jennings <ref> [96] </ref> explore team cooperation strategies for moving heavy furniture. They present several strategies, both with and without a global planner. Parker [85] describes fault-tolerant distributed cooperation methods for heterogeneous robot teams to solve complex tasks such as cleaning up a toxic spill.
Reference: [97] <author> Yasubumi Sakakibara. </author> <title> On learning from queries and counterexamples in the pres ence of noise. </title> <journal> Information Processing Letters, </journal> <volume> 37(5) </volume> <pages> 279-284, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: A number of other papers further explore various models in which the examples themselves or their classifications are corrupted (see Laird [70]; Shackelford and Volper [99]; Sloan [101, 102]; among others). Less is known about errors in query models. Sakakibara <ref> [97] </ref> proposes a model of noise in queries, which assumes that every time a query is asked there is some independent probability of getting the wrong answer. <p> The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries. Sakakibara <ref> [97] </ref> considers the case where each membership query is incorrectly answered with a fixed probability, but where one can increase reliability by asking the same membership query several times.
Reference: [98] <author> Walter J. Savitch. </author> <title> Maze recognizing automata and nondeterministic tape com plexity. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 7 </volume> <pages> 389-403, </pages> <year> 1972. </year>
Reference-contexts: Their results imply that mazes are strictly easier to search than planar graphs, since they also show that no single automaton with pebbles can search all planar graphs. Savitch <ref> [98] </ref> introduces the notion of a maze-recognizing automaton (MRA), which is a DFA with a finite number of distinguishable pebbles.
Reference: [99] <author> George Shackelford and Dennis Volper. </author> <title> Learning k-DNF with noise in the at tributes. </title> <booktitle> In First Workshop on Computatinal Learning Theory, </booktitle> <pages> pages 97-103, </pages> <address> Cambridge, Mass. August 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A number of other papers further explore various models in which the examples themselves or their classifications are corrupted (see Laird [70]; Shackelford and Volper <ref> [99] </ref>; Sloan [101, 102]; among others). Less is known about errors in query models. Sakakibara [97] proposes a model of noise in queries, which assumes that every time a query is asked there is some independent probability of getting the wrong answer. <p> counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled [6, 70, 101, 64] and additional work in models that allow attribute noise <ref> [99, 52, 75] </ref>. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [100] <author> Alistair Sinclair and Mark Jerrum. </author> <title> Approximate counting, uniform generation and rapidly mixing Markov chains. </title> <journal> Information and Computation, </journal> <volume> 82(1) </volume> <pages> 93-133, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Two robots can learn specific classes of directed graphs more quickly, such as the class of graphs with high conductance. Conductance, a measure of the expansion prop 3.2 Preliminaries 73 erties of a graph, was introduced by Sinclair and Jerrum <ref> [100] </ref>. The class of directed graphs with high conductance includes graphs with exponentially-large cover time. <p> In this section we define conductance and present an algorithm that runs more quickly than Learn-Graph for graphs with conductance greater than q 3.6.1 Conductance The conductance <ref> [100] </ref> of a graph characterizes the rate at which a random walk on the graph converges to the stationary distribution .
Reference: [101] <author> Robert H. Sloan. </author> <title> Types of noise in data for concept learning. </title> <booktitle> In First Workshop on Computational Learning Theory, </booktitle> <pages> pages 91-96. </pages> <publisher> Morgan Kaufmann, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: A number of other papers further explore various models in which the examples themselves or their classifications are corrupted (see Laird [70]; Shackelford and Volper [99]; Sloan <ref> [101, 102] </ref>; among others). Less is known about errors in query models. Sakakibara [97] proposes a model of noise in queries, which assumes that every time a query is asked there is some independent probability of getting the wrong answer. <p> Finally, we extend these definitions to the exact learning model by requiring that counterexamples to equivalence queries not be chosen from the boundary region. 2.3.3 Related Work There has been a great deal of theoretical work on PAC or mistake-bound learning in cases where the training examples may be mislabeled <ref> [6, 70, 101, 64] </ref> and additional work in models that allow attribute noise [99, 52, 75]. The p-concepts model of Kearns and Schapire [65] also falls somewhat into this category. There have also been a number of results on learning with randomly generated noisy responses to membership queries.
Reference: [102] <author> Robert H. Sloan. </author> <title> Computational Learning Theory: New Models and Algorithms. </title> <type> PhD thesis, </type> <institution> MIT EECS Department, </institution> <month> May </month> <year> 1989. </year> <note> (Published as MIT/LCS/TR-448.). </note>
Reference-contexts: A number of other papers further explore various models in which the examples themselves or their classifications are corrupted (see Laird [70]; Shackelford and Volper [99]; Sloan <ref> [101, 102] </ref>; among others). Less is known about errors in query models. Sakakibara [97] proposes a model of noise in queries, which assumes that every time a query is asked there is some independent probability of getting the wrong answer.
Reference: [103] <author> Robert H. Sloan and Gyorgy Turan. </author> <title> Learning with queries but incomplete in formation. </title> <booktitle> In Proceedings of the 7th Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 237-245. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: Additional positive results in this model are obtained by Goldman and Math-ias [54]. This model allows for a large number of "don't know" instances, but positive results in this model are typically highly dependent on the precisely uniform nature of the noise. Sloan and Turan <ref> [103] </ref> introduce the limited membership query model . In this model, an adversary may arbitrarily select some number ` of examples on which it refuses to answer membership queries (or answers "don't know"), but the learner is now allowed to ask a number of queries polynomial in `. <p> difficult than those above in the sense that the membership query errors or omissions are chosen by an adversary (unlike the random noise models [13]), and algorithms must run in time that is polynomial in the usual parameters regardless of the number of queries that might receive incorrect answers (unlike <ref> [103, 10] </ref>). For example, in the case of a 1-term monotone DNF formula with the boundary radius r = 1, there may be exponentially many (in n) instances in the 2.3 Unreliable Boundary Queries 43 boundary region. (Example: let x 4 x 7 x 9 be the target term.
Reference: [104] <author> Donna Slonim, Lincoln Stein, Leonid Kruglyak, and Eric Lander. RHMAPPER: </author> <title> An interactive computer package for constructing radiation hybrid maps. </title> <type> Unpublished manuscript, </type> <year> 1996. </year>
Reference-contexts: Our practical experiments in map construction are described in the next section. 4.7 Results 4.7.1 RHMAPPER: Interactive Map Construction Software We have written an interactive software package called RHMAPPER <ref> [104, 106] </ref> that incorporates the algorithms described here for the construction of genome-wide radiation hybrid maps. The package includes facilities to automatically detect and flag errors in the data, allowing error-correction during map assembly.
Reference: [105] <author> Carl H. Smith. </author> <title> Three decades of team learning. In Algorithmic Learning Theory. </title> <publisher> Springer Verlag, </publisher> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: Thus, if the robots can recognize landmarks some of the time, the learning algorithm runs more quickly. 3.1.2 Related Work Theoretical Results on Graph Exploration and Team Learning Previous results showing the power of team learning are plentiful, particularly in the field of inductive inference (see Smith <ref> [105] </ref> for an excellent survey). Several team learning papers explore the problems of combining the abilities of a number of different learners. Cesa-Bianchi et al. [36] consider the task of learning a probabilistic binary sequence given the predictions of a set of experts on the same sequence.
Reference: [106] <author> Lincoln Stein, Leonid Kruglyak, Donna Slonim, and Eric Lander. </author> <title> RHMAP PER software package, </title> <note> 1995. Available at http://www-genome.wi.mit.edu/ ftp/pub/software/rhmapper/, and via anonymous ftp from ftp-genome.wi.mit.edu, directory /pub/software/rhmapper. </note>
Reference-contexts: Our practical experiments in map construction are described in the next section. 4.7 Results 4.7.1 RHMAPPER: Interactive Map Construction Software We have written an interactive software package called RHMAPPER <ref> [104, 106] </ref> that incorporates the algorithms described here for the construction of genome-wide radiation hybrid maps. The package includes facilities to automatically detect and flag errors in the data, allowing error-correction during map assembly.
Reference: [107] <author> Richard Sutton, </author> <title> editor. </title> <journal> Special issue on reinforcement learning. Machine Learning, </journal> <volume> 8(3=4), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: A key property of a swarm is that no individual robot is essential for the completion of the task. There have been many projects studying the learning and behavior of robot swarms. 3.1 Introduction 69 Mataric [80] uses reinforcement learning <ref> [107] </ref> to teach "foraging" behavior to a team of twenty independently-controlled robots. Brooks, et al., [34] describe parallel algorithms for swarms of robots to select and clear a site for construction of a lunar research station.
Reference: [108] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year> <note> 176 Bibliography </note>
Reference-contexts: Or she might generate the hypothesis "a dog is any animal with four legs," and ask the teacher if her hypothesis is correct. In 1984, Valiant introduced a formal learning model intended to capture these notions <ref> [108] </ref>. The model is known as distribution-free or PAC-learning, where PAC stands for "probably approximately correct." Formally, a concept f : X ! f0; 1g is a boolean function over an instance space X . <p> Previous Work There has been a good deal of work done on errors in the distribution-free model of learning introduced by Valiant <ref> [108] </ref>. Results are encouraging for the case of random misclassification errors. In this benign error model, the teacher produces labeled positive or negative examples, where the label for any example is incorrect independently with probability .
Reference: [109] <author> Leslie G. Valiant. </author> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings IJCAI-85, </booktitle> <pages> pages 560-566. </pages> <booktitle> International Joint Committee for Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <month> August </month> <year> 1985. </year>
Reference-contexts: In particular, they show that k-CNF formulas are PAC-learnable in polynomial time with a random noise rate of less than 1 2 . Other work has focused on the case of malicious misclassification errors in examples. Valiant <ref> [109] </ref> poses the question of learning k-CNF formulas despite an adversarial teacher that draws random positive or negative examples, but with error probability fi returns an arbitrary response instead of the correctly labeled example. Valiant shows that a small rate of error can be tolerated in this model.
Reference: [110] <author> V. N. Vapnik and A. Y. Chervonenkis. </author> <title> On the uniform convergence of relative fre quencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: For each positive example ~x pos 2 S do the following. For each negative example ~x neg 2 S, query the example 2~x pos ~x neg , and if the response to 3 The VC-dimension <ref> [110] </ref> of the hypothesis class is O (n 2 ).
Reference: [111] <author> M. A. Walter, D. J. Spillett, P. Thomas, J. Weissenbach, and P. N. Goodfellow. </author> <title> A method for constructing radiation hybrid maps of whole genomes. </title> <journal> Nature Genetics, </journal> <volume> 7 </volume> <pages> 22-28, </pages> <year> 1994. </year>
Reference-contexts: A third RHMAP option uses simulated annealing to find a maximum-likelihood solution. In Section 4.4 we describe our preliminary attempts to apply similar techniques to large-scale mapping. Radiation hybrid mapping has been used successfully to create maps of human chromosomes 14 <ref> [111] </ref>, 11 [63], 4 and 12 [42]. However, building maps of entire chromosomes using RHMAP is a slow and painful process. <p> Centromeric Retention We have noticed two phenomena that occur at the centromeres of most chromosomes. First, markers near the centromeres tend to have a higher retention rate than markers from elsewhere along the chromosome. This finding has previously been noted by other researchers <ref> [63, 111] </ref>. Second, we see very low pairwise linkage between markers on opposite sides of the centromere whose genetic map positions are only a few cM apart (so that we would expect to see significant RH linkage). <p> We believe that the high retention rate at the centromeres is related to the fact that fragments can be retained by the hybrid cell in two different ways. Walter, et al. <ref> [111] </ref> have observed by fluorescence in situ hybridization (FISH) that some human DNA fragments become integrated into existing hamster chromosomes in the hybrid cells, while 4.7 Results 157 other fragments join together to form entirely new chromosomes.
Reference: [112] <author> Holly Yanco and Lynn Stein. </author> <title> An adaptive communication protocol for cooperating mobile robots. </title> <booktitle> In From Animals to Animats 2: Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: For her robot, whose navigation relies on sonar sensors and a compass, the ability to distinguish similarly-shaped landmarks is a key issue. Mataric solves this problem using the robot's estimated position, based on compass readings and approximate distances traveled. Yanco and Stein <ref> [112] </ref> describe a project in which teams of two or three robots actually learn how to communicate with one another to work together. The robot teams develop their own communication language through reinforcement learning. The teams successfully learn small languages of up to 10 words.
Reference: [113] <author> Geoffrey Zweig. HAMTSP, </author> <title> unpublished software for solving the Hamming distance traveleing salesman problem, 1994. </title> <type> Received through personal communication. </type>
Reference-contexts: Thus, it seems reasonable that the correct permutation is one that minimizes the number of gaps in the matrix. Karp's group has implemented a traveling salesman approximation algorithm as a method of approximate gap-minimization <ref> [113] </ref>. <p> Since many different human DNA fragments are retained by each hybrid cell line, the columns of the matrix would contain many groups of consecutive ones. Despite this difference, we attempted to build radiation hybrid maps using the gap-minimization code that Karp's group wrote for STS-content mapping <ref> [113] </ref>; we describe the results in Section 4.4. 4.3 The Hidden Markov Model In this section we present an answer to the first fundamental question in mapping, "how good is a map?" Our approach compares different maps by constructing a probabilistic model of the data.
References-found: 113

