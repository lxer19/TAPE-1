URL: http://www.cse.ucsc.edu/~manfred/pubs/trackdisj.ps
Refering-URL: http://www.cse.ucsc.edu/~manfred/pubs.html
Root-URL: http://www.cse.ucsc.edu
Email: pauer@igi.tu-graz.ac.at  manfred@cse.ucsc.edu  Editor:  
Title: Tracking the best disjunction  
Author: PETER AUER MANFRED K. WARMUTH 
Keyword: On-line learning, prediction, concept drift, Winnow, computational learning theory, amortized analysis.  
Address: 32/2, A-8010 Graz, Austria  Building, Santa Cruz, CA 95064 (USA)  
Affiliation: Institute for Theoretical Computer Science, University of Technology Graz, Klosterwiesgasse  Department of Computer Science, University of California at Santa Cruz, Applied Sciences  
Note: 1-27 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: Littlestone developed a simple deterministic on-line learning algorithm for learning k-literal disjunctions. This algorithm (called Winnow) keeps one weight for each of the n variables and does multiplicative updates to its weights. We develop a randomized version of Winnow and prove bounds for an adaptation of the algorithm for the case when the disjunction may change over time. In this case a possible target disjunction schedule T is a sequence of disjunctions (one per trial) and the shift size is the total number of literals that are added/removed from the disjunctions as one progresses through the sequence. We develop an algorithm that predicts nearly as well as the best disjunction schedule for an arbitrary sequence of examples. This algorithm that allows us to track the predictions of the best disjunction is hardly more complex than the original version. However the amortized analysis needed for obtaining worst-case mistake bounds requires new techniques. In some cases our lower bounds show that the upper bounds of our algorithm have the right constant in front of the leading term in the mistake bound and almost the right constant in front of the second leading term. Computer experiments support our theoretical findings. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Auer, P. </author> <year> (1993). </year> <title> On-line learning of rectangles in noisy environments. </title> <booktitle> In Proceedings of the sixth annual acm conference on computational learning theory (pp. </booktitle> <pages> 253-261). </pages> <publisher> ACM Press, </publisher> <address> New York, NY. </address>
Reference: <author> Auer, P., & Warmuth, M. K. </author> <year> (1995). </year> <title> Tracking the best disjunction. </title> <booktitle> In Proceedings of the 36th annual symposium on foundations of computer science (pp. </booktitle> <pages> 312-321). </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension (Littlestone & Warmuth, 1994; Vovk, 1990; Cesa-Bianchi et al., 1997; Haussler, Kivinen, & Warmuth, 1994). * An extended abstract appeared in <ref> (Auer & Warmuth, 1995) </ref>. ** M. K.
Reference: <author> Cesa-Bianchi, N., Freund, Y., Haussler, D., Helmbold, D. P., Schapire, R. E., & Warmuth, M. K. </author> <year> (1997). </year> <title> How to use expert advice. </title> <journal> Journal of the ACM. </journal> <note> (To appear) Cesa-Bianchi, </note> <author> N., Freund, Y., Helmbold, D. P., & Warmuth, M. K. </author> <year> (1996). </year> <title> Online prediction and conversion strategies. </title> <journal> Machine Learning, </journal> <volume> 25, </volume> <pages> 71-110. </pages> <note> (An extended abstract appeared in Eurocolt `93) Cover, </note> <author> T. </author> <year> (1965). </year> <title> Behavior of sequential predictors of binary sequences. </title> <booktitle> In Proceedings of the 4th prague conference on information theory, statistical decision functions and random processes (pp. </booktitle> <pages> 263-272). </pages> <publisher> Publishing House of the Czechoslovak Academy of Sciences. </publisher>
Reference: <author> Duda, R. O., & Hart, P. E. </author> <year> (1973). </year> <title> Pattern classification and scene analysis. </title> <publisher> Wiley. </publisher>
Reference: <author> Haussler, D., Kivinen, J., & Warmuth, M. K. </author> <year> (1994). </year> <title> Tight worst-case loss bounds for predicting with expert advice (Tech. </title> <type> Rep. </type> <institution> No. UCSC-CRL-94-36). University of California, Santa Cruz, Computer Research Laboratory. </institution> <note> (An extended abstract appeared in Eurocolt 1995. To appear in IEEE Transactions on Information Theory.) </note> <author> Haykin, S. </author> <year> (1994). </year> <title> Neural networks: a comprehensive foundation. </title> <address> New York, NY: </address> <publisher> Macmillan. </publisher>
Reference: <author> Helmbold, D. P., & Schapire, R. E. </author> <year> (1997). </year> <title> Predicting nearly as well as the best pruning of a decision tree. </title> <journal> Machine Learning, </journal> <volume> 27, </volume> <pages> 51-68. </pages>
Reference-contexts: This method was previously used for developing noise robust algorithms for predicting nearly as well as the best discretized d-dimensional axis-parallel box (Maass & Warmuth, 1998; Auer, 1993) or as well as the best pruning of a decision tree <ref> (Helmbold & Schapire, 1997) </ref>. In these cases a multiplicative algorithm maintains one weight for each of the exponentially many basic concepts. However for the above examples, the multiplicative algorithms with the exponentially many weights can still be simulated efficiently.
Reference: <author> Herbster, M., & Warmuth, M. </author> <year> (1998). </year> <title> Tracking the best expert. </title> <journal> Machine Learning. </journal> <note> (Appears in this special issue.) 27 Jumarie, </note> <author> G. </author> <year> (1990). </year> <title> Relative information. </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In addition to generalizing the work of (Littlestone & Warmuth, 1994) to arbitrary size disjunctions we were able to optimize the constant in the leading term of the mistake bound of Winnow and develop a randomized version of the algorithm. In <ref> (Herbster & Warmuth, 1998) </ref> the work of (Littlestone & Warmuth, 1994) was generalized in a different direction. <p> Now the loss does not occur in "large" discrete units. Instead the loss in a trial my be arbitrarily small and thus more sophisticated methods are needed for recovering small weights quickly <ref> (Herbster & Warmuth, 1998) </ref> than simply lower bounding the weights. Why are disjunctions so important? Whenever a richer class is built by (small) unions of a large number of simple basic concepts, our methods can be applied.
Reference: <author> Kapur, J. N., & Kesavan, H. K. </author> <year> (1992). </year> <title> Entropy optimization principles with applications. </title> <publisher> Academic Press, Inc. </publisher>
Reference: <author> Kivinen, J., & Warmuth, M. K. </author> <year> (1997). </year> <title> Additive versus exponentiated gradient updates for linear prediction. </title> <journal> Information and Computation, </journal> <volume> 132 (1), </volume> <pages> 1-64. </pages>
Reference-contexts: The key feature of Winnow is that when learning disjunctions of constant size, the number of mistakes of the algorithm grows only logarithmically with the input dimension. For many other standard algorithms such as the Perceptron Algorithm (Rosenblatt, 1958), the number of mistakes can grow linearly in the dimension <ref> (Kivinen, Warmuth, & Auer, 1997) </ref>. <p> This algorithm does additive instead of multiplicative updates. The classical Perceptron Convergence Theorem gives a mistake bound for this algorithm (Duda & Hart, 1973; Haykin, 1994), but this bound is linear in the number of attributes <ref> (Kivinen et al., 1997) </ref> whereas the bounds for the Winnow-like algorithms are logarithmic in the number of attributes. The proof of the Perceptron Convergence Theorem can also be seen as an amortized analysis. <p> In the case of linear regression a framework was developed <ref> (Kivinen & Warmuth, 1997) </ref> for deriving updates from the potential function used in the amortized analysis. The same framework can be adapted to derive both the Perceptron algorithm and Winnow. The different potential functions for the algorithms lead to the additive and multiplicative algorithms, respectively. <p> analysis of Winnow (Littlestone, 1988, 1989, 1991) is the following generalization of relative entropy to arbitrary non-negative weight vectors: D (u; w) = i=1 w i u i + u i ln w i : 17 (This distance function was also used for the analysis of the Egu regression algorithm <ref> (Kivinen & Warmuth, 1997) </ref>, which shows that Winnow is related to the Egu algorithm.) By taking derivatives it is easy to see that the distance is minimal and equal to 0 if and only if w t = u t .
Reference: <author> Kivinen, J., Warmuth, M. K., & Auer, P. </author> <year> (1997). </year> <title> The perceptron algorithm vs. Winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. </title> <journal> Artificial Intelligence. </journal> <note> (To appear) Littlestone, </note> <author> N. </author> <year> (1988). </year> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 285-318. </pages>
Reference-contexts: The key feature of Winnow is that when learning disjunctions of constant size, the number of mistakes of the algorithm grows only logarithmically with the input dimension. For many other standard algorithms such as the Perceptron Algorithm (Rosenblatt, 1958), the number of mistakes can grow linearly in the dimension <ref> (Kivinen, Warmuth, & Auer, 1997) </ref>. <p> This algorithm does additive instead of multiplicative updates. The classical Perceptron Convergence Theorem gives a mistake bound for this algorithm (Duda & Hart, 1973; Haykin, 1994), but this bound is linear in the number of attributes <ref> (Kivinen et al., 1997) </ref> whereas the bounds for the Winnow-like algorithms are logarithmic in the number of attributes. The proof of the Perceptron Convergence Theorem can also be seen as an amortized analysis. <p> In the case of linear regression a framework was developed <ref> (Kivinen & Warmuth, 1997) </ref> for deriving updates from the potential function used in the amortized analysis. The same framework can be adapted to derive both the Perceptron algorithm and Winnow. The different potential functions for the algorithms lead to the additive and multiplicative algorithms, respectively. <p> analysis of Winnow (Littlestone, 1988, 1989, 1991) is the following generalization of relative entropy to arbitrary non-negative weight vectors: D (u; w) = i=1 w i u i + u i ln w i : 17 (This distance function was also used for the analysis of the Egu regression algorithm <ref> (Kivinen & Warmuth, 1997) </ref>, which shows that Winnow is related to the Egu algorithm.) By taking derivatives it is easy to see that the distance is minimal and equal to 0 if and only if w t = u t .
Reference: <author> Littlestone, N. </author> <year> (1989). </year> <title> Mistake bounds and logarithmic linear-threshold learning algorithms. </title> <type> Unpublished doctoral dissertation, Technical Report UCSC-CRL-89-11, </type> <institution> University of California Santa Cruz. </institution>
Reference-contexts: 1. Introduction One of the most significant successes of the Computational Learning Theory community has been Littlestone's formalization of an on-line model of learning and the development of his algorithm Winnow for learning disjunctions <ref> (Littlestone, 1989, 1988) </ref>. The key feature of Winnow is that when learning disjunctions of constant size, the number of mistakes of the algorithm grows only logarithmically with the input dimension.
Reference: <author> Littlestone, N. </author> <year> (1991). </year> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th annu. workshop on comput. learning theory (pp. </booktitle> <pages> 147-156). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In some sense Winnow compresses n weights to only n weights. At this point we don't have a combinatorial interpretation of our weights. Such an interpretation was only found for the single literal (expert) case (Cesa-Bianchi, Freund, Helmbold, & Warmuth, 1996). As Littlestone <ref> (Littlestone, 1991) </ref> we use an amortized analysis with an entropic potential function to obtain our worst-case loss bounds. <p> The algorithm We present algorithm Swin ("Shifting Winnow"), see Table 1, an extension of Littlestone's Winnow2 algorithm <ref> (Littlestone, 1991) </ref>. Our extension incorporates a randomization of the algorithm, and it guarantees a lower bound on the weights used by the algorithm. The algorithm maintains a vector of n weights for the n attributes.
Reference: <author> Littlestone, N., & Warmuth, M. K. </author> <year> (1994). </year> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108 (2), </volume> <pages> 212-261. </pages>
Reference-contexts: Our extension of Winnow2 simply adds a step to the original algorithm that resets a weight to fi=n whenever it drops below this boundary. Similar methods for lower bounding the weights were used in the algorithm Wml of <ref> (Littlestone & Warmuth, 1994) </ref> which was designed for predicting as well as the 5 best shifting single literal (which is called expert in (Cesa-Bianchi et al., 1997)). In addition to generalizing the work of (Littlestone & Warmuth, 1994) to arbitrary size disjunctions we were able to optimize the constant in the <p> Similar methods for lower bounding the weights were used in the algorithm Wml of <ref> (Littlestone & Warmuth, 1994) </ref> which was designed for predicting as well as the 5 best shifting single literal (which is called expert in (Cesa-Bianchi et al., 1997)). In addition to generalizing the work of (Littlestone & Warmuth, 1994) to arbitrary size disjunctions we were able to optimize the constant in the leading term of the mistake bound of Winnow and develop a randomized version of the algorithm. In (Herbster & Warmuth, 1998) the work of (Littlestone & Warmuth, 1994) was generalized in a different direction. <p> In addition to generalizing the work of <ref> (Littlestone & Warmuth, 1994) </ref> to arbitrary size disjunctions we were able to optimize the constant in the leading term of the mistake bound of Winnow and develop a randomized version of the algorithm. In (Herbster & Warmuth, 1998) the work of (Littlestone & Warmuth, 1994) was generalized in a different direction. The focus there is to predict as well as the best shifting expert, where "well" is measured in terms of other loss functions than the discrete loss (counting mistakes) which is the loss function used in this paper. <p> The updates of the weights are performed in two steps. The first step is the original Winnow update, and the second step guarantees that no weight is smaller than fi n for some parameter fi (a similar approach was taken in <ref> (Littlestone & Warmuth, 1994) </ref>). Observe that the weights are changed only if the probability of making a mistake was non-zero. For the deterministic algorithm this means that the weights are changed only if the algorithm made a mistake. Furthermore the i-th weight is modified only if x t;i = 1. <p> Remark. As an open problem it remains to show lower bounds that have the same form as the upper bounds of Theorem 7 with the square root term. Now we turn to the non-shifting case. For k = 1 there are already lower bounds known. Lemma 4 <ref> (Littlestone & Warmuth, 1994) </ref> For any deterministic learning algorithm L, any n 2, and any A 0, there is an example sequence S 2 S 0 (1; A; n) such that M (L; S) 2A + log 2 n: A slight modification of results in (Cesa-Bianchi et al., 1997) gives Lemma
Reference: <author> Maass, W., & Warmuth, M. K. </author> <year> (1998). </year> <title> Efficient learning with virtual threshold gates. </title> <journal> Information and Computation. </journal> <note> (To appear) Rosenblatt, </note> <author> F. </author> <year> (1958). </year> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psych. Rev., </journal> <volume> 65, </volume> <pages> 386-407. </pages> <note> (Reprinted in Neurocomputing (MIT Press, 1988).) </note> <author> Vovk, V. </author> <year> (1990). </year> <title> Aggregating strategies. </title> <booktitle> In Proc. 3rd annu. workshop on comput. learning theory (pp. </booktitle> <pages> 371-383). </pages> <publisher> Morgan Kaufmann. </publisher>
References-found: 14

