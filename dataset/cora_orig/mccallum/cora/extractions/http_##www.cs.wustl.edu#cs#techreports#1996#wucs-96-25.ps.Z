URL: http://www.cs.wustl.edu/cs/techreports/1996/wucs-96-25.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Keyword: Saied Hosseini-Khayat  Key words: Generalized caching, optimal replacement, replacement algorithm.  
Address: in St. Louis  
Affiliation: Washington University  
Abstract: New Results on Generalized Caching fl Abstract. We report a number of new results in generalized caching. This problem arises in modern computer networks in which data objects of various sizes are transmitted frequently. First it is shown that its optiaml solution is NP-complete. Then we explore two methods of obtaining nearly optimal answers based on the dynamic programming algorithm that we provided in [5]. These methods enable a trade-off between optimality and speed. It is also shown that LFD (the longest forward distance algorithm which is the optimal policy in the classical case), is no longer optimal but is competitive. We also prove that LRU remains competitive in the generalized case. This is an extension of a famous result by Sleator and Tarjan [12] on LRU. Finally, it is confirmed in the general case that prefetch does not reduce the total cost if "cost" reflects only the number of bytes transmitted. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. A. Aho, P. J. Denning, J. D. Ullman, </author> <title> "Principles of Optimal Page Replacement," </title> <journal> Journal of the ACM, </journal> <volume> Vol. 18, No. 1, </volume> <pages> 80-93, </pages> <month> January </month> <year> 1971. </year>
Reference: [2] <author> L. A. Belady, </author> <title> "A Study of Replacement Algorithms for a Virtual-Storage Computer, </title> <journal> IBM System Journal, </journal> <volume> 5 (2) 78-101, </volume> <year> 1966. </year>
Reference-contexts: As in the classical case, the study of this version is important from a theoretical standpoint because its optimal solution sets an upper bound on the performance of all other solutions. The classical page replacement problem was optimally and efficiently solved by Belady <ref> [2] </ref>. In this paper after introducing our notations in Section 2 and defining the generalized problem in Section 3, we show in Section 4 that Belady's theorem does not apply to the generalized problem. Then in Section 5 we prove that this is NP-complete. <p> We focus on off-line algorithms in this paper. 4. LFD is not Optimal A special case of the generalized caching problem (gencache), known as the paging or page replacement problem, has a well-known optimal solution. If all items have unit size and cost, then it has been shown <ref> [2, 7] </ref> that replacing, among all items currently in cache, the item whose next request comes furthest in future is the optimal policy. We call this the longest forward distance (LFD) algorithm or policy. Unfortunately, when either the sizes or costs are nonuniform this policy is not optimal. <p> Also notice that the latter state sequence is the result of LFD on for the new problem and hence it is optimal <ref> [2] </ref>.
Reference: [3] <author> Allan Borodin, Nathan Linial, Michael E. </author> <title> Saks "An Optimal On-line Algorithm for Metrical Task System," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> Vol. 39, No. 4, </volume> <month> October </month> <year> 1992. </year>
Reference-contexts: In Section 4 we showed that LFD is not optimal, now we question whether it is a good heuristic. Competitive analysis, pioneered by Sleator and Tarjan [12], is a well-known way of comparing heuristic solutions. In particular it has been used for on-line algorithms (see for example <ref> [3, 6, 10] </ref>) and studies whether the cost of an algorithm lies within a constant factor of the optimal cost for every sequence. The constant factor, if any, is then used as a measure for comparing algorithms.
Reference: [4] <author> Michael R. Garey, David S. Johnson, </author> <title> "Computers and Intractability: A Guide to the Theory of NP-Completeness," W.H. </title> <publisher> Freeman and Company, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: The following result suggests that we should not expect to find an efficient algorithm for gencache. 5. Intractability We showed that LFD does not optimally solves (gencache). It turns out that gencache is NP-complete. We prove this by reducing from the 0-1 Knapsack Problem which is NP-complete <ref> [4, Problem MP9] </ref>. Specifically, we show that if an efficient (i.e. polynomial time) solution for gencache exists, it can be used to solve the knapsack problem efficiently. gencache was defined in Section 3. The statement of the knapsack problem is as follows. <p> Finally, some special cases of the problem may have efficient solutions, in which case it is better to develop solution for the special case. We mention that knapsack lends itself to a dynamic programming solution <ref> [4, page96] </ref>. In technical report [5], we presented an optimal solution dynamic programming for gen-cache. 7 6. Approximation The optimal algorithm in [5] gives an insight on developing approximate methods that are useful when finding the optimal is too costly. Here we investigate two methods. 6.1.
Reference: [5] <author> Saied Hosseini-Khayat, Jerome R. Cox, Jr., </author> <title> "Optimal Solution of Off-line and Online Generalized Caching," </title> <type> Technical Report WUCS-96-20, </type> <institution> Department of Computer Science, Washington University. </institution>
Reference-contexts: Finally, some special cases of the problem may have efficient solutions, in which case it is better to develop solution for the special case. We mention that knapsack lends itself to a dynamic programming solution [4, page96]. In technical report <ref> [5] </ref>, we presented an optimal solution dynamic programming for gen-cache. 7 6. Approximation The optimal algorithm in [5] gives an insight on developing approximate methods that are useful when finding the optimal is too costly. Here we investigate two methods. 6.1. <p> We mention that knapsack lends itself to a dynamic programming solution [4, page96]. In technical report <ref> [5] </ref>, we presented an optimal solution dynamic programming for gen-cache. 7 6. Approximation The optimal algorithm in [5] gives an insight on developing approximate methods that are useful when finding the optimal is too costly. Here we investigate two methods. 6.1. Breadth Limiting Method Recall from the previous section that the catch in the optimal algorithm is the potentially huge breadth of its DAG.
Reference: [6] <author> Mark S. Manasse, Lyle A. McGeoch, Daniel D. Sleator, </author> <title> "Competitive Algorithms for Server Problems," </title> <journal> Journal of Algorithms, </journal> <volume> No. 11, </volume> <pages> pp. 208-230, </pages> <year> 1990. </year>
Reference-contexts: In Section 4 we showed that LFD is not optimal, now we question whether it is a good heuristic. Competitive analysis, pioneered by Sleator and Tarjan [12], is a well-known way of comparing heuristic solutions. In particular it has been used for on-line algorithms (see for example <ref> [3, 6, 10] </ref>) and studies whether the cost of an algorithm lies within a constant factor of the optimal cost for every sequence. The constant factor, if any, is then used as a measure for comparing algorithms.
Reference: [7] <author> R. L. Mattson, J. Gecsei, D. R. Slutz, I. L. Traiger, </author> <title> "Evaluation Techniques for Storage Hierarchies," </title> <journal> IBM System Journal, </journal> <volume> 5 (2), </volume> <pages> 78-117, </pages> <year> 1970. </year> <month> 17 </month>
Reference-contexts: We focus on off-line algorithms in this paper. 4. LFD is not Optimal A special case of the generalized caching problem (gencache), known as the paging or page replacement problem, has a well-known optimal solution. If all items have unit size and cost, then it has been shown <ref> [2, 7] </ref> that replacing, among all items currently in cache, the item whose next request comes furthest in future is the optimal policy. We call this the longest forward distance (LFD) algorithm or policy. Unfortunately, when either the sizes or costs are nonuniform this policy is not optimal.
Reference: [8] <institution> World Wide Web home page of the National Laboratory for Applied Network Research: </institution> <note> http://www.nlanr.net/Cache. </note>
Reference-contexts: As an example, the hard disk now performs as a client-side cache holding requested WWW documents for possible future use. Caching proxy servers form the next level of hierarchy as caches of WWW documents requested by groups of users. Study of regional and national network caches is also underway <ref> [8] </ref>. These two levels will cache frequently transmitted documents on regional and national scales to reduce traffic load of the network . The ongoing information revolution is creating new services such as video-on-demand, distributed image archives and on-line libraries, that will also benefit from caching.
Reference: [9] <author> Christos H. Papadimitriou, S. Ramanathan, P. Venkat Rangan, </author> <title> "Information Caching for Delivery of Personalized Video Programs over Home Entertainment Channels," </title> <booktitle> Proceedings of The IEEE International Conference on Multimedia Computing and Systems, </booktitle> <address> Boston, MA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The ongoing information revolution is creating new services such as video-on-demand, distributed image archives and on-line libraries, that will also benefit from caching. For example, in the area of video-on-demand, caching of video programs in neighborhood servers is discussed in <ref> [9, 11] </ref>. Also the use of cache in a distributed image database is discussed in [15]. In many new applications the same scenario occurs again and again: variable-sized data objects as a whole are requested, transmitted and cached. Also the performance cost of cache misses are not all identical.
Reference: [10] <author> Prabhakar Raghavan, Marc Snir, </author> <title> "Memory Versus Randomization in On-line Algorithms," Automata, </title> <booktitle> Languages and Programming : Proceedings of the 16th International Colloquium, </booktitle> <address> Stresa Italy, </address> <month> July </month> <year> 1989, </year> <pages> pp. 687-703, </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In Section 4 we showed that LFD is not optimal, now we question whether it is a good heuristic. Competitive analysis, pioneered by Sleator and Tarjan [12], is a well-known way of comparing heuristic solutions. In particular it has been used for on-line algorithms (see for example <ref> [3, 6, 10] </ref>) and studies whether the cost of an algorithm lies within a constant factor of the optimal cost for every sequence. The constant factor, if any, is then used as a measure for comparing algorithms.
Reference: [11] <author> S. Ramanathan, P. Venkat Rangan, </author> <title> "Architectures for Personalized Multimedia," </title> <journal> IEEE Multimedia, </journal> <volume> Vol. 1, No. 1, </volume> <month> Spring </month> <year> 1994. </year>
Reference-contexts: The ongoing information revolution is creating new services such as video-on-demand, distributed image archives and on-line libraries, that will also benefit from caching. For example, in the area of video-on-demand, caching of video programs in neighborhood servers is discussed in <ref> [9, 11] </ref>. Also the use of cache in a distributed image database is discussed in [15]. In many new applications the same scenario occurs again and again: variable-sized data objects as a whole are requested, transmitted and cached. Also the performance cost of cache misses are not all identical.
Reference: [12] <author> D. D. Sleator, R. E. Tarjan, </author> <title> "Amortized Efficiency of List Update and Paging Rules," </title> <journal> Communications of the ACM Vol. </journal> <volume> 28, No. 2, </volume> <pages> pp. 202-208, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Therefore effective heuristics are needed. In Section 4 we showed that LFD is not optimal, now we question whether it is a good heuristic. Competitive analysis, pioneered by Sleator and Tarjan <ref> [12] </ref>, is a well-known way of comparing heuristic solutions. In particular it has been used for on-line algorithms (see for example [3, 6, 10]) and studies whether the cost of an algorithm lies within a constant factor of the optimal cost for every sequence. <p> However it implies that for all possible sequences its cost is no more than a constant multiple of the optimal. There are policies, e.g. LFU (Least Frequently Used), for which this is not true <ref> [12] </ref>. 8. LRU is Competitive LRU is a widely-used heuristic that performs well in memory paging. Sleator and Tarjan [12] showed that for uniform size and cost items, LRU is strongly competitive with a competitive factor of B, where B is the size of the cache. <p> There are policies, e.g. LFU (Least Frequently Used), for which this is not true <ref> [12] </ref>. 8. LRU is Competitive LRU is a widely-used heuristic that performs well in memory paging. Sleator and Tarjan [12] showed that for uniform size and cost items, LRU is strongly competitive with a competitive factor of B, where B is the size of the cache. The following theorem states that it is competitive in the generalized case.
Reference: [13] <author> Allan J. Smith, </author> <title> "Bibliography on Paging and Related Topics," </title> <journal> Operating Systems Review, </journal> <volume> vol. 12, </volume> <pages> 39-56, </pages> <month> Oct. </month> <year> 1978. </year>
Reference-contexts: Cached objects in these levels are uniform-size chunks of data, e.g. pages and cache words. The clever management of these caches has been the subject of extensive research in the past decades <ref> [13, 14] </ref>. The phenomenal growth of the Internet and emergence of distributed information systems, such as the World Wide Web, has necessitated the extension of the cache hierarchy fl Technical Report WUCS-96-25 y Applied Research Laboratory, Department of Computer Science, Washington University, Campus Box 1045, One Brookings Drive, St.
Reference: [14] <author> Allan J. Smith, </author> <title> "Second Bibliography for Cache Memories," </title> <journal> Computer Architecture News, </journal> <volume> Vol. 19, No. 4, </volume> <month> June </month> <year> 1991. </year>
Reference-contexts: Cached objects in these levels are uniform-size chunks of data, e.g. pages and cache words. The clever management of these caches has been the subject of extensive research in the past decades <ref> [13, 14] </ref>. The phenomenal growth of the Internet and emergence of distributed information systems, such as the World Wide Web, has necessitated the extension of the cache hierarchy fl Technical Report WUCS-96-25 y Applied Research Laboratory, Department of Computer Science, Washington University, Campus Box 1045, One Brookings Drive, St.
Reference: [15] <author> Thomas Stephenson, Harry Voorhees "IMACTS: </author> <title> An Interactive Multiterabyte Image Archive," </title> <booktitle> 14 th IEEE Symposium on Mass Storage Systems, </booktitle> <year> 1995. </year>
Reference-contexts: For example, in the area of video-on-demand, caching of video programs in neighborhood servers is discussed in [9, 11]. Also the use of cache in a distributed image database is discussed in <ref> [15] </ref>. In many new applications the same scenario occurs again and again: variable-sized data objects as a whole are requested, transmitted and cached. Also the performance cost of cache misses are not all identical.
References-found: 15

