URL: http://www.cs.technion.ac.il/~shaulm/papers/ijcai89-dido.ps
Refering-URL: http://www.cs.technion.ac.il/~shaulm/research.html
Root-URL: 
Title: Learning Novel Domains Through Curiosity and Conjecture Constraints: The domain is very large and the
Author: Paul D. Scott Shaul Markovitch 
Note: 1 Introduction  
Address: 2001,Commonwealth Blvd., Ann Arbor, Michigan 48105  
Affiliation: Center for Machine Intelligence  
Abstract: This paper describes DIDO, a system we have developed to carry out exploratory learning of unfamiliar domains without assistance from an external teacher. The program incorporates novel approaches to experience generation and representation generation. The experience generator uses a heuristic based on Shannon's uncertainty function to find informative examples. The representation generator makes conjectures on the basis of small amounts of evidence and retracts them if they prove to be wrong or useless. A number of experiments are described which demonstrate that the system can distribute its learning resources to steadily acquire a good representation of the whole of a domain, and that the system can readily acquire both disjunctive and This paper gives an account of DIDO, a learning system we have developed to carry out exploratory learning of unfamiliar domains * . We define the exploratory learning problem as follows: Situation: An intelligent agent is placed in a novel domain comprised of a large number of entities. The agent has two types of interaction with the domain. It is equipped with a finite set of motor operations which can be applied to entities in the domain. It is also equipped with a finite set of perceptual operations which enable it to perceive the current state of any entities present in its locality. The agent has no prior knowledge of the effect of any of its motor operations on any entity. Task: The agent knows that it may eventually have to solve problems in the domain but does not have any prior knowledge of what those problems might be. The agent must try to discover what effect its possible actions will have in any circumstances. More specifically, its task is to build a representation of the domain which will enable it to predict the outcomes of each of its motor operations in any situation. This is the basic knowledge the agent would need to engage in problem solving. * The work reported in this paper was supported by NSF Grant# MCS-8203956. This problem is significantly different from those addressed by other machine learning programs. The absence of prior knowledge means that deductive learning methods cannot be applied. Any solution must be based on inductive inference. The most widely studied type of inductive inference problem is that of learning concepts from sets of classified examples (eg.Winston, 1975; Michalski & Dietterich, 1983; Quinlan, 1983, 1986). The problem stated above differs from this type of problem in two respects: there is no external agent to supply classifications of examples, and there is no predefined classification scheme that the agent is trying to discover. A number of learning programs have been written which do not require such a predefined classification scheme (eg. Michalski & Stepp, 1983; Fisher & Langley, 1986). The task performed by such systems, which is commonly termed 'conceptual clustering', involves developing a classification scheme for a set of examples. Such programs attempt to construct a parsimonious taxonomy to cover the example set on the basis of similarity between examples. The learning problem considered here resembles conceptual clustering in that the learning system must develop its own classification scheme. On the other hand it differs significantly in that the basis for forming classes is not similarity between examples but rather similarity of their behavior when subject to the agent's motor operations. Thus the classification scheme developed is determined both by characteristics of the domain and by characteristics of the agent. In this sense the agent's task is to build an egocentric representation of its world. Learning involves two distinct but interrelated search processes (Shalin et al, 1987): a search for a good representation in the space of possible representations (Simon & Lea, 1974; Mitchell, 1977, 1979), and a search for informative examples in the space of possible experiences (Scott & Vogt 1983). The information obtained from the experiences is used to guide the search for a better representation, while the current state of the representation may be used to guide the search for informative experiences. conjunctive concepts even in the presence of noise.
Abstract-found: 1
Intro-found: 0
Reference: <author> Wilson,S.W., </author> <year> 1987, </year> <title> Classifier Systems and the Animat Problem, </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> pp 199-228. </pages>
Reference: <author> Winston,P.H. </author> , <title> 1975 , Learning Structural Descriptions from Examples , In The Psychology of Computer Vision ed P.H.Winston,McGraw-Hill </title>
References-found: 2

