URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1160/CS-TR-93-1160.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1160/
Root-URL: http://www.cs.wisc.edu
Title: TOWARDS PRACTICAL MULTIVERSION LOCKING TECHNIQUES FOR ON-LINE QUERY PROCESSING  
Author: by PAUL M. BOBER 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Date: 1993  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [Agra87] <author> Agrawal, D., A. Bernstein, P. Gupta and S. Sengupta, </author> <title> "Distributed Multiversion Optimistic Con-currency Control with Reduced Rollback," </title> <journal> Journal of Distributed Computing, Springer-Verlag, </journal> <volume> 2(1), </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: As a result, these algorithms are potentially well-suited for on-line query processing. In addition to MV2PL, which we have already mentioned, examples of such algorithms include multiversion optimistic algorithms <ref> [Robi82, Care83, Lai84, Agra87] </ref>, mul-tiversion timestamp ordering [Agra89], and the multiversion tree protocol [Silb82]. A compensation-based query processing technique has recently been proposed as an alternative to multiver-sion concurrency control for relational queries [Srin92].
Reference: [Agra89] <author> Agrawal, D., and S. Sengupta, </author> <title> "Modular Synchronization in Multiversion Databases: Version Control and Concurrency Control," </title> <booktitle> Proc. 1989 SIGMOD Conference, </booktitle> <year> 1989. </year>
Reference-contexts: In fact, Agrawal and Sengupta <ref> [Agra89] </ref> describe how this may be done in a modular fashion (i.e., separating con-currency control and version management) using any existing single-version conflict-based concurrency control algorithm. <p> As a result, these algorithms are potentially well-suited for on-line query processing. In addition to MV2PL, which we have already mentioned, examples of such algorithms include multiversion optimistic algorithms [Robi82, Care83, Lai84, Agra87], mul-tiversion timestamp ordering <ref> [Agra89] </ref>, and the multiversion tree protocol [Silb82]. A compensation-based query processing technique has recently been proposed as an alternative to multiver-sion concurrency control for relational queries [Srin92].
Reference: [Baye77] <author> Bayer, R., and Schkolnick, M., </author> <title> "Concurrency of Operations on B-trees," </title> <journal> Acta Informatica, </journal> <month> September </month> <year> 1977. </year>
Reference-contexts: While this approach supports index-only plans, is not compatible with the use of high performance non-2PL B+ tree concurrency control algorithms such as those proposed in <ref> [Baye77, Lehm81, Moha90] </ref>. Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include [East86, Ston87, Kolo89, Lome89, Lome90, Moha92].
Reference: [Baye80] <author> Bayer, et al., </author> <title> "Parallelism and Recovery in Database Systems," </title> <journal> ACM Trans. on Database Sys., </journal> <volume> 5(2), </volume> <month> June </month> <year> 1980. </year>
Reference-contexts: Furthermore, operations issued by read-only queries must update timestamp information that is physically associated with each object (possibly turning reads into writes). Several 2PL-based algorithms that retain at most two versions of data in order to reduce blocking due to read/write conflicts have also been proposed <ref> [Baye80, Stea81] </ref>. Again, however, these schemes are not ideally-suited for use with long-running read-only queries.
Reference: [Bern83] <author> Bernstein, P., and N. Goodman, </author> <title> "Multiversion Concurrency Control: Theory and Algorithms," </title> <journal> ACM Transactions on Database Systems," </journal> <volume> 8(4), </volume> <month> December </month> <year> 1983. </year>
Reference-contexts: A query is said to see strong consistency [Garc82] if it is serializable with respect to all transactions. 2 This form of consistency is characterized by an acyclic serialization graph, and is provided by algorithms that guarantee multiversion serializability <ref> [Bern83, Papa84, Hadz85] </ref>. Since the previous restriction on the commit ordering of update transactions is relaxed here, strong consistency may produce apparent anomalies in query results if users are somehow cognizant of the commit order of update transactions. The schedule and corresponding serialization graph in Figure 5.2 provide an example.
Reference: [Bern87] <author> Bernstein, P., V. Hadzilacos, and N. Goodman, </author> <title> "Concurrency Control and Recovery in Database Systems," </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1987. </year>
Reference: [Care82] <author> Carey, M. J., </author> <title> Modeling and Evaluation of Database Concurrency Control Algorithms, </title> <type> Ph.D. Thesis, </type> <institution> Comp. Sci. Dept., Univ. of California, Berkeley, </institution> <year> 1983. </year>
Reference: [Care86] <author> Carey, M., and W. Muhanna, </author> <title> "The Performance of Multiversion Concurrency Control Algorithms," </title> <journal> ACM Transactions on Computer Systems," </journal> <volume> 4(4), </volume> <month> November </month> <year> 1986. </year>
Reference: [Bobe92a] <author> Bober, P. and M. Carey, </author> <title> "On Mixing Queries and Transactions via Multiversion Locking," </title> <booktitle> Proc. of the Eighth IEEE Data Engineering Conf., </booktitle> <year> 1992. </year>
Reference-contexts: Moreover, because a query must read successively older versions (relative to the current database) as it ages, the number of version pool I/O operations that it must make to read a given page increases with time. As a result, queries may begin to thrash if they are sufficiently large <ref> [Bobe92a] </ref>. The on-page version caching refinement discussed in the next chapter was designed to alleviate these problems. 10 CHAPTER 3 EFFICIENT VERSION STORAGE MANAGEMENT 3.1.
Reference: [Bobe92b] <author> Bober, P. and M. Carey, </author> <title> "Multiversion Query Locking," </title> <booktitle> Proc. of the Eighteenth International Conference on Very Large Databases, </booktitle> <year> 1992. </year>
Reference: [Bobe92c] <author> Bober, P. and D. Dias, </author> <title> Storage Cost Tradeoffs for Multiversion Concurrency Control, </title> <type> Research Report RC 18367, </type> <institution> IBM T.J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Hence, the tradeoff of view sharing is that fewer versions are likely to be necessary beyond the commit of the transaction that overwrites them, but versions that are retained are likely to be retained for a longer period of time. <ref> [Bobe92c] </ref> explores this tradeoff further using an analytical storage cost model. 3.4. The Simulation Model In this section, we describe the model that we used to evaluate the performance of our record-level MV2PL design. The model was implemented as a collection of modules in the DeNet simulation language [Livn89].
Reference: [Chan82] <author> Chan, A., S. Fox, W. Lin, A. Nori, and Ries, D., </author> <title> "The Implementation of an Integrated Concurrency Control and Recovery Scheme," </title> <booktitle> Proc. 1982 ACM SIGMOD Conf., </booktitle> <year> 1982. </year>
Reference-contexts: This extension was also used in a system developed at Computer Corporation of America (CCA) in the same time frame <ref> [Chan82, Chan85] </ref>, and it has been incorporated in DEC's hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Unless otherwise stated, the term query in this thesis refers to a long-running read-only transaction (possibly containing many SQL statements), rather than a single SQL statement. 2 Rdb relational DBMS product as well [Ragh91]. <p> In the CCA prototype, current versions of data pages were stored as they would be in a single-version database, and prior versions of data were appended to a sequential log-like version pool <ref> [Chan82, Chan85] </ref>. This scheme supports the efficient creation of new versions as well as inexpensive garbage collection. Since accesses to the version pool are random, however, the scheme disrupts the inherent sequentiality of query access. <p> The version pool is organized as a circular buffer, hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 2 Actually, to reduce commit-time processing in the absence of a no-steal buffer management policy, the page is stamped with the creator's transaction id. A separately maintained list is then used to map from transaction ids to commit timestamps <ref> [Chan82] </ref>. 8 much like a write-ahead log in a traditional recovery manager [Gray79]. In fact, the version pool was designed to be used as a UNDO log for recovery, as well as a version storage structure for MV2PL. <p> Garbage Collection with On-Page Version Caching Prior versions are no longer necessary once they become inaccessible by any currently executing query. In the version pool, space is reclaimed sequentially when the oldest query finishes, allowing the reader-first pointer to move <ref> [Chan82] </ref>. Because of the nature of this sequential deallocation process, versions may become unnecessary before they can be garbage-collected. One resulting problem is that a very long-running query may hold up the reclamation of version pool space that is occupied by versions other than those that are in its view. <p> Chaining (CH) In the Chaining (CH) versioning selection scheme, each index leaf entry simply references the most recent version of a tuple; the remainder of the versions are chained behind the current version in reverse chronological order, as in the CCA scheme <ref> [Chan82] </ref>. The organization of data pages (with on-page caching) and the version pool was discussed in the previous section. As described earlier, each version of a tuple has a create timestamp (CTS) which is the commit timestamp of the transaction which wrote the version. <p> for any of the following reasons: (1) If the current versions of objects are clustered together, accessing an older version of an object will degrade sequential scan performance that would otherwise be available using prefetch. (2) If the versions of an object are chained in reverse chronological order (as in <ref> [Chan82] </ref>), accessing an older version will require additional I/O operations. 63 (3) Using older versions to construct a query's view will require that additional prior versions be retained for the query (thus delaying their garbage collection and increasing storage cost). <p> A version is unnecessary if, for every active query, there is a more recent committed version of the object that was created by an update transaction that is not in the query's AFTER set. The first alternative is a sequential garbage collection scheme, as proposed in <ref> [Chan82] </ref>, where prior versions are stored in a sequential log-like version pool; before an object is updated, it is appended to the version pool. In this approach, there are three pointers that mark regions in the version pool. <p> The version manager divides the database into two segments: the main segment, containing the current ver sions of pages, and the version pool, containing prior page versions. This organization is similar to the one described in <ref> [Chan82] </ref>, except that we arrange the version pool as a heap of disk tracks rather than as a circular (log-like) buffer. <p> memory-resident index is hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 9 It should be noted that the decision to use a heap-based version pool rather than a circular buffer is orthogonal to the basic MVQL and MV2PL algorithms; we could have chosen to use the circular buffer organization instead. 81 another departure from the scheme in <ref> [Chan82] </ref>, where prior versions of a page were located by chaining back from the current version. We chose the directory approach in order to present the performance differences of the algorithms relatively conservatively.
Reference: [Chan85] <author> Chan, A., and R. Gray, </author> <title> "Implementing Distributed Read-Only Transactions," </title> <journal> IEEE Trans. on Software Eng., </journal> <volume> SE-11(2), </volume> <month> Feb </month> <year> 1985. </year>
Reference-contexts: This extension was also used in a system developed at Computer Corporation of America (CCA) in the same time frame <ref> [Chan82, Chan85] </ref>, and it has been incorporated in DEC's hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Unless otherwise stated, the term query in this thesis refers to a long-running read-only transaction (possibly containing many SQL statements), rather than a single SQL statement. 2 Rdb relational DBMS product as well [Ragh91]. <p> In the CCA prototype, current versions of data pages were stored as they would be in a single-version database, and prior versions of data were appended to a sequential log-like version pool <ref> [Chan82, Chan85] </ref>. This scheme supports the efficient creation of new versions as well as inexpensive garbage collection. Since accesses to the version pool are random, however, the scheme disrupts the inherent sequentiality of query access. <p> To the best of our knowledge, almost all previously proposed multiversion concurrency control algorithms provide only strict consistency for queries. The only exception that we are aware of is distributed MV2PL, where weak consistency arises among queries at different sites due to inconsistent global state information <ref> [Chan85] </ref>. In contrast, MVQL deliberately introduces weaker forms of consistency among queries by allowing them to read newer versions of data for performance reasons.
Reference: [DeWi90] <author> DeWitt, D., et al., </author> <title> "The Gamma Database Machine Project," </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: The model was implemented as a collection of modules in the DeNet simulation language [Livn89]. The simulator was derived from a single-site configuration of a simulator constructed for the Gamma parallel database system <ref> [DeWi90] </ref> and used in studies of replication strategies [Hsai90] and complex query processing [Schn90]. We used this simulator as a starting point primarily to facilitate subsequent research on MV2PL extended for use in a parallel DBMS environment. <p> With this configuration, typical disk access times were on the order of 15 milliseconds and the system was I/O-bound for all of our experiments. The database is composed of 4 files, each containing 5000 Wisconsin benchmark-sized records <ref> [DeWi90] </ref>. Each record contains 208 bytes of data and 19 bytes of overhead, for a total of 227 bytes. For MV2PL, records contain an additional 8 bytes to store a transaction identifier and a version chain pointer. <p> The database is composed of 4 files, each containing 25,000 Wisconsin benchmark-sized records. Each record contains 208 bytes of data and 19 bytes of overhead, for a total of 227 bytes (as is the case in the Gamma system <ref> [DeWi90] </ref>). With this record size, 36 records fit on a page. Each file contains both a clustered and an unclustered B+ tree index, each with a node fanout of 450.
Reference: [DeWi92] <author> DeWitt, D., and J. Gray, </author> <title> "Parallel Database Systems: The Future of High Performance Database Processing," </title> <journal> Communications of the ACM, </journal> <volume> 35(6), </volume> <month> June </month> <year> 1992. </year>
Reference-contexts: Distributed MVQL In recent years, shared-nothing parallel database systems have begun to replace centralized mainframe database systems <ref> [DeWi92] </ref>. In this section we discuss a distributed version of MVQL that is applicable to parallel DBMSs. We do not consider at this time more general distributed database systems containing replicated data.
Reference: [DuBo82] <author> DuBourdieu, D., </author> <title> "Implementation of Distributed Transactions," </title> <booktitle> Proc. 6th Berkeley Workshop on Distributed Data Management and Computer Networks, </booktitle> <year> 1982. </year>
Reference-contexts: To solve the query/update data contention problem while providing consistent answers to queries, a multiver-sion extension to two-phase locking was proposed and implemented in a system developed at Prime Computer Corporation in the early 1980s <ref> [DuBo82] </ref>.
Reference: [East86] <author> Easton, M., </author> <title> "Key-Sequence Data Sets on Indelible Storage," </title> <journal> IBM Journal of Research and Development, </journal> <month> May </month> <year> 1986. </year>
Reference-contexts: Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include <ref> [East86, Ston87, Kolo89, Lome89, Lome90, Moha92] </ref>.
Reference: [Eswa76] <author> Eswaran, K., J. Gray, R. Lorie, I. Traiger, </author> <title> "The Notions of Consistency and Predicate Locks in a Database System," </title> <journal> CACM 19(11), </journal> <year> 1976. </year> <month> 99 </month>
Reference-contexts: INTRODUCTION 1.1. Motivation Due to the adoption of relational database technology and the increasing ability of database systems to efficiently execute ad-hoc queries, query processing is becoming an increasingly important function of on-line transaction processing (OLTP) systems. The concurrency control algorithm found in most commercial database systems, two-phase locking (2PL) <ref> [Eswa76] </ref>, however, does not efficiently support on-line query processing. This is because 2PL causes queries 1 to lock large regions of data for long periods of time, thus causing update transactions to suffer long delays due to data contention with queries.
Reference: [Fuji90] <institution> M2266S/H Intelligent Disk Drive Technical Handbook, </institution> <note> Publication FS810125-01 rev. </note> <editor> B, </editor> <publisher> Fujitsu America, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: The disk controller can prefetch up to 4 pages following a requested page; 10 the controller contains a 256K byte cache for storing prefetched pages. This model was patterned after the Fujitsu M2266 disk drive <ref> [Fuji90] </ref>, which is as an example of a current generation disk drive.
Reference: [Garc82] <author> Garcia-Molina, H., and G. Wiederhold, </author> <title> "Read-Only Transactions in a Distributed Database," </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 7(2), </volume> <month> June </month> <year> 1982. </year>
Reference-contexts: Forms of Query Consistency In the introduction of this chapter, we argued that performance advantages may be gained by relaxing the level of consistency provided to queries. In this section, we review four forms of consistency which all guarantee that queries see a transaction-consistent database: strict consistency, strong consistency <ref> [Garc82] </ref>, weak consistency [Garc82], and update consistency. An underlying requirement that we impose is that the execution of update transactions alone must be serializable; this is guaranteed in MV2PL and MVQL by having update transactions run using dynamic 2PL. <p> In this section, we review four forms of consistency which all guarantee that queries see a transaction-consistent database: strict consistency, strong consistency <ref> [Garc82] </ref>, weak consistency [Garc82], and update consistency. An underlying requirement that we impose is that the execution of update transactions alone must be serializable; this is guaranteed in MV2PL and MVQL by having update transactions run using dynamic 2PL. <p> The next form of consistency relaxes strict consistency by eliminating the requirement that the serial order of update transactions be consistent with their commit order. A query is said to see strong consistency <ref> [Garc82] </ref> if it is serializable with respect to all transactions. 2 This form of consistency is characterized by an acyclic serialization graph, and is provided by algorithms that guarantee multiversion serializability [Bern83, Papa84, Hadz85]. <p> The schedule differs from the one in the strict consistency example in that Q 1 reads Z 1 instead of Z 0 . This reduces the cost of hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 2 This definition of strong consistency is slightly different than the one presented in <ref> [Garc82] </ref>. In their definition, a strong consistency query is required to serialize only with the update transactions and other strong consistency queries. <p> A query is said to see weak consistency if it is serializable with respect to update transactions, but possibly not with respect to other queries. This form of consistency, which was first introduced in <ref> [Garc82] </ref> for use in replicated databases, still ensures that queries see transaction-consistent data. However, it permits cycles in the serialization graph that contain multiple queries plus one or more update transactions (multiple-query cycles).
Reference: [Gray76] <author> Gray, J., et al., </author> <title> "Granularity of Locks and Degrees of Consistency in a Shared Data Base," in Modeling in Data Base Systems, </title> <publisher> North Holland Publishing, </publisher> <year> 1976. </year>
Reference-contexts: Recall that a transaction-consistent database is assumed to satisfy a set of static integrity constraints, and each update transaction is assumed to take the database from one transaction-consistent state to another (possibly through one or more inconsistent intermediate states) <ref> [Gray76] </ref>.
Reference: [Gray79] <author> Gray, J., </author> <title> "Notes on Database Operating Systems," in Operating Systems: An Advanced Course, </title> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: As a result, users are often forced to make compromises in either the consistency or timeliness of queried data. One such compromise is to run queries without obtaining locks or using only short-term locks, allowing the queries to see transaction-inconsistent answers <ref> [Gray79] </ref>. These approaches are commonly referred to as GO processing and cursor stability locking [Pira90], respectively. A different compromise is to maintain two separate databases, one for OLTP transactions and another for ad-hoc queries [Pira90]. <p> A separately maintained list is then used to map from transaction ids to commit timestamps [Chan82]. 8 much like a write-ahead log in a traditional recovery manager <ref> [Gray79] </ref>. In fact, the version pool was designed to be used as a UNDO log for recovery, as well as a version storage structure for MV2PL. <p> In order to make MV2PL useful for transaction processing, we present several refinements in this chapter. First, to remove the force requirement, we separate recovery from versioning by using the traditional write-ahead logging (WAL) approach to crash recovery <ref> [Gray79, Moha89] </ref>. Second, to reduce storage overhead and increase potential concurrency, we make the (straightforward) conversion from page-level to record-level versioning and locking. These two refinements are used in DEC's Rdb/VMS system as well [Ragh91]. <p> For example, under cursor-stability locking, queries may release locks before acquiring new ones (violating the two-phase rule), and under GO processing [Pira90], queries do not obtain any locks at all (except latches to guarantee page consistency). In the terminology of <ref> [Gray79] </ref>, the former provides degree 2 consistency, and the latter, degree 1. Other examples include epsilonserializability algorithms, which accept inconsistent schedules as long as they are within some number of inversions from a serializable schedule [Wu92]. <p> We choose a more efficient solution, however, which is to piggyback the AFTER set insertions of a given update transaction on the messages exchanged during the transaction's commit processing. We assume that the two-phase commit (2PC) protocol <ref> [Gray79] </ref> (or some other suitable commit protocol) is used to guarantee the atomic commitment of update transactions. 7 Specifically, the vote messages of 2PC are used to inform the coordinator of any local query AFTER set insertions involving the update transaction being committed, and the vote-reply messages are used to propagate
Reference: [Gray81] <author> Gray, J., et al., </author> <title> "The Recovery Manager of the System R Database Manager," </title> <journal> ACM Computing Surveys, </journal> <volume> 13(2), </volume> <month> June </month> <year> 1981. </year>
Reference-contexts: This rise is caused by a decrease in the system resource demands by update transactions due to increased lock waiting; recall that the probability of lock conflict is proportional to the square of the transaction size <ref> [Gray81, Tay85] </ref>. So that we may concentrate on the most important results, we do not show the update transaction throughput here. On the other 89 hand, MVQL query throughput drops initially, and then rises. The rise is also caused by reduced resource competition from the update transactions.
Reference: [Haas90] <author> Haas, L., et al, </author> <title> "Starburst Mid-Flight: As the Dust Clears," </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: We further assume that the optional compression of TID fields described at the end of Section 3.1 is carried out whenever an index page overflows. The last component of the system model, the buffer manager, encapsulates the details of an LRU buffer manager with "LOVE/HATE" hints (a la Starburst <ref> [Haas90] </ref>). The number of page frames in the buffer pool is specified as NumBuffers, and the frames are shared among data, index, and version pool pages.
Reference: [Hadz85] <author> Hadzilacos, T., and C. Papadimitriou, </author> <title> "Algorithmic Aspects of Multiversion Concurrency Control," </title> <booktitle> Proceedings of the Fourth ACM SIGACT-SIGMOD Symposium on Principles of Database Systems, </booktitle> <year> 1985. </year>
Reference-contexts: A query is said to see strong consistency [Garc82] if it is serializable with respect to all transactions. 2 This form of consistency is characterized by an acyclic serialization graph, and is provided by algorithms that guarantee multiversion serializability <ref> [Bern83, Papa84, Hadz85] </ref>. Since the previous restriction on the commit ordering of update transactions is relaxed here, strong consistency may produce apparent anomalies in query results if users are somehow cognizant of the commit order of update transactions. The schedule and corresponding serialization graph in Figure 5.2 provide an example.
Reference: [Hsia90] <author> Hsiao, H., </author> <title> Performance and Availability in Database Machines with Replicated Data, </title> <type> Ph.D. Thesis, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> Sept. </month> <year> 1990. </year>
Reference: [Josh93] <author> Joshi, Ashok, </author> <type> Personal Communication. </type>
Reference-contexts: X X Version Pool Main Segment (current database) X last update-first reader-first hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 In contrast, DEC's Rdb system stores old versions of data on "shadow" pages which must be first read and then written whenever an update occurs <ref> [Josh93] </ref>. 9 Garbage collection in the version pool is done when the oldest query finishes, thus allowing the reader-first pointer to move. <p> One approach, taken in DEC's Rdb system, is to treat index nodes like data records at the storage level, including having MV2PL applied to them <ref> [Josh93] </ref>. While this approach supports index-only plans, is not compatible with the use of high performance non-2PL B+ tree concurrency control algorithms such as those proposed in [Baye77, Lehm81, Moha90].
Reference: [Kolo89] <author> Kolovson, C., and M. Stonebraker, </author> <title> "Indexing Techniques for Multiversion Database," </title> <booktitle> Proc. of the Fifth IEEE International Conference on Data Engineering, </booktitle> <year> 1989. </year>
Reference-contexts: Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include <ref> [East86, Ston87, Kolo89, Lome89, Lome90, Moha92] </ref>.
Reference: [Lai84] <author> Lai, M., K. Wilkinson, </author> <title> "Distributed Transaction Management in Jasmin," </title> <booktitle> Proc. of 10th International Conference on Very Large Database Systems, </booktitle> <year> 1984. </year>
Reference-contexts: As a result, these algorithms are potentially well-suited for on-line query processing. In addition to MV2PL, which we have already mentioned, examples of such algorithms include multiversion optimistic algorithms <ref> [Robi82, Care83, Lai84, Agra87] </ref>, mul-tiversion timestamp ordering [Agra89], and the multiversion tree protocol [Silb82]. A compensation-based query processing technique has recently been proposed as an alternative to multiver-sion concurrency control for relational queries [Srin92].
Reference: [Livn89] <author> Livny, M., </author> <note> DeNet User's Guide, Version 1.5, </note> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <year> 1989. </year>
Reference-contexts: The Simulation Model In this section, we describe the model that we used to evaluate the performance of our record-level MV2PL design. The model was implemented as a collection of modules in the DeNet simulation language <ref> [Livn89] </ref>. The simulator was derived from a single-site configuration of a simulator constructed for the Gamma parallel database system [DeWi90] and used in studies of replication strategies [Hsai90] and complex query processing [Schn90]. <p> As in the models used in Chapters 3 and 4, the model used in this chapter has two major components, the application model and the system model. Each of these has several subcomponents that will be described in this section. The model was implemented in the DeNet simulation language <ref> [Livn89] </ref>. 5.4.1. The Application Model The first component of the application model is the database, which is modeled as a collection of files. Each file, in turn, is modeled as a collection of records. One clustered and one unclustered index exist on each file.
Reference: [Lome89] <author> Lomet, D., and B. Salzberg, </author> <title> "Access Methods for Multiversion Data," </title> <booktitle> Proc. 1989 ACM SIGMOD Conf., </booktitle> <year> 1989. </year>
Reference-contexts: Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include <ref> [East86, Ston87, Kolo89, Lome89, Lome90, Moha92] </ref>.
Reference: [Lome90] <author> Lomet, D., and B. Salzberg, </author> <title> "The Performance of a Multiversion Access Method," </title> <booktitle> Proceedings ACM SIGMOD Conference, </booktitle> <year> 1990. </year>
Reference-contexts: Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include <ref> [East86, Ston87, Kolo89, Lome89, Lome90, Moha92] </ref>.
Reference: [Lehm81] <author> Lehman, P., and Yao, S., </author> <title> "Efficient Locking for Concurrent Operations on B-trees," </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6(4), </volume> <month> December </month> <year> 1981. </year>
Reference-contexts: While this approach supports index-only plans, is not compatible with the use of high performance non-2PL B+ tree concurrency control algorithms such as those proposed in <ref> [Baye77, Lehm81, Moha90] </ref>. Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include [East86, Ston87, Kolo89, Lome89, Lome90, Moha92].
Reference: [Moha89] <author> Mohan, C., et al., </author> <title> ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging, </title> <institution> DBTI Research Report RJ7341, IBM Almaden Research Center, </institution> <year> 1989. </year>
Reference-contexts: In order to make MV2PL useful for transaction processing, we present several refinements in this chapter. First, to remove the force requirement, we separate recovery from versioning by using the traditional write-ahead logging (WAL) approach to crash recovery <ref> [Gray79, Moha89] </ref>. Second, to reduce storage overhead and increase potential concurrency, we make the (straightforward) conversion from page-level to record-level versioning and locking. These two refinements are used in DEC's Rdb/VMS system as well [Ragh91].
Reference: [Moha90a] <author> Mohan, C., et al., </author> <title> "Single Table Access Using Multiple Indexes: Optimization, Execution, and Con-currency Control Techniques," </title> <booktitle> Proceedings International Conference on Extending Database Technology, </booktitle> <year> 1990. </year>
Reference: [Moha90b] <author> Mohan, C., "ARIES/KVL: </author> <title> A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-tree Indexes," </title> <booktitle> Proceedings of the Sixteenth International Conferences on Very Large Data Bases, </booktitle> <year> 1990. </year>
Reference: [Moha92] <author> Mohan, C., H. Pirahesh, and R. Lorie, </author> <title> "Efficient and Flexible Methods for Transient Versioning of Records to Avoid Locking by Read-Only Transactions," </title> <booktitle> Proc. 1992 ACM SIGMOD Conf., </booktitle> <year> 1992. </year>
Reference-contexts: While the query is waiting, subsequently arriving update transactions would not be allowed to discard their prior versions before commit. 2 Similar ideas, developed independently, are presented in [Wu91] and <ref> [Moha92] </ref>. 16 same startup timestamp, t b , or it may decide to generate a new logical view and run with a startup timestamp of t d . <p> Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include <ref> [East86, Ston87, Kolo89, Lome89, Lome90, Moha92] </ref>. <p> A number of other multiversion indexing approaches have been proposed in the literature; examples include [East86, Ston87, Kolo89, Lome89, Lome90, Moha92]. With the exception of <ref> [Moha92] </ref>, however, all of these hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Using an index-only plan, a query computing the average salary of a group of employees, for example, does not have to retrieve the employee tuples if an index on employee salary exists; instead it can compute the average by simply scanning the leaves of <p> Primary Index Version Selection (PI) The Primary Index (PI) version selection scheme is a modification of DP that stores the version selection table together with the tuple's primary index leaf page entry (instead of on a data page). It is similar to the scheme presented in <ref> [Moha92] </ref>, which is the only previously published indexing scheme for multiversion locking that we are aware of. 3 Figure 4.3 illustrates the PI scheme by adapting the running example. Note that a versioned tuple has only one entry in the primary index because primary index keys cannot be changed. <p> However, this optimization can be used only if the current version of a given tuple is always stored in a fixed location (determined when the tuple is created). Furthermore, read-only queries cannot use this optimiza-hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 The overall versioning scheme in <ref> [Moha92] </ref> differs somewhat in that it bounds the number of versions of each tuple by essentially restricting the number of query startup timestamps in use simultaneously. <p> Both locking and versioning are both sup ported at the page level. We chose page-level versioning to simplify the implementation of the simulator and to reduce the length of simulation runs. The basic MV2PL and MVQL algorithms are compatible with record-level versioning; schemes for record-level versioning are discussed in <ref> [Bobe92, Moha92] </ref>. The version manager divides the database into two segments: the main segment, containing the current ver sions of pages, and the version pool, containing prior page versions. <p> Directions for Future Work This thesis has opened up a number of interesting avenues for future work. To begin with, several possibilities remain in the area of storage management for versions. One possibility is to consider differential versioning <ref> [Moha92] </ref>, where prior tuple versions are represented by storing only that portion of each version that differs from the next most recent version. When combined with on-page caching, differential versioning would clearly reduce the rate of overflow to the version pool, and could thus further improve query performance.
Reference: [Papa84] <author> Papadimitriou, C., and P. Kanellakis, </author> <title> "On Concurrency Control by Multiple Versions," </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9(1), </volume> <month> March </month> <year> 1984. </year>
Reference-contexts: A query is said to see strong consistency [Garc82] if it is serializable with respect to all transactions. 2 This form of consistency is characterized by an acyclic serialization graph, and is provided by algorithms that guarantee multiversion serializability <ref> [Bern83, Papa84, Hadz85] </ref>. Since the previous restriction on the commit ordering of update transactions is relaxed here, strong consistency may produce apparent anomalies in query results if users are somehow cognizant of the commit order of update transactions. The schedule and corresponding serialization graph in Figure 5.2 provide an example.
Reference: [Papa86] <author> Papadimitriou, C., </author> <title> The Theory of Database Concurrency Control, </title> <publisher> Computer Science Press, </publisher> <address> Rockville Maryland, </address> <year> 1986. </year> <month> 100 </month>
Reference: [Pira90] <author> Pirahesh, H., et al, </author> <title> "Parallelism in Relational Database Systems: </title> <booktitle> Architectural Issues and Design Approaches," IEEE 2nd International Symposium on Databases in Parallel and Distributed Systems, </booktitle> <address> Dublin, Ireland, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: One such compromise is to run queries without obtaining locks or using only short-term locks, allowing the queries to see transaction-inconsistent answers [Gray79]. These approaches are commonly referred to as GO processing and cursor stability locking <ref> [Pira90] </ref>, respectively. A different compromise is to maintain two separate databases, one for OLTP transactions and another for ad-hoc queries [Pira90]. In this latter approach, the OLTP database is periodically extracted and copied to the ad-hoc query system. <p> These approaches are commonly referred to as GO processing and cursor stability locking <ref> [Pira90] </ref>, respectively. A different compromise is to maintain two separate databases, one for OLTP transactions and another for ad-hoc queries [Pira90]. In this latter approach, the OLTP database is periodically extracted and copied to the ad-hoc query system. <p> This form of ver-sioning, where old copies of data are retained temporarily for concurrency control purposes (as opposed to long-term retention for historical queries), is sometimes referred to as transient versioning <ref> [Pira90] </ref>. 1.2. Thesis Preview In this thesis we propose and investigate techniques for the efficient implementation of multiversion locking to support on-line query execution in high performance transaction processing systems. The thesis is subdivided into three major parts, each of which is now previewed briefly. 1.2.1. <p> This is in contrast to approaches that avoid versioning altogether, instead allowing queries to see transaction-inconsistent data. For example, under cursor-stability locking, queries may release locks before acquiring new ones (violating the two-phase rule), and under GO processing <ref> [Pira90] </ref>, queries do not obtain any locks at all (except latches to guarantee page consistency). In the terminology of [Gray79], the former provides degree 2 consistency, and the latter, degree 1.
Reference: [Ragh91] <author> Raghavan, A., and Rengarajan, </author> <title> T.K., "Database Availability for Transaction Processing," </title> <note> Digital Technical Journal 3(1), </note> <month> Winter </month> <year> 1991. </year>
Reference-contexts: (CCA) in the same time frame [Chan82, Chan85], and it has been incorporated in DEC's hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 Unless otherwise stated, the term query in this thesis refers to a long-running read-only transaction (possibly containing many SQL statements), rather than a single SQL statement. 2 Rdb relational DBMS product as well <ref> [Ragh91] </ref>. In multiversion two-phase locking (MV2PL), a timestamp mechanism is used in conjunction with the temporary retention of prior versions of data so that a read-only query can serialize before all update transactions that were active during any portion of its lifetime. <p> Second, to reduce storage overhead and increase potential concurrency, we make the (straightforward) conversion from page-level to record-level versioning and locking. These two refinements are used in DEC's Rdb/VMS system as well <ref> [Ragh91] </ref>. Third, we use on-page caches for prior versions in order to reduce I/O activity to the version pool. Last, we introduce the technique of view sharing, which is used to reduce the number of snapshots that must be maintained by the system.
Reference: [Reed83] <author> Reed, D., </author> <title> "Implementing Atomic Actions on Decentralized Data," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 1(1), </volume> <month> February </month> <year> 1983. </year>
Reference: [Robi82] <author> Robinson, J., </author> <title> Design of Concurrency Controls for Transaction Processing Systems, </title> <type> Ph.D. Thesis, </type> <institution> Comp. Sci. </institution> <type> Tech. Rep. </type> <institution> No. CMU-CS-82-114, </institution> <year> 1982. </year>
Reference-contexts: As a result, these algorithms are potentially well-suited for on-line query processing. In addition to MV2PL, which we have already mentioned, examples of such algorithms include multiversion optimistic algorithms <ref> [Robi82, Care83, Lai84, Agra87] </ref>, mul-tiversion timestamp ordering [Agra89], and the multiversion tree protocol [Silb82]. A compensation-based query processing technique has recently been proposed as an alternative to multiver-sion concurrency control for relational queries [Srin92].
Reference: [Sarg76] <author> Sargent, R., </author> <title> "Statistical Analysis of Simulation Output Data," </title> <booktitle> Procedings of the Fourth Annual Symposium on the Simulation of Computer Systems, </booktitle> <year> 1976. </year>
Reference-contexts: Our primary performance metrics are updater transaction throughput and query throughput. In addition, we are also interested in the storage cost necessary to retain prior versions. To ensure the statistical validity of our results, we verified that the 90% confidence intervals for response times (computed using batch means <ref> [Sarg76] </ref>) were sufficiently tight. The size of these confidence intervals were within approximately 1% of the mean for update transaction response time and within approximately 5% of the mean for query response time. <p> Addi tional metrics are used in the analysis of the experimental results. To ensure the statistical validity of our results, we verified that the 90% confidence intervals for response times (computed using batch means <ref> [Sarg76] </ref>) were sufficiently tight. The size of these confidence intervals were within approximately 1% of the mean for update transaction response time and within approximately 5% of the mean for query response time in almost all cases.
Reference: [Schn90] <author> Schneider, D., </author> <title> Complex Query Processing in Multiprocessor Database Machines, </title> <type> Ph.D. Thesis, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: The model was implemented as a collection of modules in the DeNet simulation language [Livn89]. The simulator was derived from a single-site configuration of a simulator constructed for the Gamma parallel database system [DeWi90] and used in studies of replication strategies [Hsai90] and complex query processing <ref> [Schn90] </ref>. We used this simulator as a starting point primarily to facilitate subsequent research on MV2PL extended for use in a parallel DBMS environment. <p> We used this simulator as a starting point primarily to facilitate subsequent research on MV2PL extended for use in a parallel DBMS environment. In addition, the basic Gamma simulator was validated against the actual Gamma implementation <ref> [Schn90, Hsai90] </ref>, so we knew that we were at least starting from something that modeled reality fairly accurately. In order to explain the model, we will break it down into two major components, the application model and the system model.
Reference: [Silb82] <author> Silberschatz, A., </author> <title> "A Multi-Version Concurrency Control Scheme with No Rollbacks," </title> <booktitle> ACM-SIGACT-SIGOPS Symposium on Principles of Distributed Computing, </booktitle> <month> August, </month> <year> 1982. </year>
Reference-contexts: As a result, these algorithms are potentially well-suited for on-line query processing. In addition to MV2PL, which we have already mentioned, examples of such algorithms include multiversion optimistic algorithms [Robi82, Care83, Lai84, Agra87], mul-tiversion timestamp ordering [Agra89], and the multiversion tree protocol <ref> [Silb82] </ref>. A compensation-based query processing technique has recently been proposed as an alternative to multiver-sion concurrency control for relational queries [Srin92]. It can be viewed as a form of semantic versioning since a query essentially creates its own consistent version of the relevant underlying data while executing [Srin92].
Reference: [Stea81] <author> Stearns, R., and D. Rosenkrantz, </author> <title> "Distributed Database Concurrency Control Using Before-Values," </title> <booktitle> Proc. of the 1981 ACM SIGMOD Conf., </booktitle> <year> 1981. </year>
Reference-contexts: Furthermore, operations issued by read-only queries must update timestamp information that is physically associated with each object (possibly turning reads into writes). Several 2PL-based algorithms that retain at most two versions of data in order to reduce blocking due to read/write conflicts have also been proposed <ref> [Baye80, Stea81] </ref>. Again, however, these schemes are not ideally-suited for use with long-running read-only queries.
Reference: [Ston87] <author> Stonebraker, M., </author> <title> "The Design of the Postgres Storage System," </title> <booktitle> Proc. Thirteenth International Conference on Very Large Database Systems, </booktitle> <year> 1987. </year>
Reference-contexts: Because (non-2PL) B+ tree concurrency control algorithms are widely viewed as being important to achieving acceptable performance, we do not consider the Rdb approach further. A number of other multiversion indexing approaches have been proposed in the literature; examples include <ref> [East86, Ston87, Kolo89, Lome89, Lome90, Moha92] </ref>.
Reference: [Tay85] <author> Tay, Y., N. Goodman, and R. Suri, </author> <title> "Locking Performance in Centralized Databases," </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 10(4), </volume> <month> December </month> <year> 1985. </year>
Reference-contexts: This rise is caused by a decrease in the system resource demands by update transactions due to increased lock waiting; recall that the probability of lock conflict is proportional to the square of the transaction size <ref> [Gray81, Tay85] </ref>. So that we may concentrate on the most important results, we do not show the update transaction throughput here. On the other 89 hand, MVQL query throughput drops initially, and then rises. The rise is also caused by reduced resource competition from the update transactions.
Reference: [Teor72] <author> Teorey, T., and T Pinkerton, </author> <title> "A Comparative Analysis of Disk Scheduling Policies," </title> <journal> Communications of the ACM, </journal> <volume> 15(3), </volume> <month> March </month> <year> 1972. </year>
Reference-contexts: a select or select-update operator TerminateCPU Cost to terminate an operator iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiic c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c Table 3.3: System Model Parameters elevator algorithm <ref> [Teor72] </ref>. The total service time is computed as the sum of the seek time, latency, settle time, and transfer time. The seek time of a disk request is computed by multiplying the parameter DiskSeekFactor by the square root of the number of tracks to seek [Bitt88]. <p> The disk manager module is designed to model the behavior of a disk controller and driver. The controller schedules disk requests according to the elevator algorithm <ref> [Teor72] </ref>. The total service time is computed as the sum of the seek time, latency, settle time, and transfer time. The seek time of a disk request is computed by multiplying the parameter DiskSeekFactor by the square root of the number of tracks to seek [Bitt88].

References-found: 50

