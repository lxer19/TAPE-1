URL: ftp://ftp.cs.uchicago.edu/pub/publications/tech-reports/TR-94-18.ps
Refering-URL: http://cs-www.uchicago.edu/publications/tech-reports/
Root-URL: 
Email: panni@cs.uchicago.edu  ms@research.att.com  
Title: Fault tolerant circuits and probabilistically checkable proofs  
Author: Anna Gal Mario Szegedy 
Keyword: Topics Computational complexity, Boolean functions, fault tolerance.  
Address: 1100 E. 58th Street Chicago, IL 60637  600 Mountain Avenue Murray Hill NJ 07974  
Affiliation: The University of Chicago Department of Computer Science  AT&T Bell Laboratories  
Abstract: We introduce a new model of fault tolerance for Boolean circuits. We consider synchronized circuits and we allow an adversary to choose a small constant fraction of the gates at each level of the circuit to be faulty. We require that even in the presence of such faults the circuit compute a "loose version" of the given function. We show that every symmetric function has a small (size O(n), depth O(log n)) fault tolerant circuit in this model. We also show a perhaps unexpected relation between our model and probabilistically checkable proofs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arora and S. Safra, </author> <title> "Probabilistic checking of proofs," </title> <booktitle> In Proc. of "33-rd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1992, </year> <pages> pp. 2-13. 10 </pages>
Reference-contexts: It may seem that introducing the loose computation of Boolean functions is a serious relaxation of the problem. In Section 2 we argue that this is not the case. There is a connection between our model and recently discovered constructions for proof encodings <ref> [1] </ref>, [5] (also see [7] for a survey). <p> In Section 5 we show that if circuits computing certain Boolean functions can be turned into fault tolerant circuits with only a polynomial increase in size and keeping the depth within a constant factor, then N P = P CP (log n; log n) <ref> [1] </ref> follows. The existence of such fault tolerant circuits is verified by Theorem 9. However, combining the two theorems we do not get a simpler proof to the notoriously hard characterization of N P in [1]: our construction uses an even harder result stating that N P = P CP (log <p> depth within a constant factor, then N P = P CP (log n; log n) <ref> [1] </ref> follows. The existence of such fault tolerant circuits is verified by Theorem 9. However, combining the two theorems we do not get a simpler proof to the notoriously hard characterization of N P in [1]: our construction uses an even harder result stating that N P = P CP (log n; 1) [5]. 2 The model In the model introduced by von Neumann the gates of a Boolean circuit fail (produce an incorrect value) independently with a probability bounded by a constant. <p> This characterization made it possible to show for the first time that to approximate the largest clique size of any graph within a constant factor is NP hard. In <ref> [1] </ref> it is shown that N P = P CP (log n; log n). <p> If x 62 L then for every oracle y the probability over all r's that M y (x; r) = 0 is at least 3/4. The result of Arora and Safra <ref> [1] </ref> was improved by Arora et al. [5] to show that N P = P CP (log n; 1). Both proofs rely on relatively difficult techniques from classical algebra, coding theory and combinatorics. <p> Both proofs rely on relatively difficult techniques from classical algebra, coding theory and combinatorics. In what follows, we give a theorem about fault tolerant circuits in our model that imply the result in <ref> [1] </ref>. As appealing as it may sound, we do not get a simpler proof to the notoriously hard characterization of N P by Arora and Safra. Our construction uses the even harder result of [5].
Reference: [2] <author> M. Ajtai, M. Ben-Or, </author> <title> "A theorem on probabilistic constant depth computations," </title> <booktitle> In Proc. of "16-th ACM Symposium on Theory of Computing", </booktitle> <year> 1984, </year> <pages> pp. 471-474. </pages>
Reference-contexts: At the first sight it may appear that computational devices that loosely compute a function f can be far weaker than those that are able to get the value of f everywhere. For instance it is well known <ref> [2] </ref> that there is an AC 0 circuit that loosely computes the majority function, whereas majority itself cannot be computed in AC 0 . One may speculate similarly that every function in N P might be loosely computed in P .
Reference: [3] <author> M. Ajtai, J. Komlos, E. Szemeredi, </author> <title> "An O(n log n) sorting network," </title> <booktitle> In Proc. of "15-th ACM Symposium on Theory of Computing", </booktitle> <year> 1983, </year> <pages> pp. 1-9. </pages>
Reference-contexts: However, the constructions we obtain in this paper work even if faults may occur at the input level. 3 Halvers Our construction for symmetric functions is based on the *-halvers of Ajtai, Komlos and Szemeredi <ref> [3] </ref>. An *-halver is a bounded depth comparator network with the property that for any set of the l smallest (largest) inputs, where l n=2, at most *l elements will be among the last (first) n=2 outputs. <p> In other words, an *-halver is a halver (a network that separates the n=2 largest and the n=2 smallest inputs into two disjoint sets) that can misplace at most an * fraction of the elements. Constant depth linear size *-halvers where constructed in <ref> [3] </ref>. More efficient *-halvers (with smaller constants) based on units called k-comparators were proven to exist in [4], but no explicit construction has been given. A k-comparator is a unit that sorts its k inputs. All our constructions work using either *-halver.
Reference: [4] <author> M. Ajtai, J. Komlos, E. Szemeredi, "Halvers and expanders," </author> <booktitle> In Proc. of "33-rd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1992, </year> <pages> pp. 686-692. </pages>
Reference-contexts: Constant depth linear size *-halvers where constructed in [3]. More efficient *-halvers (with smaller constants) based on units called k-comparators were proven to exist in <ref> [4] </ref>, but no explicit construction has been given. A k-comparator is a unit that sorts its k inputs. All our constructions work using either *-halver. If the more efficient *-halvers are used, we assume that each k-comparator is realized by depth k 2-comparator networks. <p> All our constructions work using either *-halver. If the more efficient *-halvers are used, we assume that each k-comparator is realized by depth k 2-comparator networks. We note that the depth of the realization of such *-halvers by 2-comparator networks will be 2k, since the *-halvers of <ref> [4] </ref> are depth 2 k-comparator networks. In what follows by the depth of an *-halver we always mean the depth of the realization by 2-comparator networks. For 0 1 inputs *-halvers can be realized by monotone Boolean circuits. Each comparator will be realized by an AND OR gate pair.
Reference: [5] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, M. Szegedy, </author> <title> "Proof verification and hardness of approximation problems," </title> <booktitle> In Proc. of "33-rd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1992, </year> <pages> pp. 14-23. </pages>
Reference-contexts: It may seem that introducing the loose computation of Boolean functions is a serious relaxation of the problem. In Section 2 we argue that this is not the case. There is a connection between our model and recently discovered constructions for proof encodings [1], <ref> [5] </ref> (also see [7] for a survey). <p> However, combining the two theorems we do not get a simpler proof to the notoriously hard characterization of N P in [1]: our construction uses an even harder result stating that N P = P CP (log n; 1) <ref> [5] </ref>. 2 The model In the model introduced by von Neumann the gates of a Boolean circuit fail (produce an incorrect value) independently with a probability bounded by a constant. <p> If x 62 L then for every oracle y the probability over all r's that M y (x; r) = 0 is at least 3/4. The result of Arora and Safra [1] was improved by Arora et al. <ref> [5] </ref> to show that N P = P CP (log n; 1). Both proofs rely on relatively difficult techniques from classical algebra, coding theory and combinatorics. In what follows, we give a theorem about fault tolerant circuits in our model that imply the result in [1]. <p> As appealing as it may sound, we do not get a simpler proof to the notoriously hard characterization of N P by Arora and Safra. Our construction uses the even harder result of <ref> [5] </ref>. <p> Moreover D (C 0 ) = O (log S (C 0 )) = O (log S (C)). Recall that D (C); S (C) denote the depth and size of a circuit C. Sketch of the proof: The proof connects the results of Arora et al. <ref> [5] </ref> with theorem 7 in a simple manner. Let C 1 be the subset of f0; 1g n for which C evaluates to 1 and C 0 be the set for which C evaluates to 0. In [5] an algorithm is described for turning a circuit C into a family F <p> Sketch of the proof: The proof connects the results of Arora et al. <ref> [5] </ref> with theorem 7 in a simple manner. Let C 1 be the subset of f0; 1g n for which C evaluates to 1 and C 0 be the set for which C evaluates to 0. In [5] an algorithm is described for turning a circuit C into a family F = fC i g i2I of constant size circuits with input (G (x); Y ), where G (x) is an appropriate encoding of input x to C and Y is an advise string (both have length polynomial <p> There is an * &gt; 1=2 such that for every x 2 C 0 and for every Y we have that Prob i2I (C i (G (x); Y ) = 0) * : A modification by Lund and Spielmann [13] of the construction in <ref> [5] </ref> ensures that for every x 2 C 1 the corresponding Y in condition 1 is unique. More precisely condition 1 can be replaced by: 1'.
Reference: [6] <author> S. Assaf, E. Upfal, </author> <title> "Fault tolerant sorting network", </title> <booktitle> In Proc. of "31-st IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1990, </year> <pages> pp. 275-284. </pages>
Reference-contexts: Proof: The building blocks of our construction are triplets of *-halvers with a majority preserving property. A similar component with this property was introduced by Assaf and Upfal in <ref> [6] </ref> for building fault tolerant sorting networks in the case of random faults.
Reference: [7] <author> L. Babai, </author> <title> "Transparent proofs and limits to approximation," </title> <institution> University of Chicago Technical Report CS93-15, </institution> <year> 1993. </year>
Reference-contexts: It may seem that introducing the loose computation of Boolean functions is a serious relaxation of the problem. In Section 2 we argue that this is not the case. There is a connection between our model and recently discovered constructions for proof encodings [1], [5] (also see <ref> [7] </ref> for a survey). In Section 5 we show that if circuits computing certain Boolean functions can be turned into fault tolerant circuits with only a polynomial increase in size and keeping the depth within a constant factor, then N P = P CP (log n; log n) [1] follows.
Reference: [8] <author> R. L. Dobrushin and S. I. Ortyukov, </author> <title> "Lower bound for the redundancy of self-correcting arrangements of unreliable functional elements," </title> <journal> Prob. Inf. Trans. </journal> <volume> 13, </volume> <year> 1977, </year> <pages> pp. 59-65. </pages>
Reference-contexts: These results hold if the probability of a gate being faulty is bounded by some constant &lt; 1=2. The logarithmic redundancy is necessary for some functions <ref> [8] </ref>, [10], [18]. Thus, as long as the faults occur randomly and independently, we can build circuits with optimal redundancy that work correctly with high probability, even if a constant fraction of the gates is faulty. The constructions above do not work if the faults are not random.
Reference: [9] <author> R. L. Dobrushin and S. I. Ortyukov, </author> <title> "Upper bound for the redundancy of self-correcting arrangements of unreliable functional elements," </title> <journal> Prob. Inf. Trans. </journal> <volume> 13, </volume> <year> 1977, </year> <pages> pp. 203-218. </pages>
Reference-contexts: The assumption is that the gates of the circuit may fail with probability bounded by some small constant, and the failures occur independently. The circuit should produce the correct result with high probability on any input. In this model it is known [15], <ref> [9] </ref>, [16] that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the function without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. <p> The results of [15], <ref> [9] </ref>, [16] give a transformation that takes a circuit C into another circuit C 0 such that: 1. The transformation takes polynomial time in the size of C. 2.
Reference: [10] <author> P. Gacs and A. Gal, </author> <title> "Lower Bounds for the Complexity of Reliable Boolean Circuits with Noisy Gates," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> Vol. 40, No. 2, </volume> <year> 1994, </year> <pages> pp. 579-583. </pages>
Reference-contexts: These results hold if the probability of a gate being faulty is bounded by some constant &lt; 1=2. The logarithmic redundancy is necessary for some functions [8], <ref> [10] </ref>, [18]. Thus, as long as the faults occur randomly and independently, we can build circuits with optimal redundancy that work correctly with high probability, even if a constant fraction of the gates is faulty. The constructions above do not work if the faults are not random.
Reference: [11] <author> G. I. Kirienko, </author> <title> "On self-correcting schemes from functional elements," Probl. </title> <journal> Kibern. </journal> <volume> 12, </volume> <year> 1964, </year> <pages> pp. 29-37. </pages>
Reference-contexts: Reliable circuits with small redundancy were obtained but they could tolerate only a negligible (exponentially small) fraction of the gates being faulty <ref> [11] </ref>, [12], [20].
Reference: [12] <author> G. I. Kirienko, </author> <title> "Synthesis of self-correcting schemes from functional elements for the case of growing number of faults in the scheme," </title> <journal> Diskret. Anal. </journal> <volume> 16, </volume> <year> 1970, </year> <pages> pp. 38-43. </pages>
Reference-contexts: Reliable circuits with small redundancy were obtained but they could tolerate only a negligible (exponentially small) fraction of the gates being faulty [11], <ref> [12] </ref>, [20].
Reference: [13] <author> C. Lund, D. </author> <title> Spielmann, </title> <type> Personal communication. </type>
Reference-contexts: There is an * &gt; 1=2 such that for every x 2 C 0 and for every Y we have that Prob i2I (C i (G (x); Y ) = 0) * : A modification by Lund and Spielmann <ref> [13] </ref> of the construction in [5] ensures that for every x 2 C 1 the corresponding Y in condition 1 is unique. More precisely condition 1 can be replaced by: 1'.
Reference: [14] <author> D. E. Muller, </author> <title> "Complexity in electronic switching circuits," </title> <journal> IRE Trans. Electr. Comput. </journal> <volume> 5, </volume> <year> 1956, </year> <pages> pp. 15-19. </pages>
Reference-contexts: Moreover these constructions have exponential size, thus they give small redundancy only for functions that require exponential size circuits even without faults. (Note that almost all Boolean functions require exponential size circuits [19], <ref> [14] </ref>, but there is still no explicit function known to require superlinear size circuits.) To our knowledge, there are no previous results achieving small redundancy tolerating a constant fraction of gates being faulty in the case when the faults are not random. For a survey of related results see [17].
Reference: [15] <author> J. von Neumann, </author> <title> "Probabilistic logics and the synthesis of reliable organisms from unreliable components," In Automata Studies, </title> <editor> C. E. Shannon and J. McCarthy Eds., </editor> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1956, </year> <pages> pp. 329-378. </pages>
Reference-contexts: The assumption is that the gates of the circuit may fail with probability bounded by some small constant, and the failures occur independently. The circuit should produce the correct result with high probability on any input. In this model it is known <ref> [15] </ref>, [9], [16] that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the function without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. <p> The results of <ref> [15] </ref>, [9], [16] give a transformation that takes a circuit C into another circuit C 0 such that: 1. The transformation takes polynomial time in the size of C. 2.
Reference: [16] <author> N. Pippenger, </author> <title> "On networks of noisy gates," </title> <booktitle> In Proc. of "26-th IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1985, </year> <pages> pp. 30-36. </pages>
Reference-contexts: The assumption is that the gates of the circuit may fail with probability bounded by some small constant, and the failures occur independently. The circuit should produce the correct result with high probability on any input. In this model it is known [15], [9], <ref> [16] </ref> that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the function without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. <p> The circuit should produce the correct result with high probability on any input. In this model it is known [15], [9], <ref> [16] </ref> that any function can be reliably computed by L log L size circuits, where L is the size needed to compute the function without faults. Pippenger [16] proved that almost all functions can be computed with only constant redundancy. By redundancy we mean the fraction of the size needed for computation with faults and the size needed to compute the function without faults. <p> The results of [15], [9], <ref> [16] </ref> give a transformation that takes a circuit C into another circuit C 0 such that: 1. The transformation takes polynomial time in the size of C. 2. The size of C 0 is O (S (C) log S (C)), where S (C) denotes the size of cicuit C. 3.
Reference: [17] <author> N. Pippenger, </author> <title> Developments in "The Synthesis of Reliable Organisms from Unreliable Components", </title> <booktitle> In Proc. of "Symposia in Pure Mathematics", </booktitle> <volume> Vol. 50, </volume> <year> 1990, </year> <pages> pp. 311-324. </pages>
Reference-contexts: For a survey of related results see <ref> [17] </ref>. We propose a new model of fault tolerance for Boolean circuits. We consider synchronized (leveled) circuits and let the adversary choose a certain fraction of the gates at each level to be faulty.
Reference: [18] <author> R. Reischuk, B. Schmeltz, </author> <title> "Reliable Computation with Noisy Circuits and Decision Trees A General n log n Lower Bound," </title> <booktitle> In Proc. of "32-nd IEEE Symposium on the Foundations of Computer Science", </booktitle> <year> 1991, </year> <pages> pp. 602-611. 11 </pages>
Reference-contexts: These results hold if the probability of a gate being faulty is bounded by some constant &lt; 1=2. The logarithmic redundancy is necessary for some functions [8], [10], <ref> [18] </ref>. Thus, as long as the faults occur randomly and independently, we can build circuits with optimal redundancy that work correctly with high probability, even if a constant fraction of the gates is faulty. The constructions above do not work if the faults are not random.
Reference: [19] <author> C. E. Shannon, </author> <title> "The synthesis of two-terminal switching circuits," </title> <journal> Bell Syst. Techn. J. </journal> <volume> 28, </volume> <year> 1949, </year> <pages> pp. 59-98. </pages>
Reference-contexts: Moreover these constructions have exponential size, thus they give small redundancy only for functions that require exponential size circuits even without faults. (Note that almost all Boolean functions require exponential size circuits <ref> [19] </ref>, [14], but there is still no explicit function known to require superlinear size circuits.) To our knowledge, there are no previous results achieving small redundancy tolerating a constant fraction of gates being faulty in the case when the faults are not random.
Reference: [20] <author> D. Uhlig, </author> <title> "On the synthesis of self-correcting schemes from functional elements with a small number of reliable elements," </title> <journal> Math. Notes. Acad. Sci. </journal> <volume> USSR 15, </volume> <year> 1974, </year> <pages> pp. 558-562. </pages>
Reference-contexts: Reliable circuits with small redundancy were obtained but they could tolerate only a negligible (exponentially small) fraction of the gates being faulty [11], [12], <ref> [20] </ref>.
Reference: [21] <author> I. Wegener, </author> <title> The Complexity of Boolean Functions, </title> <address> Wiley-Teubner, </address> <year> 1987. </year> <month> 12 </month>
Reference-contexts: This bound is within a constant factor of the complexity of arbitrary symmetric functions (that depend on all n inputs) in the fault free case <ref> [21] </ref>. It may seem that introducing the loose computation of Boolean functions is a serious relaxation of the problem. In Section 2 we argue that this is not the case.
References-found: 21

