URL: ftp://ftp.cogsci.indiana.edu/pub/wang.higher_order.ps
Refering-URL: http://www.cogsci.indiana.edu/farg/peiwang/papers.html
Root-URL: 
Email: pwang@cogsci.indiana.edu  
Title: Confidence as Higher Order Uncertainty proposed for handling higher order uncertainty, including the Bayesian approach,
Author: Pei Wang 
Address: 510 North Fess Street, Bloomington, IN 47408  
Affiliation: Indiana University  
Note: Center for Research on Concepts and Cognition,  Several approaches have been  and is processed accordingly.  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Anderson. </author> <title> A cognitive theory of judgment and decision. </title> <editor> In B. Brehmer, H. Jungermann, P. Lourens, and G. Sevon, editors, </editor> <booktitle> New Directions in Research on Decision Making, </booktitle> <pages> pages 63-108. </pages> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference-contexts: Because NARS is always open to new evidence, and new evidence may conflict with current belief, f can be anywhere in <ref> [0, 1] </ref> in the infinite future, no matter what its current value is. So no frequency is stable in the absolute sense.
Reference: [2] <author> P. Bonissone. </author> <title> Summarizing and propagating uncertain information with triangular norms. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 1 </volume> <pages> 71-101, </pages> <year> 1987. </year>
Reference: [3] <author> P. Cheeseman. </author> <title> In defense of probability. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1002-1009, </pages> <year> 1985. </year>
Reference: [4] <author> D. Dubois and H. Prade. </author> <title> Updating with belief functions, ordinal condi tional functions and possibility measures. </title> <editor> In P. Bonissone, M. Henrion, L. Kanal, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 311-329. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference: [5] <author> W. Edwards. </author> <title> Conservatism in human information processing. </title> <editor> In B. Kleinmuntz, editor, </editor> <booktitle> Formal Representation of Human Judgment, </booktitle> <pages> pages 17-52. </pages> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1968. </year>
Reference: [6] <author> H. Einhorn and R. Hogarth. </author> <title> Confidence in judgment: persistence of illusion of validity. </title> <journal> Psychological Review, </journal> <volume> 35 </volume> <pages> 395-416, </pages> <year> 1978. </year>
Reference: [7] <author> B. Fischhoff, P. Solvic, and S. Lichtenstein. </author> <title> Knowing with certainty: the appropriateness of extreme confidence. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 3 </volume> <pages> 552-564, </pages> <year> 1977. </year>
Reference: [8] <author> R. Fung and C. Chong. </author> <title> Metaprobability and Dempster-Shafer in ev idential reasoning. </title> <editor> In L. Kanal and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 295-302. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference: [9] <author> H. Gaifman. </author> <title> A theory of higher order probabilities. </title> <editor> In J. Halpern, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 275-292. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1986. </year>
Reference: [10] <author> B. Grosof. </author> <title> An inequality paradigm for probabilistic knowledge. </title> <editor> In L. Kanal and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 259-275. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference: [11] <author> H. Kyburg. </author> <title> Bayesian and non-Bayesian evidential updating. </title> <journal> Artificial Intelligence, </journal> <volume> 31 </volume> <pages> 271-293, </pages> <year> 1987. </year>
Reference: [12] <author> H. Kyburg. </author> <title> Higher order probabilities. </title> <editor> In L. Kanal, T. Levitt, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 15-22. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1989. </year>
Reference: [13] <author> G. Paa. </author> <title> Second order probabilities for uncertain and conflicting evi dence. </title> <editor> In P. Bonissone, M. Henrion, L. Kanal, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 447-456. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference: [14] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kauf mann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference: [15] <author> L. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1954. </year>
Reference: [16] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1976. </year>
Reference: [17] <author> G. Shafer. </author> <title> Perspectives on the theory and practice of belief functions. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 323-362, </pages> <year> 1990. </year>
Reference: [18] <author> D. Spiegelhalter. </author> <title> A statistical view of uncertainty in expert systems. </title> <editor> In W. Gale, editor, </editor> <booktitle> Artificial Intelligence and Statistics, </booktitle> <pages> pages 17-56. </pages> <publisher> Addison Wesley, </publisher> <address> Reading, </address> <year> 1986. </year>
Reference: [19] <author> P. Wang. </author> <title> Belief revision in probability theory. </title> <booktitle> In Proceed ings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 519-526. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1993. </year> <note> Available via WWW at http : ==www:cogsci:indiana:edu=f arg=pwang papers:html. 13 </note>
Reference-contexts: What is wrong about this approach, as argued in <ref> [19] </ref>, is the assumption that all re-evaluation of BEL (E), caused by new knowledge c, can be put into the form BEL (Ejc), that is, by conditionalization on c. <p> Especially, they make the system only open to certain types of new knowledge, therefore inconsistent with the definition of NARS. Generally speaking, as argued in <ref> [19] </ref>, the higher order uncertainty discussed above cannot be derived from a first order probability distribution, because it is about the background knowledge of the distribution, with is not totally accessible from the distribution function itself. Therefore, we do need a measurement which is specially for this type of uncertainty.
Reference: [20] <author> P. Wang. </author> <title> From inheritance relation to non-axiomatic logic. </title> <type> Techni cal Report 84, </type> <institution> Center for Research on Concepts and Cognition, Indi-ana University, Bloomington, Indiana, </institution> <year> 1993. </year> <note> Available via WWW at http : ==www:cogsci:indiana:edu=f arg=pwang papers:html. A revised version is going to appear in the International Journal of Approximate Reasoning. </note>
Reference-contexts: To make a reasonable choice among them, a quantitative measurement for uncertainty is necessary. Let's assume that there is a well-defined way to measure the weight of evidence for a statement (for how such a measurement is formally defined, see <ref> [20] </ref>). It is natural to judge the uncertainty of the statement by the frequency (or proportion) of available positive evidence whose weight is w + , among all relevant evidence whose weight is w, that is, by w + w . <p> What makes NARS different from the other approaches is the definition of the interval: here it is the interval where the frequency will be in the near future (see [22] for why the other interval definitions cannot be used in NARS). Let's take k = 2 (see <ref> [20] </ref> for an further explanation of k), if 10 birds are 6 observed and 9 of them can fly, then "Birds can fly" has a frequency 0.9000 and a confidence 0.8333; if 10000 birds are observed and 9000 of them can fly, then "Birds can fly" has a frequency 0.9000 and <p> In the following discussion, we'll concentrate on confidence. For a more complete description of NARS, see <ref> [20, 21] </ref>. 4.1 Negation If the truth value assigned to a statement is &lt; f; c &gt;, then what truth value should be assigned to the negation of the statement? According to above discussion, we know that f = w + w , and c = w By definition, the positive <p> If the system can determine that no evidence is repeatedly counted in the two sources (see <ref> [20] </ref> for how this is defined and checked), then the truth value of the revised judgment should be &lt; 0:8571; 0:875 &gt; (corresponding to "14 birds, 12 can fly"). <p> These rules also include functions calculating the truth value of the conclusions from those of the premises. The concrete form of the rules can be found in <ref> [20] </ref>, which is beyond the scope of this paper. In the following, I only mention two facts about these rules that is related to confidence: 1. The confidence of a conclusion is not larger than the confidence of either premise, that is, confidence "declines" in syllogistic inference. 10 2.
Reference: [21] <author> P. Wang. </author> <title> Non-axiomatic reasoning system (version 2.2). </title> <type> Technical Report 75, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana, </institution> <year> 1993. </year> <note> Available via WWW at http : ==www:cogsci:indiana:edu=f arg=pwang papers:html. </note>
Reference-contexts: These assumptions are chosen because of their theoretical importance (they can explain many aspects of intelligent behaviors) and their practical usage (many domains have these properties). For a more detailed discussion about the assumptions, see <ref> [21] </ref>. It follows directly from the assumptions that the system's judgments are usually uncertain, since the input knowledge is not necessarily conflicts-free, and the system need to make plausible inferences when the available knowledge is incomplete for a judgment task. <p> In the following discussion, we'll concentrate on confidence. For a more complete description of NARS, see <ref> [20, 21] </ref>. 4.1 Negation If the truth value assigned to a statement is &lt; f; c &gt;, then what truth value should be assigned to the negation of the statement? According to above discussion, we know that f = w + w , and c = w By definition, the positive
Reference: [22] <author> P. Wang. </author> <title> An unified treatment of uncertainties. </title> <type> Technical Re port 87, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana, </institution> <year> 1993. </year> <note> Available via WWW at http : ==www:cogsci:indiana:edu=f arg=pwang papers:html. </note>
Reference-contexts: What makes NARS different from the other approaches is the definition of the interval: here it is the interval where the frequency will be in the near future (see <ref> [22] </ref> for why the other interval definitions cannot be used in NARS). <p> NARS also accept truth values represented as a single number (by taking accuracy into consideration) or a linguistic variable (by translate it into an frequency interval). A detailed description on this issue can be found in <ref> [22] </ref>. 4 How is confidence processed in NARS After given a definition and interpretation of confidence, let's see how it is processed in by the various inference rules in NARS. In the following discussion, we'll concentrate on confidence.
Reference: [23] <author> R. Yager. </author> <title> Credibility discounting in the theory of approximate reason ing. </title> <editor> In P. Bonissone, M. Henrion, L. Kanal, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 299-310. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year> <month> 14 </month>
References-found: 23

