URL: http://www-plateau.cs.berkeley.edu/people/smoot/papers/bs/thesis.ps
Refering-URL: http://www-plateau.cs.berkeley.edu/people/smoot/papers/
Root-URL: 
Email: smoot@masala.lcs.mit.edu  
Title: ALEWIFE SYSTEMS  JUNE-BUG: A Debugger for Parallel Programs on the ALEWIFE Multiprocessor  
Author: Stephen R. Smoot 
Address: Cambridge, Mass. 02139  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Date: #15  November 13, 1995  
Pubnum: MEMO  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Abelson and G.J. Sussman with J. Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: The T language is a dialect of SCHEME developed at Yale. SCHEME is a Lisp language developed at MIT. 3.3.1 SCHEME and T SCHEME <ref> [1, 47] </ref> is a lexically-scoped Lisp dialect developed at MIT. SCHEME treats both procedures and continuations as first-class objects | they can be used in multiple contexts, freely passed between procedures, returned from them, stored in data structures, etc. SCHEME encourages functional programming, but supports side-effects.
Reference: [2] <author> William B. Ackerman. </author> <title> Data flow machines and languages. </title> <journal> IEEE Computer, </journal> <volume> 15(2), </volume> <month> February </month> <year> 1982. </year>
Reference-contexts: It is, however, unclear how much less efficient this is than creating new languages. Languages which are a radical departure, such as functional ones, are very promising in their potential parallelism <ref> [2] </ref>. However, they are difficult to program in, are incompatible with existing software, and much of the "data flow advantage" can be realized in compilers for traditional languages [19].
Reference: [3] <author> Evan Adams and Steven S. Muchnick. Dbxtool: </author> <title> A window-based symbolic debugger for Sun workstations. </title> <journal> Software Practice and Experience, </journal> <volume> 16(7) </volume> <pages> 653-669, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: The specifics of each tend to be determined by the typical program granularity, but it is still useful to look at them. One approach is to run each task through its own debugger. This can either be done in separate windows (Parasight [8, 7] and Dbxtool <ref> [3] </ref>), or through a central set of windows. Using a single set is easier to manage, but some researchers feel this is less intuitive. Dbxtool is essentially an improvement and adaptation of Dbx to both SunWindows 3 and multiprocessors. <p> Like animation graphics, these provide the information in a more easily digestible format, but do not permit repeatability. In general, the windowing environment provides nice freebies for debugging. For example, in developing Dbxtool <ref> [3] </ref>, they found that the text interface was used less, and used in a different way. They found a string-search capability was necessary. Another group extended Dbxtool to display data structures graphically, permitting a higher level view of them.
Reference: [4] <author> Anant Agarwal. </author> <title> Automatic management of locality in a scalable cache-coherent multiprocessor: The mit alewife machine. NSF Proposal, </title> <year> 1990. </year>
Reference-contexts: The only previous Mul-T system was implemented on an Encore Multimax 2 . 3.1 The ALEWIFE Computer The goal of the ALEWIFE project is to demonstrate a large shared-memory multiprocessor that takes proper advantage of locality and is easy to program <ref> [4] </ref>. It is a research machine that attacks the technology frontier on several fronts. Chaiken is studying the various tradeoffs be 1 SPARC is a trademark of Sun Microsystems, Inc. 2 Multimax is a trademark of Encore Computer Corporation 21 tween limited directory protocols and chaining [12].
Reference: [5] <author> Anant Agarwal. </author> <title> Limits on network performance. </title> <note> In preparation, </note> <year> 1990. </year>
Reference-contexts: The network is a two or three dimensional direct packet switched mesh [46]. A low dimensionality network was chosen as they scale well and maintain high local bandwidth <ref> [51, 5] </ref>. Their disadvantage, longer latencies, is handled by the processor architecture. The network is used both for interprocessor communication and processor-memory traffic. The details of a processor node are depicted in Figure 3.1.
Reference: [6] <author> Anant Agarwal, Beng Hong Lim, David Kranz, and John Kubiatowicz. </author> <month> April: </month> <title> A processor architecture for multiprocessing. </title> <note> To appear in SIGARCH 1990. </note>
Reference-contexts: The project seeks to determine the critical requirements a large shared memory multiprocessor makes on its interprocessor network. It also seeks to show the benefits of fine-grained task threading <ref> [6] </ref>. ALEWIFE is being built to determine the tradeoffs between user-determined and system-limited parallelism (see Section 3.4.4).
Reference: [7] <author> Ziya Aral and Ilya Gertner. </author> <title> Non-intrusive and interactive profiling in Parasight. </title> <booktitle> Proceedings of the ACM/SIGPLAN PPEALS (Parallel Programming: Experience with Applications, Languages and Systems) 1988, published in ACM SIGPLAN NOTICES, </booktitle> <volume> 23(9) </volume> <pages> 21-30, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: The specifics of each tend to be determined by the typical program granularity, but it is still useful to look at them. One approach is to run each task through its own debugger. This can either be done in separate windows (Parasight <ref> [8, 7] </ref> and Dbxtool [3]), or through a central set of windows. Using a single set is easier to manage, but some researchers feel this is less intuitive. Dbxtool is essentially an improvement and adaptation of Dbx to both SunWindows 3 and multiprocessors.
Reference: [8] <author> Ziya Aral and Ilya Gertner. </author> <title> High-level debugging in Parasight. </title> <booktitle> Proceedings of the ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, published in ACM SIGPLAN Notices, </booktitle> <volume> 24(1) </volume> <pages> 151-162, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: The specifics of each tend to be determined by the typical program granularity, but it is still useful to look at them. One approach is to run each task through its own debugger. This can either be done in separate windows (Parasight <ref> [8, 7] </ref> and Dbxtool [3]), or through a central set of windows. Using a single set is easier to manage, but some researchers feel this is less intuitive. Dbxtool is essentially an improvement and adaptation of Dbx to both SunWindows 3 and multiprocessors.
Reference: [9] <author> Arvind, R. S. Nikhil, and K. K. Pingali. I-Structures: </author> <title> Data Structures for Parallel Computing. </title> <booktitle> In Proceedings of the Workshop on Graph Reduction, (Springer-Verlag Lecture Notes in Computer Science 279), </booktitle> <year> 1986. </year>
Reference-contexts: Multiprocessors are much more complex than uniprocessors: they have exponentially more processor state, as well as the additional state of the interprocessor network and memory [27]. Useful parallel constructs, such as I-structures <ref> [9] </ref>, add state to every word in memory. In addition, the desire for efficiency is more of a concern.
Reference: [10] <author> Laura Dodson Bagnall. Parvis: </author> <title> A program visualization tool for multilisp. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <month> February </month> <year> 1989. </year>
Reference-contexts: An area of ongoing research: : : 2 UNIX is a trademark of AT&T Bell Laboratories 12 Second, one bought the multiprocessor for speed, so not only is program correctness something to be debugged, but so is its program efficiency <ref> [50, 13, 10] </ref>. In many multiprocessors, the ordering of events is unclear across processors [34]. The lack of total event ordering combined with the lack of single-cycle processor communication is very bad for debugging with breakpoints. They combine to make it impossible to transparently halt [14]. <p> Thus most system employ filters, to eliminate unwanted information. However, because of the amount of data, it is difficult to find the data which is relevant to the bug. Filters help reduce the volume of output, but risk discarding important information, and are difficult to specify well <ref> [10] </ref>. Another, design problem is deciding if event histories should create a total ordering or partial ordering of events. As discussed above, total ordering is more intuitive, but much less efficient. Partial ordering is not only less intuitive, but more difficult to represent to the user. <p> It is also decreasingly useful the further away from a message-passing model one's system is. 17 A representation better suited to shared memory multiprocessors are time-process diagrams <ref> [10] </ref>. These diagrams (an example is figure 2.2, where shaded areas represent uncertain orderings) depict what tasks were running on which processors when. One can scroll through "time" to look at different parts of the execution trace. Time-process diagrams also give one a high level view for debugging.
Reference: [11] <author> David Chaiken. </author> <title> Cache coherence protocol specification. </title> <note> ALEWIFE Systems Memo #5, </note> <month> March </month> <year> 1990. </year>
Reference-contexts: This creates the illusion of a global shared memory, without the bottleneck that an actual global shared memory would create. The controller maintains strong cache coherence for memory references <ref> [11] </ref>, but also provides special mechanisms to bypass coherence both for 22 research purposes [52] and for software-guaranteed-coherent accesses [32]. 3.1.2 The April Processor The April processor is designed to minimize the effects of communication and synchronization delays found in multiprocessors.
Reference: [12] <author> David Chaiken, Craig Fields, Kiyoshi Kurihara, and Anant Agarwal. </author> <title> Directory-based cache-coherence in large-scale multiprocessors. </title> <note> To appear in IEEE Computer, </note> <month> June </month> <year> 1990. </year> <month> 71 </month>
Reference-contexts: It is a research machine that attacks the technology frontier on several fronts. Chaiken is studying the various tradeoffs be 1 SPARC is a trademark of Sun Microsystems, Inc. 2 Multimax is a trademark of Encore Computer Corporation 21 tween limited directory protocols and chaining <ref> [12] </ref>. The project seeks to determine the critical requirements a large shared memory multiprocessor makes on its interprocessor network. It also seeks to show the benefits of fine-grained task threading [6]. ALEWIFE is being built to determine the tradeoffs between user-determined and system-limited parallelism (see Section 3.4.4).
Reference: [13] <author> Stewart Michael Clamen. </author> <title> Debugging in a parallel lisp environment. </title> <type> Bachelor's thesis, </type> <institution> MIT, </institution> <month> June </month> <year> 1986. </year>
Reference-contexts: An area of ongoing research: : : 2 UNIX is a trademark of AT&T Bell Laboratories 12 Second, one bought the multiprocessor for speed, so not only is program correctness something to be debugged, but so is its program efficiency <ref> [50, 13, 10] </ref>. In many multiprocessors, the ordering of events is unclear across processors [34]. The lack of total event ordering combined with the lack of single-cycle processor communication is very bad for debugging with breakpoints. They combine to make it impossible to transparently halt [14]. <p> Other debuggers pump all of their task information into a single window [16]. This can get very confusing to the user, and is much harder to manage. Yet it does permit intuitive "apply-to-all-tasks" operations, which are useful <ref> [13] </ref>. Single window systems provide mechanisms closer to transparent halting than executing commands in successive windows can provide. However, it is counter intuitive as it tends to make it appear that all tasks break simultaneously when they do not.
Reference: [14] <author> Robert Cooper. Pilgrim: </author> <title> A debugger for distributed systems. </title> <type> Technical Report 119, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> October </month> <year> 1987. </year>
Reference-contexts: In many multiprocessors, the ordering of events is unclear across processors [34]. The lack of total event ordering combined with the lack of single-cycle processor communication is very bad for debugging with breakpoints. They combine to make it impossible to transparently halt <ref> [14] </ref>. Transparent halting is either stopping everything at once or making it appear as if everything was stopped at once. The lack of instantaneous communication prevents actual simultaneous halting, and the lack of a global ordering prevents backtracking to simulate stopping instantaneously. <p> These efforts help reduce the time lag between a breakpoint and the halting of all processors, but do not permit transparency. Miller and Choi [39] developed a system which performs transparent halts on message-passing systems, but none such seems reasonable for shared memory model computers. Pilgrim <ref> [14] </ref> uses a different system to attain Lamport's partial ordering [34]. Pilgrim permits "typical operations" to occur after a breakpoint. Thus a processor can execute any command which could "just as easily" have occurred before the breakpoint, but cannot execute visible commands. Visible commands are interprocessor messages, acquiring locks, etc.
Reference: [15] <author> David A. Kranz et al. </author> <title> T, version 3.0, release notes. A description of the extensions to T since the printing of "The T Manual.", </title> <year> 1986. </year>
Reference-contexts: When involved with no arguments (via (debug)), it gives a "debug:" prompt and examines the call stack. When either called with an argument (via (crawl object)) or when an element of a frame is selected 5 All descriptions of T in this pertain report to T3.0 as described in <ref> [48, 15] </ref>. 19 ? print summary of inspector commands. A apply a procedure to the current object. B enter a read-eval-print loop in an appropriate environment. C inspect another object. D go to next deeper continuation (i.e. stack frame). E evaluate an expression in current object's environment.
Reference: [16] <author> David A. Kranz et al. </author> <title> Mul-T alpha release notes. Description of the extensions to Mul-T from T3.1, and operating system-like support for multiprocessing., </title> <month> October </month> <year> 1988. </year>
Reference-contexts: It also allows lightweight monitoring until the user narrows down the area to investigate, and can then provide additional information. This helps to reduce the volume of data and effect of the monitoring on the execution profile. Other debuggers pump all of their task information into a single window <ref> [16] </ref>. This can get very confusing to the user, and is much harder to manage. Yet it does permit intuitive "apply-to-all-tasks" operations, which are useful [13]. Single window systems provide mechanisms closer to transparent halting than executing commands in successive windows can provide. <p> However in JUNE-BUG, several of them have completely different interpretations in the two programs, while others remain identical. A direction other than imitating T could have been taken; JUNE-BUG could have been modeled after the Mul-T debugger for the Encore <ref> [16] </ref>. While lessons were learned from that implementation, it was primarily a straightforward port of the inspector with the additions of 35 36 group and task concepts and associated commands.
Reference: [17] <author> Robert J. Fowler, Thomas J. LeBlanc, and John M. Mellor-Crummey. </author> <title> An integrated approach to parallel program debugging and performance analysis on large-scale multiprocessors. </title> <booktitle> Proceedings of the ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, published in ACM SIGPLAN NOTICES, </booktitle> <volume> 24(1) </volume> <pages> 163-173, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: However, browsers put it in a better form. They do not suffer from the probe effect (except in the same sense that all event-recording systems suffer from it by virtue of the recording). An improvement over browsers is replayers. The most notable example is Instant-Replay <ref> [37, 17] </ref>. Instant-Replay is a system which not only permits event browsing, but also allows reexecution of modified code in the same event order. One can notice a bug, and modify the code to add breakpoints, etc., reexecuting in the same event order.
Reference: [18] <author> Jason Gait. </author> <title> A probe effect in concurrent programs. </title> <journal> Software|Practice and Experience, </journal> <volume> 16(3) </volume> <pages> 225-233, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: On successive iterations, the breakpoints move closer to the location of the bug, and at some point the user understands and removes the bug. Unfortunately, this does not work well in a multiprocessor environment because of the probe effect and nondeterminacy. The probe effect <ref> [18] </ref> is a change in the way a program runs due to the insertion of debugging statements. In multiprocessors, any change in code can easily change the winner of a race condition, or allow other machine state to change.
Reference: [19] <author> D.D. Gajski, D.A. Padua, D.J. Kuck, and R.H. Kuhn. </author> <title> A second opinion on data flow machines and languages. </title> <journal> IEEE Computer, </journal> <volume> 15(2), </volume> <month> February </month> <year> 1982. </year>
Reference-contexts: Languages which are a radical departure, such as functional ones, are very promising in their potential parallelism [2]. However, they are difficult to program in, are incompatible with existing software, and much of the "data flow advantage" can be realized in compilers for traditional languages <ref> [19] </ref>. The amount of COBOL and FORTRAN code still in use demonstrates that forcing programmers to switch languages 11 does not work well, and this argues against depending on new languages. Adapting old languages seems to be the best option.
Reference: [20] <author> Sharon L. Gray. </author> <title> Using futures to exploit parallelism in lisp. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <month> February </month> <year> 1986. </year>
Reference-contexts: Adapting old languages seems to be the best option. To make the transition as smooth as possible for the programmers, the languages must maintain the same flavor. In LISP languages this can be accomplished by a simple construct like future <ref> [20] </ref>. By simply denoting parts of the program which can be executed in parallel, it is easy for the programmer to understand, and permits the system to limit the parallelism as appropriate 1 . Thus it is a powerful construct, as well as an intuitive one.
Reference: [21] <author> F. Gregoretti, F. Maddaleno, and M. Zamboni. </author> <title> Monitoring tools for multiprocessors. </title> <journal> Mi-croprocessing and Microprogramming, </journal> <volume> 18(1986) </volume> <pages> 409-416, </pages> <year> 1986. </year>
Reference-contexts: This is relatively simple for message-passing schemes, where there are clear interprocessor communication paths which can be monitored. In other cases it is unclear what the hardware can do that will justify its cost. However it has proven useful for real-time systems <ref> [35, 36, 21] </ref>. It is unclear what role hardware will play in multiprocessing debugging in the future. 2.4 The T Inspector As mentioned above, it is highly desirable to make the transition from programming in a uniprocessor environment to a multiprocessor environment as simple as possible.
Reference: [22] <author> Robert H. Halstead, Jr. </author> <title> Parallel computing using multilisp. </title> <note> Unpublished. </note>
Reference-contexts: The value-return scheme can work as above (section 3.4.2). 3.4.4 Benefits of the Scheme While a detailed discussion of why this is a good construct or implementation is beyond the scope of this report (see <ref> [41, 22, 25] </ref> and future papers), it will briefly be motivated. In multiprocessor research, there is continual debate between how much work the programmer and system must do to expose parallelism. Unfortunately the decision of how much parallelism to expose is very difficult, and changes with each program and system.
Reference: [23] <author> Robert H. Halstead, Jr. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: Both SCHEME and T provide debugging facilities, T's is discussed in Section 2.4. 3.3.2 T and Futures ! Mul-T To adapt T to a multiprocessor environment, the future special form was added. Future is a construct from Multilisp <ref> [23] </ref>. Future allows one to express parallelism by denoting expressions that can be executed in parallel with the main thread of computation by (future expr). The main thread of computation may continue until it actually needs this data. <p> This provides a convenient operating-system level of description for associated tasks. Group ids are unique, and are not reused. "Stealing" is the primary method of task movement in dynamically scheduled Mul-T. It is 33 described in <ref> [23] </ref>, [41], and section 3.4.2. When a future is encountered in a program, it is immediately inlined. While it is executing, another processor may steal its continuation.
Reference: [24] <author> Robert H. Halstead, Jr. </author> <title> An assessment of multilisp: Lessons from experience. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 15(6), </volume> <month> December </month> <year> 1986. </year>
Reference-contexts: to another function, or storing it in a 25 Code: (procedure-1 x y z) (future (procedure-2 y)) (procedure-3 z) Time Processor 1 Processor N 1 (procedure-1 x y z) idle 2 package-continuation idle 3 (procedure-2 y) Notice and take work 4 (procedure-2 y) (procedure-3 z) 5 ... ... data structure <ref> [24] </ref>. Thus many operations can be done on a future before its value is actually required. If the future completes before being touched, the continuation will be able to use the value normally.
Reference: [25] <author> Robert H. Halstead, Jr. and Juan R. Loaiza. </author> <title> Exception handling in multilisp. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <address> St. Charles, Il, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: The value-return scheme can work as above (section 3.4.2). 3.4.4 Benefits of the Scheme While a detailed discussion of why this is a good construct or implementation is beyond the scope of this report (see <ref> [41, 22, 25] </ref> and future papers), it will briefly be motivated. In multiprocessor research, there is continual debate between how much work the programmer and system must do to expose parallelism. Unfortunately the decision of how much parallelism to expose is very difficult, and changes with each program and system.
Reference: [26] <author> John Hennessy. </author> <title> Symbolic debugging of optimized code. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 4(3) </volume> <pages> 323-344, </pages> <month> july </month> <year> 1982. </year>
Reference-contexts: This alters the order in which tasks are executed, and can change the entire profile of the program. Thus when debugging statements are added to a program, the bug can disappear. A similar problem occurs in both uniprocessor and multiprocessor optimized code for real-time systems, as described in <ref> [26] </ref>. In addition to the probe effect, nondeterminacy can prevent programs from running "the same way" on successive executions on multiprocessors.
Reference: [27] <author> Alfred A. Hough and Janice E. Cuny. </author> <title> Initial experiences with a pattern-oriented parallel debugger. </title> <booktitle> Proceedings of the ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, published in ACM SIGPLAN NOTICES, </booktitle> <volume> 24(1) </volume> <pages> 195-205, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: Multiprocessors are much more complex than uniprocessors: they have exponentially more processor state, as well as the additional state of the interprocessor network and memory <ref> [27] </ref>. Useful parallel constructs, such as I-structures [9], add state to every word in memory. In addition, the desire for efficiency is more of a concern. <p> This kind of system provides high level debugging information to the user. The major component of the MAD system [49] seems to be an event browser (although it has graphical and hardware components in addition). Belvedere <ref> [27] </ref> records events and presents an animated view of process communication for the user to browse. In general, browsers provide little more information than a debugger which runs alongside the executing program can. However, browsers put it in a better form. <p> They permit a more intuitive display of multiple execution traces, even giving a sense of the partial ordering of tasks. They also can provide a convenient improvement over traditional text entry. One of the first applications of graphics to interprocessor analysis was Belvedere <ref> [27] </ref>. It put a processor/network diagram in the Y-Z plane, and copies of it describing the ongoing activity over time along the T-axis (see figure 2.1 to get the flavor). This kind of presentation provides the user with a valuable high level description of the processor interaction.
Reference: [28] <author> Robert A. Iannucci and Arvind. </author> <title> Two fundamental issues in multiprocessing. </title> <booktitle> In Proceedings of DFVLR | Conference 1987 on Parallel Processing in Science and Engineering, </booktitle> <address> Bon-Bad Godesberg, West Germany, </address> <month> June </month> <year> 1987. </year> <note> Springer-Verlag LNCS 295. Also MIT-LCS Computation Group Memo 226-6. 72 </note>
Reference-contexts: It is very important that a processor in a multiprocessing environment tolerate high memory latencies and efficient process synchronization <ref> [28] </ref>. However, in scalable multiprocessor designs, high memory latency is unavoidable. APRIL hides the effects of both memory latency and synchronization waits by switching contexts. APRIL has a low context switch overhead to permit coarse grained multithreading.
Reference: [29] <author> Jeffrey Joyce, Greg Lomow, Konrad Slind, and Brian Unger. </author> <title> Monitoring distributed sys-tems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(2) </volume> <pages> 121-150, </pages> <month> May </month> <year> 1987. </year>
Reference: [30] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1978. </year>
Reference-contexts: It supports object-oriented or message passing styles of programming and contains many powerful features, such as dynamic typing, free call/return of procedures, dynamic memory allocation/deallocation, dynamic data structure definition, etc. Because of its nature, SCHEME is more expressive than more traditional computing languages, such as C <ref> [30] </ref>. However, SCHEME has never been accepted as a "real" programming language as no efficient implementations existed. ORBIT [31] has changed that enough to allow a SCHEME dialect to be the base language for a new machine. T is the version of SCHEME compiled by ORBIT [53, 48, 31].
Reference: [31] <author> David Andrew Kranz. </author> <title> ORBIT: An optimizing Compiler for Scheme. </title> <type> PhD thesis, </type> <institution> Yale, </institution> <month> February </month> <year> 1988. </year>
Reference-contexts: CPS code adds an additional argument to each procedure call, its continuation, that is called with the result of the procedure evaluation. Continuations have several advantages for compilation. See <ref> [31] </ref> for more information. High level debugging This is a view of debugging in which one looks at tasks, and task interactions, rather than individual instructions. <p> Currently it is being simulated by a home-grown simulator, ASIM. The language used both for simulations and for the eventual machine is Mul-T, a multiprocessor version of Yale's T. Mul-T is compiled to SPARC machine instructions by our version of ORBIT <ref> [31] </ref>. The only previous Mul-T system was implemented on an Encore Multimax 2 . 3.1 The ALEWIFE Computer The goal of the ALEWIFE project is to demonstrate a large shared-memory multiprocessor that takes proper advantage of locality and is easy to program [4]. <p> Because of its nature, SCHEME is more expressive than more traditional computing languages, such as C [30]. However, SCHEME has never been accepted as a "real" programming language as no efficient implementations existed. ORBIT <ref> [31] </ref> has changed that enough to allow a SCHEME dialect to be the base language for a new machine. T is the version of SCHEME compiled by ORBIT [53, 48, 31]. T takes SCHEME's object oriented capabilities and makes them automatic. <p> However, SCHEME has never been accepted as a "real" programming language as no efficient implementations existed. ORBIT [31] has changed that enough to allow a SCHEME dialect to be the base language for a new machine. T is the version of SCHEME compiled by ORBIT <ref> [53, 48, 31] </ref>. T takes SCHEME's object oriented capabilities and makes them automatic. In T, every entity is an object, with a set of operations that are valid on it.
Reference: [32] <author> John Kubiatowicz. </author> <title> Special mechanisms for multi-model support. </title> <note> ALEWIFE Systems Memo #4, </note> <month> March </month> <year> 1990. </year>
Reference-contexts: This creates the illusion of a global shared memory, without the bottleneck that an actual global shared memory would create. The controller maintains strong cache coherence for memory references [11], but also provides special mechanisms to bypass coherence both for 22 research purposes [52] and for software-guaranteed-coherent accesses <ref> [32] </ref>. 3.1.2 The April Processor The April processor is designed to minimize the effects of communication and synchronization delays found in multiprocessors. It is very important that a processor in a multiprocessing environment tolerate high memory latencies and efficient process synchronization [28]. <p> This is to combat a problem found in Multilisp | when one task errors, many others usually do, and the resulting error messages can be overwhelming, disguising the actual problem. The halting is performed via an efficient Inter-Processor Interrupt (IPI) mechanism <ref> [32] </ref>. Information about which tasks were executing is returned to the interrupting processor to be provided to the user. Clearly, there is a race condition for several processors encountering the same break. In this case, the lower-numbered processor takes control, and the higher numbered one goes on to another group.
Reference: [33] <author> Kiyoshi Kurihara. </author> <title> Performance evaluation of large-scale multiprocessors. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: ASIM denotes the union of network, cache, and APRIL node simulators. These are all tightly linked to the ORBIT compiler. The simulator is written in both C and T. It permits simulation at the cache level, network level, T/Mul-T code level, and FORTRAN traces <ref> [33] </ref>. Its organization is depicted in figure 3.2. JUNE-BUG is only concerned with the Mul-T level interface. Running compiled Mul-T, ASIM simulates approximately 40,000 assembly instructions per second on a SPARCserver 330.
Reference: [34] <author> Leslie Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 21(7), </volume> <month> July </month> <year> 1978. </year>
Reference-contexts: In many multiprocessors, the ordering of events is unclear across processors <ref> [34] </ref>. The lack of total event ordering combined with the lack of single-cycle processor communication is very bad for debugging with breakpoints. They combine to make it impossible to transparently halt [14]. <p> Miller and Choi [39] developed a system which performs transparent halts on message-passing systems, but none such seems reasonable for shared memory model computers. Pilgrim [14] uses a different system to attain Lamport's partial ordering <ref> [34] </ref>. Pilgrim permits "typical operations" to occur after a breakpoint. Thus a processor can execute any command which could "just as easily" have occurred before the breakpoint, but cannot execute visible commands. Visible commands are interprocessor messages, acquiring locks, etc.
Reference: [35] <author> B. Lazzerini and C. A. Prete. DISDEB: </author> <title> An interactive high-level debugging system for a multi-microprocessor system. </title> <journal> Microprocessing and Microprogramming, </journal> <volume> 18(1986) </volume> <pages> 401-408, </pages> <year> 1986. </year>
Reference-contexts: This is relatively simple for message-passing schemes, where there are clear interprocessor communication paths which can be monitored. In other cases it is unclear what the hardware can do that will justify its cost. However it has proven useful for real-time systems <ref> [35, 36, 21] </ref>. It is unclear what role hardware will play in multiprocessing debugging in the future. 2.4 The T Inspector As mentioned above, it is highly desirable to make the transition from programming in a uniprocessor environment to a multiprocessor environment as simple as possible.
Reference: [36] <author> Beatrice Lazzerini and Cosimo Antonio Prete. </author> <title> A programmable debugging aid for real-time software development. </title> <journal> IEEE Micro, </journal> <volume> 6(3) </volume> <pages> 34-42, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: This is relatively simple for message-passing schemes, where there are clear interprocessor communication paths which can be monitored. In other cases it is unclear what the hardware can do that will justify its cost. However it has proven useful for real-time systems <ref> [35, 36, 21] </ref>. It is unclear what role hardware will play in multiprocessing debugging in the future. 2.4 The T Inspector As mentioned above, it is highly desirable to make the transition from programming in a uniprocessor environment to a multiprocessor environment as simple as possible.
Reference: [37] <author> Thomas J. LeBlanc and John M. Mellor-Crummey. </author> <title> Debugging parallel programs with Instant Replay. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(4):471-482, </volume> <month> April </month> <year> 1987. </year>
Reference-contexts: However, browsers put it in a better form. They do not suffer from the probe effect (except in the same sense that all event-recording systems suffer from it by virtue of the recording). An improvement over browsers is replayers. The most notable example is Instant-Replay <ref> [37, 17] </ref>. Instant-Replay is a system which not only permits event browsing, but also allows reexecution of modified code in the same event order. One can notice a bug, and modify the code to add breakpoints, etc., reexecuting in the same event order.
Reference: [38] <author> Charles E. McDowell and David P. Helmbold. </author> <title> Debugging concurrent programs. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(4) </volume> <pages> 593-622, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Finally, many parallel languages (Mul-T, Multilisp, Id) support constructs that allow tasks to remain running after the expression has been evaluated. This allows programs to complete correctly and then error [43]. The traditional debugging method, cyclic debugging, has many problems in a multiprocessor environment <ref> [38, 40] </ref>. Cyclic debugging is the usual method for debugging a program; it involves running the code multiple times with the same inputs. The programmer inserts breakpoints into the code and examines the program state. <p> However, it is counter intuitive as it tends to make it appear that all tasks break simultaneously when they do not. To assist the user in dealing with the complexity, task groups and "current tasks" or "current task set" concepts are useful <ref> [38] </ref>. These efforts help reduce the time lag between a breakpoint and the halting of all processors, but do not permit transparency. Miller and Choi [39] developed a system which performs transparent halts on message-passing systems, but none such seems reasonable for shared memory model computers. <p> As discussed above, total ordering is more intuitive, but much less efficient. Partial ordering is not only less intuitive, but more difficult to represent to the user. A simple use of event histories is browsing <ref> [38] </ref>. In these systems, the debugger takes the form of a database of events. Typical queries concern which tasks modify which locations, send which messages, finish before others, etc. This kind of system provides high level debugging information to the user. <p> These features make debugging a more pleasant task. 18 2.3.4 Analysis Another way to circumvent the probe effect and nonrepeatability is to not depend on program executions, but instead statically analyze the code. Static analysis programs look for two things: synchronization errors and data-usage errors <ref> [38] </ref>. Synchronization errors are the typical scheduling errors: deadlock, livelock, starvation, etc. Data-usage errors include simultaneous updates, reades-before-writes, etc. Some static analysis has been incorporated with dynamic analysis, such as PPD [40], where events are incrementally traced to do flowback analysis.
Reference: [39] <author> Barton P. Miller and Jong-Deok Choi. </author> <title> Breakpoints and halting in distributed programs. </title> <booktitle> In Proceedings of the Eighth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 316-323, </pages> <year> 1988. </year>
Reference-contexts: To assist the user in dealing with the complexity, task groups and "current tasks" or "current task set" concepts are useful [38]. These efforts help reduce the time lag between a breakpoint and the halting of all processors, but do not permit transparency. Miller and Choi <ref> [39] </ref> developed a system which performs transparent halts on message-passing systems, but none such seems reasonable for shared memory model computers. Pilgrim [14] uses a different system to attain Lamport's partial ordering [34]. Pilgrim permits "typical operations" to occur after a breakpoint.
Reference: [40] <author> Barton P. Miller and Jong-Deok Choi. </author> <title> A mechanism for efficient debugging of parallel programs. </title> <booktitle> Proceedings of the ACM SIGPLAN '88 Conference on Programming Language Design and Implementation, published in ACM SIGPLAN Notices, </booktitle> <volume> 23(7) </volume> <pages> 135-144, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Finally, many parallel languages (Mul-T, Multilisp, Id) support constructs that allow tasks to remain running after the expression has been evaluated. This allows programs to complete correctly and then error [43]. The traditional debugging method, cyclic debugging, has many problems in a multiprocessor environment <ref> [38, 40] </ref>. Cyclic debugging is the usual method for debugging a program; it involves running the code multiple times with the same inputs. The programmer inserts breakpoints into the code and examines the program state. <p> Race conditions do not simply come from the scheduler, they also come from synchronization due to 13 spin-locks, and the availability of other resources. Furthermore guarded commands and database accesses can adversely affect repeatability <ref> [40] </ref>. Even the machine use between runs can affect cache contents, and exponential backoff values, changing runtimes. In general nonrepeatability is a problem for cyclic debugging. 2.3 Countering Multiprocessor Difficulties While the list of problems caused by the multiprocessor environment is long, it is not hopeless. <p> Static analysis programs look for two things: synchronization errors and data-usage errors [38]. Synchronization errors are the typical scheduling errors: deadlock, livelock, starvation, etc. Data-usage errors include simultaneous updates, reades-before-writes, etc. Some static analysis has been incorporated with dynamic analysis, such as PPD <ref> [40] </ref>, where events are incrementally traced to do flowback analysis. This seems to be a relatively promising area, especially in concert with dynamic debugging, but needs time to mature. 2.3.5 Hardware Another solution to the software problem is hardware | one can build on specialized hardware to assist in debugging.
Reference: [41] <author> Eric Mohr, David A. Kranz, and Robert H. Halstead, Jr. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <note> Submitted for publication. </note>
Reference-contexts: If not, then the continuation will trap, and insert itself in a queue of tasks waiting on the completion of this future. A completing future enables these tasks after storing its value. For greater detail, see <ref> [41] </ref>. 3.4 ALEWIFE Futures The ALEWIFE implementation of future is not as simple as in Multilisp. There are actually two different flavors of futures. 3.4.1 In Concept ALEWIFE has two kinds of futures. The user can just say (future (X)), where X is some expression. <p> This mechanism greatly reduces the number of instructions necessary, currently doing a future call instead of a normal procedure call takes only an additional 12 cycles, and returns take only 6 more. Implementation The ALEWIFE implementation of lazy-futures is completely described in figure <ref> [41] </ref>, so it will merely be summarized. ALEWIFE keeps its stack as a set of linked frames. It also maintains a 27 queue of future calls. Thus to separate a future's evaluation from its continuation's, one merely finds the call, and breaks the list. <p> The value-return scheme can work as above (section 3.4.2). 3.4.4 Benefits of the Scheme While a detailed discussion of why this is a good construct or implementation is beyond the scope of this report (see <ref> [41, 22, 25] </ref> and future papers), it will briefly be motivated. In multiprocessor research, there is continual debate between how much work the programmer and system must do to expose parallelism. Unfortunately the decision of how much parallelism to expose is very difficult, and changes with each program and system. <p> This provides a convenient operating-system level of description for associated tasks. Group ids are unique, and are not reused. "Stealing" is the primary method of task movement in dynamically scheduled Mul-T. It is 33 described in [23], <ref> [41] </ref>, and section 3.4.2. When a future is encountered in a program, it is immediately inlined. While it is executing, another processor may steal its continuation.
Reference: [42] <author> Eric Mohr, David A. Kranz, and Robert H. Halstead, Jr. Mul-T: </author> <title> A high performance parallel lisp. </title> <booktitle> In Proceedings of the 1989 Symposium on Programming Language Design and Implementation, </booktitle> <address> Portland, Oregon, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Or, if the user (or, in general, the compiler) knows which processor the future should be executed on, (future-on P (X)) can be done, and it will evaluate (X) on that processor. 3.4.2 Lazy-Futures Initially ALEWIFE implemented futures exactly parallel to the Encore Mul-T system <ref> [42] </ref>. 26 Code: (procedure-1 x y z) (future (procedure-2 y)) (procedure-3 z) Time Processor 1 Processor N 1 (procedure-1 x y z) idle 2 (procedure-2 y) package and take work 3 (procedure-2 y) (procedure-3 z) 4 ... ...
Reference: [43] <author> Rishiyur S. Nikhil. </author> <title> Id world reference manual (for lisp machines). </title> <institution> Laboratory for computer science technical report, Massachusetts Institute of Technology, Computation Structures Group, </institution> <month> April </month> <year> 1987. </year> <month> 73 </month>
Reference-contexts: Finally, many parallel languages (Mul-T, Multilisp, Id) support constructs that allow tasks to remain running after the expression has been evaluated. This allows programs to complete correctly and then error <ref> [43] </ref>. The traditional debugging method, cyclic debugging, has many problems in a multiprocessor environment [38, 40]. Cyclic debugging is the usual method for debugging a program; it involves running the code multiple times with the same inputs. The programmer inserts breakpoints into the code and examines the program state.
Reference: [44] <author> Rishiyur S. Nikhil. </author> <title> Id (version 88.1) reference manual. </title> <type> Technical report, </type> <institution> Computation Structures Group, MIT, Laboratory for Computer Science, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: If the language only supports debugging via print and stop, then a debugger must not only perform its normal tasks, but must make up for the language's deficiencies. The granularity size is also very important. Languages like Id <ref> [44, 45] </ref> with very small granularity size are difficult to debug, as one cannot associate extra state with each parallel-unit, making them hard to keep track of. However parallelized C code with a granularity size of a UNIX 2 process can support a lot of additional state (see section 2.3.1).
Reference: [45] <author> Rishiyur S. Nikhil and Arvind. </author> <title> Programming in Id: a parallel programming language. </title> <publisher> Nom de Qwerty, Inc., </publisher> <year> 1989. </year> <note> In preparation. </note>
Reference-contexts: If the language only supports debugging via print and stop, then a debugger must not only perform its normal tasks, but must make up for the language's deficiencies. The granularity size is also very important. Languages like Id <ref> [44, 45] </ref> with very small granularity size are difficult to debug, as one cannot associate extra state with each parallel-unit, making them hard to keep track of. However parallelized C code with a granularity size of a UNIX 2 process can support a lot of additional state (see section 2.3.1).
Reference: [46] <author> Daniel Nussbaum. </author> <title> Runtime locality enhancement on scalable multiprocessors. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <note> In preparation, </note> <year> 1990. </year>
Reference-contexts: The network is a two or three dimensional direct packet switched mesh <ref> [46] </ref>. A low dimensionality network was chosen as they scale well and maintain high local bandwidth [51, 5]. Their disadvantage, longer latencies, is handled by the processor architecture. The network is used both for interprocessor communication and processor-memory traffic. The details of a processor node are depicted in Figure 3.1.
Reference: [47] <editor> Johnathan Rees and W. Clinger. </editor> <title> Revised 3 Report on the Algorithmic Language Scheme. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 21(12) </volume> <pages> 37-79, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: The T language is a dialect of SCHEME developed at Yale. SCHEME is a Lisp language developed at MIT. 3.3.1 SCHEME and T SCHEME <ref> [1, 47] </ref> is a lexically-scoped Lisp dialect developed at MIT. SCHEME treats both procedures and continuations as first-class objects | they can be used in multiple contexts, freely passed between procedures, returned from them, stored in data structures, etc. SCHEME encourages functional programming, but supports side-effects.
Reference: [48] <author> Johnathan A. Rees, Norman I. Adams IV, and James R. Meehan. </author> <title> The T Manual. </title> <institution> Yale University Computer Science Department, Yale University, </institution> <address> New Haven, CT, </address> <month> January </month> <year> 1984. </year> <note> Fourth edition. </note>
Reference-contexts: When involved with no arguments (via (debug)), it gives a "debug:" prompt and examines the call stack. When either called with an argument (via (crawl object)) or when an element of a frame is selected 5 All descriptions of T in this pertain report to T3.0 as described in <ref> [48, 15] </ref>. 19 ? print summary of inspector commands. A apply a procedure to the current object. B enter a read-eval-print loop in an appropriate environment. C inspect another object. D go to next deeper continuation (i.e. stack frame). E evaluate an expression in current object's environment. <p> This is not entirely proper as some do not make sense (such as finding the local variables of a boolean). The operations provided are summarized in figure 2.3, and described in <ref> [48] </ref>. T supports several other debugging primitives, but all are usually accessed through the inspector. The only one of note is backtrace which prints the entire stack in brief form. This is a much faster way to get stack information than crawling through the frame, but provides less information. <p> However, SCHEME has never been accepted as a "real" programming language as no efficient implementations existed. ORBIT [31] has changed that enough to allow a SCHEME dialect to be the base language for a new machine. T is the version of SCHEME compiled by ORBIT <ref> [53, 48, 31] </ref>. T takes SCHEME's object oriented capabilities and makes them automatic. In T, every entity is an object, with a set of operations that are valid on it.
Reference: [49] <author> Robert V. Rubin, Larry Rudolph, and Dror Zernik. </author> <title> Debugging parallel programs in parallel. </title> <booktitle> Proceedings of the ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, published in ACM SIGPLAN Notices, </booktitle> <volume> 24(1) </volume> <pages> 216-225, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: In these systems, the debugger takes the form of a database of events. Typical queries concern which tasks modify which locations, send which messages, finish before others, etc. This kind of system provides high level debugging information to the user. The major component of the MAD system <ref> [49] </ref> seems to be an event browser (although it has graphical and hardware components in addition). Belvedere [27] records events and presents an animated view of process communication for the user to browse. In general, browsers provide little more information than a debugger which runs alongside the executing program can.
Reference: [50] <author> Zary Segall and Larry Rudolph. PIE: </author> <title> A programming and instrumentation environment for parallel processing. </title> <journal> IEEE Software, </journal> <volume> 2(6) </volume> <pages> 22-37, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: An area of ongoing research: : : 2 UNIX is a trademark of AT&T Bell Laboratories 12 Second, one bought the multiprocessor for speed, so not only is program correctness something to be debugged, but so is its program efficiency <ref> [50, 13, 10] </ref>. In many multiprocessors, the ordering of events is unclear across processors [34]. The lack of total event ordering combined with the lack of single-cycle processor communication is very bad for debugging with breakpoints. They combine to make it impossible to transparently halt [14].
Reference: [51] <author> Charles L. Seitz. </author> <title> Concurrent VLSI Architectures. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(12), </volume> <month> December </month> <year> 1984. </year>
Reference-contexts: The network is a two or three dimensional direct packet switched mesh [46]. A low dimensionality network was chosen as they scale well and maintain high local bandwidth <ref> [51, 5] </ref>. Their disadvantage, longer latencies, is handled by the processor architecture. The network is used both for interprocessor communication and processor-memory traffic. The details of a processor node are depicted in Figure 3.1.
Reference: [52] <author> Irene Shen. </author> <title> A study of the utility of block transfer mechanisms in the alewife multiprocessor. </title> <type> Bachelor's thesis, </type> <institution> MIT, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: This creates the illusion of a global shared memory, without the bottleneck that an actual global shared memory would create. The controller maintains strong cache coherence for memory references [11], but also provides special mechanisms to bypass coherence both for 22 research purposes <ref> [52] </ref> and for software-guaranteed-coherent accesses [32]. 3.1.2 The April Processor The April processor is designed to minimize the effects of communication and synchronization delays found in multiprocessors. It is very important that a processor in a multiprocessing environment tolerate high memory latencies and efficient process synchronization [28].
Reference: [53] <author> Stephen Slade. </author> <title> The T programming Language: A Dialect of Lisp. </title> <publisher> Prentice-Hall Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1987. </year>
Reference-contexts: However, SCHEME has never been accepted as a "real" programming language as no efficient implementations existed. ORBIT [31] has changed that enough to allow a SCHEME dialect to be the base language for a new machine. T is the version of SCHEME compiled by ORBIT <ref> [53, 48, 31] </ref>. T takes SCHEME's object oriented capabilities and makes them automatic. In T, every entity is an object, with a set of operations that are valid on it.
Reference: [54] <author> Sue Utter and Cherri M. Pancake. </author> <title> A bibliography of parallel debuggers. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(11), </volume> <month> November </month> <year> 1989. </year> <month> 74 </month>
References-found: 54

