URL: http://www.csl.sri.com/~livio/mascots.ps.Z
Refering-URL: http://www.csl.sri.com/~livio/papers.html
Root-URL: 
Email: Email: livio@csl.sri.com  
Phone: Phone: 415-8592969 Fax: 415-8592844  
Title: A Technique for the Distributed Simulation of Parallel Computers  
Author: Livio Ricciulli 
Keyword: Parallel simulation, Distributed simulation, Parallel computer simulation  
Note: Submitted to MASCOTS' 95  
Address: Menlo Park, California 94024, USA.  
Affiliation: Computer Science Laboratory SRI International  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Dubois, L. Barroso, S. Iman, J. Jeong, K. Oner, K. Ramamurty. </author> <title> "The USC Multiprocessor Testbed project: Project Review", </title> <type> USC Technical Report CENG-94-15, </type> <institution> Department of EE-Systems, University of Southern California, </institution> <address> Los Angeles, CA90089. </address>
Reference-contexts: Prototyping This technique is hardly a simulation methodology. The obvious drawbacks of this methodology are its high cost and very limited flexibility. The USC testbed <ref> [1] </ref> for the study of cache coherent DSM machines is an example of a project which tries to increase the design flexibility by making heavy usage of Field Programmable Gate-Arrays.
Reference: [2] <author> S. K. Reinhardt, M. D. Hill, J. R. Larus, A. R. Lebeck, J. C. Lewis, D. A. Wood. </author> <title> "The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers", </title> <booktitle> Proceedings of the 1993 ACM SIGMETRICS Conference", </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: In this framework the virtual and the real processors are overlapped as much as possible to reduce the ratio of the number of real instructions executed per simulated instruction. The Winsconsin Wind Tunnel <ref> [2] </ref> is an example of this technique. The virtual processors are replicated across the nodes of a CM-5 and consistency is maintained by inserting synchronization rendezvous every 100 instructions thus yielding a lock-step parallel simulation.
Reference: [3] <author> M. Brorsson, F. Dahlgren, H. Nilsson, P. Stenstrom. </author> <title> "The CacheMire Test Bench --- A flexible and Effective Approach for Simulation of Multiprocessors", </title> <type> Technical Report, </type> <institution> Dept. of Computer Engineering, Lund University, Sweden, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: Sequential Execution Driven Simulation This technique allows the simulation of a parallel system on a sequential machine by interleaving the execution of the different simulated processor in an optimal way <ref> [3] </ref> [11]. This widely used approach is very flexible and can be made quite realistic by carefully choosing the execution parameters. The only drawback of this technique is that it is not scalable to the simulation of very large systems or systems running "real-life" parallel applications.
Reference: [4] <author> L. Lamport, </author> <title> "How to make a multiprocessor computer that correctly executes multiprocess programs", </title> <address> C-28(9):241-248, </address> <month> September </month> <year> 1979. </year>
Reference-contexts: We associate shared memory accesses to events that propagate across LPs. Current distributed event driven simulation schemes can be viewed as sequentially consistent according to the definition of sequentially consistent systems given by Lamport <ref> [4] </ref>: Definition 1. [ A system is sequentially consistent if ] the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.
Reference: [5] <author> M. Dubois, C. Scheurich, F. Briggs. </author> " <title> Memory Access Buffering in Multiprocessors", </title> <booktitle> Proc. 13th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1986. </year>
Reference-contexts: This idea has appeared in the context of parallel programming as the weak ordering consistency programming model <ref> [5] </ref> where memory update messages need to be ordered only with respect to synchronization operations. In that ordering, coherence messages are sent only to maintain a correct execution rather than to emulate a serialization of global memory accesses.
Reference: [6] <author> D. Shasha, M. Snir. </author> " <title> Efficient and Correct Execution of parallel programs that share memory", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <month> April </month> <year> 1988. </year>
Reference-contexts: In order to state the necessary condition for the correctness of weak ordering simulation we need to introduce some definitions: Definition 1. Two global access events are conflicting if they access the same global location and at least a one of them is a write <ref> [6] </ref> Definition 2.
Reference: [7] <author> S. Adve, M. D. Hill. </author> <title> "Weak Ordering- A New Definition", </title> <booktitle> Proceeding of the 17th Annual Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Two global access events are conflicting if they access the same global location and at least a one of them is a write [6] Definition 2. A simulation is race free if any two conflicting global data access events have at least one proper synchronization event between them. <ref> [7] </ref> We can say that a weakly ordered distributed simulation is correct if: All synchronization events are sequentially consistent The simulation is race free Since there is a one to one correspondence between shared data movement and global simulation events we can say that our simulation is correct if the system
Reference: [8] <author> J. Boyle, R. Butler, T. Disz, B. Glickfeld, E. Lusk, R. Overbeek, J. Patterson, R. Stevens. </author> <title> "Portable programs For Parallel Processors", </title> <publisher> Holt, Reinhart and Winston, inc. </publisher> <year> 1987. </year>
Reference-contexts: This method could be sufficient to synchronize in a distrib uted manner the local virtual clocks of any system with synchronization primitives based on lock and clear operations (for example using the ANL macros <ref> [8] </ref>).
Reference: [9] <author> K. M. Chandy, J. Misra, </author> <title> "Asynchronous Distributed Simulation via a Sequence of Parallel Computations", </title> <journal> Communications of the ACM, </journal> <month> April </month> <year> 1981. </year>
Reference-contexts: In case the observable behavior of interest is the ordering of all the simulated events of the distributed entities, the simulation needs to be totally ordered of the kind proposed by Chandy and Misra <ref> [9] </ref> or Jefferson [10]. In case the observable behavior of a system is not the ordering of events itself but it is its overall performance, we can greatly simplify the simulation methodology. <p> the barrier case, virtual processors notify the controller when they enter a syn-chronization primitive and when exiting ask for the correct local time. 5 Virtual Network The real network characteristics are masked from the simulation with a simplified version of the distributed event-driven simulation methodology proposed by Chandy and Misra <ref> [9] </ref>. We assume that the hardware network will be able to deliver messages between any of the hardware nodes but we do not make any assumptions on how long the messages take to propagate.
Reference: [10] <author> D. Jefferson, </author> <title> "Virtual Time", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <month> July </month> <year> 1985. </year>
Reference-contexts: In case the observable behavior of interest is the ordering of all the simulated events of the distributed entities, the simulation needs to be totally ordered of the kind proposed by Chandy and Misra [9] or Jefferson <ref> [10] </ref>. In case the observable behavior of a system is not the ordering of events itself but it is its overall performance, we can greatly simplify the simulation methodology. <p> Unlike in time warp mechanisms <ref> [10] </ref>, we only modify the virtual clocks without having to restore previous states. In addition, we do not enforce a total ordering of the synchronization operations because this would place a very strong burden on the simulator thus reducing its efficiency.
Reference: [11] <author> H. Davis, S. R. Goldschmidt, J. Hennessy, </author> <title> "Multiprocessor Simulation and Tracing Using Tango", </title> <booktitle> Proc. of the Par. </booktitle> <address> Proc.Conf., </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Sequential Execution Driven Simulation This technique allows the simulation of a parallel system on a sequential machine by interleaving the execution of the different simulated processor in an optimal way [3] <ref> [11] </ref>. This widely used approach is very flexible and can be made quite realistic by carefully choosing the execution parameters. The only drawback of this technique is that it is not scalable to the simulation of very large systems or systems running "real-life" parallel applications.
Reference: [12] <author> P. Lincoln, J. Meseguer, L. Ricciulli, </author> <title> "The Rewrite Rule Machine Node Architecture and its Performance", </title> <note> to appear in proceedings of CONPAR 94, Linz, Austra. </note>
Reference-contexts: We plan to further investigate this important aspects in future studies. 7 Experimental Evidence Here we report some initial experimental evidence to support the effectiveness of our approach. 7.1 RRM simulator We have applied our ideas to the simulator for the Rewrite Rule Machine. The Rewrite Rule Machine (RRM) <ref> [12] </ref> is a Multiple Instruction Multiple Data/Single Instruction Multiple Data Stream (MIMD/SIMD) massively parallel computer currently being designed and simulated at SRI International.
Reference: [13] <author> H. Schwetman "Csim: </author> <title> A c-based, process-oriented simulation language", </title> <type> MCC Technical Report. </type>
Reference-contexts: The simulator holds a very detailed description of all the hardware down to the register level; it uses the libraries provided by the general- purpose simulation package Csim <ref> [13] </ref>. This package is an extension of the C language which allows very efficient process-oriented event driven simulations. Each device of each node is a separate process that interfaces with other processes through synchronization lines (events) and hardware queues (mail-boxes).
Reference: [14] <author> R. M. Fujimoto, </author> <title> "Optimistic Approaches to Parallel Discrete Event Driven Simulation", </title> <booktitle> Transactions of the society for computer simulation, </booktitle> <month> June </month> <year> 1990. </year>
Reference: [15] <author> R. M. Fujimoto, </author> " <title> Parallel discrete event simulation", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 33, </volume> <month> October </month> <year> 1990. </year>
References-found: 15

