URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/opitz.consci96.ps
Refering-URL: http://www.cs.wisc.edu/~shavlik/abstracts/opitz.consci96.ps.abstract.html
Root-URL: 
Email: opitz@cs.umt.edu shavlik@cs.wisc.edu  
Phone: 218-726-6149 608-262-7784  
Title: Actively Searching for an Effective Neural-Network Ensemble  
Author: David W. Opitz Jude W. Shavlik 
Address: 10 University Drive 1210 W. Dayton St. Duluth, MN 55812 Madison, WI 53706  MT 59812  
Affiliation: Computer Science Department Computer Sciences Department University of Minnesota University of Wisconsin  flCurrently at: Department of Computer Science; University of Montana; Missoula,  
Date: 8 (3-4), 1996.  
Note: Appears in Connection Science,  
Abstract: A neural-network ensemble is a very successful technique where the outputs of a set of separately trained neural network are combined to form one unified prediction. An effective ensemble should consist of a set of networks that are not only highly correct, but ones that make their errors on different parts of the input space as well; however, most existing techniques only indirectly address the problem of creating such a set. We present an algorithm called Addemup that uses genetic algorithms to explicitly search for a highly diverse set of accurate trained networks. Addemup works by first creating an initial population, then uses genetic operators to continually create new networks, keeping the set of networks that are highly accurate while disagreeing with each other as much as possible. Experiments on four real-world domains show that Addemup is able to generate a set of trained networks that is more accurate than several existing ensemble approaches. Experiments also show that Addemup is able to effectively incorporate prior knowledge, if available, to improve the quality of its ensemble. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aarts, E. & Korst, J. </author> <year> (1989). </year> <title> Simulated Annealing and Bolzmann Machines. </title> <publisher> Wiley. </publisher>
Reference-contexts: The alternative of randomly generating the network topologies thus trades off the overall accuracy of each single network for more disagreement between the networks. As points of comparison, we include the results of running (a) Breiman's et al. (1996a) Bagging algorithm, and (b) a simulated annealing <ref> (Aarts & Korst, 1989) </ref> version of Addemup. Bagging is a "bootstrap" (Efron & Tibshirani, 1993) ensemble method that trains each network in the ensemble with a different partition of the training set.
Reference: <author> Alpaydin, E. </author> <year> (1993). </year> <title> Multiple networks for function learning. </title> <booktitle> In Proceedings of the 1993 IEEE International Conference on Neural Networks (volume I), </booktitle> <pages> (pp. 27-32), </pages> <address> San Fransisco. </address>
Reference-contexts: Most approaches do not actively try to generate highly correct networks that disagree as much as possible. These approaches either randomly create their networks (Hansen & Salamon, 1990; Lincoln & Skrzypek, 1989), or indirectly try to create diverse networks by training each network with dissimilar learning parameters <ref> (Alpaydin, 1993) </ref>, different network architectures (Hashem et al., 1994), various initial weight settings (Maclin & Shavlik, 1995), or separate Opitz & Shavlik partitions of the training set (Breiman, 1996a; Krogh & Vedelsby, 1995).
Reference: <author> Baxt, W. </author> <year> (1992). </year> <title> Improving the accuracy of an artificial neural network using multiple differently trained networks. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 772-780. </pages>
Reference: <author> Breiman, L. </author> <year> (1996a). </year> <title> Bagging predictors. </title> <journal> Machine Learning, </journal> <volume> 24(2) </volume> <pages> 123-140. </pages>
Reference-contexts: In fact, when using domain-specific rules, our algorithm showed statistically significant improvements over (a) the single best network seen during the search, (b) a previously proposed ensemble method called Bagging <ref> (Breiman, 1996a) </ref>, and (c) a similar algorithm whose objective function is simply the validation-set correctness of the network. In summary, Addemup is successful in generating a set of neural networks that work well together in producing an accurate prediction.
Reference: <author> Breiman, L. </author> <year> (1996b). </year> <title> Stacked regressions. </title> <journal> Machine Learning, </journal> <volume> 24(1) </volume> <pages> 49-64. </pages>
Reference-contexts: One possible explanation is that optimizing the combining weights can easily lead to overfitting (Sollich & Krogh, 1996). We use validation-set accuracy, instead of Breiman's J-fold partitioning <ref> (Breiman, 1996b) </ref> since, during crossover, new networks are created from two existing networks which may have come from different folds.
Reference: <author> Opitz & Shavlik Breiman, L., Friedman, J., Olshen, R., & Stone, C. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA. </address>
Reference: <author> Clemen, R. </author> <year> (1989). </year> <title> Combining forecasts: A review and annotated bibliography. </title> <journal> International Journal of Forecasting, </journal> <volume> 5 </volume> <pages> 559-583. </pages>
Reference-contexts: Thus we define our weights for combining the networks as follows: w i = P : (7) While simply averaging the outputs can generate a good composite model <ref> (Clemen, 1989) </ref>, we include the predicted accuracy in our weights since one should believe accurate models more than inaccurate ones. We also tried more complicated models, such as emphasizing confident activations (i.e., activations near 0 or 1), but they did not improve the results on our testbeds.
Reference: <author> Drucker, H. & Cortes, C. </author> <year> (1996). </year> <title> Boosting decision trees. </title> <editor> In Touretsky, D., Mozer, M., & Hasselmo, M., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 8), </booktitle> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Drucker, H., Cortes, C., Jackel, L., LeCun, Y., & Vapnik, V. </author> <year> (1994). </year> <title> Boosting and other machine learning algorithms. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 53-61), </pages> <address> New Brunswick, NJ. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Drucker, H., Schapire, R., & Simard, P. </author> <year> (1992). </year> <title> Improving performance in neural networks using a boosting algorithm. </title> <editor> In Hanson, J., Cowan, J., & Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 5), </booktitle> <pages> (pp. 42-49), </pages> <address> Palo Alto, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Efron, B. & Tibshirani, R. </author> <year> (1993). </year> <title> An Introduction to the Bootstrap. </title> <publisher> Chapman and Hall, </publisher> <address> New York. </address>
Reference-contexts: As points of comparison, we include the results of running (a) Breiman's et al. (1996a) Bagging algorithm, and (b) a simulated annealing (Aarts & Korst, 1989) version of Addemup. Bagging is a "bootstrap" <ref> (Efron & Tibshirani, 1993) </ref> ensemble method that trains each network in the ensemble with a different partition of the training set. It generates each partition by randomly drawing, with replacement, N examples from the training set, where N is the size of the training set.
Reference: <author> Freund, Y. & Shapire, R. </author> <year> (1995). </year> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <booktitle> In Proceedings of the Second European Conference on Computational Learning. </booktitle>
Reference-contexts: Even more examples would be needed to generate a third training set. Recently, Drucker and Cortes (1996) applied a new boosting algorithm, termed AdaBoost <ref> (Freund & Shapire, 1995) </ref>, to decision trees.
Reference: <author> Goldberg, D. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference: <author> Granger, C. </author> <year> (1989). </year> <title> Combining forecasts: Twenty years later. </title> <journal> Journal of Forecasting, </journal> <volume> 8 </volume> <pages> 167-173. </pages>
Reference: <author> Hampshire, J. & Waibel, A. </author> <year> (1989). </year> <title> The meta-pi network: Building distributed knowledge representations for robust pattern recognition. </title> <type> Technical Report TR CMU-CS-89-166, </type> <address> CMU, Pittsburgh, PA. </address>
Reference-contexts: The key idea of these techniques is that a decomposition of the problem into specific subtasks might lead to more efficient representations and training <ref> (Hampshire & Waibel, 1989) </ref>. Once a problem is broken into subtasks, the resulting solutions need to be combined. Jacobs et al. (1991) propose having the gating function be a network that learns how to allocate examples to the experts.
Reference: <author> Hansen, L. & Salamon, P. </author> <year> (1990). </year> <title> Neural network ensembles. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12 </volume> <pages> 993-1001. </pages>
Reference: <author> Hashem, S., Schmeiser, B., & Yih, Y. </author> <year> (1994). </year> <title> Optimal linear combinations of neural networks: An overview. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Neural Networks, </booktitle> <address> Orlando, FL. </address>
Reference-contexts: These approaches either randomly create their networks (Hansen & Salamon, 1990; Lincoln & Skrzypek, 1989), or indirectly try to create diverse networks by training each network with dissimilar learning parameters (Alpaydin, 1993), different network architectures <ref> (Hashem et al., 1994) </ref>, various initial weight settings (Maclin & Shavlik, 1995), or separate Opitz & Shavlik partitions of the training set (Breiman, 1996a; Krogh & Vedelsby, 1995).
Reference: <author> Holland, J. </author> <year> (1975). </year> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, MI. </address>
Reference: <author> Jacobs, R., Jordan, M., Nowlan, S., & Hinton, G. </author> <year> (1991). </year> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 79-87. </pages>
Reference: <author> Kibler, D. & Langley, P. </author> <year> (1988). </year> <title> Machine learning as an experimental science. </title> <booktitle> In Proceedings of the Third European Working Session on Learning, </booktitle> <pages> (pp. 1-12), </pages> <address> Edinburgh, UK. </address>
Reference-contexts: The first, Ad-demup-weighted-examples, is Addemup with only reweighting the examples during training, while the second, Addemup-fitness, is Addemup with only its new fitness function. The 5 A lesion study is one where components of an algorithm are individually disabled to ascertain their contribution to the full algorithm's performance <ref> (Kibler & Langley, 1988) </ref>. Opitz & Shavlik Table 3: Test-set error on the lesion studies of Addemup.
Reference: <author> Koza, J. </author> <year> (1992). </year> <title> Genetic Programming. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The framework of Addemup and the theory it builds upon can be applied to any inductive learner, not just neural networks. Future work then, is to investigate applying Addemup to these other learning algorithms as well. With genetic programming <ref> (Koza, 1992) </ref>, for instance, we could translate perturbations of the domain theory into a set of dependency trees (see we would keep the set of trees that are a good fit for our objective function containing both an accuracy and diversity term.
Reference: <author> Krogh, A. & Vedelsby, J. </author> <year> (1995). </year> <title> Neural network ensembles, cross validation, and active learning. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 7), </booktitle> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Lincoln, W. & Skrzypek, J. </author> <year> (1989). </year> <title> Synergy of clustering multiple back propagation networks. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 650-659), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Maclin, R. & Shavlik, J. </author> <year> (1995). </year> <title> Combining the predictions of multiple classifiers: Using competitive learning to initialize neural networks. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada. </address>
Reference-contexts: These approaches either randomly create their networks (Hansen & Salamon, 1990; Lincoln & Skrzypek, 1989), or indirectly try to create diverse networks by training each network with dissimilar learning parameters (Alpaydin, 1993), different network architectures (Hashem et al., 1994), various initial weight settings <ref> (Maclin & Shavlik, 1995) </ref>, or separate Opitz & Shavlik partitions of the training set (Breiman, 1996a; Krogh & Vedelsby, 1995). Unlike Addemup however, these approaches do not directly address how to generate such networks that are optimized for the ensemble as a whole.
Reference: <author> Mani, G. </author> <year> (1991). </year> <title> Lowering variance of decisions by using artificial neural network portfolios. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 484-486. </pages>
Reference: <author> Opitz & Shavlik Nowlan, S. & Sejnowski, T. </author> <year> (1992). </year> <title> Filter selection model for generating visual motion signals. </title> <editor> In Hanson, S., Cowan, J., & Giles, C., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 5), </booktitle> <pages> (pp. 369-376), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Opitz, D. </author> <year> (1995). </year> <title> An Anytime Approach to Connectionist Theory Refinement: Refining the Topologies of Knowledge-Based Neural Networks. </title> <type> PhD thesis, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, WI. </institution>
Reference-contexts: Each of these domains is accompanied by a set of approximately correct rules describing what is currently known about the task <ref> (see Opitz, 1995, or Opitz and Shavlik, 1994, for more details) </ref>. The DNA domains are available at the University of Wisconsin Machine Learning (UW-ML) site via the World Wide Web (ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/ datasets/) or anonymous ftp (ftp.cs.wisc.edu, then cd to machine-learning/ shavlik-group/datasets). <p> The bottom two rows of Table 2a contain the results of the SA and GA versions of Addemup where, in both cases, their initial population (of size 20) is randomly generated using Regent's method for creating networks when no domain theory is present <ref> (refer to Opitz, 1995, for more details) </ref>. Even though both versions of Addemup train each network with the same training set, it still produces results comparable to Bagging.
Reference: <author> Opitz, D. & Shavlik, J. </author> <year> (1993). </year> <title> Heuristically expanding knowledge-based neural networks. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 1360-1365), </pages> <address> Chambery, France. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Opitz, D. & Shavlik, J. </author> <year> (1994). </year> <title> Using genetic search to refine knowledge-based neural networks. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 208-216), </pages> <address> New Brunswick, NJ. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Therefore it is desirable to have each network use the same validation set. 3.2 Creating and Crossing-Over Knowledge-Based Neural Networks Steps 1 and 2a in Table 1 specify that new networks need to be created. The algorithm we use for generating these new networks is the Regent algorithm <ref> (Opitz & Shavlik, 1994) </ref>. Regent uses genetic algorithms to search through the space of possible neural network topologies. Regent is specifically designed for KNNs, though it applies to standard neural networks as well. <p> Since Addemup continually considers new networks to include in its ensemble, it can be viewed as an "anytime" learning algorithm. Such a learning algorithm should produce a good concept quickly, then continue to search concept space, reporting the new "best" concept whenever one is found <ref> (Opitz & Shavlik, 1994) </ref>. This is important since, for most domains, an expert is willing to wait for weeks, or even months, if a learning system can produce an improved concept. Experiments demonstrate that our method is able to find an effective set of networks for our ensemble.
Reference: <author> Perrone, M. </author> <year> (1992). </year> <title> A soft-competitive splitting rule for adaptive tree-structured neural networks. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <pages> (pp. 689-693), </pages> <address> Baltimore, MD. </address>
Reference: <author> Provost, F. & Danyluk, A. </author> <year> (1995). </year> <title> Learning from bad data. </title> <booktitle> In Workshop on Applying Machine Learning in Practice, held at the Twelfth International Conference on Machine Learning, </booktitle> <address> Tahoe City, CA. </address>
Reference-contexts: in a network; we repeatedly add hidden nodes to the network being constructed by randomly selecting an existing output or hidden node, then adding new nodes to this node using one of the four methods shown in Figure 4. 4 Experimental Study We ran Addemup on Nynex's Max problem set <ref> (Provost & Danyluk, 1995) </ref> and on three problems from the Human Genome Project that aid in locating genes in DNA sequences (recognizing 4 A node's false-positive counter is incremented if changing its activation to 0 causes the network to correct an erroneous output. Counters for false negatives are defined analogously.
Reference: <author> Shapire, R. </author> <year> (1990). </year> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 197-227. </pages>
Reference-contexts: Unlike Addemup however, these approaches do not directly address how to generate such networks that are optimized for the ensemble as a whole. One method that does actively create members for its ensemble, however, is the Boosting algorithm <ref> (Shapire, 1990) </ref>. Boosting converts any learner that is guaranteed to always perform slightly better than random guessing into one that achieves arbitrarily high accuracy. Drucker et al. (1992) applied Boosting to neural networks to improve their error rate on a handwritten-digit-recognition task.
Reference: <author> Sollich, P. & Krogh, A. </author> <year> (1996). </year> <title> Learning with ensembles: How over-fitting can be useful. </title> <editor> In Touretsky, D., Mozer, M., & Hasselmo, M., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 8), </booktitle> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference-contexts: We also tried more complicated models, such as emphasizing confident activations (i.e., activations near 0 or 1), but they did not improve the results on our testbeds. One possible explanation is that optimizing the combining weights can easily lead to overfitting <ref> (Sollich & Krogh, 1996) </ref>. We use validation-set accuracy, instead of Breiman's J-fold partitioning (Breiman, 1996b) since, during crossover, new networks are created from two existing networks which may have come from different folds. <p> One must be careful in this case, since optimizing the combining weights can easily lead to the problem of overfitting which simple averaging seems to avoid <ref> (Sollich & Krogh, 1996) </ref>. Most approaches do not actively try to generate highly correct networks that disagree as much as possible.
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1994). </year> <booktitle> Knowledge-based artificial neural networks. Artificial Intelligence, </booktitle> <address> 70(1,2):119-165. </address>
Reference-contexts: Before presenting the exact details of these steps, we discuss (a) how we generate KNNs, and (b) Regent's genetic operators for refining the topology of these networks. An empirically successful algorithm for creating KNNs is the Kbann algorithm <ref> (Towell & Shavlik, 1994) </ref>. Kbann translates a set of propositional rules into a neural network, then refines the resulting KNN's weights using backpropagation. Figure 2 illustrates this translation process. Figure 2a shows a Prolog-like rule set that defines membership in category a. <p> In a symbolic rulebase that uses negation-by-failure, one can decrease false negatives by either dropping antecedents from existing rules or adding new rules to the rulebase. Since gradient-based training is effective at removing antecedents from existing rules <ref> (Towell & Shavlik, 1994) </ref>, the mutation operator adds nodes, intended to decrease false negatives, in a fashion that is analogous to adding a new rule to the rulebase (see Figure 4a,c). The mutation operator decreases false positives by creating new antecedents for the node (see Figure 4b,d).
Reference: <author> Tresp, V. & Taniguchi, M. </author> <year> (1995). </year> <title> Combining estimators using non-constant weighting functions. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 7), </booktitle> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Wolpert, D. </author> <year> (1992). </year> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 241-259. </pages>
Reference: <author> Zhang, X., Mesirov, J., & Waltz, D. </author> <year> (1992). </year> <title> Hybrid system for protein secondary structure prediction. </title> <journal> Journal of Molecular Biology, </journal> <volume> 225 </volume> <pages> 1049-1063. </pages>
References-found: 37

