URL: http://www.cs.washington.edu/homes/anhai/papers/doan-macrops.ps.Z
Refering-URL: http://www.cs.washington.edu/homes/anhai/anhai-cv.html
Root-URL: 
Email: fanhai,haddawyg@cs.uwm.edu  
Title: Generating Macro Operators for Decision-Theoretic Planning  
Author: AnHai Doan Peter Haddawy 
Address: PO Box 784 Milwaukee, WI 53201  
Affiliation: Department of Electrical Engineering and Computer Science University of Wisconsin-Milwaukee  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> L. Chrisman. </author> <title> Abstract probabilistic modeling of action. </title> <booktitle> In Proceedings of the First International Conference on Artificial Intelligence Planning Systems, </booktitle> <pages> pages 28-36, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Denote the set of all possible states as , and the set of all probability distributions over as P D (). We start by defining various types of sets of probability distributions over . A mass assignment m : 2 ! <ref> [0; 1] </ref> assigns to each subset of a probability mass portion. We have, therefore, P B m (B) = 1 and m (;) = 0. <p> A probability distribution P is said to be consistent with a mass assignment m iff P (B) = P P for all B . Denote the set of all intervals in <ref> [0; 1] </ref> as I; a general mass assignment M : 2 ! I assigns to each subset of a (probability) interval in I. M can be understood as a set of mass assignments M = fmjm : 2 ! [0; 1] s:t: 8B m (B) 2 M (B)g. <p> Denote the set of all intervals in <ref> [0; 1] </ref> as I; a general mass assignment M : 2 ! I assigns to each subset of a (probability) interval in I. M can be understood as a set of mass assignments M = fmjm : 2 ! [0; 1] s:t: 8B m (B) 2 M (B)g. Throughout the paper, M will be interpreted either as a function or a set depending on the context. Denote the set of all probability distributions consistent with a mass assignment m as -(m); we define -(M ) = m2M -(m). <p> Readers familiar with the above concept will recognize mass assignment as a subclass of lower probability. Dealing with metric domains made it necessary for us to generalize the concept of mass assignment into that of general mass assignment. Chrisman <ref> [ 1 ] </ref> presents a model in which uncertainty is represented by a single mass assignment. He then provides a projection rule that computes a post mass assignment containing all possible post probability distributions resulting from "executing" the action.
Reference: [2] <author> A.H. Doan and P. Haddawy. </author> <title> Decision-theoretic refinement planning: Principles and application. </title> <type> Technical Report TR-95-01-01, </type> <institution> Dept. of Elect. Eng. & Computer Science, University of Wisconsin-Milwaukee, </institution> <month> January </month> <year> 1995. </year> <note> Available via anonymous FTP from pub/tech_reports at ftp.cs.uwm.edu. </note>
Reference-contexts: In this paper we show how abstract macro operators can be generated which compactly represent a sequence of actions and thus reduce the cost of projection. A comprehensive theory of abstraction can be found in <ref> [ 2 ] </ref> . <p> In such an environment, general mass assignments have more expressive power than simple mass assignments. (For a more detailed discussion see <ref> [ 2 ] </ref> .) Throughout the paper we will be talking about action descriptions, but for brevity will refer to them simply as actions. Actions serve as transformations from a set of probability distributions pre into a set of probability distributions post. <p> = X M pre (B) X P I (c i j B) M iB (A) (2) The above projection rule is correct, i.e., for any general mass assignment M pre , action a, we have exec (a; -(M pre))(M post ), where M post is calcu lated using (2). (See <ref> [ 2 ] </ref> for a proof of correctness.) Projection rule 1, denoted as project 1 , states that in order to compute M post , we project each branch (triple) of a on each branch of M pre . In practice, the set of M pre 's branches is finite. <p> Action a fl is commonly referred to as macro operator. Due to the space limitation, we will skip the constructive discussion of sequential abstraction, but state the abstraction procedure. (See <ref> [ 2 ] </ref> for more details.) We define a new projection rule that is easier to implement, and can be applied in more situations, although it yields looser probability bounds than projection rule 1. <p> Since the sequence of test and wait could be repeatedly executed many times, abstracting the sequence could substantially reduce the cost of projection. We will produce an abstraction of this sequence by applying our macro operator algorithm, as well as our previously developed abstraction techniques <ref> [ 4, 2 ] </ref> . We first use the inter-action abstraction technique to abstract IPG and RUS together into NIT, as shown in Figure 2.b. We now create the macro operator NIT-and-Wait from the sequence NIT, Wait-7-Days. <p> Abstraction in probabilistic domains has long been recognized as an effective tool to faciliate faster reasoning. In this paper we focused on the technical side of obtaining a correct macro abstraction; a comprehensive theory of abstracting probabilistic actions is presented in <ref> [ 2 ] </ref> . Empirical results of applying the technique to several domains showed substantial reduction in the complexity of planning [ 2 ] . <p> In this paper we focused on the technical side of obtaining a correct macro abstraction; a comprehensive theory of abstracting probabilistic actions is presented in <ref> [ 2 ] </ref> . Empirical results of applying the technique to several domains showed substantial reduction in the complexity of planning [ 2 ] . The sequential abstraction method presented here could be easily adopted to use in both open-loop probabilistic planning [ 6 ] and Markov models [ 9 ] . We have ignored the question of abstracting schematic actions.
Reference: [3] <author> R.E. Fikes, P.E. Hart, and N.J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3(4) </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: 1 Introduction Generation of macro operators has long been known to be an effective speed-up learning technique for classical planners <ref> [ 3, 7 ] </ref> . It is to be expected that this benefit will carry over to decision-theoretic planners as well.
Reference: [4] <author> P. Haddawy and A.H. Doan. </author> <title> Abstracting probabilistic actions. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 270-277, </pages> <address> Seattle, </address> <month> July </month> <year> 1994. </year> <note> Available via anonymous FTP from pub/tech_reports at ftp.cs.uwm.edu. </note>
Reference-contexts: Trade-offs between the accuracy of projection and its cost are therefore necessary. One way to do this is to reduce the set of actions and/or the set of branches in each action by creating abstract actions. In a previous paper <ref> [ 4 ] </ref> , we presented methods for abstracting alternative actions to reduce the set of actions, and abstracting groups of branches within an action. <p> Since the sequence of test and wait could be repeatedly executed many times, abstracting the sequence could substantially reduce the cost of projection. We will produce an abstraction of this sequence by applying our macro operator algorithm, as well as our previously developed abstraction techniques <ref> [ 4, 2 ] </ref> . We first use the inter-action abstraction technique to abstract IPG and RUS together into NIT, as shown in Figure 2.b. We now create the macro operator NIT-and-Wait from the sequence NIT, Wait-7-Days.
Reference: [5] <author> C.E. Kahn and P. Haddawy. </author> <title> Optimizing diagnostic and therapeutic strategies using decision-theoretic planning: </title> <booktitle> Principles and applications. In Proceedings of the Eighth World Congress on Medical Informatics (Medinfo'95), </booktitle> <address> Vancouver, </address> <month> July </month> <year> 1995. </year> <note> (to appear). </note>
Reference-contexts: A comprehensive theory of abstraction can be found in [ 2 ] . Our work on generating macro operators was motivated by our application of the drips decision-theoretic refinement planning system to the problem of selecting the optimal test/treat strategy in a particular medical domain <ref> [ 5 ] </ref> . drips efficiently searches the space of possible plans to identify the optimal plan by representing the space using an abstraction/decomposition network (a kind of AND/OR tree). <p> Sequential abstraction may be combined with other abstraction techniques to yield abstract macro operators. We illustrate this idea through the example in the next section. 5 Examples The following example is taken from a medical problem to which we successfully applied the drips planning system <ref> [ 5 ] </ref> . The task is to choose the optimal test/treat strategy for managing patients suspected of having lower-extremity deep vein thrombosis (blood clot in the calf or thigh). We have several possible tests to choose from, including two non-invasive tests: real-time ultrasonography (RUS) and impedance plethys-mography (IPG).
Reference: [6] <author> N. Kushmerick, S. Hanks, and D. Weld. </author> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1073-1078, </pages> <address> Seattle, </address> <year> 1994. </year>
Reference-contexts: We represent uncertainty about the world and action effects with general mass assignments, i.e., with the set of probability distributions represented by the general mass assignment. This differs from most existing probabilistic planning models which represent uncertainty by a single probability distribution <ref> [ 6, 10 ] </ref> . With actions that can have metric effects, we must deal with mass assignments where we cannot determine in advance which state belongs to a focal elemment B, because B is represented by a set of constraints. <p> In practice, the set of M pre 's branches is finite. Function project 1 can be calculated easily based on P fl and P fl . It is not hard to see that the complexity of project 1 is equal to that of straightforward projection <ref> [ 6 ] </ref> in single probability distribution schemes. 3 Sequential Action Abstraction Projection rule 1 is sound, i.e., it does not leave out any possible "post-execution" probability distribution. Furthermore project 1 (a; M pre ) can be computed much faster than exec (a; M pre ). <p> Empirical results of applying the technique to several domains showed substantial reduction in the complexity of planning [ 2 ] . The sequential abstraction method presented here could be easily adopted to use in both open-loop probabilistic planning <ref> [ 6 ] </ref> and Markov models [ 9 ] . We have ignored the question of abstracting schematic actions. Further work will be focused on this problem, as well as on investigating abstractions based on qualitative properties of actions.
Reference: [7] <author> S. Minton. </author> <title> Selectively generalizing plans for problem solving. </title> <booktitle> In IJCAI85, </booktitle> <pages> pages 596-599, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction Generation of macro operators has long been known to be an effective speed-up learning technique for classical planners <ref> [ 3, 7 ] </ref> . It is to be expected that this benefit will carry over to decision-theoretic planners as well.
Reference: [8] <author> J.M. Siskind and D.A. McAllester. </author> <title> Nondeterministic lisp as a substrate for constraint logic programming. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 133-138, </pages> <address> Washington,DC, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Condition c 2 is satisfied in the chronicle constrained by c 1 and E 1 iff the set C = fc 1 ; c 0 2 g is consistent. Constraint solving techniques such as Screamer <ref> [ 8 ] </ref> can be used to check the consistency of C to see whether it is necessary to create branch (c; I; E fl ).
Reference: [9] <author> David E. Smith and Mike Williamson. </author> <title> Representation and evaluation of plans with loops. </title> <booktitle> In AAAI Spring Symposium 95 Extending Theories of Actions, </booktitle> <address> Stanford, CA, </address> <year> 1995. </year>
Reference-contexts: Empirical results of applying the technique to several domains showed substantial reduction in the complexity of planning [ 2 ] . The sequential abstraction method presented here could be easily adopted to use in both open-loop probabilistic planning [ 6 ] and Markov models <ref> [ 9 ] </ref> . We have ignored the question of abstracting schematic actions. Further work will be focused on this problem, as well as on investigating abstractions based on qualitative properties of actions.
Reference: [10] <author> S. Thiebaux, J. Hertzberg, W. Shoaff, and M. Schneider. </author> <title> A stochastic model of actions and plans for anytime planning under uncertainty. </title> <journal> International Journal of Intelligent Systems, </journal> <note> 1994. To appear. </note>
Reference-contexts: We represent uncertainty about the world and action effects with general mass assignments, i.e., with the set of probability distributions represented by the general mass assignment. This differs from most existing probabilistic planning models which represent uncertainty by a single probability distribution <ref> [ 6, 10 ] </ref> . With actions that can have metric effects, we must deal with mass assignments where we cannot determine in advance which state belongs to a focal elemment B, because B is represented by a set of constraints.
References-found: 10

