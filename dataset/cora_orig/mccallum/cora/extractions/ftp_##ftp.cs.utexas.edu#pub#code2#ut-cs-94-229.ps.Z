URL: ftp://ftp.cs.utexas.edu/pub/code2/ut-cs-94-229.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/browne/
Root-URL: http://www.cs.utexas.edu
Title: Visual Programming and Parallel Computing 1 Visual Programming and Parallel Computing During the past 15
Author: James C. Browne Jack Dongarra Syed I. Hyder Keith Moore Peter Newton 
Affiliation: University of Texas at Austin. University of Tennessee at Knoxville.  
Note: 1.0 Introduction  
Abstract: Visual programming arguably provides greater benefit in explicit parallel programming, particularly coarse grain MIMD programming, than in sequential programming. Explicitly parallel programs are multi-dimensional objects; the natural representations of a parallel program are annotated directed graphs: data ow graphs, control ow graphs, etc. where the nodes of the graphs are sequential computations. The execution of parallel programs is a directed graph of instances of sequential computations. A visually based (directed graph) representation of parallel programs is thus more natural than a pure text string language where multi-dimensional structures must be implicitly defined. The naturalness of the annotated directed graph representation of parallel programs enables methods for programming and debugging which are qualitatively different and arguably superior to the conventional practice based on pure text string languages. Annotation of the graphs is a critical element of a practical visual programming system; text is still the best way to represent many aspects of programs. This paper presents a model of parallel programming and a model of execution for parallel programs which are the conceptual framework for a complete visual programming environment including capture of parallel structure, compilation and behavior analysis (performance and debugging). Two visually-oriented parallel programming systems, CODE 2.0 and HeNCE, each based on a variant of the model of programming, will be used to illustrate the concepts. The benefits of visually-oriented realizations of these models for program structure capture, software component reuse, performance analysis and debugging will be explored and hopefully demonstrated by examples in these representations. It is only by actually implementing and using visual parallel programming languages that we have been able to fully evaluate their merits.
Abstract-found: 1
Intro-found: 1
Reference: [Ack82] <author> W. B. Ackerman, </author> <title> Data Flow Languages, </title> <journal> Computer, </journal> <volume> Vol. 15. pp.15-25, </volume> <month> Feb., </month> <year> 1982. </year> <title> Visual Programming and Parallel Computing 34 </title>
Reference-contexts: There have been several proposals for visual dataow oriented programming languages. Adamss model [Ada68] is an early example. Computations are deterministic. There are sophisticated techniques for mapping inputs to outputs, as firing and routing rules do in CODE. Ackerman <ref> [Ack82] </ref> provides a general discussion of early ideas in dataow languages. Keller and Yen [Kel81] discuss directed graph programming and Davis and Keller [Dav82] present a dataow language with special purpose nodes for non-standard firing rules and discuss graph composition. CODE 1.x J.C.
Reference: [Ada68] <author> D. A. Adams, </author> <title> A Model for Parallel Compilations, Parallel Processor Systems, </title> <booktitle> Technologies and Applications, </booktitle> <pages> pp. 311-334, </pages> <address> Spartan/MacMillan, New York, </address> <year> 1968. </year> <title> [Bab92] . Babaoglu, Paralex: An Environment for Parallel Programming in Distrib uted Systems, </title> <booktitle> Proc. ACM Int. Conf. on Supercomputing, </booktitle> <month> July, </month> <year> 1992. </year>
Reference-contexts: The model is capable of expressing some interesting numerical algorithms, but is not ex-ible enough for general use. There have been several proposals for visual dataow oriented programming languages. Adamss model <ref> [Ada68] </ref> is an early example. Computations are deterministic. There are sophisticated techniques for mapping inputs to outputs, as firing and routing rules do in CODE. Ackerman [Ack82] provides a general discussion of early ideas in dataow languages.
Reference: [Bai91] <author> D .A. Bailey, et al., ParaGraph: </author> <title> Graph Editor Support for Parallel Programming Environments, </title> <journal> International Journal of Parallel Programming, </journal> <month> Apr., </month> <year> 1991. </year>
Reference-contexts: Poker Poker [Sny85] is noteworthy as an early graphical parallel programming environment. It is, however, a fairly distant relative of CODE and HeNCE. It graphical displays lattices of virtual processing elements and allows these nodes to be annotated with a sequential algorithm. Paragraph Paragraph <ref> [Bai91] </ref> is a very interesting model of parallel programming in which computation graphs are expressed by productions in a graph grammar, thus allowing dynamically structured graphs. 7.2 Recent Systems There are some more recent systems that are similar to CODE, many of which are still under active development.
Reference: [Bau91] <author> A. Bauch, R. Braam, and E. Maehle, DAMP: </author> <title> A Dynamic Reconfigurable Multiprocessor System with a Distributed Switching Network, </title> <booktitle> Distributed Memory Computing, Lecture Notes in Computer Sciences, </booktitle> <editor> ed. A. Bode, </editor> <volume> Vol. 487, </volume> <publisher> Springer-Verlag, </publisher> <pages> pp. 495-504, </pages> <year> 1991. </year>
Reference-contexts: The language supports indexed replication, somewhat like HeNCEs. D 2 R D 2 R (Dynamic Dataow Representation) [Ros93] is a recent model that bears much resemblance to HeNCE. However, it appears to have an orientation towards scheduling research. It has been implemented on a multi-transputer system called DAMP <ref> [Bau91] </ref>. As with older versions of HeNCE, the language has both a textual and a graphical representation. There are special constructs for loops, parallel fork-join constructs, and alternatives (n-way if). The model is dynamic since the width of a fork-join, and the loop count of a loop are runtime parameters.
Reference: [Beg91a] <author> A. Beguelin, J. J. Dongarra, G. A. Geist, R. Manchek, and V. S. Sunderam, </author> <title> Graphical development tools for network-based concurrent supercomputing, </title> <booktitle> Proceedings of Supercomputing 91, pages 435--444, </booktitle> <address> Albuquerque, </address> <year> 1991. </year>
Reference-contexts: The separation of concerns which assists in reduction of complexity of programming also results in reduction of the complexity of compilation of these abstract specifications for interactions into efficient executable forms. As we shall see later, the two systems used as examples in this paper, HeNCE <ref> [Beg91a] </ref> and CODE 2.0 [New93, New92], demonstrate that in at least some circumstances, competitively efficient code can be generated from the abstract specifications of interactions.
Reference: [Beg91b] <author> A. Beguelin and G. Nutt, </author> <title> Collected Papers on Phred, </title> <institution> Dept. of Computer Sci ence, Univ. of Colorado, CU-CS-511-91, </institution> <month> Jan., </month> <year> 1991. </year>
Reference-contexts: Schedule Schedule [Don86] is a visual computation graph oriented system that facilitates calling separate sequential routines. Ideas from it inuenced later systems including Phred, HeNCE, and some versions of CODE. Phred Phred <ref> [Beg91b] </ref> is a graphical system that greatly expands on the semantics of schedule. It uses graph grammars in its language definition and special nodes for firing rules, computations, and some runtime determined computation structures. Programs consist of a combination of control ow and dataow graphs. Phred heavily inuenced HeNCE.
Reference: [Bro85] <author> J. C. Browne, </author> <title> Formulation and Programming of Parallel Computers: a Uni fied Approach, </title> <booktitle> Proc. Intl. Conf. Par. Proc., </booktitle> <year> 1985, </year> <pages> pp. 624-631. </pages>
Reference-contexts: CODE 1.x J.C. Browne has been investigating computation graph systems for many years. The general advantages of such systems and the outline of a model of parallel computation are presented in <ref> [Bro85] </ref>, and Browne and his students also developed several earlier versions of CODE [Bro89, Jai91]. These form the intellectual basis for the current version but are much less capable. CODE 1.2 served as the basis for experiments in reuse within the context of a graph model [Lee89, Bro90].
Reference: [Bro89] <author> J. C. Browne, M. Azam, and S. Sobek, </author> <title> CODE: A Unified Approach to Parallel Programming, </title> <journal> IEEE Software, </journal> <month> July, </month> <year> 1989, </year> <note> p. 11. </note>
Reference-contexts: CODE 1.x J.C. Browne has been investigating computation graph systems for many years. The general advantages of such systems and the outline of a model of parallel computation are presented in [Bro85], and Browne and his students also developed several earlier versions of CODE <ref> [Bro89, Jai91] </ref>. These form the intellectual basis for the current version but are much less capable. CODE 1.2 served as the basis for experiments in reuse within the context of a graph model [Lee89, Bro90].
Reference: [Bro90] <author> J. C. Browne, J. Werth, and T. J. Lee, </author> <title> Experimental Evaluation of a Reusability Oriented Parallel Programming Environment, </title> <journal> IEEE Trans. Soft. Engin., </journal> <volume> Vol. 16, No. 2, </volume> <year> 1990. </year>
Reference-contexts: These form the intellectual basis for the current version but are much less capable. CODE 1.2 served as the basis for experiments in reuse within the context of a graph model <ref> [Lee89, Bro90] </ref>. Schedule Schedule [Don86] is a visual computation graph oriented system that facilitates calling separate sequential routines. Ideas from it inuenced later systems including Phred, HeNCE, and some versions of CODE. Phred Phred [Beg91b] is a graphical system that greatly expands on the semantics of schedule.
Reference: [Dav82] <author> A. L. Davis and R. M. Keller, </author> <title> Data Flow Program Graphs, </title> <journal> Computer, </journal> <volume> Vol. 15., pp.26-41, </volume> <month> Feb., </month> <year> 1982. </year>
Reference-contexts: Computations are deterministic. There are sophisticated techniques for mapping inputs to outputs, as firing and routing rules do in CODE. Ackerman [Ack82] provides a general discussion of early ideas in dataow languages. Keller and Yen [Kel81] discuss directed graph programming and Davis and Keller <ref> [Dav82] </ref> present a dataow language with special purpose nodes for non-standard firing rules and discuss graph composition. CODE 1.x J.C. Browne has been investigating computation graph systems for many years.
Reference: [Don86] <author> J. J. Dongarra and D. C. Sorenson, </author> <title> SCHEDULE: Tools for Developing and Analyzing Parallel Fortran Programs, </title> <note> Argonne National Laboratory MCSD Technical Memorandum No. 86, </note> <month> Nov., </month> <year> 1986. </year>
Reference-contexts: These form the intellectual basis for the current version but are much less capable. CODE 1.2 served as the basis for experiments in reuse within the context of a graph model [Lee89, Bro90]. Schedule Schedule <ref> [Don86] </ref> is a visual computation graph oriented system that facilitates calling separate sequential routines. Ideas from it inuenced later systems including Phred, HeNCE, and some versions of CODE. Phred Phred [Beg91b] is a graphical system that greatly expands on the semantics of schedule.
Reference: [Eig91] <author> R. Eigenmann, and W. Blume, </author> <title> An Effectiveness Study of Parallelizing Com piler Techniques, </title> <booktitle> Proc. Intl. Conf. Par. Proc., </booktitle> <year> 1991, </year> <pages> pp. II 17-25. </pages>
Reference-contexts: This approach clearly provides application portability. It is the case, however, that current parallel compilers often miss significant parallelism due to the difficulties engendered by name ambiguity in programs written in todays sequential programming languages <ref> [EIG91] </ref>. This approach also suffers from the fact that, in practice, programmers must be aware of the parallel structures the compiler will produce from given source text since they must program idiomatically so that the compiler will be able to produce efficient code.
Reference: [Gei93] <author> G. A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. S. Sun-deram, </author> <title> PVM 3 Users Guide and Reference Manual, </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <year> 1993. </year> <title> Visual Programming and Parallel Computing 35 </title>
Reference-contexts: This is true also of repre sentations that show parallelism directly. Consider programs expressed in C with calls to explicit message passing libraries in the general style of the PVM system <ref> [Gei93] </ref>. An example is shown in Figure 3. Graphical display tools often represent the behavior of such programs by means of a dia gram that shows messages being sent from one process to another. In other words, every interaction between processes is shown by an arc. <p> The workstations need not all be of them same type or even made by the same manufacturer. The capabilities and speeds of such a heterogeneous collection of machines can very widely. HeNCE graphs are converted into programs which run under the PVM message passing library <ref> [Gei93] </ref>. PVM is designed to be used directly by programmers as well. The names of all of the workstations must be listed in the window segment labeled Virtual Machine (see Figure 16).
Reference: [Gli84] <author> E. P. Glinert and S. L. Tanimoto, </author> <title> PICT: An Interactive Graphical Program ming Environment, </title> <journal> IEEE Computer, </journal> <volume> Vol. 17, No. 11, </volume> <month> Nov., </month> <year> 1984. </year>
Reference-contexts: It also provides a unified framework for supporting different concurrent debugging facilities like execution history displays, animation, and model checking facilities. Visual Programming and Parallel Computing 30 7.0 Related Work There has been much work on visual programming languages and environments for sequential systems. Prograph [TGS92] and PICT <ref> [Gli84] </ref> are substantial examples. We will focus on visual parallel programming languages. 7.1 Older Systems and Proposals CODE and HeNCE are certainly not the first systems to be designed for visual programming of parallel systems via graphs that show parallel structure. This sections surveys some of the earlier attempts.
Reference: [Gra90] <author> M. Graf, </author> <title> Building a Visual Designers Environment, in Principles of Visual Programming Systems, </title> <editor> S.-K. Chang, ed., </editor> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1990. </year>
Reference-contexts: Other tools in PPSE include a graphical target machine description system, task analysis, mapping, and scheduling tools, a code generator that targets the STRAND language, a simulator, and various performance and schedule visualization tools. VERDI VERDI is a visual language used to develop distributed programs in Raddle <ref> [Gra90] </ref>. Programs consist of a set of graphs. Control ow in a graph is represented by the ow of a token through it. Data may be attached to the token.
Reference: [Hir91] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng, </author> <title> Compiler Support for Machine-Independent Parallel Programming in Fortran D, </title> <institution> Rice University, CRPC-TR91132, </institution> <year> 1991. </year>
Reference-contexts: It is merely expressed indirectly. Extend sequential languages to allow data partitions to be specified. One emerging trend is to include declarative partitioning of data structures in the sequential program formulation and to ask the compiler to utilize this parallel structure <ref> [HIR91] </ref>. This promising method is as yet immature.
Reference: [Hyd93] <author> S. I. Hyder, J. F. Werth, and J. C. Browne, </author> <title> A Unified Model for Concurrent Debugging, </title> <booktitle> Proc. International Conference on Parallel Processing, </booktitle> <month> July </month> <year> 1993. </year>
Reference-contexts: It also facilities identification of the logic faults in the program. Efforts are ongoing to implement such a debugger in the context of the CODE system <ref> [Hyd93] </ref>. The example which follows illustrates how the visual directed graph representation of a program supports both the problem formulation and the analysis steps of parallel debugging. As before, the program is a directed graph whose nodes are sites for the execution of atomic actions.
Reference: [Jai91] <author> R. Jain, J. Werth, and J. C. Browne, </author> <title> An Experimental Study of the Effectiveness of High Level Parallel Programming, </title> <booktitle> Proc. 5th SIAM Conf. Par. Pro cessing, </booktitle> <year> 1991. </year>
Reference-contexts: CODE 1.x J.C. Browne has been investigating computation graph systems for many years. The general advantages of such systems and the outline of a model of parallel computation are presented in [Bro85], and Browne and his students also developed several earlier versions of CODE <ref> [Bro89, Jai91] </ref>. These form the intellectual basis for the current version but are much less capable. CODE 1.2 served as the basis for experiments in reuse within the context of a graph model [Lee89, Bro90].
Reference: [Kar66] <author> R .M. Karp and R. E. Miller, </author> <title> Properties of a Model for Parallel Computations: determinacy, Termination, and Queueing, </title> <journal> SIAM J. Appl. Math., </journal> <volume> Vol. 14, No. 6, </volume> <month> Nov. </month> <year> 1966. </year>
Reference-contexts: We will focus on visual parallel programming languages. 7.1 Older Systems and Proposals CODE and HeNCE are certainly not the first systems to be designed for visual programming of parallel systems via graphs that show parallel structure. This sections surveys some of the earlier attempts. Karp and Miller <ref> [Kar66] </ref> proposed a graph-based model of parallel computation that includes non-fixed firing conditions. The model also permits proof of determinacy and useful theorems on computation terminations and bounding the size of queues on arcs.
Reference: [Kel81] <author> R. M. Keller, and W.-C. J. Yen, </author> <title> A Graphical Approach to Software Development using Function Graphs, </title> <booktitle> IEEE COMPCON 81, </booktitle> <month> Feb. </month> <pages> 23-26, </pages> <address> San Fran cisco, </address> <year> 1981. </year>
Reference-contexts: This paper argues that significant benefits can be obtained by going a step further and directly expressing parallel programs visually. The concept of visual directed graph programming systems is not new. The first significant system was probably that of Keller and Yen <ref> [Kel81] </ref> in 1981. It is, however, only in recent years that a significant impact from visual directed graph parallel programming languages has been obtained. <p> Adamss model [Ada68] is an early example. Computations are deterministic. There are sophisticated techniques for mapping inputs to outputs, as firing and routing rules do in CODE. Ackerman [Ack82] provides a general discussion of early ideas in dataow languages. Keller and Yen <ref> [Kel81] </ref> discuss directed graph programming and Davis and Keller [Dav82] present a dataow language with special purpose nodes for non-standard firing rules and discuss graph composition. CODE 1.x J.C. Browne has been investigating computation graph systems for many years.
Reference: [Koz90] <editor> D. Kozen, et al., </editor> <title> ALEX An Alexical Programming Language, in Visual Languages and Applications, </title> <editor> T. Ichikawa, E. Jungert, and R .R. Korfhage, eds., </editor> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: There is no hierarchy and no concept of general firing rule guards. Simple dataow nodes wait for data on all input before firing and produce data on all outputs when firing is complete. Functions that nodes run are stored in separate files. ALEX ALEX <ref> [Koz90] </ref> is an interesting functional visual parallel programming language in which the focus is on drawing pictures of data, typically arrays. For example, a matrix multiply program is created by drawing two rectangles that represent input matrices and then drawing a representative row within one and a column within another.
Reference: [Lau90] <author> R. Lauwereins, et al., </author> <title> GRAPE: A CASE Tool for Digital Signal Parallel Pro cessing, </title> <journal> IEEE ASSP Magazine, </journal> <month> Apr. </month> <year> 1990. </year>
Reference: [Lew90] <author> T. G. Lewis and W. Rudd, </author> <title> Architecture of the Parallel Programming Support Environment, </title> <booktitle> Proc. CompCon90, </booktitle> <address> San Francisco, CA, </address> <month> Feb. 26 - Mar 2., </month> <year> 1990. </year>
Reference-contexts: Paralex Paralex [Bab92] is a graphical programming environment with a model similar in expressive power to earlier versions of CODE. However, it incorporates sophisticated facilities for fault tolerance and dynamic load balancing on target architectures such as networks of workstations. PPSE The Parallel Programming Support Environment (PPSE) <ref> [Lew90] </ref> is an ambitious integrated environment for the development of parallel programs. It consists of many tools beginning with a dataow computation graph based graphical programming environment called Parallax [Lew93]. The Parallax language includes hierarchy, dataow (with named) ports, and variable storage nodes.
Reference: [Lew93] <author> T. Lewis and H. El-Rewini, </author> <title> Parallax: A Tool For Parallel Program Schedul ing, </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <pages> pp. 62-72, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: PPSE The Parallel Programming Support Environment (PPSE) [Lew90] is an ambitious integrated environment for the development of parallel programs. It consists of many tools beginning with a dataow computation graph based graphical programming environment called Parallax <ref> [Lew93] </ref>. The Parallax language includes hierarchy, dataow (with named) ports, and variable storage nodes. At this time, firing guards are not yet implemented. This greatly reduces the expressiveness of its model of computation. For now, PPSEs primary role appears to be as a basis for research in scheduling.
Reference: [New92] <author> P. Newton and J.C. Browne, </author> <title> The CODE 2.0 Graphical Parallel Programming Language, </title> <booktitle> Proc. ACM Int. Conf. on Supercomputing, </booktitle> <month> July, </month> <year> 1992. </year>
Reference-contexts: As we shall see later, the two systems used as examples in this paper, HeNCE [Beg91a] and CODE 2.0 <ref> [New93, New92] </ref>, demonstrate that in at least some circumstances, competitively efficient code can be generated from the abstract specifications of interactions.
Reference: [New93] <author> P. </author> <title> Newton, A Graphical Retargetable Parallel Programming Environment and Its Efficient Implementation, </title> <type> Technical Report TR93-28, </type> <institution> Dept. of Computer Sciences, Univ. of Texas at Austin, </institution> <year> 1993. </year>
Reference-contexts: As we shall see later, the two systems used as examples in this paper, HeNCE [Beg91a] and CODE 2.0 <ref> [New93, New92] </ref>, demonstrate that in at least some circumstances, competitively efficient code can be generated from the abstract specifications of interactions.
Reference: [Pat90] <author> David A. Patterson and John L. Hennessy, </author> <title> Computer Architecture: a Quantita tive Approach, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <title> Visual Programming and Parallel Computing 36 </title>
Reference-contexts: 1.0 Introduction During the past 15 years microprocessor performance has improved dramatically in com parison to the performance of larger systems <ref> [Pat90] </ref>. From a hardware point of view, this trend has made parallel computers increasingly attractive since high-performance machines can be built by combining large numbers of microprocessors that have been bought at commodity prices.
Reference: [Ros93] <author> J. Rost, </author> <title> D 2 R: A Dynamic Dataow Representation for Task Scheduling, </title> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 28., No. 8, </volume> <month> August, </month> <year> 1993. </year>
Reference-contexts: The language supports non-determinism since tokens can ow to varying sets of boxes, each of which would enable a different N-party interaction. The system non-deterministically chooses. The language supports indexed replication, somewhat like HeNCEs. D 2 R D 2 R (Dynamic Dataow Representation) <ref> [Ros93] </ref> is a recent model that bears much resemblance to HeNCE. However, it appears to have an orientation towards scheduling research. It has been implemented on a multi-transputer system called DAMP [Bau91]. As with older versions of HeNCE, the language has both a textual and a graphical representation.
Reference: [Sny85] <author> L. Synder, </author> <title> Poker 3.1: A Programmers Reference Guide, </title> <institution> Dept. of Comp. Sci. </institution> <type> Technical Report TR-85-09-03, </type> <institution> University of Washington, </institution> <address> Seattle, WA. </address>
Reference-contexts: Programs consist of a combination of control ow and dataow graphs. Phred heavily inuenced HeNCE. Neptune Visual Programming and Parallel Computing 31 Neptune [Tra90] is a computation graph based graphical programming environment that is similar in most respects to older versions of CODE. Poker Poker <ref> [Sny85] </ref> is noteworthy as an early graphical parallel programming environment. It is, however, a fairly distant relative of CODE and HeNCE. It graphical displays lattices of virtual processing elements and allows these nodes to be annotated with a sequential algorithm.
Reference: [Sto90] <author> P. D. Stotts, </author> <title> Graphical Operational Semantics for Visual Parallel Programming, in Visual Languages and Visual Programming, </title> <editor> S.-K. Chang, ed., </editor> <publisher> Ple num Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: In conjunction with library routines for multiplication and addition, the diagram is then extended to show how to form the resulting matrix from the rows and columns of the input matrices. PFG PFG is a graphical parallel programming language whose formal operational semantics are described by HG <ref> [Sto90] </ref>. Like HeNCE, it uses special icons to create constructs that control node execution. It has facilities for parallel branching (generalized conditional branching) and non-deterministic branching.
Reference: [TGS92] <institution> TGS Systems Limited, Prograph Reference, Halifax, Nova Scotia, Canada, </institution> <year> 1992. </year>
Reference-contexts: It also provides a unified framework for supporting different concurrent debugging facilities like execution history displays, animation, and model checking facilities. Visual Programming and Parallel Computing 30 7.0 Related Work There has been much work on visual programming languages and environments for sequential systems. Prograph <ref> [TGS92] </ref> and PICT [Gli84] are substantial examples. We will focus on visual parallel programming languages. 7.1 Older Systems and Proposals CODE and HeNCE are certainly not the first systems to be designed for visual programming of parallel systems via graphs that show parallel structure.
Reference: [Tra90] <author> B. Traversat, NEPTUNE: </author> <title> The Application of Course-Grain Data Flow Methods to Scientific Parallel Programming, </title> <type> Ph.D. dissertation, </type> <institution> The Florida State University, </institution> <year> 1990. </year>
Reference-contexts: It uses graph grammars in its language definition and special nodes for firing rules, computations, and some runtime determined computation structures. Programs consist of a combination of control ow and dataow graphs. Phred heavily inuenced HeNCE. Neptune Visual Programming and Parallel Computing 31 Neptune <ref> [Tra90] </ref> is a computation graph based graphical programming environment that is similar in most respects to older versions of CODE. Poker Poker [Sny85] is noteworthy as an early graphical parallel programming environment. It is, however, a fairly distant relative of CODE and HeNCE.
Reference: [Yan91] <author> T. Yang and A. Gerasoulis, </author> <title> A Fast Static Scheduling Algorithm for DAGs on an Unbounded Number of Processors, </title> <booktitle> Proceedings of Supercomputing 91, </booktitle> <pages> pages 633642, </pages> <address> Albuquerque, </address> <year> 1991. </year>
Reference-contexts: This is also true when sending to two different processes that have been assigned to the same physical processor. Scheduling The simpler incarnations of such graph models also lend themselves to the use of advanced scheduling techniques <ref> [Yan91] </ref> since the components are often arranged into directed acyclic graphs (or directed acyclic subgraphs can be found) and the execution times of components is often fixed from invocation to invocation. Furthermore execution characteristic of sequential elements are easier to define and measure since they are encapsulated.
References-found: 33

