URL: http://www.cs.umass.edu/~gao/cbtlb.ps
Refering-URL: http://www.cs.umass.edu/~gao/
Root-URL: 
Title: On Balancing Computational Load on Rings of Processors  
Author: L. Gao A. L. Rosenberg 
Address: Amherst, Mass. 01003, USA Amherst, Mass. 01003, USA  
Affiliation: Department of Computer Science Department of Computer Science University of Massachusetts University of Massachusetts  
Abstract: We consider a simple, deterministic policy for scheduling certain genres of dynamically evolving computations | specifically, computations in which tasks that spawn produce precisely two offspring | on rings of processors. Such computations include, for instance, tree-structured branching computations. We believe that our policy yields good parallel speedup on most computations of the genre, but we have not yet been able to verify this. In the current paper, we show that when the evolving computations end up having the structure of complete binary trees or of two- dimensional pyramidal grids, our strategy yields almost optimal parallel speedup. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho, J.E. Hopcroft, J.D. </author> <title> Ullman (1974): The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass. </address>
Reference-contexts: Therefore, W i (n) = `=0 n1 X X j : Elementary manipulations simplify this double summation to yield equation (2.1). To obtain the more perspicuous bound (2.2) on W i (n), which gauges the actual workshares' deviations from the ideal workshare, we use the Discrete Fourier Transform (DFT) <ref> [1] </ref>.
Reference: [2] <author> S.N. Bhatt and J.-Y. </author> <title> Cai (1988): Taking random walks to grow trees in hypercubes. </title> <editor> J. </editor> <booktitle> ACM 40, </booktitle> <pages> 741-764. </pages>
Reference-contexts: Part of our challenge will be to balance loads in a network whose high diameter (apparently) precludes some of the balancing state- gies that have proven efficient in low-diameter networks such as the hypercube <ref> [2] </ref> and butterfly [10].
Reference: [3] <author> R.P. </author> <title> Brent (1974): The parallel evaluation of gen-eral arithmetic expressions. </title> <editor> J. </editor> <booktitle> ACM 21, </booktitle> <pages> 201-206. </pages>
Reference-contexts: The problem of balancing computational loads so as to approach this goal has received considerable attention since the advent of (even the promise of) parallel computers (cf. <ref> [3] </ref>). In this paper, we describe a simple strategy that we believe balances and schedules loads well for a variety of dynamically evolving computations, on parallel architectures whose underlying structure is a ring of identical processors.
Reference: [4] <author> P. Fizzano, D. Karger, C. Stein, J. </author> <title> Wein (1994): Job scheduling in rings. </title> <booktitle> 6th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> 210-219. </pages>
Reference-contexts: Part of our challenge will be to balance loads in a network whose high diameter (apparently) precludes some of the balancing state- gies that have proven efficient in low-diameter networks such as the hypercube [2] and butterfly [10]. On the other hand, there is a distributed scheduling scheme <ref> [4] </ref> which is proven to be constant factor of optimal for a set of static jobs in the rings, that is, jobs are not generated dynamically while computation is in progress. 1.3 Our Load-Balancing Problem The Architecture. We focus here on rings of identical processors (PEs, for short).
Reference: [5] <author> A. Gerasoulis and T. </author> <title> Yang (1992): A comparison of clustering heuristics for scheduling dags on mul-tiprocessors. </title> <editor> J. </editor> <booktitle> Parallel and Distr. </booktitle> <publisher> Comput. </publisher>
Reference: [6] <author> S.L. </author> <title> Johnsson (1987): Communication efficient ba-sic linear algebra computations on hypercube ar-chitectures. </title> <journal> J. Parallel Distr. Comput. </journal> <volume> 4, </volume> <pages> 133-172. </pages>
Reference: [7] <author> R.M. Karp and Y. </author> <title> Zhang (1988): Randomized par-allel algorithms for backtrack search and branchand-bound computation. </title> <editor> J. </editor> <booktitle> ACM 40, </booktitle> <pages> 765-789. </pages>
Reference: [8] <author> R. Luling and B. </author> <title> Monien (1993): A dynamic, dis-tributed load-balancing algorithm with provable good performance. </title> <booktitle> 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> 164-172. </pages>
Reference-contexts: evolving computations that end up having have the structure of complete binary trees or of two-dimensional pyramidal grids. 1.2 Background It is easy to show that the naive notion of "load balancing," which insists only that all of the parallel computers' processors perform (roughly) the same amount of work (cf. <ref> [8, 11] </ref>) is inadequate since, in pathological computations, the processors could all perform their work seriatim, so that one achieves no speedup over a sequential computer. Therefore, we insist here (with, say, [10]), that (almost) all processors be occupied doing fruitful work (almost) all of the time.
Reference: [9] <author> R. Luling, B. Monien, F. </author> <title> Ramme (1990): Loadbalancing in large networks: a comparative study. </title> <institution> Typescript, Univ. Paderborn. </institution>
Reference: [10] <author> A.G. </author> <title> Ranade (1994): Optimal speedup for back-track search on a butterfly network. </title> <journal> Math. Syst. Theory 27, </journal> <pages> 85-101. </pages>
Reference-contexts: Therefore, we insist here (with, say, <ref> [10] </ref>), that (almost) all processors be occupied doing fruitful work (almost) all of the time. This will guarantee that the computation of interest is sped up by a factor of (roughly) p when executed on a p- processor machine | which is, of course, the most one could hope for. <p> Part of our challenge will be to balance loads in a network whose high diameter (apparently) precludes some of the balancing state- gies that have proven efficient in low-diameter networks such as the hypercube [2] and butterfly <ref> [10] </ref>. On the other hand, there is a distributed scheduling scheme [4] which is proven to be constant factor of optimal for a set of static jobs in the rings, that is, jobs are not generated dynamically while computation is in progress. 1.3 Our Load-Balancing Problem The Architecture.
Reference: [11] <author> L. Rudolph, M. Slivkin, E. </author> <title> Upfal (1991): A sim-ple load balancing scheme for task allocation in parallel machines. </title> <booktitle> 3rd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> 237-244. </pages>
Reference-contexts: evolving computations that end up having have the structure of complete binary trees or of two-dimensional pyramidal grids. 1.2 Background It is easy to show that the naive notion of "load balancing," which insists only that all of the parallel computers' processors perform (roughly) the same amount of work (cf. <ref> [8, 11] </ref>) is inadequate since, in pathological computations, the processors could all perform their work seriatim, so that one achieves no speedup over a sequential computer. Therefore, we insist here (with, say, [10]), that (almost) all processors be occupied doing fruitful work (almost) all of the time.
References-found: 11

