URL: http://www.cs.iastate.edu/~lutz/p10.ps
Refering-URL: http://www.cs.iastate.edu/~lutz/papers.html
Root-URL: http://www.cs.iastate.edu
Title: Completeness and Weak Completeness under Polynomial-Size Circuits  
Author: David W. Juedes Jack H. Lutz 
Address: Athens, Ohio 45701 U.S.A.  Ames, Iowa 50011 U.S.A.  
Affiliation: School of Electrical Engineering and Computer Science Ohio University  Department of Computer Science Iowa State University  
Abstract: This paper investigates the distribution and nonuniform complexity of problems that are complete or weakly complete for ESPACE under nonuniform reductions that are computed by polynomial-size circuits (P/Poly-Turing reductions and P/Poly-many-one reductions). A tight, exponential lower bound on the space-bounded Kolmogorov complexities of weakly P/Poly-Turing-complete problems is established. A Small Span Theorem for P/Poly-Turing reductions in ESPACE is proven and used to show that every P/Poly-Turing degree | including the complete degree | has measure 0 in ESPACE. (In contrast, it is known that almost every element of ESPACE is weakly P-many-one complete.) Every weakly P/Poly-many-one-complete problem is shown to have a dense, exponential, nonuniform complexity core. More importantly, the P/Poly-many-one-complete problems are shown to be unusually simple elements of ESPACE, in the sense that they obey nontrivial upper bounds on nonuniform complexity (size of nonuniform complexity cores and space-bounded Kolmogorov complexity) that are violated by almost every element of ESPACE. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai and R. Fagin, </author> <title> Reachability is harder for directed than for undirected graphs, </title> <journal> Journal of Symbolic Logic 55 (1990), </journal> <pages> pp. 113-150. </pages>
Reference-contexts: The complement of a set X of languages is X c = P (f0; 1g fl ) X. Our proof of the Small Span Theorem uses the following theorem of probability theory. Lemma 2.1 (Large Deviation Lemma | Ajtai and Fagin <ref> [1] </ref>). Let c = 1 864 , let b 0 ; : : : ; b n1 be 0/1 - valued random variables, and let N (n) = jfij0 i &lt; n and b i = 1gj.
Reference: [2] <author> E. Allender and R. Rubinstein, </author> <title> P-printable sets, </title> <journal> SIAM Journal on Computing 17 (1988), </journal> <pages> pp. 1193-1202. </pages>
Reference: [3] <author> E. W. Allender, </author> <title> Some consequences of the existence of pseudorandom generators, </title> <journal> Journal of Computer and System Sciences 39 (1989), </journal> <pages> pp. 101-124. </pages>
Reference: [4] <author> E. W. Allender and O. Watanabe, </author> <title> Kolmogorov complexity and degrees of tally sets, </title> <booktitle> Information and Computation 86 (1990), </booktitle> <pages> pp. 160-178. </pages>
Reference: [5] <author> K. Ambos-Spies, H.-C. Neis, and S. A. Terwijn, </author> <title> Genericity and measure for exponential time, </title> <note> Theoretical Computer Science, to appear. See also Proceedings of the 19 th Symposium on Mathematical Foundations of Computer Science, </note> <year> 1994, </year> <pages> pp. 221-232. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Some initial steps in this investigation have already been taken. Lindner [34] adapted the method of [26] to prove Small Span Theorems for P 1tt -reductions in E and E 2 . Ambos-Spies, Neis, and Terwijn <ref> [5] </ref> used resource-bounded genericity to generalize the method of [26], thereby obtaining Small Span Theorems for P ktt -reductions in E and E 2 for all positive integers k. In section 4, we prove the Small Span Theorem for P=Poly T -reductions in ESPACE. <p> As noted in the introduction, these problems are closely related to fundamental questions of complexity theory, so they may be very difficult. More modest, but nevertheless useful, 36 objectives, would be to (i) investigate whether the work of Ambos-Spies, Neis, and Terwijn <ref> [5] </ref> can be extended to obtain Small Span Theorems for unbounded query reductions in E and E 2 ; and (ii) find complexity-theoretic characterizations of the Small Span Theorems for P T -reductions and P=Poly T -reductions in E and E 2 .
Reference: [6] <author> K. Ambos-Spies, S. A. Terwijn, and Zheng Xizhong, </author> <title> Resource bounded randomness and weakly complete problems, </title> <booktitle> Theoretical Computer Science, to appear. See also Proceedings of the Fifth Annual International Symposium on Algorithms and Computation, </booktitle> <year> 1994, </year> <pages> pp. 369-377. </pages> <publisher> Springer-Verlag. </publisher> <pages> 37 </pages>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>. <p> Our Small Span Theorem immediately implies that every P=Poly T -degree has measure 0 in ESPACE. It also implies (in combination with a result of Juedes [25] and Ambos-Spies, Terwijn, and Zheng <ref> [6] </ref>) that there are languages that are weakly P m -complete, but not P=Poly T -complete, for ESPACE. In section 5, we investigate the nonuniform complexities of languages that are complete or weakly complete for ESPACE under P=Poly m -reductions. <p> It was subsequently proven by Juedes [25] that the set of such languages 8 does not have measure 0 in E, and by Ambos-Spies, Terwijn, and Zheng <ref> [6] </ref> that the set of such languages has measure 1 in E. All these proofs are easily modified to apply to such larger classes as E 2 and ESPACE. We thus have the following. Theorem 2.3 (Ambos-Spies, Terwijn, and Zheng [6]). <p> measure 0 in E, and by Ambos-Spies, Terwijn, and Zheng <ref> [6] </ref> that the set of such languages has measure 1 in E. All these proofs are easily modified to apply to such larger classes as E 2 and ESPACE. We thus have the following. Theorem 2.3 (Ambos-Spies, Terwijn, and Zheng [6]). Almost every language in ESPACE is weakly P m -complete for ESPACE. 3 The Distribution of Nonuniform Complexity in ESPACE In this section we investigate the distribution of languages that have high nonuniform complexity.
Reference: [7] <author> J. L. Balcazar and R. V. </author> <title> Book, Sets with small generalized Kolmogorov complexity, </title> <journal> Acta Informatica 23 (1986), </journal> <pages> pp. 679-688. </pages>
Reference: [8] <author> J. L. Balcazar and U. Schoning, </author> <title> Bi-immune sets for complexity classes, </title> <booktitle> Mathematical Systems Theory 18 (1985), </booktitle> <pages> pp. 1-10. </pages>
Reference-contexts: Second, we show that, for all c 2 N, almost every language in ESPACE has f0; 1g fl as a DSPACE (2 cn )/Poly-complexity core. (A language is P-bi-immune if and only if it has f0; 1g fl as a P-complexity core <ref> [8] </ref>, so this can be regarded as a very strong bi-immunity property.) In section 4, we investigate the complexity and distribution of languages that are complete or weakly complete for ESPACE under P=Poly T -reductions.
Reference: [9] <author> L. Berman and J. Hartmanis, </author> <title> On isomorphism and density of NP and other complete sets, </title> <journal> SIAM Journal on Computing 6 (1977), </journal> <pages> pp. 305-322. </pages>
Reference: [10] <author> P. Billingsley, </author> <title> Probability and Measure, second edition, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: The probability of this cylinder in the sample space ADV is defined to be Pr (CYL (h 0 )) = n=0 This probability measure is then extended to a complete probability measure on ADV in the usual way <ref> [19, 10] </ref>. In the proof of the following theorem, we work in the sample space = ADV fi P (f0; 1g fl ) with the product probability measure, where probability on ADV is defined as above and we use the uniform distribution on P (f0; 1g fl ).
Reference: [11] <author> R. Book and D.-Z. Du, </author> <title> The existence and density of generalized complexity cores, </title> <journal> Journal of the ACM 34 (1987), </journal> <pages> pp. 718-730. </pages>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
Reference: [12] <author> R. Book, D.-Z Du, and D. Russo, </author> <title> On polynomial and generalized complexity cores, </title> <booktitle> Proceedings of the Third Structure in Complexity Theory Conference, </booktitle> <year> 1988, </year> <pages> pp. 236-250. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
Reference: [13] <author> G. J. Chaitin, </author> <title> On the length of programs for computing finite binary sequences, </title> <journal> Journal of the Association for Computing Machinery 13 (1966), </journal> <pages> pp. 547-569. </pages>
Reference-contexts: The meanings of "efficiently" and "almost all" are parameters of this definition that may be varied according to the context. Space-bounded Kolmogorov complexity is our second measure of nonuniform complexity. Kol-mogorov complexity was introduced by Solomonoff [55], Kolmogorov [31], and Chaitin <ref> [13] </ref>. Resource-bounded Kolmogorov complexity has been investigated extensively [31, 20, 53, 33, 35, 7, 22, 30, 2, 3, 4, 36, 38, etc.]. We work with the space-bounded Kolmogorov complexity of languages.
Reference: [14] <author> S. A. Cook, </author> <title> The complexity of theorem proving procedures, </title> <booktitle> Proceedings of the Third ACM Symposium on the Theory of Computing, </booktitle> <year> 1971, </year> <pages> pp. 151-158. </pages> <institution> Association for Computing Machinery. </institution>
Reference-contexts: These are the P/Poly-Turing reductions ( P=Poly T -reductions) and the P/Poly-many-one reductions ( P=Poly m -reductions). These are natural nonuniform extensions of the polynomial-time Turing reductions ( P T -reductions, introduced by Cook <ref> [14] </ref>) and the polynomial-time many-one reductions ( P m -reductions, introduced by Karp [29] and Levin [32]), respectively. The P=Poly T -reductions (respectively, P=Poly m -reductions), are precisely those nonuniform Turing (respectively, many-one) reductions that can be computed by polynomial-size circuits.
Reference: [15] <author> D.-Z. Du, </author> <title> Generalized complexity cores and levelability of intractable sets, </title> <type> PhD thesis, </type> <institution> University of California, Santa Barbara, </institution> <year> 1985. </year>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
Reference: [16] <author> D.-Z. Du and R. </author> <title> Book, On inefficient special cases of NP-complete problems, </title> <booktitle> Theoretical Computer Science 63 (1989), </booktitle> <pages> pp. 239-252. </pages>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
Reference: [17] <author> S. Even, A. Selman, and Y. Yacobi, </author> <title> Hard core theorems for complexity classes, </title> <journal> Journal of the ACM 35 (1985), </journal> <pages> pp. 205-217. </pages>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
Reference: [18] <author> S. A. Fenner, J. H. Lutz, and E. Mayordomo, </author> <title> Weakly useful sequences, </title> <booktitle> Proceedings of the 22 nd International Colloquium on Automata, Languages, and Programming, </booktitle> <year> 1995, </year> <pages> pp. 393-404. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: We now prove the Small Span Theorem for P=Poly T -reductions in ESPACE. Our proof is a nonuniform, space-bounded extension of a technique used by Fenner, Lutz, and Mayordomo <ref> [18] </ref> in the investigation of computational depth. Theorem 4.5 (Small Span Theorem). For every A 2 ESPACE, ((P=Poly) T (A) j ESPACE) = 0 or pspace ((P=Poly) 1 T (A)) = ((P=Poly) 1 T (A) j ESPACE) = 0: Proof.
Reference: [19] <author> P. R. Halmos, </author> <title> Measure Theory, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1950. </year>
Reference-contexts: The probability of this cylinder in the sample space ADV is defined to be Pr (CYL (h 0 )) = n=0 This probability measure is then extended to a complete probability measure on ADV in the usual way <ref> [19, 10] </ref>. In the proof of the following theorem, we work in the sample space = ADV fi P (f0; 1g fl ) with the product probability measure, where probability on ADV is defined as above and we use the uniform distribution on P (f0; 1g fl ).
Reference: [20] <author> J. Hartmanis, </author> <title> Generalized Kolmogorov complexity and the structure of feasible computations, </title> <booktitle> Proceedings of the 24th IEEE Symposium on the Foundations of Computer Science, </booktitle> <year> 1983, </year> <pages> pp. 439-445. </pages> <institution> Institute of Electrical and Electronics Engineers. </institution> <month> 38 </month>
Reference: [21] <author> J. Hartmanis and Y. Yesha, </author> <title> Computation times of NP sets of different densities, </title> <booktitle> Theoretical Computer Science 34 (1984), </booktitle> <pages> pp. 17-32. </pages>
Reference-contexts: For example, ESPACE is not contained in P/Poly [28], but the relationships among NP, E, and P/Poly are not known. Our second reason for this choice is that the structure of ESPACE is closely related to the structure of important polynomial complexity classes. For example, Hartmanis and Yesha <ref> [21] </ref> have shown that E $ ESPACE () P $ P=Poly " PSPACE: (1:1) This, together with the first reason, suggests that the separation of P from PSPACE might best be achieved by separating E from ESPACE.
Reference: [22] <author> D. T. Huynh, </author> <title> Resource-bounded Kolmogorov complexity of hard languages, Structure in Complexity Theory, </title> <booktitle> 1986, </booktitle> <pages> pp. 184-195, </pages> <address> Berlin. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: We establish a tight, exponential lower bound on the space-bounded Kolmogorov complexities of languages that are weakly P=Poly T - complete for ESPACE. Specifically, we prove that for every such language H, there exists * &gt; 0 such that KS 2 n * a.e. (1:3) This extends Huynh's proof <ref> [22] </ref> that (1.3) holds for every language H that is P T -complete for ESPACE. In section 4, we also prove a Small Span Theorem for P=Poly T -reductions in ESPACE. This result requires some explanation. <p> This latter result implies that the set of all P=Poly T -hard languages for ESPACE has pspace-measure 0, and that every P=Poly T -degree has measure 0 in ESPACE. The following theorem extends a result of Huynh <ref> [22] </ref>. Theorem 4.1. For every weakly P=Poly T -hard language H for ESPACE, there exists * &gt; 0 such that KS 2 n * a.e. Proof. <p> m m a.e., and the length of hh (0); : : :; h (m)i is bounded by q (m) for some polynomial q, it follows that KS 2 n * (A m ) q (m) c 1 q &gt; 2 n * This completes the proof. 2 Corollary 4.2 (Huynh <ref> [22] </ref>).
Reference: [23] <author> D. T. Huynh, </author> <title> On solving hard problems by polynomial-size circuits, </title> <booktitle> Information Processing Letters 24 (1987), </booktitle> <pages> pp. 171-176. </pages>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K. <p> In section 5, we investigate the nonuniform complexities of languages that are complete or weakly complete for ESPACE under P=Poly m -reductions. Lower bounds on the densities of complexity cores for complete languages have already been proven by Orponen and Schoning [48] and Huynh <ref> [23] </ref>. In particular, Huynh [23] proved that every language that is P m -complete for ESPACE has a dense P/Poly-complexity core. <p> In section 5, we investigate the nonuniform complexities of languages that are complete or weakly complete for ESPACE under P=Poly m -reductions. Lower bounds on the densities of complexity cores for complete languages have already been proven by Orponen and Schoning [48] and Huynh <ref> [23] </ref>. In particular, Huynh [23] proved that every language that is P m -complete for ESPACE has a dense P/Poly-complexity core. <p> A machine/advice pair M=h is consistent with a language A f0; 1g fl if M=h (x) [[x 2 A]] for all x 2 f0; 1g fl . Nonuniform complexity cores were first defined and investigated by Huynh <ref> [23] </ref> with respect to the complexity class P/Poly. Definition (Huynh [23]). Let s : N ! N be a space bound and let A; K f0; 1g fl . Then K is a DSPACE (s (n))/Poly-complexity core of A if, for every c 2 N the following holds. <p> A machine/advice pair M=h is consistent with a language A f0; 1g fl if M=h (x) [[x 2 A]] for all x 2 f0; 1g fl . Nonuniform complexity cores were first defined and investigated by Huynh <ref> [23] </ref> with respect to the complexity class P/Poly. Definition (Huynh [23]). Let s : N ! N be a space bound and let A; K f0; 1g fl . Then K is a DSPACE (s (n))/Poly-complexity core of A if, for every c 2 N the following holds. <p> All the above bounds are shown to be tight. The following theorem extends work of Huynh <ref> [23] </ref>, who showed that every P m -hard language for ESPACE has a dense P/Poly-complexity core. <p> Thus K is a DSPACE (2 n * )/Poly-complexity core of H. 2 Corollary 5.2 (Huynh <ref> [23] </ref>). Every P m -hard language for ESPACE has a dense P/Poly-complexity core. 2 The following result shows that Theorem 5.1 cannot be significantly improved, even if we restrict attention to languages that are P m -complete for ESPACE. Fact 5.3.
Reference: [24] <author> D. W. Juedes, </author> <title> The Complexity and Distribution of Computationally Useful Problems, </title> <type> PhD thesis, </type> <institution> Iowa State University, </institution> <year> 1994. </year>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>.
Reference: [25] <author> D. W. Juedes, </author> <title> Weakly complete problems are not rare, Computational Complexity, </title> <note> to appear. </note>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>. <p> Our Small Span Theorem immediately implies that every P=Poly T -degree has measure 0 in ESPACE. It also implies (in combination with a result of Juedes <ref> [25] </ref> and Ambos-Spies, Terwijn, and Zheng [6]) that there are languages that are weakly P m -complete, but not P=Poly T -complete, for ESPACE. In section 5, we investigate the nonuniform complexities of languages that are complete or weakly complete for ESPACE under P=Poly m -reductions. <p> The existence of languages that are weakly P m -complete, but not P m -complete for E was first proven by Lutz [39]. It was subsequently proven by Juedes <ref> [25] </ref> that the set of such languages 8 does not have measure 0 in E, and by Ambos-Spies, Terwijn, and Zheng [6] that the set of such languages has measure 1 in E. All these proofs are easily modified to apply to such larger classes as E 2 and ESPACE.
Reference: [26] <author> D. W. Juedes and J. H. Lutz, </author> <title> The complexity and distribution of hard problems, </title> <journal> SIAM Journal on Computing 24 (1995), </journal> <pages> pp. 279-295. </pages>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>. <p> polynomial ), and ESPACE = DSPACE (2 linear ), that have well-understood measure structure, Lutz [39] has shown that weak P m -completeness is a proper generalization of P m -completeness. (See sections 2 and 3 for precise definitions of notation and terminology used in this introduction.) Juedes and Lutz <ref> [26] </ref> began the systematic investigation of the complexity and distribution of problems that are P m -complete or weakly P m -complete for the exponential time complexity classes E and E 2 . Main results of [26] (in the case of E) include (i) a proof that every weakly P m <p> for precise definitions of notation and terminology used in this introduction.) Juedes and Lutz <ref> [26] </ref> began the systematic investigation of the complexity and distribution of problems that are P m -complete or weakly P m -complete for the exponential time complexity classes E and E 2 . Main results of [26] (in the case of E) include (i) a proof that every weakly P m -complete problem for E has a dense exponential complexity core; (ii) a proof that almost every problem in E has f0; 1g fl as an exponential complexity core; (iii) a proof that (essentially) every exponential complexity <p> (A), R 1 (A) is negligibly small in C. (Specifically, R (A) has measure 0 in C, or R 1 (A) has -measure 0, hence measure 0 in C, where is the resource bound that induces measure structure in C.) The first Small Span Theorem, proven by Juedes and Lutz <ref> [26] </ref>, was for P m -reductions in the exponential time complexity class E = DTIME (2 linear ). This result says that, for every A 2 E, P m (A) has measure 0 in E, or P 1 m (A) has p-measure 0, hence measure 0 in E. <p> An immediate consequence of this fact is that every P m -degree | including the complete P m -degrees for E, NP, PSPACE, etc. | has measure 0 in E. Juedes and Lutz <ref> [26] </ref> also proved the Small Span Theorem for P m -reductions in the exponential time complexity class E 2 = DTIME (2 polynomial ). <p> The task now confronting us is to determine the extent to which Small Span Theorems hold for stronger types of efficient reductions. This task is important and nontrivial because it is closely related to some of the most fundamental questions of complexity theory. For example, Juedes and Lutz <ref> [26] </ref> have pointed out that a Small Span Theorem for P T -reductions in E or E 2 would imply 4 that BPP$E 2 . <p> It is thus to be hoped that a systematic investigation of Small Span Theorems will shed useful light on such fundamental questions. Some initial steps in this investigation have already been taken. Lindner [34] adapted the method of <ref> [26] </ref> to prove Small Span Theorems for P 1tt -reductions in E and E 2 . Ambos-Spies, Neis, and Terwijn [5] used resource-bounded genericity to generalize the method of [26], thereby obtaining Small Span Theorems for P ktt -reductions in E and E 2 for all positive integers k. <p> Some initial steps in this investigation have already been taken. Lindner [34] adapted the method of <ref> [26] </ref> to prove Small Span Theorems for P 1tt -reductions in E and E 2 . Ambos-Spies, Neis, and Terwijn [5] used resource-bounded genericity to generalize the method of [26], thereby obtaining Small Span Theorems for P ktt -reductions in E and E 2 for all positive integers k. In section 4, we prove the Small Span Theorem for P=Poly T -reductions in ESPACE. <p> Thus the P=Poly m -complete languages are unusually simple for languages in ESPACE. Although several of our results are similar in form to those of <ref> [26] </ref>, the nonuniform nature of the reductions and complexity measures force us to use quite different methods in the present paper. 2 Preliminaries We write f0; 1g fl for the set of all (finite, binary) strings and f0; 1g 1 for the set of all (infinite, binary) sequences. <p> Proof. Routine calculus shows that the series 1 P 2 n * is p-convergent. 2 Corollary 3.5 is a substantial improvement of Theorem 3.1 (a). We exploit this improvement throughout the paper. 3.2 Complexity Cores The distribution of languages with large uniform complexity cores in E was investigated in <ref> [26] </ref>. In this subsection we investigate the distribution of languages with large nonuniform complexity cores in ESPACE. We first present the necessary notation and definitions. <p> By Lemma 3.6, each element of X has f0; 1g fl as a DSPACE (2 cn )/Poly-complexity core. It follows that almost every language in ESPACE has f0; 1g fl as a DSPACE (2 cn )/Poly-complexity core. 2 3.3 Incompressibility In <ref> [26] </ref> it is shown that almost every language in E is incompressible by P m -reductions. Here we show that almost every language in ESPACE is n log n -incompressible by P=Poly m -reductions. First we explain "incompressibility by many-one reductions," an idea originally exploited by Meyer [46]. Definition. <p> Similar results hold for P m -complete languages for E and E 2 <ref> [26] </ref>. However, it remains an open problem whether there is a natural sense in which the P=Poly T -complete languages for ESPACE are unusually simple elements of ESPACE. Acknowledgments. The second author thanks Elvira Mayordomo and Martin Strauss for useful discussions.
Reference: [27] <author> D. W. Juedes and J. H. Lutz, </author> <booktitle> Weak completeness in E and E 2 , Theoretical Computer Science 143 (1995), </booktitle> <pages> pp. 149-158. </pages>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>.
Reference: [28] <author> R. Kannan, </author> <title> Circuit-size lower bounds and non-reducibility to sparse sets, </title> <booktitle> Information and Control 55 (1982), </booktitle> <pages> pp. 40-56. </pages>
Reference-contexts: There are two related reasons for this choice. First, ESPACE has a rich, well-behaved structure that is well enough understood that we can prove absolute results, unblemished by oracles or unproven hypotheses. In particular, much is known about the Kolmogorov complexities and circuit-size complexities of languages in ESPACE <ref> [28, 38] </ref>, while little is known at lower complexity levels. For example, ESPACE is not contained in P/Poly [28], but the relationships among NP, E, and P/Poly are not known. <p> In particular, much is known about the Kolmogorov complexities and circuit-size complexities of languages in ESPACE [28, 38], while little is known at lower complexity levels. For example, ESPACE is not contained in P/Poly <ref> [28] </ref>, but the relationships among NP, E, and P/Poly are not known. Our second reason for this choice is that the structure of ESPACE is closely related to the structure of important polynomial complexity classes.
Reference: [29] <author> R. M. Karp, </author> <title> Reducibility among combinatorial problems, </title> <editor> In R. E. Miller and J. W. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pp. 85-104. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: These are the P/Poly-Turing reductions ( P=Poly T -reductions) and the P/Poly-many-one reductions ( P=Poly m -reductions). These are natural nonuniform extensions of the polynomial-time Turing reductions ( P T -reductions, introduced by Cook [14]) and the polynomial-time many-one reductions ( P m -reductions, introduced by Karp <ref> [29] </ref> and Levin [32]), respectively. The P=Poly T -reductions (respectively, P=Poly m -reductions), are precisely those nonuniform Turing (respectively, many-one) reductions that can be computed by polynomial-size circuits. The four reduction types that we have mentioned have distinct strengths, even when attention is restricted to languages in ESPACE.
Reference: [30] <author> K. Ko, </author> <title> On the notion of infinite pseudorandom sequences, </title> <booktitle> Theoretical Computer Science 48 (1986), </booktitle> <pages> pp. 9-33. </pages>
Reference: [31] <author> A. N. </author> <title> Kolmogorov, Three approaches to the quantitative definition of `information', </title> <booktitle> Problems of Information Transmission 1 (1965), </booktitle> <pages> pp. 1-7. </pages>
Reference-contexts: The meanings of "efficiently" and "almost all" are parameters of this definition that may be varied according to the context. Space-bounded Kolmogorov complexity is our second measure of nonuniform complexity. Kol-mogorov complexity was introduced by Solomonoff [55], Kolmogorov <ref> [31] </ref>, and Chaitin [13]. Resource-bounded Kolmogorov complexity has been investigated extensively [31, 20, 53, 33, 35, 7, 22, 30, 2, 3, 4, 36, 38, etc.]. We work with the space-bounded Kolmogorov complexity of languages.
Reference: [32] <author> L. A. Levin, </author> <title> Universal sequential search problems, </title> <booktitle> Problems of Information Transmission 9 (1973), </booktitle> <pages> pp. 265-266. </pages>
Reference-contexts: These are natural nonuniform extensions of the polynomial-time Turing reductions ( P T -reductions, introduced by Cook [14]) and the polynomial-time many-one reductions ( P m -reductions, introduced by Karp [29] and Levin <ref> [32] </ref>), respectively. The P=Poly T -reductions (respectively, P=Poly m -reductions), are precisely those nonuniform Turing (respectively, many-one) reductions that can be computed by polynomial-size circuits. The four reduction types that we have mentioned have distinct strengths, even when attention is restricted to languages in ESPACE.
Reference: [33] <author> L. A. Levin, </author> <title> Randomness conservation inequalities; information and independence in mathematical theories, </title> <booktitle> Information and Control 61 (1984), </booktitle> <pages> pp. 15-37. </pages>
Reference: [34] <author> W. Lindner, </author> <title> On the polynomial time bounded measure of one-truth-table degrees and p-selectivity, </title> <institution> Diplomarbeit, Technische Universitat Berlin, </institution> <year> 1993. </year>
Reference-contexts: It is thus to be hoped that a systematic investigation of Small Span Theorems will shed useful light on such fundamental questions. Some initial steps in this investigation have already been taken. Lindner <ref> [34] </ref> adapted the method of [26] to prove Small Span Theorems for P 1tt -reductions in E and E 2 .
Reference: [35] <author> L. Longpre, </author> <title> Resource Bounded Kolmogorov Complexity, a Link Between Computational Complexity and Information Theory, </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <year> 1986, </year> <note> Technical Report TR-86-776. </note>
Reference: [36] <author> J. H. Lutz, </author> <title> Category and measure in complexity classes, </title> <journal> SIAM Journal on Computing 19 (1990), </journal> <pages> pp. 1100-1131. </pages>
Reference-contexts: A complete problem, when it is present, contains complete information about all problems in the class, and this information is organized in such a way as to be accessible by efficient reductions. A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz <ref> [36] </ref> and has recently been a subject of several investigations [26, 42, 41, 39, 25, 6, 27, 24, 45].
Reference: [37] <author> J. H. Lutz, </author> <title> An upward measure separation theorem, </title> <booktitle> Theoretical Computer Science 81 (1991), </booktitle> <pages> pp. 127-135. </pages>
Reference-contexts: Though the lower bounds of Theorem 3.1 have been useful in a variety of applications (see <ref> [37, 38] </ref>, for example), they are not strong enough for our purposes. For this reason, we ask the natural question: Can the almost-everywhere lower bounds of Theorem 3.1 be improved? We first consider Theorem 3.1 (b).
Reference: [38] <author> J. H. Lutz, </author> <title> Almost everywhere high nonuniform complexity, </title> <journal> Journal of Computer and System Sciences 44 (1992), </journal> <pages> pp. 220-258. </pages>
Reference-contexts: 1g fl such that C 2 C and all the problems in fl This work was supported in part by National Science Foundation Grant CCR-9157382, with matching funds from Rockwell International, Microware Systems Corporation, and Amoco Foundation. 1 a non-measure 0 subset of C (in the sense of resource-bounded measure <ref> [38, 40] </ref>) are R -reducible to C. <p> There are two related reasons for this choice. First, ESPACE has a rich, well-behaved structure that is well enough understood that we can prove absolute results, unblemished by oracles or unproven hypotheses. In particular, much is known about the Kolmogorov complexities and circuit-size complexities of languages in ESPACE <ref> [28, 38] </ref>, while little is known at lower complexity levels. For example, ESPACE is not contained in P/Poly [28], but the relationships among NP, E, and P/Poly are not known. <p> First, we show 3 that, for all c 2 N and * &gt; 0, almost every language A in ESPACE satisfies KS 2 cn This improves the 2 n 2 *n lower bound of <ref> [38] </ref>. <p> We very briefly review the fragment of resource-bounded measure that is used in this paper. The reader is referred to <ref> [38, 39] </ref> for motivation and details. <p> Our proof of the Small Span Theorem uses the following uniform, polynomial-space version of the classical first Borel-Cantelli lemma. Theorem 2.2 (Lutz <ref> [38] </ref>). <p> There we prove that almost every language in ESPACE is n log n -incompressible by DSPACE (2 cn )=Poly m -reductions. 3.1 Space-Bounded Kolmogorov Complexity The distribution of languages in ESPACE with high space-bounded Kolmogorov complexity was first investigated in <ref> [38] </ref>. Here we strengthen the results of [38] in two important directions. First, we show that the almost-everywhere lower bound of 2 n+1 2 *n on the space-bounded Kolmogorov complexity KS 2 cn (A n ) is tight and cannot be improved (Theorem 3.3). <p> There we prove that almost every language in ESPACE is n log n -incompressible by DSPACE (2 cn )=Poly m -reductions. 3.1 Space-Bounded Kolmogorov Complexity The distribution of languages in ESPACE with high space-bounded Kolmogorov complexity was first investigated in <ref> [38] </ref>. Here we strengthen the results of [38] in two important directions. First, we show that the almost-everywhere lower bound of 2 n+1 2 *n on the space-bounded Kolmogorov complexity KS 2 cn (A n ) is tight and cannot be improved (Theorem 3.3). <p> We now recall the following almost-everywhere lower bound result. Theorem 3.1 (Lutz <ref> [38] </ref>). Let c 2 N and * &gt; 0. (a) If (A =n ) &gt; 2 n 2 *n a.e.g; then pspace (X) = (X j ESPACE) = 1. (b) If (A n ) &gt; 2 n+1 2 *n a.e.g; then pspace (Y ) = (Y j ESPACE) = 1. <p> Though the lower bounds of Theorem 3.1 have been useful in a variety of applications (see <ref> [37, 38] </ref>, for example), they are not strong enough for our purposes. For this reason, we ask the natural question: Can the almost-everywhere lower bounds of Theorem 3.1 be improved? We first consider Theorem 3.1 (b). <p> Since deg P=Poly T (A) = P=Poly T (B), this completes the proof. 2 Finally, we note that Theorem 4.8 generalizes the following known result. Corollary 4.9 (Lutz <ref> [38] </ref>). (P=Poly j ESPACE) = 0. 5 Completeness and Weak Completeness Under P/Poly-Many One Reductions We now investigate the nonuniform complexities of languages that are hard or weakly hard for ESPACE under P=Poly m -reductions | nonuniform many-one reductions that are computed by polynomial-size circuits.
Reference: [39] <author> J. H. Lutz, </author> <title> Weakly hard problems, </title> <journal> SIAM Journal on Computing, </journal> <note> to appear. See also Proceedings of the Ninth Structure in Complexity Theory Conference, </note> <year> 1994, </year> <pages> pp. 146-161. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>. <p> For classes such as E = DTIME (2 linear ), E 2 = DTIME (2 polynomial ), and ESPACE = DSPACE (2 linear ), that have well-understood measure structure, Lutz <ref> [39] </ref> has shown that weak P m -completeness is a proper generalization of P m -completeness. (See sections 2 and 3 for precise definitions of notation and terminology used in this introduction.) Juedes and Lutz [26] began the systematic investigation of the complexity and distribution of problems that are P m <p> We very briefly review the fragment of resource-bounded measure that is used in this paper. The reader is referred to <ref> [38, 39] </ref> for motivation and details. <p> The existence of languages that are weakly P m -complete, but not P m -complete for E was first proven by Lutz <ref> [39] </ref>. It was subsequently proven by Juedes [25] that the set of such languages 8 does not have measure 0 in E, and by Ambos-Spies, Terwijn, and Zheng [6] that the set of such languages has measure 1 in E.
Reference: [40] <author> J. H. Lutz, </author> <title> Resource-bounded measure, </title> <note> in preparation. </note>
Reference-contexts: 1g fl such that C 2 C and all the problems in fl This work was supported in part by National Science Foundation Grant CCR-9157382, with matching funds from Rockwell International, Microware Systems Corporation, and Amoco Foundation. 1 a non-measure 0 subset of C (in the sense of resource-bounded measure <ref> [38, 40] </ref>) are R -reducible to C.
Reference: [41] <author> J. H. Lutz and E. Mayordomo, </author> <title> Cook versus Karp-Levin: Separating completeness notions if NP is not small, </title> <note> Theoretical Computer Science, to appear. See also Proceedings of the Eleventh Symposium on Theoretical Aspects of Computer Science, </note> <year> 1994, </year> <pages> pp. 415-426. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>.
Reference: [42] <author> J. H. Lutz and E. Mayordomo, </author> <title> Measure, stochasticity, and the density of hard languages, </title> <journal> SIAM Journal on Computing 23 (1994), </journal> <pages> pp. 762-779. </pages>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>.
Reference: [43] <author> N. Lynch, </author> <title> On reducibility to complex or sparse sets, </title> <journal> Journal of the ACM 22 (1975), </journal> <pages> pp. 341-345. </pages>
Reference-contexts: These are the density of nonuniform complexity cores and space-bounded Kolmogorov complexity. For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch <ref> [43] </ref> and has been investigated by many others [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.].
Reference: [44] <author> P. Martin-Lof, </author> <title> Complexity oscillations in infinite binary sequences, </title> <journal> Zeitschrift fur Wahrschein-lichkeitstheorie und Verwandte Gebiete 19 (1971), </journal> <pages> pp. 225-230. </pages>
Reference-contexts: For this reason, we ask the natural question: Can the almost-everywhere lower bounds of Theorem 3.1 be improved? We first consider Theorem 3.1 (b). Martin-Lof <ref> [44] </ref> has shown that, for every c 2 N and every real a &gt; 1, almost every language A f0; 1g fl has space-bounded Kolmogorov complexity KS 2 cn (In fact, Martin-Lof showed that this holds even in the absence of a space bound.) The following known bounds show that the <p> There exist constants c 1 ; c 2 2 N such that every language A satisfies the following two conditions. (i) KS 2 n 10 (ii) KS 2 c 2 n (Part (i) of Theorem 3.2 is well known and obvious. Part (ii) extends a result of Martin-Lof <ref> [44] </ref>.) Since the bound of Theorem 3.1 (b) is considerably lower than that of (3.1), one might expect to improve Theorem 3.1 (b).
Reference: [45] <author> E. Mayordomo, </author> <title> Contributions to the study of resource-bounded measure, </title> <type> PhD thesis, </type> <institution> Univer-sitat Politecnica de Catalunya, </institution> <year> 1994. </year>
Reference-contexts: A measure-theoretic generalization of completeness, called weak completeness, was proposed by Lutz [36] and has recently been a subject of several investigations <ref> [26, 42, 41, 39, 25, 6, 27, 24, 45] </ref>.
Reference: [46] <author> A. R. Meyer, </author> <year> 1977, </year> <note> reported in [9]. </note>
Reference-contexts: Here we show that almost every language in ESPACE is n log n -incompressible by P=Poly m -reductions. First we explain "incompressibility by many-one reductions," an idea originally exploited by Meyer <ref> [46] </ref>. Definition.
Reference: [47] <author> P. Orponen, </author> <title> A classification of complexity core lattices, </title> <booktitle> Theoretical Computer Science 70 (1986), </booktitle> <pages> pp. 121-130. </pages>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
Reference: [48] <author> P. Orponen and U. Schoning, </author> <title> The density and complexity of polynomial cores for intractable sets, </title> <booktitle> Information and Control 70 (1986), </booktitle> <pages> pp. 54-68. </pages>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K. <p> In section 5, we investigate the nonuniform complexities of languages that are complete or weakly complete for ESPACE under P=Poly m -reductions. Lower bounds on the densities of complexity cores for complete languages have already been proven by Orponen and Schoning <ref> [48] </ref> and Huynh [23]. In particular, Huynh [23] proved that every language that is P m -complete for ESPACE has a dense P/Poly-complexity core.
Reference: [49] <author> N. Pippenger, </author> <title> On simultaneous resource bounds, </title> <booktitle> Proceedings of the 20 th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1979, </year> <pages> pp. 307-311. </pages> <institution> Institute of Electrical and Electronics Engineers. </institution> <month> 40 </month>
Reference-contexts: Using standard techniques <ref> [49] </ref>, it is easy to see that the P=Poly T -reductions (respectively, the P=Poly m -reductions) are precisely those Turing reductions (respectively, many-one reductions) that are computed by polynomial-size circuits. We very briefly review the fragment of resource-bounded measure that is used in this paper.
Reference: [50] <author> A. Razborov and S. Rudich, </author> <title> Natural proofs, </title> <booktitle> Proceedings of the 26 th ACM Symposium on Theory of Computing, </booktitle> <year> 1994, </year> <pages> pp. 204-214. </pages> <publisher> ACM Press. </publisher>
Reference-contexts: More recent work of Regan, Sivakumar, and Cai [51] | building on the "natural proof" work of Razborov and Rudich <ref> [50] </ref> | indicates that a Small Span Theorem for P=Poly T - reductions (nonuniform Turing reductions computed by polynomial-size circuits) in E 2 would imply the nonexistence of pseudorandom generators and one-way functions with exponential nonuniform security.
Reference: [51] <author> K. W. Regan, D. Sivakumar, and J .Cai, </author> <title> On resource-bounded measure and pseudorandom generators, </title> <booktitle> Proceedings of the 36 th Symposium on the Foundations of Computer Science, </booktitle> <year> 1995, </year> <note> to appear. </note>
Reference-contexts: For example, Juedes and Lutz [26] have pointed out that a Small Span Theorem for P T -reductions in E or E 2 would imply 4 that BPP$E 2 . More recent work of Regan, Sivakumar, and Cai <ref> [51] </ref> | building on the "natural proof" work of Razborov and Rudich [50] | indicates that a Small Span Theorem for P=Poly T - reductions (nonuniform Turing reductions computed by polynomial-size circuits) in E 2 would imply the nonexistence of pseudorandom generators and one-way functions with exponential nonuniform security.
Reference: [52] <author> D. A. Russo and P. Orponen, </author> <title> On P-subset structures, </title> <booktitle> Mathematical Systems Theory 20 (1987), </booktitle> <pages> pp. 129-136. </pages>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
Reference: [53] <author> M. Sipser, </author> <title> A complexity-theoretic approach to randomness, </title> <booktitle> Proceedings of the 15th ACM Symposium on Theory of Computing, </booktitle> <year> 1983, </year> <pages> pp. 330-335. </pages> <institution> Association for Computing Machinery. </institution>
Reference: [54] <author> S. Skyum and L. G. Valiant, </author> <title> A complexity theory based on boolean algebra, </title> <journal> Journal of the ACM 32 (1985), </journal> <pages> pp. 484-502. </pages>
Reference-contexts: In the present paper, we conduct a similar investigation, but we now focus on nonuniform reductions that are computed by polynomial-size circuits. Such reductions are "combinatorially efficient," even though they need not be algorithmically computable. As noted by Skyum and Valiant <ref> [54] </ref>, the investigation of such reductions sheds light on the "purely combinatorial" aspects of the completeness phenomenon. We work in the complexity class ESPACE. There are two related reasons for this choice.
Reference: [55] <author> R. J. Solomonoff, </author> <title> A formal theory of inductive inference, </title> <booktitle> Information and Control 7 (1964), </booktitle> <pages> pp. 1-22, 224-254. </pages>
Reference-contexts: The meanings of "efficiently" and "almost all" are parameters of this definition that may be varied according to the context. Space-bounded Kolmogorov complexity is our second measure of nonuniform complexity. Kol-mogorov complexity was introduced by Solomonoff <ref> [55] </ref>, Kolmogorov [31], and Chaitin [13]. Resource-bounded Kolmogorov complexity has been investigated extensively [31, 20, 53, 33, 35, 7, 22, 30, 2, 3, 4, 36, 38, etc.]. We work with the space-bounded Kolmogorov complexity of languages.
Reference: [56] <author> H. Ye, </author> <title> Complexity cores for P/poly, 1990, </title> <type> manuscript. 41 </type>
Reference-contexts: For the first measure, we use the density of a language's "largest" nonuniform complexity core. Intuitively, a complexity core is a set of uniformly hard instances. This concept was introduced by Lynch [43] and has been investigated by many others <ref> [15, 17, 47, 48, 11, 23, 52, 12, 16, 56, etc.] </ref>. Roughly speaking, a complexity core for a language A is a fixed set K of inputs such that every machine whose decisions are consistent with A fails to decide efficiently on almost all elements of K.
References-found: 56

