URL: http://www.neci.nj.nec.com/homepages/sebastien/papers/iws3di95/final.ps.Z
Refering-URL: http://www.neci.nj.nec.com/homepages/sebastien/papers/
Root-URL: 
Email: ingemarjsebastien@research.nj.nec.com  
Title: STATISTICAL MODELLING OF EPIPOLAR MISALIGNMENT  
Author: Ingemar J. Cox and Sebastien Roy 
Address: 4 Independence Way Princeton, NJ 08540, U.S.A.  
Affiliation: NEC Research Institute  
Abstract: We investigate whether epipolar misalignment can be automatically detected and corrected without explicit knowledge of point correspondences. In this regard, the work is closely related to the problem of structure-and-motion from two frames. However, the motion estimation described here is independent of any estimation of the structure of the scene and consequently is expected to be significantly more robust than structure-and-motion algorithms in which the number of unknowns is proportional to the number of pixels in the image. Instead, it may be thought of as forming the basis of a motion-without-structure algorithm, i.e. the solution requires neither knowledge nor estimation of structure or associated properties such as correspondences or flow fields, in order to estimate motion. Of course, structure may be determined by subsequent processing. In particular, we present a method for recovering camera motion for the special cases of (1) known rotation and (2) known translation. The method does not require optical flow fields, feature point correspondences or intensity derivatives. Instead, it relies on a simple statistical characteristic of neighbouring image intensity levels. Specifically, that the variance in intensity between two arbitrary points in an image increases (approximately) monotonically with distance between the two points. Then, it is shown that a simple measure taken across the image can yield a very robust measure of the likelihood of an estimated motion. The likelihood measure allows motion estimation to be cast as an efficient search over the space of possible rotations or translations. The relation between image statistics (textures, etc.) and the accuracy of the estimated motion is discussed and experimental results on real images are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Horn and B. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: In almost all cases, either optical flow or feature points correspondence are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see <ref> [1, 2, 3, 4] </ref>). Even methods using the intensity derivatives directly or normal flow, as in [11, 12, 8, 4, 5, 6, 7], suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10].
Reference: [2] <author> J. L. Barron, D. J. Fleet, and S. S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <journal> Int. J. Computer Vision, </journal> <volume> 2(1) </volume> <pages> 43-77, </pages> <year> 1994. </year>
Reference-contexts: In almost all cases, either optical flow or feature points correspondence are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see <ref> [1, 2, 3, 4] </ref>). Even methods using the intensity derivatives directly or normal flow, as in [11, 12, 8, 4, 5, 6, 7], suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10].
Reference: [3] <author> A. D. Jepson and D. J. Heeger. </author> <title> A fast subspace algorithm for recovering rigid motion. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 124-131, </pages> <address> Princeton, NJ, </address> <year> 1991. </year>
Reference-contexts: In almost all cases, either optical flow or feature points correspondence are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see <ref> [1, 2, 3, 4] </ref>). Even methods using the intensity derivatives directly or normal flow, as in [11, 12, 8, 4, 5, 6, 7], suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10].
Reference: [4] <author> V. Sundareswaran. </author> <title> Egomotion from global flow field data. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 140-145, </pages> <address> Princeton, NJ, </address> <year> 1991. </year>
Reference-contexts: In almost all cases, either optical flow or feature points correspondence are used as the initial measurements. In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see <ref> [1, 2, 3, 4] </ref>). Even methods using the intensity derivatives directly or normal flow, as in [11, 12, 8, 4, 5, 6, 7], suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. <p> In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see [1, 2, 3, 4]). Even methods using the intensity derivatives directly or normal flow, as in <ref> [11, 12, 8, 4, 5, 6, 7] </ref>, suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene. <p> At this point, we observe an irregularity which is an artifact of bi-cubic intensity interpolation. The error in the location of the likelihood minimium is between 1 and 3 quantization units, corresponding to 2:25 to 6:75 degrees of accuracy. These results compare favorably with other methods <ref> [4, 8] </ref> which give a FOE localization error of around 9 degrees. Moreover, it is believed that these results would be improved if a finer quantization search had been performed.
Reference: [5] <author> C. Fermuller. </author> <title> Global 3-d motion estimation. </title> <booktitle> In Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 415-421, </pages> <year> 1993. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see [1, 2, 3, 4]). Even methods using the intensity derivatives directly or normal flow, as in <ref> [11, 12, 8, 4, 5, 6, 7] </ref>, suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene.
Reference: [6] <author> D. Sinclair, A. Blake, and D. Murray. </author> <title> Robust estimation of egomotion from normal flow. </title> <journal> Int. J. Computer Vision, </journal> <volume> 13(1) </volume> <pages> 57-69, </pages> <year> 1994. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see [1, 2, 3, 4]). Even methods using the intensity derivatives directly or normal flow, as in <ref> [11, 12, 8, 4, 5, 6, 7] </ref>, suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene.
Reference: [7] <author> Y. Aloimonos and Z. Duric. </author> <title> Estimating the heading direction using normal flow. </title> <journal> Int. J. Computer Vision, </journal> <volume> 13(1) </volume> <pages> 33-56, </pages> <year> 1994. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see [1, 2, 3, 4]). Even methods using the intensity derivatives directly or normal flow, as in <ref> [11, 12, 8, 4, 5, 6, 7] </ref>, suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene.
Reference: [8] <author> C. Tomasi and J. Shi. </author> <title> Direction of heading from image deformations. </title> <booktitle> In Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 422-427, </pages> <year> 1993. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see [1, 2, 3, 4]). Even methods using the intensity derivatives directly or normal flow, as in <ref> [11, 12, 8, 4, 5, 6, 7] </ref>, suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene. <p> Even methods using the intensity derivatives directly or normal flow, as in [11, 12, 8, 4, 5, 6, 7], suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see <ref> [8, 9, 10] </ref>. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene. For example, while feature based methods compute a motion estimate directly, the structure is implicitly available given the feature correspondences. <p> At this point, we observe an irregularity which is an artifact of bi-cubic intensity interpolation. The error in the location of the likelihood minimium is between 1 and 3 quantization units, corresponding to 2:25 to 6:75 degrees of accuracy. These results compare favorably with other methods <ref> [4, 8] </ref> which give a FOE localization error of around 9 degrees. Moreover, it is believed that these results would be improved if a finer quantization search had been performed.
Reference: [9] <author> I. J. Cox. </author> <title> A review of statistical data association techniques for motion correspondence. </title> <journal> Int. J. Computer Vision, </journal> <volume> 10(1) </volume> <pages> 53-66, </pages> <year> 1993. </year>
Reference-contexts: Even methods using the intensity derivatives directly or normal flow, as in [11, 12, 8, 4, 5, 6, 7], suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see <ref> [8, 9, 10] </ref>. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene. For example, while feature based methods compute a motion estimate directly, the structure is implicitly available given the feature correspondences.
Reference: [10] <author> C. Tomasi. </author> <title> Pictures and trails: a new framework for the computation of shape and motion from perspective image sequences. </title> <booktitle> In Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 913-918, </pages> <year> 1994. </year>
Reference-contexts: Even methods using the intensity derivatives directly or normal flow, as in [11, 12, 8, 4, 5, 6, 7], suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see <ref> [8, 9, 10] </ref>. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene. For example, while feature based methods compute a motion estimate directly, the structure is implicitly available given the feature correspondences.
Reference: [11] <author> B. K. P. Horn and E. J. Weldon, Jr. </author> <title> Direct methods for recovering motion. </title> <journal> Int. J. Computer Vision, </journal> <volume> 2 </volume> <pages> 51-76, </pages> <year> 1988. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see [1, 2, 3, 4]). Even methods using the intensity derivatives directly or normal flow, as in <ref> [11, 12, 8, 4, 5, 6, 7] </ref>, suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene.
Reference: [12] <author> S. Negahdaripour and B. K. P. Horn. </author> <title> Direct passive navigation. </title> <journal> IEEE PAMI, </journal> <volume> 9(1) </volume> <pages> 168-176, </pages> <year> 1987. </year>
Reference-contexts: In the first case, some inherent problems (aperture, large motions, etc.) related to optical flow computation, suggests that errors can never be lowered to a negligible level (see [1, 2, 3, 4]). Even methods using the intensity derivatives directly or normal flow, as in <ref> [11, 12, 8, 4, 5, 6, 7] </ref>, suffer from high noise sensitivity. For feature-based methods, the reliable selection and tracking of meaningful feature points is generally very difficult, see [8, 9, 10]. All prior methods of egomotion implicitly or explicitly determine the structure present in the scene.
Reference: [13] <author> I. J. Cox and S. Roy. </author> <title> Direct estimation of rotation from two frames via epipolar search. </title> <booktitle> In 6th Int. conf. on Computer Analysis of Images and Patterns, </booktitle> <year> 1995. </year>
Reference-contexts: The search is straightforward since we show in Section 3.1 that the function to minimize has only one minimum (which is the solution), provided the image is well behaved, i.e. the variance between neighboring intensity points increases monotonically with the distance between the points. Prior work by the authors <ref> [13] </ref> proposed using the difference between histograms computed along assumed correspondence epipolar lines as a likelihood function. This statistical measure is very effective in determining the rotational component of ego-motion. However, epipolar histograms are not always a reliable measure of the likelihood of a translational motion.
Reference: [14] <author> R. C. Bolles, H. H. Baker, and M. J. Hannah. </author> <title> The JISCT stereo evaluation. </title> <booktitle> In Proc. of DARPA Image Understanding Workshop, </booktitle> <pages> pages 263-274, </pages> <year> 1993. </year>
Reference-contexts: This statistical measure is very effective in determining the rotational component of ego-motion. However, epipolar histograms are not always a reliable measure of the likelihood of a translational motion. Section 4 presents experimental results from a comprehensive evaluation based on the JISCT stereo database <ref> [14] </ref>. PUBLISHED IN INTERNATIONAL WORKSHOP ON STEREOSCOPIC AND THREE DIMENSIONAL IMAGING (IWS3DI'95), SANTORINI, GRECE, (P. 115-121) Sebastien Roy is visiting from Universite de Montreal, Departement d'informatique et de recherche operationnelle, C.P. 6128, Succ. Centre-Ville, Montreal (Quebec), Canada, H3C 3J7 2.
References-found: 14

