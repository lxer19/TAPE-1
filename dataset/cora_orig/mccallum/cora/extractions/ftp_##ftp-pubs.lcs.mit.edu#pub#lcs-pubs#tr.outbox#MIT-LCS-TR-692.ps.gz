URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-692.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr600.html
Root-URL: 
Title: Efficient Garbage Collection for Large Object-Oriented Databases  
Author: by Tony C. Ng Barbara H. Liskov 
Degree: (1994) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science in Electrical Engineering and Computer Science at the  All rights reserved. Author  Certified by  Professor of Software Science and Engineering Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Date: May 1996  May, 1996  
Affiliation: B.S., University of Illinois, Urbana-Champaign  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1996.  Department of Electrical Engineering and Computer Science  NEC  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Atul Adya. </author> <title> Transaction management for mobile objects using optimistic concurrency control. </title> <type> Technical Report MIT/LCS/TR-626, </type> <institution> Massachusetts Institute of Technology, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Given a reference, the corresponding object can be accessed by sending a request to the OR identified by the OR id. The OR then uses the segment id and the object index to locate the object efficiently. Migration of objects between different ORs is supported in Thor <ref> [1] </ref>. 2.2.4 Partitions The segments in an OR are logically grouped into sets of partitions. A partition consists of one or more segments. It is the unit of garbage collection. That is, each partition is collected independently of one another. <p> The OR that receives this commit request is called the coordinator of the transaction. All ORs affected by this transaction, including the coordinator, are referred to as participants. Upon receiving a commit request, the coordinator executes a two-phase commit protocol <ref> [1, 12] </ref>. (The two phases can be combined to one if the transaction has used objects at only one OR.) In the first phase of the commit protocol, the coordinator sends a prepare message to each participant.
Reference: [2] <author> Atul Adya, Robert Gruber, Barbara Liskov, and Umesh Maheshwari. </author> <title> Efficient optimistic concurrency control using loosely synchronized clocks. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <address> San Jose, Califor-nia, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: These handles may point to new volatile objects created during this transaction and the clients may continue to use them after the transaction has aborted. Thor uses an optimistic concurrency control technique <ref> [2] </ref>. As a result, the objects cached at the FEs might be stale due to committed transactions of other clients. To reduce unnecessary aborts, an OR notifies FEs about stale objects.
Reference: [3] <author> Laurent Amsaleg, Michael Franklin, and Olivier Gruber. </author> <title> Efficient incremental garbage collection for client-server object database systems. </title> <booktitle> In Proceedings of the VLDB International Conference on Very Large Data Bases, </booktitle> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: They are also used in the partitioned GC algorithms described below. There are several recent works that address the issue of very large persistent storage spaces by using a partitioned approach for garbage collection <ref> [25, 5, 3] </ref>. However, none of these works addresses the I/O cost related to IRL modifications. Yong, Naughton, and Yu [25] evaluate a number of GC algorithms for client-server persistent object stores. They propose an incremental, partitioned, copying GC algorithm. <p> The policy is based on the observation that when a pointer is overwritten, the object it pointed to is more likely to become garbage. This work, however, does not describe the garbage collection algorithm itself. Amsaleg, Franklin, and Gruber <ref> [3] </ref> describe an incremental mark-and-sweep garbage collector for client-server object database systems. The main focus of this work is to handle issues that arise due to the caching of disk pages by clients.
Reference: [4] <author> Peter Bishop. </author> <title> Computer systems with a very large address space, and garbage collection. </title> <type> Technical Report MIT/LCS/TR-178, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1977. </year>
Reference-contexts: Furthermore, a GC flip of the from-space and to-space can only occur when the redo log is empty. Our scheme does not have this requirement. 1.2.2 Partitioned GC The idea of sub-dividing the address space into separate areas and collecting each area independently was first proposed by Bishop <ref> [4] </ref>. His work, however, was done in the context of a virtual memory system without persistence. Generational GC [14] also divides the address space into separate areas, called generations, based on the lifetimes of objects. It differs from partitioned GC in several ways. <p> As a result, collecting an old generation requires tracing all generations that are younger. Partitioned GC, on the other hand, can collect any partition independently. Our scheme uses IRLs to keep track of inter-partition references. Similar data structures are used in the work by Bishop <ref> [4] </ref>, in generational GC, as well as in distributed garbage collection algorithms to handle inter-node references [23, 18]. They are also used in the partitioned GC algorithms described below. <p> If OR 1 has a remote reference to an object in OR 2 , the OR table for OR 1 at OR 2 has an entry for the referenced object. The use of OR tables is a form of reference listing <ref> [4, 18] </ref>. 2.2.3 Segments The storage in an OR is divided into a set of segments, which are similar to large disk pages. Each segment can store many objects. It is the unit of disk transfer and caching at an OR. Segments can be of different sizes.
Reference: [5] <author> Jonathan Cook, Alexander Wolf, and Benjamin Zorn. </author> <title> Partition selection policies in object database garbage collection. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 371-382, </pages> <address> Mineapolis, Minnesota, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: It has been shown that this can increase the amount of storage reclaimed <ref> [5] </ref>. (4) The collector runs concurrently with client activities. Minimal synchronization is required between the servers and clients. Client reads and updates always proceed with no extra latency whether the collector is running or not. (5) The scheme is fault-tolerant. <p> It differs from partitioned GC in several ways. First, generational GC exploits the fact that most objects have a very short lifetime and collects areas that contain newly created objects more frequently. Partitioned GC might use a different policy to select which partition to collect <ref> [5] </ref>. Second, generational GC only maintains inter-area references from young generations to old generations. As a result, collecting an old generation requires tracing all generations that are younger. Partitioned GC, on the other hand, can collect any partition independently. Our scheme uses IRLs to keep track of inter-partition references. <p> They are also used in the partitioned GC algorithms described below. There are several recent works that address the issue of very large persistent storage spaces by using a partitioned approach for garbage collection <ref> [25, 5, 3] </ref>. However, none of these works addresses the I/O cost related to IRL modifications. Yong, Naughton, and Yu [25] evaluate a number of GC algorithms for client-server persistent object stores. They propose an incremental, partitioned, copying GC algorithm. <p> During garbage collection, locks have to be acquired on objects before they are copied to guarantee that the collector does not move an object that is being updated by an uncommitted transaction. Locking is not required in our scheme. 12 Cook, Wolf, and Zorn <ref> [5] </ref> investigate heuristics for selecting a partition to collect when a garbage collection is necessary. They show that one of its proposed partition selection policies is more cost-effective than the others. <p> The algorithm runs infrequently and should be designed to avoid excessive I/Os and paging. 6.1.3 Partition Selection Policies An important aspect of partitioned GC algorithms is how to select a partition that contains the most garbage. Relatively little work has been done in this topic <ref> [5] </ref> and further study would be beneficial. 6.1.4 Clustering of Segments into Partitions For performance reasons, it is important to cluster related objects into the same segment. When a database is divided into partitions, it is also important to group related segments into the same partition.
Reference: [6] <author> David Detlefs. </author> <title> Concurrent, atomic garbage collection. </title> <type> Technical Report CMU-CS-90-177, </type> <institution> Carnegie Mellon University, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: We divide previous work on garbage collectors for persistent stores into two categories: non-partitioned GC and partitioned GC. 1.2.1 Non-partitioned GC The research in this category focuses on designing a collector for persistent heaps that is incremental/concurrent, fault tolerant and preserves transaction semantics <ref> [6, 13, 21] </ref>. However, the approaches share one common problem. Each round of garbage collection requires the traversal of the entire persistent storage space. As a result, the schemes are not practical for very large databases. <p> As a result, the schemes are not practical for very large databases. In addition, these works are done in the context of a centralized server and do not consider caching of objects at clients. Two designs of atomic incremental garbage collectors for stable heaps are presented in Detlefs <ref> [6] </ref>, and Kolodner and Weihl [13]. In both designs, the collector is closely integrated with the recovery system to make garbage collection recoverable. The recovery algorithm is complex in both cases and each step of collection has to be logged.
Reference: [7] <author> Edsger Dijkstra, Leslie Lamport, A. Martin, C. Scholten, and E. Steffens. </author> <title> On-the-fly garbage collection: An exercise in cooperation. </title> <journal> Communications of the ACM, </journal> <volume> 21(11) </volume> <pages> 966-975, </pages> <month> November </month> <year> 1978. </year> <month> 52 </month>
Reference-contexts: It is possible, though non-trivial, to augment the design using techniques such as migration of objects with cycles into the same partition or enlarging a partition to contain the objects with cycles. Another possibility is to use a complementary scheme based on global tracing <ref> [7, 11] </ref>. 1.2 Related Work Our work draws on previous research on garbage collection. Our goal is to design a garbage collector appropriate for large, persistent object storage systems. <p> Recomputing the IRLs can be avoided if each inlist entry maintains a list of partitions with incoming references rather than just a count [8]. * Complementary Tracing It might be better to use a complementary algorithm based on global tracing <ref> [7, 11] </ref> because of its simplicity and completeness. The algorithm runs infrequently and should be designed to avoid excessive I/Os and paging. 6.1.3 Partition Selection Policies An important aspect of partitioned GC algorithms is how to select a partition that contains the most garbage.
Reference: [8] <author> Paulo Ferreira and Marc Shapiro. Larchant: </author> <title> Persistence by reachability in distributed shared memory through garbage collection. </title> <booktitle> In Proceedings of the ICDCS International Conference on Distributed Computing Systems, </booktitle> <address> Hong Kong, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Again, it is tricky to determine which partitions should be combined. It may be expensive to recompute 50 the IRLs for the new combined partition. Recomputing the IRLs can be avoided if each inlist entry maintains a list of partitions with incoming references rather than just a count <ref> [8] </ref>. * Complementary Tracing It might be better to use a complementary algorithm based on global tracing [7, 11] because of its simplicity and completeness.
Reference: [9] <author> Sanjay Ghemawat. </author> <title> The Modified Object Buffer: a storage management technique for object-oriented databases. </title> <type> Technical Report MIT/LCS/TR-666, </type> <institution> Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: In addition, the processing and discarding of log entries in an arbitrary order can be implemented efficiently. 2.2.6 Modified Object Buffer The main memory of an OR is partitioned into a segment cache and a modified object buffer (MOB) <ref> [9] </ref>, which contains the latest versions of modified or newly-persistent objects. In Thor, the modifications due to committed transactions are not immediately written to segments. Instead, they are appended to the transaction log and stored in the MOB.
Reference: [10] <author> Jim Gray and Andreas Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Introduction 1.1 Background and Overview Object-oriented databases (OODBs) provide persistent storage of objects with complex inter-relationships. They support transactions <ref> [10] </ref>, a mechanism that allows client applications to group a set of reads and writes to objects as an atomic unit. The system ensures that either all or none of the operations within a transaction are executed in spite of system failures and concurrent access by other applications.
Reference: [11] <author> John Hughes. </author> <title> A Distributed Garbage Collection Algorithm, </title> <booktitle> pages 256-272. Number 201 in Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: It is possible, though non-trivial, to augment the design using techniques such as migration of objects with cycles into the same partition or enlarging a partition to contain the objects with cycles. Another possibility is to use a complementary scheme based on global tracing <ref> [7, 11] </ref>. 1.2 Related Work Our work draws on previous research on garbage collection. Our goal is to design a garbage collector appropriate for large, persistent object storage systems. <p> Recomputing the IRLs can be avoided if each inlist entry maintains a list of partitions with incoming references rather than just a count [8]. * Complementary Tracing It might be better to use a complementary algorithm based on global tracing <ref> [7, 11] </ref> because of its simplicity and completeness. The algorithm runs infrequently and should be designed to avoid excessive I/Os and paging. 6.1.3 Partition Selection Policies An important aspect of partitioned GC algorithms is how to select a partition that contains the most garbage.
Reference: [12] <author> Andrew Kirmse. </author> <title> Implementation of the two-phase commit protocol in Thor. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: The OR that receives this commit request is called the coordinator of the transaction. All ORs affected by this transaction, including the coordinator, are referred to as participants. Upon receiving a commit request, the coordinator executes a two-phase commit protocol <ref> [1, 12] </ref>. (The two phases can be combined to one if the transaction has used objects at only one OR.) In the first phase of the commit protocol, the coordinator sends a prepare message to each participant.
Reference: [13] <author> Elliot Kolodner and William Weihl. </author> <title> Atomic Incremental Garbage Collection, </title> <booktitle> pages 365-387. Number 637 in Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: We divide previous work on garbage collectors for persistent stores into two categories: non-partitioned GC and partitioned GC. 1.2.1 Non-partitioned GC The research in this category focuses on designing a collector for persistent heaps that is incremental/concurrent, fault tolerant and preserves transaction semantics <ref> [6, 13, 21] </ref>. However, the approaches share one common problem. Each round of garbage collection requires the traversal of the entire persistent storage space. As a result, the schemes are not practical for very large databases. <p> In addition, these works are done in the context of a centralized server and do not consider caching of objects at clients. Two designs of atomic incremental garbage collectors for stable heaps are presented in Detlefs [6], and Kolodner and Weihl <ref> [13] </ref>. In both designs, the collector is closely integrated with the recovery system to make garbage collection recoverable. The recovery algorithm is complex in both cases and each step of collection has to be logged.
Reference: [14] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: Our scheme does not have this requirement. 1.2.2 Partitioned GC The idea of sub-dividing the address space into separate areas and collecting each area independently was first proposed by Bishop [4]. His work, however, was done in the context of a virtual memory system without persistence. Generational GC <ref> [14] </ref> also divides the address space into separate areas, called generations, based on the lifetimes of objects. It differs from partitioned GC in several ways. First, generational GC exploits the fact that most objects have a very short lifetime and collects areas that contain newly created objects more frequently.
Reference: [15] <author> Barbara Liskov, Atul Adya, Miguel Castro, Mark Day, Sanjay Ghemawat, Robert Gruber, Umesh Maheshwari, Andrew Myers, and Liuba Shrira. </author> <title> Safe and efficient sharing of persistant objects in Thor. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: We will concentrate on the aspects of Thor that are relevant to this thesis. A more complete description of Thor can be found in <ref> [16, 15] </ref>. Thor is an object-oriented database management system that can be used in a heterogeneous, distributed environment. Thor provides a universe of persistent objects. It permits application programs written in various programming languages to share objects. Each object in Thor has a globally unique identifier called an xref.
Reference: [16] <author> Barbara Liskov, Mark Day, and Liuba Shrira. </author> <title> Distributed object management in Thor. In Distributed Object Management. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: In addition, the recovery process should remain fast even in the presence of GC. We have designed and implemented a garbage collection scheme that addresses all the above issues. The work is done in the context of Thor <ref> [16] </ref>, a distributed, client-server object-oriented database. Our scheme uses a partitioned approach [25]. The database is divided into partitions and each partition is collected independently. Our scheme uses a copying algorithm to collect each partition. Live objects are copied from a from-space to a to-space. <p> We will concentrate on the aspects of Thor that are relevant to this thesis. A more complete description of Thor can be found in <ref> [16, 15] </ref>. Thor is an object-oriented database management system that can be used in a heterogeneous, distributed environment. Thor provides a universe of persistent objects. It permits application programs written in various programming languages to share objects. Each object in Thor has a globally unique identifier called an xref.
Reference: [17] <author> Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proceedings of the ACM SOSP Symposium on Operating Systems Principles, </booktitle> <pages> pages 226-238, </pages> <address> Pacific Grove, California, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: In Thor, the transaction log resides in the main memory of an OR. Replication is used to allow the log to survive crashes <ref> [17] </ref>. The basic idea is that the log is replicated in the main memories of several machines. These machines are connected by a fast network and are backed up by uninterruptible power supplies. A log record is considered stable if it resides in volatile memory at all of these machines.
Reference: [18] <author> Umesh Maheshwari and Barbara Liskov. </author> <title> Fault-tolerant distributed garbage collection in a client-server, object-oriented database. </title> <booktitle> In Proceedings of the PDIS International 53 Conference on Parallel and Distributed Information Systems, </booktitle> <pages> pages 239-248, </pages> <address> Austin, Texas, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Partitioned GC, on the other hand, can collect any partition independently. Our scheme uses IRLs to keep track of inter-partition references. Similar data structures are used in the work by Bishop [4], in generational GC, as well as in distributed garbage collection algorithms to handle inter-node references <ref> [23, 18] </ref>. They are also used in the partitioned GC algorithms described below. There are several recent works that address the issue of very large persistent storage spaces by using a partitioned approach for garbage collection [25, 5, 3]. <p> This problem does not occur in our system because only committed changes are sent back to servers. The paper briefly discusses how to extend the algorithm to collect partitions independently but details are not given. Work that is closely related to this thesis is described in <ref> [18] </ref>, which presents a distributed garbage collection scheme for Thor. That work concentrates on the coordination between multiple servers and clients to detect distributed garbage and turn it into local garbage, which can then be collected by local GC. However, it does not discuss the local GC. <p> However, it does not discuss the local GC. The garbage collector described in this thesis is designed to work in cooperation with the distributed GC algorithm in <ref> [18] </ref>, providing a reclamation solution for distributed database systems. 1.3 Thesis Outline The rest of this thesis is organized as follows. Chapter 2 describes the system architecture of Thor. It introduces relevant concepts that will be used in later chapters. Chapter 3 presents an overview of our garbage collection scheme. <p> This can be implemented using well-known techniques such as timestamps, time-out, re-transmission and acknowledgements. Thor is designed to handle client/FE and network failures. If an OR is unable to contact an FE for a long time, it will properly shutdown the FE-OR session <ref> [18] </ref>. An FE usually runs on the same machine as the application. An application program never obtains direct pointers to objects. Instead, an FE issues handles that can be used to identify objects in subsequent calls. The FE maintains a handle table that maps from handles to objects. <p> The latter is responsible for coordinating between different ORs as well as between ORs and 17 FEs to maintain a root set that protects all persistent objects and exposes the garbage to the local garbage collector. A design of a distributed GC protocol can be found in <ref> [18] </ref>. This thesis concentrates on the correctness and efficiency of the local GC protocol. However, we will also discuss some modifications to the distributed GC protocol described in [18]. 2.2.2 OR Tables For GC purposes, each OR maintains an OR table for every other OR, which records a conservative estimate of <p> A design of a distributed GC protocol can be found in <ref> [18] </ref>. This thesis concentrates on the correctness and efficiency of the local GC protocol. However, we will also discuss some modifications to the distributed GC protocol described in [18]. 2.2.2 OR Tables For GC purposes, each OR maintains an OR table for every other OR, which records a conservative estimate of the incoming references from that OR. <p> If OR 1 has a remote reference to an object in OR 2 , the OR table for OR 1 at OR 2 has an entry for the referenced object. The use of OR tables is a form of reference listing <ref> [4, 18] </ref>. 2.2.3 Segments The storage in an OR is divided into a set of segments, which are similar to large disk pages. Each segment can store many objects. It is the unit of disk transfer and caching at an OR. Segments can be of different sizes. <p> The insertion of entries has to be incorporated in the first phase of the two-phase commit protocol. More details can be found in <ref> [18] </ref>. To maintain the second invariant, before an OR OR 1 can inform another OR OR 2 about the deletion of a remote reference xref, it has to first ensure that the xref does not exist in any FEs it has a connection with.
Reference: [19] <author> Umesh Maheshwari and Barbara Liskov. </author> <title> Collecting cyclic distributed garbage by controlled migration. </title> <booktitle> In Proceedings of the ACM PODC Symposium on Principles of Distributed Computing, </booktitle> <address> Ottawa, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: The tricky part, however, is to identify potential garbage objects and decide where to move them. A migration scheme based on distance estimation of objects is described in <ref> [19] </ref>. The distance of an object is the number of internode references from any persistent root to that object. An object with a large distance is likely to be cyclic garbage.
Reference: [20] <author> Scott Nettles and James O'Toole. </author> <title> Real-time replication-based garbage collection. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <address> Albequerque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: In contrast, recovery in our scheme is simple and logging is only needed at the end of garbage collection. O'Toole, Nettles and Gifford [21] describe a concurrent compacting collector for persistent heaps. They use a replicating garbage collection technique <ref> [20] </ref> to simplify recovery. In addition, transaction processing and garbage collection operations are decoupled using the 11 transaction log. Our scheme uses a very similar technique to simplify recovery and increase concurrency. This work requires the garbage collector to concurrently process the entries in the log.
Reference: [21] <author> James O'Toole, Scott Nettles, and David Gifford. </author> <title> Concurrent compacting garbage collection of a persistent heap. </title> <booktitle> In Proceedings of the ACM SOSP Symposium on Operating Systems Principles, </booktitle> <pages> pages 161-174, </pages> <address> Asheville, North Carolina, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: We divide previous work on garbage collectors for persistent stores into two categories: non-partitioned GC and partitioned GC. 1.2.1 Non-partitioned GC The research in this category focuses on designing a collector for persistent heaps that is incremental/concurrent, fault tolerant and preserves transaction semantics <ref> [6, 13, 21] </ref>. However, the approaches share one common problem. Each round of garbage collection requires the traversal of the entire persistent storage space. As a result, the schemes are not practical for very large databases. <p> The recovery algorithm is complex in both cases and each step of collection has to be logged. In contrast, recovery in our scheme is simple and logging is only needed at the end of garbage collection. O'Toole, Nettles and Gifford <ref> [21] </ref> describe a concurrent compacting collector for persistent heaps. They use a replicating garbage collection technique [20] to simplify recovery. In addition, transaction processing and garbage collection operations are decoupled using the 11 transaction log. Our scheme uses a very similar technique to simplify recovery and increase concurrency.
Reference: [22] <author> James O'Toole and Liuba Shrira. </author> <title> Opportunistic log: Efficient reads in a reliable storage server. </title> <booktitle> In Proceedings of the Usenix OSDI Symposium on Operating Systems Design and Implementation, </booktitle> <address> Monterey, CA, </address> <year> 1994. </year>
Reference-contexts: If the segment is not in the cache, it has to be read from the disk. The object is then installed into the segment and the segment is written back to disk. The extra disk reads associated with object installation are referred to as installation reads <ref> [22] </ref>. Modified objects located in the same segment are installed together to reduce disk I/Os. Once the modifications 19 have been written to the disk, they are removed from the MOB and the transaction log. The flusher thread runs independently of client activities.
Reference: [23] <author> Marc Shapiro, Olivier Gruber, and David Plainfosse. </author> <title> A garbage detection protocol for a realistic distributed object-support system. </title> <type> Technical Report 1320, </type> <institution> Institut National de la Recherche en Informatique et Automatique, Rocquencourt (France), </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: Partitioned GC, on the other hand, can collect any partition independently. Our scheme uses IRLs to keep track of inter-partition references. Similar data structures are used in the work by Bishop [4], in generational GC, as well as in distributed garbage collection algorithms to handle inter-node references <ref> [23, 18] </ref>. They are also used in the partitioned GC algorithms described below. There are several recent works that address the issue of very large persistent storage spaces by using a partitioned approach for garbage collection [25, 5, 3].
Reference: [24] <author> Paul Wilson. </author> <title> Uniprocessor Garbage Collection Techniques, </title> <booktitle> pages 1-42. Number 637 in Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Garbage collection (GC) provides safe and automatic storage management of databases. While extensive research on garbage collection has been done in the context of programming languages <ref> [24] </ref>, existing GC algorithms do not readily transfer for use in OODBs. Several issues have to be addressed for garbage collection to be practical in these systems: Disk-resident data.
Reference: [25] <author> Voon-Fee Yong, Jeffrey Naughton, and Jie-Bing Yu. </author> <title> Storage reclamation and reorganization in client-server persistent object stores. </title> <booktitle> In Proceedings of the ICDE International Conference on Data Engineering, </booktitle> <pages> pages 120-133, </pages> <address> Houston, Texas, </address> <month> February </month> <year> 1994. </year> <month> 54 </month>
Reference-contexts: We have designed and implemented a garbage collection scheme that addresses all the above issues. The work is done in the context of Thor [16], a distributed, client-server object-oriented database. Our scheme uses a partitioned approach <ref> [25] </ref>. The database is divided into partitions and each partition is collected independently. Our scheme uses a copying algorithm to collect each partition. Live objects are copied from a from-space to a to-space. <p> They are also used in the partitioned GC algorithms described below. There are several recent works that address the issue of very large persistent storage spaces by using a partitioned approach for garbage collection <ref> [25, 5, 3] </ref>. However, none of these works addresses the I/O cost related to IRL modifications. Yong, Naughton, and Yu [25] evaluate a number of GC algorithms for client-server persistent object stores. They propose an incremental, partitioned, copying GC algorithm. <p> There are several recent works that address the issue of very large persistent storage spaces by using a partitioned approach for garbage collection [25, 5, 3]. However, none of these works addresses the I/O cost related to IRL modifications. Yong, Naughton, and Yu <ref> [25] </ref> evaluate a number of GC algorithms for client-server persistent object stores. They propose an incremental, partitioned, copying GC algorithm. Their scheme is fault tolerant and recovery is simple due to the use of logical object identifiers.
References-found: 25

