URL: ftp://ftp.cs.toronto.edu/pub/bonner/papers/workflow/report.ps
Refering-URL: http://www.cs.toronto.edu/DB/people/bonner/papers.html
Root-URL: 
Email: bonner@db.toronto.edu  shrufi@db.toronto.edu  steve@genome.wi.mit.edu  
Phone: 1  
Title: LabFlow-1: a Database Benchmark for High-Throughput Workflow Management The OOPSLA Workshop on Object Database Behavior,
Author: Anthony J. Bonner Adel Shrufi Steve Rozen 
Note: Portions of this report appear in: Proceedings of the International Conference on Extending Database Technology (EDBT), 1996.  1995. The NSF Workshop on Workflow and Process Automation in Information Systems,  This work was supported by funds from the U.S. National Institutes of Health, National Center for Human Genome Research, grant number P50 HG00098, and from the U.S. Department of Energy under contract DE-FG02-95ER62101.  
Date: 2 Whitehead/MIT  October 8, 1996  1996.  
Address: 10 King's College Rd Toronto, ON, Canada  One Kendall Square Building 300, Floor 5 Cambridge, MA 02139, USA  
Affiliation: University of Toronto Department of Computer Science  Center for Genome Research  
Pubnum: M5S 1A4  
Abstract: Workflow management is a ubiquitous task faced by many organizations, and entails the coordination of various activities. This coordination is increasingly carried out by software systems called workflow management systems (WFMS). An important component of many WFMSs is a DBMS for keeping track of workflow activity. This DBMS maintains an audit trail, or event history, that records the results of each activity. Like other data, the event history can be indexed and queried, and views can be defined on top of it. In addition, a WFMS must accommodate frequent workflow changes, which result from a rapidly evolving business environment. Since the database schema depends on the workflow, the DBMS must support dynamic schema evolution. These requirements are especially challenging in high-throughput WFMSs|i:e:, systems for managing high-volume, mission-critical workflows. Unfortunately, existing database benchmarks do not capture the combination of flexibility and performance required by these systems. To address this issue, we have developed LabFlow-1, the first version of a benchmark that concisely captures the DBMS requirements of high-throughput WFMSs. LabFlow-1 is based on the data and workflow management needs of a large genome-mapping laboratory, and reflects their real-world experience. In addition, we use LabFlow-1 to test the usability and performance of two object storage managers. These tests revealed substantial differences between these two systems, and highlighted the critical importance of being able to control locality of reference to persistent data. These papers and the entire report are available at the following web page: http://www.db.toronto.edu:8020/people/bonner/bonner.html 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Elmagarmid A, K, Y. Leu, W. Litwin, and M. Rusinkiewcz. </author> <title> A multidatabase transaction model for interbase. </title> <booktitle> In Proceedings of the International Conference on Very Large Data Bases (VLDB), </booktitle> <pages> pages 507-518, </pages> <address> Brisbane, Australia, </address> <month> August 13-16 </month> <year> 1990. </year>
Reference-contexts: At present, this information is all embedded in application programs, as described in the next subsection. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, <ref> [48, 1, 58, 21] </ref>). This difference might be resolved if each material were associated with a single long-running activity. This activity would exist as long as the material is being processed, and would correspond to the sequence of workflow steps that process the material.
Reference: [2] <author> S. F. Altschul, W. Gish, W. Miller, E. W. Myers, and D. J. Lipman. </author> <title> Basic local alignment search tool. </title> <journal> Journal of Molecular Biology (England), </journal> <volume> 215(3) </volume> <pages> 403-410, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: The results of such searches are often stored locally in the laboratory's database. A widely used program for carrying our these homology searches is called BLAST (Basic Local Alignment Search Tool) <ref> [2] </ref>.
Reference: [3] <institution> Standard Guide for Laboratory Information Management Systems (LIMS). American Society for Testing and Materials, </institution> <address> 1916 Race St., Philadelphia PA 19103, U.S.A, </address> <year> 1993. </year> <note> REFERENCES 41 </note>
Reference: [4] <author> T.L. Anderson, A.J. Berre, M. Mallison, H.H. Porter, and B. Schneider. </author> <title> The hypermodel benchmark. </title> <booktitle> In Proceedings of the International Conference on Extending Database Technology (EDBT), </booktitle> <pages> pages 317-331, </pages> <address> Venice, Italy, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks <ref> [13, 12, 4] </ref> are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark [54] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS).
Reference: [5] <author> Claire M. Berg, Gan Wang, Linda D. Stausbaugh, and Douglas A. Berg. </author> <booktitle> Transposon-facilitated sequencing of DNAs cloned in plasmids. Methods in Enzymology, </booktitle> <volume> 218 </volume> <pages> 279-306, </pages> <year> 1993. </year>
Reference: [6] <author> A.J. Bonner and M. Kifer. </author> <title> Transaction Logic Programming. </title> <booktitle> In Proceedings of the International Conference on Logic Programming (ICLP), </booktitle> <pages> pages 257-279, </pages> <address> Budapest, Hungary, June 21-24 1993. </address> <publisher> MIT Press. </publisher>
Reference-contexts: (M) &lt;- state (M,waiting_for_sequencing), test:sequencing_ok (M), retract (state (M,waiting_for_sequencing)), assert (state (M,waiting_for_incorporation)). test:sequencing_ok (M) &lt;- In this case, there are no constraints on the transition, so the predicate test:sequencing ok has an empty premise and always succeeds. 2 18 A logical semantics for assert and retract can be found in <ref> [7, 6] </ref>. 8 TYPICAL QUERIES AND UPDATES 29 8.3 Workflow Tracking The queries in this subsection insert new step and material instances into the database. The insertion of step instances into the database creates an event history (or audit trail) of workflow activity.
Reference: [7] <author> A.J. Bonner and M. Kifer. </author> <title> Transaction logic programming (or a logic of declarative and procedural knowledge). </title> <type> Technical Report CSRI-323, </type> <institution> University of Toronto, </institution> <month> April </month> <year> 1995. </year> <note> Available at http:// www.db.toronto.edu:8020/transaction-logic.html. </note>
Reference-contexts: (M) &lt;- state (M,waiting_for_sequencing), test:sequencing_ok (M), retract (state (M,waiting_for_sequencing)), assert (state (M,waiting_for_incorporation)). test:sequencing_ok (M) &lt;- In this case, there are no constraints on the transition, so the predicate test:sequencing ok has an empty premise and always succeeds. 2 18 A logical semantics for assert and retract can be found in <ref> [7, 6] </ref>. 8 TYPICAL QUERIES AND UPDATES 29 8.3 Workflow Tracking The queries in this subsection insert new step and material instances into the database. The insertion of step instances into the database creates an event history (or audit trail) of workflow activity.
Reference: [8] <author> I. Bratko. </author> <title> PROLOG Programming for Artificial Intelligence. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: This predicate is always true and has the standard Prolog semantics [16]. * retract (p) deletes the atomic formula p from the database. This predicate is true if p was in the database prior to deletion. It has the standard Prolog semantics <ref> [16, 8] </ref>. * create:class (obj) creates a new object identifier, obj, for class, and inserts the formula class (obj) into the database. <p> In particular, setof (Template,Query,Set) retrieves all the answers to the given Query, plugs each answer into the given Template, and then collects the instantiated templates into a Set. This is a standard Prolog predicate, similar to the more-familiar findall predicate except that duplicate query answers are eliminated <ref> [8] </ref>. Counting: In the schema in Appendix A, clone and tclone are material classes, while associate tclone, determine sequence and assemble sequence are step classes.
Reference: [9] <author> C. Burks, M. Cassidy, M. J. Cinkosky, K. E. Cumella, P. Gilna, et al. </author> <title> GenBank. </title> <journal> Nucleic Acids Research, </journal> <pages> pages 2221-2225, </pages> <year> 1991. </year>
Reference-contexts: Set and List Generation: As a genome lab produces DNA sequences, a common operation is to search international genome databases (such as EMBL and GenBank <ref> [9] </ref>) for similar (or homologous) sequences. The results of such searches are often stored locally in the laboratory's database. A widely used program for carrying our these homology searches is called BLAST (Basic Local Alignment Search Tool) [2].
Reference: [10] <author> M. Carey, D. DeWitt, G. Graefe, D. Haight, J. Richardson, D. Schuh, E. Shekita, and S. Vanden-berg. </author> <title> The EXODUS extensible DBMS project: An overview. </title> <editor> In S. Zdonik and D. Maier, editors, </editor> <booktitle> Readings in Object-Oriented Databases. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: This view need not be implemented in SQL. For instance, in the operational version of LabBase, these view predicates are implemented in persistent C++ on top of an ObjectStore database with a different schema and special access structures (see Section 5.1). Similarly, if Exodus <ref> [10] </ref> were the storage manager, these predicates would be implemented in E, the Exodus programming language. In this way, storage management, access structures, and query processing are separated. Many different storage organizations are possible, as are many different query processing strategies.
Reference: [11] <author> M.J. Carey, D.J. DeWitt, M.J. Franklin, et al. </author> <title> Shoring up persistent applications. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 383-394, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: LabBase uses four such segments, three of which contain relatively small amounts of frequently accessed data and one of which contains a relatively large amount of infrequently accessed data. 21 Thus, when based on the ObjectStore storage manager, the LabBase server is what Carey et al. term a "client-level server" <ref> [11] </ref>. 10 STORAGE-MANAGER COMPARISONS 38 Database Server Version Intvl Resource OStore Texas+TC Texas Ostore-mm Texas-mm 0.5X elapsed sec 1,424 1,469 1,402 1,384 1,407 user cpu sec 1,381 1,449 1,385 1,364 1,383 sys cpu sec 16 7 6 5 5 majflt 329 468 397 463 696 size (bytes) 16,629,760 24,281,088 24,600,576 |
Reference: [12] <author> M.J. Carey, D.J. DeWitt, and J.F. Naughton. </author> <title> The OO7 benchmark. </title> <type> Technical report, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> January </month> <year> 1994. </year> <note> Available at ftp://ftp.cs.wisc.edu/oo7/techreport.ps. </note>
Reference-contexts: Existing database benchmarks do not capture the above requirements. This should not be surprising, as it has been observed by researchers working on OODBMS benchmarks that advanced applications are too complex and diverse to be captured by a single benchmark <ref> [12, 14] </ref>. A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks [13, 12, 4] are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. <p> A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks <ref> [13, 12, 4] </ref> are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark [54] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS).
Reference: [13] <author> R.G.G. Cattell. </author> <title> An engineering database benchmark. </title> <booktitle> In [25], chapter 6, </booktitle> <pages> pages 247-281. </pages>
Reference-contexts: A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks <ref> [13, 12, 4] </ref> are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark [54] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS). <p> The workflow graph largely determines the workload for the DBMS. Appendix B gives an example of a workflow graph, one that forms the basis of the workload for the LabFlow-1 benchmark. 4 Benchmark Database Schema Like the OO1 benchmark <ref> [13] </ref> and the Sequoia 2000 benchmark [54], our benchmark is independent of the data model provided by the DBMS. We therefore describe the database schema abstractly, using an extended entity relationship (EER) diagram [57, 34]. An EER diagram is an ER diagram extended with is-a links.
Reference: [14] <author> A. Chaudhri. </author> <title> An Annotated Bibliography of Benchmarks for Object Databases. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 24(1) </volume> <pages> 50-57, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Existing database benchmarks do not capture the above requirements. This should not be surprising, as it has been observed by researchers working on OODBMS benchmarks that advanced applications are too complex and diverse to be captured by a single benchmark <ref> [12, 14] </ref>. A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks [13, 12, 4] are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications.
Reference: [15] <author> I-Min A. Chen and Victor M. Markowitz. </author> <title> The Object-Protocol Model, version 3.0. </title> <type> Technical Report LBL-32738, </type> <institution> Lawrence Berkeley Laboratory, </institution> <address> 1 Cyclotron Road, Berkeley, CA, 94720, USA, </address> <month> December </month> <year> 1994. </year> <note> This document and others on OPM available via http://gizmo.lbl.gov/ DM TOOLS/OPM/opm.html. </note>
Reference: [16] <author> W.F. Clocksin and C.S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Section 8 uses the predicates below to specify updates in the LabFlow-1 benchmark. * assert (p) inserts the atomic formula p into the database. This predicate is always true and has the standard Prolog semantics <ref> [16] </ref>. * retract (p) deletes the atomic formula p from the database. This predicate is true if p was in the database prior to deletion. <p> This predicate is always true and has the standard Prolog semantics [16]. * retract (p) deletes the atomic formula p from the database. This predicate is true if p was in the database prior to deletion. It has the standard Prolog semantics <ref> [16, 8] </ref>. * create:class (obj) creates a new object identifier, obj, for class, and inserts the formula class (obj) into the database.
Reference: [17] <institution> Communications of the ACM, </institution> <month> 34(11), November </month> <year> 1991. </year> <title> Special issue on the Human Genome Project. </title>
Reference-contexts: The example should help to motivate and clarify the benchmark. Our workflow example comes from the Whitehead Institute/MIT Center for Genome Research (the "Genome Center"), which is engaged in several large-scale genome mapping projects <ref> [17] </ref>.
Reference: [18] <author> U. Dayal, H. Garcia-Molina, M. Hsu, B. Kao, and M.-C. Shan. </author> <title> Third generation TP monitors: A database challenge. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 393-397, </pages> <address> Washington, DD, </address> <month> May </month> <year> 1993. </year>
Reference: [19] <author> E. Dyson. </author> <title> Workflow. </title> <booktitle> In Forbes, </booktitle> <pages> page 192. </pages> <month> November 23 </month> <year> 1992. </year>
Reference: [20] <editor> A. K. Elmagarmid, editor. </editor> <title> Database Transaction Models for Advanced Applications. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year> <note> REFERENCES 42 </note>
Reference: [21] <author> H. Garcia-Molina, D. Gawlick, J. Klein, K. Kleissner, and K. Salem. </author> <title> Modeling long-running activities as nested sagas. </title> <journal> Bulletin of the Technical Committee on Data Engineering (IEEE Computer Society), </journal> <volume> 14(1), </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: At present, this information is all embedded in application programs, as described in the next subsection. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, <ref> [48, 1, 58, 21] </ref>). This difference might be resolved if each material were associated with a single long-running activity. This activity would exist as long as the material is being processed, and would correspond to the sequence of workflow steps that process the material.
Reference: [22] <author> D. Georgakopoulos, M. Hornick, and A. Sheth. </author> <title> An overview of workflow management: From process modeling to infrastructure for automation. </title> <journal> Journal on Distributed and Parallel Database Systems, </journal> <volume> 3(2) </volume> <pages> 119-153, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Detailed examples of queries and updates are given in Section 8. The functions described above come largely under the heading of workflow tracking. As described in Section 2.2, a workflow management system must also provide a means of workflow modeling <ref> [22] </ref>. A workflow model specifies the dependencies among workflow steps. The Genome Center represents the most important dependencies as a workflow graph [53]. Workflow graphs are based on the idea that each material has a workflow state, and as the material is processed, it moves from one state to another.
Reference: [23] <author> Nathan Goodman. </author> <title> An object oriented DBMS war story: Developing a genome mapping database in C++. </title> <editor> In Won Kim, editor, </editor> <title> Modern Database Management: Object-Oriented and Multidatabase Technologies. </title> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference: [24] <author> Nathan Goodman, Steve Rozen, and Lincoln Stein. </author> <title> Requirements for a deductive query language in the MapBase genome-mapping database. </title> <editor> In Raghu Ramakrishnan, editor, </editor> <booktitle> Applications of Logic Databases, </booktitle> <pages> pages 259-278. </pages> <publisher> Kluwer, </publisher> <year> 1994. </year> <note> Available at ftp://genome.wi.mit.edu/ pub/papers/Y1994/requirements.ps. </note>
Reference-contexts: It is a deductive language in the tradition of Datalog and Prolog, and is very similar to the query language used at the Genome Center. The reasons the Genome Center uses a deductive query language have been described in detail elsewhere <ref> [24, 47, 46] </ref>. Broadly speaking, these reasons are expressiveness, simplicity and flexibility.
Reference: [25] <author> Jim Gray, </author> <title> editor. The Benchmark Handbook for Database and Transaction Processing Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference: [26] <author> M. Hsu, Ed. </author> <title> Special issue on workflow and extended transaction systems. </title> <journal> Bulletin of the Technical Committee on Data Engineering (IEEE Computer Society), </journal> <volume> 16(2), </volume> <month> June </month> <year> 1993. </year>
Reference: [27] <author> M. Hsu, </author> <title> Ed. </title> <journal> Special issue on workflow systems. Bulletin of the Technical Committee on Data Engineering (IEEE Computer Society), </journal> <volume> 18(1), </volume> <month> March </month> <year> 1995. </year>
Reference: [28] <author> H.V. Jagadish, I.S. Mumick, and A. Silberschatz. </author> <title> View maintenance issues for the chronicle data model. </title> <booktitle> In Proceedings of the ACM Symposium on the Principles of Database Systems (PODS), </booktitle> <pages> pages 113-124, </pages> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year>
Reference: [29] <author> Setrag Khoshafian and Marek Buckiewicz. </author> <title> Introduction to Groupware, Workflow, and Workgroup Computing. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1995. </year>
Reference-contexts: These requirements are particularly challenging because genome-mapping technology is evolving rapidly, with the consequence that the Genome Center is engaged in continual process re-engineering. 2.1 Production Workflow Workflow at the Genome Center is an example of production workflow <ref> [29] </ref>. In production workflows, activities are organized into production lines, with a mix of human and computer activities. Systems for managing production workflow are typically complex, high-volume, and central to the organizations that rely on them.
Reference: [30] <author> R.A. Kowalski. </author> <title> Database updates in the event calculus. </title> <journal> Journal of Logic Programming (JLP), </journal> 12(1&2):121-146, January 1992. 
Reference-contexts: Thus, the attributes (or type) of a material depend on the history of the material, as well as its class. This rather dynamic feature reflects the flexibility demanded by workflow management, and is closely related to research on time and action in artificial intelligence and logic programming <ref> [31, 30, 36, 44] </ref>. These issues are addressed in detail in Section 7, where we introduce structures that allow the view to be defined independently of the workflow, so that the view definition does not have to be changed each time the workflow changes. <p> The schema of a material instance depends not only on its class, but also on its history. It is worth noting that deriving most-recent values for materials is similar to certain problems of time and action in logic programming and artificial intelligence. For instance, the event calculus <ref> [31, 30] </ref> is a logic-programming methodology developed for recording and querying event histories. It includes special access structures to quickly retrieve most-recent results. As another example, the situation calculus [36, 44] encodes event histories as function terms.
Reference: [31] <author> R.A. Kowalski and M. Sergot. </author> <title> A logic-based calculus of events. </title> <journal> New Generation Computing, </journal> <volume> 4 </volume> <pages> 67-95, </pages> <year> 1986. </year>
Reference-contexts: Thus, the attributes (or type) of a material depend on the history of the material, as well as its class. This rather dynamic feature reflects the flexibility demanded by workflow management, and is closely related to research on time and action in artificial intelligence and logic programming <ref> [31, 30, 36, 44] </ref>. These issues are addressed in detail in Section 7, where we introduce structures that allow the view to be defined independently of the workflow, so that the view definition does not have to be changed each time the workflow changes. <p> The schema of a material instance depends not only on its class, but also on its history. It is worth noting that deriving most-recent values for materials is similar to certain problems of time and action in logic programming and artificial intelligence. For instance, the event calculus <ref> [31, 30] </ref> is a logic-programming methodology developed for recording and querying event histories. It includes special access structures to quickly retrieve most-recent results. As another example, the situation calculus [36, 44] encodes event histories as function terms.
Reference: [32] <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The ObjectStore database system. </title> <journal> Communications of the ACM, </journal> <volume> 34(10) </volume> <pages> 50-63, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Although LabFlow-1 is intended to be a general benchmark for DBMSs, this paper uses it to compare storage managers only. This is achieved by running the benchmark on versions of LabBase implemented on top of different storage managers, as described above. This paper compares Object-Store (version 3.0) <ref> [32, 42] </ref> and Texas (version 0.3) [51, 59]. Compared to relational systems, these storage managers have been used in few production applications, so this analysis is interesting in its own right. <p> In the tests discussed here, we used several versions of the LabBase data server, which varied in storage management. The five versions for which we report results are: 1. OStore|a version relying on ObjectStore (v3.0) <ref> [32, 42] </ref> for storage management. 2. Texas|a version relying on the Texas storage manager (v0.3) [51, 59] for storage management. 3. Texas+TC|a version almost identical to Texas, and using the same storage manager, but with additional object clustering implemented in client code. 4.
Reference: [33] <author> S. Leutenegger and D. Diaz. </author> <title> A Modeling Study of the TPC-C Benchmark. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 22-31, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: This application is characterized by a demand for flexible management of a stream of queries and updates, and of historical data and schema. On the surface, LabFlow-1 might appear similar to some TPC benchmarks <ref> [49, 33] </ref>, which are also based on a stream of transactions that construct a history. As discussed in Section 9, however, the way in which the stream is generated (the workload) is very different.
Reference: [34] <author> V.M. Markowitz and A. Shoshani. </author> <title> Representing extended entity-relationship structures in relational databases: A modular approach. </title> <journal> ACM Transactions on Database Systems (TODS), </journal> <volume> 17(3) </volume> <pages> 423-464, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: We therefore describe the database schema abstractly, using an extended entity relationship (EER) diagram <ref> [57, 34] </ref>. An EER diagram is an ER diagram extended with is-a links. The database itself can be implemented in any number of ways, e:g:, as a relational database or as an object-oriented database. As shown in Figure 1, the EER diagram has two levels (separated by a dashed line).
Reference: [35] <author> D.C. Mattes. </author> <title> LIMS and good laboratory practice. </title> <booktitle> In [38], </booktitle> <pages> pages 332-345. </pages> <year> 1985. </year> <note> REFERENCES 43 </note>
Reference: [36] <author> J.M. McCarthy and P.J. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 4, </volume> <pages> pages 463-502. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year> <note> Reprinted in Readings in Artificial Intelligence, </note> <year> 1981, </year> <title> Tioga Publ. </title> <publisher> Co. </publisher>
Reference-contexts: Thus, the attributes (or type) of a material depend on the history of the material, as well as its class. This rather dynamic feature reflects the flexibility demanded by workflow management, and is closely related to research on time and action in artificial intelligence and logic programming <ref> [31, 30, 36, 44] </ref>. These issues are addressed in detail in Section 7, where we introduce structures that allow the view to be defined independently of the workflow, so that the view definition does not have to be changed each time the workflow changes. <p> For instance, the event calculus [31, 30] is a logic-programming methodology developed for recording and querying event histories. It includes special access structures to quickly retrieve most-recent results. As another example, the situation calculus <ref> [36, 44] </ref> encodes event histories as function terms. Queries in the situation calculus ask about the present database state, which is defined to be the result of the most-recent actions.
Reference: [37] <author> R.D. McDowall. </author> <title> Introduction to laboratory information management systems. </title> <booktitle> In [38], </booktitle> <pages> pages 1-16. </pages> <year> 1985. </year>
Reference: [38] <author> R.D. McDowell, </author> <title> editor. Laboratory Information Management Systems: Concepts, Integration, Implementation. </title> <publisher> Sigma Press, </publisher> <address> Wilmslow, U.K., </address> <year> 1985. </year>
Reference: [39] <author> C.B. Medeiros, G. Vossen, and M. Weske. WASA: </author> <title> A workflow-based architecture to support scientific database applications. </title> <booktitle> In International Workshop and Conference on Database and Expert Systems Applications (DEXA), </booktitle> <address> London, U.K., </address> <month> Sept 4-8 </month> <year> 1995. </year>
Reference: [40] <author> C. Mohan. </author> <title> Tutorial: A survey and critique of advanced transaction models. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> page 521, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year> <title> Tutorial. </title>
Reference: [41] <author> Allen S. Nakagawa. LIMS: </author> <title> Implementation and Management. </title> <institution> Royal Society of Chemistry, Thomas Granham House, The Science Park, </institution> <address> Cambridge CB4 4WF, England, </address> <year> 1994. </year>
Reference: [42] <institution> Object Design, Inc., </institution> <address> 25 Burlington Mall Rd., Burlington MA 01803-4194, USA. </address> <note> Manual set for ObjectStore Release 3.0 for UNIX Systems, </note> <month> December </month> <year> 1993. </year>
Reference-contexts: Although LabFlow-1 is intended to be a general benchmark for DBMSs, this paper uses it to compare storage managers only. This is achieved by running the benchmark on versions of LabBase implemented on top of different storage managers, as described above. This paper compares Object-Store (version 3.0) <ref> [32, 42] </ref> and Texas (version 0.3) [51, 59]. Compared to relational systems, these storage managers have been used in few production applications, so this analysis is interesting in its own right. <p> In the tests discussed here, we used several versions of the LabBase data server, which varied in storage management. The five versions for which we report results are: 1. OStore|a version relying on ObjectStore (v3.0) <ref> [32, 42] </ref> for storage management. 2. Texas|a version relying on the Texas storage manager (v0.3) [51, 59] for storage management. 3. Texas+TC|a version almost identical to Texas, and using the same storage manager, but with additional object clustering implemented in client code. 4.
Reference: [43] <author> P. O'Neal. </author> <title> The set query benchmark. </title> <booktitle> In [25], chapter 5, </booktitle> <pages> pages 209-245. </pages>
Reference-contexts: In contrast, the SEQUOIA 2000 benchmark [54] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS). The Set Query benchmark <ref> [43] </ref> is concerned with queries for decision support, including aggregation, multiple joins and report generation. (Such queries also arise in workflow management|for process re-engineering|but they are only part of the story.) Like these benchmarks, LabFlow-1 specifically targets a broad application area: workflow management.
Reference: [44] <author> R. Reiter. </author> <title> On formalizing database updates: Preliminary report. </title> <booktitle> In Proceedings of the International Conference on Extending Database Technology (EDBT), </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Thus, the attributes (or type) of a material depend on the history of the material, as well as its class. This rather dynamic feature reflects the flexibility demanded by workflow management, and is closely related to research on time and action in artificial intelligence and logic programming <ref> [31, 30, 36, 44] </ref>. These issues are addressed in detail in Section 7, where we introduce structures that allow the view to be defined independently of the workflow, so that the view definition does not have to be changed each time the workflow changes. <p> For instance, the event calculus [31, 30] is a logic-programming methodology developed for recording and querying event histories. It includes special access structures to quickly retrieve most-recent results. As another example, the situation calculus <ref> [36, 44] </ref> encodes event histories as function terms. Queries in the situation calculus ask about the present database state, which is defined to be the result of the most-recent actions.
Reference: [45] <author> S. Rozen and L. Stein and N. Goodman. </author> <title> Labbase User Manual. </title> <note> Available at ftp:// genome.wi.mit.edu/pub/papers/Y1994/labbase-manual.ps. </note>
Reference-contexts: Fortunately, one can build a specialized DBMS that supports workflow on top of a storage manager that does not. This approach is taken at the Genome Center. Their specialized DBMS (called LabBase <ref> [46, 53, 45] </ref>) provides the needed support for event histories and schema evolution on top of an object storage manager. LabBase provides a historical query language, as well as structures for rapid access into history lists. <p> Section 6 outlines the query language. The rest of this section outlines the implementation of schema evolution and the access mechanisms. Further details can be found in <ref> [45, 46, 47, 53] </ref>. 5.1 Schema Evolution and Storage Organization One challenge for a workflow wrapper in Architecture (C) is to provide the user with schema evolution on top of a storage manager with a schema that is difficult to change. 7;8 The wrapper must therefore distinguish between the user's schema
Reference: [46] <author> Steve Rozen, Lincoln Stein, and Nathan Goodman. </author> <title> Constructing a domain-specific DBMS using a persistent object system. In M.P. </title> <editor> Atkinson, V. Benzaken, and D. Maier, editors, </editor> <booktitle> Persistent Object Systems, Workshops in Computing. </booktitle> <publisher> Springer-Verlag and British Computer Society, </publisher> <year> 1995. </year> <note> Presented at POS-VI, Sep. 1994. Available at ftp://genome.wi.mit.edu/pub/papers/Y1994/ labbase-design.ps.Z. </note>
Reference-contexts: Fortunately, one can build a specialized DBMS that supports workflow on top of a storage manager that does not. This approach is taken at the Genome Center. Their specialized DBMS (called LabBase <ref> [46, 53, 45] </ref>) provides the needed support for event histories and schema evolution on top of an object storage manager. LabBase provides a historical query language, as well as structures for rapid access into history lists. <p> A material derives its attributes from the steps that have processed it. 5 Implementation the LabFlow-1 benchmark. This section briefly describes the three architectures, and then describes the architecture used in our benchmark tests in more detail. Further details can be found in <ref> [46, 47] </ref>. Architecture (A) represents the most direct test of a DBMS. Here, queries and updates from 5 IMPLEMENTATION 14 LabFlow-1 are submitted directly to the DBMS, without any intervening software. This architecture is suitable for testing DBMSs that have been designed with workflow management in mind. <p> Architecture (C) is a special case of Architecture (B). Here, the workflow wrapper is LabBase, and the DBMS is an object storage manager. The Genome Center currently uses this architecture with ObjectStore as its storage manager <ref> [46, 47] </ref>. In this paper, we use Architecture (C) to evaluate various object storage managers. Since LabBase is implemented in persistent C++, we chose storage managers that provide persistent C++ as an interface to the application programmer. In this way, each workflow-data manager uses virtually the same LabBase implementation. <p> Section 6 outlines the query language. The rest of this section outlines the implementation of schema evolution and the access mechanisms. Further details can be found in <ref> [45, 46, 47, 53] </ref>. 5.1 Schema Evolution and Storage Organization One challenge for a workflow wrapper in Architecture (C) is to provide the user with schema evolution on top of a storage manager with a schema that is difficult to change. 7;8 The wrapper must therefore distinguish between the user's schema <p> It is a deductive language in the tradition of Datalog and Prolog, and is very similar to the query language used at the Genome Center. The reasons the Genome Center uses a deductive query language have been described in detail elsewhere <ref> [24, 47, 46] </ref>. Broadly speaking, these reasons are expressiveness, simplicity and flexibility.
Reference: [47] <author> Steve Rozen, Lincoln Stein, and Nathan Goodman. LabBase: </author> <title> A database to manage laboratory data in a large-scale genome-mapping project. </title> <journal> IEEE Engineering in Medicine and Biology, </journal> <note> 1995. Available at ftp://genome.wi.mit.edu/pub/papers/Y1995/labbase.ps.gz. </note>
Reference-contexts: A material derives its attributes from the steps that have processed it. 5 Implementation the LabFlow-1 benchmark. This section briefly describes the three architectures, and then describes the architecture used in our benchmark tests in more detail. Further details can be found in <ref> [46, 47] </ref>. Architecture (A) represents the most direct test of a DBMS. Here, queries and updates from 5 IMPLEMENTATION 14 LabFlow-1 are submitted directly to the DBMS, without any intervening software. This architecture is suitable for testing DBMSs that have been designed with workflow management in mind. <p> Architecture (C) is a special case of Architecture (B). Here, the workflow wrapper is LabBase, and the DBMS is an object storage manager. The Genome Center currently uses this architecture with ObjectStore as its storage manager <ref> [46, 47] </ref>. In this paper, we use Architecture (C) to evaluate various object storage managers. Since LabBase is implemented in persistent C++, we chose storage managers that provide persistent C++ as an interface to the application programmer. In this way, each workflow-data manager uses virtually the same LabBase implementation. <p> Section 6 outlines the query language. The rest of this section outlines the implementation of schema evolution and the access mechanisms. Further details can be found in <ref> [45, 46, 47, 53] </ref>. 5.1 Schema Evolution and Storage Organization One challenge for a workflow wrapper in Architecture (C) is to provide the user with schema evolution on top of a storage manager with a schema that is difficult to change. 7;8 The wrapper must therefore distinguish between the user's schema <p> It is a deductive language in the tradition of Datalog and Prolog, and is very similar to the query language used at the Genome Center. The reasons the Genome Center uses a deductive query language have been described in detail elsewhere <ref> [24, 47, 46] </ref>. Broadly speaking, these reasons are expressiveness, simplicity and flexibility.
Reference: [48] <author> M. Rusinkiewicz and A. Sheth. </author> <title> Specification and execution of transactional workflows. </title> <editor> In W. Kim, editor, </editor> <title> Modern Database Systems: The Object Model, Interoperability, and Beyond. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: At present, this information is all embedded in application programs, as described in the next subsection. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, <ref> [48, 1, 58, 21] </ref>). This difference might be resolved if each material were associated with a single long-running activity. This activity would exist as long as the material is being processed, and would correspond to the sequence of workflow steps that process the material.
Reference: [49] <author> O. </author> <title> Serlin. The history of debit credit and the TPC. </title> <booktitle> In [25], chapter 2, </booktitle> <pages> pages 19-117. </pages>
Reference-contexts: This application is characterized by a demand for flexible management of a stream of queries and updates, and of historical data and schema. On the surface, LabFlow-1 might appear similar to some TPC benchmarks <ref> [49, 33] </ref>, which are also based on a stream of transactions that construct a history. As discussed in Section 9, however, the way in which the stream is generated (the workload) is very different. <p> We therefore need to provide a simple yet realistic sequence of events, both to build the database and to serve as a workload for our benchmark. To some extent this issue is addressed by the TPC benchmarks that simulate banking debit/credit transactions <ref> [49] </ref>. In our terminology, these benchmarks have one kind of material (bank accounts), and one kind of event (change account balance). They also have one kind of query: look up an account record given its key, and return its current balance.
Reference: [50] <author> A. Sheth. </author> <title> Workflow automation: </title> <booktitle> Applications technology and research. In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> page 469, </pages> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year> <note> Tutorial. Slides available at http:/www.cs.uga.edu/LSDIS. REFERENCES 44 </note>
Reference: [51] <author> Vivek Singhal, Sheetal V. Kakkad, and Paul R. Wilson. </author> <title> Texas: an efficient, portable persistent store. </title> <booktitle> In Proceedings of the Fifth International Workshop on Persistent Object Systems (POS-V), </booktitle> <address> San Minato, Italy, </address> <month> September </month> <year> 1992. </year> <note> Available at ftp://cs.utexas.edu/ pub/garbage/texaspstore.ps. </note>
Reference-contexts: This is achieved by running the benchmark on versions of LabBase implemented on top of different storage managers, as described above. This paper compares Object-Store (version 3.0) [32, 42] and Texas (version 0.3) <ref> [51, 59] </ref>. Compared to relational systems, these storage managers have been used in few production applications, so this analysis is interesting in its own right. <p> The five versions for which we report results are: 1. OStore|a version relying on ObjectStore (v3.0) [32, 42] for storage management. 2. Texas|a version relying on the Texas storage manager (v0.3) <ref> [51, 59] </ref> for storage management. 3. Texas+TC|a version almost identical to Texas, and using the same storage manager, but with additional object clustering implemented in client code. 4. Ostore-mm and Texas-mm|versions without any persistent storage management, and running entirely in main memory. <p> The involves relationship is implemented by keeping a (C++) pointer from each material instance to a list of pointers to step instances related to that material by involves. ObjectStore and Texas also both rely on pointer swizzling at page-fault time, as described in detail in <ref> [51] </ref>. However, internally they are rather different. ObjectStore offers concurrent access with lock 10 STORAGE-MANAGER COMPARISONS 37 based concurrency control implemented in a page server that mediates all access to the database. 21 Texas does not support concurrent access, and Texas programs access their database files directly.
Reference: [52] <author> A.H. Skarra and S.B. Zdonick. </author> <title> The management of changing types in an object-oriented database. </title> <booktitle> In Proceedings of the Conference on Object-oriented Programming Systems, Languages, and Applications, </booktitle> <pages> pages 483-495, </pages> <year> 1986. </year>
Reference-contexts: In effect, as a step evolves, new versions of the step are created. Each step object is associated forever with the same version of a step class; so schema changes do not require data re-organization. A similar approach to schema evolution can be found in <ref> [52] </ref>. The main difference is that LabBase does not use an explicit versioning mechanism. Instead, it identifies versions of objects by their attribute set, as illustrated in 3 WORKFLOW TRACKING IN LABFLOW-1 10 Section 8.1. <p> For this reason, a schema change does not result in a re-organization or migration of old data to the new schema (which represents a new workflow). Instead, each data object is associated forever with the class that created it, as in <ref> [52] </ref>. In our implementation, the storage manager has a fixed schema. It consists of exactly three classes, sm step, sm material, and material set, as shown in Table 1. Each instance of step in the user's schema becomes an instance of sm step in the storage schema.
Reference: [53] <author> Lincoln Stein, Steve Rozen, and Nathan Goodman. </author> <title> Managing laboratory workflow with LabBase. </title> <booktitle> In Proceedings of the 1994 Conference on Computers in Medicine (CompMed94). </booktitle> <publisher> World Scientific Publishing Company, </publisher> <year> 1995. </year> <note> In press. Available at ftp://genome.wi.mit.edu /pub/papers/Y1995/workflow.ps.Z. </note>
Reference-contexts: Fortunately, one can build a specialized DBMS that supports workflow on top of a storage manager that does not. This approach is taken at the Genome Center. Their specialized DBMS (called LabBase <ref> [46, 53, 45] </ref>) provides the needed support for event histories and schema evolution on top of an object storage manager. LabBase provides a historical query language, as well as structures for rapid access into history lists. <p> This model may be implicit (embedded in application programs), or explicit (specified in a declarative formalism). At present, the Genome Center takes an intermediate position: the ordering of workflow steps is made explicit in workflow graphs, while data dependencies are implicit in application programs <ref> [53] </ref>. Workflow graphs are based on the idea that each material has a workflow state, and that as the material is processed, it moves from one state to another. <p> As described in Section 2.2, a workflow management system must also provide a means of workflow modeling [22]. A workflow model specifies the dependencies among workflow steps. The Genome Center represents the most important dependencies as a workflow graph <ref> [53] </ref>. Workflow graphs are based on the idea that each material has a workflow state, and as the material is processed, it moves from one state to another. The workflow graph largely determines the workload for the DBMS. <p> Section 6 outlines the query language. The rest of this section outlines the implementation of schema evolution and the access mechanisms. Further details can be found in <ref> [45, 46, 47, 53] </ref>. 5.1 Schema Evolution and Storage Organization One challenge for a workflow wrapper in Architecture (C) is to provide the user with schema evolution on top of a storage manager with a schema that is difficult to change. 7;8 The wrapper must therefore distinguish between the user's schema
Reference: [54] <author> M. Stonebraker, J. Frew, K. Gardels, and J. Meredith. </author> <title> The Sequoia 2000 storage benchmark. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 2-11, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks [13, 12, 4] are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark <ref> [54] </ref> is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS). <p> The workflow graph largely determines the workload for the DBMS. Appendix B gives an example of a workflow graph, one that forms the basis of the workload for the LabFlow-1 benchmark. 4 Benchmark Database Schema Like the OO1 benchmark [13] and the Sequoia 2000 benchmark <ref> [54] </ref>, our benchmark is independent of the data model provided by the DBMS. We therefore describe the database schema abstractly, using an extended entity relationship (EER) diagram [57, 34]. An EER diagram is an ER diagram extended with is-a links.
Reference: [55] <author> Michael Strathmann, Bruce A. Hamilton, Carol A. Mayeda, Melvin I. Simon, Elliot M. Meyerowitz, and Michael J. Palazzolo. </author> <title> Transposon-facilitated DNA sequencing. </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. </institution> <address> USA, </address> <pages> pages 1247-1250, </pages> <month> February </month> <year> 1991. </year>
Reference: [56] <author> Abdullah Uz Tansel, James Clifford, Shashi Gadia, Sushil Jajodia, Arie Segev, and Richard Snodgrass. </author> <title> Temporal Databases. </title> <publisher> The Benjamin/Cummings Publishing Company, Inc., </publisher> <year> 1993. </year>
Reference-contexts: This requires some care, however, since steps can be entered into the database in any order, and there is no guarantee that a step being entered is the most recent. To use the terminology of temporal databases, "most recent" is based on valid time, not transaction time <ref> [56] </ref>.
Reference: [57] <author> T.J. Teorey, D. Yang, and J.P. Fry. </author> <title> A logical design methodology for relational databases using the extended entity-relationship model. </title> <journal> ACM Computing Surveys, </journal> <volume> 18 </volume> <pages> 197-222, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: We therefore describe the database schema abstractly, using an extended entity relationship (EER) diagram <ref> [57, 34] </ref>. An EER diagram is an ER diagram extended with is-a links. The database itself can be implemented in any number of ways, e:g:, as a relational database or as an object-oriented database. As shown in Figure 1, the EER diagram has two levels (separated by a dashed line).
Reference: [58] <author> Helmut Wachter and Andreas Reuter. </author> <title> The ConTract model. </title> <editor> In A. K. Elmagarmid, editor, </editor> <booktitle> Database Transaction Models for Advanced Applications, </booktitle> <pages> pages 219-264. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: At present, this information is all embedded in application programs, as described in the next subsection. It is worth noting that the idea of assigning states to materials contrasts with transactional work-flow, in which states are assigned to long-running activities (e:g:, <ref> [48, 1, 58, 21] </ref>). This difference might be resolved if each material were associated with a single long-running activity. This activity would exist as long as the material is being processed, and would correspond to the sequence of workflow steps that process the material.
Reference: [59] <author> Paul R. Wilson and Sheetal V. Kakkad. </author> <title> Pointer swizzling at page fault time: Efficiently and compatibly supporting huge address spaces on standard hardware. </title> <booktitle> In International Workshop on Object Orientation in Operating Systems, </booktitle> <year> 1992. </year> <note> Available at ftp://cs.utexas.edu/ pub/garbage/swizz.ps. </note>
Reference-contexts: This is achieved by running the benchmark on versions of LabBase implemented on top of different storage managers, as described above. This paper compares Object-Store (version 3.0) [32, 42] and Texas (version 0.3) <ref> [51, 59] </ref>. Compared to relational systems, these storage managers have been used in few production applications, so this analysis is interesting in its own right. <p> The five versions for which we report results are: 1. OStore|a version relying on ObjectStore (v3.0) [32, 42] for storage management. 2. Texas|a version relying on the Texas storage manager (v0.3) <ref> [51, 59] </ref> for storage management. 3. Texas+TC|a version almost identical to Texas, and using the same storage manager, but with additional object clustering implemented in client code. 4. Ostore-mm and Texas-mm|versions without any persistent storage management, and running entirely in main memory.
References-found: 59

