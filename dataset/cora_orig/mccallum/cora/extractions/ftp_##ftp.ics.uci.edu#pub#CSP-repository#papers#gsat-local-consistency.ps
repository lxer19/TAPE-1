URL: ftp://ftp.ics.uci.edu/pub/CSP-repository/papers/gsat-local-consistency.ps
Refering-URL: http://www.ics.uci.edu/~mlearn/MLPapers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: GSAT and Local Consistency  
Author: Kalev Kask Rina Dechter 
Address: Irvine, CA 92717 USA  Irvine, CA 92717 USA  
Affiliation: Computer Science Department University of California at Irvine  Computer Science Department University of California at Irvine  
Abstract: It has been shown that hill-climbing constraint satisfaction methods like min-conflicts [ Minton et al., 1990 ] and GSAT [ Selman et al., 1992 ] can outperform complete systematic search methods like backtracking and backjumping on many large classes of problems. In this paper we investigate how preprocessing improves GSAT. In particular, we will focus on the effect of enforcing local consistency on the performance of GSAT. We will show that enforcing local consistency on uniform random problems has very little effect on the performance of GSAT. However, when the problem has hierarchical structure, local consistency can significantly improve GSAT. It has been shown [ Konolige, 1994 ] that there are certain structured problems that are very hard for GSAT while being very easy for the Davis-Putnam procedure. We will show that they become very easy for GSAT once a certain level of local con sistency is enforced.
Abstract-found: 1
Intro-found: 1
Reference: [ Dechter and Meiri, 1994 ] <author> R. Dechter and I. Meiri. </author> <title> Experimental Evaluation of Constraint Processing. </title> <journal> Artificial Intelligence, </journal> <volume> 68, </volume> <pages> 211-241, </pages> <year> 1994. </year>
Reference-contexts: It was shown that path consistency can potentially improve the performance of any backtracking search algorithm [ Mackworth, 1977 ] , since it frequently eliminates all dead ends from the search space <ref> [ Dechter and Meiri, 1994 ] </ref> . It would be interesting to know if path consistency will also improve any local search algorithm like GSAT. Unfortunately the complexity of enforcing path consistency is fi (n 3 k 3 ) which is too large for big problems. <p> <ref> [ Dechter and Meiri, 1994 ] </ref> . It would be interesting to know if path consistency will also improve any local search algorithm like GSAT. Unfortunately the complexity of enforcing path consistency is fi (n 3 k 3 ) which is too large for big problems. It was shown in [ Dechter and Meiri, 1994 ] that for many problems the overhead of path consistency is not cost effective. Therefore instead of computing path consistency exactly we will approximate it by using a restricted form of path consistency called partial path consistency. The idea is the following.
Reference: [ Dechter and Rish, 1994 ] <author> R. Dechter and I. Rish. </author> <title> Directional Resolution: The Davis-Putnam Procedure, Revisited. </title> <booktitle> In Proceedings of the Fourth International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 134-145, </pages> <year> 1994. </year>
Reference-contexts: However, we can enforce local consistency that will change the structure of the problem by adding new, induced constraints. We ran GSAT on the same problems after a preprocessing algorithm RBR-3 was run on them. RBR-3 computes a restricted form of Bound-3 resolution <ref> [ Dechter and Rish, 1994 ] </ref> by resolving only pairs of original clauses and keeps only those resolvents that have no more that 3 literals.
Reference: [ Frost and Dechter, 1994 ] <author> D. Frost and R. Dechter. </author> <title> In Search of the Best Constraint Satisfaction Search. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 301-306, </pages> <year> 1994. </year>
Reference-contexts: We ran two experiments on the same set of problems, first with just GSAT and then partial path consistency (PPC) followed by GSAT. For comparison we have included the average running time per problem of a backjumping algorithm with dynamic variable ordering of <ref> [ Frost and Dechter, 1994 ] </ref> . As we can see, enforcing partial path consistency does help GSAT solve slightly more problems given the same upper bound M axF lips.
Reference: [ Gent and Walsh, 1993 ] <author> I. P. Gent and T. Walsh. </author> <title> Towards an Understanding of Hill-Climbing Procedures for SAT. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 28-33, </pages> <year> 1993. </year>
Reference-contexts: The basic GSAT is non-deterministic because it does not specify how to break ties between two or more variables having an equally good flip, or between two or more values that would give the same increase. <ref> [ Gent and Walsh, 1993 ] </ref> suggest using historic information instead of breaking ties randomly. They propose that in the event of a tie, a variable that was flipped the longest ago be chosen. We also use clause weighting as proposed by the Breakout method of P.
Reference: [ Hampson, 1993 ] <author> S. Hampson. </author> <title> Changing Max-Flips Automatically. </title> <type> Personal Communication, </type> <year> 1993. </year>
Reference-contexts: Last, there is always the problem of choosing MAX TRIES and MAX FLIPS. We solve this problem by using a heuristic that determines the length of every try (ie. MAX FLIPS) automatically during every try <ref> [ Hampson, 1993 ] </ref> . The idea is that we search as long as we are making progress, and if we haven't made progress for a while we give up and start a new try.
Reference: [ Konolige, 1994 ] <author> K. Konolige. </author> <title> Easy to be Hard: Difficult Problems for Greedy Algorithms. </title> <booktitle> In Proceedings of the Fourth International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 374-378, </pages> <year> 1994. </year>
Reference-contexts: However, on a class of structured cluster problems, local consistency dramatically improved the performance of GSAT. In a recent paper <ref> [ Konolige, 1994 ] </ref> it was shown that there are certain classes of structured problems that are very hard for GSAT, even if the best currently known heuristics like clause weighting and random walk are used, while being very easy for the Davis-Putnam procedure. <p> The characteristic feature of these problems is the presence of tightly connected clusters of variables which, in turn, are loosely connected by another set of global constraints. This class of problems was first discovered by Kono-lige <ref> [ Konolige, 1994 ] </ref> . In this paper we have shown how to deal with these kinds of problems. Our experiments show that enforcing local consistency, like bounded resolution, can make these problems almost trivial for GSAT.
Reference: [ Mackworth, 1977 ] <author> A. K. Mackworth. </author> <title> Consistency in Networks of Relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8(1), </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference-contexts: Enforcing path consistency makes the problem more explicit: constraints that are induced by other constraints are added to the problem and thus become explicit. It was shown that path consistency can potentially improve the performance of any backtracking search algorithm <ref> [ Mackworth, 1977 ] </ref> , since it frequently eliminates all dead ends from the search space [ Dechter and Meiri, 1994 ] . It would be interesting to know if path consistency will also improve any local search algorithm like GSAT.
Reference: [ Minton et al., 1990 ] <author> S. Minton, M. D. Johnston, A. B. Philips, and P. Laired. </author> <title> Solving Large Scale Constraint Satisfaction and Scheduling Problems Using Heuristic Repair Methods. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 17-24, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Local search algorithms like min-conflicts <ref> [ Minton et al., 1990 ] </ref> and GSAT [ Selman et al., 1992 ] have been successfully applied to different classes of constraint satisfaction problems like SAT, graph coloring, binary CSPs and scheduling.
Reference: [ Montanari, 1974 ] <author> U. Montanari. </author> <title> Networks of Constraints: Fundamental Properties and Applications to Picture Processing. </title> <journal> Information Science, </journal> <volume> 7, </volume> <pages> 95-132, </pages> <year> 1974. </year>
Reference-contexts: We now take (in section 5.1) a small detour to discuss different versions of path-consistency algorithms. 5.1 Partial Path Consistency A problem is path consistent (or 3-consistent) iff any in-stantiation of any two variables that is locally consistent can be extended to a consistent assignment of any third variable <ref> [ Montanari, 1974 ] </ref> . Enforcing path consistency makes the problem more explicit: constraints that are induced by other constraints are added to the problem and thus become explicit.
Reference: [ Morris, 1993 ] <author> P. Morris. </author> <title> The Breakout Method for Escaping From Local Minima. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 40-45, </pages> <year> 1993. </year>
Reference-contexts: They propose that in the event of a tie, a variable that was flipped the longest ago be chosen. We also use clause weighting as proposed by the Breakout method of P. Morris <ref> [ Morris, 1993 ] </ref> and in a different form in [ Selman and Kautz, 1993 ] . This method proposes a method of escaping local minimums by reweighting constraints. In addition, we use a version of random walk called random noise strategy in [ Sel-man et al., 1992 ] .
Reference: [ Selman et al., 1992 ] <author> B. Selman, H. Kautz, and B. Co-hen. </author> <title> Noise Strategies for Improving Local Search. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 337-343, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Local search algorithms like min-conflicts [ Minton et al., 1990 ] and GSAT <ref> [ Selman et al., 1992 ] </ref> have been successfully applied to different classes of constraint satisfaction problems like SAT, graph coloring, binary CSPs and scheduling. <p> This question is somewhat ambiguous since there is no one single version of GSAT most of them employ clever heuristics that significantly improve their performance over the basic version of GSAT reported in <ref> [ Selman et al., 1992 ] </ref> . <p> In addition, we use a version of random walk called random noise strategy in [ Sel-man et al., 1992 ] . This method suggests picking, with probability p, a variable that appears in an unsatisfied constraint and flipping its value. Unlike <ref> [ Selman et al., 1992 ] </ref> , we flip not one, but three variables at a time and the probability p is not 50-60%, but 10-15%.
Reference: [ Selman et al., 1992 ] <author> B. Selman, H. Levesque, and D. Mitchell. </author> <title> A New Method for Solving Hard Satisfiabil-ity Problems. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 440-446, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Local search algorithms like min-conflicts [ Minton et al., 1990 ] and GSAT <ref> [ Selman et al., 1992 ] </ref> have been successfully applied to different classes of constraint satisfaction problems like SAT, graph coloring, binary CSPs and scheduling. <p> This question is somewhat ambiguous since there is no one single version of GSAT most of them employ clever heuristics that significantly improve their performance over the basic version of GSAT reported in <ref> [ Selman et al., 1992 ] </ref> . <p> In addition, we use a version of random walk called random noise strategy in [ Sel-man et al., 1992 ] . This method suggests picking, with probability p, a variable that appears in an unsatisfied constraint and flipping its value. Unlike <ref> [ Selman et al., 1992 ] </ref> , we flip not one, but three variables at a time and the probability p is not 50-60%, but 10-15%.
Reference: [ Selman and Kautz, 1993 ] <author> B. Selman and H. Kautz. </author> <title> An Empirical Study of Greedy Local Search for Satisfia-bility Testing. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 46-51, </pages> <year> 1993. </year>
Reference-contexts: They propose that in the event of a tie, a variable that was flipped the longest ago be chosen. We also use clause weighting as proposed by the Breakout method of P. Morris [ Morris, 1993 ] and in a different form in <ref> [ Selman and Kautz, 1993 ] </ref> . This method proposes a method of escaping local minimums by reweighting constraints. In addition, we use a version of random walk called random noise strategy in [ Sel-man et al., 1992 ] .
Reference: [ Tarjan and Yannakakis, 1984 ] <author> E. Tarjan and M. Yan-nakakis. </author> <title> Simple Linear-Time Algorithms to Test Chordality of Graphs, Test Acyclicity of Hypergraphs and Selectively Reduce Acyclic Hypergraphs. </title> <journal> SIAM J. Comput., </journal> <volume> 13(3), </volume> <pages> pages 566-579, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: If C = 0 then it would result in a MaxDegree ordering; if C = n, then it would result in a MaxCardinality ordering ( <ref> [ Tarjan and Yannakakis, 1984 ] </ref> ).
Reference: [ van Beek, 1994 ] <author> P. van Beek. </author> <title> On the Inherent Level of Local Consistency in Constraint Networks. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 368-373, </pages> <year> 1994. </year>
Reference-contexts: The amount of changes made by path consistency depends on the amount of local consistency present in the problem in the beginning <ref> [ van Beek, 1994 ] </ref> , [ van Beek and Dechter, 1994 ] . Intuitively, the tighter the constraints and the denser the constraint graph, the more changes PC will make. <p> As we can see, enforcing partial path consistency does help GSAT solve slightly more problems given the same upper bound M axF lips. But if we include time in our 4 This tightness was chosen because problems with this tightness are not path consistent <ref> [ van Beek, 1994 ] </ref> . consideration we see that this strategy is not very useful since the total time it takes to solve a problem gets much worse. There are two reasons for this.
Reference: [ van Beek and Dechter, 1994 ] <author> P. can Beek and R. Dechter. </author> <title> Constraint Tightness versus Global Consistency. </title> <booktitle> In Proceedings of the Fourth International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 572-582, </pages> <year> 1994. </year>
Reference-contexts: The amount of changes made by path consistency depends on the amount of local consistency present in the problem in the beginning [ van Beek, 1994 ] , <ref> [ van Beek and Dechter, 1994 ] </ref> . Intuitively, the tighter the constraints and the denser the constraint graph, the more changes PC will make.
Reference: [ Yugami et al., 1994 ] <author> N. Yugami, Y. Ohta, and H. Hara. </author> <title> Improving Repair-Based Constraint Satisfaction Methods by Value Propagation. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 344-349, </pages> <year> 1994. </year>
Reference-contexts: The third heuristic we use is similar to the one proposed in <ref> [ Yugami et al., 1994 ] </ref> . Their method proposes a way of escaping local minimums by using value propagation over unsatisfied constraints. We pick an unsatisfied constraint and check to see if it contains any variables whose value has not yet been flipped. <p> We pick an unsatisfied constraint and check to see if it contains any variables whose value has not yet been flipped. If there is at least one, we will flip one of them so that the constraint becomes satisfied. There are two differences in what we do - <ref> [ Yugami et al., 1994 ] </ref> computes a closure under value propagation, whereas we do only a fixed number of steps. Second, in [ Yugami et al., 1994 ] this is done every time a local minimum is reached. <p> There are two differences in what we do - <ref> [ Yugami et al., 1994 ] </ref> computes a closure under value propagation, whereas we do only a fixed number of steps. Second, in [ Yugami et al., 1994 ] this is done every time a local minimum is reached. We do it only at the end of every try as a way of generating a new initial assignment for the next try.
References-found: 17

