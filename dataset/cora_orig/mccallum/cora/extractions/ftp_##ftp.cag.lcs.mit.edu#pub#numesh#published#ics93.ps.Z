URL: ftp://ftp.cag.lcs.mit.edu/pub/numesh/published/ics93.ps.Z
Refering-URL: http://www.cag.lcs.mit.edu/numesh/papers/published/ics.html
Root-URL: 
Email: numesh@cag.lcs.mit.edu  
Phone: (617) 253-6036  
Title: The NuMesh: A Modular, Scalable Communications Substrate  
Author: Steve Ward, Karim Abdalla, Rajeev Dujari, Michael Fetterman, Frank Honore, Ricardo Jenez, Philippe Laffont, Ken Mackenzie, Chris Metcalf, Milan Minsky, John Nguyen, John Pezaris, Gill Pratt, Russell Tessier 
Address: Cambridge, MA 02139  
Affiliation: MIT Laboratory for Computer Science  
Abstract: Many standardized hardware communication interfaces offer run-time flexibility and configurability at the cost of efficiency. An alternate approach is the use of a highly-efficient, minimal communication element, with as much communication decision-making as possible done at compile time. NuMesh is a packaging and interconnect technology supporting high-bandwidth systolic communications on a 3D nearest-neighbor lattice; our goal is to combine Lego-like modularity with supercomputer performance. To date, the primary focus of the project has been the class of applications whose static communication patterns can be precompiled into independent and carefully choreographed finite state machines running on each node. Several extensions of the NuMesh to more general communication paradigms have been implemented, and the issues involved are under active exploration. This paper presents an overview of our approach, as well as an introduction to our current-generation prototype. We also discuss 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Abelson, A. Berlin, J. Katzenelson, W. McAllister, G. Rozas, and G. Sussman. </author> <title> The Supercomputer Toolkit and its applications. </title> <booktitle> In Proc. of the Fifth Jerusalem Conference on Information Technology, </booktitle> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic [2, 7, 8, 10, 25], whereas systolic architectures [14, 15] and systems such as the Supercomputer Toolkit <ref> [1] </ref>, use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [2] <author> A. Agarwal, D. Chaiken, G. D'Souza, K. Johnson, D. Kranz, J. Kubi atowicz, K. Kurihara, B.-H. Lim, G. Maa, D. Nussbaum, M. Parkin, and D. Yeung. </author> <title> The MIT Alewife machine: A large-scale distributed-memory multiprocessor. </title> <booktitle> In Proceedings of Workshop on Scalable Shared Memory Multiprocessors. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year> <note> An extended version of this paper has been submitted for publication, and appears as MIT/LCS Memo TM-454, </note> <year> 1991. </year>
Reference-contexts: Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic <ref> [2, 7, 8, 10, 25] </ref>, whereas systolic architectures [14, 15] and systems such as the Supercomputer Toolkit [1], use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [3] <author> G. Anagnostou, D. Dewey, and A. T. Patera. </author> <title> Geometry-defining pro cessors for engineering design and analysis. </title> <journal> The Visual Computer, </journal> <volume> 5 </volume> <pages> 304-315, </pages> <year> 1989. </year>
Reference-contexts: Generalized communications support has been integrated with processors in a variety of research and commercial projects, including iWarp [6], the Transputer [13], and the GDP <ref> [3] </ref>; such provisions are beginning to appear in contemporary DSPs, such as the Texas Instruments TMS320C40. In the early 1980's, the Warp project [4] introduced the idea of a reconfigurable systolic communication framework that, like NuMesh, uses routing information obtained at compile-time to develop a communication pattern maximizing computational efficiency. <p> The Transputer uses relatively slow asynchronous com munication links, and is targeted primarily at embedded control applications. An extreme of reconfigurability in a processor mesh is reached by the novel Geometry-Defining Processor (GDP) <ref> [3] </ref>, whose processors communicate with neighbors using bit-serial optical links, also at modest speeds. The resulting flexibility supports an approach to the analysis of physical structures using processor configurations isomorphic to the emulated object.
Reference: [4] <author> M. Annaratone et al. </author> <title> Warp architecture and implementation. </title> <booktitle> In Proc. 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 346-356, </pages> <address> Los Alamitos, Calif., 1986. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Generalized communications support has been integrated with processors in a variety of research and commercial projects, including iWarp [6], the Transputer [13], and the GDP [3]; such provisions are beginning to appear in contemporary DSPs, such as the Texas Instruments TMS320C40. In the early 1980's, the Warp project <ref> [4] </ref> introduced the idea of a reconfigurable systolic communication framework that, like NuMesh, uses routing information obtained at compile-time to develop a communication pattern maximizing computational efficiency. Subsequently, iWarp [22], an enhanced version of Warp, provided improved compile-time capabilities and support for message-based communication using dynamic routing.
Reference: [5] <author> J. C. Bier et al. Gabriel: </author> <title> A design environment for DSP. </title> <journal> IEEE Micro, </journal> <volume> 10(5) </volume> <pages> 28-45, </pages> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Much of the thrust of the NuMesh project thus centers on compiler technology. Our goals include the fully automatic generation of NuMesh implementations of application-specific high-level pro gramming models that can be specified as real-time tasks; candidates include LaRCS [19], Gabriel <ref> [5, 17] </ref>, and CONSORT [27].
Reference: [6] <author> S. Borkar, R. Cohn, G. Cox, T. Gross, H. T. Kung, M. Lam, M. Levine, B. Moore, W. Moore, C. Peterson, J. Susman, J. Sutton, J. Urbanski, and J. Webb. </author> <title> Supporting systolic and memory communication in iWarp. </title> <booktitle> In Proc. 17th Annual Symposium on Computer Architecture, </booktitle> <address> Seattle, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Generalized communications support has been integrated with processors in a variety of research and commercial projects, including iWarp <ref> [6] </ref>, the Transputer [13], and the GDP [3]; such provisions are beginning to appear in contemporary DSPs, such as the Texas Instruments TMS320C40.
Reference: [7] <author> W. J. Dally et al. </author> <title> The J-Machine: A fine-grain concurrent computer. </title> <booktitle> In Information Processing 89, </booktitle> <publisher> Elsevier, </publisher> <year> 1989. </year>
Reference-contexts: Dependence on compile-time decisions regarding routing, deadlock avoidance, and resource allocation distinguishes the NuMesh communication substrate from more general dynamic networks such as those of Seitz [8, 25] or Dally <ref> [7] </ref>. One potential advantage of precompiled communication patterns is hardware simplicity, assuming run-time routing decisions can be eliminated altogether or handled infrequently with little dedicated hardware. More significant, however, is the amenability of such patterns to very high bandwidths because of their predictability. <p> Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic <ref> [2, 7, 8, 10, 25] </ref>, whereas systolic architectures [14, 15] and systems such as the Supercomputer Toolkit [1], use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [8] <author> W. J. Dally and C. L. Seitz. </author> <title> Deadlock free message routing in multipro cessor interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5), </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: Dependence on compile-time decisions regarding routing, deadlock avoidance, and resource allocation distinguishes the NuMesh communication substrate from more general dynamic networks such as those of Seitz <ref> [8, 25] </ref> or Dally [7]. One potential advantage of precompiled communication patterns is hardware simplicity, assuming run-time routing decisions can be eliminated altogether or handled infrequently with little dedicated hardware. More significant, however, is the amenability of such patterns to very high bandwidths because of their predictability. <p> Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic <ref> [2, 7, 8, 10, 25] </ref>, whereas systolic architectures [14, 15] and systems such as the Supercomputer Toolkit [1], use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [9] <author> R. Dujari. </author> <title> Parallel Viterbi search algorithm for speech recognition. </title> <type> Master's thesis, </type> <institution> EECS Department, MIT, </institution> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Real-time speech recognition is the goal of another large-scale NuMesh application, developed in concert with the MIT Laboratory for Computer Science's Spoken Language Systems (SLS) group [28]. We have implemented a pipelined NuMesh version of the Viterbi search used to perform lexical access <ref> [9] </ref>. The parallel decomposition of the Viterbi algorithm for the NuMesh partitions and distributes the lexical network to the processors, each of which is then able to perform Viterbi searching for its own part of the lexical network.
Reference: [10] <author> D. Gustavson et al. </author> <title> Scalable Coherent Interface: Logical, physical, and cache coherence specifications, </title> <month> Jan. </month> <year> 1991. </year> <note> Preliminary draft, </note> <institution> P1596 Working Group of the IEEE Microprocessor Standards Committee. </institution>
Reference-contexts: Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic <ref> [2, 7, 8, 10, 25] </ref>, whereas systolic architectures [14, 15] and systems such as the Supercomputer Toolkit [1], use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [11] <author> R. Halstead and S. Ward. </author> <title> The MuNet: A scalable decentralized architecture for parallel computation. </title> <booktitle> In Proc. Seventh International Symposium on Computer Architecture, </booktitle> <address> La Baule, France, </address> <month> May </month> <year> 1980. </year>
Reference-contexts: Each processor periodically sends a fixed number of messages, one to each of its physical neighbors. By controlling the contents of these messages, the processor can send individual messages to particular neighbors. This diffusion scheduling <ref> [11] </ref> approach eliminates the need for any precomputed communication paths. Tolerance to processor, router, and link failures is achieved via redundancy of subtask allocation. Each node keeps a record of all subtasks it has diffused away, although at a lower priority than non-diffused subtasks.
Reference: [12] <institution> Inmos Corporation. The Transputer Databook, 1989. Consolidated Printers, Berkeley, Calif. </institution>
Reference-contexts: It was found that although systolic communication was appropriate for many forms of scientific or business computing, some dynamic routing capabilities were needed to support general-purpose computing. Current Transputer systems from Inmos <ref> [12] </ref> share NuMesh features such as run-time reconfigurability and high level programmability. The Transputer uses relatively slow asynchronous com munication links, and is targeted primarily at embedded control applications.
Reference: [13] <institution> Inmos Ltd. IMS T800 Architecture, </institution> <year> 1987. </year> <note> Inmos Technical Note 6. </note>
Reference-contexts: Generalized communications support has been integrated with processors in a variety of research and commercial projects, including iWarp [6], the Transputer <ref> [13] </ref>, and the GDP [3]; such provisions are beginning to appear in contemporary DSPs, such as the Texas Instruments TMS320C40.
Reference: [14] <author> H. T. Kung. </author> <title> Deadlock avoidance for systolic communication. </title> <booktitle> In Proc. 15th Symposium on Computer Architecture, </booktitle> <address> Honolulu, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic [2, 7, 8, 10, 25], whereas systolic architectures <ref> [14, 15] </ref> and systems such as the Supercomputer Toolkit [1], use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [15] <author> H. T. Kung and C. E. Leiserson. </author> <title> Systolic arrays for VLSI. </title> <editor> In C. A. Mead and L. A. Conway, editors, </editor> <title> Introduction to VLSI Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1980. </year>
Reference-contexts: Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic [2, 7, 8, 10, 25], whereas systolic architectures <ref> [14, 15] </ref> and systems such as the Supercomputer Toolkit [1], use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [16] <author> M. Lam. </author> <title> A Systolic Array Optimizing Compiler. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1989. </year>
Reference-contexts: The complex scheduling issues that arise from such an approach demand either very dedicated programmers or a complete scheduling compiler such as that sketched by Lam <ref> [16] </ref>. One of our example programs uses a purely static communication scheme in implementing the multigrid algorithm for solving partial differential equations. In the static multigrid implementation, the communication overhead is relatively low since, when possible, data is routed from source processors to their destinations before it is requested.
Reference: [17] <author> E. A. Lee, W. Ho, E. Goei, J. Bier, and S. Bhattacharyya. Gabriel: </author> <title> A design environment for DSP. </title> <journal> IEEE Trans. on Acoustics, Speech, and Signal Processing, </journal> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: Much of the thrust of the NuMesh project thus centers on compiler technology. Our goals include the fully automatic generation of NuMesh implementations of application-specific high-level pro gramming models that can be specified as real-time tasks; candidates include LaRCS [19], Gabriel <ref> [5, 17] </ref>, and CONSORT [27].
Reference: [18] <author> H. Li and Q. Stout. </author> <title> Reconfigurable massively parallel computers: An introduction. </title> <editor> In Li and Stout, editors, </editor> <title> Reconfigurable Massively Parallel Computers. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year>
Reference-contexts: support bidirectional transfers at backplane bus speedsconsiderably slower than NuMesh communication bandwidthsand allow diagnosis, program loading, and application-dependent communication between the NuMesh and host. 2 This may be thought of as a pipelined version of the data paths in the Gated Connection Network by Li and Stout as described in <ref> [18] </ref>. The CFSMs are designed to allow the communication substrate to be loaded and tested independently of the local processor.
Reference: [19] <author> V. M. Lo, S. Rajopadhye, S. Gupta, et al. OREGAMI: </author> <title> tools for mapping parallel computations to parallel architectures. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(3) </volume> <pages> 237-270, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Much of the thrust of the NuMesh project thus centers on compiler technology. Our goals include the fully automatic generation of NuMesh implementations of application-specific high-level pro gramming models that can be specified as real-time tasks; candidates include LaRCS <ref> [19] </ref>, Gabriel [5, 17], and CONSORT [27].
Reference: [20] <author> K. MacKenzie. </author> <title> Numesh prototype hardware description. </title> <note> NuMesh Systems Memo 1, </note> <institution> MIT Computer Architecture Group, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: internal architecture compromises the goals described earlier (see Section 2.1.1) in a variety of ways; many of these compromises are lifted in next-generation prototypes currently under development. 3.1 CFSM Architecture Data paths for the prototype CFSMs consist of bidirectional registered transceivers that serve to isolate local buses of adjacent nodes <ref> [20] </ref>. The CFSM at each node contains North-South and East-West bus segments as shown in Figure 4, the two segments being linked by an interbus transceiver (called the X transceiver).
Reference: [21] <author> S. F. McCormick, </author> <title> editor. Multigrid methods. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: It can also be convenient to simulate much larger networks than we can currently build: for example, a multi grid <ref> [21] </ref> computation was tested on the simulator for sizes of over 16,000 nodes with 2,000 states in each CFSM; the processing code was written both in C and in generic assembler, and the CFSM code was generated by a dedicated multigrid routing compiler.
Reference: [22] <author> C. Peterson, J. Sutton, and P. Wiley. </author> <title> iWarp: A 100-MOPS, LIW multiprocessor for multicomputers. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 26-29, 81-87, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: In the early 1980's, the Warp project [4] introduced the idea of a reconfigurable systolic communication framework that, like NuMesh, uses routing information obtained at compile-time to develop a communication pattern maximizing computational efficiency. Subsequently, iWarp <ref> [22] </ref>, an enhanced version of Warp, provided improved compile-time capabilities and support for message-based communication using dynamic routing. It was found that although systolic communication was appropriate for many forms of scientific or business computing, some dynamic routing capabilities were needed to support general-purpose computing.
Reference: [23] <author> G. Pratt and J. Nguyen. </author> <title> Distributed synchronous clocking. </title> <journal> IEEE Transactions on Parallel and Distributed Systems. </journal> <note> In press. </note>
Reference-contexts: A scalable clock-synchronization technique, using only local communication between nodes, is used in the current prototypes. This synchronization technique has been proven to work for network connected as two-dimensional grids; extensive simulation has verified this result and suggests its effectiveness for grids of higher dimensions. For more information, see <ref> [23] </ref>. 3.2 Host Interface and Bootstrap A prototype NuMesh can connect either to a SPARCstation, via an SBus card connected to a prototype node's FIFO, or to a Macintosh, via a DMA NuBus card connected to a node's NuMesh port.
Reference: [24] <author> G. Pratt, S. Ward, C. Metcalf, J. Nguyen, and J. Pezaris. </author> <title> The diamond interconnect. In process, </title> <year> 1993. </year>
Reference-contexts: Further details on the diamond interconnect will be available shortly <ref> [24] </ref>. 3 Prototype NuMesh Early NuMesh prototypes with conservative performance parameters have been constructed using off-the-shelf TTL and CMOS chips. They plug together in a two-dimensional four-neighbor Cartesian mesh using standard 96-pin DIN connectors, or, with different placement of the connectors, in a three-dimensional four-neighbor diamond lattice.
Reference: [25] <author> C. L. Seitz. </author> <title> The Cosmic Cube. </title> <journal> Communications of the ACM, </journal> <volume> 28(1), </volume> <month> Jan. </month> <year> 1985. </year>
Reference-contexts: Dependence on compile-time decisions regarding routing, deadlock avoidance, and resource allocation distinguishes the NuMesh communication substrate from more general dynamic networks such as those of Seitz <ref> [8, 25] </ref> or Dally [7]. One potential advantage of precompiled communication patterns is hardware simplicity, assuming run-time routing decisions can be eliminated altogether or handled infrequently with little dedicated hardware. More significant, however, is the amenability of such patterns to very high bandwidths because of their predictability. <p> Many contemporary multiprocessors rely primarily upon run time decision-making for routing general communication traffic <ref> [2, 7, 8, 10, 25] </ref>, whereas systolic architectures [14, 15] and systems such as the Supercomputer Toolkit [1], use compile-time approaches to communication scheduling that offer potential cost/performance advantages in applications where communication patterns are largely predictable and macroscopically static.
Reference: [26] <author> S. B. Shukla and D. P. Agrawal. </author> <title> Scheduling pipelined communi cation in distributed memory multiprocessors for real-time applications. </title> <booktitle> In 18th Annual International Symposium on Computer Architecture (ACM SIGARCH Computer Architecture News vol. </booktitle> <volume> 19 no. 3), </volume> <year> 1991. </year>
Reference-contexts: Further, run-time collisions can be avoided by precompiling message schedules, allowing a higher level of communications traffic before saturation, as shown by Shukla and Agrawal <ref> [26] </ref>. Our goal is to develop hardware modules and supporting software that allow high-performance, special-purpose multiprocessors to be configured for particular applications by simply plugging together the appropriate NuMesh-based modules.
Reference: [27] <author> S. Ward. </author> <title> An approach to real-time computation. </title> <booktitle> In Proc. Seventh Texas Conference on Computing Systems, </booktitle> <address> Houston, TX., </address> <month> Oct. </month> <year> 1978. </year>
Reference-contexts: Much of the thrust of the NuMesh project thus centers on compiler technology. Our goals include the fully automatic generation of NuMesh implementations of application-specific high-level pro gramming models that can be specified as real-time tasks; candidates include LaRCS [19], Gabriel [5, 17], and CONSORT <ref> [27] </ref>.
Reference: [28] <author> V. Zue, J. Glass, D. Goodine, M. Phillips, and S. Seneff. </author> <title> The Summit speech recognition system: phonological modelling and lexical access. </title> <booktitle> In IEEE Intl. Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> Albuquerque, NM, </address> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: Real-time speech recognition is the goal of another large-scale NuMesh application, developed in concert with the MIT Laboratory for Computer Science's Spoken Language Systems (SLS) group <ref> [28] </ref>. We have implemented a pipelined NuMesh version of the Viterbi search used to perform lexical access [9].
References-found: 28

