URL: ftp://csg-ftp.lcs.mit.edu/pub/users/bradley/dimacs94.ps.Z
Refering-URL: http://theory.lcs.mit.edu/~cilk/starsoc.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fcfj,bradleyg@lcs.mit.edu  
Title: Massively Parallel Chess  
Author: Christopher F. Joerg and Bradley C. Kuszmaul 
Date: October 1994)  
Note: (To be presented at the DIMACS'94 Challenge,  
Address: NE43-247, 545 Technology Square Cambridge, MA 02139  
Affiliation: MIT Laboratory for Computer Science  
Abstract: Computer chess provides a good testbed for understanding dynamic MIMD-style computations. To investigate the programming issues, we engineered a parallel chess program called *Socrates, which running on the NCSA's 512 processor CM-5, tied for third in the 1994 ACM International Computer Chess Championship. *Socrates uses the Jamboree algorithm to search game trees in parallel and uses the Cilk 1.0 language and run-time system to express and to schedule the computation. In order to obtain good performance for chess, we use several mechanisms not directly provided by Cilk, such as aborting computations and directly accessing the active message layer to implement a global transposition table distributed across the processors. We found that we can use the critical path C and the total work W to predict the performance of our chess programs. Empirically *Socrates runs in time T 0:95C +1:09W=P on P processors. For best-ordered uniform trees of height h and degree d the average available parallelism in Jamboree search is Q((d=2) h=2 ). *Socrates searching real chess trees under tournament time controls yields average available parallelism of over 1000. 
Abstract-found: 1
Intro-found: 1
Reference: [ABD82] <author> Selim G. Akl, David T. Barnard, and Ralph J. Doran. </author> <title> Design and implementation of a parallel tree search algorithm. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-4 (2), </volume> <pages> pages 192-203, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: This approach to paral-lelizing game tree search is quite natural, and it has been used by several other parallel chess programs., such as Cray Blitz [HSN89] and Zugzwang [FMM91]. Still others have proposed or analyzed variations of this style of game tree search <ref> [ABD82, MC82, Fis84, Hsu90] </ref>. We do not claim that the search algorithm is a new contribution. Instead, we view the algorithm as a testbed for evaluating mechanisms needed for the design of scalable, predictable, asynchronous parallel programs. <p> Other parallel algorithms based on Scout search include minimal tree search, mandatory work first, and principal variation splitting. S. Akl, D. Barnard and R. Do-ran <ref> [ABD82] </ref> proposed the minimal tree search, which performs the weak ff-fi search by searching the minimal tree (i.e., the Knuth-Moore critical tree [KM75]). Each position is kept in an expanded form, potentially for a long time, resulting in unrealistic storage requirements.
Reference: [Bau78] <author> G. M. Baudet. </author> <title> The Design and Analysis of Algorithms for Asynchronous Multiprocessors. </title> <type> Technical Report CMU-CS-78-116, </type> <institution> CMUCS, </institution> <month> April </month> <year> 1978, </year> <type> 182 pp. (Ph.D. thesis.) </type>
Reference-contexts: The efficiency of our programs appears to be somewhat lower, probably because the Zugzwang team has gone to substantial effort to try to ensure that they search the tree in a mostly best-first order. The parallel aspiration search algorithm <ref> [Bau78] </ref> divides the ff-fi window into segments, and gives each processor a different segment of the window to search. Aspiration search achieves only small parallel speedups. Surprisingly, the serial version of aspiration search often runs faster than a infinite window search.
Reference: [Ber79] <author> Hans Berliner. </author> <title> The B* tree search algorithm: a best-first proof procedure. </title> <journal> Artificial Intelligence, </journal> <volume> 12, </volume> <pages> pages 23-40, </pages> <year> 1979. </year>
Reference-contexts: There are several other approaches to game tree search that are not based on ff-fi search. H. Berliner's B* search algorithm <ref> [Ber79] </ref> tries to prove that one of the moves is better with respect to a pessimistic evaluation than any of the other moves with respect to an optimistic evaluation. D.
Reference: [BE89] <author> Hans Berliner and Carl Ebeling. </author> <title> Pattern knowledge and search: the SUPREM architecture. </title> <journal> Artificial Intelligence, </journal> <volume> 38 (2), </volume> <pages> pages 161-198, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Berliner's serial Hitech program <ref> [BE89] </ref>, and running on NCSA's 512-node CM-5, tied for third in the 1993 ACM International Chess Championship. *Socrates borrowed many of the techniques we developed for *Tech, including the basic search algorithm and the transposition table. *Socrates uses a new programming language and run-time system called Cilk 1.0 [BJK*94] to separate
Reference: [BJK*94] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Phil Lisiecki, Keith H. Randall, Andy Shaw, and Yuli Zhou. </author> <title> Cilk 1.1 Reference Manual. </title> <institution> Massachusetts Institute of Technology, Laboratory for Computer Science, </institution> <month> September </month> <year> 1994. </year> <note> (Avail 15 able via anonymous FTP from theory.lcs.mit.edu in /pub/cilk/manual1.0.ps.Z.) </note>
Reference-contexts: Hitech program [BE89], and running on NCSA's 512-node CM-5, tied for third in the 1993 ACM International Chess Championship. *Socrates borrowed many of the techniques we developed for *Tech, including the basic search algorithm and the transposition table. *Socrates uses a new programming language and run-time system called Cilk 1.0 <ref> [BJK*94] </ref> to separate the chess program from the problems of scheduling and load balancing on a parallel computer. To help manage the complexity of our chess systems, we divided the programming problem into two parts: an application and a scheduler. <p> We use a run-time system called Cilk 1.0 <ref> [BJK*94] </ref> 8 to distribute work among the CM-5 processors. This section explains how a program is expressed in Cilk and how the computation is distributed across the machine. To distribute work among CM-5 processors, Cilk uses a randomized work-stealing approach, in which idle processors request work. <p> The fib thread creates a thread to sum two results, and passes continuations (denoted x and y) for that thread to two subsidiary fib threads. For a more complete description of the Cilk syntax, including a tutorial, see <ref> [BJK*94] </ref>. Similarly for the Jamboree algorithm, we transform the search code shown in Figure 5 into a dataflow graph, as shown in Figure 8. Then we express the program in Cilk analogously to the Fibonacci example. Cilk automatically computes the critical path length and total work of a computation. <p> Jamboree search was used in our previous program, *Tech [Kus94]. *Socrates is a step forward compared to *Tech because we introduced a linguistic layer and run-time system called Cilk 1.0 <ref> [BJK*94] </ref> to make it easier to program the application without worrying about the scheduling issues. Many of the techniques originally used in *Tech were borrowed for *Socrates.
Reference: [BL94] <author> Robert D. Blumofe and Charles E. Leiserson. </author> <title> Scheduling multithreaded computations by work stealing. </title> <booktitle> In Proceedings of the 35th Annual Symposium on Foundations of Computer Science (FOCS '94), </booktitle> <address> Santa Fe, New Mexico, </address> <month> November </month> <year> 1994. </year> <note> (To appear.) </note>
Reference-contexts: Many of the techniques originally used in *Tech were borrowed for *Socrates. Inspired by some problems we had with early versions of our *Tech program, Leiserson and Blumofe designed a provably good scheduler that has good space and time bounds, as well as low communications requirements <ref> [BL94] </ref>. Other parallel algorithms based on Scout search include minimal tree search, mandatory work first, and principal variation splitting. S. Akl, D. Barnard and R. Do-ran [ABD82] proposed the minimal tree search, which performs the weak ff-fi search by searching the minimal tree (i.e., the Knuth-Moore critical tree [KM75]).
Reference: [Bre74] <author> Richard P. Brent. </author> <title> The parallel evaluation of general arithmetic expressions. </title> <journal> Journal of the ACM, </journal> <volume> 21 (2), </volume> <pages> pages 201-206, </pages> <month> April </month> <year> 1974. </year>
Reference-contexts: For example, the effectiveness with which the available work is scheduled into the machine can be measured by comparing it to the bound from Brent's theorem <ref> [Bre74, Lemma 2] </ref>, which states that the runtime on P processors with a perfect scheduler can be brought down to no more than C + W=P . The values of W and C depend on the parallel algorithm, rather than on the scheduler.
Reference: [BB94] <author> Eric A. Brewer and Robert D. Blumofe. Strata: </author> <title> A MultiLayer Communications Library. </title> <type> Technical Report, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> January </month> <year> 1994. </year> <note> (To appear. Available via anonymous FTP from ftp.lcs.mit.edu in /pub/supertech/strata.) </note>
Reference-contexts: To avoid the complexity involved in such a modification we chose to implement a blocking transposition table. Since there is no way to implement this blocking mechanism using Cilk primitives, we dropped to a lower level and used the Strata active message library <ref> [BB94] </ref>. We designed the transposition table such that all accesses are atomic. For example when a value is to be put into the table, the information about the position is sent to the node where the entry resides, and that node updates the entry as required.
Reference: [FMM91] <author> R. Feldmann, P. Mysliwietz, and B. Monien. </author> <title> A fully distributed chess program. </title> <editor> In D. F. Beal, ed., </editor> <booktitle> Advances in Computer Chess 6, </booktitle> <pages> pages 1-27, </pages> <publisher> Ellis Horwood, </publisher> <address> Chichester, West Sussex, England, London, </address> <year> 1991. </year> <note> (Conference held in August 1990.) </note>
Reference-contexts: This approach to paral-lelizing game tree search is quite natural, and it has been used by several other parallel chess programs., such as Cray Blitz [HSN89] and Zugzwang <ref> [FMM91] </ref>. Still others have proposed or analyzed variations of this style of game tree search [ABD82, MC82, Fis84, Hsu90]. We do not claim that the search algorithm is a new contribution. <p> Later work has separated the scheduler from the algorithm. For example, Cray Blitz [HSN89] apparently uses PV-splitting with something like a work-stealing scheduler. No critical path analysis or measurement has been performed for Cray Blitz, however. The Zugzwang program, developed by R. Feldmann, P. Mysliwietz, and B. Monien <ref> [FMM91] </ref>, uses a par allel search algorithm that is very similar to Jamboree search. Zugzwang achieves high work-efficiency, searching to within a few percent the same number of nodes in a parallel search as in a sequential search.
Reference: [FMM93] <author> R. Feldmann, P. Mysliwietz, and B. Monien. </author> <title> Game tree search on a massively parallel system. </title> <booktitle> In Advances in Computer Chess 7, </booktitle> <year> 1993. </year> <note> (The conference was held in June 1993, but the proceedings have not published as of August 1993.) </note>
Reference-contexts: Without such a methodology it can be very difficult to do algorithm design. For example, Feldmann, Monien, and Mysliwietz find themselves changing their Zugzwang chess program to increase the parallelism without really having a good way to measure their changes <ref> [FMM93] </ref>. They express concern that by serially searching the first child before starting the other children they have reduced the available parallelism. Our technique allows us to state that there is sufficient parallelism to keep thousands of processors busy without changing the algorithm.
Reference: [FF82] <author> Raphael A. Finkel and John P. Fishburn. </author> <title> Parallelism in alpha-beta search. </title> <journal> Artificial Intellgence, </journal> <volume> 19 (1), </volume> <pages> pages 89-106, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Finkel and J. Fishburn showed that if the serialization implied by ff-fi pruning is ignored by a parallel program, then it will achieve only p P speedup on P processors <ref> [FF82] </ref>. 3 (A1) Define absearch (n; ff; fi) as (A2) If n is a leaf then return static eval (n). (A3) Let ~c the children of n, and (A4) b 1: (A5) For i from 0 below j~cj do: (A6) Let s absearch (~c i ; fi; ff): (A7) If s
Reference: [Fis83] <author> John P. Fishburn. </author> <title> Another optimization of alpha-beta search. </title> <journal> SIGART Newsletter, </journal> <volume> Number 84, </volume> <pages> pages 37-38, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: We started with a variant on serial ff-fi search, called Scout search, and modified it to be a parallel algorithm. This section explains the Scout search algorithm. Fishburn <ref> [Fis83] </ref>, who called it fail-soft ff-fi search.
Reference: [Fis84] <author> J. P. Fishburn. </author> <title> Analysis of Speedup in Distributed Algorithms. </title> <publisher> UMI Research Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1984. </year>
Reference-contexts: That is, Jamboree search is worse than serial ff-fi search, even on a machine with no overhead for communications or scheduling. For comparison, parallelized negamax search achieves linear speedup on worst-ordered trees, and Fishburn's MWF algorithm achieves not-quite linear speedup on worst-ordered trees <ref> [Fis84] </ref>. 2.6 Real Chess Trees For real chess trees, we found that the better the move ordering, the lower the critical path and the less total work is performed. <p> This approach to paral-lelizing game tree search is quite natural, and it has been used by several other parallel chess programs., such as Cray Blitz [HSN89] and Zugzwang [FMM91]. Still others have proposed or analyzed variations of this style of game tree search <ref> [ABD82, MC82, Fis84, Hsu90] </ref>. We do not claim that the search algorithm is a new contribution. Instead, we view the algorithm as a testbed for evaluating mechanisms needed for the design of scalable, predictable, asynchronous parallel programs. <p> Each position is kept in an expanded form, potentially for a long time, resulting in unrealistic storage requirements. The Deep-Thought parallel algorithm as described in Hsu's thesis [Hsu90] is a variant of the high-storage-requirement minimal tree search. J. Fishburn <ref> [Fis84] </ref> proposed the mandatory work first (MWF) algorithm. Algorithm MWF is based on the weak version of ff-fi search. It explicitly computes the number of critical children of the position being searched.
Reference: [HZJ94] <author> Michael Halbherr, Yuli Zhou, and Chris F. Joerg. </author> <title> MIMD-Style Parallel Programming Based on Continuation-Passing Threads. Computation Structures Group Memo 355, </title> <institution> Massachusetts Institute of Technology, Laboratory for Computer Science, </institution> <month> April </month> <year> 1994, </year> <pages> 22 pp. </pages> <note> (A shorter version will appear in Proc. of 2nd Int. Workshop on Massive Parallelism: Hardware, Software and Applications. Capri, </note> <institution> Italy, </institution> <month> Oct. </month> <year> 1994.) </year>
Reference-contexts: When a processor runs out work locally, it sends a message to another processor, selected at random, and removes work from that processor's collection of posted work. The Cilk system was original based on the Parallel Continuation Machine run-time system of Halbherr, Zhou and Joerg <ref> [HZJ94] </ref>. In PCM, the scheduler uses a double ended queue (a deque) on every processor. When a processor posts work, it pushes it on the bottom of the deque. When a processor needs more work to do locally, it pops it off the bottom of the deque.
Reference: [HL93] <author> Robert V. Hogg and Johanenes Ledolter. </author> <title> Applied Statistics for Engineers and Physical Scientists. </title> <publisher> Macmillan Publishing Company, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Kaufman, who is an International Master. Kaufman has published several larger sets of benchmarks [Kau92, Kau93] that were used to understand *Tech [Kus94]. 6 For a definition of sample correlation coefficients and other statistical terms see, for example, <ref> [HL93, page 51] </ref>. 7 The results presented here are for *Socrates.
Reference: [Hsu90] <author> Feng-hsiung Hsu. </author> <title> Large Scale Parallelization of Alpha-Beta Search: An Algorithmic and Architectural Study with Computer Chess. </title> <type> Technical report CMU-CS-90-108, </type> <institution> Computer Science Department, Carnegie-Mellon University, </institution> <address> Pitts-burgh, PA 15213, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: But the analysis above gives us an upper bound on the cost of busy-waiting. 11 Hsu claims that increasing the size of the hash table by a factor of 256 can easily give a factor of 2 to 5 speedup <ref> [Hsu90] </ref>. and before it completes and writes its result into the hash table Processor P2 begins another search of Position B. This leads to part of the search being duplicated. In the serial code these searches would be performed sequentially so this problem would not occur. <p> This approach to paral-lelizing game tree search is quite natural, and it has been used by several other parallel chess programs., such as Cray Blitz [HSN89] and Zugzwang [FMM91]. Still others have proposed or analyzed variations of this style of game tree search <ref> [ABD82, MC82, Fis84, Hsu90] </ref>. We do not claim that the search algorithm is a new contribution. Instead, we view the algorithm as a testbed for evaluating mechanisms needed for the design of scalable, predictable, asynchronous parallel programs. <p> Each position is kept in an expanded form, potentially for a long time, resulting in unrealistic storage requirements. The Deep-Thought parallel algorithm as described in Hsu's thesis <ref> [Hsu90] </ref> is a variant of the high-storage-requirement minimal tree search. J. Fishburn [Fis84] proposed the mandatory work first (MWF) algorithm. Algorithm MWF is based on the weak version of ff-fi search. It explicitly computes the number of critical children of the position being searched.
Reference: [HSN89] <author> Robert M. Hyatt, Bruce W. Suter, and Harry L. Nel-son. </author> <title> A parallel alpha/beta tree searching algorithm. </title> <journal> Parallel Computing, </journal> <volume> 10 (3), </volume> <pages> pages 299-308, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: This approach to paral-lelizing game tree search is quite natural, and it has been used by several other parallel chess programs., such as Cray Blitz <ref> [HSN89] </ref> and Zugzwang [FMM91]. Still others have proposed or analyzed variations of this style of game tree search [ABD82, MC82, Fis84, Hsu90]. We do not claim that the search algorithm is a new contribution. <p> Later work has separated the scheduler from the algorithm. For example, Cray Blitz <ref> [HSN89] </ref> apparently uses PV-splitting with something like a work-stealing scheduler. No critical path analysis or measurement has been performed for Cray Blitz, however. The Zugzwang program, developed by R. Feldmann, P. Mysliwietz, and B. Monien [FMM91], uses a par allel search algorithm that is very similar to Jamboree search.
Reference: [KZ89] <author> Richard M. Karp and Yanjun Zhang. </author> <title> On parallel evaluation of game trees. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 409-420, </pages> <address> Santa Fe, New Mexico, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Today most state-of-the-art chess programs, including *Tech, use a serial aspiration search in which the game tree is searched with a small ff-fi window, and if the score is outside of the window, the tree is researched. R. Karp and Y. Zhang <ref> [KZ89] </ref> show how to search an AND/OR tree in parallel by carefully allocating the right number of processors to each subtree. C. Stein [Ste92] employs Karp and Zhang's algorithm as a subroutine to do a parallel ff-fi search.
Reference: [Kau92] <author> Larry Kaufman. </author> <title> Rate your own computer. </title> <journal> Computer Chess Reports, </journal> <volume> 3 (1), </volume> <pages> pages 17-19, </pages> <year> 1992. </year> <note> (Published by ICD, 21 Walt Whitman Rd., </note> <institution> Huntington Station, </institution> <address> NY 11746, 1-800-645-4710.) </address>
Reference-contexts: The low coefficients on Equation 1 indicate that the program quickly finishes the available work during the 5 Our eight problems were provided by *Socrates team member L. Kaufman, who is an International Master. Kaufman has published several larger sets of benchmarks <ref> [Kau92, Kau93] </ref> that were used to understand *Tech [Kus94]. 6 For a definition of sample correlation coefficients and other statistical terms see, for example, [HL93, page 51]. 7 The results presented here are for *Socrates.
Reference: [Kau93] <author> Larry Kaufman. </author> <title> Rate your own computer part II. </title> <journal> Computer Chess Reports, </journal> <volume> 3 (2), </volume> <pages> pages 13-15, 1992-93. </pages>
Reference-contexts: The low coefficients on Equation 1 indicate that the program quickly finishes the available work during the 5 Our eight problems were provided by *Socrates team member L. Kaufman, who is an International Master. Kaufman has published several larger sets of benchmarks <ref> [Kau92, Kau93] </ref> that were used to understand *Tech [Kus94]. 6 For a definition of sample correlation coefficients and other statistical terms see, for example, [HL93, page 51]. 7 The results presented here are for *Socrates.
Reference: [KM75] <author> Donald E. Knuth and Ronald W. Moore. </author> <title> An analysis of alpha-beta pruning. </title> <journal> Artificial Intelligence, </journal> <volume> 6 (4), </volume> <pages> pages 293-326, </pages> <month> Winter </month> <year> 1975. </year>
Reference-contexts: Any one of a number of possibilities suffices. Thus, White can stop thinking about the move without having exhaustively searched all of Black's options. The idea of pruning subtrees that do not need to be searched is embodied in the serial ff-fi search algorithm <ref> [KM75] </ref>, which computes the negamax score for a node without actually looking at the entire search tree. The algorithm is expressed as a recursive subroutine with two new parameters ff and fi. <p> The ff-fi algorithm can substantially reduce the size of the tree searched. The ff-fi algorithm works best if the best moves are considered first, because if any move can make the position fail high, then certainly the best move can make the position fail high. Knuth and Moore <ref> [KM75] </ref> show that for searches of a uniform best-ordered tree of height H and degree D, the ff-fi algorithm searches only O ( D H ) leaves instead of D H leaves. <p> Other parallel algorithms based on Scout search include minimal tree search, mandatory work first, and principal variation splitting. S. Akl, D. Barnard and R. Do-ran [ABD82] proposed the minimal tree search, which performs the weak ff-fi search by searching the minimal tree (i.e., the Knuth-Moore critical tree <ref> [KM75] </ref>). Each position is kept in an expanded form, potentially for a long time, resulting in unrealistic storage requirements. The Deep-Thought parallel algorithm as described in Hsu's thesis [Hsu90] is a variant of the high-storage-requirement minimal tree search. J. Fishburn [Fis84] proposed the mandatory work first (MWF) algorithm.
Reference: [Kus94] <author> Bradley C. Kuszmaul. </author> <title> Synchronized MIMD Computing. </title> <type> Ph.D. thesis, </type> <institution> Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, </institution> <month> May </month> <year> 1994. </year> <note> (Available via anonymous FTP from csg-ftp.lcs.mit.edu in /pub/users/bradley/phd.ps.Z.) </note>
Reference-contexts: in the 1994 ACM International Computer Chess This research was supported in part by the Advanced Research Projects Agency (DoD) under Grants N00014-94-1-0985, N00014-92-J-1310, and N00014-91-J-1698. 1 http://csg-www.lcs.mit.edu:8001/Users/cfj/ 2 http://theory.lcs.mit.edu/bradley Championship held at the end of June 1994 in Cape May, New Jersey. *Socrates is a step forward from *Tech <ref> [Kus94] </ref>, our previous chess program. *Tech is based on H. <p> Here we summarize our results. The complete statement of the theorems and proofs can be found in <ref> [Kus94] </ref>. It turns out 5 that we have two analytical results, one for best ordered trees and one for worst ordered trees. Theorem 1 states how Jamboree search behaves on best-ordered trees. <p> Kaufman, who is an International Master. Kaufman has published several larger sets of benchmarks [Kau92, Kau93] that were used to understand *Tech <ref> [Kus94] </ref>. 6 For a definition of sample correlation coefficients and other statistical terms see, for example, [HL93, page 51]. 7 The results presented here are for *Socrates. A more complete analysis of the statistical properties of the measurements for *Tech can be found in Kuszmaul's dissertation [Kus94]. 6 rl0ZrZkZ Z0Z0Zpo0 Z0Z0aNO0 <p> used to understand *Tech <ref> [Kus94] </ref>. 6 For a definition of sample correlation coefficients and other statistical terms see, for example, [HL93, page 51]. 7 The results presented here are for *Socrates. A more complete analysis of the statistical properties of the measurements for *Tech can be found in Kuszmaul's dissertation [Kus94]. 6 rl0ZrZkZ Z0Z0Zpo0 Z0Z0aNO0 Z0Z0ZQZ0 Z0Z0ZRZR 0Z0Z0s0j 0obZ0Z0o 0Z0Z0Z0O Z0ZBZPZ0 0ZPZ0ZPZ 0ZrZ0ZkZ pZ0oPm0Z mpoPo0Z0 0Z0Z0Z0Z PZBL0O0Z Z0Z0ZKSR rZ0Z0skZ 0m0Z0ZpL pZ0Z0ZPZ 0lbZBO0O S0Z0S0J0 (a) Nfig7 (b) Re6 (c) Rfig7 20 (d) Ra2 rmbZkZ0s opZ0lpop 0Z0o0m0Z 0aPZ0Z0Z PO0ZNOPO S0ZQJBZR 0Z0Z0Z0Z 0Z0j0o0Z o0ZBmPZ0 0Z0ZPM0Z 0Z0Z0Z0Z bZ0s0skZ Z0l0Zpop pZnapm0Z ZpZ0Z0Z0 O0M0ONZ0 0A0ZQOPO ZBS0ZRJ0 Z0o0Z0Sp <p> Therefore all other processors would never use the hash table. As is often the case, bugs which affect only performance can be harder to detect than bugs that affect correctness. 6 Related Search Algorithms Our chess program uses Jamboree search <ref> [Kus94] </ref>, a paral-lelization of scout search [Pea80], in which at every node of the search tree, the program searches the first child to determine its value, and then tries to prove, in parallel, that all of the other children of the node are worse alternatives than the first child. <p> We do not claim that the search algorithm is a new contribution. Instead, we view the algorithm as a testbed for evaluating mechanisms needed for the design of scalable, predictable, asynchronous parallel programs. Jamboree search was used in our previous program, *Tech <ref> [Kus94] </ref>. *Socrates is a step forward compared to *Tech because we introduced a linguistic layer and run-time system called Cilk 1.0 [BJK*94] to make it easier to program the application without worrying about the scheduling issues. Many of the techniques originally used in *Tech were borrowed for *Socrates.
Reference: [MC82] <author> T. A. Marsland and M. S. Campbell. </author> <title> Parallel search of strongly ordered game trees. </title> <journal> ACM Computing Surveys, </journal> <volume> 14 (4), </volume> <pages> pages 533-552, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: This approach to paral-lelizing game tree search is quite natural, and it has been used by several other parallel chess programs., such as Cray Blitz [HSN89] and Zugzwang [FMM91]. Still others have proposed or analyzed variations of this style of game tree search <ref> [ABD82, MC82, Fis84, Hsu90] </ref>. We do not claim that the search algorithm is a new contribution. Instead, we view the algorithm as a testbed for evaluating mechanisms needed for the design of scalable, predictable, asynchronous parallel programs. <p> Hence, for worst ordered trees, Jamboree search finds little parallelism, while MWF finds much parallelism. Any chess program that is searching worst-ordered trees is not competitive, however. Several programs use principal variant splitting (PV-splitting) <ref> [MC82] </ref>, which is a another variation on MWF, but the ideas behind PV-splitting are, like MWF, somewhat obscured by the fact that a tree-of-processors sched-uler is entangled into the search algorithm. Later work has separated the scheduler from the algorithm.
Reference: [McA88] <author> David Allen McAllester. </author> <title> Conspiracy numbers for min-max search. </title> <journal> Artificial Intelligence, </journal> <volume> 35, </volume> <pages> pages 287-310, </pages> <year> 1988. </year>
Reference-contexts: H. Berliner's B* search algorithm [Ber79] tries to prove that one of the moves is better with respect to a pessimistic evaluation than any of the other moves with respect to an optimistic evaluation. D. McAllester's Conspiracy search <ref> [McA88] </ref> expands the tree in such a way that to change the value of the root will require changing the values of many of the leaves of the tree. The SSS* algorithm [Sto79] applies branch and bound techniques to game tree search.
Reference: [PJG*94] <author> Vijay S. Pande, Chris Joerg, Alexander Yu Grosberg, and Toyoichi Tanaka. </author> <title> Enumeration of the Hamiltonian walks on a cubic sublattice. </title> <journal> Journal of Physics A., </journal> <note> 1994. (To appear.) </note>
Reference-contexts: More importantly, *Socrates employs a linguistic layer to help the programmer express the program independently of the scheduler. Separating the system greatly simplified the im plementation of *Socrates, and allowed us to implement several other parallel applications including a protein folding program <ref> [PJG*94] </ref> which was the first program to find the number of Hamiltonian paths in a 4 fi 4 fi 3 grid, and some smaller programs such as the doubly recursive Fi-bonacci routine, a backtracking search to solve the problem of determining how many ways there are to place n queens on
Reference: [Pea80] <author> Judea Pearl. </author> <title> Asymptotic properties of minimax trees and game-searching procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 14 (2), </volume> <pages> pages 113-138, </pages> <month> September </month> <year> 1980. </year>
Reference-contexts: Pearl <ref> [Pea80] </ref>. Procedure scout is similar to Procedure absearch, except that when considering any child that is not the first child, a test is first performed to determine if the child is no better a move than the best move seen so far. <p> If the test fails, then scout searches the node twice and has squandered some work. Algorithm scout bets that the tests will succeed often enough to outweigh the extra cost of any nodes that must be searched twice, and empirical evidence <ref> [Pea80] </ref> justify its dominance as the search algorithm of choice in modern serial chess-playing programs. 2.4 Jamboree Search The Jamboree algorithm, shown in Figure 5, is a paral-lelized version of the Scout search algorithm. <p> Therefore all other processors would never use the hash table. As is often the case, bugs which affect only performance can be harder to detect than bugs that affect correctness. 6 Related Search Algorithms Our chess program uses Jamboree search [Kus94], a paral-lelization of scout search <ref> [Pea80] </ref>, in which at every node of the search tree, the program searches the first child to determine its value, and then tries to prove, in parallel, that all of the other children of the node are worse alternatives than the first child.
Reference: [Ste92] <author> Clifford Stein. </author> <title> Evaluating game trees in parallel. </title> <editor> In Charles E. Leiserson, ed., </editor> <booktitle> Proceedings of the 1992 MIT Student Workshop on VLSI and Parallel Systems, </booktitle> <pages> pages (47-1)- (47-2), </pages> <publisher> MIT Endicott House, </publisher> <month> July </month> <year> 1992. </year>
Reference-contexts: R. Karp and Y. Zhang [KZ89] show how to search an AND/OR tree in parallel by carefully allocating the right number of processors to each subtree. C. Stein <ref> [Ste92] </ref> employs Karp and Zhang's algorithm as a subroutine to do a parallel ff-fi search. Stein performs a binary search for the value of the game tree, at each stage converting the game tree to an AND/OR tree with the question Is the value of the root greater than s?.
Reference: [Sto79] <author> G. C. Stockman. </author> <title> A minimax algorithm better than alpha-beta? Artificial Intelligence, </title> <type> 12 (2), </type> <pages> pages 179-196, </pages> <month> August </month> <year> 1979. </year>
Reference-contexts: D. McAllester's Conspiracy search [McA88] expands the tree in such a way that to change the value of the root will require changing the values of many of the leaves of the tree. The SSS* algorithm <ref> [Sto79] </ref> applies branch and bound techniques to game tree search. These algorithms all require space which is nearly proportional to the run time of the algorithm, but the the constant of proportionality may be small enough to be feasible.
References-found: 28

