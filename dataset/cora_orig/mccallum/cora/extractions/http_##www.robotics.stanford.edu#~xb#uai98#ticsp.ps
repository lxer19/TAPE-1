URL: http://www.robotics.stanford.edu/~xb/uai98/ticsp.ps
Refering-URL: http://www.robotics.stanford.edu/~xb/uai98/index.html
Root-URL: http://www.robotics.stanford.edu
Email: xb@cs.stanford.edu  koller@cs.stanford.edu  
Title: Tractable Inference for Complex Stochastic Processes  
Author: Xavier Boyen Daphne Koller 
Note: page 1 of 25  
Date: 1998/03/17  
Affiliation: Stanford University Computer Science Dept.  Stanford University Computer Science Dept.  
Pubnum: Technical report  
Abstract: The monitoring and control of any dynamic system depends crucially on the ability to reason about its current status and its future trajectory. In the case of a stochastic system, these tasks typically involve the use of a belief state|a probability distribution over the state of the process at a given point in time. Unfortunately, the state spaces of complex processes are very large, making an explicit representation of a belief state intractable. Even in dynamic Bayesian networks (DBNs), where the process itself can be represented compactly, the representation of the belief state is intractable. We investigate the idea of utilizing a compact approximation to the true belief state, and analyze the conditions under which the errors due to the approximations taken over the lifetime of the process do not accumulate to make our answers completely irrelevant. We show that the error in a belief state contracts exponentially as the process evolves. Thus, even with multiple approximations, the error in our process remains bounded indefinitely. We show how the additional structure of a DBN can be used to design our approximation scheme, improving its performance significantly. We demonstrate the applicability of our ideas in the context of a monitoring task, showing that orders of magnitude faster inference can be achieved with only a small degradation in accuracy. 
Abstract-found: 1
Intro-found: 1
Reference: [ Astrom, 1965 ] <author> K.J. Astrom. </author> <title> Optimal control of Markov decision processes with incomplete state estimation. </title> <journal> J. Math. Anal. Applic., </journal> <volume> 10 </volume> <pages> 174-205, </pages> <year> 1965. </year>
Reference: [ Cover and Thomas, 1991 ] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley, </publisher> <year> 1991. </year> <note> page 24 of 25 </note>
Reference: [ Dagum et al., 1992 ] <author> P. Dagum, A. Galper, and E. Horwitz. </author> <title> Dynamic network models for forecasting. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1992. </year>
Reference: [ Dean and Kanazawa, 1989 ] <author> T. Dean and K. </author> <title> Kanazawa. A model for reasoning about persistence and causation. </title> <journal> Comp. Int., </journal> <volume> 5(3), </volume> <year> 1989. </year>
Reference: [ Forbes et al., 1995 ] <author> J. Forbes, T. Huang, K. Kanazawa, and S.J. Russell. </author> <title> The BATmobile: Towards a Bayesian automated taxi. </title> <booktitle> In Proc. IJCAI, </booktitle> <pages> pages 1878-1885, </pages> <year> 1995. </year>
Reference: [ Ghahramani and Jordan, 1996 ] <author> Z. Ghahramani and M.I. Jordan. </author> <title> Factorial hidden Markov models. </title> <booktitle> In NIPS 8, </booktitle> <year> 1996. </year>
Reference-contexts: has been fairly little work on approximate inference in complex temporal models. [ Kanazawa et al., 1995 ] utilizes random sampling, ignoring the structure of the process entirely. [ Provan, 1992 ] considers the idea of using domain knowledge to simply eliminate some of the variables from each time slice. <ref> [ Ghahramani and Jordan, 1996 ] </ref> and [ Saul and Jordan, 1995 ] utilize mean field approximation in the context of various types of HMMs. Of these approaches, [ Ghahramani and Jordan, 1996 ] is the closest to our work. <p> [ Provan, 1992 ] considers the idea of using domain knowledge to simply eliminate some of the variables from each time slice. <ref> [ Ghahramani and Jordan, 1996 ] </ref> and [ Saul and Jordan, 1995 ] utilize mean field approximation in the context of various types of HMMs. Of these approaches, [ Ghahramani and Jordan, 1996 ] is the closest to our work. There, the compound process is also approximated as being composed of independent subprocesses, whose parameters are chosen in a way that depends on the evidence.
Reference: [ Huang and Darwiche, 1994 ] <author> C. Huang and A. Darwiche. </author> <title> Inference in belief networks: a procedural guide. </title> <journal> Int. J. Approx. Reas., </journal> <volume> 11 </volume> <pages> 1-158, </pages> <year> 1994. </year>
Reference: [ Jensen et al., 1989 ] <author> F.V. Jensen, U. Kjrulff, K.G. Olesen, and J. Pedersen. </author> <title> An expert system for control of waste water treatment| a pilot project. </title> <type> Technical report, </type> <note> Judex Datasystemer A/S, </note> <institution> Aalborg, Denmark, </institution> <year> 1989. </year> <note> In Danish. </note>
Reference: [ Kalman, 1960 ] <author> R.E. </author> <title> Kalman. A new approach to linear filtering and prediction problems. </title> <journal> J. of Basic Engineering, </journal> <year> 1960. </year>
Reference: [ Kanazawa et al., 1995 ] <author> K. Kanazawa, D. Koller, and S.J. Russell. </author> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <booktitle> In Proc. UAI, </booktitle> <pages> pages 346-351, </pages> <year> 1995. </year>
Reference-contexts: Indeed, we get order of magnitude savings even for small processes, at the cost of a a very low error in our approximation. For larger processes, we expect the savings to be much greater. There has been fairly little work on approximate inference in complex temporal models. <ref> [ Kanazawa et al., 1995 ] </ref> utilizes random sampling, ignoring the structure of the process entirely. [ Provan, 1992 ] considers the idea of using domain knowledge to simply eliminate some of the variables from each time slice. [ Ghahramani and Jordan, 1996 ] and [ Saul and Jordan, 1995 ]
Reference: [ Kjrulff, 1992 ] <author> U. Kjrulff. </author> <title> A computational scheme for reasoning in dynamic probabilistic networks. </title> <booktitle> In Proc. UAI, </booktitle> <pages> pages 121-129, </pages> <year> 1992. </year>
Reference-contexts: We applied this idea to the task of monitoring a stochastic process, i.e., continuously maintaining a belief state over the state at the current time. This task is known to be infeasible in complex stochastic processes involving a large number of subprocesses, since exact inference (e.g., <ref> [ Kjrulff, 1992 ] </ref> ) is forced into intractability by the full correlation of the belief state that occurs even in highly structured processes. Our approach allows us to maintain an approximate belief state in a way that guarantees that the errors from our approximations do not accumulate.
Reference: [ Lauritzen and Spiegelhalter, 1988 ] <author> S.L. Lauritzen and D.J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Roy. Stat. Soc., </journal> <volume> B 50 </volume> <pages> 157-224, </pages> <year> 1988. </year>
Reference: [ Provan, 1992 ] <author> G. Provan. </author> <title> Tradeoffs in constructing and evaluating temporal influence diagrams. </title> <booktitle> In Proc. UAI, </booktitle> <pages> pages 40-47, </pages> <year> 1992. </year>
Reference-contexts: For larger processes, we expect the savings to be much greater. There has been fairly little work on approximate inference in complex temporal models. [ Kanazawa et al., 1995 ] utilizes random sampling, ignoring the structure of the process entirely. <ref> [ Provan, 1992 ] </ref> considers the idea of using domain knowledge to simply eliminate some of the variables from each time slice. [ Ghahramani and Jordan, 1996 ] and [ Saul and Jordan, 1995 ] utilize mean field approximation in the context of various types of HMMs.
Reference: [ Rabiner and Juang, 1986 ] <author> L. Rabiner and B. Juang. </author> <title> An introduction to hidden Markov models. </title> <booktitle> IEEE Acoustics, Speech & Signal Processing, </booktitle> <year> 1986. </year>
Reference: [ Saul and Jordan, 1995 ] <author> L.K. Saul and M.I. Jordan. </author> <title> Exploiting tractable substructure in intractable networks. </title> <booktitle> In NIPS 7, </booktitle> <year> 1995. </year>
Reference-contexts: inference in complex temporal models. [ Kanazawa et al., 1995 ] utilizes random sampling, ignoring the structure of the process entirely. [ Provan, 1992 ] considers the idea of using domain knowledge to simply eliminate some of the variables from each time slice. [ Ghahramani and Jordan, 1996 ] and <ref> [ Saul and Jordan, 1995 ] </ref> utilize mean field approximation in the context of various types of HMMs. Of these approaches, [ Ghahramani and Jordan, 1996 ] is the closest to our work.
Reference: [ Smyth et al., 1996 ] <author> P. Smyth, D. Heckerman, and M.I. Jordan. </author> <title> Probabilistic independence networks for hidden Markov probability models. </title> <journal> Neural Computation, </journal> <volume> 9(2) </volume> <pages> 227-269, </pages> <year> 1996. </year> <note> page 25 of 25 </note>
References-found: 16

