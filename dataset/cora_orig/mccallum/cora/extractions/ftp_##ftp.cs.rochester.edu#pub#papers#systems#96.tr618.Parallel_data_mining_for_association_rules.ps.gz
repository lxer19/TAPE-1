URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/96.tr618.Parallel_data_mining_for_association_rules.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~anp/bibtex/kdd.bib.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Parallel Data Mining for Association Rules on Shared-memory Multi-processors  
Author: M. J. Zaki, M. Ogihara, S. Parthasarathy, and W. Li 
Keyword: Data Mining, Association Rules, Load Balancing, Hash Tree Balancing, Hashing, Shared-Memory Multi-processor  
Note: supported this work. This work was supported in part by an NSF Research Initiation Award (CCR-9409120) and ARPA contract F19628-94-C-0057.  
Address: Rochester, New York 14627  
Affiliation: The University of Rochester Computer Science Department  The University of Rochester Computer Science Department  
Pubnum: Technical Report 618  
Email: fzaki,ogihara,srini,weig@cs.rochester.edu  
Date: May 1996  
Abstract: Data mining is an emerging research area, whose goal is to extract significant patterns or interesting rules from large databases. High-level inference from large volumes of routine business data can provide valuable information to businesses, such as customer buying patterns, shelving criterion in supermarkets and stock trends. Many algorithms have been proposed for data mining of association rules. However, research so far has mainly focused on sequential algorithms. In this paper we present parallel algorithms for data mining of association rules, and study the degree of parallelism, synchronization, and data locality issues on the SGI Power Challenge shared-memory multi-processor. We further present a set of optimizations for the sequential and parallel algorithms. Experiments show that a significant improvement of performance is achieved using our proposed optimizations. We also achieved good speed-up for the parallel algorithm, but we observe a need for parallel I/O techniques for further performance gains. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Database mining: A performance perspective. </title> <journal> In IEEE Trans. on Knowledge and Data Engg., </journal> <pages> pages 5(6) 914-925, </pages> <year> 1993. </year>
Reference-contexts: Data mining is an emerging research area, whose goal is to extract significant patterns or interesting rules from such large databases. Data mining is in fact a broad area which combines research in machine learning, statistics and databases. It can be broadly classified into three main categories <ref> [1] </ref>: Classification finding rules that partition the database into disjoint classes; Sequences extracting commonly occurring sequences in temporal data; and Associations find the set of most commonly occurring groupings of items. In this paper we will concentrate on data mining for association rules.
Reference: [2] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. ACM SIGMOD Intl. Conf. Management of Data, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: In this paper we will concentrate on data mining for association rules. The problem of mining association rules over basket data was introduced in <ref> [2] </ref>. Basket data usually consists of a record per customer with a transaction date, along with items bought by the customer. An example of an association rule over such a database could be that 80% of the customers that bought bread and milk, also bought eggs. <p> This iterative process is repeated for k = 3; 4; ; until there are no more large k-itemsets to be found. 1.1 Related Work Many algorithms for finding large itemsets have been proposed in the literature since the introduction of this problem in <ref> [2] </ref> (AIS algorithm). In [7] a pass minimization approach was presented, which uses the idea that if an itemset belongs to the set of large (k + e)-itemsets, then it must contain k k-itemsets. <p> Section 5 presents our experimental results for the different optimization and the parallel performance. Finally we conclude in section 6. 2 Sequential Data Mining We now present the formal statement of the problem of mining association rules over basket data. The discussion below closely follows that in <ref> [2, 4] </ref>. Let I = fi 1 ; i 2 ; ; i m g be a set of m distinct attributes, also called items. Each transaction T in the database D of transactions, has a unique identifier T ID, and contains a set of items, such that T I.
Reference: [3] <author> R. Agrawal and J. Shafer. </author> <title> Parallel mining of association rules: design, implementation, and experience. </title> <type> Technical Report RJ10004, </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, CA 95120, </address> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: In [9], a parallel implementation of the DHP algorithm [8] is presented. However only simulation results on a shared-nothing or distributed-memory machine like IBM SP2 were presented. Parallel implementations of the Apriori algorithm on the IBM SP2 were presented in <ref> [3] </ref>. There has been no study on shared-everything or shared-memory machines to-date. In this paper we present parallel implementations of the Apriori algorithm on the SGI Power Challenge shared-memory multi-processor. We study the degree of parallelism, synchronization, and data locality issues in par-allelizing data mining applications for such architectures.
Reference: [4] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In Proc. 20th VLDB Conf., </booktitle> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: In [7] a pass minimization approach was presented, which uses the idea that if an itemset belongs to the set of large (k + e)-itemsets, then it must contain k k-itemsets. The Apriori algorithm <ref> [4] </ref> also uses the property that any subset of a large itemset must itself be large. These algorithms had performance superior to AIS. Newer algorithms with better performance than Apriori were presented in [8, 10]. <p> Section 5 presents our experimental results for the different optimization and the parallel performance. Finally we conclude in section 6. 2 Sequential Data Mining We now present the formal statement of the problem of mining association rules over basket data. The discussion below closely follows that in <ref> [2, 4] </ref>. Let I = fi 1 ; i 2 ; ; i m g be a set of m distinct attributes, also called items. Each transaction T in the database D of transactions, has a unique identifier T ID, and contains a set of items, such that T I. <p> Generate rules from these large itemsets. Given that X is a large k-itemset, for every non-empty subset A X, a rule of the form A ) B is generated, where B = X A, and provided that this rule has the required confidence. We refer the reader to <ref> [4] </ref> for more detail on rule generation. Henceforth, we will deal only with the first step. In this paper we will discuss the parallelization of the Apriori algorithm on the SGI Challenge shared-memory machine. <p> The algorithm terminates at step t, if there are no large t-itemsets. The general structure of the algorithm is given in figure 1, and a brief discussion of each step is given below (for details on its performance characteristics, we refer the reader to <ref> [4] </ref>). In the figure L k denotes the set of large k-itemsets, and C k the set of candidate k-itemsets. <p> The databases are stored on an attached 2GB disk. All processors run IRIX 5.3, and data is obtained from the disk via a NFS file server. We used different synthetic databases with size ranging form 3MB to 70MB, generated using the procedure described in <ref> [4] </ref>. These database mimic the transactions 16 in a retailing environment. Each transaction has a unique ID followed by a list of items bought in that transaction. The data-mining provides information about the set of items generally bought together. Table 2 shows the databases used and their properties. <p> The number of transactions is denoted as jDj, average transaction size as jT j, and the average maximal potentially large itemset size as jIj. The number of maximal potentially large itemsets jLj = 2000, and the number of items N = 1000. We refer the reader to <ref> [4] </ref> for more detail on the database generation. All the experiments were performed with a minimum support value of 0.5%, and a leaf threshold of 2 (i.e., max of 2 itemsets per leaf). Figure 5 shows the number of iterations and the number of large itemsets found for different databases.
Reference: [5] <author> M. Holsheimer, M. Kersten, H. Mannila, and H. Toivonen. </author> <title> A perspective on databases and data mining. </title> <booktitle> In 1st Intl. Conf. Knowledge Discovery and Data Mining, </booktitle> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: The above algorithms are all specialized black-box techniques which do not use any database operations. Algorithms using only general-purpose DBMS systems and relational algebra operations have also been proposed <ref> [5, 6] </ref>. There has been very limited work in parallel implementations of association algorithms. In [9], a parallel implementation of the DHP algorithm [8] is presented. However only simulation results on a shared-nothing or distributed-memory machine like IBM SP2 were presented.
Reference: [6] <author> M. Houtsma and A. Swami. </author> <title> Set-oriented mining of association rules. In RJ 9567. </title> <institution> IBM Almaden, </institution> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: The above algorithms are all specialized black-box techniques which do not use any database operations. Algorithms using only general-purpose DBMS systems and relational algebra operations have also been proposed <ref> [5, 6] </ref>. There has been very limited work in parallel implementations of association algorithms. In [9], a parallel implementation of the DHP algorithm [8] is presented. However only simulation results on a shared-nothing or distributed-memory machine like IBM SP2 were presented.
Reference: [7] <author> H. Mannila, H. Toivonen, and I. Verkamo. </author> <title> Efficient algorithms for discovering association rules. </title> <note> In AAAI Wkshp. Knowledge Discovery in Databases, </note> <month> July </month> <year> 1994. </year>
Reference-contexts: This iterative process is repeated for k = 3; 4; ; until there are no more large k-itemsets to be found. 1.1 Related Work Many algorithms for finding large itemsets have been proposed in the literature since the introduction of this problem in [2] (AIS algorithm). In <ref> [7] </ref> a pass minimization approach was presented, which uses the idea that if an itemset belongs to the set of large (k + e)-itemsets, then it must contain k k-itemsets. The Apriori algorithm [4] also uses the property that any subset of a large itemset must itself be large.
Reference: [8] <author> J. S. Park, M. Chen, and P. S. Yu. </author> <title> An effective hash based algorithm for mining association rules. </title> <booktitle> In Proc. ACM SIGMOD Intl. Conf. Management of Data, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: The Apriori algorithm [4] also uses the property that any subset of a large itemset must itself be large. These algorithms had performance superior to AIS. Newer algorithms with better performance than Apriori were presented in <ref> [8, 10] </ref>. The DHP algorithm [8] uses a hash table in pass k to do efficient pruning of (k+1)-itemsets. The Partition algorithm [10] minimizes I/O by scanning the database only twice. <p> The Apriori algorithm [4] also uses the property that any subset of a large itemset must itself be large. These algorithms had performance superior to AIS. Newer algorithms with better performance than Apriori were presented in [8, 10]. The DHP algorithm <ref> [8] </ref> uses a hash table in pass k to do efficient pruning of (k+1)-itemsets. The Partition algorithm [10] minimizes I/O by scanning the database only twice. <p> Algorithms using only general-purpose DBMS systems and relational algebra operations have also been proposed [5, 6]. There has been very limited work in parallel implementations of association algorithms. In [9], a parallel implementation of the DHP algorithm <ref> [8] </ref> is presented. However only simulation results on a shared-nothing or distributed-memory machine like IBM SP2 were presented. Parallel implementations of the Apriori algorithm on the IBM SP2 were presented in [3]. There has been no study on shared-everything or shared-memory machines to-date.
Reference: [9] <author> J. S. Park, M. Chen, and P. S. Yu. </author> <title> Efficient parallel data mining for association rules. </title> <type> Technical Report RC20156, </type> <institution> IBM T. J. Watson Research Center, </institution> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: The above algorithms are all specialized black-box techniques which do not use any database operations. Algorithms using only general-purpose DBMS systems and relational algebra operations have also been proposed [5, 6]. There has been very limited work in parallel implementations of association algorithms. In <ref> [9] </ref>, a parallel implementation of the DHP algorithm [8] is presented. However only simulation results on a shared-nothing or distributed-memory machine like IBM SP2 were presented. Parallel implementations of the Apriori algorithm on the IBM SP2 were presented in [3].
Reference: [10] <author> A. Savasere, E. Omiecinski, and S. Navathe. </author> <title> An efficient algorithm for mining association rules in large databases. </title> <booktitle> In Proc. 21st VLDB Conf., </booktitle> <year> 1995. </year> <month> 22 </month>
Reference-contexts: The Apriori algorithm [4] also uses the property that any subset of a large itemset must itself be large. These algorithms had performance superior to AIS. Newer algorithms with better performance than Apriori were presented in <ref> [8, 10] </ref>. The DHP algorithm [8] uses a hash table in pass k to do efficient pruning of (k+1)-itemsets. The Partition algorithm [10] minimizes I/O by scanning the database only twice. <p> These algorithms had performance superior to AIS. Newer algorithms with better performance than Apriori were presented in [8, 10]. The DHP algorithm [8] uses a hash table in pass k to do efficient pruning of (k+1)-itemsets. The Partition algorithm <ref> [10] </ref> minimizes I/O by scanning the database only twice. In the first pass it generates 1 the set of all potentially large itemsets, and in the second pass the support for all these is measured. The above algorithms are all specialized black-box techniques which do not use any database operations.
References-found: 10

