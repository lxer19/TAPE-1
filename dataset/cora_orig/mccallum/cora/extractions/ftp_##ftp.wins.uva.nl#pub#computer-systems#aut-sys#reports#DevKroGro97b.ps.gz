URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/DevKroGro97b.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Navigation of a mobile robot on the temporal development of the optic flow  Novel Functions  
Author: Anuj Dev, Ben Krose, Frans Groen RWCP 
Address: Amsterdam  
Affiliation: Department of Computer Science, University of  
Note: Proc. of the IEEE/RSJ/GI Int. Conf. on Intelligent Robots and Systems IROS'97, Grenoble, Sept. 1997, pp 558-563.  
Pubnum: SNN Laboratory  
Abstract: The robot navigation task presented in this paper is to drive through the center of a corridor, based on a sequence of images from an on-board camera. Our measurements of the system state, the distance to the wall and orientation of the wall, are derived from the optic flow. Whereas the structure of the environment is usually computed from the spatial derivatives of the optic flow, we use the structure contained in the temporal derivatives of the optic flow to compute the environment structure and hence the system state. The algorithm is used to control a `remote brain' robot and results on the accuracy of the state estimates are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.R. Bruss and B.K. Horn. </author> <title> Passive navigation. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 21, pp3-20, </volume> <year> 1983. </year>
Reference-contexts: We thus can only measure the relative depth P z =T z . 3 Ego-motion, depth and orientation from the flow Rotation To estimate the rotation we eliminate the depth T z =P z from the estimated image motion equations (1) and (2) and obtain <ref> [1] </ref>: r y _r x r x _r y r y ! y = 0 However, we must keep in mind that the optic flow vectors are estimated from an image sequence (see [2]), and that we only have noisy measurements _r x and _r y .
Reference: [2] <author> A. Dev, B.J.A. Krose and F.C.A. Groen. </author> <title> Confidence measures for image motion estimation. </title> <booktitle> RWCP symposium, </booktitle> <address> Tokyo, </address> <year> 1997. </year>
Reference-contexts: the depth T z =P z from the estimated image motion equations (1) and (2) and obtain [1]: r y _r x r x _r y r y ! y = 0 However, we must keep in mind that the optic flow vectors are estimated from an image sequence (see <ref> [2] </ref>), and that we only have noisy measurements _r x and _r y . In a region R of the image where there is sufficient confidence in the flow-vectors ([2]) the flow is used to make a robust estimate of the camera rotation. <p> A block diagram is given in Figure 5. Images can be grabbed and stored in memory continuously. From a sequence of images the motion field is computed with the method reported in <ref> [2] </ref>. A description of the dynamical behavior of the system, the controller and some experiments in simulation are described in [4]. Here we present experimental results on the accuracy of the estimation of the state of the system.
Reference: [3] <author> J.J.Koenderink. </author> <title> Optic Flow. </title> <journal> Vision Research, </journal> <volume> 26(1), </volume> <pages> 161-180, </pages> <year> 1986. </year>
Reference-contexts: In order to perform this task, the sensing system has to provide information about the ego-motion of the system and the structure of the environment. The optic flow field provides such information: the ego-motion and relative depths can be derived directly from the flow vectors <ref> [3, 7] </ref>. To compute the spatial structure of the environment, such as surface normals, usually the spatial derivatives of the optic flow field are used. In this paper we show that the temporal derivative of the flow field can be used to provide a robust estimate of the environment structure. <p> In section 6 we discuss when to use the x and when to use the y component. Orientation Koenderink has analyzed the spatial variation r r ~ _r of the image motion, concluding that this matrix can be decomposed in terms of differential invariants of the vector field <ref> [3] </ref>.
Reference: [4] <author> B.J.A. Krose, A. Dev, X. Benavent and F.C.A. Groen. </author> <title> Vehicle navigation on optic flow. </title> <booktitle> RWCP symposium, </booktitle> <address> Tokyo, </address> <year> 1997. </year>
Reference-contexts: Images can be grabbed and stored in memory continuously. From a sequence of images the motion field is computed with the method reported in [2]. A description of the dynamical behavior of the system, the controller and some experiments in simulation are described in <ref> [4] </ref>. Here we present experimental results on the accuracy of the estimation of the state of the system. In order to have a calibrated image sequence, in which the path of the camera was known, we used a robot arm with a camera mounted in the end effector.
Reference: [5] <author> J. Santos-Victor, G. Sandini, F. Curotto and S. Garibaldi. </author> <title> Divergent Stereo in Autonomous Navigation: From Bees to Robots. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 14, </volume> <month> 159-177 </month> <year> (1995). </year>
Reference-contexts: In this paper we show that the temporal derivative of the flow field can be used to provide a robust estimate of the environment structure. Our approach differs from other presented approaches on visual `wall following' <ref> [5] </ref> in the sense that we are able to extract estimates of the orientation fl Dutch Foundation for Neural Networks of the wall, and not only scaled distances, which makes it possible to make a more robust controller.
Reference: [6] <author> H.C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 (10), </volume> <pages> pp 133-135, </pages> <year> 1981. </year>
Reference: [7] <author> S. Negahdaripour, S. Lee. </author> <title> Motion Recovery from Image Sequences Using Only First Order Optic Flow Information. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(3), </volume> <pages> 163-184, </pages> <year> 1992. </year> <title> 1 The "glitches" in the estimate of t (t), and hence in the state variables, are due to the erroneous reversal of odd and even frames in our frame grabber. 5 on the horizontal axis, of (from top to bottom): t (t) in seconds, d(t)=- in seconds and (t) in rad. seconds on the horizontal axis, of (from top to bottom): t (t) in seconds, d(t)=- in seconds and (t) in rad. </title> <type> 6 </type>
Reference-contexts: In order to perform this task, the sensing system has to provide information about the ego-motion of the system and the structure of the environment. The optic flow field provides such information: the ego-motion and relative depths can be derived directly from the flow vectors <ref> [3, 7] </ref>. To compute the spatial structure of the environment, such as surface normals, usually the spatial derivatives of the optic flow field are used. In this paper we show that the temporal derivative of the flow field can be used to provide a robust estimate of the environment structure.
References-found: 7

