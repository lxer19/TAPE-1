URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-163.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Robust Estimation Using Layers of Support  
Author: Trevor J. Darrell and Alex P. Pentland 
Date: (Revised March 7, 1994)  
Address: 20 Ames Street E15-388 Cambridge MA 02139  
Affiliation: Perceptual Computing Group MIT Media Lab  
Note: Cooperative  
Abstract: M.I.T. Media Lab Vision and Modeling Group Technical Report No. 163, Feb. 1991 Abstract We present an approach to the problem of representing images that contain multiple objects or surfaces. Rather than use an edge-based approach to represent the segmentation of a scene, we propose a multi-layer estimation framework which uses support maps to represent the segmentation of the image into homogeneous chunks. This support-based approach can represent objects that are split into disjoint regions, or have surfaces that are transparently interleaved. Our framework is based on an extension of robust estimation methods which provide a theoretical basis for support-based estimation. The Minimum Description Length principle is used to decide how many support maps to use in describing a particular image. We show results applying this framework to heterogeneous interpolation and segmentation tasks on range and motion imagery.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adelson E. H., and Anandan, P., </author> <title> "Ordinal characteristics of transparency", </title> <booktitle> in Proc. AAAI workshop on Qualitative Vision, </booktitle> <pages> pp. 77-81, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: Nitzberg and Mumford propose a multi-layer signal representation which they call "The 2.1D sketch", in which the edges of each object occupy a distinct layer [24]. Adelson and Anandan proposed multi-layer representations for the modeling of static transparency <ref> [1] </ref>. Leclerc [19] has developed a region grouping strategy using MDL theory which can link disjoint regions but is dependent on an initial edge-based description stage to find candidate regions.
Reference: [2] <author> Azarbayejani, A. J., Horowitz B.,, and Pentland, A. P., </author> <title> Recursive Estimation of Structure and Motion using the Relative Orientation Constraint In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, </title> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: We use the recursive estimation approach to estimating Structure From Motion (SFM) of Azarbayejani and Pentland <ref> [2] </ref>. This method formulates the estimation problem as an instance of an Extended Kalman Filter (EKF) which solves for the optimal estimate of the relative orientation and pointwise structure of an object at each time step, given a set of explicitly tracked features which belong to a single coherent object. <p> Our extension is thus to handle the multiple-motion case, where there are an unknown number of rigid-body motions in the scene. First we briefly review the recursive structure from motion model presented in <ref> [2] </ref>. This formulation embeds the constraints of the well-known relative orientation approach to structure from motion [13, 14] directly into an EKF measurement relationship. Motion is defined as the 3-D translation and rotation of the camera (or object) with respect to the first frame in the sequence. <p> Features were tracked on this sequence using the (human-assisted) method described in <ref> [2] </ref>. Hypotheses were constructed by taking random selections of 4 points and computing a motion estimates based only on these points. <p> Since the values of f i are bounded, S (dja) is bounded, and thus must converge. 32 B Extended Kalman Filter for Rigid-body Structure from Motion B.1 Single motion formalism The following presentation of the EKF is adapted from <ref> [2] </ref>. <p> The observation at each time step is a set of N 2D measurements which is a nonlinear function of the state vector: y (t) = B y 1 (t) y N (t) C The imaging geometry outlined in Section 2 (see <ref> [2] </ref> for details) define the nonlinear function h (x (t)), with an uncertainty term (t), modeled as Gaussian distributed white noise.
Reference: [3] <author> Attneave, F., "Pragnanz and soap-bubble systems: </author> <title> A theoretical exploration", </title> <editor> in J. Beck (Ed.) </editor> <booktitle> Organization and representation in perception. </booktitle> <address> Hillsdale, New Jersey: Erl-baum, </address> <year> 1992. </year>
Reference-contexts: Recent researchers in this tradition have used structural rules to define simplicity [20] as well as process models <ref> [3] </ref>. 5 that maximizes this Bayesian likelihood. x MAP = arg max fP (djy (x))P (y (x))g : (8) The MAP choice is also the minimal encoding of the image when we use an optimal code.
Reference: [4] <author> Beaton, A. E, and Tukey, J. W. </author> <title> "The fitting of power series, meaning polynomials, </title> <journal> illustrated on band-spectroscopic data", Technometrics, </journal> <volume> vol. 16, </volume> <pages> pp. 147-185, </pages> <year> 1974. </year>
Reference-contexts: However, estimating parameters for robust norms 3 is much more difficult, since in general there are no analytic solutions to the normal equations for an arbitrary (). One solution technique which has been presented for solving the M-estimation problem is Iteratively Reweighted Least Squares (IRLS) <ref> [4] </ref>. This algorithm approximates an arbitrary norm by the iterative application of a least-squares norm with a dynamic weighting factor on each point.
Reference: [5] <author> Besl, P. J., Birch, J. B., and Watson, L. T., </author> <title> "Robust Window Operators", </title> <booktitle> in Proc. 2nd. Intl. Conf. Computer Vision, </booktitle> <pages> pp. 591-600, </pages> <year> 1988. </year>
Reference-contexts: is derived from the robust statistics and estimation literature, based on the M-estimation framework and the notion of finding segmentation though minimal length description. 2.1 Robust estimation Robust estimation methods have become popular for image processing, since they have been found to be tolerant to occlusion and other outlier contamination <ref> [23, 5] </ref>. The use of a support map for estimation is simply an instance of outlier rejection, which is a well known robust estimation method. In this approach a confidence factor is used to weight the contribution of each point to the estimation.
Reference: [6] <author> Blake, A. and Zisserman, A. </author> <title> Visual Reconstruction. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <year> 1987. </year>
Reference-contexts: Often a fixed "edge-detector" is run to find the edges of an image as a first stage of processing, which are then used to mark the boundaries of regions from which parameters are estimated. The line process, introduced by Geman and Geman [10] and later expanded upon by <ref> [28, 32, 6] </ref>, merged these two steps into a single regularization/reconstruction framework. This approach simultaneously estimates an interpolated surface, which regularizes the data according to a prior model of surface smoothness, and a discontinuity field, which indicates allowed departures from the smoothness constraint.
Reference: [7] <author> Darrell, T., Sclaroff, S., and Pentland, P. </author> <title> "Segmentation by Minimal Description", </title> <booktitle> in Proc. 3rd Intl. Conf. Computer Vision, </booktitle> <pages> pp. 112-116, </pages> <year> 1990. </year>
Reference-contexts: Second, once we have obtained an estimate of K, we revise the parameter and support estimates for each component, using an iterative refinement procedure. 3.3 Estimation of K We have advocated the use of a Hypothesize, Test, and Select approach to estimating the number of objects in a signal <ref> [7, 26] </ref>. In our method a set of hypothesizes is generated, each is tested against the observed data to compute a set of support maps, and the subset of hypotheses which optimally (in an MDL sense) accounts for the data is selected.
Reference: [8] <author> Darrell, T., and Pentland, A. P., </author> <title> "Robust Estimation of a Multi-Layer Motion Representation", </title> <booktitle> in Proceedings IEEE Workshop on Visual Motion, </booktitle> <pages> pp. 173-177, </pages> <year> 1991. </year>
Reference-contexts: Two views are shown of the recovered 3-D model. 21 4.2 Image sequence segmentation using global velocity field models We have also applied our method to the domain of motion segmentation using global velocity field models <ref> [8] </ref>. In this case the task is to decompose an image sequence into a set of layers corresponding to homogeneous motions, based on a global model of coherent flow and a gradient-based model of local velocity measurements.
Reference: [9] <author> Darrell, T., and Simoncelli, E. P., </author> <title> "Separation of Transparent Motion into Layers using Velocity-Tuned Mechanisms", </title> <booktitle> presented at Proceedings Assn. Research in Vision and Opth. annual conference (ARVO93), </booktitle> <institution> available as MIT Media Lab Percom TR-244. </institution>
Reference-contexts: We rendered ten frames of this motion sequence; the first frame is shown in 4 for the extension of our model to the case of motion with additive transparency, see <ref> [9] </ref> 22 We adopted an initial set of velocity field hypotheses corresponding to 8 planar shifts: f (a; b; c)g = f (1; 1; 0); (1; 0; 0); (1; 1; 0); (0; 1; 0); (0; 1; 0); (30) plus a full field looming hypothesis f (0; 0; 1)g with fixed offsets
Reference: [10] <author> Geman S., and Geman D. </author> <title> "Stochastic relaxation, Gibbs distribution, and the Bayesian restoration of images", </title> <journal> in IEEE Trans. Pattern Anal. and Machine Intell., </journal> <volume> Vol 6, </volume> <pages> pp. 721-741, </pages> <year> 1984. </year>
Reference-contexts: Often a fixed "edge-detector" is run to find the edges of an image as a first stage of processing, which are then used to mark the boundaries of regions from which parameters are estimated. The line process, introduced by Geman and Geman <ref> [10] </ref> and later expanded upon by [28, 32, 6], merged these two steps into a single regularization/reconstruction framework. This approach simultaneously estimates an interpolated surface, which regularizes the data according to a prior model of surface smoothness, and a discontinuity field, which indicates allowed departures from the smoothness constraint.
Reference: [11] <author> Hochberg, J.E., and McAlister, E. </author> <title> "A quantitative approach to figure goodness", </title> <journal> J. Experimental Psychology, </journal> <volume> vol 46, </volume> <pages> pp. 361-364, </pages> <year> 1953. </year>
Reference-contexts: The Maximum a Posteriori (MAP) principle dictates that we should pick the representation 1 Similarly, simplicity and parsimony have been recognized as essential to notions of representation since the pioneering work of the Gestalt psychologists in the early twentieth century [17]. The minimum principle <ref> [11] </ref> holds that the best representation is the one that accounts for the data with the simplest model.
Reference: [12] <author> J. J. Hopfield, and D. W. Tank, </author> <title> Neural computation of decisions in Optimization Problems. </title> <journal> Biological Cybernetics, </journal> <volume> Vol. 52, </volume> <pages> pp. 141-152. </pages> <year> 1985. </year>
Reference: [13] <author> B. K. P. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Our extension is thus to handle the multiple-motion case, where there are an unknown number of rigid-body motions in the scene. First we briefly review the recursive structure from motion model presented in [2]. This formulation embeds the constraints of the well-known relative orientation approach to structure from motion <ref> [13, 14] </ref> directly into an EKF measurement relationship. Motion is defined as the 3-D translation and rotation of the camera (or object) with respect to the first frame in the sequence. Similarly, structure is represented as the 3-D locations of points seen in the first camera frame.
Reference: [14] <author> B. K. P. Horn. </author> <title> Relative orientation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4(1) </volume> <pages> 59-78, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Our extension is thus to handle the multiple-motion case, where there are an unknown number of rigid-body motions in the scene. First we briefly review the recursive structure from motion model presented in [2]. This formulation embeds the constraints of the well-known relative orientation approach to structure from motion <ref> [13, 14] </ref> directly into an EKF measurement relationship. Motion is defined as the 3-D translation and rotation of the camera (or object) with respect to the first frame in the sequence. Similarly, structure is represented as the 3-D locations of points seen in the first camera frame.
Reference: [15] <author> Huber, P. </author> <title> Robust Statistical Procedures SIAM CBMS-NSF series in Appl. </title> <journal> Math., </journal> <volume> Vol. 27, </volume> <year> 1977. </year>
Reference-contexts: In this approach a confidence factor is used to weight the contribution of each point to the estimation. The confidence value is itself iteratively updated based on the residual error of the current fit. Formally, this type of estimation is known as M-estimation <ref> [15] </ref>. M-estimators are maximum likelihood estimators which allow an arbitrary error norm. Given an image data vector d, and a model, y (x), we wish to find parameters x which are most likely to have generated the observed data, d j ; 0 &lt; j &lt; N .
Reference: [16] <author> Husain, M., Treue, S., and Andersen, R., </author> <title> "Surface interpolation in three-dimensional structure-from-motion perception", </title> <journal> Neural Computation, </journal> <volume> Vol 1, </volume> <pages> pp. 324-333, </pages> <year> 1989. </year>
Reference-contexts: A good example of this type of phenomena is the transparent motion display developed by Husain, Treue and Andersen for psychophysical experimentation <ref> [16] </ref>. In these examples, dots are placed on an otherwise transparent cylinder which rotates around its major axis. Two populations of intermingled random dots are seen, one corresponding to the foreground surface of the cylinder and the other corresponding to the background.
Reference: [17] <author> Koffka, K. </author> <booktitle> Principles of Gestalt Psychology. </booktitle> <address> New York: </address> <publisher> Harcourt, Brace & World, </publisher> <year> 1935. </year> <month> 35 </month>
Reference-contexts: The Maximum a Posteriori (MAP) principle dictates that we should pick the representation 1 Similarly, simplicity and parsimony have been recognized as essential to notions of representation since the pioneering work of the Gestalt psychologists in the early twentieth century <ref> [17] </ref>. The minimum principle [11] holds that the best representation is the one that accounts for the data with the simplest model.
Reference: [18] <author> Leclerc, Y., </author> <title> "Constructing Simple Stable Descriptions for Image Partitioning", </title> <journal> Intl. J. Computer Vision, </journal> <volume> Vol 3, pp.73-102, </volume> <year> 1989. </year>
Reference-contexts: As pointed out by Leclerc, this method is useful in vision problems because it gives us a way to produce estimates using image models that are too complex for calculation of direct priors <ref> [18] </ref>. We adopt the MDL approach for evaluating a representation, since we have no direct access to the relevant priors.
Reference: [19] <author> Leclerc, Y., </author> <title> "Region Grouping using the Minimum-Description-Length Principle", </title> <booktitle> in DARPA Image Understanding Workshop Proceedings, </booktitle> <pages> pp. 473-479, </pages> <year> 1990. </year>
Reference-contexts: Nitzberg and Mumford propose a multi-layer signal representation which they call "The 2.1D sketch", in which the edges of each object occupy a distinct layer [24]. Adelson and Anandan proposed multi-layer representations for the modeling of static transparency [1]. Leclerc <ref> [19] </ref> has developed a region grouping strategy using MDL theory which can link disjoint regions but is dependent on an initial edge-based description stage to find candidate regions.
Reference: [20] <author> Leeuwenberg, E.L.J, </author> <title> "A perceptual coding language for visual and auditory patterns", </title> <journal> American Jour. of Psychology, </journal> <volume> Vol 84, </volume> <pages> pp. 307-399, </pages> <year> 1971. </year>
Reference-contexts: Recent researchers in this tradition have used structural rules to define simplicity <ref> [20] </ref> as well as process models [3]. 5 that maximizes this Bayesian likelihood. x MAP = arg max fP (djy (x))P (y (x))g : (8) The MAP choice is also the minimal encoding of the image when we use an optimal code.
Reference: [21] <author> Li, G. </author> <title> "Robust Regression", In D.C. Hoaglin, </title> <editor> F. Mosteller and J.W. Tukey (Eds.) </editor> <title> Exploring Data, Tables, Trends and Shapes. </title> <address> New York: </address> <publisher> John Wiley & Sons, </publisher> <pages> pp. 281-343, </pages> <year> 1985. </year>
Reference-contexts: The support of an M-estimator is often initialized to cover the entire image (in the absence of any a priori knowledge); in this case the breakdown point places a severe limit 4 on the amount of occlusion the estimator can handle. Li <ref> [21] </ref> has shown M-estimators have breakdown points that are less than 1=(p + 1), where p is the number of parameters in the regression. Thus even a planar regression fit (with p = 3) cannot reliably fit a surface when it becomes more than 25% contaminated with occluding data.
Reference: [22] <author> Marroquin, J. L., </author> <title> "Random Measure Fields and the Integration of Visual Information", </title> <journal> IEEE Trans. Sys. Man., Cybernetics, </journal> <volume> vol. 22, </volume> <pages> pp. 705-716, </pages> <year> 1992. </year>
Reference-contexts: Adelson and Anandan proposed multi-layer representations for the modeling of static transparency [1]. Leclerc [19] has developed a region grouping strategy using MDL theory which can link disjoint regions but is dependent on an initial edge-based description stage to find candidate regions. Marroqiun <ref> [22] </ref> has extended the Markov Random Field formulation to include a notion of disconnected support, and has shown results using simple piecewise-constant models.
Reference: [23] <author> Meer, P., Mintz, D., and Rosenfeld, A., </author> <title> "Robust regression methods for computer vision: A review", </title> <journal> Intl. J. Computer Vision, </journal> <volume> vol 6, </volume> <pages> pp. 60-70, </pages> <year> 1991. </year>
Reference-contexts: is derived from the robust statistics and estimation literature, based on the M-estimation framework and the notion of finding segmentation though minimal length description. 2.1 Robust estimation Robust estimation methods have become popular for image processing, since they have been found to be tolerant to occlusion and other outlier contamination <ref> [23, 5] </ref>. The use of a support map for estimation is simply an instance of outlier rejection, which is a well known robust estimation method. In this approach a confidence factor is used to weight the contribution of each point to the estimation. <p> The breakdown point, b, of an M-estimator characterizes this limit of robust performance; it is defined as the smallest fraction of contamination which will force the value of an estimate outside an arbitrary range <ref> [23] </ref>. If there is more contamination than the breakdown point, the estimate will not necessarily converge to the optimal value. Thus to recover an optimal estimate using an M-estimator, at least (1 b) of the initial support must cover a single homogeneous region.
Reference: [24] <author> Nitzberg, M., and Mumford, D., </author> <title> "The 2.1-D Sketch", </title> <booktitle> Proc. 3rd Intl. Conf. on Computer Vision, </booktitle> <pages> pp. 138-144, </pages> <year> 1990. </year>
Reference-contexts: Other authors have proposed approaches to segmentation which go beyond single edge-map representations. Nitzberg and Mumford propose a multi-layer signal representation which they call "The 2.1D sketch", in which the edges of each object occupy a distinct layer <ref> [24] </ref>. Adelson and Anandan proposed multi-layer representations for the modeling of static transparency [1]. Leclerc [19] has developed a region grouping strategy using MDL theory which can link disjoint regions but is dependent on an initial edge-based description stage to find candidate regions.
Reference: [25] <author> Pentland, A., </author> <title> "Part Segmentation for Object Recognition", </title> <journal> Neural Computation, </journal> <volume> vol 1, </volume> <pages> pp. 82-91, </pages> <year> 1989. </year>
Reference-contexts: However, if the space of support maps is quite large and complex it is possible that spurious local maxima may exist. In previous work <ref> [25] </ref> we have employed a continuation method on the overhead cost ff when local maxima were a problem. This continuation method initially biases the method to first find descriptions that cover large regions of the image, and then find smaller descriptions.
Reference: [26] <author> Pentland, A., </author> <title> "Automatic recovery of deformable part models", </title> <journal> Intl. J. Computer Vision, </journal> <volume> vol 4, </volume> <pages> pp. 107-126, </pages> <year> 1990. </year>
Reference-contexts: Second, once we have obtained an estimate of K, we revise the parameter and support estimates for each component, using an iterative refinement procedure. 3.3 Estimation of K We have advocated the use of a Hypothesize, Test, and Select approach to estimating the number of objects in a signal <ref> [7, 26] </ref>. In our method a set of hypothesizes is generated, each is tested against the observed data to compute a set of support maps, and the subset of hypotheses which optimally (in an MDL sense) accounts for the data is selected.
Reference: [27] <author> Pentland, A., and Sclaroff, S., </author> <title> "Closed form solutions for physically based shape modeling and recognition", </title> <journal> IEEE Trans. Pattern Anal. and Machine Intell., </journal> <volume> vol 13, </volume> <pages> pp. 715-729, </pages> <year> 1991. </year>
Reference-contexts: However, because the polynomial basis functions are not a perfect model for the actual surfaces in the scene, a small number of points are misclassified in the recovered support map. Better models of the surface (such as modal models <ref> [27] </ref>) would help to alleviate this. * To test the stability of segmentations using this method, we applied it to a series of different views of a 3D figure. Figure 7 (a) shows synthetic range data of a human figure taken from three different viewpoints. <p> We were able to use the resulting segmentations to recover an 3-D model from the range data. A modal model part was fit to data for a corresponding part in each view using the ThingWorld modeling system <ref> [27] </ref>. Camera position was known for the views used in this example, so the part correspondences were straightforward to compute.
Reference: [28] <author> Poggio, T., Torre, V., and Koch, C. </author> <title> "Computational vision and regularization theory", </title> <journal> Nature, </journal> <volume> vol. 317(26), </volume> <year> 1985. </year>
Reference-contexts: Often a fixed "edge-detector" is run to find the edges of an image as a first stage of processing, which are then used to mark the boundaries of regions from which parameters are estimated. The line process, introduced by Geman and Geman [10] and later expanded upon by <ref> [28, 32, 6] </ref>, merged these two steps into a single regularization/reconstruction framework. This approach simultaneously estimates an interpolated surface, which regularizes the data according to a prior model of surface smoothness, and a discontinuity field, which indicates allowed departures from the smoothness constraint. <p> This will cause very small regions of support, such as those from accidental zeros, to be reduced. Parameters are estimated from the data via Eq. (4), and residual error is computed by (k) where E is a thin-plate regularization function <ref> [28] </ref>. In these examples we used = 1:0. We show the results of our system on several different piecewise-polynomial images.
Reference: [29] <author> Irani , M., and Peleg, S., </author> <title> Image sequence enhancement using multiple motions analysis. </title> <type> Technical Report 91-15, </type> <institution> Department of Computer Science Technical Report, The Hebrew University of Jerusalem, Israel, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: This model is appropriate for a large class of common sequences, e.g. those that predominantly contain translations in 3-D. For more complicated sequences higher-order velocity field models may be appropriate, such as the affine model <ref> [29, 36] </ref>. In our model, each hypothesis is a global velocity field, which will imply a local velocity at every point in the scene. To test the support of a hypothesis, we thus need to estimate whether a particular velocity is present in a local region.
Reference: [30] <editor> Press, W., et. al; Numerical Recipes in C. </editor> <address> New York: </address> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: We implement this optimization using forward-Euler discretization, with C serving as an integration constant <ref> [30] </ref>. As shown in Appendix B, Eq. (19) will converge to a local maxima of S (dja).
Reference: [31] <author> Shannon, C.E. </author> <title> The Mathematical Theory of Communication, </title> <address> Urbana: U. </address> <publisher> Illinois Press, </publisher> <year> 1949. </year>
Reference-contexts: the notion that the optimal representation for a given image is found by minimizing the combined length of encoding the representation and the residual error. (See also [37] for the related Minimum Message Length criteria.) The theory of information laid out by Claude Shannon, provides the motivation for this approach <ref> [31] </ref>. Shannon defined "entropy" to be to the lack of predictability between elements in a representation; if there is some predictability from one element to another, then entropy is not at its maximum, and a shorter encoding can be constructed.
Reference: [32] <author> Terzopoulos, D. </author> <title> "The computation of visible surface representations", </title> <journal> IEEE Trans. Pattern Anal. and Machine Intell., </journal> <volume> vol. 10:4, </volume> <year> 1988 </year>
Reference-contexts: Often a fixed "edge-detector" is run to find the edges of an image as a first stage of processing, which are then used to mark the boundaries of regions from which parameters are estimated. The line process, introduced by Geman and Geman [10] and later expanded upon by <ref> [28, 32, 6] </ref>, merged these two steps into a single regularization/reconstruction framework. This approach simultaneously estimates an interpolated surface, which regularizes the data according to a prior model of surface smoothness, and a discontinuity field, which indicates allowed departures from the smoothness constraint.
Reference: [33] <author> Rissanen, J. </author> <title> "A universal prior for integers and estimation by minimum description length", </title> <journal> The Annals of Statistics, </journal> <volume> vol 11(2), </volume> <pages> pp. 416-431, </pages> <year> 1983. </year>
Reference-contexts: We need a method for balancing model complexity with model accuracy. In the Minimum Description Length (MDL) paradigm <ref> [33] </ref>, this is formalized by the notion that the optimal representation for a given image is found by minimizing the combined length of encoding the representation and the residual error. (See also [37] for the related Minimum Message Length criteria.) The theory of information laid out by Claude Shannon, provides the
Reference: [34] <author> Rissanen, J. </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific: </publisher> <address> Teaneck NJ, </address> <year> 1989. </year>
Reference: [35] <author> Simoncelli, E., Adelson, E. H., and Heeger, D. J., </author> <title> "Probability Distributions of Optical Flow", </title> <booktitle> Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <year> 1991. </year>
Reference-contexts: According to the gradient constraint, the spatial and temporal image derivatives at a point obey the equation D (v (x; y))I (x; y; t) = 0, where D (v) = 4 v y 3 @ + v y @y @ ) : (28) Simoncelli <ref> [35] </ref> has derived a probabilistic model for optic flow computation, which we use to define the residual error of a velocity hypothesis.
Reference: [36] <author> Wang, J., and Adelson, E. H., </author> <title> "Layered Representations for Image Sequence Coding", </title> <booktitle> to appear in Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <year> 1993. </year>
Reference-contexts: This model is appropriate for a large class of common sequences, e.g. those that predominantly contain translations in 3-D. For more complicated sequences higher-order velocity field models may be appropriate, such as the affine model <ref> [29, 36] </ref>. In our model, each hypothesis is a global velocity field, which will imply a local velocity at every point in the scene. To test the support of a hypothesis, we thus need to estimate whether a particular velocity is present in a local region.
Reference: [37] <author> Wallace, C.S., Boulton, </author> <title> D.M., "An Information Measure for Classification", </title> <journal> Computing Journal, </journal> <volume> vol. 11(2), </volume> <pages> pp. 185-195, </pages> <year> 1968. </year> <month> 37 </month>
Reference-contexts: In the Minimum Description Length (MDL) paradigm [33], this is formalized by the notion that the optimal representation for a given image is found by minimizing the combined length of encoding the representation and the residual error. (See also <ref> [37] </ref> for the related Minimum Message Length criteria.) The theory of information laid out by Claude Shannon, provides the motivation for this approach [31].
References-found: 37

