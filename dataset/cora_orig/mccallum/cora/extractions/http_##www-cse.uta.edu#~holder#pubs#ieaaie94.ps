URL: http://www-cse.uta.edu/~holder/pubs/ieaaie94.ps
Refering-URL: http://www-cse.uta.edu/~holder/pubs.html
Root-URL: 
Email: Email: chaudhry@cse.uta.edu, holder@cse.uta.edu  
Title: AN EMPIRICAL APPROACH TO SOLVING THE GENERAL UTILITY PROBLEM IN SPEEDUP LEARNING  
Author: Anurag Chaudhry and Lawrence B. Holder 
Address: Box 19015, Arlington, TX 76019-0015  
Affiliation: Learning and Planning Laboratory, Department of Computer Science Engineering University of Texas at Arlington,  
Abstract: Many recent approaches to avoiding the utility problem in speedup learning (the eventual degradation of performance due to increasing amounts of learned problem-solver control knowledge) rely on sophisticated utility measures and significant numbers of training problems to accurately estimate the utility of control knowledge. Empirical results presented here and elsewhere indicate that a simple selection strategy of retaining all control rules derived from a training problem solution quickly defines an efficient set of control knowledge from few training problems. This simple selection strategy provides a low-cost alternative to example-intensive approaches for improving the speed of a problem solver. Experimentation illustrates the existence of a minimum (representing least cost) in the learning curve which is reached after a few training examples. Stress is placed on controlling the amount of learned knowledge as opposed to which knowledge. An attempt is also made to relate domain characteristics to the shape of the learning curve. 
Abstract-found: 1
Intro-found: 1
Reference: [EM92] <author> O. Etzioni and S. Minton. </author> <title> Why EBL produces overly-specific knowledge: A critique of the PRODIGY approaches. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pages 137-143, </pages> <year> 1992. </year>
Reference-contexts: However, increasing amounts of low-utility control knowledge may eventually degrade performance. This phenomenon is called the utility problem [Min88a]. Initial attempts to solve the utility problem in speedup learning using empirical evaluations of control rules met with limited success due to a limited understanding of the problem solver's behavior <ref> [EM92] </ref>. More recent work applies statistical measures to learn control rules for which there is a high certainty of utility [GD92, GJ92]. However, these approaches require a large number of training problems to estimate the distribution and ensure utile control rules.
Reference: [EZ90] <author> M. Eskey and M. </author> <title> Zweben. Learning search control for constraint-based scheduling. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 908-915, </pages> <year> 1990. </year>
Reference-contexts: RELATED WORK Most approaches to avoiding the utility problem rely on training examples to empirically evaluate the utility of learned knowledge. Minton's Prodigy system [Min88a] utilizes a utility function that evaluates control knowledge based on application cost, frequency of use and average savings. Eskey and Zweben <ref> [EZ90] </ref> describe a plausible approach to speedup learning when several examples are needed to support an instance of the target concept.
Reference: [GD92] <author> J. Gratch and G. DeJong. COMPOSER: </author> <title> A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 235-240, </pages> <year> 1992. </year>
Reference-contexts: More recent work applies statistical measures to learn control rules for which there is a high certainty of utility <ref> [GD92, GJ92] </ref>. However, these approaches require a large number of training problems to estimate the distribution and ensure utile control rules. <p> Several examples are needed to support an explanation with high confidence and adopt the corresponding control rules. The Composer system <ref> [GD92] </ref> embodies a probabilistic solution to the utility problem. Composer defines the utility of a planner as the sum of the utility of each problem in the distribution weighted by its probability of occurrence. A candidate control rule is evaluated in the context of the existing planner.
Reference: [GJ92] <author> R. Greiner and I. Jurisica. </author> <title> A statistical ap-proach to solving the EBL utility problem. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 241-248, </pages> <year> 1992. </year>
Reference-contexts: More recent work applies statistical measures to learn control rules for which there is a high certainty of utility <ref> [GD92, GJ92] </ref>. However, these approaches require a large number of training problems to estimate the distribution and ensure utile control rules. <p> Composer incrementally adds control rules to its control strategy. The utility of the rule depends on the current control strategy. A rule is added only after demonstrating benefit to a pre-specified confidence level. Higher confidence levels require larger numbers of examples. The PALO (Probably Approximately Locally Optimal) <ref> [GJ92] </ref> approach adopts a hill-climbing technique that evaluates transformations to the planner (as effected by control knowledge) using a statistical method. Learning terminates when PALO has identified (with high probability) a near-local maximum in the transformation space. <p> Typically, a large number of training examples are necessary to accurately estimate the problem distribution and the utility of control knowledge. Moreover, the task of finding the optimal set of control knowledge, even knowing the distribution, is intractable most of the time <ref> [GJ92] </ref>. On the other end of the spectrum, simply limiting the amount of the learned knowledge (while ignoring utility) may be advantageous in terms of learning time saved. PALO tries to estimate the unknown distribution, but the learning time is extremely high.
Reference: [HC93] <author> L. B. Holder and A. Chaudhry. </author> <title> Simple selection of utile control rules in speedup learning. </title> <booktitle> In Proceedings of the Third International Workshop on Knowledge Compilation and Speedup Learning, </booktitle> <pages> pages 77-82, </pages> <year> 1993. </year>
Reference-contexts: Control rules are generated by solutions to training problems. Our approach keeps all control rules generated by the training problems. Duplicate control rules increment corresponding counters. As indicated by results in <ref> [HC93] </ref> and this work, a global minimum exists in the learning curve. Few training examples (&lt; 5) are required to reach this minimum.
Reference: [Hol92a] <author> L. B. Holder. </author> <title> Empirical analysis of the general utility problem in machine learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 249-254, </pages> <year> 1992. </year>
Reference-contexts: More recent work applies statistical measures to learn control rules for which there is a high certainty of utility [GD92, GJ92]. However, these approaches require a large number of training problems to estimate the distribution and ensure utile control rules. Preliminary results in <ref> [Hol92a, Hol92b] </ref> and more recent results reported here suggest that a simple intermediate approach may yield sufficient speedup with fewer training problems and without specific utility measures. This work also tries to identify characteristics of domains which cause the use of a particular type of control knowledge to be beneficial.
Reference: [Hol92b] <author> L. B. Holder. </author> <title> Unifying empirical and explanation-based learning by modeling the utility of learned knowledge. </title> <booktitle> In Proceedings of the ML92 Workshop on Knowledge Compilation and Speedup Learning, </booktitle> <year> 1992. </year>
Reference-contexts: More recent work applies statistical measures to learn control rules for which there is a high certainty of utility [GD92, GJ92]. However, these approaches require a large number of training problems to estimate the distribution and ensure utile control rules. Preliminary results in <ref> [Hol92a, Hol92b] </ref> and more recent results reported here suggest that a simple intermediate approach may yield sufficient speedup with fewer training problems and without specific utility measures. This work also tries to identify characteristics of domains which cause the use of a particular type of control knowledge to be beneficial.
Reference: [Min88a] <author> S. Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: INTRODUCTION Speedup learning attempts to learn control knowledge for improving the speed of a planning system based on previously-solved problems. However, increasing amounts of low-utility control knowledge may eventually degrade performance. This phenomenon is called the utility problem <ref> [Min88a] </ref>. Initial attempts to solve the utility problem in speedup learning using empirical evaluations of control rules met with limited success due to a limited understanding of the problem solver's behavior [EM92]. <p> RELATED WORK Most approaches to avoiding the utility problem rely on training examples to empirically evaluate the utility of learned knowledge. Minton's Prodigy system <ref> [Min88a] </ref> utilizes a utility function that evaluates control knowledge based on application cost, frequency of use and average savings. Eskey and Zweben [EZ90] describe a plausible approach to speedup learning when several examples are needed to support an instance of the target concept.
Reference: [Min88b] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 564-569, </pages> <year> 1988. </year>
Reference-contexts: Thus, a typical cost (classification error) curve as a function of the amount of learned knowledge will be similar to that in figure 1. The utility problem has been verified in several speedup learning systems <ref> [Min88b, TR89, Moo89, MS89] </ref>; however, the underlying cause is less obvious than in inductive learning. If control knowledge is used, the expected cost to solve a representative sample (from which the control knowledge was learned) of the problems is less. This may not be true for unseen examples.
Reference: [Moo89] <author> R. J. Mooney. </author> <title> The effect of rule use on the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 725-730, </pages> <year> 1989. </year>
Reference-contexts: Thus, a typical cost (classification error) curve as a function of the amount of learned knowledge will be similar to that in figure 1. The utility problem has been verified in several speedup learning systems <ref> [Min88b, TR89, Moo89, MS89] </ref>; however, the underlying cause is less obvious than in inductive learning. If control knowledge is used, the expected cost to solve a representative sample (from which the control knowledge was learned) of the problems is less. This may not be true for unseen examples.
Reference: [MS89] <author> S. Markovitch and P. D. Scott. </author> <title> Utilization filtering: A method for reducing the inherent harmfulness of deductively learned knowledge. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 738-743, </pages> <year> 1989. </year>
Reference-contexts: Thus, a typical cost (classification error) curve as a function of the amount of learned knowledge will be similar to that in figure 1. The utility problem has been verified in several speedup learning systems <ref> [Min88b, TR89, Moo89, MS89] </ref>; however, the underlying cause is less obvious than in inductive learning. If control knowledge is used, the expected cost to solve a representative sample (from which the control knowledge was learned) of the problems is less. This may not be true for unseen examples.
Reference: [TR89] <author> M. Tambe and P. Rosenbloom. </author> <title> Eliminating expensive chunks by restricting expressiveness. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 731-737, </pages> <year> 1989. </year>
Reference-contexts: Thus, a typical cost (classification error) curve as a function of the amount of learned knowledge will be similar to that in figure 1. The utility problem has been verified in several speedup learning systems <ref> [Min88b, TR89, Moo89, MS89] </ref>; however, the underlying cause is less obvious than in inductive learning. If control knowledge is used, the expected cost to solve a representative sample (from which the control knowledge was learned) of the problems is less. This may not be true for unseen examples.
References-found: 12

