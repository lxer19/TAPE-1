URL: http://www.robotics.stanford.edu/~parr/bounded-optimal.ps.gz
Refering-URL: http://www.robotics.stanford.edu/~parr/
Root-URL: http://www.robotics.stanford.edu
Email: russell@cs.berkeley.edu  devika@cs.cornell.edu  parr@guard.berkeley.edu  
Title: Provably bounded optimal agents  
Author: Stuart J. Russell Devika Subramanian Ronald Parr 
Address: CA 94720, USA  Ithaca, NY 14853, USA  CA 94720, USA  
Affiliation: University of California, Berkeley  Cornell University  University of California, Berkeley  
Abstract: A program is bounded optimal for a given computational device for a given environment, if the expected utility of the program running on the device in the environment is at least as high as that of all other programs for the device. Bounded optimality differs from the decision-theoretic notion of rationality in that it explicitly allows for the finite computational resources of real agents. It is thus a central issue in the foundations of artificial intelligence. In this paper we consider a restricted class of agent architectures, in which a program consists of a sequence of decision procedures generated by a learning program or given a priori. For this class of agents, we give an efficient construction algorithm that generates a bounded optimal program for any episodic environment, given a set of training examples. The algorithm includes solutions to a new class of optimization problems, namely scheduling computational processes for real-time environments. This class appears to contain significant practical applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agre, P., and Chapman, D. </author> <year> (1987) </year> <month> Pengi: </month> <title> An implementation of a theory of activity. </title> <booktitle> In Proc. 6th National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA: </address> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: workings of the agent (such as that it should reason logically, for example) helps in three ways: first, it allows us to view such `cognitive faculties' as planning and reasoning as occurring in the service of finding the right thing to do; second, it makes room for those among us <ref> [ 1, 3 ] </ref> who take the position that systems can do the right thing without such cognitive faculties; third, it allows more freedom to consider various specifications, boundaries and interconnections of subsystems.
Reference: [2] <author> Breese, J. S., and Fehling, M. R. </author> <title> (1990) Control of problem-solving: Principles and architecture. </title> <editor> In Shachter, R. D., Levitt, T., Kanal, L., and Lemmer, J. (Eds.) </editor> <booktitle> Uncertainty in Artificial Intelligence 4. </booktitle> <address> Ams-terdam: </address> <publisher> North Holland. </publisher>
Reference-contexts: Combined with the idea of anytime [ 5 ] or flexible algorithms [ 11 ] , that return better results as time goes by, a simple form of metareasoning allows an agent to behave well in a real-time environment. Breese and Fehling <ref> [ 2 ] </ref> apply similar ideas to controlling multiple decision procedures. Russell and Wefald [ 18 ] give a general method for precompiling certain aspects of metareason-ing so that a system can efficiently estimate the effects of individual computations on its intentions, giving fine-grained control of reasoning.
Reference: [3] <author> Brooks, R. A. </author> <title> (1986) A robust, layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1), </volume> <pages> 14-23. </pages>
Reference-contexts: workings of the agent (such as that it should reason logically, for example) helps in three ways: first, it allows us to view such `cognitive faculties' as planning and reasoning as occurring in the service of finding the right thing to do; second, it makes room for those among us <ref> [ 1, 3 ] </ref> who take the position that systems can do the right thing without such cognitive faculties; third, it allows more freedom to consider various specifications, boundaries and interconnections of subsystems.
Reference: [4] <author> Cherniak, C. </author> <title> (1986) Minimal rationality. </title> <publisher> Cambridge: MIT Press. </publisher>
Reference-contexts: Good does not define the space of possible deliberations, but from his informal descriptions, it is clear that Type II rationality is intended to prescribe optimal sequences of computational steps. Unfortunately, these may be even harder to select than actions themselves. Recognizing these problems, Cherniak <ref> [ 4 ] </ref> suggested a definition of "minimal rationality", specifying lower bounds on the reasoning powers of any rational agent, instead of upper bounds. A philosophical proposal generally consistent with the notion of bounded optimality can be found in Dennett's "Moral First Aid Manual" [ 6 ] . <p> By neglecting the fact of limited resources for computation, classical decision theory fails to provide an adequate theoretical basis for artificial intelligence. The `finitary predicament' <ref> [ 4 ] </ref> arises because real agents have only finite computational power and because they don't have all the time in the world. In terms of our simple formal description of agents introduced above, it is easy to see where the difficulty has arisen.
Reference: [5] <author> Dean, T. and Boddy, M. </author> <title> (1988) An analysis of time-dependent planning. </title> <booktitle> In AAAI-88, </booktitle> <pages> 49-54. </pages>
Reference-contexts: Metareasoning | reasoning about reasoning | is an important technique in this area, since it enables an agent to control its deliberations according to their costs and benefits. Combined with the idea of anytime <ref> [ 5 ] </ref> or flexible algorithms [ 11 ] , that return better results as time goes by, a simple form of metareasoning allows an agent to behave well in a real-time environment. Breese and Fehling [ 2 ] apply similar ideas to controlling multiple decision procedures.
Reference: [6] <author> Dennett, D. </author> <title> (1986) The moral first aid manual. Tanner lectures on human values, </title> <institution> University of Michigan. </institution>
Reference-contexts: Recognizing these problems, Cherniak [ 4 ] suggested a definition of "minimal rationality", specifying lower bounds on the reasoning powers of any rational agent, instead of upper bounds. A philosophical proposal generally consistent with the notion of bounded optimality can be found in Dennett's "Moral First Aid Manual" <ref> [ 6 ] </ref> . Many researchers in AI, some of whose work is discussed below, have worked on the problem of designing agents with limited computational resources; the 1989 AAAI Symposium on AI and Limited Rationality [ 9 ] contains an interesting variety of work on the topic.
Reference: [7] <author> Doyle, J. </author> <title> (1983) What is rational psychology? Toward a modern mental philosophy. </title> <journal> AI Magazine 4 (3), </journal> <pages> 50-53. </pages>
Reference-contexts: 1 Introduction Since before the beginning of artificial intelligence, philosophers and economists have looked for a satisfactory definition of rational behaviour. This is needed to underpin theories of ethics, inductive learning, reasoning, decision-making and economic modelling. Doyle <ref> [ 7 ] </ref> has proposed that AI itself be defined as the computational study of rational behaviour.
Reference: [8] <author> O. Etzioni. </author> <title> Tractable decision-analytic control. </title> <booktitle> Proc. of 1st International Conference on Knowledge Representation and Reasoning, </booktitle> <pages> 114-125, </pages> <year> 1989. </year>
Reference-contexts: The agent function is an entirely abstract entity, unlike the agent program. Computability theory relates these abstract functions to their finite representations as programs running on a machine. 4 This move is analogous to the development of `rule utilitarianism' from `act utilitarianism'. 5 Recent work by Etzioni <ref> [ 8 ] </ref> and Russell and Zilber-stein [ 20 ] can be seen as optimizing over a well-defined set of agent designs. We will consider a physical agent as consisting of an architecture and a program.
Reference: [9] <editor> Fehling, M., and Russell, S. J. (Eds.) </editor> <booktitle> (1989) Proceedings of the AAAI Spring Symposium on Limited Rationality. </booktitle> <address> Stanford, CA. </address>
Reference-contexts: Many researchers in AI, some of whose work is discussed below, have worked on the problem of designing agents with limited computational resources; the 1989 AAAI Symposium on AI and Limited Rationality <ref> [ 9 ] </ref> contains an interesting variety of work on the topic. Metareasoning | reasoning about reasoning | is an important technique in this area, since it enables an agent to control its deliberations according to their costs and benefits.
Reference: [10] <author> Good, I. J. </author> <title> (1971) Twenty-seven principles of rationality. </title> <editor> In Godambe, V. P., and Sprott, D. A. (Eds.) </editor> <title> Foundations of Statistical Inference. </title> <publisher> Toronto: Holt, Rinehart, Winston. </publisher>
Reference-contexts: I. J. Good <ref> [ 10 ] </ref> emphasized the conceptual distinction between classical or "type I" rationality, and what he called "type II" rationality, or the maximization of expected utility taking into account deliberation costs. 3 What this means is that an agent exhibits type II rationality if at the end of its deliberation and
Reference: [11] <author> Horvitz, E. J. </author> <title> (1988) Reasoning about beliefs and actions under computational resource constraints. </title> <editor> In Levitt, T., Lemmer, J., and Kanal, L. (Eds.) </editor> <booktitle> Uncertainty in Artificial Intelligence 3. </booktitle> <address> Amsterdam: </address> <publisher> North Holland. </publisher>
Reference-contexts: Metareasoning | reasoning about reasoning | is an important technique in this area, since it enables an agent to control its deliberations according to their costs and benefits. Combined with the idea of anytime [ 5 ] or flexible algorithms <ref> [ 11 ] </ref> , that return better results as time goes by, a simple form of metareasoning allows an agent to behave well in a real-time environment. Breese and Fehling [ 2 ] apply similar ideas to controlling multiple decision procedures. <p> Horvitz <ref> [ 11 ] </ref> uses the term bounded optimality to refer to "the optimization of computational utility given a set of assumptions about expected problems and constraints in reasoning resources." Russell and Wefald [ 19 ] say that an agent exhibits bounded optimality "if its program is a solution to the constrained
Reference: [12] <author> Horvitz, E., Cooper, G., and Heckerman, D. </author> <title> (1989) Reflection and action under scarce resources: Theoretical principles and empirical study. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [13] <author> Kearns, M., Schapire, R., and Sellie, L. </author> <title> (1992) Toward efficient agnostic learning. </title> <booktitle> In Proc. 5th Ann. Workshop on Computational Learning Theory. </booktitle> <address> Pittsburgh, PA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In order to work in any environment, it must be agnostic <ref> [ 13 ] </ref> in that it makes no assumptions about the target function, that is, the form of the correct decision rule. It searches for the best subject to a complexity parameter k that bounds the size of the rules. <p> It searches for the best subject to a complexity parameter k that bounds the size of the rules. Kearns, Schapire and Sellie have shown (Theorems 4 and 5 in <ref> [ 13 ] </ref> ) that, for some languages J , the error in the learned approximation can be bounded to within * of the best rule in J ; k that fits the examples, with probability 1 ffi.
Reference: [14] <author> McCarthy, J. </author> <title> (1958) Programs with common sense. </title> <booktitle> In Proceedings of the Symposium on the Mechanization of Thought Processes, </booktitle> <address> Teddington, England: HMSO. </address>
Reference-contexts: The expectation is taken according to the agent's own beliefs; thus, perfect rationality does not require omniscience. In artificial intelligence, the logical definition of rationality, known in philosophy as the "practical syllogism", was put forward by McCarthy <ref> [ 14 ] </ref> , and reiterated strongly by Newell [ 15 ] . Under this definition, an agent should take any action that it believes is guaranteed to achieve any of its goals.
Reference: [15] <author> Newell, A. </author> <title> (1981) The knowledge level. </title> <journal> AI Magazine 2, </journal> <pages> 1-20. </pages>
Reference-contexts: The expectation is taken according to the agent's own beliefs; thus, perfect rationality does not require omniscience. In artificial intelligence, the logical definition of rationality, known in philosophy as the "practical syllogism", was put forward by McCarthy [ 14 ] , and reiterated strongly by Newell <ref> [ 15 ] </ref> . Under this definition, an agent should take any action that it believes is guaranteed to achieve any of its goals.
Reference: [16] <author> Nilsson, N. J. </author> <booktitle> (1991) Logic and artificial intelligence. Artificial Intelligence 45, </booktitle> <pages> 31-56. </pages>
Reference: [17] <author> Russell, S. J., and Subramanian, D. </author> <title> (1992) On provably rational agents with limited performance hardware. </title> <editor> In Baum, E. (Ed.) </editor> <booktitle> Computational learning and cognition: Proceedings of the Third NEC Symposium, </booktitle> <publisher> SIAM Press. </publisher>
Reference-contexts: Corollary 1 There exists an optimal strategy ending with the highest-quality job in R. Proofs of all the above results appear in <ref> [ 17 ] </ref> . 4.6.1 A Dynamic Programming Algorithm The dynamic programming method can be used to obtain an optimal sequence of decision rules in pseudo-polynomial time.
Reference: [18] <author> Russell, S. J., and Wefald, E. H. </author> <booktitle> (1989) Principles of metareasoning. In Proc. KR-89. </booktitle>
Reference-contexts: Breese and Fehling [ 2 ] apply similar ideas to controlling multiple decision procedures. Russell and Wefald <ref> [ 18 ] </ref> give a general method for precompiling certain aspects of metareason-ing so that a system can efficiently estimate the effects of individual computations on its intentions, giving fine-grained control of reasoning.
Reference: [19] <author> Russell, S. J., and Wefald, E. H. </author> <title> (1991) Do the right thing: Studies in limited rationality. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Horvitz [ 11 ] uses the term bounded optimality to refer to "the optimization of computational utility given a set of assumptions about expected problems and constraints in reasoning resources." Russell and Wefald <ref> [ 19 ] </ref> say that an agent exhibits bounded optimality "if its program is a solution to the constrained optimization problem presented by its architecture." The philosophical "move", from optimizing over actions or deliberation sequences to optimization over programs, is the key to our proposal. 4 In reality, designers of intelligent
Reference: [20] <author> Russell, S. J., and Zilberstein, </author> <title> S (1991) Composing real-time systems. </title> <booktitle> In Proc. IJCAI-91, </booktitle> <address> Sydney. </address>
Reference-contexts: Computability theory relates these abstract functions to their finite representations as programs running on a machine. 4 This move is analogous to the development of `rule utilitarianism' from `act utilitarianism'. 5 Recent work by Etzioni [ 8 ] and Russell and Zilber-stein <ref> [ 20 ] </ref> can be seen as optimizing over a well-defined set of agent designs. We will consider a physical agent as consisting of an architecture and a program. The architecture is responsible for interfacing between the program and the discrete, deterministic environment, and for running the program itself. <p> Bounded optimality may provide a suitable basis for theoretical research in artificial intelligence. Asymptotic bounded optimality in particular promises to yield useful results on composite agent designs, using the optimality-preserving composition methods in <ref> [ 20 ] </ref> . As a robust measure of rationality, it's possible that it could do for AI what "big-O" descriptions did for complexity theory. Bounded optimality also philosophically interesting implications.
Reference: [21] <author> Savage, L. J. </author> <booktitle> (1972) The foundations of statistics, 2nd rev. </booktitle> <publisher> ed. </publisher> <address> New York: </address> <publisher> Dover. </publisher>
Reference: [22] <author> Simon, H. A. </author> <title> (1976) On how to decide what to do. </title> <booktitle> In [ 23 </booktitle> ] . 
Reference-contexts: provide useful insights into the general problem of control of reasoning, but there is no reason to suppose that the days before formal intractability results in computation were known, that in the early stages of the field it was important to concentrate on "epistemological adequacy" before "heuristic adequacy". 3 Simon <ref> [ 22 ] </ref> also says: "The global optimization problem is to find the least-cost or best-return decision, net of computational costs." approximations used are optimal in any sense.
Reference: [23] <author> Simon, H. A. </author> <title> (1982) Models of bounded rationality, </title> <booktitle> Volume 2. </booktitle> <address> Cambridge: </address> <publisher> MIT Press. </publisher>
Reference-contexts: McCarthy believed, probably correctly, in the halcyon Economists have used rationality as an abstract model of economic entities, for the purposes of economic forecasting and designing market mechanisms. Unfortunately, as Simon <ref> [ 23 ] </ref> pointed out, real economic entities have limited time and limited powers of deliberation.
Reference: [24] <author> Valiant, L. G. </author> <title> (1984) A theory of the learnable. </title> <journal> Communications of the ACM 18(11), </journal> <pages> 1134-42. </pages> <note> [25] von Neumann, </note> <author> J., and Morgenstern, O. </author> <title> (1947) Theory of games and economic behavior. </title> <publisher> Princeton: Princeton University Press. </publisher>
References-found: 24

