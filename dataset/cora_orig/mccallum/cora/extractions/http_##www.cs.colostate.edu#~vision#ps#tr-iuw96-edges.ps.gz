URL: http://www.cs.colostate.edu/~vision/ps/tr-iuw96-edges.ps.gz
Refering-URL: http://www.cs.colostate.edu/~vision/html/publications.html
Root-URL: 
Phone: Phone: (970) 491-5792 Fax: (970) 491-2466  
Title: Model Pose  
Author: Mark R. Stevens and J. Ross Beveridge 
Keyword: Optical Linear Feature Detection Based  
Web: WWW: http://www.cs.colostate.edu  
Address: Fort Collins, CO 80523-1873  
Affiliation: Computer Science Department Colorado State University  
Date: December 16, 1995  
Note: on  This work was sponsored by the Advanced Research Projects Agency (ARPA) under grant DAAH04-93-G-422, monitored by the U. S. Army Research Office.  
Pubnum: Technical Report CS-96-110  
Abstract: Computer Science Technical Report 
Abstract-found: 1
Intro-found: 1
Reference: [Ant96] <author> Anthony N. A. Schwickerath and J. Ross Beveridge. </author> <title> Coregis-tering 3D Models, Range, and Optical Imagery Using Least-Median Squares Fitting. </title> <booktitle> In Proceedings: Image Understanding Workshop, page (to appear), </booktitle> <address> Los Altos, CA, </address> <month> February </month> <year> 1996. </year> <title> ARPA, </title> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: below a certain threshold, and no further improvement can be made, the current position of the edge is returned as the data line corresponding to the current model edge. 3 Results The local search algorithm is currently being used in a multi-sensor object recognition algorithm here at Col-orado State University <ref> [Ant96] </ref>. The results of the search are shown in Figure 3. Figure 3a shows the predicted model edges thought to be visible in the image for the given pose hypothesis. Figure 3b shows the data segments extracted for matching to those model features.
Reference: [BHP94] <author> J. Ross Beveridge, Allen Hanson, and Durga Panda. </author> <title> Integrated color ccd, flir & ladar based object modeling and recognition. </title> <type> Technical report, </type> <institution> Colorado State University and Alliant Techsystems and University of Massachusetts, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Using a method to predict visible model lines for a hypothesized pose [Mar96], the model features can be projected into a given image using known sensor characteristics <ref> [BHP94] </ref>. Local search then maximizes the segment orientation and position based on the current gradient response.
Reference: [BHR86] <author> J. Brian Burns, Allen R. Hanson, and Edward M. Rise-man. </author> <title> Extracting Straight Lines. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-8(4):425-455, </volume> <month> July </month> <year> 1986. </year>
Reference-contexts: Color imagery in the ATR domain often contains many different structural events taking place simultaneously (camouflage on military vehicles set against natural terrain is an excellent example). Current edge detection algorithms <ref> [BHR86, LB83, FL88] </ref> do not deal well with these type of scenes and will produce many small fragmented line segments which can easily distract a model-based matching system.
Reference: [Can86] <author> John Canny. </author> <title> A Computation Approach to Edge Detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-8(6):679-697, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: There are many precedents both for using tuned edge masks <ref> [Can86] </ref> and the first derivative Gaussian [TP86]. Others have also used different methods to obtain gradient estimates based on steerable filters [Shu94, FA91] for use in bottom-up edge detection.
Reference: [Cla89] <author> James J. Clark. </author> <title> Authenticating Edges Produced by Zero-Crossing Algorithms. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-11(1):43-57, </volume> <month> January </month> <year> 1989. </year> <editor> a. +X Shift b. -X Shift c. +Y Shift d. -Y Shift e. +Begin Rotation f. -Begin Rotation g. +End Rotation h. -End Rotation i. +Rotation j. -Rotation a. Model Lines b. </editor> <booktitle> Data Lines </booktitle>
Reference-contexts: The process differs from the traditional low-level bottom-up edge detection process [MH80, Hil83] which can be highly error-prone <ref> [Cla89] </ref>. The main problem with bottom-up detection is the inability to deal with large amounts of scene complexity and clutter. Color imagery in the ATR domain often contains many different structural events taking place simultaneously (camouflage on military vehicles set against natural terrain is an excellent example). <p> S. Army Research Office. y Appears also in the Proceedings of the 1996 ARPA Image Understanding Workshop. to the vehicle in the scene <ref> [Cla89] </ref>. The model matching process will be more robust if there is a one-to-one correspondence between extracted data lines and model features. Our experience suggests bottom-up feature extraction can not meet the requirements of this domain.
Reference: [FA91] <author> William T. Freeman and Edward H. Adelson. </author> <title> The Design and Use of Steerable Filters. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-13(9):891-906, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: There are many precedents both for using tuned edge masks [Can86] and the first derivative Gaussian [TP86]. Others have also used different methods to obtain gradient estimates based on steerable filters <ref> [Shu94, FA91] </ref> for use in bottom-up edge detection. However, contrary to other approaches [FL88], we are not searching for the maximum gradient of a line of an arbitrary orientation, but rather the gradient for the orientation of the current model edge.
Reference: [FL88] <author> Pascal Fua and Yvan G. Leclerc. </author> <title> Model driven edge detection. </title> <booktitle> In Proceedings: Image Understanding Workshop - 1988, </booktitle> <pages> pages 1016 - 1021. </pages> <publisher> DARPA, Morgan Kaufmann, </publisher> <month> April </month> <year> 1988. </year>
Reference-contexts: Color imagery in the ATR domain often contains many different structural events taking place simultaneously (camouflage on military vehicles set against natural terrain is an excellent example). Current edge detection algorithms <ref> [BHR86, LB83, FL88] </ref> do not deal well with these type of scenes and will produce many small fragmented line segments which can easily distract a model-based matching system. <p> There are many precedents both for using tuned edge masks [Can86] and the first derivative Gaussian [TP86]. Others have also used different methods to obtain gradient estimates based on steerable filters [Shu94, FA91] for use in bottom-up edge detection. However, contrary to other approaches <ref> [FL88] </ref>, we are not searching for the maximum gradient of a line of an arbitrary orientation, but rather the gradient for the orientation of the current model edge. The horizontal first derivative of a bi-variate Gaussian is given by: G (a; b) = 2ye b + b 2 (1) a.
Reference: [Hil83] <author> Ellen C. Hildreth. </author> <title> The Detection of Intensity Changes by Computer and Biological Vision Systems. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 22 </volume> <pages> 1-27, </pages> <year> 1983. </year>
Reference-contexts: Using a hypothesized model pose to predict visible features from a CAD model [Mar96, Ste95], a local optimization procedure is used to find the corresponding and consistent data features in the image. The process differs from the traditional low-level bottom-up edge detection process <ref> [MH80, Hil83] </ref> which can be highly error-prone [Cla89]. The main problem with bottom-up detection is the inability to deal with large amounts of scene complexity and clutter.
Reference: [LB83] <author> David G. Lowe and T. O. Binford. </author> <title> The Perceptual Organization of Visual Images: Segmentation as a Basis for Recognition. </title> <booktitle> In Proceedings Image Understanding Workshop, Stan-ford, </booktitle> <pages> pages 203 - 209, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: Color imagery in the ATR domain often contains many different structural events taking place simultaneously (camouflage on military vehicles set against natural terrain is an excellent example). Current edge detection algorithms <ref> [BHR86, LB83, FL88] </ref> do not deal well with these type of scenes and will produce many small fragmented line segments which can easily distract a model-based matching system.
Reference: [Mar96] <author> Mark R. Stevens and J. Ross Beveridge. </author> <title> Interleaving 3D Model Feature Prediction and Matching to Support Multi-Sensor Object Recognition. </title> <booktitle> In Proceedings: Image Understanding Workshop, page (to appear), </booktitle> <address> Los Altos, CA, </address> <month> Febru-ary </month> <year> 1996. </year> <title> ARPA, </title> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: 1 Introduction Edge detection in the Automatic Target Recognition (ATR) domain should be driven by the expectation of which model features are assumed to be visible in a given image. Using a hypothesized model pose to predict visible features from a CAD model <ref> [Mar96, Ste95] </ref>, a local optimization procedure is used to find the corresponding and consistent data features in the image. The process differs from the traditional low-level bottom-up edge detection process [MH80, Hil83] which can be highly error-prone [Cla89]. <p> Our experience suggests bottom-up feature extraction can not meet the requirements of this domain. Consequently, we take a top-down approach in which the current set of model features drives the search for line segments in color images. Using a method to predict visible model lines for a hypothesized pose <ref> [Mar96] </ref>, the model features can be projected into a given image using known sensor characteristics [BHP94]. Local search then maximizes the segment orientation and position based on the current gradient response. <p> Local search then maximizes the segment orientation and position based on the current gradient response. A similar approach has been applied using gradient descent to perturb the line segment [SWF95]. 2 Local Search The model-driven approach is initialized by projecting the predicted 3D model edges <ref> [Mar96] </ref> into the color image. An error function uses a gradient mask oriented to the direction of the model edge to determine the underlying changes in pixel intensity.
Reference: [MH80] <author> David Marr and Ellen C. Hildreth. </author> <title> Theory of Edge Detection. </title> <journal> Proceedings of the Royal Society of London, </journal> <volume> B207:187-217, </volume> <year> 1980. </year>
Reference-contexts: Using a hypothesized model pose to predict visible features from a CAD model [Mar96, Ste95], a local optimization procedure is used to find the corresponding and consistent data features in the image. The process differs from the traditional low-level bottom-up edge detection process <ref> [MH80, Hil83] </ref> which can be highly error-prone [Cla89]. The main problem with bottom-up detection is the inability to deal with large amounts of scene complexity and clutter.
Reference: [Pin88] <author> Juan Pineda. </author> <title> A Parallel Algorithm for Polygon Rasterization. </title> <booktitle> In Proceedings of Siggraph '88, </booktitle> <pages> pages 17-20, </pages> <year> 1988. </year>
Reference-contexts: i=Line xa Line yb X j=Line ya w (i; j) where (Grad (i; j)) is the gradient mask response, and w (i; j) is a weighting mask based on the distance of the pixel from the true line, thus allowing the computation of ^ G Line (k) with sub-pixel accuracy <ref> [Pin88] </ref>. A threshold for w (i; j) neglects pixels lying outside some radius. The fl term is the largest expected gradient possible for the current mask, and will normalize ^ G Line (k) to the range [0; 1] for each line segment.
Reference: [Shu94] <author> Alexander Shustorovich. </author> <title> Scale Specific and Robust Edge/Line Encoding with Linear Combinations of Gabor Wavelets. </title> <journal> Pattern Recognition, </journal> <volume> 27(5) </volume> <pages> 713-725, </pages> <year> 1994. </year>
Reference-contexts: There are many precedents both for using tuned edge masks [Can86] and the first derivative Gaussian [TP86]. Others have also used different methods to obtain gradient estimates based on steerable filters <ref> [Shu94, FA91] </ref> for use in bottom-up edge detection. However, contrary to other approaches [FL88], we are not searching for the maximum gradient of a line of an arbitrary orientation, but rather the gradient for the orientation of the current model edge.
Reference: [Ste95] <author> Mark R. Stevens. </author> <title> Obtaining 3d shilhouettes and sampled surfaces from solid models for use in computer vision. </title> <type> Master's thesis, </type> <institution> Colorado State Univeristy, Fort Collins, Colorado, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Edge detection in the Automatic Target Recognition (ATR) domain should be driven by the expectation of which model features are assumed to be visible in a given image. Using a hypothesized model pose to predict visible features from a CAD model <ref> [Mar96, Ste95] </ref>, a local optimization procedure is used to find the corresponding and consistent data features in the image. The process differs from the traditional low-level bottom-up edge detection process [MH80, Hil83] which can be highly error-prone [Cla89].
Reference: [SWF95] <author> G.D Sullivan, A.D. Worrall, and J.M Ferryman. </author> <title> Visual Object Recognition Using Deformable Models of Vehicles. </title> <booktitle> In Workshop on Context-Based Vision, </booktitle> <pages> pages 75-86, </pages> <month> june </month> <year> 1995. </year>
Reference-contexts: Local search then maximizes the segment orientation and position based on the current gradient response. A similar approach has been applied using gradient descent to perturb the line segment <ref> [SWF95] </ref>. 2 Local Search The model-driven approach is initialized by projecting the predicted 3D model edges [Mar96] into the color image. An error function uses a gradient mask oriented to the direction of the model edge to determine the underlying changes in pixel intensity.
Reference: [TP86] <author> Vincent Torre and Tomaso A. Poggio. </author> <title> On Edge Detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-8(2):147-164, </volume> <month> March </month> <year> 1986. </year> <month> 3 </month>
Reference-contexts: There are many precedents both for using tuned edge masks [Can86] and the first derivative Gaussian <ref> [TP86] </ref>. Others have also used different methods to obtain gradient estimates based on steerable filters [Shu94, FA91] for use in bottom-up edge detection.
References-found: 16

