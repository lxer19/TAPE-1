URL: http://www.umiacs.umd.edu/users/westling/Papers/accv98.ps.gz
Refering-URL: http://www.umiacs.umd.edu/users/westling/
Root-URL: 
Phone: 2  
Title: Interpretation of Complex Scenes Using Bayesian Networks  
Author: Mark F. Westling and Larry S. Davis 
Address: 7500 Woodmont Ave. Suite 1007, Bethesda MD 20814, USA  College Park MD 20742, USA  
Affiliation: 1 Perceptus Technologies,  Computer Vision Laboratory, Center for Automation Research, University of Maryland,  
Abstract: In most object recognition systems, interactions between objects in a scene are ignored and the best interpretation is considered to be the set of hypothesized objects that matches the greatest number of image features. We show how image interpretation can be cast as the problem of finding the most probable explanation (MPE) in a Bayesian network that models both visual and physical object interactions. The problem of how to determine exact conditional probabilities for the network is shown to be unimportant, since the goal is to find the most probable configuration of objects, not to calculate absolute probabilities. We furthermore show that evaluating configurations by feature counting is equivalent to calculating the joint probability of the configuration using a restricted Bayesian network, and derive the assumptions about probabilities necessary to make a Bayesian formulation reasonable.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Beveridge. </author> <title> A Local Search Algorithms for Geometric Object Recognition: Optimal Correspondence and Pose. </title> <type> PhD thesis, </type> <institution> University of Massachussets, </institution> <year> 1993. </year>
Reference-contexts: This notion is extended by [11] and [12] by also including negative evidence, e.g., for unlikely conditions such as image edges that pass through model edges at large angles. Similarly, [26] derives a statistical match function that penalizes unmatched image features while <ref> [1] </ref> includes a penalty for unmatched model features. Occlusions are specifically considered by [24] as an explanation for unmatched model features.
Reference: 2. <author> T.O. Binford and T.S. Levitt. </author> <title> Model-based recognition of objects in complex scenes. </title> <booktitle> In 1994 ARPA Image Understanding Workshop, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Bayesian network can be effective with only a few assumptions. 2 Related Work 2.1 Bayesian Networks in Image Understanding Bayesian networks, in combination with geometric reasoning systems, have been used in 3-D object understanding to relate model components to predicted appearances and to control the interpretation process ([16], [3], [15], <ref> [2] </ref>, [19], [18], [23]). The highest level of the model is a hierarchy of 3-D components, which predict the appearance of surfaces and contours. These surfaces and contours in turn predict the appearance of edges. Matching edges, finally, form the evidence nodes.
Reference: 3. <author> T.O. Binford, T.S. Levitt, and W.B. Mann. </author> <title> Bayesian inference in model-based machine vision. </title> <booktitle> Uncertainty in AI, </booktitle> <volume> 3 </volume> <pages> 73-94, </pages> <year> 1989. </year>
Reference-contexts: how a Bayesian network can be effective with only a few assumptions. 2 Related Work 2.1 Bayesian Networks in Image Understanding Bayesian networks, in combination with geometric reasoning systems, have been used in 3-D object understanding to relate model components to predicted appearances and to control the interpretation process ([16], <ref> [3] </ref>, [15], [2], [19], [18], [23]). The highest level of the model is a hierarchy of 3-D components, which predict the appearance of surfaces and contours. These surfaces and contours in turn predict the appearance of edges. Matching edges, finally, form the evidence nodes.
Reference: 4. <author> T. M. Breuel. </author> <title> Fast recognition using adaptive subdivisions of transformation space. </title> <booktitle> In CVPR92, </booktitle> <pages> pages 445-451. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: In the related approach of geometric hashing, [22] gives a technique for computing the weights of evidence using Bayesian calculations. Other transform space search techniques similarly collect maximal sets of matches ([7], <ref> [4] </ref>). Counting features can be viewed as collecting positive evidence. This notion is extended by [11] and [12] by also including negative evidence, e.g., for unlikely conditions such as image edges that pass through model edges at large angles.
Reference: 5. <author> T.M. Breuel. </author> <title> Higher-order statistics in object recognition. </title> <booktitle> In CVPR93, </booktitle> <pages> pages 707-708. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: Similarly, [26] derives a statistical match function that penalizes unmatched image features while [1] includes a penalty for unmatched model features. Occlusions are specifically considered by [24] as an explanation for unmatched model features. Feature counting methods do not account for dependence between features, and <ref> [5] </ref> suggests the use of a log-linear model to represent high-order statistical properties such as low expected fragmentation of edges and high correlation of detection between nearby features. 2.3 Finding the Most Probable Explanation Pearl [21] describes an algorithm that finds the MPE of a Bayesian network using a message-passing scheme
Reference: 6. <author> H. Buxton and S.G. Gong. </author> <title> Visual surveillance in a dynamic and uncertain world. </title> <booktitle> AI, </booktitle> <address> 78(1-2):431-459, </address> <month> October </month> <year> 1995. </year>
Reference: 7. <author> T.A. Cass. </author> <title> Polynomial-time object recognition in the presence of clutter, </title> <booktitle> occlusions, and uncertainty. In DARPA92, </booktitle> <pages> pages 693-704, </pages> <year> 1992. </year>
Reference: 8. <author> B. D'Ambrosio. </author> <title> SPI in large BN2O networks. </title> <booktitle> In Proceedings of the Tenth Annual Conference on Uncertainty in Artificial Intelligence (UAI-94), </booktitle> <pages> pages 128-135, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference: 9. <author> R. Fisher. </author> <title> Performance comparison of ten variations on the interpretation tree matching algorithm. </title> <booktitle> In ECCV94, </booktitle> <pages> pages 507-512, </pages> <year> 1994. </year>
Reference-contexts: Matched features may be weighted equally or according to complexity and distance between predicted appearance and detected appearance. The interpretation tree method ([10], <ref> [9] </ref>) searches a correspondence space tree of model-to-feature pairings for the longest consistent path or the first path of some given minimal length.
Reference: 10. <author> W.E.L. </author> <title> Grimson. Object Recognition by Computer: The Role of Geometric Constraints. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Our networks are well suited to the technique of conditioning, whereby a node is temporarily instantiated to render the network singly connected. 7 Example 7.1 2-D Scenes For illustrative purposes, we demonstrate how this technique works on simple images of 2-D scenes. <ref> [10] </ref> gives many example of recognizing laminar parts in complex, cluttered 2-D gray-scale images with approximately orthogonal projection. Because the images are nearly binary, one cannot determine spatial interference nor occlusion ordering. When two objects overlap, edge features will be missing from both objects, giving the appearance of "mutual" occlusion.
Reference: 11. <author> C. Hansen and T. Henderson. </author> <title> CAGD-based computer vision. </title> <journal> PAMI, </journal> <volume> 11(11) </volume> <pages> 1181-1193, </pages> <year> 1989. </year>
Reference-contexts: In the related approach of geometric hashing, [22] gives a technique for computing the weights of evidence using Bayesian calculations. Other transform space search techniques similarly collect maximal sets of matches ([7], [4]). Counting features can be viewed as collecting positive evidence. This notion is extended by <ref> [11] </ref> and [12] by also including negative evidence, e.g., for unlikely conditions such as image edges that pass through model edges at large angles. Similarly, [26] derives a statistical match function that penalizes unmatched image features while [1] includes a penalty for unmatched model features.
Reference: 12. <author> D.P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> IJCV, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: In the related approach of geometric hashing, [22] gives a technique for computing the weights of evidence using Bayesian calculations. Other transform space search techniques similarly collect maximal sets of matches ([7], [4]). Counting features can be viewed as collecting positive evidence. This notion is extended by [11] and <ref> [12] </ref> by also including negative evidence, e.g., for unlikely conditions such as image edges that pass through model edges at large angles. Similarly, [26] derives a statistical match function that penalizes unmatched image features while [1] includes a penalty for unmatched model features.
Reference: 13. <author> F. V. Jensen. </author> <title> An Introduction to Bayesian Networks. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: The first condition directly affects the cost of MPE calculation, while the second condition determines the topology of the network. Many algorithms exist for converting a multiply-connected network to a single-connected network; for an overview, see [21] and <ref> [13] </ref>.
Reference: 14. <editor> V.P. Kumar and U.B. </editor> <title> Desai. Image interpretation using Bayesian networks. </title> <journal> PAMI, </journal> <volume> 18(1) </volume> <pages> 74-77, </pages> <month> January </month> <year> 1996. </year>
Reference: 15. <author> T.S. Levitt, J.M. Agosta, </author> <title> and T.O. Binford. Model-based influence diagrams for machine vision. </title> <booktitle> Uncertainty in AI, </booktitle> <volume> 5 </volume> <pages> 233-244, </pages> <year> 1990. </year>
Reference-contexts: a Bayesian network can be effective with only a few assumptions. 2 Related Work 2.1 Bayesian Networks in Image Understanding Bayesian networks, in combination with geometric reasoning systems, have been used in 3-D object understanding to relate model components to predicted appearances and to control the interpretation process ([16], [3], <ref> [15] </ref>, [2], [19], [18], [23]). The highest level of the model is a hierarchy of 3-D components, which predict the appearance of surfaces and contours. These surfaces and contours in turn predict the appearance of edges. Matching edges, finally, form the evidence nodes.
Reference: 16. <author> T.S. Levitt, T.O. Binford, G.J. Ettinger, and P. Gelband. </author> <title> Probability-based control for computer vision. </title> <booktitle> In DARPA89, </booktitle> <pages> pages 355-369, </pages> <year> 1989. </year>
Reference: 17. <author> Z. Li and B. D'Ambrosio. </author> <title> Efficient inference in Bayes nets as a combinatorial optimization problem. </title> <journal> Intl Journal of Approximate Reasoning, </journal> <volume> 11(1) </volume> <pages> 55-81, </pages> <year> 1994. </year>
Reference-contexts: The second most likely probable explanation can also be computed using this algorithm. An algorithm for calculating the MPE of singly connected networks in time linear in the number of instantiated variables, using symbolic factoring of the expressions for distributions in the network, is given in <ref> [17] </ref>. Also given is a method for finding the l next most probable explanations in linear time. The algorithm is also efficient for multiply connected networks. <p> This simplifies the network and allows us to find the MPE more quickly. The MPE can be computed efficiently from the SPI representation. A non-search algorithm given in <ref> [17] </ref> computes the MPE of singly connected networks (i.e., networks in which a single path exists between any two nodes) with time complexity O (k fi 2n), where k is the number of non-marginal nodes of the network and n is the largest size (in terms of possible values) of a
Reference: 18. <author> J. Liang, F. Jensen, and H. Christensen. </author> <title> A framework for generic object recognition with Bayesian networks. </title> <booktitle> In Proceedings of the First International Symposium on Soft Computing for Pattern Recognition, </booktitle> <address> Reading, U.K., </address> <month> March </month> <year> 1996. </year>
Reference-contexts: can be effective with only a few assumptions. 2 Related Work 2.1 Bayesian Networks in Image Understanding Bayesian networks, in combination with geometric reasoning systems, have been used in 3-D object understanding to relate model components to predicted appearances and to control the interpretation process ([16], [3], [15], [2], [19], <ref> [18] </ref>, [23]). The highest level of the model is a hierarchy of 3-D components, which predict the appearance of surfaces and contours. These surfaces and contours in turn predict the appearance of edges. Matching edges, finally, form the evidence nodes. Another application is the understanding of 2-D aerial photographs ([14]).
Reference: 19. <author> W.B. Mann and T.O. Binford. SUCCESSOR: </author> <title> Interpretation overview and constraint system. </title> <booktitle> In ARPA96, </booktitle> <pages> pages 1505-1518, </pages> <year> 1996. </year>
Reference-contexts: network can be effective with only a few assumptions. 2 Related Work 2.1 Bayesian Networks in Image Understanding Bayesian networks, in combination with geometric reasoning systems, have been used in 3-D object understanding to relate model components to predicted appearances and to control the interpretation process ([16], [3], [15], [2], <ref> [19] </ref>, [18], [23]). The highest level of the model is a hierarchy of 3-D components, which predict the appearance of surfaces and contours. These surfaces and contours in turn predict the appearance of edges. Matching edges, finally, form the evidence nodes.
Reference: 20. <author> V. Murino, M.F. Peri, and C.S. Regazzoni. </author> <title> Distributed belief revision for adaptive image processing regulation. </title> <booktitle> In ECCV92, </booktitle> <pages> pages 87-91, </pages> <year> 1992. </year>
Reference: 21. <author> J. Pearl. </author> <title> Probabilistic Resoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: Feature counting methods do not account for dependence between features, and [5] suggests the use of a log-linear model to represent high-order statistical properties such as low expected fragmentation of edges and high correlation of detection between nearby features. 2.3 Finding the Most Probable Explanation Pearl <ref> [21] </ref> describes an algorithm that finds the MPE of a Bayesian network using a message-passing scheme similar to his method for computing the posterior probabilities of nodes. <p> The first condition directly affects the cost of MPE calculation, while the second condition determines the topology of the network. Many algorithms exist for converting a multiply-connected network to a single-connected network; for an overview, see <ref> [21] </ref> and [13].
Reference: 22. <author> I. Rigoutsos and R. Hummel. </author> <title> Distributed Bayesian object recognition. </title> <booktitle> In CVPR93, </booktitle> <pages> pages 180-186. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: The generalized Hough transform ([10]) collects evidence for hypotheses by incrementing an accumulator array that is indexed by a model pose; hence, the peaks in the array correspond to poses with the largest number of matched features. In the related approach of geometric hashing, <ref> [22] </ref> gives a technique for computing the weights of evidence using Bayesian calculations. Other transform space search techniques similarly collect maximal sets of matches ([7], [4]). Counting features can be viewed as collecting positive evidence.
Reference: 23. <author> R. D. Rimey. </author> <title> Control of Selective Perception Using Bayes Nets and Decision Theory. </title> <type> PhD thesis, </type> <institution> University of Rochester, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: be effective with only a few assumptions. 2 Related Work 2.1 Bayesian Networks in Image Understanding Bayesian networks, in combination with geometric reasoning systems, have been used in 3-D object understanding to relate model components to predicted appearances and to control the interpretation process ([16], [3], [15], [2], [19], [18], <ref> [23] </ref>). The highest level of the model is a hierarchy of 3-D components, which predict the appearance of surfaces and contours. These surfaces and contours in turn predict the appearance of edges. Matching edges, finally, form the evidence nodes. Another application is the understanding of 2-D aerial photographs ([14]).
Reference: 24. <author> C. Rothwell. </author> <title> Reasoning about occlusions during hypothesis verification. </title> <booktitle> In ECCV96, </booktitle> <volume> volume 1, </volume> <pages> pages 599-609, </pages> <year> 1996. </year>
Reference-contexts: Similarly, [26] derives a statistical match function that penalizes unmatched image features while [1] includes a penalty for unmatched model features. Occlusions are specifically considered by <ref> [24] </ref> as an explanation for unmatched model features.
Reference: 25. <author> S. Srinivas and P. Nayak. </author> <title> Efficient enumeration of instantiations in Bayesian networks. </title> <booktitle> In Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence (UAI-96), </booktitle> <pages> pages 500-508, </pages> <address> Portland, Oregon, </address> <year> 1996. </year>
Reference-contexts: Also given is a method for finding the l next most probable explanations in linear time. The algorithm is also efficient for multiply connected networks. A method with similar complexity is described in <ref> [25] </ref>, but implemented using a message-passing scheme based on the lazy enumeration of a sorted list of all instantiations of a network. 3 Problem Definition Given a single 2-D image, possibly color, of a complex scene containing multiple 3-D objects, our goal is to find the best interpretation of the scene.
Reference: 26. <author> W. Wells. </author> <title> Statistical Pattern Recognition. </title> <type> PhD thesis, </type> <institution> Massachussetts Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: Counting features can be viewed as collecting positive evidence. This notion is extended by [11] and [12] by also including negative evidence, e.g., for unlikely conditions such as image edges that pass through model edges at large angles. Similarly, <ref> [26] </ref> derives a statistical match function that penalizes unmatched image features while [1] includes a penalty for unmatched model features. Occlusions are specifically considered by [24] as an explanation for unmatched model features.
Reference: 27. <author> M. Westling and L. Davis. </author> <title> Object recognition by fast hypothesis generation and reasoning about object interactions. </title> <booktitle> In ICPR96, </booktitle> <pages> pages 148-153, </pages> <address> Vienna, </address> <year> 1996. </year>
Reference-contexts: We assume that we have some method of generating hypotheses of objects from an image and a set of models; in the implementation, we use a memory-based technique described in <ref> [27] </ref>. The image is processed in some way to reveal a set of image features that can be associated with objects in the scene. A feature is vector of information associated with a region of pixels at some point of the image.
References-found: 27

