URL: ftp://ftp.cs.helsinki.fi/pub/Reports/by_Project/Cosco/Learning_Bayesian_Prototype_Trees_by_Simulated_Annealing.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~tirri/publications.html
Root-URL: 
Email: Petri.Myllymaki@cs.Helsinki.FI, Henry.Tirri@cs.Helsinki.FI  
Title: Learning Bayesian Prototype Trees by Simulated Annealing  
Author: Petri Myllymaki and Henry Tirri 
Affiliation: University of Helsinki, Department of Computer Science  
Address: Helsinki 1994.  P.O.Box 26, FIN-00014 University of Helsinki, FINLAND  
Note: Pp. 32-37 in Proceedings of the Conference on Artificial Intelligence Research in Finland (Turku, Finland, August 1994), edited by C.Carlsson, T.Jarvi and T.Reponen. Finnish Artificial Intelligence Society,  
Abstract: Given a set of samples of an unknown probability distribution, we study the problem of constructing a good approximative Bayesian network model of the probability distribution in question. This task can be viewed as a search problem, where the goal is to find a maximal probability network model, given the data. In this work, we do not make an attempt to learn arbitrarily complex multi-connected Bayesian network structures, since such resulting models can be unsuitable for practical purposes due to the exponential amount of time required for the reasoning task. Instead, we restrict ourselves to a special class of simple tree-structured Bayesian networks called Bayesian prototype trees, for which a polynomial time algorithm for Bayesian reasoning exists. We show how the probability of a given Bayesian prototype tree model can be evaluated, given the data, and how this evaluation criterion can be used in a stochastic simulated annealing algorithm for searching the model space. The simulated annealing algorithm provably finds the maximal probability model, provided that a sufficient amount of time is used. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aarts, E., and Korst, J., </author> <title> Simulated Annealing and Boltzmann Machines: A Stochastic Approach to Combinatorial Optimization and Neural Computing. </title> <publisher> John Wiley & Sons, </publisher> <address> Chich-ester, </address> <year> 1989. </year>
Reference-contexts: t (M t+1 ) &lt; RANDREAL (0,1) ) then c (h) = c; /* reject new clustering, restore old value */ If the computational temperature T (t) is decreased slowly enough, the simulated annealing algorithm given will converge to the maximum probability clustering resulting to maximum probability model M fl <ref> [1] </ref>. Unfortunately, finding a proper cooling schedule for decreasing the temperature may be difficult in practice [20]. V. Conclusion We have presented a method for deriving probabilistic Bayesian network models from data.
Reference: [2] <author> Barker, A.A., </author> <title> Monte Carlo calculations of the radial distribution functions for a proton-electron plasma. Aust. </title> <journal> J. Phys. </journal> <volume> 18 (1965), </volume> <pages> 119-133. </pages>
Reference-contexts: The value of the function T is usually called the (computational) temperature of the process. Without the temperature parameter, the probability p t is identical to the acceptance probability proposed by Barker in <ref> [2] </ref>.
Reference: [3] <author> Brown, D.E., and Huntley, C.L., </author> <title> A practical application of simulated annealing to clustering. </title> <journal> Pattern Recognition, </journal> <volume> 25 (1992) 4, </volume> <pages> 401-412. </pages>
Reference-contexts: In the following, we show how the simulated annealing algorithm can be used for performing a more elaborate stochastic local search in the model space. Our approach is supported by the results of applying simulated annealing for solving optimal clustering problems (see e.g., <ref> [3, 28] </ref>). We start by assuming that the number of clusters to be used does not exceed N , the number of items in the training set.
Reference: [4] <author> Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., and Freeman, D., </author> <title> AutoClass: A Bayesian Classification System. Pp. </title> <booktitle> 54-64 in 36 Proc. of the Fifth International Conference on Machine Learning, </booktitle> <address> Ann Arbor, June 12-14, </address> <publisher> 1988 (Morgan Kaufmann). </publisher>
Reference: [5] <author> Cheeseman, P., </author> <title> On Finding the Most Probable Model. Pp. 73-95 in Computational Models of Scientific Discovery and Theory Formation, edited by J. </title> <editor> Shrager and P. Langley. </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference: [6] <author> Connolly, D., </author> <title> Constructing hidden variables in Bayesian networks via conceptual clustering. Pp. </title> <booktitle> 65-72 in Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <address> Amherst, June 27-29, </address> <publisher> 1993 (Morgan Kauf-mann). </publisher>
Reference-contexts: In principle our approach is akin to the work in <ref> [6] </ref>, but instead of heuristic evaluation criteria we use MDL approximations and for search theoretically sound simulated annealing replacing the conceptual clustering algorithm (COBWEB). We will now proceed by showing how different clustering schemes can be compared by evaluating the corresponding Bayesian tree models. III.
Reference: [7] <author> Cooper, </author> <title> G.F., The computational complexity of probabilistic inference using Bayesian belief networks. </title> <booktitle> Artificial Intelligence 42 (1990) 2-3 (March), </booktitle> <pages> 393-405. </pages>
Reference: [8] <author> Cooper, G.F., and Herskovits, E., </author> <title> A Bayesian Method for Induction of Probabilistic Networks from Data. </title> <journal> Machine Learning, </journal> <volume> vol. </volume> <pages> 9 , pp. 309-347, </pages> <year> 1992. </year>
Reference-contexts: For example, applying the theorems of Cooper and Her-skovitz in <ref> [8] </ref>, in our framework with m attributes and n i values for each attribute A i , we get for a Bayesian prototype tree with l prototypes the probability P (D j M) = (N + l 1)! k=1 i=1 k=1 @ (n i 1)! n i Y F k (a <p> An alternative formula for computing P (D j M) is given in [16]. In <ref> [8] </ref>, Cooper and Herskovitz did not take into the account the prior probabilities P (M), but assumed all struc tures to be equally probable. In the following, we 34 use the size of the prototype tree for determining the prior probabilities, introducing a bias towards simple structures.
Reference: [9] <author> Geman, S. and Geman, D., </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence 6 (1984), </journal> <pages> 721-741. </pages>
Reference: [10] <author> Gyllenberg, M., Gyllenberg, H.G., Koski, T., and Schindler, J., </author> <title> Non-uniqueness of Numerical Taxonomic Structures. Binary, </title> <booktitle> Vol. 5 (1993), </booktitle> <pages> 138-144. </pages>
Reference: [11] <author> Hsu, W., Hsu, </author> <title> L.S., and Tenorio, M.F., The Clusnet Algorithm and Time Series Prediction. </title> <journal> International Journal of Neural Systems, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 247-255, </pages> <month> September </month> <year> 1993. </year>
Reference: [12] <author> Kirkpatrick, S., Gelatt, D. and Vecchi, </author> <title> M.P., Optimization by simulated annealing. </title> <booktitle> Science 220 (1983) 4598 (May), </booktitle> <pages> 671-680. </pages>
Reference: [13] <author> Kitano, H., </author> <title> Challenges of Massive Parallelism. Pp. </title> <booktitle> 813-834 in Proc. of IJCAI-93, the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France, </address> <publisher> August 1993 (Morgan Kaufmann). </publisher>
Reference: [14] <author> Kononenko, I., </author> <title> Successive Naive Bayesian Classifier. </title> <journal> Informatica, </journal> <volume> vol. 17, </volume> <pages> pp. 167-174, </pages> <year> 1993. </year>
Reference: [15] <author> Langley, P., </author> <title> Induction of Recursive Bayesian Classifiers. </title> <note> Pp. 153-164 in P.B. </note> <editor> Brazdil (ed.), </editor> <booktitle> Proc. of ECML-93, European Conference on Machine Learning, </booktitle> <address> Vienna, Austria, April 5-7, </address> <publisher> 1993 (Springer-Verlag). </publisher>
Reference: [16] <author> Lam W., and Bacchus, F., </author> <title> Using Causal Information and Local Measures to Learn Bayesian Networks. Pp. </title> <editor> 243-250 in D. Heckerman and A. Mamdani (eds.), </editor> <booktitle> Proc. of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Washington, D.C., July 9-11, </address> <publisher> 1993 (Morgan Kaufmann). </publisher>
Reference-contexts: An alternative formula for computing P (D j M) is given in <ref> [16] </ref>. In [8], Cooper and Herskovitz did not take into the account the prior probabilities P (M), but assumed all struc tures to be equally probable. In the following, we 34 use the size of the prototype tree for determining the prior probabilities, introducing a bias towards simple structures. <p> Observe that for a particular problem domain m, n i and r will be constants, but l can vary from 1 to N (the size of the data set). This approach is very similar to the MDL approximation of S (M) in <ref> [16] </ref>, but as their model is used for learning general multiply connected Bayesian networks, the encoding scheme is biased towards sparse networks with few values, and in our case it will give too high a penalty for introducing new values to the root node, i.e., for introducing new classes (class values
Reference: [17] <author> Lee S., and Shimoji, S., BAYESNET: </author> <title> Bayesian Classification Network Based on Biased Random Competition using Gaussian Kernels. Pp. </title> <booktitle> 1354-1359 in Proc. of the IEEE International Conf. on Neural Networks, </booktitle> <address> San Francisco, </address> <publisher> March 1993 (IEEE Press). </publisher>
Reference: [18] <author> Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, M.N. and Teller, E., </author> <title> Equations of state calculations by fast computing machines. </title> <journal> Journal of Chem. Phys. </journal> <volume> 21 (1953), </volume> <pages> 1087-1092. </pages>
Reference-contexts: The value of the function T is usually called the (computational) temperature of the process. Without the temperature parameter, the probability p t is identical to the acceptance probability proposed by Barker in [2]. An alternative form for the acceptance probability, proposed originally by Metropolis et al. in <ref> [18] </ref>, is given by p t (M t+1 ) = 1 ; if P (M t jD) 1, P (M t+1 jD) 1 P (M t+1 jD) (9) It has been argued that in practice the Metropolis form should be preferred since in the case of equally probable states, Barker's method
Reference: [19] <author> Moody, J., and Darken, C., </author> <title> Fast learning in networks of locally-tuned processing units. </title> <journal> Neural Computation, </journal> <volume> vol. 1, </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference: [20] <author> Myllymaki, P., </author> <title> Bayesian Reasoning by Stochastic Neural Networks. Ph. Lic. </title> <type> Thesis, Report C-1993-67, </type> <institution> Department of Computer Science, University of Helsinki, </institution> <year> 1993. </year>
Reference-contexts: However, it should be noted that the stochastic process generated by using the Barker's formula can be implemented extremely efficiently by using a massively parallel architecture <ref> [20, 21] </ref>. Theoretically there is no preference for either of these models, since using the candidate generation scheme described above both methods lead to a stochastic process fulfilling the condition (7) (see [20]). <p> Theoretically there is no preference for either of these models, since using the candidate generation scheme described above both methods lead to a stochastic process fulfilling the condition (7) (see <ref> [20] </ref>). Algorithm 1 1. /* start with a random clustering: */ for h = 1 to N do (a) c (h) = RANDINT (1,N); 2. <p> Unfortunately, finding a proper cooling schedule for decreasing the temperature may be difficult in practice <ref> [20] </ref>. V. Conclusion We have presented a method for deriving probabilistic Bayesian network models from data. In this work, we have restricted ourselves to a class of simple tree-structured Bayesian prototype tree models, although in principle the approach presented can be adapted also for learning multi-connected Bayesian networks.
Reference: [21] <author> Myllymaki, P., </author> <title> Using Bayesian networks for incorporating probabilistic a priori knowledge into Boltzmann machines. </title> <booktitle> Proc. </booktitle> <address> of SOUTH-CON'94 (Orlando, </address> <month> March </month> <year> 1994), </year> <pages> 97-102. </pages>
Reference-contexts: However, it should be noted that the stochastic process generated by using the Barker's formula can be implemented extremely efficiently by using a massively parallel architecture <ref> [20, 21] </ref>. Theoretically there is no preference for either of these models, since using the candidate generation scheme described above both methods lead to a stochastic process fulfilling the condition (7) (see [20]).
Reference: [22] <author> Myllymaki, P., and Tirri, H., </author> <title> Bayesian Case-Based Reasoning with Neural Networks. Pp. </title> <booktitle> 422-427 in Proc. of the IEEE International Conf. on Neural Networks, </booktitle> <address> San Francisco, </address> <publisher> March 1993 (IEEE Press). </publisher>
Reference: [23] <author> Myllymaki, P., and Tirri, H., </author> <title> Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics. </title> <note> Pp. 48-53 in M.M. </note> <editor> Richter, S. Wess, K.-D. Althoff and F. Maurer (eds.), </editor> <booktitle> Proc. of the First European Workshop on Case-Based Reasoning, </booktitle> <institution> University of Kaiserslautern, </institution> <month> 1-5 November, </month> <year> 1993. </year> <type> SEKI Report SR-93-12 (SFB 314), </type> <institution> University of Kaiserslautern. </institution>
Reference: [24] <author> Myllymaki, P., and Tirri, H., </author> <title> Learning in neural networks with Bayesian prototypes. </title> <booktitle> Proc. </booktitle> <address> of SOUTHCON'94 (Orlando, </address> <month> March </month> <year> 1994), </year> <pages> 60-64. </pages>
Reference-contexts: In <ref> [24] </ref> we presented a greedy heuristic for the search process. This heuristic was a "bottom-up" approach which starts by partitioning all the data vectors in separate clusters, and continues by combining the two prototypes which produce the greatest increase in the probability P (M j D).
Reference: [25] <author> Pearl, J., </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Mor-gan Kaufmann, </publisher> <year> 1988. </year>
Reference: [26] <author> Rissanen, J., </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific, </publisher> <year> 1989. </year>
Reference-contexts: This criterion can also be approximated using the Minimum Description Length <ref> [26] </ref> approach, where the goal is to minimize the sum log P (M) log P (D j M): There are many different approaches to approximating the probabilities P (M) and P (D j M). <p> In the following, we 34 use the size of the prototype tree for determining the prior probabilities, introducing a bias towards simple structures. To approximate the prior probability P (M), let us first code all the different Bayesian trees using the information theoretically optimal coding scheme in <ref> [26] </ref>. Using this coding scheme, we can approximate the prior probability as P (M) = 2 S (M) ; where S (M) denotes the number of bits needed to represent Bayesian prototype tree M.
Reference: [27] <author> Robinson, W.R., </author> <title> Counting unlabeled acyclic digraphs. In C.H.C. Little (ed.), </title> <booktitle> Lecture notes in mathematics 622: Combinatorial mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1977. </year>
Reference: [28] <author> Selim, S.Z., and Alsultan, K., </author> <title> A simulated annealing algorithm for the clustering problem. </title> <booktitle> Pattern Recognition 24 (1991) 10, </booktitle> <pages> 1003-1008. </pages>
Reference-contexts: In the following, we show how the simulated annealing algorithm can be used for performing a more elaborate stochastic local search in the model space. Our approach is supported by the results of applying simulated annealing for solving optimal clustering problems (see e.g., <ref> [3, 28] </ref>). We start by assuming that the number of clusters to be used does not exceed N , the number of items in the training set.
Reference: [29] <author> Specht, D.F., </author> <title> Probabilistic Neural Networks. </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 3, </volume> <pages> pp. 109-118, </pages> <year> 1990. </year> <month> 37 </month>
References-found: 29

