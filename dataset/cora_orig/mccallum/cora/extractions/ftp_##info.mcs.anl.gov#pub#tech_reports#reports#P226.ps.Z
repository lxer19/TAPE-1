URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P226.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/preprints.htm
Root-URL: http://www.mcs.anl.gov
Title: INTERIOR POINT METHODS FOR OPTIMAL CONTROL OF DISCRETE-TIME SYSTEMS  
Author: STEPHEN J. WRIGHT 
Keyword: Key words. interior point algorithms, optimal control, banded linear systems.  
Abstract: We show that recently developed interior point methods for quadratic programming and linear complementarity problems can be put to use in solving discrete-time optimal control problems, with general pointwise constraints on states and controls. We describe interior point algorithms for a discrete time linear-quadratic regulator problem with mixed state/control constraints, and show how it can be efficiently incorporated into an inexact sequential quadratic programming algorithm for nonlinear problems. The key to the efficiency of the interior-point method is the narrow-banded structure of the coefficient matrix which is factorized at each iteration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. P. Bertsekas, </author> <title> Projected Newton methods for optimization problems with simple constraints, </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 20 (1982), </volume> <pages> pp. 221-246. </pages>
Reference-contexts: )(Y k + ffiY k )e (y k + ffiy k ) T ( k + ffi k ) m fl fl fl 4 (y k + ffiy k ) T ( k + ffi k ) 2 m 2 = 0 by using a safeguarded search in the interval <ref> [0; 1] </ref> with an algorithm that has local third-order convergence. Typically about three iterations are required. <p> Efficient algorithms for this problem are well known, e.g., the two-metric gradient projection algorithms of Bertsekas <ref> [1] </ref> and Dunn [7] and the second-order DDP algorithms of Jacobson and Mayne [14]. We compare the interior point algorithms with the implementation of the Bertsekas algorithm described in Wright [32], on three examples from the literature. These are Euler discretizations of the following three continuous-time problems: Example 1: (Bertsekas [1]) <p> <ref> [1] </ref> and Dunn [7] and the second-order DDP algorithms of Jacobson and Mayne [14]. We compare the interior point algorithms with the implementation of the Bertsekas algorithm described in Wright [32], on three examples from the literature. These are Euler discretizations of the following three continuous-time problems: Example 1: (Bertsekas [1]) n s = 2, n c = 1, m = 2. min 0 " _x 2 = x 2 # ju (t)j B; x 1 (0) = 15; x 2 (0) = 5; where B is a positive constant to be specified below. <p> This is a linear-quadratic problem, and hence only one SQP iteration is resquired. The optimal control tends to be on its bound for only a small part of the interval <ref> [0; 1] </ref>. Example 2: Same as Example 1, but with objective function min 0 This problem has a bang-bang solution. When B = 1, there is a single switching point from u (t) = 1 to u (t) = 1 at about t = :512.
Reference: [2] <author> J. E. Cuthrell and L. T. Biegler, </author> <title> Simultaneous optimization and solution methods for batch reactor control profiles, </title> <journal> Computers chem. Engng., </journal> <volume> 13 (1989), </volume> <pages> pp. 49-62. </pages>
Reference-contexts: In the numerical results of Section 6, we restrict attention to simple discretizations of the continuous problems. Higher-order discretizations are possible: for example, Cuthrell and Biegler <ref> [2] </ref> use collocation at Gauss points to convert (1.1) to a nonlinear programming problem. Many issues arise in the discretization process, particularly when the solution of (1.1) contains singular arcs (and so the first-order necessary conditions give rise to a higher-index differential-algebraic equation).
Reference: [3] <author> V. F. Demyanov and A. M. Rubinov, </author> <title> Approximate Methods in Optimization Problems, </title> <publisher> American Elsevier, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Research supported by the Applied Mathematical Sciences subprogram of the Office of Energy Research, U. S. Department of Energy, under Contract W-31-109-Eng-38. 1 projection class are easily implementable (see, for example, Demyanov and Rubinov <ref> [3] </ref>, Dunn [5, 6]). In the finite-dimensional problem, these methods have the advantage that the set of currently-active constraints can change extensively at each iteration, whereas "active set" methods only allow a single change to the active set, which causes poor performance when there are many constraints.
Reference: [4] <author> G. Di Pillo, L. Grippo, and F. Lampariello, </author> <title> A class of structured quasi-Newton algorithms for optimal control problems, </title> <booktitle> in IFAC Conference on Applications of Nonlinear Programming to Optimization and Control, Proceedings, </booktitle> <year> 1983. </year>
Reference-contexts: Polak, Yang and Mayne [28] describe a first-order algorithm which makes use of barrier functions for the inequality constraints. Evtushenko [10, Chapter 6] describes a variety of augmented Lagrangian penalty function methods, in which (1.2) is reduced to an unconstrained problem. Di Pillo, Grippo and Lampariello <ref> [4] </ref> describe a structured quasi-Newton method for a particular augmented Lagrangian, and take advantage of the same feature which we exploit in this paper: bandedness of the coefficient matrix which is factored at each iteration. In this paper, we focus on a linear-quadratic version of the discrete problem (1.2). <p> N # active SQP iters potential reduction inner iters CPU time 100 43 4 8,5,8,1 1.10 10000 4294 3 14,16,28 297. From the given starting point, the convexity condition (1.4) does not hold at the solution, but we still observe convergence. Example 7: (Di Pillo et. al. <ref> [4, Example 2] </ref>) n s = n c = 1, m = 1 min 0 x (t) 0:9; x (1) 1; x (0) = 1: We show results for SQP with potential reduction inner iterations in Tables 6.8 and 6.9.
Reference: [5] <author> J. C. Dunn, </author> <title> Global and asymptotic convergence rate estimates for a class of projected gradient processes, </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 19 (1981), </volume> <pages> pp. </pages> <month> 368-400. </month> <title> [6] , On the convergence of projected gradient processes to singular critical points, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 55 (1987), </volume> <pages> pp. </pages> <month> 203-216. </month> <title> [7] , A projected Newton method for minimization problems with nonlinear inequality constraints, </title> <journal> Numerische Mathematik, </journal> <volume> 53 (1988), </volume> <pages> pp. 377-409. </pages>
Reference-contexts: Research supported by the Applied Mathematical Sciences subprogram of the Office of Energy Research, U. S. Department of Energy, under Contract W-31-109-Eng-38. 1 projection class are easily implementable (see, for example, Demyanov and Rubinov [3], Dunn <ref> [5, 6] </ref>). In the finite-dimensional problem, these methods have the advantage that the set of currently-active constraints can change extensively at each iteration, whereas "active set" methods only allow a single change to the active set, which causes poor performance when there are many constraints.
Reference: [8] <author> J. C. Dunn and D. P. Bertsekas, </author> <title> Efficient dynamic programming implementations of Newton's method for unconstrained optimal control problems, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 63 (1989), </volume> <pages> pp. 23-38. </pages>
Reference-contexts: In the "unconstrained" case (that is, when g, g i and g f are absent), Newton-like methods and conjugate gradient methods for (1.1) are described by Polak [27]; for (1.2), Newton's method, and its efficient implementation, is discussed in Dunn and Bertsekas <ref> [8] </ref>. A variety of quasi-Newton approaches have also been applied to the unconstrained version of (1.1); see, for example, Edge and Powers [9] and Kelley and Sachs [16], and the references therein.
Reference: [9] <author> E. R. Edge and W. F. </author> <title> Powers, Function space quasi-Newton algorithms for optimal control problems with bounded controls and singular arcs, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 20 (1976), </volume> <pages> pp. 455-479. </pages>
Reference-contexts: A variety of quasi-Newton approaches have also been applied to the unconstrained version of (1.1); see, for example, Edge and Powers <ref> [9] </ref> and Kelley and Sachs [16], and the references therein.
Reference: [10] <author> Y. G. Evtushenko, </author> <title> Numerical Optimization Techniques, Optimization Software, </title> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Polak, Yang and Mayne [28] describe a first-order algorithm which makes use of barrier functions for the inequality constraints. Evtushenko <ref> [10, Chapter 6] </ref> describes a variety of augmented Lagrangian penalty function methods, in which (1.2) is reduced to an unconstrained problem.
Reference: [11] <author> R. Fletcher, </author> <title> Practical Methods of Optimization (Second Edition), </title> <publisher> John Wiley and Sons, </publisher> <year> 1987. </year>
Reference-contexts: If (1.3) arises as a discretization of a continuous problem, alternative algorithms from mathematical programming would seem to be less efficient as N grows very large. For example, the number of iterations required by active set methods (see Fletcher <ref> [11, Chapter 10] </ref>) could reasonably be expected to be proportional to the number of constraints, that is, O (N ). Since each such iteration involves the solution of a certain narrow-banded linear system of dimension O (N ), the total complexity would probably be (N 2 ).
Reference: [12] <author> E. M. Gafni and D. P. Bertsekas, </author> <title> Two-metric projection methods for constrained optimization, </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 22 (1984), </volume> <pages> pp. 936-964. </pages>
Reference-contexts: More recently, Newtonian scaling has been added to gradient projection algorithms (see Gafni and Bertsekas <ref> [12] </ref>, Dunn [7]) to improve their asymptotic rate of convergence, and the resulting methods have proven to be useful for the control-constrained version of (1.2), as we see in Section 6.
Reference: [13] <author> C.-G. Han, P. Pardalos, and Y. Ye, </author> <title> Computational aspects of an interior point algorithm for quadratic programming problems with box constraints, in Large-Scale Numerical Optimization, </title> <editor> T. F. Coleman and Y. Li, eds., </editor> <publisher> SIAM Publications, </publisher> <address> Philadelphia, PA, </address> <year> 1990, </year> <pages> pp. 92-112. </pages>
Reference-contexts: However, the choices of ae k and k that yield the most efficient practical algorithms lie outside the scope of this analysis. We use the following heuristics (which are similar to those utilized by Han, Pardalos and Ye <ref> [13] </ref>): initially: ae min m 1:5 the k-th iteration: ae k max (ae min ; 1= k ); calculate the step (ffiz k ; ffi k ; ffiw k ; ffiy k ); set k = maxf j 1; y k i + ffiy k i 0; k i 0; i
Reference: [14] <author> D. H. Jacobson and D. Q. Mayne, </author> <title> Differential Dynamic Programming, </title> <publisher> American Elsevier, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Efficient algorithms for this problem are well known, e.g., the two-metric gradient projection algorithms of Bertsekas [1] and Dunn [7] and the second-order DDP algorithms of Jacobson and Mayne <ref> [14] </ref>. We compare the interior point algorithms with the implementation of the Bertsekas algorithm described in Wright [32], on three examples from the literature. <p> When B = 2, the switch from u (t) = 2 to u (t) = 2 occurs at about t = :500. Example 3: (Jacobson and Mayne <ref> [14, Section 2.4.7] </ref>) n s = 2, n c = 1, m = 2. min 0 " _x 2 = x 2 # ju (t)j B; x 1 (0) = 5; x 2 (0) = 5; where, again, B &gt; 0 will be specified later. <p> (4:2); _x 2 = 5x 1 0:5x 2 + u _x 4 = 10x 3 0:6x 4 + u ju (t)j 1; x i (4:2) 1; i = 1; : : : ; 4: Versions of this problem have been discussed by a number of authors, including Jacobson and Mayne <ref> [14, page 85] </ref> (who exclude the terminal inequality constraints) and Longsdon [19]. The problem has a bang-bang solution with eight switching times. <p> The problem has a bang-bang solution with eight switching times. It is solved in [19] by using a discrete nonlinear programming formulation, and in <ref> [14] </ref> by using a second-order method 23 Table 6.3 Results for Example 3 with N = 1000. Number of active constraints at the solution is reported in the second column.
Reference: [15] <author> J. Ji, F. Potra, and S. Huang, </author> <title> A predictor-corrector method for linear complementarity problems with polynomial complexity and superlinear convergence, </title> <type> Tech. Rep. 18, </type> <institution> Department of Mathematics, The University of Iowa, Iowa City, Iowa, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: The second algorithm we consider is of the "predictor-corrector" type. For linear programming problems, this algorithm is described by Mizuno, Todd and Ye [22] and Ye, Tapia and Zhang [34]. The analysis is extended to linear complementarity problems by Ji, Potra and Huang <ref> [15] </ref>.
Reference: [16] <author> C. T. Kelley and E. W. Sachs, </author> <title> A pointwise quasi-Newton method for unconstrained optimal control problems, </title> <journal> Numerische Mathematik, </journal> <volume> 55 (1989), </volume> <pages> pp. 159-176. </pages>
Reference-contexts: A variety of quasi-Newton approaches have also been applied to the unconstrained version of (1.1); see, for example, Edge and Powers [9] and Kelley and Sachs <ref> [16] </ref>, and the references therein. In the control-constrained case (in which g f is absent, and the states x and x i do not appear in g and g i ), the problem is traditionally treated as a constrained optimization problem in u or u i .
Reference: [17] <author> M. Kojima, S. Mizuno, and A. Yoshise, </author> <title> An O( p nL) iteration potential reduction algorithm for linear complementarity problems, </title> <type> Tech. Rep. </type> <institution> Research Report B-217, Department of Information Sciences, Tokyo Institute of Technology, </institution> <year> 1988. </year> <title> [18] , A polynomial-time algorithm for a class of linear complementarity problems, </title> <journal> Mathematical Programming, </journal> <volume> 44 (1989), </volume> <pages> pp. 1-26. </pages>
Reference-contexts: The following result can be used to demonstrate polynomial complexity of the basic potential reduction algorithm. It is proved by Kojima, Mizuno and Yoshise <ref> [17] </ref> for the linear complementarity problem in standard form, but can be easily extended to the "mixed" linear complementarity problem (2.3)-(2.7). Theorem 2.2.
Reference: [19] <author> J. S. Longsdon, </author> <title> Efficient determination of optimal control profiles for differential algebraic systems, </title> <type> PhD thesis, </type> <institution> Department of Chemical Engineering, Carnegie-Mellon University, </institution> <year> 1990. </year>
Reference-contexts: 4 = 10x 3 0:6x 4 + u ju (t)j 1; x i (4:2) 1; i = 1; : : : ; 4: Versions of this problem have been discussed by a number of authors, including Jacobson and Mayne [14, page 85] (who exclude the terminal inequality constraints) and Longsdon <ref> [19] </ref>. The problem has a bang-bang solution with eight switching times. It is solved in [19] by using a discrete nonlinear programming formulation, and in [14] by using a second-order method 23 Table 6.3 Results for Example 3 with N = 1000. <p> i = 1; : : : ; 4: Versions of this problem have been discussed by a number of authors, including Jacobson and Mayne [14, page 85] (who exclude the terminal inequality constraints) and Longsdon <ref> [19] </ref>. The problem has a bang-bang solution with eight switching times. It is solved in [19] by using a discrete nonlinear programming formulation, and in [14] by using a second-order method 23 Table 6.3 Results for Example 3 with N = 1000. Number of active constraints at the solution is reported in the second column. <p> The final function value of f = 1:00357374 obtained for the larger version of Example 4 compares with a final value of f = 1:00347 obtained by Longsdon <ref> [19] </ref>, who required over 6 hours of CPU time on a VAX 6320 to compute his solution. A comparison of the two solutions appears in Table 6.5. <p> These are Example 6: Van der Pol problem, with state constraint. n s = 2, n c = 1. min 0 " _x 2 = (1 x 2 x 1 ; Table 6.5 Comparison of control profiles for computed solutions of Example 4. Longsdon <ref> [19] </ref> Interior Point, N = 2500 (f = 1:00347) (f = 1:00357374) Switching time u Switching time u 0.0 -1.0 0.0 -1.0 0.89979 -1.0 0.8980 -1.0 2.16960 -1.0 2.1680 -1.0 3.43619 -1.0 3.4356 -1.0 Table 6.6 Results for Example 5 with different values of the discretization parameter N .
Reference: [20] <author> O. L. Mangasarian, </author> <title> Nonlinear Programming, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: The dual of (2.1) is max 2 The relationship between problems (2.1) and (2.2) is outlined in the following proposition (see, for example, Monteiro and Adler [23, Propositions 2.1-2.3] and Mangasarian <ref> [20, Sec tion 8.2] </ref>): Proposition 2.1. (i) If (2.1) has an optimal solution (z fl ; fl ), then there exist w fl and y fl such that (v; w; y) = (z fl ; w fl ; y fl ) is an optimal solution for (2.2).
Reference: [21] <author> A. Miele, </author> <title> Recent advances in gradient algorithms for optimal control problems, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 17 (1975), </volume> <pages> pp. 361-430. </pages>
Reference-contexts: Algorithms based on nonlinear programming techniques appear to be the most promising. In these algorithms, both states and controls are treated as unknowns and the state equation and "auxiliary" constraints as equality and inequality constraints, respectively. Miele <ref> [21] </ref> deals mainly with the case in which the auxiliary constraints g in (1.1) are equalities (rather than inequalities) and proposes algorithms of the reduced gradient type, with features added to ensure near-feasibility of all iterates.
Reference: [22] <author> S. Mizuno, M. Todd, and Y. Ye, </author> <title> On adaptive-step primal-dual interior point algorithms for linear programming, </title> <type> Tech. Rep. 944, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, </institution> <address> Ithaca, NY, </address> <year> 1990. </year> <note> To appear in Mathematics of Operations Research. </note>
Reference-contexts: The second algorithm we consider is of the "predictor-corrector" type. For linear programming problems, this algorithm is described by Mizuno, Todd and Ye <ref> [22] </ref> and Ye, Tapia and Zhang [34]. The analysis is extended to linear complementarity problems by Ji, Potra and Huang [15].
Reference: [23] <author> R. D. C. Monteiro and I. Adler, </author> <title> Interior path-following primal-dual algorithms. part II: Convex 27 quadratic programming, </title> <journal> Mathematical Programming, </journal> <volume> 44 (1989), </volume> <pages> pp. 43-66. </pages>
Reference-contexts: The dual of (2.1) is max 2 The relationship between problems (2.1) and (2.2) is outlined in the following proposition (see, for example, Monteiro and Adler <ref> [23, Propositions 2.1-2.3] </ref> and Mangasarian [20, Sec tion 8.2]): Proposition 2.1. (i) If (2.1) has an optimal solution (z fl ; fl ), then there exist w fl and y fl such that (v; w; y) = (z fl ; w fl ; y fl ) is an optimal solution for <p> Monteiro and Adler <ref> [23] </ref> and Kojima, Mizuno and Yoshise [18] show how to construct feasible initial points that are on or near the central path by introducing artificial variables into convex quadratic 10 programs and linear complementarity problems, respectively.
Reference: [24] <author> K. Ohno, </author> <title> A new approach to differential dynamic programming for discrete-time systems, </title> <journal> IEEE Transactions on Automatic Control, </journal> <month> AC-23 </month> <year> (1978), </year> <pages> pp. 37-47. </pages>
Reference-contexts: The computational results we report in Section 6 for the lienar-quadatic problems appear to be similar in efficiency to those reported by Zhu and Rockafellar [36], who performed computations with randomly generated examples on similar workstation equipment. Our approach bears some similarity to one described by Ohno <ref> [24] </ref>. Ohno treats the first-order stationarity conditions for (1.2), and the complementarity conditions y T i g i (x i ; u i ) = 0 as a system of nonlinear equations, which are then solved by a differential dynamic programming method that is similar to Newton's method.
Reference: [25] <author> J.-S. Pang, </author> <title> Inexact Newton methods for the nonlinear complementarity problem, </title> <journal> Mathematical Programming, </journal> <volume> 36 (1986), </volume> <pages> pp. 54-71. </pages>
Reference-contexts: Pang <ref> [25] </ref> suggests the following algorithm for solving (4.5) and hence (4.1): initially: choose (z 0 ; w 0 ; y 0 ), set j = 0 each iteration: find (ffi z ; w; y) such that 16 kH j (ffi z ; w; y)k j j fl fl fl 2 4 <p> When Q j is positive semidefinite, we can use the algorithm of Section 2 to obtain an approximate solution to (4.6), terminating the inner iterations when the criterion (4.8) is satisfied. The following convergence result can be obtained by making straightforward modifications to Theorem 1 of Pang <ref> [25] </ref>. Its proof is omitted. Theorem 4.1. Suppose that (z fl ; w fl ; y fl ) is a solution triple for (4.1), that L, h and g are twice continuously differentiable in a neighborhood of z fl and that conditions (4.2), (4.3) and (4.4) are satisfied. <p> Remarks. 17 1. In Pang <ref> [25] </ref>, only non-mixed NLCP are considered. For mixed NLCP (i.e., those with equality relations as well as inequalities) the definition of H j has to be modified as described above, but the same techniques can be used in the convergence analysis. 2. <p> For mixed NLCP (i.e., those with equality relations as well as inequalities) the definition of H j has to be modified as described above, but the same techniques can be used in the convergence analysis. 2. The value of j is specified more precisely in <ref> [25] </ref>. It depends on the regularity properties of (4.5) at the point (z fl ; w fl ; y fl ) and the size of the neighborhood in which the iterates (z j ; w j ; y j ) are constrained to lie. 3.
Reference: [26] <author> J. F. A. d. O. Pantoja and D. Q. Mayne, </author> <title> Sequential quadratic programming algorithm for discrete optimal control problems with control inequality constraints, </title> <journal> International Journal of Control, </journal> <volume> 53 (1991), </volume> <pages> pp. 823-836. </pages>
Reference-contexts: More recently, Newtonian scaling has been added to gradient projection algorithms (see Gafni and Bertsekas [12], Dunn [7]) to improve their asymptotic rate of convergence, and the resulting methods have proven to be useful for the control-constrained version of (1.2), as we see in Section 6. Pantoja and Mayne <ref> [26] </ref> have described a stagewise algorithm for the control-constrained case that, in a neighborhood of a solution of (1.2), produces iterates that are identical to sequential quadratic programming iterates.
Reference: [27] <author> E. Polak, </author> <title> Computational Methods in Optimization, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: In the "unconstrained" case (that is, when g, g i and g f are absent), Newton-like methods and conjugate gradient methods for (1.1) are described by Polak <ref> [27] </ref>; for (1.2), Newton's method, and its efficient implementation, is discussed in Dunn and Bertsekas [8]. A variety of quasi-Newton approaches have also been applied to the unconstrained version of (1.1); see, for example, Edge and Powers [9] and Kelley and Sachs [16], and the references therein.
Reference: [28] <author> E. Polak, T. H. Yang, and D. Q. Mayne, </author> <title> A method of centers based on barrier functions for solving optimal control problems with continuum state and control constraints, </title> <booktitle> in Proceedings of the 29th Conference on Decision and Control, </booktitle> <month> December </month> <year> 1990, </year> <pages> pp. 2327-2332. </pages>
Reference-contexts: Miele [21] deals mainly with the case in which the auxiliary constraints g in (1.1) are equalities (rather than inequalities) and proposes algorithms of the reduced gradient type, with features added to ensure near-feasibility of all iterates. Polak, Yang and Mayne <ref> [28] </ref> describe a first-order algorithm which makes use of barrier functions for the inequality constraints. Evtushenko [10, Chapter 6] describes a variety of augmented Lagrangian penalty function methods, in which (1.2) is reduced to an unconstrained problem.
Reference: [29] <author> S. M. Robinson, </author> <title> Strongly regular generalized equations, </title> <journal> Mathematics of Operations Research, </journal> <volume> 11 (1980), </volume> <pages> pp. 43-62. </pages>
Reference-contexts: Given (4.2), (4.3) and (4.4), Robinson <ref> [29, Theorem 4.1] </ref> shows that (z fl ; w fl ; y fl ) is a regular solution of the mixed nonlinear complementarity problem (NLCP) dL + d z w + d z y = 0; g (z) 0; y 0; y T g (z) = 0: ("Regularity" is referred to <p> (z fl ; w fl ; y fl ) is a regular solution of the mixed nonlinear complementarity problem (NLCP) dL + d z w + d z y = 0; g (z) 0; y 0; y T g (z) = 0: ("Regularity" is referred to as "strong regularity" in <ref> [29] </ref>.) A common variant of the sequential quadratic programming algorithm for (4.1) obtains a new iterate (z j+1 ; w j+1 ; y j+1 ) from the current iterate (z j ; w j ; y j ) by solving the quadratic program min 2 z Q j ffi z +
Reference: [30] <author> R. T. Rockafellar and R. J. Wets, </author> <title> Generalized linear-quadratic problems of deterministic and stochastic optimal control in discrete time, </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 28 (1990), </volume> <pages> pp. 810-822. </pages>
Reference-contexts: Other researchers have also noted that in many cases the iteration count is practically almost independent of N though, as we show in the next section, formal analyses suggest that it should be O (N 1=2 ). Interesting algorithms have recently been proposed by Rockafellar and co-workers <ref> [30, 36] </ref> for extended linear-quadratic programming, a class of problems that includes discrete-time linear-quadratic optimal control problems.
Reference: [31] <author> S. J. Wright, </author> <title> Partitioned dynamic programming for optimal control, </title> <type> Tech. Rep. </type> <institution> MCS-P173-0890, Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Illinois, </institution> <month> September </month> <year> 1990. </year> <note> To appear in SIAM J. </note> <editor> Optimization. </editor> <title> [32] , Solution of discrete-time optimal control problems on parallel computers, </title> <booktitle> Parallel Computing, 16 (1990), </booktitle> <pages> pp. </pages> <month> 221-238. </month> <title> [33] , A parallel algorithm for banded linear systems, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 12 (1991), </volume> <pages> pp. 824-842. </pages>
Reference-contexts: Instead of making use of the inherent structure in (1.2) at the level of the linear algebra computations, as we do in this paper and also in <ref> [32, 31] </ref>, Pantoja and Mayne exploit the structure at a somewhat higher level.
Reference: [34] <author> Y. Ye, R. A. Tapia, and Y. Zhang, </author> <title> A superlinearly convergent o( p nl)-iteration algorithm for linear programming, </title> <type> Tech. Rep. </type> <institution> TR91-22, Department of Mathematical Sciences, Rice University, Houston, TX, </institution> <year> 1991. </year>
Reference-contexts: The second algorithm we consider is of the "predictor-corrector" type. For linear programming problems, this algorithm is described by Mizuno, Todd and Ye [22] and Ye, Tapia and Zhang <ref> [34] </ref>. The analysis is extended to linear complementarity problems by Ji, Potra and Huang [15].
Reference: [35] <author> Y. Zhang, R. A. Tapia, and J. E. Dennis, </author> <title> On the superlinear and quadratic convergence of primal-dual interior point linear programming algorithms, </title> <type> Tech. Rep. </type> <institution> TR90-6, Department of Mathematical Sciences, Rice University, </institution> <year> 1990. </year>
Reference-contexts: The heuristic above was found, after some experimentation, to be quite successful. As noted by Zhang, Tapia and Dennis <ref> [35] </ref>, the choice ae k = 1= k (which takes effect during the last few iterations) ensures quadratic convergence of the duality gap to zero. The second algorithm we consider is of the "predictor-corrector" type.
Reference: [36] <author> C. Zhu and R. T. Rockafellar, </author> <title> Primal-dual projected gradient algorithms for extended linear quadratic programming, </title> <type> tech. rep., </type> <institution> Department of Applied Mathematics, University of Washington, </institution> <address> Seattle, Washington, </address> <month> August </month> <year> 1990. </year> <month> 28 </month>
Reference-contexts: Other researchers have also noted that in many cases the iteration count is practically almost independent of N though, as we show in the next section, formal analyses suggest that it should be O (N 1=2 ). Interesting algorithms have recently been proposed by Rockafellar and co-workers <ref> [30, 36] </ref> for extended linear-quadratic programming, a class of problems that includes discrete-time linear-quadratic optimal control problems. <p> They aim to find the saddle point of a Lagrangian which, for multistage problems such as (1.3), has the property that it is decomposable with respect to the primal variables when the dual variables are fixed, and vice versa. In Zhu and Rockafellar <ref> [36] </ref>, primal-dual steepest descent and conjugate gradient algorithms which take advantage of this structure are used, and linear convergence results are proved. A finite termination results is proved for the conjugate gradient algorithm. <p> Conclusions. We have described the use of interior point techniques in discrete-time optimal control problems. The computational results we report in Section 6 for the lienar-quadatic problems appear to be similar in efficiency to those reported by Zhu and Rockafellar <ref> [36] </ref>, who performed computations with randomly generated examples on similar workstation equipment. Our approach bears some similarity to one described by Ohno [24].
References-found: 31

