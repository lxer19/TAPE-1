URL: ftp://ftpipr.ira.uka.de/pub/papers/1994/ecai94mk.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Title: Integration of Symbolic and Connectionist Learning to ease Robot Programming and Control  
Author: Michael Kaiser and Jurgen Kreuziger Prof. Dr.-Ing. U. Rembold, Prof. Dr.-Ing. R. Dillmann 
Address: Germany  
Affiliation: University of Karlsruhe Institute for Real-Time Computer Systems Robotics  Karlsruhe  
Note: In: ECAI-94 Workshop on Combining Symbolic and Connectionist Processing, Amsterdam, The Netherlands,  
Pubnum: D-76128  
Email: E-Mail: fkaiserjkreuzigg@ira.uka.de  
Phone: Phone: +49 721 6084051 Fax: +49 721 606740  
Date: 1994  
Abstract: This paper presents an overview on the advantages an integrated symbolic connectionist approach can offer for robot programming and control. It describes the functional dependency of symbolic and connectionist modules being parts of an hierarchical robot control system as well as their descriptive and methodological integration. Moreover, it is shown how both symbolic and connectionist learning techniques can be used to make robot programming easier, namely by means of employing a new technique called "Robot Programming by Demonstration" on several levels of the robot control system. 
Abstract-found: 1
Intro-found: 1
Reference: [Albus et al., 1981] <author> J.E. Albus, A.J. Barbera, and R.N. Nagel. </author> <title> Theory and practice of hierarchical control. </title> <booktitle> In Proceedings of the 23rd IEEE Computer Society International Conference, </booktitle> <year> 1981. </year>
Reference: [Asada & Yang, 1989] <author> H. Asada and B.-H. Yang. </author> <title> Skill acquisition from human experts through pattern processing of teaching data. </title> <booktitle> In Proceedings of the 1989 IEEE International Conference on Robotics and Automation, </booktitle> <year> 1989. </year>
Reference: [Barto et al., 1983] <author> A. G. Barto, R. S. Sutton, and C. W. Anderson. </author> <title> Neuronlike elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <pages> pages 835-846, </pages> <year> 1983. </year>
Reference-contexts: If the evaluation indicates that a certain skill is not sufficient, the output of the corresponding network must be modified. However, this modification is not straightforward, since in general it is not known what would be a "better" output in a given situation. Principally, Reinforcement Learning (e.g., <ref> [Barto et al., 1983] </ref>) is an appropriate learning technique to handle such cases. However, especially for use in real robots the typical random exploration employed in Reinforcement Learning is unfeasible, since the exploration strategy must be both safe and efficient.
Reference: [Brunner et al., 1992] <author> B. Brunner, G. Hirzinger, K. Landzettel, and J. Heindl. </author> <title> Multi-sensory shared autonomy and telesensor-programming key issues in the space robot technology experiment ROTEX. </title> <booktitle> In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '92), </booktitle> <year> 1992. </year>
Reference-contexts: In telerobotics, robots provide the capability to autonomously execute certain operations and relieve the operator from difficult control tasks. These individual capabilities are referred to as skills, the concept itself is also known as shared autonomy ([Hasegawa et al., 1992], <ref> [Brunner et al., 1992] </ref>). Robot programming relies on the existence of a set of skills as the building blocks 1 of a robot program (see also [Dufay & Latombe, 1984], [Heise, 1989], [Munch et al., 1994]).
Reference: [Delson & West, 1993] <author> N. Delson and H. West. </author> <title> Robot programming by human demonstration: subtask compliance controller identification. </title> <booktitle> In Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems, </booktitle> <address> Yokohama, Japan, </address> <year> 1993. </year>
Reference-contexts: Approaches to skill learning are mainly aiming at identifying a control function for a given task. They can be found both in the Robotics ([Asada & Yang, 1989], <ref> [Delson & West, 1993] </ref>) and the Machine Learning community ([Lin, 1993], [Singh, 1994]).
Reference: [Dufay & Latombe, 1984] <author> B. Dufay and J.-C. Latombe. </author> <title> An approach to automatic robot programming based on inductive learning. </title> <booktitle> In Proceedings of the 1st International Symposium on Robotics Research, </booktitle> <year> 1984. </year>
Reference-contexts: These individual capabilities are referred to as skills, the concept itself is also known as shared autonomy ([Hasegawa et al., 1992], [Brunner et al., 1992]). Robot programming relies on the existence of a set of skills as the building blocks 1 of a robot program (see also <ref> [Dufay & Latombe, 1984] </ref>, [Heise, 1989], [Munch et al., 1994]). Approaches to skill learning are mainly aiming at identifying a control function for a given task.
Reference: [Giordana et al., 1994] <author> A. Giordana, M. Kaiser, and M. Nuttin. </author> <title> On the reduction of costs for robot controller synthesis. </title> <booktitle> In International Symposium on Intelligent Robotic Systems (IRS '94), </booktitle> <address> Grenoble, France, </address> <year> 1994. </year>
Reference-contexts: M S is the set of all skills. The situation-action rules as well as the situation evaluation function can be codified by different function approximators, such as fuzzy rules or neural networks (see <ref> [Giordana et al., 1994] </ref> for a comparison of both). <p> Off-line controller generation and test: The actual controller generation comprises training of the several networks representing each skill, where the learning method can be varied (see, for instance, <ref> [Giordana et al., 1994] </ref>). In addition, it is necessary to find criteria indicating if an erroneous situation has been encountered during execution.
Reference: [Gupta & Rao, 1994] <author> M.M. Gupta and D.H. Rao. </author> <title> On the principles of fuzzy neural networks. </title> <journal> Fuzzy Sets and Systems, </journal> <volume> (61):1 - 18, </volume> <year> 1994. </year>
Reference-contexts: The integration in symbolic connectionist systems is usually limited to rule compilation or the mapping of networks into rules, both closely related to the field of fuzzy neural networks ([Towell & Shavlik, 1992], <ref> [Gupta & Rao, 1994] </ref>) and to the application of neural networks in the context of expert systems. This paper investigates the applicability and advantages of an integrated symbolic connectionist approach for robot programming and control.
Reference: [Hasegawa et al., 1992] <author> T. Hasegawa, T. Suehiro, and K. Takase. </author> <title> A model-based manipulation system with skill-based execution. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(5), </volume> <year> 1992. </year>
Reference: [Heise, 1989] <author> R. Heise. </author> <title> Demonstration instead of programming: Focussing attention in robot task acquisition. Research report no. </title> <type> 89/360/22, </type> <institution> Department of Computer Science, University of Calgary, </institution> <year> 1989. </year>
Reference-contexts: This paper investigates the applicability and advantages of an integrated symbolic connectionist approach for robot programming and control. Especially, the robot's ability to communicate with and to learn from an operator is considered, leading to the recently emerging paradigm of Robot Programming by Human Demonstration (RPD, <ref> [Heise, 1989] </ref>, [Munch et al., 1994]). RPD is an intuitive method to program a robot. The programmer shows how a particular task is performed, using an interface device that allows the measurement and recording of the human's motions and the forces that are applied. <p> Robot programming relies on the existence of a set of skills as the building blocks 1 of a robot program (see also [Dufay & Latombe, 1984], <ref> [Heise, 1989] </ref>, [Munch et al., 1994]). Approaches to skill learning are mainly aiming at identifying a control function for a given task. They can be found both in the Robotics ([Asada & Yang, 1989], [Delson & West, 1993]) and the Machine Learning community ([Lin, 1993], [Singh, 1994]).
Reference: [Hinton, 1990] <author> G. E. Hinton. </author> <title> Special issue on connectionist symbolic processing. </title> <journal> Artificial Intelligence, </journal> <year> 1990. </year>
Reference: [Kaiser et al., 1994] <author> M. Kaiser, A. Giordana, and M. Nuttin. </author> <title> Integrated acquisition, execution, evaluation and tuning of elementary skills for intelligent robots. </title> <booktitle> In Proceedings of the IFAC Symposium on Artificial Intelligence in Real Time Control (AIRTC '94), </booktitle> <address> Valencia, Spain, </address> <year> 1994. </year>
Reference-contexts: The skill handler, which extents the system architecture towards the control level, takes care of these requirements. 2.3 The Skill Handler As well as in the superimposed system architecture, the skill handler is designed to use learning capabilities as an integral part of the system (see also <ref> [Kaiser et al., 1994] </ref>). One of the most important aspects in this context is to use a representation that allows for an explicit access to and an alteration of the represented knowledge.
Reference: [Kaiser, 1994] <author> M. Kaiser. </author> <title> A framework for the generation of robot controllers from examples. </title> <booktitle> In Proceedings of the 10th ISPE/IFAC Symposium on CAD/CAM, Robotics, and Factories of the Future, </booktitle> <address> Ottawa, Canada, </address> <year> 1994. </year>
Reference-contexts: Based on previous work ([Kreuziger & Hauser, 1993], <ref> [Kaiser, 1994] </ref>), this article outlines the different integration tasks that must be considered for both the design and the operation of a sophisticated learning robot control system. It also illustrates possibilities for the actual realization of the integration by means of detailed descriptions of the representations underlying the individual components. <p> Gray arrows mark feedback loops. also <ref> [Kaiser, 1994] </ref>). This procedure comprises the generation and initial processing of the examples as well as an initialization of the parameters of the method that is actually used to learn the control function described by the examples.
Reference: [Kreuziger & Hauser, 1993] <author> J. Kreuziger and M. Hauser. </author> <title> A new system architecture for applying symbolic learning techniques to robot manipulation. </title> <booktitle> In Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems, </booktitle> <address> Yokohama, </address> <year> 1993. </year>
Reference-contexts: Nevertheless, this distinction is resembled in Machine Learning as well by separating subsymbolic techniques strictly from the symbolic ones. Therefore, the functional and methodological integration of these components is an important issue. 2.2 The System Architecture The basic system architecture (see figure 1, for a thorough description see also <ref> [Kreuziger & Hauser, 1993] </ref>) has been designed such that learning could become an integrated part of knowledge acquisition, problem solving, and knowledge refinement.
Reference: [Kreuziger, 1994] <author> J. Kreuziger. </author> <title> An architecture for the application of symbolic learning in robotics. </title> <type> PhD thesis, </type> <institution> University of Karlsruhe, Department of Computer Science, </institution> <year> 1994. </year> <note> In German. </note>
Reference-contexts: Especially the application of symbolic learning in Robotics usually considers only simple problems or takes place in simulation only (see, for instance, [Van De Velde, 1991] or <ref> [Kreuziger, 1994] </ref> for an overview). <p> tasks of the learning system and the tasks of the robot first and to design an architecture being able to host both the learning and the performance components afterwards. 2.1 Learning Tasks There are several learning tasks that can be identified in the framework of Robotics and robot control (see <ref> [Kreuziger, 1994] </ref> for an overview).
Reference: [Kung & Hwang, 1989] <author> S. Y. Kung and J. N. Hwang. </author> <title> Neural network architectures for robotic applications. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(5), </volume> <year> 1989. </year>
Reference: [Lin, 1993] <author> L. J. Lin. </author> <title> Reinforcement learning for robots using neural networks. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1993. </year>
Reference: [Michalski, 1993] <author> R. S. </author> <title> Michalski. </title> <journal> Special issue on multistrategy learning. Machine Learning, </journal> <volume> 11, </volume> <year> 1993. </year>
Reference-contexts: Currently, approaches to Multi-strategy Learning are mainly aiming at integrating empirical and analytical learning methods in order to speed up the empirical learning process ([Hinton, 1990], <ref> [Michalski, 1993] </ref>).
Reference: [Munch et al., 1994] <author> S. Munch, J. Kreuziger, M. Kaiser, and R. Dillmann. </author> <title> Robot programming by demonstration using machine learning and user interaction methods for the development of easy and comfortable robot programming systems. </title> <booktitle> In Proceedings of the International Symposium on Industrial Robots (ISIR '94), </booktitle> <year> 1994. </year>
Reference-contexts: This paper investigates the applicability and advantages of an integrated symbolic connectionist approach for robot programming and control. Especially, the robot's ability to communicate with and to learn from an operator is considered, leading to the recently emerging paradigm of Robot Programming by Human Demonstration (RPD, [Heise, 1989], <ref> [Munch et al., 1994] </ref>). RPD is an intuitive method to program a robot. The programmer shows how a particular task is performed, using an interface device that allows the measurement and recording of the human's motions and the forces that are applied. <p> Robot programming relies on the existence of a set of skills as the building blocks 1 of a robot program (see also [Dufay & Latombe, 1984], [Heise, 1989], <ref> [Munch et al., 1994] </ref>). Approaches to skill learning are mainly aiming at identifying a control function for a given task. They can be found both in the Robotics ([Asada & Yang, 1989], [Delson & West, 1993]) and the Machine Learning community ([Lin, 1993], [Singh, 1994]).
Reference: [Nuttin et al., In preparation] <author> M. Nuttin, J. Peirs, A.S. Soembagijo, S. Sonck, and H. Van Brussel. </author> <title> Learning the peg-into-hole assembly with a connectionist reinforcement technique. </title> <type> Technical report, </type> <institution> KU Leuven, </institution> <note> In preparation. </note>
Reference-contexts: In this implicit representation, knowledge is not learnable 1 , hence most work concerning learning deals with the improvement of control knowledge by means of Neural Networks ([Kung & Hwang, 1989], [Sontag, 1993]) or reinforcement learning ([Lin, 1993], <ref> [Nuttin et al., In preparation] </ref>)). Especially the application of symbolic learning in Robotics usually considers only simple problems or takes place in simulation only (see, for instance, [Van De Velde, 1991] or [Kreuziger, 1994] for an overview).
Reference: [Plaza, 1993] <editor> E. Plaza, editor. </editor> <booktitle> Proceedings of the Workshop on Integrated Learning Architectures (ILA '93), </booktitle> <address> Vienna, Austria, </address> <year> 1993. </year>
Reference: [Singh, 1994] <author> S. P. Singh. </author> <title> Learning to solve markovian decision processes. </title> <type> PhD thesis, </type> <institution> University of Mas-sachusetts, Department of Computer Sciene, </institution> <year> 1994. </year>
Reference-contexts: Approaches to skill learning are mainly aiming at identifying a control function for a given task. They can be found both in the Robotics ([Asada & Yang, 1989], [Delson & West, 1993]) and the Machine Learning community ([Lin, 1993], <ref> [Singh, 1994] </ref>).
Reference: [Sontag, 1993] <author> E.D. Sontag. </author> <title> Some topics in neural networks and control. </title> <booktitle> In Proceedings of the European Control Conference, </booktitle> <year> 1993. </year>
Reference-contexts: In this implicit representation, knowledge is not learnable 1 , hence most work concerning learning deals with the improvement of control knowledge by means of Neural Networks ([Kung & Hwang, 1989], <ref> [Sontag, 1993] </ref>) or reinforcement learning ([Lin, 1993], [Nuttin et al., In preparation])). Especially the application of symbolic learning in Robotics usually considers only simple problems or takes place in simulation only (see, for instance, [Van De Velde, 1991] or [Kreuziger, 1994] for an overview).
Reference: [Torras, 1992] <author> C. Torras. </author> <title> Symbolic planning versus neural control in robots. </title> <editor> In F. Cervantes P. Rudomin, M. Arbib, editor, </editor> <booktitle> Natural and Artificial Intelligence: A Meeting between Neuroscience and AI. </booktitle> <year> 1992. </year>
Reference: [Towell & Shavlik, 1992] <author> G. G. Towell and J. W. Shavlik. </author> <title> Using symbolic learning to improve knowledge-based neural networks. </title> <booktitle> In Proceedings of the tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <year> 1992. </year>
Reference: [Van De Velde, 1991] <author> W. Van De Velde. </author> <title> Special issue: Towards learning robots. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <address> 8(1,2), </address> <year> 1991. </year>
Reference-contexts: Especially the application of symbolic learning in Robotics usually considers only simple problems or takes place in simulation only (see, for instance, <ref> [Van De Velde, 1991] </ref> or [Kreuziger, 1994] for an overview).
References-found: 26

