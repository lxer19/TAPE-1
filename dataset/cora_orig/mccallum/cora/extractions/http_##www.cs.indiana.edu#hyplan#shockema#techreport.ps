URL: http://www.cs.indiana.edu/hyplan/shockema/techreport.ps
Refering-URL: http://www.cs.indiana.edu/hyplan/shockema/resume.html
Root-URL: http://www.cs.indiana.edu
Title: Faster MUSE CSP Arc Consistency Algorithms  
Author: Mary P. Harper, Christopher M. White, Randall A. Helzerman, and Stephen A. Hockema 
Note: This research was supported by a grant from the Intel Research Council and the National Science Foundation under Grant No. IRI-9704358.  
Address: Building  West Lafayette, IN 47907  
Affiliation: School of Electrical and Computer Engineering 1285 Electrical Engineering  Purdue University,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Christian Bessiere. </author> <title> Arc-consistency and arc-consistency again. </title> <journal> Artificial Intelligence, </journal> <volume> 65 </volume> <pages> 179-190, </pages> <year> 1994. </year>
Reference-contexts: Although AC-4 has a worst-case running time of fi (el 2 ) (where e is the number of constraint arcs), AC-3 [7] with a worst-case running time of fi (el 3 ) often performs better than AC-4 in practice. Recently, Bessiere developed a new algorithm, AC-6 <ref> [1] </ref>, which has the same worst-case running time as AC-4 and is faster than AC-3 and AC-4 in practice. In this paper, we focus on providing faster MUSE arc consistency algorithms by applying techniques similar to those developed by Bessiere. <p> applies Bessiere's method to improve upon MUSE AC-1, and MUSE AC-3, which, in addition to Bessiere's method, uses our "lazy" evaluation method for keeping track of the Prev-Support, Next-Support, Local-Prev-Support, and Local-Next-Support sets. 2 AC-6 To improve the average-case performance while maintaining the same worst-case time complexity of AC-4, Bessiere <ref> [1] </ref> developed AC-6, an algorithm conceptually similar to AC-4 but which avoids much of the work always carried out by AC-4. <p> The results of this experiment are displayed in Figures 13 (b), 14 (b), and 15 (b). Each subfigure displays the running times for each of the three MUSE AC algorithms. Following Bessiere <ref> [1] </ref>, we measure the running times of each MUSE AC algorithm by counting the number of times an atomic operation is executed. <p> We have shown that MUSE AC-2 performs fewer operations than MUSE AC-1 simply by using the method of initializing and updating the S sets as in <ref> [1] </ref>. MUSE AC-3 improves upon MUSE AC-2 by using our "lazy" method to initialize and update the DAG support sets.
Reference: [2] <author> C. Han and C. Lee. </author> <title> Comments on Mohr and Henderson's path consistency algorithm. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 125-130, </pages> <year> 1988. </year>
Reference-contexts: Helzerman and Harper [6] also defined the concepts of MUSE node, arc, and path consistency and developed algorithms for MUSE arc consistency, MUSE AC-1, and MUSE path consistency, MUSE PC-1. These algorithms are similar to the CSP arc consistency algorithm AC-4 [11] and path consistency algorithm PC-4 <ref> [2] </ref>. Although AC-4 has a worst-case running time of fi (el 2 ) (where e is the number of constraint arcs), AC-3 [7] with a worst-case running time of fi (el 3 ) often performs better than AC-4 in practice.
Reference: [3] <author> M. P. Harper and R. A. Helzerman. </author> <title> Extensions to constraint dependency parsing for spoken language processing. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 9(3) </volume> <pages> 187-234, </pages> <year> 1995. </year>
Reference-contexts: Hence, Harper and Helzerman <ref> [3] </ref> adapted the parsing algorithm to support the simultaneous parsing of alternative sentences resulting from lexical or feature ambiguity or from word segmentation ambiguity during speech recognition. <p> MUSE AC-3 improves upon MUSE AC-2 by using our "lazy" method to initialize and update the DAG support sets. These runtime improvements have proven useful for applications using a MUSE CSP based parser, including spoken 17 each sentence. language understanding systems <ref> [3] </ref> and natural language front ends for multiple databases [4]. These algorithms should also be effective for other CSP problems that have problems comparable to lexical ambiguity, feature ambiguity, or ambiguity resulting from the inability to segment a signal into higher-level chunks in a single way.
Reference: [4] <author> M. P. Harper and R. A. Helzerman. </author> <title> Managing multiple knowledge sources in constraint-based parsing of spoken language. </title> <note> Fundamenta Informaticae, 23(2,3,4):303-353, </note> <year> 1995. </year>
Reference-contexts: The MUSE AC-1, MUSE AC-2, and MUSE AC-3 algorithms have been incorporated into our CDG parser to perform arc consistency prior to extraction of legal parses. This parser uses methods developed by Harper and Helzerman <ref> [4] </ref> to parse a sentence containing words with multiple lexical categories and multiple feature values. This method applies constraints in multiple stages such that, at the initial stage, the MUSE network representing the sentence is fairly small. <p> These runtime improvements have proven useful for applications using a MUSE CSP based parser, including spoken 17 each sentence. language understanding systems [3] and natural language front ends for multiple databases <ref> [4] </ref>. These algorithms should also be effective for other CSP problems that have problems comparable to lexical ambiguity, feature ambiguity, or ambiguity resulting from the inability to segment a signal into higher-level chunks in a single way. Two examples of comparable domains are visual understanding and handwriting analysis. 18
Reference: [5] <author> Randall A. Helzerman and Mary P. Harper. </author> <title> An approach to multiply-segmented constraint satisfaction problems. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 350-355, </pages> <year> 1994. </year>
Reference-contexts: From this work, the concept of a MUSE CSP (MU ltiply SE gmented C onstraint S atisfaction P roblem) <ref> [5, 6] </ref> was developed to support the efficient simultaneous processing of multiple alternative CSP problems. <p> The proof of correctness of the algorithms is comparable to that for MUSE AC-1 <ref> [5, 6] </ref>, and so we will not give the proof here. 4 Experiments, Results, and Conclusions In order to compare the performance of MUSE AC-1, MUSE AC-2, and MUSE AC-3, we have conducted experiments in which we randomly generate MUSE CSP instances with three different topologies.
Reference: [6] <author> Randall A. Helzerman and Mary P. Harper. </author> <title> MUSE CSP: An extension to the constraint satisfaction problem. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 5 </volume> <pages> 239-288, </pages> <year> 1996. </year>
Reference-contexts: From this work, the concept of a MUSE CSP (MU ltiply SE gmented C onstraint S atisfaction P roblem) <ref> [5, 6] </ref> was developed to support the efficient simultaneous processing of multiple alternative CSP problems. <p> Since a MUSE CSP is represented as a directed acyclic graph, segments are defined as paths through the MUSE CSP from a special purpose start to end node. Helzerman and Harper <ref> [6] </ref> also defined the concepts of MUSE node, arc, and path consistency and developed algorithms for MUSE arc consistency, MUSE AC-1, and MUSE path consistency, MUSE PC-1. These algorithms are similar to the CSP arc consistency algorithm AC-4 [11] and path consistency algorithm PC-4 [2]. <p> Hence, there is more information that must be tracked in any MUSE arc consistency algorithm. MUSE arc consistency is enforced by removing those labels in each L i that violate the conditions of Definition 2. MUSE AC-1 <ref> [6] </ref> builds and maintains several data structures defined in Figure 1, some that are similar to those used by AC-4 and some that are new (i.e., those below the double line in Figure 1), to allow it to correctly perform this operation. <p> Figure 5 shows the algorithm for initializing the data structures and Figure 6 contains the algorithm for eliminating inconsistent labels from the domains. The procedures to update the DAG support sets for MUSE AC-2 are the same as for MUSE AC-1 (see <ref> [6] </ref>) and appear in Figure 7. MUSE AC-3 manages the S support sets in the same way as in MUSE AC-2; however, it uses a new method for initializing the DAG support sets and updating them in Figure 5. <p> The proof of correctness of the algorithms is comparable to that for MUSE AC-1 <ref> [5, 6] </ref>, and so we will not give the proof here. 4 Experiments, Results, and Conclusions In order to compare the performance of MUSE AC-1, MUSE AC-2, and MUSE AC-3, we have conducted experiments in which we randomly generate MUSE CSP instances with three different topologies.
Reference: [7] <author> A. K. Mackworth and E. Freuder. </author> <title> The complexity of some polynomial network-consistency algorithms for constraint-satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 65-74, </pages> <year> 1985. </year>
Reference-contexts: These algorithms are similar to the CSP arc consistency algorithm AC-4 [11] and path consistency algorithm PC-4 [2]. Although AC-4 has a worst-case running time of fi (el 2 ) (where e is the number of constraint arcs), AC-3 <ref> [7] </ref> with a worst-case running time of fi (el 3 ) often performs better than AC-4 in practice. Recently, Bessiere developed a new algorithm, AC-6 [1], which has the same worst-case running time as AC-4 and is faster than AC-3 and AC-4 in practice.
Reference: [8] <author> H. Maruyama. </author> <title> Constraint dependency grammar. </title> <type> Technical Report #RT0044, </type> <institution> IBM, </institution> <address> Tokyo, Japan, </address> <year> 1990. </year>
Reference-contexts: This approach has been used in a variety of disciplines including machine vision, belief maintenance, temporal reasoning, graph theory, circuit design, diagnostic reasoning, and natural language processing. Constraint Dependency Grammar (CDG) parsing, as introduced by Maruyama <ref> [8, 9, 10] </ref>, was framed as a constraint satisfaction problem (CSP); the parsing rules are the constraints and the solutions are the parses.
Reference: [9] <author> H. Maruyama. </author> <title> Constraint dependency grammar and its weak generative capacity. </title> <booktitle> Computer Software, </booktitle> <year> 1990. </year>
Reference-contexts: This approach has been used in a variety of disciplines including machine vision, belief maintenance, temporal reasoning, graph theory, circuit design, diagnostic reasoning, and natural language processing. Constraint Dependency Grammar (CDG) parsing, as introduced by Maruyama <ref> [8, 9, 10] </ref>, was framed as a constraint satisfaction problem (CSP); the parsing rules are the constraints and the solutions are the parses.
Reference: [10] <author> H. Maruyama. </author> <title> Structural disambiguation with constraint propagation. </title> <booktitle> In The Proceedings of the Annual Meeting of ACL, </booktitle> <pages> pages 31-38, </pages> <year> 1990. </year>
Reference-contexts: This approach has been used in a variety of disciplines including machine vision, belief maintenance, temporal reasoning, graph theory, circuit design, diagnostic reasoning, and natural language processing. Constraint Dependency Grammar (CDG) parsing, as introduced by Maruyama <ref> [8, 9, 10] </ref>, was framed as a constraint satisfaction problem (CSP); the parsing rules are the constraints and the solutions are the parses.
Reference: [11] <author> R. Mohr and T. C. Henderson. </author> <title> Arc and path consistency revisited. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 225-233, </pages> <year> 1986. </year>
Reference-contexts: Helzerman and Harper [6] also defined the concepts of MUSE node, arc, and path consistency and developed algorithms for MUSE arc consistency, MUSE AC-1, and MUSE path consistency, MUSE PC-1. These algorithms are similar to the CSP arc consistency algorithm AC-4 <ref> [11] </ref> and path consistency algorithm PC-4 [2]. Although AC-4 has a worst-case running time of fi (el 2 ) (where e is the number of constraint arcs), AC-3 [7] with a worst-case running time of fi (el 3 ) often performs better than AC-4 in practice.
Reference: [12] <author> P. J. Price, W. Fischer, J. Bernstein, and D. Pallett. </author> <title> A database for continuous speech recognition in a 1000-word domain. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 651-654, </pages> <year> 1988. </year> <month> 19 </month>
Reference-contexts: This method of parsing keeps the size of the MUSE network relatively small. For this experiment, we randomly chose 100 sentences to parse from the Resource Management Corpus <ref> [12] </ref> in order to compare the 15 by branching factor fi path length. Each node has 16 labels, and the probability of a constraint between two nodes is 50 percent. 16 Comparing MUSE Mean Median Std.
References-found: 12

