URL: http://cobar.cs.umass.edu/pubfiles/cb-20.ps
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Title: Using CBR to Drive IR  
Author: Edwina L. Rissland and Jody J. Daniels 
Address: Amherst, MA 01003 USA  
Affiliation: Department of Computer Science University of Massachusetts  
Note: c flAAAI. Published in IJCAI-95 pps. 400--407, August, 1995, Montreal, Canada. 1  
Abstract: We discuss the use of Case-Based Reasoning (CBR) to drive an Information Retrieval (IR) system. Our hybrid CBR-IR approach takes as input a standard frame-based representation of a problem case, and outputs texts of relevant cases retrieved from a document corpus dramatically larger than the case base available to the CBR system. While the smaller case base is accessible by the usual case-based indexing, and is amenable to knowledge-intensive methods, the larger IR corpus is not. Our approach provides two benefits: it extends the reach of CBR (for retrieval purposes) to much larger corpora, and it enables the injection of knowledge-based techniques into traditional IR. Our system works by first performing a standard HYPO-style CBR analysis, and then using texts associated with certain important cases found in this analysis to seed a modified version of INQUERY's relevance feedback mechanism in order to generate a query. We describe our approach and report on experiments performed in two different legal domains.
Abstract-found: 1
Intro-found: 1
Reference: [ Ashley, 1990 ] <author> Kevin D. Ashley. </author> <title> Modeling Legal Argument: Reasoning with Cases and Hypotheticals. </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Any further analysis of these retrieved texts, for instance, for the purpose of making a case-based argument, is up to the user. Our hybrid CBR-IR system works by first performing a standard HYPO-style CBR analysis ( <ref> [ Ashley, 1990 ] </ref> ; [ Riss-land and Ashley, 1987 ] ), and then using the results to cause the INQUERY IR system [ Callan et al., 1992 ] to generate and act on a query. <p> Our own CBR systems, which use detailed case representations-HYPO <ref> [ Ashley, 1990 ] </ref> [ Rissland and Ash-ley, 1987 ] , CABARET [ Rissland and Skalak, 1991 ] , FRANK [ Rissland et al., 1993 ] , BankXX [ Rissland et al., 1994a ] [ Riss-land et al., 1994b ] -have typically had case bases in the range of three to <p> The same case representation is used for representing a problem case and cases in the CBR module's case-knowledge base or CKB. We use a standard HYPO-styled CBR module to perform the case-based reasoning <ref> [ Ashley, 1990 ] </ref> , [ Rissland and Ash-ley, 1987 ] .
Reference: [ Blair and Maron, 1985 ] <author> David C. Blair and M. E. Maron. </author> <title> An Evaluation of Retrieval Effectiveness for a Full-Text Document-Retrieval System. </title> <journal> Communications of the ACM, </journal> <volume> 28(3) </volume> <pages> 289-299, </pages> <month> March </month> <year> 1985. </year>
Reference-contexts: For instance, one study found that although many users felt that they had retrieved most of the right documents (i.e., that recall was high), in fact, they had retrieved only a mere 25% of the relevant texts <ref> [ Blair and Maron, 1985 ] </ref> . The other typical problem is that of retrieving too much information, only some of which is relevant.
Reference: [ Callan et al., 1992 ] <author> James P. Callan, W. Bruce Croft, and Stephen M. Harding. </author> <title> The INQUERY Retrieval System. </title> <editor> In A. M. Tjoa and I. Ramos, editors, </editor> <booktitle> Database and Expert Systems Applications: Proceedings of the International Conference in Valencia, Spain, </booktitle> <pages> pp 78-83, </pages> <address> Valencia, Spain, 1992. </address> <publisher> Springer Verlag, </publisher> <address> NY. </address>
Reference-contexts: Our hybrid CBR-IR system works by first performing a standard HYPO-style CBR analysis ( [ Ashley, 1990 ] ; [ Riss-land and Ashley, 1987 ] ), and then using the results to cause the INQUERY IR system <ref> [ Callan et al., 1992 ] </ref> to generate and act on a query. This is done by applying a modified version of INQUERY's relevance feedback (RF) mechanism to the documents associated with important cases found during the CBR analysis, such as most on-point cases.
Reference: [ Creecy et al., 1992 ] <author> Robert H. Creecy, Brij M. Masand, Stephen J. Smith, and David L. Waltz. </author> <title> Trading MIPs and Memory for Knowledge Engineering. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 48-64, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: If the case base is constructed after the fact from pre-existing archives of textual materials, the task can be daunting. Most CBR systems that have represented large numbers of cases have used fairly simple case representations (e.g., MBRtalk [ Stanfill and Waltz, 1986 ] , PACE <ref> [ Creecy et al., 1992 ] </ref> , JOHNNY [ Stanfill, 1988 ] , Anapron [ Golding and Rosenbloom, 1991 ] ) or have used representations easily derived from solved problems [ Veloso, 1992 ] .
Reference: [ Croft and Das, 1990 ] <author> W. Bruce Croft and Raj Das. </author> <title> Experiments with Query Acquisition and Use in Document Retrieval Systems. </title> <booktitle> In 13th International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp 349-365, </pages> <year> 1990. </year>
Reference-contexts: An RF module uses a selection metric to extract a set of terms from the relevant texts. The top n terms are then weighted according to another metric. For our experiments, we apply the selection and weighting metrics used in a similar application <ref> [ Croft and Das, 1990 ] </ref> . A query consists of a weighted sum of terms. Ordinarily INQUERY would not engage in relevance feedback until a retrieval, based on user input, had been made and a set of documents retrieved, examined, and tagged by the user. <p> In fact, in most instances our system achieved results as good as or better than with queries with fewer terms. Thus, not only is there limited cost associated with using this many terms, there is no detrimental effect. Our results stand in contrast to those of Croft and Das, <ref> [ Croft and Das, 1990 ] </ref> , who claimed that relevance feedback may not be beneficial when using only a small set of relevant documents. We found this not to be the case. Their doubts are due to the potential lack of concept coverage by a small set of documents.
Reference: [ Golding and Rosenbloom, 1991 ] <author> Andrew R. Golding and Paul S. Rosenbloom. </author> <title> Improving Rule-Based Systems Through Case-Based Reasoning. </title> <booktitle> In Proceedings, Ninth International Conference on Artificial Intelligence, </booktitle> <volume> volume 1, </volume> <pages> pp 22-27, </pages> <address> Anaheim, CA, </address> <month> July </month> <year> 1991. </year> <note> AAAI. </note>
Reference-contexts: Most CBR systems that have represented large numbers of cases have used fairly simple case representations (e.g., MBRtalk [ Stanfill and Waltz, 1986 ] , PACE [ Creecy et al., 1992 ] , JOHNNY [ Stanfill, 1988 ] , Anapron <ref> [ Golding and Rosenbloom, 1991 ] </ref> ) or have used representations easily derived from solved problems [ Veloso, 1992 ] .
Reference: [ Haines and Croft, 1993 ] <author> David Haines and Bruce Croft. </author> <title> Relevance Feedback and Inference Networks. </title> <type> Technical report, </type> <institution> University of Massachusetts at Amherst, </institution> <address> Amherst, MA, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: The HOD-corpus contains cases addressing a great many legal questions. It was built by adding approximately 200 cases to another already existing, nearly 12,000 document collection, called the West or FSupp collection <ref> [ Haines and Croft, 1993 ] </ref> , [ Turtle, 1994 ] . The additional texts are for cases contained in the CABARET CKB and cases found when the query home office was posed to the on-line WestLaw Federal Taxation Case Law database. <p> The figures for the original FSupp collection are taken from <ref> [ Haines and Croft, 1993 ] </ref> . 5.4 Answer Keys For each problem, we constructed an answer key that specifies the documents to be considered as relevant. In these experiments, we used a very broad sense of relevance.
Reference: [ Kolodner, 1993 ] <author> Janet L. Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Among current CBR systems there are few with large case bases (say, larger than 1000 cases) and fewer still with both large case bases and large-sized cases, although all CBR systems use symbolic representations of cases and many perform highly sophisticated reasoning <ref> [ Kolodner, 1993 ] </ref> . On the other hand, full-text information retrieval (IR) systems are not hampered by any lack of available cases (in textual form).
Reference: [ Rissland and Ashley, 1987 ] <author> Edwina L. Rissland and Kevin D. Ashley. </author> <title> A Case-Based System for Trade Secrets Law. </title> <booktitle> In Proceedings, First International Conference on Artificial Intelligence and Law. ACM, </booktitle> <publisher> ACM Press, </publisher> <month> May </month> <year> 1987. </year> [ <editor> Rissland and Skalak, 1991 ] Edwina L. Rissland and David B. Skalak. CABARET: </editor> <title> Rule Interpretation in a Hybrid Architecture. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 34 </volume> <pages> 839-887, </pages> <year> 1991. </year>
Reference: [ Rissland et al., 1993 ] <author> E. L. Rissland, J. J. Daniels, Z. B. Ru-binstein, and D. B. Skalak. </author> <title> Case-Based Diagnostic Analysis in A Blackboard Architecture. </title> <booktitle> In Proceedings, The 11th National Conference on Artificial Intelligence, </booktitle> <pages> pp 66-72, </pages> <address> Washington D.C., </address> <month> July </month> <year> 1993. </year> <note> AAAI. </note>
Reference-contexts: Our own CBR systems, which use detailed case representations-HYPO [ Ashley, 1990 ] [ Rissland and Ash-ley, 1987 ] , CABARET [ Rissland and Skalak, 1991 ] , FRANK <ref> [ Rissland et al., 1993 ] </ref> , BankXX [ Rissland et al., 1994a ] [ Riss-land et al., 1994b ] -have typically had case bases in the range of three to five dozen cases.
Reference: [ Rissland et al., 1994a ] <author> Edwina L. Rissland, D. B. Skalak, and M. Timur Friedman. BankXX: </author> <title> Supporting Legal Arguments through Heuristic Retrieval. </title> <type> Technical Report 94-76, </type> <institution> University of Massachusetts at Amherst, </institution> <address> Amherst, MA, </address> <year> 1994. </year>
Reference-contexts: Our own CBR systems, which use detailed case representations-HYPO [ Ashley, 1990 ] [ Rissland and Ash-ley, 1987 ] , CABARET [ Rissland and Skalak, 1991 ] , FRANK [ Rissland et al., 1993 ] , BankXX <ref> [ Rissland et al., 1994a ] </ref> [ Riss-land et al., 1994b ] -have typically had case bases in the range of three to five dozen cases. <p> Rather, we used pretty much as is the representations developed in two past CBR projects from our lab: CABARET [ Rissland and Skalak, 1991 ] and BankXX <ref> [ Rissland et al., 1994a ] </ref> [ Rissland et al., 1994b ] . We only added one additional slot to each case: the document identifier of the case's opinion in the text collection.
Reference: [ Rissland et al., 1994b ] <author> Edwina L. Rissland, D. B. Skalak, and M. Timur Friedman. </author> <title> Heuristic Harvesting of Information for Case-Based Argument. </title> <booktitle> In Proceedings, The 12th National Conference on Artificial Intelligence, </booktitle> <pages> pp 36-43, </pages> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year> <note> AAAI. </note>
Reference-contexts: Rather, we used pretty much as is the representations developed in two past CBR projects from our lab: CABARET [ Rissland and Skalak, 1991 ] and BankXX [ Rissland et al., 1994a ] <ref> [ Rissland et al., 1994b ] </ref> . We only added one additional slot to each case: the document identifier of the case's opinion in the text collection. The same case representation is used for representing a problem case and cases in the CBR module's case-knowledge base or CKB. <p> and the main parameters varied in our experiments. 5.1 Domains We have used two domains in our work thus far: 1. the home office deduction domain, used originally in our CABARET project [ Rissland and Skalak, 1991 ] ; 2. the good faith bankruptcy domain, used in our BankXX project <ref> [ Rissland et al., 1994b ] </ref> . CABARET's original case base consisted of 36 real and hypothetical cases concerning the home office deduction, as specified in Section 280A (c)(1) of the Internal Revenue Code.
Reference: [ Salton, 1989 ] <author> Gerard Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: There are huge case bases and individual cases are often very large (e.g., tens of pages of text); however, the level of representation is shallow at best (i.e., the text itself), and the indexing is weak (e.g., based on statistics of the collection) <ref> [ Salton, 1989 ] </ref> . fl This research was supported by NSF Grant no. EEC-9209623, State/Industry/University Cooperative Research on Intelligent Information Retrieval, Digital Equipment Corporation and the National Center for Automated Information Research. Thus we have two well-developed technologies, each with its own strengths and limitations. <p> Full-text versions of the opinions for cases selected for inclusion in the RF-CKB are passed to a modified version of INQUERY's relevance feedback module. Relevance feedback is a widely-used method for improving retrieval. It can improve precision significantly <ref> [ Salton, 1989 ] </ref> . In relevance feedback, a user tags texts as to their relevance. Using information derived from the texts tagged as relevant, an RF algorithm alters the weights of the terms used in the original query, and/or adds additional query terms, to produce a modified query.
Reference: [ Shimazu et al., 1993 ] <author> Hideo Shimazu, Hiroaki Kitano, and Akihiro Shibata. </author> <title> Retrieving Cases from Relational DataBases: Another Stride Toward Corporate-Wide Case-Base Systems. </title> <booktitle> In Proceedings, 13th International Joint Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> pp 909-914, </pages> <address> Chambery, France, </address> <year> 1993. </year> <title> IJCAI, </title> <publisher> Morgan-Kaufmann. </publisher>
Reference-contexts: In a very few situations, large case bases have been constructed through a combination of case acquisition as a side-effect of customer service and follow-up knowledge engineering by a team specifically tasked with creating a case base <ref> [ Shimazu et al., 1993 ] </ref> .
Reference: [ Stanfill and Waltz, 1986 ] <author> Craig Stanfill and David Waltz. </author> <title> Toward Memory-Based Reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1213-1228, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: If the case base is constructed after the fact from pre-existing archives of textual materials, the task can be daunting. Most CBR systems that have represented large numbers of cases have used fairly simple case representations (e.g., MBRtalk <ref> [ Stanfill and Waltz, 1986 ] </ref> , PACE [ Creecy et al., 1992 ] , JOHNNY [ Stanfill, 1988 ] , Anapron [ Golding and Rosenbloom, 1991 ] ) or have used representations easily derived from solved problems [ Veloso, 1992 ] .
Reference: [ Stanfill, 1988 ] <author> Craig Stanfill. </author> <title> Learning to Read: A Memory-Based Model. </title> <booktitle> In Proceedings of the Case-Based Reasoning Workshop, </booktitle> <pages> pp 402-413, </pages> <address> Clearwater Beach, FL, </address> <month> May </month> <year> 1988. </year> <pages> DARPA. </pages>
Reference-contexts: Most CBR systems that have represented large numbers of cases have used fairly simple case representations (e.g., MBRtalk [ Stanfill and Waltz, 1986 ] , PACE [ Creecy et al., 1992 ] , JOHNNY <ref> [ Stanfill, 1988 ] </ref> , Anapron [ Golding and Rosenbloom, 1991 ] ) or have used representations easily derived from solved problems [ Veloso, 1992 ] .
Reference: [ Turtle and Croft, 1991 ] <author> H. R. Turtle and W. B. Croft. </author> <title> Evaluation of an Inference Network-Based Retrieval Model. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 9(3) </volume> <pages> 187-222, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: The resulting sort of relevant cases can be shown in a so-called claim lattice. (See Figure 2 for an example.) Cases just below the root are the mopc's. We use the INQUERY retrieval engine as our IR component. INQUERY uses an inference network model <ref> [ Turtle and Croft, 1991 ] </ref> , specifically, a Bayesian probabilistic inference net. It uses a directed acyclic graph with a query node at the root, document nodes at the leaves, and a layer of query concept nodes and a layer of content representation nodes in between.
Reference: [ Turtle, 1994 ] <author> Howard Turtle. </author> <title> Natural Language vs. Boolean Query Evaluation: A Comparison of Retrieval Performance. </title> <booktitle> In Proceedings of the 17th Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp 212-220, </pages> <address> Dublin, Ireland, </address> <month> July </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: The HOD-corpus contains cases addressing a great many legal questions. It was built by adding approximately 200 cases to another already existing, nearly 12,000 document collection, called the West or FSupp collection [ Haines and Croft, 1993 ] , <ref> [ Turtle, 1994 ] </ref> . The additional texts are for cases contained in the CABARET CKB and cases found when the query home office was posed to the on-line WestLaw Federal Taxation Case Law database. We restricted the query to cases decided between January 1986 and November 1993.
Reference: [ Veloso, 1992 ] <author> Manuela M. Veloso. </author> <title> Learning by Analogical Reasoning in General Problem Solving. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: large numbers of cases have used fairly simple case representations (e.g., MBRtalk [ Stanfill and Waltz, 1986 ] , PACE [ Creecy et al., 1992 ] , JOHNNY [ Stanfill, 1988 ] , Anapron [ Golding and Rosenbloom, 1991 ] ) or have used representations easily derived from solved problems <ref> [ Veloso, 1992 ] </ref> . In a very few situations, large case bases have been constructed through a combination of case acquisition as a side-effect of customer service and follow-up knowledge engineering by a team specifically tasked with creating a case base [ Shimazu et al., 1993 ] .
References-found: 19

