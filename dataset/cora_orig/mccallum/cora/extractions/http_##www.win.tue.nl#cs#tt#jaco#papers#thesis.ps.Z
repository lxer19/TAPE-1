URL: http://www.win.tue.nl/cs/tt/jaco/papers/thesis.ps.Z
Refering-URL: http://www.win.tue.nl/cs/tt/jaco/papers/
Root-URL: http://www.win.tue.nl
Title: Termination of Higher-order Rewrite Systems  Met literatuur opgave. Met samenvatting in het Nederlands.  
Author: Pol, Jan Cornelis van de /Jan Cornelis van de Pol 
Address: Wijsbegeerte.  
Affiliation: Utrecht: Universiteit Utrecht, Faculteit  Proefschrift Universiteit Utrecht.  
Note: c 1996, Jaco van de Pol. All rights reserved.  (Quaestiones infinitae, ISSN 0927-3395; volume 16)  ISBN 90-393-1357-1  
Abstract-found: 0
Intro-found: 1
Reference: [AB91] <author> G.J. Akkerman and J.C.M. Baeten. </author> <title> Term rewriting analysis in process algebra. </title> <type> Technical Report CS-R9130, </type> <institution> CWI, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: We only concentrate on the fragment with non-deterministic choice (+), sequential composition ( ), deadlock (ffi) and the data dependent choice () from CRL. The Process Algebra part can be formulated in a first order Term Rewriting System (see for instance <ref> [AB91] </ref>). The rules for the Sum-operator require higher-order rewrite rules to deal with the bound variables. A similar formulation of CRL can be found in [Sel94]. There are two base types: fProc; Datag. <p> The function symbols are interpreted in the following way: [[+]] = a:b:a + b + 1 [[ffi]] = 1 P In the right hand sides of these equations, denotes multiplication and + denotes addition on natural numbers. This is an extension of the interpretation in <ref> [AB91] </ref> for the Process Algebra part of the system. The first three functions are strictly monotonic in N 1 , hence strict.
Reference: [Acz78] <author> P. Aczel. </author> <title> A general Church-Rosser theorem. </title> <type> Technical report, </type> <institution> University of Manchester, </institution> <month> July </month> <year> 1978. </year>
Reference-contexts: In 1980 Klop introduced combinatory reduction systems (CRS) [Klo80, KOR93]. This is the first systematic study of TRSs with bound variables (lambda calculus with particular extensions had already been studied before; Aczel <ref> [Acz78] </ref> already considered general extensions of lambda calculus). In combinatory reduction systems, untyped lambda calculus is used as substitution calculus. Instead of reduction to normal form (which is impossible in untyped lambda calculus) developments are used. The left hand sides of the rules are restricted to patterns.
Reference: [AGM92] <editor> S. Abramsky, D.M. Gabbay, and T.S.E. Maibaum, editors. </editor> <booktitle> Handbook of Logic in Computer Science, volume II. </booktitle> <publisher> Oxford University Press, </publisher> <year> 1992. </year>
Reference: [AGM94] <editor> D.J. Andrews, J.F. Groote, and C.A. Middelburg, editors. </editor> <booktitle> Proceedings of the International Workshop on Semantics of Specification Languages, </booktitle> <address> Utrecht, The Netherlands, </address> <year> 1993, </year> <title> Workshops in Computing. </title> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: [Aka93] <author> Y. Akama. </author> <title> On Mints' reduction for ccc-calculus. </title> <booktitle> In Bezem and Groote [BG93], </booktitle> <pages> pages 1-12. </pages>
Reference-contexts: With ! fij we denote the ARS (fl ! ; ! fij ). Proposition 2.4.5 ! fij is strongly normalizing and confluent. Proofs of this fact can be found in <ref> [CK94, Aka93, Dou93] </ref>. Therefore, each lambda term has a unique fij-normal form, which is denoted by M # fij .
Reference: [Bak92] <author> S. van Bakel. </author> <title> Complete restrictions of the intersection type discipline. </title> <journal> Theoretical Computer Science, </journal> <volume> 102(1) </volume> <pages> 135-163, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: THE SYSTEMS not. Stronger typing systems have been studied, that capture more and more strongly normalizing terms, most notably System F (capturing second order polymorphism) [Gir72], System F ! (featured by unlimited polymorphism) and " (incorporating intersection types). In the latter system, strong normalization and typability coincide <ref> [Bak92] </ref>. Of course, in this system it is undecidable whether a term is typable or not. Long normal forms. At first sight, the most reasonable direction of the equation schema (j) is from left to right, for only in that direction the terms get smaller.
Reference: [Bar84] <author> H.P. Barendregt. </author> <title> The Lambda Calculus. Its Syntax and Semantics. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <note> second, revised edition, </note> <year> 1984. </year>
Reference-contexts: Section 2.4.1 is on the static part: terms, types and a lot of terminology. In Section 2.4.2 we will introduce the rewrite relations. Simply-typed lambda calculus was introduced by Church in [Chu40]. For general notions and notation in lambda calculus, see <ref> [Bar84] </ref>. For an overview of typed lambda calculi the reader is referred to [Bar92]. 2.4.1 Terms and Types In fact we should speak about simply-typed lambda calculi. We allow several parameters to vary, namely the base types, the constants and the variables that are used. <p> In a computer program, or in formalized proofs, one cannot escape from renaming the variables explicitly. To make the choice of variable names systematic, De Bruijn indices (i.e. numbers referring to the binders) can be used instead of named variables [Bru72]. See <ref> [Bar84, p. 26] </ref>, where a more severe variable convention is introduced. Restricted classes of terms. A subclass of lambda terms, the so called I-terms, is obtained by restricting the formation of x:M to the case that x 2 FV (M ). We denote this class by fl ! -I. <p> Confluence does not depend on typing information. The untyped lambda calculus is already confluent. Proofs of this fact are due to Church and Rosser (in fact this proof is in the setting of the untyped I-calculus), and Martin-Lof and Tait. The proofs can be found in e.g. <ref> [Bar84] </ref>. Theorem 2.4.2 ! fi is weakly normalizing. By the previous theorems, every simply-typed lambda term has a unique fi-normal form. It is not difficult to characterize this normal form.
Reference: [Bar92] <author> H.P. Barendregt. </author> <title> Lambda calculi with types. </title> <editor> In Abramsky et al. </editor> <booktitle> [AGM92], </booktitle> <pages> pages 117-310. </pages>
Reference-contexts: In Section 2.4.2 we will introduce the rewrite relations. Simply-typed lambda calculus was introduced by Church in [Chu40]. For general notions and notation in lambda calculus, see [Bar84]. For an overview of typed lambda calculi the reader is referred to <ref> [Bar92] </ref>. 2.4.1 Terms and Types In fact we should speak about simply-typed lambda calculi. We allow several parameters to vary, namely the base types, the constants and the variables that are used. This information is stored in a signature. 2.4. SIMPLY-TYPED LAMBDA CALCULUS 17 Types.
Reference: [Ber93] <author> U. Berger. </author> <title> Program extraction from normalization proofs. </title> <booktitle> In Bezem and Groote [BG93], </booktitle> <pages> pages 91-106. </pages>
Reference-contexts: Remarkably, this program equals (more or less) the functional [[LM fl ]] ff L , assigned to M in the proof a la Gandy. The idea of using a realizability interpretation to extract functionals from Tait's SN-proof already occurs in <ref> [Ber93] </ref>. In that paper, a program to compute the normal form of a term is extracted. Our contribution is, that by extracting numerical upper bounds for the length of reduction sequences, a comparison with Gandy's proof can be made. <p> To this end we use modified realizability, introduced by Kreisel [Kre59]. In [Tro73, x 3.4] modified realizability is presented as a translation of HA ! into itself. This interpretation eliminates existential quantifiers, at the cost of introducing functions of finite type (functionals), represented by -terms. Following Berger <ref> [Ber93] </ref>, we present modified realizability as an interpretation of a first order fragment (MF) into a higher-order, negative (i.e. 9-free) fragment (NH). <p> (d)t ep (d 8x :'(x) t ) := ep (d) ep (9 [d; y; u '(y) ; e ]) := ep (e)[y := s][~x u := ~ t ]; where s; ~ t = ep (d 9x :'(x) ) The whole enterprise is justified by the following Theorem 6.2.4 (Correctness <ref> [Ber93] </ref>) If d is an MF derivation of ', then there exists an NH derivation (d) of ep (d) mr '. Moreover, the only free assumptions in (d) are of the form ~x u mr , for some assumption u occurring in d already. <p> We only deal with three cases, see e.g. <ref> [Ber93] </ref> for the other cases: ! + : By the induction hypothesis, (d) : ep (d) mr . <p> Induction is needed to deal with Godel's T in Section 6.4. This is well known theory, apart from the axioms under (2), which explore the special nature of the 8-quantifier. Axioms as under (1) are exploited in <ref> [Ber93] </ref>. Case (3) and (4) can be found in [Tro73]. 6.2.3.1 9-free Axioms and Harrop Formulae Consider a 9-free MF formula '. We have o (') = *, so the only potential realizer is the empty sequence. Let ' 0 be the formula obtained from ' by deleting all underlinings.
Reference: [Bez86] <author> M.A. Bezem. </author> <title> Bar Recursion and Functionals of Finite Type. </title> <type> PhD thesis, </type> <institution> Utrecht University, </institution> <month> October </month> <year> 1986. </year>
Reference-contexts: The only difference with the hereditarily monotonic functionals defined in Section 3.3 is that is used on base types instead of &gt; . This results in the fact that constant functions are weakly monotonic, although they are not hereditarily monotonic. Another related notion is strong majorization <ref> [Bez86] </ref>. The (highly) recursive clause for the latter notion is: f majorizes g if and only if for all x; y that can be majorized, if x majorizes y then f (x) majorizes both f (y) and g (y). <p> Another challenge would be to give a semantical termination proof for the system of Bar Recursion (see <ref> [Bez86] </ref> for a termination proof using compact sets of terms). 96 CHAPTER 5. TERMINATION OF HRSs Chapter 6 Computability versus Functionals of Finite Type In this chapter, we compare the semantic termination proofs, with the traditional strong-normalization proofs, that use strong computability predicates.
Reference: [BFG94] <author> F. Barbanera, M. Fernandez, and H. </author> <title> Geuvers. Modularity of strong normalization and confluence in the algebraic--cube. </title> <booktitle> In Proceedings of the Ninth Annual IEEE Symposium on Logic in Computer Science, Paris, France, </booktitle> <pages> pages 406-415, </pages> <note> juli 1994. To appear in the Journal of Functional Programming. 133 134 BIBLIOGRAPHY </note>
Reference-contexts: The reduction relation is much simpler, because matching is not done modulo a theory, but it is just a syntactic matter. In [JO91] this is extended to higher-order rules of a certain format. Also higher type systems can be used, e.g. in <ref> [BFG94] </ref> the combination of the Calculus of Constructions with a set of higher-order rewrite rules is studied. In the approach using lambda calculus as substitution calculus it is possible to formulate beta-reduction on the rewrite level. <p> See Theorem 5.2.6 for an alternative proof. In [BG90] this result is extended to the polymorphic lambda calculus. In [JO91] a kind of primitive recursive format for higher-order rules is given, which combined with polymorphic lambda calculus guarantees termination. This is extended by <ref> [BFG94] </ref> to the calculus of constructions. In all these cases, the proofs are based on strong computability arguments, so essentially a method from the lambda calculus is used. 46 CHAPTER 3.
Reference: [BG90] <author> V. Breazu-Tannen and J. Gallier. </author> <title> Polymorphic rewriting conserves algebraic strong normalization. </title> <journal> Theoretical Computer Science, </journal> <volume> 83 </volume> <pages> 3-28, </pages> <year> 1990. </year>
Reference-contexts: Finally, we mention some work on termination for the direct combination of lambda calculus with rewrite rules. In [Bre88] it is proved that the combination of a terminating TRS with the simply-typed lambda calculus is still terminating. See Theorem 5.2.6 for an alternative proof. In <ref> [BG90] </ref> this result is extended to the polymorphic lambda calculus. In [JO91] a kind of primitive recursive format for higher-order rules is given, which combined with polymorphic lambda calculus guarantees termination. This is extended by [BFG94] to the calculus of constructions.
Reference: [BG93] <editor> M. Bezem and J.F. Groote, editors. </editor> <booktitle> Proceedings of the First International Conference on Typed Lambda Calculi and Applications, Utrecht, The Netherlands, volume 664 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1993. </year>
Reference: [BK84] <author> J.A. Bergstra and J.W. Klop. </author> <title> The algebra of recursively defined processes and the algebra of regular processes. </title> <booktitle> In Proceedings of the 11 th ICALP, Antwerpen, volume 172 of Lecture Notes in Computer Science, </booktitle> <pages> pages 82-95. </pages> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: Moreover, rules for permutative conversions have to be added to find nice normal forms. In Section 5.5 we show that permutative conversions for existential quantifiers can be dealt with. 5.1.2.3 Process Algebra with Data The final second-order application comes from process algebra <ref> [BK84] </ref>, or better CRL, which extends process algebra with abstract data types [GP90, GP94]. We only concentrate on the fragment with non-deterministic choice (+), sequential composition ( ), deadlock (ffi) and the data dependent choice () from CRL.
Reference: [Bre88] <author> V. Breazu-Tannen. </author> <title> Combining algebra and higher-order types. </title> <booktitle> In Proceedings of the Third Annual IEEE Symposium on Logic in Computer Science, </booktitle> <address> Edinburgh, Scotland, </address> <pages> pages 82-90, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: HORSs parametrize over the substitution calculus that is used. Our HRSs, fi-HRSs and the HRSs based on fi fi are instances of Van Oostrom's HORSs. Quite another approach can be found in <ref> [Bre88, Dou92] </ref>, where the typed lambda calculus is not used as a substitution calculus. Instead of this, a first-order TRS is combined with the fi-reduction from the simply-typed, or even polymorphic lambda calculus. Each reduction step is either a TRS-step (performed on lambda-terms) or a fi-reduction step. <p> Their methods are restricted to second-order HRSs, with patterns in the left hand sides of the rules. Very recently, [JR96] defined a recursive path order on arbitrary fij-normal forms. Finally, we mention some work on termination for the direct combination of lambda calculus with rewrite rules. In <ref> [Bre88] </ref> it is proved that the combination of a terminating TRS with the simply-typed lambda calculus is still terminating. See Theorem 5.2.6 for an alternative proof. In [BG90] this result is extended to the polymorphic lambda calculus. <p> Following e.g. <ref> [Bre88, Dou92, JO91] </ref>, it is also possible to add fi-reduction as an ordinary rewrite rule. Given a set of rewrite rules, the reduction relation is then obtained by closing the rules under the fi-rule, substitution and context. <p> The one step rewrite relation is easier to compute, because it is not generated modulo a theory. 80 CHAPTER 5. TERMINATION OF HRSs First-order rules. A particular situation arises when the rewrite rules form a (first-order) TRS. It is proved in <ref> [Bre88] </ref>, that if the TRS R is terminating, then the combination R [ fi terminates too. A similar modularity result holds for confluence. The preservation of termination is a non-trivial modularity result. We have no restrictions on the TRS, so in particular it can have duplicating and collapsing rules. <p> Also fi-reduction may duplicate and collapse arguments. Hence the situation seems quite bad in view of Toyama's example, given in Section 3.1.2. The combination is even not completely disjoint, because both components share the same application symbols. The proof in <ref> [Bre88] </ref> is based on the SN-proof for simply-typed lambda calculus that uses computability predicates. We will give an alternative proof of this fact. Our proof is more or less a corollary of the semantical proof of termination of simply-typed lambda calculus.
Reference: [Bru72] <author> N.G. de Bruijn. </author> <title> Lambda calculus notation with nameless dummies, a tool for automatic formula manipulation, with application to the Church-Rosser theorem. </title> <journal> Indagationes Math., </journal> <volume> 34 </volume> <pages> 381-392, </pages> <year> 1972. </year>
Reference-contexts: In a computer program, or in formalized proofs, one cannot escape from renaming the variables explicitly. To make the choice of variable names systematic, De Bruijn indices (i.e. numbers referring to the binders) can be used instead of named variables <ref> [Bru72] </ref>. See [Bar84, p. 26], where a more severe variable convention is introduced. Restricted classes of terms. A subclass of lambda terms, the so called I-terms, is obtained by restricting the formation of x:M to the case that x 2 FV (M ).
Reference: [CFC58] <author> H.B. Curry, R. Feys, and W. Craig. </author> <booktitle> Combinatory Logic, </booktitle> <volume> volume 1. </volume> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1958. </year> <note> Second printing 1968. </note>
Reference-contexts: The claim is, that objects of such languages (programs, formulae, proofs) can be faithfully represented by lambda terms containing (higher-order) constants. This point of view is not new at all. In <ref> [CFC58, p. 85] </ref> e.g. the following is stated (and proved): "Any binding operation can in principle be defined in terms of functional abstraction and an ordinary operation". The modern slogan for this attempt is "higher-order syntax".
Reference: [Chu40] <author> A. Church. </author> <title> A formulation of the simple theory of types. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 5 </volume> <pages> 56-68, </pages> <year> 1940. </year>
Reference-contexts: We will introduce two reduction relations on terms, ! fi and ! fij . Section 2.4.1 is on the static part: terms, types and a lot of terminology. In Section 2.4.2 we will introduce the rewrite relations. Simply-typed lambda calculus was introduced by Church in <ref> [Chu40] </ref>. For general notions and notation in lambda calculus, see [Bar84]. For an overview of typed lambda calculi the reader is referred to [Bar92]. 2.4.1 Terms and Types In fact we should speak about simply-typed lambda calculi.
Reference: [CK94] <author> R. Di Cosmo and D. Kesner. </author> <title> Simulating expansions without expansions. </title> <booktitle> Mathematical Structures in Computer Science, </booktitle> <volume> 4 </volume> <pages> 315-362, </pages> <year> 1994. </year>
Reference-contexts: With ! fij we denote the ARS (fl ! ; ! fij ). Proposition 2.4.5 ! fij is strongly normalizing and confluent. Proofs of this fact can be found in <ref> [CK94, Aka93, Dou93] </ref>. Therefore, each lambda term has a unique fij-normal form, which is denoted by M # fij .
Reference: [CR36] <author> A. Church and J.B. Rosser. </author> <title> Some properties of conversion. </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> 39 </volume> <pages> 472-482, </pages> <year> 1936. </year>
Reference-contexts: For this reason, ! fi is the prototype to study parameter passing in functional languages. The system ! fi has been studied extensively. As a reduction system, it has many nice properties. We only list a few of them. Theorem 2.4.1 <ref> [CR36] </ref> ! fi is confluent. Confluence does not depend on typing information. The untyped lambda calculus is already confluent. Proofs of this fact are due to Church and Rosser (in fact this proof is in the setting of the untyped I-calculus), and Martin-Lof and Tait.
Reference: [Der82] <author> N. Dershowitz. </author> <title> Orderings for term-rewriting systems. </title> <journal> Theoretical Computer Science, </journal> <volume> 17(3) </volume> <pages> 279-301, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: Therefore any method to prove termination is bound to be a semi-procedure. It is either limited to a subclass of TRSs, or the method itself cannot be automated. Semi-decision procedures of the former kind are various forms of lexicographic and recursive path orders, see e.g. <ref> [Der82, Der87] </ref>. The approach using monotone algebras is an example of a method that cannot be automated itself, as it is complete. Such methods only give heuristics how to tackle termination proofs. Various combinations of these two approaches have been proposed, e.g. [KL80, Ges94, Zan95].
Reference: [Der87] <author> N. Dershowitz. </author> <title> Termination of rewriting. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 3(1) </volume> <pages> 69-116, </pages> <year> 1987. </year> <journal> Corrigendum: </journal> <volume> 4 (3): </volume> <pages> 409-410. </pages>
Reference-contexts: Therefore any method to prove termination is bound to be a semi-procedure. It is either limited to a subclass of TRSs, or the method itself cannot be automated. Semi-decision procedures of the former kind are various forms of lexicographic and recursive path orders, see e.g. <ref> [Der82, Der87] </ref>. The approach using monotone algebras is an example of a method that cannot be automated itself, as it is complete. Such methods only give heuristics how to tackle termination proofs. Various combinations of these two approaches have been proposed, e.g. [KL80, Ges94, Zan95].
Reference: [DJ90] <author> N. Dershowitz and J.-P. Jouannaud. </author> <title> Rewrite systems. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B, chapter 6, </booktitle> <pages> pages 243-320. </pages> <publisher> Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: First order term rewriting can be seen as the proof theory that comes with equational logic. Alternatively, it can be seen as the operational semantics of abstract data types. The study of TRSs yields a lot of insights in functional programming languages. Standard texts on term rewriting are <ref> [HO80, DJ90, Klo92] </ref>. Definition of TRSs. A first-order signature is a tuple (F; V), where F is the set of function symbols and V is a set of variables. It is assumed that F " V = ?.
Reference: [Dou92] <author> D.J. Dougherty. </author> <title> Adding algebraic rewriting to the untyped lambda calculus. </title> <journal> Information and Computation, </journal> <volume> 101 </volume> <pages> 251-267, </pages> <year> 1992. </year>
Reference-contexts: HORSs parametrize over the substitution calculus that is used. Our HRSs, fi-HRSs and the HRSs based on fi fi are instances of Van Oostrom's HORSs. Quite another approach can be found in <ref> [Bre88, Dou92] </ref>, where the typed lambda calculus is not used as a substitution calculus. Instead of this, a first-order TRS is combined with the fi-reduction from the simply-typed, or even polymorphic lambda calculus. Each reduction step is either a TRS-step (performed on lambda-terms) or a fi-reduction step. <p> Following e.g. <ref> [Bre88, Dou92, JO91] </ref>, it is also possible to add fi-reduction as an ordinary rewrite rule. Given a set of rewrite rules, the reduction relation is then obtained by closing the rules under the fi-rule, substitution and context.
Reference: [Dou93] <author> D.J. Dougherty. </author> <title> Some lambda calculi with categorical sums and products. </title> <booktitle> In Kirchner [Kir93], </booktitle> <pages> pages 137-151. BIBLIOGRAPHY 135 </pages>
Reference-contexts: With ! fij we denote the ARS (fl ! ; ! fij ). Proposition 2.4.5 ! fij is strongly normalizing and confluent. Proofs of this fact can be found in <ref> [CK94, Aka93, Dou93] </ref>. Therefore, each lambda term has a unique fij-normal form, which is denoted by M # fij .
Reference: [Fer95] <author> M.C.F. Ferreira. </author> <title> Termination of Term Rewriting. </title> <type> PhD thesis, </type> <institution> Univer-siteit Utrecht, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: need at least three values 0 + 0 &lt; 0 + 1 &lt; 1 + 1.) Requiring strictly monotonic functions implies that the sets (I ) all have the same order type, which must be a power of !, i.e. ! fl for some ordinal fl (for the latter see <ref> [Fer95, Thm. 5.25] </ref>). In the rest of this section, we work in a fixed ordered domain of the form ((I ; &gt; ; 0 ) 2B ; (+ ; ) ;2B ), unless stated otherwise. <p> For (1) we will often choose the ordered domain (N; &gt;; 0; +). It is well-known that even for first-order term rewriting this is not enough. There exist terminating TRSs for which a non-total order is necessary. See <ref> [Zan94, Fer95] </ref> for a hierarchy of underlying partial orders. There is no general recipe how to find a suitable strict interpretation (2). There are two starting points. The first starting point is the standard interpretation of the rewrite system as an equational theory, which yields a model.
Reference: [Gan80] <author> R.O. </author> <title> Gandy. Proofs of strong normalization. </title> <editor> In J.R. Hindley and J.P. Seldin, editors, </editor> <booktitle> To H.B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism, </booktitle> <pages> pages 457-477. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1980. </year>
Reference-contexts: Finally, Theorem 2.4.4 ! fi is strongly normalizing. There are many proofs of the last fact <ref> [Gan80, Tai67, Tro73] </ref>. We will present Gandy's proof in Section 3.3. Tait's proof is presented in Section 6.1. Chapter 6 is devoted to the comparison of these two proofs. Normalization essentially relies on typing information. In the untyped lambda calculus, WN does not hold. <p> In Section 3.2 we show the standard model of functionals of finite type for the simply-typed lambda calculus and we show in Section 3.3 how a subset of them, the hereditarily monotonic functionals can be used to prove termination of this calculus <ref> [Gan80] </ref>. Finally, in Section 3.4, we investigate how similar techniques can be used for termination proofs of higher-order term rewriting systems. The latter section also contains a short overview of other approaches to termination proofs of higher-order rewrite systems. <p> Our proposal to prove termination of HRSs (Chapter 4, 5) can be seen as a modification of these concepts. We will only give definitions, statements and some proof sketches to illustrate certain points. For detailed proofs and extensions to other systems, we refer to <ref> [Gan80] </ref>. For simplicity we assume that there is only one base type, called o. Furthermore, we assume that there exist constants 0 : o, Succ : o ! o and + : o ! o ! o. <p> Hence we may apply Lemma 3.3.2.(2), which yields C [M ] = fi C [(~xM )~x] wm &gt; C [(~xN )~x] = fi C [N ] : 42 CHAPTER 3. SEMANTICS FOR TERMINATION PROOFS The proof is somewhat simpler than the corresponding one in <ref> [Gan80, 1.4] </ref>. Note that the corollary heavily depends on the restriction to I-terms. Such terms denote hereditarily monotonic functionals, so they preserve the order in the desired way. <p> This work is preceded by [Ned73] and succeded by [Sor96]. As far as we know, [Pol94] provides the first method to prove termination of arbitrary HRSs, by using a semantical approach. This work is based on similar work for TRSs [Zan94] and for simply-typed lambda calculus <ref> [Gan80] </ref>. Kahrs [Kah95] shows that it is possible to use the hereditarily monotonic function-als in termination proofs for HRSs. He avoids constant functions by systematically 3.4. TOWARDS TERMINATION OF HRSs 45 translating lambda terms to I-terms (using the translation M fl ). <p> So the higher-order monotone algebra indicated above is a termination model. By Theorem 5.1.4, the system for the "surjective disjoint union" is terminating. To get full disjunction, we have to add a union operator as type forming constructor, and we have to add case distinctions for arbitrary types. See <ref> [Gan80, Kah95] </ref> for a semantical termination proof of the resulting system. Moreover, rules for permutative conversions have to be added to find nice normal forms. <p> These reductions are divided in proper reductions and permutative conversions. Strong normalization is then proved via a refined notion of strong computability, called strong validity (see the Appendix for a reproduction of this proof). In <ref> [Gan80] </ref> also examples taken from proof theory occur. There a normalization proof is given via hereditarily monotonic functionals, but the permutative conversions are not dealt with. Girard gives another adaptation of Gandy's approach, which can be extended to the full calculus, including permutative conversions (see [Gir87, Exc. 2.C.10]). <p> Disjunction is not included, to avoid that we have to extend the previous theory with coproduct types. This extension is possible (actually <ref> [Gan80, Kah95] </ref> treat coproduct types), but not necessary for our purpose, namely to show that the seman-tical proof method can deal with permutative conversions. Also negation is absent, so we work in minimal logic, where negation plays no special role (? may be present as 0-ary function symbol). <p> Extensions of the method. The method for proving termination can be extended in various directions. First, the underlying theory can be extended to other type disciplines. Secondly, we can try more complex examples. We already noted that coproduct types can be treated. In <ref> [Gan80, Kah95] </ref> this is worked out in the setting of the hereditarily monotonic functionals. We don't see a problem in adapting that work to the setting of our strict functionals, so this should be a routine extension. <p> For the moment we are interested in simply-typed lambda calculus and Godel's T, a system with higher-order primitive recursion; therefore we can stick to Troelstra's variation on Tait's predicates. We will compare this with the method to prove strong normalization by using functionals of finite type, invented by Gandy <ref> [Gan80] </ref> and discussed in Section 3.3. In this method, to each typed term a functional of the same type is associated. This functional is measured by a natural number. <p> In Chapter 5 of this thesis we showed how to generalize the semantical method to higher-order rewrite systems [Pol94] and in Section 5.5, how to prove termination of the permutative conversions with the extended theory [PS95]. In the literature, these two methods are often put in contrast (e.g. <ref> [Gan80, x 6.3] </ref> 97 98 CHAPTER 6. COMPUTABILITY VERSUS FUNCTIONALS and [GLT89, x 4.4]). Using functionals seems to be more transparent and economizes on proof theoretical complexity; strong computability should generalize to more complex systems. <p> As extracted program, we get ep ( M ) : nat, 6.3.3 Comparison with Gandy's Proof In order to compare the extracted programs from the formalized proofs with the strictly monotonic functionals used by Gandy <ref> [Gan80] </ref>, we recapitulate these programs and introduce a readable notation for them. <p> This expression can be compared with the functionals in the proof of Gandy. First of all, the ingredients are the same. In <ref> [Gan80] </ref> a functional (L, see Section 3.3.2) is defined, that plays the role of both S 0 and M (and indeed, S oe!nat 0 = M oe ). S is a special strictly monotonic functional and M serves as a measure on function-als. <p> In our proof Konig's Lemma is avoided by having a binary SN-predicate, which gives an upper bound on the numerical value. 122 CHAPTER 6. COMPUTABILITY VERSUS FUNCTIONALS 6.4.4 Comparison with Gandy's Functionals We compare the results of the program extraction, with the functionals given in <ref> [Gan80, PS95] </ref> and Section 5.3. First, we present the extracted programs in a more readable fashion. Note that the programs contain the primitive recursor R oe , because Lemma 6.4.7 contains induction on a formula ' with o (') = oe. <p> CONCLUSION 123 6.5 Conclusion With two case studies we showed, that modified realizability is a useful tool to reveal the similarity between SN-proofs using strong computability and SN-proofs using strictly monotonic functionals. The extra effort for Godel's T has paid off, because we found sharper upper bounds than in <ref> [Gan80, PS95] </ref>. Moreover, the new upper bound puts a bound on the sum of the length and the numerical value of each reduction sequence. This information helps to improve the proof that uses strictly monotonic functionals (Section 5.3). We think that our method can be applied more often. <p> This object is mapped to an upper bound by the proof that SC implies SN. The realizability interpretation follows the type system closely. To deal with Godel's T, induction was added. In the same way, conjunction and disjunction can be added to deal with products and coproducts (see also <ref> [Gan80] </ref>). Recently, Loader [Loa95] extended Gandy's proof to System F. As he points out, Girard's SN proof for System F (using reducibility candidates, see e.g. [GLT89]) can be decorated, after which modified realizability yields the same upper bound expressions.
Reference: [Ges94] <author> A. Geser. </author> <title> An improved general path order. </title> <type> Technical Report MIP-9407, </type> <institution> Fakultat fur Mathematik und Informatik, Universitat Passau, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: The approach using monotone algebras is an example of a method that cannot be automated itself, as it is complete. Such methods only give heuristics how to tackle termination proofs. Various combinations of these two approaches have been proposed, e.g. <ref> [KL80, Ges94, Zan95] </ref>. Another indication that termination is a difficult problem is that termination is not a modular property. This means that there are terminating TRSs, with disjoint sets of function symbols, whose union is not terminating.
Reference: [Gir72] <author> J.-Y. Girard. </author> <title> Interpretation fonctionelle et elimination des coupures dans l'arithmetique d'ordre superieur. </title> <type> PhD thesis, </type> <institution> Universite Paris VII, </institution> <year> 1972. </year>
Reference-contexts: It is undecidable whether an untyped lambda term is strongly normalizing or 22 CHAPTER 2. THE SYSTEMS not. Stronger typing systems have been studied, that capture more and more strongly normalizing terms, most notably System F (capturing second order polymorphism) <ref> [Gir72] </ref>, System F ! (featured by unlimited polymorphism) and " (incorporating intersection types). In the latter system, strong normalization and typability coincide [Bak92]. Of course, in this system it is undecidable whether a term is typable or not. Long normal forms. <p> Troelstra [Tro73] uses similar predicates (now called strong computability) in strong normalization proofs. Prawitz [Pra71] used a variant, to deal with permutative conversions, arising from natural deduction for first order predicate logic (see the Appendix). Gi-rard <ref> [Gir72] </ref> introduced a stronger variant, to deal with the impredicative system F. For the moment we are interested in simply-typed lambda calculus and Godel's T, a system with higher-order primitive recursion; therefore we can stick to Troelstra's variation on Tait's predicates.
Reference: [Gir87] <author> J.-Y. Girard. </author> <title> Proof theory and Logical Complexity, volume I. Studies in Proof Theory. </title> <type> Bibliopolis, </type> <institution> Napoli, </institution> <year> 1987. </year>
Reference-contexts: In [Gan80] also examples taken from proof theory occur. There a normalization proof is given via hereditarily monotonic functionals, but the permutative conversions are not dealt with. Girard gives another adaptation of Gandy's approach, which can be extended to the full calculus, including permutative conversions (see <ref> [Gir87, Exc. 2.C.10] </ref>). Instead of bounding reduction lengths by functionals, Girard uses the 86 CHAPTER 5. TERMINATION OF HRSs length of a specific reduction path, given by a weak normalization theorem for the full calculus. We present a termination proof for the whole calculus, including the permutative conversions.
Reference: [GLT89] <author> J.-Y. Girard, Y. Lafont, and P. Taylor. </author> <title> Proofs and Types, </title> <booktitle> volume 7 of Cambridge tracts in theoretical computer science. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1989. </year>
Reference-contexts: In the literature, these two methods are often put in contrast (e.g. [Gan80, x 6.3] 97 98 CHAPTER 6. COMPUTABILITY VERSUS FUNCTIONALS and <ref> [GLT89, x 4.4] </ref>). Using functionals seems to be more transparent and economizes on proof theoretical complexity; strong computability should generalize to more complex systems. On the other hand, seeing the two proofs one gets the feeling that "somehow, the same thing is going on". <p> In the same way, conjunction and disjunction can be added to deal with products and coproducts (see also [Gan80]). Recently, Loader [Loa95] extended Gandy's proof to System F. As he points out, Girard's SN proof for System F (using reducibility candidates, see e.g. <ref> [GLT89] </ref>) can be decorated, after which modified realizability yields the same upper bound expressions. Another extension could deal with recursion over infinitely branching trees (known as Kleene's O or Zucker's T 1 -trees). A problem arises with the permutative conversions for existential quantifiers in first order logic.
Reference: [GP90] <author> J.F. Groote and A. Ponse. </author> <title> The syntax and semantics of CRL. </title> <type> Technical Report CS-R9076, </type> <institution> CWI, </institution> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: In Section 5.5 we show that permutative conversions for existential quantifiers can be dealt with. 5.1.2.3 Process Algebra with Data The final second-order application comes from process algebra [BK84], or better CRL, which extends process algebra with abstract data types <ref> [GP90, GP94] </ref>. We only concentrate on the fragment with non-deterministic choice (+), sequential composition ( ), deadlock (ffi) and the data dependent choice () from CRL. The Process Algebra part can be formulated in a first order Term Rewriting System (see for instance [AB91]).
Reference: [GP94] <author> J.F. Groote and A. Ponse. </author> <title> Proof theory for CRL: a language for processes with data. </title> <editor> In Andrews et al. </editor> <booktitle> [AGM94], </booktitle> <pages> pages 232-251. </pages>
Reference-contexts: In Section 5.5 we show that permutative conversions for existential quantifiers can be dealt with. 5.1.2.3 Process Algebra with Data The final second-order application comes from process algebra [BK84], or better CRL, which extends process algebra with abstract data types <ref> [GP90, GP94] </ref>. We only concentrate on the fragment with non-deterministic choice (+), sequential composition ( ), deadlock (ffi) and the data dependent choice () from CRL. The Process Algebra part can be formulated in a first order Term Rewriting System (see for instance [AB91]).
Reference: [HL78] <author> G. Huet and D.S. Lankford. </author> <title> On the uniform halting problem for term rewriting systems. </title> <type> Technical Report Rapport Laboria 283, </type> <institution> INRIA, </institution> <year> 1978. </year>
Reference-contexts: Huet and Lankford proved that termination of TRSs with finitely many rules is undecidable <ref> [HL78] </ref>. Therefore any method to prove termination is bound to be a semi-procedure. It is either limited to a subclass of TRSs, or the method itself cannot be automated. Semi-decision procedures of the former kind are various forms of lexicographic and recursive path orders, see e.g. [Der82, Der87].
Reference: [HMMN94] <editor> J. Heering, K. Meinke, B. Moller, and T. Nipkow, editors. </editor> <booktitle> Proceedings of the First International Workshop on Higher-Order Algebra, Logic and Term Rewriting, Amsterdam, The Netherlands, HOA '93, volume 816 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: [HO80] <author> G. Huet and D. Oppen. </author> <title> Equations and rewrite rules a survey. </title> <booktitle> In Formal Language Theory Perspectives and Open Problems, </booktitle> <pages> pages 349-405. </pages> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: First order term rewriting can be seen as the proof theory that comes with equational logic. Alternatively, it can be seen as the operational semantics of abstract data types. The study of TRSs yields a lot of insights in functional programming languages. Standard texts on term rewriting are <ref> [HO80, DJ90, Klo92] </ref>. Definition of TRSs. A first-order signature is a tuple (F; V), where F is the set of function symbols and V is a set of variables. It is assumed that F " V = ?.
Reference: [Hsi95] <editor> J. Hsiang, editor. </editor> <booktitle> Proceedings of the Sixth International Conference on Rewriting Techniques and Applications, Kaiserslautern, Germany, volume 914 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [JO91] <author> J.-P. Jouannaud and M. Okada. </author> <title> Executable higher-order algebraic specification languages. </title> <booktitle> In Proceedings of the Sixth Annual IEEE Symposium on Logic in Computer Science, </booktitle> <address> Amsterdam, The Netherlands, </address> <pages> pages 350-361, </pages> <year> 1991. </year>
Reference-contexts: Each reduction step is either a TRS-step (performed on lambda-terms) or a fi-reduction step. The reduction relation is much simpler, because matching is not done modulo a theory, but it is just a syntactic matter. In <ref> [JO91] </ref> this is extended to higher-order rules of a certain format. Also higher type systems can be used, e.g. in [BFG94] the combination of the Calculus of Constructions with a set of higher-order rewrite rules is studied. <p> In [Bre88] it is proved that the combination of a terminating TRS with the simply-typed lambda calculus is still terminating. See Theorem 5.2.6 for an alternative proof. In [BG90] this result is extended to the polymorphic lambda calculus. In <ref> [JO91] </ref> a kind of primitive recursive format for higher-order rules is given, which combined with polymorphic lambda calculus guarantees termination. This is extended by [BFG94] to the calculus of constructions. <p> Following e.g. <ref> [Bre88, Dou92, JO91] </ref>, it is also possible to add fi-reduction as an ordinary rewrite rule. Given a set of rewrite rules, the reduction relation is then obtained by closing the rules under the fi-rule, substitution and context. <p> By Theorem 5.2.3 it can be extended to a termination model of H Rfi . fi Higher-order rules. What happens when we combine higher-order rules with fi-reduction? In <ref> [JO91] </ref> a kind of primitive recursive format occurs. It is proved there that the rewrite system composed from a set of higher-order rules in this format, combined with an arbitrary terminating TRS and fi-reduction is still terminating. <p> nil) 7! nil (iii) map (f; cons (k; `)) 7! cons (f (k); map (f; `)) (iv) append (append (k; `); m) 7! append (k; append (`; m)) (v) map (f; append (`; k)) 7! append (map (f; `); map (f; k)) (vi) The rules fit in the schema of <ref> [JO91] </ref>, for the rules of append form a terminating TRS and the rules for map are primitive recursive. The rules contain no lambdas, hence we can also apply Theorem 5.2.7.
Reference: [Joa95] <author> Felix Joachimski. </author> <title> Kontrolloperatoren und klassische Logik. </title> <type> Master's thesis, </type> <institution> Mathematisches Institut der Universitat Munchen, </institution> <year> 1995. </year> <note> 136 BIBLIOGRAPHY </note>
Reference-contexts: Remark. In fact, 6.b.(ii) and 6.c.(ii) are superfluous as shown by <ref> [Joa95, p. 99] </ref>. The reason is that these parts can be proved after Lemma 11 has been proved. This not only simplifies the definition, but also the proof of Lemma 12. 9. Lemma Let d 1 ! d 2 and SV (d 1 ). Then SV (d 2 ).
Reference: [JR96] <author> J.-P. Jouannaud and A. Rubio. </author> <title> A recursive path ordering for higher-order terms in j-long fi-normal form. </title> <booktitle> In Proceedings of the Seventh International Conference on Rewriting Techniques and Applications, </booktitle> <address> New Brunswick, NJ, USA, </address> <pages> pages 108-122, </pages> <year> 1996. </year>
Reference-contexts: These approaches have a first-order flavor, because they generalize a method from first-order term rewriting. Their methods are restricted to second-order HRSs, with patterns in the left hand sides of the rules. Very recently, <ref> [JR96] </ref> defined a recursive path order on arbitrary fij-normal forms. Finally, we mention some work on termination for the direct combination of lambda calculus with rewrite rules. In [Bre88] it is proved that the combination of a terminating TRS with the simply-typed lambda calculus is still terminating.
Reference: [Kah95] <author> S. Kahrs. </author> <title> Towards a domain theory for termination proofs. </title> <booktitle> In Hsiang [Hsi95], </booktitle> <pages> pages 241-255. </pages>
Reference-contexts: This work is preceded by [Ned73] and succeded by [Sor96]. As far as we know, [Pol94] provides the first method to prove termination of arbitrary HRSs, by using a semantical approach. This work is based on similar work for TRSs [Zan94] and for simply-typed lambda calculus [Gan80]. Kahrs <ref> [Kah95] </ref> shows that it is possible to use the hereditarily monotonic function-als in termination proofs for HRSs. He avoids constant functions by systematically 3.4. TOWARDS TERMINATION OF HRSs 45 translating lambda terms to I-terms (using the translation M fl ). <p> So the higher-order monotone algebra indicated above is a termination model. By Theorem 5.1.4, the system for the "surjective disjoint union" is terminating. To get full disjunction, we have to add a union operator as type forming constructor, and we have to add case distinctions for arbitrary types. See <ref> [Gan80, Kah95] </ref> for a semantical termination proof of the resulting system. Moreover, rules for permutative conversions have to be added to find nice normal forms. <p> Disjunction is not included, to avoid that we have to extend the previous theory with coproduct types. This extension is possible (actually <ref> [Gan80, Kah95] </ref> treat coproduct types), but not necessary for our purpose, namely to show that the seman-tical proof method can deal with permutative conversions. Also negation is absent, so we work in minimal logic, where negation plays no special role (? may be present as 0-ary function symbol). <p> Extensions of the method. The method for proving termination can be extended in various directions. First, the underlying theory can be extended to other type disciplines. Secondly, we can try more complex examples. We already noted that coproduct types can be treated. In <ref> [Gan80, Kah95] </ref> this is worked out in the setting of the hereditarily monotonic functionals. We don't see a problem in adapting that work to the setting of our strict functionals, so this should be a routine extension.
Reference: [Kah96] <author> S. Kahrs. </author> <title> Termination proofs in an abstract setting. </title> <note> Obtainable via http://www.dcs.ed.ac.uk/generated/home-links/smk/, 1996. </note>
Reference-contexts: As a consequence, testing whether a rule is decreasing involves a syntactical analysis of the applied substitution. His method is tailored to proving termination of extensions of simply-typed lambda calculus, the main example being a calculus with products and co-products. See also <ref> [Kah96] </ref>. Another approach to termination of HRSs can be found in [LS93, Lor94, LP95], where lexicographic path orders have been generalized from the first-order to the higher-order case. These approaches have a first-order flavor, because they generalize a method from first-order term rewriting. <p> By Theorem 5.1.4, H 9 is terminating. 5.6 Incompleteness and Possible Extensions Contrary to Theorem 3.1.3, we have Theorem 5.1.4 only in one direction. The other direction really fails, as illustrated by the following example, which is a simplification of the one occurring in <ref> [Kah96] </ref>. Hence our proof method is not complete. Example.
Reference: [Kir93] <editor> C. Kirchner, editor. </editor> <booktitle> Proceedings of the Fifth International Conference on Rewriting Techniques and Applications, Montreal, Canada, volume 690 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference: [KL80] <author> S. Kamin and J.J. Levy. </author> <title> Two generalizations of the recursive path ordering. </title> <type> Technical report, </type> <institution> University of Illinois, </institution> <year> 1980. </year>
Reference-contexts: The approach using monotone algebras is an example of a method that cannot be automated itself, as it is complete. Such methods only give heuristics how to tackle termination proofs. Various combinations of these two approaches have been proposed, e.g. <ref> [KL80, Ges94, Zan95] </ref>. Another indication that termination is a difficult problem is that termination is not a modular property. This means that there are terminating TRSs, with disjoint sets of function symbols, whose union is not terminating.
Reference: [Klo80] <author> J.W. Klop. </author> <title> Combinatory Reduction Systems. </title> <type> PhD thesis, </type> <address> Rijksuniver-siteit Utrecht, Amsterdam, </address> <year> 1980. </year>
Reference-contexts: There are many different definitions of higher-order (term) rewrit (e)(ing) in recent literature. We only mention a few mile stones. For a historical overview of the several formats and a technical comparison between several of them, see e.g. [OR94, Oos94, Raa96]. In 1980 Klop introduced combinatory reduction systems (CRS) <ref> [Klo80, KOR93] </ref>. This is the first systematic study of TRSs with bound variables (lambda calculus with particular extensions had already been studied before; Aczel [Acz78] already considered general extensions of lambda calculus). In combinatory reduction systems, untyped lambda calculus is used as substitution calculus. <p> Existing work on termination. Confluence for higher-order rewriting systems is rather well-studied. Klop (in the context of combinatory reduction systems), Nipkow and Van Oostrom are mainly concerned with confluence. Some of the main results are that orthogonal CRSs are confluent <ref> [Klo80] </ref>, weakly orthogonal HRSs are confluent [Oos94, Raa96] and a critical pair lemma for HRSs [Nip91]. Remarkably, termination for higher-order rewriting is much less studied. Van Raamsdonk [Raa96] proves that outermost-fair rewriting is a normalizing strategy for orthogonal higher-order term rewriting. <p> Remarkably, termination for higher-order rewriting is much less studied. Van Raamsdonk [Raa96] proves that outermost-fair rewriting is a normalizing strategy for orthogonal higher-order term rewriting. But note that termination (or strong normalization) requires that all reduction sequences end in a normal form. Furthermore, for orthogonal CRSs, Klop <ref> [Klo80] </ref> gives a method to reduce strong normalization to weak normalization, which is often easier to prove. This work is preceded by [Ned73] and succeded by [Sor96]. As far as we know, [Pol94] provides the first method to prove termination of arbitrary HRSs, by using a semantical approach.
Reference: [Klo92] <author> J.W. Klop. </author> <title> Term rewriting systems. </title> <editor> In Abramsky et al. </editor> <booktitle> [AGM92], </booktitle> <pages> pages 1-116. </pages>
Reference-contexts: First order term rewriting can be seen as the proof theory that comes with equational logic. Alternatively, it can be seen as the operational semantics of abstract data types. The study of TRSs yields a lot of insights in functional programming languages. Standard texts on term rewriting are <ref> [HO80, DJ90, Klo92] </ref>. Definition of TRSs. A first-order signature is a tuple (F; V), where F is the set of function symbols and V is a set of variables. It is assumed that F " V = ?.
Reference: [KOR93] <author> J.W. Klop, V. van Oostrom, and F. van Raamsdonk. </author> <title> Combinatory reduction systems, introduction and survey. </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 121(1-2):279-308, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: There are many different definitions of higher-order (term) rewrit (e)(ing) in recent literature. We only mention a few mile stones. For a historical overview of the several formats and a technical comparison between several of them, see e.g. [OR94, Oos94, Raa96]. In 1980 Klop introduced combinatory reduction systems (CRS) <ref> [Klo80, KOR93] </ref>. This is the first systematic study of TRSs with bound variables (lambda calculus with particular extensions had already been studied before; Aczel [Acz78] already considered general extensions of lambda calculus). In combinatory reduction systems, untyped lambda calculus is used as substitution calculus.
Reference: [Kre59] <author> G. Kreisel. </author> <title> Interpretation of analysis by means of constructive functionals of finite types. </title> <editor> In A. Heyting, editor, </editor> <booktitle> Constructivity in Mathematics, </booktitle> <pages> pages 101-128. </pages> <publisher> North-Holland, </publisher> <year> 1959. </year>
Reference-contexts: A REFINEMENT OF REALIZABILITY 101 6.2 A Refinement of Realizability As mentioned before, we want to extract the computational content from the SN-proof of Section 6.1. To this end we use modified realizability, introduced by Kreisel <ref> [Kre59] </ref>. In [Tro73, x 3.4] modified realizability is presented as a translation of HA ! into itself. This interpretation eliminates existential quantifiers, at the cost of introducing functions of finite type (functionals), represented by -terms.
Reference: [Loa95] <author> R. Loader. </author> <title> Normalisation by translation. Note distributed on "types" mailing list. </title> <note> Obtainable via http://sable.ox.ac.uk/~loader/, April 1995. </note>
Reference-contexts: We don't see a problem in adapting that work to the setting of our strict functionals, so this should be a routine extension. We note that Loader uses an adaptation of the semantical proof method in order to prove strong normalization of System F <ref> [Loa95] </ref>. We have not investigated whether this approach can be generalized to arbitrary higher-order rewrite systems with polymorphic types. (Nor is it clear whether such systems would be useful). <p> The realizability interpretation follows the type system closely. To deal with Godel's T, induction was added. In the same way, conjunction and disjunction can be added to deal with products and coproducts (see also [Gan80]). Recently, Loader <ref> [Loa95] </ref> extended Gandy's proof to System F. As he points out, Girard's SN proof for System F (using reducibility candidates, see e.g. [GLT89]) can be decorated, after which modified realizability yields the same upper bound expressions.
Reference: [Lor94] <author> C.A. Loria-Saenz. </author> <title> A Theoretical Framework for Reasoning about Program Construction based on Extensions of Rewrite Systems. </title> <type> PhD thesis, </type> <institution> Fachbereich Informatik der Universitat Kaiserslautern, </institution> <year> 1994. </year>
Reference-contexts: His method is tailored to proving termination of extensions of simply-typed lambda calculus, the main example being a calculus with products and co-products. See also [Kah96]. Another approach to termination of HRSs can be found in <ref> [LS93, Lor94, LP95] </ref>, where lexicographic path orders have been generalized from the first-order to the higher-order case. These approaches have a first-order flavor, because they generalize a method from first-order term rewriting. Their methods are restricted to second-order HRSs, with patterns in the left hand sides of the rules.
Reference: [LP95] <author> O. Lysne and J. Piris. </author> <title> A termination ordering for higher order rewrite systems. </title> <booktitle> In Hsiang [Hsi95], </booktitle> <pages> pages 26-40. </pages>
Reference-contexts: His method is tailored to proving termination of extensions of simply-typed lambda calculus, the main example being a calculus with products and co-products. See also [Kah96]. Another approach to termination of HRSs can be found in <ref> [LS93, Lor94, LP95] </ref>, where lexicographic path orders have been generalized from the first-order to the higher-order case. These approaches have a first-order flavor, because they generalize a method from first-order term rewriting. Their methods are restricted to second-order HRSs, with patterns in the left hand sides of the rules.
Reference: [LS93] <author> C.A. Loria-Saenz and Joachim Steinbach. </author> <title> Termination of combined (rewrite and -calculus) systems. </title> <booktitle> In Rusinowitch and Remy [RR93], </booktitle> <pages> pages 143-147. BIBLIOGRAPHY 137 </pages>
Reference-contexts: His method is tailored to proving termination of extensions of simply-typed lambda calculus, the main example being a calculus with products and co-products. See also [Kah96]. Another approach to termination of HRSs can be found in <ref> [LS93, Lor94, LP95] </ref>, where lexicographic path orders have been generalized from the first-order to the higher-order case. These approaches have a first-order flavor, because they generalize a method from first-order term rewriting. Their methods are restricted to second-order HRSs, with patterns in the left hand sides of the rules.
Reference: [Mid89] <author> A. Middeldorp. </author> <title> A sufficient condition for the termination of the direct sum of term rewriting systems. </title> <booktitle> In Proceedings of the Fourth Annual IEEE Symposium on Logic in Computer Science , Pacific Grove, </booktitle> <pages> pages 396-401, </pages> <year> 1989. </year>
Reference-contexts: FUNCTIONALS OF FINITE TYPE 37 Rusinowitch [Rus87] and Middeldorp <ref> [Mid89] </ref> proved that it is essential for all such counter examples that one of the systems has a duplicating rule, and the other a collapsing rule. In other cases, termination is preserved by the disjoint union.
Reference: [Mil91] <author> D. Miller. </author> <title> A logic programming language with lambda-abstraction, function variables, and simple unification. </title> <editor> In P. Schroeder-Heister, editor, </editor> <booktitle> Extensions of Logic Programming: International Workshop, Tubingen FRG, 1989, volume 475 of Lecture Notes in Computer Science, </booktitle> <pages> pages 253-281. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Now M is a pattern, if all variables y 2 FV (N ) occur in a position yz 1 : : : z n and the z 1 ; : : : ; z n are pairwise distinct free variables. This class is important for higher-order matching <ref> [Mil91] </ref>. 2.4.2 fi- and j-Reduction Equations. So far, we have no calculus yet. We will now introduce two schematic equations, traditionally called fi and j. The fi equality expresses what happens if we apply a term x:M to a term N .
Reference: [MOZ96] <author> A. Middeldorp, H. Ohsaki, and H. Zantema. </author> <title> Transforming termination by self-labelling. </title> <type> Technical Report UU-CS-1996-15, </type> <institution> Utrecht University, </institution> <year> 1996. </year> <note> To appear in CADE-13. </note>
Reference-contexts: Another (incomparable) modularity result is the following: Proposition 3.1.4 Let R = (F; V; R) be a terminating TRS. Then the TRS R 0 = (F ] fgg; V; R ] g (x; y) 7! x) is also terminating. This is a corollary of a more general theorem in <ref> [MOZ96] </ref>. The proof uses semantic self-labeling. Notice that adding the second projection too does not always preserve termination, as is witnessed by Toyama's example above.
Reference: [Ned73] <author> R.P. </author> <title> Nederpelt. Strong Normalization in a Typed Lambda Calculus with Lambda Structured Types. </title> <type> PhD thesis, </type> <institution> Eindhoven Technological University, </institution> <address> The Netherlands, </address> <year> 1973. </year>
Reference-contexts: But note that termination (or strong normalization) requires that all reduction sequences end in a normal form. Furthermore, for orthogonal CRSs, Klop [Klo80] gives a method to reduce strong normalization to weak normalization, which is often easier to prove. This work is preceded by <ref> [Ned73] </ref> and succeded by [Sor96]. As far as we know, [Pol94] provides the first method to prove termination of arbitrary HRSs, by using a semantical approach. This work is based on similar work for TRSs [Zan94] and for simply-typed lambda calculus [Gan80].
Reference: [New42] <author> M.H.A. Newman. </author> <title> On theories with a combinatorial definition of "equivalence". </title> <journal> Annals of Mathematics, </journal> <volume> 43(2) </volume> <pages> 223-243, </pages> <year> 1942. </year>
Reference-contexts: This check can often be automated, especially in case ! is generated by a finite number of rules. We can now give a second reason to be interested in strong normalization: Lemma 2.2.2 <ref> [New42] </ref> If A is SN and WCR, then it is CR. The only properties that we have not yet motivated are the binary SN-predicate and the finite branching. If we know SN (a; n), we have an upper bound on the longest reduction sequence from a.
Reference: [Nip91] <author> T. Nipkow. </author> <title> Higher-order critical pairs. </title> <booktitle> In Proceedings of the Sixth Annual IEEE Symposium on Logic in Computer Science, </booktitle> <address> Amsterdam, The Netherlands, </address> <pages> pages 342-349, </pages> <year> 1991. </year>
Reference-contexts: All other binding mechanisms are formulated via this metalanguage. This guarantees that all binding mechanisms 24 CHAPTER 2. THE SYSTEMS are treated in a uniform way. Hence matters of scope, renaming of local variables, substitution, free parameter provisos etc. have to be dealt with only once. Following <ref> [Nip91, Nip93] </ref>, we will take the simply-typed lambda calculus with fij-reduction as a metalanguage. Following [Oos94, Raa96] we will refer to the metalanguage as the substitution calculus. As a typical example, let us consider finding the prenex normal form of first-order logical formulae. <p> Instead of reduction to normal form (which is impossible in untyped lambda calculus) developments are used. The left hand sides of the rules are restricted to patterns. The systems in this thesis are inspired by and very similar to Nipkow's higher-order rewrite systems <ref> [Nip91, Nip93] </ref>. The main difference is that Nipkow builds in the restriction to patterns. This is however inspired by his work on confluence, and plays a less important role for termination. <p> First, lambda-calculus can be expressed in simple rules, without any side conditions. This enables the study of lambda calculus in a general setting. E.g. results on critical pairs to prove local confluence for HRSs can be directly applied to lambda calculus <ref> [Nip91] </ref>. 2.5. HIGHER-ORDER TERM REWRITING 31 A second advantage is that we can add more rules to this system. This admits a uniform approach for the study of definitional extensions of lambda calculus. <p> Klop (in the context of combinatory reduction systems), Nipkow and Van Oostrom are mainly concerned with confluence. Some of the main results are that orthogonal CRSs are confluent [Klo80], weakly orthogonal HRSs are confluent [Oos94, Raa96] and a critical pair lemma for HRSs <ref> [Nip91] </ref>. Remarkably, termination for higher-order rewriting is much less studied. Van Raamsdonk [Raa96] proves that outermost-fair rewriting is a normalizing strategy for orthogonal higher-order term rewriting. But note that termination (or strong normalization) requires that all reduction sequences end in a normal form. <p> B! ; H U! g. case (inl (X); F; G) 7! F (X) case (inr (Y ); F; G) 7! G (Y ) case (Z; x A :H (inl (x)); y B :H (inr (y))) 7! H (Z) Note that this example does not fit in the framework of Nipkow <ref> [Nip91, p. 347] </ref>, because the left hand side of the last rule is not a pattern (the argument of H is not a bound variable). Termination for this example is less trivial than for the prenex normal form, because there is an application of two free variables.
Reference: [Nip93] <author> T. Nipkow. </author> <title> Orthogonal higher-order rewrite systems are confluent. </title> <booktitle> In Bezem and Groote [BG93], </booktitle> <pages> pages 306-317. </pages>
Reference-contexts: All other binding mechanisms are formulated via this metalanguage. This guarantees that all binding mechanisms 24 CHAPTER 2. THE SYSTEMS are treated in a uniform way. Hence matters of scope, renaming of local variables, substitution, free parameter provisos etc. have to be dealt with only once. Following <ref> [Nip91, Nip93] </ref>, we will take the simply-typed lambda calculus with fij-reduction as a metalanguage. Following [Oos94, Raa96] we will refer to the metalanguage as the substitution calculus. As a typical example, let us consider finding the prenex normal form of first-order logical formulae. <p> Instead of reduction to normal form (which is impossible in untyped lambda calculus) developments are used. The left hand sides of the rules are restricted to patterns. The systems in this thesis are inspired by and very similar to Nipkow's higher-order rewrite systems <ref> [Nip91, Nip93] </ref>. The main difference is that Nipkow builds in the restriction to patterns. This is however inspired by his work on confluence, and plays a less important role for termination.
Reference: [Oos94] <author> V. van Oostrom. </author> <title> Confluence for Abstract and Higher-Order Rewriting. </title> <type> PhD thesis, </type> <institution> Vrije Universiteit, </institution> <address> Amsterdam, </address> <year> 1994. </year>
Reference-contexts: Termination (or strong normalization) is convenient, because in that case we need not care about a reduction strategy: Every reduction eventually leads to a normal form. (A strategy may become important if we also take efficiency into consideration.) Confluence and termination are often difficult to prove. We refer to <ref> [Oos94] </ref> for a recent study on confluence proofs. It is often more easy to prove local confluence. The difference is that for any object, we only have to prove something for its one-step reducts. <p> THE SYSTEMS are treated in a uniform way. Hence matters of scope, renaming of local variables, substitution, free parameter provisos etc. have to be dealt with only once. Following [Nip91, Nip93], we will take the simply-typed lambda calculus with fij-reduction as a metalanguage. Following <ref> [Oos94, Raa96] </ref> we will refer to the metalanguage as the substitution calculus. As a typical example, let us consider finding the prenex normal form of first-order logical formulae. In this normal form, the quantifiers only occur at the outside of the formula. <p> Other approaches. There are many different definitions of higher-order (term) rewrit (e)(ing) in recent literature. We only mention a few mile stones. For a historical overview of the several formats and a technical comparison between several of them, see e.g. <ref> [OR94, Oos94, Raa96] </ref>. In 1980 Klop introduced combinatory reduction systems (CRS) [Klo80, KOR93]. This is the first systematic study of TRSs with bound variables (lambda calculus with particular extensions had already been studied before; Aczel [Acz78] already considered general extensions of lambda calculus). <p> Wolfram requires the rules of base type, and also defines a rewrite step in terms of contexts, substitutions and fij-reduction, but these differences can be seen as presentation matters only. 28 CHAPTER 2. THE SYSTEMS We also mention Van Oostrom <ref> [Oos94] </ref> and Van Raamsdonk [Raa96], who introduced the so called Higher-Order Rewriting Systems (HORS), meant to generalize all existing formalisms. HORSs parametrize over the substitution calculus that is used. Our HRSs, fi-HRSs and the HRSs based on fi fi are instances of Van Oostrom's HORSs. <p> The curried version will be used later in order to add higher-order rules to an arbitrary TRS, e.g. fi-reduction on the rewrite level. The same translation occurs in <ref> [Oos94] </ref>. 2.5.4.3 Untyped lambda calculus Another typical example of HRSs is the untyped lambda calculus, with fi and j-reduction. This HRS has a signature with as only base type o, the type of untyped lambda terms. <p> Existing work on termination. Confluence for higher-order rewriting systems is rather well-studied. Klop (in the context of combinatory reduction systems), Nipkow and Van Oostrom are mainly concerned with confluence. Some of the main results are that orthogonal CRSs are confluent [Klo80], weakly orthogonal HRSs are confluent <ref> [Oos94, Raa96] </ref> and a critical pair lemma for HRSs [Nip91]. Remarkably, termination for higher-order rewriting is much less studied. Van Raamsdonk [Raa96] proves that outermost-fair rewriting is a normalizing strategy for orthogonal higher-order term rewriting.
Reference: [OR94] <author> V. van Oostrom and F. van Raamsdonk. </author> <title> Comparing combinatory reduction systems and higher-order rewrite systems. </title> <editor> In Heering et al. </editor> <booktitle> [HMMN94], </booktitle> <pages> pages 276-304. </pages>
Reference-contexts: Other approaches. There are many different definitions of higher-order (term) rewrit (e)(ing) in recent literature. We only mention a few mile stones. For a historical overview of the several formats and a technical comparison between several of them, see e.g. <ref> [OR94, Oos94, Raa96] </ref>. In 1980 Klop introduced combinatory reduction systems (CRS) [Klo80, KOR93]. This is the first systematic study of TRSs with bound variables (lambda calculus with particular extensions had already been studied before; Aczel [Acz78] already considered general extensions of lambda calculus).
Reference: [Pol94] <author> J.C. van de Pol. </author> <title> Termination proofs for higher-order rewrite systems. </title> <editor> In Heering et al. </editor> <booktitle> [HMMN94], </booktitle> <pages> pages 305-325. </pages>
Reference-contexts: Note that termination, as well as realizability and semantic models play an important role in consistency proofs of logical systems. It is interesting to connect these notions. Whether the connection we found has logical consequences remains open. Most results of this thesis have been published in conference proceedings. In <ref> [Pol94] </ref> a description of the semantical proof method is given. In [PS95] several computation rules are given and the method is applied to larger examples. The former two papers form the basis of Chapter 4 and 5. Chapter 6 is the full version of [Pol96]. <p> Furthermore, for orthogonal CRSs, Klop [Klo80] gives a method to reduce strong normalization to weak normalization, which is often easier to prove. This work is preceded by [Ned73] and succeded by [Sor96]. As far as we know, <ref> [Pol94] </ref> provides the first method to prove termination of arbitrary HRSs, by using a semantical approach. This work is based on similar work for TRSs [Zan94] and for simply-typed lambda calculus [Gan80]. Kahrs [Kah95] shows that it is possible to use the hereditarily monotonic function-als in termination proofs for HRSs. <p> The main motivation for introducing them is that they are useful in termination proofs for higher-order rewrite systems. This chapter is mainly based on <ref> [Pol94, PS95] </ref>. In Section 3.4 we pointed out why the hereditarily monotonic functionals are less suitable for termination proofs. Recall that all I-terms are hereditarily monotonic (Lemma 3.3.2). In order to capture all lambda terms, we introduce the class of weakly monotonic functionals. <p> We present this method in Section 5.1.1. Section 5.1.2 is devoted to some straightforward applications of the proof method. This part is mainly based on <ref> [Pol94] </ref>. We then investigate how the scope of our method can be extended. To this end, we internalize the simply-typed lambda calculus (Section 5.2). With this we mean that its terms and the fi-rule are encoded in an HRS. <p> Gandy deals with simply-typed lambda calculus, Godel's T and with fi-reductions in proof theory including disjunction and existential quantification. However, the permutative conversions for these connectives could not be dealt with. In Chapter 5 of this thesis we showed how to generalize the semantical method to higher-order rewrite systems <ref> [Pol94] </ref> and in Section 5.5, how to prove termination of the permutative conversions with the extended theory [PS95]. In the literature, these two methods are often put in contrast (e.g. [Gan80, x 6.3] 97 98 CHAPTER 6. COMPUTABILITY VERSUS FUNCTIONALS and [GLT89, x 4.4]).
Reference: [Pol96] <author> J.C. van de Pol. </author> <title> Two different strong normalization proofs? Computability versus functionals of finite type. </title> <editor> In G. Dowek, J. Heering, K. Meinke, and B. Moller, editors, </editor> <booktitle> Proceedings of the Second International Workshop on Higher-Order Algebra, Logic and Term Rewriting, Paderborn, Germany, HOA '95, volume 1074 of Lecture Notes in Computer Science, </booktitle> <pages> pages 201-220. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: In [Pol94] a description of the semantical proof method is given. In [PS95] several computation rules are given and the method is applied to larger examples. The former two papers form the basis of Chapter 4 and 5. Chapter 6 is the full version of <ref> [Pol96] </ref>. The modularity results have not been published before. For pointers to related work we refer to Section 2.5.3, Chapter 3 (especially the last section), the introduction to Chapter 6 and the Bibliography. Chapter 2 The Systems This chapter is devoted to the syntactical introduction of several systems. <p> TERMINATION OF HRSs Chapter 6 Computability versus Functionals of Finite Type In this chapter, we compare the semantic termination proofs, with the traditional strong-normalization proofs, that use strong computability predicates. This chapter is a full version of the paper that appeared as <ref> [Pol96] </ref>. The computability method is often attributed to Tait [Tai67], who used convertibility predicates to prove a normal form theorem for various systems. Troelstra [Tro73] uses similar predicates (now called strong computability) in strong normalization proofs.
Reference: [Pra71] <author> D. Prawitz. </author> <title> Ideas and results in proof theory. </title> <editor> In Jens Erik Fenstad, editor, </editor> <booktitle> Proc. of the Second Scandinavian Logic Symposium, </booktitle> <pages> pages 235-307, </pages> <address> Amsterdam, 1971. </address> <publisher> North-Holland. 138 BIBLIOGRAPHY </publisher>
Reference-contexts: This scheme is carried out for simply-typed lambda calculus and Godel's T. Finally, the Appendix contains a reproduction of Prawitz's proof based on a variant of strong computability. We added it because there are a number of connections with our work. Our reproduction is denser than the text in <ref> [Pra71] </ref>. Contribution and Related Work. The major contribution of this thesis is a general method to prove termination of higher-order rewrite systems. Although the method is not complete, it covers a lot of examples, as will be extensively shown. <p> Because the ordered domain is projective and the HRS contains no lambdas, also the combination of surjective pairing with fi-reduction is terminating (Theorem 5.2.7). 5.5 Example: Permutative Conversions in Natural Deduction The next example comes from proof theory in the style of Prawitz. In <ref> [Pra71] </ref> proofs are formalized by natural deduction trees. Several reduction rules on those trees are given, to bring them into a certain normal form. These reductions are divided in proper reductions and permutative conversions. <p> Also negation is absent, so we work in minimal logic, where negation plays no special role (? may be present as 0-ary function symbol). We now introduce derivation terms. They can be seen as linear notations for natural deduction trees (cf. <ref> [Pra71] </ref>), with assumptions labeled by variables. This corresponds to the Curry-Howard isomorphism, but now we add also existential quantification. Metavariables d; e; f range over derivation terms. Simultaneously with derivations, the set of free assumptions in a derivation (denoted FA (d)) is defined. <p> This gives rise to the notion FV (d), the free object variables in d, which can be defined inductively. The following conversion rules are taken from <ref> [Pra71] </ref>. The first five are the proper reductions, the last five are called permutative conversions. These are necessary to 88 CHAPTER 5. <p> This chapter is a full version of the paper that appeared as [Pol96]. The computability method is often attributed to Tait [Tai67], who used convertibility predicates to prove a normal form theorem for various systems. Troelstra [Tro73] uses similar predicates (now called strong computability) in strong normalization proofs. Prawitz <ref> [Pra71] </ref> used a variant, to deal with permutative conversions, arising from natural deduction for first order predicate logic (see the Appendix). Gi-rard [Gir72] introduced a stronger variant, to deal with the impredicative system F. <p> Another extension could deal with recursion over infinitely branching trees (known as Kleene's O or Zucker's T 1 -trees). A problem arises with the permutative conversions for existential quantifiers in first order logic. The semantical proof given in Section 5.5 is based on strict functionals. Prawitz <ref> [Pra71] </ref> gives an SN-proof using strong validity (SV), see the Appendix. But the SV-predicate is defined using a general inductive definition, hence the computational contents of Prawitz's proof is not clear. Consequently, the two SN-proofs cannot be related by our method. 124 CHAPTER 6. <p> But the SV-predicate is defined using a general inductive definition, hence the computational contents of Prawitz's proof is not clear. Consequently, the two SN-proofs cannot be related by our method. 124 CHAPTER 6. COMPUTABILITY VERSUS FUNCTIONALS Appendix A Strong Validity for the Permutative Conversions In <ref> [Pra71] </ref> Prawitz proves strong normalization for a rewrite relation on proof trees of full classical logic. The rewrite rules include not only the usual fi-rules, but also the so called permutative reductions. In this appendix we reproduce this proof, with some minor modifications. <p> In this appendix we reproduce this proof, with some minor modifications. Instead of proof trees, derivation terms are used. The definition of an end segment is formalized (Definition 5). In the definition of strong validity a little deviation of the definition in <ref> [Pra71] </ref> can be found. Lemma 6, 7 and 11 are not proved in [Pra71]. Note that in Section 5.5 we give a semantical termination proof of this system without disjunction. 0. <p> Instead of proof trees, derivation terms are used. The definition of an end segment is formalized (Definition 5). In the definition of strong validity a little deviation of the definition in <ref> [Pra71] </ref> can be found. Lemma 6, 7 and 11 are not proved in [Pra71]. Note that in Section 5.5 we give a semantical termination proof of this system without disjunction. 0.
Reference: [PS95] <author> J.C. van de Pol and H. Schwichtenberg. </author> <title> Strict functionals for termination proofs. </title> <editor> In M. Dezani-Ciancaglini and G. Plotkin, editors, </editor> <booktitle> Proceedings of the Second International Conference on Typed Lambda Calculi and Applications, Edinburgh, Scotland, volume 902 of Lecture Notes in Computer Science, </booktitle> <pages> pages 350-364. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: It is interesting to connect these notions. Whether the connection we found has logical consequences remains open. Most results of this thesis have been published in conference proceedings. In [Pol94] a description of the semantical proof method is given. In <ref> [PS95] </ref> several computation rules are given and the method is applied to larger examples. The former two papers form the basis of Chapter 4 and 5. Chapter 6 is the full version of [Pol96]. The modularity results have not been published before. <p> The main motivation for introducing them is that they are useful in termination proofs for higher-order rewrite systems. This chapter is mainly based on <ref> [Pol94, PS95] </ref>. In Section 3.4 we pointed out why the hereditarily monotonic functionals are less suitable for termination proofs. Recall that all I-terms are hereditarily monotonic (Lemma 3.3.2). In order to capture all lambda terms, we introduce the class of weakly monotonic functionals. <p> This is stronger in two respects. First, f and g are arbitrary weakly monotonic, instead of restricted to denotations of closed lambda terms. In the second place, the x may appear more than once in M . The proof can be found in <ref> [PS95] </ref> and is similar to the one given here. We will only need the theorem in the form stated above. 4.3.2 The Existence of Strict Functionals It is not immediately clear that strict functionals exist for all types. <p> The goal of the current section, is to add product types to ! fi . The resulting system will be fi fi . The theory developed so far, will be extended in order to be applicable to HRSs with fi fi as substitution calculus. In <ref> [PS95] </ref> product types were incorporated. However, we have changed some definitions. The main difference is that in that paper, the definition of HRSs is taken modulo the fi-calculus, i.e. also projections are performed implicitly. We have now decided to add only product types without changing the terms. <p> In the latter case, the rules are formed by the proper reduction rules, that remove detours, and the permutative conversions. These examples are based on <ref> [PS95] </ref>. Finally, we give an example of an HRS that cannot be proved terminating by the method. We will also sketch a possible modification of the method, to tackle at least this kind of examples. <p> However, the permutative conversions for these connectives could not be dealt with. In Chapter 5 of this thesis we showed how to generalize the semantical method to higher-order rewrite systems [Pol94] and in Section 5.5, how to prove termination of the permutative conversions with the extended theory <ref> [PS95] </ref>. In the literature, these two methods are often put in contrast (e.g. [Gan80, x 6.3] 97 98 CHAPTER 6. COMPUTABILITY VERSUS FUNCTIONALS and [GLT89, x 4.4]). Using functionals seems to be more transparent and economizes on proof theoretical complexity; strong computability should generalize to more complex systems. <p> In our proof Konig's Lemma is avoided by having a binary SN-predicate, which gives an upper bound on the numerical value. 122 CHAPTER 6. COMPUTABILITY VERSUS FUNCTIONALS 6.4.4 Comparison with Gandy's Functionals We compare the results of the program extraction, with the functionals given in <ref> [Gan80, PS95] </ref> and Section 5.3. First, we present the extracted programs in a more readable fashion. Note that the programs contain the primitive recursor R oe , because Lemma 6.4.7 contains induction on a formula ' with o (') = oe. <p> CONCLUSION 123 6.5 Conclusion With two case studies we showed, that modified realizability is a useful tool to reveal the similarity between SN-proofs using strong computability and SN-proofs using strictly monotonic functionals. The extra effort for Godel's T has paid off, because we found sharper upper bounds than in <ref> [Gan80, PS95] </ref>. Moreover, the new upper bound puts a bound on the sum of the length and the numerical value of each reduction sequence. This information helps to improve the proof that uses strictly monotonic functionals (Section 5.3). We think that our method can be applied more often.
Reference: [Raa96] <author> F. van Raamsdonk. </author> <title> Confluence and Normalisation for Higher-Order Rewriting. </title> <type> PhD thesis, </type> <institution> Vrije Universiteit, </institution> <address> Amsterdam, </address> <year> 1996. </year>
Reference-contexts: THE SYSTEMS are treated in a uniform way. Hence matters of scope, renaming of local variables, substitution, free parameter provisos etc. have to be dealt with only once. Following [Nip91, Nip93], we will take the simply-typed lambda calculus with fij-reduction as a metalanguage. Following <ref> [Oos94, Raa96] </ref> we will refer to the metalanguage as the substitution calculus. As a typical example, let us consider finding the prenex normal form of first-order logical formulae. In this normal form, the quantifiers only occur at the outside of the formula. <p> Other approaches. There are many different definitions of higher-order (term) rewrit (e)(ing) in recent literature. We only mention a few mile stones. For a historical overview of the several formats and a technical comparison between several of them, see e.g. <ref> [OR94, Oos94, Raa96] </ref>. In 1980 Klop introduced combinatory reduction systems (CRS) [Klo80, KOR93]. This is the first systematic study of TRSs with bound variables (lambda calculus with particular extensions had already been studied before; Aczel [Acz78] already considered general extensions of lambda calculus). <p> Wolfram requires the rules of base type, and also defines a rewrite step in terms of contexts, substitutions and fij-reduction, but these differences can be seen as presentation matters only. 28 CHAPTER 2. THE SYSTEMS We also mention Van Oostrom [Oos94] and Van Raamsdonk <ref> [Raa96] </ref>, who introduced the so called Higher-Order Rewriting Systems (HORS), meant to generalize all existing formalisms. HORSs parametrize over the substitution calculus that is used. Our HRSs, fi-HRSs and the HRSs based on fi fi are instances of Van Oostrom's HORSs. <p> Existing work on termination. Confluence for higher-order rewriting systems is rather well-studied. Klop (in the context of combinatory reduction systems), Nipkow and Van Oostrom are mainly concerned with confluence. Some of the main results are that orthogonal CRSs are confluent [Klo80], weakly orthogonal HRSs are confluent <ref> [Oos94, Raa96] </ref> and a critical pair lemma for HRSs [Nip91]. Remarkably, termination for higher-order rewriting is much less studied. Van Raamsdonk [Raa96] proves that outermost-fair rewriting is a normalizing strategy for orthogonal higher-order term rewriting. <p> Some of the main results are that orthogonal CRSs are confluent [Klo80], weakly orthogonal HRSs are confluent [Oos94, Raa96] and a critical pair lemma for HRSs [Nip91]. Remarkably, termination for higher-order rewriting is much less studied. Van Raamsdonk <ref> [Raa96] </ref> proves that outermost-fair rewriting is a normalizing strategy for orthogonal higher-order term rewriting. But note that termination (or strong normalization) requires that all reduction sequences end in a normal form.
Reference: [RR93] <editor> M. Rusinowitch and J.-L. Remy, editors. </editor> <booktitle> Proceedings of the Third International Workshop on Conditional Term Rewriting Systems, Ponta-Mousson, France, CTRS '92, volume 656 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference: [Rus87] <author> M. Rusinowitch. </author> <title> On termination of the direct sum of term rewriting systems. </title> <journal> Information Processing Letters, </journal> <volume> 26 </volume> <pages> 65-70, </pages> <year> 1987. </year>
Reference-contexts: FUNCTIONALS OF FINITE TYPE 37 Rusinowitch <ref> [Rus87] </ref> and Middeldorp [Mid89] proved that it is essential for all such counter examples that one of the systems has a duplicating rule, and the other a collapsing rule. In other cases, termination is preserved by the disjoint union.
Reference: [Sel94] <author> M.P.A. </author> <title> Sellink. Verifying process algebra proofs in type theory. </title> <editor> In An-drews et al. </editor> <booktitle> [AGM94], </booktitle> <pages> pages 315-339. </pages>
Reference-contexts: The Process Algebra part can be formulated in a first order Term Rewriting System (see for instance [AB91]). The rules for the Sum-operator require higher-order rewrite rules to deal with the bound variables. A similar formulation of CRL can be found in <ref> [Sel94] </ref>. There are two base types: fProc; Datag.
Reference: [Sor96] <author> M.H. Sorensen. </author> <title> Strong normalization from weak normalization in typed lambda-calculi. </title> <type> Technical report, </type> <institution> University of Copen-hagen, Denmark, </institution> <year> 1996. </year> <note> Submitted for publication; obtainable via http://www.diku.dk/research-groups/topps/personal/rambo.html. </note>
Reference-contexts: But note that termination (or strong normalization) requires that all reduction sequences end in a normal form. Furthermore, for orthogonal CRSs, Klop [Klo80] gives a method to reduce strong normalization to weak normalization, which is often easier to prove. This work is preceded by [Ned73] and succeded by <ref> [Sor96] </ref>. As far as we know, [Pol94] provides the first method to prove termination of arbitrary HRSs, by using a semantical approach. This work is based on similar work for TRSs [Zan94] and for simply-typed lambda calculus [Gan80].
Reference: [Tai67] <author> W.W. Tait. </author> <title> Intensional interpretation of functionals of finite types I. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 32 </volume> <pages> 198-212, </pages> <year> 1967. </year>
Reference-contexts: Finally, Theorem 2.4.4 ! fi is strongly normalizing. There are many proofs of the last fact <ref> [Gan80, Tai67, Tro73] </ref>. We will present Gandy's proof in Section 3.3. Tait's proof is presented in Section 6.1. Chapter 6 is devoted to the comparison of these two proofs. Normalization essentially relies on typing information. In the untyped lambda calculus, WN does not hold. <p> This chapter is a full version of the paper that appeared as [Pol96]. The computability method is often attributed to Tait <ref> [Tai67] </ref>, who used convertibility predicates to prove a normal form theorem for various systems. Troelstra [Tro73] uses similar predicates (now called strong computability) in strong normalization proofs. Prawitz [Pra71] used a variant, to deal with permutative conversions, arising from natural deduction for first order predicate logic (see the Appendix).
Reference: [Toy87] <author> Y. Toyama. </author> <title> Counterexamples to termination for the direct sum of term rewriting systems. </title> <journal> Information Processing Letters, </journal> <volume> 25 </volume> <pages> 141-143, </pages> <year> 1987. </year>
Reference-contexts: This means that there are terminating TRSs, with disjoint sets of function symbols, whose union is not terminating. So a termination problem cannot be tackled by dividing a TRS into small parts, even not when these parts have nothing in common. The following example is due to Toyama <ref> [Toy87] </ref>: f (0; 1; x) 7! f (x; x; x) g (x; y) 7! y Although the rule defining f is terminating, and the rules defining g are terminating too, there exists an infinite reduction in the combined system, starting with the term f (0; 1; g (0; 1)). 3.2.
Reference: [Tro73] <author> A.S. Troelstra. </author> <title> Metamathematical Investigation of Intuitionistic Arithmetic and Analysis. Number 344 in LNM. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1973. </year> <note> Second corrected edition appeared as report ILLC X-93-05, </note> <institution> University of Amsterdam, </institution> <year> 1993. </year>
Reference-contexts: Finally, Theorem 2.4.4 ! fi is strongly normalizing. There are many proofs of the last fact <ref> [Gan80, Tai67, Tro73] </ref>. We will present Gandy's proof in Section 3.3. Tait's proof is presented in Section 6.1. Chapter 6 is devoted to the comparison of these two proofs. Normalization essentially relies on typing information. In the untyped lambda calculus, WN does not hold. <p> This chapter is a full version of the paper that appeared as [Pol96]. The computability method is often attributed to Tait [Tai67], who used convertibility predicates to prove a normal form theorem for various systems. Troelstra <ref> [Tro73] </ref> uses similar predicates (now called strong computability) in strong normalization proofs. Prawitz [Pra71] used a variant, to deal with permutative conversions, arising from natural deduction for first order predicate logic (see the Appendix). Gi-rard [Gir72] introduced a stronger variant, to deal with the impredicative system F. <p> A REFINEMENT OF REALIZABILITY 101 6.2 A Refinement of Realizability As mentioned before, we want to extract the computational content from the SN-proof of Section 6.1. To this end we use modified realizability, introduced by Kreisel [Kre59]. In <ref> [Tro73, x 3.4] </ref> modified realizability is presented as a translation of HA ! into itself. This interpretation eliminates existential quantifiers, at the cost of introducing functions of finite type (functionals), represented by -terms. <p> Induction is needed to deal with Godel's T in Section 6.4. This is well known theory, apart from the axioms under (2), which explore the special nature of the 8-quantifier. Axioms as under (1) are exploited in [Ber93]. Case (3) and (4) can be found in <ref> [Tro73] </ref>. 6.2.3.1 9-free Axioms and Harrop Formulae Consider a 9-free MF formula '. We have o (') = *, so the only potential realizer is the empty sequence. Let ' 0 be the formula obtained from ' by deleting all underlinings. We have * mr ' j ' 0 . <p> If d ' is the MF-derivation, ~ t can be obtained from ep (d) by replacing all free variables introduced by the axioms IP, IU and intro by the identity. We will not address the question whether the inverse of this correctness result also holds. In <ref> [Tro73, x 3.4.8] </ref> it is proved that HA ! +IP+AC, axiomatizes modified realizability. However, AC is neither a formula of MF nor of NH, as it contains both higher-order variables and existential quantifiers, so we cannot use that result here directly. <p> Induction can be postulated by introducing axioms ind ' : '(0) ! (8n; '(n) ! '(Sn)) ! 8n:'(n) : In the general case, induction can be realized by simultaneous primitive recursion operators (See <ref> [Tro73, x 1.6.16, x 3.4.5] </ref>). We will only need the special case that o (') = oe, so the induction formula is realized by exactly one term. In this case, the usual recursion operator is a potential realizer. <p> So here we lose a kind of uniformity. It is well known that the absence of a uniform first-order proof is essential, because the computability predicate is not arithmetizable <ref> [Tro73, x 2.3.11] </ref>. Another incompleteness arises, because some combinatorial results will be plugged in as axioms. This second incompleteness is harmless for our purpose, because all these axioms are formulated without using existential quantifiers. <p> It is a well known fact that ! fiR is a terminating rewrite relation. The proof a la Tait of this fact (see e.g. <ref> [Tro73, 2.2.31] </ref>) extends the case of the fi-rule, by proving that the new constants are strongly computable. We will present a version with concrete upper bounds. It turns out to be rather cumbersome to give a concrete number. <p> All these axioms are realized by the identity, which we left out. Remark: In <ref> [Tro73, x 2.2.18] </ref> Konig's Lemma (or intuitionistically the Fan Theorem) is used to prove that in the reduction tree of a strongly normalizing term, the maximal value is bounded.
Reference: [Vrij87] <author> R. de Vrijer. </author> <title> Exactly estimating functionals and strong normalization. </title> <journal> Proceedings of the Koninklijke Nederlandse Akademie van Wetenschap-pen, </journal> <volume> 90(4) </volume> <pages> 479-493, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: In order to achieve that a rewrite step gives rise to a decrease of the associated number, the notion hereditarily monotonic functional was developed. The number is an upper bound for the length of reduction sequences starting from a certain term. De Vrijer <ref> [Vrij87] </ref> used a variant to compute the exact length of the longest reduction sequence. Gandy deals with simply-typed lambda calculus, Godel's T and with fi-reductions in proof theory including disjunction and existential quantification. However, the permutative conversions for these connectives could not be dealt with. <p> Using functionals seems to be more transparent and economizes on proof theoretical complexity; strong computability should generalize to more complex systems. On the other hand, seeing the two proofs one gets the feeling that "somehow, the same thing is going on". Indeed De Vrijer <ref> [Vrij87, x 0.1] </ref> remarks that a proof using strong computability can be seen as abstracting from concrete information in the functionals that is not strictly needed in a termination proof, but which provides for an estimate of reduction lengths. In this chapter we will substantiate this feeling. <p> This formula is equivalent to 8p:8m:SN (p; m) ! 9n:SN (rp; n). So we can bound the reduction length of rp uniformly in the upper bound for p. More precisely, if SN (p; m) then SN (rp; [[r]](m)). A stronger uniformity principle appears in <ref> [Vrij87, x 2.3.4] </ref>). The uniformity principle does not hold if we substitute R o M N for r: Although SN (S k 0; 0) holds for each k, RM N (S k 0) can perform k reduction steps. So SC (RM N ) 6.4.
Reference: [Wol93] <author> D.A. Wolfram. </author> <title> The Clausal Theory of Types, </title> <booktitle> volume 21 of Cambridge tracts in theoretical computer science. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cam-bridge, </address> <year> 1993. </year>
Reference-contexts: Minor differences are that Nipkow requires the rules to be of base type (where we require them to be closed) and defines the rewrite relation in terms of contexts, substitutions and fij-reduction. Wolfram studies higher-order term rewriting systems <ref> [Wol93] </ref>. These systems are the same as the HRSs that we study, up to minor differences. Wolfram requires the rules of base type, and also defines a rewrite step in terms of contexts, substitutions and fij-reduction, but these differences can be seen as presentation matters only. 28 CHAPTER 2.
Reference: [Zan94] <author> H. Zantema. </author> <title> Termination of term rewriting: Interpretation and type elimination. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 17 </volume> <pages> 23-50, </pages> <year> 1994. </year>
Reference-contexts: Every rewrite step gives rise to a decrease of the corresponding values in the termination model. Hence the existence of a termination model ensures termination. In Section 3.1 we recapitulate how termination proofs for TRSs can use monotone algebras <ref> [Zan94] </ref>. In Section 3.2 we show the standard model of functionals of finite type for the simply-typed lambda calculus and we show in Section 3.3 how a subset of them, the hereditarily monotonic functionals can be used to prove termination of this calculus [Gan80]. <p> This work is preceded by [Ned73] and succeded by [Sor96]. As far as we know, [Pol94] provides the first method to prove termination of arbitrary HRSs, by using a semantical approach. This work is based on similar work for TRSs <ref> [Zan94] </ref> and for simply-typed lambda calculus [Gan80]. Kahrs [Kah95] shows that it is possible to use the hereditarily monotonic function-als in termination proofs for HRSs. He avoids constant functions by systematically 3.4. TOWARDS TERMINATION OF HRSs 45 translating lambda terms to I-terms (using the translation M fl ). <p> For (1) we will often choose the ordered domain (N; &gt;; 0; +). It is well-known that even for first-order term rewriting this is not enough. There exist terminating TRSs for which a non-total order is necessary. See <ref> [Zan94, Fer95] </ref> for a hierarchy of underlying partial orders. There is no general recipe how to find a suitable strict interpretation (2). There are two starting points. The first starting point is the standard interpretation of the rewrite system as an equational theory, which yields a model.

References-found: 76

