URL: ftp://ftp.cs.rochester.edu/pub/u/rao/papers/tr97.1.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Title: Eye Movements in Visual Cognition: A Computational Study  
Author: Rajesh P. N. Rao Gregory J. Zelinsky Mary M. Hayhoe Dana H. Ballard 
Note: A preliminary account of this work appeared as Rao et al., 1996  
Address: Rochester, NY 14627 Urbana, IL 61801  Rochester, NY 14627 Rochester, NY 14627  
Affiliation: Department of Computer Science Beckman Institute University of Rochester University of Illinois  Center for Visual Science Department of Computer Science University of Rochester University of Rochester  
Abstract: Technical Report 97.1 National Resource Laboratory for the Study of Brain and Behavior Department of Computer Science, University of Rochester March 1997 
Abstract-found: 1
Intro-found: 1
Reference: [ Ahmad and Omohundro, 1991 ] <author> S. Ahmad and S. Omohundro. </author> <title> Efficient visual search: A connectionist solution. </title> <booktitle> In Proceeding of the 13th Annual Conference of the Cognitive Science Society, </booktitle> <address> Chicago, </address> <year> 1991. </year>
Reference: [ Allport, 1989 ] <author> A. Allport. </author> <title> Visual attention. In M.I. Posner, editor, </title> <booktitle> Foundations of Cognitive Science, </booktitle> <pages> pages 631-682. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference: [ Andersen and Van Essen, 1987 ] <author> C.H. Andersen and D.C. Van Essen. </author> <title> Shifter circuits: A computational strategy for dynamic aspects of visual processing. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 84 </volume> <pages> 6297-6301, </pages> <year> 1987. </year>
Reference-contexts: Such a situation may occur in the case of the skipping eye movements, as the targeting is based on a correlation process which is being done sequentially across scales. Of course, the partial correlation results contained in the saliency map have to be shifted <ref> [ Andersen and Van Essen, 1987 ] </ref> due to the intermediate eye movements, before being integrated, but the scene frame contains the information necessary to perform this shifting.
Reference: [ Andersen et al., 1985 ] <author> R.A. Andersen, G.K. Essick, and R.M. Siegel. </author> <title> Encoding of spatial location by posterior parietal neurons. </title> <journal> Science, </journal> <volume> 230 </volume> <pages> 456-458, </pages> <year> 1985. </year>
Reference-contexts: We also assume that the transform T sr is continually updated using vestibular and posture signals (efference copies or corollary discharges [ Brooks, 1986 ] ) as derived from eye, head, and body movements. This assumption is partly supported by neurophysiological findings in the parietal cortex <ref> [ Andersen et al., 1985; Duhamel et al., 1992 ] </ref> . <p> These ideas motivate the notion of gain fields or basis fields [ Pouget and Sejnowski, 1995; Salinas and Abbott, 1996 ] that have proved useful in modeling neuronal responses in the parietal cortex <ref> [ Andersen et al., 1985 ] </ref> , where head coordinates are encoded with a variable unit strategy, but target coordinates are encoded with punctate value unit receptive fields.
Reference: [ Ballard et al., 1995 ] <author> D.H. Ballard, M. Hayhoe, and J. Pelz. </author> <title> Memory representations in natural tasks. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 7(1) </volume> <pages> 66-80, </pages> <year> 1995. </year>
Reference-contexts: In a task involving the copying of a model block pattern on a board, subjects have been shown to employ fixations for accessing crucial information during different stages of the copying task <ref> [ Ballard et al., 1995; 1997 ] </ref> . In natural language processing, there is recent evidence that fixations reflect the instantaneous parsing of a spoken sentence [ Tanenhaus et al., 1995 ] . <p> the first task [ Zelinsky et al., 1996 ] involving visual search, subjects were shown an image of a realistic object and then asked to report, as quickly and accurately as possible, if it was present in a subsequent image containing one to five similar objects (Section 4). 2 Another <ref> [ Ballard et al., 1995 ] </ref> was a visuo-motor task, where subjects were asked to replicate a pattern of colored blocks (Section 5). In both tasks, the eye movements predicted by the model were found to be in close agreement with observed human eye movements. <p> The pattern of eye movements in the case where the scene is continuously available was examined using a second task, that of copying patterns of colored blocks <ref> [ Ballard et al., 1995 ] </ref> . During this task, subjects do not seem to exhibit the pronounced skipping movements that were observed in the previous visual search task.
Reference: [ Ballard et al., 1997 ] <author> D.H. Ballard, M.M. Hayhoe, P.K. Pook, and R.P.N. Rao. </author> <title> Deictic codes for the embodiment of cognition. </title> <journal> Behavioral and Brain Sciences, </journal> <note> 1997. In press. </note>
Reference-contexts: Only one point (the target point) has a correlation greater than 0:94 (demarcated by an arrow) in the multiple scale case (b) whereas 936 candidate points fall in this category in the single scale case (a). 3 Modeling Visual Search We have argued elsewhere <ref> [ Rao and Ballard, 1995a; Ballard et al., 1997 ] </ref> that visual behavior can be viewed as task-specific compositions of visual routines [ Ullman, 1984 ] . In particular, visual behaviors can be composed using two different types of visual routines.
Reference: [ Ballard, 1986 ] <author> D.H. Ballard. </author> <title> Cortical connections and parallel processing: Structure and function. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 9(1) </volume> <pages> 67-120, </pages> <year> 1986. </year>
Reference-contexts: There is an asymmetry between these frames, in that the former needs to keep track of multiple targets, whereas the latter needs only keep track of a single data point, namely, the relation of the scene to retinal origin. As discussed in <ref> [ Ballard, 1986 ] </ref> , there are two basic kinds of encoding that can be employed by neurons. For multiple targets, a value unit encoding can be used, wherein the neuron's receptive field is localized and the peak firing rate signals a specific location.
Reference: [ Barrow, 1987 ] <author> H.G. Barrow. </author> <title> Learning receptive fields. </title> <booktitle> In Proceedings of the IEEE Int. Conf. on Neural Networks, </booktitle> <pages> pages 115-121, </pages> <year> 1987. </year>
Reference-contexts: Such a learning procedure allows the weights for each color channel to be determined from red-green-blue (RGB) pixel inputs. Next, the learning rule can be applied to image patches along each channel separately. The resultant basis functions for the achromatic channel resemble oriented Gaussian derivative filters of different orders <ref> [ Barrow, 1987 ] </ref> (see [ Olshausen and Field, 1996; Rao and Ballard, 1997b; Bell and Sejnowski, 1996 ] for alternate learning strategies). 5 used in the copying task is shown at the top.
Reference: [ Bell and Sejnowski, 1996 ] <author> A.J. Bell and T.J. Sejnowski. </author> <title> The `independent components' of natural scenes are edge filters. </title> <note> Submitted to Vision Research, </note> <year> 1996. </year>
Reference: [ Breitmeyer, 1975 ] <author> B.G. Breitmeyer. </author> <title> Simple reaction time as a measure of the temporal response properties of transient and sustained channels. </title> <journal> Vision Research, </journal> <volume> 15 </volume> <pages> 1411-1412, </pages> <year> 1975. </year>
Reference-contexts: This interpretation of the data is appealing in two aspects. First, it reflects a long history of observations on the priority of large scale channels in vision <ref> [ Navon, 1977; Breitmeyer, 1975; Parker and Dutch, 1987 ] </ref> , even though the reaction time differences between spatial frequencies may be quite small.
Reference: [ Brooks, 1986 ] <author> V.B. Brooks. </author> <title> The neural basis of motor control. </title> <address> New York: </address> <publisher> Oxford University Press, </publisher> <year> 1986. </year>
Reference-contexts: We also assume that the transform T sr is continually updated using vestibular and posture signals (efference copies or corollary discharges <ref> [ Brooks, 1986 ] </ref> ) as derived from eye, head, and body movements. This assumption is partly supported by neurophysiological findings in the parietal cortex [ Andersen et al., 1985; Duhamel et al., 1992 ] .
Reference: [ Burt, 1988 ] <author> P.J. Burt. </author> <title> Attention mechanisms for vision in a dynamic world. </title> <booktitle> In ICPR, </booktitle> <pages> pages 977-987, </pages> <year> 1988. </year>
Reference-contexts: coordinates. (d) An eye movement is made to the location containing the peak of the saliency map after the resource area has been delimited using spatial memory. 25 fine strategies have also enjoyed recent popularity in computer vision with the advent of image pyramids for tasks such as motion detection <ref> [ Burt, 1988 ] </ref> . One key question that remains is the source of sequential application of the filters in the human visual system. A possible source is the variation in resolution of the retina.
Reference: [ Carpenter, 1988 ] <author> R.H.S. Carpenter. </author> <title> Movements of the Eyes. </title> <address> London: Pion, </address> <year> 1988. </year> <month> 29 </month>
Reference-contexts: These rapid eye movements, which are made at the rate of about three per second, orient the high-acuity foveal region of the eye over targets of interest in a visual scene. The characteristic properties of saccadic eye movements (or saccades) have been well studied <ref> [ Carpenter, 1988 ] </ref> . The high velocity of saccades, reaching up to 700 ffi per second for large movements, serves to minimize the time in flight, so that most of the time is spent fixating the chosen targets.
Reference: [ Chapman, 1991 ] <author> D. Chapman. </author> <title> Vision, Instruction, and Action. </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: [ Chase and Simon, 1973 ] <author> W.G. Chase and H.A. Simon. </author> <title> Perception in chess. </title> <journal> Cognitive Psychology, </journal> <volume> 4 </volume> <pages> 55-81, </pages> <year> 1973. </year>
Reference-contexts: In chess, it has been shown that saccades are used to assess the current situation on the board in the course of making a decision to move, but the exact information that is being represented is not yet known <ref> [ Chase and Simon, 1973 ] </ref> . In a task involving the copying of a model block pattern on a board, subjects have been shown to employ fixations for accessing crucial information during different stages of the copying task [ Ballard et al., 1995; 1997 ] .
Reference: [ Chatfield and Collins, 1980 ] <author> C. Chatfield and A.J. Collins. </author> <title> Introduction to Multivariate Analysis. </title> <address> New York: </address> <publisher> Chapman and Hall, </publisher> <year> 1980. </year>
Reference-contexts: noted that the soft competitive learning rule performs maximum likelihood estimation [ Nowlan, 1990 ] and generates piece-wise approximations to the principal surfaces of data distributions [ Mulier and Cherkassky, 1995; Ritter et al., 1992 ] ; these surfaces are nonlinear generalizations of the linear technique of principal components analysis <ref> [ Chatfield and Collins, 1980 ] </ref> . Such a learning procedure allows the weights for each color channel to be determined from red-green-blue (RGB) pixel inputs. Next, the learning rule can be applied to image patches along each channel separately.
Reference: [ Coren and Hoenig, 1972 ] <author> S. Coren and P. Hoenig. </author> <title> Effect of non-target stimuli upon length of voluntary saccades. Perceptual and Motor Skills, </title> <booktitle> 34 </booktitle> <pages> 499-508, </pages> <year> 1972. </year>
Reference: [ Daugman, 1980 ] <author> J.G. Daugman. </author> <title> Two-dimensional spectral analysis of cortical receptive field profiles. </title> <journal> Vision Research, </journal> <volume> 20 </volume> <pages> 847-856, </pages> <year> 1980. </year>
Reference: [ Derrico and Buchsbaum, 1991 ] <author> J.B. Derrico and G. Buchsbaum. </author> <title> A computational model of spa-tiochromatic image coding in early vision. </title> <journal> Journal of Visual Communication and Image Representation, </journal> <volume> 2(1) </volume> <pages> 31-38, </pages> <year> 1991. </year>
Reference: [ Didday and Arbib, 1975 ] <author> R.L. Didday and M.A. Arbib. </author> <title> Eye movements and visual perception: A two visual system model. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 7 </volume> <pages> 547-569, </pages> <year> 1975. </year>
Reference: [ Duhamel et al., 1992 ] <author> J. Duhamel, L. Colby, and M.E. Goldberg. </author> <title> The updating of the representation of visual space in parietal cortex by intended eye movements. </title> <journal> Science, </journal> <volume> 255 </volume> <pages> 90-92, </pages> <year> 1992. </year>
Reference-contexts: We also assume that the transform T sr is continually updated using vestibular and posture signals (efference copies or corollary discharges [ Brooks, 1986 ] ) as derived from eye, head, and body movements. This assumption is partly supported by neurophysiological findings in the parietal cortex <ref> [ Andersen et al., 1985; Duhamel et al., 1992 ] </ref> .
Reference: [ Duncan and Humphreys, 1992 ] <author> J. Duncan and G.W. Humphreys. </author> <title> Beyond the search surface: Visual search and attentional engagement. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 18 </volume> <pages> 578-588, </pages> <year> 1992. </year>
Reference: [ Felleman and Van Essen, 1991 ] <author> D.J. Felleman and D.C. Van Essen. </author> <title> Distributed hierarchical processing in the primate cerebral cortex. </title> <journal> Cerebral Cortex, </journal> <volume> 1 </volume> <pages> 1-47, </pages> <year> 1991. </year>
Reference-contexts: In a neurobiological setting, the model assumes that the memorized top-down target representations r m can be correlated with the current striate and extra-striate representations r (x; y) by exploiting the massive feedback connections <ref> [ Felleman and Van Essen, 1991 ] </ref> from higher cortical areas, including areas in the infero-temporal cortex and possibly frontal lobe regions, where the memorized target representations are assumed to be stored.
Reference: [ Findlay, 1982 ] <author> J. Findlay. </author> <title> Global visual processing for saccadic eye movements. </title> <journal> Vision Research, </journal> <volume> 22 </volume> <pages> 1033-1045, </pages> <year> 1982. </year>
Reference: [ Findlay, 1987 ] <author> J. Findlay. </author> <title> Visual computation and saccadic eye movements: A theoretical perspective. Spatial Vision, </title> <booktitle> 2 </booktitle> <pages> 175-189, </pages> <year> 1987. </year>
Reference: [ Fischer and Boch, 1983 ] <author> B. Fischer and R. Boch. </author> <title> Saccadic eye movements after extremely short reaction times in the monkey. </title> <journal> Brain Research, </journal> <volume> 260 </volume> <pages> 21-26, </pages> <year> 1983. </year> <month> 30 </month>
Reference: [ Fischer and Ramsperger, 1984 ] <author> B. Fischer and E. Ramsperger. </author> <title> Human express-saccades: ex-tremely short reaction times of goal directed eye movements. </title> <journal> Experimental Brain Research, </journal> <volume> 57 </volume> <pages> 191-195, </pages> <year> 1984. </year>
Reference: [ Fischer and Weber, 1993 ] <author> B. Fischer and H. Weber. </author> <title> Express saccades and visual attention. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 16 </volume> <pages> 553-610, </pages> <year> 1993. </year>
Reference: [ Freeman and Adelson, 1991 ] <author> W.T. Freeman and E.H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: For example, color can be represented by a single achromatic and two color opponent channels (Figure 1 (a)). Along each of these channels, a local image patch can be characterized using a zeroth order Gaussian G 0 and nine of its oriented derivatives (Figure 1 (b)) as follows <ref> [ Freeman and Adelson, 1991 ] </ref> : G n where n denotes the order of the filter and n refers to the preferred orientation of the filter. <p> Before concluding this section, we note that the iconic representations can also be made invariant to rotations in the image plane (for a fixed scale) without additional convolutions by exploiting the property of steerability <ref> [ Freeman and Adelson, 1991 ] </ref> to rotate the filter responses to a canonical orientation. View rotations about an image plane axis are ameliorated in two ways.
Reference: [ Geisler and Chou, 1995 ] <author> W.S. Geisler and K.-L. Chou. </author> <title> Separation of low-level and high-level factors in complex tasks: Visual search. </title> <journal> Psychological Review, </journal> <volume> 102(2) </volume> <pages> 356-378, </pages> <year> 1995. </year>
Reference-contexts: A possible source is the variation in resolution of the retina. Since resolution falls off with distance from the fovea, the fine spatial scales may be ineffective during early stages of search purely because the fixation point is distant from the target. Indeed, <ref> [ Geisler and Chou, 1995 ] </ref> have shown that much of the variation in search time for spatially filtered Gaussian noise images can be accounted for by the discriminability of the target from the background, so this is undoubtedly a factor in the current experiment and presumably for a variety of
Reference: [ Giefing et al., 1991 ] <author> G.-J. Giefing, H. Janen, and H. Mallot. </author> <title> A saccadic camera movement system for object recognition. </title> <editor> In T. Kohonen, K. Makisara, O. Simula, and J. Kangas, editors, </editor> <booktitle> Artificial Neural Networks (Vol. </booktitle> <volume> 1), </volume> <pages> pages 63-68. </pages> <address> Amsterdam: </address> <publisher> Elsevier, </publisher> <year> 1991. </year>
Reference: [ Groner, 1988 ] <author> R. Groner. </author> <title> Eye movements, attention and visual information processing: Some experimental results and methodological considerations. </title> <editor> In G. Luer, U. Lass, and J. Shallo-Hoffman, editors, </editor> <title> Eye movement research: </title> <journal> Physiological and psychological aspects, </journal> <pages> pages 295-319. </pages> <address> Gottingen, Germany: Hogrefe, </address> <year> 1988. </year>
Reference-contexts: Such an interpretation is especially attractive since it allows a single targeting mechanism to parsimoniously account for both covert and overt search. It is also consistent with the conclusions of both [ Shepherd et al., 1986 ] and <ref> [ Groner, 1988 ] </ref> suggesting that the attentional and saccadic system are regulated by different but closely related oculomotor control systems. Acknowledgments This work was supported by NSF research grant no.
Reference: [ Grossberg, 1976 ] <author> S. Grossberg. </author> <title> Adaptive pattern classification and universal recoding: I. parallel development and coding of neural feature detectors. </title> <journal> Biological Cybernetics, </journal> <volume> 23 </volume> <pages> 121-134, </pages> <year> 1976. </year>
Reference-contexts: This generalizes the more frequently used winner-take-all form of competitive learning <ref> [ Grossberg, 1976; Rumelhart and Zipser, 1986 ] </ref> , where only the most similar weight vector is modified.
Reference: [ Hancock et al., 1992 ] <author> P.J.B. Hancock, R.J. Baddeley, and L.S. Smith. </author> <title> The principal components of natural images. </title> <journal> Network, </journal> <volume> 3 </volume> <pages> 61-70, </pages> <year> 1992. </year>
Reference: [ He and Kowler, 1989 ] <author> P. He and E. Kowler. </author> <title> The role of location probability in the programming of saccades: Implications for center-of-gravity tendencies. </title> <journal> Vision Research, </journal> <volume> 29 </volume> <pages> 1165-1181, </pages> <year> 1989. </year>
Reference: [ Hinton, 1981 ] <author> G.E. Hinton. </author> <title> A parallel computation that assigns canonical object-based frames of reference. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <year> 1981. </year>
Reference-contexts: A computationally attractive solution to this problem is to store spatial locations in an additional frame of reference that is independent of the current fixation. It is easy to demonstrate the usefulness of such an additional frame, termed the object-centered frame <ref> [ Hinton, 1981 ] </ref> . In reading, the position of letters with respect to the retina is unimportant compared to their position in the encompassing word.
Reference: [ Hooge, 1996 ] <author> I.T.C. Hooge. </author> <title> Control of eye movements in visual search. </title> <type> PhD thesis, </type> <institution> University of Utrecht, Netherlands, </institution> <year> 1996. </year>
Reference-contexts: In order to avoid the prohibitive cost of updating in retinal coordinates, an object-centered frame can be used for retaining spatial memory of relevant target locations. The proposed model shares some similarities with the visual search model proposed in <ref> [ Hooge, 1996 ] </ref> (and more generally, the ideas of [ Milner and Goodale, 1995 ] ). In fact, the what, where, and when mechanisms of [ Hooge, 1996 ] address the appearance models, the spatial memory model, and the decision process respectively. <p> The proposed model shares some similarities with the visual search model proposed in <ref> [ Hooge, 1996 ] </ref> (and more generally, the ideas of [ Milner and Goodale, 1995 ] ). In fact, the what, where, and when mechanisms of [ Hooge, 1996 ] address the appearance models, the spatial memory model, and the decision process respectively.
Reference: [ Just and Carpenter, 1976 ] <author> M.A. </author> <title> Just and P.A. Carpenter. </title> <journal> Eye fixations and cognitive processes. Cognitive Psychology, </journal> <volume> 8 </volume> <pages> 441-480, </pages> <year> 1976. </year> <month> 31 </month>
Reference-contexts: In addition, it is known that saccade size during reading is modulated according to the specific nature of the pattern recognition task at hand [ Kowler and Anton, 1987 ] . Tasks requiring same/different judgments of complex patterns also elicit characteristic saccades <ref> [ Just and Carpenter, 1976 ] </ref> .
Reference: [ Kanerva, 1988 ] <author> P. Kanerva. </author> <title> Sparse Distributed Memory. </title> <address> Cambridge, MA: </address> <publisher> Bradford Books, </publisher> <year> 1988. </year>
Reference-contexts: The high-dimensionality of the vectors makes them remarkably robust to noise due to the orthogonality inherent in high-dimensional spaces: given any vector, almost all of the other vectors in the space tend to be relatively uncorrelated with the given vector <ref> [ Kanerva, 1988; Rao and Ballard, 1995a ] </ref> , and almost none are identical with respect to each other. The result is that the filter response vector for a given point is unique for all practical purposes and can therefore be used to define search targets.
Reference: [ Koch and Ullman, 1985 ] <author> C. Koch and S. Ullman. </author> <title> Shifts in selective visual attention: Toward the underlying neural circuitry. </title> <journal> Human Neurobiology, </journal> <volume> 4(4) </volume> <pages> 219-227, </pages> <year> 1985. </year>
Reference-contexts: The oculomotor process will continue to be execute eye movements as long as the decision process has not terminated, using the current best guess of target location as computed by the targeting process. All three processes use a saliency map <ref> [ Koch and Ullman, 1985 ] </ref> to represent locations. The saliency map is a retinotopically organized array of model neurons. Neural activity at a given location in this map is assumed to represent the corresponding retinotopic spatial location. <p> The technical advantage of such a strategy is that, since gaze is fixed, retinal coordinates can be used for keeping track of examined locations for inhibition of return <ref> [ Koch and Ullman, 1985 ] </ref> . However, since signal transmission through visual cortex is on the order of 80-100 milliseconds, performing covert search with an attentional spotlight while simultaneously obeying this stringent time constraint seems a difficult endeavor.
Reference: [ Kowler and Anton, 1987 ] <author> E. Kowler and S. Anton. </author> <title> Reading twisted text: Implications for the role of saccades. </title> <journal> Vision Research, </journal> <volume> 27 </volume> <pages> 45-60, </pages> <year> 1987. </year>
Reference-contexts: In addition, it is known that saccade size during reading is modulated according to the specific nature of the pattern recognition task at hand <ref> [ Kowler and Anton, 1987 ] </ref> . Tasks requiring same/different judgments of complex patterns also elicit characteristic saccades [ Just and Carpenter, 1976 ] .
Reference: [ Krose and Julesz, 1989 ] <author> B.J.A. Krose and B. Julesz. </author> <title> The control and speed of shifts of attention. </title> <journal> Vision Research, </journal> <volume> 29(11) </volume> <pages> 1607-1619, </pages> <year> 1989. </year>
Reference-contexts: Some of the search results have suggested that targets can be examined at the rate of about 25 milliseconds per item, with the attentional spotlight moving from one location to the next at a speed of about one attentional shift every 30-50 milliseconds <ref> [ Krose and Julesz, 1989; Saarinen and Julesz, 1991 ] </ref> . Models of attention (for example, [ Niebur 27 and Koch, 1996 ] ) have in fact literally modeled this shift of the focus of attention.
Reference: [ Land and Furneaux, 1997 ] <author> M.F. Land and S. Furneaux. </author> <title> The knowledge base of the oculomotor system. </title> <booktitle> In Proceedings of the Royal Society Conference on Knowledge-Based Vision, </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: In natural language processing, there is recent evidence that fixations reflect the instantaneous parsing of a spoken sentence [ Tanenhaus et al., 1995 ] . The role of gaze has been studied by <ref> [ Land and Furneaux, 1997 ] </ref> in a variety of other visuo-motor tasks such as driving, music reading and playing ping pong. In each case, gaze was found to play a central functional role, closely linked to the ongoing task demands.
Reference: [ Marcelja, 1980 ] <author> S. Marcelja. </author> <title> Mathematical description of the responses of simple cortical cells. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 70 </volume> <pages> 1297-1300, </pages> <year> 1980. </year>
Reference: [ McIlwain, 1991 ] <author> J.T. McIlwain. </author> <title> Distributed spatial coding in the superior colliculus: A review. </title> <journal> Visual Neuroscience, </journal> <volume> 6 </volume> <pages> 3-13, </pages> <year> 1991. </year>
Reference-contexts: The target location for a saccade at each iteration is computed using a weighted averaging scheme. The use of an averaging mechanism for targeting is supported by recent neurophysiological evidence <ref> [ McIlwain, 1991 ] </ref> suggesting that the superior colliculus, a multilayered neuronal structure in the brain stem implicated in the generation of saccadic eye movements, employs a population averaging scheme for computing saccadic motor vectors.
Reference: [ Milner and Goodale, 1995 ] <author> A.D. Milner and M.A. Goodale. </author> <title> The Visual Brain in Action. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1995. </year>
Reference-contexts: In order to avoid the prohibitive cost of updating in retinal coordinates, an object-centered frame can be used for retaining spatial memory of relevant target locations. The proposed model shares some similarities with the visual search model proposed in [ Hooge, 1996 ] (and more generally, the ideas of <ref> [ Milner and Goodale, 1995 ] </ref> ). In fact, the what, where, and when mechanisms of [ Hooge, 1996 ] address the appearance models, the spatial memory model, and the decision process respectively.
Reference: [ Mulier and Cherkassky, 1995 ] <author> F. Mulier and V. Cherkassky. </author> <title> Self-organization as an iterative kernel smoothing process. </title> <journal> Neural Computation, </journal> <volume> 7(6) </volume> <pages> 1165-1177, </pages> <year> 1995. </year>
Reference-contexts: It has been noted that the soft competitive learning rule performs maximum likelihood estimation [ Nowlan, 1990 ] and generates piece-wise approximations to the principal surfaces of data distributions <ref> [ Mulier and Cherkassky, 1995; Ritter et al., 1992 ] </ref> ; these surfaces are nonlinear generalizations of the linear technique of principal components analysis [ Chatfield and Collins, 1980 ] . Such a learning procedure allows the weights for each color channel to be determined from red-green-blue (RGB) pixel inputs.
Reference: [ Navon, 1977 ] <author> D. Navon. </author> <title> Forest before trees: The precedence of global features in visual perception. </title> <journal> Cognitive Psychology, </journal> <volume> 9 </volume> <pages> 353-383, </pages> <year> 1977. </year>
Reference-contexts: This interpretation of the data is appealing in two aspects. First, it reflects a long history of observations on the priority of large scale channels in vision <ref> [ Navon, 1977; Breitmeyer, 1975; Parker and Dutch, 1987 ] </ref> , even though the reaction time differences between spatial frequencies may be quite small.
Reference: [ Niebur and Koch, 1996 ] <author> E. Niebur and C. Koch. </author> <title> Control of selective visual attention: Modeling the where pathway. </title> <editor> In D. Touretzky, M. Mozer, and M. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 802-808. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference: [ Noton and Stark, 1971 ] <author> D. Noton and L. Stark. </author> <title> Scanpaths in saccadic eye movements while viewing and recognizing patterns. </title> <journal> Vision Reseach, </journal> <volume> 11 </volume> <pages> 929-942, </pages> <year> 1971. </year>
Reference-contexts: It was proposed that the saccadic movements and their resultant fixations allowed the formation of a visual-motor memory (scan path) that could be used for encoding objects and scenes <ref> [ Noton and Stark, 1971 ] </ref> . However, a number of studies, starting from Yarbus' classical work [ Yarbus, 1967 ] , have suggested that gaze changes are most often directed according to the ongoing demands of the task at hand.
Reference: [ Nowlan, 1990 ] <author> S.J. Nowlan. </author> <title> Maximum likelihood competitive learning. </title> <editor> In D.S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 574-582. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year> <month> 32 </month>
Reference-contexts: For example, a set of basis functions can be learned by using a soft form of the competitive learning rule <ref> [ Yair et al., 1992; Nowlan, 1990 ] </ref> . For a given input, each weight vector (basis function), encoding the synaptic strength from the inputs to an output unit in a feedforward neural network, is adapted towards the input vector in proportion to its similarity with the input vector. <p> This generalizes the more frequently used winner-take-all form of competitive learning [ Grossberg, 1976; Rumelhart and Zipser, 1986 ] , where only the most similar weight vector is modified. It has been noted that the soft competitive learning rule performs maximum likelihood estimation <ref> [ Nowlan, 1990 ] </ref> and generates piece-wise approximations to the principal surfaces of data distributions [ Mulier and Cherkassky, 1995; Ritter et al., 1992 ] ; these surfaces are nonlinear generalizations of the linear technique of principal components analysis [ Chatfield and Collins, 1980 ] . <p> The initial fixation point is denoted by `+'. (b) depicts a summary of such movements over many target-present search trials as a function of the six possible locations of a target object on the table. 3. The most likely target location was computed using a soft form of competition <ref> [ Nowlan, 1990 ] </ref> according to a saliency-based weighted averaging scheme rather than a pure winner-take-all mechanism. <p> For the experiments, we used: F (S (x; y)) = P This choice is attractive since it allows an interpretation of the search algorithm as computing maximum likelihood estimates (cf. <ref> [ Nowlan, 1990 ] </ref> ) of target locations. In the above, (k) is a temperature parameter that is decreased with k.
Reference: [ Olshausen and Field, 1996 ] <author> B.A. </author> <title> Olshausen and D.J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. </title> <journal> Nature, </journal> <volume> 381 </volume> <pages> 607-609, </pages> <year> 1996. </year>
Reference: [ Olshausen et al., 1993 ] <author> B.A. Olshausen, D.C. Van Essen, and C.H. Anderson. </author> <title> A neurobiolog-ical model of visual attention and invariant pattern recognition based on dynamic routing of information. </title> <journal> Journal of Neuroscience, </journal> <volume> 13 </volume> <pages> 4700-4719, </pages> <year> 1993. </year>
Reference: [ Oram and Perrett, 1992 ] <author> M.W. Oram and D.I. Perrett. </author> <title> Time course of neural responses discriminating different views of the face and head. </title> <journal> Journal of Neurophysiology, </journal> <volume> 68(1) </volume> <pages> 70-84, </pages> <year> 1992. </year>
Reference-contexts: Speed: Targets must be computed quickly in order to model observed human performance. Using millisecond neural circuitry, the targets for the next fixation need to be computed in approximately 80-100 milliseconds, allowing barely one pass through the cortex <ref> [ Thorpe and Imbert, 1989; Oram and Perrett, 1992 ] </ref> . 3.
Reference: [ O'Regan, 1990 ] <author> J.K. O'Regan. </author> <title> Eye movements and reading. </title> <editor> In E. Kowler, editor, </editor> <booktitle> Eye Movements and Their Role in Visual and Cognitive Processes, </booktitle> <pages> pages 455-477. </pages> <address> New York: </address> <publisher> Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: However, a number of studies, starting from Yarbus' classical work [ Yarbus, 1967 ] , have suggested that gaze changes are most often directed according to the ongoing demands of the task at hand. The task-specific use of gaze is best understood for reading text <ref> [ O'Regan, 1990 ] </ref> where the eyes fixate almost every word, sometimes skipping over small function words. In addition, it is known that saccade size during reading is modulated according to the specific nature of the pattern recognition task at hand [ Kowler and Anton, 1987 ] .
Reference: [ Palmer et al., 1991 ] <author> L.A. Palmer, J.P. Jones, and R.A. Stepnoski. </author> <title> Striate receptive fields as linear filters: Characterization in two dimensions of space. In A.G. Leventhal, editor, </title> <booktitle> The Neural Basis of Visual Function, </booktitle> <pages> pages 246-265. </pages> <address> Boca Raton: </address> <publisher> CRC Press, </publisher> <year> 1991. </year>
Reference: [ Parker and Dutch, 1987 ] <author> D.M. Parker and S. </author> <title> Dutch. Perceptual latency and spatial frequency. </title> <journal> Vision Research, </journal> <volume> 27 </volume> <pages> 1279-1283, </pages> <year> 1987. </year>
Reference-contexts: This interpretation of the data is appealing in two aspects. First, it reflects a long history of observations on the priority of large scale channels in vision <ref> [ Navon, 1977; Breitmeyer, 1975; Parker and Dutch, 1987 ] </ref> , even though the reaction time differences between spatial frequencies may be quite small.
Reference: [ Posner and Petersen, 1990 ] <author> M.I. Posner and S.E. Petersen. </author> <title> The attention system of the human brain. </title> <journal> Annual Review of Neuroscience, </journal> <volume> 13 </volume> <pages> 25-42, </pages> <year> 1990. </year>
Reference: [ Pouget and Sejnowski, 1995 ] <author> A. Pouget and T.J. Sejnowski. </author> <title> Spatial representations in the parietal cortex may use basis functions. </title> <editor> In D.S. Touretzky and T.K. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 7, </booktitle> <pages> pages 157-164. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: For single targets, a variable unit encoding can be used, wherein the firing rate is proportional to 26 a scalar parameter pertaining to the encoded target. These ideas motivate the notion of gain fields or basis fields <ref> [ Pouget and Sejnowski, 1995; Salinas and Abbott, 1996 ] </ref> that have proved useful in modeling neuronal responses in the parietal cortex [ Andersen et al., 1985 ] , where head coordinates are encoded with a variable unit strategy, but target coordinates are encoded with punctate value unit receptive fields.
Reference: [ Rao and Ballard, 1995a ] <author> R.P.N. Rao and D.H. Ballard. </author> <title> An active vision architecture based on iconic representations. </title> <journal> Artificial Intelligence (Special Issue on Vision), </journal> <volume> 78 </volume> <pages> 461-505, </pages> <year> 1995. </year>
Reference-contexts: The high-dimensionality of the vectors makes them remarkably robust to noise due to the orthogonality inherent in high-dimensional spaces: given any vector, almost all of the other vectors in the space tend to be relatively uncorrelated with the given vector <ref> [ Kanerva, 1988; Rao and Ballard, 1995a ] </ref> , and almost none are identical with respect to each other. The result is that the filter response vector for a given point is unique for all practical purposes and can therefore be used to define search targets. <p> The result is that the filter response vector for a given point is unique for all practical purposes and can therefore be used to define search targets. This property also makes the filter template robust to partial occlusions, which commonly occur in natural viewing (see <ref> [ Rao and Ballard, 1995a ] </ref> for some examples). <p> Drastic rotations are handled by storing feature vectors from different views. The multiscale representation also allows interpolation strategies for scale invariance. We refer the interested reader to <ref> [ Rao and Ballard, 1995a ] </ref> for more details. 7 vector for a selected target point in the dining table scene (Figure 5 (b)) and all other points in the scene is shown for single scale response vectors (a) and multiple scale vectors (b). <p> Only one point (the target point) has a correlation greater than 0:94 (demarcated by an arrow) in the multiple scale case (b) whereas 936 candidate points fall in this category in the single scale case (a). 3 Modeling Visual Search We have argued elsewhere <ref> [ Rao and Ballard, 1995a; Ballard et al., 1997 ] </ref> that visual behavior can be viewed as task-specific compositions of visual routines [ Ullman, 1984 ] . In particular, visual behaviors can be composed using two different types of visual routines. <p> An oculomotor process that accepts retinotopic target locations from the where process and executes a saccade to the target location (a method for learning this sensorimotor mapping is given in [ Rao and Ballard, 1995b ] ). 1 This is essentially the identification visual routine, described in greater detail in <ref> [ Rao and Ballard, 1995a ] </ref> . 8 We assume that these processes are running concurrently. The oculomotor process will continue to be execute eye movements as long as the decision process has not terminated, using the current best guess of target location as computed by the targeting process.
Reference: [ Rao and Ballard, 1995b ] <author> R.P.N. Rao and D.H. Ballard. </author> <title> Learning saccadic eye movements using multiscale spatial filters. </title> <editor> In G. Tesauro, D.S. Touretzky, and T.K. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 7, </booktitle> <pages> pages 893-900. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: An oculomotor process that accepts retinotopic target locations from the where process and executes a saccade to the target location (a method for learning this sensorimotor mapping is given in <ref> [ Rao and Ballard, 1995b ] </ref> ). 1 This is essentially the identification visual routine, described in greater detail in [ Rao and Ballard, 1995a ] . 8 We assume that these processes are running concurrently.
Reference: [ Rao and Ballard, 1997a ] <author> R.P.N. Rao and D.H. Ballard. </author> <title> A computational model of spatial representations that explains object-centered neglect in parietal patients. </title> <editor> In J. Bower, editor, </editor> <booktitle> Computation Neuroscience 1996. </booktitle> <address> New York, NY: </address> <publisher> Plenum Press, </publisher> <year> 1997. </year>
Reference-contexts: The transformation T os is also assumed to be represented in parietal cortex, with each half in a separate hemisphere. This model is elaborated in greater detail in <ref> [ Rao and Ballard, 1997a ] </ref> , where it is used to explain various forms of object-centered neglect in patients with parietal lesions. To demonstrate the spatial memory model, we picked a problem that recurs often in the blocks copying task. <p> The third, which is the composition of the other two, describes how objects are transformed with respect to the retina (T or ). In our model, T sr is updated with eye movements (in general, head and body movements <ref> [ Rao and Ballard, 1997a ] </ref> ), so that the current retinal location of a target memorized in scene-centered coordinates can always be obtained by combining T os and T sr . 23 contain yellow blocks, but, in addition, the region denoting the resource area in the object frame is used
Reference: [ Rao and Ballard, 1997b ] <author> R.P.N. Rao and D.H. Ballard. </author> <title> Dynamic model of visual recognition predicts neural response properties in the visual cortex. </title> <journal> Neural Computation, </journal> <volume> 9 </volume> <pages> 805-847, </pages> <year> 1997. </year> <month> 33 </month>
Reference: [ Rao et al., 1996 ] <author> R.P.N. Rao, G.J. Zelinsky, M.M. Hayhoe, and D.H. Ballard. </author> <title> Modeling saccadic targeting in visual search. </title> <editor> In D. Touretzky, M. Mozer, and M. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 830-836. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference: [ Rimey and Brown, 1991 ] <author> R. D. Rimey and C. M. Brown. </author> <title> Controlling eye movements with hidden Markov models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(1) </volume> <pages> 47-65, </pages> <year> 1991. </year>
Reference: [ Ritter et al., 1992 ] <author> H. Ritter, T. Martinetz, and K. Schulten. </author> <title> Neural Computation and Self-Organizing Maps: An Introduction. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: It has been noted that the soft competitive learning rule performs maximum likelihood estimation [ Nowlan, 1990 ] and generates piece-wise approximations to the principal surfaces of data distributions <ref> [ Mulier and Cherkassky, 1995; Ritter et al., 1992 ] </ref> ; these surfaces are nonlinear generalizations of the linear technique of principal components analysis [ Chatfield and Collins, 1980 ] . Such a learning procedure allows the weights for each color channel to be determined from red-green-blue (RGB) pixel inputs.
Reference: [ Rumelhart and Zipser, 1986 ] <author> D. E. Rumelhart and D. Zipser. </author> <title> Feature discovery by competitive learning. </title> <editor> In D.E. Rumelhart, J.L. McClelland, and the PDP Research Group, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> volume 2, </volume> <pages> pages 151-193. </pages> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: This generalizes the more frequently used winner-take-all form of competitive learning <ref> [ Grossberg, 1976; Rumelhart and Zipser, 1986 ] </ref> , where only the most similar weight vector is modified.
Reference: [ Rybak et al., 1997 ] <institution> I.A. Rybak, V.I. </institution> <address> Gusakova, A.V. Golovan, L.N. </address> <month> Podladchikova, </month> <title> and N.A. Shevtsova. A model of attention-guided visual perception and recognition. </title> <note> Submitted to Vision Research, </note> <year> 1997. </year>
Reference: [ Saarinen and Julesz, 1991 ] <author> J. Saarinen and B. Julesz. </author> <title> The speed of attentional shifts in the visual field. </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 88 </month> <pages> 1812-1814, </pages> <year> 1991. </year>
Reference-contexts: Some of the search results have suggested that targets can be examined at the rate of about 25 milliseconds per item, with the attentional spotlight moving from one location to the next at a speed of about one attentional shift every 30-50 milliseconds <ref> [ Krose and Julesz, 1989; Saarinen and Julesz, 1991 ] </ref> . Models of attention (for example, [ Niebur 27 and Koch, 1996 ] ) have in fact literally modeled this shift of the focus of attention.
Reference: [ Salinas and Abbott, 1996 ] <author> E. Salinas and L.F. Abbott. </author> <title> Transfer of coded information from sensory to motor networks. </title> <journal> Journal of Neuroscience, </journal> <volume> 15 </volume> <pages> 6461-6474, </pages> <year> 1996. </year>
Reference-contexts: For single targets, a variable unit encoding can be used, wherein the firing rate is proportional to 26 a scalar parameter pertaining to the encoded target. These ideas motivate the notion of gain fields or basis fields <ref> [ Pouget and Sejnowski, 1995; Salinas and Abbott, 1996 ] </ref> that have proved useful in modeling neuronal responses in the parietal cortex [ Andersen et al., 1985 ] , where head coordinates are encoded with a variable unit strategy, but target coordinates are encoded with punctate value unit receptive fields.
Reference: [ Shepherd et al., 1986 ] <author> M. Shepherd, J. Findlay, and R. Hockey. </author> <title> The relationship between eye movements and spatial attention. </title> <journal> Quarterly Journal of Exp. Psychology, </journal> <volume> 38A:475-491, </volume> <year> 1986. </year>
Reference-contexts: Such an interpretation is especially attractive since it allows a single targeting mechanism to parsimoniously account for both covert and overt search. It is also consistent with the conclusions of both <ref> [ Shepherd et al., 1986 ] </ref> and [ Groner, 1988 ] suggesting that the attentional and saccadic system are regulated by different but closely related oculomotor control systems. Acknowledgments This work was supported by NSF research grant no.
Reference: [ Tanenhaus et al., 1995 ] <editor> M.K. Tanenhaus, M.J. Spivey-Knowlton, K.M. Eberhard, and J.E. Sedivy. </editor> <title> Integration of visual and linguistic information in spoken language comprehension. </title> <journal> Science, </journal> <volume> 268 </volume> <pages> 632-634, </pages> <year> 1995. </year>
Reference-contexts: In natural language processing, there is recent evidence that fixations reflect the instantaneous parsing of a spoken sentence <ref> [ Tanenhaus et al., 1995 ] </ref> . The role of gaze has been studied by [ Land and Furneaux, 1997 ] in a variety of other visuo-motor tasks such as driving, music reading and playing ping pong.
Reference: [ Thorpe and Imbert, 1989 ] <author> S.J. Thorpe and M. Imbert. </author> <title> Biological contraints on connectionist mod-elling. </title> <editor> In R. Pfeifer, Z. Schreter, F. Fogelman-Soulie, and L.Steels, editors, </editor> <booktitle> Connectionism in Perspective, </booktitle> <pages> pages 63-92. </pages> <address> Amsterdam: </address> <publisher> Elsevier, </publisher> <year> 1989. </year>
Reference-contexts: Speed: Targets must be computed quickly in order to model observed human performance. Using millisecond neural circuitry, the targets for the next fixation need to be computed in approximately 80-100 milliseconds, allowing barely one pass through the cortex <ref> [ Thorpe and Imbert, 1989; Oram and Perrett, 1992 ] </ref> . 3.
Reference: [ Treisman, 1988 ] <author> A. Treisman. </author> <title> Features and objects: The fourteenth Bartlett memorial lecture. </title> <journal> The Quarterly Journal of Experimental Psychology, </journal> <volume> 40(2) </volume> <pages> 201-237, </pages> <year> 1988. </year> <month> 34 </month>
Reference: [ Treismann and Gelade, 1980 ] <author> A. Treismann and G. Gelade. </author> <title> A feature-integration theory of atten-tion. </title> <journal> Cognitive Psychology, </journal> <volume> 12 </volume> <pages> 97-136, </pages> <year> 1980. </year>
Reference: [ Tsioutsias and Mjolsness, 1996 ] <author> D.I. Tsioutsias and E. Mjolsness. </author> <title> A multiscale attentional framework for relaxation neural networks. </title> <editor> In D. Touretzky, M. Mozer, and M. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 633-639. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference: [ Tsotsos et al., 1995 ] <author> J.K. Tsotsos, S.M. Culhane, W.Y.K. Wai, Y. Lai, N. Davis, and F. Nuflo. </author> <title> Modeling visual attention via selective tuning. </title> <journal> Artificial Intelligence (Special Issue on Vision), </journal> <volume> 78 </volume> <pages> 507-545, </pages> <year> 1995. </year>
Reference: [ Ullman, 1984 ] <author> S. Ullman. </author> <title> Visual routines. </title> <journal> Cognition, </journal> <volume> 18 </volume> <pages> 97-160, </pages> <year> 1984. </year>
Reference-contexts: in the multiple scale case (b) whereas 936 candidate points fall in this category in the single scale case (a). 3 Modeling Visual Search We have argued elsewhere [ Rao and Ballard, 1995a; Ballard et al., 1997 ] that visual behavior can be viewed as task-specific compositions of visual routines <ref> [ Ullman, 1984 ] </ref> . In particular, visual behaviors can be composed using two different types of visual routines. One class of routines computes allocentric properties of the visual image near the fovea (what). The other subserves the function of locating a previously memorized prototype anywhere on the retina (where).
Reference: [ Wolfe et al., 1989 ] <author> J. Wolfe, K. Cave, and S. Franzel. </author> <title> Guided search: An alternative to the feature integration model for visual search. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 15 </volume> <pages> 419-433, </pages> <year> 1989. </year>
Reference: [ Wolfe, 1996 ] <author> J.M. Wolfe. </author> <title> Visual search. </title> <editor> In H. Pashler, editor, Attention. </editor> <address> London, UK: </address> <publisher> University College London Press, </publisher> <year> 1996. </year>
Reference-contexts: There are two remaining possibilities: (a) the resolution fall-off in the cortex is different from the retinal variation in a way that supports the data (cf. experiments on the useful field of view <ref> [ Wolfe, 1996 ] </ref> ), or (b) the cortical machinery is set up to match the larger scales first as target information is propagated via cortico-cortical feedback from higher to lower areas in the visual cortical hierarchy (Section 3).
Reference: [ Yair et al., 1992 ] <author> E. Yair, K. Zeger, and A. Gersho. </author> <title> Competitive learning and soft competition for vector quantizer design. </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 40(2) </volume> <pages> 294-309, </pages> <year> 1992. </year>
Reference-contexts: For example, a set of basis functions can be learned by using a soft form of the competitive learning rule <ref> [ Yair et al., 1992; Nowlan, 1990 ] </ref> . For a given input, each weight vector (basis function), encoding the synaptic strength from the inputs to an output unit in a feedforward neural network, is adapted towards the input vector in proportion to its similarity with the input vector.
Reference: [ Yamada and Cottrell, 1995 ] <author> K. Yamada and G.W. Cottrell. </author> <title> A model of scan paths applied to face recognition. </title> <booktitle> In Proc. 17th Annual Conf. of the Cognitive Science Society, </booktitle> <pages> pages 55-60, </pages> <year> 1995. </year>
Reference: [ Yarbus, 1967 ] <author> A. Yarbus. </author> <title> Eye Movements and Vision. </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1967. </year>
Reference-contexts: It was proposed that the saccadic movements and their resultant fixations allowed the formation of a visual-motor memory (scan path) that could be used for encoding objects and scenes [ Noton and Stark, 1971 ] . However, a number of studies, starting from Yarbus' classical work <ref> [ Yarbus, 1967 ] </ref> , have suggested that gaze changes are most often directed according to the ongoing demands of the task at hand.
Reference: [ Young, 1985 ] <author> R.A. Young. </author> <title> The Gaussian derivative theory of spatial vision: Analysis of cortical cell receptive field line-weighting profiles. </title> <journal> General Motors Research Publication GMR-4920, </journal> <year> 1985. </year>
Reference: [ Zelinsky et al., 1996 ] <author> G.J. Zelinsky, R.P.N. Rao, M.M. Hayhoe, and D.H. Ballard. </author> <title> Eye movements reveal the spatio-temporal dynamics of visual search. </title> <journal> Psychological Science, </journal> <note> 1996. In review. 35 </note>
Reference-contexts: For remembered targets, additional spatial information in scene-centered coordinates can be used to speed up the target computation (Section 6). Eye movements predicted by the model were compared to actual eye movements made by human subjects in two visual tasks. In the first task <ref> [ Zelinsky et al., 1996 ] </ref> involving visual search, subjects were shown an image of a realistic object and then asked to report, as quickly and accurately as possible, if it was present in a subsequent image containing one to five similar objects (Section 4). 2 Another [ Ballard et al., <p> be accounted for by a slight change in the model. 10 4 Comparing the Model to Experimental Data In order to validate the simple winner-take-all targeting model described in the previous section, eye movements from four human subjects were recorded for the following search task, described in more detail in <ref> [ Zelinsky et al., 1996 ] </ref> . Subjects were asked to fixate a point near the bottom of a 12 fi 16 degree display. They were given a one second preview of an image containing a single object (e.g. a tool) at the fixation point. <p> This skipping of the saccades in this search paradigm was unexpected but proved to be an extraordinarily robust finding, occurring in almost all trials across all four subjects <ref> [ Zelinsky et al., 1996 ] </ref> . <p> Additional effects were seen by comparing color and grayscale searches after additional saccades. These were most apparent for the search scenes containing five objects. After the second saccade, the endpoint error was a full one degree lesser in the case of color images <ref> [ Zelinsky et al., 1996 ] </ref> , strongly suggesting that color information is being used in the targeting computation. Although the simulation results described in this section modeled human eye movement data from grayscale images, the model can be readily extended for saccadic targeting based on color information. <p> Under certain circumstances, express saccades are also observed [ Fischer and Boch, 1983; Fischer and Ramsperger, 1984; Fischer and Weber, 1993 ] . The fixation periods for express saccades are much shorter, in the range 70 100 milliseconds. An analysis of the visual search results <ref> [ Zelinsky et al., 1996 ] </ref> revealed that the fixation periods of some of the center-of-gravity skipping eye movements are much smaller than normal (around 80-130 milliseconds), small enough to qualify them as express saccades.
References-found: 85

