URL: ftp://ftp.cs.rochester.edu/pub/u/fuentes/smc.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Email: e-mail: ffuentes,rao,vanwieg@cs.rochester.edu  
Title: Hierarchical Learning of Reactive Behaviors in an Autonomous Mobile Robot  
Author: Olac Fuentes, Rajesh P. N. Rao and Michael Van Wie 
Address: Rochester, New York 14627, USA  
Affiliation: Computer Science Department University of Rochester  
Abstract: We describe an autonomous mobile robot that employs a simple sensorimotor learning algorithm at three different behavioral levels to achieve coherent goal-directed behavior. The robot autonomously navigates to a goal destination within an obstacle-ridden environment by using the learned behaviors of obstacle-detection, obstacle-avoidance, and beacon-following. These reactive behaviors are learned in a hierarchical manner by using a hillclimbing routine that attempts to find the optimal transfer function from perceptions to actions for each behavior. We present experimental results that show that each behavior was successfully learned by the robot within a reasonably short period of time. We conclude by discussing salient features of our approach and possible directions for future research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1) </volume> <pages> 14-22, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: In such cases, it is our belief that hierarchical behavior-based decomposition of the control architecture, as originally suggested by Brooks <ref> [1] </ref>, can simplify the task of programming complex systems. In addition, it is desirable in many cases to endow the robot with the ability to adapt its constituent behaviors on-line in response to environmental stimuli by allowing it to learn autonomously the transfer function mapping sensory input into motor commands. <p> This approach is reminiscent of Brooks's sub-sumption architecture <ref> [1] </ref>. Figure 3 illustrates our robot's three-level hierarchical architecture. Hierarchical partitioning of the sensory space allows the robot to learn the sensorimotor mapping that corresponds to each layer independent of the other layers.
Reference: [2] <author> M. Colombetti and M. Dorigo. </author> <title> Learning to control an autonomous robot by distributed genetic algorithms. </title> <editor> In J. A. Meyer, H. Roitblat, and S. Wil-son, editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the Second International Conference on the Simulation of Adaptive Behavior, </booktitle> <pages> pages 305-312. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <month> December </month> <year> 1992. </year>
Reference-contexts: Since we only keep in memory a policy that encodes a series of statements of the form perception ! action, the method can be implemented using little memory. This is in contrast to some machine learning techniques recently applied to mobile robotics (for example, genetic programming [5], genetic algorithms <ref> [2] </ref>, reinforcement learning [3], and neural networks [4]) that usually require the storage of considerable amounts of information. Let A be the set of discrete actions that the robot can perform, and P be the set of relevant perceptions that the robot can obtain from its sensors.
Reference: [3] <author> D. Gachet, M. Salchis, L. Moreno, and J. R. Pimentel. </author> <title> Learning emergent tasks for an autonomous mobile robot. </title> <booktitle> In IEEE/RSJ International Conference on Intelligent Robots an Systems, </booktitle> <pages> pages 290-297, </pages> <year> 1994. </year>
Reference-contexts: This is in contrast to some machine learning techniques recently applied to mobile robotics (for example, genetic programming [5], genetic algorithms [2], reinforcement learning <ref> [3] </ref>, and neural networks [4]) that usually require the storage of considerable amounts of information. Let A be the set of discrete actions that the robot can perform, and P be the set of relevant perceptions that the robot can obtain from its sensors.
Reference: [4] <author> B. J. A. Krose and M. Eecen. </author> <title> A self-organizing representation of sensor space for mobile robot navigation. </title> <booktitle> In IEEE/RSJ International Conference on Intelligent Robots an Systems, </booktitle> <pages> pages 9-14, </pages> <year> 1994. </year>
Reference-contexts: This is in contrast to some machine learning techniques recently applied to mobile robotics (for example, genetic programming [5], genetic algorithms [2], reinforcement learning [3], and neural networks <ref> [4] </ref>) that usually require the storage of considerable amounts of information. Let A be the set of discrete actions that the robot can perform, and P be the set of relevant perceptions that the robot can obtain from its sensors.
Reference: [5] <author> M. A. Lewis, A. H. Fagg, and A. Solidum. </author> <title> Genetic programming approach to the construction of a neural network for control of a walking robot. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: Since we only keep in memory a policy that encodes a series of statements of the form perception ! action, the method can be implemented using little memory. This is in contrast to some machine learning techniques recently applied to mobile robotics (for example, genetic programming <ref> [5] </ref>, genetic algorithms [2], reinforcement learning [3], and neural networks [4]) that usually require the storage of considerable amounts of information. Let A be the set of discrete actions that the robot can perform, and P be the set of relevant perceptions that the robot can obtain from its sensors.
Reference: [6] <author> P. Maes and R. A. Brooks. </author> <title> Learning to coordinate behaviors. </title> <booktitle> In Proceedings of the 1990 AAAI Conference, </booktitle> <year> 1990. </year>
Reference-contexts: We believe such decompositions can be found for most complex tasks. The algorithm's quick convergence and low resource requirements make it ideal for implementation on real robots. Possible future work includes further experiments regarding integration of additional behaviors and autonomous learning of coordination among behaviors <ref> [6] </ref>.
Reference: [7] <author> D. Pierce and B. Kuipers. </author> <title> Learning hill-climbing functions as a strategy for generating behaviors in a mobile robot. </title> <booktitle> In From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 327-336, </pages> <year> 1991. </year>
Reference-contexts: For even moderately complex tasks and/or robots, the high dimensionality of the sensorimotor space makes learning difficult. One commonly used approach to make robot learning feasible despite the high dimensionality of the sensory space is to run the learning algorithm on a simulated environment (for example, <ref> [7] </ref>). However, in many situations, it is difficult or impossible to gather enough knowledge about the robot and its environment to build an accurate simulation. Moreover, some physical events, such as collisions, are difficult to simulate even when we have accurate knowledge of our environment.
References-found: 7

