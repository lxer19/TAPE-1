URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/89.TR311.Psyche_VM.ps.Z
Refering-URL: http://www.cs.rochester.edu/trs/systems-trs.html
Root-URL: 
Email: leblanc@cs.rochester.edu marsh@cs.rochester.edu scott@cs.rochester.edu  
Title: MEMORY MANAGEMENT FOR LARGE-SCALE NUMA MULTIPROCESSORS  
Author: Thomas J. LeBlanc Brian D. Marsh Michael L. Scott 
Note: This work was supported in part by NSF CER grant number DCR-8320136 and Darpa/ETL contract number DACA76-85-C-0001.  
Date: March 1989  
Address: Rochester, New York 14627  
Affiliation: Computer Science Department University of Rochester  
Abstract: Large-scale shared-memory multiprocessors such as the BBN Butterfly and IBM RP3 introduce a new level in the memory hierarchy: multiple physical memories with different memory access times. An operating system for these NUMA (NonUniform Memory Access) multiprocessors should provide traditional virtual memory management, facilitate dynamic and widespread memory sharing, and minimize the apparent disparity between local and nonlocal memory. In addition, the implementation must be scalable to configurations with hundreds or thousands of processors. This paper describes memory management in the Psyche multiprocessor operating system, under development at the University of Rochester. The Psyche kernel manages a multi-level memory hierarchy consisting of local memory, nonlocal memory, and backing store. Local memory stores private data and serves as a cache for shared data; nonlocal memory stores shared data and serves as a disk cache. The system structure isolates the policies and mechanisms that manage different layers in the memory hierarchy, so that customized data structures and policies can be constructed for each layer. Local memory management policies are implemented using mechanisms that are independent of the architectural configuration; global policies are implemented using multiple processes that increase in number as the architecture scales. Psyche currently runs on the BBN Butterfly Plus multiprocessor. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh
Abstract-found: 1
Intro-found: 1
Reference: 1. <institution> BBN Advanced Computers Inc., Inside the Butterfly Plus, </institution> <month> Oct </month> <year> 1987. </year>
Reference-contexts: 1. Introduction Large-scale, shared-memory multiprocessors with hundreds or thousands of processing nodes offer tremendous computing potential. This potential remains largely unrealized, due in part to the complexity of managing shared memory. NUMA (NonUniform Memory Access) architectures such as the BBN Butterfly <ref> [1] </ref> and IBM RP3 [17] further complicate matters by introducing a new level in the memory hierarchy: multiple physical memories with different memory access times.
Reference: 2. <author> O. Babaoglu and W. Joy, </author> <title> ``Converting a Swap-Based System to do Paging in an Architecture Lacking PageReferenced Bits,'' </title> <booktitle> Proc. 8th ACM Symp. on Operating System Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> Dec </month> <year> 1981, </year> <pages> pp. 78-86. </pages>
Reference-contexts: However, as the only hardware protection mechanism provided by most architectures and the sole indicator of dynamic memory reference patterns, memory mappings 4 are often used to serve other purposes as well. For example, in BSD Unix, invalid page mappings are used to simulate reference bits <ref> [2] </ref>. In the Apollo Aegis system, memory management is used to implement a single-level store, thereby unifying memory and backing store [14]. Accent [10] and Mach [21] use memory mapping techniques to implement efficient communication, employing copy-on-write to avoid multiple physical copies of messages. <p> The Clock algorithm requires that we maintain reference information for each page. Although this task is straightforward on a uniprocessor that supports reference bits, and is even feasible on a uniprocessor lacking hardware reference bits <ref> [2] </ref>, several complications arise in the multiprocessor environment. g Reference bits are associated with page table entries, and therefore record page map reference information, rather than page reference information. In a typical uniprocessor environment, where each page is mapped by a single page table entry, this distinction is not important.
Reference: 3. <author> D. Black, R. Rashid, D. Golub, C. Hill and R. Baron, </author> <title> ``Translation Lookaside Buffer Consistency: A Software Approach,'' </title> <booktitle> Proc. of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Boston, MA, </address> <month> Apr </month> <year> 1989, </year> <pages> pp. 113-122. </pages>
Reference-contexts: Even if reference information is only computed for pages in local memory, page tables that map the page may be located anywhere in memory. In addition, translation lookaside buffer (TLB) entries may need to be flushed to maintain consistency with page table entries, introducing additional cost and complexity <ref> [3, 20] </ref>. g To minimize average memory access time on a NUMA multiprocessor, a logical page might be represented by many physical copies. Page reference information for the logical page must be synthesized from the reference information for the various copies.
Reference: 4. <author> W. J. Bolosky, R. P. Fitzgerald and M. L. Scott, </author> <title> ``Simple But Effective Techniques for NUMA Memory Management,'' </title> <booktitle> Proc. 12th ACM Symp. on Operating System Principles, </booktitle> <address> Litchfield, AZ, </address> <month> Dec </month> <year> 1989, </year> <pages> pp. 19-31. </pages>
Reference-contexts: Page migration can also be used with read-write pages, improving access time without the need for a consistency protocol. Efficient page migration and replication policies are currently under investigation <ref> [4, 11] </ref>. Here we will describe the mechanisms provided by the Psyche memory management system and the simple policy we have implemented. Any policy for effective page replication and migration requires extensive reference information. <p> A Mach implementation for a NUMA multiprocessor is expected to provide a uniform memory abstraction within the machine-dependent module. Mach implementations on the RP3 [5] and ACE multiprocessor workstation <ref> [4] </ref> exploit global memory to implement the uniform memory model; page allocation and reclamation are performed in the machine-independent portion of the kernel without regard to local policies.
Reference: 5. <author> R. Bryant, </author> <type> Private Communication, </type> <institution> RP3 Group, IBM T. J. Watson Research Center, </institution> <month> Mar </month> <year> 1989. </year>
Reference-contexts: The Mach pmap module exports a single uniform memory model; our NUMA layer exports a physical memory hierarchy, which is managed by the UMA layer. A Mach implementation for a NUMA multiprocessor is expected to provide a uniform memory abstraction within the machine-dependent module. Mach implementations on the RP3 <ref> [5] </ref> and ACE multiprocessor workstation [4] exploit global memory to implement the uniform memory model; page allocation and reclamation are performed in the machine-independent portion of the kernel without regard to local policies.
Reference: 6. <author> R. Campbell, V. Russo and G. Johnston, </author> <title> ``A Class Hierarchical Object-Oriented Approach to Virtual Memory Management in Multiprocessor Operating Systems,'' </title> <type> TR UIUCDCS-R-88-1459, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> Sept </month> <year> 1988. </year>
Reference-contexts: Copies that go unused locally are discovered by the local Clock daemon and freed by the global page daemon. Future references cause page faults, which trigger a new decision on page placement. 17 6. Related Work Several recent projects, including Mach [18], Symunix II [9], and Choices <ref> [6] </ref>, have addressed various aspects of the memory management problem for multiprocessors. None of these systems, however, has attempted to address the full range of issues in the scope of a single system. Mach emphasizes portability, Symunix II focuses on scalability, and Choices is designed for modularity.
Reference: 7. <author> R. Carr and J. Hennessy, </author> <title> ``WSClock A Simple and Effective Algorithm for Virtual Memory Management,'' </title> <booktitle> Proc. 8th ACM Symp. on Operating System Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> Dec </month> <year> 1981, </year> <pages> pp. 87-95. </pages>
Reference-contexts: When a need for physical memory on a particular node arises, the least-recently-used (LRU) page on that node is chosen for replacement. We use the Clock algorithm [8] to implement LRU 10 approximation. Clock is an example of a global page replacement algorithm <ref> [7] </ref>, in that the algorithm considers a page for replacement without regard to which process owns the page.
Reference: 8. <author> F. J. Corbato, </author> <title> ``A Paging Experiment with the Multics System,'' MIT Project MAC Report MAC-M-384, </title> <month> May </month> <year> 1968. </year>
Reference-contexts: Each processor node has a NUMA page daemon to manage its local memory. When a need for physical memory on a particular node arises, the least-recently-used (LRU) page on that node is chosen for replacement. We use the Clock algorithm <ref> [8] </ref> to implement LRU 10 approximation. Clock is an example of a global page replacement algorithm [7], in that the algorithm considers a page for replacement without regard to which process owns the page.
Reference: 9. <author> J. Edler, J. Lipkis and E. Schonberg, </author> <title> ``Memory Management in Symunix II: A Design for Large-Scale Shared Memory Multiprocessors,'' Ultracomputer Note #135, </title> <institution> Ultracomputer Research Laboratory, </institution> <address> New York University, </address> <month> Apr </month> <year> 1988. </year>
Reference-contexts: Copies that go unused locally are discovered by the local Clock daemon and freed by the global page daemon. Future references cause page faults, which trigger a new decision on page placement. 17 6. Related Work Several recent projects, including Mach [18], Symunix II <ref> [9] </ref>, and Choices [6], have addressed various aspects of the memory management problem for multiprocessors. None of these systems, however, has attempted to address the full range of issues in the scope of a single system. Mach emphasizes portability, Symunix II focuses on scalability, and Choices is designed for modularity.
Reference: 10. <author> R. Fitzgerald and R. F. Rashid, </author> <title> ``The Integration of Virtual Memory Management and Interprocess Communication in Accent,'' </title> <journal> ACM Transactions on Computer Systems 4, </journal> <month> 2 (May </month> <year> 1986), </year> <pages> pp. 147-177. </pages>
Reference-contexts: For example, in BSD Unix, invalid page mappings are used to simulate reference bits [2]. In the Apollo Aegis system, memory management is used to implement a single-level store, thereby unifying memory and backing store [14]. Accent <ref> [10] </ref> and Mach [21] use memory mapping techniques to implement efficient communication, employing copy-on-write to avoid multiple physical copies of messages. Kai Li has used memory management to implement a distributed shared memory [16].
Reference: 11. <author> R. J. Fowler and A. L. Cox, </author> <title> ``An Overview of PLATINUM: A Platform for Investigating Non Uniform Memory,'' </title> <type> TR 262, </type> <institution> Department of Computer Science, University of Rochester, </institution> <month> Nov </month> <year> 1988. </year>
Reference-contexts: Page migration can also be used with read-write pages, improving access time without the need for a consistency protocol. Efficient page migration and replication policies are currently under investigation <ref> [4, 11] </ref>. Here we will describe the mechanisms provided by the Psyche memory management system and the simple policy we have implemented. Any policy for effective page replication and migration requires extensive reference information. <p> Choices has been implemented on an UMA multiprocessor and is now being ported to a NORMA (No Remote Memory Access) multiprocessor (the Intel Hypercube); the particular problems presented by a NUMA multiprocessor have not been addressed. 18 Our work is complementary to the experimental Platinum kernel <ref> [11] </ref> in use at the University of Rochester. Platinum is not intended to be a complete operating system; it is a platform for investigating nonuniform memory management. Platinum implements an abstraction called coherent memory, which is implemented in software as an extension of a directory-based caching mechanism using invalidation.
Reference: 12. <author> M. A. Holliday, </author> <title> ``Reference History, Page Size, and Migration Daemons in Local/Remote Architectures,'' </title> <booktitle> Proc. of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Boston, MA, </address> <month> Apr </month> <year> 1989, </year> <pages> pp. 104-112. </pages>
Reference-contexts: Ideally, page usage information for each processor would be available. Although potentially expensive to maintain, approximate page usage statistics based on aging reference bits can result in substantially better policy decisions than single reference bits <ref> [12] </ref>. An alternative is to base page placement decisions on more recent information, such as the last reference to the page. Both short-term and long-term reference behavior can play a role in a global memory management policy. <p> Platinum is being used to empirically evaluate various migration and replication policies; we plan to incorporate the results of this evaluation into our UMA layer implementation. Our work can also exploit the results of simulation and policy studies for NUMA management performed at Duke <ref> [12, 13] </ref>. The simulation studies use software page tables and software address translation to study the effects of reference history, page size, and page table locking on NUMA management schemes.
Reference: 13. <author> R. P. LaRowe and C. S. Ellis, </author> <title> ``Virtual Page Placement Policies for NUMA Multiprocessors,'' </title> <type> TR CS-1990-10, </type> <institution> Department of Computer Science, Duke University, </institution> <month> Dec </month> <year> 1988. </year>
Reference-contexts: Platinum is being used to empirically evaluate various migration and replication policies; we plan to incorporate the results of this evaluation into our UMA layer implementation. Our work can also exploit the results of simulation and policy studies for NUMA management performed at Duke <ref> [12, 13] </ref>. The simulation studies use software page tables and software address translation to study the effects of reference history, page size, and page table locking on NUMA management schemes.
Reference: 14. <author> P. J. Leach, P. H. Levine, B. P. Douros, J. A. Hamilton, D. L. Nelson and B. L. Stumpf, </author> <title> ``The Architecture of an Integrated Local Network,'' </title> <journal> IEEE Journal on Selected Areas in 20 Communications SAC-1 5 (Nov 1983), </journal> <pages> pp. 842-857. </pages>
Reference-contexts: For example, in BSD Unix, invalid page mappings are used to simulate reference bits [2]. In the Apollo Aegis system, memory management is used to implement a single-level store, thereby unifying memory and backing store <ref> [14] </ref>. Accent [10] and Mach [21] use memory mapping techniques to implement efficient communication, employing copy-on-write to avoid multiple physical copies of messages. Kai Li has used memory management to implement a distributed shared memory [16].
Reference: 15. <author> S. J. Leffler, M. K. McKusick, M. J. Karels and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: In Psyche, local reference information is used and maintained by the NUMA page daemon, which runs when the available memory on a node falls below some threshold. The daemon executes a two-handed Clock algorithm <ref> [15] </ref> on the local core map to select a page to be replaced in the local memory. The core map contains node-local reference bits, which are set only if the page has been referenced locally.
Reference: 16. <author> K. Li, </author> <title> ``Shared Virtual Memory on Loosely Coupled Multiprocessors,'' </title> <booktitle> YALEU/International Conference on Distributed Computing Systems/RR-492 (Ph.D. Thesis), </booktitle> <institution> Department of Computer Science, Yale University, </institution> <month> Sept </month> <year> 1986. </year>
Reference-contexts: Accent [10] and Mach [21] use memory mapping techniques to implement efficient communication, employing copy-on-write to avoid multiple physical copies of messages. Kai Li has used memory management to implement a distributed shared memory <ref> [16] </ref>. As the role of the memory management system has expanded within the operating system, it has become increasingly important to structure the implementation to separate the disparate functions supported by the mapping hardware.
Reference: 17. <author> G. R. Pfister, W. C. Brantley, D. A. George, S. L. Harvey, W. J. Kleinfelder, K. P. McAuliffe, E. A. Melton, V. A. Norton and J. Weiss, </author> <title> ``The IBM Research Parallel Processor Prototype (RP3): Introduction and Architecture,'' </title> <booktitle> Proc. 1985 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> Aug </month> <year> 1985, </year> <pages> pp. 764-771. </pages>
Reference-contexts: 1. Introduction Large-scale, shared-memory multiprocessors with hundreds or thousands of processing nodes offer tremendous computing potential. This potential remains largely unrealized, due in part to the complexity of managing shared memory. NUMA (NonUniform Memory Access) architectures such as the BBN Butterfly [1] and IBM RP3 <ref> [17] </ref> further complicate matters by introducing a new level in the memory hierarchy: multiple physical memories with different memory access times. An operating system for NUMA multiprocessors should provide traditional virtual memory management, facilitate dynamic and wide-spread sharing, and minimize the apparent disparity between local and nonlocal memory.
Reference: 18. <author> R. Rashid, A. Tevanian, M. Young, D. Golub, R. Baron, D. Black, W. Bolosky and J. Chew, </author> <title> ``Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures,'' </title> <booktitle> Proc. of the 2nd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Palo Alto, CA, </address> <month> Oct </month> <year> 1987, </year> <pages> pp. 31-41. </pages>
Reference-contexts: As the role of the memory management system has expanded within the operating system, it has become increasingly important to structure the implementation to separate the disparate functions supported by the mapping hardware. For example, Mach separates the machine-dependent and machine-independent portions of the memory management system <ref> [18] </ref>, and the page replacement decision from the management of backing store [21]. To meet our goals of scalability, portability, and generality, we have extended this trend. 3.2. Layers The Psyche memory mangement system is structured into four layers of abstraction. <p> The PUMA (Psyche memory) layer implements the Psyche kernel interface. This layering is depicted in Figure 1. The NUMA layer isolates the machine-dependent portion of the memory management system by exporting an interface analogous to the pmap interface in Mach <ref> [18] </ref>. The NUMA layer defines two abstractions: NUMA pages and NUMA address spaces. The NUMA page size is a multiple of the physical page size. <p> The mappings for individual pages in the protection domain reside in the VUMA layer. Multiple copies of each page are described in the UMA layer. Multiple hardware page tables for each UMA address space are maintained in the NUMA layer. As in Mach <ref> [18] </ref>, we can discard information within a layer and use lazy evaluation to construct it. Whenever an invalid fault cannot be interpreted at a given layer, it is propagated to the next layer, which can reconstruct mappings in the lower layer. <p> Copies that go unused locally are discovered by the local Clock daemon and freed by the global page daemon. Future references cause page faults, which trigger a new decision on page placement. 17 6. Related Work Several recent projects, including Mach <ref> [18] </ref>, Symunix II [9], and Choices [6], have addressed various aspects of the memory management problem for multiprocessors. None of these systems, however, has attempted to address the full range of issues in the scope of a single system.
Reference: 19. <author> M. L. Scott, T. J. LeBlanc and B. D. Marsh, </author> <title> ``Evolution of an Operating System for Large Scale Shared-Memory Multiprocessors,'' </title> <type> TR 309, </type> <institution> Department of Computer Science, University of Rochester, </institution> <month> Mar </month> <year> 1989. </year>
Reference-contexts: No low-level layer takes advantage of Psychespecific abstractions, so changes in the kernel interface are localized in the implementation. No high-level layer takes advantage of particular hardware properties, enhancing portability. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 The evolution of the Psyche design is presented in a companion paper <ref> [19] </ref>. 3 We present a brief overview of Psyche in section 2, followed by a description of the memory management abstraction layers in section 3. We then describe how the various layers cooperate to implement virtual memory (section 4) and NUMA memory management (section 5). <p> We then describe how the various layers cooperate to implement virtual memory (section 4) and NUMA memory management (section 5). Related work and conclusions are discussed in sections 6 and 7. 2. Psyche Overview The Psyche programming model <ref> [19] </ref> is based on passive data abstractions called realms, which include both code and data. The code constitutes a protocol for manipulating the data and for scheduling threads of control. Invocation of protocol operations is the principal mechanism for accessing shared memory, thereby implementing interprocess communication.
Reference: 20. <author> P. J. Teller, R. Kenner and M. Snir, </author> <title> ``TLB Consistency on Highly-Parallel Shared-Memory Multiprocessors,'' </title> <booktitle> Proc. Twenty-First Annual Hawaii International Conference on System Science, </booktitle> <address> Kailua-Kona, HI, </address> <month> Jan </month> <year> 1988, </year> <pages> pp. 184-192. </pages>
Reference-contexts: Even if reference information is only computed for pages in local memory, page tables that map the page may be located anywhere in memory. In addition, translation lookaside buffer (TLB) entries may need to be flushed to maintain consistency with page table entries, introducing additional cost and complexity <ref> [3, 20] </ref>. g To minimize average memory access time on a NUMA multiprocessor, a logical page might be represented by many physical copies. Page reference information for the logical page must be synthesized from the reference information for the various copies.
Reference: 21. <author> M. Young, A. Tevanian, R. Rashid, D. Golub, J. Eppinger, J. Chew, W. Bolosky, D. Black and R. Baron, </author> <title> ``The Duality of Memory and Communication in the Implementation of a Multiprocessor Operating System,'' </title> <booktitle> Proc. 11th ACM Symp. on Operating System Principles, </booktitle> <address> Austin, TX, </address> <month> Nov </month> <year> 1987, </year> <pages> pp. 63-76. </pages>
Reference-contexts: For example, in BSD Unix, invalid page mappings are used to simulate reference bits [2]. In the Apollo Aegis system, memory management is used to implement a single-level store, thereby unifying memory and backing store [14]. Accent [10] and Mach <ref> [21] </ref> use memory mapping techniques to implement efficient communication, employing copy-on-write to avoid multiple physical copies of messages. Kai Li has used memory management to implement a distributed shared memory [16]. <p> For example, Mach separates the machine-dependent and machine-independent portions of the memory management system [18], and the page replacement decision from the management of backing store <ref> [21] </ref>. To meet our goals of scalability, portability, and generality, we have extended this trend. 3.2. Layers The Psyche memory mangement system is structured into four layers of abstraction. The NUMA (nonuniform memory) layer is responsible for local physical memory allocation and hardware page tables. <p> Two VUMA pages are resident in memory and their contents are contained in two UMA pages. Three VUMA pages are resident on backing store. A default system pager in the VUMA layer manages backing store for user programs. Psyche also allows users to define Mach-style external pagers <ref> [21] </ref> that manage backing store for an application. The VUMA layer propagates requests for VUMA pages backed by a user-defined pager to the PUMA layer, where communication with external pagers is implemented.
References-found: 21

