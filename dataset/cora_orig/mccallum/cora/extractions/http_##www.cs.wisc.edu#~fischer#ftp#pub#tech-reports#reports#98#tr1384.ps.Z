URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/reports/98/tr1384.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/reports/98/
Root-URL: http://www.cs.wisc.edu
Title: TECHNIQUES FOR SOFTWARE RENOVATION  
Author: By Michael Benjamin Siff 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science) at the  
Date: 1998  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Mart in Abadi and Luca Cardelli. </author> <title> A Theory of Objects. </title> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: More formally, if X O such that t ((X)) = X, then t 0 ( 0 (X)) = X where t 0 and 0 are the common-object and common-attribute relations, respectively, for context C 0 . 111 <ref> [1] </ref> A 0 A [3] while (O; A 0 ; R 0 ) is not well formed do [4] let x; y 2 O be such that (fxg) ( (fyg) [5] let a 2 A 0 be such that a 62 (fxg), a 2 (fyg) [6] A 0 A 0 [ <p> P and W are both initialized to the singleton set containing the atomic partition. The algorithm works by considering partitions from worklist W until W is empty. For each partition removed from W , new partitions are formed (when possible) by 114 <ref> [1] </ref> A covs (?) // the atomic partition [2] P fAg [4] while W 6= ; do [5] remove some p from W [6] for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) <p> Suppose we initialize an array of pointers to Points: Point p; ColorPoint cp; ... Point *A [2]; A [0] = &p; A <ref> [1] </ref> = (Point *)(&cp); /* upcast */ We can then use the following loop to print out each the contents of each point in the array: int i; int n; /* number of elements in A */ for (i=0; i &lt; n; i++) A [i]-&gt;print (A [i]); /* simulated virtual function <p> When A [i] actually points to a colorPoint the call A [i]-&gt;print (A [i]) is implicitly "downcasting" the argument. The execution of this loop is type safe, since the downcast is only performed when the pointer to the Point at A <ref> [1] </ref> is really pointing to a ColorPoint (that was assigned to A [1] via an upcast). 4.6 Formalizing Physical Subtypes In this section, we present our non-standard type system for C and formally define physical subtyping. <p> The execution of this loop is type safe, since the downcast is only performed when the pointer to the Point at A <ref> [1] </ref> is really pointing to a ColorPoint (that was assigned to A [1] via an upcast). 4.6 Formalizing Physical Subtypes In this section, we present our non-standard type system for C and formally define physical subtyping. <p> The execution of this loop is type safe, since the downcast is only performed when the pointer to a Point at A <ref> [1] </ref> is really pointing to a ColorPoint via an upcast. The example illustrates the utility of identifying downcasts, even if their type safety cannot be determined. It is another clue as to how classes, subclasses, and virtual functions might be extracted out of C programs. <p> The type system developed in this chapter has similarities with several type systems proposed by Cardelli <ref> [12, 13, 1] </ref>. The primary difference is that we take into account the physical layout of data types when determining subtype relationships, while in Cardelli's work the notion of physical layout does not apply. <p> This type system differs from the one employed in the generalization problem by allowing subtype polymorphism instead of parametric polymorphism. The type system is in some ways similar to other subtyping systems, 216 such as those in <ref> [12, 12, 1] </ref>, but is unique in that it focuses on the storage representation of struct and union types. The modularization process as applied to the C-to-C++ conversion problem can also be thought of as a type-inference problem: how to infer classes in C program.
Reference: [2] <author> B. L. Achee and Doris L. Carver. </author> <title> A greedy approach to object identification in imperative code. </title> <booktitle> In Third Workshop on Program Comprehension, </booktitle> <pages> pages 4-11, </pages> <year> 1994. </year>
Reference-contexts: The algorithm works by considering partitions from worklist W until W is empty. For each partition removed from W , new partitions are formed (when possible) by 114 [1] A covs (?) // the atomic partition <ref> [2] </ref> P fAg [4] while W 6= ; do [5] remove some p from W [6] for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p <p> The additional discriminatory power of the concept-analysis approach is due to the fact that it is able to exploit both positive and negative information. In contrast with the approach to identifying objects described in <ref> [2] </ref>, our technique is aimed at analyzing relationships among functions and types to identify classes. In [2], the aim is to identify objects that link functions to specific variables. <p> In contrast with the approach to identifying objects described in <ref> [2] </ref>, our technique is aimed at analyzing relationships among functions and types to identify classes. In [2], the aim is to identify objects that link functions to specific variables. <p> A similar effect can be achieved via concept analysis by introducing one attribute for each actual parameter. 136 There has been a certain amount of work involving the use of cluster analysis to identify potential modules (e.g., <ref> [33, 2, 39, 9] </ref>). This work (implicitly or explicitly) involves the identification of potential modules by determining a similarity measure among pairs of functions. <p> Suppose we initialize an array of pointers to Points: Point p; ColorPoint cp; ... Point *A <ref> [2] </ref>; A [0] = &p; A [1] = (Point *)(&cp); /* upcast */ We can then use the following loop to print out each the contents of each point in the array: int i; int n; /* number of elements in A */ for (i=0; i &lt; n; i++) A [i]-&gt;print
Reference: [3] <author> Alex Aiken. </author> <title> Set constraints: Results, applications, and future directions, </title> <note> 1994. http://http.cs.berkeley.edu/ aiken/ftp/ppcp94.ps. </note>
Reference-contexts: More formally, if X O such that t ((X)) = X, then t 0 ( 0 (X)) = X where t 0 and 0 are the common-object and common-attribute relations, respectively, for context C 0 . 111 [1] A 0 A <ref> [3] </ref> while (O; A 0 ; R 0 ) is not well formed do [4] let x; y 2 O be such that (fxg) ( (fyg) [5] let a 2 A 0 be such that a 62 (fxg), a 2 (fyg) [6] A 0 A 0 [ fag, where a is <p> The language used for the downcast-analysis problem could be a matched-parentheses language in which the open parentheses are upcasts and the closed parentheses are downcasts. * Constraint-based-type analyses <ref> [4, 3, 16] </ref>.
Reference: [4] <author> Alexander Aiken and Edward L. Wimmers. </author> <title> Type inclusion constraints and type inference, </title> <month> November </month> <year> 1993. </year> <note> http://http.cs.berkeley.edu/ aiken/ftp/fpca93.ps. </note>
Reference-contexts: such that t ((X)) = X, then t 0 ( 0 (X)) = X where t 0 and 0 are the common-object and common-attribute relations, respectively, for context C 0 . 111 [1] A 0 A [3] while (O; A 0 ; R 0 ) is not well formed do <ref> [4] </ref> let x; y 2 O be such that (fxg) ( (fyg) [5] let a 2 A 0 be such that a 62 (fxg), a 2 (fyg) [6] A 0 A 0 [ fag, where a is a new attribute [7] R 0 R 0 [ f (x; a)j (x; a) <p> The algorithm works by considering partitions from worklist W until W is empty. For each partition removed from W , new partitions are formed (when possible) by 114 [1] A covs (?) // the atomic partition [2] P fAg <ref> [4] </ref> while W 6= ; do [5] remove some p from W [6] for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c <p> The language used for the downcast-analysis problem could be a matched-parentheses language in which the open parentheses are upcasts and the closed parentheses are downcasts. * Constraint-based-type analyses <ref> [4, 3, 16] </ref>.
Reference: [5] <author> Ted. J. Biggerstaff and Alan J. Perlis, </author> <title> editors. Software Reusability Volume I: Concepts and Models. </title> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: Software reuse enables software engineers to save time (and often space) by using program components that are already implemented <ref> [5, 6] </ref>. Furthermore, using components and algorithms that have been tested before and are well understood not only save time in the present, but also save time later as there is less need to debug. There are several ways in which to achieve effective software reuse. <p> = X where t 0 and 0 are the common-object and common-attribute relations, respectively, for context C 0 . 111 [1] A 0 A [3] while (O; A 0 ; R 0 ) is not well formed do [4] let x; y 2 O be such that (fxg) ( (fyg) <ref> [5] </ref> let a 2 A 0 be such that a 62 (fxg), a 2 (fyg) [6] A 0 A 0 [ fag, where a is a new attribute [7] R 0 R 0 [ f (x; a)j (x; a) 62 R 0 g [8] endwhile 112 top (fcats; gibbons; dogs; dolphins; <p> The algorithm works by considering partitions from worklist W until W is empty. For each partition removed from W , new partitions are formed (when possible) by 114 [1] A covs (?) // the atomic partition [2] P fAg [4] while W 6= ; do <ref> [5] </ref> remove some p from W [6] for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 <p> The algorithm begins with the atomic partition (consisting of concepts, c 0 , c 1 , c 2 , and c 6 ) as the sole member of the worklist. The algorithm removes the atomic partition from the worklist, as p in line <ref> [5] </ref> of Figure 51. Suppose that in the first iteration of the for loop in line [6], c refers to c 0 . The covering set of c 0 is the singleton set consisting of c 4 , so c 0 is assigned c 4 in line [7].
Reference: [6] <author> Ted. J. Biggerstaff and Alan J. Perlis, </author> <title> editors. Software Reusability Volume II: Applications and Experience. </title> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: Software reuse enables software engineers to save time (and often space) by using program components that are already implemented <ref> [5, 6] </ref>. Furthermore, using components and algorithms that have been tested before and are well understood not only save time in the present, but also save time later as there is less need to debug. There are several ways in which to achieve effective software reuse. <p> context C 0 . 111 [1] A 0 A [3] while (O; A 0 ; R 0 ) is not well formed do [4] let x; y 2 O be such that (fxg) ( (fyg) [5] let a 2 A 0 be such that a 62 (fxg), a 2 (fyg) <ref> [6] </ref> A 0 A 0 [ fag, where a is a new attribute [7] R 0 R 0 [ f (x; a)j (x; a) 62 R 0 g [8] endwhile 112 top (fcats; gibbons; dogs; dolphins; humans; whalesg; ;) c 5 (fgibbons; dolphins; humans; whalesg; fintelligentg) c 4 (fcats; dogs; gibbonsg; <p> For each partition removed from W , new partitions are formed (when possible) by 114 [1] A covs (?) // the atomic partition [2] P fAg [4] while W 6= ; do [5] remove some p from W <ref> [6] </ref> for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g <p> The algorithm removes the atomic partition from the worklist, as p in line [5] of Figure 51. Suppose that in the first iteration of the for loop in line <ref> [6] </ref>, c refers to c 0 . The covering set of c 0 is the singleton set consisting of c 4 , so c 0 is assigned c 4 in line [7].
Reference: [7] <author> Frederick P. Brooks, Jr. </author> <title> The Mythical Man Month. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: The last decade or so has seen the gradual transition from C to C++ as the standard programming language for systems development. While companies recognize the superiority of object-oriented languages, particularly C++, for large system implementation and maintenance <ref> [7] </ref>, there is a plethora of large-scale legacy systems written in C that are actively used. These are difficult to maintain because of their size and complexity. The C-to-C++ conversion problem is also important because: - C++ is easier to maintain because it facilitates reuse and encapsulation. <p> 0 ; R 0 ) is not well formed do [4] let x; y 2 O be such that (fxg) ( (fyg) [5] let a 2 A 0 be such that a 62 (fxg), a 2 (fyg) [6] A 0 A 0 [ fag, where a is a new attribute <ref> [7] </ref> R 0 R 0 [ f (x; a)j (x; a) 62 R 0 g [8] endwhile 112 top (fcats; gibbons; dogs; dolphins; humans; whalesg; ;) c 5 (fgibbons; dolphins; humans; whalesg; fintelligentg) c 4 (fcats; dogs; gibbonsg; fhair-coveredg) c 7 (fdolphins, humans, whalesg; fnot hair-coveredg) c 3 (fgibbons, humans; fintelligent; <p> For each partition removed from W , new partitions are formed (when possible) by 114 [1] A covs (?) // the atomic partition [2] P fAg [4] while W 6= ; do [5] remove some p from W [6] for each c 2 p <ref> [7] </ref> for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 <p> Suppose that in the first iteration of the for loop in line [6], c refers to c 0 . The covering set of c 0 is the singleton set consisting of c 4 , so c 0 is assigned c 4 in line <ref> [7] </ref>. In line [8], p 0 is assigned the value of p minus the subordinate concepts of c 4 (i.e., c 1 , c 0 , and bottom), so p 0 is fc 2 ; c 6 g.
Reference: [8] <author> G. Caldiera and V.R. Basili. </author> <title> Identifying and analyzing reusable software components. </title> <journal> IEEE Computer, </journal> <volume> 24 </volume> <pages> 61-70, </pages> <year> 1991. </year>
Reference-contexts: Although much has been written about the problem of software reuse (for example, see [68, 46, 54]), including work on identifying reusable components <ref> [18, 8] </ref>, we are unaware of previous work on the problem of automatically creating polymorphic functions from monomorphic functions. Our work may be contrasted with what is provided by the NORA system, which also makes use of type inference to support polymorphic components [27]. <p> O be such that (fxg) ( (fyg) [5] let a 2 A 0 be such that a 62 (fxg), a 2 (fyg) [6] A 0 A 0 [ fag, where a is a new attribute [7] R 0 R 0 [ f (x; a)j (x; a) 62 R 0 g <ref> [8] </ref> endwhile 112 top (fcats; gibbons; dogs; dolphins; humans; whalesg; ;) c 5 (fgibbons; dolphins; humans; whalesg; fintelligentg) c 4 (fcats; dogs; gibbonsg; fhair-coveredg) c 7 (fdolphins, humans, whalesg; fnot hair-coveredg) c 3 (fgibbons, humans; fintelligent; thumbedg) c 2 (fdolphins, whalesg; fintelligent; marine; not hair-coveredg) c 6 (fhumansg; fintelligent; thumbed; not <p> partition removed from W , new partitions are formed (when possible) by 114 [1] A covs (?) // the atomic partition [2] P fAg [4] while W 6= ; do [5] remove some p from W [6] for each c 2 p [7] for each c 0 2 covs (c) <ref> [8] </ref> p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 g [14] endif [15] endif [16] endfor [17] <p> Suppose that in the first iteration of the for loop in line [6], c refers to c 0 . The covering set of c 0 is the singleton set consisting of c 4 , so c 0 is assigned c 4 in line [7]. In line <ref> [8] </ref>, p 0 is assigned the value of p minus the subordinate concepts of c 4 (i.e., c 1 , c 0 , and bottom), so p 0 is fc 2 ; c 6 g. <p> On some architectures, doubles are required to be aligned in memory at double-word boundaries (eight-bytes on many machines), while chars (and therefore char arrays) have no alignment requirement. Consider the following code: struct A f char d <ref> [8] </ref>; g a; struct B f double d; g; void set_double (struct B *b) f g 194 It is system dependent as to where the a is aligned, but any object of type struct B must be double-word aligned.
Reference: [9] <author> G. Canfora, A. Cimitile, and M. Munro. </author> <title> An improved algorithm for identifying objects in code. </title> <journal> Software | Practice and Experience, </journal> <volume> 26(1) </volume> <pages> 25-48, </pages> <month> January </month> <year> 1996. </year> <month> 218 </month>
Reference-contexts: formed (when possible) by 114 [1] A covs (?) // the atomic partition [2] P fAg [4] while W 6= ; do [5] remove some p from W [6] for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) <ref> [9] </ref> if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 g [14] endif [15] endif [16] endfor [17] endfor [18] endwhile selecting a concept of the <p> In line [8], p 0 is assigned the value of p minus the subordinate concepts of c 4 (i.e., c 1 , c 0 , and bottom), so p 0 is fc 2 ; c 6 g. In line <ref> [9] </ref>, the union of the extents of c 2 and 115 c 6 is disjoint with the extent of c 4 ; thus, in line [10], the partition p 00 = fc 2 ; c 6 g [ fc 4 g is formed. p 00 is added to the set of <p> Given that some user interaction will be required, the concept-analysis approach offers certain advantages over other previously proposed techniques (e.g., <ref> [42, 17, 49, 43, 9] </ref>), namely, 132 Ast BuildAstCLexCLrV als yp CompileHelpP arseC SizeofSym b able TDefT able T enT able T eUtil ADORNMENT p p p p BUILD AST p COMP HELP p p p p p p p C LR VALS p p C MODEL p p p p <p> The reader is referred to <ref> [9, pp. 27-32] </ref> for an extensive discussion of the literature on the modularization problem. In the remainder of this section, we discuss only the work that is most relevant to the approach we have taken. <p> It may be possible to combine the techniques from [11] and [17] with the concept-analysis approach of this chapter. Canfora et al. discuss two types of links that cause undesirable clustering of functions <ref> [9] </ref>. The first type, "coincidental links", caused by routines that implement more than one function, can be overcome by program slicing [64, 32]. The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. <p> The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. In most of the approaches mentioned above, spurious links arise from a function that accesses several global variables of different types. The work described in <ref> [42, 17, 43, 67, 9] </ref> will all stumble on examples that exhibit spurious links. In our approach, an analogous kind of spurious link arises due to functions that access internal fields of more than one struct. <p> A similar effect can be achieved via concept analysis by introducing one attribute for each actual parameter. 136 There has been a certain amount of work involving the use of cluster analysis to identify potential modules (e.g., <ref> [33, 2, 39, 9] </ref>). This work (implicitly or explicitly) involves the identification of potential modules by determining a similarity measure among pairs of functions.
Reference: [10] <author> G. Canfora, A. Cimitile, M. Tortorella, and M. Munro. </author> <title> Experiments in identifying reusable abstract data types in program code. </title> <booktitle> In Second Workshop on Program Comprehension, </booktitle> <pages> pages 36-45, </pages> <year> 1993. </year>
Reference-contexts: A class with a ten-element array can be specified as intArray&lt;10&gt;. Thus, another generalization opportunity that exists in C++ class generalization is the identification of constants that can be "lifted" to fixed-type template arguments. For instance, class ten f int a <ref> [10] </ref>; g; could be generalized to the class template intArray in the example above. Existing occurrences of ten are then replaced by intArray&lt;10&gt;. It is also possible to lift function names. For example, suppose we have a class that 64 makes use of a random number generator. <p> The resulting information can then be supplied to a suitable transformation tool that maps C code to C++ code, as in the aforementioned example. Although other modularization algorithms are able to identify the same decomposition <ref> [10, 67] </ref>, they are unable to handle a variant of this example in which stacks and queues are more tightly intertwined (see Section 3.3.2). In Section 3.3.2, we show that concept analysis is able to group the code from the latter example into separate queue and stack modules. <p> It is relatively straightforward to separate the code shown in Figure 37 into two modules, and techniques such as those described in <ref> [10, 67] </ref> will also create the same grouping. We now show that concept analysis offers the possibility to go beyond previously defined methods: It offers the ability to tease apart code that is, in some sense, more "tangled". <p> ; do [5] remove some p from W [6] for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint <ref> [10] </ref> p 00 p 0 [ fc 0 g [12] P P [ fp 00 g [14] endif [15] endif [16] endfor [17] endfor [18] endwhile selecting a concept of the partition, choosing a cover of that concept, adding it to the partition, and removing overlapping concepts. <p> In line [9], the union of the extents of c 2 and 115 c 6 is disjoint with the extent of c 4 ; thus, in line <ref> [10] </ref>, the partition p 00 = fc 2 ; c 6 g [ fc 4 g is formed. p 00 is added to the set of partitions and to the worklist in line [12] and line [13]. <p> As explained above, the concept-analysis approach can naturally generate a variety of possible decompositions (i.e., different collections of concepts that partition the set of objects). The concept-analysis approach is more general than that of Canfora et al. <ref> [10] </ref>, which identifies abstract data types by analyzing a graph that links functions to their argument types and return types. <p> By adding attributes that indicate whether fields of compound data types are used in a function, as is done in the example used in Section 3.3, concept-analysis 135 becomes a more powerful tool for identifying potential modules than the technique described in <ref> [10] </ref>. The work described in [11] and [17] expands on the abstract-data-type identification technique described in [10]: Call and dominance information is used to introduce a hierarchical nesting structure to modules. It may be possible to combine the techniques from [11] and [17] with the concept-analysis approach of this chapter. <p> compound data types are used in a function, as is done in the example used in Section 3.3, concept-analysis 135 becomes a more powerful tool for identifying potential modules than the technique described in <ref> [10] </ref>. The work described in [11] and [17] expands on the abstract-data-type identification technique described in [10]: Call and dominance information is used to introduce a hierarchical nesting structure to modules. It may be possible to combine the techniques from [11] and [17] with the concept-analysis approach of this chapter. Canfora et al. discuss two types of links that cause undesirable clustering of functions [9]. <p> For example: typedef struct f .... g Point; typedef struct f Color c; g AuxColor; typedef struct f Point p; AuxColor aux; g ColorPoint; 163 typedef struct f char name <ref> [10] </ref>; g AuxName; typedef struct f Point p; AuxColor aux; AuxName aux2; g NamedColorPoint; Notice that NamedColorPoint can be thought of a subclass of Point by the first-member idiom and as a subclass of ColorPoint by the redundant-declaration idiom.
Reference: [11] <author> G. Canfora, A. De Lucia, G. A. Di Lucca, and A. R. Fasolino. </author> <title> Recovering the architectural design for software comprehension. </title> <booktitle> In Third Workshop on Program Comprehension, </booktitle> <pages> pages 30-38, </pages> <year> 1994. </year>
Reference-contexts: By adding attributes that indicate whether fields of compound data types are used in a function, as is done in the example used in Section 3.3, concept-analysis 135 becomes a more powerful tool for identifying potential modules than the technique described in [10]. The work described in <ref> [11] </ref> and [17] expands on the abstract-data-type identification technique described in [10]: Call and dominance information is used to introduce a hierarchical nesting structure to modules. It may be possible to combine the techniques from [11] and [17] with the concept-analysis approach of this chapter. <p> The work described in <ref> [11] </ref> and [17] expands on the abstract-data-type identification technique described in [10]: Call and dominance information is used to introduce a hierarchical nesting structure to modules. It may be possible to combine the techniques from [11] and [17] with the concept-analysis approach of this chapter. Canfora et al. discuss two types of links that cause undesirable clustering of functions [9]. The first type, "coincidental links", caused by routines that implement more than one function, can be overcome by program slicing [64, 32].
Reference: [12] <author> Luca Cardelli. </author> <title> A semantics of multiple inheritance. </title> <editor> In G.Kahn, D.B. MacQueen, and G. Plotkin, editors, </editor> <booktitle> Semantics of Data Types, number 173 in Lecture Notes in Computer Science, </booktitle> <pages> pages 51-68. </pages> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: operator overloading is ordinarily synonymous with ad hoc polymorphism, in our work we make use of the C++ features that support ad hoc polymorphism in a disciplined way: Operator overloading 2 By "standard notion of subtype between records" we refer to the subtyping between records as discussed by Cardelli in <ref> [12, 13] </ref>. This is a substantially different form of subtyping than physical subtyping, which is the subject of Chapter 4. <p> for each c 2 p [7] for each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g <ref> [12] </ref> P P [ fp 00 g [14] endif [15] endif [16] endfor [17] endfor [18] endwhile selecting a concept of the partition, choosing a cover of that concept, adding it to the partition, and removing overlapping concepts. The algorithm is given in Figure 51. <p> 2 and 115 c 6 is disjoint with the extent of c 4 ; thus, in line [10], the partition p 00 = fc 2 ; c 6 g [ fc 4 g is formed. p 00 is added to the set of partitions and to the worklist in line <ref> [12] </ref> and line [13]. In the worst case, the number of partitions can be exponential in the number of concepts. Furthermore, the techniques for making contexts well-formed, discussed in Section 3.4.1, only exacerbate the problem: More precise means of distinguishing sets of objects translates to more concepts. <p> It is tempting, because of the name "union", to consider C union types as if they are Cardelli-style union types (also known as variant types or variant-record types) <ref> [12] </ref>. <p> The type system developed in this chapter has similarities with several type systems proposed by Cardelli <ref> [12, 13, 1] </ref>. The primary difference is that we take into account the physical layout of data types when determining subtype relationships, while in Cardelli's work the notion of physical layout does not apply. <p> This type system differs from the one employed in the generalization problem by allowing subtype polymorphism instead of parametric polymorphism. The type system is in some ways similar to other subtyping systems, 216 such as those in <ref> [12, 12, 1] </ref>, but is unique in that it focuses on the storage representation of struct and union types. The modularization process as applied to the C-to-C++ conversion problem can also be thought of as a type-inference problem: how to infer classes in C program.
Reference: [13] <author> Luca Cardelli and Peter Wegner. </author> <title> On understanding types, data abstraction, and polymorphism. </title> <journal> Computing Surveys, </journal> <volume> 17(4) </volume> <pages> 471-522, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: operator overloading is ordinarily synonymous with ad hoc polymorphism, in our work we make use of the C++ features that support ad hoc polymorphism in a disciplined way: Operator overloading 2 By "standard notion of subtype between records" we refer to the subtyping between records as discussed by Cardelli in <ref> [12, 13] </ref>. This is a substantially different form of subtyping than physical subtyping, which is the subject of Chapter 4. <p> We adopt the standard notion of subtype between C struct types (based on the presentation of record subtyping in <ref> [13] </ref>) 4 : The subtype relation is the trivial relation (i.e., t is a subtype of t 0 if and only if t and t 0 are the same type) for all types except structs; 5 a struct type s is a subtype of another struct type s 0 if, for <p> c 6 is disjoint with the extent of c 4 ; thus, in line [10], the partition p 00 = fc 2 ; c 6 g [ fc 4 g is formed. p 00 is added to the set of partitions and to the worklist in line [12] and line <ref> [13] </ref>. In the worst case, the number of partitions can be exponential in the number of concepts. Furthermore, the techniques for making contexts well-formed, discussed in Section 3.4.1, only exacerbate the problem: More precise means of distinguishing sets of objects translates to more concepts. <p> The type system developed in this chapter has similarities with several type systems proposed by Cardelli <ref> [12, 13, 1] </ref>. The primary difference is that we take into account the physical layout of data types when determining subtype relationships, while in Cardelli's work the notion of physical layout does not apply.
Reference: [14] <author> Frank M. Carrano, Paul Helman, and Robert Veroff. </author> <title> Data Abstraction and Problem Solving with C++: Walls and Mirrors. </title> <publisher> Addison-Wesley, </publisher> <year> 1998. </year>
Reference-contexts: each c 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 g <ref> [14] </ref> endif [15] endif [16] endfor [17] endfor [18] endwhile selecting a concept of the partition, choosing a cover of that concept, adding it to the partition, and removing overlapping concepts. The algorithm is given in Figure 51. <p> There are several ways in which programmers may emulate multiple inheritance in C. Here we illustrate one such method, which we call the +1 idiom. The following example is based on an example in <ref> [14] </ref>: 164 typedef struct f ... g Clock; typedef struct f ... g Radio; typedef struct f Clock clock; Radio radio; g ClockRadio; The type ClockRadio can be thought of as a class that multiply inherits from the types (classes) Clock and Radio.
Reference: [15] <author> Giuseppe Castagna. </author> <title> Covariance and contravariance: Conflict without a cause. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 17(3) </volume> <pages> 341-447, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: 0 2 covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 g [14] endif <ref> [15] </ref> endif [16] endfor [17] endfor [18] endwhile selecting a concept of the partition, choosing a cover of that concept, adding it to the partition, and removing overlapping concepts. The algorithm is given in Figure 51. <p> Our definition of physical subtyping assumes that a function pointer is a subtype of another function pointer only if the two types are the same. This is to avoid type-safety problems with covariant function subtypes. See <ref> [19, 15] </ref> for more details. <p> To avoid the sticky issue of contravariance of functional subtypes <ref> [19, 15] </ref>, the definition of physical subtypes given in Section 4.6.2 states that two pointers to functions are only subtypes of each other if they have the same type.
Reference: [16] <author> Satish Chandra, Thomas Ball, Krishna Kunchithapadam, Thomas Reps, and Michael Siff. </author> <title> Physical type checking in c via physical subtyping. </title> <booktitle> submitted to the Twenty-Sixth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <month> July </month> <year> 1998. </year>
Reference-contexts: covs (c) [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 g [14] endif [15] endif <ref> [16] </ref> endfor [17] endfor [18] endwhile selecting a concept of the partition, choosing a cover of that concept, adding it to the partition, and removing overlapping concepts. The algorithm is given in Figure 51. <p> The language used for the downcast-analysis problem could be a matched-parentheses language in which the open parentheses are upcasts and the closed parentheses are downcasts. * Constraint-based-type analyses <ref> [4, 3, 16] </ref>. <p> Most downcasts we have examined appear to be sensible (at least by our manual examination), but require a more extensive type-checking algorithm, such as the constraint-based algorithm of <ref> [16] </ref> to determine if the code that uses the downcast is physically type safe. We note that most of the benchmarks we applied our analyses to are time-tested 204 and robust C programs, so it is perhaps not unsurprising that we found few physical type errors in them. <p> After the downcast, the format-specific functions execute code that is particular to a given format. 4.9 Related Work Many of the ideas of this chapter are also discussed in <ref> [16] </ref>. The identification of classes in the context of the C-to-C++ problem is discussed in Chapter 3. Section 3.7 describes related work in that area. This chapter has examined the related problem of determining how the (user-defined) types in a C program might be organized into a C++ class hierarchy.
Reference: [17] <author> A. Cimitile, M. Tortorella, and M. Munro. </author> <title> Program comprehension through the 219 identification of abstract data types. </title> <booktitle> In Third Workshop on Program Comprehension, </booktitle> <pages> pages 12-19, </pages> <year> 1994. </year>
Reference-contexts: [8] p 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 g [14] endif [15] endif [16] endfor <ref> [17] </ref> endfor [18] endwhile selecting a concept of the partition, choosing a cover of that concept, adding it to the partition, and removing overlapping concepts. The algorithm is given in Figure 51. <p> Given that some user interaction will be required, the concept-analysis approach offers certain advantages over other previously proposed techniques (e.g., <ref> [42, 17, 49, 43, 9] </ref>), namely, 132 Ast BuildAstCLexCLrV als yp CompileHelpP arseC SizeofSym b able TDefT able T enT able T eUtil ADORNMENT p p p p BUILD AST p COMP HELP p p p p p p p C LR VALS p p C MODEL p p p p <p> By adding attributes that indicate whether fields of compound data types are used in a function, as is done in the example used in Section 3.3, concept-analysis 135 becomes a more powerful tool for identifying potential modules than the technique described in [10]. The work described in [11] and <ref> [17] </ref> expands on the abstract-data-type identification technique described in [10]: Call and dominance information is used to introduce a hierarchical nesting structure to modules. It may be possible to combine the techniques from [11] and [17] with the concept-analysis approach of this chapter. <p> The work described in [11] and <ref> [17] </ref> expands on the abstract-data-type identification technique described in [10]: Call and dominance information is used to introduce a hierarchical nesting structure to modules. It may be possible to combine the techniques from [11] and [17] with the concept-analysis approach of this chapter. Canfora et al. discuss two types of links that cause undesirable clustering of functions [9]. The first type, "coincidental links", caused by routines that implement more than one function, can be overcome by program slicing [64, 32]. <p> The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. In most of the approaches mentioned above, spurious links arise from a function that accesses several global variables of different types. The work described in <ref> [42, 17, 43, 67, 9] </ref> will all stumble on examples that exhibit spurious links. In our approach, an analogous kind of spurious link arises due to functions that access internal fields of more than one struct.
Reference: [18] <author> A. Cimitile and G. Visaggio. </author> <title> Software salvaging and the call dominance tree. </title> <journal> Journal of Systems Software, </journal> <volume> 28 </volume> <pages> 117-127, </pages> <year> 1995. </year>
Reference-contexts: Although much has been written about the problem of software reuse (for example, see [68, 46, 54]), including work on identifying reusable components <ref> [18, 8] </ref>, we are unaware of previous work on the problem of automatically creating polymorphic functions from monomorphic functions. Our work may be contrasted with what is provided by the NORA system, which also makes use of type inference to support polymorphic components [27]. <p> 0 p subs (c 0 ) [9] if ( p 0 ) " c 0 = ; // if p 0 and c 0 are disjoint [10] p 00 p 0 [ fc 0 g [12] P P [ fp 00 g [14] endif [15] endif [16] endfor [17] endfor <ref> [18] </ref> endwhile selecting a concept of the partition, choosing a cover of that concept, adding it to the partition, and removing overlapping concepts. The algorithm is given in Figure 51. As an example, consider the atomic partition of the concept lattice derived from the uniquely-attributed mammal context (see Figure 48).
Reference: [19] <author> W. Cook, W. Hill, and P. Canning. </author> <title> Inheritance is not subtyping. </title> <booktitle> In Proceedings of the Seventeenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 125-135, </pages> <year> 1990. </year>
Reference-contexts: Our definition of physical subtyping assumes that a function pointer is a subtype of another function pointer only if the two types are the same. This is to avoid type-safety problems with covariant function subtypes. See <ref> [19, 15] </ref> for more details. <p> To avoid the sticky issue of contravariance of functional subtypes <ref> [19, 15] </ref>, the definition of physical subtypes given in Section 4.6.2 states that two pointers to functions are only subtypes of each other if they have the same type.
Reference: [20] <author> James O. Coplien. </author> <title> Advanced C++ Programming Styles and Idioms. </title> <publisher> Addison Wesley, </publisher> <year> 1992. </year>
Reference-contexts: This section articulates some of these relationships. 1.1.1 Software Reuse In general, reuse is the idea of applying that which is already at hand|whether it be physical resources or conceptual resources|to avoid duplication of effort over time and 12 space <ref> [20] </ref>. Software reuse enables software engineers to save time (and often space) by using program components that are already implemented [5, 6]. <p> There are several ways in which to achieve effective software reuse. Probably the best way to attain high levels of reuse is to design for reuse <ref> [20] </ref>. However, it is too late to rebuild and redesign from the ground up when dealing with large legacy systems. One of the goals of my work on software renovation has been to make legacy code reusable.
Reference: [21] <author> Luis Damas and Robin Milner. </author> <title> Principal type-schemes for functional programs. </title> <booktitle> In Ninth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-212, </pages> <month> January </month> <year> 1982. </year>
Reference-contexts: Thus, if P is a type-safe C program, then P 0 , its generalization, is a type-safe C++ program. Type-inference rules We have developed a set of type-inference rules in the style of <ref> [21] </ref>.
Reference: [22] <author> B.A. Davey and H.A. Priestley. </author> <title> Introduction to lattices and order. </title> <publisher> Cambridge University Press, </publisher> <year> 1990. </year>
Reference-contexts: This work (implicitly or explicitly) involves the identification of potential modules by determining a similarity measure among pairs of functions. We are currently investigating the link between concept analysis and cluster analysis. <ref> [22] </ref> offers background on lattice theory and an introduction to concept analysis. [65] formalizes the notions of concept analysis and provides a proof of the fundamental theorem. Concept analysis has been applied to many kinds of problems.
Reference: [23] <author> David Evans. </author> <title> Static detection of dynamic memory errors. </title> <booktitle> In Proceedings of the ACM SIGPLAN'96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 44-53, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Furthermore, this memory model differs from ours in that it is a static model while ours is a dynamic model (see Section 4.4). The tools we have developed based on physical-subtype analysis (see Section 4.8) are related to, but complementary to, such tools as lint [36, 35] and LCLint <ref> [23] </ref>. Our tools, as well as lint and LCLint, can be used to assist in the static detection of type errors that escape the notice of many C compilers.
Reference: [24] <author> David Garlan and Dewayne Perry. </author> <title> Introduction to the special issue on software architecture. </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> April </month> <year> 1995. </year>
Reference: [25] <author> David Garlan and Mary Shaw. </author> <title> An introduction to software architecture. </title> <type> Technical Report CMU-CS-94-166, </type> <institution> Carnegie Mellon University, </institution> <year> 1994. </year> <month> 220 </month>
Reference: [26] <author> R. Godin and R. Missaoui H. Alaoui. </author> <title> Incremental concept formation algorithms based on Galois (concept) lattices. </title> <journal> Computational Intelligence, </journal> <volume> 11(2) </volume> <pages> 246-267, </pages> <year> 1995. </year>
Reference-contexts: An example of the application of the fundamental theorem is shown in Figure 40. There are several algorithms for computing the concept lattice for a given context <ref> [26, 60] </ref>. We describe a simple bottom-up algorithm here. An important fact about concepts and contexts used in the algorithm is that, given a set of objects X, the smallest concept with extent containing X is (t ((X)); (X)).
Reference: [27] <author> F.-J. Grosch and G. Snelting. </author> <title> Polymorphic components for monomorphic languages. </title> <editor> In R. Prieto-Diaz and W.B. Frakes, editors, </editor> <booktitle> Advances in software reuse: Selected papers from the Second International Workshop on Software Reusability, </booktitle> <pages> pages 47-55, </pages> <address> Lucca, Italy, March 1993. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Our work may be contrasted with what is provided by the NORA system, which also makes use of type inference to support polymorphic components <ref> [27] </ref>. The paradigm in NORA is to extend a base language (e.g., C, Pascal, Modula-2) with a more powerful type system that permits fragments to be given types and units containing unbound names to be given types. <p> A generalizer could be used to create code to be placed into libraries and the signature matcher could be used to retrieve generalized code. The idea of mixing polymorphism with C appears in several places, among them <ref> [27, 59, 50] </ref>. [59] concerns a new dialect of C that is polymorphic and type safe. <p> Section 3.7 describes related work in that area. This chapter has examined the related problem of determining how the (user-defined) types in a C program might be organized into a C++ class hierarchy. The idea of applying alternate type systems to C appears in several places, among them <ref> [27, 59, 50, 58, 61] </ref>. Most of these references discuss the application of parametric polymorphism to C (see Chapter 2), while in this Chapter we discuss the application of subtype polymorphism to C.
Reference: [28] <author> Carl A. Gunter. </author> <title> Semantics of Programming Languages. </title> <publisher> The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: A variant is a labeled disjoint sum, that looks like a record: it is an unordered set of label-type pairs, often denoted with square brackets as in the following simple example taken from <ref> [28] </ref>: type Vehicle = [Air : AirVehicle, Land : LandVehicle, Water : WaterVehicle] The idea here is that an object of type Vehicle is one of the three member types. There is usually only one operation that can be applied to variants|case selection. <p> There is usually only one operation that can be applied to variants|case selection. Case selection prescribes a different action for each member of the variant and then executes the action corresponding to the form the variant takes. 183 In the type system presented in <ref> [28] </ref>, a variant v [l 1 : t 1 ; l 2 : t 2 ; : : : ; l k : t k ] is a subtype of a variant v 0 [l 1 : t 0 2 ; : : : ; l k : t 0 k
Reference: [29] <author> Samuel P. Harbison and Guy L. Steele Jr. </author> <title> C: A Reference Manual. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year>
Reference-contexts: In this section, we briefly review the storage model for C data structures. For a more detailed account, the reader is directed to <ref> [29, 38, 34] </ref>. All data objects in C are represented by an integral number of bytes in memory. The size of a data object is the number of bytes occupied by the data object [29]. <p> For a more detailed account, the reader is directed to [29, 38, 34]. All data objects in C are represented by an integral number of bytes in memory. The size of a data object is the number of bytes occupied by the data object <ref> [29] </ref>. A character type (char, signed char, unsigned char) is defined to occupy one byte of memory. The sizes of other C types are implementation dependent, but must conform to the following guidelines: * signed, unsigned, const, and volatile qualifiers do not affect the size of a type. <p> A scalar type is an arithmetic type, a pointer type, or an enumerated type <ref> [29] </ref>. A dereference (or indirection) is an expression that takes an address (a value of pointer type) and returns the value to which the address points. We define a scalar dereference to be a dereference of an address pointing to a scalar type. <p> If overlap does occur, the behavior of the assignment is implementation dependent <ref> [29] </ref>. 153 *u = *v; /* equivalent to: u-&gt;d = v-&gt;d; */ The remaining case is member selection of a dereference of a pointer to a struct or a pointer to a union. If the member selected is a scalar type, we are done. <p> We call such an error a physical type error. We say that the expected type of a C expression is the type associated with the 157 expression according to the propagation and promotion rules prescribed by the C language <ref> [34, 38, 29] </ref>. In other words, the expected type of an expression is the type the compiler expects the expression to be. <p> Experience has shown that there are cases where it is useful to consider two function pointer types as subtypes, again at a loss of type safety. Bit fields According to the ANSI C Standard, the rules for storing bit fields are implementation dependent <ref> [38, 29] </ref>, thus in order to maintain physical type safety (as well as portability), types with bit-field members are not considered to be physical subtypes or 6 void* has not always been available in C. 192 physical supertypes of any other types.
Reference: [30] <author> Fritz Henglein. </author> <title> Type inference with polymorphic recursion. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <year> 1992. </year>
Reference-contexts: The polynomial worst-cast running-time complexity of our type inference algorithm is an interesting contrast with the complexity of other polymorphic type inference algorithms. Type inference on the polymorphic recursive lambda calculus, which has a type system similar to ours, is an undecidable problem <ref> [30] </ref>. The complexity of type inference for ML is exponential-time complete [37]. 61 2.8 Generalization of C++ Classes A process similar to C-to-C++ function generalization can be applied in the case where C++ is both the source and target language.
Reference: [31] <author> R. Hindley. </author> <title> The principal type-scheme of an object in combinatory logic. </title> <journal> Transactions of the AMS, </journal> <volume> 146 </volume> <pages> 29-60, </pages> <year> 1969. </year>
Reference-contexts: The type-inference algorithm is based on Hindley-Milner type inference <ref> [31, 47] </ref>, but with the augmentations specific to the C-to-C++ conversion problem: operator overloading, constructors, casts, etc. The idea of mixing polymorphism with C appears in several places, among them [59, 50]. [59] concerns a new dialect of C that is polymorphic and type safe. <p> issues that have been examined in previous studies of type inference, there are various details that concern the application of type inference to the problem of program generalization. (Some related issues, concerning differences between our approach to type inference and the ways in which type inference has been traditionally formulated <ref> [31, 47, 48] </ref>, are discussed in Section 2.3.) 2.2.1 Parametric Polymorphism Via Operator Overloading Parametric polymorphism captures certain kinds of commonalities among similar operations on different types. This is a powerful mechanism for code-oriented software reuse. <p> Ordinarily, type inference is treated as a problem of showing that type annotations are completely superfluous. Specifically, many type-inference problems can be cast in the following framework, in which a typed language is related to an untyped language <ref> [31, 47, 48] </ref>: Suppose L is a typed language, L 0 is a related untyped language, and "erasure" function Erase : L ! L 0 removes type annotations from terms of L. <p> One of the central ideas behind the generalization process described in Chapter 2 is to impose a parametric polymorphic type system on C programs in place of C's traditional monomorphic types. The type-inference algorithm is based on Hindley-Milner type inference <ref> [31, 47] </ref>, but with the augmentations such as operator overloading, constructor introduction and struct subtyping. Physical-subtype detection is also based on the imposition of a new type system on C programs.
Reference: [32] <author> Susan Horwitz, Thomas Reps, and David Binkley. </author> <title> Interprocedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: This reveals 2 Some legacy code is monolithic|multiple tasks are contained within one function. In such cases, it may be preferable to have objects correspond to slices <ref> [64, 32] </ref> rather than functions. 103 that the type of f 's first argument is distinct from the type of its second argument (even though they had the same declared type). <p> Canfora et al. discuss two types of links that cause undesirable clustering of functions [9]. The first type, "coincidental links", caused by routines that implement more than one function, can be overcome by program slicing <ref> [64, 32] </ref>. The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. In most of the approaches mentioned above, spurious links arise from a function that accesses several global variables of different types.
Reference: [33] <author> David H. Hutchens and Victor R. Basili. </author> <title> System structure analysis: Clustering with data bindings. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11(8):749-757, </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: A similar effect can be achieved via concept analysis by introducing one attribute for each actual parameter. 136 There has been a certain amount of work involving the use of cluster analysis to identify potential modules (e.g., <ref> [33, 2, 39, 9] </ref>). This work (implicitly or explicitly) involves the identification of potential modules by determining a similarity measure among pairs of functions.
Reference: [34] <author> ISO/IEC. </author> <title> Programming langauges|C. Number 9899. </title> <address> ISO/IEC, </address> <year> 1990. </year> <month> 221 </month>
Reference-contexts: In this section, we briefly review the storage model for C data structures. For a more detailed account, the reader is directed to <ref> [29, 38, 34] </ref>. All data objects in C are represented by an integral number of bytes in memory. The size of a data object is the number of bytes occupied by the data object [29]. <p> We call such an error a physical type error. We say that the expected type of a C expression is the type associated with the 157 expression according to the propagation and promotion rules prescribed by the C language <ref> [34, 38, 29] </ref>. In other words, the expected type of an expression is the type the compiler expects the expression to be.
Reference: [35] <author> S. C. Johnson. </author> <title> Lint, a C program checker, </title> <month> July </month> <year> 1978. </year>
Reference-contexts: Furthermore, this memory model differs from ours in that it is a static model while ours is a dynamic model (see Section 4.4). The tools we have developed based on physical-subtype analysis (see Section 4.8) are related to, but complementary to, such tools as lint <ref> [36, 35] </ref> and LCLint [23]. Our tools, as well as lint and LCLint, can be used to assist in the static detection of type errors that escape the notice of many C compilers.
Reference: [36] <author> S. C. Johnson and D. M. Ritchie. </author> <title> UNIX time-sharing system: Portability of C programs and the UNIX system. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 57(6) </volume> <pages> 2021-2048, </pages> <year> 1978. </year>
Reference-contexts: Furthermore, this memory model differs from ours in that it is a static model while ours is a dynamic model (see Section 4.4). The tools we have developed based on physical-subtype analysis (see Section 4.8) are related to, but complementary to, such tools as lint <ref> [36, 35] </ref> and LCLint [23]. Our tools, as well as lint and LCLint, can be used to assist in the static detection of type errors that escape the notice of many C compilers.
Reference: [37] <author> Paris C. Kannellakis, Harry G. Mairson, and John C. Mitchell. </author> <title> Computational Logic: </title> <booktitle> Essays in Honor of Alan Robinson, chapter Unification and ML Type Reconstruction, </booktitle> <pages> pages 444-478. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: In the worst case all the functions are all mutually recursive. The complexity of one iteration through all functions is linear in the number of unification operations required. Unification is itself a linear-time operation in terms of the size of the type expressions being unified <ref> [37] </ref>. Initially there are are O (n) type variables (type expressions of size O (1)). In the worst case, the complexity of the type expressions can be linear. So, for each iteration, the number of operations is bounded above by O (n 2 ). <p> Type inference on the polymorphic recursive lambda calculus, which has a type system similar to ours, is an undecidable problem [30]. The complexity of type inference for ML is exponential-time complete <ref> [37] </ref>. 61 2.8 Generalization of C++ Classes A process similar to C-to-C++ function generalization can be applied in the case where C++ is both the source and target language. There are several motivations for developing a tool to automatically generalize C++ programs: 1.
Reference: [38] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice Hall, </publisher> <address> second edition, </address> <year> 1988. </year>
Reference-contexts: The Valid-Code Assumption also allows us to ignore issues about implicit type conversions and promotions that can occur among arithmetic types <ref> [38, pages 197-202] </ref>. For this reason, the type system uses a single symbol, , to represent monomorphic types. (Most other type-inference systems have collection of different monomorphic types, e.g., int, float, int ! float, etc.) Type is the one "base type" of the type system. <p> These measures all help to prevent the creation of overly general templates. However, it is still possible for over-generalization to occur. For instance, consider the version of the power function shown in Figure 12 <ref> [38, page 25] </ref>. This version is equivalent to the function given in Figure 8, but has a second local variable, i, which is used as the iteration variable in the loop. <p> In this section, we briefly review the storage model for C data structures. For a more detailed account, the reader is directed to <ref> [29, 38, 34] </ref>. All data objects in C are represented by an integral number of bytes in memory. The size of a data object is the number of bytes occupied by the data object [29]. <p> We call such an error a physical type error. We say that the expected type of a C expression is the type associated with the 157 expression according to the propagation and promotion rules prescribed by the C language <ref> [34, 38, 29] </ref>. In other words, the expected type of an expression is the type the compiler expects the expression to be. <p> Experience has shown that there are cases where it is useful to consider two function pointer types as subtypes, again at a loss of type safety. Bit fields According to the ANSI C Standard, the rules for storing bit fields are implementation dependent <ref> [38, 29] </ref>, thus in order to maintain physical type safety (as well as portability), types with bit-field members are not considered to be physical subtypes or 6 void* has not always been available in C. 192 physical supertypes of any other types.
Reference: [39] <author> Thomas Kunz. </author> <title> Evaluating process clusters to support automatic program understanding. </title> <booktitle> In Fourth Workshop on Program Comprehension, </booktitle> <pages> pages 198-207, </pages> <year> 1996. </year>
Reference-contexts: A similar effect can be achieved via concept analysis by introducing one attribute for each actual parameter. 136 There has been a certain amount of work involving the use of cluster analysis to identify potential modules (e.g., <ref> [33, 2, 39, 9] </ref>). This work (implicitly or explicitly) involves the identification of potential modules by determining a similarity measure among pairs of functions.
Reference: [40] <author> Christian Lindig and Gregor Snelting. </author> <title> Assessing modular structure of legacy code based on mathematical concept analysis. </title> <booktitle> In Proceedings of the 19th International Conference on Software Engineering, </booktitle> <pages> pages 349-359, </pages> <year> 1997. </year>
Reference-contexts: It is based on concept analysis, a branch of lattice theory that can be used to identify similarities among a set of objects based on their attributes. Our work compares favorably with contemporaneous work on on concept analysis and modularization by Lindig and Snelting <ref> [40] </ref> and Sahraoui et al. [57]. (See Section 3.7.) * Physical-subtype detection is also based on the imposition of a new type system on C programs. This type systems differs from the one employed in the 15 generalization problem by allowing subtype polymorphism instead of parametric polymorphism. <p> Other possibilities for attributes include the following: * Variable-usage information: Related functions can sometimes be identified by their use of common global variables. An attribute capturing this information might be of the form "uses global variable x" <ref> [40, 57] </ref>. * Dataflow and slicing information can be useful in identifying modules. <p> Concept analysis has been applied to many kinds of problems. Concept analysis was first applied to software engineering in the NORA/RECS tool, where it was used to identify conflicts in software-configuration information [60]. Contemporaneously with our own work, Lindig and Snelting <ref> [40] </ref> and Sahraoui et al. [57] independently explored the idea of applying concept analysis to the modulariza-tion problem. In both of these studies, the context relations used for concept analysis relate each function of the program to the global variables accessed by the function. <p> As with the generalization tool, we have applied the concept-analysis tool to the SPEC benchmark, as well to as bash. We discuss how our techniques are more flexible and powerful than several other modularization techniques. We contrast our work to that of Lindig and Snelting <ref> [40] </ref> and that of Sahraoui et al. [57], both which also apply concept analysis to the modularization problem. Our results appear to be more successful than the results reported in their work because the concept lattices our tool generates remain of tractable size, even for medium-to-large C programs.
Reference: [41] <author> Barbara Liskov. </author> <title> Data abstraction and hierarchy. </title> <journal> SIGPLAN Notices, </journal> <volume> 23(5), </volume> <month> May </month> <year> 1988. </year>
Reference-contexts: conforms to the Liskov Substitution Principle: For every object x of type t there is an object x 0 of type t 0 , such that for all programs P defined in terms of t 0 , the behavior of P is unchanged when x is substituted for x 0 <ref> [41] </ref>. 143 We say that a programming language L supports subtyping if a user may define types t and t 0 in a program P in L such that: 1.
Reference: [42] <author> Sying-Syang Liu and Norman Wilde. </author> <title> Identifying objects in a conventional procedural language: An example of data design recovery. </title> <booktitle> In Conference on Software Maintenance, </booktitle> <pages> pages 266-271. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> November </month> <year> 1990. </year> <month> 222 </month>
Reference-contexts: Given that some user interaction will be required, the concept-analysis approach offers certain advantages over other previously proposed techniques (e.g., <ref> [42, 17, 49, 43, 9] </ref>), namely, 132 Ast BuildAstCLexCLrV als yp CompileHelpP arseC SizeofSym b able TDefT able T enT able T eUtil ADORNMENT p p p p BUILD AST p COMP HELP p p p p p p p C LR VALS p p C MODEL p p p p <p> The reader is referred to [9, pp. 27-32] for an extensive discussion of the literature on the modularization problem. In the remainder of this section, we discuss only the work that is most relevant to the approach we have taken. Liu and Wilde <ref> [42] </ref> make use of a table that is very much like the object-attribute relation of a context. However, whereas our work uses concept analysis to analyze such tables, Liu and Wilde propose a less powerful analysis. <p> The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. In most of the approaches mentioned above, spurious links arise from a function that accesses several global variables of different types. The work described in <ref> [42, 17, 43, 67, 9] </ref> will all stumble on examples that exhibit spurious links. In our approach, an analogous kind of spurious link arises due to functions that access internal fields of more than one struct.
Reference: [43] <author> Panos E. Livadas and Theodore Johnson. </author> <title> A new approach to finding objects in programs. Software Maintenance: </title> <journal> Research and Practice, </journal> <volume> 6 </volume> <pages> 249-260, </pages> <year> 1994. </year>
Reference-contexts: Given that some user interaction will be required, the concept-analysis approach offers certain advantages over other previously proposed techniques (e.g., <ref> [42, 17, 49, 43, 9] </ref>), namely, 132 Ast BuildAstCLexCLrV als yp CompileHelpP arseC SizeofSym b able TDefT able T enT able T eUtil ADORNMENT p p p p BUILD AST p COMP HELP p p p p p p p C LR VALS p p C MODEL p p p p <p> The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. In most of the approaches mentioned above, spurious links arise from a function that accesses several global variables of different types. The work described in <ref> [42, 17, 43, 67, 9] </ref> will all stumble on examples that exhibit spurious links. In our approach, an analogous kind of spurious link arises due to functions that access internal fields of more than one struct.
Reference: [44] <author> David Melski and Thomas Reps. </author> <title> Interconvertibility of set constraints and context-free language reachability. </title> <booktitle> In PEPM '97: Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 74-89, </pages> <address> New York, </address> <month> June </month> <year> 1997. </year> <note> ACM. </note>
Reference-contexts: Such techniques might include: * Dataflow analysis in conjunction with context-free-language reachability. Context-free-language reachability (CFL-reachability) is a generalization of ordinary graph reachability in which each edge of a graph is labeled with a letter from an alphabet <ref> [44] </ref>. A path p from s to t is considered to connect s to t only if the word spelled out by the letters on the edges of p is in a given context-free language.
Reference: [45] <author> Bertrand Meyer. </author> <title> Object-Oriented Software Construction. </title> <publisher> Prentice Hall International, </publisher> <year> 1988. </year>
Reference-contexts: Maintenance tasks are often carried out by new software engineers, who these days are trained primarily in C++ and not in C. * Encapsulation. Information hiding (or encapsulation) is the separation of the external aspects (the interface) of a data type, from its internal implementation details <ref> [45, 56] </ref>. Encapsulation prevents a program from becoming so interdependent that small changes have large ripple effects. C++ supports private and protected members of classes, whereas C has no mechanism for encapsulation. * Type safety. <p> For example, in the programming language Eiffel, no such safety-preserving principle 147 holds for subtypes <ref> [45] </ref>. However, the goal of this chapter is to develop a definition of subtyping in C that jibes with the definition of subtyping in C++. Because in C++ substitution of subtypes preserves type safety, we formally define type safety in C as motivation for the subsequent definition of physical subtypes.
Reference: [46] <author> Hafedh Mili, Fatma Mili, and Ali Mili. </author> <title> Resuing software: Issues and research directions. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(6), </volume> <month> June </month> <year> 1995. </year>
Reference-contexts: Although much has been written about the problem of software reuse (for example, see <ref> [68, 46, 54] </ref>), including work on identifying reusable components [18, 8], we are unaware of previous work on the problem of automatically creating polymorphic functions from monomorphic functions.
Reference: [47] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <year> 1978. </year>
Reference-contexts: The type-inference algorithm is based on Hindley-Milner type inference <ref> [31, 47] </ref>, but with the augmentations specific to the C-to-C++ conversion problem: operator overloading, constructors, casts, etc. The idea of mixing polymorphism with C appears in several places, among them [59, 50]. [59] concerns a new dialect of C that is polymorphic and type safe. <p> Section 2.10 concerns related work. 2.2 Sources of Polymorphism The basic idea behind the program-generalization algorithm is as follows: We discard the standard C type system and replace it with a parametric polymorphic type system. Type inference is carried out in a relatively standard fashion <ref> [47] </ref>, and then generalization is performed by mapping free type variables in the resulting type expressions to template parameters. As mentioned in the introduction, the types inferred during this process are unsound with respect to C. <p> issues that have been examined in previous studies of type inference, there are various details that concern the application of type inference to the problem of program generalization. (Some related issues, concerning differences between our approach to type inference and the ways in which type inference has been traditionally formulated <ref> [31, 47, 48] </ref>, are discussed in Section 2.3.) 2.2.1 Parametric Polymorphism Via Operator Overloading Parametric polymorphism captures certain kinds of commonalities among similar operations on different types. This is a powerful mechanism for code-oriented software reuse. <p> In this case, &lt; has type 8ff:ff fi ff ! . 3 At each occurrence of a standard operator, the generic type is instantiated in the usual way <ref> [47] </ref>; that is, the quantifiers are stripped off, and the body of the type is instantiated with fresh type variables different from all other type variables used elsewhere. Unification of type expressions allows the system to deduce how certain types are related to other types. <p> Ordinarily, type inference is treated as a problem of showing that type annotations are completely superfluous. Specifically, many type-inference problems can be cast in the following framework, in which a typed language is related to an untyped language <ref> [31, 47, 48] </ref>: Suppose L is a typed language, L 0 is a related untyped language, and "erasure" function Erase : L ! L 0 removes type annotations from terms of L. <p> One of the central ideas behind the generalization process described in Chapter 2 is to impose a parametric polymorphic type system on C programs in place of C's traditional monomorphic types. The type-inference algorithm is based on Hindley-Milner type inference <ref> [31, 47] </ref>, but with the augmentations such as operator overloading, constructor introduction and struct subtyping. Physical-subtype detection is also based on the imposition of a new type system on C programs.
Reference: [48] <author> John C. Mitchell. </author> <booktitle> Handbook of Theoretical Computer Science, volume B, chapter Type systems for programming languages, </booktitle> <pages> pages 365-458. </pages> <publisher> The M.I.T. </publisher> <address> Press/Esevier, </address> <year> 1990. </year>
Reference-contexts: issues that have been examined in previous studies of type inference, there are various details that concern the application of type inference to the problem of program generalization. (Some related issues, concerning differences between our approach to type inference and the ways in which type inference has been traditionally formulated <ref> [31, 47, 48] </ref>, are discussed in Section 2.3.) 2.2.1 Parametric Polymorphism Via Operator Overloading Parametric polymorphism captures certain kinds of commonalities among similar operations on different types. This is a powerful mechanism for code-oriented software reuse. <p> Ordinarily, type inference is treated as a problem of showing that type annotations are completely superfluous. Specifically, many type-inference problems can be cast in the following framework, in which a typed language is related to an untyped language <ref> [31, 47, 48] </ref>: Suppose L is a typed language, L 0 is a related untyped language, and "erasure" function Erase : L ! L 0 removes type annotations from terms of L.
Reference: [49] <author> Philip Newcomb. </author> <title> Reengineering procedural into object-oriented systems. </title> <booktitle> In Second Working Conference on Reverse Engineering, </booktitle> <pages> pages 237-249, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Given that some user interaction will be required, the concept-analysis approach offers certain advantages over other previously proposed techniques (e.g., <ref> [42, 17, 49, 43, 9] </ref>), namely, 132 Ast BuildAstCLexCLrV als yp CompileHelpP arseC SizeofSym b able TDefT able T enT able T eUtil ADORNMENT p p p p BUILD AST p COMP HELP p p p p p p p C LR VALS p p C MODEL p p p p
Reference: [50] <author> Robert O'Callahan and Daniel Jackson. </author> <title> Detecting shared representations using type inference. </title> <type> Technical Report CMU-CS-95-202, </type> <institution> Carnegie Mellon University, </institution> <month> September </month> <year> 1995. </year> <month> 223 </month>
Reference-contexts: The type-inference algorithm is based on Hindley-Milner type inference [31, 47], but with the augmentations specific to the C-to-C++ conversion problem: operator overloading, constructors, casts, etc. The idea of mixing polymorphism with C appears in several places, among them <ref> [59, 50] </ref>. [59] concerns a new dialect of C that is polymorphic and type safe. <p> The idea of mixing polymorphism with C appears in several places, among them [59, 50]. [59] concerns a new dialect of C that is polymorphic and type safe. This differs from our approach in that it is not aimed at adding polymorphism to existing code. <ref> [50] </ref> uses polymorphic type inference on existing C programs, but for determining information about the transfer of values, as opposed to producing reusable code. * The modularization process as applied to the C-to-C++ conversion problem can be thought of as a type-inference problem: how to infer classes in C program. <p> A generalizer could be used to create code to be placed into libraries and the signature matcher could be used to retrieve generalized code. The idea of mixing polymorphism with C appears in several places, among them <ref> [27, 59, 50] </ref>. [59] concerns a new dialect of C that is polymorphic and type safe. <p> The idea of mixing polymorphism with C appears in several places, among them [27, 59, 50]. [59] concerns a new dialect of C that is polymorphic and type safe. This differs from our approach in that it is not aimed at adding polymorphism to existing code. <ref> [50] </ref> uses polymorphic type inference on existing C programs, but for determining information about the transfer of values, as opposed to producing reusable code. 2.11 Summary This chapter has discussed the problem of C function generalization and given an algorithm that provides a way to transform one or more C functions <p> Section 3.7 describes related work in that area. This chapter has examined the related problem of determining how the (user-defined) types in a C program might be organized into a C++ class hierarchy. The idea of applying alternate type systems to C appears in several places, among them <ref> [27, 59, 50, 58, 61] </ref>. Most of these references discuss the application of parametric polymorphism to C (see Chapter 2), while in this Chapter we discuss the application of subtype polymorphism to C. <p> Section 2.10 describes related work pertaining to the application of parametric polymorphism to C. [59] concerns a new dialect of C that is polymorphic and type safe. This differs from our approach in that it is not aimed at adding polymorphism to existing code. <ref> [50] </ref> uses 210 polymorphic type inference on existing C programs, but for determining information about the transfer of values, as opposed to producing reusable code. The type system developed in this chapter has similarities with several type systems proposed by Cardelli [12, 13, 1].
Reference: [51] <author> Robert O'Callahan and Daniel Jackson. </author> <title> Practical program understanding with type inference. </title> <type> Technical Report CMU-CS-96-130, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Attributes capturing this information might be of the form "may use a value that flows from statement s" or "is part of the slice with respect to statement s". * Information obtained from type inferencing: Type inference can be used to uncover distinctions between seemingly identical types (see <ref> [58, 51] </ref>). For example, if f is a function declared to be of type int fi int ! bool, type inference might discover that f 's most general type is of the form ff fi fi ! bool.
Reference: [52] <author> D. L. Parnas. </author> <title> On the criteria to be used in decomposing systems into modules. </title> <journal> Communications of the ACM, </journal> <volume> 15(12) </volume> <pages> 1053-1058, </pages> <month> December </month> <year> 1972. </year>
Reference-contexts: Modularization. The goal of modularization is to encapsulate data types with related functions into distinct classes or modules. Ideally, modules have a clear-cut purpose (they are maximally cohesive) and are independent of each other (they are minimally coupled ) <ref> [52] </ref>. In the C-to-C++ domain, modularization refers to the identification of struct types and functions that manipulate values of those types that can be sensibly organized into C++ classes.
Reference: [53] <author> Laurence C. Paulson. </author> <title> ML for the Working Programmer. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: This lifting process is much like the corresponding process of lifting constant expressions to fixed-type parameters in C++ class templates, discussed in Section 2.8. Sometimes generalizing a structure requires more subtlety. Consider the binary-search-tree structure in Figure 32 (adapted from <ref> [53, p. 127] </ref>). Tree is a btree constructor from triples of type 'a btree * (int * 'a) * 'a btree. The type of the key is required to be int because of the use of the &lt; operator to compare keys.
Reference: [54] <editor> Ruben Prieto-D iaz and editors William B. Frakes. </editor> <booktitle> Advances in Software Reuse. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1993. </year>
Reference-contexts: Although much has been written about the problem of software reuse (for example, see <ref> [68, 46, 54] </ref>), including work on identifying reusable components [18, 8], we are unaware of previous work on the problem of automatically creating polymorphic functions from monomorphic functions.
Reference: [55] <author> Charles Rich and Richard C. Waters. </author> <title> Formalizing reusable software components in the Programmer's Apprentice. </title> <editor> In Ted. J. Biggerstaff and Alan J. Perlis, editors, </editor> <booktitle> Software Reusability Volume II: Applications and Experience, chapter 15, </booktitle> <pages> pages 313-343. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: In particular, this work may be contrasted with the problem of cliche recognition <ref> [55, 66] </ref>. Cliches are widely used algorithms and data structures (such as 13 stacks and stack operations) as well as commonly employed computational idioms such as iteration and filtering.
Reference: [56] <author> James Rumbaugh, Michael Blaha, William Premerlani, Frederick Eddy, and William Lorensen. </author> <title> Object-Oriented Modeling and Design. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year>
Reference-contexts: Maintenance tasks are often carried out by new software engineers, who these days are trained primarily in C++ and not in C. * Encapsulation. Information hiding (or encapsulation) is the separation of the external aspects (the interface) of a data type, from its internal implementation details <ref> [45, 56] </ref>. Encapsulation prevents a program from becoming so interdependent that small changes have large ripple effects. C++ supports private and protected members of classes, whereas C has no mechanism for encapsulation. * Type safety.
Reference: [57] <author> Houari A. Sahraoui, Walcelio Melo, Hakim Lounis, and Fran~cois Dumont. </author> <title> Applying concept formation methods to object identification in procedural code. </title> <type> Technical Report CRIM-97/05-77, </type> <institution> CRIM, </institution> <year> 1997. </year>
Reference-contexts: It is based on concept analysis, a branch of lattice theory that can be used to identify similarities among a set of objects based on their attributes. Our work compares favorably with contemporaneous work on on concept analysis and modularization by Lindig and Snelting [40] and Sahraoui et al. <ref> [57] </ref>. (See Section 3.7.) * Physical-subtype detection is also based on the imposition of a new type system on C programs. This type systems differs from the one employed in the 15 generalization problem by allowing subtype polymorphism instead of parametric polymorphism. <p> Other possibilities for attributes include the following: * Variable-usage information: Related functions can sometimes be identified by their use of common global variables. An attribute capturing this information might be of the form "uses global variable x" <ref> [40, 57] </ref>. * Dataflow and slicing information can be useful in identifying modules. <p> Concept analysis has been applied to many kinds of problems. Concept analysis was first applied to software engineering in the NORA/RECS tool, where it was used to identify conflicts in software-configuration information [60]. Contemporaneously with our own work, Lindig and Snelting [40] and Sahraoui et al. <ref> [57] </ref> independently explored the idea of applying concept analysis to the modulariza-tion problem. In both of these studies, the context relations used for concept analysis relate each function of the program to the global variables accessed by the function. <p> We discuss how our techniques are more flexible and powerful than several other modularization techniques. We contrast our work to that of Lindig and Snelting [40] and that of Sahraoui et al. <ref> [57] </ref>, both which also apply concept analysis to the modularization problem. Our results appear to be more successful than the results reported in their work because the concept lattices our tool generates remain of tractable size, even for medium-to-large C programs.
Reference: [58] <author> Michael Siff and Thomas Reps. </author> <title> Program generalization for software reuse: From C to C++. </title> <booktitle> In Fourth ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <pages> pages 135-146, </pages> <address> San Francisco, </address> <month> October </month> <year> 1996. </year> <month> 224 </month>
Reference-contexts: structure P = Power (structure S = struct type t = int val c = fn x =&gt; x val binOp = (op * ) : int * int -&gt; int end) val power = P.power 2.10 Related Work Many of the ideas of this chapter are also discussed in <ref> [58] </ref>. Although much has been written about the problem of software reuse (for example, see [68, 46, 54]), including work on identifying reusable components [18, 8], we are unaware of previous work on the problem of automatically creating polymorphic functions from monomorphic functions. <p> Attributes capturing this information might be of the form "may use a value that flows from statement s" or "is part of the slice with respect to statement s". * Information obtained from type inferencing: Type inference can be used to uncover distinctions between seemingly identical types (see <ref> [58, 51] </ref>). For example, if f is a function declared to be of type int fi int ! bool, type inference might discover that f 's most general type is of the form ff fi fi ! bool. <p> Section 3.7 describes related work in that area. This chapter has examined the related problem of determining how the (user-defined) types in a C program might be organized into a C++ class hierarchy. The idea of applying alternate type systems to C appears in several places, among them <ref> [27, 59, 50, 58, 61] </ref>. Most of these references discuss the application of parametric polymorphism to C (see Chapter 2), while in this Chapter we discuss the application of subtype polymorphism to C.
Reference: [59] <author> Geoffrey Smith and Dennis Volpano. </author> <title> Towards an ML-style polymorphic type system for C. </title> <booktitle> In 1996 European Symposium on Programming, </booktitle> <month> April </month> <year> 1996. </year> <note> to appear. </note>
Reference-contexts: The type-inference algorithm is based on Hindley-Milner type inference [31, 47], but with the augmentations specific to the C-to-C++ conversion problem: operator overloading, constructors, casts, etc. The idea of mixing polymorphism with C appears in several places, among them <ref> [59, 50] </ref>. [59] concerns a new dialect of C that is polymorphic and type safe. <p> The type-inference algorithm is based on Hindley-Milner type inference [31, 47], but with the augmentations specific to the C-to-C++ conversion problem: operator overloading, constructors, casts, etc. The idea of mixing polymorphism with C appears in several places, among them [59, 50]. <ref> [59] </ref> concerns a new dialect of C that is polymorphic and type safe. <p> A generalizer could be used to create code to be placed into libraries and the signature matcher could be used to retrieve generalized code. The idea of mixing polymorphism with C appears in several places, among them <ref> [27, 59, 50] </ref>. [59] concerns a new dialect of C that is polymorphic and type safe. <p> A generalizer could be used to create code to be placed into libraries and the signature matcher could be used to retrieve generalized code. The idea of mixing polymorphism with C appears in several places, among them [27, 59, 50]. <ref> [59] </ref> concerns a new dialect of C that is polymorphic and type safe. <p> Section 3.7 describes related work in that area. This chapter has examined the related problem of determining how the (user-defined) types in a C program might be organized into a C++ class hierarchy. The idea of applying alternate type systems to C appears in several places, among them <ref> [27, 59, 50, 58, 61] </ref>. Most of these references discuss the application of parametric polymorphism to C (see Chapter 2), while in this Chapter we discuss the application of subtype polymorphism to C. <p> Most of these references discuss the application of parametric polymorphism to C (see Chapter 2), while in this Chapter we discuss the application of subtype polymorphism to C. Section 2.10 describes related work pertaining to the application of parametric polymorphism to C. <ref> [59] </ref> concerns a new dialect of C that is polymorphic and type safe.
Reference: [60] <author> Gregor Snelting. </author> <title> Reengineering of configurations based on mathematical concept analysis. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 5(2) </volume> <pages> 146-189, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: An example of the application of the fundamental theorem is shown in Figure 40. There are several algorithms for computing the concept lattice for a given context <ref> [26, 60] </ref>. We describe a simple bottom-up algorithm here. An important fact about concepts and contexts used in the algorithm is that, given a set of objects X, the smallest concept with extent containing X is (t ((X)); (X)). <p> Concept analysis has been applied to many kinds of problems. Concept analysis was first applied to software engineering in the NORA/RECS tool, where it was used to identify conflicts in software-configuration information <ref> [60] </ref>. Contemporaneously with our own work, Lindig and Snelting [40] and Sahraoui et al. [57] independently explored the idea of applying concept analysis to the modulariza-tion problem.
Reference: [61] <author> Bjarne Steensgaard. </author> <title> Points-to analysis by type inference of programs with structures and unions. </title> <booktitle> In Proceedings of the 1996 International Conference on Compiler Construction, number 1060 in Lecture Notes in Computer Science, </booktitle> <pages> pages 136-150. </pages> <publisher> Springer-Verlag, </publisher> <month> April </month> <year> 1996. </year>
Reference-contexts: The type system focuses on the storage representation of aggregate data types and in that sense is similar in spirit to the work on pointer aliasing in the presence of struct and union types discussed in <ref> [61, 70] </ref>. 1.2 Organization of the Thesis The remaining chapters of this thesis are organized as follows: In Chapter 2, we consider the problem of identifying functions that can be generalized to C++ function templates that can operate on a wide variety of types. <p> Section 3.7 describes related work in that area. This chapter has examined the related problem of determining how the (user-defined) types in a C program might be organized into a C++ class hierarchy. The idea of applying alternate type systems to C appears in several places, among them <ref> [27, 59, 50, 58, 61] </ref>. Most of these references discuss the application of parametric polymorphism to C (see Chapter 2), while in this Chapter we discuss the application of subtype polymorphism to C. <p> union u is a subtype of a union u 0 , if each type of each member of u is a subtype of each type of each member of u 0 . (See Section 4.6.2 and Section 4.7.1.) Our work may be contrasted with the pointer-alias analyses described by Steens-gaard <ref> [61] </ref> and Zhang et al. [70]. The common use of pointer-alias analysis is for improving the precision of dataflow analyses for compile-time optimizations. However, pointer-alias detection can also be useful for program-comprehension tools and 211 software-engineering tools. <p> However, the system described in [70] has no provision for handling type casts and considers two structs to be related only if they are of equal type, whereas in our system we can relate one struct as a physical subtype of another. Steensgaard, in <ref> [61] </ref>, imposes a "non-standard" type system upon C programs and then uses type inference for the purpose of improving the efficiency and accuracy of points-to analysis.
Reference: [62] <author> Bjarne Stroustrup. </author> <title> The C++ Programming Language. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: In particular, C++ function templates are subject to the following restriction: Each template argument must affect the type of at least one of the function arguments <ref> [62, page 280] </ref>. Nor does C++ offer any way of expressing "the type of the i field in class T". <p> For example, a function template containing a cast (int)e can only 49 be called with arguments that have an int conversion, either predefined, as one has for arithmetic and pointer types, or explicitly defined (see <ref> [62, page 232] </ref>). <p> For example, a function template containing a cast (int)e can only be called with arguments that have an int conversion, either predefined, as one has for arithmetic and pointer types, or explicitly defined (see <ref> [62, page 232] </ref>). The intuition is that the type cast to long is really like a function that takes an argument from the source type (short in Figure 19) and returns a value of type long. <p> There is an abundance of C++ code that does not make use of templates because many C++ compilers did not correctly support templates in early versions. 2. It is often easier to develop and test code written in terms of specific types, even if the code is general. Stroustrup, <ref> [62, p. 257] </ref>, argues that "it is usually a good idea to debug a particular class before turning it into a template." 3. It is not always easy to identify opportunities for generalization in classes and functions by casual inspection. <p> Type inference is then used to determine which types can be generalized and made into template arguments. The result of the generalization is a class template. An example: Stack template The following example, adapted from <ref> [62, pages 256-257] </ref>, demonstrates how the generalization paradigm can be used to transform C++ classes into template classes. A class representing a stack of integers is defined in Figure 22. For simplicity, the stack ignores such issues as underflow and overflow.
Reference: [63] <author> Mads Tofte. </author> <title> Type inference for polymorphic references. </title> <journal> Information and Computation, </journal> <volume> 89 </volume> <pages> 1-34, </pages> <year> 1990. </year>
Reference-contexts: Type schemes are of the form: ::= t j8ff: 42 A type environment, te, is a map from program variables to type schemes. As demonstrated in <ref> [63] </ref>, polymorphic type inference in the presence of imperative programming features can make a Milner-style type system unsound. The type unsoundness arises in the use of polymorphic references|it is unsafe to treat the same memory cell as two different types.
Reference: [64] <author> Mark Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(4):352-357, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: This reveals 2 Some legacy code is monolithic|multiple tasks are contained within one function. In such cases, it may be preferable to have objects correspond to slices <ref> [64, 32] </ref> rather than functions. 103 that the type of f 's first argument is distinct from the type of its second argument (even though they had the same declared type). <p> Canfora et al. discuss two types of links that cause undesirable clustering of functions [9]. The first type, "coincidental links", caused by routines that implement more than one function, can be overcome by program slicing <ref> [64, 32] </ref>. The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. In most of the approaches mentioned above, spurious links arise from a function that accesses several global variables of different types.
Reference: [65] <author> Rudolf Wille. </author> <title> Restructuring lattice theory: An approach based on hierarchies of concepts. </title> <editor> In Ivan Rival, editor, </editor> <booktitle> Ordered Sets, </booktitle> <pages> pages 445-470. </pages> <institution> NATO Advanced Study Institute, </institution> <month> September </month> <year> 1981. </year>
Reference-contexts: intelligent marine thumbed cats p p objects dogs p p dolphins p p gibbons p p p humans p p whales p p Table 2: A crude characterization of mammals. 3.2 A Concept Analysis Primer Concept analysis provides a way to identify sensible groupings of objects that have common attributes <ref> [65] </ref>. To illustrate concept analysis, we consider the example of a crude classification of a group of mammals: cats, gibbons, dogs, dolphins, humans, and whales. Suppose we consider five attributes: four-legged, hair-covered, intelligent, marine, and thumbed. Table 2 shows which animals are considered to have which attributes. <p> The concept lattice for the mammal example is shown in Figure 39. Each node in the lattice represents a concept. A key indicating the extent and intent of each concept is shown in Table 3. The fundamental theorem for concept lattices <ref> [65] </ref> relates subconcepts and super-concepts as follows: 88 top (fcats; gibbons; dogs; dolphins; humans; whalesg; ;) c 5 (fgibbons; dolphins; humans; whalesg; fintelligentg) c 4 (fcats; gibbons; dogsg; fhair-coveredg) c 3 (fgibbons; humansg; fintelligent; thumbedg) c 2 (fdolphins, whalesg; fintelligent; marineg) c 1 (fgibbonsg; fhair-covered; intelligent; thumbedg) c 0 (fcats; dogsg; <p> This work (implicitly or explicitly) involves the identification of potential modules by determining a similarity measure among pairs of functions. We are currently investigating the link between concept analysis and cluster analysis. [22] offers background on lattice theory and an introduction to concept analysis. <ref> [65] </ref> formalizes the notions of concept analysis and provides a proof of the fundamental theorem. Concept analysis has been applied to many kinds of problems. Concept analysis was first applied to software engineering in the NORA/RECS tool, where it was used to identify conflicts in software-configuration information [60].
Reference: [66] <author> Linda Wills. </author> <title> Automated Program Recognition by Graph Parsing. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> July </month> <year> 1992. </year> <month> 225 </month>
Reference-contexts: In particular, this work may be contrasted with the problem of cliche recognition <ref> [55, 66] </ref>. Cliches are widely used algorithms and data structures (such as 13 stacks and stack operations) as well as commonly employed computational idioms such as iteration and filtering.
Reference: [67] <author> Alexander Yeh, David R. Harris, and Howard B. Reubenstein. </author> <title> Recovering abstract data types and object instances from a conventional procedural language. </title> <booktitle> In Second Working Conference on Reverse Engineering, </booktitle> <pages> pages 227-236, </pages> <year> 1995. </year>
Reference-contexts: The resulting information can then be supplied to a suitable transformation tool that maps C code to C++ code, as in the aforementioned example. Although other modularization algorithms are able to identify the same decomposition <ref> [10, 67] </ref>, they are unable to handle a variant of this example in which stacks and queues are more tightly intertwined (see Section 3.3.2). In Section 3.3.2, we show that concept analysis is able to group the code from the latter example into separate queue and stack modules. <p> It is relatively straightforward to separate the code shown in Figure 37 into two modules, and techniques such as those described in <ref> [10, 67] </ref> will also create the same grouping. We now show that concept analysis offers the possibility to go beyond previously defined methods: It offers the ability to tease apart code that is, in some sense, more "tangled". <p> The second type, "spurious links", is caused by functions that access supporting data structures of more than one object type. In most of the approaches mentioned above, spurious links arise from a function that accesses several global variables of different types. The work described in <ref> [42, 17, 43, 67, 9] </ref> will all stumble on examples that exhibit spurious links. In our approach, an analogous kind of spurious link arises due to functions that access internal fields of more than one struct.
Reference: [68] <author> Mansour Zand and Mansur Samadzadeh. </author> <title> Special issue on software reuse. </title> <journal> Journal of Systems Software, </journal> <volume> 30(3), </volume> <month> September </month> <year> 1995. </year>
Reference-contexts: Although much has been written about the problem of software reuse (for example, see <ref> [68, 46, 54] </ref>), including work on identifying reusable components [18, 8], we are unaware of previous work on the problem of automatically creating polymorphic functions from monomorphic functions.
Reference: [69] <author> Amy Moorman Zaremski and Jeannette M. Wing. </author> <title> Signature matching: a tool for using software libraries. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <month> April </month> <year> 1995. </year>
Reference-contexts: In other words, whereas NORA supports the use of polymorphic components, our goal is to provide support for extracting such components from existing code. Our work may also be contrasted with the signature-matching tool described in <ref> [69] </ref>. While that work also employs type inference to facilitate software reuse, it does so by assisting the user in finding suitable code from software libraries rather than 80 automatically producing generalized code. A signature matching tool might work nicely in conjunction with the work described in this chapter.
Reference: [70] <author> Sean Zhang, Barbara G. Ryder, and William Landi. </author> <title> Program decomposition for pointer aliasing: A step toward practical analyses. </title> <booktitle> In Fourth ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <pages> pages 81-92, </pages> <address> San Fran-cisco, </address> <month> October </month> <year> 1996. </year> <month> 226 </month>
Reference-contexts: The type system focuses on the storage representation of aggregate data types and in that sense is similar in spirit to the work on pointer aliasing in the presence of struct and union types discussed in <ref> [61, 70] </ref>. 1.2 Organization of the Thesis The remaining chapters of this thesis are organized as follows: In Chapter 2, we consider the problem of identifying functions that can be generalized to C++ function templates that can operate on a wide variety of types. <p> of a union u 0 , if each type of each member of u is a subtype of each type of each member of u 0 . (See Section 4.6.2 and Section 4.7.1.) Our work may be contrasted with the pointer-alias analyses described by Steens-gaard [61] and Zhang et al. <ref> [70] </ref>. The common use of pointer-alias analysis is for improving the precision of dataflow analyses for compile-time optimizations. However, pointer-alias detection can also be useful for program-comprehension tools and 211 software-engineering tools. These applications of pointer-alias analysis resemble some of the uses of physical subtyping described in Section 4.8. In [70], <p> <ref> [70] </ref>. The common use of pointer-alias analysis is for improving the precision of dataflow analyses for compile-time optimizations. However, pointer-alias detection can also be useful for program-comprehension tools and 211 software-engineering tools. These applications of pointer-alias analysis resemble some of the uses of physical subtyping described in Section 4.8. In [70], a subtype-like relationship called a weakly right-regular relation is defined for pairs of C expressions. The definition of the relation has some of the flavor of the physical-subtyping rules discussed in this chapter. <p> The definition of the relation has some of the flavor of the physical-subtyping rules discussed in this chapter. For example, if x is related to x 0 and both are pointers, then *x is related to *x 0 . However, the system described in <ref> [70] </ref> has no provision for handling type casts and considers two structs to be related only if they are of equal type, whereas in our system we can relate one struct as a physical subtype of another.
References-found: 70

