URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-296.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Tracking Using a Local Closed-World Assumption: Tracking in the Football Domain  
Author: by Stephen S. Intille Advisor: Aaron F. Bobick 
Degree: in partial fulfillment of the requirements for the degree of Master of Science in Media Arts and Sciences  
Date: August 5, 1994  
Affiliation: Media Arts and Sciences, School of  
Note: Submitted to the Program in  Architecture and Planning on  This work was supported in part by a grant from Interval Research.  
Abstract: M.I.T. Media Lab Perceptual Computing Group Technical Report No. 296 Abstract In this work we address the problem of tracking objects in a complex, dynamic scene. The objects are non-rigid and difficult to model geometrically. Their motion is erratic and they change shape rapidly between frames sampled at 30 frames per second. The objects have low spatial resolution, and the video used for tracking was taken with a panning and zooming camera. Finally, the objects are tracked in sequences up to eight seconds long while moving over a complex background. We suggest that conventional tracking methods are unlikely to perform well at tracking small objects in complex environments because they do not use contextual information to drive feature selection. We propose using closed-world analysis to incorporate contextual knowledge into low-level tracking. A closed-world is a space-time region of an image where contextual information like the number and type of objects within the region is assumed to be known. Given that knowledge, the region can be analyzed locally using image processing algorithms and context-specific features can be selected for tracking. A context-specific feature is one that has been chosen based upon the context to maximize the chance of successful tracking between frames. We test our algorithm in the football domain. We describe how closed-world analysis and context-specific tracking can be applied to tracking football players and present the details of our implementation. We include tracking results that demonstrate the wide range of tracking situations the algorithm will successfully handle as well as a few examples of where the algorithm fails. Finally, we suggest some improvements and future extensions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.E. Allen and C.E. Thorpe. </author> <title> Some approaches to finding birds in video imagery. </title> <type> Robotics Institute Technical Report 91-34, </type> <institution> Carnegie Mellon University, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: The authors suggest that simple vision routines like color histogramming are only effective when contextual information has significantly narrowed the visual search space. 17 Allen designs four algorithms that track or locate four different types of birds in low-resolution video imagery <ref> [1] </ref>. The authors find that no single method will work and that the best method depends upon the state of the birds (i.e. flying or resting), the type of the birds, and the location of the birds. In crowded scenes of the Musse colony, template matching is used.
Reference: [2] <author> M. Allmen and C.R. Dyer. </author> <title> Computing spatiotemporal surface flow. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <pages> pages 47-50, </pages> <year> 1990. </year>
Reference-contexts: In practice, simplifying assumptions are often made when tracking objects in space-time volumes. Bolles [12] makes the simplifying assumption that the camera is moving linearly and uses the features in the epipolar plane to track points. Other authors make similar 15 simplifying assumptions <ref> [2, 3] </ref>. Baker extends the method to arbitrary camera geometries by use of spatio--temporal surfaces [6], but the method requires finding meaningful edges in three space that is difficult in practice. Nakanishi has used spatio-temporal analysis to extract length and velocity information on vehicles [34].
Reference: [3] <author> M. Allmen and C.R. Dyer. </author> <title> Long-range spatiotemporal motion understanding using spatiotemporal flow curves. </title> <booktitle> In Proc. Comp. Vis. and Pattern Rec., </booktitle> <pages> pages 303-309, </pages> <year> 1991. </year>
Reference-contexts: In practice, simplifying assumptions are often made when tracking objects in space-time volumes. Bolles [12] makes the simplifying assumption that the camera is moving linearly and uses the features in the epipolar plane to track points. Other authors make similar 15 simplifying assumptions <ref> [2, 3] </ref>. Baker extends the method to arbitrary camera geometries by use of spatio--temporal surfaces [6], but the method requires finding meaningful edges in three space that is difficult in practice. Nakanishi has used spatio-temporal analysis to extract length and velocity information on vehicles [34].
Reference: [4] <author> E. Andre, G. Gerzog, and T. Rist. </author> <title> On the simultaneous intepretation of real world image sequences and their natural language descriptions: the system soccer. </title> <booktitle> In Proc. European Conf. AI, </booktitle> <pages> pages 449-454, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The system uses no visual input. Conceivably, accurately tracked players could be used as input to a COACH-like system that attempted to improve the types of plays run by a particular team. The SOCCER system <ref> [4] </ref> generates incremental linguistic reports of short sections of a soccer game by taking player temporal trajectories as input. The authors speculate that a vision system could provide the tracked input data, although the input was actually generated manually and assumed to be noise-free for the testing of SOCCER.
Reference: [5] <author> S. Ayer, P. Schroeter, and J. Bigun. </author> <title> Segmentation of moving objects by robust motion parameter estimation over multiple frames. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <volume> volume 2, </volume> <pages> pages 316-327, </pages> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The most common motion model assumes that an object is moving with a constant velocity or a smoothly changing path. Occasionally acceleration is modeled, but noisy image data and spatial and temporal subsampling can make acceleration estimation difficult. Some techniques that use a smooth motion model are described in <ref> [19, 43, 21, 25, 11, 23, 5] </ref>. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features [46].
Reference: [6] <author> H.H. Baker and R.C. Bolles. </author> <title> Generalizing epipolar-plane image analysis on the spatiotemporal surface. </title> <journal> Int. J. of Comp. Vis., </journal> <volume> 3 </volume> <pages> 33-49, </pages> <year> 1989. </year>
Reference-contexts: Bolles [12] makes the simplifying assumption that the camera is moving linearly and uses the features in the epipolar plane to track points. Other authors make similar 15 simplifying assumptions [2, 3]. Baker extends the method to arbitrary camera geometries by use of spatio--temporal surfaces <ref> [6] </ref>, but the method requires finding meaningful edges in three space that is difficult in practice. Nakanishi has used spatio-temporal analysis to extract length and velocity information on vehicles [34].
Reference: [7] <author> A. Baumberg and D. Hogg. </author> <title> Learning flexible models from image sequences. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <volume> volume 1, </volume> <pages> pages 299-308, </pages> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Cootes and Baumberg both use a flexible shape point distribution model that describes objects using a silhouette defined by a spline. Cootes [14] hand-labels points on a set of objects and then uses principal components analysis to find significant modes that the shape may assume. Baumberg <ref> [7] </ref> builds upon this method by automatically extracting object silhouettes given a stationary camera and no occlusion and then using the recovered modes to create a shape model constrained by likely changes over time and directionality. The shape model is used for simple non-occlusion tracking. <p> The majority of tracking algorithms for objects in complex scenes use a static camera for sequence acquisition <ref> [7, 21, 50, 40, 27] </ref>. Often these methods depend upon on accurate difference motion blob generation that might not be attainable with a complexly moving camera.
Reference: [8] <author> M. Berthod. </author> <title> Approximation polygonale de chanes de contours. Programmes c, </title> <institution> INRIA, INRIA Sophia-Antipolis, F-06565 Valbonne Cedex, </institution> <year> 1986. </year>
Reference-contexts: The intersection points between the side lines and yard lines can also be used. 2 4.5 Image-model rectification implementation details The details of the football image-model rectification are as follows. Edges are extracted from the original football imagery a frame at a time using edge-finding software developed at INRIA <ref> [16, 20, 8] </ref>. The recovered lines are classified into yard lines or side lines based upon orientation. Line-linking software using the slope of the lines merges line segments that are significantly close in space and orientation and form a single line.
Reference: [9] <author> M. Bichsel. </author> <title> Segmenting simply connected moving objects in a static scene. </title> <institution> Dept. of Computer Science Multi-Media Laboratory Technical Report, University of Zurich, </institution> <year> 1993. </year>
Reference-contexts: Given still cameras, accurate motion blobs can be extracted from video using simple but effective background differencing schemes and median filtering <ref> [9] </ref>. However, 27 The geometrical features (i.e. lines) are modeled precisely. The turf (shown in black here), numbers, and field logos are modeled using approximate pixel-map representations extracted from the image sequence. some useful tracking tasks require that tracking algorithms analyze video recorded with a moving camera.
Reference: [10] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> Affine-invariant contour tracking with automatic control of spatiotemporal scale. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <pages> pages 66-75, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Choosing a appropriate energy model is the key component of any successful system. A few relevant works are described below. Blakes's energy-based deformation model <ref> [10] </ref> illustrates the type of deformation model studied recently. An affine-invariant template using a b-spline curve and the Mahalanobis distance is combined with a Kalman velocity filter to track objects with high contrast edges.
Reference: [11] <author> S.D. Blostein and T.S. Huang. </author> <title> Detecting small, moving objects in image sequences using sequential hypothesis testing. </title> <journal> IEEE Trans. Signal Proc., </journal> <volume> 39(7) </volume> <pages> 1611-1629, </pages> <year> 1991. </year>
Reference-contexts: The most common motion model assumes that an object is moving with a constant velocity or a smoothly changing path. Occasionally acceleration is modeled, but noisy image data and spatial and temporal subsampling can make acceleration estimation difficult. Some techniques that use a smooth motion model are described in <ref> [19, 43, 21, 25, 11, 23, 5] </ref>. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features [46].
Reference: [12] <author> R. Bolles, H. Baker, and D. Marimont. </author> <title> Epipolar-plane image analysis: an approach to determining structure from motion. </title> <journal> Int. J. of Comp. Vis., </journal> <volume> 1 </volume> <pages> 7-55, </pages> <year> 1987. </year>
Reference-contexts: In principle, the analysis can be used to find occluded and occluding objects. In practice, simplifying assumptions are often made when tracking objects in space-time volumes. Bolles <ref> [12] </ref> makes the simplifying assumption that the camera is moving linearly and uses the features in the epipolar plane to track points. Other authors make similar 15 simplifying assumptions [2, 3].
Reference: [13] <author> G. Collins. </author> <title> Plan creation: using strategies as blueprints. </title> <institution> Computer Science Dept., </institution> <type> Technical Report RR 599, </type> <institution> Yale University Department of Computer Science, </institution> <month> May </month> <year> 1987. </year>
Reference-contexts: The COACH, SOCCER, and REPLAI projects would all directly benefit from accurate sports player tracking. The COACH system <ref> [13] </ref> looks at forced plan creation by studying the football domain. Given a particular defensive play, the system generates a new offensive play using several domain-independent transformation rules. The system uses no visual input.
Reference: [14] <author> T.J. Cootes, C.J. Taylor, D.H. Cooper, and J. Graham. </author> <title> Training models of shape from sets of examples. </title> <booktitle> In Proc. British Mach. Vis. Conf., </booktitle> <pages> pages 9-18, </pages> <month> September </month> <year> 1992. </year> <month> 58 </month>
Reference-contexts: In the work developed here, we specifically design our tracker to select the features for tracking that are most likely to successfully match in the next frame. Cootes and Baumberg both use a flexible shape point distribution model that describes objects using a silhouette defined by a spline. Cootes <ref> [14] </ref> hand-labels points on a set of objects and then uses principal components analysis to find significant modes that the shape may assume.
Reference: [15] <author> T. Darrell, I. Essa, and A. Pentland. </author> <title> Correlationa dn interpolation networks for real-time expression analysis/synthesis. </title> <type> Perceptual Computing Technical Report 284, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1994. </year>
Reference-contexts: More detail on correlation can be found in [44]. Basic correlation with a static template is often designed into real-time vision systems using specialized hardware <ref> [15] </ref>. Unfortunately, correlation templates are sensitive to occlusion and small changes in the patch being tracked in adjacent frames. This sensitivity is particularly problematic in scenes where objects can deform or collide. A zooming camera can also generate undesirable patch changes between adjacent frames.
Reference: [16] <author> R. Deriche. </author> <title> Using Canny's criteria to derive an optimal edge detector recursively implemented. </title> <journal> Int. J. of Comp. Vis., </journal> <volume> 2 </volume> <pages> 167-187, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: The intersection points between the side lines and yard lines can also be used. 2 4.5 Image-model rectification implementation details The details of the football image-model rectification are as follows. Edges are extracted from the original football imagery a frame at a time using edge-finding software developed at INRIA <ref> [16, 20, 8] </ref>. The recovered lines are classified into yard lines or side lines based upon orientation. Line-linking software using the slope of the lines merges line segments that are significantly close in space and orientation and form a single line.
Reference: [17] <author> R. Deriche and O. Faugeras. </author> <title> Tracking line segments. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <pages> pages 259-268, </pages> <address> Antibes, France, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: The goal is to find features that are robust to the changes expected between frames in the imagery. Edgel-tracking is generally more robust to lighting changes than correlation and often excellent for tracking rigid objects with high contrast. An illustrative edge tracking scheme has been developed by Deriche <ref> [17] </ref>. A Kalman filter predicts the location of an edge and the Mahalanobis distance is used to compute a matching score. A more sophisticated tracker recently described by Sawhney uses a four parameter affine model that handles scale, rotation and translation to track collections of lines [42].
Reference: [18] <author> D.D. Fu, K.J. Hammond, and M.J. Swain. </author> <title> Vision and navigation in man-made environments: looking for syrup in all the right places. </title> <booktitle> In Proc. Work. Visual Behaviors, </booktitle> <pages> pages 20-26, </pages> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: A system that uses the knowledge about regularities in grocery stores to find objects is being designed by Fu <ref> [18] </ref>. SHOPPER attempts to find products like Mrs. Butterworth's pancake mix by using contextual information like cereals are grouped together and cereals sit on shelves. The current context is used to select which of three different visual routines should be used for the search.
Reference: [19] <author> J.P. Gambotto. </author> <title> Correspondence analysis for target tracking in infared images. </title> <booktitle> In Proc. Int. Conf. Pattern Rec., </booktitle> <pages> pages 526-529, </pages> <address> Montreal, Canada, </address> <year> 1984. </year>
Reference-contexts: The most common motion model assumes that an object is moving with a constant velocity or a smoothly changing path. Occasionally acceleration is modeled, but noisy image data and spatial and temporal subsampling can make acceleration estimation difficult. Some techniques that use a smooth motion model are described in <ref> [19, 43, 21, 25, 11, 23, 5] </ref>. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features [46].
Reference: [20] <author> G. Giraudon. </author> <title> Chanage efficace contour. </title> <institution> Rapport de Recherche 605, INRIA, Sophia-Antipolis, France, </institution> <month> Februrary </month> <year> 1987. </year>
Reference-contexts: The intersection points between the side lines and yard lines can also be used. 2 4.5 Image-model rectification implementation details The details of the football image-model rectification are as follows. Edges are extracted from the original football imagery a frame at a time using edge-finding software developed at INRIA <ref> [16, 20, 8] </ref>. The recovered lines are classified into yard lines or side lines based upon orientation. Line-linking software using the slope of the lines merges line segments that are significantly close in space and orientation and form a single line.
Reference: [21] <author> G.L. Gordon. </author> <title> On the tracking of featureless objects with occlusion. </title> <booktitle> In Proc. Work. Visual Motion, </booktitle> <pages> pages 13-20, </pages> <year> 1989. </year>
Reference-contexts: The most common motion model assumes that an object is moving with a constant velocity or a smoothly changing path. Occasionally acceleration is modeled, but noisy image data and spatial and temporal subsampling can make acceleration estimation difficult. Some techniques that use a smooth motion model are described in <ref> [19, 43, 21, 25, 11, 23, 5] </ref>. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features [46]. <p> The majority of tracking algorithms for objects in complex scenes use a static camera for sequence acquisition <ref> [7, 21, 50, 40, 27] </ref>. Often these methods depend upon on accurate difference motion blob generation that might not be attainable with a complexly moving camera.
Reference: [22] <author> U. Gupta. </author> <title> High-tech eye finds its place on playing field. </title> <journal> Wall Street Journal, </journal> <note> January 10, Section B 1990. </note>
Reference-contexts: First, football player tracking is a real annotation problem with an immediate, practical application. The football video used in this work was obtained from Boston College. Like nearly all other professional and collegiate football teams, the Boston College team has a computerized play database <ref> [22] </ref>. A team employee tapes each play every game from a pan and zoom camera above the stadium. After the game, approximately thirty pieces of play information are entered into the computer database system. The information recorded includes video timecodes, formation, play called, defensive formation, and the play result.
Reference: [23] <author> C. Huang and C. Wu. </author> <title> Dynamic scene analysis using path and shape coherence. </title> <journal> Pattern Recognition, </journal> <volume> 25(5) </volume> <pages> 245-461, </pages> <year> 1992. </year>
Reference-contexts: The most common motion model assumes that an object is moving with a constant velocity or a smoothly changing path. Occasionally acceleration is modeled, but noisy image data and spatial and temporal subsampling can make acceleration estimation difficult. Some techniques that use a smooth motion model are described in <ref> [19, 43, 21, 25, 11, 23, 5] </ref>. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features [46].
Reference: [24] <author> D. Huttenlocher, P. Noh, J. Jae, and J. William. </author> <title> Tracking non-rigid objects in complex scenes. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <address> Berlin, Germany, </address> <month> September </month> <year> 1999. </year>
Reference-contexts: A more sophisticated tracker recently described by Sawhney uses a four parameter affine model that handles scale, rotation and translation to track collections of lines [42]. Huttenlocher uses a more unusual edge-based tracking for tracking non-rigid, high-resolution images of people <ref> [24] </ref>. A 2D shape feature for matching is computed from the edges of binary background subtraction. Assuming gradual shape change between frames, direct matching of the edge shapes for tracking is performed using the Hausdorff distance and a motion predictor. The shape model is revised at each timestep.
Reference: [25] <author> V.S.S. Hwang. </author> <title> Tracking feature points in time-varying images using an opportunistic selection approach. </title> <journal> Pattern Recognition, </journal> <volume> 22(3) </volume> <pages> 247-256, </pages> <year> 1989. </year>
Reference-contexts: The most common motion model assumes that an object is moving with a constant velocity or a smoothly changing path. Occasionally acceleration is modeled, but noisy image data and spatial and temporal subsampling can make acceleration estimation difficult. Some techniques that use a smooth motion model are described in <ref> [19, 43, 21, 25, 11, 23, 5] </ref>. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features [46].
Reference: [26] <author> T. Kawashima, K. Yoshino, and Y. Aoki. </author> <title> Qualititative image analysis of group behavior. </title> <booktitle> In Proc. Comp. Vis. and Pattern Rec., </booktitle> <pages> pages 690-693, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Retz-Schmidt's system, REPLAI [38], takes the events recovered by SOCCER and attempts to determine the intention of the player actions, where intention is considered to be an unfinished plan [38, 39]. Synthetic input is still used by SOCCER. Finally, Kawashima <ref> [26] </ref> analyzes the group behavior of soccer players using color histogram backpro-jection to isolate players on each team. Player blobs located using the histograms are grouped hierarchically and the authors suggest that the relationship between the scaled groupings can be used for dynamic scene interpretation.
Reference: [27] <author> D. Koller, K. Daniilidis, and H.-H. Nagel. </author> <title> Model-based object tracking in monocular image sequences of road traffic scenes. </title> <journal> Int. J. of Comp. Vis., </journal> <volume> 10(3) </volume> <pages> 257-281, </pages> <year> 1993. </year>
Reference-contexts: The background frame is usually obtained using median filtering in time from video taken with a static camera. Background differencing with a static camera is frequently used as the first stage of input for a tracking system <ref> [40, 41, 27] </ref>. The blobs are matched based upon size and shape characteristic and sometimes combined with model information. Trackers using motion differencing generally require relatively high contour accuracy and authors do not propose methods of dealing with panning and zooming video. <p> Tracking is only performed on isolated cars with a stationary background and a much simpler tracker might have sufficed given those conditions. Koller's vehicle tracker <ref> [27] </ref> has been updated to use optical flow analysis by Kollnig [30]. That system uses the output from 3D blob tracking to characterize vehicle actions by motion verbs in an intersection scene more complex than those used in previous vehicle tracking work. <p> The majority of tracking algorithms for objects in complex scenes use a static camera for sequence acquisition <ref> [7, 21, 50, 40, 27] </ref>. Often these methods depend upon on accurate difference motion blob generation that might not be attainable with a complexly moving camera.
Reference: [28] <author> D. Koller, K. Daniilidis, T. Thorhallsson, and H.-H. Nagel. </author> <title> Model-based object tracking in traffic scenes. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <pages> pages 437-452, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Using a twelve parameter model of a car that model object shadows, Koller tracks cars assumed to be traveling in a circular path around a rotary using a recursive motion estimator <ref> [28] </ref>. Driver intent is modeled as noise within a MAP model and the Mahalanobis distance is used for matching image data and 3D model line segments. Tracking is only performed on isolated cars with a stationary background and a much simpler tracker might have sufficed given those conditions. <p> In the examples shown so far, players have crossed field line and hashmark features. The method also performs well on more complicated examples where players change direction quickly and run over field numbers. Erratically-moving objects are problematic for Kalman filter based trackers that estimate velocity <ref> [28] </ref>. Figure 6-6 shows the result of tracking the right outside linebacker for 230 frames. The player starts standing still, accelerates to a sprint while running over several field numbers, and then stops and changes direction.
Reference: [29] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust multiple car tracking with occlusion reasoning. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <volume> volume 1, </volume> <pages> pages 189-196, </pages> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The use of the ground plane is noteworthy because it is a piece of knowledge not directly associated with the vehicle model. It is instead a bit of contextual knowledge based upon the position of the vehicle in the world. Koller also included a bit of contextual knowledge <ref> [29] </ref>. Given the direction of a road upon which vehicles are to be tracked, an occlusion reasoning step is invoked. Instead of determining the occlusion based solely upon the image and model data, the directionality of the road, which is a significant occlusion indicator, is used to direct processing.
Reference: [30] <author> H. Kollnig, H.-H. Nagel, and M. Otte. </author> <title> Association of motion verbs with vehicle movements extracted from dense optical flow fields. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <volume> volume 2, </volume> <pages> pages 338-347, </pages> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Tracking is only performed on isolated cars with a stationary background and a much simpler tracker might have sufficed given those conditions. Koller's vehicle tracker [27] has been updated to use optical flow analysis by Kollnig <ref> [30] </ref>. That system uses the output from 3D blob tracking to characterize vehicle actions by motion verbs in an intersection scene more complex than those used in previous vehicle tracking work.
Reference: [31] <author> R.F. Marslin, G.D. Sullivan, and K.D. Baker. </author> <title> Kalman filters in constrained model-based tracking. </title> <booktitle> In Proc. British Mach. Vis. Conf., </booktitle> <pages> pages 371-374, </pages> <address> Glasgow, UK, </address> <month> September </month> <year> 1991. </year> <month> 59 </month>
Reference-contexts: The technique is sensitive to objects that occlude vehicles. In a companion paper, Marslin extends the tracking to use estimates of speed and orientation using a Kalman filter <ref> [31] </ref>. Using a twelve parameter model of a car that model object shadows, Koller tracks cars assumed to be traveling in a circular path around a rotary using a recursive motion estimator [28].
Reference: [32] <author> J. Mundy. </author> <title> Draft document on MORSE. </title> <type> Technical report, </type> <institution> General Electric Company Research and Development Center, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: The Condor system treats objects as component parts of larger contexts from which they cannot be separated. Objects have no independent existence. Strat notes that it is easier to design visual routines that work within some specified context. Mundy's MORSE system <ref> [32] </ref> will operate using a closed-world assumption that all data in a modelboard scene should be consistent with all the rules and objects known to exist in the domain. MORSE assumes a simple explanation for the closed space and then gradually works up to the most complicated examples.
Reference: [33] <author> H.-H. Nagel. </author> <title> From image sequences towards conceptual descriptions. </title> <journal> Image and Vision Comp., </journal> <volume> 6(2) </volume> <pages> 59-74, </pages> <year> 1988. </year>
Reference-contexts: Visual routines for computing the internal state can be selected using the context of the closed-world and any information that has already been learned about the state within the world. A few authors develop systems that use contextual information and a closed-world-like assumption. Nagel <ref> [33] </ref> has hinted at using a closed-world assumption when building systems that extract conceptual descriptions from image sequences. He states, the system should be endowed with an exhaustive internal representation for all tasks and environmental conditions it is expected to handle in order to serve its purpose.
Reference: [34] <author> T. Nakanishi and K. Ishii. </author> <title> Automatic vehicle image extraction based on spatio-temporal image analysis. </title> <booktitle> In Proc. Int. Conf. Pattern Rec., volume A, </booktitle> <pages> pages 500-504, </pages> <year> 1992. </year>
Reference-contexts: Baker extends the method to arbitrary camera geometries by use of spatio--temporal surfaces [6], but the method requires finding meaningful edges in three space that is difficult in practice. Nakanishi has used spatio-temporal analysis to extract length and velocity information on vehicles <ref> [34] </ref>. To do so, however, the author assumes that the vehicles move with constant velocity along a straight road orthogonal to the camera. The method works with a stationary background, simple object motion, a restriction on the type of occlusion that can occur, and rigid objects.
Reference: [35] <author> Newsweek. </author> <title> The Americans' secret weapon. </title> <booktitle> Newsweek, </booktitle> <pages> page 41, </pages> <month> July 11 </month> <year> 1994. </year>
Reference-contexts: Ideally, the information that is manually entered for each play could be entered by an automatic computer annotation vision system. Video sports databases like the system at Boston College are growing in popularity in the football community and other sports <ref> [35] </ref>. Even high schools are predicted to be using the systems in the 5 near future, which will only increase the demand for an automatic sports tracking and annotation system.
Reference: [36] <author> P.N. Prokopowicz, M.J. Swain, and R.E. Kahn. </author> <title> Task and environment-sensitive tracking. </title> <booktitle> In Proc. Work. Visual Behaviors, </booktitle> <pages> pages 73-78, </pages> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Context-based tracking methods are much more likely to transfer to other domains than methods that only use one piece of particularly useful information. The next section summarizes a few systems that use context-based knowledge. 2.2.3 Context-based knowledge Prokopowicz <ref> [36] </ref> has constructed a real-time active vision target tracking platform. Contextual information about the current task, target characteristics, and the tracking environment are used to select the best visual tracking routines. The routine selection is computed using the output of several state condition indicators like busy background.
Reference: [37] <author> J.M. Rehg and A.P. Witkin. </author> <title> Visual tracking with deformation models. </title> <booktitle> In Proc. IEEE Int. Conf. Robotics and Automation, </booktitle> <year> 1991. </year>
Reference-contexts: Two authors have developed energy-based template matchers that are unusual because each uses multiple types of intensity features to match a single template with the image. With Rehg's energy-based deformation model <ref> [37] </ref>, a 2D deformable patch acts as an intermediate representation between the image and a 3D model. The patch defines the pixels being tracked and constrains the interpretation of motion.
Reference: [38] <author> G. Retz-Schmidt. </author> <title> Recognizing intentions in the domain of soccer games. </title> <booktitle> In Proc. European Conf. AI, </booktitle> <pages> pages 455-457, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Player states like tackle, have ball, and pass must be known. Such descriptors are likely to be difficult to obtain from video in which the ball may be barely visible and will require a sophisticated object tracking system that uses contextual knowledge during tracking. Retz-Schmidt's system, REPLAI <ref> [38] </ref>, takes the events recovered by SOCCER and attempts to determine the intention of the player actions, where intention is considered to be an unfinished plan [38, 39]. Synthetic input is still used by SOCCER. <p> Retz-Schmidt's system, REPLAI [38], takes the events recovered by SOCCER and attempts to determine the intention of the player actions, where intention is considered to be an unfinished plan <ref> [38, 39] </ref>. Synthetic input is still used by SOCCER. Finally, Kawashima [26] analyzes the group behavior of soccer players using color histogram backpro-jection to isolate players on each team.
Reference: [39] <author> G. Retz-Schmidt. </author> <title> Recognizing intentions, interactions, and causes of plan failures. </title> <booktitle> User modeling and use-adapted interaction, </booktitle> <volume> 1(2) </volume> <pages> 173-202, </pages> <year> 1991. </year>
Reference-contexts: Retz-Schmidt's system, REPLAI [38], takes the events recovered by SOCCER and attempts to determine the intention of the player actions, where intention is considered to be an unfinished plan <ref> [38, 39] </ref>. Synthetic input is still used by SOCCER. Finally, Kawashima [26] analyzes the group behavior of soccer players using color histogram backpro-jection to isolate players on each team.
Reference: [40] <author> P.L. Rosin and T. Ellis. </author> <title> Detecting and classifying intruders in image sequences. </title> <booktitle> In Proc. British Mach. Vis. Conf., </booktitle> <pages> pages 24-26, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: The background frame is usually obtained using median filtering in time from video taken with a static camera. Background differencing with a static camera is frequently used as the first stage of input for a tracking system <ref> [40, 41, 27] </ref>. The blobs are matched based upon size and shape characteristic and sometimes combined with model information. Trackers using motion differencing generally require relatively high contour accuracy and authors do not propose methods of dealing with panning and zooming video. <p> Grounded auklets are located using optical flow and flying auklets are tracked using thresholding and convolution. Individual bird tracking on the flying auklets (against a sky background) is attempted but fails when birds fly close together. A system for analyzing scenes taken from an outdoor security camera by Rosin <ref> [40] </ref> uses contextual information to supplement blob tracking. The goal is to identify moving people and ignore all other objects, and the outdoor scene and low spatial and temporal resolution makes use of detailed geometrical models difficult. <p> The majority of tracking algorithms for objects in complex scenes use a static camera for sequence acquisition <ref> [7, 21, 50, 40, 27] </ref>. Often these methods depend upon on accurate difference motion blob generation that might not be attainable with a complexly moving camera.
Reference: [41] <author> A. Sato, K. Mase, A. Tomono, and K. Ishii. </author> <title> Pedestrian counting system robust against illumination changes. </title> <type> NTT Human Interface Laboratories technical report, </type> <institution> NTT Human Interface Laboratories, </institution> <year> 1994. </year>
Reference-contexts: The background frame is usually obtained using median filtering in time from video taken with a static camera. Background differencing with a static camera is frequently used as the first stage of input for a tracking system <ref> [40, 41, 27] </ref>. The blobs are matched based upon size and shape characteristic and sometimes combined with model information. Trackers using motion differencing generally require relatively high contour accuracy and authors do not propose methods of dealing with panning and zooming video.
Reference: [42] <author> H. Sawhney and A. Hansen. </author> <title> Trackability as a cue for potential obstacle identification and 3-d description. </title> <journal> Int. J. of Comp. Vis., </journal> <volume> 11(1) </volume> <pages> 237-265, </pages> <year> 1993. </year>
Reference-contexts: A Kalman filter predicts the location of an edge and the Mahalanobis distance is used to compute a matching score. A more sophisticated tracker recently described by Sawhney uses a four parameter affine model that handles scale, rotation and translation to track collections of lines <ref> [42] </ref>. Huttenlocher uses a more unusual edge-based tracking for tracking non-rigid, high-resolution images of people [24]. A 2D shape feature for matching is computed from the edges of binary background subtraction.
Reference: [43] <author> I.K. Sethi and R. Jain. </author> <title> Finding trajectories of feature points in a monocular image sequence. </title> <journal> IEEE Trans. Patt. Analy. and Mach. Intell., </journal> <volume> 2 </volume> <pages> 574-581, </pages> <year> 1987. </year>
Reference-contexts: The most common motion model assumes that an object is moving with a constant velocity or a smoothly changing path. Occasionally acceleration is modeled, but noisy image data and spatial and temporal subsampling can make acceleration estimation difficult. Some techniques that use a smooth motion model are described in <ref> [19, 43, 21, 25, 11, 23, 5] </ref>. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features [46].
Reference: [44] <author> I. Shapiro and D. Eckroth. </author> <booktitle> Encyclopedia of Artificial Intelligence. </booktitle> <publisher> Jonh Wiley and Sons, </publisher> <year> 1987. </year>
Reference-contexts: Using normalized correlation, where the correlation value is divided by the standard deviation over the region, the correlation measure is still sensitive to the signal-to-noise ratio, but the size of the window and the average intensity and contrast are normalized. More detail on correlation can be found in <ref> [44] </ref>. Basic correlation with a static template is often designed into real-time vision systems using specialized hardware [15]. Unfortunately, correlation templates are sensitive to occlusion and small changes in the patch being tracked in adjacent frames. This sensitivity is particularly problematic in scenes where objects can deform or collide.
Reference: [45] <author> J. Shi and C. Tomasi. </author> <title> Good features to track. </title> <booktitle> In Proc. Comp. Vis. and Pattern Rec., </booktitle> <pages> pages 593-600, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In practice, knowledge-free tracking systems often require that many features be tracked on single objects so that the tracking errors that occur can be handled by higher-level clustering and outlier removal routines. Shi <ref> [45] </ref>, however, suggests that low-level trackers should be able to evaluate the trackability of their features directly so that high-level analysis is more likely to succeed. A method is described that evaluates the trackability of rigid features based upon how the features change over time.
Reference: [46] <author> A. Shio and J. Sklansky. </author> <title> Segmentation of people in motion. </title> <booktitle> In Proc. Work. Visual Motion, </booktitle> <pages> pages 325-332, </pages> <year> 1991. </year>
Reference-contexts: Some techniques that use a smooth motion model are described in [19, 43, 21, 25, 11, 23, 5]. Other techniques, however, use differential optical flow motion algorithms to predict where an object has moved without explicitly matching image features <ref> [46] </ref>. Optical flow motion algorithms fail at occlusion discontinuities since they assume that pixel changes between two images should be smooth and small. Colliding and occluding, low-resolution, blob-like objects are poorly modeled since the two most common optical flow constraints, smoothness and planar motion, are weak. <p> The assumptions of smooth, small, and rigid motions do not hold in the football domain, and motion tracking is difficult to exploit. Given non-rigid objects, it might be possible to find an accurate object motion vector by averaging all the vectors recovered over the entire player <ref> [46] </ref>. Even though one arm or leg may be moving opposite to the body, the average velocity should be approximately correct. This technique, however, suffers from the same drifting problem as adapting correlation windows.
Reference: [47] <author> T.M. Strat and M.A. Fischler. </author> <title> Context-based vision: recognizing objects using information from both 2D and 3D imagery. </title> <journal> IEEE Trans. Patt. Analy. and Mach. Intell., </journal> <volume> 13(10) </volume> <pages> 1050-1065, </pages> <year> 1991. </year>
Reference-contexts: He speculates that one way to improve motion recovery is to exhaustively model all types of motion expected within the given domain. Further, he suggests that a description of a scene will require describing the intentions of the objects in the world. The Condor system designed by Strat <ref> [47] </ref> uses the output of many simple vision processes and local context in the scene for recognition of outdoor imagery. The Condor system treats objects as component parts of larger contexts from which they cannot be separated. Objects have no independent existence.
Reference: [48] <author> P. Tagliabue. </author> <title> Official playing rules of the National Football League. </title> <publisher> Triumph books, </publisher> <address> Chicago, IL, </address> <year> 1993. </year>
Reference-contexts: The model we have constructed is shown in The field model was obtained in the following way. Precise measurements of geometrical features like lines and hashmarks were obtained from the official rule book of the NFL and modified for a collegiate field <ref> [48] </ref>. That model did not include the field features like numbers, directional arrows, and logos since exact specifications for those objects cannot be obtained directly from any source. The rectification process described in the following sections was performed using the lines and hashmarks of the geometrical field model. <p> Those points are matched with points in a model of the background, and that registration can be used to warp the background model to each frame of the imagery or vice versa. In the football domain, the field is modeled as a single plane with grid markings <ref> [48] </ref>.
Reference: [49] <author> T.N. Tan, G.D. Sullivan, and K.D. Baker. </author> <title> Pose determination and recognition of vehicles in traffic scenes. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <volume> volume 1, </volume> <pages> pages 501-506, </pages> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Further, all of the the methods described above assume a static camera, and nearly all rely heavily upon accurate motion-blob detection. 16 2.2.2 Heuristic knowledge A few researchers have developed methods that use knowledge other than 3D model knowledge about the object being tracked. Tan <ref> [49] </ref> uses knowledge of the ground plane to restrict possible matches between image edges and a 3D vehicle model in a vehicle tracking system. The use of the ground plane is noteworthy because it is a piece of knowledge not directly associated with the vehicle model.
Reference: [50] <author> A.F. Toal and H. Buxton. </author> <title> Spatio-temporal reasoning with a traffic surveillance system. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <pages> pages 884-892, </pages> <address> S. Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The tracking routines include motion differencing, color histogramming, correlation, and other common vision methods for tracking large objects. Toal discusses a system that uses uses a ground-plane map of a complex intersection to reason about behavioral constraints placed upon the objects in the scene <ref> [50] </ref>. The system consists of a perceptual component for recognition of vehicles and a situation assessment component (SAC) that attempts to understand the events occurring over time. <p> The majority of tracking algorithms for objects in complex scenes use a static camera for sequence acquisition <ref> [7, 21, 50, 40, 27] </ref>. Often these methods depend upon on accurate difference motion blob generation that might not be attainable with a complexly moving camera.
Reference: [51] <author> J.A. Webb and J.K. Aggarwal. </author> <title> Visually interpreting the motion of objects in space. </title> <journal> Computer, </journal> <volume> 14 </volume> <pages> 40-46, </pages> <year> 1981. </year>
Reference-contexts: Finally, some sports-related projects that might benefit from the type of tracking developed in this work are briefly described. 2.1 Basic tracking techniques Several types of tracking techniques are used frequently in vision applications. Aggarwal <ref> [51] </ref> classified correspondence processes into those based on iconic models, or correlation templates and structural models, or features. Correlation tracking matches a region of one image to some region in the next image.
Reference: [52] <author> J. Woodfill and R. Zabih. </author> <title> An algorithm for real-time tracking of non-rigid objects. </title> <booktitle> In Proc. Nat. Conf. on Artif. Intell., </booktitle> <pages> pages 718-723, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Colliding and occluding, low-resolution, blob-like objects are poorly modeled since the two most common optical flow constraints, smoothness and planar motion, are weak. Woodfill develops a real-time object tracker that will track isolated, arbitrarily-shaped objects <ref> [52] </ref>. The method has two parts: motion estimation using a fast optical flow approximation technique and object boundary refinement using stereo or the motion field. The algorithm may have problems with objects that have internal motion boundaries and objects that move too rapidly or too slowly.
Reference: [53] <author> A.D. Worrall, R.F. Marslin, G.D. Sullivan, and K.D. Baker. </author> <title> Model-based tracking. </title> <booktitle> In Proc. British Mach. Vis. Conf., </booktitle> <pages> pages 310-318, </pages> <address> Glasgow, UK, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: Some recent and relevant work is outlined below. Most of the vehicle tracking is done on low-resolution vehicles using edges. Worrall uses camera position, motion blobs, edges, and precise 3D car and scene models to match image data to model data <ref> [53] </ref>. The technique is sensitive to objects that occlude vehicles. In a companion paper, Marslin extends the tracking to use estimates of speed and orientation using a Kalman filter [31].
Reference: [54] <author> A.D. Worrall, G.D. Sullivan, and K.D. Baker. </author> <title> Pose refinement of active models using forces in 3D. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <volume> volume 1, </volume> <pages> pages 341-350, </pages> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Recently, Worrall has shown that 3D vehicle models can be matched to line segment imagery using spring-like forces in 3D <ref> [54] </ref>. Worrall claims that performing matching using true 3D forces simplifies the use of information about physical objects like a ground plane. The detailed 3D models described above are only applicable to rigid objects where edge-like features are well defined.

References-found: 54

