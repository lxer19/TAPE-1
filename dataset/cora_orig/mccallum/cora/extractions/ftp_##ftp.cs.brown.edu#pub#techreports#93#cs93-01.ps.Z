URL: ftp://ftp.cs.brown.edu/pub/techreports/93/cs93-01.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-93-01.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> "Connection Machine Model CM-2 Technical Summary," Thinking Machines Corporation TMC Technical Report HA 87-4, </institution> <year> 1987. </year>
Reference-contexts: An array M S called the mob schedule is given in advance; the sth mob size is M S [s]. The initial mob size, M S <ref> [1] </ref>, is about 10% of jV j.
Reference: [2] <author> P. Banerjee, M. H. Jones, and J. S. Sargent, </author> <title> "Parallel Simulated Annealing Algorithms for Cell Placement on Hypercube Multiprocessors," </title> <journal> IEEE Transactions on Parallel and Distributed Systems PDS-1 (January 1990), </journal> <pages> 91-106. </pages>
Reference-contexts: All processors then update their data structures to incorporate the executed move. They show equivalence with serial SA but the degree of parallelism is very small and their technique has a serial bottleneck at high temperatures. Banerjee et al <ref> [2] </ref> have implemented SA for an Intel Hypercube and their version is also consistent with serial SA. As a consequence, no large benefits in solution quality are obtained and the time they spend to maintain serial consistency is very great.
Reference: [3] <author> G. E. Blelloch, </author> <title> "Scans as Primitive Parallel Operations," </title> <journal> IEEE Transactions on Computers 38 (1989), </journal> <pages> 1526-1538. </pages>
Reference-contexts: We use edge and vertex data structures to support the exchange of vertices and the computation of gains and costs with minimal communication overhead. Our edge data structure is based on that described by Blelloch <ref> [3] </ref> and implemented for the graph partitioning Mob heuristic [21]. The Connection Machine supports the concept of virtual processor. Our implementation assigns one virtual processor per record in each vertex and edge data structure. <p> Segmented scan operations are scan operations performed over contiguous segments of the full vector. If a segment begins at the ith position, y i = x i ; otherwise, y i = y i1 x i . Scans and segmented scans can be implemented efficiently on most parallel machines <ref> [3] </ref>. 12 3 Experimental Results for Random Graphs The performance of the Mob hypercube and grid-embedding algorithms were evaluated by conducting experiments on the CM-2. 1-to-1 and 16-to-1 mappings of source to target graphs were studied.
Reference: [4] <author> S. H. Bokhari, </author> <title> "On the Mapping Problem," </title> <journal> IEEE Transactions on Computers C-30 (Mar. </journal> <year> 1981), </year> <pages> 207-214. </pages>
Reference-contexts: edges under the HCU BE cost function is P where HCU BE (a; b) is the Hamming distance between a and b, i.e. the number of bit positions in which the vertices a and b differ when represented as binary k-tuples. 1.2 Previous Experimental Work In an early paper, Bokhari <ref> [4] </ref> gives a heuristic to embed communication graphs into an n fi n 2-D grid with connections between horizontal, vertical, and diagonal neighbors. His cost function is the number of adjacent source vertices mapped to adjacent target vertices. The goal is to maximize this cost function.
Reference: [5] <author> A. Casotto and A. Sangiovanni-Vincentelli, </author> <title> "Placement of Standard Cells Using Simulated Annealing on the Connection Machine," </title> <address> ICCAD (Nov. </address> <year> 1987), </year> <pages> 350-453. </pages>
Reference-contexts: Because non-interacting moves are considered for acceptance, the number of possible parallel moves tends to be small. Also, the strategy of only accepting certain moves introduces artifacts which degrade convergence behavior. Parallel SA heuristics for VLSI circuit placement have been studied by Casotto and Sangiovanni-Vincentelli <ref> [5] </ref> for the CM-1, Wong and Fiebrich [22] for the CM-2 Connection Machine, and by Darema et al [9] for grid-based multiprocessors. Casotto et al used a 16-K processor CM-1 on a circuit with 800 cells and 843 nets (hypergraph edges) and 2935 pins.
Reference: [6] <author> W. -K. Chen, E. F. Gehringer, and M. F. M. Stallmann, </author> <title> "Hypercube Embedding Heuristics: An Evaluation," </title> <booktitle> International Journal of Parallel Programming 18 (1989), </booktitle> <pages> 505-549. </pages>
Reference-contexts: Darema et al demonstrated a speedup of 14 in their parallel SA heuristic to embed a 9 fi 9 grid onto itself when simulating up to 32 virtual processors. Chen, Stallmann, and Gehringer <ref> [6] </ref> examine the running time and performance of twelve hypercube-embedding algorithms. They compare these by embedding random graphs, geometrical random graphs, trees, hypercubes and hypercubes with randomly selected missing edges into a 128-node hypercube. The algorithms considered include SA [9], SA restricted to moves across hyperplanes (SAC) [6], Kernighan-Lin applied to <p> Stallmann, and Gehringer <ref> [6] </ref> examine the running time and performance of twelve hypercube-embedding algorithms. They compare these by embedding random graphs, geometrical random graphs, trees, hypercubes and hypercubes with randomly selected missing edges into a 128-node hypercube. The algorithms considered include SA [9], SA restricted to moves across hyperplanes (SAC) [6], Kernighan-Lin applied to the all partitions of the cube along hyperplanes (RMB) [10], greedy heuristics such as steepest descent, and local search heuristics using as neighborhoods all possible pairs of vertices (LS) and pairs of vertices adjacent across a hyperplane (LSC).
Reference: [7] <author> W. -K. Chen and M. F. M. Stallmann, </author> <title> "Local Search Variants for Hypercube Embedding," </title> <booktitle> Proceedings 5th Distributed Memory Computer Conference (1990), </booktitle> <pages> 1375-1383. </pages>
Reference: [8] <author> E. D. Dahl, </author> <title> "Mapping and Compiled Communication on the Connection Machine," </title> <booktitle> Proceedings 5th Distributed Memory Computer Conference (1990), </booktitle> <pages> 756-766. </pages>
Reference-contexts: As a consequence, no large benefits in solution quality are obtained and the time they spend to maintain serial consistency is very great. Parallel simulated annealing has been applied by Dahl <ref> [8] </ref> to reduce communication costs (measured in the HCUBE metric) on the CM-2 Connection Machine hypercube network. Multiple source vertices are mapped to a target hypercube vertex and assigned a hypercube dimension. A dimension is chosen at random.
Reference: [9] <author> F. Darema, S. Kirkpatrick, and V. A. Norton, </author> <title> "Parallel Algorithms for Chip Placement by Simulated Annealing," </title> <journal> IBM Journal of Research and Development 31 (May 1987), </journal> <pages> 391-401. </pages>
Reference-contexts: Also, the strategy of only accepting certain moves introduces artifacts which degrade convergence behavior. Parallel SA heuristics for VLSI circuit placement have been studied by Casotto and Sangiovanni-Vincentelli [5] for the CM-1, Wong and Fiebrich [22] for the CM-2 Connection Machine, and by Darema et al <ref> [9] </ref> for grid-based multiprocessors. Casotto et al used a 16-K processor CM-1 on a circuit with 800 cells and 843 nets (hypergraph edges) and 2935 pins. One iteration of their SA algorithm took 2 seconds. <p> Chen, Stallmann, and Gehringer [6] examine the running time and performance of twelve hypercube-embedding algorithms. They compare these by embedding random graphs, geometrical random graphs, trees, hypercubes and hypercubes with randomly selected missing edges into a 128-node hypercube. The algorithms considered include SA <ref> [9] </ref>, SA restricted to moves across hyperplanes (SAC) [6], Kernighan-Lin applied to the all partitions of the cube along hyperplanes (RMB) [10], greedy heuristics such as steepest descent, and local search heuristics using as neighborhoods all possible pairs of vertices (LS) and pairs of vertices adjacent across a hyperplane (LSC).
Reference: [10] <author> F. Ercal, J. Ramanujam, and P. Sadayappan, </author> <title> "Task Allocation onto a Hypercube by Recursive Mincut Bipartitioning," </title> <journal> Journal of Parallel and Distributed Computing 10 (1990), </journal> <pages> 35-44. </pages>
Reference-contexts: They compare these by embedding random graphs, geometrical random graphs, trees, hypercubes and hypercubes with randomly selected missing edges into a 128-node hypercube. The algorithms considered include SA [9], SA restricted to moves across hyperplanes (SAC) [6], Kernighan-Lin applied to the all partitions of the cube along hyperplanes (RMB) <ref> [10] </ref>, greedy heuristics such as steepest descent, and local search heuristics using as neighborhoods all possible pairs of vertices (LS) and pairs of vertices adjacent across a hyperplane (LSC).
Reference: [11] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: We implemented this algorithm on the CM-2 Connection Machine. It gives very good partitions of large graphs in very little time. Because graph partitioning is an important N P -complete problem <ref> [11] </ref>, much effort has been devoted to developing good heuristics for it. (See for example, the paper by Johnson et al [13].) The Mob heuristic is as effective for graph partitioning as simulated annealing (SA) [15] and the Kernighan-Lin (KL) heuristic [14], the best serial heuristics for GP, but exhibits a
Reference: [12] <author> W. D. Hillis, </author> <title> The Connection Machine, </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference: [13] <author> D. S. Johnson, C. A. Aragon, L. A. McGeoch, and C. Schevon, </author> <title> "Optimization by Simulated Annealing: An Experimental Evaluation (Part 1)," </title> <note> Operations Research 37 (Nov.-Dec. </note> <year> 1989), </year> <pages> 865-892. </pages>
Reference-contexts: It gives very good partitions of large graphs in very little time. Because graph partitioning is an important N P -complete problem [11], much effort has been devoted to developing good heuristics for it. (See for example, the paper by Johnson et al <ref> [13] </ref>.) The Mob heuristic is as effective for graph partitioning as simulated annealing (SA) [15] and the Kernighan-Lin (KL) heuristic [14], the best serial heuristics for GP, but exhibits a high degree of parallelism and gives bisection widths that are at least as good as these heuristics [19,21]. <p> Graph-partitioning experiments by Johnson et al <ref> [13] </ref> were performed on random geometric graphs generated with the Euclidean metric. Chen et al [6,7] used random geometric graphs generated with the infinity metric to test hypercube embedding algorithms. 4.1 Efficient Construction of Random Geometric Graphs We now address the problem of efficiently generating geometric graphs. <p> Each set is now sorted along the other dimension. The procedure of sorting along alternating dimensions and halving the sets is repeated until the sets are of size one. At this point every vertex has a unique grid node assigned to it. Johnson et al <ref> [13] </ref> used a similar approach in designing their LINE heuristic for partitioning geometric graphs: the unit square is cut into half to obtain a graph partition.
Reference: [14] <author> B. W. Kernighan and S. Lin, </author> <title> "An Efficient Heuristic Procedure for Partitioning Graphs," </title> <institution> AT&T Bell Labs. Tech. J. </institution> <month> 49 (Feb. </month> <year> 1970), </year> <pages> 291-307. </pages>
Reference-contexts: graph partitioning is an important N P -complete problem [11], much effort has been devoted to developing good heuristics for it. (See for example, the paper by Johnson et al [13].) The Mob heuristic is as effective for graph partitioning as simulated annealing (SA) [15] and the Kernighan-Lin (KL) heuristic <ref> [14] </ref>, the best serial heuristics for GP, but exhibits a high degree of parallelism and gives bisection widths that are at least as good as these heuristics [19,21]. <p> If the bisection width bw (L) of L is less than that of K, the mob size M [s] 8 remains unchanged. Otherwise the next mob size is selected. The Mob heuristic has elements in common with simulated annealing (SA) [15] and the Kernighan-Lin Heuristic (KL) <ref> [14] </ref>. SA explores neighborhoods by picking a pair of vertices of highest gain in each half of a partition and computing the effect on the bisection width if they are swapped. If the bisection width would decrease, the swap is made.
Reference: [15] <author> S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi, </author> <title> "Optimization by Simulated Annealing," </title> <booktitle> Science 220 (May 1983), </booktitle> <pages> 671-680. 26 </pages>
Reference-contexts: Because graph partitioning is an important N P -complete problem [11], much effort has been devoted to developing good heuristics for it. (See for example, the paper by Johnson et al [13].) The Mob heuristic is as effective for graph partitioning as simulated annealing (SA) <ref> [15] </ref> and the Kernighan-Lin (KL) heuristic [14], the best serial heuristics for GP, but exhibits a high degree of parallelism and gives bisection widths that are at least as good as these heuristics [19,21]. <p> If the bisection width bw (L) of L is less than that of K, the mob size M [s] 8 remains unchanged. Otherwise the next mob size is selected. The Mob heuristic has elements in common with simulated annealing (SA) <ref> [15] </ref> and the Kernighan-Lin Heuristic (KL) [14]. SA explores neighborhoods by picking a pair of vertices of highest gain in each half of a partition and computing the effect on the bisection width if they are swapped. If the bisection width would decrease, the swap is made.
Reference: [16] <author> S. Kravitz and R. Rutenbar, </author> <title> "Multiprocessor-based Placement by Simulated Anneal--ing," </title> <booktitle> 23rd IEEE Design Automation Conf. </booktitle> <year> (1986), </year> <pages> 567-573. </pages>
Reference-contexts: Experiments were conducted with thirteen graphs of up to 80 edges embedded into square grids of up to seven vertices on a side. Respectable increases in the value of the cost function were obtained. Kravitz and Rutenbar <ref> [16] </ref> give a parallel version of SA for VLSI placement. Because non-interacting moves are considered for acceptance, the number of possible parallel moves tends to be small. Also, the strategy of only accepting certain moves introduces artifacts which degrade convergence behavior.
Reference: [17] <author> R. H. J. M. Otten, </author> <title> "Automatic Floorplan Design," </title> <booktitle> Proc. 19th IEEE Design Automation Conf. </booktitle> <year> (1982), </year> <pages> 261-267. </pages>
Reference-contexts: The Slice heuristic presented here is a divide-and-conquer algorithm to find unique vertex to grid mappings by slightly displacing the vertices on the unit square. The Slice heuristic is closely related to the slicing structure tree introduced by Otten <ref> [17] </ref> for VLSI floorplan design. The vertices are sorted along the x- or the y-dimension. The sorted vertices are divided into two sets, which are mapped to different halves of the grid. Each set is now sorted along the other dimension.
Reference: [18] <author> P. Roussel-Ragot and G. Dreyfus, </author> <title> "A Problem Independent Parallel Implementation of Simulated Annealing: Models and Experiments," </title> <journal> IEEE Trans. Computer-Aided Design 9 (Aug. </journal> <year> 1990), </year> <pages> 827-835. </pages>
Reference-contexts: Roussel-Ragout and Dreyfus <ref> [18] </ref> propose a parallel implementation of SA on a MIMD multiprocessor. Every processor evaluates one move and at most one of the accepted moves is chosen at random by a master processor. All processors then update their data structures to incorporate the executed move.
Reference: [19] <author> J. E. Savage and M. G. Wloka, </author> <title> "On Parallelizing Graph-Partitioning Heuristics," </title> <booktitle> Proceedings of the ICALP'90 (July 1990), </booktitle> <pages> 476-489. </pages>
Reference: [20] <author> J. E. Savage and M. G. Wloka, </author> <title> "Parallel Graph-Embedding Heuristics," </title> <booktitle> 5th SIAM Conference on Parallel Processing for Scientific Computing (Mar. </booktitle> <year> 1991), </year> <pages> 472-47. </pages>
Reference: [21] <author> J. E. Savage and M. G. Wloka, </author> <title> "Parallelism in Graph-Partitioning," </title> <journal> Journal of Parallel and Distributed Computing 13 (Nov. </journal> <year> 1991), </year> <pages> 257-272. </pages>
Reference-contexts: 1 Introduction We introduce and report on the Mob heuristic for the embedding of graphs into grids and hypercubes. This heuristic is an extension of our Mob heuristic for graph partitioning <ref> [21] </ref>. These heuristics exploit parallelism and give results at least as good as their most effective serial counterparts for the problems for which they are designed, namely, the partitioning and embedding of low-degree random graphs, yet they handle problems hundreds to thousands of times larger. <p> We use edge and vertex data structures to support the exchange of vertices and the computation of gains and costs with minimal communication overhead. Our edge data structure is based on that described by Blelloch [3] and implemented for the graph partitioning Mob heuristic <ref> [21] </ref>. The Connection Machine supports the concept of virtual processor. Our implementation assigns one virtual processor per record in each vertex and edge data structure. Edge Data Structure The edge data structure is constructed of records representing edges of an undirected source graph G.

References-found: 21

