URL: file://net.cs.utexas.edu/pub/techreports/tr95-13.ps
Refering-URL: http://www.cs.utexas.edu/users/rvdg/abstracts/SUMMA.html
Root-URL: 
Email: rvdg@cs.utexas.edu  jwatts@scp.caltech.edu  
Title: SUMMA: Scalable Universal Matrix Multiplication Algorithm  
Author: Robert A. van de Geijn Jerrell Watts 
Address: Austin, Texas 78712  Pasadena, California 91125  
Affiliation: Department of Computer Sciences The University of Texas at Austin  Scalable Concurrent Programming Laboratory California Institute of Technology  
Abstract: In this paper, we give a straight forward, highly efficient, scalable implementation of common matrix multiplication operations. The algorithms are much simpler than previously published methods, yield better performance, and require less work space. MPI implementations are given, as are performance results on the Intel Paragon system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, E., Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. DuCroz, A. Greenbaum, S. Hammarling, A. McKenney, and D. Sorensen, </author> <title> "Lapack: A Portable Linear Algebra Library for High Performance Computers," </title> <booktitle> Proceedings of Supercomputing '90, </booktitle> <publisher> IEEE Press, </publisher> <year> 1990, </year> <pages> pp. 1-10. </pages>
Reference-contexts: We summarize those in this section. It is very interesting to note that we started pursuing the presented algorithm by making the following simple observation: The blocked right-looking LU factorization, as implemented in LAPACK <ref> [1, 2] </ref>, is much like a matrix-matrix multiplication, C = AB, implemented as a series of rank nb updates, except that they require pivoting, matrices A, B, and C are all the same matrix, and the updates progressively affect less of the matrix being updated.
Reference: [2] <author> Anderson, E., Z. Bai, J. Demmel, J. Dongarra, J. DuCroz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen, </author> <title> LAPACK Users' Guide, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: We summarize those in this section. It is very interesting to note that we started pursuing the presented algorithm by making the following simple observation: The blocked right-looking LU factorization, as implemented in LAPACK <ref> [1, 2] </ref>, is much like a matrix-matrix multiplication, C = AB, implemented as a series of rank nb updates, except that they require pivoting, matrices A, B, and C are all the same matrix, and the updates progressively affect less of the matrix being updated.
Reference: [3] <author> Barnett, M., S. Gupta, D. Payne, L. Shuler, R. van de Geijn, and J. Watts, </author> <title> "Interprocessor Collective Communication Library (InterCom)," </title> <booktitle> Scalable High Performance Computing Conference 1994. </booktitle>
Reference-contexts: In the absense of network conflicts, communicating a message between two nodes requires time ff + nfi, which is reasonable on machines like the Intel Paragon system <ref> [3] </ref> . Parameters ff and fi represent the startup and cost per item transfer time, respectively. Performing a floating point computation requires time fl. 4 Data Decomposition We will consider two dimensional data decompositions.
Reference: [4] <author> M. Barnett, D.G. Payne, R. van de Geijn, and J. Watts, </author> <title> Broadcasting on Meshes with Worm-Hole Routing, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> submitted. </note>
Reference-contexts: Alternative broadcast algorithms, e.g. pipelined or scatter-collect broadcasts <ref> [4, 20] </ref> can be used to eliminate the log (p) factor, at the expense of a larger number of startups.
Reference: [5] <author> Cannon, L.E., </author> <title> A Cellular Computer to Implement the Kalman Filter Algorithm, </title> <type> Ph.D. Thesis (1969), </type> <institution> Mon-tana State University. </institution>
Reference-contexts: One would think that by now we would be able to manage such an apparently straight forward task with simple, highly efficient implementations. Nonetheless, we appear to have gained a new insight into this problem. Different approaches proposed for matrix-matrix multiplication include 1D-systolic [14], 2D-systolic [14], Cannon's algorithm <ref> [5, 14] </ref>, Broadcast-Multiply-Roll [12, 13], and the Transpose algorithm [19].
Reference: [6] <author> Choi J., J. J. Dongarra, R. Pozo, and D. W. Walker, </author> <title> "Scalapack: A Scalable Linear Algebra Library for Distributed Memory Concurrent Computers, </title> <booktitle> Proceedings of the Fourth Symposium on the Frontiers of Massively Parallel Computation. </booktitle> <publisher> IEEE Comput. Soc. Press, </publisher> <year> 1992, </year> <pages> pp. 120-127. </pages>
Reference: [7] <author> Choi, J., J. J. Dongarra, and D. W. Walker, </author> <title> "Level 3 BLAS for distributed memory concurrent computers", </title> <booktitle> CNRS-NSF Workshop on Environments and Tools for Parallel Scientific Computing, </booktitle> <address> Saint Hilaire du Touvet, France, </address> <month> Sept. </month> <pages> 7-8, </pages> <address> 1992. </address> <publisher> Elsevier Science Publishers, </publisher> <year> 1992. </year>
Reference: [8] <author> Choi, J., J. J. Dongarra, and D. W. Walker, "PUMMA: </author> <title> Parallel Universal Matrix Multiplication Algorithms on distributed memory concurrent computers," </title> <journal> Concurrency: Practice and Experience, </journal> <volume> Vol 6(7), </volume> <pages> 543-570, </pages> <year> 1994. </year>
Reference-contexts: Different approaches proposed for matrix-matrix multiplication include 1D-systolic [14], 2D-systolic [14], Cannon's algorithm [5, 14], Broadcast-Multiply-Roll [12, 13], and the Transpose algorithm [19]. Two recent efforts extend the work by Fox et. al. to general meshes of nodes: the paper by Choi et. al. <ref> [8] </ref> uses a two-dimensional block-wrapped (block-cyclic) data decomposition, while the papers by Huss-Lederman et. al. [17, 18] use a "virtual" 2-D torus wrap data layout. Both these efforts report very good performance attained on the Intel Touchstone Delta, achieving a sizeable percentage of peak performance. <p> Instead, we compare the performance of our basic matrix-multiplication algorithms for C = ffAB + fiC and C = ffAB T + fiC with that achieved by the PUMMA implementation in <ref> [8] </ref>, which we obtained from netlib. We modified the PUMMA code to call the most efficient forms of NX communication primitives (including forced messages). The implementation of SUMMA is essentially the one given in this paper.
Reference: [9] <author> Dongarra, J. J., I. S. Duff, D. C. Sorensen, and H. A. van der Vorst, </author> <title> Solving Linear Systems on Vector and Shared Memory Computers, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference: [10] <author> Dongarra, J. J., J. Du Croz, S. Hammarling, and I. Duff, </author> <title> "A Set of Level 3 Basic Linear Algebra Subprograms," </title> <journal> TOMS, </journal> <volume> Vol. 16, No. 1, </volume> <pages> pp. 1-16, </pages> <year> 1990. </year>
Reference-contexts: Fellowship. 2 Notation We will consider the formation of the matrix products C = ffAB + fiC (1) C = ffAB T + fiC (2) C = ffA T B + fiC (3) These are the special cases implemented as part of the widely used sequential Basic Linear Algebra Subprograms <ref> [10] </ref>. We will assume that each matrix X is of dimension m X fi n X , X 2 fA; B; Cg. <p> Matrix-matrix operations perform O (n 3 ) computation on O (n 2 ) data, thereby overcoming the memory access bandwidth bottleneck present on most modern microprocessors. Highly optimized versions of an important set of such operations (the level-3 BLAS <ref> [10] </ref>) are typically provided by major vendors of high performance microprocessors.
Reference: [11] <author> Dongarra, J. J., R. A. van de Geijn, and D. W. Walker, </author> <title> "Scalability Issues Affecting the Design of a Dense Linear Algebra Library," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 22, No. 3, </volume> <month> Sept. </month> <year> 1994, </year> <pages> pp. 523-537. </pages>
Reference-contexts: Examples of this occur in ScaLAPACK routines like those for the LU and QR factorization <ref> [11] </ref>. In such cases, our approach continues to be useful.
Reference: [12] <author> Fox, G. C., M. A. Johnson, G. A. Lyzenga, S. W. Otto, J. K. Salmon, and D. W. Walker, </author> <title> Solving Problems on Concurrent Processors, </title> <journal> Vol. </journal> <volume> 1, </volume> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1988. </year>
Reference-contexts: Nonetheless, we appear to have gained a new insight into this problem. Different approaches proposed for matrix-matrix multiplication include 1D-systolic [14], 2D-systolic [14], Cannon's algorithm [5, 14], Broadcast-Multiply-Roll <ref> [12, 13] </ref>, and the Transpose algorithm [19].
Reference: [13] <author> Fox, G., S. Otto, and A. Hey, </author> <title> "Matrix algorithms on a hypercube I: matrix multiplication," </title> <booktitle> Parallel Computing 3 (1987), </booktitle> <pages> pp 17-31. </pages>
Reference-contexts: Nonetheless, we appear to have gained a new insight into this problem. Different approaches proposed for matrix-matrix multiplication include 1D-systolic [14], 2D-systolic [14], Cannon's algorithm [5, 14], Broadcast-Multiply-Roll <ref> [12, 13] </ref>, and the Transpose algorithm [19].
Reference: [14] <author> Golub, G. H. , and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins University Press, </publisher> <editor> 2nd ed., </editor> <year> 1989. </year>
Reference-contexts: One would think that by now we would be able to manage such an apparently straight forward task with simple, highly efficient implementations. Nonetheless, we appear to have gained a new insight into this problem. Different approaches proposed for matrix-matrix multiplication include 1D-systolic <ref> [14] </ref>, 2D-systolic [14], Cannon's algorithm [5, 14], Broadcast-Multiply-Roll [12, 13], and the Transpose algorithm [19]. <p> One would think that by now we would be able to manage such an apparently straight forward task with simple, highly efficient implementations. Nonetheless, we appear to have gained a new insight into this problem. Different approaches proposed for matrix-matrix multiplication include 1D-systolic <ref> [14] </ref>, 2D-systolic [14], Cannon's algorithm [5, 14], Broadcast-Multiply-Roll [12, 13], and the Transpose algorithm [19]. <p> One would think that by now we would be able to manage such an apparently straight forward task with simple, highly efficient implementations. Nonetheless, we appear to have gained a new insight into this problem. Different approaches proposed for matrix-matrix multiplication include 1D-systolic [14], 2D-systolic [14], Cannon's algorithm <ref> [5, 14] </ref>, Broadcast-Multiply-Roll [12, 13], and the Transpose algorithm [19].
Reference: [15] <author> Gropp, W., E. Lusk, A. Skjellum, </author> <title> Using MPI: Portable Programming with the Message-Passing Interface, </title> <publisher> The MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: However, we show how this restriction can be easily relaxed to achieve the wrapped decompositions mentioned above, as well as more general decompositions. This paper makes a number of contributions: We present a new approach and its scalability analysis. In addition, we give complete Message Passing Interface (MPI) <ref> [15] </ref> implementations, demonstrating the power of this standard for coding concurrent algorithms.
Reference: [16] <author> C.-T. Ho and S. L. Johnsson, </author> <title> Distributed Routing Algorithms for Broadcasting and Personalized Communication in Hypercubes, </title> <booktitle> In Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 640-648, </pages> <publisher> IEEE, </publisher> <year> 1986. </year> <month> 18 </month>
Reference: [17] <author> Huss-Lederman, S., E. Jacobson, A. Tsao, </author> <title> "Comparison of Scalable Parallel Matrix Multiplication Libraries," </title> <booktitle> in Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <address> Starksville, MS, </address> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Two recent efforts extend the work by Fox et. al. to general meshes of nodes: the paper by Choi et. al. [8] uses a two-dimensional block-wrapped (block-cyclic) data decomposition, while the papers by Huss-Lederman et. al. <ref> [17, 18] </ref> use a "virtual" 2-D torus wrap data layout. Both these efforts report very good performance attained on the Intel Touchstone Delta, achieving a sizeable percentage of peak performance. The method presented our paper has the benefit of being more general, simpler and more efficient.
Reference: [18] <author> Huss-Lederman, S., E. Jacobson, A. Tsao, G. Zhang, </author> <title> "Matrix Multiplication on the Intel Touchstone DELTA," </title> <journal> Concurrency: Practice and Experience, </journal> <volume> Vol. 6 (7), </volume> <month> Oct. </month> <year> 1994, </year> <pages> pp. 571-594. </pages>
Reference-contexts: Two recent efforts extend the work by Fox et. al. to general meshes of nodes: the paper by Choi et. al. [8] uses a two-dimensional block-wrapped (block-cyclic) data decomposition, while the papers by Huss-Lederman et. al. <ref> [17, 18] </ref> use a "virtual" 2-D torus wrap data layout. Both these efforts report very good performance attained on the Intel Touchstone Delta, achieving a sizeable percentage of peak performance. The method presented our paper has the benefit of being more general, simpler and more efficient.
Reference: [19] <author> Lin, C., and L. Snyder, </author> <title> "A Matrix Product Algorithm and its Comparative Performance on Hypercubes," </title> <booktitle> in Proceedings of Scalable High Performance Computing Conference, </booktitle> <editor> (Stout, Q, and M. Wolfe, eds.), </editor> <publisher> IEEE Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1992, </year> <pages> pp. 190-3. </pages>
Reference-contexts: Nonetheless, we appear to have gained a new insight into this problem. Different approaches proposed for matrix-matrix multiplication include 1D-systolic [14], 2D-systolic [14], Cannon's algorithm [5, 14], Broadcast-Multiply-Roll [12, 13], and the Transpose algorithm <ref> [19] </ref>. Two recent efforts extend the work by Fox et. al. to general meshes of nodes: the paper by Choi et. al. [8] uses a two-dimensional block-wrapped (block-cyclic) data decomposition, while the papers by Huss-Lederman et. al. [17, 18] use a "virtual" 2-D torus wrap data layout.
Reference: [20] <author> Watts, J. and R. van de Geijn, </author> <title> "A Pipelined Broadcast for Multidimensional Meshes," </title> <note> Parallel Processing Letters, to appear. 19 </note>
Reference-contexts: Alternative broadcast algorithms, e.g. pipelined or scatter-collect broadcasts <ref> [4, 20] </ref> can be used to eliminate the log (p) factor, at the expense of a larger number of startups.
References-found: 20

