URL: http://www.cs.umn.edu/Users/dept/users/kumar/pcg-ieee.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Performance and Scalability of Preconditioned Conjugate Gradient Methods on Parallel Computers  
Author: Anshul Gupta, Vipin Kumar, and Ahmed Sameh 
Note: This work was supported by IST/SDIO through the Army Research Office grant 28408-MA-SDI to the University of Minnesota and by the University of Minnesota Army High Performance Computing Research Center under contract DAAL03-89-C-0038. CM-5 is a trademark of the  
Date: July 30, 1997  
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science University of Minnesota  Thinking Machines Corporation.  
Abstract: This paper analyzes the performance and scalability of an iteration of the Preconditioned Conjugate Gradient Algorithm on parallel architectures with a variety of interconnection networks, such as the mesh, the hypercube, and that of the CM-5 TM y parallel computer. It is shown that for block-tridiagonal matrices resulting from two dimensional finite difference grids, the communication overhead due to vector inner products dominates the communication overheads of the remainder of the computation on a large number of processors. However, with a suitable mapping, the parallel formulation of a PCG iteration is highly scalable for such matrices on a machine like the CM-5 whose fast control network practically eliminates the overheads due to inner product computation. The use of the truncated Incomplete Cholesky (IC) preconditioner can lead to further improvement in scalability on the CM-5 by a constant factor. As a result, a parallel formulation of the PCG algorithm with IC preconditioner may execute faster than that with a simple diagonal preconditioner even if the latter runs faster in a serial implementation. For the matrices resulting from three dimensional finite difference grids, the scalability is quite good on a hypercube or the CM-5, but not as good on a 2-D mesh architecture. In case of unstructured sparse matrices with a constant number of non-zero elements in each row, the parallel formulation of the PCG iteration is unscalable on any message passing parallel architecture, unless some ordering is applied on the sparse matrix. The parallel system can be made scalable either if, after re-ordering, the non-zero elements of the N fi N matrix can be confined in a band whose width is O(N y ) for any y &lt; 1, or if the number of non-zero elements per row increases as N x for any x &gt; 0. Scalability increases as the number of non-zero elements per row is increased and/or the width of the band containing these elements is reduced. For unstructured sparse matrices, the scalability is asymptotically the same for all architectures. Many of these analytical results are experimentally verified on the CM-5 parallel computer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Edward Anderson. </author> <title> Parallel implementation of preconditioned conjugate gradient methods for solving sparse systems of linear equations. </title> <type> Technical Report 805, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <year> 1988. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>. <p> The two diagonals in the lower triangular part of A have the same lengths as their upper triangular counterparts. These are indexed from <ref> [1] </ref> to [N 1] and from [ p N ] to [N 1] respectively.
Reference: [2] <author> Cevdet Aykanat, Fusun Ozguner, Fikret Ercal, and Ponnuswamy Sadayappan. </author> <title> Iterative algorithms for solution of large sparse systems of linear equations on hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(12) </volume> <pages> 1554-1567, </pages> <year> 1988. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>. <p> In this section, we describe a different mapping and analyze its scalability. Given the matrix of coefficients A and the vector b, this mapping is fairly straightforward and has often been used in parallel implementations of the PCG algorithm due to its simplicity <ref> [16, 2, 21, 14] </ref>. Here we will compare this mapping with the one discussed in Section 6.1 in the context of a CM-5 type architecture. According to this scheme, the matrix A and the vector b are partitioned among p processors as shown in Figure 6.
Reference: [3] <author> D. L. Eager, J. Zahorjan, and E. D. Lazowska. </author> <title> Speedup versus efficiency in parallel systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(3) </volume> <pages> 408-423, </pages> <year> 1989. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures.
Reference: [4] <author> A. George and J. W.-H. Liu. </author> <title> Computer Solution of Large Sparse Positive Definite Systems. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: Often, such systems are en countered where the non-zero elements of matrix A occur only within a band around the principal diagonal. Even if the non-zero elements are scattered throughout the matrix, it is often possible to restrict them to a band through certain re-ordering techniques <ref> [4, 5] </ref>. Such a system is shown in along the principal diagonal. Let the width of the band of the N fi N matrix be given by b, and b = fiN y , and 0 y 1. <p> Various techniques for re-ordering sparse systems to yield banded or partially banded sparse matrices are available <ref> [4, 5] </ref>. These techniques may vary in their complexity and effectiveness. By using Equation (32) the benefit of a certain degree of re-ordering can be quantitatively determined in terms of improvement in scalability. In this section we have presented the results for the diagonal preconditioner only. <p> In particular, the non-zero elements can be organized within a band by using some re-ordering techniques <ref> [4, 5] </ref>. Such 5 Unstructured sparse matrices arise in several applications.
Reference: [5] <author> N. E. Gibbs, W. G. Poole, and P. K. Stockmeyer. </author> <title> A comparison of several bandwidth and profile reduction algorithms. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 2 </volume> <pages> 322-330, </pages> <year> 1976. </year>
Reference-contexts: Often, such systems are en countered where the non-zero elements of matrix A occur only within a band around the principal diagonal. Even if the non-zero elements are scattered throughout the matrix, it is often possible to restrict them to a band through certain re-ordering techniques <ref> [4, 5] </ref>. Such a system is shown in along the principal diagonal. Let the width of the band of the N fi N matrix be given by b, and b = fiN y , and 0 y 1. <p> Various techniques for re-ordering sparse systems to yield banded or partially banded sparse matrices are available <ref> [4, 5] </ref>. These techniques may vary in their complexity and effectiveness. By using Equation (32) the benefit of a certain degree of re-ordering can be quantitatively determined in terms of improvement in scalability. In this section we have presented the results for the diagonal preconditioner only. <p> In particular, the non-zero elements can be organized within a band by using some re-ordering techniques <ref> [4, 5] </ref>. Such 5 Unstructured sparse matrices arise in several applications.
Reference: [6] <author> Gene H. Golub and Charles Van Loan. </author> <title> Matrix Computations: Second Edition. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, MD, </address> <year> 1989. </year>
Reference-contexts: In this paper, we study performance and scalability of parallel formulations of an iteration of the Preconditioned Conjugate Gradient (PCG) algorithm <ref> [6] </ref> for solving large sparse linear systems of equations of the form A x = b, where A is a symmetric positive definite matrix. Although, we specifically deal with the Preconditioned CG algorithm only, the analysis of the diagonal preconditioner case applies to the non-preconditioned method also. <p> Thus, for this application, the control network is highly useful. There are certain iterative schemes, like the Jacobi method <ref> [6] </ref>, that require inner product calculation only for the purpose of performing a convergence check. In such schemes, the parallel formulation can be made almost linearly scalable even on mesh and hypercube architectures by performing the convergence check once in a few iterations.
Reference: [7] <author> Ananth Grama, Anshul Gupta, and Vipin Kumar. Isoefficiency: </author> <title> Measuring the scalability of parallel algorithms and architectures. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 1(3) </volume> <pages> 12-21, </pages> <month> August, </month> <year> 1993. </year> <note> Also available as Technical Report TR 93-24, </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN. </institution>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures. <p> Many different measures have been developed to study the scalability of parallel algorithms and architectures [3, 7, 10, 15, 19, 22, 28, 32, 33]. In this paper, we use the isoefficiency metric <ref> [18, 7, 19] </ref> to study the scalability of an iteration of the PCG algorithm on some important architectures. <p> For a variety of parallel systems, given any number of processors p, speedup arbitrarily close to p can be obtained by simply executing the parallel algorithm on big enough problem instances (e.g., <ref> [18, 7, 11, 32] </ref>). The ease with which a parallel algorithm can achieve speedups proportional to p on a parallel architecture can serve as a measure of the scalability of the parallel system. <p> The ease with which a parallel algorithm can achieve speedups proportional to p on a parallel architecture can serve as a measure of the scalability of the parallel system. The isoefficiency function <ref> [18, 7] </ref> is one such metric of scalability which is a measure of an algorithm's capability to effectively utilize an increasing number of processors on a parallel architecture.
Reference: [8] <author> Anshul Gupta and Vipin Kumar. </author> <title> A scalable parallel algorithm for sparse matrix factorization. </title> <type> Technical Report 94-19, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> A short version appears in Supercomputing '94 Proceedings. TR available in users/kumar at anonymous FTP site ftp.cs.umn.edu. </note>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [9] <author> Anshul Gupta and Vipin Kumar. </author> <title> The scalability of FFT on parallel computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(8) </volume> <pages> 922-932, </pages> <month> August </month> <year> 1993. </year> <note> A detailed version available as Technical Report TR 90-53, </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN. </institution>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [10] <author> John L. Gustafson. </author> <title> Reevaluating Amdahl's law. </title> <journal> Communications of the ACM, </journal> <volume> 31(5) </volume> <pages> 532-533, </pages> <year> 1988. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures.
Reference: [11] <author> John L. Gustafson, Gary R. Montry, and Robert E. Benner. </author> <title> Development of parallel methods for a 1024-processor hypercube. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9(4) </volume> <pages> 609-638, </pages> <year> 1988. </year>
Reference-contexts: For a variety of parallel systems, given any number of processors p, speedup arbitrarily close to p can be obtained by simply executing the parallel algorithm on big enough problem instances (e.g., <ref> [18, 7, 11, 32] </ref>). The ease with which a parallel algorithm can achieve speedups proportional to p on a parallel architecture can serve as a measure of the scalability of the parallel system.
Reference: [12] <author> S. W. Hammond and Robert Schreiber. </author> <title> Efficient ICCG on a shared-memory multiprocessor. </title> <journal> International Journal of High Speed Computing, </journal> <volume> 4(1) </volume> <pages> 1-22, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>.
Reference: [13] <author> Kai Hwang. </author> <title> Advanced Computer Architecture: Parallelism, Scalability, Programmability. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [14] <author> C. Kamath and A. H. Sameh. </author> <title> The preconditioned conjugate gradient algorithm on a multiprocessor. </title> <editor> In R. Vichn-evetsky and R. S. Stepleman, editors, </editor> <title> Advances in Computer Methods for Partial Differential Equations. </title> <booktitle> IMACS, </booktitle> <year> 1984. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>. <p> In this paper, we will consider two kinds of preconditioner matrices M - (i) when M is chosen to be a diagonal matrix, usually derived from the principal diagonal of A, and (ii) when M is obtained through a truncated Incomplete Cholesky (IC) factorization <ref> [14, 29] </ref> of A. <p> These series may be truncated to (k +1) terms where k o N because M is diagonally dominant <ref> [14, 29] </ref>. In our formulation, we form the matrix ~ L = (I + L + L 2 + ... + L k ) explicitly. <p> In this section, we describe a different mapping and analyze its scalability. Given the matrix of coefficients A and the vector b, this mapping is fairly straightforward and has often been used in parallel implementations of the PCG algorithm due to its simplicity <ref> [16, 2, 21, 14] </ref>. Here we will compare this mapping with the one discussed in Section 6.1 in the context of a CM-5 type architecture. According to this scheme, the matrix A and the vector b are partitioned among p processors as shown in Figure 6.
Reference: [15] <author> Alan H. Karp and Horace P. Flatt. </author> <title> Measuring parallel processor performance. </title> <journal> Communications of the ACM, </journal> <volume> 33(5) </volume> <pages> 539-543, </pages> <year> 1990. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures.
Reference: [16] <author> S. K. Kim and A. T. Chronopoulos. </author> <title> A class of Lanczos-like algorithms implemented on parallel computers. </title> <journal> Parallel Computing, </journal> <volume> 17 </volume> <pages> 763-777, </pages> <year> 1991. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>. <p> In this section, we describe a different mapping and analyze its scalability. Given the matrix of coefficients A and the vector b, this mapping is fairly straightforward and has often been used in parallel implementations of the PCG algorithm due to its simplicity <ref> [16, 2, 21, 14] </ref>. Here we will compare this mapping with the one discussed in Section 6.1 in the context of a CM-5 type architecture. According to this scheme, the matrix A and the vector b are partitioned among p processors as shown in Figure 6.
Reference: [17] <author> Kouichi Kimura and Ichiyoshi Nobuyuki. </author> <title> Probabilistic analysis of the efficiency of the dynamic load distribution. </title> <booktitle> In The Sixth Distributed Memory Computing Conference Proceedings, </booktitle> <year> 1991. </year>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [18] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> Benjamin/Cummings, Redwood City, CA, </address> <year> 1994. </year> <month> 31 </month>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures [3, 7, 10, 15, 19, 22, 28, 32, 33]. In this paper, we use the isoefficiency metric <ref> [18, 7, 19] </ref> to study the scalability of an iteration of the PCG algorithm on some important architectures. <p> For a variety of parallel systems, given any number of processors p, speedup arbitrarily close to p can be obtained by simply executing the parallel algorithm on big enough problem instances (e.g., <ref> [18, 7, 11, 32] </ref>). The ease with which a parallel algorithm can achieve speedups proportional to p on a parallel architecture can serve as a measure of the scalability of the parallel system. <p> The ease with which a parallel algorithm can achieve speedups proportional to p on a parallel architecture can serve as a measure of the scalability of the parallel system. The isoefficiency function <ref> [18, 7] </ref> is one such metric of scalability which is a measure of an algorithm's capability to effectively utilize an increasing number of processors on a parallel architecture. <p> When M is an IC preconditioner, the structure of M is identical to that of A. A method for solving M z = r, originally proposed for vector machines [29], is briefly described below. A detailed description of the same can be found in <ref> [18] </ref>. As shown in Section 6, this method is perfectly parallelizable on CM-5 and other architectures ranging from mesh to hypercube. <p> Such 5 Unstructured sparse matrices arise in several applications. More details on scalable parallel formulations of sparse matrix-vector multiplication (and hence, iterative methods such as PCG) involving unstructured matrices arising in finite element problems are discussed in <ref> [18] </ref>. 30 restructuring techniques can improve the efficiency (for a given number of processors, problem size, machine architecture, etc.) as well as the asymptotic scalability of the PCG algorithm.
Reference: [19] <author> Vipin Kumar and Anshul Gupta. </author> <title> Analyzing scalability of parallel algorithms and architectures. </title> <type> Technical Report TR 91-18, </type> <institution> Department of Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1991. </year> <note> To appear in Journal of Parallel and Distributed Computing, </note> <year> 1994. </year> <booktitle> A shorter version appears in Proceedings of the 1991 International Conference on Supercomputing, </booktitle> <pages> pages 396-405, </pages> <year> 1991. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures. <p> Many different measures have been developed to study the scalability of parallel algorithms and architectures [3, 7, 10, 15, 19, 22, 28, 32, 33]. In this paper, we use the isoefficiency metric <ref> [18, 7, 19] </ref> to study the scalability of an iteration of the PCG algorithm on some important architectures.
Reference: [20] <author> C. E. Leiserson. Fat-trees: </author> <title> Universal networks for hardware efficient supercomputing. </title> <booktitle> In Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <pages> pages 393-402, </pages> <year> 1985. </year>
Reference-contexts: The analytical results presented in the paper are verified through experiments on the CM-5 parallel computer. On CM-5, the fat-tree <ref> [20] </ref> like communication network provides (almost) simultaneous paths for communication between all pairs of processors. The length of these paths may vary from 2 to 2 log p, if the distance between two switches or a processor and a switch is considered to be one unit [20]. <p> On CM-5, the fat-tree <ref> [20] </ref> like communication network provides (almost) simultaneous paths for communication between all pairs of processors. The length of these paths may vary from 2 to 2 log p, if the distance between two switches or a processor and a switch is considered to be one unit [20]. Hence, the cost of passing a message of size q between any pair of processors on the CM-5 is approximately t s + t w q + t h fi O (log p).
Reference: [21] <author> Rami Melhem. </author> <title> Toward efficient implementation of preconditioned conjugate gradient methods on vector supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> I(1):70-97, </volume> <year> 1987. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>. <p> In this section, we describe a different mapping and analyze its scalability. Given the matrix of coefficients A and the vector b, this mapping is fairly straightforward and has often been used in parallel implementations of the PCG algorithm due to its simplicity <ref> [16, 2, 21, 14] </ref>. Here we will compare this mapping with the one discussed in Section 6.1 in the context of a CM-5 type architecture. According to this scheme, the matrix A and the vector b are partitioned among p processors as shown in Figure 6.
Reference: [22] <author> Daniel Nussbaum and Anant Agarwal. </author> <title> Scalability of parallel machines. </title> <journal> Communications of the ACM, </journal> <volume> 34(3) </volume> <pages> 57-61, </pages> <year> 1991. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures.
Reference: [23] <author> S. Ranka and S. Sahni. </author> <title> Hypercube Algorithms for Image Processing and Pattern Recognition. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [24] <author> Youcef Saad. SPARSKIT: </author> <title> A basic tool kit for sparse matrix computations. </title> <type> Technical Report 90-20, </type> <institution> Research Institute for Advanced Computer Science, NASA Ames Research Center, Moffet Field, </institution> <address> CA, </address> <year> 1990. </year>
Reference-contexts: Suitable values of the constants fi and y can be selected to represent the kind of systems being solved. If fi = 1 and y = 1, we have the case of a totally unstructured sparse 20 matrix. The matrix A is stored in the Ellpack-Itpack format <ref> [24] </ref>. In this storage scheme, the non-zero elements of the matrix are stored in an N fi m array while another N fi m integer array stores the column numbers of the matrix elements. <p> It can be shown that co-ordinate and the compressed sparse column storage formats incur much higher communication overheads, thereby leading to unscalable parallel formulations. Two other storage schemes, namely jagged diagonals <ref> [24] </ref> and compressed sparse rows involve communication overheads similar to the Ellpack-Itpack scheme, but the latter is the easiest to work with when the number of non-zero elements is almost the same in each row of the sparse matrix.
Reference: [25] <author> Youcef Saad and M. H. Schultz. </author> <title> Parallel implementations of preconditioned conjugate gradient methods. </title> <type> Technical Report YALEU/DCS/RR-425, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1985. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>.
Reference: [26] <author> Vineet Singh, Vipin Kumar, Gul Agha, and Chris Tomlinson. </author> <title> Scalability of parallel sorting on mesh multicomputers. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(2), </volume> <year> 1991. </year>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [27] <author> Zhimin Tang and Guo-Jie Li. </author> <title> Optimal granularity of grid iteration problems. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages I111-I118, </pages> <year> 1990. </year>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [28] <author> Fredric A. Van-Catledge. </author> <title> Towards a general model for evaluating the relative performance of computer systems. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(2) </volume> <pages> 100-108, </pages> <year> 1989. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures.
Reference: [29] <author> Henk A. van der Vorst. </author> <title> A vectorizable variant of some ICCG methods. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> III(3):350-356, </volume> <year> 1982. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>. <p> In this paper, we will consider two kinds of preconditioner matrices M - (i) when M is chosen to be a diagonal matrix, usually derived from the principal diagonal of A, and (ii) when M is obtained through a truncated Incomplete Cholesky (IC) factorization <ref> [14, 29] </ref> of A. <p> The matrix-vector multiplication operation takes time proportional to 5N . When M is an IC preconditioner, the structure of M is identical to that of A. A method for solving M z = r, originally proposed for vector machines <ref> [29] </ref>, is briefly described below. A detailed description of the same can be found in [18]. As shown in Section 6, this method is perfectly parallelizable on CM-5 and other architectures ranging from mesh to hypercube. <p> These series may be truncated to (k +1) terms where k o N because M is diagonally dominant <ref> [14, 29] </ref>. In our formulation, we form the matrix ~ L = (I + L + L 2 + ... + L k ) explicitly.
Reference: [30] <author> Henk A. van der Vorst. </author> <title> Large tridiagonal and block tridiagonal linear systems on vector and parallel computers. </title> <journal> Parallel Computing, </journal> <volume> 5 </volume> <pages> 45-54, </pages> <year> 1987. </year>
Reference-contexts: As a result there has been a great deal of interest in implementing the Conjugate Gradient algorithm on parallel computers <ref> [1, 2, 12, 14, 16, 21, 25, 29, 30] </ref>.
Reference: [31] <author> Jinwoon Woo and Sartaj Sahni. </author> <title> Computing biconnected components on a hypercube. </title> <journal> Journal of Supercomputing, </journal> <month> June </month> <year> 1991. </year> <note> Also available as Technical Report TR 89-7 from the Department of Computer Science, </note> <institution> University of Minnesota, Minneapolis, MN. </institution>
Reference-contexts: Isoefficiency analysis has been found to be very useful in characterizing the scalability of a variety of parallel algorithms <ref> [9, 8, 13, 17, 23, 27, 26, 31] </ref>. An important feature of isoefficiency analysis is that it succinctly captures the effects of characteristics of the parallel algorithm as well as the parallel architecture on which it is implemented, in a single expression.
Reference: [32] <author> Patrick H. Worley. </author> <title> The effect of time constraints on scaled speedup. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 11(5) </volume> <pages> 838-858, </pages> <year> 1990. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures. <p> For a variety of parallel systems, given any number of processors p, speedup arbitrarily close to p can be obtained by simply executing the parallel algorithm on big enough problem instances (e.g., <ref> [18, 7, 11, 32] </ref>). The ease with which a parallel algorithm can achieve speedups proportional to p on a parallel architecture can serve as a measure of the scalability of the parallel system.
Reference: [33] <author> J. R. Zorbas, D. J. Reble, and R. E. VanKooten. </author> <title> Measuring the scalability of parallel computer systems. </title> <booktitle> In Supercomputing '89 Proceedings, </booktitle> <pages> pages 832-841, </pages> <year> 1989. </year> <month> 32 </month>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [3, 7, 10, 15, 19, 22, 28, 32, 33] </ref>. In this paper, we use the isoefficiency metric [18, 7, 19] to study the scalability of an iteration of the PCG algorithm on some important architectures.
References-found: 33

