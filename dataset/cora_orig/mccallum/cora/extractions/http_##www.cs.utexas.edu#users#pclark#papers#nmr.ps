URL: http://www.cs.utexas.edu/users/pclark/papers/nmr.ps
Refering-URL: http://www.cs.utexas.edu/users/pclark/papers/nmr.abs.html
Root-URL: 
Title: Nonmonotonic Reasoning, Argumentation and Machine Learning  
Author: Peter Clark 
Date: 29th June 1990  
Address: 36 N.Hanover St Glasgow, UK  
Affiliation: The Turing Institute  
Abstract: Technical Report TIMLG-38, Turing Institute, Glasgow, UK (June 1990) http://www.cs.utexas.edu/users/pclark/papers/nmr.ps Abstract Machine learning and nonmonotonic reasoning are closely related, both concerned with making plausible as well as certain inferences based on available data. In this document a brief overview of different approaches to nonmonotonic reasoning is presented, and it is shown how the concept of argumentation systems arises. The relationship with machine learning work is also discussed. The document aims to highlight the links between nonmonotonic reasoning, argumentation and machine learning and as a result propose some potentially useful directions for new research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Brachman. </author> <title> `i lied about the trees', or, defaults and definitions in knowledge representation. </title> <journal> AI Magazine, </journal> <volume> 6(3), </volume> <year> 1985. </year>
Reference-contexts: The most prominent method is that of taxonomic inheritance with exceptions (eg. <ref> [7, 1] </ref>). Here, the principle of specificity is used to resolve conflict: information about subclasses overrides information about more general classes in the case of conflict. If Tweety is a bird, assume he flies, but if Tweety is an ostrich then assume he does not.
Reference: [2] <author> W. Buntine. </author> <title> Modelling default and likelihood reasoning as probabilistic reasoning. </title> <journal> Annals of Mathematics and AI, </journal> <note> 1990. to appear. </note>
Reference-contexts: We will discuss ways in which the two can be combined later. In the rest of this paper, we use the term `default' in the logical rather than probabilistic sense. Buntine has formulated a logic for `default' reasoning using a probabilistic interpretation of `by default' to mean `most' <ref> [2] </ref>. 2 1.3 Their Relationship Monotonicity and uncertainty representation are related (eg. it is not possible to draw tentative conclusions without being able to at least express them). However, the two should not be mixed.
Reference: [3] <author> P. R. Cohen. </author> <title> Heuristic reasoning about uncertainty : An AI approach. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: Here we refer to it as the `justification' for the argument. Many expert systems lack representation of the justification for their rules, limiting their explanation capabilities. Cohen has similarly called for the explicit representation and use of this meta-knowledge (termed `endorsements') in probabilistic reasoning <ref> [3] </ref>. In the described systems, the user is assumed to provide all the arguments manually. In contrast, some machine learning (ML) systems derive plausible relations automatically from provided data.
Reference: [4] <author> T. R. Davies and S. J. Russell. </author> <title> A logical approach to reasoning by analogy. </title> <booktitle> In IJCAI-87, </booktitle> <pages> pages 264-270, </pages> <year> 1987. </year>
Reference-contexts: While the domain of law is an obvious example, it should be noted that consistency of judgement 7 plays a fundamental role in many decision-making tasks. We can say that the arguments should completely determine the outcome, a concept developed by Russell in his theory of determinations <ref> [4] </ref>. Use of precedents has the advantage of avoiding a representation of how argument strength is calculated and compared. Instead, only the results of previous conflict resolutions are needed, without requiring knowledge of how those results were reached.
Reference: [5] <author> J. de Kleer. </author> <title> Back to backtracking: Controlling the atms. </title> <booktitle> In AAAI-86, </booktitle> <pages> pages 910-917, </pages> <year> 1986. </year>
Reference: [6] <author> J. Doyle. </author> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference: [7] <author> S. E. Fahlman. </author> <title> NETL: A System for Representing and Using Real-World Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Ma, </address> <year> 1977. </year>
Reference-contexts: The most prominent method is that of taxonomic inheritance with exceptions (eg. <ref> [7, 1] </ref>). Here, the principle of specificity is used to resolve conflict: information about subclasses overrides information about more general classes in the case of conflict. If Tweety is a bird, assume he flies, but if Tweety is an ostrich then assume he does not.
Reference: [8] <author> J. Fox, A. J. Glowinski, M. J. O'Neil, and D. A. Clark. </author> <title> Decision making as a logical process. </title> <editor> In B. Kelly and A. Rector, editors, </editor> <booktitle> Research and Development in Expert Systems V, </booktitle> <pages> pages 160-175. </pages> <publisher> University Press, </publisher> <address> Cambridge, </address> <year> 1989. </year>
Reference-contexts: In Fox et als. system, conflicts are resolved by simply by counting the number of arguments `for' and `against', and assuming the majority wins <ref> [8] </ref>. This method suffers from the problem of assigning numeric strengths to arguments. A single number is a poor representation of the justification for why an argument is valid, how strong and reliable that justification is, and how it interacts with justifications for other arguments.
Reference: [9] <author> M. R. Genesereth and N. J. Nilsson. </author> <booktitle> Logical Foundations for Artificial Intelligence. </booktitle> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1987. </year>
Reference-contexts: PC still suffers from the three limitations described above, although some disjuncts can be handled using `predicate ordering' techniques <ref> [9] </ref>. Circumscription can be viewed as a more general form of these methods, and will cope with disjunctive formulae in such as equation 1 above. Circumscription is applied to a particular predicate (P, say) in .
Reference: [10] <author> K. Konolige. </author> <title> Defesible argumentation in reasoning about events. </title> <editor> In Z. W. Ras and L. Saitta, editors, </editor> <booktitle> Methods for Intelligent Systems, </booktitle> <volume> 3, </volume> <pages> pages 380-390. </pages> <publisher> Elsevier, </publisher> <address> NY, </address> <year> 1988. </year>
Reference-contexts: He states that "general domain-independent principles [for adjudicating among conflict] will be very weak, and that information from the semantics of the domain will be the most important way of deciding among competing arguments" <ref> [10] </ref> p381 In support of this, he proposes a formalism called ARGH 1 for describing events [10, 11]. Arguments are classed into two types. A set of inference rules are used to resolve conflict, making use of information about argument type. <p> He states that "general domain-independent principles [for adjudicating among conflict] will be very weak, and that information from the semantics of the domain will be the most important way of deciding among competing arguments" [10] p381 In support of this, he proposes a formalism called ARGH 1 for describing events <ref> [10, 11] </ref>. Arguments are classed into two types. A set of inference rules are used to resolve conflict, making use of information about argument type.
Reference: [11] <author> K. Konolige and M. E. Pollack. </author> <title> Ascribing plans to agents. </title> <booktitle> In IJCAI-89, </booktitle> <volume> volume 2, </volume> <pages> pages 924-930, </pages> <year> 1989. </year>
Reference-contexts: He states that "general domain-independent principles [for adjudicating among conflict] will be very weak, and that information from the semantics of the domain will be the most important way of deciding among competing arguments" [10] p381 In support of this, he proposes a formalism called ARGH 1 for describing events <ref> [10, 11] </ref>. Arguments are classed into two types. A set of inference rules are used to resolve conflict, making use of information about argument type.
Reference: [12] <author> J. Pearl. </author> <title> Embracing causality in formal reasoning. </title> <booktitle> In AAAI-87, </booktitle> <pages> pages 369-373, </pages> <year> 1987. </year>
Reference-contexts: Finally, Pearl has proposed a system for default reasoning which uses knowledge of causality to make default assumptions <ref> [12] </ref>. Given some effect E, a given cause C is assumed true by default unless some other possible cause C 0 of E is already known to hold.
Reference: [13] <author> R. Reiter. </author> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13(1-2):81-132, </volume> <year> 1980. </year>
Reference-contexts: McDermott and Doyle's nonmonotonic logic [14] introduces a modal operator M meaning `is consistent', for example: 8x Bird (x) ^ M Flies (x) ! Flies (x) means `if x is a bird, and it is consistent to believe x flies, then x flies'. 4 2. Reiter's default logic <ref> [13] </ref> uses default rules of the form ff : M fi=! meaning `if ff is known, and fi is consistent with what is known, then assume !'.
Reference: [14] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <editor> In H. E. Shrobe, editor, </editor> <booktitle> Exploring Artificial Intelligence, </booktitle> <pages> pages 439-481. </pages> <publisher> Kaufmann, </publisher> <address> Ca, </address> <year> 1988. </year>
Reference-contexts: Probabilistic statements (`most birds fly') are often used in reasoning, but not all knowledge can be represented in this way. Logical statements are also often used, especially for conveying conventions (`assume normal conditions unless told otherwise'). As an example of this, McCarthy <ref> [14] </ref> points out that in the missionary-and-cannibals problem we assume the boat is not leaky on the basis of this logical convention rather than a probabilistic analysis of boat leakage likelihood. An ideal system for plausible reasoning should be able to represent both probabilistic and logical statements. <p> To overcome this, and allow inconsistency checking as a method for blocking the use of default rules, several nonmonotic logics have been proposed including: 1. McDermott and Doyle's nonmonotonic logic <ref> [14] </ref> introduces a modal operator M meaning `is consistent', for example: 8x Bird (x) ^ M Flies (x) ! Flies (x) means `if x is a bird, and it is consistent to believe x flies, then x flies'. 4 2.
Reference: [15] <author> E. L. Rissland and K. D. Ashley. </author> <title> Hypotheticals as heuristic device. </title> <booktitle> In AAAI-86, </booktitle> <pages> pages 289-297, </pages> <year> 1986. </year>
Reference-contexts: These act as `anchor points', mooring the combinations of `pro' and `con' arguments to fixed outcomes. 4.5.1 Some Systems We now mention some systems in terms of argument space. 1. In their system Hypo, Rissland and Ashley <ref> [15] </ref> refer to the axes of argument space as `dimensions' some dimensions are continuous, where the value of some parameter is deemed to strengthen/weaken the argument.
Reference: [16] <author> K. Sycara. </author> <title> Resolving goal conflicts via negotiation. </title> <booktitle> In AAAI-88, </booktitle> <pages> pages 245-250, </pages> <year> 1988. </year>
Reference-contexts: Several authors have proposed using metrics to determine which OldCase the New-Case is `nearest' to, and adopt that OldCase's conclusion for NewCase. Thus a gradient of argument strength is established between known points in argument space. An example is the system Persuader <ref> [16] </ref>. The problem with this approach is finding an adequate metric for assessing similarity. Although most systems use ad hoc techniques, it is difficult to see how to avoid this. 2.
Reference: [17] <author> S. E. Toulmin. </author> <title> The Uses of Argument. </title> <publisher> University Press, </publisher> <address> Cambridge, UK, </address> <year> 1958. </year>
Reference-contexts: In everyday argumentation it is common to question the validity of arguments others put forward, and often a level of detail will be `pushed' to `sub'-argue about whether a particular argument is valid. Toulmin, in his proposed schemata for argument structures, calls this meta-knowledge the `backing' <ref> [17] </ref> for an argument, and considers it an integral component of argumentation. Here we refer to it as the `justification' for the argument. Many expert systems lack representation of the justification for their rules, limiting their explanation capabilities.
Reference: [18] <author> A. v.d.L. Gardner. </author> <title> The design of a legal analysis program. </title> <booktitle> In AAAI-83, </booktitle> <pages> pages 114-118, </pages> <year> 1983. </year> <month> 10 </month>
Reference-contexts: Gardner's system for legal reasoning similarly searches for previous precedents where an identical pattern of argument occurred in order to resolve argument con flicts and ambiguities in a legal case <ref> [18] </ref>. All these systems are unable to adjudicate conflicts where appropriate precedents do not exist. Ideally, though, we would like to attempt some judgement based on the 8 precedents which we do have available.
References-found: 18

