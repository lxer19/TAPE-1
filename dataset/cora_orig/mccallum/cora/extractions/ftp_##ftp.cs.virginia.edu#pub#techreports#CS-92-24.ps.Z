URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-92-24.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Memory Bandwidth Optimizations for Wide-Bus Machines  
Abstract: Michael J. Alexander, Mark W. Bailey, Bruce R. Childers, Jack W. Davidson, Sanjay Jinturkar Technical Report No. CS-92-24 
Abstract-found: 1
Intro-found: 1
Reference: [ALP92] <institution> Alpha Architecture Handbook. Digital Equipment Corporation, </institution> <year> 1992. </year>
Reference-contexts: For example, the VAX-11 instruction set contained instructions for storing quad-words (64 bits) and octa-words (128 bits), but the SBI (Synchronous Backplane Interconnect) on the VAX-11/780 was only 32 bits wide [VAX82] . We are aware of at least three WBMs available from system vendors, the DEC Alpha <ref> [ALP92] </ref> , the Motorola 88110 [MC891] , and the MIPS R4000 [KAN92] . These machines share the characteristic that 64-bits can be loaded from or stored to memory. Of these machines, the DEC Alpha is closest to our vision of what future 64-bit machines will look like.
Reference: [BEN88] <author> Benitez, M. E. and Davidson, J. W. </author> <title> A Portable Global Optimizer and Linker. </title> <booktitle> Proceedings of the SIGPLAN '88 Symposium on Programming Language Design, </booktitle> <pages> pages 329-338, </pages> <address> Atlanta, GA, </address> <month> June, </month> <year> 1988. </year>
Reference-contexts: MEMORY BANDWIDTH CODE IMPROVEMENTS In order to design, implement, and evaluate memory bandwidth code improvements for WBMs, we modified an existing retargetable optimizer to include the memory bandwidth code improvements. The optimizer, called vpo, is a sophisticated, global optimizer that can be used to build optimizing compilers <ref> [BEN88, DAV84, DAV84] </ref> . Figure 1 contains a schematic showing the overall organization of a C compiler constructed using vpo. Vertical columns represent logical phases which operate serially. Columns that are divided horizontally into rows indicate that the sub-phases of the column many be executed in an arbitrary order.
Reference: [BEN91] <author> Benitez, M. E. and Davidson, J. W. </author> <title> Code Generation for Streaming: an Access/ Execute Mechanism. </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support, </booktitle> <pages> pages 132-141, </pages> <address> Santa, CA, </address> <month> April, </month> <year> 1991. </year>
Reference-contexts: Register blocking and cache blocking can be used in combination to reduce the number of memory references and cache misses. Another program transformation that reduces a programs memory bandwidth requirements is called recurrence detection and optimization <ref> [BEN91] </ref> . Knuth [KNU73] defines - 5 - a recurrence relation as a rule which defines each element of a sequence in terms of the preceding elements. Recurrence relations appear in the solutions to a large number of compute and memory intensive problems.
Reference: [CAL90] <author> Callahan, D. and Carr, S. and Kennedy, K. </author> <title> Improving Register Allocation for Subscripted Variables. </title> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 53-65, </pages> <address> White Plains, NY, </address> <month> June, </month> <year> 1990. </year>
Reference-contexts: Register blocking can be considered a specific application of scalar replacement of subscripted variables <ref> [CAL90] </ref> and loop unrolling. Scalar replacement identifies subscripted variables which appear in loops but whose subscripts are loop invariant. These variables can be loaded into registers outside the loop allowing register references replace the memory references inside the loop.
Reference: [BUR92] <author> Bursky, D. </author> <title> Memory-CPU Interface Speeds up Data Transfers. </title> <booktitle> Electronic Design 40(6) </booktitle> <month> 137-142 March </month> <year> 1992. </year>
Reference-contexts: The approaches to solving the problem can be categorized as either software or hardware solutions. This paper focuses solely on software solutions. The interested reader is referred to Patterson and Hennessy [HEN90] and Goodman [GOO83] for a discussion of system-oriented hardware approaches to solving the problem. Bursky <ref> [BUR92] </ref> , Nakagome and Itoh [NAK91] , and Hidaka, Matsuda, and Asakura [HID90] discuss the potential for improvements in DRAM and memory interface technology. Most of the related work in software approaches has focused on ways to reduce the memory bandwidth requirements of a program.
Reference: [CHO90] <author> Chow, F. C. and Hennessy, J. L. </author> <title> The Priority-Based Coloring Approach to Register Allocation. </title> <journal> ACM Transactions on Programming Languages and Systems 12(4) </journal> <month> 501-536 October </month> <year> 1990. </year>
Reference-contexts: A recent evaluation of the register coloring approach to register allocation showed that up to 75 percent of the scalar memory references can be removed <ref> [CHO90] </ref> using these techniques. Another class of code transformation that can reduce a programs memory bandwidth requirements is blocking transformation such as: cache blocking and register blocking. These transformations can profitably be applied to codes that process large sets of data held in arrays.
Reference: [DAV84] <author> Davidson, J. W. and Fraser, C. W. </author> <title> Code Selection through Object Code Optimization. </title> <journal> Transactions on Programming Languages and Systems 6(4) </journal> <month> 7-32 October </month> <year> 1984. </year>
Reference-contexts: The extensions are shown below using RTLs (Register Transfer Lists) <ref> [DAV84] </ref> and the corresponding assembly language instructions: Register Transfer List Representation Assembly Language r [4]=R [r [29]+8];r [5]=R [r [29]+12]; ld64 %4,8 (%29) f [0]=F [r [29]+16];f [2]=F [r [29]+20]; ldf64 %0,16 (%29) It is assumed that the implementation of the instruction-set architecture will support the above operations in a single <p> MEMORY BANDWIDTH CODE IMPROVEMENTS In order to design, implement, and evaluate memory bandwidth code improvements for WBMs, we modified an existing retargetable optimizer to include the memory bandwidth code improvements. The optimizer, called vpo, is a sophisticated, global optimizer that can be used to build optimizing compilers <ref> [BEN88, DAV84, DAV84] </ref> . Figure 1 contains a schematic showing the overall organization of a C compiler constructed using vpo. Vertical columns represent logical phases which operate serially. Columns that are divided horizontally into rows indicate that the sub-phases of the column many be executed in an arbitrary order.
Reference: [DAV90] <author> Davidson, J. W. and Whalley, D. B. </author> <title> Ease: An Environment for Architecture Study and Experimentation. </title> <booktitle> Proceedings of the 1990 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 259-260, </pages> <address> Boulder, CO, </address> <month> May, </month> <year> 1990. </year>
Reference-contexts: Consequently, we expect that the performance benefits reported here will be close to what other optimizing compilers can expect to realize. Third, vpo and a companion tool, called ease (Environment for Architecture Study and Experimentation) <ref> [DAV90] </ref> , provide facilities for experimenting and evaluating the performance of new architectural features. These facilities and how they are used for this study are described in Section 4. <p> EVALUATION We implemented the above optimizations in an optimizing C compiler targeted to our prototype WBM. To evaluate the effectiveness of the code improvements, we used an environment - 15 - called ease (Environment for Architecture Study and Experimentation) <ref> [DAV90] </ref> . ease provides two capabilities that are necessary to perform the evaluation. First, ease provides the capability for emulating one architecture on another. <p> For this study, ease measured, broken down by type, the number of memory references performed and the number of instructions executed. The interested reader is referred to [WHA90] and <ref> [DAV90] </ref> for more details on how ease efficiently and simply gathers these detailed measurements. To evaluate the effects of the code improvements on memory traffic, we used two sets of programs (see Table I).
Reference: [DAV84] <author> Davidson, J. W. and Fraser, C. W. </author> <title> Register Allocation and Exhaustive Peephole Optimization. </title> <journal> Software--Practice and Experience 14(9) </journal> <month> 857-866 September </month> <year> 1984. </year>
Reference-contexts: The extensions are shown below using RTLs (Register Transfer Lists) <ref> [DAV84] </ref> and the corresponding assembly language instructions: Register Transfer List Representation Assembly Language r [4]=R [r [29]+8];r [5]=R [r [29]+12]; ld64 %4,8 (%29) f [0]=F [r [29]+16];f [2]=F [r [29]+20]; ldf64 %0,16 (%29) It is assumed that the implementation of the instruction-set architecture will support the above operations in a single <p> MEMORY BANDWIDTH CODE IMPROVEMENTS In order to design, implement, and evaluate memory bandwidth code improvements for WBMs, we modified an existing retargetable optimizer to include the memory bandwidth code improvements. The optimizer, called vpo, is a sophisticated, global optimizer that can be used to build optimizing compilers <ref> [BEN88, DAV84, DAV84] </ref> . Figure 1 contains a schematic showing the overall organization of a C compiler constructed using vpo. Vertical columns represent logical phases which operate serially. Columns that are divided horizontally into rows indicate that the sub-phases of the column many be executed in an arbitrary order.
Reference: [GOO83] <author> Goodman, J. R. </author> <title> Using Cache Memory to Reduce Processor-Memory Traffic. </title> <booktitle> Proceedings of the 10th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 124-131, </pages> <address> Stockholm, Sweden, </address> <month> June, </month> <year> 1983. </year>
Reference-contexts: The approaches to solving the problem can be categorized as either software or hardware solutions. This paper focuses solely on software solutions. The interested reader is referred to Patterson and Hennessy [HEN90] and Goodman <ref> [GOO83] </ref> for a discussion of system-oriented hardware approaches to solving the problem. Bursky [BUR92] , Nakagome and Itoh [NAK91] , and Hidaka, Matsuda, and Asakura [HID90] discuss the potential for improvements in DRAM and memory interface technology.
Reference: [HEN90] <author> Hennessy, J. L. and Patterson, D. A. </author> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <month> - 22 </month> - 
Reference-contexts: For example, processors operating at speeds of 66 to 100 megahertz are available now and implementations that operate in the 100 to 200 megahertz range have been announced. On the other hand, current DRAM cycle times are an order of magnitude slower than processor cycle times <ref> [HEN90] </ref> . Providing a cache constructed of faster SRAM parts reduces the performance gap, but caches cannot eliminate the problem. Furthermore, for processors used in scientific computing applications, the large problem sizes can make caches less effective. <p> The approaches to solving the problem can be categorized as either software or hardware solutions. This paper focuses solely on software solutions. The interested reader is referred to Patterson and Hennessy <ref> [HEN90] </ref> and Goodman [GOO83] for a discussion of system-oriented hardware approaches to solving the problem. Bursky [BUR92] , Nakagome and Itoh [NAK91] , and Hidaka, Matsuda, and Asakura [HID90] discuss the potential for improvements in DRAM and memory interface technology.
Reference: [HID90] <author> Hidaka, H. and Matsuda, Y. and Asakura, M. </author> <title> The Cache DRAM Architecture: a DRAM with an on-chip cache memory. </title> <booktitle> IEEE Micro 10(2) </booktitle> <month> 14-25 April </month> <year> 1990. </year>
Reference-contexts: This paper focuses solely on software solutions. The interested reader is referred to Patterson and Hennessy [HEN90] and Goodman [GOO83] for a discussion of system-oriented hardware approaches to solving the problem. Bursky [BUR92] , Nakagome and Itoh [NAK91] , and Hidaka, Matsuda, and Asakura <ref> [HID90] </ref> discuss the potential for improvements in DRAM and memory interface technology. Most of the related work in software approaches has focused on ways to reduce the memory bandwidth requirements of a program.
Reference: [KAN92] <author> Kane, G. and Heinrich, J. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: We are aware of at least three WBMs available from system vendors, the DEC Alpha [ALP92] , the Motorola 88110 [MC891] , and the MIPS R4000 <ref> [KAN92] </ref> . These machines share the characteristic that 64-bits can be loaded from or stored to memory. Of these machines, the DEC Alpha is closest to our vision of what future 64-bit machines will look like.
Reference: [KNU73] <author> Knuth, D. E. </author> <title> Volume 1: Fundamental Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: Register blocking and cache blocking can be used in combination to reduce the number of memory references and cache misses. Another program transformation that reduces a programs memory bandwidth requirements is called recurrence detection and optimization [BEN91] . Knuth <ref> [KNU73] </ref> defines - 5 - a recurrence relation as a rule which defines each element of a sequence in terms of the preceding elements. Recurrence relations appear in the solutions to a large number of compute and memory intensive problems. Interestingly, codes containing recurrences often cannot be vectorized.
Reference: [LAM91] <author> Lam, M. and Rothberg, E. E. and Wolf, M. E. </author> <title> The Cache Performance and Optimizations of Blocked Algorithms. </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 63-74, </pages> <address> Santa Clara, CA, </address> <month> April, </month> <year> 1991. </year>
Reference-contexts: Cache blocking, however, transforms the code so that a block of the array that will fit in the cache is read in once, used many times, and then replaced by the next block. The performance benefits from this transformation can be quite good. Lam, Rothberg, and Wolf <ref> [LAM91] </ref> show that for multiplication of large, floating-point arrays, cache blocking can easily triple the performance of a cache-based system.
Reference: [MC891] <author> MC88110: </author> <title> Second Generation RISC Microprocessor User's Manual. Motorola, </title> <publisher> Inc., </publisher> <address> Phoenix, AZ, </address> <year> 1991. </year>
Reference-contexts: We are aware of at least three WBMs available from system vendors, the DEC Alpha [ALP92] , the Motorola 88110 <ref> [MC891] </ref> , and the MIPS R4000 [KAN92] . These machines share the characteristic that 64-bits can be loaded from or stored to memory. Of these machines, the DEC Alpha is closest to our vision of what future 64-bit machines will look like.
Reference: [NAK91] <author> Nakagome, Y. and Itoh, K. </author> <title> Reviews and Prospects of DRAM Technology. </title> <journal> IEICE Transactions on Communications Electronics Information and Systems 74(4) </journal> <month> 799-811 April </month> <year> 1991. </year>
Reference-contexts: This paper focuses solely on software solutions. The interested reader is referred to Patterson and Hennessy [HEN90] and Goodman [GOO83] for a discussion of system-oriented hardware approaches to solving the problem. Bursky [BUR92] , Nakagome and Itoh <ref> [NAK91] </ref> , and Hidaka, Matsuda, and Asakura [HID90] discuss the potential for improvements in DRAM and memory interface technology. Most of the related work in software approaches has focused on ways to reduce the memory bandwidth requirements of a program.
Reference: [SYS89] <institution> Systems Performance Evaluation Cooperative. </institution> <note> SPEC Newsletter: Benchmark Results Fall 1989. </note>
Reference-contexts: To evaluate the effects of the code improvements on memory traffic, we used two sets of programs (see Table I). Set 1 consists of a group of well-known user programs and the four C programs from the original SPEC benchmark suite <ref> [SYS89] </ref> . These programs are intended to represent typical user code. Set 2 consists of a set of loops that represent memory intensive kernels. For example, several of the loops are from the well known Livermore loops benchmark suite.
Reference: [VAX82] <institution> VAX Hardware Handbook. Digital Equipment Corporation, Maynard, </institution> <address> MA, </address> <year> 1982. </year>
Reference-contexts: For example, the VAX-11 instruction set contained instructions for storing quad-words (64 bits) and octa-words (128 bits), but the SBI (Synchronous Backplane Interconnect) on the VAX-11/780 was only 32 bits wide <ref> [VAX82] </ref> . We are aware of at least three WBMs available from system vendors, the DEC Alpha [ALP92] , the Motorola 88110 [MC891] , and the MIPS R4000 [KAN92] . These machines share the characteristic that 64-bits can be loaded from or stored to memory.
Reference: [WHA90] <author> Whalley, D. B. </author> <title> Ease: An Environment for Architecture Study and Experimentation. </title> <type> Ph.D. Dissertation, </type> <institution> University of Virginia, </institution> <address> Charlottesville, VA, </address> <year> 1990. </year>
Reference-contexts: When the program is run to completion, the count information is written out and correlated with the information about the instructions. For this study, ease measured, broken down by type, the number of memory references performed and the number of instructions executed. The interested reader is referred to <ref> [WHA90] </ref> and [DAV90] for more details on how ease efficiently and simply gathers these detailed measurements. To evaluate the effects of the code improvements on memory traffic, we used two sets of programs (see Table I).
References-found: 20

