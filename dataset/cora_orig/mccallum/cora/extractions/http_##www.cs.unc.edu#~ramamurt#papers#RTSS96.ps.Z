URL: http://www.cs.unc.edu/~ramamurt/papers/RTSS96.ps.Z
Refering-URL: http://www.cs.unc.edu/~ramamurt/papers.html
Root-URL: http://www.cs.unc.edu
Title: A Framework for Implementing Objects and Scheduling Tasks in Lock-Free Real-Time Systems  
Author: James H. Anderson and Srikanth Ramamurthy 
Address: Chapel Hill  
Affiliation: Department of Computer Science, University of North Carolina at  
Abstract: We present an integrated framework for developing real-time systems in which lock-free algorithms are employed to implement shared objects. There are two key objectives of our work. The first is to enable functionality for object sharing in lock-free real-time systems that is comparable to that in lock-based systems. Our main contribution toward this objective is an efficient approach for implementing multi-object lock-free operations and transactions. A second key objective of our work is to improve upon previously proposed scheduling conditions for tasks that share lock-free objects. When developing such conditions, the key issue is to bound the cost of operation "interferences". We present a general approach for doing this, based on linear programming. Experimental results are presented that show that lock-free objects implemented within our framework outperform lock-based implementations in a variety of settings. These experiments involve tasks that perform single- and multi-object operations on queues and balanced trees.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, ACM, </booktitle> <address> New York, </address> <month> August </month> <year> 1995, </year> <pages> pp. 184-193. </pages>
Reference-contexts: For our purposes, such an implementation should be lock-free or wait-free. Unfortunately, previous lock-free and wait-free implementations of primitives like MWCAS have rather high worst-case time complexity <ref> [1, 6, 11, 20] </ref>. Thus, they are of limited utility in real-time systems. One of the main contributions of this paper is to show that a wait-free MWCAS primitive can be implemented efficiently if one assumes a priority-based task scheduler. <p> We denote operations by line segments, with time running from left to right. 6 val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 <p> 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) <p> (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 1 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 1 Status [4]: <p> [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save <ref> [3; 1] </ref>: 22 Status [3]: 1 Status [4]: 1 (d) respectively.
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> Proceedings of the Ninth International Workshop on Distributed Algorithms, Lecture Notes in Computer Science 972, </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1995, </year> <pages> pp. 168-182. </pages>
Reference-contexts: [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 1 Status [4]: 1 (d) respectively. <p> In order to modify the contents of the array, a task makes a copy of each block to be changed, and then attempts to replace the old version of that block by its modified copy. This copy-based implementation generalizes previous universal lock-free constructions that rely on state copying <ref> [2, 9] </ref>. In Figure 6, BANK is a B-word shared array. Each element of BANK contains a pointer to a block of size S and a version number (see below) for the pointer. The B blocks pointed to by BANK constitute the current version of the MEM array.
Reference: [3] <author> J. Anderson, S. Ramamurthy, M. Moir, and K. Jeffay, </author> <title> "Lock-Free Transactions for Real-Time Systems", </title> <booktitle> Proceedings of the First International Workshop on Real-Time Databases: Issues and Applications, </booktitle> <month> March </month> <year> 1996, </year> <pages> pp. 107-114. </pages>
Reference-contexts: Note that the current value of each word matches the desired old value. Inset (b) shows the variables after the first phase of m has completed, assuming no interferences by higher-priority tasks. Note that the current value of each word is unchanged. Also, Status <ref> [3] </ref> has been updated to indicate that task T 3 has been interfered with. T 3 must be of lower priority than T 4 because it had only partially completed a MWCAS operation before T 4 began its operation. <p> Inset (d) shows relevant variables at the termination of m, assuming that an interference occurs by task T 9 (which must be a higher-priority task) on word z. Status [4] is now 1, indicating the failure of T 4 's operation. Status <ref> [3] </ref> is still 1, indicating that T 3 's operation has also failed. Observe that T 4 has successfully restored the values of words x and y to their original values. <p> We denote operations by line segments, with time running from left to right. 6 val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 <p> We denote operations by line segments, with time running from left to right. 6 val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save [3; 1]: 22 Status <ref> [3] </ref>: 0 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 <p> 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) <p> 10 z: 17 0 true 4 Val (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status <ref> [3] </ref>: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; <p> [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save <ref> [3; 1] </ref>: 22 Status [3]: 1 Status [4]: 1 (d) respectively. <p> 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status <ref> [3] </ref>: 1 Status [4]: 1 (d) respectively. <p> Such transactions can be applied to perform database operations, or to implement complex operations on shared objects. The implementation presented here is similar to one presented previously by us and colleagues in <ref> [3] </ref>. Because MWCAS and READ are used, we require that all tasks performing transactions are executed in accordance with the task model discussed in Section 2.1. Lock-free transactions have several advantages over more conventional schemes for concurrency control.
Reference: [4] <author> J. Anderson, S. Ramamurthy and K. Jeffay, </author> <title> "Real-Time Computing with Lock-Free Shared Objects (Extended Abstract)", </title> <booktitle> Proceedings of the 16th IEEE Real-Time Systems Symposium, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1995, </year> <pages> pp. 28-37. </pages>
Reference-contexts: Head and tail pointers fl= procedure Dequeue () returns flQtype repeat old := H ; if old = NULL then return NULL fi; new := old&gt;next until CAS2 (&H ; &(old&gt;next ); old; new ; new; NULL); return (old) in such applications was first established by Anderson, Ramamurthy, and Jeffay <ref> [4] </ref>. Operations on lock-free objects are usually implemented using "retry loops". Figure 1 depicts an example, a lock-free queue implementation. <p> Anderson et al. observed that, on a uniprocessor, the cost of such failed loop iterations over an interval of time can be bounded by the number of job releases 3 within that interval <ref> [4] </ref>. This observation is the basis of scheduling conditions presented in [4] for the rate-monotonic (RM) [15], deadline-monotonic (DM) [14], and earliest-deadline-first (EDF) [15] schemes. <p> Anderson et al. observed that, on a uniprocessor, the cost of such failed loop iterations over an interval of time can be bounded by the number of job releases 3 within that interval <ref> [4] </ref>. This observation is the basis of scheduling conditions presented in [4] for the rate-monotonic (RM) [15], deadline-monotonic (DM) [14], and earliest-deadline-first (EDF) [15] schemes. <p> Results presented by Anderson et al. suggest that lock-free objects require less overhead than wait-free objects in uniprocessor real-time systems <ref> [4] </ref>. 2 The first two parameters of CAS2 specify addresses of two shared variables, the next two parameters are values to which these variables are compared, and the last two parameters are new values to assign to the variables if both comparisons succeed. 3 We use the term job to refer <p> In particular, we use it to obtain scheduling conditions for the RM, DM, and EDF schemes, and a variation of the EDF scheme, which we call the EDF/NPD scheme, in which deadlines do not equal periods. These conditions are much tighter than those originally reported in <ref> [4] </ref>. How do lock-free objects implemented using the results of this paper compare to lock-based implementations? To answer this question, we conducted a number of simulation experiments involving randomly generated sets of tasks that perform both single- and multi-object operations. <p> Also, Status [3] has been updated to indicate that task T 3 has been interfered with. T 3 must be of lower priority than T 4 because it had only partially completed a MWCAS operation before T 4 began its operation. Note that changing the value of Status <ref> [4] </ref> from 0 to 2 in inset (b) would have the effect of atomically changing the current value of each of x, y, and z to the desired new value. Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority tasks. <p> Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority tasks. Note that the current value of each word is now the desired new value, and that all valid fields are true (so the value of Status <ref> [4] </ref> is no longer relevant). Inset (d) shows relevant variables at the termination of m, assuming that an interference occurs by task T 9 (which must be a higher-priority task) on word z. Status [4] is now 1, indicating the failure of T 4 's operation. <p> the desired new value, and that all valid fields are true (so the value of Status <ref> [4] </ref> is no longer relevant). Inset (d) shows relevant variables at the termination of m, assuming that an interference occurs by task T 9 (which must be a higher-priority task) on word z. Status [4] is now 1, indicating the failure of T 4 's operation. Status [3] is still 1, indicating that T 3 's operation has also failed. Observe that T 4 has successfully restored the values of words x and y to their original values. <p> 22 z: 8 3 true 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status <ref> [4] </ref>: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; <p> 0 true 4 Val (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 1 Save <ref> [4; 0] </ref>: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status <p> (z) = 17 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 1 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 1 Status [4]: <p> [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 Status [4]: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 1 Status [4]: 1 (d) respectively. <p> count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 1 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status <ref> [4] </ref>: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 1 Status [4]: 1 (d) respectively. <p> [4; 1]: 22 Save [4; 2]: 8 Status <ref> [4] </ref>: 0 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 1 Status [4]: 1 (d) respectively. The contents of relevant shared variables are shown (a) at the beginning of the operation; (b) after the loop in lines 3..17; (c) at the end of the operation, assuming success; and (d) at the end of the operation, assuming failure on word z. <p> We illustrate the utility of this approach by applying it to obtain scheduling conditions for the RM, DM, EDF, and EDF/NPD schemes. These new scheduling conditions are much tighter than those originally reported in <ref> [4] </ref>. <p> The second set of constraints follow from a result presented in <ref> [4] </ref>, which states that the total number of interferences in all jobs of tasks T 0 through T i in an interval I of length t is bounded by the maximum number of jobs of tasks T 0 through T i1 released in I. <p> Hence, 0 b i (k) r i (k). (For the RM scheme, it is possible to prove a tighter bound (r i (k); r i (k + 1)] on the range of b i (k). See <ref> [4] </ref> for details.) We now present sufficient scheduling conditions for the RM, DM, EDF, and EDF/NPD schemes. <p> Let the k th job of some task T i be the first to miss its deadline. In <ref> [4] </ref>, it is shown that "if the k th job of T i misses its deadline, and if t is some point in [b i (k); r i (k + 1)), then the difference between the total demand placed on the processor by T i and higher-priority tasks in the interval <p> The predicted BCU when lock-based objects were used is given by "blocking predicted". Predicted BCU for this case was obtained using the PCP scheduling condition given in [17]. BCU figures predicted by the scheduling conditions presented 18 in this paper and the conditions in <ref> [4] </ref> are given by "lockfree predicted new" and "lockfree predicted old", respectively. Observe that the conditions presented in this paper are much tighter than those given in [4]. The results in Figure 9 indicate that lock-free objects are competitive with lock-based objects in most cases. <p> BCU figures predicted by the scheduling conditions presented 18 in this paper and the conditions in <ref> [4] </ref> are given by "lockfree predicted new" and "lockfree predicted old", respectively. Observe that the conditions presented in this paper are much tighter than those given in [4]. The results in Figure 9 indicate that lock-free objects are competitive with lock-based objects in most cases. In particular, lock-free objects outperform their lock-based counterparts when most of the operations are read-only operations (graphs (a) and (b)), or when most of the objects are queues (graphs (a) and (c)).
Reference: [5] <author> T. Baker, </author> <title> "Stack-Based Scheduling of Real-Time Processes", </title> <journal> Journal of Real-Time Systems, </journal> <volume> Vol. 3, No. 1, </volume> <month> March </month> <year> 1991, </year> <pages> pp. 67-99. </pages>
Reference-contexts: Mechanisms that work in this way include the priority inheritance protocol [17, 19], the priority ceiling protocol (PCP) <ref> [5, 17, 19] </ref>, the dynamic PCP (DPCP) [8], and the earliest-deadline-first scheme with dynamic deadline modification (EDF/DDM) [13]. Although such mechanisms provide a general framework for real-time object sharing, they suffer from several shortcomings. One obvious shortcoming is added operating system overhead.
Reference: [6] <author> G. Barnes, </author> <title> "A Method for Implementing Lock-Free Shared Data Structures", </title> <booktitle> Proceedings of the fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1993, </year> <pages> pp. 261-270. </pages>
Reference-contexts: For our purposes, such an implementation should be lock-free or wait-free. Unfortunately, previous lock-free and wait-free implementations of primitives like MWCAS have rather high worst-case time complexity <ref> [1, 6, 11, 20] </ref>. Thus, they are of limited utility in real-time systems. One of the main contributions of this paper is to show that a wait-free MWCAS primitive can be implemented efficiently if one assumes a priority-based task scheduler.
Reference: [7] <author> S. Baruah, R. Howell, and L. Rosier, </author> <title> "Feasibility Problems for Recurring Tasks on One Processor", </title> <booktitle> Theoretical Computer Science, 118 (1993), </booktitle> <pages> pp. 3-20. </pages>
Reference-contexts: In particular, we only need to consider values less than or equal to the least common multiple of the task periods. (If an upper bound on the utilization available for the tasks is known, then we can restrict t to a much smaller range <ref> [7] </ref>.) 4 Experimental Results In this section, we present results from simulation experiments that compare lock-free and lock-based object implementations under the RM scheme. These experiments involve randomly generated task sets that perform single- and multi-object operations on queues and skew heaps (a type of balanced tree).
Reference: [8] <author> M. I. Chen and K. J. Lin, </author> <title> "Dynamic Priority Ceiling: A Concurrency Control Protocol for Real Time Systems", </title> <journal> Real-Time Systems Journal , Vol. </journal> <volume> 2, No. 1, </volume> <year> 1990, </year> <pages> pp. 325-346. </pages>
Reference-contexts: Mechanisms that work in this way include the priority inheritance protocol [17, 19], the priority ceiling protocol (PCP) [5, 17, 19], the dynamic PCP (DPCP) <ref> [8] </ref>, and the earliest-deadline-first scheme with dynamic deadline modification (EDF/DDM) [13]. Although such mechanisms provide a general framework for real-time object sharing, they suffer from several shortcomings. One obvious shortcoming is added operating system overhead. <p> Other shortcomings stem from the fact that these mechanisms do not entirely eliminate priority inversions, but merely bound their duration. Priority inversions, even if bounded in duration, can adversely impact scheduling, and can result in added context switching overhead in some schemes <ref> [8, 17, 19] </ref>. In scheduling conditions, overhead associated with priority inversions is manifested as "blocking factors". The blocking factor of a task is the maximum amount of time that that task can be delayed by lower-priority tasks.
Reference: [9] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 5, </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: In order to modify the contents of the array, a task makes a copy of each block to be changed, and then attempts to replace the old version of that block by its modified copy. This copy-based implementation generalizes previous universal lock-free constructions that rely on state copying <ref> [2, 9] </ref>. In Figure 6, BANK is a B-word shared array. Each element of BANK contains a pointer to a block of size S and a version number (see below) for the pointer. The B blocks pointed to by BANK constitute the current version of the MEM array.
Reference: [10] <author> M. Herlihy and J. Wing, </author> <title> "Linearizability: A Correctness Condition for Concurrent Objects," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 12, No. 3, </volume> <month> July </month> <year> 1990, </year> <pages> pp. 463-492. </pages>
Reference-contexts: Another subtlety involves the conditions under which a MWCAS operation may fail. Strictly speaking, it should be possible linearize any MWCAS operation to some point during its execution at which it "appears" to take effect <ref> [10] </ref>. Successful MWCAS operations can be linearized to the state at which line 18 is executed.
Reference: [11] <author> A. Israeli and L. Rappoport, </author> <title> "Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives", </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing, ACM, </booktitle> <address> New York, </address> <month> August </month> <year> 1994, </year> <pages> pp. 151-160. </pages>
Reference-contexts: For our purposes, such an implementation should be lock-free or wait-free. Unfortunately, previous lock-free and wait-free implementations of primitives like MWCAS have rather high worst-case time complexity <ref> [1, 6, 11, 20] </ref>. Thus, they are of limited utility in real-time systems. One of the main contributions of this paper is to show that a wait-free MWCAS primitive can be implemented efficiently if one assumes a priority-based task scheduler.
Reference: [12] <author> K. Jeffay, D. Stone, and D. Poirier, "YARTOS: </author> <title> Kernel Support for Efficient, Predictable Real-Time Systems", </title> <journal> Real-Time Systems Newsletter , Vol. </journal> <volume> 7, No. 4, </volume> <month> Fall </month> <year> 1991, </year> <pages> pp. 8-13. </pages>
Reference-contexts: In this case, peek returns the value of the element at the root of the tree. We determined execution times for these operations by implementing queues and skew heaps on a 33 MHz 80386-based IBM PC running the YARTOS <ref> [12] </ref> real-time operating system. Lock-based objects were implemented using the priority-ceiling protocol (PCP). Lock-free queues were implemented using an algorithm similar to that in Figure 1, and lock-free skew heaps were implemented using a copy-based algorithm similar to that in Figure 6.
Reference: [13] <author> K. Jeffay, </author> <title> "Scheduling Sporadic Tasks with Shared Resources in Hard Real-Time Systems", </title> <booktitle> Proceedings of the 13 th IEEE Symposium on Real-Time Systems, </booktitle> <address> Phoenix, AZ, </address> <year> 1992, </year> <pages> pp. 89-99. </pages>
Reference-contexts: Mechanisms that work in this way include the priority inheritance protocol [17, 19], the priority ceiling protocol (PCP) [5, 17, 19], the dynamic PCP (DPCP) [8], and the earliest-deadline-first scheme with dynamic deadline modification (EDF/DDM) <ref> [13] </ref>. Although such mechanisms provide a general framework for real-time object sharing, they suffer from several shortcomings. One obvious shortcoming is added operating system overhead. Other shortcomings stem from the fact that these mechanisms do not entirely eliminate priority inversions, but merely bound their duration.
Reference: [14] <author> J.Y.T. Leung and J. Whitehead, </author> <title> "On the Complexity of Fixed-Priority Scheduling of Periodic, Real-Time Tasks", </title> <journal> Performance Evaluation, </journal> <volume> Vol. 2, No. 4, </volume> <year> 1982, </year> <pages> pp. 237-250. </pages>
Reference-contexts: This observation is the basis of scheduling conditions presented in [4] for the rate-monotonic (RM) [15], deadline-monotonic (DM) <ref> [14] </ref>, and earliest-deadline-first (EDF) [15] schemes. Each of these conditions is based on the same insight: a set of tasks that share lock-free objects is schedulable if there is enough free processor time to accommodate the failed loop iterations that can occur over any interval.
Reference: [15] <author> C. Liu and J. Layland, </author> <title> "Scheduling Algorithms for Multiprogramming in a Hard Real-Time Environment", </title> <journal> Journal of the ACM , Vol 30., </journal> <month> Jan. </month> <year> 1973, </year> <pages> pp. 46-61. </pages>
Reference-contexts: Anderson et al. observed that, on a uniprocessor, the cost of such failed loop iterations over an interval of time can be bounded by the number of job releases 3 within that interval [4]. This observation is the basis of scheduling conditions presented in [4] for the rate-monotonic (RM) <ref> [15] </ref>, deadline-monotonic (DM) [14], and earliest-deadline-first (EDF) [15] schemes. Each of these conditions is based on the same insight: a set of tasks that share lock-free objects is schedulable if there is enough free processor time to accommodate the failed loop iterations that can occur over any interval. <p> This observation is the basis of scheduling conditions presented in [4] for the rate-monotonic (RM) <ref> [15] </ref>, deadline-monotonic (DM) [14], and earliest-deadline-first (EDF) [15] schemes. Each of these conditions is based on the same insight: a set of tasks that share lock-free objects is schedulable if there is enough free processor time to accommodate the failed loop iterations that can occur over any interval.
Reference: [16] <author> A. Mok, </author> <title> Fundamental Design Problems of Distributed Systems for the Hard Real-Time Environment , Ph.D. </title> <type> Thesis, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1983. </year>
Reference-contexts: In addition, the old value of w is saved in the shared variable Save [r; k] (line 10). The pid and 4 The only common scheduling policy that we know of that violates these requirements is least-laxity-first (LLF) scheduling <ref> [16] </ref>.
Reference: [17] <author> R. Rajkumar, </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach, </title> <publisher> Kluwer Academic Publications, </publisher> <year> 1991. </year>
Reference-contexts: Mechanisms that work in this way include the priority inheritance protocol <ref> [17, 19] </ref>, the priority ceiling protocol (PCP) [5, 17, 19], the dynamic PCP (DPCP) [8], and the earliest-deadline-first scheme with dynamic deadline modification (EDF/DDM) [13]. Although such mechanisms provide a general framework for real-time object sharing, they suffer from several shortcomings. One obvious shortcoming is added operating system overhead. <p> Mechanisms that work in this way include the priority inheritance protocol [17, 19], the priority ceiling protocol (PCP) <ref> [5, 17, 19] </ref>, the dynamic PCP (DPCP) [8], and the earliest-deadline-first scheme with dynamic deadline modification (EDF/DDM) [13]. Although such mechanisms provide a general framework for real-time object sharing, they suffer from several shortcomings. One obvious shortcoming is added operating system overhead. <p> Other shortcomings stem from the fact that these mechanisms do not entirely eliminate priority inversions, but merely bound their duration. Priority inversions, even if bounded in duration, can adversely impact scheduling, and can result in added context switching overhead in some schemes <ref> [8, 17, 19] </ref>. In scheduling conditions, overhead associated with priority inversions is manifested as "blocking factors". The blocking factor of a task is the maximum amount of time that that task can be delayed by lower-priority tasks. <p> The predicted BCU when lock-based objects were used is given by "blocking predicted". Predicted BCU for this case was obtained using the PCP scheduling condition given in <ref> [17] </ref>. BCU figures predicted by the scheduling conditions presented 18 in this paper and the conditions in [4] are given by "lockfree predicted new" and "lockfree predicted old", respectively. Observe that the conditions presented in this paper are much tighter than those given in [4].
Reference: [18] <author> S. Ramamurthy, M. Moir, and J. Anderson, </author> <title> "Real-Time Object Sharing with Minimal System Support", </title> <booktitle> to be presented at the 15th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Our implementation of MWCAS was inspired by recent results of Ramamurthy, Moir, and Anderson, who were the first to realize that properties of priority-based schedulers can be exploited to simply wait-free (and lock-free) implementations <ref> [18] </ref>. The basis of this realization is the fact that certain task interleavings cannot occur when using such schedulers. <p> Then, in Section 2.2, we further illustrate the utility of MWCAS by showing how to use it to implement lock-free transactions. 2.1 A Wait-Free Implementation of MWCAS requires a CAS instruction. Requiring CAS is not a severe limitation, because Ramamurthy et al. <ref> [18] </ref> have shown that CAS can be implemented on most priority-based real-time systems from reads and writes with time complexity that is linear in the number of tasks. Most processors, in fact, either provide CAS directly or provide synchronization instructions that can be used to implement CAS in constant time. <p> For example, CAS is provided in hardware on the Motorola 680x0 line of processors and on the Intel Pentium. It can be implemented in constant time on the Intel 80x86 line of processors using a memory-to-memory move instruction (see <ref> [18] </ref> for details), and on the PowerPC using load-linked and store-conditional instructions. In our implementation, a task performs a MWCAS operation on a collection of words by invoking the MWCAS procedure. <p> In fact, if one assumes a conventional asynchronous task model, then the implementation does not work. The priority-based task assumed here is the same as that considered in the work of Ramamurthy et al. <ref> [18] </ref>. This model is characterized by two simple requirements: (i) a task's priority may change over time, but not during a MWCAS or READ operation; (ii) if a given task has an enabled statement at a state, then no lower-priority task has an enabled statement at that state.
Reference: [19] <author> L. Sha, R. Rajkumar, and J. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time System Synchronization", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 39, No. 9, </volume> <year> 1990, </year> <pages> pp. 1175-1185. </pages>
Reference-contexts: Mechanisms that work in this way include the priority inheritance protocol <ref> [17, 19] </ref>, the priority ceiling protocol (PCP) [5, 17, 19], the dynamic PCP (DPCP) [8], and the earliest-deadline-first scheme with dynamic deadline modification (EDF/DDM) [13]. Although such mechanisms provide a general framework for real-time object sharing, they suffer from several shortcomings. One obvious shortcoming is added operating system overhead. <p> Mechanisms that work in this way include the priority inheritance protocol [17, 19], the priority ceiling protocol (PCP) <ref> [5, 17, 19] </ref>, the dynamic PCP (DPCP) [8], and the earliest-deadline-first scheme with dynamic deadline modification (EDF/DDM) [13]. Although such mechanisms provide a general framework for real-time object sharing, they suffer from several shortcomings. One obvious shortcoming is added operating system overhead. <p> Other shortcomings stem from the fact that these mechanisms do not entirely eliminate priority inversions, but merely bound their duration. Priority inversions, even if bounded in duration, can adversely impact scheduling, and can result in added context switching overhead in some schemes <ref> [8, 17, 19] </ref>. In scheduling conditions, overhead associated with priority inversions is manifested as "blocking factors". The blocking factor of a task is the maximum amount of time that that task can be delayed by lower-priority tasks.
Reference: [20] <author> N. Shavit and D. Touitou, </author> <title> "Software Transactional Memory", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, ACM, </booktitle> <address> New York, </address> <month> August </month> <year> 1995, </year> <pages> pp. 204-213. 20 </pages>
Reference-contexts: For our purposes, such an implementation should be lock-free or wait-free. Unfortunately, previous lock-free and wait-free implementations of primitives like MWCAS have rather high worst-case time complexity <ref> [1, 6, 11, 20] </ref>. Thus, they are of limited utility in real-time systems. One of the main contributions of this paper is to show that a wait-free MWCAS primitive can be implemented efficiently if one assumes a priority-based task scheduler.
References-found: 20

