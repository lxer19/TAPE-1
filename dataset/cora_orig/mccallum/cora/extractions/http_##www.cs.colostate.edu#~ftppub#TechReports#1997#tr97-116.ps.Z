URL: http://www.cs.colostate.edu/~ftppub/TechReports/1997/tr97-116.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Email: malaiya@cs.colostate.edu  
Phone: Phone: (970) 491-5792 Fax: (970) 491-2466  
Title: Automatic Test Generation using Checkpoint Encoding and Antirandom Testing  
Author: Huifang Yin, Zemen Lebne-Dengely and Yashwant K. Malaiya 
Note: This research was supported by a BMDO funded project monitored by ONR  
Web: WWW: http://www.cs.colostate.edu  
Address: Fort Collins, CO 80523  Fort Collins, CO 80525  Fort Collins, CO 80523-1873  
Affiliation: Computer Science  Computer Science Dept. Colorado State University  Graphics Technology Lab Hewlett-Packard Co.  Computer Science Department Colorado State University  
Pubnum: Technical Report  Technical Report CS-97-116  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> V. Basili and D. Weiss, </author> <title> "A methodology for collecting valid software engineering data," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> Vol. SE-10, </volume> <pages> pp. 728-738, </pages> <month> Nov. </month> <year> 1984. </year>
Reference-contexts: In dividing the input space into subdomains, it is expected that software responds to all the points within the same subdomain in a similar way by validating program correctness or by uncovering a fault or exhibiting illegal behavior <ref> [1, 20, 23] </ref>. While this expectation is an idealization, it allows us to feel reasonably assured that only one or few test cases within a subdomain are enough to cover the expected behavior for the whole subdomain.
Reference: [2] <author> T. Y. Chen and Y. T. Yu, </author> <title> "On the expected number of failures detected by subdomain testing and random testing," </title> <journal> IEEE Trans. Software Engineering, </journal> <month> Feb. </month> <year> 1996, </year> <pages> pp. 109-119. </pages>
Reference-contexts: In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely [9, 10, 19, 23, 25]. Useful heuristics [6] of selecting test data are designed to exercise boundary values <ref> [2, 25] </ref> as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications). This has the advantage of reducing testing effort while preserving testing effectiveness.
Reference: [3] <author> D. M. Cohen, S. R. Dalal, J. Parelius and G. C. Patton, A., </author> <title> "The combinatorial design approach to automatic test generation," </title> <journal> IEEE Software, </journal> <month> Sept. </month> <year> 1996, </year> <pages> pp. 83-88. </pages>
Reference-contexts: 1 Introduction Testing of software requires a significant commitment of resources [12, 17]. It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness <ref> [3, 6, 13, 15] </ref>. There are many testing techniques discussed in the literature that can be termed black-box testing [6, 8, 9, 13, 20]. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. <p> This has the advantage of reducing testing effort while preserving testing effectiveness. Another approach to increasing test effectiveness and efficiency is to reduce the number of tests required by limiting the number of combinations of tests to be considered. Orthogonal latin squares [15] and combinatorial design <ref> [3] </ref> are among the approaches that have been discussed in the literature. Recently, Malaiya [13] introduced the concept of antirandom testing for black-box testing.
Reference: [4] <author> D. M. Cohen, S. R. Dalal, A. Kajla and G. C. Patton, A., </author> <title> "The automatic efficient test generator (AETG) system," </title> <booktitle> Proc. </booktitle> <address> ISSRE, </address> <month> Nov. </month> <year> 1994, </year> <pages> pp. 303-309. </pages>
Reference-contexts: Test coverage measures have been demonstrated to have a relationship to defect coverage [5, 14], thus the coverage measure can be used as an approximate measure of test effectiveness. 3.1 Testing data generation procedure Automatic test generation <ref> [4, 7, 24] </ref> is designed to ease the test effort. Here we have used three different approaches for automatic test generation. 1. Antirandom with checkpoint encoding 2. Random with checkpoint encoding. 3. Random without checkpoint encoding. In the plots and the tables, these are respectively termed Antirandom, Encoderandom, Pureran-dom.
Reference: [5] <author> S. R. Dalal, J. R. Horgan and J. R. Kettenring, </author> <title> "Reliable Software and Communication: Software Quality, Reliability and Safety," </title> <booktitle> Proc. International Conference on Software Engineering, </booktitle> <year> 1993, </year> <pages> pp. 425-435. </pages>
Reference-contexts: Coverage measures are used to quantitatively compare the testing approaches. The GCT coverage tool [16] is used to instrument the programs to get quantitative code coverage measures using branches, loops, multiple conditions and relational operations covered. Test coverage measures have been demonstrated to have a relationship to defect coverage <ref> [5, 14] </ref>, thus the coverage measure can be used as an approximate measure of test effectiveness. 3.1 Testing data generation procedure Automatic test generation [4, 7, 24] is designed to ease the test effort. Here we have used three different approaches for automatic test generation. 1.
Reference: [6] <author> R. A. Demillo, R. J. Lipton and F. G. Sayward, </author> <title> "Hints on test data selection: Help for the practicing programmer," </title> <booktitle> IEEE Computer, </booktitle> <month> Apr. </month> <year> 1978, </year> <pages> pp. 34-41. 16 </pages>
Reference-contexts: 1 Introduction Testing of software requires a significant commitment of resources [12, 17]. It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness <ref> [3, 6, 13, 15] </ref>. There are many testing techniques discussed in the literature that can be termed black-box testing [6, 8, 9, 13, 20]. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. <p> It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing <ref> [6, 8, 9, 13, 20] </ref>. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. It considers the program's input domain as a single whole and randomly selects test inputs from this domain. <p> Natfos have shown that random testing under certain situations can be effective and is worth considering [8], specially considering the relative ease of test generation and potential for automation. fl This research was supported by a BMDO funded project monitored by ONR 1 A number of test data selection strategies <ref> [6, 11, 26] </ref> have been discussed in the literature. In partition testing approach, the program's input domain is divided into subsets, and one or more tests from each of these subsets are selected to exercise the program. <p> Economizing on test data selection this way can make the cumulative number of input test cases manageable and can make testing much more cost effective. In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely [9, 10, 19, 23, 25]. Useful heuristics <ref> [6] </ref> of selecting test data are designed to exercise boundary values [2, 25] as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications). This has the advantage of reducing testing effort while preserving testing effectiveness. <p> They are a string matching program STRMAT [29], a triangle classification program TRIANGLE <ref> [6, 8, 12, 17] </ref> and FIND which can be part of a sorting program [6, 13, 29]. Coverage measures are used to quantitatively compare the testing approaches. <p> They are a string matching program STRMAT [29], a triangle classification program TRIANGLE [6, 8, 12, 17] and FIND which can be part of a sorting program <ref> [6, 13, 29] </ref>. Coverage measures are used to quantitatively compare the testing approaches. The GCT coverage tool [16] is used to instrument the programs to get quantitative code coverage measures using branches, loops, multiple conditions and relational operations covered. <p> Antirandom r r r r r r r r r r r r r r r r r r r Encoderandom b b b b b b b b b b b b b Purerandom1 Purerandom2 3.3.2 The TRIANGLE program This triangle example is used by Jorgenson [12]. Demillo <ref> [6] </ref> has also discussed test data selection for this program. Given three integers as input values for the three sides, TRIANGLE classifies whether we have a legal triangle or not.
Reference: [7] <author> R. A. Demillo and A. J. Offutt, </author> <title> "Constrained based automatic test data generation," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> Vol. SE-17, No. 9, </volume> <pages> pp. 900-910, </pages> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Test coverage measures have been demonstrated to have a relationship to defect coverage [5, 14], thus the coverage measure can be used as an approximate measure of test effectiveness. 3.1 Testing data generation procedure Automatic test generation <ref> [4, 7, 24] </ref> is designed to ease the test effort. Here we have used three different approaches for automatic test generation. 1. Antirandom with checkpoint encoding 2. Random with checkpoint encoding. 3. Random without checkpoint encoding. In the plots and the tables, these are respectively termed Antirandom, Encoderandom, Pureran-dom.
Reference: [8] <author> J. W. Duran and S. C. Natfos, </author> <title> "An evaluation of random testing," </title> <journal> IEEE Trans. Software Engineering, </journal> <month> July </month> <year> 1984, </year> <pages> pp. 438-444. </pages>
Reference-contexts: It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing <ref> [6, 8, 9, 13, 20] </ref>. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. It considers the program's input domain as a single whole and randomly selects test inputs from this domain. <p> It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing [6, 8, 9, 13, 20]. Random testing <ref> [8] </ref> chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. It considers the program's input domain as a single whole and randomly selects test inputs from this domain. There are different opinions regarding the effectiveness of random testing. <p> Meyers [17] claims that random testing is an ineffective strategy to uncover errors in the software. Other studies such as that of Duran and Natfos have shown that random testing under certain situations can be effective and is worth considering <ref> [8] </ref>, specially considering the relative ease of test generation and potential for automation. fl This research was supported by a BMDO funded project monitored by ONR 1 A number of test data selection strategies [6, 11, 26] have been discussed in the literature. <p> In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely [9, 10, 19, 23, 25]. Useful heuristics [6] of selecting test data are designed to exercise boundary values [2, 25] as well as uncover simple errors that tend to have a coupling effect <ref> [8] </ref> to larger errors (errors that violate the software specifications). This has the advantage of reducing testing effort while preserving testing effectiveness. Another approach to increasing test effectiveness and efficiency is to reduce the number of tests required by limiting the number of combinations of tests to be considered. <p> They are a string matching program STRMAT [29], a triangle classification program TRIANGLE <ref> [6, 8, 12, 17] </ref> and FIND which can be part of a sorting program [6, 13, 29]. Coverage measures are used to quantitatively compare the testing approaches.
Reference: [9] <author> R. G. Hamlet and R. Taylor, </author> <title> "Partition testing does not inspire confidence," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> Vol. SE-16, No. 12, </volume> <pages> pp. 1402-1411, </pages> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing <ref> [6, 8, 9, 13, 20] </ref>. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. It considers the program's input domain as a single whole and randomly selects test inputs from this domain. <p> Economizing on test data selection this way can make the cumulative number of input test cases manageable and can make testing much more cost effective. In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely <ref> [9, 10, 19, 23, 25] </ref>. Useful heuristics [6] of selecting test data are designed to exercise boundary values [2, 25] as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications).
Reference: [10] <author> D. Hamlet, </author> <title> "Are we testing for true reliability," </title> <journal> IEEE Software, </journal> <month> July </month> <year> 1992, </year> <pages> pp. 21-27. </pages>
Reference-contexts: Economizing on test data selection this way can make the cumulative number of input test cases manageable and can make testing much more cost effective. In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely <ref> [9, 10, 19, 23, 25] </ref>. Useful heuristics [6] of selecting test data are designed to exercise boundary values [2, 25] as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications).
Reference: [11] <author> W. E. Howden, </author> <title> "The theory and practice of functional testing," </title> <journal> IEEE Software, </journal> <month> Sept. </month> <year> 1995, </year> <pages> pp. 6-17. </pages>
Reference-contexts: Natfos have shown that random testing under certain situations can be effective and is worth considering [8], specially considering the relative ease of test generation and potential for automation. fl This research was supported by a BMDO funded project monitored by ONR 1 A number of test data selection strategies <ref> [6, 11, 26] </ref> have been discussed in the literature. In partition testing approach, the program's input domain is divided into subsets, and one or more tests from each of these subsets are selected to exercise the program.
Reference: [12] <author> Paul C. Jorgensen, </author> <title> Software Testing: A Craftsman's Approach, </title> <publisher> CRC Press, </publisher> <address> New York 1995. </address>
Reference-contexts: 1 Introduction Testing of software requires a significant commitment of resources <ref> [12, 17] </ref>. It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing [6, 8, 9, 13, 20]. <p> They are a string matching program STRMAT [29], a triangle classification program TRIANGLE <ref> [6, 8, 12, 17] </ref> and FIND which can be part of a sorting program [6, 13, 29]. Coverage measures are used to quantitatively compare the testing approaches. <p> Antirandom r r r r r r r r r r r r r r r r r r r Encoderandom b b b b b b b b b b b b b Purerandom1 Purerandom2 3.3.2 The TRIANGLE program This triangle example is used by Jorgenson <ref> [12] </ref>. Demillo [6] has also discussed test data selection for this program. Given three integers as input values for the three sides, TRIANGLE classifies whether we have a legal triangle or not. <p> Studies <ref> [12, 17] </ref> have shown that one of the causes for software bugs that are not being identified early enough is that testers were not exercising the specification fully.
Reference: [13] <author> Y. K. Malaiya, </author> <title> "Antirandom Testing: Getting the most out of black-box testing," </title> <booktitle> Proc. International Symposium On Software Reliability Engineering, </booktitle> <month> Oct. </month> <year> 1995, </year> <pages> pp. 86-95. </pages>
Reference-contexts: 1 Introduction Testing of software requires a significant commitment of resources [12, 17]. It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness <ref> [3, 6, 13, 15] </ref>. There are many testing techniques discussed in the literature that can be termed black-box testing [6, 8, 9, 13, 20]. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. <p> It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing <ref> [6, 8, 9, 13, 20] </ref>. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. It considers the program's input domain as a single whole and randomly selects test inputs from this domain. <p> Another approach to increasing test effectiveness and efficiency is to reduce the number of tests required by limiting the number of combinations of tests to be considered. Orthogonal latin squares [15] and combinatorial design [3] are among the approaches that have been discussed in the literature. Recently, Malaiya <ref> [13] </ref> introduced the concept of antirandom testing for black-box testing. It is based on the view that testing is both effective and efficient if the next test in the sequence is chosen to have maximum distance from all previous tests that have been applied. <p> Finally concluding remarks are 2 presented and future areas of investigation are briefly discussed. 2 The CEAR test generation scheme The Checkpoint Encoded Antirandom testing (CEAR) scheme used here was proposed by Malaiya <ref> [13] </ref>. This scheme integrates antirandom testing with checkpoint encoding as explained below, and is designed to process input test vectors on the fly automatically and to exercise the software under test, thus making the scheme cost effective. <p> The next binary test vector in the sequence, t 1 is then obtained by calculating the maximum hamming or maximum Cartesian distance away from t 0 . Construction of maximal hamming distance antirandom test sequence (MHDATS) and maximal Cartesian distance antirandom test sequence (MCDATS) is discussed in detail in <ref> [13] </ref>. Each subsequent test vector t i is then chosen such that the total distance between t i and all the previous tests t i1 ; t i2 ; :::; t 0 is a maximum. <p> They are a string matching program STRMAT [29], a triangle classification program TRIANGLE [6, 8, 12, 17] and FIND which can be part of a sorting program <ref> [6, 13, 29] </ref>. Coverage measures are used to quantitatively compare the testing approaches. The GCT coverage tool [16] is used to instrument the programs to get quantitative code coverage measures using branches, loops, multiple conditions and relational operations covered. <p> The program sorts the array elements such that all elements to the left of B (F) are no larger than B (F), and all elements to the right of B (F) are no smaller than B (F). The legal range for F is 1 F S. In <ref> [13] </ref>, Malaiya examined this program to illustrate how checkpoint encoding can be used. The encoding scheme for this program shown in Table 8 is similar to what was described in [13]. <p> The legal range for F is 1 F S. In <ref> [13] </ref>, Malaiya examined this program to illustrate how checkpoint encoding can be used. The encoding scheme for this program shown in Table 8 is similar to what was described in [13].
Reference: [14] <author> Y. K. Malaiya, N. Li, R. Karcich and B. Skbbe, </author> <title> "The relationship between test coverage and reliability," </title> <booktitle> Proc. International Symposium On Software Reliability Engineering, </booktitle> <month> Nov. </month> <year> 1994, </year> <pages> pp. 186-195. </pages>
Reference-contexts: Various approaches can be taken to gauge the effectiveness of testing [21, 22]. Here effectiveness of the various testing approaches was evaluated by measuring code coverage. This is an acceptable approach, since higher test coverage generally implies better defect detection capability <ref> [14, 27] </ref>. Test generation in this case is based on the external specification of the problem (black-box). Test coverage, unlike testing effort, is a direct measure of how well the software under test has been exercised [14]. <p> Test generation in this case is based on the external specification of the problem (black-box). Test coverage, unlike testing effort, is a direct measure of how well the software under test has been exercised <ref> [14] </ref>. The purpose of this paper is to demonstrate the feasibility of automatic test generation using approaches that are not random, and to show the promise of such approaches. <p> Coverage measures are used to quantitatively compare the testing approaches. The GCT coverage tool [16] is used to instrument the programs to get quantitative code coverage measures using branches, loops, multiple conditions and relational operations covered. Test coverage measures have been demonstrated to have a relationship to defect coverage <ref> [5, 14] </ref>, thus the coverage measure can be used as an approximate measure of test effectiveness. 3.1 Testing data generation procedure Automatic test generation [4, 7, 24] is designed to ease the test effort. Here we have used three different approaches for automatic test generation. 1.
Reference: [15] <author> R. Mandl, </author> <title> "Orthogonal Latin Squares: An application of experiment design to compiler testing," </title> <journal> Comm. ACM, </journal> <month> Oct. </month> <year> 1985, </year> <pages> pp. 1054-1058. </pages>
Reference-contexts: 1 Introduction Testing of software requires a significant commitment of resources [12, 17]. It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness <ref> [3, 6, 13, 15] </ref>. There are many testing techniques discussed in the literature that can be termed black-box testing [6, 8, 9, 13, 20]. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. <p> This has the advantage of reducing testing effort while preserving testing effectiveness. Another approach to increasing test effectiveness and efficiency is to reduce the number of tests required by limiting the number of combinations of tests to be considered. Orthogonal latin squares <ref> [15] </ref> and combinatorial design [3] are among the approaches that have been discussed in the literature. Recently, Malaiya [13] introduced the concept of antirandom testing for black-box testing.
Reference: [16] <author> Brian Marick, </author> <title> The Generic Coverage Test (GCT) User's Manual, </title> <year> 1981. </year>
Reference-contexts: They are a string matching program STRMAT [29], a triangle classification program TRIANGLE [6, 8, 12, 17] and FIND which can be part of a sorting program [6, 13, 29]. Coverage measures are used to quantitatively compare the testing approaches. The GCT coverage tool <ref> [16] </ref> is used to instrument the programs to get quantitative code coverage measures using branches, loops, multiple conditions and relational operations covered. <p> purerandom testing, for each program, we choose two different seeds to generate the actual input values randomly according to the range specified to illustrate the possible variation of the results. 3.2 Testing effectiveness evaluation Once a test suite is prepared based on the testing approaches discussed earlier, the GCT tool <ref> [16] </ref> is used to instrument the program. <p> Antirandom r r r r r r Encoderandom b b b Purerandom1 Purerandom2 18 f 19 scanf ("%d", &a [i]); 20 gets (mystr); 21 g 27 printf ("%5dnn", a [i]); GCT <ref> [16] </ref> does have a mechanism to edit the report and remove infeasible path conditions, once the tester determines which ones they are.
Reference: [17] <author> G. Meyers, </author> <title> The Art of Software Testing, </title> <publisher> John Wiley & Sons Inc., </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: 1 Introduction Testing of software requires a significant commitment of resources <ref> [12, 17] </ref>. It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing [6, 8, 9, 13, 20]. <p> It considers the program's input domain as a single whole and randomly selects test inputs from this domain. There are different opinions regarding the effectiveness of random testing. Meyers <ref> [17] </ref> claims that random testing is an ineffective strategy to uncover errors in the software. <p> They are a string matching program STRMAT [29], a triangle classification program TRIANGLE <ref> [6, 8, 12, 17] </ref> and FIND which can be part of a sorting program [6, 13, 29]. Coverage measures are used to quantitatively compare the testing approaches. <p> Studies <ref> [12, 17] </ref> have shown that one of the causes for software bugs that are not being identified early enough is that testers were not exercising the specification fully.
Reference: [18] <author> T. J. Ostrand and E. J. Weyuker, </author> <title> "Collecting and categorizing software error data in an industrial environment," </title> <journal> Journal of Systems, </journal> <volume> Vol. 14, </volume> <year> 1984, </year> <pages> pp. 289-300. </pages>
Reference: [19] <author> K. C. Tai, </author> <title> "Condition based software testing strategies," </title> <booktitle> Proc. COMPSAC 1990, </booktitle> <month> Oct. </month> <year> 1990, </year> <pages> pp. 564-569. </pages>
Reference-contexts: Economizing on test data selection this way can make the cumulative number of input test cases manageable and can make testing much more cost effective. In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely <ref> [9, 10, 19, 23, 25] </ref>. Useful heuristics [6] of selecting test data are designed to exercise boundary values [2, 25] as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications).
Reference: [20] <author> Markos Z. Tsoukalas and Joe W. Duran, </author> <title> "On some reliability estimation problems in Random and Partition testing,"IEEE Transactions on Software Engineering, </title> <booktitle> Vol 19, </booktitle> <volume> No 7, </volume> <pages> pp. 687-697, </pages> <month> Jul. </month> <year> 1993. </year>
Reference-contexts: It is of considerable practical and theoretical importance to explore ways to reduce the testing effort while maximizing test effectiveness [3, 6, 13, 15]. There are many testing techniques discussed in the literature that can be termed black-box testing <ref> [6, 8, 9, 13, 20] </ref>. Random testing [8] chooses tests randomly based on some input distribution, without attempting to exploit information gained by tests applied earlier. It considers the program's input domain as a single whole and randomly selects test inputs from this domain. <p> In dividing the input space into subdomains, it is expected that software responds to all the points within the same subdomain in a similar way by validating program correctness or by uncovering a fault or exhibiting illegal behavior <ref> [1, 20, 23] </ref>. While this expectation is an idealization, it allows us to feel reasonably assured that only one or few test cases within a subdomain are enough to cover the expected behavior for the whole subdomain.
Reference: [21] <author> M. D. Weiser, J. D. Gannon and P. R. McMullin, </author> <title> "A comparison of structural test coverage metrics," </title> <journal> IEEE Software, </journal> <volume> Vol. 19, no.6, </volume> <year> 1989, </year> <pages> pp. 80-85. </pages>
Reference-contexts: For this study we take three common benchmark programs which have been used in the literature. We present possible approaches for checkpoint encoding to ensure that we are probing the input space in an efficient way. Various approaches can be taken to gauge the effectiveness of testing <ref> [21, 22] </ref>. Here effectiveness of the various testing approaches was evaluated by measuring code coverage. This is an acceptable approach, since higher test coverage generally implies better defect detection capability [14, 27]. Test generation in this case is based on the external specification of the problem (black-box).
Reference: [22] <author> N. Weiss, </author> <title> "Comparing test data adequacy criteria," </title> <journal> Software Engineering Notes vol. </journal> <volume> 14, no. 6, </volume> <pages> pp. 42-49. </pages>
Reference-contexts: For this study we take three common benchmark programs which have been used in the literature. We present possible approaches for checkpoint encoding to ensure that we are probing the input space in an efficient way. Various approaches can be taken to gauge the effectiveness of testing <ref> [21, 22] </ref>. Here effectiveness of the various testing approaches was evaluated by measuring code coverage. This is an acceptable approach, since higher test coverage generally implies better defect detection capability [14, 27]. Test generation in this case is based on the external specification of the problem (black-box).
Reference: [23] <author> E. J. Weyuker, S. N. Weiss and R. G. Hamlet, </author> <title> "A comparison of program testing strategies," </title> <booktitle> Proceedings of the fourth Symposium on Software testing, Analysis and Verification, </booktitle> <address> Victoria, Canada, </address> <month> Oct. </month> <year> 1991, </year> <pages> pp. 154-164. </pages>
Reference-contexts: In dividing the input space into subdomains, it is expected that software responds to all the points within the same subdomain in a similar way by validating program correctness or by uncovering a fault or exhibiting illegal behavior <ref> [1, 20, 23] </ref>. While this expectation is an idealization, it allows us to feel reasonably assured that only one or few test cases within a subdomain are enough to cover the expected behavior for the whole subdomain. <p> Economizing on test data selection this way can make the cumulative number of input test cases manageable and can make testing much more cost effective. In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely <ref> [9, 10, 19, 23, 25] </ref>. Useful heuristics [6] of selecting test data are designed to exercise boundary values [2, 25] as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications).
Reference: [24] <author> E. J. Weyuker, T. Goradia and A. Singh, </author> <title> "Automatically generating test data from a boolean specification," </title> <journal> IEEE Trans. Software Engineering, </journal> <month> May </month> <year> 1994, </year> <pages> pp. 353-363. </pages>
Reference-contexts: Test coverage measures have been demonstrated to have a relationship to defect coverage [5, 14], thus the coverage measure can be used as an approximate measure of test effectiveness. 3.1 Testing data generation procedure Automatic test generation <ref> [4, 7, 24] </ref> is designed to ease the test effort. Here we have used three different approaches for automatic test generation. 1. Antirandom with checkpoint encoding 2. Random with checkpoint encoding. 3. Random without checkpoint encoding. In the plots and the tables, these are respectively termed Antirandom, Encoderandom, Pureran-dom.
Reference: [25] <author> E. J. Weyuker and B. Jeng, </author> <title> "Analyzing partition testing strategies," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-17, No 7, </volume> <pages> pp. 703-711, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Economizing on test data selection this way can make the cumulative number of input test cases manageable and can make testing much more cost effective. In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely <ref> [9, 10, 19, 23, 25] </ref>. Useful heuristics [6] of selecting test data are designed to exercise boundary values [2, 25] as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications). <p> In real programs, however, this idealized scenario of clean and nonoverlapping partitioning into subdomains happens rarely [9, 10, 19, 23, 25]. Useful heuristics [6] of selecting test data are designed to exercise boundary values <ref> [2, 25] </ref> as well as uncover simple errors that tend to have a coupling effect [8] to larger errors (errors that violate the software specifications). This has the advantage of reducing testing effort while preserving testing effectiveness.
Reference: [26] <author> L. White and E. Cohen, </author> <title> "A domain strategy for computer program testing," </title> <journal> IEEE Trans. Software Engineering, </journal> <month> May </month> <year> 1980, </year> <pages> pp. 247-257. 17 </pages>
Reference-contexts: Natfos have shown that random testing under certain situations can be effective and is worth considering [8], specially considering the relative ease of test generation and potential for automation. fl This research was supported by a BMDO funded project monitored by ONR 1 A number of test data selection strategies <ref> [6, 11, 26] </ref> have been discussed in the literature. In partition testing approach, the program's input domain is divided into subsets, and one or more tests from each of these subsets are selected to exercise the program.
Reference: [27] <author> W. E. Wong, J. R. Horgan, S. London and A. P. Mathur, </author> <title> "Effect of test set minimization on fault detection effectiveness," </title> <booktitle> IEEE International Conference on Software Engineering, </booktitle> <year> 1995, </year> <pages> pp. 41-50. </pages>
Reference-contexts: Various approaches can be taken to gauge the effectiveness of testing [21, 22]. Here effectiveness of the various testing approaches was evaluated by measuring code coverage. This is an acceptable approach, since higher test coverage generally implies better defect detection capability <ref> [14, 27] </ref>. Test generation in this case is based on the external specification of the problem (black-box). Test coverage, unlike testing effort, is a direct measure of how well the software under test has been exercised [14]. <p> A likely mistake could be using "&lt;" when "&lt;=" is intended. 3.3 Experimental results 3.3.1 The STRMAT program This example has also been used by Wong et al. <ref> [27, 28] </ref> to investigate test coverage issues. The program is given as input a string of zero to 80 characters, and a pattern at most 3 characters long. The objective is to see if the pattern is matched in the string.
Reference: [28] <author> W. E. Wong, J. R. Horgan, S. London and A. P. Mathur, </author> <title> "Effect of test size and block coverage on fault detection effectiveness," </title> <booktitle> Fifth International Symposium on Software Reliability Engineering, </booktitle> <year> 1994, </year> <pages> pp. 230-238. </pages>
Reference-contexts: A likely mistake could be using "&lt;" when "&lt;=" is intended. 3.3 Experimental results 3.3.1 The STRMAT program This example has also been used by Wong et al. <ref> [27, 28] </ref> to investigate test coverage issues. The program is given as input a string of zero to 80 characters, and a pattern at most 3 characters long. The objective is to see if the pattern is matched in the string.
Reference: [29] <author> W. E. Wong, </author> <title> On mutation and dataflow, </title> <type> PhD thesis, </type> <institution> Purdue University, Computer Science Department, </institution> <year> 1993. </year>
Reference-contexts: They are a string matching program STRMAT <ref> [29] </ref>, a triangle classification program TRIANGLE [6, 8, 12, 17] and FIND which can be part of a sorting program [6, 13, 29]. Coverage measures are used to quantitatively compare the testing approaches. <p> They are a string matching program STRMAT [29], a triangle classification program TRIANGLE [6, 8, 12, 17] and FIND which can be part of a sorting program <ref> [6, 13, 29] </ref>. Coverage measures are used to quantitatively compare the testing approaches. The GCT coverage tool [16] is used to instrument the programs to get quantitative code coverage measures using branches, loops, multiple conditions and relational operations covered. <p> Examination of lines 17 and 26 as shown in the program listing (see Appendix <ref> [29] </ref>) shows that it is impossible to traverse the for loop 0 times, since the problem specification say that the array size, n, is greater than 1: 17 for (i=1;i&lt;=n;i++) 20 40 60 80 100 total coverage (%) test vector no.

References-found: 29

