URL: http://www.cs.ubc.ca/spider/cebly/Papers/aij95update.ps
Refering-URL: http://www.cs.ubc.ca/spider/cebly/papers.html
Root-URL: 
Email: email: cebly@cs.ubc.ca  
Title: Abduction to Plausible Causes: An Event-based Model of Belief Update  
Author: Craig Boutilier 
Address: CANADA, V6T 1Z4  
Affiliation: Department of Computer Science University of British Columbia Vancouver, British Columbia  
Date: 1995  January 11, 1995  
Note: To appear, Artificial Intelligence,  
Abstract: The Katsuno and Mendelzon (KM) theory of belief update has been proposed as a reasonable model for revising beliefs about a changing world. However, the semantics of update relies on information which is not readily available. We describe an alternative semantical view of update in which observations are incorporated into a belief set by: a) explaining the observation in terms of a set of plausible events that might have caused that observation; and b) predicting further consequences of those explanations. We also allow the possibility of conditional explanations. We show that this picture naturally induces an update operator conforming to the KM postulates under certain assumptions. However, we argue that these assumptions are not always reasonable, and they restrict our ability to integrate update with other forms of revision when reasoning about action. fl Some parts of this report appeared in preliminary form as An Event-Based Abductive Model of Update, Proc. of Tenth Canadian Conf. on in AI, Banff, Alta., (1994). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Carlos Alchourr on, Peter G ardenfors, and David Makinson. </author> <title> On the logic of theory change: Partial meet contraction and revision functions. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-530, </pages> <year> 1985. </year>
Reference-contexts: One of the most influential theories of belief change has been the AGM theory proposed by Alchourr on, G ardenfors and Makinson <ref> [1] </ref>. Imagine an agent possesses a belief set or knowledge base KB. The AGM theory provides a set of postulates constraining the possible ways in which the agent can change KB in order to accommodate a new belief A.
Reference: [2] <author> Craig Boutilier. </author> <title> Actions, observations and belief dynamics. </title> <type> (manuscript), </type> <year> 1994. </year>
Reference-contexts: Indeed, we will show that such an ordering over worlds is derivable from this more readily available information. This provides a possible interpretation of the update process, and in our view, a very natural one. 5 Furthermore, as we describe in the concluding section (and in detail in <ref> [2] </ref>), by breaking update into two components, we will be able to extend the type of reasoning about action one can perform in this setting. Using explanation for reasoning about action has been proposed by a number of people, especially within the framework of the situation calculus. <p> As a further generalization, if events are nondeterministic, we might suppose that the possible outcomes are ranked by probability or plausibility. We set aside this complication (but see <ref> [2] </ref>). In order to explain certain observations by appeal to plausible event occurrences, we need some metric for ranking explanations. We assume that the events in the set E are ranked by plausibility; 6 It is best to think of events as analogous to action attempts. <p> This perspective is especially fruitful when combining the process of update (changing knowledge) with belief revision (gaining knowledge). A model that puts both components together in a broader abductive framework is described in <ref> [2] </ref>. <p> We have side-stepped such issues by focusing on the semantics of update. We are currently investigating various action representations, such as STRIPS and the situation calculus, and the means they provide for generating conditional explanations. This is partially developed in <ref> [2] </ref>, where we provide a representation for actions using a conditional default logic to capture the defeasibility and nondeterminism of action effects, and use elements of dynamic logic to 22 To appear, Artificial Intelligence, 1995 capture the evolution of the world.
Reference: [3] <author> Craig Boutilier. </author> <title> Conditional logics of normality: A modal approach. </title> <journal> Artificial Intelligence, </journal> <volume> 68 </volume> <pages> 87-154, </pages> <year> 1994. </year>
Reference-contexts: We can 18 To appear, Artificial Intelligence, 1995 extend the Katsuno-Mendelzon representation theorem to deal with update operators of this type. The required postulate embodies a variant of the principle of rational monotonicity, cited widely in connection with nonmonotonic systems of inference and conditional logics (see, e.g., <ref> [3, 19] </ref>). (U9) If KB is complete, (KB A) 6j= :B and (KB A) j= C then (KB (A ^ B)) j= C Theorem 11 An update operator satisfies postulates (U1) through (U9) iff there exists an appropriate family of faithful total preorders f w : w 2 W g that
Reference: [4] <author> Craig Boutilier. </author> <title> Unifying default reasoning and belief revision in a modal framework. </title> <journal> Artificial Intelligence, </journal> <volume> 68 </volume> <pages> 33-85, </pages> <year> 1994. </year>
Reference-contexts: This perspective is especially fruitful when combining the process of update (changing knowledge) with belief revision (gaining knowledge). A model that puts both components together in a broader abductive framework is described in [2]. Roughly, the logic for belief revision set forth in <ref> [4] </ref> is used to capture the revision process, but is combined with elements of dynamic logic [14] to capture the evolution of the world due to action occurrences. 4.2 Related Work Other have presented models of update that, like ours and unlike the KM-model, have their basis in reasoning about action.
Reference: [5] <author> Craig Boutilier and Veronica Becher. </author> <title> Abduction as belief revision. </title> <journal> Artificial Intelligence, </journal> <note> 1994. (in press). </note>
Reference-contexts: We formalize this notion in an abstract manner obtaining a class of explanation-change operators that are similar in spirit and intent to KM update operators, but somewhat more general. We note that explanation has often been closely linked with belief revision [12]. Indeed, Boutilier and Becher <ref> [5] </ref> present a model of abduction where explanations are determined by explicit belief revision. Given this connection and the fact that update can be viewed as an essentially abductive process, we may also take update to be a certain kind of belief revision. <p> However, these restrictions are inappropriate in many cases, calling into question the suitability of some of the update postulates. 4.1 Relationship to Belief Revision It has frequently been suggested that abduction can be modeled by appeal to belief revision [12]. Boutilier and Becher <ref> [5] </ref> present a model of abduction along these lines, whereby an explanation for 19 To appear, Artificial Intelligence, 1995 an observation O, with respect to some KB, is a sentence E such that KB fl E entails O.
Reference: [6] <author> Craig Boutilier and Richard Dearden. </author> <title> Using abstractions for decision-theoretic planning with time constraints. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1016-1022, </pages> <address> Seattle, </address> <year> 1994. </year>
Reference-contexts: For each such condition, a set of effects is specified. An example of this is the classical situation calculus representation of actions (in the deterministic case). Another is the modified STRIPS representation presented in <ref> [18, 6] </ref>. The key feature of these, and other representations, is that each action/event induces a function between worlds (or worlds and sets of worlds). 7 Thus, most action representations will fit within this abstract model. <p> Finally, we can formalize our initial example. We first adopt a conditional STRIPS-like representation of events, using variables to schematically capture a set of propositions, and take each event specification to induce the obvious transformation on possible worlds (see, e.g., <ref> [18, 6] </ref>).
Reference: [7] <author> Thomas Dean, Leslie Pack Kaelbling, Jak Kirman, and Ann Nicholson. </author> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 574-579, </pages> <address> Washington, D.C., </address> <year> 1993. </year>
Reference-contexts: This assumption underlies all work in classical planning and reasoning about action, ranging from STRIPS [10] to the situation calculus [20, 24] to more sophisticated probabilistic representations <ref> [18, 7] </ref>. With such information, the predictions associated with explanations (event occurrences) can be easily determined. Furthermore, an ordering over the relative likelihood of possible events also seems something which an agent or system designer or user might easily postulate.
Reference: [8] <author> Alvaro del Val and Yoav Shoham. </author> <title> Deriving properties of belief update from theories of action. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 584-589, </pages> <address> San Jose, </address> <year> 1992. </year>
Reference-contexts: We also argue that proper modification of belief states in response to observations in dynamic settings involves a combination of belief revision and belief update. Finally, we compare our construction to the model of update proposed by del Val and Shoham <ref> [8] </ref>. Proofs of the main results can be found in the appendix. 2 The Semantics of Update Katsuno and Mendelzon [16] have proposed a general characterization of belief update. <p> this paper we will usually think of (external) events as the impetus for change, rather than actions over which the agent has direct control (or of which the agent has direct knowledge). 4 This assumption is embodied to a certain extent in the update models of del Val and Shoham <ref> [8, 9] </ref> and Goldszmidt and Pearl [13], as we discuss in Section 4. 7 To appear, Artificial Intelligence, 1995 Before formalizing this idea, it is important to realize that this perspective is very natural. <p> the revision process, but is combined with elements of dynamic logic [14] to capture the evolution of the world due to action occurrences. 4.2 Related Work Other have presented models of update that, like ours and unlike the KM-model, have their basis in reasoning about action. del Val and Shoham <ref> [8, 9] </ref>, using the situation calculus, show how one 21 To appear, Artificial Intelligence, 1995 can determine an update operator by reasoning about the changes induced by a given action. <p> Action theories such as those exploited in <ref> [8, 13] </ref> might also be used to greater advantage.
Reference: [9] <author> Alvaro del Val and Yoav Shoham. </author> <title> Deriving properties of belief update from theories of action (II). </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 732-737, </pages> <address> Chambery, FR, </address> <year> 1993. </year>
Reference-contexts: this paper we will usually think of (external) events as the impetus for change, rather than actions over which the agent has direct control (or of which the agent has direct knowledge). 4 This assumption is embodied to a certain extent in the update models of del Val and Shoham <ref> [8, 9] </ref> and Goldszmidt and Pearl [13], as we discuss in Section 4. 7 To appear, Artificial Intelligence, 1995 Before formalizing this idea, it is important to realize that this perspective is very natural. <p> the revision process, but is combined with elements of dynamic logic [14] to capture the evolution of the world due to action occurrences. 4.2 Related Work Other have presented models of update that, like ours and unlike the KM-model, have their basis in reasoning about action. del Val and Shoham <ref> [8, 9] </ref>, using the situation calculus, show how one 21 To appear, Artificial Intelligence, 1995 can determine an update operator by reasoning about the changes induced by a given action.
Reference: [10] <author> Richard E. Fikes and Nils J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year> <note> 23 To appear, Artificial Intelligence, </note> <year> 1995 </year>
Reference-contexts: It is reasonable to suppose that an agent (or builder of a KB) has ready access to some description of the preconditions and effects of the possible events in a given domain. This assumption underlies all work in classical planning and reasoning about action, ranging from STRIPS <ref> [10] </ref> to the situation calculus [20, 24] to more sophisticated probabilistic representations [18, 7]. With such information, the predictions associated with explanations (event occurrences) can be easily determined.
Reference: [11] <author> Nir Friedman and Joseph Y. Halpern. </author> <title> A knowledge-based framework for belief change, part II: Revision and update. </title> <booktitle> In Proceedings of the Fourth International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 190-201, </pages> <address> Bonn, </address> <year> 1994. </year>
Reference-contexts: Using these as semantic primitives one can capture beliefs about the actual state of the world in addition to event occurrences. While not directly suited to our task, the revision model of Friedman and Halpern <ref> [11] </ref>, in which runs are ranked in manner suitable for belief revision, is precisely the type of system upon which a more elaborate model of update, revision and explanation can be built.
Reference: [12] <author> Peter G ardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: We formalize this notion in an abstract manner obtaining a class of explanation-change operators that are similar in spirit and intent to KM update operators, but somewhat more general. We note that explanation has often been closely linked with belief revision <ref> [12] </ref>. Indeed, Boutilier and Becher [5] present a model of abduction where explanations are determined by explicit belief revision. Given this connection and the fact that update can be viewed as an essentially abductive process, we may also take update to be a certain kind of belief revision. <p> However, these restrictions are inappropriate in many cases, calling into question the suitability of some of the update postulates. 4.1 Relationship to Belief Revision It has frequently been suggested that abduction can be modeled by appeal to belief revision <ref> [12] </ref>. Boutilier and Becher [5] present a model of abduction along these lines, whereby an explanation for 19 To appear, Artificial Intelligence, 1995 an observation O, with respect to some KB, is a sentence E such that KB fl E entails O.
Reference: [13] <author> Mois es Goldszmidt and Judea Pearl. </author> <title> Rank-based systems: A simple approach to belief revision, belief update, and reasoning about evidence and actions. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 661-672, </pages> <address> Cambridge, </address> <year> 1992. </year>
Reference-contexts: of (external) events as the impetus for change, rather than actions over which the agent has direct control (or of which the agent has direct knowledge). 4 This assumption is embodied to a certain extent in the update models of del Val and Shoham [8, 9] and Goldszmidt and Pearl <ref> [13] </ref>, as we discuss in Section 4. 7 To appear, Artificial Intelligence, 1995 Before formalizing this idea, it is important to realize that this perspective is very natural. <p> As we have described above, this will usually not be the case. Conditional explanations, explanations that use different actions for different segments of KB, will be very common. A related mechanism is proposed by Goldszmidt and Pearl <ref> [13] </ref>, who use qualitative causal networks to represent an action theory. Again, update formula are implicitly assumed to be propositions asserting the occurrence of some action or event. <p> Action theories such as those exploited in <ref> [8, 13] </ref> might also be used to greater advantage.
Reference: [14] <author> David Harel. </author> <title> Dynamic logic. </title> <editor> In D. Gabbay and F. Guenthner, editors, </editor> <booktitle> Handbook of Philosophical Logic, </booktitle> <pages> pages 497-604. </pages> <address> D. </address> <publisher> Reidel, </publisher> <address> Dordrecht, </address> <year> 1984. </year>
Reference-contexts: A model that puts both components together in a broader abductive framework is described in [2]. Roughly, the logic for belief revision set forth in [4] is used to capture the revision process, but is combined with elements of dynamic logic <ref> [14] </ref> to capture the evolution of the world due to action occurrences. 4.2 Related Work Other have presented models of update that, like ours and unlike the KM-model, have their basis in reasoning about action. del Val and Shoham [8, 9], using the situation calculus, show how one 21 To appear,
Reference: [15] <author> Hirofumi Katsuno and Alberto O. Mendelzon. </author> <title> On the difference between updating a knowledge database and revising it. </title> <type> Technical Report KRR-TR-90-6, </type> <institution> University of Toronto, Toronto, </institution> <month> August </month> <year> 1990. </year>
Reference: [16] <author> Hirofumi Katsuno and Alberto O. Mendelzon. </author> <title> On the difference between updating a knowledge database and revising it. </title> <booktitle> In Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 387-394, </pages> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: It was pointed out by Winslett [27] that the AGM theory is inappropriate for reasoning about changes in belief due to the evolution of a changing world. A new form of belief change dubbed update was proposed in full generality by Katsuno and Mendelzon <ref> [16] </ref>, who provided a set of postulates, distinct from the AGM postulates, that characterize this type of belief change. Semantically, Katsuno and Mendelzon have shown that belief update can be characterized by positing a family of orderings over possible worlds, with each ordering being indexed by some world. <p> Finally, we compare our construction to the model of update proposed by del Val and Shoham [8]. Proofs of the main results can be found in the appendix. 2 The Semantics of Update Katsuno and Mendelzon <ref> [16] </ref> have proposed a general characterization of belief update. Update is distinguished from belief revision conceptually by viewing update as reflecting belief change in response to changes in the world, whereas revision is thought to be more appropriate for changing (possibly erroneous) beliefs about a static world. <p> If some new fact A is observed in response to some (unspecified) change in the world (i.e., some action or event occurrence), then the formula KB A denotes the new belief set incorporating this change. The KM postulates <ref> [16] </ref> governing admissible update operators are (U1) KB A j= A (U2) If KB j= A then KB A is equivalent to KB (U3) If KB and A are satisfiable, then KB A is satisfiable (U4) If j= A B then KB A KB B (U5) (KB A) ^ B j= <p> Corollary 12 Let EM be the explanation-change operator induced by some total order event model. Then EM satisfies postulate (U9). Indeed, Katsuno and Mendelzon <ref> [16] </ref> also discuss the possibility of totally ordered plausibility rankings and provide a postulate (U9) related to the one above, and the proof of equivalence is similar to that suggested by them (see also their work on total orders for belief revision [17]).
Reference: [17] <author> Hirofumi Katsuno and Alberto O. Mendelzon. </author> <title> Propositional knowledge base revision and minimal change. </title> <journal> Artificial Intelligence, </journal> <volume> 52 </volume> <pages> 263-294, </pages> <year> 1991. </year>
Reference-contexts: Indeed, Katsuno and Mendelzon [16] also discuss the possibility of totally ordered plausibility rankings and provide a postulate (U9) related to the one above, and the proof of equivalence is similar to that suggested by them (see also their work on total orders for belief revision <ref> [17] </ref>). As a final remark, we note that the converses of Theorems 8 and 9 are trivially and uninterestingly true. For any update operator , one can construct an appropriate set of events (and orderings) that will induce that operator.
Reference: [18] <author> Nicholas Kushmerick, Steve Hanks, and Daniel Weld. </author> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1073-1078, </pages> <address> Seattle, </address> <year> 1994. </year>
Reference-contexts: This assumption underlies all work in classical planning and reasoning about action, ranging from STRIPS [10] to the situation calculus [20, 24] to more sophisticated probabilistic representations <ref> [18, 7] </ref>. With such information, the predictions associated with explanations (event occurrences) can be easily determined. Furthermore, an ordering over the relative likelihood of possible events also seems something which an agent or system designer or user might easily postulate. <p> For each such condition, a set of effects is specified. An example of this is the classical situation calculus representation of actions (in the deterministic case). Another is the modified STRIPS representation presented in <ref> [18, 6] </ref>. The key feature of these, and other representations, is that each action/event induces a function between worlds (or worlds and sets of worlds). 7 Thus, most action representations will fit within this abstract model. <p> Finally, we can formalize our initial example. We first adopt a conditional STRIPS-like representation of events, using variables to schematically capture a set of propositions, and take each event specification to induce the obvious transformation on possible worlds (see, e.g., <ref> [18, 6] </ref>).
Reference: [19] <author> Daniel Lehmann. </author> <booktitle> What does a conditional knowledge base entail? In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 212-222, </pages> <address> Toronto, </address> <year> 1989. </year>
Reference-contexts: We can 18 To appear, Artificial Intelligence, 1995 extend the Katsuno-Mendelzon representation theorem to deal with update operators of this type. The required postulate embodies a variant of the principle of rational monotonicity, cited widely in connection with nonmonotonic systems of inference and conditional logics (see, e.g., <ref> [3, 19] </ref>). (U9) If KB is complete, (KB A) 6j= :B and (KB A) j= C then (KB (A ^ B)) j= C Theorem 11 An update operator satisfies postulates (U1) through (U9) iff there exists an appropriate family of faithful total preorders f w : w 2 W g that
Reference: [20] <author> John McCarthy and P.J. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <journal> Machine Intelligence, </journal> <volume> 4 </volume> <pages> 463-502, </pages> <year> 1969. </year> <note> 24 To appear, Artificial Intelligence, </note> <year> 1995 </year>
Reference-contexts: 1 Introduction Reasoning about action and change has been a central focus of research in AI for many years, dating at least to the origins of the situation calculus <ref> [20] </ref>. For example, a planning agent must be able to predict the effects of its actions on the world in order to verify whether a potential plan achieves a desired goal. <p> This assumption underlies all work in classical planning and reasoning about action, ranging from STRIPS [10] to the situation calculus <ref> [20, 24] </ref> to more sophisticated probabilistic representations [18, 7]. With such information, the predictions associated with explanations (event occurrences) can be easily determined. Furthermore, an ordering over the relative likelihood of possible events also seems something which an agent or system designer or user might easily postulate.
Reference: [21] <author> Leora Morgenstern and Lynn Andrea Stein. </author> <title> Why things go wrong: A formal theory of causal reasoning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 518-523, </pages> <address> St. Paul, </address> <year> 1988. </year>
Reference-contexts: Using explanation for reasoning about action has been proposed by a number of people, especially within the framework of the situation calculus. Work on temporal projection and prediction failures often exploits the notion of explanation. For instance, Morgenstern and Stein <ref> [21] </ref> propose a model where an observation that conflicts with the predicted effects of an agent's actions causes the agent to infer the existence of some external event occurrence.
Reference: [22] <author> David Poole. </author> <title> A logical framework for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 27-47, </pages> <year> 1988. </year>
Reference-contexts: If Expl P (O; w) = ;, we say that O is not predictively explainable relative to w. The distinction between weak and predictive explanations is very similar to that made between consistency-based diagnosis [23] and predictive (or abductive) diagnosis <ref> [22] </ref>. This distinction is illustrated in Figure 2. Both e and f are nondeterministic events. Event e predictively explains O, while f weakly explains O but does not predictively explain O. We are interested here in weak explanations, for these seem most appropriate when dealing with nondeterministic events.
Reference: [23] <author> Raymond Reiter. </author> <title> A theory of diagnosis from first principles. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 57-95, </pages> <year> 1987. </year>
Reference-contexts: If Expl P (O; w) = ;, we say that O is not predictively explainable relative to w. The distinction between weak and predictive explanations is very similar to that made between consistency-based diagnosis <ref> [23] </ref> and predictive (or abductive) diagnosis [22]. This distinction is illustrated in Figure 2. Both e and f are nondeterministic events. Event e predictively explains O, while f weakly explains O but does not predictively explain O.
Reference: [24] <author> Raymond Reiter. </author> <title> The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression. </title> <editor> In V. Lifschitz, editor, </editor> <booktitle> Artificial Intelligence and Mathematical Theory of Computation (Papers in Honor of John McCarthy), </booktitle> <pages> pages 359-380. </pages> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1991. </year>
Reference-contexts: This assumption underlies all work in classical planning and reasoning about action, ranging from STRIPS [10] to the situation calculus <ref> [20, 24] </ref> to more sophisticated probabilistic representations [18, 7]. With such information, the predictions associated with explanations (event occurrences) can be easily determined. Furthermore, an ordering over the relative likelihood of possible events also seems something which an agent or system designer or user might easily postulate. <p> Allowing preconditions is a trivial and uninteresting addition for our purposes here. 7 In the case of the situation calculus, dynamic logic or other temporal formalisms, one would require some solution to the frame problem. For example, the solution of Reiter <ref> [24] </ref> induces just such a mapping. 9 To appear, Artificial Intelligence, 1995 hence, we postulate an indexed family of event orderings f w : w 2 W g over E.
Reference: [25] <author> Raymond Reiter. </author> <title> On specifying database updates. </title> <type> Technical Report KRR-TR-92-3, </type> <institution> University of Toronto, Toronto, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Third, we will not limit attention to any particular model of action (such as the situation calculus). Finally, our goal is to show how explanation can account for the update of a knowledge base. We should point out that Reiter <ref> [25, and personal communication] </ref> has informally suggested that update can be viewed as explanation to events causing an observation.
Reference: [26] <author> Murray Shanahan. </author> <title> Explanation in the situation calculus. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 160-165, </pages> <address> Chambery, FR, </address> <year> 1993. </year>
Reference-contexts: Work on temporal projection and prediction failures often exploits the notion of explanation. For instance, Morgenstern and Stein [21] propose a model where an observation that conflicts with the predicted effects of an agent's actions causes the agent to infer the existence of some external event occurrence. Shanahan <ref> [26] </ref> proposes a model with a similar motivation, but adopts a truly abductive model (where candidate events are hypothesized rather than deduced from an observation). Our model will be rather different in several ways. First, explanations will be conditional (i.e., explaining events are conditioned on certain propositions).
Reference: [27] <author> Marianne Winslett. </author> <title> Reasoning about action using a possible models approach. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 89-93, </pages> <address> St. Paul, </address> <year> 1988. </year> <title> Acknowledgements Discussions with Ray Reiter have helped to clarify my initial thoughts on update. </title> <note> Thanks to Richard Dearden and David Poole for helpful discussions on this topic and to Alvaro del Val and David Makinson for well-considered comments on an earlier draft of this paper. Thanks also to the referees for suggestions that helped clarify the presentation. This research was supported by NSERC Research Grant OGP0121843. </note>
Reference-contexts: Notice that this revision of KB need not be straightforward, for the new belief A may conflict with beliefs in KB. It was pointed out by Winslett <ref> [27] </ref> that the AGM theory is inappropriate for reasoning about changes in belief due to the evolution of a changing world.
References-found: 27

