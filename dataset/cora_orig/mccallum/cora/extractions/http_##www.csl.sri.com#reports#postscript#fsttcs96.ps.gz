URL: http://www.csl.sri.com/reports/postscript/fsttcs96.ps.gz
Refering-URL: http://www.csl.sri.com/reports/postscript/
Root-URL: 
Title: Mechanized Formal Methods: Progress and Prospects  
Author: John Rushby 
Address: Menlo Park, CA 94025, USA  
Affiliation: Computer Science Laboratory, SRI International,  
Date: December 1996.  
Note: Invited paper presented at the 16th Conference on the Foundations of Software Technology and Theoretical Computer Science, Hyderabad, India,  Springer-Verlag Lecture Notes in Computer Science, volume 1180, pages 43-51.  
Abstract: In the decade of the 1990s, formal methods have progressed from an academic curiosity at best, and a target of ridicule at worst, to a point where the leading manufacturer of microprocessors has indicated that its next design will be formally verified. In this short paper, I sketch a plausible history of the developments that led to this transformation, present a snapshot of the current state of the practice, and indicate some promising directions for the future. Mindful of the title of this conference, I suggest how formal methods might have an impact on software similar to that which they have had on hardware.
Abstract-found: 1
Intro-found: 1
Reference: <institution> Papers by SRI authors are generally available from http://www.csl.sri.com/fm.html. </institution>
Reference: [1] <editor> Rajeev Alur and Thomas A. Henzinger, editors. </editor> <booktitle> Computer-Aided Verification, CAV '96, volume 1102 of Lecture Notes in Computer Science, </booktitle> <address> New Brunswick, NJ, July/August 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference: [2] <author> Asgeir Th. Eirksson and Ken L. McMillan. </author> <title> Using formal verification/analysis methods on the critical path in system design: A case study. </title> <editor> In Pierre Wolper, editor, </editor> <booktitle> Computer-Aided Verification, CAV '95, volume 939 of Lecture Notes in Computer Science, </booktitle> <pages> pages 367-380, </pages> <address> Liege, Belgium, June 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Using these and other techniques, model checkers based on both explicit state-enumeration and symbolic representations are able to tackle cache-coherence problems sufficiently well to be used in the design process for these systems <ref> [2, 11] </ref>. But although they are effective for detecting bugs, the severely downscaled models used in model checking cannot serve to verify the general case.
Reference: [3] <author> Bishop Brock, Matt Kaufmann, and J Strother Moore. </author> <title> ACL2 theorems about commercial microprocessors. </title> <booktitle> In Srivas and Camilleri [34], </booktitle> <pages> pages 275-293. </pages>
Reference-contexts: Most importantly, the practitioners of these approaches to formal methods followed the lead of the model checkers in applying them to complex, real-world systems <ref> [3, 35] </ref>. 2 The Present An idea of the current capabilities and accomplishments of mechanized formal methods can be obtained by considering two examples from hardware design.
Reference: [4] <author> Randal E. Bryant. </author> <title> Symbolic boolean manipulation with ordered binary-decision diagrams. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(3) </volume> <pages> 293-318, </pages> <month> September </month> <year> 1992. </year> <month> 7 </month>
Reference-contexts: The bug was in the lookup table of an SRT divider [25]. Binary Decision Diagrams (BDDs) have been used successfully to verify many kinds of digital circuits|but not multipliers and dividers, where they grow exponentially large <ref> [4] </ref>. Nonetheless, Bryant was able to verify a single iteration of an SRT circuit using BDDs [5].
Reference: [5] <author> Randal E. Bryant. </author> <title> Bit-level analysis of an SRT divider circuit. </title> <booktitle> In Proceedings of the 33rd Design Automation Conference, </booktitle> <pages> pages 661-665, </pages> <address> Las Vegas, NV, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Binary Decision Diagrams (BDDs) have been used successfully to verify many kinds of digital circuits|but not multipliers and dividers, where they grow exponentially large [4]. Nonetheless, Bryant was able to verify a single iteration of an SRT circuit using BDDs <ref> [5] </ref>. Explosive growth of the BDD representation has generally also precluded application of symbolic model checking to dividers; however, by using a different "word level" representation, Clarke, Khaira, and Zhao were able to apply model checking to this problem [7].
Reference: [6] <author> E. M. Clarke, S. M. German, and X. Zhao. </author> <title> Verifying the SRT division algorithm using theorem proving techniques. </title> <booktitle> In Alur and Henzinger [1], </booktitle> <pages> pages 111-122. </pages>
Reference-contexts: Clarke, German, and Zhao were also able to verify an SRT divider using a special-purpose theorem prover based on the Mathe-matica symbolic algebra system <ref> [6] </ref>. Using the PVS general-purpose verification system [21], Rue, Shankar, and Srivas gave a formally verified treatment of the general theory of SRT division, and then verified a particular circuit and lookup table [27].
Reference: [7] <author> E. M. Clarke, Manpreet Khaira, and Xudong Zhao. </author> <title> Word level symbolic model checking|avoiding the Pentium FDIV error. </title> <booktitle> In Proceedings of the 33rd Design Automation Conference, </booktitle> <pages> pages 645-648, </pages> <address> Las Veqas, NV, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Explosive growth of the BDD representation has generally also precluded application of symbolic model checking to dividers; however, by using a different "word level" representation, Clarke, Khaira, and Zhao were able to apply model checking to this problem <ref> [7] </ref>. Clarke, German, and Zhao were also able to verify an SRT divider using a special-purpose theorem prover based on the Mathe-matica symbolic algebra system [6].
Reference: [8] <author> Edmund M. Clarke, Orna Grumberg, Hiromi Haraishi, Somesh Jha, David E. Long, Kenneth L. McMillan, and Linda A. Ness. </author> <title> Verification of the Futurebus+ cache coherence protocol. </title> <booktitle> Formal Methods in System Design, </booktitle> <volume> 6(2) </volume> <pages> 217-232, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: And find bugs it did: because model checking is well-suited to concurrent systems, it was immediately applied to some of the hardest problems in system design, such as multiprocessor cache-coherence protocols, where "high-value bugs" were quickly detected <ref> [8] </ref>.
Reference: [9] <author> Dan Craigen, Susan Gerhart, and Ted Ralston. </author> <title> Formal methods reality check: Industrial usage. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(2) </volume> <pages> 90-98, </pages> <month> Febru-ary </month> <year> 1995. </year>
Reference-contexts: many details as possible; whereas previously the goal had been to establish unequivocal correctness, there was now seen to be a variety of other useful purposes that could be served by formal analysis; and whereas previously the applications had generally been to routine designs (see, 2 for example, the survey <ref> [9] </ref>), there was now an enthusiasm for applying formal methods to the hardest and most difficult problems of design.
Reference: [10] <author> David A. Cyrluk and Mandayam K. Srivas. </author> <title> Theorem proving: Not an esoteric diversion, but the unifying framework for industrial verification. </title> <booktitle> In International Conference on Computer Design: VLSI in Computers and Processors (ICCD '95), </booktitle> <pages> pages 538-544, </pages> <address> Austin, TX, </address> <month> October </month> <year> 1995. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: hub of such an environment must be a theorem prover, since that is what has the capability to check that problems are decomposed appropriately, that constraints on the application of certain procedures are satisfied, and that all the pieces come together to solve the whole problem in a sound manner <ref> [10] </ref>. In collaboration with David Dill of Stanford University, we are about to begin construction of such an environment. 4 Conclusion These are exciting times for mechanized formal methods, with opportunities for rapid and significant progress in the capabilities of tools and the quality and scale of their applications.
Reference: [11] <author> David L. Dill, Andreas J. Drexler, Alan J. Hu, and C. Han Yang. </author> <title> Protocol verification as a hardware design aid. </title> <booktitle> In International Conference on Computer Design: VLSI in Computers and Processors, </booktitle> <pages> pages 522-525. </pages> <publisher> IEEE Computer Society, </publisher> <address> Oc-tober 1992. Cambridge, MA. </address>
Reference-contexts: Using these and other techniques, model checkers based on both explicit state-enumeration and symbolic representations are able to tackle cache-coherence problems sufficiently well to be used in the design process for these systems <ref> [2, 11] </ref>. But although they are effective for detecting bugs, the severely downscaled models used in model checking cannot serve to verify the general case.
Reference: [12] <author> Klaus Havelund and N. Shankar. </author> <title> Experiments in theorem proving and model checking for protocol verification. </title> <booktitle> In Formal Methods Europe FME '96, volume 1051 of Lecture Notes in Computer Science, </booktitle> <pages> pages 662-681, </pages> <address> Oxford, UK, March 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Special-purpose tools can help with these activities, and finite-state methods can be invoked during the proof process to check that proposed invariants really are so, and that subgoals are true (on finite instances) <ref> [12] </ref>. Different methods come into play on a single problem as easy bugs are eliminated and those that remain become harder to find; in a related progression, different methods come into play in the treatment of classes of problems as our understanding and techniques improve.
Reference: [13] <author> Mats P. E. Heimdahl. </author> <title> Experiences and lessons from the analysis of TCAS II. </title> <editor> In Steven J. Zeil, editor, </editor> <booktitle> International Symposium on Software Testing and Analysis (ISSTA), </booktitle> <pages> pages 79-83, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1996. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: When tautology checking proved inadequate for an example derived from the TCAS II specification <ref> [13] </ref>, Czerny and Heim-dahl turned to the PVS verification system in order to make use of its decision procedures. However, because those decision procedures could not be accessed separately, they had to invoke the entire PVS system, which entailed more baggage and less performance than they desired [14].
Reference: [14] <author> Mats P. E. Heimdahl and Barbara J. Czerny. </author> <title> Using PVS to analyze hierarchical state-based requirements for completeness and consistency. </title> <booktitle> In IEEE High-Assurance Systems Engineering Workshop (HASE '96), Niagara on the Lake, </booktitle> <address> Canada, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: However, because those decision procedures could not be accessed separately, they had to invoke the entire PVS system, which entailed more baggage and less performance than they desired <ref> [14] </ref>. What is really needed is an open environment that provides access to components such as decision procedures and the other building blocks of theorem provers and model checkers, and in which customized combinations can be quickly constructed.
Reference: [15] <author> Mats P. E. Heimdahl and Nancy G. Leveson. </author> <title> Completeness and consistency in hierarchical state-based requirements. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 22(6) </volume> <pages> 363-377, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: For example, an attractive application of formal 6 reasoning to software requirements is to check consistency and completeness of the conditions that label the rows and columns of tabular specifications <ref> [15] </ref>. Depending on the logic and theories used in specifying these conditions, the deductive capabilities needed to perform the checks range from propositional tautology checking, though decision procedures for ground linear arithmetic, to full interactive theorem proving.
Reference: [16] <author> Daniel Jackson and Craig A. Damon. </author> <title> Elements of style: Analyzing a software design feature with a counterexample detector. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 22(7) </volume> <pages> 484-495, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: effective in applications of formal methods to hardware can also be used for software (see, for example, [33], where the SMV model checker is applied to a software requirements specification); alternatively, ideas from those tools can be incorporated into new tools that are specifically tailored to the characteristics of software <ref> [16] </ref>.
Reference: [17] <author> Cliff B. Jones. </author> <title> Systematic Software Development Using VDM. </title> <publisher> Prentice Hall International Series in Computer Science, </publisher> <address> Hemel Hempstead, UK, </address> <year> 1990. </year>
Reference-contexts: In the spacecraft data just cited, approximately 50% of faults were traced to requirements (mainly omissions), and 25% to each of interfaces and design. During the 1980s, attention shifted from program correctness to the use of formalism in specifications, exemplified by approaches such as Z [32] and VDM <ref> [17] </ref>. Although these methods initially stressed the role of proof in development, they came to be used mainly as specification languages, and their advocates commended the utility of mathematical concepts such as sets, functions, and relations in constructing precise yet abstract descriptions of computational systems.
Reference: [18] <author> Robyn R. Lutz. </author> <title> Analyzing software requirements errors in safety-critical embedded systems. </title> <booktitle> In IEEE International Symposium on Requirements Engineering, </booktitle> <pages> pages 126-133, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: For example, of 197 critical faults detected during integration and system testing of the Voyager and Galileo spacecraft, just 3 were coding errors <ref> [18] </ref>. The large majority of faults arise in requirements, interfaces, and intrinsically difficult design problems (e.g., fault tolerance, and the coordination of concurrent activities). In the spacecraft data just cited, approximately 50% of faults were traced to requirements (mainly omissions), and 25% to each of interfaces and design.
Reference: [19] <author> Kenneth L. McMillan. </author> <title> Symbolic Model Checking. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1993. </year>
Reference-contexts: It was the arrival of efficient techniques for model checking in the early 1990s <ref> [19] </ref> (and related methods such as language inclusion) that first made large-scale mechanized calculations a practical reality for formal methods and demonstrated their utility to a wide audience. No less important than the techniques that made model checking practical was the change in approach and outlook that its use engendered.
Reference: [20] <author> Paul S. Miner and James F. Leathrum, Jr. </author> <title> Verification of IEEE compliant subtractive division algorithms. </title> <booktitle> In Srivas and Camilleri [34], </booktitle> <pages> pages 64-78. 8 </pages>
Reference-contexts: Miner and Leathrum extended the PVS treatment to include IEEE-compliance, generalized the whole development to encompass the broader class of subtractive division algorithms that includes SRT, and presented a methodology that enabled specific algorithms to be debugged and verified quite easily|which they demonstrated on various SRT tables <ref> [20] </ref>. Cache coherence protocols for distributed shared memory multiprocessors are notoriously difficult to design. Some of the early successes with symbolic model checking were in its application to this type of problem.
Reference: [21] <author> S. Owre, S. Rajan, J.M. Rushby, N. Shankar, and M.K. Srivas. PVS: </author> <title> Combining specification, proof checking, and model checking. </title> <booktitle> In Alur and Henzinger [1], </booktitle> <pages> pages 411-414. </pages>
Reference-contexts: Clarke, German, and Zhao were also able to verify an SRT divider using a special-purpose theorem prover based on the Mathe-matica symbolic algebra system [6]. Using the PVS general-purpose verification system <ref> [21] </ref>, Rue, Shankar, and Srivas gave a formally verified treatment of the general theory of SRT division, and then verified a particular circuit and lookup table [27].
Reference: [22] <author> Sam Owre, John Rushby, Natarajan Shankar, and Friedrich von Henke. </author> <title> Formal verification for fault-tolerant architectures: Prolegomena to the design of PVS. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(2) </volume> <pages> 107-125, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Decision procedures for basic theories such as linear arithmetic and equality received renewed attention and acceptance, and integrated combinations of decision procedures, rewriting, and customized tactics achieved significant automation and efficiency on interesting classes of problems <ref> [22] </ref>.
Reference: [23] <author> Seungjoon Park and David L. Dill. </author> <title> An executable specification, analyzer and verifier for RMO (Relaxed Memory Order). </title> <booktitle> In 7th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 34-51, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: In similar work for the Sparc V9 memory model, they were able to verify the behavior of synchronization code using Mur, and were able to verify the executable Mur model against its axiomatic specification using PVS <ref> [23] </ref>. The interesting feature of these examples is the diversity of approaches employed|and the diversity would be even greater if I had considered other examples such as pipelines, microcode, communications and switching protocols, or hybrid systems.
Reference: [24] <author> Seungjoon Park and David L. Dill. </author> <title> Verification of the FLASH cache coherence protocol by aggregation of distributed transactions. </title> <booktitle> In 8th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 288-296, </pages> <address> Padua, Italy, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Recently, however, by using a method called "aggregation" to guide construction of the abstraction function, Park and Dill have been able, using PVS in a quite straightforward manner, to verify the behavior of the protocol used in the Stanford FLASH processor <ref> [24] </ref>. Furthermore, using the Mur explicit state-enumeration system they were able to construct an executable model for the non-sequentially-consistent memory behavior of the processor.
Reference: [25] <author> Vaughan Pratt. </author> <title> Anatomy of the Pentium bug. </title> <booktitle> In TAPSOFT '95: Theory and Practice of Software Development, volume 915 of Lecture Notes in Computer Science, </booktitle> <pages> pages 97-107, </pages> <address> Aarhus, Denmark, May 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The Pentium FDIV bug, which attracted a great deal of public interest, also caught the attention of the formal verification community|not least because it caused Intel to take a $475 million charge against revenues. The bug was in the lookup table of an SRT divider <ref> [25] </ref>. Binary Decision Diagrams (BDDs) have been used successfully to verify many kinds of digital circuits|but not multipliers and dividers, where they grow exponentially large [4]. Nonetheless, Bryant was able to verify a single iteration of an SRT circuit using BDDs [5].
Reference: [26] <author> S. Rajan, N. Shankar, </author> <title> and M.K. Srivas. An integration of model-checking with automated proof checking. </title> <editor> In Pierre Wolper, editor, </editor> <booktitle> Computer-Aided Verification, CAV '95, volume 939 of Lecture Notes in Computer Science, </booktitle> <pages> pages 84-97, </pages> <address> Liege, Belgium, June 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Such an integration of theorem proving and model checking has been achieved <ref> [26] </ref>, but it required extending the implementation of a complex verification system. Future systems should be designed in a much more "open" manner, so that components can be added, modified, interconnected, and accessed in a modular fashion.
Reference: [27] <author> H. Rue, N. Shankar, and M. K. Srivas. </author> <title> Modular verification of SRT division. </title> <booktitle> In Alur and Henzinger [1], </booktitle> <pages> pages 123-134. </pages>
Reference-contexts: Using the PVS general-purpose verification system [21], Rue, Shankar, and Srivas gave a formally verified treatment of the general theory of SRT division, and then verified a particular circuit and lookup table <ref> [27] </ref>. While being more general, the theorem proving treatments achieved a level of automation and efficiency comparable to the BDD and model checking approaches, and were equally adept at catching errors in the tables.
Reference: [28] <author> John Rushby. </author> <title> Automated deduction and formal methods. </title> <booktitle> In Alur and Henzinger [1], </booktitle> <pages> pages 169-183. </pages>
Reference-contexts: Rather than loose integration of a number of different tools, however, what is really required is tight integration of a number of different capabilities <ref> [28, 31] </ref>.
Reference: [29] <author> John Rushby. </author> <title> Calculating with requirements. </title> <booktitle> In 3rd IEEE International Symposium on Requirements Engineering, Annapolis, </booktitle> <address> MD, </address> <month> January </month> <year> 1997. </year> <journal> IEEE Computer Society. </journal> <note> To appear. </note>
Reference-contexts: Formal methods are singularly well-adapted to the specification and analysis of requirements, because they allow precision without premature detail (unlike pseudocode and prototyping), and they allow useful analyses to be performed on very abstract or incomplete descriptions <ref> [29] </ref>. Use powerful tools, and a spectrum of methods. Without tools, formal methods are just documentation; it is tools that make formal methods useful, and powerful tools that make them productive.
Reference: [30] <author> N. Shankar. </author> <title> Computer-aided computing. </title> <editor> In Bernhard Moller, editor, </editor> <booktitle> Mathematics of Program Construction '95, volume 947 of Lecture Notes in Computer Science, </booktitle> <pages> pages 50-66. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: to prove the general case with the theorem prover, whereas tight integration might allow the theorem prover actively to use the model checker|so that the theorem prover could set up the induction to prove the general case, with the base case and inductive step then being discharged by model checking <ref> [30] </ref>. Such an integration of theorem proving and model checking has been achieved [26], but it required extending the implementation of a complex verification system. Future systems should be designed in a much more "open" manner, so that components can be added, modified, interconnected, and accessed in a modular fashion.
Reference: [31] <author> Natarajan Shankar. </author> <title> Unifying verification paradigms. </title> <editor> In Bengt Jonsson and Joachim Parrow, editors, </editor> <booktitle> Formal Techniques in Real-Time and Fault-Tolerant Systems, volume 1135 of Lecture Notes in Computer Science, </booktitle> <pages> pages 22-39, </pages> <institution> Uppsala, Sweden, </institution> <month> September </month> <year> 1996. </year> <note> Springer-Verlag. </note>
Reference-contexts: Rather than loose integration of a number of different tools, however, what is really required is tight integration of a number of different capabilities <ref> [28, 31] </ref>.
Reference: [32] <author> J. M. Spivey, </author> <title> editor. The Z Notation: A Reference Manual. </title> <publisher> Prentice Hall International Series in Computer Science, </publisher> <address> Hemel Hempstead, UK, </address> <year> 1993. </year>
Reference-contexts: In the spacecraft data just cited, approximately 50% of faults were traced to requirements (mainly omissions), and 25% to each of interfaces and design. During the 1980s, attention shifted from program correctness to the use of formalism in specifications, exemplified by approaches such as Z <ref> [32] </ref> and VDM [17]. Although these methods initially stressed the role of proof in development, they came to be used mainly as specification languages, and their advocates commended the utility of mathematical concepts such as sets, functions, and relations in constructing precise yet abstract descriptions of computational systems.
Reference: [33] <author> Tirumale Sreemani and Joanne M. Atlee. </author> <title> Feasibility of model checking software requirements. </title> <booktitle> In COMPASS '96 (Proceedings of the Eleventh Annual Conference on Computer Assurance), </booktitle> <pages> pages 77-88, </pages> <address> Gaithersburg, MD, </address> <month> June </month> <year> 1996. </year> <institution> IEEE Washington Section. </institution>
Reference-contexts: Without tools, formal methods are just documentation; it is tools that make formal methods useful, and powerful tools that make them productive. Many of the tools that have been effective in applications of formal methods to hardware can also be used for software (see, for example, <ref> [33] </ref>, where the SMV model checker is applied to a software requirements specification); alternatively, ideas from those tools can be incorporated into new tools that are specifically tailored to the characteristics of software [16].
Reference: [34] <author> Mandayam Srivas and Albert Camilleri, </author> <title> editors. </title> <booktitle> Formal Methods in Computer-Aided Design (FMCAD '96), volume 1166 of Lecture Notes in Computer Science, </booktitle> <address> Palo Alto, CA, </address> <month> November </month> <year> 1996. </year> <note> Springer-Verlag. </note>

References-found: 35

