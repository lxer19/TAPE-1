URL: http://www.iscs.nus.sg/~plong/papers/linear.ps
Refering-URL: 
Root-URL: 
Title: ON-LINE LEARNING OF LINEAR FUNCTIONS  
Author: Nicholas Littlestone, Philip M. Long and Manfred K. Warmuth 
Abstract: We present an algorithm for the on-line learning of linear functions which is optimal to within a constant factor with respect to bounds on the sum of squared errors for a worst case sequence of trials. The bounds are logarithmic in the number of variables. Furthermore, the algorithm is shown to be optimally robust with respect to noise in the data (again to within a constant factor). Key words. Machine learning; computational learning theory; on-line learning; linear functions; worst-case loss bounds; adaptive filter theory. Subject classifications. 68T05. 
Abstract-found: 1
Intro-found: 1
Reference: <author> S. S. Agaian, </author> <title> Hadamard Matrices and Their Applications. </title> <booktitle> Number 1168 in Lecture Notes in Mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: It has been conjectured that Hadamard matrices exist for all n divisible by 4 <ref> (see discussion in Agaian 1985) </ref>. Recall that the total loss of our algorithm was O ((cM ) 2 log n + N ).
Reference: <author> E.J. Bernstein, </author> <title> Absolute error bounds for learning linear functions on line. </title> <booktitle> Proceedings of the 1992 Workshop on Computational Learning Theory, </booktitle> <year> 1992, </year> <pages> 160-163. </pages>
Reference: <author> A. Blum, L. Hellerstein, and N. Littlestone, </author> <title> Learning in the presence of finitely many or infinitely many irrelevant attributes. </title> <booktitle> The 1991 Workshop on Computational Learning Theory, </booktitle> <year> 1991, </year> <pages> 157-166. </pages>
Reference: <author> N. Cesa-Bianchi, </author> <title> P.M. Long, and M.K. Warmuth, Worst-case quadratic loss bounds for a generalization of the Widrow-Hoff rule. </title> <booktitle> The 1993 Workshop on Computational Learning Theory, </booktitle> <year> 1993, </year> <pages> 429-438. </pages>
Reference: <author> R. O. Duda and P. E. Hart, </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference: <author> D. Haussler, </author> <title> Learning conjunctive concepts in structural domains. </title> <booktitle> Machine Learning 4(1) (1989), </booktitle> <pages> 7-40. </pages>
Reference: <author> M. Kearns, M. Li, L. Pitt, and L.G. Valiant, </author> <title> On the learnability of boolean formulae. </title> <booktitle> Proceedings of the 19th Annual Symposium on the Theory of Computation, </booktitle> <year> 1987, </year> <pages> 285-295. </pages>
Reference: <author> S. Kullback, </author> <title> A lower bound for discrimination in terms of variation. </title> <journal> IEEE transactions on Information Theory 13 (1967), </journal> <pages> 126-127. </pages>
Reference-contexts: Lemma 2.1. <ref> (Kullback 1967) </ref> For ; 2 [0; 1], I ((; 1 )jj (; 1 )) 2 ( ) 2 : Lemma 2.2. (Littlestone 1989) For all fi &gt; 0; x 2 [0; 1], fi x 1 + (fi 1)x: The inequality is an equality iff x = 0 or x = 1.
Reference: <author> N. Littlestone, </author> <title> Learning quickly when irrelevant attributes abound: a new linear-threshold algorithm. </title> <booktitle> Machine Learning 2 (1988), </booktitle> <pages> 285-318. </pages>
Reference-contexts: In the discrete case, this approach can lead to logarithmic total mistake bounds <ref> (Littlestone 1988, 1989, Littlestone & Warmuth 1994) </ref>. <p> This is in contrast to the case of learning boolean functions, such as boolean linear-threshold functions, where in general (for classes closed under permutation of the attributes) learning gets harder as the number of relevant variables increases <ref> (Littlestone 1988, 1989, Littlestone & Warmuth 1994, Blum et al. 1991) </ref>. (Some of the upper bounds of Littlestone ( 1989 ) depend on a product of two factors, one of which shows the same decreasing dependence on entropy observed here; that decrease is typically dwarfed by an increase in the other
Reference: <author> N. Littlestone, </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, </type> <institution> UC Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: Lemma 2.1. (Kullback 1967) For ; 2 [0; 1], I ((; 1 )jj (; 1 )) 2 ( ) 2 : Lemma 2.2. <ref> (Littlestone 1989) </ref> For all fi &gt; 0; x 2 [0; 1], fi x 1 + (fi 1)x: The inequality is an equality iff x = 0 or x = 1. The following series of lemmas also give approximations for quantities arising in our analysis. The first can be easily verified.
Reference: <author> N. Littlestone and M. Warmuth, </author> <title> The weighted majority algorithm. </title> <note> Information and Computation (1994). To appear. </note>
Reference-contexts: Given this interpretation, a natural reweighting strategy is to reduce the weights of each economist according to some monotone function of how far off her estimate was <ref> (e.g., the Weighted Majority algorithm in Littlestone & Warmuth 1994) </ref>, and then normalize so that the weights sum to one. In the discrete case, this approach can lead to logarithmic total mistake bounds (Littlestone 1988, 1989, Littlestone & Warmuth 1994). <p> Learning linear functions 21 The fact that our algorithm must know a bound on the sum of the absolute values of the coefficients of the target function might make it appear somewhat unattractive to practitioners. However, this problem may be circumvented by application of the Weighted Majority algorithm <ref> ( Littlestone & Warmuth 1994 ) </ref> to a pool consisting of algorithms that assume various upper bounds on the size of the hidden coefficient vectors.
Reference: <author> J. Mycielski, </author> <title> A learning algorithm for linear operators. </title> <booktitle> Proceedings of the American Mathematical Society 103(2) (1988), </booktitle> <month> 547-550. </month> <title> Learning linear functions 23 L. Pitt and M.K. Warmuth, Prediction preserving reducibility. </title> <journal> Journal of Computer and System Sciences 41(3) (1990), </journal> <pages> 430-467. </pages>
Reference-contexts: Instead of giving bounds in terms of P m t=1 (~~x t t ) 2 , he states his bounds in terms of m max t (~ ~x t t ) 2 <ref> ( Mycielski 1988 ) </ref> .) When is it advantageous to use the algorithm of this paper as opposed to the Widrow-Hoff algorithm? To attempt to gain some insight, let us consider two simple examples. (A similar comparison, in the context of learning linear threshold functions, was undertaken by Littlestone ( 1989
Reference: <author> G. Strang, </author> <title> Linear Algebra and its Applications. </title> <publisher> Harcourt, Brace, Jovanovich, </publisher> <year> 1988. </year>
Reference-contexts: Note that the choice for ~w t might not be unique. We consider the least squares algorithm that breaks ties in favor of shorter weight vectors, as suggested, for example, in Strang ( 1988 ) . The following lemma applies. Lemma 5.4. <ref> (Strang 1988) </ref> The linear least squares algorithm which breaks ties in favor of shorter weight vectors (in the Euclidian norm) has the property that its weight vector is initially zero and in later trials, is a linear combination of the previous examples.
Reference: <author> B. Widrow and M.E. Hoff, </author> <title> Adaptive switching circuits. 1960 IRE WESCON Convention Record (1960), </title> <type> 96-104. Manuscript received May 30, </type> <institution> 1992 Nicholas Littlestone NEC Research Institute 4 Independence Way Princeton, NJ 08540 nickl@research.nj.nec.com Philip M. Long Computer Science Department Duke University, </institution> <address> P.O. Box 90129 Durham, NC 27708 plong@cs.duke.edu Manfred K. </address> <institution> Warmuth CIS Board, UC Santa Cruz Santa Cruz, </institution> <address> CA 95064 manfred@mira.ucsc.edu </address>
Reference-contexts: We show a case where the worst-case total loss of the Widrow-Hoff rule (also sometimes called the delta rule) <ref> (Widrow & Hoff 1960, Duda & Hart 1973) </ref> is (c 2 M 2 n + N), where, again, N is the total loss of the best fixed weight vector, and our algorithm has a bound of O (c 2 M 2 log n + N). <p> case when exactly one of the hidden i 's is 1 and the rest are 0. (These results are with respect to the loss function j t t j.) As in the algorithms of Littlestone ( 1988, 1989 ) , Littlestone & Warmuth ( 1994 ) and the Widrow-Hoff rule <ref> (Widrow & Hoff 1960, Duda & Hart 1973) </ref>, our algorithms maintain a vector of n weights that is updated each trial after the response is received. Let ~v t represent this weight vector before trial t.
References-found: 14

