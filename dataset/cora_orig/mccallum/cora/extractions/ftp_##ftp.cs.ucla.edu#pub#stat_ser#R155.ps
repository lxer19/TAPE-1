URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R155.ps
Refering-URL: http://singapore.cs.ucla.edu/csl_papers.html
Root-URL: http://www.cs.ucla.edu
Title: A Statistical Semantics for Causation Key words: causality, induction, learning  
Author: Judea Pearl TS Verma &lt; judea@cs:ucla:edu &gt; &lt; verma@cs:ucla:edu &gt; 
Address: Los Angeles, CA 90024  
Affiliation: Cognitive Systems Laboratory, Computer Science Department University of California,  
Abstract: We propose a model-theoretic definition of causation, and show that, contrary to common folklore, genuine causal influences can be distinguished from spurious covari-ations following standard norms of inductive reasoning. We also establish a complete characterization of the conditions under which such a distinction is possible. Finally, we provide a proof-theoretical procedure for inductive causation and show that, for a large class of data and structures, effective algorithms exist that uncover the direction of causal influences as defined above.
Abstract-found: 1
Intro-found: 1
Reference: [Freedman 87] <author> As Others See Us: </author> <title> A Case Study in Path Analysis (with discussion). </title> <journal> Journal of Educational Statistics, 1987, </journal> <volume> 12 </volume> <pages> 101-223. </pages>
Reference-contexts: From a methodological viewpoint, our results should settle some of the on going disputes between the descriptive and structural approaches to theory formation <ref> [Freedman 87] </ref>. It shows that the methodology governing path-analytic techniques is legitimate, faithfully adhering to the traditional norms of scientific investigation.
Reference: [Forbus & Gentner 86] <author> Forbus, K. D. and Gentner, D., </author> <title> Causal Reasoning about Quantities. </title> <booktitle> Proceedings Cognitive Science Society, </booktitle> <address> Amherst, </address> <year> 1986, </year> <pages> 196-207. </pages>
Reference: [Gardenfors, 1988] <author> Gardenfors, P. </author> <title> Causation and the Dynamics of Belief, </title> <editor> in W.L. Harper and B. Skyrms (eds.) </editor> <title> Causation in Decision, Belief Change and Statistics II Kluwr Academic Publishers, </title> <booktitle> 1988. </booktitle> <pages> pp 85-104. </pages> <note> 5 apparently this lack of transitivity has not been utilized by path analysts. 7 </note>
Reference-contexts: of my grass and that of the parking lot (such as the water saturating my lawn, running off into the gutter and into the parking lot). 6 Conclusions The results presented in this paper dispel the claim that statistical analysis can never distinguish genuine causation from spurious covariation [Otte 81], <ref> [Gardenfors, 1988] </ref>. We show that certain patterns of dependencies dictate a direct causal relationship between variables, one that cannot be attributed to hidden causes lest we violate one of the basic maxims of scientific methodology: the semantical version of Occam's razor.
Reference: [Glymour et al. 87] <author> Glymour, C.; Scheines, R.; Spirtes, P.; and Kelly, K. </author> <title> Discovering Causal Structure, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [Granger, 1987] <author> Granger, C.W.J. </author> <title> Causality Testing in a Decision Science in W.L. </title> <editor> Harper and B. Skyrms (eds.) </editor> <title> Causation in Decision, Belief Change and Statistics I Kluwr Academic Publishers, </title> <booktitle> 1988. </booktitle> <pages> pp. 1-20. </pages>
Reference-contexts: Condition (1) in Definition 12 may be established either by statistical methods (per Definition 11) or by other sources of information e.g., experimental studies or temporal succession (i.e. that Z precedes X in time). When temporal information is available, as it is assumed in the formulations of [Suppes 70], <ref> [Granger, 1987] </ref> and [Spohn, 1983], then every link constructed in step 1 of the IC-algorithm corresponds to a potential cause (genuine or spurious cause in Suppes terminology).
Reference: [Iwasaki & Simon 86] <author> Iwasaki, Y.; and Simon H. A. </author> <title> Causality in Device Behavior. </title> <journal> Artificial Intelligence, 1986, </journal> <volume> 29(1) </volume> <pages> 3-32. </pages>
Reference: [Kautz 87] <institution> A formal Theory of Plan Recognition. </institution> <type> PhD thesis, </type> <institution> University of Rochester, Rochester, </institution> <address> N.Y., </address> <month> May </month> <year> 1987. </year>
Reference: [Otte 81] <author> Otte, R. </author> <title> A critique of Suppes' theory of Probabilistic causality. </title> <type> Synthese 48 </type> <pages> 167-189. </pages>
Reference-contexts: the wetness of my grass and that of the parking lot (such as the water saturating my lawn, running off into the gutter and into the parking lot). 6 Conclusions The results presented in this paper dispel the claim that statistical analysis can never distinguish genuine causation from spurious covariation <ref> [Otte 81] </ref>, [Gardenfors, 1988]. We show that certain patterns of dependencies dictate a direct causal relationship between variables, one that cannot be attributed to hidden causes lest we violate one of the basic maxims of scientific methodology: the semantical version of Occam's razor.
Reference: [Pearl & Verma 87] <author> Pearl, J.; and Verma, T. S. </author> <title> The logic of representing dependencies by directed acyclic graphs. </title> <booktitle> Proceedings of AAAI-87, </booktitle> <year> 1987, </year> <pages> 347-379, </pages> <address> Seattle Washington. </address>
Reference: [Pearl 88] <author> Pearl, J. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <address> Morgan-Kaufman, San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: This is indeed the eventuality that permits our algorithm to begin orienting edges in the graph (step 2), and assign arrowheads pointing at c. Another explanation of this principle appeals to the perception of "voluntary control" <ref> [Pearl 88, page 396] </ref>. The reason people insist that the rain causes the grass to become wet, and not the other way around, is that they can find other means of getting the grass wet, totally independent of the rain.
Reference: [Pearl 90] <author> Pearl, J. </author> <title> Probabilistic and Qualitative Abduction, </title> <booktitle> in Proceedings of AAAI Spring Symposium on Abduction, </booktitle> <address> Stanford, March 27-29, </address> <year> 1990, </year> <pages> 155-158. </pages>
Reference-contexts: X is a genuine cause of Z and Z is a genuine cause of Y . Definition 11 was formulated in <ref> [Pearl 90] </ref> as a relation between events (rather than variables) with the added condition P (Y jX) &gt; P (Y ) in the spirit of [Suppes 70].
Reference: [Simon 54] <author> Simon, H. </author> <title> Spurious correlations: A causal interpretation. </title> <journal> Journal American Statistical Association, 1954, </journal> <volume> 49 </volume> <pages> 469-492. </pages>
Reference: [Spirtes, Glymour & Scheines 89] <author> Spirtes, P.; Glymour, C.; and Scheines, R. </author> <title> Causality from probability. </title> <type> Technical Report CMU-LCL-89-4, </type> <institution> Department of Philosophy Carnegie-Mellon University, </institution> <year> 1989. </year>
Reference-contexts: It conveys the assumption that all vanishing dependencies are structural, not formed by incidental equalities of numerical parameters. 2 2 It is possible to show that, if the parameters are chosen at random from any reasonable distribution, then any unstable distribution has measure zero <ref> [Spirtes, Glymour & Scheines 89] </ref>. Stability precludes deterministic constraints. 3 Definition 8 Let I (P) denote the set of all conditional independence relationships embod--ieded in P . A causal theory T =&lt;D; fi D &gt; generates a stable distribution iff it contains no extraneous independences, i.e.
Reference: [Spirtes and Glymour, 1991] <author> Spirtes, P. and Glymour, C. </author> <title> An Algorithm for Fast Recovery of Sparse Causal Graphs, </title> <journal> Social Science Computer Review, </journal> <note> 9 (1991) in Press. </note>
Reference-contexts: This search is exponential in general, but simplifies significantly when the underlying structure is sparse (see [Verma & Pearl 90] and <ref> [Spirtes and Glymour, 1991] </ref> for such algorithms). 4 Recovering Latent Structures When Nature decides to "hide" some variables, the observed distribution ^ P need no longer be stable relative to the observable set O, i.e. ^ P may result from many equivalent minimal latent structures, each containing any number of hidden
Reference: [Spohn, 1983] <author> Spohn, W. </author> <title> Deterministic and Probabilistic Reasons and Causes, </title> <booktitle> Erkenntnis 19 </booktitle> <pages> 371-396. </pages>
Reference-contexts: When temporal information is available, as it is assumed in the formulations of [Suppes 70], [Granger, 1987] and <ref> [Spohn, 1983] </ref>, then every link constructed in step 1 of the IC-algorithm corresponds to a potential cause (genuine or spurious cause in Suppes terminology). In such cases, Definition 12 can be used to distinguish genuine from spurious causes without requiring that all causally relevant background factors be measurable.
Reference: [Suppes 70] <author> Suppes, P. </author> <title> A Probabilistic Theory of Causation. </title> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1970. </year>
Reference-contexts: X is a genuine cause of Z and Z is a genuine cause of Y . Definition 11 was formulated in [Pearl 90] as a relation between events (rather than variables) with the added condition P (Y jX) &gt; P (Y ) in the spirit of <ref> [Suppes 70] </ref>. Condition (1) in Definition 12 may be established either by statistical methods (per Definition 11) or by other sources of information e.g., experimental studies or temporal succession (i.e. that Z precedes X in time). When temporal information is available, as it is assumed in the formulations of [Suppes 70], <p> of <ref> [Suppes 70] </ref>. Condition (1) in Definition 12 may be established either by statistical methods (per Definition 11) or by other sources of information e.g., experimental studies or temporal succession (i.e. that Z precedes X in time). When temporal information is available, as it is assumed in the formulations of [Suppes 70], [Granger, 1987] and [Spohn, 1983], then every link constructed in step 1 of the IC-algorithm corresponds to a potential cause (genuine or spurious cause in Suppes terminology).
Reference: [Reichenbach 1956] <institution> The Direction of Time, Berkeley: University of California Press. </institution>
Reference: [Verma & Pearl 88] <author> Influence Diagrams and d-Separation, </author> <type> Technical Report R-101, </type> <institution> Cognitive Systems Laboratory, Computer Science Department, UCLA. </institution>
Reference-contexts: The search for the minimal model then boils down to recovering the structure of the underlying dag from probabilistic dependencies that perfectly reflect this structure (see <ref> [Verma & Pearl 88] </ref> for a characterization of these dependencies).
Reference: [Verma & Pearl 90] <author> Verma, T. S.; and Pearl J. </author> <title> Equivalence and Synthesis of Causal Models. </title> <booktitle> Proceedings 6th Conference on Uncertainty in AI, </booktitle> <address> Mass, </address> <month> July </month> <year> 1990, </year> <pages> 220-227. 8 </pages>
Reference-contexts: This search is exponential in general, but simplifies significantly when the underlying structure is sparse (see <ref> [Verma & Pearl 90] </ref> and [Spirtes and Glymour, 1991] for such algorithms). 4 Recovering Latent Structures When Nature decides to "hide" some variables, the observed distribution ^ P need no longer be stable relative to the observable set O, i.e. ^ P may result from many equivalent minimal latent structures, each
References-found: 19

