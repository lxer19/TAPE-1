URL: http://www.iro.umontreal.ca/~marcotte/ARTIPS/banach2.ps.gz
Refering-URL: http://www.iro.umontreal.ca/~marcotte/publi.html
Root-URL: http://www.iro.umontreal.ca
Title: CONVERGENCE PROPERTIES OF FEASIBLE DESCENT ALGORITHMS FOR SOLVING VARIATIONAL INEQUALITIES IN BANACH SPACES  
Author: Patrice MARCOTTE Daoli ZHU 
Keyword: Banach spaces, variational inequalities, Frank-Wolfe algorithm, global con vergence, projection.  
Date: January 9, 1997  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Auslender, A., </author> <title> Optimisation, </title> <publisher> Methodes numeriques, Masson, </publisher> <address> Paris (1976). </address>
Reference-contexts: Definition 2 A functional f : C X ! R is convex on C if there exists a nonnegative constant b such that, for all x, y in C and all ff in <ref> [0; 1] </ref>: f (ffx + (1 ff)y) fff (x) + (1 ff)f (y) 2 If b is positive, we say that f is strongly convex with modulus b. <p> Proof. (i) Under the optimal stepsize rule, one has that OE (x k+1 ) is a nonnegative decreasing sequence of real numbers. Let OE fl be its limiting value. We have, for all t 2 <ref> [0; 1] </ref>: OE (x k+1 ) OE (x k ) OE (x k + td k ) OE (x k ) = thOE 0 (x k ); d k i + thOE 0 () OE 0 (x k ); d k i tOE (x k ) + tDkOE 0 () OE <p> It is well known that the problem (71) is equivalent to the variational inequality problem hf 0 (x fl ); x x fl i 0: (72) Descent methods for solving optimization problems in infinite dimensional spaces have been addressed by several researchers, including Auslender <ref> [1] </ref>, Valadier [15] and Dunn [4] [5] (extension of Frank-Wolfe and projected gradient methods), Zhu and Marcotte [16] (coupling descent methods with the auxiliary problem principle). In particular, Dunn [5] has given the convergence properties of linearization and gradient projection algorithms.
Reference: [2] <author> Cohen, G., </author> <title> "Auxiliary problem principle and decomposition of optimization problems", </title> <note> Journal of Optimization Theory and Applications 32 (1980) 277-305. </note>
Reference-contexts: Next we show that several algorithms satisfy the given descent condition. These are: a variant of the Frank-Wolfe (conditional gradient) method, Fukushima's modified projection method [7], the general descent method of Zhu and Marcotte [17], and the auxiliary principle descent method <ref> [2] </ref> [16]. The first three of these methods have so far been only proposed for finite-dimensional spaces. The remainder of the paper will address the choice of the mapping Y and the stepsize t k . But first, let us recall some concepts that will be used throughout the paper.
Reference: [3] <author> Demyanov, V. F. and Rubinov, A. M., </author> <title> Approximate Methods in Optimization problems, </title> <publisher> American Elsevier, </publisher> <address> New York (1970). </address>
Reference: [4] <author> Dunn, J. C., </author> <title> "Conditional gradient algorithms with open loop step size rules", </title> <note> Journal of Mathematical Analysis and Applications 62 (1978) 432-444. </note>
Reference-contexts: Constant stepsize rule: t k = t 0 for all k. Open loop stepsize rule: t k 2 (0; 1] and: 1 X t k = 1 k=0 k &lt; 1: (14) As mentioned in Dunn <ref> [4] </ref> a sequence satisfying the assumptions of the open loop stepsize rule can be obtained through the recursion: t 0 = 1 k =2: (15) The following lemmas on real sequences will be used in the convergence proofs. <p> It is well known that the problem (71) is equivalent to the variational inequality problem hf 0 (x fl ); x x fl i 0: (72) Descent methods for solving optimization problems in infinite dimensional spaces have been addressed by several researchers, including Auslender [1], Valadier [15] and Dunn <ref> [4] </ref> [5] (extension of Frank-Wolfe and projected gradient methods), Zhu and Marcotte [16] (coupling descent methods with the auxiliary problem principle). In particular, Dunn [5] has given the convergence properties of linearization and gradient projection algorithms.
Reference: [5] <author> Dunn, J. C., </author> <title> "Global and asymtopic convergence rate estimates for a class of projected gradient processes", </title> <note> SIAM Journal on Control and Optimization 19 (1981) 368-400. </note>
Reference-contexts: It is well known that the problem (71) is equivalent to the variational inequality problem hf 0 (x fl ); x x fl i 0: (72) Descent methods for solving optimization problems in infinite dimensional spaces have been addressed by several researchers, including Auslender [1], Valadier [15] and Dunn [4] <ref> [5] </ref> (extension of Frank-Wolfe and projected gradient methods), Zhu and Marcotte [16] (coupling descent methods with the auxiliary problem principle). In particular, Dunn [5] has given the convergence properties of linearization and gradient projection algorithms. <p> i 0: (72) Descent methods for solving optimization problems in infinite dimensional spaces have been addressed by several researchers, including Auslender [1], Valadier [15] and Dunn [4] <ref> [5] </ref> (extension of Frank-Wolfe and projected gradient methods), Zhu and Marcotte [16] (coupling descent methods with the auxiliary problem principle). In particular, Dunn [5] has given the convergence properties of linearization and gradient projection algorithms.
Reference: [6] <author> Frank, M. and Wolfe, P., </author> <title> "An algorithm for quadratic programming", </title> <note> Naval Research Logistics Quartely 3 (1956) 95-110. </note>
Reference: [7] <author> Fukushima, M., </author> <title> "Equivalent differentiable optimization problems and descent method for asymmetric varational inequality problem", </title> <note> Mathematical Programming 53 (1992) 161-220. </note>
Reference-contexts: Next we show that several algorithms satisfy the given descent condition. These are: a variant of the Frank-Wolfe (conditional gradient) method, Fukushima's modified projection method <ref> [7] </ref>, the general descent method of Zhu and Marcotte [17], and the auxiliary principle descent method [2] [16]. The first three of these methods have so far been only proposed for finite-dimensional spaces. <p> In this latter work, an Armijo stepsize rule is proposed and its convergence properties analyzed. Numerical results on large scale multiclass traffic assignment problems are reported in Marcotte et al. [10]. 3.2 Extension of Fukushima's method For finite-dimensional, strongly monotone and continuously differentiable mappings, Fuku-shima <ref> [7] </ref> proposed the function: OE (x) = max hF (x); x yi 2ff The solution Y (x) of this maximization problem is unique and given by the projection of x ffF (x) onto the set C: Y (x) = Proj C (x ffF (x)): (68) The function OE is continuously differentiable.
Reference: [8] <author> Fukushima, M., </author> <title> "Merit functions for variational inequality and complementarity problems", forthcoming in Nonlinear Optimization and Applications. </title>
Reference-contexts: A solution can then be obtained by globally minimizing OE over C. Merit functions such as OE, differentiable or not, are sometimes referred to as gap functions, and have been given attention in the recent literature (see the surveys by Fukushima <ref> [8] </ref> and Larsson and Patriksson [9]).
Reference: [9] <author> Larsson, T. and Patriksson, M., </author> <title> "A class of gap functions for variational inequalities", </title> <note> Mathematical Programming 64 (1994) 53-79. </note>
Reference-contexts: A solution can then be obtained by globally minimizing OE over C. Merit functions such as OE, differentiable or not, are sometimes referred to as gap functions, and have been given attention in the recent literature (see the surveys by Fukushima [8] and Larsson and Patriksson <ref> [9] </ref>).
Reference: [10] <author> Marcotte, P., Nguyen, S. and Tanguay, K., </author> <title> "Implementation of an efficient algorithm for the multiclass traffic assignment problem", </title> <editor> in: J.-B. Lesort, ed.: </editor> <title> Transportation and Traffic Theory. </title> <booktitle> Proceedings of the 13th International Symposium on Transportation and Traffic Theory, </booktitle> <publisher> Pergamon, </publisher> <address> Oxford (1996) 217 - 236. </address> <month> 13 </month>
Reference-contexts: However it is satisfied naturally in the context of the multiclass variational inequality studied by Marcotte and Zhu [11]. In this latter work, an Armijo stepsize rule is proposed and its convergence properties analyzed. Numerical results on large scale multiclass traffic assignment problems are reported in Marcotte et al. <ref> [10] </ref>. 3.2 Extension of Fukushima's method For finite-dimensional, strongly monotone and continuously differentiable mappings, Fuku-shima [7] proposed the function: OE (x) = max hF (x); x yi 2ff The solution Y (x) of this maximization problem is unique and given by the projection of x ffF (x) onto the set C:
Reference: [11] <author> Marcotte, P. and Zhu, D. L., </author> <title> "On continuous multiclass problems", </title> <type> Report CRT 95--63, </type> <institution> Centre de recherche sur les transports, Universite de Montreal, </institution> <address> Montreal, Canada (1995). </address>
Reference-contexts: The condition that the mapping Y be single-valued is a strong one, and not likely to hold in finite-dimensional applications, unless the set C is strongly convex. However it is satisfied naturally in the context of the multiclass variational inequality studied by Marcotte and Zhu <ref> [11] </ref>. In this latter work, an Armijo stepsize rule is proposed and its convergence properties analyzed.
Reference: [12] <author> Marcotte, P. and Zhu, D. L., </author> <title> "Weak sharp solutions and finite convergence of algorithms for solving variational inequalities", </title> <type> preprint. </type>
Reference-contexts: The remainder of the proof is similar to that of Theorem 1. 2 We close this section by stating a finite convergence result, based on the notions of sharpness and pseudomonotonicity + , and established by Marcotte and Zhu <ref> [12] </ref>. <p> Theorem 4 (Marcotte and Zhu <ref> [12] </ref>) Let F be single-valued, pseudomonotone + , uniformly continuous on C and the solution x fl of the variational inequality (1) be sharp and unique. Then the algorithm generates a sequence fx k g converging to x fl .
Reference: [13] <author> Patriksson, M., </author> <title> "On the convergence of descent methods for monotone variational inequalities", </title> <note> Operations Research Letters 16 (1994) 265-269. </note>
Reference-contexts: If x fl is a sharp solution of the variational inequality, the convergence is finite. Remark. Convergence results for descent algorithms have been obtained under the weaker assumption that the mapping be monotone (see Zhu and Marcotte [18] and Patriksson <ref> [13] </ref>). However, the constraint C was required to be compact. It would be interesting to see if an equivalent result holds in infinite dimension. 3.3 A remark on optimization problems Let us consider the optimization problem min f (x) (71) where f is pseudoconvex and differentiable on C.
Reference: [14] <author> Polyak., B. T., </author> <title> "Introduction to Optimization", Optimization Software Inc., </title> <address> New York (1987). </address>
Reference-contexts: Lemma 3 (Polyak <ref> [14] </ref>) Let f* k g be a sequence of nonnegative numbers and fu k g a sequence of positive numbers such that: u k+1 u k * k u k (16) for some positive constant p.
Reference: [15] <author> Valadier, M., </author> <title> "Extension d'un algorithme de Frank-Wolfe", </title> <type> Revue Francaise de Recherche Operationnelle 36 (1965) 251-253. </type>
Reference-contexts: It is well known that the problem (71) is equivalent to the variational inequality problem hf 0 (x fl ); x x fl i 0: (72) Descent methods for solving optimization problems in infinite dimensional spaces have been addressed by several researchers, including Auslender [1], Valadier <ref> [15] </ref> and Dunn [4] [5] (extension of Frank-Wolfe and projected gradient methods), Zhu and Marcotte [16] (coupling descent methods with the auxiliary problem principle). In particular, Dunn [5] has given the convergence properties of linearization and gradient projection algorithms.
Reference: [16] <author> Zhu, D. L. and Marcotte, P., </author> <title> "Coupling the auxiliary problem principle with descent methods of pseudoconvex programming", </title> <note> European Journal of Operational Research 83 (1995) 670-685. </note>
Reference-contexts: Next we show that several algorithms satisfy the given descent condition. These are: a variant of the Frank-Wolfe (conditional gradient) method, Fukushima's modified projection method [7], the general descent method of Zhu and Marcotte [17], and the auxiliary principle descent method [2] <ref> [16] </ref>. The first three of these methods have so far been only proposed for finite-dimensional spaces. The remainder of the paper will address the choice of the mapping Y and the stepsize t k . But first, let us recall some concepts that will be used throughout the paper. <p> the variational inequality problem hf 0 (x fl ); x x fl i 0: (72) Descent methods for solving optimization problems in infinite dimensional spaces have been addressed by several researchers, including Auslender [1], Valadier [15] and Dunn [4] [5] (extension of Frank-Wolfe and projected gradient methods), Zhu and Marcotte <ref> [16] </ref> (coupling descent methods with the auxiliary problem principle). In particular, Dunn [5] has given the convergence properties of linearization and gradient projection algorithms.
Reference: [17] <author> Zhu, D. L. and Marcotte, P., </author> <title> "An extended descent framework for monotone variational inequalities," </title> <note> Journal of Optimization Theory and Applications 80 (1994) 349-366. </note>
Reference-contexts: Next we show that several algorithms satisfy the given descent condition. These are: a variant of the Frank-Wolfe (conditional gradient) method, Fukushima's modified projection method [7], the general descent method of Zhu and Marcotte <ref> [17] </ref>, and the auxiliary principle descent method [2] [16]. The first three of these methods have so far been only proposed for finite-dimensional spaces. The remainder of the paper will address the choice of the mapping Y and the stepsize t k .
Reference: [18] <author> Zhu, D. L. and Marcotte, P., </author> <title> "Modified descent methods for solving the monotone variational inequality problem", </title> <note> Operations Research Letters 14 (1993) 111-120. </note>
Reference-contexts: If x fl is a sharp solution of the variational inequality, the convergence is finite. Remark. Convergence results for descent algorithms have been obtained under the weaker assumption that the mapping be monotone (see Zhu and Marcotte <ref> [18] </ref> and Patriksson [13]). However, the constraint C was required to be compact.
Reference: [19] <author> Ekeland, I. and Temam, R., </author> <title> "Convex analysis and variational problems", </title> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, Holland (1970). </address> <month> 14 </month>
Reference-contexts: It is interesting to note that these results can be recovered using the techniques of the present paper, if one defines the functional OE as OE (x) = f (x) f (x fl ): If f is convex and continuous, f is also weakly lower semicontinuous, see <ref> [19] </ref>. Hence OE is naturally subweakly continuous in this context .
References-found: 19

