URL: http://www.isle.org/~gervasio/pub/aaai90.ps
Refering-URL: http://www.isle.org/~gervasio/compleat.html
Root-URL: 
Email: gervasio@cs.uiuc.edu  
Title: Learning General Completable Reactive Plans  
Author: Melinda T. Gervasio* 
Address: 405 N. Mathews Ave., Urbana, Illinois 61801  
Affiliation: Beckman Institute for Advanced Science and Technology University of Illinois at Urbana-Champaign  
Date: (1990)  
Note: Appears in the Proceedings of the Eighth National Conference on Artificial Intelligence  
Abstract: This paper presents an explanation-based learning strategy for learning general plans for use in an integrated approach to planning. The integrated approach augments a classical planner with the ability to defer achievable goals, thus preserving the construction of provably-correct plans while gaining the ability to utilize runtime information in planning. Proving achievability is shown to be possible without having to determine the actions to achieve the associated goals. A learning strategy called contingent explanation-based learning uses conjectured variables to represent the eventual values of plan parameters with unknown values a priori, and completors to determine these values during execution. An implemented system demonstrates the use of contingent EBL in learning a general completable reactive plan for spaceship acceleration. 
Abstract-found: 1
Intro-found: 1
Reference: [Agre87] <author> P. Agre and D. Chapman, Pengi: </author> <title> An Implementation of a Theory of Activity, </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: Provided a classical planner has perfect a priori knowledge, its plans are guaranteed to achieve the given goals. Unfortunately, real world domains can rarely be characterized perfectly. Reactive planning <ref> [Agre87, Firby87, Schoppers87, Suchman87] </ref> is an alternative approach which makes no predictions about the future and instead repeats a cycle of evaluating the environment and determining an appropriate action. Reactive planning thus solves the extended prediction problem faced by classical planning [Shoham86] simply by eliminating it.
Reference: [Blythe89] <author> J. Blythe and T. M. Mitchell, </author> <title> On Becoming Reactive, </title> <booktitle> Proceedings of The Sixth International Workshop on Machine Learning, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Furthermore, reactive planners must also be hand-tailored to achieve the desired behavior. Thus, while machine learning strategies have been successfully applied to classical planners in various domains [Chien89, Fikes72, Hammond86, Minton85], only preliminary work has been done in learning reactive rules <ref> [Blythe89, Schoppers87] </ref>. * This research was supported by the Office of Naval Research under grant N-00014-86-0309. The planning approach presented in this paper integrates classical planning and reactive planning to solve some of their limitations while retaining their merits. <p> The contingent explanation-based learning algorithm presented in this paper was developed to allow for the learning of general reactive plans for use in the integrated approach. Other work on learning to be reactive <ref> [Blythe89] </ref> has been on learning stimulus-response rules such as that used in reactive planning. The planning approach described in this paper presents an integration of classical planning and reactive planning which provides for the construction of completable reactive plans.
Reference: [Chapman87] <author> D. Chapman, </author> <title> Planning for Conjunctive Goals, </title> <booktitle> Artificial Intelligence 32, </booktitle> <month> 3 </month> <year> (1987). </year>
Reference-contexts: Introduction The planning problem may be characterized as the problem of determining an ordered sequence of actions which when executed from a given initial state will achieve a given goal. In classical planning <ref> [Chapman87, Fikes71, Stefik81] </ref>, plans are determined completely prior to execution by using inference to predict the effects of actions and essentially construct proofs of goal achievement. Provided a classical planner has perfect a priori knowledge, its plans are guaranteed to achieve the given goals.
Reference: [Chien89] <author> S. A. Chien, </author> <title> Using and Refining Simplifications: Explanation-based Learning of Plans in Intractable Domains, </title> <booktitle> Proceedings of The Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: Furthermore, reactive planners must also be hand-tailored to achieve the desired behavior. Thus, while machine learning strategies have been successfully applied to classical planners in various domains <ref> [Chien89, Fikes72, Hammond86, Minton85] </ref>, only preliminary work has been done in learning reactive rules [Blythe89, Schoppers87]. * This research was supported by the Office of Naval Research under grant N-00014-86-0309.
Reference: [Cohen89] <author> P. R. Cohen, M. L. Greenberg, D. M. Hart and A. E. Howe, </author> <title> Trial by Fire: Understanding the Design Requirements for Agents in Complex Environments, </title> <journal> Artificial Intelligence Magazine 10, </journal> <month> 3 </month> <year> (1989). </year>
Reference-contexts: However any monitoring and failure recovery capabilities applicable to a classical planner can also be incorporated into this approach. The idea of integrating a priori planning and reactivity has also been investigated in other work <ref> [Cohen89, Turney89] </ref>. The work presented in this paper differs primarily in that it focuses on the integration of planning and execution within a single plan rather than the integration of the planning and execution of multiple plans.
Reference: [DeJong86] <author> G. F. DeJong and R. J. Mooney, </author> <title> Explanation-Based Learning: An Alternative View, </title> <booktitle> Machine Learning 1, </booktitle> <month> 2 (April </month> <year> 1986). </year>
Reference-contexts: t2)) " (value q v2 t2)) (between v1 v0 v2) ) " [$ t1 (within t1 [t0 t2]) AND ( (qualitative_behavior q increasing (t0 t1)) " (value q v1 t1) ) ] ] v 1 v 2 for an increasing quantity. time quantity value from an example of the concept <ref> [DeJong86, Mitchell86] </ref>. EBL involves constructing an explanation for why a particular training example is an example of the goal concept, and then generalizing the explanation into a general functional definition of that concept or more general subconcepts.
Reference: [Fikes71] <author> R. E. Fikes and N. J. Nilsson, </author> <title> STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving, </title> <booktitle> Artificial Intelligence 2, </booktitle> <month> 3/4 </month> <year> (1971). </year>
Reference-contexts: Introduction The planning problem may be characterized as the problem of determining an ordered sequence of actions which when executed from a given initial state will achieve a given goal. In classical planning <ref> [Chapman87, Fikes71, Stefik81] </ref>, plans are determined completely prior to execution by using inference to predict the effects of actions and essentially construct proofs of goal achievement. Provided a classical planner has perfect a priori knowledge, its plans are guaranteed to achieve the given goals.
Reference: [Fikes72] <author> R. E. Fikes, P. E. Hart and N. J. Nilsson, </author> <title> Learning and Executing Generalized Robot Plans, </title> <booktitle> Artificial Intelligence 3, </booktitle> <month> 4 </month> <year> (1972). </year>
Reference-contexts: Furthermore, reactive planners must also be hand-tailored to achieve the desired behavior. Thus, while machine learning strategies have been successfully applied to classical planners in various domains <ref> [Chien89, Fikes72, Hammond86, Minton85] </ref>, only preliminary work has been done in learning reactive rules [Blythe89, Schoppers87]. * This research was supported by the Office of Naval Research under grant N-00014-86-0309. <p> This work relates in different ways to other work in various research areas. The problems arising from imperfect a priori knowledge in classical planning was recognized as early as the STRIPS system, whose PLANEX component employed an execution algorithm which adapted predetermined plans to the execution environment <ref> [Fikes72] </ref>. Later work such as [Wilkins88] further addresses the problem of execution monitoring and failure recovery. The integrated approach to planning presented in this paper currently monitors execution only to complete the partial plans constructed prior to execution.
Reference: [Firby87] <author> R. J. Firby, </author> <title> An Investigation into Reactive Planning in Complex Domains, </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: Provided a classical planner has perfect a priori knowledge, its plans are guaranteed to achieve the given goals. Unfortunately, real world domains can rarely be characterized perfectly. Reactive planning <ref> [Agre87, Firby87, Schoppers87, Suchman87] </ref> is an alternative approach which makes no predictions about the future and instead repeats a cycle of evaluating the environment and determining an appropriate action. Reactive planning thus solves the extended prediction problem faced by classical planning [Shoham86] simply by eliminating it.
Reference: [Forbus84] <author> K. D. Forbus, </author> <title> Qualitative Process Theory, </title> <booktitle> Artificial Intelligence 24, </booktitle> <year> (1984). </year>
Reference-contexts: Else Signal FAILURE. Example A system written in Common LISP and running on an IBM RT Model 125 implements the integrated approach to planning and learning reactive operators. The system uses a simple interval-based representation and borrows simple qualitative reasoning concepts from Qualitative Process Theory <ref> [Forbus84] </ref>. The system is thus able to reason about quantity values at time points as well as quantity behaviors over time intervals.
Reference: [Hammond86] <author> K. Hammond, </author> <title> Learning to Anticipate and Avoid Planning Failures through the Explanation of Failures, </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Philadel-phia, PA, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: Furthermore, reactive planners must also be hand-tailored to achieve the desired behavior. Thus, while machine learning strategies have been successfully applied to classical planners in various domains <ref> [Chien89, Fikes72, Hammond86, Minton85] </ref>, only preliminary work has been done in learning reactive rules [Blythe89, Schoppers87]. * This research was supported by the Office of Naval Research under grant N-00014-86-0309.
Reference: [Minton85] <author> S. Minton, </author> <title> Selectively Generalizing Plans for Problem-Solving, </title> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Angeles, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: Furthermore, reactive planners must also be hand-tailored to achieve the desired behavior. Thus, while machine learning strategies have been successfully applied to classical planners in various domains <ref> [Chien89, Fikes72, Hammond86, Minton85] </ref>, only preliminary work has been done in learning reactive rules [Blythe89, Schoppers87]. * This research was supported by the Office of Naval Research under grant N-00014-86-0309.
Reference: [Mitchell86] <author> T. M. Mitchell, R. Keller and S. Kedar-Cabelli, </author> <title> Explanation-Based Generalization: A Unifying View, </title> <booktitle> Machine Learning 1, </booktitle> <month> 1 (January </month> <year> 1986). </year>
Reference-contexts: t2)) " (value q v2 t2)) (between v1 v0 v2) ) " [$ t1 (within t1 [t0 t2]) AND ( (qualitative_behavior q increasing (t0 t1)) " (value q v1 t1) ) ] ] v 1 v 2 for an increasing quantity. time quantity value from an example of the concept <ref> [DeJong86, Mitchell86] </ref>. EBL involves constructing an explanation for why a particular training example is an example of the goal concept, and then generalizing the explanation into a general functional definition of that concept or more general subconcepts.
Reference: [Mooney86] <author> R. J. Mooney and S. W. Bennett, </author> <title> A Domain Independent Explanation-Based Generalizer, </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: In planning, explanation and generalization may be carried out over situations and actions to yield macro-operators or general control rules. Here, we are interested in learning macro-operators or general plans. Reactive plans present a problem for standard explanation-based learning <ref> [Mooney86] </ref>. Imagine the problem of learning how to cross. After the presentation of an example, an explanation for how the crosser got to the other side of the street may be that the crossing took place through some suitably-sized gap between two cars. <p> The system also uses a modified EGGS algorithm <ref> [Mooney86] </ref> in constructing and generalizing contingent explanations. The system is given the task of learning how to achieve a particular goal velocity higher than some initial velocity-- i.e. acceleration.
Reference: [Schoppers87] <author> M. J. Schoppers, </author> <title> Universal Plans for Reactive Robots in Unpredictable Environments, </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <month> August </month> <year> 1987. </year>
Reference-contexts: Provided a classical planner has perfect a priori knowledge, its plans are guaranteed to achieve the given goals. Unfortunately, real world domains can rarely be characterized perfectly. Reactive planning <ref> [Agre87, Firby87, Schoppers87, Suchman87] </ref> is an alternative approach which makes no predictions about the future and instead repeats a cycle of evaluating the environment and determining an appropriate action. Reactive planning thus solves the extended prediction problem faced by classical planning [Shoham86] simply by eliminating it. <p> Furthermore, reactive planners must also be hand-tailored to achieve the desired behavior. Thus, while machine learning strategies have been successfully applied to classical planners in various domains [Chien89, Fikes72, Hammond86, Minton85], only preliminary work has been done in learning reactive rules <ref> [Blythe89, Schoppers87] </ref>. * This research was supported by the Office of Naval Research under grant N-00014-86-0309. The planning approach presented in this paper integrates classical planning and reactive planning to solve some of their limitations while retaining their merits.
Reference: [Shoham86] <author> Y. Shoham, </author> <title> Reasoning about Change: Time and Causation from the Standpoint of Artificial Intelligence, </title> <type> PhD. Thesis, </type> <institution> Yale University, Dept. of Computer Science, </institution> <address> New Haven, CT, </address> <year> 1986. </year>
Reference-contexts: Reactive planning [Agre87, Firby87, Schoppers87, Suchman87] is an alternative approach which makes no predictions about the future and instead repeats a cycle of evaluating the environment and determining an appropriate action. Reactive planning thus solves the extended prediction problem faced by classical planning <ref> [Shoham86] </ref> simply by eliminating it. Because reactive planning is essentially a hill-climbing approach, however, one wrong reaction may delay or prevent a reactive planner from achieving its goals. Furthermore, reactive planners must also be hand-tailored to achieve the desired behavior.
Reference: [Stefik81] <author> M. Stefik, </author> <title> Planning and Metaplanning (MOL-GEN: </title> <booktitle> Part 2), Artificial Intelligence 16, </booktitle> <month> 2 </month> <year> (1981). </year>
Reference-contexts: Introduction The planning problem may be characterized as the problem of determining an ordered sequence of actions which when executed from a given initial state will achieve a given goal. In classical planning <ref> [Chapman87, Fikes71, Stefik81] </ref>, plans are determined completely prior to execution by using inference to predict the effects of actions and essentially construct proofs of goal achievement. Provided a classical planner has perfect a priori knowledge, its plans are guaranteed to achieve the given goals.
Reference: [Suchman87] <author> L. A. Suchman, </author> <title> Plans and Situated Actions, </title> <publisher> Cam-bridge University Press, </publisher> <address> Cambridge, </address> <year> 1987. </year>
Reference-contexts: Provided a classical planner has perfect a priori knowledge, its plans are guaranteed to achieve the given goals. Unfortunately, real world domains can rarely be characterized perfectly. Reactive planning <ref> [Agre87, Firby87, Schoppers87, Suchman87] </ref> is an alternative approach which makes no predictions about the future and instead repeats a cycle of evaluating the environment and determining an appropriate action. Reactive planning thus solves the extended prediction problem faced by classical planning [Shoham86] simply by eliminating it.
Reference: [Turney89] <author> J. Turney and A. Segre, SEPIA: </author> <title> An Experiment in Integrated Planning and Improvisation, </title> <booktitle> Proceedings of The American Association for Artificial Intelligence Spring Symposium on Planning and Search, </booktitle> <month> March </month> <year> 1989. </year>
Reference-contexts: However any monitoring and failure recovery capabilities applicable to a classical planner can also be incorporated into this approach. The idea of integrating a priori planning and reactivity has also been investigated in other work <ref> [Cohen89, Turney89] </ref>. The work presented in this paper differs primarily in that it focuses on the integration of planning and execution within a single plan rather than the integration of the planning and execution of multiple plans.
Reference: [Wilkins88] <author> D. E. Wilkins, </author> <title> Practical Planning: Extending the Classical Artificial Intelligence Planning Paradigm, </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: The problems arising from imperfect a priori knowledge in classical planning was recognized as early as the STRIPS system, whose PLANEX component employed an execution algorithm which adapted predetermined plans to the execution environment [Fikes72]. Later work such as <ref> [Wilkins88] </ref> further addresses the problem of execution monitoring and failure recovery. The integrated approach to planning presented in this paper currently monitors execution only to complete the partial plans constructed prior to execution.
References-found: 20

