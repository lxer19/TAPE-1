URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/TM205.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts95.htm
Root-URL: http://www.mcs.anl.gov
Title: Nexus: Runtime Support for Task-Parallel Programming Languages  
Author: by Ian Foster, Carl Kesselman, and Steven Tuecke 
Note: (draft)  
Date: February 1995  
Web: ANL/MCS-TM-205  
Address: 9700 South Cass Avenue Argonne, IL 60439  
Affiliation: ARGONNE NATIONAL LABORATORY  Mathematics and Computer Science Division  
Pubnum: Technical Memorandum No. 205  
Abstract: This work was supported by the Office of Scientific Computing, U.S. Department of Energy, under Contract W-31-109-Eng-38, and by the National Science Foundation's Center for Research in Parallel Computation under Contract CCR-8809615. fl Dept. of Computer Science, California Institute of Technology, Pasadena, CA 91125. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Z. Bozkus, Alok Choudhary, Geoffrey C. Fox, T. Haupt, and S. Ranka. </author> <title> Fortran 90D/HPF compiler for distributed memory MIMD computers: Design, implementation, and performance results. </title> <booktitle> In Proc. Supercomputing '93. IEEE, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: These are designed for programmer use and are not necessarily good compiler targets. In particular, the focus on process-based rather than thread-based communication causes difficulty for task-parallel languages. Two representative runtime systems layered on top of a send/receive model are the HPF runtime of Bozkus et al. <ref> [1] </ref> and CHAOS [21]. Both support an SPMD programming model. In Bozkus et al.'s runtime, the focus is on providing efficient support for collective operations on distributed arrays. Services include rotation of a matrix by row and column and broadcast along specific dimensions.
Reference: [2] <author> Peter Buhr and R. Stroobosscher. </author> <title> The system: Providing light-weight con-currency on shared-memory multiprocessor systems running Unix. </title> <journal> Software Practice and Experience, </journal> <pages> pages 929-964, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The drawback to this approach is that POSIX was designed as an application program interface, with features such as real-time scheduling support that may add overhead for parallel systems. A lower-level interface designed specifically as a compiler target would most likely result in better performance <ref> [2, 9] </ref> and will be investigated in future research. To summarize, the mapping of computation to physical processors is determined by both the mapping of threads to contexts and the mapping of contexts to nodes. The relationship between nodes, contexts, and threads is illustrated in Fig. 1. Global Pointers.
Reference: [3] <author> R. Butler and E. Lusk. </author> <title> Monitors, message, and clusters: The p4 parallel programming system. </title> <note> Parallel Computing (to appear), </note> <year> 1994. </year>
Reference-contexts: Consequently, it is straightforward for a compiler to place a corresponding receive in the generated code. The send/receive model is supported by a variety of machine-specific and portable communication libraries, including NX, p4, PVM, and MPI <ref> [3, 11, 8] </ref>. These are designed for programmer use and are not necessarily good compiler targets. In particular, the focus on process-based rather than thread-based communication causes difficulty for task-parallel languages. <p> P4 has several special multiprotocol implementations, such as a version for the Paragon that allows the nodes to use both NX and TCP <ref> [3] </ref>. But it does not allow arbitrary mixing of protocols. 4 Nexus as a Compiler Target Nexus is currently being used as the runtime system for two different programming languages: CC ++ and FM. Although both languages provide a task-parallel programming model, they have very different characteristics.
Reference: [4] <author> K. Mani Chandy and Carl Kesselman. </author> <title> CC ++ : A declarative concurrent object oriented programming notation. In Research Directions in Object Oriented Programming. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Rather than present a comprehensive discussion of compilation strategies, our goal is to present representative examples that illustrate the correspondence between Nexus features and the runtime requirements of these languages. 9 4.1 Compiling CC ++ Using Nexus CC ++ <ref> [4, 5] </ref> is a general-purpose parallel programming comprising all of C ++ plus six new keywords.
Reference: [5] <author> K. Mani Chandy and Carl Kesselman. </author> <title> Compositional C ++ : Compositional parallel programming. </title> <booktitle> In Proc. Fifth Int'l Workshop on Parallel Languages and Compilers. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Rather than present a comprehensive discussion of compilation strategies, our goal is to present representative examples that illustrate the correspondence between Nexus features and the runtime requirements of these languages. 9 4.1 Compiling CC ++ Using Nexus CC ++ <ref> [4, 5] </ref> is a general-purpose parallel programming comprising all of C ++ plus six new keywords.
Reference: [6] <author> Barbra Chapman, Piyush Mehrotra, and Hans Zima. </author> <title> Programming in Vienna Fortran. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 31-50, </pages> <year> 1992. </year>
Reference-contexts: Most existing runtime systems support the single-program, multiple-data (SPMD) programming model used to implement data-parallel languages such as High Performance Fortran (HPF) [10], Fortran-D [18], Vienna Fortran <ref> [6] </ref>, and pC ++ [17]. In this model, each processor in a parallel computer executes a copy of the same program.
Reference: [7] <editor> David Culler et al. </editor> <booktitle> Parallel programming in Split-C. In Proc. Supercomputing '93. ACM, </booktitle> <year> 1993. </year>
Reference-contexts: As an example, a handler that implements the get and put operations found in Split-C <ref> [7] </ref> can take advantage of this optimization. 3.2 Implementation In our description of the Nexus implementation, we focus on the techniques used to support execution in heterogeneous environments: in particular, to support multiple communication protocols.
Reference: [8] <author> J. Dongarra, G. Geist, R. Manchek, and V. Sunderam. </author> <title> Integrated PVM framework supports heterogeneous network computing. </title> <booktitle> In Computers in Physics, </booktitle> <month> April </month> <year> 1993. </year> <month> 16 </month>
Reference-contexts: Consequently, it is straightforward for a compiler to place a corresponding receive in the generated code. The send/receive model is supported by a variety of machine-specific and portable communication libraries, including NX, p4, PVM, and MPI <ref> [3, 11, 8] </ref>. These are designed for programmer use and are not necessarily good compiler targets. In particular, the focus on process-based rather than thread-based communication causes difficulty for task-parallel languages. <p> During a remote service request, data can be transferred between contexts by the use of a buffer. Data is inserted into a buffer and removed from a buffer through the use of packing and unpacking functions similar to those found in PVM and MPI <ref> [8, 11] </ref>. Invoking a remote service request is a three-step process: 1. The remote service request is initialized by providing a global pointer to an address in the destination context and the identifier for the handler in the remote context. A buffer is returned from the initialization operation. 2. <p> Although some existing message-passing systems support limited network heterogeneity, none do so with the same generality. For example, PVM3 allows processors in a parallel computer to communicate with external computers by sending messages to the pvmd daemon process which acts as a message forwarder <ref> [8] </ref>. However, this approach is not optimal on machines such as the IBM SP1 and the Intel Paragon, whose nodes are able to support TCP directly, and it limits PVM programs to using just one protocol in addition to TCP. <p> Watson Research Center to explore this possibility.) The experiments reported here compare the performance of a CC ++ program compiled to use Nexus and a similar C ++ program using PVM <ref> [8] </ref> for communication. The CC ++ program uses a function call through a CC ++ global pointer to transfer an array of double-precision floating-point numbers between two processor objects (Nexus contexts).
Reference: [9] <author> D. Engler, G. Andrews, and D. Lowenthal. Filaments: </author> <title> Efficient support for fine-grained parallelism. </title> <type> Technical Report 93-13, </type> <institution> Dept. of Computer Science, U. Arizona, Tuscon, Ariz., </institution> <year> 1993. </year>
Reference-contexts: The drawback to this approach is that POSIX was designed as an application program interface, with features such as real-time scheduling support that may add overhead for parallel systems. A lower-level interface designed specifically as a compiler target would most likely result in better performance <ref> [2, 9] </ref> and will be investigated in future research. To summarize, the mapping of computation to physical processors is determined by both the mapping of threads to contexts and the mapping of contexts to nodes. The relationship between nodes, contexts, and threads is illustrated in Fig. 1. Global Pointers.
Reference: [10] <author> High Performance Fortran Forum. </author> <title> High performance Fortran language specification, version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Center for Research on Parallel Computation, Rice University, Houston, Texas, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Most existing runtime systems support the single-program, multiple-data (SPMD) programming model used to implement data-parallel languages such as High Performance Fortran (HPF) <ref> [10] </ref>, Fortran-D [18], Vienna Fortran [6], and pC ++ [17]. In this model, each processor in a parallel computer executes a copy of the same program.
Reference: [11] <author> Message Passing Interface Forum. </author> <title> Document for a standard messge-passing interface, </title> <month> March </month> <year> 1994. </year> <note> (available from netlib). </note>
Reference-contexts: Consequently, it is straightforward for a compiler to place a corresponding receive in the generated code. The send/receive model is supported by a variety of machine-specific and portable communication libraries, including NX, p4, PVM, and MPI <ref> [3, 11, 8] </ref>. These are designed for programmer use and are not necessarily good compiler targets. In particular, the focus on process-based rather than thread-based communication causes difficulty for task-parallel languages. <p> During a remote service request, data can be transferred between contexts by the use of a buffer. Data is inserted into a buffer and removed from a buffer through the use of packing and unpacking functions similar to those found in PVM and MPI <ref> [8, 11] </ref>. Invoking a remote service request is a three-step process: 1. The remote service request is initialized by providing a global pointer to an address in the destination context and the identifier for the handler in the remote context. A buffer is returned from the initialization operation. 2.
Reference: [12] <author> I. Foster, B. Avalani, A. Choudhary, and M. Xu. </author> <title> A compilation system that integrates High Performance Fortran and Fortran M. </title> <booktitle> In Proc. 1994 Scalable High Performance Computing Conf. IEEE, </booktitle> <year> 1994. </year> <note> to appear. </note>
Reference-contexts: FM is designed to support both the modular construction of large parallel programs and the development of libraries implementing other programming paradigms. For example, in a joint project with Syracuse, such a library has been used to integrate HPF programs into a task-parallel framework <ref> [12] </ref>. FM programs can dynamically create and destroy processes, single-reader/single-writer channels, and multiple-writer, single-reader mergers. Processes can encapsulate state (common data) and communicate by sending and receiving messages on channels and mergers; references to channels, called ports, can be transferred between processes in messages.
Reference: [13] <author> Ian Foster and K. Mani Chandy. </author> <title> Fortran M: A language for modular parallel programming. </title> <journal> J. Parallel and Distributed Computing, </journal> <note> 1994. to appear. </note>
Reference-contexts: Because remote service requests are unidirectional, the CC ++ compiler can detect when a return value is not required and optimize out the return remote service request. 4.2 Compiling FM Using Nexus FM <ref> [13, 15] </ref> is a small set of extensions to Fortran 77 for task-parallel programming. FM is designed to support both the modular construction of large parallel programs and the development of libraries implementing other programming paradigms.
Reference: [14] <author> Ian Foster, Carl Kesselman, Robert Olson, and Steve Tuecke. </author> <title> Nexus: An interoperability toolkit for parallel and distributed computer systems. </title> <type> Technical Report ANL/MCS-TM-189, </type> <institution> Argonne National Laboratory, </institution> <year> 1994. </year>
Reference-contexts: We expect to examine these issues in future research. 3.1 Core Abstractions The Nexus interface is organized around five basic abstractions: nodes, contexts, threads, global pointers, and remote service requests. The associated services provide direct support for light-weight threading, address space management, communication, and synchronization <ref> [14] </ref>. A computation consists of a set of threads, each executing in an address space called a context. An individual thread executes a sequential program, which may read and write data shared with other threads 4 executing in the same context.
Reference: [15] <author> Ian Foster, Bob Olson, and Steve Tuecke. </author> <title> Programming in Fortran M. </title> <type> Technical Report ANL-93/26, </type> <institution> Argonne National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: Because remote service requests are unidirectional, the CC ++ compiler can detect when a return value is not required and optimize out the return remote service request. 4.2 Compiling FM Using Nexus FM <ref> [13, 15] </ref> is a small set of extensions to Fortran 77 for task-parallel programming. FM is designed to support both the modular construction of large parallel programs and the development of libraries implementing other programming paradigms.
Reference: [16] <author> Ian Foster and Stephen Taylor. </author> <title> A compiler approach to scalable concurrent program design. </title> <journal> ACM TOPLAS, </journal> <note> 1994. to appear. </note>
Reference-contexts: An alternative approach is to define an abstract machine that defines the runtime environment. An abstract machine provides an instruction set tailored to compilation of the parallel language; the compiler translates programs into this instruction set. Examples include the Program Composition Machine (PCM) <ref> [16] </ref> and the Threaded Abstract Machine (TAM) [23]. PCM was designed as a compilation target for the task-parallel language PCN. It provides task creation, memory management via distributed garbage collection, synchronization via data-flow variables, and data transfer functions.
Reference: [17] <author> Dennis Gannon et al. </author> <title> Implementing a parallel C++ runtime system for scalable parallel systems. </title> <booktitle> In Proc. Supercomputing '93, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: Most existing runtime systems support the single-program, multiple-data (SPMD) programming model used to implement data-parallel languages such as High Performance Fortran (HPF) [10], Fortran-D [18], Vienna Fortran [6], and pC ++ <ref> [17] </ref>. In this model, each processor in a parallel computer executes a copy of the same program.
Reference: [18] <author> Seema Hiranandani, Ken Kenedy, and Chau-Wen Tseng. </author> <title> Compiling Fortran D for MIMD distributed memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Most existing runtime systems support the single-program, multiple-data (SPMD) programming model used to implement data-parallel languages such as High Performance Fortran (HPF) [10], Fortran-D <ref> [18] </ref>, Vienna Fortran [6], and pC ++ [17]. In this model, each processor in a parallel computer executes a copy of the same program.
Reference: [19] <author> C.A.R Hoare. </author> <title> Monitors: An operating system structuring concept. </title> <journal> Communications of the ACM, </journal> <volume> 17(10) </volume> <pages> 549-557, </pages> <month> October </month> <year> 1974. </year>
Reference-contexts: Threads waiting for the value of a sync variable block on the condition variable. Atomic functions provide a means for controlling the scheduling of threads. An atomic function is like a monitor <ref> [19] </ref>. Within an instance of a given C ++ class, only one atomic function is allowed to execute at a time. Atomic functions are implemented by requiring that they obtain a Nexus mutex prior to executing the function body. Managing Processing Resources.
Reference: [20] <author> IEEE. </author> <title> Threads extension for portable operating systems (draft 6), </title> <month> February </month> <year> 1992. </year>
Reference-contexts: The thread routines in Nexus are modeled 5 N O D E N O D E Context TT T T T T T Context Context after a subset of the POSIX thread specification <ref> [20] </ref>. The operations supported include thread creation, termination, and yielding the current thread. Mutexes and condition variables are also provided for synchronization between threads within a context.
Reference: [21] <author> Ravi Ponnusamy, Joel Saltz, and Alok Choudhary. </author> <title> Runtime-compilation techniques for data partitioning and communication schedule reuse. </title> <institution> Computer Science Technical Report CS-TR-3055, University of Maryland, </institution> <year> 1993. </year> <month> 17 </month>
Reference-contexts: In particular, the focus on process-based rather than thread-based communication causes difficulty for task-parallel languages. Two representative runtime systems layered on top of a send/receive model are the HPF runtime of Bozkus et al. [1] and CHAOS <ref> [21] </ref>. Both support an SPMD programming model. In Bozkus et al.'s runtime, the focus is on providing efficient support for collective operations on distributed arrays. Services include rotation of a matrix by row and column and broadcast along specific dimensions.
Reference: [22] <author> Thorsten von Eicken, David Culler, Seth Copen Goldstein, and Klaus Erik Schauser. </author> <title> Active messages: a mechanism for integrated communication and computation. </title> <booktitle> In Proc. 19th Int'l Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: Because communication is between threads, not nodes, and can take place asynchronously, it can be difficult for a compiler to place receive operations. In addition, few existing send/receive libraries are thread safe. A promising alternative model is active messages <ref> [22] </ref>. Here, a sender specifies the data that is to be transferred and the address of a compiler-generated active message handler that will process the data. When the data arrives at the destination processor, an interrupt is generated and the specified handler is executed as the interrupt handler. <p> A remote service request is not a remote procedure call, because there is no acknowledgement or return value from the call, and the thread that initiated the request does not block. Remote service requests are similar in some respects to active messages <ref> [22] </ref>. They also differ in significant ways, however. Because active message handlers are designed to execute within an interrupt handler, there are restrictions on the ways in which they can modify the environment of a node. For example, they cannot call memory allocation routines.
Reference: [23] <author> Thorsten von Eicken, David Culler, Seth Copen Goldstein, and Klaus Erik Schauser. </author> <title> TAM | a compiler controlled threaded abstract machine. </title> <journal> J. Parallel and Distributed Computing, </journal> <year> 1992. </year> <month> 18 </month>
Reference-contexts: An abstract machine provides an instruction set tailored to compilation of the parallel language; the compiler translates programs into this instruction set. Examples include the Program Composition Machine (PCM) [16] and the Threaded Abstract Machine (TAM) <ref> [23] </ref>. PCM was designed as a compilation target for the task-parallel language PCN. It provides task creation, memory management via distributed garbage collection, synchronization via data-flow variables, and data transfer functions. TAM was designed to support the compilation of the data-flow language ID 90. <p> We are also interested in the performance implications of the POSIX-based thread interface, and the potential benefits of lower-level interfaces or lighter-weight threads. Finally, we wish to investigate the locality properties of compiler-generated Nexus code, to determine whether a hierarchical scheduling mechanism such as found in TAM <ref> [23] </ref> can improve performance. Acknowledgments We are grateful to Bob Olson and James Patton for their considerable input to the Nexus design and implementation. The FM runtime support was designed and implemented by Robert Olson, and the NX protocol module by Tal Lancaster.
References-found: 23

