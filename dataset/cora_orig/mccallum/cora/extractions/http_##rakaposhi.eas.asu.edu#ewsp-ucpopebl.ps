URL: http://rakaposhi.eas.asu.edu/ewsp-ucpopebl.ps
Refering-URL: http://rakaposhi.eas.asu.edu/yochan.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: fyqu, raog@asu.edu  
Title: Learning Search Control rules for Plan-space Planners: Factors affecting the performance  
Author: Yong Qu and Subbarao Kambhampati 
Note: Appears in Current Trends in AI Planning: EWSP '95, IOS Press  
Web: WWW: http://rakaposhi.eas.asu.edu:8001/yochan.html  
Address: Tempe, AZ 85287-5406  
Affiliation: Department of Computer Science and Engineering, Arizona State University,  
Abstract: Given the intractability of domain-independent planning, learning effective search control knowledge is vitally important. One way of learning search control knowledge is to use explanation based learning (EBL) methods. This paper aims to analyze and understand the factors influencing the effectiveness of EBL. We present an EBL framework for UCPOP, a partial order planner, and use it to systematically analyze the effect of (i) expressive action representations (ii) domain specific failure theories and (iii) sophisticated backtracking strategies on the utility of EBL. Through empirical studies, we demonstrate that expressive action representations allow for more explicit domain representations which in turn increase the ability of EBL to learn from analytical failures, and obviate the need for domain specific failure theories. We also explore the strong affinity between dependency directed backtracking and EBL in planning.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Bhatnagar and J. Mostow. </author> <title> On-line Learning From Search Failures Machine Learning, </title> <journal> Vol. </journal> <volume> 15, </volume> <pages> pp. 69-117, </pages> <year> 1994. </year>
Reference-contexts: One way of doing this involves learning search control rules to customize the planner's search to the expected problem population. Control rule learning has originally been developed in the context of state space planning <ref> [8, 1] </ref>. More recently, we extended it to plan-space planners [6], and developed SNLP+EBL, which learns control rules for the partial order planner SNLP. <p> They include inconsistent orderings (e.g. (s 1 s 2 ); (s 2 s 1 ) 2 O) , inconsistent bindings (e.g. (x y); (x 6 y) 2 B), inconsistent preconditions (e.g. p@s 1 ; :p@s 1 2 A), and inconsistent effects (e.g. inittrue (x); inittrue (:x)). As discussed in <ref> [6, 1] </ref>, these analytical failures alone are not enough to detect and terminate every failing branch before they cross search depth limits. In such cases, UCPOP+EBL can utilize any available domain specific failure theories to analyze implicit failures in the plans crossing depth limits. <p> This in turn depends on the nature of the domain theory (viz, how much information is left implicit and how much is represented explicitly), and the availability of domain specific theories of failure (c.f. <ref> [6, 1] </ref>). Finally, availability of sophisticated dependency directed backtracking strategies can directly compete with the performance improvements produced through learned control rules. We have used our implementation of UCPOP+EBL to investigate the effect of these factors. In this section, we will describe the results from these studies, and analyze them.
Reference: [2] <author> R. Dechter. </author> <title> Enhancement schemes for learning: Backjumping, learning and cutset decomposition. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 41, </volume> <pages> pp. 273-312, </pages> <year> 1990. </year>
Reference-contexts: This is not surprising since lack of detectable analytical failures will hurt both the effectiveness of ddb and that of EBL. (Similar relation has been observed in the constraint satisfaction literature between backjumping and learning <ref> [2] </ref>). 4 Conclusion Learning search control rules for plan-space planning is an important problem that has received relatively little attention. This paper presents an empirical analysis of the factors that influence the effectiveness of explanation based search control rule learning for partial order planners.
Reference: [3] <author> D. Joslin and M. Pollack. </author> <title> Least-cost flaw repair: A plan refinement strategy for partial order planning. </title> <booktitle> Proceedings of AAAI-94, </booktitle> <year> 1994. </year>
Reference-contexts: Since it is well-known that the performance of a plan-space planner depends critically on the order in which open condition flaws are handled (goal selection order) <ref> [3] </ref>, we experimented with two goal-selection strategies -- one which corresponds to a LIFO strategy and one that works on goals with the least number of variable left uninstantiated (mimicking the least-cost flaw refinement strategy, [3]). Results: Table 2 shows the statistics from these experiments. <p> depends critically on the order in which open condition flaws are handled (goal selection order) <ref> [3] </ref>, we experimented with two goal-selection strategies -- one which corresponds to a LIFO strategy and one that works on goals with the least number of variable left uninstantiated (mimicking the least-cost flaw refinement strategy, [3]). Results: Table 2 shows the statistics from these experiments. The performance of the base level planner varies considerably across the three domains and the two goal selection strategies.
Reference: [4] <author> D. McAllester and D. </author> <booktitle> Rosenblitt Systematic Nonliner Planning In Proceedings of AAAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: Finally, Section 4 presents our conclusions. A more detailed description of the design and analysis of UCPOP+EBL can be found in [7]. That paper also explains in detail the differences between SNLP+EBL [6] and UCPOP+EBL. 2 Overview of UCPOP+EBL 2.1 Base level Planner: UCPOP Like SNLP <ref> [4] </ref>, UCPOP [14] searches in a space of partial plans, refining (adding constraints to) a partial plan until it becomes a complete solution to the planning problem.
Reference: [5] <author> S. Kambhampati and S. Kedar. </author> <title> A unified framework for explanation-based generalization of partially ordered and partially instantiated plans Artificial Intelligence, </title> <journal> Vol. </journal> <volume> 67, No. 1, </volume> <year> 1994. </year>
Reference: [6] <author> S. Katukam and S. Kambhampati. </author> <title> Learning Explanation-based Search Control Rules For Partial Order Planning In Proceedings of AAAI-94, </title> <year> 1994 </year>
Reference-contexts: One way of doing this involves learning search control rules to customize the planner's search to the expected problem population. Control rule learning has originally been developed in the context of state space planning [8, 1]. More recently, we extended it to plan-space planners <ref> [6] </ref>, and developed SNLP+EBL, which learns control rules for the partial order planner SNLP. Although our work with SNLP+EBL [6] showed that control rule learning is an effective way of improving the performance of a plan space planner, it also brought up the critical dependencies between the effectiveness of control rule <p> Control rule learning has originally been developed in the context of state space planning [8, 1]. More recently, we extended it to plan-space planners <ref> [6] </ref>, and developed SNLP+EBL, which learns control rules for the partial order planner SNLP. Although our work with SNLP+EBL [6] showed that control rule learning is an effective way of improving the performance of a plan space planner, it also brought up the critical dependencies between the effectiveness of control rule learning, and a variety of other fl This research is supported in part by NSF research initiation award (RIA) <p> Section 2 contains an overview of the learning framework used in UCPOP+EBL. Apart from reviewing the details of the base level planner, and the way control rules are synthesized and generalized from failures detected during search (which is a straightforward extension of SNLP+EBL algorithm described in <ref> [6] </ref>), the overview will also bring out the connections between EBL, dependency directed backtracking and domain representation. Section 3 provides an evaluation of UCPOP+EBL and also describes the results of a focussed empirical study to analyze the factors affecting the performance of UCPOP+EBL. Finally, Section 4 presents our conclusions. <p> Finally, Section 4 presents our conclusions. A more detailed description of the design and analysis of UCPOP+EBL can be found in [7]. That paper also explains in detail the differences between SNLP+EBL <ref> [6] </ref> and UCPOP+EBL. 2 Overview of UCPOP+EBL 2.1 Base level Planner: UCPOP Like SNLP [4], UCPOP [14] searches in a space of partial plans, refining (adding constraints to) a partial plan until it becomes a complete solution to the planning problem. <p> They include inconsistent orderings (e.g. (s 1 s 2 ); (s 2 s 1 ) 2 O) , inconsistent bindings (e.g. (x y); (x 6 y) 2 B), inconsistent preconditions (e.g. p@s 1 ; :p@s 1 2 A), and inconsistent effects (e.g. inittrue (x); inittrue (:x)). As discussed in <ref> [6, 1] </ref>, these analytical failures alone are not enough to detect and terminate every failing branch before they cross search depth limits. In such cases, UCPOP+EBL can utilize any available domain specific failure theories to analyze implicit failures in the plans crossing depth limits. <p> Furthermore, as discussed elsewhere, the ability of EBL to learn control rules crucially depends on detecting and explaining failures in the partial plans before they cross depth limits <ref> [6] </ref>. This in turn depends on the nature of the domain theory (viz, how much information is left implicit and how much is represented explicitly), and the availability of domain specific theories of failure (c.f. [6, 1]). <p> This in turn depends on the nature of the domain theory (viz, how much information is left implicit and how much is represented explicitly), and the availability of domain specific theories of failure (c.f. <ref> [6, 1] </ref>). Finally, availability of sophisticated dependency directed backtracking strategies can directly compete with the performance improvements produced through learned control rules. We have used our implementation of UCPOP+EBL to investigate the effect of these factors. In this section, we will describe the results from these studies, and analyze them. <p> This paper presents an empirical analysis of the factors that influence the effectiveness of explanation based search control rule learning for partial order planners. To facilitate this analysis, we first presented UCPOP+EBL, that extends our previous work on control rule learning for a propositional partial order planner, SNLP <ref> [6] </ref> to UCPOP, a planner that is powerful enough to handle actions with conditional and quantified effects, as well as quantified and disjunctive preconditions.
Reference: [7] <author> S. Kambhampati, S. Katukam and Y. Qu. </author> <title> Failure Driven Search Control for Partial Order Planners: An Explanation based approach. </title> <type> ASU CSE TR 95-010, </type> <month> July </month> <year> 1995. </year> <note> Submitted for journal publication. </note>
Reference-contexts: Section 3 provides an evaluation of UCPOP+EBL and also describes the results of a focussed empirical study to analyze the factors affecting the performance of UCPOP+EBL. Finally, Section 4 presents our conclusions. A more detailed description of the design and analysis of UCPOP+EBL can be found in <ref> [7] </ref>.
Reference: [8] <author> S. Minton, J.G Carbonell, C.A. Knoblock, D.R. Kuokka, O. Etzioni and Y. Gil. </author> <title> Explanation-Based Learning: A Problem Solving Perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40:63--118, </volume> <year> 1989. </year>
Reference-contexts: One way of doing this involves learning search control rules to customize the planner's search to the expected problem population. Control rule learning has originally been developed in the context of state space planning <ref> [8, 1] </ref>. More recently, we extended it to plan-space planners [6], and developed SNLP+EBL, which learns control rules for the partial order planner SNLP.
Reference: [9] <author> S. Minton. </author> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1988. </year>
Reference-contexts: We generated 100 random problems containing between 3 to 5 objects, 3 to 5 locations and between 3 to 5 goal conjuncts. The second domain is the blocks world domain called BW-quant described in Figure 5. We generated 100 random problems using the procedure described in <ref> [9] </ref>. The problems contained between 3 to 6 blocks, and 3 to 4 goals. In each domain, we compared the performance of the from-scratch planner with that of the planner using the search control rules generated by UCPOP+EBL. Table 1 shows the results of these experiments.
Reference: [10] <author> S. Minton. </author> <title> Quantitative Results Concerning the Utility of Explanation Based Learn ing Artificial Intelligence, </title> <address> 42:363--391, </address> <year> 1990. </year>
Reference: [11] <author> R.J. Mooney and S. Bennett. </author> <title> A domain independent explanation-based generalizer. </title> <booktitle> In Proc. AAAI-86, </booktitle> <year> 1986. </year>
Reference: [12] <author> J.M. Zelle and R.J. Mooney. </author> <title> Combining FOIL and EBG to speedup logic programs. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <year> 1993. </year>
Reference: [13] <author> E.P.D. Pednault. </author> <title> Generalizing nonlinear planning to handle complex goals and actions with context dependent effects. </title> <booktitle> In Proc. IJCAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: Figure 1 (a) shows the description of a simple example domain for UCPOP called the briefcase domain <ref> [14, 13] </ref>, which involves moving objects from one location to another with the help of a briefcase. Note that the actions contain conditional and quantified effects.
Reference: [14] <author> J.S. Penberthy and D.S. Weld UCPOP: </author> <title> A Sound, Complete, Partial Order Planner for ADL In Proceedings of KR-92, </title> <year> 1992 </year>
Reference-contexts: Finally, Section 4 presents our conclusions. A more detailed description of the design and analysis of UCPOP+EBL can be found in [7]. That paper also explains in detail the differences between SNLP+EBL [6] and UCPOP+EBL. 2 Overview of UCPOP+EBL 2.1 Base level Planner: UCPOP Like SNLP [4], UCPOP <ref> [14] </ref> searches in a space of partial plans, refining (adding constraints to) a partial plan until it becomes a complete solution to the planning problem. <p> Figure 1 (a) shows the description of a simple example domain for UCPOP called the briefcase domain <ref> [14, 13] </ref>, which involves moving objects from one location to another with the help of a briefcase. Note that the actions contain conditional and quantified effects.
Reference: [15] <author> A. Segre and C. Elkan. </author> <title> A High Performance Explanation-based learning algorithm. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 69, </volume> <pages> pp. 1-50, </pages> <year> 1994. </year>
Reference: [16] <author> M. Veloso. </author> <title> Learning by analogical reasoning in general problem solving. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1992. </year>
Reference-contexts: This domain is similar in character to the logistics transportation domain described in <ref> [16] </ref>, except with conditional and quantified effects. We generated 100 random problems containing between 3 to 5 objects, 3 to 5 locations and between 3 to 5 goal conjuncts. The second domain is the blocks world domain called BW-quant described in Figure 5.
References-found: 16

