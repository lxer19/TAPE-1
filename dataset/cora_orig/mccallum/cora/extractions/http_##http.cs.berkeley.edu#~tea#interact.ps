URL: http://http.cs.berkeley.edu/~tea/interact.ps
Refering-URL: http://www.cs.washington.edu/homes/tom/
Root-URL: 
Note: This page intentionally left blank.  
Abstract-found: 0
Intro-found: 1
Reference: [Agarwal et al. 88] <author> A. Agarwal, J. Hennessy, and M. Horowitz. </author> <title> Cache performance of operating system and mul-tiprogramming workloads. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(4) </volume> <pages> 393-431, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: But the amount of information overlooked can be huge. In trace-driven studies gathered through a microcode-based tool, Agarwal et al. found that during the execution of two VAX Ul- trix workloads, over 50% of the references were system references <ref> [Agarwal et al. 88] </ref>; worse, this study and others (such as [Clark & Emer 85]) have shown operat ing system behavior to differ significantly from applica-tion behavior.
Reference: [Agarwal et al. 90] <author> A. Agarwal, B.-H. Lim, and J. Kubiatowicz. </author> <month> April: </month> <title> A processor architecture for multiprocessing. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 104-114, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: It is not surprising, then, that some researchers use a SPARC register window per thread as a way of optimizing context switches instead of procedure calls <ref> [Agarwal et al. 90] </ref>. VAX 88000 R2/3000 SPARC i860 RS6000 Registers 16 32 32 136 32 32 F.P. State 0 0 32 32 32 64 Misc.
Reference: [Anderson et al. 89] <author> T. Anderson, E. Lazowska, and H. Levy. </author> <title> The performance implications of thread management al-ternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12) </volume> <pages> 1631-1644, </pages> <address> De cember 1989. </address>
Reference-contexts: With carefully-implemented user-level thread systems, it is possible to provide high-performance parallel programming primitives that approach minimal hardware costs, e.g., new thread creation in 5-10 times the cost of a procedure call <ref> [Anderson et al. 89, Massalin & Pu 89] </ref>. This is due to the low cost of communication within a single address space running in a single protection mode.
Reference: [Anderson et al. 90] <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <type> Technical Report 90-04-02, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: This is due to the low cost of communication within a single address space running in a single protection mode. Also, through careful kernel-to-user interface design, user-level threads can provide all of the function of kernel-level threads without sacrificing performance <ref> [Anderson et al. 90] </ref>. It is likely that the importance of threads will continue to increase in the future, as programmers and compilers seek speedup through finer and finer grained parallelism.
Reference: [Baskett et al. 75] <author> F. Baskett, J. H. Howard, and J. T. Mon tague. </author> <title> Task communication in DEMOS. </title> <booktitle> In Proceedings of the 6th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 23-31, </pages> <month> November </month> <year> 1975. </year>
Reference: [Bershad et al. 88] <author> B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> PRESTO: A system for object-oriented parallel programming. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 713-732, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: caches and imprecise interrupts, operating systems for modern architectures may need to be less aggressive in their use of copy-on-write and similar mechanisms that rely on fast fault handling. 4 Threads and Multiprocessing Threads, or "lightweight processes," have become a common and necessary component of new languages and operating systems <ref> [Jones & Rashid 86, Halstead 85, Bershad et al. 88] </ref>. Threads allow the programmer or compiler to express, create, and control parallel activities, contributing to the structure and performance of parallel programs. A thread is simply one stream of control within a parallel program.
Reference: [Bershad et al. 90a] <author> B. Bershad, T. Anderson, E. Lazowska, and H. Levy. </author> <title> Lightweight remote procedure call. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1):3755, </volume> <month> February </month> <year> 1990. </year>
Reference-contexts: The performance of local cross-address space RPC determines how effectively the operating system can be decomposed, as well as how rapidly clients can communicate with local servers. One mechanism geared to rapid local communication is called lightweight remote procedure call (LRPC) <ref> [Bershad et al. 90a] </ref>. LRPC achieves performance for the null call that only marginally exceeds the optimal time permitted by the hardware. For the simplest local calls, LRPC achieves a 3-fold performance improvement over previous methods.
Reference: [Bershad et al. 90b] <author> B. N. Bershad, T. E. Anderson, E. D. Lazowska, and H. M. Levy. </author> <title> User-level interprocess communication for shared-memory multiprocessors. </title> <type> Technical Report TR-90-05-07, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> July </month> <year> 1990. </year>
Reference-contexts: Operating system designers must be aware that architectural trends will lead towards relatively more expensive system calls, and should look for mechanisms that avoid the kernel when possible (e.g., <ref> [Bershad et al. 90b] </ref>). 3 Virtual Memory The most basic use of virtual memory is to support address spaces larger than the physical memory.
Reference: [Birrell & Nelson 84] <author> A. D. Birrell and B. J. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: This use is predicated on the ability of processors to communicate efficiently across networks. In fact, in many environments, truly stand-alone computers no longer exist. 2.1 Cross-Machine Communication To simplify communication for the programmer, most systems now support Remote Procedure Call (RPC) <ref> [Birrell & Nelson 84] </ref>. RPC has become the preferred method to communicate between address spaces, both on the same machine and across a network, because it encapsulates message- oriented communication in procedure call semantics. In an RPC system, clients make procedure calls to remote servers.
Reference: [Cheriton 84] <author> D. R. Cheriton. </author> <title> The V kernel: A software base for distributed systems. </title> <journal> IEEE Software, </journal> <volume> 1(2) </volume> <pages> 19-42, </pages> <month> April </month> <year> 1984. </year>
Reference: [Cheriton et al. 88] <author> D. R. Cheriton, A. Gupta, P. D. Boyle, and H. A. Goosen. </author> <title> The VMP multiprocessor: Initial ex-perience, refinements and performance evaluation. </title> <booktitle> In Proceedings of the 15th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 410-421, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: A write-back cache or DECstation 5000-style memory can help, at the cost of added complexity. The problem of data copying for message passing and cache interference is significant enough that some researchers have proposed special architectural support to optimize copy operations <ref> [Cheriton et al. 88] </ref>. 2.5 Summary In modern operating systems, communication performance is crucial, because it enables good operating system structure and allows effective use of networks and distribution.
Reference: [Cheriton et al. 90] <author> D. R. Cheriton, G. R. Whitehead, and E. W. Sznyter. </author> <title> Binary emulation of Unix using the V ker-nel. </title> <booktitle> In Proceedings of the Summer 1990 USENIX Conference, </booktitle> <pages> pages 73-85, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Thus, while the Unix system interface has become standard in engineering and scientific computing, future Unix systems are unlikely to resemble current Unix implementations at lower levels. Newer operating systems will simply support Unix as one of several available interfaces, as is done, for example, on V <ref> [Cheriton et al. 90] </ref>, Mach [Golub et al. 90], and Topaz [Thacker et al. 88].
Reference: [Clark & Bhandarkar 91] <author> D. W. Clark and D. Bhandarkar. </author> <title> VAX versus RISC: Quantitative evidence from comparable implementations. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems. ACM, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: The MIPS R2000 requires 15% fewer cycles than the CVAX for a system call, but this is small compared to the advantage the R2000 should have over the CVAX in total required cycles <ref> [Clark & Bhandarkar 91] </ref>. The most telling row of Table 5 shows the cost of call preparation for these three machines | the work needed, following the trap, to prepare the processor to execute a procedure call to a C-level operating system routine.
Reference: [Clark & Emer 85] <author> D. W. Clark and J. S. Emer. </author> <title> Performance of the VAX-11/780 translation buffer: Simulation and measurement. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 31-62, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: In trace-driven studies gathered through a microcode-based tool, Agarwal et al. found that during the execution of two VAX Ul- trix workloads, over 50% of the references were system references [Agarwal et al. 88]; worse, this study and others (such as <ref> [Clark & Emer 85] </ref>) have shown operat ing system behavior to differ significantly from applica-tion behavior. Thus, the result of ignoring such a large execution component could be dramatic. * In those modern architectures where the needs of operating systems have been carefully considered, "traditional Unix" has driven the design. <p> For example, in a study of TLB performance on the VAX-11/780, Clark and Emer found that while the VMS operating system accounts for only one fifth of all references, it accounts for more than two thirds of all TLB misses <ref> [Clark & Emer 85] </ref>. On the other hand, this system space structure has several problems with respect to modern operating systems.
Reference: [Cyp 90] <institution> Cypress Semiconductor, </institution> <address> San Jose, CA. </address> <note> SPARC RISC User's Guide, </note> <year> 1990. </year>
Reference-contexts: examined a CISC implementation, the VAXstation 3200 (11.1 MHz CVAX [Leonard 87]), and four RISC implementations: the Tektronix XD88/01 (20 MHz Motorola 88000 [Mot 88a, Mot 88b]), DECstation 3100 (16.6 MHz MIPS R2000 [Kane 87]), DECstation 5000/200 (25 MHz MIPS R3000 1 ), and SPARCstation 1+ (25 MHz Sun SPARC <ref> [Sun 87, Cyp 90] </ref>). For brevity, our tables list the architecture or microprocessor names, rather than the system names, although performance is of course affected not only by instruction set architecture and processor technology, but by attributes specific to particular system-level implementation choices, such as cache size and organization. <p> With small-kernel operating systems, much operating system code runs in user mode and therefore cannot benefit from this hardware. Perhaps a better solution to increasing the utilization of TLB entries, particularly for the operating system, is found in the SPARC/Cypress <ref> [Cyp 90] </ref> implementation. In this case, the architecture supports a 3-level page table structure. The first-level table maps the entire 4GB address space; it contains pointers to second-level tables, each of which maps a 16MB region.
Reference: [DeMoney et al. 86] <author> M. DeMoney, J. Moore, and J. Mashey. </author> <title> Operating system support on a RISC. </title> <booktitle> In Proceedings of the 31st Computer Society International Conference (Spring Compcon '86), </booktitle> <pages> pages 138-143, </pages> <month> March </month> <year> 1986. </year>
Reference: [Ellis et al. 88] <author> J. R. Ellis, K. Li, and A. W. Appel. </author> <title> Real-time concurrent collection on stock multiprocessors. </title> <booktitle> In Proceedings of the ACM SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Along with copy-on-write and distributed virtual memory, other operating system functions are being overloaded on virtual memory protection bits as well: these include garbage collection <ref> [Ellis et al. 88] </ref>, checkpointing [Li et al. 90], recoverable virtual memory [Eppinger 89], and transaction locking [Radin 82]. Because these functions often are implemented at the run-time level, their implementations are simplified by user-level handling of page faults and efficient modification of TLB or page table entry access bits.
Reference: [Eppinger 89] <author> J. L. Eppinger. </author> <title> Virtual Memory Management for Transaction Processing Systems. </title> <type> PhD dissertation, </type> <institution> Carnegie-Mellon University, </institution> <month> February </month> <year> 1989. </year>
Reference-contexts: Along with copy-on-write and distributed virtual memory, other operating system functions are being overloaded on virtual memory protection bits as well: these include garbage collection [Ellis et al. 88], checkpointing [Li et al. 90], recoverable virtual memory <ref> [Eppinger 89] </ref>, and transaction locking [Radin 82]. Because these functions often are implemented at the run-time level, their implementations are simplified by user-level handling of page faults and efficient modification of TLB or page table entry access bits.
Reference: [Fitzgerald & Rashid 86] <author> R. Fitzgerald and R. F. Rashid. </author> <title> The integration of virtual memory management and interprocess communication in Accent. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(2) </volume> <pages> 147-177, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: In addition to supporting large address spaces, modern operating systems are making new demands on virtual mem ory, often to enhance system performance. For example, Accent and Mach use a copy-on-write mechanism to speed program startup and cross-address space communication for large data messages <ref> [Fitzgerald & Rashid 86, Young et al. 87] </ref>. In the latter case, the kernel maps large message buffers into the receiver's address space, so they are shared read-only by both sender and receiver.
Reference: [Golub et al. 90] <author> D. Golub, R. Dean, A. Forin, and R. Rashid. </author> <title> Unix as an application program. </title> <booktitle> In Proceedings of the Summer 1990 USENIX Conference, </booktitle> <pages> pages 87-95, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Newer operating systems will simply support Unix as one of several available interfaces, as is done, for example, on V [Cheriton et al. 90], Mach <ref> [Golub et al. 90] </ref>, and Topaz [Thacker et al. 88]. Unfortunately, modern operating systems and architectures have evolved somewhat independently: * While simulation and measurement studies (such as [Katevenis 85]) have been used to guide hardware design tradeoffs, these studies have tended to overlook the operating system.
Reference: [Halstead 85] <author> R. Halstead. </author> <title> Multilisp: A language for concur-rent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: caches and imprecise interrupts, operating systems for modern architectures may need to be less aggressive in their use of copy-on-write and similar mechanisms that rely on fast fault handling. 4 Threads and Multiprocessing Threads, or "lightweight processes," have become a common and necessary component of new languages and operating systems <ref> [Jones & Rashid 86, Halstead 85, Bershad et al. 88] </ref>. Threads allow the programmer or compiler to express, create, and control parallel activities, contributing to the structure and performance of parallel programs. A thread is simply one stream of control within a parallel program.
Reference: [Hennessy et al. 82] <author> J. Hennessy, N. Jouppi, F. Baskett, T. Gross, and J. Gill. </author> <title> Hardware/software tradeoffs for increased performance. </title> <booktitle> In Proceedings of the Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 2-11. </pages> <publisher> ACM, </publisher> <month> March </month> <year> 1982. </year>
Reference: [IBM 90] <institution> IBM Corporation, Advanced Workstation Division, Austin, Texas. POWER Processor Architecture, </institution> <year> 1990. </year>
Reference-contexts: If the floating point pipeline could be in use, the save/restore process adds 60 or more instructions to i860 page fault and other exception handling. Such complexities are not necessary; for example, the IBM RS6000 <ref> [IBM 90] </ref>, the SPARC, and the R2/3000, each of which has several independent pipelined functional units, implement precise interrupts [Smith & Pleszkun 88], thereby shielding software from much of the detail of pipelined processing.
Reference: [Int 89] <author> Intel Corporation. </author> <title> i860 64-bit Microprocessor Programmer's Reference Manual, </title> <year> 1989. </year>
Reference-contexts: To illustrate this point, Table 2 shows a count of the number of instructions executed along the shortest path in our drivers used for Table 1 (along with a similar estimate for the Intel i860 <ref> [Int 89] </ref>). These numbers are meant only to give a qualitative indication of the added complexity; obviously some VAX instructions, such as those used for context switching, do large amounts of work in microcode.
Reference: [Jones & Rashid 86] <author> M. B. Jones and R. F. Rashid. </author> <title> Mach and Matchmaker: Kernel and language support for object-oriented distributed systems. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, </booktitle> <pages> pages 67-77, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: Over the same period, operating systems too have seen an evolution. Operating system functions have changed to meet new requirements: fast local communication, distributed programming, parallel programming, virtual memory, and others. For improved extensibility, maintainability, and fault tolerance, modern operating systems such as Mach <ref> [Jones & Rashid 86] </ref> are moving from the traditional monolithic structure to a more modular organization. These requirements have led to much research in new underlying structures. <p> caches and imprecise interrupts, operating systems for modern architectures may need to be less aggressive in their use of copy-on-write and similar mechanisms that rely on fast fault handling. 4 Threads and Multiprocessing Threads, or "lightweight processes," have become a common and necessary component of new languages and operating systems <ref> [Jones & Rashid 86, Halstead 85, Bershad et al. 88] </ref>. Threads allow the programmer or compiler to express, create, and control parallel activities, contributing to the structure and performance of parallel programs. A thread is simply one stream of control within a parallel program.
Reference: [Kane 87] <author> G. Kane. </author> <title> MIPS R2000 RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1987. </year>
Reference-contexts: This does not include the time to find another process to run. Our measurements examined a CISC implementation, the VAXstation 3200 (11.1 MHz CVAX [Leonard 87]), and four RISC implementations: the Tektronix XD88/01 (20 MHz Motorola 88000 [Mot 88a, Mot 88b]), DECstation 3100 (16.6 MHz MIPS R2000 <ref> [Kane 87] </ref>), DECstation 5000/200 (25 MHz MIPS R3000 1 ), and SPARCstation 1+ (25 MHz Sun SPARC [Sun 87, Cyp 90]).
Reference: [Katevenis 85] <author> M. G. H. Katevenis. </author> <title> Reduced Instruction Set Computer Architectures for VLSI. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1985. </year>
Reference-contexts: Unfortunately, modern operating systems and architectures have evolved somewhat independently: * While simulation and measurement studies (such as <ref> [Katevenis 85] </ref>) have been used to guide hardware design tradeoffs, these studies have tended to overlook the operating system. The problem is partly technological: most early program tracing tools were unable to trace operating system code. But the amount of information overlooked can be huge.
Reference: [Kleiman & Williams 88] <author> S. Kleiman and D. Williams. </author> <title> SunOS on SPARC. </title> <institution> Sun Technology, </institution> <month> Summer </month> <year> 1988. </year>
Reference-contexts: Measurements of Sun Unix have shown that for SPARC systems with 8 windows, on average three need to be saved/restored on each context switch <ref> [Kleiman & Williams 88] </ref>. Our SPARC context switch driver for Table 1, which assumes the SUN Unix average, spends 70% of its time saving and restoring windows (12.8 seconds per window). Thus, the cost of reading and writing these registers makes fine-grained threads highly inefficient.
Reference: [Lamport 87] <author> L. Lamport. </author> <title> A fast mutual exclusion algo-rithm. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 5(1):111, </volume> <month> February </month> <year> 1987. </year>
Reference-contexts: But in Mach 3.0 the operating system's critical sections execute at user-level; a trap to the kernel is needed to provide mutual exclusion. (Existing non-trap based solutions to the mutual exclusion problem (e.g., <ref> [Lamport 87] </ref>) still have overheads on the order of dozens of cycles.) 6 Conclusions We have described the operating system needs in three fundamental areas and the relationship of modern architectures to those needs.
Reference: [Leonard 87] <author> T. E. Leonard, </author> <title> editor. VAX Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <address> Bedford, MA, </address> <year> 1987. </year>
Reference-contexts: This does not include the time to find another process to run. Our measurements examined a CISC implementation, the VAXstation 3200 (11.1 MHz CVAX <ref> [Leonard 87] </ref>), and four RISC implementations: the Tektronix XD88/01 (20 MHz Motorola 88000 [Mot 88a, Mot 88b]), DECstation 3100 (16.6 MHz MIPS R2000 [Kane 87]), DECstation 5000/200 (25 MHz MIPS R3000 1 ), and SPARCstation 1+ (25 MHz Sun SPARC [Sun 87, Cyp 90]).
Reference: [Li & Hudak 89] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: This relies on the ability to quickly trap and change page protection bits. Virtual memory also can be used to transparently support parallel programming across networks. Such loosely- coupled multiprocessing will become increasingly common as today's Ethernets are replaced by much faster networks. In systems such as Ivy <ref> [Li & Hudak 89] </ref>, a network-wide shared virtual memory is used to give the programmer on a workstation network the illusion of a shared-memory multiprocessor. Pages can be replicated on different workstations as long as the copies are mapped read-only. When one node attempts a write, it faults.
Reference: [Li et al. 90] <author> K. Li, J. F. Naughton, and J. S. Plank. </author> <title> Realtime concurrent checkpoint for parallel programs. </title> <booktitle> In Proceedings of the 2nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 79-88, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Along with copy-on-write and distributed virtual memory, other operating system functions are being overloaded on virtual memory protection bits as well: these include garbage collection [Ellis et al. 88], checkpointing <ref> [Li et al. 90] </ref>, recoverable virtual memory [Eppinger 89], and transaction locking [Radin 82]. Because these functions often are implemented at the run-time level, their implementations are simplified by user-level handling of page faults and efficient modification of TLB or page table entry access bits.
Reference: [Massalin & Pu 89] <author> H. Massalin and C. Pu. </author> <title> Threads and in-put/output in the Synthesis kernel. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 191-201, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: With carefully-implemented user-level thread systems, it is possible to provide high-performance parallel programming primitives that approach minimal hardware costs, e.g., new thread creation in 5-10 times the cost of a procedure call <ref> [Anderson et al. 89, Massalin & Pu 89] </ref>. This is due to the low cost of communication within a single address space running in a single protection mode.
Reference: [Mot 88a] <author> Motorola, Inc., </author> <title> Phoenix, AZ. MCS 88100 RISC Microprocessor User's Manual, </title> <year> 1988. </year>
Reference-contexts: This does not include the time to find another process to run. Our measurements examined a CISC implementation, the VAXstation 3200 (11.1 MHz CVAX [Leonard 87]), and four RISC implementations: the Tektronix XD88/01 (20 MHz Motorola 88000 <ref> [Mot 88a, Mot 88b] </ref>), DECstation 3100 (16.6 MHz MIPS R2000 [Kane 87]), DECstation 5000/200 (25 MHz MIPS R3000 1 ), and SPARCstation 1+ (25 MHz Sun SPARC [Sun 87, Cyp 90]).
Reference: [Mot 88b] <author> Motorola, Inc., </author> <title> Phoenix, AZ. MCS 88200 Cache/Memory Management Unit User's Manual, </title> <year> 1988. </year>
Reference-contexts: This does not include the time to find another process to run. Our measurements examined a CISC implementation, the VAXstation 3200 (11.1 MHz CVAX [Leonard 87]), and four RISC implementations: the Tektronix XD88/01 (20 MHz Motorola 88000 <ref> [Mot 88a, Mot 88b] </ref>), DECstation 3100 (16.6 MHz MIPS R2000 [Kane 87]), DECstation 5000/200 (25 MHz MIPS R3000 1 ), and SPARCstation 1+ (25 MHz Sun SPARC [Sun 87, Cyp 90]).
Reference: [Ousterhout 90a] <author> J. K. Ousterhout. </author> <type> Personal communication, </type> <month> July </month> <year> 1990. </year>
Reference-contexts: Thus, Ouster- hout found in the Sprite operating system [Ousterhout et al. 88] that kernel-to-kernel null RPC time was reduced by only half when moving from a Sun-3/75 to a SPARCstation-1, even though integer performance increased by a factor of five <ref> [Ousterhout 90a] </ref>. For larger RPC requests, network transmission time becomes more significant: e.g., nearly 50% for SRC RPC with a 1500-byte result packet. However, the checksum component also doubles in percentage, and the cost of parameter copying (called "marshalling") becomes substantial since it too is memory intensive.
Reference: [Ousterhout 90b] <author> J. K. Ousterhout. </author> <booktitle> Why aren't operating sys-tems getting faster as fast as hardware? In Proceedings of the Summer 1990 USENIX Conference, </booktitle> <pages> pages 247-256, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This paper examines recent changes and directions in computer architecture and operating systems, and the implications of changes in each domain on the other. Ousterhout has already demonstrated that operating systems are not receiving the same benefit as applications from new hardware platforms <ref> [Ousterhout 90b] </ref>. He attributes this principally to the operating system's appetite for memory bandwidth and disk performance. In this paper we look at a different granularity, focusing instead on the relationship between essential operating system primitives and hardware support. <p> With its write buffer, the DECstation 5000 runs without memory-induced slowdown in the common case of cache hits on reads and successive writes to a page, but even so, its trap performance still does not scale with the CVAX. 2.4 Data Copying As noted by Ousterhout <ref> [Ousterhout 90b] </ref>, data copying is another area in which modern processors have not scaled proportionally to their integer performance, yet it is an important aspect of local and remote communication. <p> The problem is that faster systems often have a mismatch between memory speed and processor speed. In fact, Ouster- hout found that for a range of RISCs and CISCs, "the relative performance of memory copying drops almost monotonically with faster processors, both for RISC and CISC machines <ref> [Ousterhout 90b] </ref>." This should not be surprising, in part because the same commodity memory parts are typically used for main memories on both RISCs and CISCs in various performance ranges. Most modern processors have on-chip caches, as well as second-level caches, but these on- chip caches are still relatively small.
Reference: [Ousterhout et al. 88] <author> J. K. Ousterhout, A. R. Cherenson, F. Douglis, M. N. Nelson, and B. B. Welch. </author> <title> The Sprite network operating system. </title> <journal> IEEE Computer, </journal> <volume> 21(2) </volume> <pages> 23-36, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Thus, Ouster- hout found in the Sprite operating system <ref> [Ousterhout et al. 88] </ref> that kernel-to-kernel null RPC time was reduced by only half when moving from a Sun-3/75 to a SPARCstation-1, even though integer performance increased by a factor of five [Ousterhout 90a].
Reference: [Patterson & Ditzel 80] <author> D. A. Patterson and D. R. Ditzel. </author> <title> The case for the reduced instruction set computer. </title> <journal> Computer Architecture News, </journal> <volume> 8(6) </volume> <pages> 25-33, </pages> <month> October </month> <year> 1980. </year>
Reference: [Patterson & Sequin 82] <author> D. A. Patterson and C. H. Sequin. </author> <title> A VLSI RISC. </title> <journal> IEEE Computer, </journal> <volume> 15(9) </volume> <pages> 8-21, </pages> <month> September </month> <year> 1982. </year>
Reference: [Radin 82] <author> G. Radin. </author> <title> The 801 minicomputer. </title> <booktitle> In Proceedings of the Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 39-47. </pages> <publisher> ACM, </publisher> <month> March </month> <year> 1982. </year>
Reference-contexts: Along with copy-on-write and distributed virtual memory, other operating system functions are being overloaded on virtual memory protection bits as well: these include garbage collection [Ellis et al. 88], checkpointing [Li et al. 90], recoverable virtual memory [Eppinger 89], and transaction locking <ref> [Radin 82] </ref>. Because these functions often are implemented at the run-time level, their implementations are simplified by user-level handling of page faults and efficient modification of TLB or page table entry access bits.
Reference: [Rashid & Robertson 81] <author> R. F. Rashid and G. G. Robertson. </author> <title> Accent: A communication oriented network operating system kernel. </title> <booktitle> In Proceedings of the 8th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 6475, </pages> <month> December </month> <year> 1981. </year>
Reference: [Schroeder & Burrows 90] <author> M. D. Schroeder and M. Burrows. </author> <title> Performance of Firefly RPC. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1) </volume> <pages> 1-17, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: This operating system involvement adds overhead that usually dominates network latency. For example, Table 3 shows the distribution of time spent in a round-trip cross-machine null RPC for a small (74-byte) packet in SRC RPC <ref> [Schroeder & Burrows 90] </ref> executing on VAX-II Firefly multiprocessors [Thacker et al. 88] connected by an Ethernet. For SRC RPC, one of the fastest RPC systems, only 17% of the time for a small packet is spent on the wire.
Reference: [Smith & Pleszkun 88] <author> J. E. Smith and A. R. Pleszkun. </author> <title> Implementing precise interrupts in pipelined processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(5) </volume> <pages> 562-573, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Such complexities are not necessary; for example, the IBM RS6000 [IBM 90], the SPARC, and the R2/3000, each of which has several independent pipelined functional units, implement precise interrupts <ref> [Smith & Pleszkun 88] </ref>, thereby shielding software from much of the detail of pipelined processing. A second factor in fault handling is the reduction, in some processors, of the information provided to handle faults.
Reference: [SPEC 90] <editor> SPEC newsletter benchmark results. </editor> <booktitle> Systems Performance Evaluation Cooperative, </booktitle> <year> 1990. </year>
Reference-contexts: switch 28.3 22.8 14.8 7.4 53.9 1.2 1.9 3.8 .5 Application Performance 3.5 4.2 6.7 4.3 Table 1: Relative Performance of Primitive OS Functions Our measurements, presented in Table 1, show that while the application code performance of the RISCs is excellent relative to the CVAX (we use the SPECmark <ref> [SPEC 90] </ref> as a measure of application performance), the performance of these operating system functions has not scaled in a commensurate way. In the following sections we will discuss why these primitive functions are important, and why they have not received the expected performance gain.
Reference: [Sun 87] <author> Sun Microsystems, Inc., </author> <title> Mountain View, CA. The SPARC Architecture Manual, </title> <year> 1987. </year>
Reference-contexts: examined a CISC implementation, the VAXstation 3200 (11.1 MHz CVAX [Leonard 87]), and four RISC implementations: the Tektronix XD88/01 (20 MHz Motorola 88000 [Mot 88a, Mot 88b]), DECstation 3100 (16.6 MHz MIPS R2000 [Kane 87]), DECstation 5000/200 (25 MHz MIPS R3000 1 ), and SPARCstation 1+ (25 MHz Sun SPARC <ref> [Sun 87, Cyp 90] </ref>). For brevity, our tables list the architecture or microprocessor names, rather than the system names, although performance is of course affected not only by instruction set architecture and processor technology, but by attributes specific to particular system-level implementation choices, such as cache size and organization.
Reference: [Thacker et al. 88] <author> C. P. Thacker, L. C. Stewart, and E. H. Satterthwaite, Jr. Firefly: </author> <title> A multiprocessor worksta-tion. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(8):909920, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: Newer operating systems will simply support Unix as one of several available interfaces, as is done, for example, on V [Cheriton et al. 90], Mach [Golub et al. 90], and Topaz <ref> [Thacker et al. 88] </ref>. Unfortunately, modern operating systems and architectures have evolved somewhat independently: * While simulation and measurement studies (such as [Katevenis 85]) have been used to guide hardware design tradeoffs, these studies have tended to overlook the operating system. <p> This operating system involvement adds overhead that usually dominates network latency. For example, Table 3 shows the distribution of time spent in a round-trip cross-machine null RPC for a small (74-byte) packet in SRC RPC [Schroeder & Burrows 90] executing on VAX-II Firefly multiprocessors <ref> [Thacker et al. 88] </ref> connected by an Ethernet. For SRC RPC, one of the fastest RPC systems, only 17% of the time for a small packet is spent on the wire.
Reference: [van Renesse et al. 88] <author> R. van Renesse, H. van Staveren, and A. S. Tanenbaum. </author> <title> Performance of the world's fastest distributed operating system. </title> <journal> ACM Operating Systems Review, </journal> <volume> 22(4) </volume> <pages> 25-34, </pages> <month> October </month> <year> 1988. </year>
Reference: [Wagner 89] <author> D. B. Wagner. </author> <title> Conservative Parallel Discrete-Event Simulation: Principles and Practice. </title> <type> PhD disserta-tion, </type> <institution> Univeristy of Washington, </institution> <month> September </month> <year> 1989. </year>
Reference-contexts: Since context switching was expensive in earlier operating systems, it was avoided if possible. But to realize potential speedup on current parallel machines, thread context switches implemented completely at user-level may become more frequent. As one test, we ran several experiments with the Synapse parallel simulation environment <ref> [Wagner 89] </ref> executing on a Sequent shared-memory multiprocessor. Synapse is an object-oriented system with lightweight threads scheduled at user-level.
Reference: [Wall 86] <author> D. W. Wall. </author> <title> Global register allocation at link time. </title> <booktitle> In ACM SIGPLAN Symposium on Compiler Construction, </booktitle> <month> June </month> <year> 1986. </year>
Reference-contexts: But, in a fine-grained user-level thread system, these reads and writes become the dominating cost. Optimizations that reduce the amount of state saving, e.g., saving only those registers that are in active use <ref> [Wall 86] </ref>, may become crucial to minimizing context switch costs. On the SPARC architecture, the number of registers to be saved depends on the number of register windows in use at the time of the context switch.
Reference: [Young et al. 87] <author> M. Young, A. Tevanian, R. Rashid, D. Golub, J. Eppinger, J. Chew, W. Bolosky, D. Black, and R. Baron. </author> <title> The duality of memory and communica-tion in the implementation of a multiprocessor oper-ating system. </title> <booktitle> In Proceedings of the 11th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 6376, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: In addition to supporting large address spaces, modern operating systems are making new demands on virtual mem ory, often to enhance system performance. For example, Accent and Mach use a copy-on-write mechanism to speed program startup and cross-address space communication for large data messages <ref> [Fitzgerald & Rashid 86, Young et al. 87] </ref>. In the latter case, the kernel maps large message buffers into the receiver's address space, so they are shared read-only by both sender and receiver. <p> As a result, systems must find a way of quickly reflecting page faults back to the user level, so that user-level code can make an appropriate management decision <ref> [Young et al. 87] </ref>.
References-found: 51

