URL: ftp://ftp.research.microsoft.com/users/viveknar/histogram_conf.ps
Refering-URL: http://www.research.microsoft.com/~surajitc/
Root-URL: http://www.research.microsoft.com
Email: E-mail: surajitc@microsoft.com  E-mail: rajeev@cs.stanford.edu  E-mail: viveknar@microsoft.com  
Title: Random Sampling for Histogram Construction: How much is enough?  
Author: Surajit Chaudhuri Rajeev Motwani Vivek Narasayya 
Affiliation: Microsoft Research  Stanford University  Microsoft Research  
Abstract: Random sampling is a standard technique for constructing (approximate) histograms for query optimization. However, any real implementation in commercial products requires solving the hard problem of determining "How much sampling is enough?" We address this critical question in the context of equi-height histograms used in many commercial products, including Microsoft SQL Server. We introduce a conservative error metric capturing the intuition that for an approximate histogram to have low error, the error must be small in all regions of the histogram. We then present a result establishing an optimal bound on the amount of sampling required for pre-specified error bounds. We also describe an adaptive page sampling algorithm which achieves greater efficiency by using all values in a sampled page but adjusts the amount of sampling depending on clustering of values in pages. Next, we establish that the problem of estimating the number of distinct values is provably difficult, but propose a new error metric which has a reliable estimator and can still be exploited by query optimizers to influence the choice of execution plans. The algorithm for histogram construction was prototyped on Microsoft SQL Server 7.0 and we present experimental results showing that the adaptive algorithm accurately approximates the true histogram over different data distributions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bunge and M. Fitzpatrick. </author> <title> Estimating the Number of Species: A Review. </title> <journal> Journal of the American Statistical Association 88(1993): </journal> <pages> 364-373. </pages>
Reference-contexts: In the statistics literature, the problem of estimating the number of distinct values (called the problem of estimating the number of species) has received a great deal of attention <ref> [1] </ref>. Recent work in the database literature includes the results of Naughton and Seshadri [22], and Haas, Naughton, Seshadri, and Stokes [10].
Reference: [2] <author> K.P. Burnham and W.S. Overton. </author> <title> Estimation of the size of a closed population when capture possibilities vary among animals. </title> <journal> Biometrika 65(1978): </journal> <pages> 625-633. </pages>
Reference-contexts: As observed by the latter, we obtain fairly poor performance when using the standard statistical estimators for the number of distinct values, e.g., the estimators due to Goodman [9], Chao [4], and Burnham and Overton <ref> [2, 3] </ref> which have been used earlier in the database context in the work of Hou, Ozsoyoglu, and Taneja [13, 14] and Ozsoyoglu et al [25]. As Haas et al [10] remark, distinct value estimation is a hard and relatively unsolved problem, and few analytic results are available.
Reference: [3] <author> K.P. Burnham and W.S. Overton. </author> <title> Robust estimation of population size when capture possibilities vary among animals. </title> <booktitle> Ecology 60(1979): </booktitle> <pages> 927-936. </pages>
Reference-contexts: As observed by the latter, we obtain fairly poor performance when using the standard statistical estimators for the number of distinct values, e.g., the estimators due to Goodman [9], Chao [4], and Burnham and Overton <ref> [2, 3] </ref> which have been used earlier in the database context in the work of Hou, Ozsoyoglu, and Taneja [13, 14] and Ozsoyoglu et al [25]. As Haas et al [10] remark, distinct value estimation is a hard and relatively unsolved problem, and few analytic results are available.
Reference: [4] <author> A. Chao. </author> <title> Nonparametric estimation of the number of classes in a population. </title> <journal> Scandinavian Journal of Statistical Theory and Applications 11(1984): </journal> <pages> 265-270. </pages>
Reference-contexts: As observed by the latter, we obtain fairly poor performance when using the standard statistical estimators for the number of distinct values, e.g., the estimators due to Goodman [9], Chao <ref> [4] </ref>, and Burnham and Overton [2, 3] which have been used earlier in the database context in the work of Hou, Ozsoyoglu, and Taneja [13, 14] and Ozsoyoglu et al [25].
Reference: [5] <author> S. Chaudhuri, R. Motwani, and V. Narasayya. </author> <title> Using Random Sampling for Histogram Construction. </title> <note> Mi-crosoft Research Report, In preparation, </note> <year> 1997. </year>
Reference-contexts: We devise a simple estimator which we believe is optimal. In this paper, we focus on equi-height (or, equi-depth) histograms. We chose equi-height histograms for our analysis since they are commonly used in many commercial opti-mizers, including SQL Server. In the full paper <ref> [5] </ref>, we also discuss how the above analysis can be adapted to the related family of compressed histograms. Extending our results to the case of other histogram structures [15, 16] is one of our ongoing research goals. The rest of the paper is organized as follows. <p> The proof is in the full paper <ref> [5] </ref>. Theorem 1 Consider a range query with output size s = tn=k for some t &lt; 1. (All bounds below are tight.) 1. A perfect equi-height histograms cannot guarantee ab solute error ff &lt; 2n k or relative error fi &lt; 2 t for all range queries. 2. <p> The converse is obviously not true, implying that the max error is the strongest notion of error. The proof is in the full paper <ref> [5] </ref>. Theorem 2 If a k-histogram has max error max ffi (or, is ffi-deviant) then it must be the case that: avg ffi, and var ffi. However, the converse is not true in general. <p> Theorem 3 shows that bounding the histogram error in terms of max error does indeed guarantee small estimation error for range query sizes, in fact the error is fairly close to best possible (that which is obtained by the perfect histogram). The proof is in the full paper <ref> [5] </ref>. Theorem 3 Consider a range query with output size s = tn=k. An approximate histogram with max error max = f n=k guarantees absolute error ff (1 + f ) 2n k and relative error fi (1 + f ) 2 t for all possible range queries. <p> As in most applications of random sampling, our results do carry over to the latter style of sampling without any noticeable change in the bounds obtained, but we defer the details to the full paper <ref> [5] </ref>. <p> for a random sample R of size r from a value set V of size n gives a ffi-deviant k-histogram for V with probability at least 1 fl (fl &gt; 0), provided that r kffi 2 or, equivalently, ffi r rk We defer the detailed proof to the full paper <ref> [5] </ref>. We delay a discussion of the implications of Theorem 4 until after the presentation of the stronger error bound in Theorem 5 below. <p> The following theorem shows that the amount of random sampling needed to guarantee ffi-separation is not much more than that required for ensuring ffi-deviation. We defer the proof to the full paper <ref> [5] </ref>. Theorem 5 Let ffi n k and fl &gt; 0. <p> A detailed exploration of these ideas, as well as a comprehensive analysis is deferred to the full paper <ref> [5] </ref>. 4.3 Analysis of Adaptive Algorithm The analysis of our adaptive algorithm needs some notation. Definition 3 Given a histogram H and a set S V , let S j be the number of values from S that lie in the jth bucket of H. <p> The following theorem, a generalization of Theorem 4, lays the theoretical foundation for our adaptive strategy. We defer the proof to the full paper <ref> [5] </ref>. Theorem 7 1. Let H be a k-histogram for V with deviation ffi = 2f n=k, for f 1=2. Let S be a sample of size s from V , where s f 2 : Then, the probability that ffi S f s=k is at most fl. 2. <p> Note that this theorem only considers deviation above the norm, but a similar theorem can be proved for the case of deviation below the norm <ref> [5] </ref>. Let us examine in detail the implications. The first part of the theorem says that given a histogram with max error &gt; 2f n=k, a sample of size s is likely to have max error exceeding f s=k when it is partitioned according to this histogram. <p> One standard approach for dealing with this issue is to employ compressed histograms. Such histograms separate the representation of values of multiplicity higher than n=k from the rest of the values. We will consider this in detail in the full version <ref> [5] </ref> of the paper. Here we focus on a different approach based on generalizing the max error metric itself in the presence of duplicate values. Suppose that the separators obtained from the sample are s 1 , : : :, s k1 . <p> The denominator scales the error by the number of values in the jth distinct range. In the full paper, we discuss how the analytical results extend to this generalized error metric <ref> [5] </ref>. 6 Estimating the Number of Distinct Values Consider the problem of estimating the number of distinct values, say d, in V . <p> Our estimator is: e = n f 1 + j=2 where f + 1 = maxff 1 ; 1g. We give only a brief justification for this estimator, deferring a more detailed justification to the full paper <ref> [5] </ref>. Consider values whose frequency in the data is significantly more than n=r. We expect these values to occur more than once in the sample and therefore they are accounted for in the latter summation. <p> In addition to histograms, the SQL Server also collects information on density [27]. However, because the estimation of the density was extremely accurate whenever the CVB algorithm converges, we defer a discussion of density estimation to the full version of the paper <ref> [5] </ref>. Implementation: The experiments were conducted on an Intel Pentium 200MHz processor with 64 MB RAM. The database was stored on external Seagate ST34371N disk drives. The CVB algorithm was implemented on Microsoft SQL Server 7.0. <p> The details of experimentation with step sizes is deferred to the full version of the paper <ref> [5] </ref>. For the purposes of experiments in this section, the adaptive algorithm uses the following sizes for the successive random samples: 5isqrt (n), for i = 1; 2; : : :, for accumulated samples. <p> Subsequently, when we clustered the relation on tuple-id, we ensured that 20% of the duplicates were placed sequentially on the table. The full paper <ref> [5] </ref> will discuss extensive variations in layouts that were considered. 7.2 Experimental Results Varying the number of records: In our first experiment we studied the effect of varying the number of records in the table on the required sampling rate.
Reference: [6] <author> S. Chaudhuri and V. Narasayya. </author> <title> An Efficient, Cost-Driven Index Selection Tool for Microsoft SQL Server. </title> <booktitle> In Proc. 23rd VLDB, </booktitle> <year> 1997. </year>
Reference-contexts: In addition to greatly enhancing the accuracy of the optimizer's estimates, such statistical information is of great interest in tools that help decide physical database design <ref> [7, 6] </ref>. In many commercial systems, including Microsoft SQL Server, the optimizer relies on histograms on selected columns to estimate selectivities of queries. In addition to histograms, density as well as number of distinct values in the columns are other statistical parameters of interest.
Reference: [7] <author> S. Finkelstein, M. Schkolnick, and P. Tiberio. </author> <title> Physical Database Design for Relational Databases. </title> <journal> ACM TODS, </journal> <volume> 13(1988): </volume> <pages> 91-128. </pages>
Reference-contexts: In addition to greatly enhancing the accuracy of the optimizer's estimates, such statistical information is of great interest in tools that help decide physical database design <ref> [7, 6] </ref>. In many commercial systems, including Microsoft SQL Server, the optimizer relies on histograms on selected columns to estimate selectivities of queries. In addition to histograms, density as well as number of distinct values in the columns are other statistical parameters of interest.
Reference: [8] <author> P.B. Gibbons, Y. Matias, and V. Poosala. </author> <title> Fast Incremental Maintenance of Approximate Histograms. </title> <booktitle> In Proc. 23rd VLDB, </booktitle> <pages> pages 466-475, </pages> <year> 1997. </year>
Reference-contexts: In sharp contrast, the problem of approximating histograms require us to derive a histogram that is reasonably accurate for a large class of queries (preferably all) with high probability. Although the main focus of the work in Gibbons, Matias, and Poosala <ref> [8] </ref> is on the incremental maintenance of histograms, they do provide a distribution-independent bound on the required amount of sampling. However, our bounds are significantly stronger and lends to ease of use. We will discuss the relationship between this and our results in Section 3. <p> How much error should we expect in the histogram? The answer is that f is bounded by 14%. 3.4 Comparison to Previous Work Perhaps the most similar earlier work is that of Gibbons, Matias, and Poosala <ref> [8] </ref>.
Reference: [9] <author> L.A. Goodman. </author> <title> On the estimation of the number of classes in a population. </title> <journal> Annals of Mathematical Statistics 20(1949): </journal> <pages> 572-579. </pages>
Reference-contexts: Recent work in the database literature includes the results of Naughton and Seshadri [22], and Haas, Naughton, Seshadri, and Stokes [10]. As observed by the latter, we obtain fairly poor performance when using the standard statistical estimators for the number of distinct values, e.g., the estimators due to Goodman <ref> [9] </ref>, Chao [4], and Burnham and Overton [2, 3] which have been used earlier in the database context in the work of Hou, Ozsoyoglu, and Taneja [13, 14] and Ozsoyoglu et al [25].
Reference: [10] <author> P.J. Haas, J.F. Naughton, S. Seshadri, and L. </author> <title> Stokes. Sampling-based estimation of the number of distinct values of an attribute. </title> <booktitle> In Proc. 21st VLDB, </booktitle> <pages> pages 311-322, </pages> <year> 1995. </year>
Reference-contexts: However, our bounds are significantly stronger and lends to ease of use. We will discuss the relationship between this and our results in Section 3. As regards the problem of estimating the number of distinct values, we have sharpened the intuition obtained in earlier work <ref> [10, 26] </ref> by providing a negative result which explains why distinct values cannot be approximated reliably. <p> Recent work in the database literature includes the results of Naughton and Seshadri [22], and Haas, Naughton, Seshadri, and Stokes <ref> [10] </ref>. <p> As Haas et al <ref> [10] </ref> remark, distinct value estimation is a hard and relatively unsolved problem, and few analytic results are available. In this section, we first establish that no estimator for d can guarantee a small error. <p> Then, for any fl &gt; e r , there exists a choice of the relation such that with probability at least fl, error ( b d) r r Consider the results of Haas et al <ref> [10] </ref> who obtained average error 1.33 and maximum error 2.86 (over a total of 24 high-skew distributions) using a random sample of size r = 0:2n. Setting fl = 0:5, we obtain that there exists a scenario where the error is at least 1:86.
Reference: [11] <author> P.J. </author> <title> Haas and A.N. Swami. Sequential Sampling Procedures for Query Size Estimation. </title> <booktitle> In Proc. ACM SIG-MOD Conference, </booktitle> <pages> pages 341-350, </pages> <year> 1992. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> Such strategies have been considered earlier in the literature: adaptive sampling by Lipton and Naughton [18], Lipton, Naughton, and Schneider [19], and Lipton, Naughton, Schneider, and Se-shadri [20]; double sampling by Hou, Ozsoyoglu, and Dogdu [12]; and, sequential sampling by Haas and Swami <ref> [11] </ref>. A comparative evaluation of these methods can be found in Ling and Sun [17]. None of these methods is directly engineered for constructing histograms; they were designed at query cost estimation.
Reference: [12] <author> W. Hou, G. Ozsoyoglu, and E. Dogdu. </author> <title> Error-Constrained COUNT Query Evaluation in Relational Databases. </title> <booktitle> In Proc. ACM SIGMOD Conference, </booktitle> <pages> pages 278-287, </pages> <year> 1991. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> Such strategies have been considered earlier in the literature: adaptive sampling by Lipton and Naughton [18], Lipton, Naughton, and Schneider [19], and Lipton, Naughton, Schneider, and Se-shadri [20]; double sampling by Hou, Ozsoyoglu, and Dogdu <ref> [12] </ref>; and, sequential sampling by Haas and Swami [11]. A comparative evaluation of these methods can be found in Ling and Sun [17]. None of these methods is directly engineered for constructing histograms; they were designed at query cost estimation.
Reference: [13] <author> W. Hou, G. Ozsoyoglu, and B. Taneja. </author> <title> Statistical estimators for relational algebra expressions. </title> <booktitle> In Proc. 7th ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 276-287, </pages> <year> 1988. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> latter, we obtain fairly poor performance when using the standard statistical estimators for the number of distinct values, e.g., the estimators due to Goodman [9], Chao [4], and Burnham and Overton [2, 3] which have been used earlier in the database context in the work of Hou, Ozsoyoglu, and Taneja <ref> [13, 14] </ref> and Ozsoyoglu et al [25]. As Haas et al [10] remark, distinct value estimation is a hard and relatively unsolved problem, and few analytic results are available. In this section, we first establish that no estimator for d can guarantee a small error.
Reference: [14] <author> W. Hou, G. Ozsoyoglu, and B. Taneja. </author> <title> Processing aggregate relational queries with hard time constraints. </title> <booktitle> In Proc. ACM SIGMOD Conference, </booktitle> <pages> pages 68-77, </pages> <year> 1989. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> latter, we obtain fairly poor performance when using the standard statistical estimators for the number of distinct values, e.g., the estimators due to Goodman [9], Chao [4], and Burnham and Overton [2, 3] which have been used earlier in the database context in the work of Hou, Ozsoyoglu, and Taneja <ref> [13, 14] </ref> and Ozsoyoglu et al [25]. As Haas et al [10] remark, distinct value estimation is a hard and relatively unsolved problem, and few analytic results are available. In this section, we first establish that no estimator for d can guarantee a small error.
Reference: [15] <author> Y. Ioannidis and V. Poosala. </author> <title> Balancing Histogram Optimality and Practicality for Query Result Size Estimation. </title> <booktitle> In Proc. ACM SIGMOD Conference, </booktitle> <pages> pages 233-244, </pages> <year> 1995. </year>
Reference-contexts: In the full paper [5], we also discuss how the above analysis can be adapted to the related family of compressed histograms. Extending our results to the case of other histogram structures <ref> [15, 16] </ref> is one of our ongoing research goals. The rest of the paper is organized as follows. In the remainder of this section, we briefly summarize past work in the area.
Reference: [16] <author> Y. Ioannidis and V. Poosala. </author> <title> Histogram-Based Solutions to Diverse Database Estimation Problems. </title> <journal> IEEE Data Engineering Bulletin 18(1995): </journal> <pages> 10-18. </pages>
Reference-contexts: In the full paper [5], we also discuss how the above analysis can be adapted to the related family of compressed histograms. Extending our results to the case of other histogram structures <ref> [15, 16] </ref> is one of our ongoing research goals. The rest of the paper is organized as follows. In the remainder of this section, we briefly summarize past work in the area.
Reference: [17] <author> Y. Ling and W. Sun. </author> <title> An Evaluation of Sampling-Based Size Estimation Methods for Selections in Database Systems. </title> <booktitle> In Proc. IEEE Conference on Data Engineering, </booktitle> <pages> pages 532-539, </pages> <year> 1995. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> A comparative evaluation of these methods can be found in Ling and Sun <ref> [17] </ref>. None of these methods is directly engineered for constructing histograms; they were designed at query cost estimation. All three methods compute a confidence interval on the error based on past sampling and terminate the sampling process when this interval is suitably small.
Reference: [18] <author> R.J. Lipton and J.F. Naughton. </author> <title> Query Size Estimation by Adaptive Sampling. </title> <booktitle> In Proc. ACM PODS, </booktitle> <pages> pages 40-46, </pages> <year> 1990. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> Such strategies have been considered earlier in the literature: adaptive sampling by Lipton and Naughton <ref> [18] </ref>, Lipton, Naughton, and Schneider [19], and Lipton, Naughton, Schneider, and Se-shadri [20]; double sampling by Hou, Ozsoyoglu, and Dogdu [12]; and, sequential sampling by Haas and Swami [11]. A comparative evaluation of these methods can be found in Ling and Sun [17].
Reference: [19] <author> R.J. Lipton, J.F. Naughton, and D.A. Schneider. </author> <title> Practical Selectivity Estimation through Adaptive Sampling. </title> <booktitle> In Proc. ACM SIGMOD Conference, </booktitle> <pages> pages 1-11, </pages> <year> 1990. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> Such strategies have been considered earlier in the literature: adaptive sampling by Lipton and Naughton [18], Lipton, Naughton, and Schneider <ref> [19] </ref>, and Lipton, Naughton, Schneider, and Se-shadri [20]; double sampling by Hou, Ozsoyoglu, and Dogdu [12]; and, sequential sampling by Haas and Swami [11]. A comparative evaluation of these methods can be found in Ling and Sun [17].
Reference: [20] <author> R.J. Lipton, J.F. Naughton, D.A. Schneider, and S. Se-shadri. </author> <title> Efficient Sampling Strategies for Relational Database Operations. </title> <booktitle> Theoretical Computer Science 116(1993): </booktitle> <pages> 195-226. </pages>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases [23, 24]. In particular, a large body of work <ref> [18, 19, 20, 13, 14, 12, 11, 17] </ref> has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> Such strategies have been considered earlier in the literature: adaptive sampling by Lipton and Naughton [18], Lipton, Naughton, and Schneider [19], and Lipton, Naughton, Schneider, and Se-shadri <ref> [20] </ref>; double sampling by Hou, Ozsoyoglu, and Dogdu [12]; and, sequential sampling by Haas and Swami [11]. A comparative evaluation of these methods can be found in Ling and Sun [17]. None of these methods is directly engineered for constructing histograms; they were designed at query cost estimation.
Reference: [21] <author> R. Motwani and P. Raghavan. </author> <title> Randomized Algorithms. </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: We give essentially optimal formulas describing the trade-off between the various parameters, notably the number of buckets k, the error ffi, and the number of random samples r. 3 Refer to Motwani and Raghavan <ref> [21] </ref> for all basic definitions/results on randomization used in this paper. Theorem 4 Let ffi n k .
Reference: [22] <author> J.F. Naughton and S. Seshadri. </author> <title> On Estimating the Size of Projections. </title> <booktitle> In Proc. Third International Conference on Database Theory, </booktitle> <pages> pages 499-513, </pages> <year> 1990. </year>
Reference-contexts: In the statistics literature, the problem of estimating the number of distinct values (called the problem of estimating the number of species) has received a great deal of attention [1]. Recent work in the database literature includes the results of Naughton and Seshadri <ref> [22] </ref>, and Haas, Naughton, Seshadri, and Stokes [10].
Reference: [23] <author> F. Olken. </author> <title> Random Sampling from Databases. </title> <type> PhD Thesis, </type> <institution> Computer Science, U.C. Berkeley, </institution> <year> 1993. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases <ref> [23, 24] </ref>. In particular, a large body of work [18, 19, 20, 13, 14, 12, 11, 17] has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling. <p> As pointed out by Olken <ref> [23] </ref>, all known estimators give exceedingly large errors on at least some of datasets. We show that large error is unavoidable even for relatively large samples regardless of the estimator used.
Reference: [24] <author> F. Olken and D. Rotem. </author> <title> Random Sampling from Databases A Survey. </title> <type> Manuscript, </type> <year> 1995. </year>
Reference-contexts: We conclude this section with a summary of our proposal for effective use of sampling for approximating histograms and distinct values. 1.1 Related Work Random sampling has been proposed and used in many different contexts in databases <ref> [23, 24] </ref>. In particular, a large body of work [18, 19, 20, 13, 14, 12, 11, 17] has addressed the problem of estimating result size for a given query using random sampling. In contrast, the problem that we have addressed requires us to estimate a histogram using random sampling.
Reference: [25] <author> G. Ozsoyoglu, K. Du, A. Tjahjana, W. Hou, </author> <title> and D.Y. Rowland. On estimating COUNT, SUM, and AVERAGE relational algebra queries. </title> <booktitle> In Proc. Conference on Database and Expert Systems Applications, </booktitle> <pages> pages 406-412, </pages> <year> 1991. </year>
Reference-contexts: when using the standard statistical estimators for the number of distinct values, e.g., the estimators due to Goodman [9], Chao [4], and Burnham and Overton [2, 3] which have been used earlier in the database context in the work of Hou, Ozsoyoglu, and Taneja [13, 14] and Ozsoyoglu et al <ref> [25] </ref>. As Haas et al [10] remark, distinct value estimation is a hard and relatively unsolved problem, and few analytic results are available. In this section, we first establish that no estimator for d can guarantee a small error.
Reference: [26] <author> V. Poosala, Y. Ioannidis, P. Haas, and E. Shekita. </author> <title> Improved Histograms for Selectivity Estimation of Range Predicates. </title> <booktitle> In Proc. ACM SIGMOD Conference, </booktitle> <pages> pages 294-305, </pages> <year> 1996. </year>
Reference-contexts: However, our bounds are significantly stronger and lends to ease of use. We will discuss the relationship between this and our results in Section 3. As regards the problem of estimating the number of distinct values, we have sharpened the intuition obtained in earlier work <ref> [10, 26] </ref> by providing a negative result which explains why distinct values cannot be approximated reliably.
Reference: [27] <author> G. Piatetsky-Shapiro and C. Connell. </author> <title> Accurate estimation of the number of tuples satisfying a condition. </title> <booktitle> In Proc. ACM SIGMOD Conference, </booktitle> <pages> pages 256-276, </pages> <year> 1984. </year>
Reference-contexts: Furthermore, in most earlier work, the recommended sampling bounds are based on distribution-specific assumptions and heuristic analysis. The use of random sampling for estimating histogram was proposed by Piatetsky-Shapiro and Connell <ref> [27] </ref>. They show that given a particular query, only a small sample size is needed to estimate a histogram that is adequate for the query with a high probability. <p> As mentioned in Section 2, such histograms are characterized by their separators (step boundaries). In addition to histograms, the SQL Server also collects information on density <ref> [27] </ref>. However, because the estimation of the density was extremely accurate whenever the CVB algorithm converges, we defer a discussion of density estimation to the full version of the paper [5]. Implementation: The experiments were conducted on an Intel Pentium 200MHz processor with 64 MB RAM.
Reference: [28] <author> P.G. Selinger, D.D. Astrahan, R.A. Chamberlain, R.A. Lorie, and T.G. Price. </author> <title> Access path selection in a relational database management system. </title> <booktitle> In Proc. ACM SIGMOD Conference, </booktitle> <pages> pages 23-34, </pages> <year> 1979. </year>
Reference-contexts: Estimating the number of distinct values is an important subproblem in query optimization, e.g., for estimating projection size or in estimating relative error in join-selectivity estimation formulas used in System R <ref> [28] </ref>. We are interested in the issue of devising a good estimator for d based on a random sample from V .
Reference: [29] <author> G.E. Zipf. </author> <title> Human Behavior and the Principle of Least Effort. </title> <publisher> Addison-Wesley Press, Inc, </publisher> <year> 1949. </year>
Reference-contexts: For an integer column this translates to 600 bins. We modified the histogram data structure so that the number of bins could be varied. Data Generation: We generated data using the Zipf distributions <ref> [29] </ref>. The skewness parameter Z was varied. Although we studied several different values of Z varying from 0 to 4, we present results only for three values of Z | 0, 2, and 4.
References-found: 29

