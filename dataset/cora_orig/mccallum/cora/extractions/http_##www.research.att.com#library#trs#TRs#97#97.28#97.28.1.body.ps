URL: http://www.research.att.com/library/trs/TRs/97/97.28/97.28.1.body.ps
Refering-URL: http://www.research.att.com/library/trs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (estherjroberto)@research.att.com  
Title: A STOCHASTIC MODEL OF COMPUTER-HUMAN INTERACTION FOR LEARNING DIALOGUE STRATEGIES  
Author: Esther Levin and Roberto Pieraccini 
Address: Labs-Research, 180 Park Avenue, Floram Park, NJ 07932-0971, USA  
Affiliation: AT&T  
Abstract: Recent progress in the field of spoken natural language understanding expanded the scope of spoken language systems to include mixed initiative dialogue. Currently there are no agreed upon theoretical foundations for the design of such systems. In this work we propose a stochastic model of computer-human interactions. This model can be used for learning and adaptation of the dialogue strategy and for objective evaluation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Glass, J. et al., </author> <title> "The MIT Atis System: December 1994 Progress Report", </title> <booktitle> Proc. of 1995 ARPA Spoken Language Systems Technology Workshop, </booktitle> <address> Austin Texas, </address> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Man-machine interactions, from simple touch tone menus to more complex speech based systems are ubiquitous in today's world. In the natural language and AI research communities there are even more complex examples of dialogue systems that make use of natural ways of communication like speech and language <ref> [1, 2, 3, 6] </ref>. In this paper we show that such dialogue systems can be formally described in terms of their state space, action set and strategy.
Reference: [2] <author> Sadek, M.D., Bretier, P., Cadoret, V., Cozannet, A., Dupont, P., Ferrieux, A., & Panaget, F., </author> <title> "A Cooperative Spoken Dialogue System Based on a Rational Agent Model: A First Implementation on the AGS Application," </title> <booktitle> Proceedings of the ESCA/ETR Workshop on Spoken Dialogue Systems, </booktitle> <address> Hanstholm, Den-mark, </address> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Man-machine interactions, from simple touch tone menus to more complex speech based systems are ubiquitous in today's world. In the natural language and AI research communities there are even more complex examples of dialogue systems that make use of natural ways of communication like speech and language <ref> [1, 2, 3, 6] </ref>. In this paper we show that such dialogue systems can be formally described in terms of their state space, action set and strategy.
Reference: [3] <author> Stallard, D., </author> <title> "The BBN ATIS4 Dialogue System," </title> <booktitle> Proc. of 1995 ARPA Spoken Language Systems Technology Workshop, </booktitle> <address> Austin Texas, </address> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Man-machine interactions, from simple touch tone menus to more complex speech based systems are ubiquitous in today's world. In the natural language and AI research communities there are even more complex examples of dialogue systems that make use of natural ways of communication like speech and language <ref> [1, 2, 3, 6] </ref>. In this paper we show that such dialogue systems can be formally described in terms of their state space, action set and strategy.
Reference: [4] <author> Kaelbling, L. P., Littman, M. L., Moore, A. W., </author> <title> "Reinforcement Learning: A Survey," </title> <journal> in Journal of Artificial Intelligence Research, </journal> <volume> No. 4, </volume> <pages> pp. 237-285, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Due to the complexity of the system, the optimal strategy cannot be derived analytically in this case. Hence we propose to represent the dialogue system as a stochastic model known as Markov Decision Process (MDP) and to use reinforcement learning algorithms <ref> [4] </ref> to find the optimal strategy automatically. 2. <p> Markov Decision Process The quantitative dialogue model relies on the description of dialogue system in terms of Markov Decision Process (MDP) <ref> [4] </ref>. Formally a Markov Decision process is a stochastic model that consists of: * State space S, including initial and final states s I and s F . <p> We cannot derive the optimal strategy analyt ically. Currently we are experimenting with a reinforcement learning algorithm for learning the optimal strategy from interactions <ref> [4] </ref>. 6. SUMMARY In this paper we propose a formal quantitative model for man-machine dialogue systems. First, we introduce a general formalization of such systems in terms of their state space, action set and strategy.
Reference: [5] <author> Marcus, S. M., Brown, D. W., Goldberg, R. G., Schoe*er, M. S., Wetzel, W. R., and Rosinski, R. R. </author> <title> "Prompt Constrained Natural Language Evolving the Next Generation of Telephony Services," </title> <booktitle> Proc. of ICSLP '96, </booktitle> <address> Philadephia (PA), </address> <month> October </month> <year> 1996. </year>
Reference-contexts: We illustrate this formalization in two examples. One is a simple form filling application for which an optimal strategy is derived analytically, and it quantifies a reasonable strategy adopted in real systems <ref> [5] </ref>. The other example refers to our research database retrieval dialogue system [6]. Due to the complexity of the system, the optimal strategy cannot be derived analytically in this case.
Reference: [6] <author> Pieraccini, R., Levin, E., "AMICA: </author> <title> the AT&T Mixed Initiative Conversational Architecture," </title> <booktitle> Eurospeech 97, </booktitle> <address> Rhodes (Greece), </address> <month> Sept. </month> <year> 1997 </year>
Reference-contexts: 1. INTRODUCTION Man-machine interactions, from simple touch tone menus to more complex speech based systems are ubiquitous in today's world. In the natural language and AI research communities there are even more complex examples of dialogue systems that make use of natural ways of communication like speech and language <ref> [1, 2, 3, 6] </ref>. In this paper we show that such dialogue systems can be formally described in terms of their state space, action set and strategy. <p> We illustrate this formalization in two examples. One is a simple form filling application for which an optimal strategy is derived analytically, and it quantifies a reasonable strategy adopted in real systems [5]. The other example refers to our research database retrieval dialogue system <ref> [6] </ref>. Due to the complexity of the system, the optimal strategy cannot be derived analytically in this case. Hence we propose to represent the dialogue system as a stochastic model known as Markov Decision Process (MDP) and to use reinforcement learning algorithms [4] to find the optimal strategy automatically. 2. <p> EXAMPLE 2: AMICA AMICA <ref> [6] </ref> dialogue system is a research mixed initiative spontaneously spoken input dialogue system that was initially developed for the ARPA ATIS task. The application here is an intelligent interface between a user and a relational database. <p> It reflects the preference of users for short and concise, but non-empty, outputs. In our case: f (N D ) = 0 1 N D 3 C 2 N D 3 Referring to the system description in <ref> [6] </ref> we can map specific modules to cost terms of equation (8): the minimal information module tries to minimize the database access cost N D ; the constraining and relaxation modules try to minimize the cost of the output channel f (N D ); and all of them contribute to the
References-found: 6

