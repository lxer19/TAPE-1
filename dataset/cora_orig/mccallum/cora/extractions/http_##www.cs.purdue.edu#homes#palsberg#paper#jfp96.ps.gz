URL: http://www.cs.purdue.edu/homes/palsberg/paper/jfp96.ps.gz
Refering-URL: http://www.cs.purdue.edu/homes/palsberg/publications.html
Root-URL: http://www.cs.purdue.edu
Email: Internet: anders@diku.dk  Internet: palsberg@daimi.aau.dk  
Title: Generating Action Compilers by Partial Evaluation  
Author: Anders Bondorf Jens Palsberg 
Address: Universitetsparken 1 DK-2100 Copenhagen Denmark  DK-8000 Aarhus C, Denmark  
Affiliation: DIKU, Department of Computer Science  Computer Science Department Aarhus University  
Abstract: We have obtained an action compiler in a much simpler way: by partial evaluation of an action interpreter. Even though our compiler produces Scheme code, the code runs as fast as that produced by the previous action compilers.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Lars Ole Andersen. </author> <title> Self-applicable C program specialization. </title> <booktitle> In Proc. of PEPM'92, Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 54-61, </pages> <month> June </month> <year> 1992. </year> <type> (Technical Report YALEU/DCS/RR-909, </type> <institution> Yale University). </institution>
Reference-contexts: It may hinder practical use of our system that target programs are in Scheme, which is rather slow compared to C. It might be worthwhile rewriting the action interpreter in C, and then use Andersen's partial evaluator of C programs <ref> [1] </ref>. At the initial stages of our project we considered writing a meta-interpreter for action semantic descriptions. The arguments of such a meta-interpreter should be both a language semantics and a program in that language.
Reference: [2] <author> Anders Bondorf. </author> <title> Automatic autoprojection of higher order recursive equations. </title> <booktitle> Science of Computer Programming, </booktitle> <address> 17(1-3):3-34, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: We have obtained an action compiler in a much simpler way: by partial evaluation of an action interpreter. The action interpreter is written in Scheme, and is straightforward, except for some binding time improving parts [10]. We have obtained the action compiler using the Similix partial evaluator <ref> [4, 5, 2, 3] </ref>. Even though our action compiler produces Scheme code, the code runs as fast as that produced by the previous action compilers. We have used the generated action compiler in an action semantics directed compiler generator.
Reference: [3] <author> Anders Bondorf. </author> <title> Improving binding times without explicit cps--conversion. </title> <booktitle> In 1992 ACM Conference on Lisp and Functional Programming. </booktitle> <address> San Francisco, California. </address> <booktitle> LISP Pointers V, </booktitle> <volume> 1, </volume> <pages> pages 1-10, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: We have obtained an action compiler in a much simpler way: by partial evaluation of an action interpreter. The action interpreter is written in Scheme, and is straightforward, except for some binding time improving parts [10]. We have obtained the action compiler using the Similix partial evaluator <ref> [4, 5, 2, 3] </ref>. Even though our action compiler produces Scheme code, the code runs as fast as that produced by the previous action compilers. We have used the generated action compiler in an action semantics directed compiler generator.
Reference: [4] <author> Anders Bondorf. </author> <title> Similix 5.0 Manual. </title> <institution> DIKU, University of Copenhagen, Denmark, </institution> <month> April </month> <year> 1993. </year> <note> Included in Similix 5.0 distribution. </note>
Reference-contexts: We have obtained an action compiler in a much simpler way: by partial evaluation of an action interpreter. The action interpreter is written in Scheme, and is straightforward, except for some binding time improving parts [10]. We have obtained the action compiler using the Similix partial evaluator <ref> [4, 5, 2, 3] </ref>. Even though our action compiler produces Scheme code, the code runs as fast as that produced by the previous action compilers. We have used the generated action compiler in an action semantics directed compiler generator. <p> The trouble points are the higher order control transfers where the target code generated by partial evaluation becomes parameterized over the complete-continuation. The improvements involve inserting eta-redexes at 11 appropriate places <ref> [4] </ref>; these places are marked with comments bt-imp 3 and bt-imp 9 in Appendix B. With these improvements, the complete-continuations will be static everywhere, except at higher order control transfers; the target program will consequently only manipulate continuations if there are higher order control transfers.
Reference: [5] <author> Anders Bondorf and Olivier Danvy. </author> <title> Automatic autoprojection of recursive equations with global variables and abstract data types. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 16 </volume> <pages> 151-195, </pages> <year> 1991. </year>
Reference-contexts: We have obtained an action compiler in a much simpler way: by partial evaluation of an action interpreter. The action interpreter is written in Scheme, and is straightforward, except for some binding time improving parts [10]. We have obtained the action compiler using the Similix partial evaluator <ref> [4, 5, 2, 3] </ref>. Even though our action compiler produces Scheme code, the code runs as fast as that produced by the previous action compilers. We have used the generated action compiler in an action semantics directed compiler generator. <p> The operation _sim-memoize (just above bt-imp 4) is also a kind of binding time improvement: it forces the partial evaluator to specialize/memoize at this point (instead of using the default "dynamic conditional" strategy <ref> [5] </ref>). This results in shorter and somewhat faster target code (with fewer function calls), and also faster partial evaluation. Current work by Malmkjr addresses finding (good) specialization points automatically [14]. We have experimented with making the escape and fail continuations static; this yields bigger and/or slower target programs.
Reference: [6] <author> Deryck F. Brown, Hermano Moura, and David A. Watt. Actress: </author> <title> an action semantics directed compiler generator. </title> <booktitle> In Proc. CC'92, 4th International Conference on Compiler Construction, Paderborn, Germany, </booktitle> <pages> pages 95-109. </pages> <publisher> Springer-Verlag (LNCS 641), </publisher> <year> 1992. </year>
Reference-contexts: It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt <ref> [6] </ref>, and also by the second author [22, 20, 21]. Journal of Functional Programming, 6 (2):269-298, 1996. Also in Proc. FPCA'93, pages 308-317. The core of each of their two action semantics directed compiler generators is a handwritten action compiler, producing either C or machine code.
Reference: [7] <author> Charles Consel and Olivier Danvy. </author> <title> Static and dynamic semantics processing. </title> <booktitle> In Eighteenth Symposium on Principles of Programming Languages, </booktitle> <pages> pages 14-24, </pages> <year> 1991. </year>
Reference-contexts: Jtrgensen [12] used partial evaluation to generate a compiler for a lazy functional language, and this compiler emits code that compares favorably to that emitted by handwritten compilers. Consel and Danvy <ref> [7] </ref> used partial evaluation to generate a compiler from denotational semantics, and their compiler produces target code that is only two times slower than that produced by handwritten compilers. A key point in the development of Consel and Danvy [7] is to identify and process the static semantics by partial evaluation. <p> Consel and Danvy <ref> [7] </ref> used partial evaluation to generate a compiler from denotational semantics, and their compiler produces target code that is only two times slower than that produced by handwritten compilers. A key point in the development of Consel and Danvy [7] is to identify and process the static semantics by partial evaluation. Our approach is similar: we identify and process the static semantics partly by a separate action type checker and partly by partial evaluation.
Reference: [8] <author> Olivier Danvy, Karoline Malmkjr, and Jens Palsberg. </author> <title> The essence of eta-expansion in partial evaluation. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 8(3) </volume> <pages> 209-227, </pages> <year> 1995. </year> <note> Preliminary version in Proc. </note> <editor> PEPM'94, </editor> <booktitle> ACM SIG-PLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 11-20, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Intuitively, this works because it makes sense to have a static continuation where its arguments x1, x2, x3 are dynamic. For a thorough treatment of the insertion of eta-redexes, see <ref> [8] </ref>. In the terminology of that paper, the trouble point bt-imp 3 is an occurrence of "a static value in a dynamic context" and the trouble point bt-imp 9 is an occurrence of "a dynamic value in a static context". <p> These binding-time improvements are the data structure analogues of the ones for functions (bt-imp 3 and bt-imp 9) that were explained above (see also <ref> [8] </ref>). The operation _sim-memoize (just above bt-imp 4) is also a kind of binding time improvement: it forces the partial evaluator to specialize/memoize at this point (instead of using the default "dynamic conditional" strategy [5]).
Reference: [9] <author> Carsten K. Gomard. </author> <title> A self-applicable partial evaluator for the lambda calculus: Correctness and pragmatics. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 14(2) </volume> <pages> 147-172, </pages> <year> 1991. </year>
Reference-contexts: For examples of such proofs for toy partial evaluators, see the papers by Gomard <ref> [9] </ref> and Wand [25]. Note, however, that Similix has not been proved correct. Our subset of action notation is statically typed. We use the same type-checker as the second author did in his previous work [21, 22, 20]. Thus, we first run the type-checker and then the interpreter.
Reference: [10] <author> Neil D. Jones, Carsten K. Gomard, and Peter Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <booktitle> Prentice-Hall International, </booktitle> <year> 1993. </year>
Reference-contexts: These compilers are rather complicated and, due to their complexity, difficult to modify. We have obtained an action compiler in a much simpler way: by partial evaluation of an action interpreter. The action interpreter is written in Scheme, and is straightforward, except for some binding time improving parts <ref> [10] </ref>. We have obtained the action compiler using the Similix partial evaluator [4, 5, 2, 3]. Even though our action compiler produces Scheme code, the code runs as fast as that produced by the previous action compilers.
Reference: [11] <author> Neil D. Jones, Peter Sestoft, and Harald Stndergaard. </author> <title> An experiment in partial evaluation: The generation of a compiler generator. </title> <editor> In J.-P. Jouannaud, editor, </editor> <booktitle> Proc. Rewriting Techniques and Applications, </booktitle> <pages> pages 225-282. </pages> <publisher> Springer-Verlag (LNCS 202), </publisher> <year> 1985. </year>
Reference-contexts: This is part of the reason why our system is faster than the classical systems. The claim that partial evaluation may lead to the generation of acceptable compilers has been made many times, for example in the first paper on Jones, Sestoft, and Stndergaard's Mix partial evaluator <ref> [11] </ref>. Jtrgensen [12] used partial evaluation to generate a compiler for a lazy functional language, and this compiler emits code that compares favorably to that emitted by handwritten compilers.
Reference: [12] <author> Jesper Jtrgensen. </author> <title> Generating a compiler for a lazy language by partial evaluation. </title> <booktitle> In Nineteenth Annual ACM SIGACT-SIGPLAN Sym 37 posium on Principles of Programming Languages. </booktitle> <address> Albuquerque, New Mexico, </address> <pages> pages 258-268, </pages> <year> 1992. </year>
Reference-contexts: This is part of the reason why our system is faster than the classical systems. The claim that partial evaluation may lead to the generation of acceptable compilers has been made many times, for example in the first paper on Jones, Sestoft, and Stndergaard's Mix partial evaluator [11]. Jtrgensen <ref> [12] </ref> used partial evaluation to generate a compiler for a lazy functional language, and this compiler emits code that compares favorably to that emitted by handwritten compilers.
Reference: [13] <author> Peter Lee. </author> <title> Realistic Compiler Generation. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Even though our action compiler produces Scheme code, the code runs as fast as that produced by the previous action compilers. We have used the generated action compiler in an action semantics directed compiler generator. The generated compilers produce target code that, by comparison with measurements reported in <ref> [13] </ref>, is at least ten times faster than that produced by the compilers generated by the classical systems of Mosses [15], Paulson, [23], and Wand [24], but still around 100 times slower than target programs produced by handwritten compilers.
Reference: [14] <author> Karoline Malmkjr. </author> <title> Towards efficient partial evaluation. </title> <booktitle> In Proc. PEPM'93, Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Copenhagen, Denmark, </address> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: This results in shorter and somewhat faster target code (with fewer function calls), and also faster partial evaluation. Current work by Malmkjr addresses finding (good) specialization points automatically <ref> [14] </ref>. We have experimented with making the escape and fail continuations static; this yields bigger and/or slower target programs.
Reference: [15] <author> Peter D. Mosses. </author> <title> SIS|semantics implementation system. </title> <type> Technical Report Daimi MD-30, </type> <institution> Computer Science Department, Aarhus University, </institution> <year> 1979. </year> <title> Out of print. </title>
Reference-contexts: We have used the generated action compiler in an action semantics directed compiler generator. The generated compilers produce target code that, by comparison with measurements reported in [13], is at least ten times faster than that produced by the compilers generated by the classical systems of Mosses <ref> [15] </ref>, Paulson, [23], and Wand [24], but still around 100 times slower than target programs produced by handwritten compilers. None the classical systems of Mosses, Paulson, and Wand include a binding-time analysis.
Reference: [16] <author> Peter D. Mosses. </author> <title> Unified algebras and action semantics. </title> <booktitle> In Proc. STACS'89, </booktitle> <pages> pages 17-35. </pages> <publisher> Springer-Verlag (LNCS 349), </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction Action semantics is a framework for formal semantics of programming languages, developed by Mosses <ref> [16, 17, 18] </ref> and Watt [19, 26]. It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author [22, 20, 21].
Reference: [17] <author> Peter D. Mosses. </author> <title> An introduction to action semantics. </title> <type> Technical Report DAIMI PB-370, </type> <institution> Computer Science Department, Aarhus University, </institution> <year> 1991. </year> <booktitle> Lecture Notes for the Marktoberdorf'91 Summer School, to be published in the Proceedings of the Summer School by Springer-Verlag (Series F). </booktitle>
Reference-contexts: 1 Introduction Action semantics is a framework for formal semantics of programming languages, developed by Mosses <ref> [16, 17, 18] </ref> and Watt [19, 26]. It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author [22, 20, 21].
Reference: [18] <author> Peter D. Mosses. </author> <title> Action Semantics. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year> <note> Number 26 Tracts in Theoretical Computer Science. </note>
Reference-contexts: 1 Introduction Action semantics is a framework for formal semantics of programming languages, developed by Mosses <ref> [16, 17, 18] </ref> and Watt [19, 26]. It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author [22, 20, 21]. <p> Transients are produced only on completion or escape, and bindings are produced only on completion. In contrast, changes to the store are made during action performance, and are unaffected by subsequent divergence or failure. Dependent data are entities that can be evaluated to yield data during action performance. (In <ref> [18] </ref>, dependent data are called yielders; they may be thought of as expressions.) The data yielded may depend on the current information, i.e., the given transients, the received bindings, and the current state of the store. Evaluation cannot affect the current information. <p> In the following we present the resulting, annotated action. We use an appropriate concrete syntax, rather than the abstract syntax of Appendix A. For readability, we have rearranged the action using some of the algebraic laws of actions <ref> [18] </ref>. 33 execute [[ "const" "n" "=" 10 ";" . . . "end" ]] = furthermore bind "n" to 10 (ok) before (("n") 0 0) allocate integer cell then bind "x" to it (ok) hence (("x" "n") 0 0) give 0 (ok) then store it in the cell bound to "x"
Reference: [19] <author> Peter D. Mosses and David A. Watt. </author> <title> The use of action semantics. </title> <booktitle> In Proc. IFIP TC2 Working Conference on Formal Description of Programming Concepts III (Gl. </booktitle> <address> Averns, </address> <year> 1986), </year> <pages> pages 135-163. </pages> <publisher> North-Holland, </publisher> <year> 1987. </year>
Reference-contexts: 1 Introduction Action semantics is a framework for formal semantics of programming languages, developed by Mosses [16, 17, 18] and Watt <ref> [19, 26] </ref>. It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author [22, 20, 21]. Journal of Functional Programming, 6 (2):269-298, 1996.
Reference: [20] <author> Jens Palsberg. </author> <title> An automatically generated and provably correct compiler for a subset of Ada. </title> <booktitle> In Proc. ICCL'92, Fourth IEEE International Conference on Computer Languages, </booktitle> <pages> pages 117-126, </pages> <address> Oakland, Califor-nia, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author <ref> [22, 20, 21] </ref>. Journal of Functional Programming, 6 (2):269-298, 1996. Also in Proc. FPCA'93, pages 308-317. The core of each of their two action semantics directed compiler generators is a handwritten action compiler, producing either C or machine code. <p> Evaluation cannot affect the current information. Data is a special case of dependent data, and it always yields itself when evaluated. 3 The language of actions is called action notation. We use a subset of action notation which was also studied in <ref> [22, 20] </ref> and defined in [21]. This subset covers roughly half of the full action notation and is sufficiently general to allow the easy description of Lee's HypoPL [22] and a non-trivial subset of Ada [20]. For an example of an action semantic description using this subset, see Appendix C. <p> We use a subset of action notation which was also studied in [22, 20] and defined in [21]. This subset covers roughly half of the full action notation and is sufficiently general to allow the easy description of Lee's HypoPL [22] and a non-trivial subset of Ada <ref> [20] </ref>. For an example of an action semantic description using this subset, see Appendix C. Scaling up our results to full action notation would require significant extension of our action interpreter, especially to handle communication. <p> This system was essentially obtained by replacing the hand-written action compiler in the Cantor system of the second author <ref> [22, 20, 21] </ref> with the automatically generated action compiler. <p> For examples of such proofs for toy partial evaluators, see the papers by Gomard [9] and Wand [25]. Note, however, that Similix has not been proved correct. Our subset of action notation is statically typed. We use the same type-checker as the second author did in his previous work <ref> [21, 22, 20] </ref>. Thus, we first run the type-checker and then the interpreter. Both operate on the same abstract syntax: the type-checker inserts various information in the syntax-tree. This information is about type correctness, tokens, and number of transients, see later. <p> Our conclusion is "optimize the straightline code". 6 Performance Evaluation We have tested our compiler generator on specifications of Lee's HypoPL and a substantial subset of Ada. These language specifications may be found in <ref> [22, 20, 21] </ref>. Our example programs are a bubblesort program (written in both Hy-poPL and Ada), and programs for performing the sieve of Erathosthenes and the algorithm of Euclid (written in Ada). These programs may be found in [21]. <p> The L A T E X source text of the appendix is a legal input to both the compiler generator (Cantor) of the second author <ref> [22, 20, 21] </ref> and also to our new one.
Reference: [21] <author> Jens Palsberg. </author> <title> Provably Correct Compiler Generation. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Aarhus University, </institution> <year> 1992. </year>
Reference-contexts: It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author <ref> [22, 20, 21] </ref>. Journal of Functional Programming, 6 (2):269-298, 1996. Also in Proc. FPCA'93, pages 308-317. The core of each of their two action semantics directed compiler generators is a handwritten action compiler, producing either C or machine code. <p> Evaluation cannot affect the current information. Data is a special case of dependent data, and it always yields itself when evaluated. 3 The language of actions is called action notation. We use a subset of action notation which was also studied in [22, 20] and defined in <ref> [21] </ref>. This subset covers roughly half of the full action notation and is sufficiently general to allow the easy description of Lee's HypoPL [22] and a non-trivial subset of Ada [20]. For an example of an action semantic description using this subset, see Appendix C. <p> This system was essentially obtained by replacing the hand-written action compiler in the Cantor system of the second author <ref> [22, 20, 21] </ref> with the automatically generated action compiler. <p> generated by our system first expands the input program to an action, then it type checks the action, and finally it runs the action compiler on the result, see Appendix D for an example. 4 The Action Interpreter Our subset of action notation, see Appendix A, has an operational semantics <ref> [21] </ref>. From that we have systematically derived an action interpreter, written in Scheme, see Appendix B. Its size is approximately half the size of the operational semantics. In previous work [21], the second author defined and proved the correctness of a type analysis and a code generator for our subset of <p> D for an example. 4 The Action Interpreter Our subset of action notation, see Appendix A, has an operational semantics <ref> [21] </ref>. From that we have systematically derived an action interpreter, written in Scheme, see Appendix B. Its size is approximately half the size of the operational semantics. In previous work [21], the second author defined and proved the correctness of a type analysis and a code generator for our subset of action notion. In comparison, our interpreter is less than a third of the size of the code generator, and about one tenth of the size of the (sketchy) proof. <p> For examples of such proofs for toy partial evaluators, see the papers by Gomard [9] and Wand [25]. Note, however, that Similix has not been proved correct. Our subset of action notation is statically typed. We use the same type-checker as the second author did in his previous work <ref> [21, 22, 20] </ref>. Thus, we first run the type-checker and then the interpreter. Both operate on the same abstract syntax: the type-checker inserts various information in the syntax-tree. This information is about type correctness, tokens, and number of transients, see later. <p> These binding times correspond exactly to those implicitly used by the handwritten action compiler of the second author <ref> [21] </ref>. We partially evaluated that version of the interpreter with respect to some actions and found that the target code ran several times slower than the target programs produced by the handwritten action compiler. <p> Our conclusion is "optimize the straightline code". 6 Performance Evaluation We have tested our compiler generator on specifications of Lee's HypoPL and a substantial subset of Ada. These language specifications may be found in <ref> [22, 20, 21] </ref>. Our example programs are a bubblesort program (written in both Hy-poPL and Ada), and programs for performing the sieve of Erathosthenes and the algorithm of Euclid (written in Ada). These programs may be found in [21]. <p> These language specifications may be found in [22, 20, 21]. Our example programs are a bubblesort program (written in both Hy-poPL and Ada), and programs for performing the sieve of Erathosthenes and the algorithm of Euclid (written in Ada). These programs may be found in <ref> [21] </ref>. The four example programs were all compiled both by compilers generated by the Cantor system of the second author, and by compilers generated by applying the (self-application generated) compiler generator of Similix 5.0 to the interpreter in Appendix B. <p> This makes our new system much better for experimental use than the Cantor system. The run times in the third table are encouraging, considering that the action compiler in the Cantor system is designed specifically to generate SPARC code <ref> [21] </ref>. In contrast, our action compiler generates Scheme code. Currently, we do not understand why there is a difference between the HypoPL and the Ada bubblesort programs. <p> The L A T E X source text of the appendix is a legal input to both the compiler generator (Cantor) of the second author <ref> [22, 20, 21] </ref> and also to our new one.
Reference: [22] <author> Jens Palsberg. </author> <title> A provably correct compiler generator. </title> <booktitle> In Proc. ESOP'92, European Symposium on Programming, </booktitle> <pages> pages 418-434. </pages> <publisher> Springer-Verlag (LNCS 582), Rennes, </publisher> <address> France, </address> <month> February </month> <year> 1992. </year> <month> 38 </month>
Reference-contexts: It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author <ref> [22, 20, 21] </ref>. Journal of Functional Programming, 6 (2):269-298, 1996. Also in Proc. FPCA'93, pages 308-317. The core of each of their two action semantics directed compiler generators is a handwritten action compiler, producing either C or machine code. <p> Evaluation cannot affect the current information. Data is a special case of dependent data, and it always yields itself when evaluated. 3 The language of actions is called action notation. We use a subset of action notation which was also studied in <ref> [22, 20] </ref> and defined in [21]. This subset covers roughly half of the full action notation and is sufficiently general to allow the easy description of Lee's HypoPL [22] and a non-trivial subset of Ada [20]. For an example of an action semantic description using this subset, see Appendix C. <p> We use a subset of action notation which was also studied in [22, 20] and defined in [21]. This subset covers roughly half of the full action notation and is sufficiently general to allow the easy description of Lee's HypoPL <ref> [22] </ref> and a non-trivial subset of Ada [20]. For an example of an action semantic description using this subset, see Appendix C. Scaling up our results to full action notation would require significant extension of our action interpreter, especially to handle communication. <p> This system was essentially obtained by replacing the hand-written action compiler in the Cantor system of the second author <ref> [22, 20, 21] </ref> with the automatically generated action compiler. <p> For examples of such proofs for toy partial evaluators, see the papers by Gomard [9] and Wand [25]. Note, however, that Similix has not been proved correct. Our subset of action notation is statically typed. We use the same type-checker as the second author did in his previous work <ref> [21, 22, 20] </ref>. Thus, we first run the type-checker and then the interpreter. Both operate on the same abstract syntax: the type-checker inserts various information in the syntax-tree. This information is about type correctness, tokens, and number of transients, see later. <p> Our conclusion is "optimize the straightline code". 6 Performance Evaluation We have tested our compiler generator on specifications of Lee's HypoPL and a substantial subset of Ada. These language specifications may be found in <ref> [22, 20, 21] </ref>. Our example programs are a bubblesort program (written in both Hy-poPL and Ada), and programs for performing the sieve of Erathosthenes and the algorithm of Euclid (written in Ada). These programs may be found in [21]. <p> The L A T E X source text of the appendix is a legal input to both the compiler generator (Cantor) of the second author <ref> [22, 20, 21] </ref> and also to our new one.
Reference: [23] <author> Lawrence Paulson. </author> <title> A semantics-directed compiler generator. </title> <booktitle> In Ninth Symposium on Principles of Programming Languages, </booktitle> <pages> pages 224-233, </pages> <year> 1982. </year>
Reference-contexts: We have used the generated action compiler in an action semantics directed compiler generator. The generated compilers produce target code that, by comparison with measurements reported in [13], is at least ten times faster than that produced by the compilers generated by the classical systems of Mosses [15], Paulson, <ref> [23] </ref>, and Wand [24], but still around 100 times slower than target programs produced by handwritten compilers. None the classical systems of Mosses, Paulson, and Wand include a binding-time analysis. Binding-time analysis enables computations to take place at compile-time and it is an integrated component of the Similix partial evaluator.
Reference: [24] <author> Mitchell Wand. </author> <title> A semantic prototyping system. </title> <booktitle> In Proc. ACM SIG-PLAN'84 Symposium on Compiler Construction, </booktitle> <pages> pages 213-221. </pages> <address> Sig-plan Notices, </address> <year> 1984. </year>
Reference-contexts: The generated compilers produce target code that, by comparison with measurements reported in [13], is at least ten times faster than that produced by the compilers generated by the classical systems of Mosses [15], Paulson, [23], and Wand <ref> [24] </ref>, but still around 100 times slower than target programs produced by handwritten compilers. None the classical systems of Mosses, Paulson, and Wand include a binding-time analysis. Binding-time analysis enables computations to take place at compile-time and it is an integrated component of the Similix partial evaluator.
Reference: [25] <author> Mitchell Wand. </author> <title> Specifying the correctness of binding-time analysis. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(3) </volume> <pages> 365-387, </pages> <year> 1993. </year>
Reference-contexts: For examples of such proofs for toy partial evaluators, see the papers by Gomard [9] and Wand <ref> [25] </ref>. Note, however, that Similix has not been proved correct. Our subset of action notation is statically typed. We use the same type-checker as the second author did in his previous work [21, 22, 20]. Thus, we first run the type-checker and then the interpreter.
Reference: [26] <author> David A. Watt. </author> <title> Programming Language Syntax and Semantics. </title> <publisher> Prentice-Hall, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction Action semantics is a framework for formal semantics of programming languages, developed by Mosses [16, 17, 18] and Watt <ref> [19, 26] </ref>. It differs from denotational semantics in using semantic entities called actions, rather than higher-order functions. Compiler generation based on action semantics has been studied by Brown, Moura, and Watt [6], and also by the second author [22, 20, 21]. Journal of Functional Programming, 6 (2):269-298, 1996.
Reference: [27] <author> David A. Watt. </author> <type> Personal communication. </type> <year> 1992. </year> <month> 39 </month>
Reference-contexts: With the above measurements, our system yields roughly the same results. Note that the system of Brown, Moura, and Watt does not distinguish between committed and non-committed failures <ref> [27] </ref>. We believe that this is a significant simplification because our target programs contain a considerable amount of code to distinguish failures. 7 Conclusion We have obtained an action compiler by partially evaluating an action interpreter.
References-found: 27

