URL: http://www.cs.ucsb.edu/oocsb/papers/ecoop95-dispatch.ps
Refering-URL: http://www.cs.ucsb.edu/oocsb/papers/dispatch.html
Root-URL: http://www.cs.ucsb.edu
Abstract-found: 0
Intro-found: 1
Reference: [APS93] <author> Ole Agesen, Jens Palsberg, and Michael I. Schwartzbach. </author> <title> Type Inference of SELF: Analysis of Objects with Dynamic and Multiple Inheritance. </title> <booktitle> In ECOOP '93 Conference Proceedings, p. </booktitle> <pages> 247-267. </pages> <address> Kaiserslautern, Germany, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94]. Similarly, concrete type inference <ref> [OPS92, VHU92, APS93, PC94, AH95] </ref> or link-time optimizations [App88, Fer95] can determine the concrete receiver types of calls, possibly eliminating dynamic dispatch for many sends. 8 Conclusions We have evaluated the dispatch cost of a range of dispatch mechanisms, taking into account the performance characteristics of modern pipelined superscalar microprocessors.
Reference: [AH95] <author> Ole Agesen and Urs Hlzle. </author> <title> Type Feedback vs. Concrete Type Inference: A Comparison of Optimization Techniques for Object-Oriented Languages. </title> <type> Technical Report TRCS 95-04, </type> <institution> Department of Computer Science, UCSB, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94]. Similarly, concrete type inference <ref> [OPS92, VHU92, APS93, PC94, AH95] </ref> or link-time optimizations [App88, Fer95] can determine the concrete receiver types of calls, possibly eliminating dynamic dispatch for many sends. 8 Conclusions We have evaluated the dispatch cost of a range of dispatch mechanisms, taking into account the performance characteristics of modern pipelined superscalar microprocessors.
Reference: [AGS94] <author> Eric Amiel, Olivier Gruber, and Eric Simon. </author> <title> Optimizing Multi-Method Dispatch Using Compressed Dispatch Tables. </title> <booktitle> In OOPSLA 94 Conference Proceedings, </booktitle> <pages> pp. 244-258, </pages> <month> October </month> <year> 1994. </year> <note> Published as SIGPLAN Notices 29(10), </note> <month> October </month> <year> 1994. </year>
Reference-contexts: Since multi-method dispatch techniques (e.g., <ref> [KR90, AGS94] </ref>) are similar and include single dispatch as an important (very frequent) special case, we hope that the results will nevertheless be useful for implementors or designers of multiple dispatch techniques. <p> Calder et al. propose to improve performance with if-conversion, an inline cache with a statically determined target. For each call site the address of the most frequently called function is determined from execution profiles. We have considered single dispatch only; multiple dispatch techniques are discussed in [KR90] and <ref> [AGS94] </ref>. However, singly-dispatched calls are so frequent even in systems offering multiple dispatch that implementations usually special-case these calls. Ingalls [Ing86] shows how to implement multiple dispatch with a sequence of single dispatch, but such implementations may not be optimal [AGS94]. <p> dispatch only; multiple dispatch techniques are discussed in [KR90] and <ref> [AGS94] </ref>. However, singly-dispatched calls are so frequent even in systems offering multiple dispatch that implementations usually special-case these calls. Ingalls [Ing86] shows how to implement multiple dispatch with a sequence of single dispatch, but such implementations may not be optimal [AGS94]. Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94].
Reference: [AR92] <author> P. Andr and J.-C. Royer. </author> <title> Optimizing Method Search with Lookup Caches and Incremental Coloring. </title> <booktitle> OOPSLA 92 Conference Proceedings, </booktitle> <address> Vancouver, Canada, </address> <month> October </month> <year> 1992. </year> <note> Published as SIGPLAN Notices 27(10), </note> <month> October </month> <year> 1992. </year>
Reference-contexts: Thus, with dynamic typing, VTBL dispatch tables would degenerate to STI tables since any arbitrary message could be sent to an object, forcing selector numbers to be globally unique. 4.3 Selector coloring (SC) Selector coloring <ref> [D+89, AR92] </ref> is a compromise between VTBL and STI. SC is similar to STI, but instead of using the selector to index into the table, SC uses the selectors color. <p> Therefore we do not give example space data for multiple inheritance. However, it is obvious in [DH95] that P RD &lt; P VTBL &lt; P SC for samples with a As shown in <ref> [AR92] </ref>, the use of multiple inheritance introduces conicts between selector colors that are hard to deal with and that substantially increase the overhead. b Tables are harder to fit together because multiple inheritance causes more irregular empty regions to appear. c Every time a class inherits from more than one superclass,
Reference: [App88] <institution> Apple Computer, Inc. </institution> <note> Object Pascal Users Manual. Cupertino, </note> <year> 1988. </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94]. Similarly, concrete type inference [OPS92, VHU92, APS93, PC94, AH95] or link-time optimizations <ref> [App88, Fer95] </ref> can determine the concrete receiver types of calls, possibly eliminating dynamic dispatch for many sends. 8 Conclusions We have evaluated the dispatch cost of a range of dispatch mechanisms, taking into account the performance characteristics of modern pipelined superscalar microprocessors.
Reference: [CG94] <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing Indirect Function Call Overhead in C++ Programs. </title> <booktitle> In 21st Annual ACM Symposium on Principles of Programming Languages, p. </booktitle> <pages> 397-408, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: miss LC 250 a LC miss cost (find method in class dictionaries); conservative estimate based on data in [Ung87] h IC 95% inline caching hit ratio; from [Ung87] and [HCU91] miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) <ref> [HCU91, CG94] </ref> k 3.54 dynamic number of type tests per PIC stub (from SELF [Hl94]) p 10% average branch misprediction rate (estimate from [HP90]) M 1% fraction of calls from highly polymorphic call sites (&gt; 10 receiver types); conservative estimate (in SELF, M &lt; 0.1% [Hl94]) miss PIC 150 a +L+LC <p> The data presented so far assume a hit ratio of 95% which is typical for Smalltalk programs [Ung87] but may not represent other systems. For example, Calder et al. <ref> [CG94] </ref> report inline cache hit ratios for C++ programs that vary between 74% and 100%, with an average of 91%. Thus, the performance characteristics of IC and PIC deserve a closer investigation. expected, ICs cost increases with decreasing hit ratio. <p> The schemes dispatch cost is a linear combination of the two techniques cost. For example, Calders data <ref> [CG94] </ref> suggest that at least 66% of all virtual calls in C++ could be handled without misses by IC, reducing dispatch cost on P97 from 13 cycles for a pure VTBL implementation to 13* 0.34 + 4 * 0.66 = 5.6 cycles for VTBL+IC. <p> Hlzle et al. [HCU91] compare IC and PIC for the SELF system running on a scalar SPARC processor. Milton and Schmidt [MS94] compare the performance of VTBL-like techniques for Sather. None of these studies takes superscalar processors into account. Calder et al. <ref> [CG94] </ref> discuss branch misprediction penalties for indirect function calls in C++. Their measurements of several C++ programs indicate that inline caching might be effective for many C++ programs (although measurements by Garrett et al. [G+94] are somewhat less optimistic).
Reference: [CUL89] <author> Craig Chambers, David Ungar, and Elgin Lee. </author> <title> An Efficient Implementation of SELF, a Dynamically-Typed Object-Oriented Language Based on Prototypes. </title> <booktitle> In OOPSLA 89 Conference Proceedings, p. </booktitle> <pages> 49-70, </pages> <address> New Orleans, LA, </address> <month> October </month> <year> 1989. </year> <note> Published as SIGPLAN Notices 24(10), </note> <month> October </month> <year> 1989. </year>
Reference-contexts: Furthermore, we focus on dispatch performance and only briey discuss other issues such as space overhead and the closed vs. openworld assumption (see section 6). For space reasons, we consider only the main variant of each technique. 1 Alternatively, a system could duplicate code (e.g., as in SELF <ref> [CUL89] </ref>) or access instance variables indirectly (as is done in Eiffel and Sather [MS94]). variable b1 is different in instances of B versus instances of C. pb pc B ... ... ... ... a1 A B C adjusted pb A further simplification on the hardware side is that we do not <p> Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization <ref> [CUL89] </ref> and type feedback [HU94].
Reference: [CU+91] <author> Craig Chambers, David Ungar, Bay-Wei Chang, and Urs Hlzle. </author> <title> Parents are Shared Parts: Inheritance and Encapsulation in SELF. Lisp and Symbolic Computation 4(3), </title> <publisher> Kluwer Academic Publishers, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: Since multi-method dispatch techniques (e.g., [KR90, AGS94]) are similar and include single dispatch as an important (very frequent) special case, we hope that the results will nevertheless be useful for implementors or designers of multiple dispatch techniques. Also, we do not consider dynamic inheritance (as used in SELF <ref> [CU+91] </ref>), i.e., inheritance hierarchies that can change their structure at run-time. Furthermore, we focus on dispatch performance and only briey discuss other issues such as space overhead and the closed vs. openworld assumption (see section 6).
Reference: [CPL83] <author> T. Conroy and E. Pelegri-Llopart. </author> <title> An Assessment of Method-Lookup Caches for Smalltalk-80 Implementations. </title> <booktitle> In [GR83]. </booktitle>
Reference: [Cy90] <author> Cypress Semiconductors. </author> <title> CY7C601 SPARC processor, </title> <year> 1990. </year>
Reference-contexts: integer instructions/ cycle 1 2 4 max. loads or stores / cycle 1 1 2 max. control transfers (branch, call) / cycle 1 1 1 load latency (L) a 2 2 2 branch prediction no yes yes branch miss penalty (B) 1 b 3 6 examples of equivalent commercial CPUs <ref> [M92, Cy90] </ref> [M94, Gw94] N/A Table 2.
Reference: [DDH84] <author> P. Dencker, K. Drre, and J. Heuft. </author> <title> Optimization of Parser Tables for Portable Compilers. </title> <journal> TOPLAS 6(4) </journal> <pages> 546-572, </pages> <year> 1984. </year>
Reference-contexts: The algorithms goal is to minimize the size of the resulting master array by minimizing the number of empty entries; this problem is similar to parse table minimization for table-driven parsers <ref> [DDH84] </ref>. [Dri93a] discusses a selector numbering scheme that leaves only 33% of the entries empty for the Smalltalk image. If the table is sliced according to columns (instead of rows), the table can even be filled to 99.7% with an appropriate class numbering scheme [DH95].
Reference: [DH95] <author> Karel Driesen, Urs Hlzle. </author> <title> Minimizing Row Displacement Dispatch Tables. </title> <type> Technical Report TRCS 95-05, </type> <institution> Department of Computer Science, UCSB, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: If the table is sliced according to columns (instead of rows), the table can even be filled to 99.7% with an appropriate class numbering scheme <ref> [DH95] </ref>. Like SC, RD needs only a single table per class even with multiple inheritance, and the technique is applicable to dynamically-typed languages. <p> Most parameter values are taken from the ParcPlace Visualworks 1.0 Smalltalk system and thus model a fairly large application. For the multiple inheritance overhead we do not give typical values because there are none. The few samples in which multiple inheritance is extensively used in <ref> [DH95] </ref> show that the overhead varies much more than with single inheritance hierarchies (between 215% and 330% for VTBL), and that it is extremely dependent on how frequently MI is used. Therefore we do not give example space data for multiple inheritance. However, it is obvious in [DH95] that P RD <p> extensively used in <ref> [DH95] </ref> show that the overhead varies much more than with single inheritance hierarchies (between 215% and 330% for VTBL), and that it is extremely dependent on how frequently MI is used. Therefore we do not give example space data for multiple inheritance. However, it is obvious in [DH95] that P RD &lt; P VTBL &lt; P SC for samples with a As shown in [AR92], the use of multiple inheritance introduces conicts between selector colors that are hard to deal with and that substantially increase the overhead. b Tables are harder to fit together because multiple inheritance causes <p> (receiver class, selector) pairs; from Smalltalk e 4096 entries in LC lookup cache O DTS 133% DTS overhead factor = #total entries / #non-empty entries; from Smalltalk O SC 175% single inheritance overhead factor for SC; lower bound, from Smalltalk O RD 101% single inheritance overhead factor for RD; from <ref> [DH95] </ref> O CT 15% single inheritance compression rate for CT [VH94] P SC no data multiple inheritance overhead factor for SC a P RD no data multiple inheritance overhead factor for RD b P VTBL no data multiple inheritance overhead factor for CT c k 3.2 average number of cases in
Reference: [DM73] <author> O.-J. Dahl and B. Myrhaug. </author> <title> Simula Implementation Guide. </title> <institution> Publication S47, Norwegian Computing Center, Oslo, </institution> <month> March </month> <year> 1973. </year>
Reference-contexts: All of the static techniques discussed below try to retain the idea of STI (indexing into a table of function pointers) while reducing the space cost by omitting empty entries in the dispatch table. 4.2 Virtual function tables (VTBL) Virtual function tables were first used in Simula <ref> [DM73] </ref> and today are the preferred C++ dispatch mechanism [ES90]. Instead of assigning selector codes globally, VTBL assigns codes only within the scope of a class. In the single-inheritance case, selectors are numbered consecutively, starting with the highest selector number used in the superclass.
Reference: [DS84] <author> L. Peter Deutsch and Alan Schiffman. </author> <title> Efficient Implementation of the Smalltalk-80 System. </title> <booktitle> Proceedings of the 11th Symposium on the Principles of Programming Languages, </booktitle> <address> Salt Lake City, UT, </address> <year> 1984. </year>
Reference-contexts: For example, several studies have shown that the receiver type at a given call site remains constant 95% of the time in Smalltalk code <ref> [DS84, Ung87, UP87] </ref>. This locality of type usage can be exploited by caching the looked-up method address at the call site. <p> This locality of type usage can be exploited by caching the looked-up method address at the call site. Because the lookup result is cached in line at every call site (i.e., no separate lookup cache is accessed in the case of a hit), the technique is called inline caching <ref> [DS84, UP87] </ref>. The previous lookup result is cached by changing the call instruction implementing the send, i.e., by modifying the compiled program on the y. Initially, the call instruction calls the systems lookup routine. The first time this call is executed, the lookup routine finds the target method.
Reference: [D+89] <author> R. Dixon, T. McKee, P. Schweitzer, and M. Vaughan. </author> <title> A Fast Method Dispatcher for Compiled Languages with Multiple Inheritance. </title> <booktitle> OOPSLA 89 Conference Proceedings, </booktitle> <pages> pp. 211-214, </pages> <address> New Orleans, LA, </address> <month> October </month> <year> 1989. </year> <note> Published as SIGPLAN Notices 24(10), </note> <month> October </month> <year> 1989. </year>
Reference-contexts: Thus, with dynamic typing, VTBL dispatch tables would degenerate to STI tables since any arbitrary message could be sent to an object, forcing selector numbers to be globally unique. 4.3 Selector coloring (SC) Selector coloring <ref> [D+89, AR92] </ref> is a compromise between VTBL and STI. SC is similar to STI, but instead of using the selector to index into the table, SC uses the selectors color.
Reference: [Dri93a] <author> Karel Driesen. </author> <title> Selector Table Indexing and Sparse Arrays. </title> <booktitle> OOPSLA 93 Conference Proceedings, p. </booktitle> <pages> 259-270, </pages> <address> Washington, D.C., </address> <year> 1993. </year> <note> Published as SIGPLAN Notices 28(10), </note> <month> September </month> <year> 1993. </year>
Reference-contexts: Otherwise, an erroneous send (which should result in a message not understood error) could invoke a method with a different selector that shares the same color. For example, in 4.4 Row displacement (RD) Row displacement <ref> [Dri93a] </ref> is another way of compressing STIs dispatch table. It slices the (two-dimensional) STI table into rows and fits the rows into a one-dimensional array so that non-empty entries overlap only with empty ones (Figure 9). <p> The algorithms goal is to minimize the size of the resulting master array by minimizing the number of empty entries; this problem is similar to parse table minimization for table-driven parsers [DDH84]. <ref> [Dri93a] </ref> discusses a selector numbering scheme that leaves only 33% of the entries empty for the Smalltalk image. If the table is sliced according to columns (instead of rows), the table can even be filled to 99.7% with an appropriate class numbering scheme [DH95].
Reference: [Dri93b] <author> Karel Driesen. </author> <title> Method Lookup Strategies in Dynamically-Typed Object-Oriented Programming Languages. </title> <type> Masters Thesis, </type> <institution> Vrije Universiteit Brussel, </institution> <year> 1993. </year>
Reference-contexts: Unfortunately, the resulting dispatch table is very large (O (c*s)) and very sparse, since most messages are defined for only a few classes. For example, about 95% of the entries would be empty in a table for a Smalltalk image <ref> [Dri93b] </ref>. With multiple inheritance, every entry consists of a method code address and a delta (the adjustment to the receiver address). To avoid cluttering the graphics, we do not show the latter in any figure. STI works equally well for static and dynamic typing, and its dispatch sequence is fast. <p> b c e fd g 0 A 5 D 1 4 a b e d g 2 method prologue (dynamic typing in bold) entry = object-&gt;table [#color]; entry.func (object, entry.delta, #selector, arguments) /* method prologue */ if (S != #mySelector) error (Message Not Understood); adjusted = delta + object; system <ref> [Dri93b] </ref>. As shown in Figure 8, coloring allows the sharing of columns of the selector table used in STI. Compared to VTBL, SC has two potential advantages. First, since selector colors are global, only one dispatch table is needed per class, even in the context of multiple inheritance. <p> VTBL, RD, and SC require significantly more data space than DTS because they duplicate information. Each class stores all the messages it understands, instead of all the messages it defines. For example, in the Smalltalk system a class inherits 20 methods for each one it defines <ref> [Dri93b] </ref>, so the number of entries stored in the class dispatch table increases by a factor of 20. Dynamic typing makes a relatively small difference in space cost. Dynamic techniques have no extra overhead because each dispatch already contains a run-time check to test for the cache hit. <p> Other studies have analyzed the performance of one or two dispatch sequences. For example, Ungar [Ung87] analyzes the performance of IC, LC, and no caching on SOAR, a RISC-processor designed to run Smalltalk. Driesen <ref> [Dri93b] </ref> analyzes algorithmic issues of a number of dispatch techniques for dynamically-typed languages, but without taking processor architecture into account. Hlzle et al. [HCU91] compare IC and PIC for the SELF system running on a scalar SPARC processor. Milton and Schmidt [MS94] compare the performance of VTBL-like techniques for Sather.
Reference: [Dus89] <author> P. Dussud. TICLOS: </author> <title> An implementation of CLOS for the Explorer Family. </title> <booktitle> OOPSLA 89 Conference Proceedings, </booktitle> <pages> pp. 215-220, </pages> <address> New Orleans, LA, </address> <month> October </month> <year> 1989. </year> <note> Published as SIGPLAN Notices 24(10), </note> <month> October </month> <year> 1989. </year>
Reference: [ES90] <author> Margaret A. Ellis and Bjarne Stroustrup. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference-contexts: Hard-coded offsets can be retained if the receiver objects address is adjusted just before a B method is executed, so that it points to the B subobject within C <ref> [Kro85, ES90] </ref>. 1 The adjustment can be different for every class that has B as a (co-)parent. (If dynamic typing is combined with multiple inheritance it is necessary to keep track of both the unadjusted address and the adjustment.) Strictly speaking, this extra code is not part of method lookup, but <p> below try to retain the idea of STI (indexing into a table of function pointers) while reducing the space cost by omitting empty entries in the dispatch table. 4.2 Virtual function tables (VTBL) Virtual function tables were first used in Simula [DM73] and today are the preferred C++ dispatch mechanism <ref> [ES90] </ref>. Instead of assigning selector codes globally, VTBL assigns codes only within the scope of a class. In the single-inheritance case, selectors are numbered consecutively, starting with the highest selector number used in the superclass. <p> In C++ <ref> [ES90] </ref>, the conict is resolved by using multiple virtual tables per class. <p> For example, 43% of the entries are empty (i.e., contain message not understood) for the Smalltalk 1 Due to limited space, we ignore virtual base classes in this discussion. They introduce an extra overhead of a memory reference and a subtraction <ref> [ES90] </ref>. 2 The selectors are the nodes of the graph, and two nodes are connected by an arc if the two selectors co occur in any class. c 0 A 5 D 1 4 2 a b c e fd g 0 A 5 D 1 4 a b e d
Reference: [Fer95] <author> Mary F. Fernandez. </author> <title> Simple and effective link-time optimization of Modula-3 programs. </title> <booktitle> To appear in Proceedings of the SIGPLAN 95 Conference on Programming Language Design and Implementation, </booktitle> <year> 1995. </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94]. Similarly, concrete type inference [OPS92, VHU92, APS93, PC94, AH95] or link-time optimizations <ref> [App88, Fer95] </ref> can determine the concrete receiver types of calls, possibly eliminating dynamic dispatch for many sends. 8 Conclusions We have evaluated the dispatch cost of a range of dispatch mechanisms, taking into account the performance characteristics of modern pipelined superscalar microprocessors.
Reference: [G+94] <author> Charles D. Garrett, Jeffrey Dean, David Grove, and Craig Chambers. </author> <title> Measurement and Application of Dynamic Receiver Class Distributions. </title> <type> Technical Report CSE-TR-94-03-05, </type> <institution> University of Washington, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: None of these studies takes superscalar processors into account. Calder et al. [CG94] discuss branch misprediction penalties for indirect function calls in C++. Their measurements of several C++ programs indicate that inline caching might be effective for many C++ programs (although measurements by Garrett et al. <ref> [G+94] </ref> are somewhat less optimistic). Calder et al. propose to improve performance with if-conversion, an inline cache with a statically determined target. For each call site the address of the most frequently called function is determined from execution profiles.
Reference: [GR83] <author> Adele Goldberg and David Robson. </author> <title> Smalltalk-80: The Language and its Implementation. Second Edition, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1985. </year>
Reference-contexts: This section discusses two kinds of caching: global caching (one large cache per system) and inline caching (one small cache per call site). 3.1 Global lookup caches (LC) First-generation Smalltalk implementations relied on a global cache to speed up method lookup <ref> [GR83, Kra83] </ref>. The class of a receiver, combined with the message selector, hashes into an index in a global cache. Each cache entry consists of a class, a selector and a method address.
Reference: [Gw94] <author> Linley Gwennap. </author> <title> Digital leads the pack with 21164. </title> <type> Microprocessor Report 8(12), </type> <month> September 12, </month> <year> 1994. </year>
Reference-contexts: cycle 1 2 4 max. loads or stores / cycle 1 1 2 max. control transfers (branch, call) / cycle 1 1 1 load latency (L) a 2 2 2 branch prediction no yes yes branch miss penalty (B) 1 b 3 6 examples of equivalent commercial CPUs [M92, Cy90] <ref> [M94, Gw94] </ref> N/A Table 2. <p> branch penalty B in the formulas of Tables 5 and 6, but the extent of the reduction depends on the BTB miss ratio (i.e., inline cache miss ratio) of the application. 1 Procedure returns are the exception, but these can be handled more efficiently by a return address prediction buffer <ref> [Gw94] </ref>. 6 Other considerations Besides the actual speed of message sends, other considerations inuence the choice between dispatch techniques.
Reference: [HP90] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers Inc. </publisher> <year> 1990. </year>
Reference-contexts: Branch penalty. The processor predicts the outcome of a conditional branch; if the prediction is correct, the branch incurs no additional cost. However, if the prediction is incorrect, the processor will stall for B cycles while fetching and decoding the instructions following the branch <ref> [HP90] </ref>. We assume that indirect calls or jumps cannot be predicted and always incur the branch penalty. 1 Virtually all processors announced since 1993 exhibit all three characteristics. We also assumed out-of-order execution for the superscalar machines (P95 and P97). <p> caching hit ratio; from [Ung87] and [HCU91] miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) [HCU91, CG94] k 3.54 dynamic number of type tests per PIC stub (from SELF [Hl94]) p 10% average branch misprediction rate (estimate from <ref> [HP90] </ref>) M 1% fraction of calls from highly polymorphic call sites (&gt; 10 receiver types); conservative estimate (in SELF, M &lt; 0.1% [Hl94]) miss PIC 150 a +L+LC PIC miss cost; based on miss IC (overhead for updating the PIC) s 99.93% percentage of single (non-overloaded) entries in CT [VH94] e <p> For details on pipeline organization, we refer the reader to <ref> [HP90] </ref>. single inheritance multiple inheritance static typing dynamic typing static typing dynamic typing LC h LC *(9+max (7,2L)+(1-h LC )*miss LC h LC *(9+max (10,2L))+(1-h LC )*miss LC VTBL 2+2L N/A 2+2L N/A SC 2+2L 4+2L 2+2L 5+2L CT s*(2+3L)+(1-s) s*(8+3L)+(1-s) N/A N/A IC h IC * (2+max (3,L)) + (1-h <p> Since VTBL uses an indirect call, the processor does not know its target 1 Recall that P92 machines had a branch latency B = 1, which can be eliminated using explicit branch delay slots; see <ref> [HP90] </ref> for details. <p> Dependencies are indicated with arrows. 6 address until after the branch executes (in cycle 2L). At that point, it starts fetching new instructions, but it takes B cycles until the first new instruction reaches the EX (execute) stage of the pipeline <ref> [HP90] </ref>, resulting in a total execution time of 2L+B+1. Finally, P97 can execute up to 4 instructions per cycle, but again this capability is largely unused, except that instructions 2 and 3 (two loads) can execute in parallel. <p> aggressively superscalar P97 processor, dispatch cost rises for many dispatch techniques instead of falling further as one would expect. 1 3 cycles in P95 to 6 cycles in P97 because the latter processor has a deeper pipeline in order to achieve a higher clock rate and thus better overall performance <ref> [HP90] </ref>. Except for the inline caching variants (IC and PIC), all techniques have at least one unpredictable branch even in the best case, and thus their cost increases with the cost of a branch misprediction. <p> Furthermore, the average basic block length (and thus the number of instructions readily available to be scheduled with the call) is quite small, usually between five and six <ref> [HP90] </ref>. On superscalar processors (especially on P97) most dispatch sequences have plenty of holes to accommodate that number of instructions. Thus, we assume that most techniques would benefit from co-scheduled application code to roughly the same extent. A branch target buffer (BTB) [HP90] allows hardware to predict indirect calls by storing <p> is quite small, usually between five and six <ref> [HP90] </ref>. On superscalar processors (especially on P97) most dispatch sequences have plenty of holes to accommodate that number of instructions. Thus, we assume that most techniques would benefit from co-scheduled application code to roughly the same extent. A branch target buffer (BTB) [HP90] allows hardware to predict indirect calls by storing the target address of the previous call, similar to inline caching.
Reference: [HCU91] <author> Urs Hlzle, Craig Chambers, and David Ungar. </author> <title> Optimizing Dynamically-Typed Object-Oriented Languages with Polymorphic Inline Caches. </title> <booktitle> In ECOOP 91 Conference Proceedings, Geneva, 1991. Published as Springer Verlag Lecture Notes in Computer Science 512, </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: Fortunately, hit ratios are usually very good, on the order of 90-99% for typical Smalltalk or SELF code <ref> [Ung87, HCU91] </ref>. Therefore, many current Smalltalk implementations incorporate inline caches. 3.3 Polymorphic inline caching (PIC) Inline caches are effective only if the receiver type (and thus the call target) remains relatively constant at a call site. <p> The performance impact of inline cache misses can become severe in highly efficient systems. For example, measurements of the SELF-90 system showed that it spent up to 25% of its time handling inline cache misses <ref> [HCU91] </ref>. Polymorphic inline caches (PICs) [HCU91] reduce the inline cache miss overhead by caching several lookup results for a given polymorphic call site using a dynamically-generated PIC routine. <p> The performance impact of inline cache misses can become severe in highly efficient systems. For example, measurements of the SELF-90 system showed that it spent up to 25% of its time handling inline cache misses <ref> [HCU91] </ref>. Polymorphic inline caches (PICs) [HCU91] reduce the inline cache miss overhead by caching several lookup results for a given polymorphic call site using a dynamically-generated PIC routine. Instead of just switching the inline cache at a miss, the new receiver type is added to the cache by extending the stub routine. <p> characteristics Variable Typical value Comments h LC 98% lookup cache hit ratio ([CPL83] lists 93% for a very small cache size) miss LC 250 a LC miss cost (find method in class dictionaries); conservative estimate based on data in [Ung87] h IC 95% inline caching hit ratio; from [Ung87] and <ref> [HCU91] </ref> miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) [HCU91, CG94] k 3.54 dynamic number of type tests per PIC stub (from SELF [Hl94]) p 10% average branch misprediction rate (estimate from [HP90]) M 1% fraction of calls from <p> hit ratio ([CPL83] lists 93% for a very small cache size) miss LC 250 a LC miss cost (find method in class dictionaries); conservative estimate based on data in [Ung87] h IC 95% inline caching hit ratio; from [Ung87] and <ref> [HCU91] </ref> miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) [HCU91, CG94] k 3.54 dynamic number of type tests per PIC stub (from SELF [Hl94]) p 10% average branch misprediction rate (estimate from [HP90]) M 1% fraction of calls from highly polymorphic call sites (&gt; 10 receiver types); conservative estimate <p> miss LC 250 a LC miss cost (find method in class dictionaries); conservative estimate based on data in [Ung87] h IC 95% inline caching hit ratio; from [Ung87] and [HCU91] miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) <ref> [HCU91, CG94] </ref> k 3.54 dynamic number of type tests per PIC stub (from SELF [Hl94]) p 10% average branch misprediction rate (estimate from [HP90]) M 1% fraction of calls from highly polymorphic call sites (&gt; 10 receiver types); conservative estimate (in SELF, M &lt; 0.1% [Hl94]) miss PIC 150 a +L+LC <p> For example, Ungar [Ung87] analyzes the performance of IC, LC, and no caching on SOAR, a RISC-processor designed to run Smalltalk. Driesen [Dri93b] analyzes algorithmic issues of a number of dispatch techniques for dynamically-typed languages, but without taking processor architecture into account. Hlzle et al. <ref> [HCU91] </ref> compare IC and PIC for the SELF system running on a scalar SPARC processor. Milton and Schmidt [MS94] compare the performance of VTBL-like techniques for Sather. None of these studies takes superscalar processors into account. Calder et al. [CG94] discuss branch misprediction penalties for indirect function calls in C++.
Reference: [HU94] <author> Urs Hlzle and David Ungar. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In PLDI 94 Conference Proceedings, </booktitle> <pages> pp. 326-335, </pages> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year> <note> Published as SIGPLAN Notices 29(6), </note> <month> June </month> <year> 1994. </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback <ref> [HU94] </ref>.
Reference: [Hl94] <author> Urs Hlzle. </author> <title> Adaptive Optimization for Self: Reconciling High Performance with Exploratory Programming. </title> <type> Ph.D. Thesis, Technical Report STAN-CS-TR-94-1520, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1994. </year>
Reference-contexts: based on data in [Ung87] h IC 95% inline caching hit ratio; from [Ung87] and [HCU91] miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) [HCU91, CG94] k 3.54 dynamic number of type tests per PIC stub (from SELF <ref> [Hl94] </ref>) p 10% average branch misprediction rate (estimate from [HP90]) M 1% fraction of calls from highly polymorphic call sites (&gt; 10 receiver types); conservative estimate (in SELF, M &lt; 0.1% [Hl94]) miss PIC 150 a +L+LC PIC miss cost; based on miss IC (overhead for updating the PIC) s 99.93% <p> from monomorphic call sites (PIC) [HCU91, CG94] k 3.54 dynamic number of type tests per PIC stub (from SELF <ref> [Hl94] </ref>) p 10% average branch misprediction rate (estimate from [HP90]) M 1% fraction of calls from highly polymorphic call sites (&gt; 10 receiver types); conservative estimate (in SELF, M &lt; 0.1% [Hl94]) miss PIC 150 a +L+LC PIC miss cost; based on miss IC (overhead for updating the PIC) s 99.93% percentage of single (non-overloaded) entries in CT [VH94] e 2.25 number of tests per overloaded entry in CT Table 3. Additional parameters inuencing performance previously published performance studies). <p> compression rate for CT [VH94] P SC no data multiple inheritance overhead factor for SC a P RD no data multiple inheritance overhead factor for RD b P VTBL no data multiple inheritance overhead factor for CT c k 3.2 average number of cases in a PIC stub; from SELF <ref> [Hl94] </ref> f 7.2% polymorphic call sites, as a fraction of total; from SELF [Hl94] e 3.49 average number of functions in an overloaded entry (CT) n 0.07% overloaded entries, as fraction of total (CT) Table 7. Parameters used for space cost analysis extensive MI. <p> for SC a P RD no data multiple inheritance overhead factor for RD b P VTBL no data multiple inheritance overhead factor for CT c k 3.2 average number of cases in a PIC stub; from SELF <ref> [Hl94] </ref> f 7.2% polymorphic call sites, as a fraction of total; from SELF [Hl94] e 3.49 average number of functions in an overloaded entry (CT) n 0.07% overloaded entries, as fraction of total (CT) Table 7. Parameters used for space cost analysis extensive MI. Table 8 contains formulas for computing the space cost if the overhead is known. <p> Ingalls [Ing86] shows how to implement multiple dispatch with a sequence of single dispatch, but such implementations may not be optimal [AGS94]. Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches <ref> [Hl94] </ref> with compiler optimizations such as customization [CUL89] and type feedback [HU94].
Reference: [Ing86] <author> Daniel H. Ingalls. </author> <title> A simple technique for handling multiple polymorphism. </title> <booktitle> OOPSLA 86 Conference Proceedings, p. </booktitle> <pages> 347-349, </pages> <address> Portland, OR., </address> <year> 1986. </year> <note> Published as SIGPLAN Notices 21(11), </note> <month> November </month> <year> 1986. </year>
Reference-contexts: We have considered single dispatch only; multiple dispatch techniques are discussed in [KR90] and [AGS94]. However, singly-dispatched calls are so frequent even in systems offering multiple dispatch that implementations usually special-case these calls. Ingalls <ref> [Ing86] </ref> shows how to implement multiple dispatch with a sequence of single dispatch, but such implementations may not be optimal [AGS94]. Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast).
Reference: [KR90] <author> Gregor Kiczales and Louis Rodriguez. </author> <title> Efficient Method Dispatch in PCL. </title> <booktitle> Proc. ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1990. </year> <note> Also in [Pae93]. </note>
Reference-contexts: Since multi-method dispatch techniques (e.g., <ref> [KR90, AGS94] </ref>) are similar and include single dispatch as an important (very frequent) special case, we hope that the results will nevertheless be useful for implementors or designers of multiple dispatch techniques. <p> Calder et al. propose to improve performance with if-conversion, an inline cache with a statically determined target. For each call site the address of the most frequently called function is determined from execution profiles. We have considered single dispatch only; multiple dispatch techniques are discussed in <ref> [KR90] </ref> and [AGS94]. However, singly-dispatched calls are so frequent even in systems offering multiple dispatch that implementations usually special-case these calls. Ingalls [Ing86] shows how to implement multiple dispatch with a sequence of single dispatch, but such implementations may not be optimal [AGS94].
Reference: [Kra83] <author> Glenn Krasner. </author> <title> Smalltalk-80: Bits of History, Words of Advice. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference-contexts: This section discusses two kinds of caching: global caching (one large cache per system) and inline caching (one small cache per call site). 3.1 Global lookup caches (LC) First-generation Smalltalk implementations relied on a global cache to speed up method lookup <ref> [GR83, Kra83] </ref>. The class of a receiver, combined with the message selector, hashes into an index in a global cache. Each cache entry consists of a class, a selector and a method address.
Reference: [Kro85] <author> Stein Krogdahl. </author> <title> Multiple inheritance in Simula-like languages. BIT 25, </title> <booktitle> p. </booktitle> <pages> 318-326, </pages> <year> 1985. </year>
Reference-contexts: Hard-coded offsets can be retained if the receiver objects address is adjusted just before a B method is executed, so that it points to the B subobject within C <ref> [Kro85, ES90] </ref>. 1 The adjustment can be different for every class that has B as a (co-)parent. (If dynamic typing is combined with multiple inheritance it is necessary to keep track of both the unadjusted address and the adjustment.) Strictly speaking, this extra code is not part of method lookup, but
Reference: [MS94] <author> S. Milton and Heinz W. Schmidt. </author> <title> Dynamic Dispatch in Object-Oriented Languages. </title> <type> Technical Report TR-CS-94-02, </type> <institution> The Australian National University, Canberra, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: For space reasons, we consider only the main variant of each technique. 1 Alternatively, a system could duplicate code (e.g., as in SELF [CUL89]) or access instance variables indirectly (as is done in Eiffel and Sather <ref> [MS94] </ref>). variable b1 is different in instances of B versus instances of C. pb pc B ... ... ... ... a1 A B C adjusted pb A further simplification on the hardware side is that we do not consider every possible processor implementation feature. <p> Driesen [Dri93b] analyzes algorithmic issues of a number of dispatch techniques for dynamically-typed languages, but without taking processor architecture into account. Hlzle et al. [HCU91] compare IC and PIC for the SELF system running on a scalar SPARC processor. Milton and Schmidt <ref> [MS94] </ref> compare the performance of VTBL-like techniques for Sather. None of these studies takes superscalar processors into account. Calder et al. [CG94] discuss branch misprediction penalties for indirect function calls in C++.
Reference: [M92] <institution> MIPS Inc. </institution> <type> R4000 Technical Brief, </type> <year> 1992. </year>
Reference-contexts: integer instructions/ cycle 1 2 4 max. loads or stores / cycle 1 1 2 max. control transfers (branch, call) / cycle 1 1 1 load latency (L) a 2 2 2 branch prediction no yes yes branch miss penalty (B) 1 b 3 6 examples of equivalent commercial CPUs <ref> [M92, Cy90] </ref> [M94, Gw94] N/A Table 2.
Reference: [M94] <institution> MIPS Inc. R10000 Technical Brief, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: cycle 1 2 4 max. loads or stores / cycle 1 1 2 max. control transfers (branch, call) / cycle 1 1 1 load latency (L) a 2 2 2 branch prediction no yes yes branch miss penalty (B) 1 b 3 6 examples of equivalent commercial CPUs [M92, Cy90] <ref> [M94, Gw94] </ref> N/A Table 2.
Reference: [OPS92] <author> Nicholas Oxhy, Jens Palsberg, and Michael I. Schwartzbach. </author> <title> Making Type Inference Practical. </title> <booktitle> In ECOOP 92 Conference Proceedings, p. </booktitle> <pages> 329-349, </pages> <address> Utrecht, The Netherlands, </address> <month> June/July </month> <year> 1992 </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94]. Similarly, concrete type inference <ref> [OPS92, VHU92, APS93, PC94, AH95] </ref> or link-time optimizations [App88, Fer95] can determine the concrete receiver types of calls, possibly eliminating dynamic dispatch for many sends. 8 Conclusions We have evaluated the dispatch cost of a range of dispatch mechanisms, taking into account the performance characteristics of modern pipelined superscalar microprocessors.
Reference: [Pae93] <author> Andreas Paepcke (ed.). </author> <title> Object-Oriented Programming: The CLOS Perspective, </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference: [PC94] <author> John Plevyak and Andrew A. Chien. </author> <title> Precise concrete type inference for object-oriented languages. </title> <booktitle> In OOPSLA 94 Conference Proceedings, </booktitle> <pages> pp. 324-340, </pages> <month> October </month> <year> 1994. </year> <note> Published as SIGPLAN Notices 29(10), </note> <month> October </month> <year> 1994. </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94]. Similarly, concrete type inference <ref> [OPS92, VHU92, APS93, PC94, AH95] </ref> or link-time optimizations [App88, Fer95] can determine the concrete receiver types of calls, possibly eliminating dynamic dispatch for many sends. 8 Conclusions We have evaluated the dispatch cost of a range of dispatch mechanisms, taking into account the performance characteristics of modern pipelined superscalar microprocessors.
Reference: [PW90] <author> William Pugh and Grant Weddell. </author> <title> Two-Directional Record Layout for Multiple Inheritance. </title> <booktitle> In Proceedings of the SIGPLAN 90 Conference on Programming Language Design and Implementation, p. </booktitle> <pages> 85-91, </pages> <address> White Plains, NY, </address> <month> June, </month> <year> 1990. </year> <note> Published as SIGPLAN Notices 25(6), </note> <month> June </month> <year> 1990. </year>
Reference: [Ros88] <author> John Rose. </author> <title> Fast Dispatch Mechanisms for Stock Hardware. </title> <booktitle> OOPSLA'88 Conference Proceedings, p. </booktitle> <pages> 27-35, </pages> <address> San Diego, CA, </address> <month> November </month> <year> 1988. </year> <note> Published as SIGPLAN Notices 23(11), </note> <month> November </month> <year> 1988. </year>
Reference-contexts: For this study, only the simplest and fastest version of each technique was considered, but any variant can be analyzed using the same evaluation methodology. 7 Related work Rose <ref> [Ros88] </ref> analyzes dispatch performance for a number of table-based techniques, assuming a RISC architecture and a scalar processor. The analysis included both dispatch and tag checking code sequences. The study considers some architecture-related performance aspects such as the limited range of immediates in instructions.
Reference: [UP83] <author> David Ungar and David Patterson. </author> <title> Berkeley Smalltalk: Who Knows Where the Time Goes? In [GR83]. </title>
Reference: [Ung87] <author> David Ungar. </author> <title> The Design and Evaluation of a High-Performance Smalltalk System. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: For example, several studies have shown that the receiver type at a given call site remains constant 95% of the time in Smalltalk code <ref> [DS84, Ung87, UP87] </ref>. This locality of type usage can be exploited by caching the looked-up method address at the call site. <p> Fortunately, hit ratios are usually very good, on the order of 90-99% for typical Smalltalk or SELF code <ref> [Ung87, HCU91] </ref>. Therefore, many current Smalltalk implementations incorporate inline caches. 3.3 Polymorphic inline caching (PIC) Inline caches are effective only if the receiver type (and thus the call target) remains relatively constant at a call site. <p> Processor characteristics Variable Typical value Comments h LC 98% lookup cache hit ratio ([CPL83] lists 93% for a very small cache size) miss LC 250 a LC miss cost (find method in class dictionaries); conservative estimate based on data in <ref> [Ung87] </ref> h IC 95% inline caching hit ratio; from [Ung87] and [HCU91] miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) [HCU91, CG94] k 3.54 dynamic number of type tests per PIC stub (from SELF [Hl94]) p 10% average branch <p> Processor characteristics Variable Typical value Comments h LC 98% lookup cache hit ratio ([CPL83] lists 93% for a very small cache size) miss LC 250 a LC miss cost (find method in class dictionaries); conservative estimate based on data in <ref> [Ung87] </ref> h IC 95% inline caching hit ratio; from [Ung87] and [HCU91] miss IC 80 a +L+LC IC miss cost; from [HCU91] m 66% fraction of calls from monomorphic call sites (PIC) [HCU91, CG94] k 3.54 dynamic number of type tests per PIC stub (from SELF [Hl94]) p 10% average branch misprediction rate (estimate from [HP90]) M 1% fraction of <p> Instead, dispatch cost is a function of program behavior: different programs will see different dispatch costs if their polymorphism characteristics (and thus their inline cache hit ratios) vary. The data presented so far assume a hit ratio of 95% which is typical for Smalltalk programs <ref> [Ung87] </ref> but may not represent other systems. For example, Calder et al. [CG94] report inline cache hit ratios for C++ programs that vary between 74% and 100%, with an average of 91%. <p> The analysis included both dispatch and tag checking code sequences. The study considers some architecture-related performance aspects such as the limited range of immediates in instructions. Other studies have analyzed the performance of one or two dispatch sequences. For example, Ungar <ref> [Ung87] </ref> analyzes the performance of IC, LC, and no caching on SOAR, a RISC-processor designed to run Smalltalk. Driesen [Dri93b] analyzes algorithmic issues of a number of dispatch techniques for dynamically-typed languages, but without taking processor architecture into account.
Reference: [UP87] <author> David Ungar and David Patterson. </author> <title> What Price Smalltalk? In IEEE Computer 20(1), </title> <month> January </month> <year> 1987. </year>
Reference-contexts: For example, several studies have shown that the receiver type at a given call site remains constant 95% of the time in Smalltalk code <ref> [DS84, Ung87, UP87] </ref>. This locality of type usage can be exploited by caching the looked-up method address at the call site. <p> This locality of type usage can be exploited by caching the looked-up method address at the call site. Because the lookup result is cached in line at every call site (i.e., no separate lookup cache is accessed in the case of a hit), the technique is called inline caching <ref> [DS84, UP87] </ref>. The previous lookup result is cached by changing the call instruction implementing the send, i.e., by modifying the compiled program on the y. Initially, the call instruction calls the systems lookup routine. The first time this call is executed, the lookup routine finds the target method.
Reference: [VH94] <author> Jan Vitek and R. N. Horspool. </author> <title> Taming Message Passing: Efficient Method Look-Up for Dynamically-Typed Languages. </title> <booktitle> In ECOOP '94 Conference Proceedings, </booktitle> <address> Bologna, Italy, </address> <year> 1994. </year>
Reference-contexts: 71 2 8 4 entry = object-&gt;table [#selector]; entry.func (object, entry.delta, #selector, arguments); /* method prologue */ if (S != #mySelector) error (Message Not Understood); adjusted = delta + object; 0 A 0 C 4 0 E 7 48 4.5 Compact Selector-Indexed Dispatch Tables (CT) The third table compaction method <ref> [VH94] </ref>, unlike the two previous methods, generates selector-specific dispatch code sequences. The technique separates selectors into two categories. Standard selectors have one main definition and are only overridden in the subclasses (e.g., a and b in Figure 10). <p> Subtype tests are implemented with a simple series of logical operations (a bit-wise AND and a comparison) [Vit95]. Figure 11 shows the code for a call through a CT dispatch table. This version of the algorithm (from <ref> [VH94] </ref>) only handles single inheritance, because of the lack of fast type inclusion test for multiple inheritance. 1 5 Analysis 5.1 Parameters inuencing performance To evaluate the performance of the dispatch mechanisms, we implemented the dispatch instruction sequence of each technique on a simple RISC-like architecture. 2 Table A-2 in the <p> from [HP90]) M 1% fraction of calls from highly polymorphic call sites (&gt; 10 receiver types); conservative estimate (in SELF, M &lt; 0.1% [Hl94]) miss PIC 150 a +L+LC PIC miss cost; based on miss IC (overhead for updating the PIC) s 99.93% percentage of single (non-overloaded) entries in CT <ref> [VH94] </ref> e 2.25 number of tests per overloaded entry in CT Table 3. Additional parameters inuencing performance previously published performance studies). However, it should be emphasized that these values merely represent one particular data point. Different systems, applications, or languages may well exhibit different parameter values. <p> LC lookup cache O DTS 133% DTS overhead factor = #total entries / #non-empty entries; from Smalltalk O SC 175% single inheritance overhead factor for SC; lower bound, from Smalltalk O RD 101% single inheritance overhead factor for RD; from [DH95] O CT 15% single inheritance compression rate for CT <ref> [VH94] </ref> P SC no data multiple inheritance overhead factor for SC a P RD no data multiple inheritance overhead factor for RD b P VTBL no data multiple inheritance overhead factor for CT c k 3.2 average number of cases in a PIC stub; from SELF [Hl94] f 7.2% polymorphic call
Reference: [VH95] <author> Jan Vitek and R.N. Horspool, </author> <title> Fast Constant-Time Type Inclusion Tests, </title> <type> Unpublished manuscript, </type> <year> 1995. </year>
Reference-contexts: Load latency. Because of pipelining, the result of a load started in cycle i is not available until cycle i + L (i.e., the processor will stall if the result is used before that time). 1 This problem is tackled in <ref> [VH95] </ref>. [Vit95] presents a version of the algorithm which improves dispatch speed and shortens the calling sequence.
Reference: [Vit95] <author> Jan Vitek. </author> <title> Compact Dispatch Tables for Dynamically-Typed Object-Oriented Languages. M.S. </title> <type> Thesis, </type> <institution> University of Victoria, B.C., forthcoming. </institution>
Reference-contexts: For statically-typed languages, only the code stubs of overloaded entries need such a test. Subtype tests are implemented with a simple series of logical operations (a bit-wise AND and a comparison) <ref> [Vit95] </ref>. Figure 11 shows the code for a call through a CT dispatch table. <p> Load latency. Because of pipelining, the result of a load started in cycle i is not available until cycle i + L (i.e., the processor will stall if the result is used before that time). 1 This problem is tackled in [VH95]. <ref> [Vit95] </ref> presents a version of the algorithm which improves dispatch speed and shortens the calling sequence.
Reference: [VHU92] <author> Jan Vitek, R. N. Horspool, and J. Uhl. </author> <title> Compile-time analysis of object-oriented programs. </title> <booktitle> Proc. CC'92, 4th International Conference on Compiler Construction, </booktitle> <pages> pp. 236-250, </pages> <address> Paderborn, Germany, </address> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Dispatch overhead can also be reduced by eliminating dispatches (rather than just making them fast). For example, the SELF-93 system inlines 95% of all dispatches [Hl94] with compiler optimizations such as customization [CUL89] and type feedback [HU94]. Similarly, concrete type inference <ref> [OPS92, VHU92, APS93, PC94, AH95] </ref> or link-time optimizations [App88, Fer95] can determine the concrete receiver types of calls, possibly eliminating dynamic dispatch for many sends. 8 Conclusions We have evaluated the dispatch cost of a range of dispatch mechanisms, taking into account the performance characteristics of modern pipelined superscalar microprocessors.
References-found: 46

