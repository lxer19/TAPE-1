URL: ftp://ftp.cs.arizona.edu/reports/1998/TR98-11.ps
Refering-URL: http://www.cs.arizona.edu/research/reports.html
Root-URL: http://www.cs.arizona.edu
Email: fbkmoon,ifvegag@cs.arizona.edu vijay.immanuel@tandem.com  
Title: Scalable Algorithms for Large-Scale Temporal Aggregation  
Author: Bongki Moon Ines Fernando Vega Lopez Vijaykumar Immanuel 
Note: November  This work was sponsored in part by National Science Foundation Research Infrastructure program EIA-9500991. The authors assume all responsibility for the contents of the paper.  
Date: 98-11  1998  
Address: 19333 Vallco Pkwy Tucson, AZ 85721 Cupertino, CA 95014  Tucson, AZ 85721  
Affiliation: Dept. of Computer Science Tandem Computers Inc. University of Arizona  Department of Computer Science The University of Arizona  
Pubnum: Technical Report  
Abstract: The ability to model time-varying natures is essential to many database applications such as data warehousing and mining. However, the temporal aspects provide many unique characteristics and challenges for query processing and optimization. Among the challenges is computing temporal aggregates, which is complicated by having to compute temporal grouping. In this paper, we introduce a variety of temporal aggregation algorithms that overcome major drawbacks of previous work. First, for small-scale aggregations, both the worst-case and average-case processing time have been improved significantly. Second, for large-scale aggregations, the proposed algorithms can deal with a database that is substantially larger than the size of available memory. Third, the parallel algorithm designed on a shared-nothing architecture achieves scalable performance by delivering nearly linear scale-up and speed-up. The contributions made in this paper are particularly important because the rate of increase in database size and response time requirements has out-paced advancements in processor and mass storage technology. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Barnett, S. Gupta, D. Payne, L. Shuler R. van de Geijn, and J. Watts. </author> <title> Interprocessor collective communication library (InterCom). </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference (SHPCC-94), </booktitle> <pages> pages 357-364, </pages> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year> <month> 17 </month>
Reference-contexts: For example, op will be an addition operator for a count aggregation and a maximum operator for a max aggregation. Such collective communication for computing a final global meta array can be implemented efficiently on most parallel computers and networks of workstations <ref> [1] </ref>.
Reference: [2] <author> Jon Louis Bentley. </author> <title> Algorithms for Klee's rectangle problems. </title> <type> Technical Report unpublished, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1977. </year>
Reference-contexts: The aggregation tree is a binary tree, which is similar to the segment tree by Bentley <ref> [2] </ref>. The segment tree is a static structure, which can be balanced for a given set of abscissae.
Reference: [3] <institution> Ohio Supercomputer Center. </institution> <note> LAM/MPI parallel computing. http://www.osc.edu/lam.html, 1998. </note>
Reference-contexts: The workstations are connected by a 100 Mbps switched Ethernet network. The switch can handle an aggregate bandwidth of 2.4 Gbps in an all-to-all type communication. For message passing between the Pentium workstations, we used the LAM implementation of the MPI communication standard <ref> [3] </ref>. With the LAM message passing package on the Pentium cluster, we observed an average communication latency of 790 microseconds and an average transfer rate of about 5 Mbytes/second.
Reference: [4] <author> Surajit Chaudhuri and Umeshwar Dayal. </author> <title> An overview of data warehousing and OLAP technology. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 26(1), </volume> <month> March </month> <year> 1997. </year>
Reference-contexts: This temporal aggregation can be processed in a sequential or parallel fashion. The parallel processing technology becomes even more attractive, as the size of data-intensive applications grows as evidenced in OLAP and data warehousing environments <ref> [4, 6] </ref>. Although several sequential and parallel algorithms have been developed for computing temporal aggregates [10, 12, 15, 19, 21], they suffer from serious limitations such as the size of aggregation restricted by available memory and requirement of a priori knowledge about the orderedness of an input database.
Reference: [5] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> McGraw Hill, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year>
Reference-contexts: the tag, each node stores two counters: one storing the number of tuples starting at the 4 (a) (b) (c) timestamp and the other storing the number of tuples ending at the timestamp. 1 Additionally, a color tag is stored in each node, as we use the red-black insertion algorithm <ref> [5] </ref> to keep the tree balanced dynamically. the figure, we only show timestamps and counters, which are relevant to temporal aggregate computation.
Reference: [6] <author> Anindya Datta, Bongki Moon, and Helen Thomas. </author> <title> A case for parallelism in data warehousing and OLAP. </title> <booktitle> In Proceedings of the Ninth International Workshop on Database and Expert Systems Applications (DEXA'98), </booktitle> <pages> pages 226-231, </pages> <address> Vienna, Austria, </address> <month> August </month> <year> 1998. </year>
Reference-contexts: This temporal aggregation can be processed in a sequential or parallel fashion. The parallel processing technology becomes even more attractive, as the size of data-intensive applications grows as evidenced in OLAP and data warehousing environments <ref> [4, 6] </ref>. Although several sequential and parallel algorithms have been developed for computing temporal aggregates [10, 12, 15, 19, 21], they suffer from serious limitations such as the size of aggregation restricted by available memory and requirement of a priori knowledge about the orderedness of an input database.
Reference: [7] <author> David J. DeWitt, Randy H. Katz, Frank Olken, Leonard D. Shapiro, Michael R. Stonebraker, and David Wood. </author> <title> Implementation techniques for main memory database systems. </title> <booktitle> In Proceedings of the 1984 ACM-SIGMOD Conference, </booktitle> <pages> pages 1-8, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: ft 2 ; t 3 ; t 4 g Bucket B 4 = ft 2 ; t 3 ; t 4 g join algorithm requires three database scans if the number of buffer pages is larger than a square root of the number of disk pages in a smaller relation <ref> [7] </ref>. Although the idea of data partitioning appears promising for relational hash join operation, it cannot be applied directly to temporal aggregation. Tuples associated with time intervals are not readily partitioned into temporally disjoint equivalence classes (e.g., hash buckets), because the time intervals of tuples may be of any length.
Reference: [8] <author> Robert Epstein. </author> <title> Techniques for processing of aggregates in relational database systems. </title> <type> Technical Report UCB/ERL M7918, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> February </month> <year> 1979. </year>
Reference-contexts: A scalar aggregate is composed of an aggregate expression and an optional qualification. A simple two-step algorithm was proposed by Epstein for evaluating scalar aggregates <ref> [8] </ref>. To handle many scalar aggregates in a query, the algorithm computes each of them separately and stores each result in a singleton relation, referring to that singleton relation when evaluating the rest of the query. <p> The aggregation tree after inserting the rest of the records in Figure 1 (a) is shown in Figure 2 (d). To compute the number of tuples (i.e., count aggregate) for the period <ref> [8; 12] </ref> in this example, The count from the leaf node [8; 12] (which is 1) is added to its parents' count values. <p> The aggregation tree after inserting the rest of the records in Figure 1 (a) is shown in Figure 2 (d). To compute the number of tuples (i.e., count aggregate) for the period <ref> [8; 12] </ref> in this example, The count from the leaf node [8; 12] (which is 1) is added to its parents' count values. Starting from the root, the sum of the parents' counts is 0 + 0 + 1 = 1 and adding the leaf count, gives a total of 2.
Reference: [9] <author> J. C. Freytag and N. GoodmanN. </author> <title> Translating aggregate queries into iterative programs. </title> <booktitle> In Proceedings of the 12th VLDB Conference, </booktitle> <pages> pages 138-146, </pages> <address> Kyoto, Japan, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: A different approach employing program transformation methods was proposed to systematically generate efficient iterative programs for aggregate queries <ref> [9] </ref>. The first approach for implementing temporal aggregation was proposed by Tuma [19] and was based on an extension of Epstein's algorithm. In this approach, the constant intervals are determined first, then the aggregate is evaluated using the Epstein's technique.
Reference: [10] <author> Jose Alvin G. Gendrano, Bruce C. Huang, Jim M. Rodrigue, Bongki Moon, and Richard T. Snod-grass. </author> <title> Parallel algorithms for computing temporal aggregates. </title> <note> To appear in Proceedings of the 15th International Conference on Data Engineering (ICDE'99). Also available as Technical Report TR 98-9, </note> <institution> University of Arizona, Department of Computer Science. </institution>
Reference-contexts: The parallel processing technology becomes even more attractive, as the size of data-intensive applications grows as evidenced in OLAP and data warehousing environments [4, 6]. Although several sequential and parallel algorithms have been developed for computing temporal aggregates <ref> [10, 12, 15, 19, 21] </ref>, they suffer from serious limitations such as the size of aggregation restricted by available memory and requirement of a priori knowledge about the orderedness of an input database. <p> Recently, there have been some research efforts to develop parallel algorithms for computing temporal aggregates for large-scale databases. Ye and Keane proposed two approaches to parallelize the aggregation tree algorithm on a shared-memory architecture [21]. Gendrano et al. have also developed several new parallel algorithms <ref> [10] </ref> for computing temporal aggregates, specifically on a shared-nothing architecture, by parallelizing the ag 3 gregation tree algorithm. Gendrano et al. showed promising scale-up performance of the parallel algorithms through extensive empirical studies under various conditions.
Reference: [11] <author> Christian S. Jensen and Richard T. Snodgrass. </author> <title> Semantics of time-varying information. </title> <journal> Information Systems, </journal> <volume> 21(4) </volume> <pages> 311-352, </pages> <year> 1996. </year>
Reference-contexts: Database applications often need to capture the time-varying nature of an enterprise they model. The importance of such need has been recognized by several database research groups, and temporal database models and query languages have been developed and reported in the literature <ref> [11, 17] </ref>. In fact, there are several temporal query languages supporting temporal aggregation [14, 15]. However, temporal data and queries provide many unique characteristics and challenges for query processing and optimization. Among the challenges is computing temporal aggregates, which is complicated by having to compute temporal grouping.
Reference: [12] <author> Nick Kline and Richard T. Snodgrass. </author> <title> Computing temporal aggregates. </title> <booktitle> In Proceedings of the 11th Inter. Conference on Data Engineering, </booktitle> <pages> pages 222-231, </pages> <address> Taipei, Taiwan, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Computing instant aggregates is expensive because it is necessary to know which tuples overlap each instant, and simply considering each tuple in order in a sorted-by-time relation will not be sufficient due to the varying interval lengths <ref> [12] </ref>. For example, computing the time-varying maximum salary of employees involves computing the temporal extent of each maximum value, which requires determining the tuples that overlap each temporal instant. <p> The parallel processing technology becomes even more attractive, as the size of data-intensive applications grows as evidenced in OLAP and data warehousing environments [4, 6]. Although several sequential and parallel algorithms have been developed for computing temporal aggregates <ref> [10, 12, 15, 19, 21] </ref>, they suffer from serious limitations such as the size of aggregation restricted by available memory and requirement of a priori knowledge about the orderedness of an input database. <p> Since the two steps are separate and the first one must be completed before the second one, a database must be read twice. More recent algorithms were proposed by Kline and Snodgrass <ref> [12] </ref> for temporal aggregation based on instant grouping of tuples. The algorithms are called aggregation tree and its variant k-ordered aggregation tree, as they build a tree while scanning a database. <p> The aggregation tree after inserting the rest of the records in Figure 1 (a) is shown in Figure 2 (d). To compute the number of tuples (i.e., count aggregate) for the period <ref> [8; 12] </ref> in this example, The count from the leaf node [8; 12] (which is 1) is added to its parents' count values. <p> The aggregation tree after inserting the rest of the records in Figure 1 (a) is shown in Figure 2 (d). To compute the number of tuples (i.e., count aggregate) for the period <ref> [8; 12] </ref> in this example, The count from the leaf node [8; 12] (which is 1) is added to its parents' count values. Starting from the root, the sum of the parents' counts is 0 + 0 + 1 = 1 and adding the leaf count, gives a total of 2. <p> In particular, the size of the database those parallel algorithms can handle will be limited by the aggregate memory of participating processors. 3 Improved Algorithms for Small-Scale Aggregation In this section, we present two new algorithms for computing temporal aggregates, as alternatives to the aggregation tree algorithm <ref> [12] </ref>. The aggregation tree is a binary tree, which is similar to the segment tree by Bentley [2]. The segment tree is a static structure, which can be balanced for a given set of abscissae. <p> We generated synthetic data in the same way as in <ref> [12] </ref>. Each database has a time-line of one million temporal instants. We considered two basic life spans for tuples: short-lived and long-lived.
Reference: [13] <author> Donald E. Knuth. </author> <title> Sorting and Searching, </title> <booktitle> volume 3 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Mass., </address> <year> 1973. </year>
Reference-contexts: The solution to the second group is called a merge-sort aggregation algorithm, which is similar to the classical merge-sort algorithm <ref> [13] </ref>. This algorithm will be presented in Section 3.2. In this section, we assume that the memory is large enough to store the entire data structures required by each aggregation algorithm.
Reference: [14] <author> R. T. Snodgrass et al. </author> <title> The TSQL2 Temporal Query Language. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: The importance of such need has been recognized by several database research groups, and temporal database models and query languages have been developed and reported in the literature [11, 17]. In fact, there are several temporal query languages supporting temporal aggregation <ref> [14, 15] </ref>. However, temporal data and queries provide many unique characteristics and challenges for query processing and optimization. Among the challenges is computing temporal aggregates, which is complicated by having to compute temporal grouping. <p> In temporal databases, temporal grouping is a process where the time-line is partitioned over time and tuples are grouped over these partitions. Then, aggregate values are computed over these groups. In general, temporal grouping is done by two types of partitioning <ref> [14] </ref>: span grouping and instant grouping. Span grouping is based on a defined length in time, such as week or month, and is independent of temporal attribute values of database tuples. On the other hand, instant grouping depends on the data stored.
Reference: [15] <author> R. T. Snodgrass, S. Gomez, and E. Mackenzie. </author> <title> Aggregates in the temporal query language TQuel. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(5) </volume> <pages> 826-842, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: The importance of such need has been recognized by several database research groups, and temporal database models and query languages have been developed and reported in the literature [11, 17]. In fact, there are several temporal query languages supporting temporal aggregation <ref> [14, 15] </ref>. However, temporal data and queries provide many unique characteristics and challenges for query processing and optimization. Among the challenges is computing temporal aggregates, which is complicated by having to compute temporal grouping. <p> The parallel processing technology becomes even more attractive, as the size of data-intensive applications grows as evidenced in OLAP and data warehousing environments [4, 6]. Although several sequential and parallel algorithms have been developed for computing temporal aggregates <ref> [10, 12, 15, 19, 21] </ref>, they suffer from serious limitations such as the size of aggregation restricted by available memory and requirement of a priori knowledge about the orderedness of an input database.
Reference: [16] <author> Michael Stonebraker. </author> <title> The case for shared nothing. </title> <journal> A Quarterly bulletin of the IEEE Computer Society Technical Committee on Database Engineering, </journal> <volume> 9(1) </volume> <pages> 4-9, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: Then, the processors perform operations on the partitioned data in parallel, achieving speed-up in query processing times. Among the various architectures that have been proposed for parallel database systems, a shared-nothing architecture <ref> [16] </ref> has made it an attractive choice for large-scale database applications due to its high potential for scalability. By scalability we mean the capability of delivering an increase in performance proportional to an increase in the number of participating processors.
Reference: [17] <author> A. Tansel et al. </author> <title> Temporal Databases: Theory, Design and Implementation. Database Systems and Applications Series. </title> <address> Benjamin/Cummings, Redwood City, CA, </address> <year> 1993. </year>
Reference-contexts: Database applications often need to capture the time-varying nature of an enterprise they model. The importance of such need has been recognized by several database research groups, and temporal database models and query languages have been developed and reported in the literature <ref> [11, 17] </ref>. In fact, there are several temporal query languages supporting temporal aggregation [14, 15]. However, temporal data and queries provide many unique characteristics and challenges for query processing and optimization. Among the challenges is computing temporal aggregates, which is complicated by having to compute temporal grouping.
Reference: [18] <institution> Transaction Processing Performance Council, </institution> <address> San Jose, </address> <month> CA. </month> <title> TPC Benchmark D (Decision Support) Standard Specification, revision 1.2.3 edition, </title> <month> June </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Aggregate functions compute a scalar value, such as the maximum salary, when applied to a set of tuples. These functions are an essential component of database query languages, and are heavily used in many applications. Several prominent query benchmarks such as TPC-D <ref> [18] </ref> and AS 3 AP [20] contain a high percentage of aggregate operations. Hence, efficient execution of aggregate functions is an important goal. Database applications often need to capture the time-varying nature of an enterprise they model.
Reference: [19] <author> P. A. Tuma. </author> <title> Implementing historical aggregates in TempIS. </title> <type> Master's thesis, </type> <institution> Wayne State University, </institution> <address> Detroit, Michigan, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: The parallel processing technology becomes even more attractive, as the size of data-intensive applications grows as evidenced in OLAP and data warehousing environments [4, 6]. Although several sequential and parallel algorithms have been developed for computing temporal aggregates <ref> [10, 12, 15, 19, 21] </ref>, they suffer from serious limitations such as the size of aggregation restricted by available memory and requirement of a priori knowledge about the orderedness of an input database. <p> A different approach employing program transformation methods was proposed to systematically generate efficient iterative programs for aggregate queries [9]. The first approach for implementing temporal aggregation was proposed by Tuma <ref> [19] </ref> and was based on an extension of Epstein's algorithm. In this approach, the constant intervals are determined first, then the aggregate is evaluated using the Epstein's technique.
Reference: [20] <author> Carolyn Turbyfill, Cyril Orji, and Dina Bitton. </author> <title> AS 3 AP: An ANSI SQL standard scaleable and portable benchmark for relational database systems. </title> <editor> In Jim Gray, editor, </editor> <booktitle> The Benchmark Handbook : for Database and Transaction Processing Systems (2ed), </booktitle> <pages> pages 317-357. </pages> <publisher> Morgan Kaufman Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Aggregate functions compute a scalar value, such as the maximum salary, when applied to a set of tuples. These functions are an essential component of database query languages, and are heavily used in many applications. Several prominent query benchmarks such as TPC-D [18] and AS 3 AP <ref> [20] </ref> contain a high percentage of aggregate operations. Hence, efficient execution of aggregate functions is an important goal. Database applications often need to capture the time-varying nature of an enterprise they model.
Reference: [21] <author> Xinfeng Ye and John A. Keane. </author> <title> Processing temporal aggregates in parallel. </title> <booktitle> In IEEE Inter. Conf. on Systems, Man, and Cybernetics, </booktitle> <pages> pages 1373-1378, </pages> <address> Orlando, FL, </address> <month> October </month> <year> 1997. </year> <month> 18 </month>
Reference-contexts: The parallel processing technology becomes even more attractive, as the size of data-intensive applications grows as evidenced in OLAP and data warehousing environments [4, 6]. Although several sequential and parallel algorithms have been developed for computing temporal aggregates <ref> [10, 12, 15, 19, 21] </ref>, they suffer from serious limitations such as the size of aggregation restricted by available memory and requirement of a priori knowledge about the orderedness of an input database. <p> Recently, there have been some research efforts to develop parallel algorithms for computing temporal aggregates for large-scale databases. Ye and Keane proposed two approaches to parallelize the aggregation tree algorithm on a shared-memory architecture <ref> [21] </ref>. Gendrano et al. have also developed several new parallel algorithms [10] for computing temporal aggregates, specifically on a shared-nothing architecture, by parallelizing the ag 3 gregation tree algorithm. Gendrano et al. showed promising scale-up performance of the parallel algorithms through extensive empirical studies under various conditions.
References-found: 21

