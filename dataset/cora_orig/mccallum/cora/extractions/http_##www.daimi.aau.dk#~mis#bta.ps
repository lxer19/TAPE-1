URL: http://www.daimi.aau.dk/~mis/bta.ps
Refering-URL: http://www.daimi.aau.dk/~mis/papers.html
Root-URL: http://www.daimi.aau.dk
Email: mis@daimi.aau.dk  
Keyword: Binding-time Analysis:  
Address: Ny Munkegade, DK-8000 Aarhus C, Denmark  
Affiliation: Computer Science Department, Aarhus University  
Note: Proc. ICCL'94, Fifth IEEE International Conference on Computer Languages, pages 289-298.  palsberg@daimi.aau.dk  
Abstract: Interpretation versus Type Inference Abstract Binding-time analysis is important in partial evaluators. Its task is to determine which parts of a program can be evaluated if some of the expected input is known. Two approaches to do this are abstract interpretation and type inference. We compare two specific such analyses to see which one determines most program parts to be eliminable. The first is a an abstract interpretation approach based on closure analysis and the second is the type inference approach of Gomard and Jones. Both apply to the pure -calculus. We prove that the abstract interpretation approach is more powerful than that of Gomard and Jones: the former determines the same and possibly more program parts to be eliminable as the latter. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Henk P. Barendregt. </author> <title> The Lambda Calculus: Its Syntax and Semantics. </title> <publisher> North-Holland, </publisher> <year> 1981. </year>
Reference-contexts: 1 Introduction In this paper we compare two techniques for doing binding-time analysis of terms in the pure -calculus <ref> [1] </ref>. The binding-times we are concerned with are "static" (compile-time) and "dynamic" (run-time). Binding-time analysis has been formulated in various settings. Most of them are based on either abstract interpretation or type inference.
Reference: [2] <author> Anders Bondorf. </author> <title> Automatic autoprojection of higher order recursive equations. </title> <booktitle> Science of Computer Programming, </booktitle> <address> 17(1-3):3-34, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: Binding-time analysis has been formulated in various settings. Most of them are based on either abstract interpretation or type inference. For examples of the former that are applicable to higher-order languages, see the work of Mogensen [11, 12], Bondorf, <ref> [2] </ref>, Consel [3], and Hunt and Sands [8]. For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson [13], and Gomard and Jones [6]. Only little is known, however, about the relative quality of these analyses. <p> We will compare two fundamentally different binding-time analyses. The first is a an abstract interpretation approach based on closure analysis [14] and the second is the type inference approach of Gomard and Jones [6]. The first is intended to capture the binding-time analyses of Bondorf <ref> [2] </ref> and Consel [3], when restricted to the -calculus. We have not given a proof of this connection, however, so this analysis may turn out to be novel. The binding-time analyses of Bondorf, Consel, and Gomard and Jones are successfully used in the Similix, Schism, and Lambda-mix partial evaluators, respectively. <p> Henglein gave a pseudo-linear time algorithm for computing this v-least term [7]. A New Notion of Well-annotatedness The new notion of well-annotatedness is based on an abstract interpretation called closure analysis <ref> [18, 2] </ref> (also called control flow analysis by Jones [10] and Shivers [19]). The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate [10, 18, 2, 19]. <p> The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate <ref> [10, 18, 2, 19] </ref>. Both Bondorf and Consel's binding-time analyses may be understood as a closure analysis that in addition to closures also incorporates a special value Dyn (Dyn is called D by Bondorf). The intuition behind Dyn is the same as that behind the Dyn used in Gomard/Jones well-annotatedness.
Reference: [3] <author> Charles Consel. </author> <title> Binding time analysis for higher order untyped functional languages. </title> <booktitle> In Proc. ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 264-272, </pages> <year> 1990. </year>
Reference-contexts: Binding-time analysis has been formulated in various settings. Most of them are based on either abstract interpretation or type inference. For examples of the former that are applicable to higher-order languages, see the work of Mogensen [11, 12], Bondorf, [2], Consel <ref> [3] </ref>, and Hunt and Sands [8]. For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson [13], and Gomard and Jones [6]. Only little is known, however, about the relative quality of these analyses. <p> We will compare two fundamentally different binding-time analyses. The first is a an abstract interpretation approach based on closure analysis [14] and the second is the type inference approach of Gomard and Jones [6]. The first is intended to capture the binding-time analyses of Bondorf [2] and Consel <ref> [3] </ref>, when restricted to the -calculus. We have not given a proof of this connection, however, so this analysis may turn out to be novel. The binding-time analyses of Bondorf, Consel, and Gomard and Jones are successfully used in the Similix, Schism, and Lambda-mix partial evaluators, respectively.
Reference: [4] <author> Carsten K. Gomard. </author> <title> Higher order partial evaluation HOPE for the lambda calculus. </title> <type> Master's thesis, </type> <institution> DIKU, University of Copenhagen, </institution> <month> Septem-ber </month> <year> 1989. </year>
Reference-contexts: For any -term, there is a v-least annotated version for which GJ is solvable, for a proof see Gomard's Master's thesis <ref> [4] </ref>. Henglein gave a pseudo-linear time algorithm for computing this v-least term [7]. A New Notion of Well-annotatedness The new notion of well-annotatedness is based on an abstract interpretation called closure analysis [18, 2] (also called control flow analysis by Jones [10] and Shivers [19]).
Reference: [5] <author> Carsten K. Gomard. </author> <title> Partial type inference for untyped functional programs. </title> <booktitle> In Proc. ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 282-287, </pages> <year> 1990. </year>
Reference-contexts: Thus, the best possible implementations are algorithms that produce the v-least well-annotated versions of their inputs. We compare the best possible implementations of the two well-annotatedness criteria. These algorithms indeed exist, as follows. Both the algorithms of Go--mard <ref> [5] </ref> and Henglein [7] produce the v-least Go-mard/Jones well-annotated 2-level version of a given -term. We believe (but have not proved) that the algorithms of Bondorf and Consel produces the v-least Palsberg/Schwartzbach well-annotated 2-level version of a given -term.
Reference: [6] <author> Carsten K. Gomard and Neil D. Jones. </author> <title> A partial evaluator for the untyped lambda-calculus. </title> <journal> Journal of Functional Programming, </journal> <volume> 1(1) </volume> <pages> 21-69, </pages> <year> 1991. </year>
Reference-contexts: For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson [13], and Gomard and Jones <ref> [6] </ref>. Only little is known, however, about the relative quality of these analyses. For comparison with strictness analysis, note that Jensen [9] has proved the equivalence of two strictness analyses based on abstract interpretation and type inference, respectively. We will compare two fundamentally different binding-time analyses. <p> We will compare two fundamentally different binding-time analyses. The first is a an abstract interpretation approach based on closure analysis [14] and the second is the type inference approach of Gomard and Jones <ref> [6] </ref>. The first is intended to capture the binding-time analyses of Bondorf [2] and Consel [3], when restricted to the -calculus. We have not given a proof of this connection, however, so this analysis may turn out to be novel. <p> It could also produce (x:x @ y) @ z. Both these 2-level -terms are consistent. In the first case, a partial evaluator will do a single reduction and obtain z @ y. Following Gomard and Jones <ref> [6] </ref>, we partially order the set of 2-level -terms as follows. Given 2-level -terms E and E 0 , E v E 0 if and only if they are equal except for underlinings and E 0 has the same and possibly more underlinings than E. <p> In the following section we discuss the key concept of well-annotatedness, in Section 3 we define the two analyses, and in Section 4 we prove our result. 2 Well-annotatedness A sufficient and decidable condition for consistency, called well-annotatedness, was first presented by Go-mard and Jones <ref> [6] </ref>. Their binding-time analysis always produces well-annotated terms. In this paper we present another condition for consistency. It is defined to capture the outputs of the binding-time analyses of Bondorf and Consel, when restricted to the -calculus. <p> Our comparison proceeds by first proving that Gomard/Jones well-annotatedness implies Pals-berg/Schwartzbach well-annotatedness. This leads to the desired result because the input/output behavior of the two chosen analyses are fully defined by their specifications. Gomard and Jones formulated their well-annota-tedness criterion via inference rules <ref> [6] </ref>. For the purpose of this paper, we will rephrase it using constraint systems. The new notion of well-annotatedness will also be phrased using constraint systems. <p> Sometimes we write GJ (E 0 ) to emphasize that the constraint system is generated from E 0 . Each type constraint matches an inference rule in Gomard and Jones' formulation of the predicate <ref> [6] </ref>. The initial constraints of the form [[x]] = Dyn reflect that the free variables of E 0 correspond to unknown input. The initial constraint [[E 0 ]] = Dyn reflects that a partial evaluator is supposed to produce a residual program.
Reference: [7] <author> Fritz Henglein. </author> <title> Efficient type inference for higher-order binding-time analysis. </title> <booktitle> In Proc. Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 448-472. </pages> <publisher> Springer-Verlag (LNCS 523), </publisher> <year> 1991. </year>
Reference-contexts: Thus, the best possible implementations are algorithms that produce the v-least well-annotated versions of their inputs. We compare the best possible implementations of the two well-annotatedness criteria. These algorithms indeed exist, as follows. Both the algorithms of Go--mard [5] and Henglein <ref> [7] </ref> produce the v-least Go-mard/Jones well-annotated 2-level version of a given -term. We believe (but have not proved) that the algorithms of Bondorf and Consel produces the v-least Palsberg/Schwartzbach well-annotated 2-level version of a given -term. A naive algorithm that computes this v-least 2-level -term is sketched below. <p> A solution of GJ assigns a type to each type variable such that all constraints are satisfied. The constraint system GJ ((x:y) @ (z:z @ z)) is shown in figure 1. Note that the constraints differ from those presented by Henglein <ref> [7] </ref>; the latter are defined on pure -terms with the purpose of specifying the computation (rather than the well-annotatedness) of an annotation. For any -term, there is a v-least annotated version for which GJ is solvable, for a proof see Gomard's Master's thesis [4]. <p> For any -term, there is a v-least annotated version for which GJ is solvable, for a proof see Gomard's Master's thesis [4]. Henglein gave a pseudo-linear time algorithm for computing this v-least term <ref> [7] </ref>. A New Notion of Well-annotatedness The new notion of well-annotatedness is based on an abstract interpretation called closure analysis [18, 2] (also called control flow analysis by Jones [10] and Shivers [19]). The closures of a term are simply the subterms corresponding to abstractions. <p> They differ in their treatment of static entities: GJ uses a type discipline to handle abstractions whereas WA uses abstract interpretation. Gomard and Jones' analysis can apparently be computed faster than the new analysis <ref> [7] </ref>. In return for the longer running time, the new analysis produces better results. For example, consider (x:y) @ (z:z @ z). The abstract interpretation approach yields no underlin-ings at all because WA ((x:y) @ (z:z @ z)) is solvable, see figure 2.
Reference: [8] <author> Sebastian Hunt and David Sands. </author> <title> Binding time analysis: a new PERspective. </title> <booktitle> In Proc. ACM SIGPLAN Symposium on Partial Evaluation and Semantics Based Program Manipulation, </booktitle> <pages> pages 154-165. </pages> <booktitle> Sigplan Notices, </booktitle> <year> 1991. </year>
Reference-contexts: Binding-time analysis has been formulated in various settings. Most of them are based on either abstract interpretation or type inference. For examples of the former that are applicable to higher-order languages, see the work of Mogensen [11, 12], Bondorf, [2], Consel [3], and Hunt and Sands <ref> [8] </ref>. For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson [13], and Gomard and Jones [6]. Only little is known, however, about the relative quality of these analyses.
Reference: [9] <author> Thomas P. Jensen. </author> <title> Strictness analysis in logical form. </title> <booktitle> In Proc. Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 352-366. </pages> <publisher> Springer-Verlag (LNCS 523), </publisher> <year> 1991. </year>
Reference-contexts: For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson [13], and Gomard and Jones [6]. Only little is known, however, about the relative quality of these analyses. For comparison with strictness analysis, note that Jensen <ref> [9] </ref> has proved the equivalence of two strictness analyses based on abstract interpretation and type inference, respectively. We will compare two fundamentally different binding-time analyses.
Reference: [10] <author> Neil D. Jones. </author> <title> Flow analysis of lambda expressions. </title> <booktitle> In Proc. Eighth Colloquium on Automata, Languages, and Programming, </booktitle> <pages> pages 114-128. </pages> <publisher> Springer-Verlag (LNCS 115), </publisher> <year> 1981. </year>
Reference-contexts: Henglein gave a pseudo-linear time algorithm for computing this v-least term [7]. A New Notion of Well-annotatedness The new notion of well-annotatedness is based on an abstract interpretation called closure analysis [18, 2] (also called control flow analysis by Jones <ref> [10] </ref> and Shivers [19]). The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate [10, 18, 2, 19]. <p> The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate <ref> [10, 18, 2, 19] </ref>. Both Bondorf and Consel's binding-time analyses may be understood as a closure analysis that in addition to closures also incorporates a special value Dyn (Dyn is called D by Bondorf). The intuition behind Dyn is the same as that behind the Dyn used in Gomard/Jones well-annotatedness.
Reference: [11] <author> Torben AE. Mogensen. </author> <title> Binding time analysis for polymorphically typed higher order languages. </title> <booktitle> In Proc. TAPSOFT'89, </booktitle> <pages> pages 298-312. </pages> <publisher> Springer-Verlag (LNCS 352), </publisher> <month> March </month> <year> 1989. </year>
Reference-contexts: The binding-times we are concerned with are "static" (compile-time) and "dynamic" (run-time). Binding-time analysis has been formulated in various settings. Most of them are based on either abstract interpretation or type inference. For examples of the former that are applicable to higher-order languages, see the work of Mogensen <ref> [11, 12] </ref>, Bondorf, [2], Consel [3], and Hunt and Sands [8]. For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson [13], and Gomard and Jones [6]. Only little is known, however, about the relative quality of these analyses.
Reference: [12] <author> Torben AE. Mogensen. </author> <title> Self-applicable partial eval-uation for pure lambda calculus. </title> <booktitle> In Proc. ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 116-121, </pages> <year> 1992. </year>
Reference-contexts: The binding-times we are concerned with are "static" (compile-time) and "dynamic" (run-time). Binding-time analysis has been formulated in various settings. Most of them are based on either abstract interpretation or type inference. For examples of the former that are applicable to higher-order languages, see the work of Mogensen <ref> [11, 12] </ref>, Bondorf, [2], Consel [3], and Hunt and Sands [8]. For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson [13], and Gomard and Jones [6]. Only little is known, however, about the relative quality of these analyses. <p> Thus, E B v E G . 2 The -term (x:y) @ (z:z @ z) from Section 3 shows that in some cases the abstract interpretation based analysis produces strictly v-smaller annotated versions than does Gomard and Jones' analysis. Mogensen <ref> [12] </ref> extended the binding-time analysis of Gomard and Jones with the use of recursive types. The type constraints are the same but types can now be regular trees, not only finite ones. This allows solutions to constraints such as X = X ! X. <p> The type constraints are the same but types can now be regular trees, not only finite ones. This allows solutions to constraints such as X = X ! X. Mogensen's well-annotatedness criterion does have the property that for each -term there is a v-least well-annotated version of it <ref> [12] </ref>. Corollary 8 For all -terms, the abstract interpretation based analysis produces v-smaller annotated versions than does Mogensen's analysis. Proof.
Reference: [13] <author> Hanne R. Nielson and Flemming Nielson. </author> <title> Automatic binding time analysis for a typed - calculus. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 10 </volume> <pages> 139-176, </pages> <year> 1988. </year>
Reference-contexts: For examples of the former that are applicable to higher-order languages, see the work of Mogensen [11, 12], Bondorf, [2], Consel [3], and Hunt and Sands [8]. For examples of the latter that are also applicable to higher-order languages, see the work of Nielson and Nielson <ref> [13] </ref>, and Gomard and Jones [6]. Only little is known, however, about the relative quality of these analyses. For comparison with strictness analysis, note that Jensen [9] has proved the equivalence of two strictness analyses based on abstract interpretation and type inference, respectively. <p> Again, our comparison shows that the two chosen analyses differ even in the absence of static input. The output of a binding-time analysis can be presented as an annotated version of the analyzed -term. The language of annotated -terms is usually called a 2-level -calculus <ref> [13] </ref>. It is defined by the grammar: E :: = x (variable) j x:E (static abstraction) j E 1 @ E 2 (static application) j x:E (dynamic abstraction) j E 1 @ E 2 (dynamic application) Intuitively, "static" means "statically known", and "dynamic" means "not statically known".
Reference: [14] <author> Jens Palsberg. </author> <title> Correctness of binding-time analysis. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(3) </volume> <pages> 347-363, </pages> <year> 1993. </year>
Reference-contexts: For comparison with strictness analysis, note that Jensen [9] has proved the equivalence of two strictness analyses based on abstract interpretation and type inference, respectively. We will compare two fundamentally different binding-time analyses. The first is a an abstract interpretation approach based on closure analysis <ref> [14] </ref> and the second is the type inference approach of Gomard and Jones [6]. The first is intended to capture the binding-time analyses of Bondorf [2] and Consel [3], when restricted to the -calculus. <p> The static entities are those that can be eliminated during partial evaluation. The purpose of a binding-time analysis for the -calculus is to produce consistent 2-level -terms <ref> [14] </ref>. Consistency prevents partial evaluators from "going wrong" [14]. For example, the 2-level - term (x:x) @ y is inconsistent: even though the function part of the static application is an abstraction, it is marked as dynamic. For another example, consider (x:x @ y) @ z. <p> The static entities are those that can be eliminated during partial evaluation. The purpose of a binding-time analysis for the -calculus is to produce consistent 2-level -terms <ref> [14] </ref>. Consistency prevents partial evaluators from "going wrong" [14]. For example, the 2-level - term (x:x) @ y is inconsistent: even though the function part of the static application is an abstraction, it is marked as dynamic. For another example, consider (x:x @ y) @ z. <p> This justifies calling the new condition "well-annotatedness". For clarity, we will call the new condition "Palsberg/Schwartzbach well-annotatedness". Thus, if a 2-level -term is Gomard/Jones well-annotated, then it will also be Palsberg/Schwartzbach well-annotated. It has been proved by the first author <ref> [14] </ref> that Palsberg/Schwartzbach well-annotatedness, hence also Gomard/Jones well-annotatedness, implies consistency. The two definitions of well-annotatedness can be understood as specifications of binding-time analyses. Such a specification is implemented by any algorithm that always produces well-annotated 2-level -terms. We need not be satisfied with any such algorithm, however. <p> This approach emphasizes both the similarities and differences between Gomard/Jones well-annotatedness and Palsberg/Schwartzbach well-annotatedness. (The definition of well-annotatedness in <ref> [14] </ref> is slightly different but equivalent to the one given here.) In the new notion of well-annotatedness, type variables range over the set D of binding-time values.
Reference: [15] <author> Jens Palsberg. </author> <title> Global program analysis in constraint form. </title> <booktitle> In Proc. CAAP'94, Colloquium on Trees in Algebra and Programming, </booktitle> <pages> pages 276-290. </pages> <publisher> Springer-Verlag (LNCS 787), Edinburgh, </publisher> <address> Scotland, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: The intuition behind Dyn is the same as that behind the Dyn used in Gomard/Jones well-annotatedness. We define the new well-annotatedness criterion as follows. For static entities, we generate the usual constraints of closure analysis <ref> [17, 16, 15] </ref>; and for dy Constraints: y [[y]] = Dyn x:y [[x:y]] = [[x]] ! [[y]] (x:y) @ (z:z @ z) [[x:y]] = [[z:z @ z]] ! [[(x:y) @ (z:z @ z)]] Solution: The mapping L where L [[x]] = L [[z:z @ z]] = Dyn ! Dyn L [[z]]
Reference: [16] <author> Jens Palsberg and Michael I. Schwartzbach. </author> <title> Safety analysis versus type inference. </title> <journal> Information and Computation. </journal> <note> To appear. </note>
Reference-contexts: The intuition behind Dyn is the same as that behind the Dyn used in Gomard/Jones well-annotatedness. We define the new well-annotatedness criterion as follows. For static entities, we generate the usual constraints of closure analysis <ref> [17, 16, 15] </ref>; and for dy Constraints: y [[y]] = Dyn x:y [[x:y]] = [[x]] ! [[y]] (x:y) @ (z:z @ z) [[x:y]] = [[z:z @ z]] ! [[(x:y) @ (z:z @ z)]] Solution: The mapping L where L [[x]] = L [[z:z @ z]] = Dyn ! Dyn L [[z]]
Reference: [17] <author> Jens Palsberg and Michael I. Schwartzbach. </author> <title> Safety analysis versus type inference for partial types. </title> <journal> Information Processing Letters, </journal> <volume> 43 </volume> <pages> 175-180, </pages> <year> 1992. </year>
Reference-contexts: The intuition is "the fewer underlinings, the better". We prove that the abstract interpretation based analysis is more powerful than that of Gomard and Jones, in the sense that it always produces v-smaller 2-level -terms. Our proof technique is a generalization of one used in <ref> [17] </ref>. That paper also compares two analyses based on abstract interpretation and type inference, respectively. The key difference is that the abstract interpretation in [17] uses a lattice whereas the one in this paper does not. Our new proof technique can handle both cases. <p> Our proof technique is a generalization of one used in <ref> [17] </ref>. That paper also compares two analyses based on abstract interpretation and type inference, respectively. The key difference is that the abstract interpretation in [17] uses a lattice whereas the one in this paper does not. Our new proof technique can handle both cases. <p> The intuition behind Dyn is the same as that behind the Dyn used in Gomard/Jones well-annotatedness. We define the new well-annotatedness criterion as follows. For static entities, we generate the usual constraints of closure analysis <ref> [17, 16, 15] </ref>; and for dy Constraints: y [[y]] = Dyn x:y [[x:y]] = [[x]] ! [[y]] (x:y) @ (z:z @ z) [[x:y]] = [[z:z @ z]] ! [[(x:y) @ (z:z @ z)]] Solution: The mapping L where L [[x]] = L [[z:z @ z]] = Dyn ! Dyn L [[z]]
Reference: [18] <author> Peter Sestoft. </author> <title> Replacing function parameters by global variables. </title> <booktitle> In Proc. Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 39-53, </pages> <year> 1989. </year>
Reference-contexts: Henglein gave a pseudo-linear time algorithm for computing this v-least term [7]. A New Notion of Well-annotatedness The new notion of well-annotatedness is based on an abstract interpretation called closure analysis <ref> [18, 2] </ref> (also called control flow analysis by Jones [10] and Shivers [19]). The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate [10, 18, 2, 19]. <p> The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate <ref> [10, 18, 2, 19] </ref>. Both Bondorf and Consel's binding-time analyses may be understood as a closure analysis that in addition to closures also incorporates a special value Dyn (Dyn is called D by Bondorf). The intuition behind Dyn is the same as that behind the Dyn used in Gomard/Jones well-annotatedness.
Reference: [19] <author> Olin Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages. </title> <type> PhD thesis, CMU, </type> <month> May </month> <year> 1991. </year> <month> CMU-CS-91-145. </month>
Reference-contexts: Henglein gave a pseudo-linear time algorithm for computing this v-least term [7]. A New Notion of Well-annotatedness The new notion of well-annotatedness is based on an abstract interpretation called closure analysis [18, 2] (also called control flow analysis by Jones [10] and Shivers <ref> [19] </ref>). The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate [10, 18, 2, 19]. <p> The closures of a term are simply the subterms corresponding to abstractions. A closure analysis approximates for every subterm the set of possible closures to which it may evaluate <ref> [10, 18, 2, 19] </ref>. Both Bondorf and Consel's binding-time analyses may be understood as a closure analysis that in addition to closures also incorporates a special value Dyn (Dyn is called D by Bondorf). The intuition behind Dyn is the same as that behind the Dyn used in Gomard/Jones well-annotatedness.
Reference: [20] <author> Mitchell Wand. </author> <title> A simple algorithm and proof for type inference. </title> <journal> Fundamentae Informaticae, </journal> <volume> X:115-122, </volume> <year> 1987. </year>
Reference-contexts: In each case, the idea is that the condition is true of a 2-level -term E 0 iff a constraint system generated from E 0 is solvable. Both constraint systems are generated in the style of Wand <ref> [20] </ref>, as follows. First, the 2-level -term is ff-converted so that every -bound (or -bound) variable is distinct. This means that every abstraction x:E (or x:E) can be denoted by the unique lambda token x (or x). Second, a type variable [[E]] is assigned to every subterm E.
References-found: 20

