URL: http://dimacs.rutgers.edu/Workshops/Codes/abs-visweswariah.ps
Refering-URL: http://dimacs.rutgers.edu/Workshops/Codes/program.html
Root-URL: http://www.cs.rutgers.edu
Email: karthik@ee.princeton.edu  kulkarni@ee.princeton.edu  verdu@ee.princeton.edu  
Title: Worst case bounds on Universal Variable-to-Fixed Length Source Codes 1  
Author: K. Visweswariah S. R. Kulkarni S. Verdu 
Address: Princeton Univ., NJ 08544  Princeton Univ., NJ 08544  Princeton Univ., NJ 08544  
Affiliation: Dept. of Electrical Engg.  Dept. of Electrical Engg.  Dept. of Electrical Engg.  
Abstract: In [6] universal variable-to-fixed length codes were considered which were shown to be asymptotically optimal. Here we consider their performance on an individual sequence x n 1 . We also look at the performance on individual sequences of the scheme introduced in [1]. We bound the performance in terms of the best code length achievable for the string from a class of coders.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Nissenbaum, and M. </author> <title> Feder , "An adaptive variable-to-fix lossles coding scheme," </title> <booktitle> IEEE International Symposium on Information Theory, </booktitle> <pages> pp. 193, </pages> <address> Trondheim, Norway, </address> <year> 1994. </year>
Reference-contexts: 1 . We also look at the performance on individual sequences of the scheme introduced in <ref> [1] </ref>. We bound the performance in terms of the best code length achievable for the string from a class of coders. I. Introduction We consider the compression of a source that takes values in a finite set A. <p> Tjalkens and Willems [4] gave asymptotically optimal universal codes for binary i.i.d sources. Asymptotically optimal universal codes for Markov sources were given in [6]. II. Problem Formulation Here we will consider the performance of codes given in [6] and <ref> [1] </ref> on individual sequences. We will consider a sequence x n 1 2 A n and bound the performance of the codes on this sequence in terms of the best possible code length form a class of codes. <p> Our next result is an upper-bound on the performance of the coding method described in <ref> [1] </ref>, which allows the use of a variable-fixed length code along with an estimator of proba bilities. We will use as an estimator the context tree weight ing method [7]. Let us denote the compression achieved by the scheme as R NF (x n 1 ).
Reference: [2] <author> S. A. Savari, and R. G. </author> <title> Gallager " Generalized Tunstall codes for sources with memory," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> vol. IT-43, </volume> <pages> pp. 658-668, </pages> <month> March. </month> <year> 1997. </year>
Reference-contexts: Thus a goal while designing the dictionary is to try and maximize E (L) for a fixed dictionary size. Tunstall [5] gave an algorithm to maximize E (L) for a fixed jDj for an i.i.d source. Generalization of Tunstall's method to Markov sources were given in <ref> [2] </ref>, [3]. Tjalkens and Willems [4] gave asymptotically optimal universal codes for binary i.i.d sources. Asymptotically optimal universal codes for Markov sources were given in [6]. II. Problem Formulation Here we will consider the performance of codes given in [6] and [1] on individual sequences.
Reference: [3] <author> T. J. Tjalkens, and F. M. J. </author> <title> Willems "Variable to fixed-length codes for Markov sources," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> vol. IT-33, </volume> <pages> pp. 246-257, </pages> <month> March. </month> <year> 1987. </year>
Reference-contexts: Thus a goal while designing the dictionary is to try and maximize E (L) for a fixed dictionary size. Tunstall [5] gave an algorithm to maximize E (L) for a fixed jDj for an i.i.d source. Generalization of Tunstall's method to Markov sources were given in [2], <ref> [3] </ref>. Tjalkens and Willems [4] gave asymptotically optimal universal codes for binary i.i.d sources. Asymptotically optimal universal codes for Markov sources were given in [6]. II. Problem Formulation Here we will consider the performance of codes given in [6] and [1] on individual sequences.
Reference: [4] <author> T. J. Tjalkens, and F. M. J. </author> <title> Willems "A universal variable-to-fixed length source code based on Lawrence's Algorithm," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> vol. 38, </volume> <pages> pp. 247-253, </pages> <month> March. </month> <year> 1992. </year>
Reference-contexts: Tunstall [5] gave an algorithm to maximize E (L) for a fixed jDj for an i.i.d source. Generalization of Tunstall's method to Markov sources were given in [2], [3]. Tjalkens and Willems <ref> [4] </ref> gave asymptotically optimal universal codes for binary i.i.d sources. Asymptotically optimal universal codes for Markov sources were given in [6]. II. Problem Formulation Here we will consider the performance of codes given in [6] and [1] on individual sequences.
Reference: [5] <author> B.P. Tunstall, </author> <title> "Synthesis of Noiseless compression codes," </title> <type> Ph.D. </type> <institution> dissert., Georgia Inst. of Technology., </institution> <address> Atlanta, GA, </address> <month> Sept. </month> <year> 1967. </year>
Reference-contexts: This is justified because for Markov sources for long input strings the compression converges to log jDj=E (L). Thus a goal while designing the dictionary is to try and maximize E (L) for a fixed dictionary size. Tunstall <ref> [5] </ref> gave an algorithm to maximize E (L) for a fixed jDj for an i.i.d source. Generalization of Tunstall's method to Markov sources were given in [2], [3]. Tjalkens and Willems [4] gave asymptotically optimal universal codes for binary i.i.d sources.
Reference: [6] <author> K. Viswewswariah, and S. </author> <title> Kulkarni , "Universal variable-to-fixed length source codes for Markov sources," </title> <booktitle> IEEE International Symposium on Information Theory, </booktitle> <address> Cambridge, MA, </address> <year> 1998. </year>
Reference-contexts: Generalization of Tunstall's method to Markov sources were given in [2], [3]. Tjalkens and Willems [4] gave asymptotically optimal universal codes for binary i.i.d sources. Asymptotically optimal universal codes for Markov sources were given in <ref> [6] </ref>. II. Problem Formulation Here we will consider the performance of codes given in [6] and [1] on individual sequences. <p> Generalization of Tunstall's method to Markov sources were given in [2], [3]. Tjalkens and Willems [4] gave asymptotically optimal universal codes for binary i.i.d sources. Asymptotically optimal universal codes for Markov sources were given in <ref> [6] </ref>. II. Problem Formulation Here we will consider the performance of codes given in [6] and [1] on individual sequences. We will consider a sequence x n 1 2 A n and bound the performance of the codes on this sequence in terms of the best possible code length form a class of codes. <p> We will bound R (x n 1 ) in terms of the best achievable compression performance from our class of codes. In <ref> [6] </ref> a method to construct trees was given which was 1 This work was supported in part by the National Science Foun dation under Grants NYI award IRI-9457645 and NCR 9523805 shown to achieve asymptotically optimal performance. <p> x n 1 2 A n and initial state s 0 R (x n n C (l; jAj; ffi) log log M n 1 1 ) 1 + ffi log M The proof of the theorem above is constructive and the method of construction of the code is as in <ref> [6] </ref>. Our next result is an upper-bound on the performance of the coding method described in [1], which allows the use of a variable-fixed length code along with an estimator of proba bilities. We will use as an estimator the context tree weight ing method [7].
Reference: [7] <author> F. M. J. Willems, Y. M. Shtarkov, and T. J. Tjalkens, </author> <title> "The context-tree weighting method: basic properties," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> vol. 41, </volume> <pages> pp. 653-664, </pages> <month> May. </month> <year> 1995. </year>
Reference-contexts: Our next result is an upper-bound on the performance of the coding method described in [1], which allows the use of a variable-fixed length code along with an estimator of proba bilities. We will use as an estimator the context tree weight ing method <ref> [7] </ref>. Let us denote the compression achieved by the scheme as R NF (x n 1 ). Here our comparison class will be the class of sources with memory smaller than l. As in [7] let P (x n 1 j; S) denote the probability of x n 1 when the <p> We will use as an estimator the context tree weight ing method <ref> [7] </ref>. Let us denote the compression achieved by the scheme as R NF (x n 1 ). Here our comparison class will be the class of sources with memory smaller than l. As in [7] let P (x n 1 j; S) denote the probability of x n 1 when the source model is S and parameter vector is .
References-found: 7

