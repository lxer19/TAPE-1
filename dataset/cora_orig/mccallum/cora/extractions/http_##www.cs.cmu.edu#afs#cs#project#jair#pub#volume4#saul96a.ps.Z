URL: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/saul96a.ps.Z
Refering-URL: http://www.cs.washington.edu/research/jair/abstracts/saul96a.html
Root-URL: 
Email: lksaul@psyche.mit.edu Tommi Jaakkola tommi@psyche.mit.edu  jordan@psyche.mit.edu  
Title: Mean Field Theory for Sigmoid Belief Networks  
Author: Lawrence K. Saul Michael I. Jordan 
Address: 79 Amherst Street, E10-243 Cambridge, MA 02139  
Affiliation: Center for Biological and Computational Learning Massachusetts Institute of Technology  
Note: Journal of Artificial Intelligence Research 4 (1996) 61|76 Submitted 11/95; published 3/96  
Abstract: We develop a mean field theory for sigmoid belief networks based on ideas from statistical mechanics. Our mean field theory provides a tractable approximation to the true probability distribution in these networks; it also yields a lower bound on the likelihood of evidence. We demonstrate the utility of this framework on a benchmark problem in statistical pattern recognition|the classification of handwritten digits.
Abstract-found: 1
Intro-found: 1
Reference: <author> Ackley, D., Hinton, G., & Sejnowski, T. </author> <title> (1985) A learning algorithm for Boltzmann machines. </title> <journal> Cognitive Science, </journal> <volume> 9, </volume> <pages> 147-169. </pages>
Reference-contexts: Our approach in this paper relies on a different tool from statistical mechanics|namely, mean field theory (Parisi, 1988). The mean field approximation is well known for probabilistic models that can be represented as undirected graphs|so-called Markov networks. For example, in Boltzmann machines <ref> (Ackley, Hinton, & Sejnowski, 1985) </ref>, mean field learning rules have been shown to yield tremendous savings in time and computation over sampling-based methods (Peterson & Anderson, 1987). The main motivation for this work was to extend the mean field approximation for undirected graphical models to their directed counterparts.
Reference: <author> Buntine, W. </author> <title> (1994) Operations for learning with graphical models. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2, </volume> <pages> 159-225. </pages>
Reference: <author> Cooper, G. </author> <title> (1990) Computational complexity of probabilistic inference using Bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42, </volume> <pages> 393-405. </pages>
Reference-contexts: As a computational tool, our mean field theory has two main virtues: first, it provides a tractable approximation to the conditional distributions required for inference; second, it provides a lower bound on the likelihoods required for learning. The problem of computing exact likelihoods in belief networks is NP-hard <ref> (Cooper, 1990) </ref>; the same is true for approximating likelihoods to within a guaranteed degree of accuracy (Dagum & Luby, 1993). It follows that one cannot establish universal guarantees for the accuracy of the mean field approximation.
Reference: <author> Cover, T., & Thomas, J. </author> <booktitle> (1991) Elements of Information Theory. </booktitle> <address> New York: </address> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: Let us first consider the origin of the lower bound. Clearly, for any approximating distribution Q (HjV ), we have the equality: ln P (V ) = ln H = ln H Q (HjV ) : (10) To obtain a lower bound, we now apply Jensen's inequality <ref> (Cover & Thomas, 1991) </ref>, pushing the logarithm through the sum over hidden states and into the expectation: ln P (V ) H Q (HjV ) : (11) It is straightforward to verify that the difference between the left and right hand side of eq. (11) is the Kullback-Leibler divergence (Cover & <p> inequality <ref> (Cover & Thomas, 1991) </ref>, pushing the logarithm through the sum over hidden states and into the expectation: ln P (V ) H Q (HjV ) : (11) It is straightforward to verify that the difference between the left and right hand side of eq. (11) is the Kullback-Leibler divergence (Cover & Thomas, 1991): KL (QjjP ) = X Q (HjV ) ln Q (HjV ) Thus, the better the approximation to P (HjV ), the tighter the bound on ln P (V ). 64 Mean Field Theory for Sigmoid Belief Networks Anticipating the connection to statistical mechanics, we will refer
Reference: <author> Dagum, P., & Luby, M. </author> <title> (1993) Approximately probabilistic reasoning in Bayesian belief networks is NP-hard. </title> <journal> Artificial Intelligence, </journal> <volume> 60, </volume> <month> 141-153. </month> <title> 74 Mean Field Theory for Sigmoid Belief Networks Dayan, </title> <editor> P., Hinton, G., Neal, R., & Zemel, R. </editor> <booktitle> (1995) The Helmholtz machine. Neural Computation, </booktitle> <volume> 7, </volume> <pages> 889-904. </pages>
Reference-contexts: The problem of computing exact likelihoods in belief networks is NP-hard (Cooper, 1990); the same is true for approximating likelihoods to within a guaranteed degree of accuracy <ref> (Dagum & Luby, 1993) </ref>. It follows that one cannot establish universal guarantees for the accuracy of the mean field approximation. For certain networks, clearly, the mean field approximation is bound to fail|it cannot capture logical constraints or strong correlations between fluctuating units.
Reference: <author> Dempster, A., Laird, N., and Rubin, D. </author> <title> (1977) Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B39, </journal> <pages> 1-38. </pages>
Reference-contexts: This is equivalent to minimizing the gap between the true log-likelihood, ln P (V ), and the lower bound obtained from mean field theory. The 2. A similar average is performed in the E-step of an EM algorithm <ref> (Dempster, Laird, & Rubin, 1977) </ref>; the difference here is that the average is performed over the mean field distribution, Q (HjV ), rather than the true posterior, P (HjV ). For a related discussion, see Neal & Hinton (1993). 3. Our terminology is as follows.
Reference: <author> Frey, B., Hinton, G., & Dayan, P. </author> <title> (1995) Does the wake-sleep algorithm learn good density estimators? In D. </title> <editor> Touretzky, M. Mozer, and M. Hasselmo (eds). </editor> <booktitle> Advances of Neural Information Processing Systems: Proceedings of the 1995 Conference. </booktitle>
Reference-contexts: A similar approximation for models of continous random variables is discussed by Jaakkola et al (1995). The idea of bounding the likelihood in sigmoid belief networks was introduced in a related architecture known as the Helmholtz machine <ref> (Hinton, Dayan, Frey, & Neal 1995) </ref>. A fundamental advance of this work was to establish a framework for approximation that is especially conducive to learning the parameters of layered belief networks. The close connection between this idea and the mean field approximation from statistical mechanics, however, was not developed. <p> Finally, cycle through the patterns in the training set, maximizing their likelihoods 6 for a fixed number of iterations or until one detects the onset of overfitting (e.g., by cross-validation). The above procedure uses a lower bound on the log-likelihood as a cost function for training belief networks <ref> (Hinton, Dayan, Frey, & Neal, 1995) </ref>. The fact that we have a lower bound on the log-likelihood, rather than an upper bound, is of course crucial to the success of this learning algorithm. <p> As expected, digits with relatively simple constructions (e.g., zeros, ones, and sevens) are more easily modeled than the rest. Both measures of performance|error rate and log-likelihood score|are competitive with previously published results <ref> (Hinton, Dayan, Frey, & Neal, 1995) </ref> on this data set. The success of the algorithm affirms both the strategy of maximizing a lower bound and the utility of the mean field approximation. <p> The success of the algorithm affirms both the strategy of maximizing a lower bound and the utility of the mean field approximation. Though similar results can be obtained via Gibbs sampling, this seems to require considerably more computation than methods based on maximizing a lower bound <ref> (Frey, Dayan, & Hinton, 1995) </ref>. 71 Saul, Jaakkola, & Jordan algorithm classification error nearest neighbor 6.7% back-propagation 5.6% wake-sleep 4.8% mean field 4.6% Table 2: Classification error rates for the data set of handwritten digits. <p> The formalism in this paper differs in a number of respects from the Helmholtz machine. Most importantly, it enables one to compute a rigorous lower bound on the likelihood. This cannot be said for the wake-sleep algorithm <ref> (Frey, Hinton, & Dayan, 1995) </ref>, which relies on sampling-based methods, or the heuristic approximation of Dayan et al (1995), which does not guarantee a rigorous lower bound.
Reference: <author> Geman, S., & Geman, D. </author> <title> (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6, </volume> <pages> 721-741. </pages>
Reference-contexts: Indeed, in large networks with dense or layered connectivity, exact methods are intractable as they require summing over an exponentially large number of hidden states. One approach to dealing with such networks has been to use Gibbs sampling (Pearl, 1988), a stochastic simulation methodology with roots in statistical mechanics <ref> (Geman & Geman, 1984) </ref>. Our approach in this paper relies on a different tool from statistical mechanics|namely, mean field theory (Parisi, 1988). The mean field approximation is well known for probabilistic models that can be represented as undirected graphs|so-called Markov networks.
Reference: <author> Hertz, J., Krogh, A., and Palmer, R. G. </author> <title> (1991) Introduction to the Theory of Neural Computation. </title> <address> Redwood City, CA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The first two terms in this equation are familiar from Markov networks with pairwise interactions <ref> (Hertz, Krogh, & Palmer, 1991) </ref>; the last term is peculiar to sigmoid belief networks. Note that the overall energy is neither a linear function of the weights nor a polynomial function of the units.
Reference: <author> Hinton, G., Dayan, P., Frey, B., & Neal, R. </author> <title> (1995) The wake-sleep algorithm for unsupervised neural networks. </title> <journal> Science, </journal> <volume> 268, </volume> <pages> 1158-1161. </pages>
Reference-contexts: A similar approximation for models of continous random variables is discussed by Jaakkola et al (1995). The idea of bounding the likelihood in sigmoid belief networks was introduced in a related architecture known as the Helmholtz machine <ref> (Hinton, Dayan, Frey, & Neal 1995) </ref>. A fundamental advance of this work was to establish a framework for approximation that is especially conducive to learning the parameters of layered belief networks. The close connection between this idea and the mean field approximation from statistical mechanics, however, was not developed. <p> Finally, cycle through the patterns in the training set, maximizing their likelihoods 6 for a fixed number of iterations or until one detects the onset of overfitting (e.g., by cross-validation). The above procedure uses a lower bound on the log-likelihood as a cost function for training belief networks <ref> (Hinton, Dayan, Frey, & Neal, 1995) </ref>. The fact that we have a lower bound on the log-likelihood, rather than an upper bound, is of course crucial to the success of this learning algorithm. <p> As expected, digits with relatively simple constructions (e.g., zeros, ones, and sevens) are more easily modeled than the rest. Both measures of performance|error rate and log-likelihood score|are competitive with previously published results <ref> (Hinton, Dayan, Frey, & Neal, 1995) </ref> on this data set. The success of the algorithm affirms both the strategy of maximizing a lower bound and the utility of the mean field approximation. <p> The success of the algorithm affirms both the strategy of maximizing a lower bound and the utility of the mean field approximation. Though similar results can be obtained via Gibbs sampling, this seems to require considerably more computation than methods based on maximizing a lower bound <ref> (Frey, Dayan, & Hinton, 1995) </ref>. 71 Saul, Jaakkola, & Jordan algorithm classification error nearest neighbor 6.7% back-propagation 5.6% wake-sleep 4.8% mean field 4.6% Table 2: Classification error rates for the data set of handwritten digits. <p> moreover, that all the above qualifications apply to Markov networks, and that in this domain, mean field methods are already well-established. 72 Mean Field Theory for Sigmoid Belief Networks The idea of bounding the likelihood in sigmoid belief networks was introduced in a related architecture known as the Helmholtz machine <ref> (Hinton, Dayan, Neal, & Zemel, 1995) </ref>. The formalism in this paper differs in a number of respects from the Helmholtz machine. Most importantly, it enables one to compute a rigorous lower bound on the likelihood. <p> The formalism in this paper differs in a number of respects from the Helmholtz machine. Most importantly, it enables one to compute a rigorous lower bound on the likelihood. This cannot be said for the wake-sleep algorithm <ref> (Frey, Hinton, & Dayan, 1995) </ref>, which relies on sampling-based methods, or the heuristic approximation of Dayan et al (1995), which does not guarantee a rigorous lower bound.
Reference: <author> Itzykson, C., & Drouffe, J.M. </author> <year> (1991). </year> <title> Statistical Field Theory. </title> <publisher> Cambridge: Cambridge University Press. </publisher>
Reference-contexts: Mean Field Theory The mean field approximation appears under a multitude of guises in the physics literature; indeed, it is "almost as old as statistical mechanics" <ref> (Itzykson & Drouffe, 1991) </ref>. Let us briefly explain how it acquired its name and why it is so ubiquitous.
Reference: <author> Jaakkola, T., Saul, L., & Jordan, M. </author> <title> (1995) Fast learning by bounding likelihoods in sigmoid-type belief networks. </title> <editor> In D. Touretzky, M. Mozer, and M. Hasselmo (eds). </editor> <booktitle> Advances of Neural Information Processing Systems: Proceedings of the 1995 Conference. </booktitle>
Reference: <author> Jaakkola, T., & Jordan, M. </author> <title> (1996a) Mixture model approximations for belief networks. </title> <note> Manuscript in preparation. </note>
Reference: <author> Jaakkola, T., & Jordan, M. </author> <title> (1996b) Computing upper and lower bounds on likelihoods in intractable networks. </title> <note> Submitted. </note>
Reference: <author> Jensen, C. S., Kong, A., & Kjaerulff, U. </author> <title> (1995) Blocking Gibbs sampling in very large probabilistic expert systems. </title> <journal> International Journal of Human Computer Studies. </journal> <note> Special Issue on Real-World Applications of Uncertain Reasoning. </note>
Reference-contexts: There exist provably efficient algorithms for computing likelihoods in belief networks with tree or chain-like architectures. In practice, these algorithms also tend to perform well on more general sparse networks. However, for networks in which nodes have many parents, the exact algorithms are too slow <ref> (Jensen, Kong, & Kjaefulff, 1995) </ref>. Indeed, in large networks with dense or layered connectivity, exact methods are intractable as they require summing over an exponentially large number of hidden states.
Reference: <author> Lauritzen, S., & Spiegelhalter, D. </author> <year> (1988). </year> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 50, </volume> <pages> 157-224. </pages>
Reference-contexts: In solving these equations by iteration, the values of the instantiated units are propagated throughout the entire network. An analogous propagation of information occurs in exact algorithms <ref> (Lauritzen & Spiegelhalter, 1988) </ref> to compute likelihoods in belief networks. While the factorized approximation to the true posterior is not exact, the mean field equations set the parameters f i g i2H to values which make the approximation as accurate as possible.
Reference: <author> McCullagh, P., & Nelder, J. A. </author> <title> (1983) Generalized Linear Models. </title> <publisher> London: Chapman and Hall. </publisher>
Reference-contexts: The relation to noisy-OR models is discussed in appendix A. 62 Mean Field Theory for Sigmoid Belief Networks P (S = 1jz) = (z) is the conditional probability that node S is activated. logistic regression <ref> (McCullagh & Nelder, 1983) </ref>. The conditional probability distribution for S i may be summarized as: P (S i jpa (S i )) = h P i h P i : (4) Note that substituting S i = 1 in eq. (4) recovers the result in eq. (2).
Reference: <author> Neal, R. </author> <title> (1992) Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56, </volume> <pages> 71-113. </pages>
Reference-contexts: The reason is that probabilistic models which have compact representations as DAGs may have unwieldy representations as undirected graphs. As we shall see, avoiding this complexity and working directly on DAGs requires an extension of existing methods. In this paper we focus on sigmoid belief networks <ref> (Neal, 1992) </ref>, for which the resulting mean field theory is most straightforward. These are networks of binary random variables whose local c fl1996 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. Saul, Jaakkola, & Jordan conditional distributions are based on log-linear models. <p> fS 1 ; S 2 ; : : : S i1 g; this is the smallest set of nodes for which P (S i jS 1 ; S 2 ; : : : ; S i1 ) = P (S i jpa (S i )): (1) In sigmoid belief networks <ref> (Neal, 1992) </ref>, the conditional distributions attached to each node are based on log-linear models.
Reference: <author> Neal, R., & Hinton, G. </author> <title> (1993) A new view of the EM algorithm that justifies incremental and other variants. </title> <note> Submitted for publication. </note>
Reference: <author> Parisi, G. </author> <title> (1988) Statistical Field Theory. </title> <address> Redwood City, CA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: One approach to dealing with such networks has been to use Gibbs sampling (Pearl, 1988), a stochastic simulation methodology with roots in statistical mechanics (Geman & Geman, 1984). Our approach in this paper relies on a different tool from statistical mechanics|namely, mean field theory <ref> (Parisi, 1988) </ref>. The mean field approximation is well known for probabilistic models that can be represented as undirected graphs|so-called Markov networks. <p> Because of its simplicity, however, it is widely used as a first step in understanding many types of physical phenomena. Though this explains the philological origins of mean field theory, there are in fact many ways to derive what amounts to the same approximation <ref> (Parisi, 1988) </ref>. In this paper we present the formulation most appropriate for inference and learning in graphical models. In particular, we view mean field theory as a principled method for approximating an intractable graphical model by a tractable one.
Reference: <author> Pearl, J. </author> <booktitle> (1988) Probabilistic Reasoning in Intelligent Systems. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Indeed, in large networks with dense or layered connectivity, exact methods are intractable as they require summing over an exponentially large number of hidden states. One approach to dealing with such networks has been to use Gibbs sampling <ref> (Pearl, 1988) </ref>, a stochastic simulation methodology with roots in statistical mechanics (Geman & Geman, 1984). Our approach in this paper relies on a different tool from statistical mechanics|namely, mean field theory (Parisi, 1988). <p> The argument of the sigmoid function may be viewed as an effective input to the ith unit in the belief network. This effective input is composed of terms from the unit's Markov blanket <ref> (Pearl, 1988) </ref>, shown in Figure 3; in particular, these terms take into account the unit's internal bias, the values of its parents and children, and, through the matrix K ji , the values of its children's other parents. <p> Appendix A. Sigmoid versus Noisy-OR The semantics of the sigmoid function are similar, but not identical, to the noisy-OR gates <ref> (Pearl, 1988) </ref> more commonly found in the belief network literature. Noisy-OR gates use the weights in the network to represent independent causal events.
Reference: <author> Peterson, C., & Anderson, J.R. </author> <title> (1987) A mean field theory learning algorithm for neural networks. </title> <journal> Complex Systems, </journal> <volume> 1, </volume> <pages> 995-1019. </pages>
Reference-contexts: The mean field approximation is well known for probabilistic models that can be represented as undirected graphs|so-called Markov networks. For example, in Boltzmann machines (Ackley, Hinton, & Sejnowski, 1985), mean field learning rules have been shown to yield tremendous savings in time and computation over sampling-based methods <ref> (Peterson & Anderson, 1987) </ref>. The main motivation for this work was to extend the mean field approximation for undirected graphical models to their directed counterparts.
Reference: <author> Press, W. H., Flannery, B. P., Teukolsky, S.A., & Vetterling, W. T. </author> <title> (1986) Numerical Recipes. </title> <publisher> Cambrige: Cambridge University Press. </publisher>
Reference-contexts: The minimization over f~ i g therefore reduces to N independent minimizations over the interval [0; 1]. These can be done by any number of standard methods <ref> (Press, Flannery, Teukolsky, & Vetterling, 1986) </ref>. To choose the means, we set the gradients of the bound with respect to f i g i2H equal to zero.
Reference: <author> Russell, S., Binder, J., Koller, D., & Kanazawa, K. </author> <year> (1995). </year> <title> Local learning in probabilistic networks with hidden variables. </title> <booktitle> In Proceedings of IJCAI-95. </booktitle> <volume> 75 Saul, </volume> <editor> Jaakkola, & Jordan Saul, L., & Jordan, M. </editor> <title> (1995) Exploiting tractable substructures in intractable networks. </title> <address> In D. </address>
Reference: <editor> Touretzky, M. Mozer, and M. Hasselmo (eds). </editor> <booktitle> Advances of Neural Information Processing Systems: Proceedings of the 1995 Conference. </booktitle>
Reference: <author> Seung, H. </author> <year> (1995). </year> <title> Annealed theories of learning. </title> <editor> In J.-H. Oh, C. Kwon, and S. Cho, eds. </editor> <booktitle> Neural Networks: The Statistical Mechanics Perspective, Proceedings of the CTP-PRSRI Joint Workshop on Theoretical Physics. </booktitle> <address> Singapore, </address> <publisher> World Scientific. </publisher> <pages> 76 </pages>
Reference-contexts: A tighter bound <ref> (Seung, 1995) </ref> can be obtained, however, by allowing non-zero values of ~. This is illustrated in unit variance.
References-found: 26

