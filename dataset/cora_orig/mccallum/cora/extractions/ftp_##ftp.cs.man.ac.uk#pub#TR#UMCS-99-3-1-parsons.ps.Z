URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-99-3-1-parsons.ps.Z
Refering-URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-99-3-1.html
Root-URL: http://www.cs.man.ac.uk
Email: fs.d.parsons, m.j.wooldridgeg@elec.qmw.ac.uk  fola.pettersson, alessandro.saffiottig@ton.oru.se  
Phone: 2  26.3.99  
Title: Robots with the Best of Intentions  
Author: S. Parsons O. Pettersson A. Saffiotti M. Wooldridge 
Web: http://www.elec.qmw.ac.uk/isag  http://www.oru.se/forsk/aass  
Address: London, London E1 4NS, U.K.  S-70182 Orebro, Sweden  
Affiliation: 1 Department of Electronic Engineering Queen Mary and Westfield College University of  Applied Autonomous Sensor Systems Department of Technology and Science Orebro University,  
Abstract: Intelligent mobile robots need the ability to integrate robust navigation facilities with higher level reasoning. This paper is an attempt at combining results and techniques from the areas of robot navigation and of intelligent agency. We propose to integrate an existing navigation system based on fuzzy logic with a deliberator based on the so-called BDI model. We discuss some of the subtleties involved in this integration, and illustrate it on a simulated example. Experiments on a real mobile robot are under way. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. E. Bratman. </author> <title> Intention, Plans, and Practical Reason. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: The development of the BDI paradigm was to a great extent driven by Bratman's theory of (human) practical reasoning <ref> [1] </ref>, in which intentions play a central role. Put crudely, since an agent cannot deliberate indefinitely about what courses of action to pursue, the idea is it should eventually commit to achieving certain states of affairs, and then devote resources to achieving them. <p> is a fuzzy location in the robot's map. (More precisely, a goal is formally defined in the TC framework as a fuzzy set of trajectories.) This means that a goal in TC can be more or less satisfied, as measured by a degree of satisfaction, a real number in the <ref> [0; 1] </ref> interval. Typically, this degree depends on the distance between the robot and the desired location, but more complex goals may have more complex degrees of satisfaction. <p> Secondly, the `adequacy' of the current B-plan which is monitored by the TC is in fact a degree of adequacy, again measured by a number in <ref> [0; 1] </ref>.
Reference: [2] <author> M. E. Bratman, D. J. Israel, and M. E. Pollack. </author> <title> Plans and resource-bounded practical reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 4 </volume> <pages> 349-355, </pages> <year> 1988. </year>
Reference-contexts: These chosen states of affairs are intentions, and once adopted, they play a central role in future practical reasoning <ref> [2, 3] </ref>. It should be noted that the current popularity of the BDI paradigm in the area of software agents is due to more than just an anthropomorphic desire to attribute mental states to inanimate objects.
Reference: [3] <author> P. R. Cohen and H. J. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 213-261, </pages> <year> 1990. </year>
Reference-contexts: These chosen states of affairs are intentions, and once adopted, they play a central role in future practical reasoning <ref> [2, 3] </ref>. It should be noted that the current popularity of the BDI paradigm in the area of software agents is due to more than just an anthropomorphic desire to attribute mental states to inanimate objects. <p> An agent cannot simply maintain an intention, once adopted, without ever stopping to reconsider it. From time-to-time, it will be necessary to check, for example, whether the intention has been achieved, or whether it is believed to be no longer achievable <ref> [3] </ref>. In such situations, it is necessary for an agent to deliberate over its intentions, and, if necessary, to change focus by dropping existing intentions and adopting new ones. In [15] we started the formal analysis of this problem.
Reference: [4] <author> M. P. Georgeff and F. F. Ingrand. </author> <title> Decision-making in an embedded reasoning system. </title> <booktitle> In Procs. of the AAAI Conf., </booktitle> <pages> pages 972-978, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: Several proposals have already appeared in the literatures that use a BDI approach for this goal. For example, the Saphira architecture [9] uses a simplified version of PRS <ref> [4] </ref>, a computational incarnation of the BDI model, at the higher level, and fuzzy navigation behaviours at the lower level. In that architecture, the PRS system arbitrates the on-off activation of individual fuzzy behaviours, which are seen as ground level intentions.
Reference: [5] <author> M. P. Georgeff and F. F. Ingrand. </author> <title> Monitoring and control of spacecraft systems using procedural reasoning. </title> <booktitle> In Proceedings of the Space Operations Automation and Robotics Workshop, </booktitle> <year> 1989. </year>
Reference-contexts: In addition, the BDI approach has proved effective as the basis of a number of exacting applications, including the monitoring and control of spacecraft systems <ref> [5] </ref>, and managing the flow of aircraft arriving at an airport [6]. A major issue in the design of agents that are based upon models of intention is that of when to reconsider intentions. An agent cannot simply maintain an intention, once adopted, without ever stopping to reconsider it.
Reference: [6] <author> M. P. Georgeff and A. S. </author> <title> Rao. </title> <journal> Profile of the Australian Artificial Intelligence Institute. IEEE Expert, </journal> <volume> 6, December:89-92, </volume> <year> 1996. </year>
Reference-contexts: In addition, the BDI approach has proved effective as the basis of a number of exacting applications, including the monitoring and control of spacecraft systems [5], and managing the flow of aircraft arriving at an airport <ref> [6] </ref>. A major issue in the design of agents that are based upon models of intention is that of when to reconsider intentions. An agent cannot simply maintain an intention, once adopted, without ever stopping to reconsider it.
Reference: [7] <author> F. F. Ingrand, R. Chatila, R. Alami, and F. Robert. </author> <title> PRS: a high level supervision and control language for autonomous mobile robots. </title> <booktitle> In Procs. of the Int. Conf. on Robotics and Automation, </booktitle> <address> Minneapolis, MN, </address> <year> 1996. </year>
Reference-contexts: In that architecture, the PRS system arbitrates the on-off activation of individual fuzzy behaviours, which are seen as ground level intentions. A similar approach is taken in <ref> [7] </ref> and in [10], where PRS-like systems are used to arbitrate low-level processes. Our proposal departs from these approaches in the way we partition the responsibilities between the Thinking Cap and the BDI deliberation system.
Reference: [8] <author> D. Kinny and M. Georgeff. </author> <title> Commitment and effectiveness of situated agents. </title> <booktitle> In Procs. of the Int. Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 82-88, </pages> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: "an agent is optimal if it always deliberates when deliberation will change its intentions and never deliberates when deliberation would not change its intentions", and showed that this can be used to develop a formal description of agents which are bold and cautious in the sense of Kinny and Georgeff <ref> [8] </ref>. The idea is that different types of environment require different types of strategies. In rapidly changing environments it makes sense for an agent to spend a lot of time deliberating in order to avoid spending time trying to achieve things which have become impossible.
Reference: [9] <author> K. Konolige, K.L. Myers, E.H. Ruspini, and A. Saffiotti. </author> <title> The Saphira architecture: A design for autonomy. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 9(1) </volume> <pages> 215-235, </pages> <year> 1997. </year>
Reference-contexts: Several proposals have already appeared in the literatures that use a BDI approach for this goal. For example, the Saphira architecture <ref> [9] </ref> uses a simplified version of PRS [4], a computational incarnation of the BDI model, at the higher level, and fuzzy navigation behaviours at the lower level. In that architecture, the PRS system arbitrates the on-off activation of individual fuzzy behaviours, which are seen as ground level intentions.
Reference: [10] <author> J. Lee, M. J. Huber, E. H. Durfee, and P. G. Kenny. UM-PRS: </author> <title> an implementation of the procedural reasoning system for multirobot applications. </title> <booktitle> In AIAA/NASA Conf. on Int. Robots in Field, Factory, </booktitle> <institution> Service and Space. American Institute of Aeronautics and Astronautics, </institution> <year> 1994. </year>
Reference-contexts: In that architecture, the PRS system arbitrates the on-off activation of individual fuzzy behaviours, which are seen as ground level intentions. A similar approach is taken in [7] and in <ref> [10] </ref>, where PRS-like systems are used to arbitrate low-level processes. Our proposal departs from these approaches in the way we partition the responsibilities between the Thinking Cap and the BDI deliberation system.
Reference: [11] <author> A. Saffiotti. </author> <title> Autonomous robot navigation: a fuzzy logic approach. </title> <type> PhD thesis, </type> <institution> Universite Libre de Bruxelles, </institution> <address> Brussels, Belgium, </address> <year> 1998. </year>
Reference-contexts: A full description of the TC can be found in <ref> [11] </ref>. Parts of the TC were previously reported in [13, 12, 14]. <p> In closing, we note that the example shown above has only been run in simulation | although the navigation system alone has been extensively validated on several real robots <ref> [13, 12, 11] </ref>. We are aware that the actual verification of the ideas sketched in this paper will only come from intensive testing in real and challenging environments.
Reference: [12] <author> A. Saffiotti, K. Konolige, and E. H. Ruspini. </author> <title> A multivalued-logic approach to integrating planning and control. </title> <journal> Artificial Intelligence, </journal> <volume> 76(1-2):481-526, </volume> <year> 1995. </year>
Reference-contexts: A full description of the TC can be found in [11]. Parts of the TC were previously reported in <ref> [13, 12, 14] </ref>. <p> In closing, we note that the example shown above has only been run in simulation | although the navigation system alone has been extensively validated on several real robots <ref> [13, 12, 11] </ref>. We are aware that the actual verification of the ideas sketched in this paper will only come from intensive testing in real and challenging environments.
Reference: [13] <author> A. Saffiotti, E. H. Ruspini, and K. Konolige. </author> <title> Blending reactivity and goal-directedness in a fuzzy controller. </title> <booktitle> In Proc. of the 2nd IEEE Int. Conf. on Fuzzy Systems, </booktitle> <pages> pages 134-139, </pages> <address> San Francisco, California, 1993. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: A full description of the TC can be found in [11]. Parts of the TC were previously reported in <ref> [13, 12, 14] </ref>. <p> In closing, we note that the example shown above has only been run in simulation | although the navigation system alone has been extensively validated on several real robots <ref> [13, 12, 11] </ref>. We are aware that the actual verification of the ideas sketched in this paper will only come from intensive testing in real and challenging environments.
Reference: [14] <author> A. </author> <title> Saffiotti and L.P. Wesley. Perception-based self-localization using fuzzy locations. </title> <editor> In M. van Lam-balgen L. Dorst and F. Voorbraak, editors, </editor> <booktitle> Reasoning with Uncertainty in Robotics | Proc. of the 1st Int. Workshop, number 1093 in LNAI, </booktitle> <pages> pages 368-385. </pages> <publisher> Springer, </publisher> <address> Berlin, DE, </address> <year> 1996. </year>
Reference-contexts: A full description of the TC can be found in [11]. Parts of the TC were previously reported in <ref> [13, 12, 14] </ref>.
Reference: [15] <author> M. Wooldridge and S. Parsons. </author> <title> Intention reconsideration reconsidered. </title> <booktitle> In Proc. of the 5th Int. Workshop on Agent Theories Architectures and Languages (ATAL), </booktitle> <address> Paris, F, </address> <year> 1998. </year>
Reference-contexts: In such situations, it is necessary for an agent to deliberate over its intentions, and, if necessary, to change focus by dropping existing intentions and adopting new ones. In <ref> [15] </ref> we started the formal analysis of this problem. <p> A consequence of this premise is that it might be profitable to combine the TC with a BDI architecture of the kind proposed in <ref> [15] </ref>. Our first attempt to integrate these two different systems is to consider them as separated blocks with a minimal interface between them, as shown in Fig. 1. <p> Including this idea in our framework would lead to a "tower of meta-controllers" similar to the one suggested in <ref> [15] </ref>. Such an approach would allow the robot to dynamically adjust its policy for redeliberation if it finds that its current policy is incorrect with respect to its current environment.
References-found: 15

