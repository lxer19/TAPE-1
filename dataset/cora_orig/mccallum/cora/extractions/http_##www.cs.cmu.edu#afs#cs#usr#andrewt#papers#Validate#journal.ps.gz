URL: http://www.cs.cmu.edu/afs/cs/usr/andrewt/papers/Validate/journal.ps.gz
Refering-URL: http://www.cs.cmu.edu/~andrewt/papers.html
Root-URL: 
Title: Validation of Image Defect Models for Optical Character Recognition  
Author: Yanhong Li Daniel Lopresti George Nagy Andrew Tomkins 
Keyword: Index Terms: optical character recognition, document image defect models, OCR error classification, defect model validation.  
Date: June 5, 1995  
Abstract: In this paper, we consider the problem of evaluating character image generators that model distortions encountered in optical character recognition (OCR). While a number of such defect models have been proposed, the contention that they produce the desired result is typically argued in an ad hoc and informal way. We introduce a rigorous and more pragmatic definition of when a model is accurate: we say a defect model is validated if the OCR errors induced by the model are indistinguishable from the errors encountered when using real scanned documents. We describe four measures to quantify this similarity, and compare and contrast them using over ten million scanned and synthesized characters in three fonts. The measures differentiate effectively between different fonts and different scans of the same font regardless of the underlying text. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. V. Rice, J. Kanai, and T. Nartker. </author> <title> An evaluation of OCR accuracy. </title> <booktitle> In Annual Report of UNLV Information Science Research Institute, </booktitle> <pages> pages 9-34, </pages> <address> Las Vegas, NV, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Differences between documents account for far more of the variation in OCR error rates than do differences between classification methods adopted by the various OCR manufacturers <ref> [1] </ref>.
Reference: [2] <author> R. Bradford. </author> <title> Technical factors in the creation of large full-text databases. </title> <booktitle> In Proc. DOE Infotech Conf., </booktitle> <institution> Oak Ridge, TN, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: A small fraction of highly degraded pages can significantly increase the overall error rate and the resulting post-editing cost <ref> [2] </ref>. In character recognition, it has proved difficult to model mathematically either the signal or the noise. Printed and handprinted characters simply are not amenable to concise formal description, and the sources of noise and distortion are manifold and complex.
Reference: [3] <author> H. S. Baird. </author> <title> Document image defect models and their uses. </title> <booktitle> In Proc. Int. Conf. on Doc. Anal. and Recog., </booktitle> <pages> pages 62-67, </pages> <address> Tsukuba Science City, Japan, </address> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Although some aspects of these models are based on observable physical phenomena, compelling arguments can also be made for purely empirical or descriptive models <ref> [3] </ref>. The use of randomly-generated characters in place of real data was popular twenty years ago for the same reason it is popular today: it is much easier to generate large data sets from a few prototypes under program control than it is to scan, segment, and label real data.
Reference: [4] <author> Q. R. Wang, Y. X. Gu, and C. Y. Suen. </author> <title> Applications of multi-layer decision tree in computer recognition of chinese characters. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 5 </volume> <pages> 83-89, </pages> <year> 1983. </year>
Reference-contexts: For bi-level images, however, it is simplest to randomly and independently switch black pixels to white with probability p, and white pixels to black with probability q. clumps An improvement over this white-noise model, local correlation between pix els, was introduced by Suen and Wang in 1983 <ref> [4] </ref>. deterministic degradation Pavlidis generated isolated character samples from pho totypesetter font descriptions of nine different typefaces using a scan-conversion algorithm.
Reference: [5] <author> T. Pavlidis. </author> <title> Effects of distortions on the recognition rate of a structural OCR system. </title> <booktitle> In Proc. Conf. on Comp. Vision and Pattern Recog., </booktitle> <pages> pages 303-309, </pages> <address> Washington, DC, </address> <year> 1983. </year>
Reference-contexts: He used the model to show the effects on classification of horizontal and vertical scaling, rotation, sampling rate, and amplitude quantization threshold <ref> [5] </ref>. pseudo-random defect models Baird classified over one million character arrays generated from one hundred different digital fonts [6]. Some of the parameters are fixed, and some are probabilistic [7].
Reference: [6] <author> H. S. Baird and R. Fossey. </author> <title> A 100-font classifier. </title> <booktitle> In Proc. Int. Conf. on Doc. Anal. and Recog., </booktitle> <pages> pages 332-339, </pages> <address> St. Malo, France, </address> <year> 1991. </year>
Reference-contexts: He used the model to show the effects on classification of horizontal and vertical scaling, rotation, sampling rate, and amplitude quantization threshold [5]. pseudo-random defect models Baird classified over one million character arrays generated from one hundred different digital fonts <ref> [6] </ref>. Some of the parameters are fixed, and some are probabilistic [7].
Reference: [7] <author> H. S. Baird. </author> <title> Document image defect models. </title> <editor> In H. S. Baird, H. Bunke, and K. Yamamoto, editors, </editor> <booktitle> Structured Document Analysis, </booktitle> <pages> pages 546-556. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: Some of the parameters are fixed, and some are probabilistic <ref> [7] </ref>.
Reference: [8] <author> R. M. Haralick. </author> <title> English document database design and implementation methodology. </title> <booktitle> In Proc. Symp. on Doc. Anal. and Info. Ret., </booktitle> <pages> pages 65-104, </pages> <address> Las Vegas, NV, </address> <month> Apr. </month> <year> 1993. </year> <month> 17 </month>
Reference-contexts: Some of the parameters are fixed, and some are probabilistic [7]. The variations modeled in an eight-million character test set that Baird contributed to a public-domain database <ref> [8] </ref> are: nominal point size, spatial sampling rate, character skew (rotation), horizontal and vertical scaling, horizontal and vertical translation, individual pixel displacement, Gaussian point-spread function, and threshold. 1 In truth, the problem we address is more properly termed "defect model invalidation," since our null hypothesis is that the model and real
Reference: [9] <author> F. Jenkins, J. Kanai, and T. Nartker. </author> <title> Using ideal images to establish a baseline of OCR performance. </title> <booktitle> In Annual Report of UNLV Information Science Research Institute, </booktitle> <address> Las Vegas, NV, </address> <year> 1993. </year>
Reference-contexts: Still, we prefer the "positive" terminology. 3 digital bitmaps Experiments on bitmaps obtained from digital fonts remain popu-lar. Recently, Jenkins and Kanai showed that commercial classifiers are often more accurate on clean scanned versions of the characters than on the digital prototypes themselves <ref> [9] </ref>. edge noise For their word recognition experiments, Khoubyari and Hull generated entire passages, in different typefaces, from the Brown Corpus [10]. They thickened the character strokes to produce some touching characters, then randomly erased some of the black pixels to simulate broken characters.
Reference: [10] <author> S. Khoubyari and J. J. Hull. </author> <title> Keyword location in noisy document image. </title> <booktitle> In Proc. Symp. on Doc. Anal. and Info. Ret., </booktitle> <pages> pages 217-232, </pages> <address> Las Vegas, NV, </address> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: Recently, Jenkins and Kanai showed that commercial classifiers are often more accurate on clean scanned versions of the characters than on the digital prototypes themselves [9]. edge noise For their word recognition experiments, Khoubyari and Hull generated entire passages, in different typefaces, from the Brown Corpus <ref> [10] </ref>. They thickened the character strokes to produce some touching characters, then randomly erased some of the black pixels to simulate broken characters.
Reference: [11] <author> T. Kanungo, R. Haralick, and I. Phillips. </author> <title> Global and local document degradation models. </title> <booktitle> In Proc. Int. Conf. on Doc. Anal. and Recog., </booktitle> <pages> pages 730-738, </pages> <address> Tsukuba Science City, Japan, </address> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: In this model, the probability of a change in a pixel's value depends on its distance from the edge of the character <ref> [11] </ref>. perspective distortion Haralick has also modeled the geometric and photometric distortions introduced by the curl of the pages when copying bound volumes [11]. page distortion Buchman's page distortion model allows for varying the amount of rotation, blurring, line addition and drop-out, speckle, contrast, bleed-through, and amplitude quantization [12]. <p> In this model, the probability of a change in a pixel's value depends on its distance from the edge of the character <ref> [11] </ref>. perspective distortion Haralick has also modeled the geometric and photometric distortions introduced by the curl of the pages when copying bound volumes [11]. page distortion Buchman's page distortion model allows for varying the amount of rotation, blurring, line addition and drop-out, speckle, contrast, bleed-through, and amplitude quantization [12]. A trained observer would not confuse any of the published ensembles of artificial characters with scanned copy, but some individual characters do look authentic.
Reference: [12] <author> M. Buchman. </author> <title> Distortion modeling for document images. </title> <booktitle> In Proc. DIMUND Work. on Page Decomp., Char. Recog., and Data Standards, </booktitle> <address> Harper's Ferry, WV, </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: the character [11]. perspective distortion Haralick has also modeled the geometric and photometric distortions introduced by the curl of the pages when copying bound volumes [11]. page distortion Buchman's page distortion model allows for varying the amount of rotation, blurring, line addition and drop-out, speckle, contrast, bleed-through, and amplitude quantization <ref> [12] </ref>. A trained observer would not confuse any of the published ensembles of artificial characters with scanned copy, but some individual characters do look authentic.
Reference: [13] <author> G. Nagy. </author> <title> On the auto-correlation function of noise in sampled typewritten characters. </title> <booktitle> In IEEE Region III Conv. Record, </booktitle> <address> New Orleans, LA, </address> <year> 1968. </year>
Reference-contexts: One possible reason for the lack of realism is that few if any of these models simulate the random phase angle of spatial sampling, which gives rise to highly correlated noise <ref> [13, 14] </ref>. Yet the displacement of the character pattern relative to the scanning array is one of the most significant sources of distortion for cleanly printed characters in common point sizes.
Reference: [14] <author> D. Lopresti, G. Nagy, P. Sarkar, and J. Zhou. </author> <title> Spatial sampling effects in optical character recognition. </title> <note> In Proc. Int. Conf. on Doc. Anal. and Rec. (to appear), </note> <institution> Montreal, Canada, </institution> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: One possible reason for the lack of realism is that few if any of these models simulate the random phase angle of spatial sampling, which gives rise to highly correlated noise <ref> [13, 14] </ref>. Yet the displacement of the character pattern relative to the scanning array is one of the most significant sources of distortion for cleanly printed characters in common point sizes.
Reference: [15] <author> K. Ishii. </author> <title> Design of a recognition dictionary using artificially distorted characters. </title> <journal> Systems and Computers in Japan, </journal> <volume> 21(9) </volume> <pages> 35-44, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, it is the only source of noise that affects uniformly all bi-level scanners with a given spatial resolution and that does not require any calibration. The models mentioned above are intended for printed or typewritten characters only. However, models for handprinting have also been developed <ref> [15] </ref>, and Plam-ondon and his colleagues have demonstrated a physiologically-plausible generative model for cursive writing [16]. As mentioned, individual variations in handprinting and writing often dominate noise due to the copying or scanning processes. A realistic defect generator for digitized characters would have many applications.
Reference: [16] <author> M. Parizeau and R. Plamondon. </author> <title> A handwriting model for syntactic recognition of cursive script. </title> <booktitle> In Proc. Int. Conf. on Pattern Recog., </booktitle> <pages> pages 308-312, </pages> <address> The Hague, Netherlands, </address> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: The models mentioned above are intended for printed or typewritten characters only. However, models for handprinting have also been developed [15], and Plam-ondon and his colleagues have demonstrated a physiologically-plausible generative model for cursive writing <ref> [16] </ref>. As mentioned, individual variations in handprinting and writing often dominate noise due to the copying or scanning processes. A realistic defect generator for digitized characters would have many applications. In the design phase, an accurate model could be used for training set augmentation 4 and parameter optimization.
Reference: [17] <author> T. Kanungo et al. </author> <title> Document degradation models: Parameter estimation and model validation. </title> <booktitle> In Proc. IAPR Work. on Machine Vision Apps., </booktitle> <pages> pages 552-557, </pages> <address> Kawasaki, Japan, </address> <month> Dec. </month> <year> 1994. </year>
Reference-contexts: amounts to designing an ad hoc classifier. hypothesis test on pixel distributions In principle, given the multinomial nature of the class-conditional pixel distributions, it is possible to test whether the distribution on the synthetic data is similar to the distribution on real data, as proposed by Kanungo and his colleagues <ref> [17] </ref>. However, it seems unlikely that a single distance measure could capture all possible differences between two pixel distributions.
Reference: [18] <author> R. A. Wilkinson et al. </author> <title> The first census optical character recognition systems conference. </title> <type> Technical Report NISTIR 1912, </type> <institution> National Institute of Standards and Technology, </institution> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: However, even for only 10 classes and 10-dimensional normally-distributed features, over 500 parameters must be estimated. Assuming that the features (or pixels) are class-conditionally uncorrelated just begs the question. A recent study compares two (real) hand-printed data sets using Karhunen-Loeve expansions of locally-averaged pixels <ref> [18] </ref>. <p> Then the converse experiment is performed, with training on a subset of B. If all four error rates are essentially the same, then there is reason to believe that A and B are similar, or at least equally easy (or difficult) for the given classifier <ref> [18] </ref>. This approach is most similar in spirit to our proposal. calibration If the printing, copying, and scanning mechanisms are available to the experimenter, then physical model parameters could be measured using test patterns. Baird has demonstrated a method that recovers most of the parameters [19].
Reference: [19] <author> H. S. Baird. </author> <title> Calibration of document image defect models. </title> <booktitle> In Proc. Symp. on Doc. Anal. and Info. Ret., </booktitle> <pages> pages 1-16, </pages> <address> Las Vegas, NV, </address> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: This approach is most similar in spirit to our proposal. calibration If the printing, copying, and scanning mechanisms are available to the experimenter, then physical model parameters could be measured using test patterns. Baird has demonstrated a method that recovers most of the parameters <ref> [19] </ref>. He has yet to calibrate the model against scanned data, though. Even if a set of parameters were obtained, the question of how completely the selected defects model real data would remain.
Reference: [20] <author> R. A. Wagner and M. J. Fischer. </author> <title> The string-to-string correction problem. </title> <journal> JACM, </journal> <volume> 21(1) </volume> <pages> 168-173, </pages> <year> 1974. </year>
Reference-contexts: The OCR process introduces errors which can be identified and categorized using an error classification procedure. An OCR'ed data set induces a distribution over the set of errors based on the relative frequencies of each type. For instance, if standard string edit distance is employed <ref> [20] </ref>, the possible errors are single character deletions, insertions, and substitutions. This simple model does not, however, capture the notion of segmentation failures correctly. Consider, for example, the pattern fm!rng.
Reference: [21] <author> J. Esakov, D. P. Lopresti, J. S. Sandberg, and J. Zhou. </author> <title> Issues in automatic OCR error classification. </title> <booktitle> In Proc. Symp. on Doc. Anal. and Info. Ret., </booktitle> <pages> pages 401-412, </pages> <address> Las Vegas, NV, </address> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: The error classification procedure we use, as described in <ref> [21] </ref>, handles arbitrary g:h multi-character substitutions. In all of our tests, we set 0 g; h 4, so patterns such as fnn!IlIlg, an error we observed in practice, are correctly identified as a single event.
Reference: [22] <author> P. A. Devijver and J. Kittler. </author> <title> Pattern Recognition: a Statistical Approach. </title> <publisher> Pren-tice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: p i = Prob [pattern e i occurs in the real data] q j = Prob [pattern e j occurs in the synthetic data] The function F may be any one of a number of measures available for comparing two probability distributions, e.g., Chernoff, Bhattacharyya, Matusita, Divergence, Patrick-Fisher, Lissack-Fu, Kolmogorov <ref> [22] </ref>. The discrete probability functions p i and q j are the error distributions of the real and synthetic data sets.
Reference: [23] <author> D. Harman. </author> <title> Ranking algorithms. </title> <editor> In W. B. Frakes and R. Baeza-Yates, editors, </editor> <booktitle> Information Retrieval: Data Structures and Algorithms, </booktitle> <pages> pages 363-392. </pages> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: q) u t i=1 The range for this measure is from 0 for identical distributions to p n for completely different distributions. 4.2 The Vector Space Measure The Vector Space model is widely used in information retrieval to quantify the similarity between two documents, or a query and a document <ref> [23] </ref>. In this approach, a text is represented by a vector of index terms or keywords. If a particular element is present in the document, the corresponding entry in the vector is set to 1; otherwise, it is set to 0.
Reference: [24] <author> J. J. Hull and Y. Li. </author> <title> Word recognition result interpretation using the vector space model for information retrieval. </title> <booktitle> In Proc. Symp. on Doc. Anal. and Info. </booktitle> <address> Ret., Las Vegas, NV, </address> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: This measure is equal to the cosine of the angle between the two vectors, and hence is sometimes called "cosine similarity." The Vector Space model has also been used recently in conjunction with OCR in a system that classifies documents based on keyword frequency using weighted cosine similarity <ref> [24] </ref>. We treat the two error distributions p and q as vectors by taking ~ V (p) = hv (p) n i, where v (p) i = p i (and similarly for ~ V (q) ).
Reference: [25] <author> Y. Li, D. Lopresti, G. Nagy, and A. Tomkins. </author> <title> Validation of image defect models for optical character recognition. </title> <type> Technical Report 69-93R, </type> <institution> Matsushita Information Technology Laboratory, </institution> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: The question of whether to include non-error patterns (i.e., fff!ffg) in the analysis is a natural one. When we augmented the data for Figure 2 in this way, all of the measures lost the ability to discriminate between fonts <ref> [25] </ref>. Since it seems reasonable to expect different fonts to exhibit different, characteristic OCR error patterns, this phenomenon requires some explanation. The OCR software we used to generate the test data, in conjunction with the clean, first-generation copy, yielded very high accuracy rates, occasionally in excess of 99.8%. <p> When space errors are included in the analysis, a slight bias can be noted towards same-font pairings for the Bhattacharyya and Coin Bias measures, but in no case are the classes linearly separable <ref> [25] </ref>. 5.3 Comparison of the Measures We now consider briefly how the measures relate to one another. Our first observation is that the Matusita measure is the only one that fails to distinguish between fonts (Figure 2). In a sense, this is not surprising.
Reference: [26] <author> Y. Li, D. Lopresti, and A. Tomkins. </author> <title> Validation of document image defect models for optical character recognition. </title> <booktitle> In Proc. Symp. on Doc. Anal. and Info. Ret., </booktitle> <pages> pages 137-150, </pages> <address> Las Vegas, NV, </address> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: a simple check on the validity of synthetic data may go a long way towards alleviating skepticism about its potential usefulness in OCR research and development. 8 Acknowledgments This paper is the synthesis of two independent works originally presented at the Third Annual Symposium on Document Analysis and Information Retrieval <ref> [26, 27] </ref>. George Nagy acknowledges the benefit of spirited discussions with Henry Baird, Tin Kam Ho, and David Ittner (AT&T Bell Laboratories), Junichi Kanai and Stephen Rice (UNLV), Michael Sabourin and Danny Thomas (BNR), Theo Pavlidis (SUNY-Stony Brook), Sharad Seth (UNL), and James Tien (RPI).

References-found: 26

