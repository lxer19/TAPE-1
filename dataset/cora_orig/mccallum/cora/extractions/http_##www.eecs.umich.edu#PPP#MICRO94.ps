URL: http://www.eecs.umich.edu/PPP/MICRO94.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Title: Minimum Register Requirements for a Modulo Schedule  
Author: Alexandre E. Eichenberger and Edward S. Davidson Santosh G. Abraham 
Address: 1501 Page Mill Road Ann Arbor, MI 48109-2122 Palo Alto, CA 94304  
Affiliation: Advanced Computer Architecture Laboratory Hewlett Packard Laboratories EECS Department, University of Michigan  
Abstract: Modulo scheduling is an efficient technique for exploiting instruction level parallelism in a variety of loops, resulting in high performance code but increased register requirements. We present a combined approach that schedules the loop operations for minimum register requirements, given a modulo reservation table. Our method determines optimal register requirements for machines with finite resources and for general dependence graphs. This method demonstrates the potential of lifetime-sensitive modulo scheduling and is useful in evaluating the performance of lifetime-sensitive modulo scheduling heuristics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. R. Rau and J. A. Fisher, </author> <title> "Instruction-level parallel processing: History, overview, and perspective", </title> <journal> in The Journal of Supercomputing, </journal> <volume> vol. 7, </volume> <pages> pp. 9-50, </pages> <address> Boston, July 1993. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: For if-converted basic blocks, we assume that all predicates are set to true when performing Step 2. Our iteration-scheduling method satisfies the dependence constraints while simultaneously minimizing MaxLive <ref> [1] </ref>, the minimum number of registers required to generate spill-free code. MaxLive corresponds to the maximum number of live values at any single cycle of the loop schedule. We present two algorithms for iteration-scheduling, both of which schedule for machines with finite resources.
Reference: [2] <author> P. Y Hsu, </author> <title> Highly Concurrent Scalar Processing, </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference: [3] <author> B. R. Rau, C. D. Glaeser, and R. L. </author> <title> Picard, "Efficient code generation for horizontal architecture: Compiler techniques and architecture support", </title> <booktitle> Proceedings of the Ninth Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 131-139, </pages> <year> 1982. </year>
Reference: [4] <author> M. Lam, </author> <title> "Software pipelining: An effective scheduling technique for VLIW machines", </title> <booktitle> Proceedings of the ACM SIGPLAN'88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. 318-328, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: As a result, searching for a schedule with a given II is greatly simplified. The scope of modulo scheduling has been widened to a large variety of loops. Loops with conditional statements are handled using hierarchical reduction <ref> [4] </ref> or if-conversion [5][6]. Loops with conditional exits can also be modulo scheduled [7]. Furthermore, the code expansion due to modulo scheduling can be eliminated when using special hardware, such as rotating register files and predicated execution [8].
Reference: [5] <author> N. J. Warter, G. E. Haab, and J. W. Bockhaus, </author> <title> "Enhanced modulo scheduling for loops with conditional branches", </title> <booktitle> Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1992. </year>
Reference: [6] <author> N. J. Warter, </author> <title> Modulo Scheduling with Isomorphic Control Transformations, </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference: [7] <author> P. P. Tirumalai, M. Lee, and M. S. Schlansker, </author> <title> "Par-allelization of loops with exits on pipelined architectures", </title> <booktitle> Proceedings of Supercomputing '90, </booktitle> <pages> pp. 200-212, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: The scope of modulo scheduling has been widened to a large variety of loops. Loops with conditional statements are handled using hierarchical reduction [4] or if-conversion [5][6]. Loops with conditional exits can also be modulo scheduled <ref> [7] </ref>. Furthermore, the code expansion due to modulo scheduling can be eliminated when using special hardware, such as rotating register files and predicated execution [8]. Since modulo scheduling achieves a high throughput by overlapping the execution of several iterations, it results in higher register requirements.
Reference: [8] <author> B. R. Rau, M. Lee, P. P. Tirumalai, and M. S. Schlansker, </author> <title> "Register allocation for software pipelined loops", </title> <booktitle> Proceedings of the ACM SIGPLAN'92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. 283-299, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Loops with conditional statements are handled using hierarchical reduction [4] or if-conversion [5][6]. Loops with conditional exits can also be modulo scheduled [7]. Furthermore, the code expansion due to modulo scheduling can be eliminated when using special hardware, such as rotating register files and predicated execution <ref> [8] </ref>. Since modulo scheduling achieves a high throughput by overlapping the execution of several iterations, it results in higher register requirements. <p> Our linear-time algorithm permits multiple uses of each virtual register, provided that the underlying dependence graph is acyclic. Our second (more complex) method handles general dependence graphs, including loop-carried dependence and common sub-expressions. This work complements the register allocation algorithm presented by Rau et al. <ref> [8] </ref>, which achieves register allocations that are within one register of the MaxLive bound for the vast majority of modulo-scheduled loops on machines with rotating register files and predicated execution to support modulo-scheduling.
Reference: [9] <author> W. Mangione-Smith, S. G. Abraham, and E. S. David-son, </author> <title> "Register requirements of pipelined processors", </title> <booktitle> Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pp. 260-271, </pages> <year> 1992. </year>
Reference-contexts: Since modulo scheduling achieves a high throughput by overlapping the execution of several iterations, it results in higher register requirements. Furthermore, the register requirements increase as the concurrency increases <ref> [9] </ref>, whether due to using and exploiting machines with faster To appear in the Proceedings of the 27th Annual International Symposium on Microarchitecture, page 75-84, November 1994, San Jose, California clocks and deeper pipelines, wider issue, or a combination of both. <p> This method is thus useful in assessing the performance of modulo-scheduling heuristics. This work extends the linear-time algorithm for determining minimum register requirements by Mangione-Smith et al. <ref> [9] </ref>, which requires that each virtual register is used at most once. Our linear-time algorithm permits multiple uses of each virtual register, provided that the underlying dependence graph is acyclic. Our second (more complex) method handles general dependence graphs, including loop-carried dependence and common sub-expressions. <p> Therefore, we say that the load/mult operation pair has a skip factor of 1. Similarly, the skip factor is 2 for the mult/add operation pair and 0 for the add/store operation pair. The skip factor is within 1 of the iteration difference used in <ref> [9] </ref> [13]. The problem addressed in this paper can now be defined formally as follows: choose a skip factor (place a circle in the replicated MRT) for each operation in one iteration so as to generate a valid iteration-schedule that minimizes MaxLive. <p> The total MaxLive is the sum of the fractional and integral MaxLives. The iteration-schedule presented in Figure 1 results in the minimum register requirements for this kernel, MRT, and set of functional unit latencies. Mangione-Smith et al. <ref> [9] </ref> have shown that for dependence graphs with at most a single use per virtual register, as in Example 1, minimizing each skip factor individually always results in the minimum register requirements. However, this result does not apply to general dependence graphs with unrestricted common sub-expressions and loop carried dependences.
Reference: [10] <author> R. A. Huff, </author> <title> "Lifetime-sensitive modulo scheduling", </title> <booktitle> Proceedings of the ACM SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. 258-267, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: As a result, a scheduling algorithm that reduces the register pressure while scheduling for high throughput is increasingly important. Lifetime-sensitive modulo-scheduling proposed by Huff <ref> [10] </ref> is a heuristic that attempts to address this concern. In this paper, we treat modulo scheduling as a three step procedure. Some code generation strategies combine steps to simultaneously meet distinct objectives; e.g. Huff's approach combines steps one and two below. 1. <p> Their algorithm, after extensive loop unrolling and consequent code expansion, typically achieves register allocations that are within four registers of the MaxLive bound on machines without hardware support. Huff <ref> [10] </ref> presents a lower bound that is independent of the MRT-schedule. Our minimum MaxLive value is dependent on the given MRT-schedule; however, our MaxLive is tight since we also produce an actual iteration schedule that achieves this MaxLive.
Reference: [11] <author> J. H. Patel and E. S. Davidson, </author> <title> "Improving the throughput of a pipeline by insertion of delays", </title> <booktitle> Proceedings of the Third Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 159-164, </pages> <year> 1976. </year>
Reference: [12] <author> C. Eisenbeis, W. Jalby, and A. </author> <title> Lichnewsky, "Squeezing more performance out of a Cray-2 by vector block scheduling", </title> <booktitle> Proceedings of Supercomputing '88, </booktitle> <pages> pp. 237-246, </pages> <month> November </month> <year> 1988. </year>
Reference: [13] <author> Q. Ning and G. R. Gao, </author> <title> "A novel framework of register alloccation for software pipelining", </title> <booktitle> Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 29-42, </pages> <year> 1993. </year>
Reference-contexts: Huff [10] presents a lower bound that is independent of the MRT-schedule. Our minimum MaxLive value is dependent on the given MRT-schedule; however, our MaxLive is tight since we also produce an actual iteration schedule that achieves this MaxLive. Finally, in contrast to the work by Ning and Gao <ref> [13] </ref> and Ramanujam [14], we allow finite machine resource con 1 The underlying graph is an undirected graph formed by ignoring the direction of each arc. straints. <p> Therefore, we say that the load/mult operation pair has a skip factor of 1. Similarly, the skip factor is 2 for the mult/add operation pair and 0 for the add/store operation pair. The skip factor is within 1 of the iteration difference used in [9] <ref> [13] </ref>. The problem addressed in this paper can now be defined formally as follows: choose a skip factor (place a circle in the replicated MRT) for each operation in one iteration so as to generate a valid iteration-schedule that minimizes MaxLive.
Reference: [14] <author> J. Ramanujam, </author> <title> "Optimal software pipelining of nested loops", </title> <booktitle> Proceedings of the International Parallel Processing Symposium, </booktitle> <pages> pp. 335-342, </pages> <year> 1994. </year>
Reference-contexts: Our minimum MaxLive value is dependent on the given MRT-schedule; however, our MaxLive is tight since we also produce an actual iteration schedule that achieves this MaxLive. Finally, in contrast to the work by Ning and Gao [13] and Ramanujam <ref> [14] </ref>, we allow finite machine resource con 1 The underlying graph is an undirected graph formed by ignoring the direction of each arc. straints.
Reference: [15] <author> F. S. Hillier and G. J. Lieberman, </author> <title> Introduction to Mathematical Programming, </title> <publisher> McGraw-Hill, </publisher> <year> 1990. </year> <month> 83 </month>
Reference-contexts: 0 0 + 1; p 2 1 + p 0 3 + 4 + p 0 6 + 5 (10) We can now reduce the problem of finding an iteration-schedule that results in the minimum integral MaxLive to a well-known class of problems, solved by a linear programming (LP) solver <ref> [15] </ref>. Note, however, that (10) is not acceptable as the input to an LP-solver, because the objective function cannot contain any max functions. However, since we are minimizing the objective function, we can remove the max function by using some additional inequalities, called Max Constraints. <p> Fortunately, the minimum integral MaxLive problem is analogous to the minimum cost flow problem, a class of problems that satisfies the integer property <ref> [15] </ref>. This property holds when two conditions are fulfilled. The first condition specifies that the variables (p x i and m i ) can only be multiplied by the coefficients +1, -1, or 0. This condition holds since each edge occurs at most once on the path of an underlying-cycle.
Reference: [16] <author> J. C. Tiernan, </author> <title> "An efficient search algorithm to find the elementary circuits of a graph", </title> <journal> Communications of the ACM, </journal> <pages> pp. 722-726, </pages> <month> December </month> <year> 1970. </year> <month> 84 </month>
Reference-contexts: Algorithm 1 The minimum integral MaxLive for a kernel with a general dependence graph, 3 MRT, and set of functional unit latencies is found as follows: 1. Compute all s x i using Equation (3) and search for all elementary cycles in the underlying dependence graph <ref> [16] </ref>. 2. If the underlying dependence graph is acyclic, the solution that produces the minimum integral MaxLive is obtained by setting the values of all p x i to zero. 3. Otherwise, build an underlying-cycle constraint for each elementary cycle of the underlying dependence graph using Equations (6) and (7).
References-found: 16

