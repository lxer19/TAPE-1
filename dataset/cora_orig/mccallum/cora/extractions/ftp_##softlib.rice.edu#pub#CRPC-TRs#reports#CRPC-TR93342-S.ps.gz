URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR93342-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Parallelization of Linearized Applications in Fortran D  
Author: Lorie M. Liebrock Ken Kennedy 
Address: P.O. Box 1892 Houston, TX 77251-1892  
Affiliation: Rice University  
Note: Center for Research on Parallel Computation  This research was supported by: Center for Research on Parallel Computation, a National Science Foundation Science and Technology Center, through Cooperative Agreement No. CCR-9120008, NSF/NASA Agreement No. ASC-9213821, and ONR Agreement No. N00014-93-1-0158. Use of the Intel i860 was provided under a Texas CER Grant No. CISE 8619893.  
Date: November, 1993  
Pubnum: CRPC TR93342-S  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> An interactive environment for data partitioning and distribution. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: This example is a two-dimensional code similar to a part of one of the three-dimensional routines from UTCOMP. For good performance in an application implementation, the user or an automatic alignment and distribution system <ref> [7, 1] </ref> would align each array to minimize communication. In the example of Figure 6, all of the arrays are perfectly aligned with decomposition D. Code generation for this simple code is outlined in Figure 7.
Reference: [2] <author> H. Berryman, J. Saltz, and J. Scroggs. </author> <title> Execution time support for adaptive scientific algorithms on distributed memory machines. </title> <type> ICASE Report 90-41, </type> <institution> Institute for Computer Application in Science and Engineering, Hamp-ton, VA, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: When index arrays are used, the Fortran D compiler cannot handle the code as regular. As the data reference pattern is not analyzable at compile time, the only support for this case is via an inspector/executor strategy <ref> [14, 2] </ref>. There are a number of problems with this approach. To begin with, current compilers cannot yet generate the inspector/executor automatically. Hence, this conversion must be done by hand.
Reference: [3] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: To permit a modular programming style, the effects of data decomposition specifications are limited to the scope of the enclosing procedure. However, procedures do inherit the decompositions of their callers. The complete language is described in detail elsewhere <ref> [3] </ref>. Page 3 Note that the original Fortran D language specification does not support alignment of linearized arrays according to their logical topology and that irregular data distributions require runtime support. This work makes it possible to more efficiently compile the class of linearized regular application codes. <p> For example, in the code fragment of Figure 3, the (block,block) distribution of array x and the transposed (block,block) distribution of array y cannot be accomplished in the currently proposed version of High Performance Fortran or as a regular computation in Fortran D <ref> [3] </ref>. 3.2 Index Array Specification Linearized arrays are typically indexed in one of two ways. The most straightforward indexing method is direct, inline computation of linearized indices according to Fortran's standard array storage allocation.
Reference: [4] <author> G. Fox and S. Otto. </author> <title> Algorithms for concurrent processors. </title> <journal> Physics Today, </journal> <volume> 37 </volume> <pages> 50-59, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: However, this might not provide the best performance as we shall illustrate with an example. It is well known <ref> [4, 12] </ref> that the computation to communication ratio is one of the most important numbers there is in determining the efficacy of a parallelization, so let's examine the relationship between parallelization topology and the computation to communication ratio for two parallelization topologies: the natural problem topology and a one dimensional topology.
Reference: [5] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler support for machine-independent parallel programming in Fortran D. </title> <type> Technical Report TR90-149, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> January </month> <year> 1991. </year> <note> To appear in J. </note> <editor> Saltz and P. Mehrotra, editors, </editor> <title> Compilers and Runtime Software for Scalable Multiprocessors, </title> <publisher> Elsevier, </publisher> <year> 1991. </year>
Reference-contexts: We examine each of these stages in detail. We will discuss each stage in terms of the needed modifications/additions to the Rice Fortran D compiler. For a discussion of the original Fortran D compiler see reference <ref> [5] </ref>. An outline of the compilation process is shown in Figure 9.
Reference: [6] <author> C. Koelbel. </author> <title> Compiling Programs for Nonshared Memory Machines. </title> <type> PhD thesis, </type> <institution> Purdue University, West Lafayette, IN, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: The logical dimension specifications support this analysis. This would eliminate the need to execute the inspector. For more details on how such index computations may be evaluated by the compiler see <ref> [6] </ref>. Once such computations are recognized, the compiler can determine whether the indirection implies a communication from the distribution in effect. Communication can be generated at this point because the indices of the source and sink of the dependence are known, as are the processors that store the values.
Reference: [7] <author> L.M. Liebrock, D.L. Hicks, K.W. Kennedy, and J.J. Dongarra. </author> <title> Using problem and algorithm topology in parallelization. </title> <type> Technical Report 91-166, </type> <institution> Rice University, Center for Research in Parallel Computation, Houston, TX, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: This example is a two-dimensional code similar to a part of one of the three-dimensional routines from UTCOMP. For good performance in an application implementation, the user or an automatic alignment and distribution system <ref> [7, 1] </ref> would align each array to minimize communication. In the example of Figure 6, all of the arrays are perfectly aligned with decomposition D. Code generation for this simple code is outlined in Figure 7.
Reference: [8] <institution> Olaf Lubeck. Computer Research and Development, Los Alamos National Laboratories, </institution> <month> February </month> <year> 1993. </year> <title> Private communication. </title>
Reference-contexts: This porting was done by linearizing all of the three physical dimensions of the arrays and breaking the long resulting vectors over the eight processors. The researchers found that direct inline computation of linearized addresses was faster than using index arrays <ref> [8] </ref>. Linearization was a recommended technique for vectorization on the early vector processors such as the CDC Cyber 205 and the Hitachi-S9 with integrated array processor [15]. The Los Alamos porting experience indicates that linearization is still useful for modern vector computers.
Reference: [9] <institution> Vince Mousseau. EG&G Idaho, Idaho National Engineering Laboratories, </institution> <month> March </month> <year> 1993. </year> <title> Private communication. </title>
Reference-contexts: Some examples of these codes are UTCOMP and UTCHEM from the University of Texas, and reservoir simulation codes such as VIP-COMP, MORE and ECLIPSE [11]. Another such linearized code is KIVA, for chemically reacting flow simulation <ref> [9] </ref>. A global ocean model simulation code at Los Alamos National Laboratories has recently been ported from the Thinking Machines CM-2 to the Cray YMP. This porting was done by linearizing all of the three physical dimensions of the arrays and breaking the long resulting vectors over the eight processors.
Reference: [10] <institution> Marcelo Rame. Computational and Applied Mathematics Department, Rice University, </institution> <month> December </month> <year> 1992. </year> <title> Private communication: This code was supplied as representative of the computations in UTCOMP. </title>
Reference-contexts: The third routine, disper, which computes the dispersion term for UTCOMP, is over one thousand lines long, uses index arrays including double indirection and is representative of the code throughout UTCOMP <ref> [10] </ref>. This code was not parallelized using standard Fortran D as that would require runtime support. The requirement for runtime support is due to the indirections that use index arrays. This support is not available in the current version of the Rice Fortran D project.
Reference: [11] <institution> Marcelo Rame. Computational and Applied Mathematics Department, Rice University, </institution> <month> February </month> <year> 1993. </year> <title> Private communication. </title>
Reference-contexts: These specifications significantly simplify communication analysis for the special-case arrays. 2 Motivation Many applications' codes have been linearized to improve performance on vector processors. Some examples of these codes are UTCOMP and UTCHEM from the University of Texas, and reservoir simulation codes such as VIP-COMP, MORE and ECLIPSE <ref> [11] </ref>. Another such linearized code is KIVA, for chemically reacting flow simulation [9]. A global ocean model simulation code at Los Alamos National Laboratories has recently been ported from the Thinking Machines CM-2 to the Cray YMP. <p> Unfortunately, as Rame and Kremer learned while attempting to delinearize part of UTCOMP, this is not always an easy task. Often the functionality of the code is obscured during linearization, particularly if there is further development of the linearized code. Such was the case with UTCOMP <ref> [11] </ref>. This paper addresses the problem by providing a way to get the advantages of Page 1 delinearization without requiring that the programmer perform this tedious process by hand. Users would like porting to parallel processors to be easy but the result must provide efficient execution to be acceptable.
Reference: [12] <author> D. Reed, L. Adams, and M. Patrick. </author> <title> Stencils and problem partitioning: Their influence on performance of multiprocessor systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(7):845-858, </volume> <month> July </month> <year> 1987. </year>
Reference-contexts: However, this might not provide the best performance as we shall illustrate with an example. It is well known <ref> [4, 12] </ref> that the computation to communication ratio is one of the most important numbers there is in determining the efficacy of a parallelization, so let's examine the relationship between parallelization topology and the computation to communication ratio for two parallelization topologies: the natural problem topology and a one dimensional topology.
Reference: [13] <institution> Joel Saltz. Computer Science Department, University of Maryland, </institution> <month> February </month> <year> 1993. </year> <title> Private communication. </title>
Reference-contexts: The good news is that a new version of the Fortran D compiler will soon be able to generate the inspector and executor automatically. This compiler may or may not be able to handle double indirection and logical comparisons of index values <ref> [13] </ref>. Even if the complete inspector/executor can be generated automatically, there is still extra execution time associated with the resulting parallelization. Communication requirements must be determined at runtime and communication satisfying those requirements must be generated. <p> This approach is still used for irregular problems that do not have standard distributions. For irregular problems with standard distributions, the indices are now "dereferenced" via a function. The elimination of the distributed translation table provides up to a factor of five improvement in runtime of the inspector <ref> [13] </ref>. Standard distributions (supplied as part of PARTI) are BLOCK and CYCLIC. Note that the BLOCK distribution will provide the linear distribution that has been discussed. The user may also modify the PARTI routines to support other regular distributions. <p> The version of that compiler currently in progress may or may not be able to handle the double indirection and/or the logical comparisons with global index values <ref> [13] </ref>. Page 13 Also note that we are not claiming that the approach we have presented can achieve all of the things that can be done via use of the PARTI routines.
Reference: [14] <author> R. v. Hanxleden, K. Kennedy, C. Koelbel, R. Das, and J. Saltz. </author> <title> Compiler analysis for irregular problems in fortran d. </title> <booktitle> In Proceedings of the 5th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, Page 17 CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: When index arrays are used, the Fortran D compiler cannot handle the code as regular. As the data reference pattern is not analyzable at compile time, the only support for this case is via an inspector/executor strategy <ref> [14, 2] </ref>. There are a number of problems with this approach. To begin with, current compilers cannot yet generate the inspector/executor automatically. Hence, this conversion must be done by hand.
Reference: [15] <author> G. Wolfgang. </author> <title> Notes on Numberical Fluid Mechanics, Volumne 8: Vectorization of Computer Programs with Applications to computational Fluid Dynamics. </title> <publisher> Friedr. Vieweg and Sohn, Wiesbaden, </publisher> <address> Germany, </address> <year> 1984. </year> <pages> Page 18 </pages>
Reference-contexts: The researchers found that direct inline computation of linearized addresses was faster than using index arrays [8]. Linearization was a recommended technique for vectorization on the early vector processors such as the CDC Cyber 205 and the Hitachi-S9 with integrated array processor <ref> [15] </ref>. The Los Alamos porting experience indicates that linearization is still useful for modern vector computers. Since the standard supercomputer today is a vector processor, the science and engineering community will encounter many linearized arrays when converting these codes to parallel systems.
References-found: 15

