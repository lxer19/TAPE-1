URL: http://charm.cs.uiuc.edu/papers/ConverseRTSPP98.ps
Refering-URL: http://charm.cs.uiuc.edu/papers/ConverseRTSPP98.html
Root-URL: http://www.cs.uiuc.edu
Title: Multiparadigm, Multilingual Interoperability: Experience with Converse  
Author: L. V. Kale, Milind Bhandarkar, Robert Brunner, and Joshua Yelon 
Affiliation: Dept. of Computer Science, University of Illinois  
Abstract: The Converse run-time framework was designed with dual objectives: that of supporting quick development of portable run-time systems for new parallel programming paradigms, and that of permitting interoperability between multi-paradigm modules in a single application. This paper reports on the refinements made to the original Converse model since its inception almost two years ago, and assesses our experience in using Converse to satisfy the above objectives. A brief overview of the motivation and overall design of Converse is included for completeness. Extensions and refinements in Converse are discussed along with the reasons for their inclusion. Several languages/paradigms were implemented using Converse; techniques used in these implementations and our experience with specific features of Converse used in them are discussed. A major multilingual multi-paradigm parallel application developed within the Converse framework is described.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Arvind, R. S. Nikhil, and K. Pingali. I-structures: </author> <title> Data structures for parallel computing. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 598-632, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Remote processors can then use functions provided in Converse to asynchronously or synchronously read and write (Get and Put) into this memory. Converse' global pointer mechanism is being used in the implementations of an all-software Distributed Shared Memory (DSM) scheme called CRL (in progress), and I-structures <ref> [1] </ref>. Parallelizing compilers implemented assuming a runtime support for DSM, can be retargeted to use Converse global pointers. 2.3 Vector Sends Messaging routines often accept user data, concatenate a header onto that data, and then send the header and data together.
Reference: 2. <author> P. Beckman and D. Gannon. Tulip: </author> <title> A portable run-time system for object-parallel systems. </title> <booktitle> In Proceedings of the 10th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: After Charm++ was retargeted to Converse, DP was automatically retargeted and is available for programming data parallel algorithms in a multilingual application. pC++ <ref> [5, 2] </ref> is a C++ extension for data-parallel computation using collection of objects. The method execution semantics of C++ objects is extended to include method invocation in parallel on a collection of objects. <p> Nexus [6] supports dynamic addition of processors on the Internet and provides flexible communication protocol. These features are useful for some applications but they add complexity to the programming model. Run-time frameworks aimed at supporting parallel languages on dedicated parallel machines include Tulip <ref> [2] </ref>, Panda [4], and Chant [7]. We believe that a few additional frameworks are also being developed at research laboratories. We propose to collaborate with these researchers to combine useful features from these systems so as to broaden the set of paradigms that can be supported by run-time frameworks.
Reference: 3. <author> Milind Bhandarkar and L. V. Kale. </author> <title> MICE: A Prototype MPI Implementation in Converse Environment. </title> <booktitle> In Proceedings of the second MPI Developers Conference, </booktitle> <pages> pages 26-31, </pages> <address> South Bend, Indiana, </address> <month> July </month> <year> 1996. </year>
Reference-contexts: This means that the implementation of any parallel language using Converse must be almost as efficient as a native implementation on each particular machine. Results so far <ref> [3] </ref> suggest that Converse meets this goal. To achieve this level of efficiency, the Converse API must subsume capabilities offered by most parallel machines. To ensure that each language pays for only those features that it uses, the Converse architecture consists of a set of very simple, efficient core components. <p> This makes it possible to link modules written with the PVM or MPI primitives to each other or other parallel languages. The MPI implementation <ref> [3] </ref> is based on MPICH [22]. MPICH is an implementation of MPI which can be easily retargeted, we simply retargeted it to Converse. Interestingly, the Converse port of MPICH is very close in efficiency to the native port of MPICH on the machines we tested.
Reference: 4. <author> Raoul Bhoedjang, Tim Ruhl, Rutger Hofman, Koen Langendoen, Henri Bal, and Frans Kaashoek. Panda: </author> <title> A portable platform to support parallel programming languages. </title> <booktitle> In Experiences with Distributed and Multiprocessor Systems (SEDMS IV), </booktitle> <pages> pages 213-226. </pages> <publisher> USENIX, </publisher> <address> San Diego, CA, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Nexus [6] supports dynamic addition of processors on the Internet and provides flexible communication protocol. These features are useful for some applications but they add complexity to the programming model. Run-time frameworks aimed at supporting parallel languages on dedicated parallel machines include Tulip [2], Panda <ref> [4] </ref>, and Chant [7]. We believe that a few additional frameworks are also being developed at research laboratories. We propose to collaborate with these researchers to combine useful features from these systems so as to broaden the set of paradigms that can be supported by run-time frameworks.
Reference: 5. <author> F. Bodin, P. Beckman, D. Gannon, S. Narayana, and S. Yang. </author> <title> Distributed pC++: Basic ideas for an object parallel language, </title> <year> 1992. </year>
Reference-contexts: After Charm++ was retargeted to Converse, DP was automatically retargeted and is available for programming data parallel algorithms in a multilingual application. pC++ <ref> [5, 2] </ref> is a C++ extension for data-parallel computation using collection of objects. The method execution semantics of C++ objects is extended to include method invocation in parallel on a collection of objects.
Reference: 6. <author> Ian Foster, Carl Kesselman, Robert Olson, and Steven Tuecke. </author> <title> Nexus: An Interoperability Layer for Parallel and Distributed Computer Systems. </title> <type> Technical Report ANL/MCS-TM-189, </type> <institution> Argonne National Laboratory, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: We also describe a large production quality application that employs modules written using different languages running on top of Converse. Several other systems have been designed with objectives similar to Converse. Nexus <ref> [6] </ref> supports dynamic addition of processors on the Internet and provides flexible communication protocol. These features are useful for some applications but they add complexity to the programming model. Run-time frameworks aimed at supporting parallel languages on dedicated parallel machines include Tulip [2], Panda [4], and Chant [7].
Reference: 7. <author> M. Haines, D. Cronk, and P. Mehrotra. </author> <title> On the Design of Chant: A Talking Threads Package. </title> <booktitle> In Proceedings of Supercomputing 1994, </booktitle> <address> Washington D.C., </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Nexus [6] supports dynamic addition of processors on the Internet and provides flexible communication protocol. These features are useful for some applications but they add complexity to the programming model. Run-time frameworks aimed at supporting parallel languages on dedicated parallel machines include Tulip [2], Panda [4], and Chant <ref> [7] </ref>. We believe that a few additional frameworks are also being developed at research laboratories. We propose to collaborate with these researchers to combine useful features from these systems so as to broaden the set of paradigms that can be supported by run-time frameworks.
Reference: 8. <author> Matthew Haines and Koen Lagendoen. </author> <title> Platform-independent runtime optimiza-tions using openthreads. </title> <booktitle> In 11th International Parallel Processing Symposium, </booktitle> <month> april </month> <year> 1997. </year>
Reference-contexts: Threads are normally scheduled automatically by Converse, but hooks are provided so that the Converse user can write alternate scheduling code. This is not unlike a facility provided by OpenThreads <ref> [8] </ref>. However, to keep conflicts between modules to a minimum, alternate scheduling code only affects those threads that explicitly request it. This helps preserve interoperability. Support for shared memory and shared variables is provided in a portable manner as described in the section on the machine model below.
Reference: 9. <author> R. Halstead. </author> <title> Multilisp: A Language for Concurrent Symbolic Computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <month> October </month> <year> 1985. </year>
Reference-contexts: It supports variable numbers of tags, and wild cards in the lookup process. It can also be used to store any data that must be indexed by integer tags. The futures library implements the futures abstraction <ref> [9] </ref> in a library-form. It provides a future "object", with methods to fill the object remotely, get its value, and block until the value has been filled. The Converse Parameter Marshalling system is a small C preprocessor and code generator that produces remote function-invocation code.
Reference: 10. <author> L. V. Kale, Milind Bhandarkar, Robert Brunner, Neal Krawetz, James Phillips, and Aritomo Shinozaki. </author> <title> A case study in multilingual parallel programming. </title> <type> Technical report, </type> <institution> Theoretical Biophysics Group, Beckman Institute, University of Illinois, Urbana, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: Eventually, since DPMTA made the PVM variant more useful, more development time was spent on it, and the Charm++ version fell into disrepair. By that time, though, the haphazard mix of SPMD and message-driven code had reduced the readability of the program. NAMD 2 <ref> [10] </ref> was conceived as a rewrite of the core parallel code to increase scalability and modifiability.
Reference: 11. <author> L. V. Kale, Milind Bhandarkar, Narain Jagathesan, Sanjeev Krishnan, and Joshua Yelon. </author> <title> Converse: An Interoperable Framework for Parallel Programming. </title> <booktitle> In Proceedings of the 10th International Parallel Processing Symposium, </booktitle> <pages> pages 212-217, </pages> <address> Honolulu, Hawaii, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Higher-level functionality is layered on top of this core in the form of optional modules. The idea of need-based cost is discussed further in <ref> [11] </ref>. The set of core components is chosen so that a wide variety of programming models, and their coexistence, can be supported. Converse models the machine as a set of semi-independent processors that communicate primarily via messages. Each processor is running a scheduler, which is responsible for all message reception.
Reference: 12. <author> L. V. Kale, Milind Bhandarkar, and Terry Wilmarth. </author> <title> Design and implementation of parallel java with a global object space. </title> <booktitle> In Proc. Conf. on Parallel and Distributed Processing Technology and Applications, </booktitle> <address> Las Vegas, Nevada, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Because of the interoperable nature of languages implemented on top of Converse, these entities could also be used across multiple language modules. We also developed a Java binding for the Charm++ constructs and entities such as remote objects with global name space, and asynchronous method invocation using Converse <ref> [12] </ref>. Currently this binding is supported on machines where Sun's Java Development Kit 1.1 is available. Converse runtime system functionality was made available to this implementation through native methods of the PRuntime class.
Reference: 13. <author> L. V. Kale and Sanjeev Krishnan. Charm++: </author> <title> Parallel Programming with Message-Driven Objects. </title> <editor> In Gregory V. Wilson and Paul Lu, editors, </editor> <booktitle> Parallel Programming using C++, </booktitle> <pages> pages 175-213. </pages> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference: 14. <author> L. V. Kale and Joshua Yelon. </author> <title> Threads for Interoperable Parallel Programming. </title> <booktitle> In Proc. 9th Conference on Languages and Compilers for Parallel Computers, </booktitle> <address> San Jose, California, </address> <month> August </month> <year> 1996. </year>
Reference: 15. <author> L. V. Kale, Joshua M. Yelon, and T. Knauff. </author> <title> Parallel import report. </title> <type> Technical Report 95-16, </type> <institution> Parallel Programming Laboratory, Department of Computer Science, University of Illinois, Urbana-Champaign, </institution> <year> 1995. </year>
Reference-contexts: It was indeed very simple task to provide an implementation of pC++ on top of Converse. 3.5 Other Languages Several experimental languages have been recently implemented on top of Converse. We describe these languages briefly. Import <ref> [15] </ref> is a simulation language based on Modsim. Import models a simulation system as a set of objects. The sequential version of the language has a centralized discrete event queue where each event is a time stamp, an object, and a method.
Reference: 16. <author> L.V. Kale. </author> <title> The Chare Kernel parallel programming language and system. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: The implementation of PVM-Converse is much like the implementation of CSM as described above. The PVM-Converse library is currently used in a major production quality molecular dynamics application (See section 4.) 3.3 Message-Driven Languages Charm <ref> [16] </ref> and Charm++[13] were developed before Converse. The design of Converse was a result of our experiences with making Charm and Charm++ portable and making modules written in both Charm and Charm++ interop-erate within the same application. Charm and Charm++ were later retargeted to Converse.
Reference: 17. <author> David Keppel. </author> <title> Tools and techniques for building fast portable threads packages. </title> <type> Technical Report UWCSE 93-05-06, </type> <institution> University of Washington Department of Computer Science and Engineering, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: This turned out to be a maintenance problem: each time we added a feature to the threads package, we had to code the feature into each version separately. The problem was solved by reimplementing Converse threads on top of the QuickThreads <ref> [17] </ref> library. While Quickthreads does contain machine-dependent code, the fact that the Quickthreads API has been frozen for years prevents this from becoming a maintenance issue. Any features added to Converse threads are now implemented on top of the stable Quickthreads layer.
Reference: 18. <author> E. Kornkven and L. V. Kale. </author> <title> Efficient implementation of high performance fortran via adaptive scheduling an overview. </title> <booktitle> In Proceedings of the International Workshop on Parallel Processing, </booktitle> <address> Bangalore, India, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: We had to modify the machine layer implementation on networks of workstations, because the common resources used by JDK1.1 are not separated into kernel-level threads in the JDK implementation. This problem will be fixed in the future versions of JDK. 3.4 Data Parallel Languages DP <ref> [18] </ref>, a subset of High Performance Fortran (HPF) was implemented on top of Charm++ before the development of Converse.
Reference: 19. <author> Mark Nelson, William Humphrey, Attila Gursoy, Andrew Dalke, Laxmikant Kale, Robert D. Skeel, and Klaus Schulten. </author> <title> NAMD| A parallel, object-oriented molecular dynamics program. </title> <journal> Intl. J. Supercomput. Applics. High Performance Computing, </journal> <volume> 10(4) </volume> <pages> 251-268, </pages> <month> Winter </month> <year> 1996. </year>
Reference-contexts: The scheduler of Converse is made available to Perl programs to schedule computations received from remote processors. For common programming tasks such as analyzing the log information of a WWW server, we have obtained a near linear speedup using mdPerl. 4 Multilingual Programming: Applications NAMD <ref> [19] </ref> is a parallel molecular dynamics simulation program being developed with the Theoretical Biophysics group at the University of Illinois.
Reference: 20. <author> W. Rankin and J. </author> <title> Board. A portable distributed implementation of the parallel multipole tree algorithm. </title> <booktitle> IEEE Symposium on High Performance Distributed Computing, </booktitle> <year> 1995. </year> <note> [Duke University Technical Report 95-002]. </note>
Reference-contexts: Two variants of the program were initially developed. One variant used Charm++, which provided support for straightforward expression of the message-driven design. The other variant used PVM in order to allow us to use the DPMTA <ref> [20] </ref> library developed by collaborators at Duke University. The DPMTA library provides efficient long-range electrostatic force computation, which is necessary for some simulations. The PVM variant of NAMD originally had a message-driven design, but new features tended to be added around rather than within the message-driven core design, sacrificing maintainability.
Reference: 21. <author> Sanjeev Krishnan and L. V. Kale. </author> <title> A parallel array abstraction for data-driven objects. </title> <booktitle> In Proc. Parallel Object-Oriented Methods and Applications Conference, </booktitle> <month> February </month> <year> 1996. </year>
Reference: 22. <author> W. Gropp and E. Lusk. </author> <title> MPICH ADI Implementation Reference Manual, </title> <month> August </month> <year> 1995. </year>
Reference-contexts: This makes it possible to link modules written with the PVM or MPI primitives to each other or other parallel languages. The MPI implementation [3] is based on MPICH <ref> [22] </ref>. MPICH is an implementation of MPI which can be easily retargeted, we simply retargeted it to Converse. Interestingly, the Converse port of MPICH is very close in efficiency to the native port of MPICH on the machines we tested.
Reference: 23. <author> Joshua Yelon and L. V. Kale. </author> <title> Agents: An undistorted representation of problem structure. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 1033, </volume> <pages> pages 551-565. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: The implementation of Time Warp was challenging, but the Converse interface was straightforward. The implementation relies upon the Converse messaging primitives, its priority mechanisms, and its and shared variable mechanisms. Speedups for our sample simulations have been excellent. Agents <ref> [23] </ref> is an experimental object-oriented language dedicated to exploring the idea of immutable, static networks of objects. The language supports remote method invocation, and thus, its implementation is much like the implementation of Charm (see section 3.3).
References-found: 23

