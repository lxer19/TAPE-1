URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-95-32.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Bounds on Memory Bandwidth in Streamed Computations  
Author: Sally A. McKee, Wm. A. Wulf, and Trevor C. 
Affiliation: Landon  
Date: August 1995.  
Note: Appeared in Proceedings of Europar95, Stockholm, Sweden,  Lecture Notes in Computer Science 966, S. Haridi, et al., Eds., Springer-Verlag, Berlin, 1995, pages 83-99.  
Abstract: Computer Science Report CS-95-32 March 1, 1995 
Abstract-found: 1
Intro-found: 1
Reference: [Bae91] <author> Baer, J. L., Chen, T. F., </author> <title> An Effective On-Chip Preloading Scheme To Reduce Data Access Penalty, </title> <booktitle> Proc. </booktitle> <address> Supercomputing91, </address> <month> Nov. </month> <year> 1991. </year>
Reference: [Ben91] <author> Benitez, M.E., and Davidson, J.W., </author> <title> Code Generation for Streaming: An Access/ Execute Mechanism, </title> <booktitle> Proc. </booktitle> <address> ASPLOS-IV, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: McKee and Wulf examine access-ordering in depth, developing performance bounds for these and other access-ordering schemes [McK95]. The limitations inherent in compile-time techniques motivate us to consider an implementation that reorders accesses dynamically. Benitez and Davidsons algorithm can be used to detect streams at compile-time <ref> [Ben91] </ref>, and the stream parameters can be transmitted to the reordering hardware at run-time. Appeared in Proceedings of Europar95, Stockholm, Sweden, August 1995. Lecture Notes in Computer Science 966, S.
Reference: [Cal91] <author> Callahan, D., Kennedy, K., and Porterfield, A., </author> <title> Software Prefetching, </title> <booktitle> Proc. </booktitle> <address> ASPLOS-IV, </address> <month> April </month> <year> 1991. </year> <note> Appeared in Proceedings of Europar95, </note> <institution> Stockholm, Sweden, </institution> <month> August </month> <year> 1995. </year> <note> Lecture Notes in Computer Science 966, </note> <editor> S. Haridi, et al., Eds., </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1995, </year> <pages> pages 83-99. 17 </pages>
Reference: [Chi94] <author> Chiueh, T., </author> <title> Sunder: A Programmable Hardware Prefetch Architecture for Numerical Loops, </title> <booktitle> Proc. Supercomputing 94, </booktitle> <month> Nov. </month> <year> 1994. </year>
Reference: [Fu91] <author> Fu, J.W.C., and Patel, J.H., </author> <title> Data Prefetching in Multiprocessor Vector Cache Memories, </title> <booktitle> Proc. 18th ISCA, </booktitle> <month> May </month> <year> 1991. </year>
Reference: [Gup91] <author> Gupta, A., et. al., </author> <title> Comparative Evaluation of Latency Reducing and Tolerating Techniques, </title> <booktitle> Proc. 18th ISCA, </booktitle> <month> May </month> <year> 1991. </year>
Reference: [IEE92] <author> High-speed DRAMs, </author> <title> Special Report, </title> <journal> IEEE Spectrum, </journal> <volume> 29(10), </volume> <month> Oct. </month> <year> 1992. </year>
Reference: [Jou90] <author> Jouppi, N., </author> <title> Improving Direct-Mapped Cache Performance by the Addition of a Small Fully Associative Cache and Prefetch Buffers, </title> <booktitle> Proc. 17th ISCA, </booktitle> <month> May </month> <year> 1990. </year>
Reference: [Kla91] <author> Klaiber, A.C., and Levy, H.M., </author> <title> An Architecture for Software-Controlled Data Prefetching, </title> <booktitle> Proc. 18th ISCA, </booktitle> <month> May </month> <year> 1991. </year>
Reference: [Lee93] <author> Lee, K. </author> <title> The NAS860 Library Users Manual, </title> <type> NAS TR RND-93-003, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: Moyers scheme unrolls loops and groups accesses to each stream, so that the cost of each DRAM page-miss can be amortized over several references to the same page. Lee develops subroutines to mimic Cray instructions on the Intel i860XR <ref> [Lee93] </ref>. His routine for streaming vector elements reads data in blocks (using non-caching load instructions) and then writes the data to a pre-allocated portion of cache. Meadows describes a similar scheme for the PGI i860 compiler [Mea92], and Loshin and Budge give a general description of the technique [Los92].
Reference: [Los92] <author> Loshin, D., and Budge, D., </author> <title> Breaking the Memory Bottleneck, Parts 1 & 2, </title> <booktitle> Supercomputing Review, </booktitle> <address> Jan./Feb. </address> <year> 1992. </year>
Reference-contexts: His routine for streaming vector elements reads data in blocks (using non-caching load instructions) and then writes the data to a pre-allocated portion of cache. Meadows describes a similar scheme for the PGI i860 compiler [Mea92], and Loshin and Budge give a general description of the technique <ref> [Los92] </ref>. Register-level schemes are restricted by the size of the register file, and cache-level schemes potentially suffer from cache conicts. Moreover, optimal orderings cannot be generated without the address alignment information usually available only at run-time. Nonetheless, these techniques are useful to the extent to which they can be applied.
Reference: [McK93a] <author> McKee, S.A, </author> <title> Hardware Support for Access Ordering: Performance of Some Design Options, </title> <institution> Univ. of Virginia, Department of Computer Science, </institution> <type> Technical Report CS-93-08, </type> <month> August </month> <year> 1993. </year>
Reference-contexts: Complete uniprocessor results, including a detailed description of each access-ordering heuristic, can be found in <ref> [McK93a] </ref>; highlights of these results are presented in r gcd b stride,( ) - F 1 Ns M - Ns 3 R s v 1 - gcd b stride,( ) F Ns - gcd b stride,( ) F Ns 2 -= = = % peak bandwidth = h 100 - gcd
Reference: [McK94a] <author> McKee, S.A., et. al., </author> <title> Experimental Implementation of Dynamic Access Ordering, </title> <booktitle> Proc. 27th Hawaii International Conference on Systems Sciences, </booktitle> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: In this paper we develop analytic models that bound the performance of any uniprocessor or symmetric multiprocessor memory system on streams. We present highlights of these results, comparing them to the performance of a scheme we have proposed for accessing stream data the Stream Memory Controller (SMC) <ref> [McK94a, McK94b] </ref>. There are two independent comparisons: a bus-level simulation, and a gate-level simulation of the SMCs VHDL description. Both forms predict the SMC consistently delivers nearly the maximum attainable bandwidth determined by the analytic bounds.
Reference: [McK94b] <author> McKee, S.A., Moyer, S.A., Wulf, Wm.A., and Hitchcock, C., </author> <title> Increasing Memory Bandwidth for Vector Computations, </title> <booktitle> Proc. Programming Languages and System Architectures, </booktitle> <address> Zurich, Switzerland, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: In this paper we develop analytic models that bound the performance of any uniprocessor or symmetric multiprocessor memory system on streams. We present highlights of these results, comparing them to the performance of a scheme we have proposed for accessing stream data the Stream Memory Controller (SMC) <ref> [McK94a, McK94b] </ref>. There are two independent comparisons: a bus-level simulation, and a gate-level simulation of the SMCs VHDL description. Both forms predict the SMC consistently delivers nearly the maximum attainable bandwidth determined by the analytic bounds.
Reference: [McK94c] <author> McKee, S.A., </author> <title> Dynamic Access Ordering for Symmetric Shared-Memory Multiprocessors, </title> <institution> Univ. of Virginia, </institution> <type> Technical Report CS-94-14, </type> <month> April </month> <year> 1994. </year>
Reference-contexts: We calculate the attainable bandwidth for an optimal data distribution, thus performance bounds derived for this scheduling model hold for other scheduling techniques. For details of SMC performance under other task-scheduling strategies, see our technical reports <ref> [McK94c, McK94d] </ref>. <p> Lecture Notes in Computer Science 966, S. Haridi, et al., Eds., Springer-Verlag, Berlin, 1995, pages 83-99. 12 [McK94a,McK94b]. Complete shared-memory multiprocessor results can be found in <ref> [McK94c] </ref>. Since our concern here is to correlate the performance bounds of our analytic model with our functional simulation results, we present only the maximum percentage of peak bandwidth attained by any order/issue policy simulated for a given memory system and benchmark.
Reference: [McK94d] <author> McKee, S.A., </author> <title> Dynamic Access Ordering: Bounds on Memory Bandwidth, </title> <institution> Univ. of Virginia, </institution> <type> Technical Report CS-94-38, </type> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: We calculate the attainable bandwidth for an optimal data distribution, thus performance bounds derived for this scheduling model hold for other scheduling techniques. For details of SMC performance under other task-scheduling strategies, see our technical reports <ref> [McK94c, McK94d] </ref>.
Reference: [McK95] <author> McKee, S.A., and Wulf, </author> <title> Wm.A., Access Ordering and Memory-Conscious Cache Utilization, </title> <booktitle> Proc. High Performance Computer Architecture, </booktitle> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: Moreover, optimal orderings cannot be generated without the address alignment information usually available only at run-time. Nonetheless, these techniques are useful to the extent to which they can be applied. McKee and Wulf examine access-ordering in depth, developing performance bounds for these and other access-ordering schemes <ref> [McK95] </ref>. The limitations inherent in compile-time techniques motivate us to consider an implementation that reorders accesses dynamically. Benitez and Davidsons algorithm can be used to detect streams at compile-time [Ben91], and the stream parameters can be transmitted to the reordering hardware at run-time.
Reference: [Mea92] <author> Meadows, L., et.al., </author> <title> A Vectorizing Software Pipelining Compiler for LIW and Superscalar Architectures, </title> <booktitle> Proc. </booktitle> <address> RISC92. </address>
Reference-contexts: Lee develops subroutines to mimic Cray instructions on the Intel i860XR [Lee93]. His routine for streaming vector elements reads data in blocks (using non-caching load instructions) and then writes the data to a pre-allocated portion of cache. Meadows describes a similar scheme for the PGI i860 compiler <ref> [Mea92] </ref>, and Loshin and Budge give a general description of the technique [Los92]. Register-level schemes are restricted by the size of the register file, and cache-level schemes potentially suffer from cache conicts. Moreover, optimal orderings cannot be generated without the address alignment information usually available only at run-time.
Reference: [Mow92] <author> Mowry, T.C., Lam, M., and Gupta, A., </author> <title> Design and Evaluation of a Compiler Algorithm for Prefetching, </title> <booktitle> Proc. ASPLOS-V, </booktitle> <month> Sept. </month> <year> 1992. </year>
Reference: [Moy93] <author> Moyer, S.A., </author> <title> Access Ordering and Effective Memory Bandwidth, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, Univ. of Virginia, </institution> <type> Technical Report CS-93-18, </type> <month> April </month> <year> 1993. </year>
Reference-contexts: Most of these schemes simply mask latency without increasing effective bandwidth. Such techniques are still useful, but they will be most effective when combined with complementary technology to take advantage of memory component capabilities. Software access-ordering techniques range from Moyers algorithms for non-caching register loads <ref> [Moy93] </ref> to schemes that stream vector data into the cache, explicitly managing it as a fast, local memory [Lee93,Los92,Mea92]. Moyers scheme unrolls loops and groups accesses to each stream, so that the cost of each DRAM page-miss can be amortized over several references to the same page.
Reference: [Qui91] <author> Quinnell, R., </author> <title> High-speed DRAMs, </title> <type> EDN, </type> <month> May 23 </month> <year> 1991. </year>
Reference: [Ram92] <institution> Architectural Overview, Rambus Inc., Mountain View, </institution> <address> CA 1992. </address>
Reference: [Skl92] <author> Sklenar, Ivan, </author> <title> Prefetch Unit for Vector Operation on Scalar Computers, </title> <journal> Computer Architecture News, </journal> <volume> 20(4), </volume> <month> Sept. </month> <year> 1992. </year>
Reference: [Soh91] <author> Sohi, G. and Franklin, M., </author> <title> High Bandwidth Memory Systems for Superscalar Processors, </title> <booktitle> Proc. </booktitle> <address> ASPLOS-IV, </address> <month> April </month> <year> 1991. </year>
References-found: 24

