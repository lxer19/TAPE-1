URL: ftp://dimacs.rutgers.edu/pub/dimacs/TechnicalReports/TechReports/1995/95-03.ps.gz
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1995.html
Root-URL: http://www.cs.rutgers.edu
Email: Ricardo.Correa@imag.fr  ferreira@lip.ens-lyon.fr  
Title: Best-First Branch-and-Bound in Discrete Optimization: a Framework 1  
Author: by Ricardo Corr^ea Afonso Ferreira 
Address: 46, av. Felix Viallet, 38031 Grenoble Cedex, France  46, allee d'Italie, 69364 Lyon Cedex 07, France  
Affiliation: LMC IMAG  CNRS LIP- ENS-Lyon  
Note: Parallel  DIMACS is a cooperative project of Rutgers University, Princeton University, AT&T Bell Laboratories and Bellcore. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology.  
Abstract: DIMACS Technical Report 95-03 1 This work was partially supported by DIMACS NSF grant STC-91-199999 and the NJ Commission on Science and Technology, by DRET, by the project Stratageme of the French CNRS, and by the Human Capital and Mobility project SCOOP of the European Union. A revised version of this report is to appear in Solving Combinatorial Optimization Problems in Parallel I: Methods, Springer-Verlag. 2 Partially supported by a CNPq (Brazil) fellowship, grant 201421/92-5 (BC). 3 Visiting member. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Abdelrahman and T. Mudge. </author> <title> Parallel branch and bound algorithms on hypercube multiprocessors. </title> <booktitle> In 1988 ACM Conf. on Lisp and Funct. Prog., </booktitle> <pages> pages 1492-1499. </pages> <publisher> ACM Press, </publisher> <year> 1988. </year>
Reference-contexts: The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>. <p> We give below a list (non exhaustive) of such applications and their references. More details about the distributed memory implementations can be found in the following subsections, relating each implementation to its corresponding theoretic model. Problem reference Integer linear programming shared memory [6], distributed memory <ref> [1] </ref> Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem <p> The sequential B&B algorithm used is such that, in parallel, the ratio of the communication overhead to the computation time for a subproblem decomposition is high. For this reason, good speedups were obtained only with a few processors. No analyses concerning the amount of useful work are provided <ref> [1] </ref>. J. Eckstein: this CM-5-oriented asynchronous implementation for the mixed integer programming problem used the centralized strategy to assess the seriousness of the resulting bottlenecks. <p> Using a dynamic quantitative workload sharing algorithm, which is based on the principle that an idle processor requests work from another processor, good speedups were obtained, for the instances tested, up to 32 processors. These results were all better than the SDOM, centralized strategy, ones <ref> [1] </ref>. J. Eckstein: in order to use a DDM to extend its previous SDOM, centralized strategy, implementation, this author uses a randomized workload sharing scheme proposed by Karp and Zhang [25]. In this scheme, each processor randomly chooses, from time to time, a processor to send a just generated subproblem.
Reference: [2] <author> G. Ananth, V. Kumar, and P. Pardalos. </author> <title> Parallel processing of discrete optimization problems. </title> <journal> Encyclopedia of Microcomputers, </journal> <volume> 13 </volume> <pages> 129-147, </pages> <year> 1993. </year>
Reference-contexts: The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>.
Reference: [3] <author> S. Arvindam, V. Kumar, and V. N. Rao. </author> <title> Efficient parallel algorithms for search problems: Applications in VLSI CAD. </title> <booktitle> In Proceedings of the Frontiers 90 Conference on Massively Parallel Computation, </booktitle> <month> October </month> <year> 1990. </year> <month> - 26 </month> - 
Reference-contexts: There is another important motivation for using parallel processing. In several industrial, research or other real-world environments, mathematical programmers must face up to moderate instances of NP-hard problems for which an exact optimal solution is highly desirable (e.g. VLSI floor-plan optimization <ref> [3] </ref>). In such circumstances, parallel processing can bring the time of solution from some days or months, that is typical when one workstation is used, to some minutes or seconds. This is crucial in some applications that require real time solutions (e.g. robot motion planning and speech understanding).
Reference: [4] <editor> A. Barr and E. Feigenbaum. </editor> <booktitle> The Handbook of Artificial Intelligence, volume I. </booktitle> <publisher> William Kaufmann, Inc., </publisher> <year> 1981. </year>
Reference-contexts: Then, v j can be eliminated of further decompositions [24]. 16 Although not in the scope of this report, there are other search algorithms, known as graph search algorithms (as A fl and its derivations), for which T is a graph because replication of subproblems are allowed <ref> [4, 49] </ref>. - 6 - l = 1 l = 15 l = 20 l = 20 l = 25 3 Analytic models for parallel B&B In this section, we first establish our models for global data organization.
Reference: [5] <author> D. Bertsekas and J. Tsitsiklis. </author> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice-Hall International Editions, </publisher> <year> 1989. </year>
Reference-contexts: We recall that a selection may be empty. In order to guarantee that all processors work, we assume the following, as it was done in <ref> [5] </ref> in the context of systems of equations.
Reference: [6] <author> R. Boehning, R. Butler, and B. Gillett. </author> <title> A parallel integer LP algorithm. </title> <journal> European Journal of Operations Reasearch, </journal> <volume> 34 </volume> <pages> 393-398, </pages> <year> 1988. </year>
Reference-contexts: We give below a list (non exhaustive) of such applications and their references. More details about the distributed memory implementations can be found in the following subsections, relating each implementation to its corresponding theoretic model. Problem reference Integer linear programming shared memory <ref> [6] </ref>, distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin
Reference: [7] <author> J. Clausen. </author> <title> Do inherently sequential branch-and-bound algorithms exist? Parallel Processing Letters, </title> <note> 1994. To appear. </note>
Reference-contexts: The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration [11, 30, 31, 34, 48, 57]. Other sources of parallelism exist, but they have not been widely explored <ref> [7, 57] </ref>. In general terms, the potential to be explored consists of a linear on the number of processors - reduction on the number of iterations and, as a consequence, a linear improvement on the search efficiency of B&B algorithms. <p> It is implicitly assumed that if the problem in question is "sufficiently large", the number of worthwhile open subproblems at any time is large enough to keep all processors busy working with subproblems which have to be decomposed <ref> [7] </ref>. However, the exact number of iterations required depends upon the shape of the search tree. Previous results on speedup anomalies showed unsurprisingly that dense search trees with short critical paths yield to parallel attack more readily than sparse trees with long critical paths [31]. <p> These results must be analyzed with some caution. If the problem possesses a good bound computation scheme producing tight bounds, then parallelizing the subproblem investigation might produce an algorithm which scales poorly and may make meaningful use of only a few processors <ref> [7] </ref>. It is important to keep in mind that they concern "academic problems", with randomly generated instances.
Reference: [8] <author> T. Cormen, C. Leiserson, and R. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, McGraw-Hill, </publisher> <year> 1990. </year>
Reference-contexts: Even though parallelism will not be able to overdue the assumed worst case exponential time or memory complexity of those problems (unless an exponential number of processors is used) <ref> [8] </ref>, the average time complexity of heuristic search algorithms for many NP-hard problems is polynomial [56] (also, there are some heuristic search algorithms which find suboptimal solutions in polynomial time [59]). <p> A large number of references is provided. 2 Preliminaries on sequential B&B A sequential B&B algorithm consists of a sequence of iterations, in which some operators are applied over a data structure D. This data structure keeps a priority list of subproblems <ref> [8, 40] </ref>. These operators choose a subproblem from D, decompose it and eventually insert new subproblems into the data structure, chosen among those generated by the decomposition. Feasible solutions are found during the search in two situations.
Reference: [9] <author> R. Corr^ea and A. Ferreira. </author> <title> A distributed implementation of asynchronous parallel branch-and-bound. In IRREGULAR '94, </title> <month> Aug. </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: Then we recall the definition of synchronous parallel B&B from the literature <ref> [9, 11, 30, 31, 34, 48] </ref>, and we describe two general asynchronous models of parallel B&B. The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable [9, 58]. <p> The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable <ref> [9, 58] </ref>. Essentially, the only two informations in a parallel B&B algorithm to be considered by all processors are the value of the current best solution and the heuristic order of open subproblems. The synchronous model uses these global informations. <p> The operations are executed indivisibly, e.g., the model guarantees serializability of operation invocations; if two operations are applied simultaneously, then the result is as if one of them is executed before the other; the order of invocation, however, is non-deterministic <ref> [9, 10] </ref>. <p> The SDOM guarantees an upper bound on the number of iterations (section 5), and allows implicit qualitative and quantitative workload sharing <ref> [9] </ref>. (evaluation) selection/ insertion q 0 (decomp.) q 1 q p1 latency time D (open subproblems, U) 3.2 Synchronous model under SDOM For the sake of convenience and without loss of generality, we assume that the synchronous model applies uniquely under the SDOM. <p> The bounds in parallel are functions of these parameters. Now, let us consider asynchronous B&B, of which we are interested in counting the number of iterations of parallel B&B. In this context, the analysis of anomalies and speedup bounds requires a causality among some special subproblems (namely basic subproblems <ref> [9] </ref> or basic nodes [34]), which is well represented by the iterations in the SDOM. On the other hand, under DDM, the concept of asynchronous iteration is not precisely defined, making such analysis difficult. We concentrate, then, on the SDOM. <p> In this case, they state tight bounds by calculating the number of subproblems to be decomposed by level of T . It is shown in <ref> [9] </ref> that there is a lower bound for A (p; ) that depends on the asynchronism measure and on the number of processors employed, under the assumptions 1 (page 11) and 2 (page 14). <p> We give below a list (non exhaustive) of such applications and their references. More details about the distributed memory implementations can be found in the following subsections, relating each implementation to its corresponding theoretic model. Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory <ref> [9] </ref> Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming <p> The application used is the knapsack problem, with randomly generated hard instances. Besides the fine grained nature of the problem, good speedup were obtained up to 32 processors <ref> [9] </ref>. V. Kumar, K. Ramesh and V. Nageshwara Rao: two SDOM implementations were tested by these authors, being one synchronous and other asynchronous. Both implementations were done in a BBN Butterfly composed of up to 256 processors.
Reference: [10] <author> R. Corr^ea and A. Ferreira. </author> <title> Modeling parallel branch-and-bound for asynchronous implementations. </title> <booktitle> In '94 DIMACS Workshop on Parallel Processing. </booktitle> <institution> DIMACS Center, Rutgers University, </institution> <month> Apr. </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: The operations are executed indivisibly, e.g., the model guarantees serializability of operation invocations; if two operations are applied simultaneously, then the result is as if one of them is executed before the other; the order of invocation, however, is non-deterministic <ref> [9, 10] </ref>.
Reference: [11] <author> R. Corr^ea and A. Ferreira. </author> <title> On the effectiveness of synchronous branch-and-bound algorithms. </title> <note> 1994. Submitted for publication. </note>
Reference-contexts: The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration <ref> [11, 30, 31, 34, 48, 57] </ref>. Other sources of parallelism exist, but they have not been widely explored [7, 57]. <p> The best feasible solution found so far is kept, as well as its value. At some points of the execution, some subproblems shown not to contain a feasible solution better than the current best known feasible solution are eliminated <ref> [11, 18, 23, 24, 40, 42, 57] </ref>. We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated. <p> The goal of the third operation, evaluation, is to allow an intelligent search in S that avoids considering subproblems known not to be leading to an optimal solution of the original problem. We use the following lemma to describe it <ref> [11, 18, 23] </ref>. Lemma 1 At an iteration, if l (v) U then v cannot lead to a feasible solution which is better than the current best known feasible solution. Def. 4 (Evaluation) For each iteration, the evaluation eliminates all subproblems v such that l (v) U . <p> Then we recall the definition of synchronous parallel B&B from the literature <ref> [9, 11, 30, 31, 34, 48] </ref>, and we describe two general asynchronous models of parallel B&B. The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable [9, 58]. <p> Of the 105 randomly generated instances run, only six exhibited anomalous behavior, all in the knapsack problem. There was only one case of detrimental anomaly. Other simulations with the knapsack problem, where the instances randomly generated were hard instances, produced no anomalies <ref> [11] </ref>. Similar results exist in the literature for the traveling salesperson problem [50, 51, 52], for the vertex-cover problem [58], for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem [35, 47, 54]. These results must be analyzed with some caution. <p> In the following, we shall define parallel efficiency measures which take into account the two factors involved in the efficiency of parallel synchronous B&B algorithms (or, in general, of non-isoergotic parallel algorithms): the parallel work of the processors and the quality of the heuristic selection function <ref> [11] </ref>. The following two sections are devoted to the asynchronous case. 5.1 Measuring effectiveness In this subsection, we revise the definitions presented in [11]. The slight difference we introduce here concerns the definition of "useful work" below. We first recall the measure comparing parallel and sequential versions. <p> efficiency of parallel synchronous B&B algorithms (or, in general, of non-isoergotic parallel algorithms): the parallel work of the processors and the quality of the heuristic selection function <ref> [11] </ref>. The following two sections are devoted to the asynchronous case. 5.1 Measuring effectiveness In this subsection, we revise the definitions presented in [11]. The slight difference we introduce here concerns the definition of "useful work" below. We first recall the measure comparing parallel and sequential versions. From now on, let i represent the set of sub-problems decomposed during an execution using i processors. <p> Def. 9 (Selection efficiency) e s (p) = I fl pI (p) Finally, the effectiveness is measured as the rate of processor utilization for doing useful work <ref> [11] </ref>. Def. 10 (Effectiveness) *(p) = e u (p):e s (p) The effectiveness is a simple and general framework for the analysis of parallel B&B algorithms. There are two factors on the effectiveness that behave symmetrically.
Reference: [12] <author> J. Eckstein. </author> <title> Control strategies for parallel mixed integer branch and bound. </title> <editor> In I. C. S. Press, editor, </editor> <booktitle> Supercomputing '94, </booktitle> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>. <p> It is important to keep in mind that they concern "academic problems", with randomly generated instances. If we think of "industrial strength" problems , with real-world instances, pathological cases exist such that anomalies can be frequent (for an illustration, see <ref> [12, 13] </ref>). 5 Efficiency: counting iterations and time Consider, initially, the synchronous case. Let us define efficiency as e (p) = A (p)=p. <p> (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory <ref> [12, 13] </ref> In the following, a set of distributed implementation is presented which stress the most important conclusions obtained empirically about parallel B&B. <p> Impressive speedup values were obtained, mainly for a problem whose estimated sequential time was 6.6 days and that was solved in only 34.9 min with 128 processors <ref> [12] </ref>. The results were extended in [13] with more efficient decompositions and lower bound calculations. With this improvement in the sequential algorithm and a better scalar performance of the version of the CM-5 used, most of the superlinear speedups disappeared [12, 13]. M. <p> The results were extended in [13] with more efficient decompositions and lower bound calculations. With this improvement in the sequential algorithm and a better scalar performance of the version of the CM-5 used, most of the superlinear speedups disappeared <ref> [12, 13] </ref>. M. Quinn: in order to predict the performance of the synchronous implementation described in his paper to solve the traveling salesperson problem, the author describes a model. This model predicts, and the experimental results confirm, an eventual drop in speedup caused by an increase in communication overhead. <p> An interesting point to remark is that this scheme used solely is worse than the randomized in terms of speedup (in average). Apparently, randomization removes the "easy" parts of the task of workload sharing, and the specialized workload sharing scheme improves the performance taking care of the difficult aspects <ref> [12, 13] </ref>. V. Kumar, K. Ramesh and V. Nageshwara Rao: besides the SDOM implementations, these authors also experimented two DDM implementations. In both implementations, specialized workload sharing schemes were used. They are the random strategy of Karp and Zhang, and a ring strategy.
Reference: [13] <author> J. Eckstein. </author> <title> Parallel branch-and-bound algorithms for general mixed integer programming on the CM-5. </title> <type> Technical Report TMC-257, </type> <institution> Thinking Machines Corporation, </institution> <year> 1994. </year> <note> To appear in the SIAM Journal on Optimization, </note> <year> 1994. </year>
Reference-contexts: The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>. <p> It is important to keep in mind that they concern "academic problems", with randomly generated instances. If we think of "industrial strength" problems , with real-world instances, pathological cases exist such that anomalies can be frequent (for an illustration, see <ref> [12, 13] </ref>). 5 Efficiency: counting iterations and time Consider, initially, the synchronous case. Let us define efficiency as e (p) = A (p)=p. <p> (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory <ref> [12, 13] </ref> In the following, a set of distributed implementation is presented which stress the most important conclusions obtained empirically about parallel B&B. <p> Impressive speedup values were obtained, mainly for a problem whose estimated sequential time was 6.6 days and that was solved in only 34.9 min with 128 processors [12]. The results were extended in <ref> [13] </ref> with more efficient decompositions and lower bound calculations. With this improvement in the sequential algorithm and a better scalar performance of the version of the CM-5 used, most of the superlinear speedups disappeared [12, 13]. M. <p> The results were extended in [13] with more efficient decompositions and lower bound calculations. With this improvement in the sequential algorithm and a better scalar performance of the version of the CM-5 used, most of the superlinear speedups disappeared <ref> [12, 13] </ref>. M. Quinn: in order to predict the performance of the synchronous implementation described in his paper to solve the traveling salesperson problem, the author describes a model. This model predicts, and the experimental results confirm, an eventual drop in speedup caused by an increase in communication overhead. <p> An interesting point to remark is that this scheme used solely is worse than the randomized in terms of speedup (in average). Apparently, randomization removes the "easy" parts of the task of workload sharing, and the specialized workload sharing scheme improves the performance taking care of the difficult aspects <ref> [12, 13] </ref>. V. Kumar, K. Ramesh and V. Nageshwara Rao: besides the SDOM implementations, these authors also experimented two DDM implementations. In both implementations, specialized workload sharing schemes were used. They are the random strategy of Karp and Zhang, and a ring strategy.
Reference: [14] <editor> A. Ferreira and J. Rolim, editors. </editor> <title> Solving Irregular Problems in Parallel: State of the Art. </title> <publisher> Kluwer Academic Publisher, </publisher> <address> Boston (USA), </address> <year> 1995. </year>
Reference-contexts: However, the reduction on the number of iterations can deviate considerably from linear due to possible speedup anomalies (details in section 4). Parallel B&B is traditionally considered as an irregular parallel algorithm due to the fact that the structure of the search tree is not known beforehand <ref> [14] </ref>. The search in T involves heuristic choices of paths which determine subproblem (s), depending on the number of available processors, to decompose at each iteration.
Reference: [15] <author> R. Finkel and U. Manber. </author> <title> DIB A distributed implementation of backtracking. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(2) </volume> <pages> 235-256, </pages> <month> Apr. </month> <year> 1987. </year>
Reference-contexts: A number of parallel implementations have been reported in the literature. Their origins lay in the simulations already cited in previous sections and in parallel implementations of related techniques, as divide-and-conquer [22] and backtracking <ref> [15] </ref>. These implementations involve the classical communication versus computation tradeoff. Briefly speaking, the amount of - 19 - decomposed subproblems can be reduced at the cost of increased communication, and vice-versa. The vast majority of published implementations have focused on specialized algorithms for "pure" combinatorial problems.
Reference: [16] <author> B. Fox, J. Lenstra, A. Rinnooy Kan, and L. </author> <title> Schrage. Branching from the largest upper bound: folklore and facts. Europ. </title> <journal> Journal of Op. Res., </journal> <pages> pages 191-194, </pages> <year> 1978. </year>
Reference-contexts: The maximization version is also known as branching from the largest upper bound <ref> [16] </ref>. 14 Or bottom nodes [24], terminal nodes [40]. 15 Or critical node [30, 31]. - 5 - The worthwhile subproblems of a BB-tree T form the critical subtree T fl of T [31, 40]. <p> Indeed, Fox et al. had already observed, in the late 70's, that, even in the case of a single processor, when several nodes have the same lower bound, then some best-first strategies are non-optimal <ref> [16] </ref>. We summarize in this section the most important known results concerning the anomalies in synchronous B&B algorithms. <p> Given that a worthwhile subproblem can house an optimal solution, it is reasonable to say that the useful work is exclusively composed of the decompositions of worthwhile subproblems and the ones leading the algorithm to the solution <ref> [16, 40] </ref>. In other words, let C m be the minimum over all of the minimum critical paths of each of the trees of T T fl (the resulting forest when we delete T fl from T ).
Reference: [17] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. F. </editor> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: 1 Introduction The use of parallel algorithms for solving NP-hard problems becomes attractive as massively parallel systems consisting of a number of powerful processors offer large computation power and memory storage capacity (for a theory of NP-hardness, see <ref> [17] </ref>).
Reference: [18] <author> M. Gengler. </author> <title> Axiomatique de branch and bound. </title> <institution> Rapport interne 77, LITH - Ecole Polytechnique Federale de Lausanne, </institution> <year> 1992. </year> <month> - 27 </month> - 
Reference-contexts: The best feasible solution found so far is kept, as well as its value. At some points of the execution, some subproblems shown not to contain a feasible solution better than the current best known feasible solution are eliminated <ref> [11, 18, 23, 24, 40, 42, 57] </ref>. We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated. <p> The goal of the third operation, evaluation, is to allow an intelligent search in S that avoids considering subproblems known not to be leading to an optimal solution of the original problem. We use the following lemma to describe it <ref> [11, 18, 23] </ref>. Lemma 1 At an iteration, if l (v) U then v cannot lead to a feasible solution which is better than the current best known feasible solution. Def. 4 (Evaluation) For each iteration, the evaluation eliminates all subproblems v such that l (v) U .
Reference: [19] <author> M. Gengler and G. Coray. </author> <title> A parallel best-first B&B with synchronization phases. </title> <editor> In L. Bouge, M. Cosnard, Y. Robert, and D. Trystram, editors, </editor> <booktitle> Parallel Processing: CONPAR 92 - VAPP V, </booktitle> <volume> LNCS 634, </volume> <pages> pages 515-526. </pages> <publisher> Springer-Verlag, </publisher> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>.
Reference: [20] <author> S. Gnesi, U. Montanari, and A. Martelli. </author> <title> Dynamic programming as graph searching: An algebraic approach. </title> <journal> Journal of the ACM, </journal> <volume> 28(4) </volume> <pages> 737-751, </pages> <month> Oct. 81. </month>
Reference-contexts: The algorithm consists of a heuristic iterative search in T that avoids visiting some subproblems which are known not to contain an optimal solution, and is detailed in section 2. Backtracking, dynamic programming, A fl and AND-OR tree search can be viewed as variations of B&B algorithms <ref> [20, 28, 43, 44] </ref>. Parallel processing has been widely studied as an additional source of improvement in search efficiency in discrete optimization. A variety of interconnection networks and parallel algorithms have been proposed for processor-processor or processor-memory communication, as ways for parallelizing sequential algorithms [27].
Reference: [21] <author> J. Gustafson. </author> <title> The consequences of fixed time performance measurement. </title> <booktitle> In 25th Hawaii Int. Conf. on Syst. Sc., volume III. IEEE, </booktitle> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: This phenomenon is also one of the explanations for speedup anomalies (see section 4). Gustafson cites the parallel B&B as a counterexample to the affirmation that "the best sequential algorithm defines the least work necessary", which he considers as a myth of performance measurement <ref> [21] </ref>. The definition of e (p) considers this myth as a fact to measure the computational parallel efficiency of parallel B&B algorithms.
Reference: [22] <author> E. Horowitz and A. Zorat. </author> <title> Divide-and-conquer for parallel processing. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-32(6):582-585, </volume> <month> June </month> <year> 1983. </year>
Reference-contexts: A number of parallel implementations have been reported in the literature. Their origins lay in the simulations already cited in previous sections and in parallel implementations of related techniques, as divide-and-conquer <ref> [22] </ref> and backtracking [15]. These implementations involve the classical communication versus computation tradeoff. Briefly speaking, the amount of - 19 - decomposed subproblems can be reduced at the cost of increased communication, and vice-versa. The vast majority of published implementations have focused on specialized algorithms for "pure" combinatorial problems.
Reference: [23] <author> T. Ibaraki. </author> <title> Theoretical comparisons of search strategies in branch-and-bound algorithms. </title> <journal> Int. Journal of Computing and Information Sc., </journal> <volume> 5(4) </volume> <pages> 315-344, </pages> <year> 1976. </year>
Reference-contexts: The best feasible solution found so far is kept, as well as its value. At some points of the execution, some subproblems shown not to contain a feasible solution better than the current best known feasible solution are eliminated <ref> [11, 18, 23, 24, 40, 42, 57] </ref>. We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated. <p> The goal of the third operation, evaluation, is to allow an intelligent search in S that avoids considering subproblems known not to be leading to an optimal solution of the original problem. We use the following lemma to describe it <ref> [11, 18, 23] </ref>. Lemma 1 At an iteration, if l (v) U then v cannot lead to a feasible solution which is better than the current best known feasible solution. Def. 4 (Evaluation) For each iteration, the evaluation eliminates all subproblems v such that l (v) U .
Reference: [24] <author> T. Ibaraki. </author> <title> The power of dominance relations in branch-and-bound algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 24(2) </volume> <pages> 264-279, </pages> <month> Apr. </month> <year> 1977. </year>
Reference-contexts: The best feasible solution found so far is kept, as well as its value. At some points of the execution, some subproblems shown not to contain a feasible solution better than the current best known feasible solution are eliminated <ref> [11, 18, 23, 24, 40, 42, 57] </ref>. We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated. <p> Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound <ref> [24, 52, 53] </ref>. <p> The maximization version is also known as branching from the largest upper bound [16]. 14 Or bottom nodes <ref> [24] </ref>, terminal nodes [40]. 15 Or critical node [30, 31]. - 5 - The worthwhile subproblems of a BB-tree T form the critical subtree T fl of T [31, 40]. It is easy to see that all worthwhile subproblems must be selected during a B&B execution. <p> In this case, a dominance relation is verified, in the sense that v i dominates v j . Then, v j can be eliminated of further decompositions <ref> [24] </ref>. 16 Although not in the scope of this report, there are other search algorithms, known as graph search algorithms (as A fl and its derivations), for which T is a graph because replication of subproblems are allowed [4, 49]. - 6 - l = 1 l = 15 l =
Reference: [25] <author> R. Karp and Y. Zhang. </author> <title> A randomized parallel branch-and-bound procedure. </title> <booktitle> In Symposium on Theory of Computing, </booktitle> <pages> pages 290-300, </pages> <year> 1988. </year>
Reference-contexts: These results were all better than the SDOM, centralized strategy, ones [1]. J. Eckstein: in order to use a DDM to extend its previous SDOM, centralized strategy, implementation, this author uses a randomized workload sharing scheme proposed by Karp and Zhang <ref> [25] </ref>. In this scheme, each processor randomly chooses, from time to time, a processor to send a just generated subproblem. Comparing the results obtained with this scheme with the results with the SDOM, he noticed an increasing in the parallel execution time of about 30 percent in average.
Reference: [26] <author> R. Karp and Y. Zhang. </author> <title> Randomized parallel algorithms for backtrack search and branch-and-bound computations. </title> <journal> Journal of the ACM, </journal> <volume> 40(3) </volume> <pages> 765-789, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: At each iteration, the data structure D is composed of a collection of open subproblems, called 9 Or live nodes [30], active subproblems [57], unexamined nodes [52], frontier nodes <ref> [26] </ref>. - 4 - openset 10 , an upper bound 11 U , which is the best value found so far, and a feasible solution whose value is U . <p> The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>. <p> This fact can be seen as an advantage over other asynchronous approaches (that do not keep any order on the subproblems) in terms of the quality of the subproblems selected <ref> [26, 27, 37] </ref>.
Reference: [27] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <publisher> The Benjamin/Cummings Publishing Company, Inc., </publisher> <year> 1994. </year>
Reference-contexts: Parallel processing has been widely studied as an additional source of improvement in search efficiency in discrete optimization. A variety of interconnection networks and parallel algorithms have been proposed for processor-processor or processor-memory communication, as ways for parallelizing sequential algorithms <ref> [27] </ref>. We review in this report the literature pertinent to modeling, performance characterization and implementation of parallel branch-and-bound algorithms for discrete optimization problems. The focus is on distributed memory parallel systems. <p> The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>. <p> This fact can be seen as an advantage over other asynchronous approaches (that do not keep any order on the subproblems) in terms of the quality of the subproblems selected <ref> [26, 27, 37] </ref>. <p> The simplest way to implement D assigns it to a given central processor, and is called centralized strategy <ref> [27] </ref>. However, this strategy limits performance since the latency time at each iteration grows linearly with the number of processors. Moreover, at least two communications are necessary between each processor and the central processor per decomposition (corresponding to the selection and insertions).
Reference: [28] <author> V. Kumar and L. Kanal. </author> <title> The CDP: a unifying formulation for heuristic search, dynamic programming, and branch-and-bound. </title> <booktitle> In National Conf. on A.I., </booktitle> <year> 1983. </year>
Reference-contexts: The algorithm consists of a heuristic iterative search in T that avoids visiting some subproblems which are known not to contain an optimal solution, and is detailed in section 2. Backtracking, dynamic programming, A fl and AND-OR tree search can be viewed as variations of B&B algorithms <ref> [20, 28, 43, 44] </ref>. Parallel processing has been widely studied as an additional source of improvement in search efficiency in discrete optimization. A variety of interconnection networks and parallel algorithms have been proposed for processor-processor or processor-memory communication, as ways for parallelizing sequential algorithms [27].
Reference: [29] <author> V. Kumar, K. Ramesh, and V. N. Rao. </author> <title> Parallel best-first search of state-space graphs: A summary of results. </title> <booktitle> In Proceedings of the 1988 National Conf. on Artificial Intelligence, </booktitle> <pages> pages 122-127, </pages> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory <ref> [29, 41, 52, 55] </ref> Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set of distributed implementation is presented which stress the most important conclusions <p> Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory <ref> [29, 38] </ref> Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set of distributed implementation is presented which stress the most important conclusions obtained empirically about parallel B&B. <p> For a sufficiently large instance of the traveling salesperson problem, this synchronous algorithm attains good speedups. The vertex cover problem, as a fine grain problem, revealed inadequate. The asynchronous implementations exhibited good speedups for both application problems <ref> [29] </ref>. D. Miller and J. Pekny: they also used a BBN Butterfly computer to implement their algorithm (14 processors). It is an asynchronous parallel B&B under SDOM. The application used is the traveling salesperson problem. <p> The results confirm this affirmation. For the TSP, both DDM strategies are worse than the SDOM strategies. For the VCP, the SDOM implementation also yields better speedups, but the randomized scheme also gives good results <ref> [29] </ref>. P. Laursen: this author uses the QAP problem to compare asynchronous parallel B&B implementations under DDM, with and without specialized dynamic workload sharing. The emphasis in his work was the simplicity. He measures the average processor utilization rate to determine efficiency.
Reference: [30] <author> T. Lai and S. Sahni. </author> <title> Anomalies in parallel branch-and-bound algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 594-602, </pages> <year> 1984. </year>
Reference-contexts: A notation sheet can be found at the end of the report. 2 Or linear (pure) integer programming problem [45, 46]. 3 If Z n is replaced by f0; 1g n we have a combinatorial optimization problem. 4 Or criterion function <ref> [30] </ref>. 5 Or answer node [30]. 6 Or cost [30]. 7 Or least-cost answer node [30]. - 2 - exhaustive search is often impracticable. The method called branch-and-bound (noted B&B) is a tree search algorithm often used as an intelligent search in this context. <p> A notation sheet can be found at the end of the report. 2 Or linear (pure) integer programming problem [45, 46]. 3 If Z n is replaced by f0; 1g n we have a combinatorial optimization problem. 4 Or criterion function <ref> [30] </ref>. 5 Or answer node [30]. 6 Or cost [30]. 7 Or least-cost answer node [30]. - 2 - exhaustive search is often impracticable. The method called branch-and-bound (noted B&B) is a tree search algorithm often used as an intelligent search in this context. <p> A notation sheet can be found at the end of the report. 2 Or linear (pure) integer programming problem [45, 46]. 3 If Z n is replaced by f0; 1g n we have a combinatorial optimization problem. 4 Or criterion function <ref> [30] </ref>. 5 Or answer node [30]. 6 Or cost [30]. 7 Or least-cost answer node [30]. - 2 - exhaustive search is often impracticable. The method called branch-and-bound (noted B&B) is a tree search algorithm often used as an intelligent search in this context. <p> at the end of the report. 2 Or linear (pure) integer programming problem [45, 46]. 3 If Z n is replaced by f0; 1g n we have a combinatorial optimization problem. 4 Or criterion function <ref> [30] </ref>. 5 Or answer node [30]. 6 Or cost [30]. 7 Or least-cost answer node [30]. - 2 - exhaustive search is often impracticable. The method called branch-and-bound (noted B&B) is a tree search algorithm often used as an intelligent search in this context. Its principle lies in successive decompositions of the original problem in smaller disjoint subproblems until an optimal solution is found. <p> The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration <ref> [11, 30, 31, 34, 48, 57] </ref>. Other sources of parallelism exist, but they have not been widely explored [7, 57]. <p> We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated. At each iteration, the data structure D is composed of a collection of open subproblems, called 9 Or live nodes <ref> [30] </ref>, active subproblems [57], unexamined nodes [52], frontier nodes [26]. - 4 - openset 10 , an upper bound 11 U , which is the best value found so far, and a feasible solution whose value is U . <p> The liveliness condition above points out that if there is an open subproblem at the beginning of an iteration, then at least one such a subproblem will be chosen for decomposition. A selected subproblem is called an E-node <ref> [30] </ref>. To each subproblem generated during the execution is associated a lower bound 12 , defined in the following. It is calculated when the subproblem is generated by a decomposition. <p> The leaves of T are solution nodes 14 , which solved directly in a decomposition. Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function <ref> [30] </ref>. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound [24, 52, 53]. <p> Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function <ref> [30] </ref>. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound [24, 52, 53]. <p> The maximization version is also known as branching from the largest upper bound [16]. 14 Or bottom nodes [24], terminal nodes [40]. 15 Or critical node <ref> [30, 31] </ref>. - 5 - The worthwhile subproblems of a BB-tree T form the critical subtree T fl of T [31, 40]. It is easy to see that all worthwhile subproblems must be selected during a B&B execution. <p> Then we recall the definition of synchronous parallel B&B from the literature <ref> [9, 11, 30, 31, 34, 48] </ref>, and we describe two general asynchronous models of parallel B&B. The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable [9, 58]. <p> Related to these features, many authors noted, in the middle of the 80's, the existence of speedup anomalies, that are due to bad selections when several subproblems have a lower bound that equals f fl <ref> [30, 31] </ref> (for a historical note, see [51]). Indeed, Fox et al. had already observed, in the late 70's, that, even in the case of a single processor, when several nodes have the same lower bound, then some best-first strategies are non-optimal [16]. <p> The speedup anomalies are of two types: acceleration anomaly, where A (p) &gt; p; and detrimental anomaly, where A (p) &lt; 1 <ref> [30, 31, 34] </ref>. Obviously, it is desirable to preserve acceleration anomalies and avoid detrimental anomalies. 4.1 Conditions for preventing detrimental anomalies Several authors have analyzed detrimental anomalies in the general case [30, 31]. <p> Obviously, it is desirable to preserve acceleration anomalies and avoid detrimental anomalies. 4.1 Conditions for preventing detrimental anomalies Several authors have analyzed detrimental anomalies in the general case <ref> [30, 31] </ref>. Lai and Sahni have shown that if l (v) 6= f fl whenever v is not a solution node, then synchronous parallel B&B with p &gt; 1 does not increase the number of iterations accomplished in sequential [30]. <p> Lai and Sahni have shown that if l (v) 6= f fl whenever v is not a solution node, then synchronous parallel B&B with p &gt; 1 does not increase the number of iterations accomplished in sequential <ref> [30] </ref>. The reason is that, in these particular cases, I (p) is bounded by the number of worthwhile subproblems. <p> The proofs for the synchronous case can be found in [34]. In the next section, a similar result is presented for the asynchronous case. The existence of anomalies when increasing the number of processors used in parallel was also studied <ref> [30, 31] </ref>. The conditions above are no longer sufficient when the comparisons consider p &gt; 1 as the reference case. <p> In <ref> [30] </ref>, it is demonstrated that, given a problem, an instance of its BB-tree can be found such that an acceleration anomaly occurs for a certain p. On the other hand, it is also demonstrated in [30] that, if one assumes that l (v) 6= f fl whenever v is not an <p> In <ref> [30] </ref>, it is demonstrated that, given a problem, an instance of its BB-tree can be found such that an acceleration anomaly occurs for a certain p. On the other hand, it is also demonstrated in [30] that, if one assumes that l (v) 6= f fl whenever v is not an optimal solution, then acceleration anomalies do not occur. <p> Theoretical analysis and experiments have shown that anomalies are rare when optimal solutions are sought using best-first searches and the problem is sufficiently large. Simulations with the knapsack and traveling salesperson problems are shown in <ref> [30] </ref>. Of the 105 randomly generated instances run, only six exhibited anomalous behavior, all in the knapsack problem. There was only one case of detrimental anomaly. Other simulations with the knapsack problem, where the instances randomly generated were hard instances, produced no anomalies [11]. <p> In isoergotic algorithms, the total quantity of work accomplished remains the same in the two cases (sequential and parallel), and e (p) is a good measure of efficiency in this case, since the total amount of work can be computed as p:e (p) <ref> [30, 34, 51, 57] </ref>. The notion of computational parallel efficiency is always related to the idea of velocity of a parallel algorithm, often as a comparative parameter with respect to a sequential counterpart (see section 2).
Reference: [31] <author> T. Lai and A. Sprague. </author> <title> Performance of parallel branch-and-bound algorithms. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(10):962-964, </volume> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration <ref> [11, 30, 31, 34, 48, 57] </ref>. Other sources of parallelism exist, but they have not been widely explored [7, 57]. <p> We concentrate on best-first 13 search, where h (v) = l (v) and ffi selects the subproblem with smallest priority. A search tree T = (V; fi), with the domain S, the objective function f and a lower bound function l, is called a BB-tree <ref> [31] </ref>. The leaves of T are solution nodes 14 , which solved directly in a decomposition. Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost <p> S, the objective function f and a lower bound function l, is called a BB-tree <ref> [31] </ref>. The leaves of T are solution nodes 14 , which solved directly in a decomposition. Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound [24, 52, 53]. <p> lower bound function l, is called a BB-tree <ref> [31] </ref>. The leaves of T are solution nodes 14 , which solved directly in a decomposition. Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound [24, 52, 53]. <p> Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset <ref> [31] </ref>, active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound [24, 52, 53]. <p> The maximization version is also known as branching from the largest upper bound [16]. 14 Or bottom nodes [24], terminal nodes [40]. 15 Or critical node <ref> [30, 31] </ref>. - 5 - The worthwhile subproblems of a BB-tree T form the critical subtree T fl of T [31, 40]. It is easy to see that all worthwhile subproblems must be selected during a B&B execution. <p> The maximization version is also known as branching from the largest upper bound [16]. 14 Or bottom nodes [24], terminal nodes [40]. 15 Or critical node [30, 31]. - 5 - The worthwhile subproblems of a BB-tree T form the critical subtree T fl of T <ref> [31, 40] </ref>. It is easy to see that all worthwhile subproblems must be selected during a B&B execution. A critical path is a path in T from the root to a solution node housing an optimal solution, and its length is its number of edges. <p> Then we recall the definition of synchronous parallel B&B from the literature <ref> [9, 11, 30, 31, 34, 48] </ref>, and we describe two general asynchronous models of parallel B&B. The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable [9, 58]. <p> Related to these features, many authors noted, in the middle of the 80's, the existence of speedup anomalies, that are due to bad selections when several subproblems have a lower bound that equals f fl <ref> [30, 31] </ref> (for a historical note, see [51]). Indeed, Fox et al. had already observed, in the late 70's, that, even in the case of a single processor, when several nodes have the same lower bound, then some best-first strategies are non-optimal [16]. <p> The speedup anomalies are of two types: acceleration anomaly, where A (p) &gt; p; and detrimental anomaly, where A (p) &lt; 1 <ref> [30, 31, 34] </ref>. Obviously, it is desirable to preserve acceleration anomalies and avoid detrimental anomalies. 4.1 Conditions for preventing detrimental anomalies Several authors have analyzed detrimental anomalies in the general case [30, 31]. <p> Obviously, it is desirable to preserve acceleration anomalies and avoid detrimental anomalies. 4.1 Conditions for preventing detrimental anomalies Several authors have analyzed detrimental anomalies in the general case <ref> [30, 31] </ref>. Lai and Sahni have shown that if l (v) 6= f fl whenever v is not a solution node, then synchronous parallel B&B with p &gt; 1 does not increase the number of iterations accomplished in sequential [30]. <p> The proofs for the synchronous case can be found in [34]. In the next section, a similar result is presented for the asynchronous case. The existence of anomalies when increasing the number of processors used in parallel was also studied <ref> [30, 31] </ref>. The conditions above are no longer sufficient when the comparisons consider p &gt; 1 as the reference case. <p> Lai and Sprague showed that f l (v) 6= f fl whenever v is not a solution node g is a sufficient condition to prevent detrimental anomalies when the number of processors is doubled <ref> [31] </ref>. <p> However, the exact number of iterations required depends upon the shape of the search tree. Previous results on speedup anomalies showed unsurprisingly that dense search trees with short critical paths yield to parallel attack more readily than sparse trees with long critical paths <ref> [31] </ref>. Theoretical analysis and experiments have shown that anomalies are rare when optimal solutions are sought using best-first searches and the problem is sufficiently large. Simulations with the knapsack and traveling salesperson problems are shown in [30].
Reference: [32] <author> P. S. Laursen. </author> <title> Simple approaches to parallel Branch and Bound. </title> <journal> Paral. Comp., </journal> <volume> 19 </volume> <pages> 143-152, </pages> <year> 1993. </year>
Reference-contexts: More details about the distributed memory implementations can be found in the following subsections, relating each implementation to its corresponding theoretic model. Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory <ref> [32, 47] </ref> Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set <p> Even the version without dynamic workload sharing exhibited average processor utilization rates between 80 and 90 percent, indicating that the tree search is quite "regular" in this case. The quantitative workload sharing used is simple, and bring the average processor utilization to 98 percent <ref> [32] </ref>. R. Luling and B. Monien: the VCP was also used by these authors as an application in order to investigate DDM implementations. The emphasis of their proposal is a quality workload sharing specialized scheme. They proposed some weight functions to express the workload of a processor.
Reference: [33] <author> W. Levelt, M. Kaashoek, H. Bal, and A. Tanenbaum. </author> <title> A comparision of two paradigms for distributed shared memory. </title> <journal> Software Practice and Experience, </journal> <volume> 22(11) </volume> <pages> 985-1010, </pages> <month> Nov. </month> <year> 1992. </year> <month> - 28 </month> - 
Reference-contexts: The SDOM allows processors to communicate only through a global data structure, which possesses exactly one priority list of subproblems <ref> [33] </ref>. On the other hand, in the DDM, each processor has its own local data structure, and the processors communicate by exchanging subproblems among the local data structures, each one with one priority list of subproblems. Some examples of implementations are summarized in section 6.
Reference: [34] <author> G. Li and B. Wah. </author> <title> Coping with anomalies in parallel branch-and-bound algorithms. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(6):568-573, </volume> <month> June </month> <year> 1986. </year>
Reference-contexts: The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration <ref> [11, 30, 31, 34, 48, 57] </ref>. Other sources of parallelism exist, but they have not been widely explored [7, 57]. <p> Then we recall the definition of synchronous parallel B&B from the literature <ref> [9, 11, 30, 31, 34, 48] </ref>, and we describe two general asynchronous models of parallel B&B. The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable [9, 58]. <p> The speedup anomalies are of two types: acceleration anomaly, where A (p) &gt; p; and detrimental anomaly, where A (p) &lt; 1 <ref> [30, 31, 34] </ref>. Obviously, it is desirable to preserve acceleration anomalies and avoid detrimental anomalies. 4.1 Conditions for preventing detrimental anomalies Several authors have analyzed detrimental anomalies in the general case [30, 31]. <p> We assume that, like in the case studied originally by Li and Wah <ref> [34] </ref>, the priority function h satisfies the following assumption, where a consistent selection order is used to avoid detrimental anomalies. <p> The proofs for the synchronous case can be found in <ref> [34] </ref>. In the next section, a similar result is presented for the asynchronous case. The existence of anomalies when increasing the number of processors used in parallel was also studied [30, 31]. The conditions above are no longer sufficient when the comparisons consider p &gt; 1 as the reference case. <p> Another necessary condition for acceleration anomalies were stated in <ref> [34] </ref>. Such condition is based on the complete consistency of the heuristic function, in the sense that h should not be completely consistent with l. <p> In isoergotic algorithms, the total quantity of work accomplished remains the same in the two cases (sequential and parallel), and e (p) is a good measure of efficiency in this case, since the total amount of work can be computed as p:e (p) <ref> [30, 34, 51, 57] </ref>. The notion of computational parallel efficiency is always related to the idea of velocity of a parallel algorithm, often as a comparative parameter with respect to a sequential counterpart (see section 2). <p> Li and Wah, in their work in speedup anomalies <ref> [34] </ref>, also calculated the lower bound on the speedup given by A (p) 1, under assumption 2 (page 14). In [40], lower and upper bounds on A (p) are presented, also in the synchronous case. <p> Now, let us consider asynchronous B&B, of which we are interested in counting the number of iterations of parallel B&B. In this context, the analysis of anomalies and speedup bounds requires a causality among some special subproblems (namely basic subproblems [9] or basic nodes <ref> [34] </ref>), which is well represented by the iterations in the SDOM. On the other hand, under DDM, the concept of asynchronous iteration is not precisely defined, making such analysis difficult. We concentrate, then, on the SDOM. <p> It is shown in [9] that there is a lower bound for A (p; ) that depends on the asynchronism measure and on the number of processors employed, under the assumptions 1 (page 11) and 2 (page 14). These results generalize the ones in synchronous B&B in <ref> [34] </ref> and shows that, as for the synchronous case, those are sufficient conditions to bound the total number of iterations.
Reference: [35] <author> Y. Li and P. Pardalos. </author> <title> Parallel algorithms for the quadratic assignment problem. </title> <editor> In P. Pardalos, editor, </editor> <booktitle> Advances in Optimization and Parallel Computing, </booktitle> <pages> pages 177-189. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Similar results exist in the literature for the traveling salesperson problem [50, 51, 52], for the vertex-cover problem [58], for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem <ref> [35, 47, 54] </ref>. These results must be analyzed with some caution. If the problem possesses a good bound computation scheme producing tight bounds, then parallelizing the subproblem investigation might produce an algorithm which scales poorly and may make meaningful use of only a few processors [7].
Reference: [36] <author> J. Little, K. Murty, D. Sweeney, and C. Karel. </author> <title> An algorithm for the traveling salesman problem. </title> <journal> Operations Research, </journal> <volume> 11 </volume> <pages> 972-989, </pages> <year> 1963. </year>
Reference-contexts: This model predicts, and the experimental results confirm, an eventual drop in speedup caused by an increase in communication overhead. The sequential algorithm uses an old decomposition heuristic based on the assignment problem, but that does not use the special structure of the TSP <ref> [36] </ref>. The 30 tested instances were generated randomly from a uniform distribution [52]. Distributed strategy R. Corr^ea and A. Ferreira: the synchronous and asynchronous implementations described in their paper approach the question of the relation between the order of selections and the possibility of overlap between communication and computation.
Reference: [37] <author> R. Luling and B. Monien. </author> <title> Load balancing for distributed branch & bound algorithms, </title> <year> 1992. </year>
Reference-contexts: The amount of work can be defined in several different forms, but it is always related to subproblem decompositions. Several experiments have shown that, in many situation of interest, this dynamic workload sharing must take into account the heuristic function h (qualitative workload sharing) to minimize search overhead <ref> [1, 2, 12, 13, 19, 26, 27, 37] </ref>. <p> This fact can be seen as an advantage over other asynchronous approaches (that do not keep any order on the subproblems) in terms of the quality of the subproblems selected <ref> [26, 27, 37] </ref>.
Reference: [38] <author> R. Luling and B. Monien. </author> <title> Load balancing for distributed branch & bound algorithms. </title> <type> Technical Report Nr. 114, </type> <institution> Universitat Gesamthochschule Paderborn, </institution> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory <ref> [29, 38] </ref> Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set of distributed implementation is presented which stress the most important conclusions obtained empirically about parallel B&B. <p> Two communication topologies were used, namely de Bruijn and ring. For local workload sharing strategy, low diameter networks are well adapted, thus the implementations in the de Bruijn network presented better results. Impressive good speedups were obtained to sufficiently large instances, even up to 256 processors <ref> [38] </ref>. R. Ma, F. Tsung and M. Ma: they studied two implementations of an asynchronous parallel B&B under DDM. In the first implementation, there is no specialized workload sharing scheme. In this case, subproblems are allocated to the processors, and the processors work independently.
Reference: [39] <author> R. Ma, F. Tsung, and M. Ma. </author> <title> A dynamic load balancer for a parallel branch and bound algorithm. </title> <booktitle> In 1988 ACM Conf. on Lisp and Funct. Prog., </booktitle> <pages> pages 1505-1513. </pages> <publisher> ACM Press, </publisher> <year> 1988. </year>
Reference-contexts: Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory <ref> [39] </ref> Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set of distributed implementation is presented <p> Good speedup values were attained with dynamic workload sharing and a resource scheduling problem as target application (no details about the instance chosen are provided). The workload imbalance caused bad speedup values in the first implementation <ref> [39] </ref>. P. Pardalos and J. Crouse: these authors used a sophisticated sequential B&B algorithm to find all optimal solutions of a quadratic assignment problem, which prevents the possibility of speedup anomalies (see section 4). The asynchronous parallel B&B algorithm is based on this sequential one, under DDM.
Reference: [40] <author> B. Mans. </author> <title> Contribution a l'Algorithmique Non Numerique Parallele : Parallelisation de Methodes de Recherche Arborescente. </title> <type> PhD thesis, </type> <institution> Universite Paris VI, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: A large number of references is provided. 2 Preliminaries on sequential B&B A sequential B&B algorithm consists of a sequence of iterations, in which some operators are applied over a data structure D. This data structure keeps a priority list of subproblems <ref> [8, 40] </ref>. These operators choose a subproblem from D, decompose it and eventually insert new subproblems into the data structure, chosen among those generated by the decomposition. Feasible solutions are found during the search in two situations. <p> The best feasible solution found so far is kept, as well as its value. At some points of the execution, some subproblems shown not to contain a feasible solution better than the current best known feasible solution are eliminated <ref> [11, 18, 23, 24, 40, 42, 57] </ref>. We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated. <p> The maximization version is also known as branching from the largest upper bound [16]. 14 Or bottom nodes [24], terminal nodes <ref> [40] </ref>. 15 Or critical node [30, 31]. - 5 - The worthwhile subproblems of a BB-tree T form the critical subtree T fl of T [31, 40]. It is easy to see that all worthwhile subproblems must be selected during a B&B execution. <p> The maximization version is also known as branching from the largest upper bound [16]. 14 Or bottom nodes [24], terminal nodes [40]. 15 Or critical node [30, 31]. - 5 - The worthwhile subproblems of a BB-tree T form the critical subtree T fl of T <ref> [31, 40] </ref>. It is easy to see that all worthwhile subproblems must be selected during a B&B execution. A critical path is a path in T from the root to a solution node housing an optimal solution, and its length is its number of edges. <p> Given that a worthwhile subproblem can house an optimal solution, it is reasonable to say that the useful work is exclusively composed of the decompositions of worthwhile subproblems and the ones leading the algorithm to the solution <ref> [16, 40] </ref>. In other words, let C m be the minimum over all of the minimum critical paths of each of the trees of T T fl (the resulting forest when we delete T fl from T ). <p> Li and Wah, in their work in speedup anomalies [34], also calculated the lower bound on the speedup given by A (p) 1, under assumption 2 (page 14). In <ref> [40] </ref>, lower and upper bounds on A (p) are presented, also in the synchronous case. In that work, there is a characterization of T in different regions, depending on l and f fl .
Reference: [41] <author> D. Miller and J. Pekny. </author> <title> Results from a parallel branch and bound algorithm for the asymmetric traveling salesman problem. </title> <journal> Operations Research Letters, </journal> <volume> 8 </volume> <pages> 129-135, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory <ref> [29, 41, 52, 55] </ref> Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set of distributed implementation is presented which stress the most important conclusions <p> For reduced numbers of decomposed subproblems, the speedup tended to one, and deceleration speedup anomalies were detected. For instances whose the number of subproblems is sufficiently large, the speedups tended to p, and acceleration anomalies were verified <ref> [41, 50] </ref>. 6.2 Distributed data model The most important question to be addressed in the context of DDM is the dynamic workload sharing. Three choices must be done. The first choice consists of deciding between quantity or quality workload sharing.
Reference: [42] <author> L. Mitten. </author> <title> Branch-and-bound methods: General formulation and properties. </title> <journal> Operations Research, </journal> <volume> 18 </volume> <pages> 24-34, </pages> <year> 1970. </year>
Reference-contexts: The best feasible solution found so far is kept, as well as its value. At some points of the execution, some subproblems shown not to contain a feasible solution better than the current best known feasible solution are eliminated <ref> [11, 18, 23, 24, 40, 42, 57] </ref>. We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated.
Reference: [43] <author> T. Morin and R. Marsten. </author> <title> Branch-and-bound strategies for dynamic programming. </title> <journal> Operations Research, </journal> <volume> 24(4) </volume> <pages> 611-627, </pages> <month> Aug. </month> <year> 1976. </year>
Reference-contexts: The algorithm consists of a heuristic iterative search in T that avoids visiting some subproblems which are known not to contain an optimal solution, and is detailed in section 2. Backtracking, dynamic programming, A fl and AND-OR tree search can be viewed as variations of B&B algorithms <ref> [20, 28, 43, 44] </ref>. Parallel processing has been widely studied as an additional source of improvement in search efficiency in discrete optimization. A variety of interconnection networks and parallel algorithms have been proposed for processor-processor or processor-memory communication, as ways for parallelizing sequential algorithms [27].
Reference: [44] <author> D. Nau, V. Kumar, and L. Kanal. </author> <title> General branch and bound, and its relation to A fl and AO fl . Artificial Intelligence, </title> (23):29-58, 1984. 
Reference-contexts: The algorithm consists of a heuristic iterative search in T that avoids visiting some subproblems which are known not to contain an optimal solution, and is detailed in section 2. Backtracking, dynamic programming, A fl and AND-OR tree search can be viewed as variations of B&B algorithms <ref> [20, 28, 43, 44] </ref>. Parallel processing has been widely studied as an additional source of improvement in search efficiency in discrete optimization. A variety of interconnection networks and parallel algorithms have been proposed for processor-processor or processor-memory communication, as ways for parallelizing sequential algorithms [27].
Reference: [45] <author> G. Nemhauser and L. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> John Wiley and Sons Interscience, </publisher> <year> 1988. </year>
Reference-contexts: We also highlight the definitions in order to make easy their identification in the text. A notation sheet can be found at the end of the report. 2 Or linear (pure) integer programming problem <ref> [45, 46] </ref>. 3 If Z n is replaced by f0; 1g n we have a combinatorial optimization problem. 4 Or criterion function [30]. 5 Or answer node [30]. 6 Or cost [30]. 7 Or least-cost answer node [30]. - 2 - exhaustive search is often impracticable.
Reference: [46] <author> C. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice Hall Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: We also highlight the definitions in order to make easy their identification in the text. A notation sheet can be found at the end of the report. 2 Or linear (pure) integer programming problem <ref> [45, 46] </ref>. 3 If Z n is replaced by f0; 1g n we have a combinatorial optimization problem. 4 Or criterion function [30]. 5 Or answer node [30]. 6 Or cost [30]. 7 Or least-cost answer node [30]. - 2 - exhaustive search is often impracticable.
Reference: [47] <author> P. Pardalos and J. Crouse. </author> <title> A parallel algorithm for the quadratic assignment problem. </title> <booktitle> In Proceedings Supercomputing 1989, </booktitle> <pages> pages 351-360. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: Similar results exist in the literature for the traveling salesperson problem [50, 51, 52], for the vertex-cover problem [58], for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem <ref> [35, 47, 54] </ref>. These results must be analyzed with some caution. If the problem possesses a good bound computation scheme producing tight bounds, then parallelizing the subproblem investigation might produce an algorithm which scales poorly and may make meaningful use of only a few processors [7]. <p> More details about the distributed memory implementations can be found in the following subsections, relating each implementation to its corresponding theoretic model. Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory <ref> [32, 47] </ref> Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set <p> A sufficiently large number of subprob-lems is initially generated and evenly distributed over the processors. The speedup is measured for two classes of test problems used to evaluate the algorithm. Good speedups were obtained only for sufficiently large instances <ref> [47] </ref>. 6.3 General remarks In the light of the large empirical investigation on parallel B&B algorithm found in the literature, it is clear that parallelism is useful to improve its search performance. However, an universal parallelization strategy seems not to exist.
Reference: [48] <author> P. Pardalos and X. Li. </author> <title> Parallel branch-and-bound algorithms for combinatorial optimization. </title> <booktitle> Supercomputer, </booktitle> <pages> pages 23-30, </pages> <month> Sept. </month> <year> 1990. </year> <month> - 29 </month> - 
Reference-contexts: The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration <ref> [11, 30, 31, 34, 48, 57] </ref>. Other sources of parallelism exist, but they have not been widely explored [7, 57]. <p> Then we recall the definition of synchronous parallel B&B from the literature <ref> [9, 11, 30, 31, 34, 48] </ref>, and we describe two general asynchronous models of parallel B&B. The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable [9, 58].
Reference: [49] <author> J. Pearl. </author> <title> Heuristics Intelligent Search Strategies for Computer Problem Solving. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1984. </year>
Reference-contexts: Then, v j can be eliminated of further decompositions [24]. 16 Although not in the scope of this report, there are other search algorithms, known as graph search algorithms (as A fl and its derivations), for which T is a graph because replication of subproblems are allowed <ref> [4, 49] </ref>. - 6 - l = 1 l = 15 l = 20 l = 20 l = 25 3 Analytic models for parallel B&B In this section, we first establish our models for global data organization.
Reference: [50] <author> J. Pekny and D. Miller. </author> <title> A parallel branch and bound algorithm for solving large asymmetric traveling salesman problems. </title> <journal> Mathematical Programming, </journal> <volume> 55 </volume> <pages> 17-33, </pages> <year> 1992. </year>
Reference-contexts: There was only one case of detrimental anomaly. Other simulations with the knapsack problem, where the instances randomly generated were hard instances, produced no anomalies [11]. Similar results exist in the literature for the traveling salesperson problem <ref> [50, 51, 52] </ref>, for the vertex-cover problem [58], for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem [35, 47, 54]. These results must be analyzed with some caution. <p> For reduced numbers of decomposed subproblems, the speedup tended to one, and deceleration speedup anomalies were detected. For instances whose the number of subproblems is sufficiently large, the speedups tended to p, and acceleration anomalies were verified <ref> [41, 50] </ref>. 6.2 Distributed data model The most important question to be addressed in the context of DDM is the dynamic workload sharing. Three choices must be done. The first choice consists of deciding between quantity or quality workload sharing.
Reference: [51] <author> E. Pruul, G. Nemhauser, and R. Rushmeier. </author> <title> Branch-and-bound and parallel computation: a historical note. Op. </title> <journal> Res. Letters, </journal> <volume> 7(2) </volume> <pages> 65-69, </pages> <month> Apr. </month> <year> 1988. </year>
Reference-contexts: Related to these features, many authors noted, in the middle of the 80's, the existence of speedup anomalies, that are due to bad selections when several subproblems have a lower bound that equals f fl [30, 31] (for a historical note, see <ref> [51] </ref>). Indeed, Fox et al. had already observed, in the late 70's, that, even in the case of a single processor, when several nodes have the same lower bound, then some best-first strategies are non-optimal [16]. <p> There was only one case of detrimental anomaly. Other simulations with the knapsack problem, where the instances randomly generated were hard instances, produced no anomalies [11]. Similar results exist in the literature for the traveling salesperson problem <ref> [50, 51, 52] </ref>, for the vertex-cover problem [58], for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem [35, 47, 54]. These results must be analyzed with some caution. <p> In isoergotic algorithms, the total quantity of work accomplished remains the same in the two cases (sequential and parallel), and e (p) is a good measure of efficiency in this case, since the total amount of work can be computed as p:e (p) <ref> [30, 34, 51, 57] </ref>. The notion of computational parallel efficiency is always related to the idea of velocity of a parallel algorithm, often as a comparative parameter with respect to a sequential counterpart (see section 2).
Reference: [52] <author> M. Quinn. </author> <title> Analysis and Implementation of Branch and Bound Algorithms on a Hypercube Multicomputer. </title> <journal> IEEE Trans. on Comp., </journal> <volume> 39(3) </volume> <pages> 384-387, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: At each iteration, the data structure D is composed of a collection of open subproblems, called 9 Or live nodes [30], active subproblems [57], unexamined nodes <ref> [52] </ref>, frontier nodes [26]. - 4 - openset 10 , an upper bound 11 U , which is the best value found so far, and a feasible solution whose value is U . <p> The leaves of T are solution nodes 14 , which solved directly in a decomposition. Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl <ref> [52] </ref>. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound [24, 52, 53]. <p> Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound <ref> [24, 52, 53] </ref>. <p> There was only one case of detrimental anomaly. Other simulations with the knapsack problem, where the instances randomly generated were hard instances, produced no anomalies [11]. Similar results exist in the literature for the traveling salesperson problem <ref> [50, 51, 52] </ref>, for the vertex-cover problem [58], for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem [35, 47, 54]. These results must be analyzed with some caution. <p> Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory <ref> [29, 41, 52, 55] </ref> Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set of distributed implementation is presented which stress the most important conclusions <p> The sequential algorithm uses an old decomposition heuristic based on the assignment problem, but that does not use the special structure of the TSP [36]. The 30 tested instances were generated randomly from a uniform distribution <ref> [52] </ref>. Distributed strategy R. Corr^ea and A. Ferreira: the synchronous and asynchronous implementations described in their paper approach the question of the relation between the order of selections and the possibility of overlap between communication and computation.
Reference: [53] <author> M. Quinn and N. Deo. </author> <title> An upper bound for the speedup of parallel best-first branch-and-bound algorithms. </title> <journal> BIT, </journal> (26):35-43, 1986. 
Reference-contexts: Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set [57]. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound <ref> [24, 52, 53] </ref>. <p> Intuitively, this partial order may induce bad selections, the asynchronism may vary the number of iterations accomplished, and may also vary the average iteration time with respect to its synchronous counterpart. An upper bound on the speedup is presented in <ref> [53] </ref>. Let level of a subproblem v in T define the number of edges of the shortest path in T from its root to v. In that work, assuming the same time for decomposition of subproblems at a same level of T , they also calculate time bounds.
Reference: [54] <author> C. Roucairol. </author> <title> A parallel branch and bound algorithm for the quadratic assignment problem. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 18, </volume> <year> 1987. </year>
Reference-contexts: Similar results exist in the literature for the traveling salesperson problem [50, 51, 52], for the vertex-cover problem [58], for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem <ref> [35, 47, 54] </ref>. These results must be analyzed with some caution. If the problem possesses a good bound computation scheme producing tight bounds, then parallelizing the subproblem investigation might produce an algorithm which scales poorly and may make meaningful use of only a few processors [7]. <p> More details about the distributed memory implementations can be found in the following subsections, relating each implementation to its corresponding theoretic model. Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory <ref> [54] </ref>, distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory [29, 41, 52, 55] Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the
Reference: [55] <author> K. Schawan, J. Gawkowski, and B. Blake. </author> <title> Process and workload migration for a parallel branch-and-bound algorithm on a hypercube multicomputer. </title> <booktitle> In 1988 ACM Conf. on Lisp and Funct. Prog., </booktitle> <pages> pages 1520-1530. </pages> <publisher> ACM Press, </publisher> <year> 1988. </year>
Reference-contexts: Problem reference Integer linear programming shared memory [6], distributed memory [1] Knapsack distributed memory [9] Quadratic assignment (QAP) shared memory [54], distributed memory [32, 47] Scheduling distributed memory [39] Traveling salesperson (TSP) distributed memory <ref> [29, 41, 52, 55] </ref> Vertex cover (VCP) distributed memory [29, 38] Also, some "industrial strength" implementations, bearing some resemblance to commer cial packages, begin to emerge: Problem reference Mixed integer programming distributed memory [12, 13] In the following, a set of distributed implementation is presented which stress the most important conclusions
Reference: [56] <author> D. R. Smith. </author> <title> Random trees and the analysis of branch and bound. </title> <journal> Journal of the ACM, </journal> <volume> 31(1) </volume> <pages> 163-188, </pages> <year> 1984. </year>
Reference-contexts: Even though parallelism will not be able to overdue the assumed worst case exponential time or memory complexity of those problems (unless an exponential number of processors is used) [8], the average time complexity of heuristic search algorithms for many NP-hard problems is polynomial <ref> [56] </ref> (also, there are some heuristic search algorithms which find suboptimal solutions in polynomial time [59]). Consequently, those parallel systems, possibly with hundreds or thousands of processors, give us the perspective of efficiently solving relatively large instances of NP-hard problems, being a motivation for using parallel processing.
Reference: [57] <author> H. Trienekens. </author> <title> Parallel Branch and Bound Algorithms. </title> <type> PhD thesis, </type> <institution> Erasmus University, Rotterdam, </institution> <year> 1990. </year>
Reference-contexts: The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration <ref> [11, 30, 31, 34, 48, 57] </ref>. Other sources of parallelism exist, but they have not been widely explored [7, 57]. <p> The principle of the (high level) parallelization considered in this report goes in this direction. It consists of concurrently decomposing several subproblems at each iteration [11, 30, 31, 34, 48, 57]. Other sources of parallelism exist, but they have not been widely explored <ref> [7, 57] </ref>. In general terms, the potential to be explored consists of a linear on the number of processors - reduction on the number of iterations and, as a consequence, a linear improvement on the search efficiency of B&B algorithms. <p> Therefore, a distributed memory parallel system, executing a parallel B&B algorithm, incurs a number of overheads, including communication overheads and idle time due to workload imbalance and contention on common data structures. These overheads can degrade the 8 Or problem tree <ref> [57] </ref>. - 3 - performance. As a consequence, several special techniques have been developed to address the problems related to the irregularity of the search tree or of the parallel tree searching process, essentially related to the amount of "necessary" work assigned to each processor. <p> The best feasible solution found so far is kept, as well as its value. At some points of the execution, some subproblems shown not to contain a feasible solution better than the current best known feasible solution are eliminated <ref> [11, 18, 23, 24, 40, 42, 57] </ref>. We call open subproblems 9 the subproblems that contain a feasible solution and that, at any point of the execution, were generated but neither decomposed nor eliminated. <p> At each iteration, the data structure D is composed of a collection of open subproblems, called 9 Or live nodes [30], active subproblems <ref> [57] </ref>, unexamined nodes [52], frontier nodes [26]. - 4 - openset 10 , an upper bound 11 U , which is the best value found so far, and a feasible solution whose value is U . <p> The leaves of T are solution nodes 14 , which solved directly in a decomposition. Let worthwhile subproblem 15 be a subproblem v so that l (v) &lt; f fl [52]. 10 Or liveset [31], active set <ref> [57] </ref>. 11 Or incumbent [31]. 12 Or bounding function [30]. 13 Or least-cost branch-and-bound [30], best-bound-first [31], best-bound [24, 52, 53]. <p> In isoergotic algorithms, the total quantity of work accomplished remains the same in the two cases (sequential and parallel), and e (p) is a good measure of efficiency in this case, since the total amount of work can be computed as p:e (p) <ref> [30, 34, 51, 57] </ref>. The notion of computational parallel efficiency is always related to the idea of velocity of a parallel algorithm, often as a comparative parameter with respect to a sequential counterpart (see section 2).
Reference: [58] <author> B. Wah and Y. Eva. </author> <title> MANIP Amulticomputer architecture for solving combinatorial extremum-search problems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(5):377-390, </volume> <month> May </month> <year> 1984. </year>
Reference-contexts: The difference between these two asynchronous models is the parallel computation model assumed, although both of them imply implementations that are modularly expandable <ref> [9, 58] </ref>. Essentially, the only two informations in a parallel B&B algorithm to be considered by all processors are the value of the current best solution and the heuristic order of open subproblems. The synchronous model uses these global informations. <p> There was only one case of detrimental anomaly. Other simulations with the knapsack problem, where the instances randomly generated were hard instances, produced no anomalies [11]. Similar results exist in the literature for the traveling salesperson problem [50, 51, 52], for the vertex-cover problem <ref> [58] </ref>, for knapsack, integer programming and vertex-cover problem [59], and for the quadratic assignment problem [35, 47, 54]. These results must be analyzed with some caution.

References-found: 58

