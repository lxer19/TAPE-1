URL: http://www.cs.iastate.edu/tech-reports/TR95-02.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: http://www.cs.iastate.edu
Title: An Efficient Interactive Algorithm for Regular Language Learning TR95-02  
Author: Rajesh Parekh Vasant Honavar 
Address: 226 Atanasoff Ames, IA 50011  
Affiliation: Iowa State University of Science and Technology Department of Computer Science  
Date: February 6, 1995  
Abstract-found: 0
Intro-found: 1
Reference: [Angluin, 87] <author> Angluin, D. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Information and Computation, </journal> <volume> 75. </volume> <pages> pp 87-106. </pages>
Reference: [Biermann & Feldman, 72] <author> Biermann, A.W. and Feldman, J.A. </author> <title> A Survey of Results in Grammatical Inference. </title> <editor> In Watanabe S. (editor), </editor> <booktitle> Frontiers of Pattern Recognition. </booktitle> <publisher> Academic Press pp. </publisher> <pages> 31-54. </pages>
Reference-contexts: The equivalent regular grammar is represented by the following production rules: S ! , S ! bS, S ! aA, A ! bS. S stands for the start symbol. 1.2 The Grammar Inference Problem The grammar inference problem <ref> [Biermann & Feldman, 72, Parekh & Honavar, 95] </ref> is defined as follows: For an unknown grammar G, given a finite set of positive examples S + that belong to L (G), and possibly a finite set of negative examples S , infer a grammar G fl equivalent to G.
Reference: [Fu, 82] <author> Fu. </author> <title> K.S. Syntactic Pattern Recognition and Applications. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, N.J. </address> <year> 1982 </year>
Reference-contexts: 1 Introduction Grammar inference is an important machine learning problem with many applications of practical significance in pattern recognition and language acquisition <ref> [Fu, 82, Honavar, 94] </ref>. <p> Regular grammars, although limited in their descriptive power (as compared to context-free and context-sensitive grammars), represent a particularly useful class of formal grammars for practical applications for several reasons including: Every finite grammar is regular; Context-free grammars can be closely approximated by regular grammars <ref> [Fu, 82] </ref>; Regular grammars are probably the most tractable of all formal grammars for machine learning [Natarajan, 92].
Reference: [Giles et al, 91] <author> Giles, C., Chen, D., Miller, H., Sun, G., and Lee, Y. </author> <title> Second-order recurrent neural networks for grammatical inference. </title> <booktitle> In Proceedings of the International Joint conference on Neural Networks 91, </booktitle> <volume> vol. 2, </volume> <pages> pp. 273-281, </pages> <month> July </month> <year> 1991. </year>
Reference: [Gold, 78] <author> Gold, M. </author> <title> Complexity of Automaton Identification from Given Data. </title> <journal> Information and Control, </journal> <volume> 37, </volume> <pages> pp. 302-320, </pages> <year> 1978. </year>
Reference: [Harrison, 65] <author> Harrison, M. </author> <title> Introduction to switching and automata theory. </title> <publisher> McGraw-Hill, </publisher> <address> New York 1965. </address>
Reference-contexts: 0 ; Cg where, W = S fi T, w 0 = (s 0 ; t 0 ) , ffi w ((s,t); ) = (ffi s (s; ); ffi t (t; )) for all 2 and C = f (s,t) j s 2 A and t 2 T - Bg <ref> [Harrison, 65] </ref>. A query of the form "y 2 G ?" is posed to the teacher. Based on the teacher's response fi is pruned and elements of S and G become progressively more general and more specific respectively.
Reference: [Honavar, 94] <author> Honavar, V.G. </author> <title> Toward Learning Systems That Integrate Different Strategies and Representations. In: Artificial Intelligence and Neural Networks: Steps toward Principled Integration. Honavar, </title> <editor> V. & Uhr, L. </editor> <address> (editors) New York: </address> <publisher> Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Grammar inference is an important machine learning problem with many applications of practical significance in pattern recognition and language acquisition <ref> [Fu, 82, Honavar, 94] </ref>.
Reference: [Mitchell, 82] <editor> Generalization as search. </editor> <booktitle> Artificial Intelligence, </booktitle> <volume> 18. </volume> <pages> pp 203-226. </pages>
Reference: [Natarajan, 92] <author> Natarajan, B. K., </author> <title> Machine Learning: A theoretical approach. </title> <publisher> Morgan Kaufmann San Mateo, </publisher> <address> California. </address>
Reference-contexts: to context-free and context-sensitive grammars), represent a particularly useful class of formal grammars for practical applications for several reasons including: Every finite grammar is regular; Context-free grammars can be closely approximated by regular grammars [Fu, 82]; Regular grammars are probably the most tractable of all formal grammars for machine learning <ref> [Natarajan, 92] </ref>. This paper develops an algorithm for learning regular grammars within an active learning framework in which in addition to the sample strings provided by the teacher, the learner uses the teacher's responses to membership queries to efficiently search the space of candidate grammars.
Reference: [Pao & Carr, 78] <author> Pao, T.W.L., and Carr, J.W.III. </author> <title> A solution of the Syntactic Induction-Inference Problem for Regular Languages. </title> <journal> Computer Languages, </journal> <volume> Vol. 3 1978, </volume> <pages> pp. 53-64. 17 </pages>
Reference-contexts: provided by the teacher in the form of answers to queries posed by the learner. 2 Grammar Inference Algorithm The teacher provides a set of positive samples S + which implicitly defines a lattice of candidate grammars or the initial hypothesis space that is guaranteed to contain the unknown grammar <ref> [Pao & Carr, 78, Parekh & Honavar, 93] </ref>. The learner generates strings and queries the teacher about their membership in the unknown grammar G.
Reference: [Parekh & Honavar, 93] <author> Parekh R.G., and Honavar V.G. </author> <title> Efficient Learn--ing of Regular Languages using teacher supplied positive samples and learner generated queries. </title> <institution> Computer Science Department, </institution> <type> Technical Report TR 93-25, </type> <institution> Iowa State University, Ames, Iowa. </institution> <note> (Preliminary version appeared in Proceedings of the 5th UNB AI Syposium, Fredericton, </note> <institution> Canada, </institution> <year> 1993). </year>
Reference-contexts: provided by the teacher in the form of answers to queries posed by the learner. 2 Grammar Inference Algorithm The teacher provides a set of positive samples S + which implicitly defines a lattice of candidate grammars or the initial hypothesis space that is guaranteed to contain the unknown grammar <ref> [Pao & Carr, 78, Parekh & Honavar, 93] </ref>. The learner generates strings and queries the teacher about their membership in the unknown grammar G.
Reference: [Parekh & Honavar, 95] <author> Parekh, R. G. and Honavar, V.G. </author> <title> Grammar Inference for Machine Learning. </title> <note> Paper in preparation. </note>
Reference-contexts: The equivalent regular grammar is represented by the following production rules: S ! , S ! bS, S ! aA, A ! bS. S stands for the start symbol. 1.2 The Grammar Inference Problem The grammar inference problem <ref> [Biermann & Feldman, 72, Parekh & Honavar, 95] </ref> is defined as follows: For an unknown grammar G, given a finite set of positive examples S + that belong to L (G), and possibly a finite set of negative examples S , infer a grammar G fl equivalent to G. <p> Vanlehn and Ball [87] have proposed a version-space approach to learning context-free grammars that returns a set of grammars consistent with the given sample set. Giles et al [91] use recurrent neural networks to learn FSA using positive and negative samples. The interested reader is refered to <ref> [Parekh & Honavar, 95] </ref> for a more detailed discussion of grammar inference techniques for machine learning. In this paper, we have presented a provably correct mechanism for inference of regular grammars given a structurally complete set of samples and a teacher that responds reliably to membership queries.
Reference: [Porat & Feldman, 91] <author> Porat S., and Feldman J.A. </author> <title> Learning Automata from Ordered Examples. </title> <journal> Machine Learning, </journal> <volume> Vol 7, </volume> <pages> pp 109-138. </pages> <year> 1991. </year>
Reference: [Schapire, 91] <author> Schapire, R.E., </author> <title> The Design and Analysis of Efficient Learning Algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1992. </year>
Reference: [Vanlehn & Ball, 87] <author> Vanlehn, K. and Ball, W. </author> <title> A Version Space Approach to Learning Context-Free Grammars. </title> <journal> Machine Learning Vol. </journal> <volume> 2, </volume> <pages> pp 39-74, </pages> <year> 1987. </year>
References-found: 15

