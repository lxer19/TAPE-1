URL: http://rakaposhi.eas.asu.edu/ebljpap.ps
Refering-URL: http://rakaposhi.eas.asu.edu/yochan.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Failure Driven Dynamic Search Control for Partial Order Planners: An Explanation based approach  
Author: Subbarao Kambhampati and Suresh Katukam and Yong Qu 
Address: Tempe, AZ 85287-5406  
Affiliation: Department of Computer Science and Engineering, Arizona State University  
Abstract: Given the intractability of domain-independent planning, the ability to control the search of a planner is vitally important. One way of doing this involves learning from search failures. This paper describes SNLP+EBL, the first implementation of explanation based search control rule learning framework for a partial order (plan-space) planner. We will start by describing the basic learning framework of SNLP+EBL. We will then concentrate on SNLP+EBL's ability to learn from failures, and describe the results of empirical studies which demonstrate the effectiveness of the search-control rules SNLP+EBL learns using our method. We then demonstrate the generality of our learning methodology by extending it to UCPOP [39], a descendant of SNLP that allows for more expressive domain theories. The resulting system, UCPOP+EBL, is used to analyze and understand the factors influencing the effectiveness of EBL. Specifically, we analyze the effect of (i) expressive action representations (ii) domain specific failure theories and (iii) sophisticated backtracking strategies on the utility of EBL. Through empirical studies, we demonstrate that expressive action representations allow for more explicit domain representations which in turn increase the ability of EBL to learn from analytical failures, and obviate the need for domain specific failure theories. We also explore the strong affinity between dependency directed backtracking and EBL in planning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barrett and D.S. Weld. </author> <title> Partial Order Planning: Evaluating Possible Efficiency Gains. </title> <institution> University of Washington, </institution> <type> Technical Report 92-05-01, </type> <year> 1992 </year>
Reference-contexts: It is straightforward to formalize these decisions as STRIPS-type operators whose away, they only accumulate. However, ``flaws'' do go away during planning. This can be reconciled by the fact that flaws go away as constraints are added. 5 Readers familiar with SNLP algorithm in <ref> [1] </ref> will note that by defining a threat in terms of necessary codesignation, rather than possible codesignation, we obviate the need for separation as a way of resolving unsafe links. <p> The rules learned from analytical failures detected by SNLP+EBL were successful in improving performance of SNLP in some synthetic domains (such as D m S 2fl described in <ref> [1] </ref>). Unfortunately however, learning from analytical failures alone turned out to be less useful in many domains. 14 The reason is that often the planner crosses the depth limit, without encountering any failure (see Figure 17).
Reference: [2] <author> N. Bhatnagar. </author> <title> On-line Learning From Search Failures PhD thesis, </title> <institution> Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1992. </year>
Reference-contexts: Although proving that a partial plan is inconsistent is hard, often we may know that the presence of a set of features is losely ``indicative'' of the unpromising nature of the partial plan. For example, 64 FAILSAFE system <ref> [2] </ref> constructs explanations that explicate why the current node is not the goal node, inspite of many refinements. 22 Relaxing soundess requirement on failure explanations will allow UCPOP+EBL to learn with incomplete explanations, thus improving the number of learning opportunities.
Reference: [3] <author> N. Bhatnagar and J. Mostow. </author> <title> On-line Learning From Search Failures Machine Learning, </title> <journal> Vol. </journal> <volume> 15, </volume> <pages> pp. 69-117, </pages> <year> 1994. </year>
Reference: [4] <author> D. Borrajo and M. Veloso. </author> <title> Incremental learning of control knowledge for nonlinear problem solving. </title> <booktitle> In Proc. European Conference on Machine Learning, </booktitle> <year> 1994. </year>
Reference-contexts: In particular, EBL methods can be used to isolate the features of the problem that are relevant to the failure and then inductive methods can be used to generalize over these partial explanations of failure (or success). Borrajo and Veloso <ref> [4] </ref> discuss an approach of this type in the context of a state-space planner, while Estlin and Mooney present a similar method in the context of partial order planning [12].
Reference: [5] <author> S.A. Chien. </author> <title> An Explanation-Based Learning Approach to Incremental Planning. </title> <type> PhD thesis, TR. UIUCDCS-R-90-1646 (Ph.D. Thesis). </type> <institution> Dept. of Computer Science, University of Illinois, Urbana, IL, </institution> <year> 1990. </year> <month> 68 </month>
Reference: [6] <author> S. Chien and G. DeJong. </author> <title> Constructing Simplified Plans via Truth Criteria Approximation. </title> <booktitle> In Proc. 2nd Intl. Conference on Artificial Intelligence Planning Systems (pp. </booktitle> <pages> 19-24), </pages> <month> June </month> <year> 1994. </year>
Reference: [7] <author> K. Currie and A. Tate. O-Plan: </author> <title> The Open Planning Architecture. </title> <journal> Artificial Intelligence, </journal> <volume> 51(1), </volume> <year> 1991. </year>
Reference-contexts: Although there has been a significant amount of work on dependency directed backtracking in the the constraint satisfaction community [48], very little such work has been done in planning. There do exist planning systems, such as OPLAN-2 <ref> [7] </ref>, that claim to use some form of ``intelligent'' backtracking. Typically, such methods are driven by a carefully constructed decision dependency graph (c.f. [8]). The regression and propagation based approach for dependency directed backtracking provides an interesting alternative that does not require explicit construction of decision graphs.
Reference: [8] <author> L. Daniel. </author> <title> Planning: Modifying non-linear plans University Of Edinburgh, </title> <note> DAI Working Paper: 24 </note>
Reference-contexts: There do exist planning systems, such as OPLAN-2 [7], that claim to use some form of ``intelligent'' backtracking. Typically, such methods are driven by a carefully constructed decision dependency graph (c.f. <ref> [8] </ref>). The regression and propagation based approach for dependency directed backtracking provides an interesting alternative that does not require explicit construction of decision graphs. The affinity between dependency directed backtracking and learning has been observed in the CSP literature.
Reference: [9] <author> R. Dechter. </author> <title> Enhancement schemes for learning: Back-jumping, learning and cutset decomposition. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 41, </volume> <pages> pp. 273-312, </pages> <year> 1990. </year>
Reference-contexts: This is not surprising since lack of detectable analytical failures will hurt both the effectiveness of DDB and that of EBL. (Similar relation has been observed in the constraint satisfaction literature between back-jumping and learning <ref> [9] </ref>). What is interesting is that EBL is able to outperform DDB at least in some cases. Specifically, in the case of the LIFO goal selection strategy, control rules do bring out significant additional savings over DDB (see Table 3).
Reference: [10] <author> G. DeJong and R. Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2):145 -- 176, </volume> <year> 1986. </year>
Reference: [11] <author> M. Drummond and K. Currie. </author> <title> Exploiting Temporal coherence in nonlinear plan construction. </title> <journal> Computational Intelligence, </journal> <volume> 4(2) </volume> <pages> 341-348, </pages> <year> 1988. </year>
Reference-contexts: When such looping makes SNLP cross depth-limit, SNLP+EBL uses the npconditions based consistency check, to detect and explain this implicit failure, and learn from that explanation. To keep the consistency check tractable, SNLP+EBL utilizes a restricted representation for domain axioms (first proposed in <ref> [11] </ref>): each domain axiom is represented as a conjunction of literals, with a set of binding constraints. The table below lists a set of domain axioms for the blocks world.
Reference: [12] <author> T. Estlin and R. Mooney. </author> <title> Hybrid Learning of Search Control for Partial-order planning. </title> <booktitle> In Proc. 3rd European Workshop on Planning, </booktitle> <year> 1995. </year>
Reference-contexts: Borrajo and Veloso [4] discuss an approach of this type in the context of a state-space planner, while Estlin and Mooney present a similar method in the context of partial order planning <ref> [12] </ref>. It would be interesting to see how such hybrid methods can be adapted to UCPOP+EBL. 22 It is tempting to use the complete description of the unpromising plan as its own explanation of failure. However, this can seriously inhibit any useful learning from taking place.
Reference: [13] <author> O. Etzioni. </author> <title> Acquiring search control knowledge via static analysis Artificial Intelligence, </title> <journal> Vol. </journal> <volume> 62, No. 2, </volume> <year> 1993. </year>
Reference-contexts: In particular, it is theoretically possible to derive equivalent (and some times more general) search control knowledge by simply analyzing the domain theory used by the problem solver. Such static analyses have been the basis of some EBL systems, such as the PRODIGY/STATIC system by Etzioni <ref> [13] </ref>. This system analyzes a structure called the ``Problem Space Graph (PSG)'' -- which is a graphical structure capturing the precondition/effect dependencies between the actions in the domain -- to detect necessary interactions between different types of subgoals.
Reference: [14] <author> O. Etzioni. </author> <title> A structural theory of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 60, No. 1, </volume> <year> 1993. </year>
Reference-contexts: It would be interesting to see how our dynamic search control rule learning methods for partial order planning, can be integrated with the operator graph methods such as those being developed by Smith and Peot [47]. In <ref> [14] </ref>, Etzioni also develops a structural theory of EBL that attempts to explain what features of the problem spaces (domains) are predictive of the effectiveness of EBL. Our work complements and extends this theory in several directions. <p> Their conclusions are similar to those we reached in our experiments (Section 10.4). In <ref> [14] </ref>, Etzioni hypothesizes that DDB reduces the impact of EBL, but leaves the verification of the hypothesis for future work. Our experimental results in Section 10.4 can be seen as a partial confirmation and refinement of Etzioni's hypothesis.
Reference: [15] <author> O. Etzioni and R. Etzioni. </author> <title> Statistical methods for analyzing speedup learning experiments. </title> <journal> Machine Learning, </journal> <volume> Vol 14, </volume> <year> 1994. </year>
Reference-contexts: Figure 20 shows the cumulative performance graphs for the three methods in the second test set. Our results clearly show that SNLP+EBL was able to outperform SNLP significantly on these problem populations (p-value for this was .24 for sign test and .00 for signed rank test <ref> [15] </ref>). A closer analysis of the second set revealed that SNLP+EBL outperformed SNLP in 36 problems, resulting in a cumulative saving of 3,587 cpu. sec. SNLP on the other hand outperformed SNLP+EBL in 43 instances, but the cumulative difference in this case was a mere 27 sec.
Reference: [16] <author> D. Frost and R. Dechter. </author> <title> Dead-end driven learning. </title> <booktitle> In Proc. AAAI-94, </booktitle> <year> 1994. </year>
Reference: [17] <author> L. Ihrig and S. Kambhampati. </author> <title> Integrating EBL with Replay to improve planning performance. </title> <booktitle> In Proc. 3rd European Planning Workshop, </booktitle> <year> 1995. </year>
Reference-contexts: Since partial order planner do not need to backtrack on goal ordering decisions, target concepts based on subgoal interactions are not relevant for SNLP+EBL and UCPOP+EBL. While learning from successes is important, we believe that macro learning strategies such as reuse and replay are more effective in doing this <ref> [17] </ref> (see Section 11.2). Interaction between Learner and planner: In PRODIGY+EBL, the learning starts after the planning phase is completed. In contrast, both FAILSAFE, and our systems SNLP+EBL, UCPOP+EBL do on-line learning, where the learning component is activated any time the planner encounters a failure. <p> In particular, it is possible to use similar analyses in conjunction with other types of speedup learning frameworks, such as plan reuse and/or replay. As an example, recently, we adapted the SNLP+EBL framework to learn to improve case-retrieval based on previous replay failures <ref> [17] </ref>. 11.3 Relation to speedup learning methods that use static analyses Although most EBL systems base their learning on the experiences of the underlying problem solver, this is not always required.
Reference: [18] <author> M. Ginsberg and D. McAllester. </author> <title> GSAT and Dynamic Backtracking. </title> <booktitle> In Proc. </booktitle> <address> KRR, </address> <year> 1994. </year>
Reference-contexts: In [43], we also discuss the relations between DDB as presented here, and many other intelligent backtracking schemes, including dynamic backtracking <ref> [18] </ref>. 11.5 Effect of the default search strategy on performance of EBL The discussion about the effect of sophisticated backtracking strategies on the impact of EBL brings to fore the more general issue of the impact of the default search strategy used by the planner on the effectiveness of EBL.
Reference: [19] <author> M. Goldszmidt, A. Darwiche, T. Chavez, D. Smith and J. </author> <title> White. </title> <institution> Decision-theory for Crisis Management ROME Laboratory Technical Report, RL-TR-94-235. </institution> <year> 1994. </year>
Reference-contexts: There are also some differences between PSGs and operator graphs in terms of when the construction is terminated. 61 operator graphs can provide a variety of search control strategies for partial order planners <ref> [19, Section 3] </ref>, including analysis on which types of unsafe link conflicts can be postponed indefinitely, thereby improving performance of the planner.
Reference: [20] <author> J .Gratch and G. DeJong COMPOSER: </author> <title> A Probabilistic Solution to the Utility problem in Speed-up Learning. </title> <booktitle> In Proc. AAAI 92, </booktitle> <address> pp:235--240, </address> <year> 1992 </year>
Reference-contexts: To prune rules of questionable utility, PRODIGY+EBL tracks the usage statistics associated with the control rules, including the application frequency, match cost and reduction in search entailed by the rule, when it is applicable. More recent work such as that by Gratch and DeJong <ref> [20] </ref> provides a sound statistical basis for such utility models. SNLP+EBL and UCPOP+EBL currently do not use any sophisticated models for tracking the utility of learned rules. <p> We believe however that as the complexity of the domains increase, the utility models such as those developed in <ref> [20] </ref> can be profitably adapted to our EBL framework (see Section 12.1). 11.2 Relation to EBL methods that do not learn search control rules Although our work is the first to adapt failure based search control rule learning to partial order planning, the general explanation based generalization framework has been applied <p> We believe however that the existing approaches to utility management in EBL will still be applicable for UCPOP+EBL. It would be interesting to integrate the rule utility monitoring approaches such as those embodied in the COMPOSER system <ref> [20] </ref> into UCPOP+EBL. The framework for EBL and DDB, presented in this paper, applies with very little changes to constraint satisfaction problems. In particular, in [43], we adapt our framework to general refinement search, which subsumes many models of planning and constraint satisfaction problems.
Reference: [21] <author> D. Joslin and M. Pollack. </author> <title> Least-cost flaw repair: A plan refinement strategy for partial order planning. </title> <booktitle> Proceedings of AAAI-94, </booktitle> <year> 1994. </year>
Reference-contexts: In our current implementation, we simply avoid learning from any failure branches corresponding to uninstantiated goals. Fortunately, efficient planning anyway demands that the planner prefer working on maximally instantiated open conditions since such goals will have least number of possible establishment branches <ref> [21] </ref>. Therefore, this restriction does not seem to affect the efficiency of the learner. <p> Since it is well-known that the performance of a plan-space planner depends critically on the order in which open condition flaws are handled (goal selection order) <ref> [21] </ref>, we experimented with two goal-selection strategies -- one which corresponds to a LIFO strategy and one that works on goals with the least number of variables left uninstantiated, called MIGF strategy. 19 19 Since partially instantiated goals have larger number of establishment possibilities, this goal selection strategy approximates the least-cost <p> two goal-selection strategies -- one which corresponds to a LIFO strategy and one that works on goals with the least number of variables left uninstantiated, called MIGF strategy. 19 19 Since partially instantiated goals have larger number of establishment possibilities, this goal selection strategy approximates the least-cost flaw refinement strategy, <ref> [21] </ref> 53 Domain I. Scratch II. with analytical failures III. with dom. spec. fail. theories % Solv cpu Solv cpu rules. % Solv cpu rules.
Reference: [22] <author> S. Kambhampati and S. Kedar. </author> <title> Explanation-based generalization of partially ordered plans. </title> <booktitle> In Proc. AAAI-91, </booktitle> <pages> pp. </pages> <address> 679--685, </address> <month> July </month> <year> 1991. </year>
Reference: [23] <author> S. Kambhampati and J.A. Hendler. </author> <title> during Plan reuse. Controlling refitting during Plan reuse In Proc. </title> <booktitle> IJCAI-89, </booktitle> <year> 1989. </year> <month> 69 </month>
Reference: [24] <author> S. Kambhampati and S. Kedar. </author> <title> A unified framework for explanation-based generalization of partially ordered and partially instantiated plans. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 67, No. 1, </volume> <pages> pp. 29-70, </pages> <year> 1994. </year>
Reference-contexts: Kambhampati and Kedar <ref> [24] </ref> 60 describe how partial order plans can be generalized in a variety of ways based on their explanations of success. Similar methods were also developed independently by Chien and DeJong [5,6].
Reference: [25] <author> S. Kambhampati, C. Knoblock and Q. Yang. </author> <title> Planning as Refinement Search: A Unified framework for evaluating design tradeoffs in partial order planning. </title> <note> ASU-CSE-TR 94-002. To appear in Artificial Intelligence special issue on Planning and Scheduling. </note> <year> 1995. </year>
Reference-contexts: The steps, effects, bindings, orderings, causal links, and preconditions can all be seen as constraints on the partial plan in that they constrain the set of solution plans consistent with the partial plan. (For more on the semantics of partial plans, see <ref> [25] </ref>). 3 The original description if SNLP [30] also ensures that no intervening step can delete all the condition supported by the causal link. This is however not required for completeness [25]. 3.2 The planning process SNLP starts its planning process with the ``null'' plan * S: fs 0 ; s <p> the set of solution plans consistent with the partial plan. (For more on the semantics of partial plans, see <ref> [25] </ref>). 3 The original description if SNLP [30] also ensures that no intervening step can delete all the condition supported by the causal link. This is however not required for completeness [25]. 3.2 The planning process SNLP starts its planning process with the ``null'' plan * S: fs 0 ; s 1 g; O: fs 0 s 1 g; C: fg i @s 1 jg i 2 goal stateg; E: fs ! je 2 initial stateg; L: ; + where C is
Reference: [26] <author> S. Kambhampati. </author> <title> Admissible Pruning strategies based on plan minimality for plan-space planning. </title> <booktitle> In Proc. IJCAI-95, </booktitle> <year> 1995. </year>
Reference-contexts: An important reason for this turns out to be that, in many cases, SNLP goes into an unpromising branch and continues adding locally useful, but globally useless constraints (steps, orderings, bindings) to the plan, without making any progress towards a solution <ref> [26] </ref>. An example here might help to see why SNLP gets into infinite loops. In Figure 18, SNLP achieves On (A; B) at G by establishing it from initial state. <p> Recently, we showed that much of the looping in partial order planning can be tied to production of non-minimal plans (i.e., plans with redundant steps), and developed conditions under which such pruning strategies do not lead to loss of completeness <ref> [26] </ref>. We are currently investigating if it is possible to learn effective search control rules from such pruning techniques. The second approach for improving the chances of failure detection is to relax the requirement for soundness of failure explanations.
Reference: [27] <author> S. Kambhampati and B. Srivastava. </author> <title> Universal Classical Planner: An Algorithm for unifying state-space and plan-space planning. </title> <booktitle> In Proc. 3rd European Workshop on Planning Systems, </booktitle> <year> 1995. </year>
Reference-contexts: The primary difference between these efforts and our work is that we adapt EBL to plan-space planners. In some ways, the SNLP+EBL/UCPOP+EBL frameworks can be seen as a generalization of the EBL techniques for state space planning. In particular, recent work <ref> [27] </ref> shows that partial order and state space planning approaches can be cast and combined in a single refinement planning framework, that is not very different from the one used in this paper.
Reference: [28] <author> S. Katukam and S. Kambhampati. </author> <title> Learning explanation based search control rules for partial order planning. </title> <booktitle> In Proc. AAAI-94, </booktitle> <year> 1994. </year>
Reference-contexts: Furthermore, as discussed elsewhere, the ability of EBL to learn control rules crucially depends on detecting and explaining failures in the partial plans before they cross depth limits <ref> [28] </ref>. This in turn depends on the nature of the domain theory (viz, how much information is left implicit and how much is represented explicitly), and the availability of domain specific theories of failure (c.f. [28,2]).
Reference: [29] <author> S. Katukam. </author> <title> Learning EBL Based Search Control Rules for Partial Order Planni ng Masters Thesis, </title> <institution> Arizona State University, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: While this can be done (see <ref> [29] </ref>), it turns out to be more cumbersome than is necessary for our purposes.
Reference: [30] <author> D. McAllester and D. </author> <title> Rosenblitt Systematic Nonliner Planning In Proc. </title> <booktitle> AAAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: The steps, effects, bindings, orderings, causal links, and preconditions can all be seen as constraints on the partial plan in that they constrain the set of solution plans consistent with the partial plan. (For more on the semantics of partial plans, see [25]). 3 The original description if SNLP <ref> [30] </ref> also ensures that no intervening step can delete all the condition supported by the causal link. <p> This discussion will also demonstrate that it is relatively straightforward to extend our framework to other plan space planners. Like SNLP <ref> [30] </ref>, UCPOP [39] searches in a space of partial plans, refining (adding constraints to) a partial plan until it becomes a complete solution to the planning problem.
Reference: [31] <author> S. Minton. </author> <title> Learning Effective Search Control Knowledge: An Explanation- Based Approach. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1988. </year>
Reference-contexts: Another reason is that since we only learn rejection rules based on search failures, in general we have fewer search control rules compared to planners such as PRODIGY <ref> [31] </ref> that learn from a variety of target concepts. 5 On the Soundness of Search control rules learned by SNLP+EBL As explained in chapter 4.6, a rule is said to be sound if it does not affect the completeness of the underlying planner. <p> The problems all had randomly generated initial states consisting of 3 to 8 blocks (using the procedure outlined in Minton's thesis <ref> [31] </ref>). The first test set contained 30 problems all of which had random 3-block stacks in the goal state. The second test set contained 100 randomly generated goal states (using the procedure in [31]) with 2 to 6 goals . <p> randomly generated initial states consisting of 3 to 8 blocks (using the procedure outlined in Minton's thesis <ref> [31] </ref>). The first test set contained 30 problems all of which had random 3-block stacks in the goal state. The second test set contained 100 randomly generated goal states (using the procedure in [31]) with 2 to 6 goals . For each test set, the planner was run on a set of randomly generated problems drawn from the same distribution (20 for the first set and 50 for the second). <p> We generated 100 random problems containing between 3 to 5 objects, 3 to 5 locations and between 3 to 5 goal conjuncts. The second domain is the blocks world domain called BW-quant described in Figure 21. We generated 100 random problems using the procedure described in <ref> [31] </ref>. The problems contained between 3 to 6 blocks, and 3 to 4 goals. In each domain, we compared the performance of the from-scratch planner with that of the planner using the search control rules generated by UCPOP+EBL. Table 2 shows the results of these experiments. <p> Two such systems are closely related to our work. The first, PRODIGY+EBL, was developed by Minton <ref> [31] </ref> . It learns 58 search control rules and improves performance of a state-space planer using means ends analysis. The second, FAILSAFE, was developed by Bhatnagar and Mostow [2,3]. It learns search control rules for a forward searching state-space planner.
Reference: [32] <author> S. Minton, J.G Carbonell, Craig A. Knoblock, D.R. Kuokka, Oren Etzioni and Yolanda Gil. </author> <title> Explanation-Based Learning: A Problem Solving Perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40:63--118, </volume> <year> 1989. </year>
Reference-contexts: One of the reasons for the concentration of explanation based learning (EBL) work on state-space planners has been the concern that a sophisticated planner may make the learning component's job more difficult (c.f. <ref> [32] </ref>). However, given the current status of plan-space planning as the dominant planning paradigm, it is important to adapt the speed-up learning techniques to the plan-space planners. In this paper we present an explanation based learning framework for a partial order plan-space planner, that is both clean and elegant.
Reference: [33] <author> S. Minton. </author> <title> Quantitative Results Concerning the Utility of Explanation Based Learning Artificial Intelligence, </title> <address> 42:363--391, </address> <year> 1990. </year>
Reference: [34] <author> S. Minton, J. Bresina and M. Drummond. </author> <title> Total Order and Partial Order Planning: a comparative analysis. </title> <note> Journal of Artificial Intelligence Research 2 (1994) 227-262. </note>
Reference: [35] <author> T. M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli. </author> <title> Explanation-based learning: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1):47 -- 80, </volume> <year> 1986. </year>
Reference-contexts: This method can be shown to produce the same 31 results as the 2-pass generalization methods used by the EBG systems <ref> [35] </ref>. To see how this works, consider the example of attempting to achieve :Clear (T able). Suppose we are using the name sensitive P uton operator in Figure 16.
Reference: [36] <author> N.J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga, </publisher> <address> Palo Alto, </address> <year> 1980. </year>
Reference-contexts: The domain operators are specified in the STRIPS operator formalism <ref> [36] </ref>, involving precondition, add and delete lists. Typically, a family of operators are specified compactly as an operator schema, such that any instance of the schema gives rise to a legal operator. Figure 3 shows the example of an operator schema, P uton (x; y; z) in blocks world. <p> that must be present in the partial plan before the decision d, such that c is present after taking the decision. 9 Regression of this type is typically studied in planning in conjunction with backward application of STRIPS-type operators (with add, delete, and precondition lists), and is quite well-understood (see <ref> [36] </ref>).
Reference: [37] <author> E.P.D. Pednault. </author> <title> Synthesizing Plans that contain actions with Context-Dependent Effects. </title> <journal> Computational Intelligence, </journal> <volume> Vol. 4, </volume> <month> 356-372 </month> <year> (1988). </year>
Reference-contexts: This in turn may require extensions to the EBL framework. In the following sections, we shall discuss these differences in detail and explain the 18 UCPOP, which is based on Pednault's ADL theory of planning, <ref> [37] </ref>, does not allow non-deterministic postconditions. <p> While the preconditions of an operator should be true for it to be applicable, a particular effect [prec ; ef f ect] will be true only when the antecedent conditions prec are true in the state proceeding the operator (these are thus called the secondary preconditions; <ref> [37] </ref>). As a special case, we can think of non-conditional effects used by SNLP as effects with secondary precondition ``True''. The presence of conditional effects has direct ramifications on establishment and threat resolution processes of the planner.
Reference: [38] <author> E.P.D. Pednault. </author> <title> Generalizing nonlinear planning to handle complex goals and actions with context dependent effects. </title> <booktitle> In Proc. IJCAI-91, </booktitle> <year> 1991. </year>
Reference: [39] <author> J.S. Penberthy and D. Weld. UCPOP: </author> <title> A Sound, Complete, Partial Order Planner for ADL. </title> <booktitle> In Proc. </booktitle> <address> KR-92, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: This discussion will also demonstrate that it is relatively straightforward to extend our framework to other plan space planners. Like SNLP [30], UCPOP <ref> [39] </ref> searches in a space of partial plans, refining (adding constraints to) a partial plan until it becomes a complete solution to the planning problem.
Reference: [40] <author> M.A. Peot and D.E. Smith. </author> <title> Threat-Removal Strategies for Nonlinear Planning. </title> <booktitle> In Proc. Eleventh AAAI, </booktitle> <year> 1993. </year> <month> 70 </month>
Reference-contexts: Empirical studies <ref> [40] </ref> show that this strategy tends to improve the efficiency of SNLP. 10 Demote (s 1 :p 00 p 0 Resolve the conflict between the link s 2 p 0 ! s 3 and the effect p 00 of step s 1 Preconditions:s 2 p 0 s 1 ! 2 E
Reference: [41] <author> A. Perez and O. Etzioni. </author> <title> DYNAMIC: A new role for training problems in EBL. </title> <booktitle> In Proc. of 9th Intl. Machine Learning Conference, </booktitle> <year> 1992. </year>
Reference-contexts: It is not clear whether this type of analysis can be extended to learn simple establishment possibilities, such as the first rule in Figure 19. As Etzioni points out <ref> [41] </ref>, both static and dynamic search control rule learning methods have their advantages. <p> For example, while static methods can improve the performance of the planner before the first failure is even encountered, the dynamic methods have the ability to exploit the problem distribution and the default behavior of the problem solver. Etzioni and Perez <ref> [41] </ref> describe a way of combining static and dynamic analyses to exploit both their advantages. There has been some work on using PSG-like structures in partial order planning.
Reference: [42] <author> Y. Qu and S. Kambhampati. </author> <title> Learning control rules for expressive planners: Factors influencing performance. </title> <booktitle> In Proc. 3rd European Planning Workshop, </booktitle> <year> 1995. </year>
Reference: [43] <author> S. Kambhampati. </author> <title> Formalizing Dependency directed backtracking and explanation based learning in refinement search. </title> <type> ASU CSE Tech. Report 96-001, </type> <year> 1996. </year>
Reference-contexts: Sadeh et. al. [46] discuss a variety of techniques for improving DDB, including changing the flaw resolution order such that the flaw whose resolution lead to the latest failure is tried first after DDB (this is an instance of the ``fail-first'' principle [48]). In <ref> [43] </ref>, we also discuss the relations between DDB as presented here, and many other intelligent backtracking schemes, including dynamic backtracking [18]. 11.5 Effect of the default search strategy on performance of EBL The discussion about the effect of sophisticated backtracking strategies on the impact of EBL brings to fore the more <p> It would be interesting to integrate the rule utility monitoring approaches such as those embodied in the COMPOSER system [20] into UCPOP+EBL. The framework for EBL and DDB, presented in this paper, applies with very little changes to constraint satisfaction problems. In particular, in <ref> [43] </ref>, we adapt our framework to general refinement search, which subsumes many models of planning and constraint satisfaction problems.
Reference: [44] <author> Y. Qu. </author> <title> Learning Search control Rules for Plan-space Planners: </title> <type> Factors Affecting the Performance Masters Thesis, </type> <institution> Arizona State University, </institution> <month> June </month> <year> 1995. </year>
Reference: [45] <author> S. Russell and P. Norvig. </author> <booktitle> Artificial Intelligence: </booktitle> <publisher> A Modern Approach Prentice Hall, </publisher> <year> 1995. </year>
Reference: [46] <author> N. Sadeh, K. Sycara and Y. Xiong. </author> <title> Backtracking techniques for job shop scheduling constraint satisfaction problem. </title> <journal> Artificial Intelligence, </journal> <volume> Vol 76, </volume> <month> July </month> <year> 1995. </year>
Reference-contexts: It is also possible to exploit the DDB component of UCPOP+EBL more effectively than we did in the current work. Sadeh et. al. <ref> [46] </ref> discuss a variety of techniques for improving DDB, including changing the flaw resolution order such that the flaw whose resolution lead to the latest failure is tried first after DDB (this is an instance of the ``fail-first'' principle [48]).
Reference: [47] <author> D.E. Smith and M.A. </author> <title> Peot Postponing Threats in Partial-Order Planning. </title> <booktitle> In Proc. AAAI-93, </booktitle> <address> pp:500--506, </address> <year> 1993. </year>
Reference-contexts: Etzioni and Perez [41] describe a way of combining static and dynamic analyses to exploit both their advantages. There has been some work on using PSG-like structures in partial order planning. Smith and Peot <ref> [47] </ref> propose structures called ``Operator Graphs.'' 21 , and show that 20 It is not clear from Etzioni's papers whether the goal-ordering rules or the operator rejection rules had more effect on the performance of PRODIGY. 21 Unlike PSGs, that are domain-specific, the operator graphs are problem-specific, and are constructed for <p> It would be interesting to see how our dynamic search control rule learning methods for partial order planning, can be integrated with the operator graph methods such as those being developed by Smith and Peot <ref> [47] </ref>. In [14], Etzioni also develops a structural theory of EBL that attempts to explain what features of the problem spaces (domains) are predictive of the effectiveness of EBL. Our work complements and extends this theory in several directions.
Reference: [48] <author> E. Tsang. </author> <title> Foundations of Constraint Satisfaction, </title> <publisher> (Academic Press, </publisher> <address> San Diego, California, </address> <year> 1993). </year> <month> 71 </month>
Reference-contexts: Although there has been a significant amount of work on dependency directed backtracking in the the constraint satisfaction community <ref> [48] </ref>, very little such work has been done in planning. There do exist planning systems, such as OPLAN-2 [7], that claim to use some form of ``intelligent'' backtracking. Typically, such methods are driven by a carefully constructed decision dependency graph (c.f. [8]). <p> Sadeh et. al. [46] discuss a variety of techniques for improving DDB, including changing the flaw resolution order such that the flaw whose resolution lead to the latest failure is tried first after DDB (this is an instance of the ``fail-first'' principle <ref> [48] </ref>).
References-found: 48

