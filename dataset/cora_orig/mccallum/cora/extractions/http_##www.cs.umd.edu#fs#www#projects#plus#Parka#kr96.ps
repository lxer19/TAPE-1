URL: http://www.cs.umd.edu/fs/www/projects/plus/Parka/kr96.ps
Refering-URL: http://www.cs.umd.edu/users/mtaylor/
Root-URL: 
Email: stoffel,mtaylor,hendler@cs.umd.edu  
Title: Parka-db: Integrating knowledge- and data-based technologies  
Author: Kilian Stoffel, Merwyn Taylor, and James Hendler 
Note: This research was supported in part by grants from NSF(IRI-9306580), ONR (N00014-J-91-1451), AFOSR (F49620-93-1-0065), the ARPA/Rome Laboratory Planning Initiative (F30602-93-C-0039, DABT-63-95-C-0037), the ARPA I3 Initiative (N00014-94-10907). Dr. Hendler is also affiliated with the UM Institute for Systems Research (NSF Grant NSF EEC 94-02384).  
Address: Colloge Park, Maryland 20742  
Affiliation: Department of Computer Science University of Maryland  
Abstract: Keywords: Implemented KR&R Systems: Reports, Evaluations, Updates, and (Parallel and Distributed Implementations) Abstract Real world applications are demanding that KR systems provide support for knowledge bases containing millions of assertions. We present Parka-db, a high-performance reimplementation of the Parka KR language which uses a standard relational DBMS. The integration of a DBMS and the Parka KR language allows us to efficiently support complex queries on extremely large KBs using a single processor, as opposed to our earlier massively parallel system. In addition, the system can make good use of secondary memory, with the whole system needing less than 16MB of RAM to hold a KB of over 2,000,000 assertions. We demonstrate empirically that this reduction in primary storage requires only about 10% overhead in time, and decreases the load time of very large KBs by more than two orders of magnitude. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Proceedings of the 12th National Conference of the American Association for Artificial Intelligence. </institution> <address> AAAI Press, </address> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference: [2] <author> W. Andersen, M. Evett, J. Hendler, and B. Kettler. </author> <title> Massively Parallel Matching of Knowledge Structures. </title> <booktitle> Massively Parallel Artificial Intelligence. </booktitle> <publisher> AAAI/MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: This reduces the size of the inheritance scans (thus reducing the KB inferencing times) and also reduces the size of the relational joins (reducing the DB times). A CM-5 multiprocessor version of Parka <ref> [2] </ref> used heuristics to do just this sort of optimization, and we believe we can duplicate this work in the new framework at the cost of only a minimal amount of additional preprocessing time.
Reference: [3] <author> A. Barak, O. Laden, and Y. Yarom. </author> <title> The now mosix and its preemptive process migration scheme. </title> <journal> Bulletin of the IEEE Technical Committee on Operating Systems and Application Environments, </journal> <volume> 7(2) </volume> <pages> 5-11, </pages> <year> 1995. </year>
Reference-contexts: In addition, we have recently prototyped a version of Parka's inferencing algorithms on the distributed Mosix system developed at Hebrew University <ref> [3] </ref> with speedups through more than 12 processors on an ethernet-based system. We are now working on porting Parka-db to both parallel and distributed systems, and expect to see similar speedups.
Reference: [4] <author> A. Borgida and P.F. Patel-Schneider. </author> <title> A semantics and complete algorithm for subsumption in the classic description logic. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1, </volume> <year> 1994. </year>
Reference-contexts: While it is difficult to exactly compare KR languages, a very loose categorization would put Parka as more expressive than Classic <ref> [4] </ref>, due to the presence of exception handling, although slightly less expressive than Loom [15] due to the lack of extensive numerical capabilities. A full description of the language, and more details on past results can be found in http://www.cs.umd.edu/projects/plus/Parka.
Reference: [5] <author> Paolo Bresciani. </author> <title> The challenge of integrating knowledge representation and databases. </title> <booktitle> In KARP-95 Second International Symposium on Knowledge Acquisition, Representation and Processing, </booktitle> <pages> pages 16-18. </pages> <institution> Auburn University, AL, USA, </institution> <year> 1995. </year> <note> Extended version in IRST TR 9412-06, IRST, </note> <institution> Povo TN (Italy). </institution>
Reference-contexts: general exceptions (i.e. cancellation links) is exponentially hard, we've demonstrated that IDO with multiple inheritance exceptions can be computed in polynomial time and is efficiently parallelizable [18]. 2 lar, it has been noted that data mining systems can benefit from the use of KBs to provide semantic information for datamining <ref> [5] </ref>. We are exploiting this sort of information by using medical knowledge in the datamining of an OB-Gyn patient database containing records on over 20,000 patients.
Reference: [6] <author> M. Evett, J. Hendler, and L. Spector. </author> <title> Parallel knowledge representation on the connection machine. </title> <journal> International Journal of Parallel and Distributed Computing, </journal> <volume> 22(2), </volume> <year> 1994. </year>
Reference-contexts: One of the key features of Parka is that it has been shown to efficiently handle its inferencing on KBs containing millions of assertions. Early work on the system gained most of its efficiency through massive parallelism <ref> [6] </ref>, however in recent years we've made increasing use of database management techniques to remove the need for parallelism (although still allowing for efficient parallelization). The version we describe in this paper uses DBMS technologies to support inferencing and data management. <p> A CM-5 multiprocessor version of Parka [2] used heuristics to do just this sort of optimization, and we believe we can duplicate this work in the new framework at the cost of only a minimal amount of additional preprocessing time. Secondly, Parka was originally designed for parallel supercomputing environments <ref> [6] </ref> and the algorithms have been proven to scale well to a wide range of supercomputing systems [19] guaranteeing a parallel efficiency better than 50% up to 16 processors for the case-bases described in this paper.
Reference: [7] <author> T.R. Gruber. </author> <title> A translation approach to portable ontology specifications. </title> <journal> Knowledge Acquisition, </journal> <volume> 5(2) </volume> <pages> 199-220, </pages> <year> 1993. </year>
Reference-contexts: However, this excuse is no longer valid. Current research has resulted in the development of extremely large KBs including not only the "common sense" KB of Lenat's CYC [14], but also (much larger) KBs including machine-readable dictionaries [13], large ontologies <ref> [7] </ref>, and very large case-bases for AI planning systems [12]. Despite this, most of the current KR systems are not able to accommodate these KBs, which may contain millions of assertions about many thousands of objects.
Reference: [8] <editor> Kenneth Haase. Framer. In A. Cohn, editor, </editor> <booktitle> Proceedings of the 11th Eu-ropean Conference on Artificial Intelligence. </booktitle> <publisher> John Wiley & Sons, </publisher> <address> Chich-ester, New York, </address> <year> 1994. </year>
Reference-contexts: The IDI (Intelligent Database Interface) project [16] can also be viewed in a similar manner, although that work is meant to deal more with access to distributed DBs then as a KR system per se. Another system dealing with disk-based knowledge is Haase's Framer system <ref> [8] </ref>. Framer is an object oriented storage system designed to be used to implement a KR system. The system provides the basic routines for simple inferencing mechanisms, but provides neither a full KR language nor the sort 10 of conjunctive querying provided by Parka-db.
Reference: [9] <author> J. Hendler, K. Stoffel, and A. Mulvehill. </author> <title> High Performance Support for Case-Based Planning Applications. Advanced Planning Technology. </title> <publisher> MIT/AAAI Press, </publisher> <address> Menlo Park, CA., USA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: The Caper KBs, the largest of which contains over 2,000,000 assertions, are described later in this paper (section 4). Parka is also being used to support a logistics planning project, jointly being developed with MITRE Corp. <ref> [9] </ref>, with a KB currently containing over 250,000 assertions. * A recent project involves the use of Parka as a hybrid knowledge and database for storing and retrieving designs and process plans for mechanical products, as part of ongoing effort to develop a new hybrid variant/generative approach to process planning in
Reference: [10] <author> J.F. Horty, R.H. Thomason, and D.S. Touretzky. </author> <title> A skeptical theroy of inheritance in nonmonotonic semantic networks. </title> <type> Technical Report CMU-CS-87-175, </type> <institution> Carnegie Mellon, Department of Computer Science, </institution> <address> Pittsburgh, PA, USA, </address> <month> Oct. </month> <year> 1987. </year>
Reference-contexts: Property values can themselves be frames, or alternatively can be string, numeric values, or specialized data structures (used primarily in the implementation). The language allows exceptions, in the form of multiple-inheritance, and provides extremely efficient (and efficiently parallelizable) algorithms for performing inheritance using a true inferential-distance-ordering calculation <ref> [10] </ref>. 1 Parka has also been shown to effectively compute recognition, and also to handle extremely complex "structure matching" queries a class of conjunctive queries relating a set of variables and constraints and unifying these against the larger KB.
Reference: [11] <author> Peter D. Karp and Suzanne M. Paley. </author> <title> Knowledge representation in the large. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 751-758. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1995. </year>
Reference-contexts: In particular, each assertion type is associated with a relational table in Parka-rel. Frames in Parka-db thus have their information distributed amongst several tables. This contrasts with other attempts to use database technology for supporting knowledge bases (see section 5). Other systems <ref> [11, 16] </ref> store frames in a much more centralized manner they attempt to gather as much information about a frame as possible when loading data from external storage. Parka-db only loads into memory that information which is needed for processing a query. <p> In addition, significantly faster loading times are an added benefit for the databased reimplementation. 5 Related Work Several research projects have dealt with the use of secondary storage to support large frame- based systems. Karp and Paley <ref> [11] </ref> discuss integrating database storage technology into KR systems. They pull in much data about individual frames, rather than distributing the frames as we discussed earlier. Thus, their system functions more as a "persistent store" than as a query system such as ours.
Reference: [12] <author> Brian B. Kettler. </author> <title> Case-based Planning with High-Performance Parallel Memory. </title> <type> PhD thesis, </type> <institution> University of Maryland, College Park, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: However, this excuse is no longer valid. Current research has resulted in the development of extremely large KBs including not only the "common sense" KB of Lenat's CYC [14], but also (much larger) KBs including machine-readable dictionaries [13], large ontologies [7], and very large case-bases for AI planning systems <ref> [12] </ref>. Despite this, most of the current KR systems are not able to accommodate these KBs, which may contain millions of assertions about many thousands of objects. In this paper, we describe a new implementation of the Parka knowledge representation system which is based on a relational database system. <p> The current Parka-db KB has over 1.2 million assertions. 2 . * Several Case-based planning applications including the memory-intensive case-based planning system, Caper, developed by Brian Kettler in his recent doctoral thesis <ref> [12] </ref>. The Caper KBs, the largest of which contains over 2,000,000 assertions, are described later in this paper (section 4). <p> Table 1 shows the sizes (in terms of frames and assertions) of the three KBs we have used in testing the system. All three of these were generated for the Case-based planning work described in section 2 and discussed in <ref> [12] </ref>. The case-bases were created via a generative planning system, and contain information on the plans, sub-plan structure, and causal information used by the planner, as well as ontology information about the logistics-planning domain. Details on this work and the planning domain can be found in http://www.cs.umd.edu/projects/plus/Caper/ and http://www.cs.umd.edu/projects/plus/UMT respectively.
Reference: [13] <author> K. Knight and S. Luk. </author> <title> Building a large knowledge base for machine translation. </title> <booktitle> In AAAI-94 [1]. </booktitle>
Reference-contexts: However, this excuse is no longer valid. Current research has resulted in the development of extremely large KBs including not only the "common sense" KB of Lenat's CYC [14], but also (much larger) KBs including machine-readable dictionaries <ref> [13] </ref>, large ontologies [7], and very large case-bases for AI planning systems [12]. Despite this, most of the current KR systems are not able to accommodate these KBs, which may contain millions of assertions about many thousands of objects.
Reference: [14] <author> Douglas B. Lenat and R.V. Guha. </author> <title> Building Large Knowledge-Based Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: However, this excuse is no longer valid. Current research has resulted in the development of extremely large KBs including not only the "common sense" KB of Lenat's CYC <ref> [14] </ref>, but also (much larger) KBs including machine-readable dictionaries [13], large ontologies [7], and very large case-bases for AI planning systems [12]. Despite this, most of the current KR systems are not able to accommodate these KBs, which may contain millions of assertions about many thousands of objects.
Reference: [15] <author> Robert M. MacGregor. </author> <title> A description classifier for the predicate calculus. </title> <booktitle> In AAAI-94 [1]. </booktitle>
Reference-contexts: While it is difficult to exactly compare KR languages, a very loose categorization would put Parka as more expressive than Classic [4], due to the presence of exception handling, although slightly less expressive than Loom <ref> [15] </ref> due to the lack of extensive numerical capabilities. A full description of the language, and more details on past results can be found in http://www.cs.umd.edu/projects/plus/Parka. One of the key features of Parka is that it has been shown to efficiently handle its inferencing on KBs containing millions of assertions.
Reference: [16] <author> D.P. McKay, T.W. Finin, and A.O'Hara. </author> <title> The intelligent database interface: Integrating ai and database systems. </title> <booktitle> In Proceedings of the 1990 National Conference on Artificial Intelligence, </booktitle> <pages> pages 677-684. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference-contexts: In particular, each assertion type is associated with a relational table in Parka-rel. Frames in Parka-db thus have their information distributed amongst several tables. This contrasts with other attempts to use database technology for supporting knowledge bases (see section 5). Other systems <ref> [11, 16] </ref> store frames in a much more centralized manner they attempt to gather as much information about a frame as possible when loading data from external storage. Parka-db only loads into memory that information which is needed for processing a query. <p> They pull in much data about individual frames, rather than distributing the frames as we discussed earlier. Thus, their system functions more as a "persistent store" than as a query system such as ours. The IDI (Intelligent Database Interface) project <ref> [16] </ref> can also be viewed in a similar manner, although that work is meant to deal more with access to distributed DBs then as a KR system per se. Another system dealing with disk-based knowledge is Haase's Framer system [8].
Reference: [17] <author> Edward Pattison-Gordon. Thenetsys: </author> <title> A semantic network system. </title> <type> Technical Report DSG -93-02, </type> <institution> Decision Systems Group, Harward Medical School, </institution> <address> Boston, Massachusetts, 02115, </address> <year> 1993. </year>
Reference-contexts: The system provides the basic routines for simple inferencing mechanisms, but provides neither a full KR language nor the sort 10 of conjunctive querying provided by Parka-db. Another alternate approach is that of Thenetsys <ref> [17] </ref> which is a semantic network system that employs somewhat of a virtual memory approach to semantic network management. In Thenetsys, semantic networks are stored on disk. When a node from a network is requested, Thenetsys has to find room for the node and its related data.
Reference: [18] <author> K. Stoffel and J. Hendler. </author> <title> An efficient inferential-distance-ordering algorithm for parallel and distributed systems. </title> <note> submitted for publication, </note> <year> 1996. </year>
Reference-contexts: In particu 1 Although it has been shown that IDO with fully general exceptions (i.e. cancellation links) is exponentially hard, we've demonstrated that IDO with multiple inheritance exceptions can be computed in polynomial time and is efficiently parallelizable <ref> [18] </ref>. 2 lar, it has been noted that data mining systems can benefit from the use of KBs to provide semantic information for datamining [5]. We are exploiting this sort of information by using medical knowledge in the datamining of an OB-Gyn patient database containing records on over 20,000 patients.
Reference: [19] <editor> K. Stoffel, J. Hendler, and J. Saltz. </editor> <booktitle> Parka on mimd-supercomputers. In 3rd International Workshop on Parallel Processing in AI, </booktitle> <address> Montral, Canada, </address> <month> August </month> <year> 1995. </year> <pages> IJCAI. </pages>
Reference-contexts: Secondly, Parka was originally designed for parallel supercomputing environments [6] and the algorithms have been proven to scale well to a wide range of supercomputing systems <ref> [19] </ref> guaranteeing a parallel efficiency better than 50% up to 16 processors for the case-bases described in this paper.
Reference: [20] <author> Merwyn Taylor. </author> <title> Hybrid kb-db. </title> <booktitle> In Proceedings of the 13th National Conference of the American Association for Artificial Intelligence. </booktitle> <publisher> AAAI Press, MIT Press, </publisher> <year> 1996. </year> <note> to appear. </note>
Reference-contexts: Parka-db is being used in a number of research initiatives at the University of Maryland. Some of the projects using Parka-db include * A KDD <ref> [20] </ref> application for a large medical knowledge base.
References-found: 20

