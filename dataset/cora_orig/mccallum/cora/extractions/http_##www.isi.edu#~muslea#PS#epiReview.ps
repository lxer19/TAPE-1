URL: http://www.isi.edu/~muslea/PS/epiReview.ps
Refering-URL: http://www.isi.edu/~muslea/RISE/index.html
Root-URL: http://www.isi.edu
Email: muslea@isi.edu  
Title: Extraction Patterns: from Information Extraction to Wrapper Generation  
Author: Ion Muslea 
Date: July 9, 1998  
Address: California  
Affiliation: Information Sciences Institute Computer Science Department University of Southern  
Abstract-found: 0
Intro-found: 1
Reference: [ Appelt et al., 1993 ] <author> Appelt, D.; Hobbs, J.; Bear, J.; Israel, D.; and Tyson, M. </author> <year> 1993. </year> <title> Fastus: A finite-state processor for information extraction from real-world text. </title> <booktitle> Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93) 1172-1178. </booktitle>
Reference-contexts: is the expressivity of context free grammars for the parsing speed of finite automata, and we continue with an extension of CRYSTAL that can handle HTML pages. 6 3.1 FASTUS In order to avoid the drawbacks specific to context-free grammars (i.e., slow parsing and ambiguity of long sentences), the FASTUS <ref> [ Appelt et al., 1993 ] </ref> approach to IE is based on finite-state automata (FSA). More specifically, FSAs are used both for the phrasal decomposition and for the recognition of domain-specific phrases based on combinations of heads found during the phrasal decomposition.
Reference: [ Brill, 1994 ] <author> Brill, E. </author> <year> 1994. </year> <title> Some advances in rule-based part of speech tagging. </title> <booktitle> Proceedings of the Twelfth Annual Conference on Artificial Intelligence 722-727. </booktitle>
Reference-contexts: The "Filler pattern" imposes constraints on the structure of the information to be extracted: it consists of at most two words that were labeled "nn" or "nns" by the POS tagger <ref> [ Brill, 1994 ] </ref> (i.e., one or two singular or plural common nouns).
Reference: [ Califf & Mooney, 1997 ] <author> Califf, M., and Mooney, R. </author> <year> 1997. </year> <title> Relational learning of pattern-match rules for information extraction. </title> <booktitle> Working Papers of the ACL-97 Workshop in Natural Language Learning 9-15. </booktitle>
Reference-contexts: In final analysis, WHISK can be seen as the system that elaborated the two novelties introduced by FASTUS: the use of finite state automata, and the "skipping" over irrelevant structural components. 4.2 RAPIER The RAPIER system <ref> [ Califf & Mooney, 1997 ] </ref> learns unbounded ELIZA-like patterns [ Weiz-man, 1966 ] that use limited syntactic information (e.g., the output of a part-of-speech tagger) and semantic class information (e.g., hypernim links from WordNet [ Miller, 1995 ] ).
Reference: [ Cardie, 1997 ] <author> Cardie, C. </author> <year> 1997. </year> <title> Empirical methods in information extraction. </title> <journal> AI Journal 18(4) </journal> <pages> 65-79. </pages>
Reference: [ Freitag, 1998 ] <author> Freitag, D. </author> <year> 1998. </year> <title> Information extraction from html: Application of a general learning approach. </title> <note> To appear in Proceedings of AAAI-98. </note>
Reference-contexts: extraction patterns that are based both on delimiters and content description, it is easy to see that WHISK patterns are more flexible: they allow a finer description of the information content, and their regular expressions are not limited to a sequence of tokens immediately preceding the content. 4.3 SRV SRV <ref> [ Freitag, 1998 ] </ref> generates first-order logic extraction patterns that are based on attribute-value tests and the relational structure of the documents. For instance, the pattern from 10 Telecommunications. SOLARIS System Information to be extracted: Admin. 38-44K.
Reference: [ Hsu & Dung, 1998 ] <author> Hsu, C., and Dung, M. </author> <year> 1998. </year> <title> Wrapping semistructured web pages with finite-state transducers. </title> <booktitle> To appear in the Proceedings of the Conference on Autonomous Learning and Discovery CONALD-98. </booktitle> <pages> 15 </pages>
Reference-contexts: It is easy to see that the WIEN rule can be successfully applied to sample documents D1 and D2 (see Figure 14), but it will fail on D3 because of the different ordering of the phone number and rating items. SoftMealy <ref> [ Hsu & Dung, 1998 ] </ref> can be seen as an extension of WIEN that allows the use of disjunctions, which are especially useful when the documents contain various orderings of the items of interest.
Reference: [ Huffman, 1995 ] <author> Huffman, S. </author> <year> 1995. </year> <title> Learning information extraction patterns from examples. </title> <booktitle> Workshop on new approaches to learning for natural language processing (IJCAI-95) 127-142. </booktitle>
Reference-contexts: to see that we can use the above concept node to extract the target of the terrorist attack in the sentence The Parliament was bombed by the guerrillas. but we need an active-verb-based concept to perform the same task for the sentence The guerrillas bombed the Parliament. 2.2 LIEP LIEP <ref> [ Huffman, 1995 ] </ref> is a learning system that can be seen as a multi-slot version of Au-toSlog. That is, rather than learning one extraction pattern for each item of interest in a sentence (e.g., target and perpetrator), LIEP generates a single rule for all items of interest.
Reference: [ Kim & Moldovan, 1995 ] <author> Kim, J., and Moldovan, D. </author> <year> 1995. </year> <title> Acquisition of linguistic patterns for knowledge-based information extraction. </title> <journal> IEEE Transactiops on Knowledge and Data Engineering 7(5) </journal> <pages> 713-724. </pages>
Reference-contexts: It is easy to see that the above LIEP extraction pattern is equivalent to the "union" of two AutoSlog-like rules: one for the target, and one for the perpetrator. 2.3 PALKA The PALKA system <ref> [ Kim & Moldovan, 1995 ] </ref> learns extraction patterns that are expressed as frame-phrasal pattern structures or, for short, FP-structures. As shown in Figure 3, an FP-structure consists of a meaning frame and a phrasal pattern.
Reference: [ Krupka, 1995 ] <author> Krupka, G. </author> <year> 1995. </year> <title> Description of the sra system as used for muc-6. </title> <booktitle> Proceedings of the Sixth Message Understanding Conference 221-235. </booktitle>
Reference-contexts: Pattern: ( (PHYSICAL-OBJECT) was bombed by (TERRORIST-GROUP) ) FP-structure = MeaningFrame + PhrasalPattern (BOMBING target: PHYSICAL-OBJECT agent: TERRORIST-GROUP pattern:( (target) was bombed by (agent) ) 4 BOMBING: TARGET NP semantic = physical-object ANCHOR VG root = bomb PERPETRATOR NP semantic = terrorist-group 2.4 HASTEN As the only description on HASTEN <ref> [ Krupka, 1995 ] </ref> is sketchy and informal, we discuss here HASTEN's extraction patterns just for sake of completeness. HASTEN introduces a class of extraction patterns called Egraphs (see Figure 4). One Egraph can be seen as a list of pairs (SemanticLabel, StructuralElem).
Reference: [ Kushmerick, Weld, & Doorenbos, 1997 ] <author> Kushmerick, N.; Weld, D.; and Doorenbos, R. </author> <year> 1997. </year> <title> Wrapper induction for information extraction. </title> <booktitle> Proceedings of 15th International Concerence on Artificial Intelligence 729-735. </booktitle>
Reference: [ Miller, 1995 ] <author> Miller, G. </author> <year> 1995. </year> <title> Wordnet: A lexical database for english. </title> <journal> Communications of the ACM 38(11) </journal> <pages> 39-41. </pages>
Reference-contexts: finite state automata, and the "skipping" over irrelevant structural components. 4.2 RAPIER The RAPIER system [ Califf & Mooney, 1997 ] learns unbounded ELIZA-like patterns [ Weiz-man, 1966 ] that use limited syntactic information (e.g., the output of a part-of-speech tagger) and semantic class information (e.g., hypernim links from WordNet <ref> [ Miller, 1995 ] </ref> ). The IE task for which RAPIER was trained consists of extracting details about job postings to USENET newsgroups. A typical example of target text, extracted information, and extraction pattern is presented in Figure 10. <p> The most interesting constraints are imposed by the last two predicates, which use features derived by the link grammar parser (see [ Sleator & Temperley, 1993 ] ) and WordNet <ref> [ Miller, 1995 ] </ref> . The meaning of the "wn-word X" construct is the following: if X is a noun or a verb, the "wn-word" constructs specify all synsets in the hypernim path to the root of the hypernim tree in which the X occurs.
Reference: [ Muslea, Minton, & Knoblock, 1998 ] <author> Muslea, I.; Minton, S.; and Knoblock, C. </author> <year> 1998. </year> <title> Wrapper induction for semistructured, web-based information sources. </title> <booktitle> To appear in the Proceedings of the Conference on Autonomous Learning and Discovery CONALD-98. </booktitle>
Reference-contexts: STALKER <ref> [ Muslea, Minton, & Knoblock, 1998 ] </ref> is a WG system that addresses all the problems above by using individual extraction patterns for each slot. In Figure 15, we show two STALKER extraction patterns: one for cuisine, and one for phone number.
Reference: [ Riloff, 1993 ] <author> Riloff, E. </author> <year> 1993. </year> <title> Automatically constructing a dictionary for information extraction tasks. </title> <booktitle> Proceedings of the Eleventh Annual Conference on Artificial Intelligence 811-816. </booktitle>
Reference-contexts: This annotation phase represents a major bottleneck because the process is difficult and time consuming, and it also requires a high level of expertise. 2.1 AutoSlog AutoSlog <ref> [ Riloff, 1993 ] </ref> is a dictionary-construction tool that automatically builds a domain-specific dictionary of extraction patterns called concepts or concept nodes. An AutoSlog concept has three key components: the conceptual anchor that activates it. the linguistic pattern and the set of enabling conditions that guarantee its applicability.
Reference: [ Sleator & Temperley, 1993 ] <author> Sleator, D., and Temperley, D. </author> <year> 1993. </year> <title> Parsing english with a link grammar. </title> <booktitle> Third International Workshop on Parsing Technologies. </booktitle>
Reference-contexts: The most interesting constraints are imposed by the last two predicates, which use features derived by the link grammar parser (see <ref> [ Sleator & Temperley, 1993 ] </ref> ) and WordNet [ Miller, 1995 ] .
Reference: [ Soderland et al., 1995 ] <author> Soderland, S.; Fisher, D.; Aseltine, J.; and Lehnert, W. </author> <year> 1995. </year> <title> Crystal: Inducing a conceptual dictionary. </title> <booktitle> Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95) 1314-1319. </booktitle>
Reference-contexts: Then it uses a set of fixed weight factors to compute the percentage of the matched Egraph, and it compares the final score with a predefined threshold value. 2.5 CRYSTAL CRYSTAL ( <ref> [ Soderland et al., 1995 ] </ref> ) generates concept node extraction patterns that are similar in nature, but significantly more expressive than the ones used by AutoSlog. CRYSTAL allows both semantic and exact word constraints in any component phrases. Furthermore, CRYSTAL also allows the use of multi-slot extraction patterns.
Reference: [ Soderland, 1997 ] <author> Soderland, S. </author> <year> 1997. </year> <title> Learning to extract text-based information from the world wide web. </title> <booktitle> Proceedings of Third International Conference on Knowledge Discovery and Data Mining (KDD-97). </booktitle>
Reference-contexts: For instance, the pattern Subject fPrepos NounGrpg* VerbGrp skips over the prepositional phrases located between the subject and the verb. 4) The incident merging pahse combines into a single incident the information extracted into several complementary incidents. 3.2 CRYSTAL + Webfoot In <ref> [ Soderland, 1997 ] </ref> , the author proposes a preprocessing step that would allow the user to run CRYSTAL on training examples extracted from Web pages.
Reference: [ Soderland, 1998 ] <author> Soderland, S. </author> <year> 1998. </year> <title> Learning information extraction rules for semi-structured and free text. </title> <address> http://www.cs.washington.edu/homes/soderlan/WHISK.ps. </address>
Reference-contexts: In order to deal with the new types of application domains, researchers introduced extraction patterns that are based both on syntactic/semantic constraints, and delimiters that "bound" the text to be extracted, 4.1 WHISK WHISK <ref> [ Soderland, 1998 ] </ref> is a learning system that generates extraction patterns for a wide variety of online information ranging from structured text (i.e., rigidly formatted) to free text.
Reference: [ Weizman, 1966 ] <author> Weizman, J. </author> <year> 1966. </year> <title> Eliza a computer program for the study of natural language communications between man and machines. </title> <journal> Communications of the ACM 9 </journal> <pages> 36-45. </pages>
References-found: 18

