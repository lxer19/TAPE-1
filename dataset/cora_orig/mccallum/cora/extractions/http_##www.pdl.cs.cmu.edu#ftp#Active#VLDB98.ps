URL: http://www.pdl.cs.cmu.edu/ftp/Active/VLDB98.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/er1p/www/ErikRiedel.html
Root-URL: 
Title: Active Storage For Large-Scale Data Mining and Multimedia  
Abstract: The increasing performance and decreasing cost of processors and memory are causing system intelligence to move into peripherals from the CPU. Storage system designers are using this trend toward excess compute power to perform more complex processing and optimizations inside storage devices. To date, such optimizations have been at relatively low levels of the storage protocol. At the same time, trends in storage density, mechanics, and electronics are eliminating the bottleneck in moving data off the media and putting pressure on interconnects and host processors to move data more efficiently. We propose a system called Active Disks that takes advantage of processing power on individual disk drives to run application-level code. Moving portions of an applications processing to execute directly at disk drives can dramatically reduce data traffic and take advantage of the storage parallelism already present in large systems today. We discuss several types of applications that would benefit from this capability with a focus on the areas of database, data mining, and multimedia. We develop an analytical model of the speedups possible for scan-intensive applications in an Active Disk system. We also experiment with a prototype Active Disk system using relatively low-powered processors in comparison to a database server system with a single, fast processor. Our experiments validate the intuition in our model and demonstrate speedups of 2x on 10 disks across four scan-based applications. The model promises linear speedups in disk arrays of hundreds of disks, provided the application data is large enough. 
Abstract-found: 1
Intro-found: 1
Reference: [Acharya98] <author> Acharya, A., Uysal, M. and Saltz, J. </author> <type> Active Disks Technical Report TRCS98-06, </type> <month> March </month> <year> 1998. </year>
Reference-contexts: Work at Santa Barbara and Maryland has applied Active Disk ideas to a set of similar applications, including database select, external sort, datacubes, and image processing, using an extended-firmware model for next-generation SCSI disks <ref> [Acharya98] </ref>.
Reference: [Agrawal95] <author> Agrawal, R. and Srikant, R. </author> <title> Fast Algorithms for Mining Association Rules VLDB, </title> <month> September </month> <year> 1994. </year>
Reference-contexts: Finally, the state required at the disk is simply the storage for the list of k closest records. 4.2 Data Mining - Frequent Sets The second application is an implementation of the Apriori algorithm for discovering association rules in sales transactions <ref> [Agrawal95] </ref>. Again, we use synthetic data generated using a tool from the Quest group to create databases containing transactions from hypothetical point-of-sale information. Each record contains a &lt;transaction id&gt;, a &lt;customer id&gt;, and a list of &lt;items&gt; purchased.
Reference: [Agrawal96] <author> Agrawal, R. </author> <title> and Schafer, </title> <journal> J. Parallel Mining of Association Rules IEEE Transactions on Knowledge and Data Engineering 8,6. </journal> <month> December </month> <year> 1996. </year>
Reference-contexts: This is exactly the idea behind recent high-dimensionality indexing methods such as X-trees [Berchtold96] which deliberately revert to sequential scanning for high dimensionalities. In data mining, algorithms such as association discovery and classification also require repeated scans of the data <ref> [Agrawal96] </ref>. In addition to supporting complex, scan-based queries, trends are toward larger and larger database sizes. One hour of video requires approximately 1 GB of storage and video databases such as daily news broadcasts can easily contain over 1 TB of data [Wactlar96].
Reference: [Almaden97] <institution> Almaden CattleCam, IBM Almaden Research Center www.almaden.ibm.com/almaden/cattle, January 1998. </institution>
Reference-contexts: We use real images from Almadens CattleCam <ref> [Almaden97] </ref> and attempt to detect cows in the landscape above San Jose. The application processes a set of 256 KB images and returns only the edges found in the data using a fixed 37 pixel mask.
Reference: [Arpaci-Dusseau97] <author> Arpaci-Dusseau, A.C., Arpaci-Dusseau, R.H., Culler, D.E., Hellerstein, J.M. and Patterson, D.A. </author> <title> High-Performance Sorting on Networks of Workstations ACM SIGMOD, </title> <month> June </month> <year> 1997. </year>
Reference-contexts: Consider a parallel sample sort algorithm running across a network of workstations similar to the setup of NowSort <ref> [Arpaci-Dusseau97] </ref>. The algorithm is composed of a sample phase and a sort phase [Blelloch98]. During the sample phase, a subset of the total data is read and a histogram is created allowing the key space to be divided into n buckets of roughly equal size.
Reference: [Arya94] <author> Arya, M., Cody, W., Faloutsos, C., Richardson, J. and Toga, A. QBISM: </author> <title> Extending a DBMS to Support 3D Medical Images International Conference on Data Engineering, </title> <month> February </month> <year> 1994. </year>
Reference-contexts: Such databases can be searched by content (video, text, or audio) and utilize both feature extraction and a combination of the searching algorithms mentioned above. Medical image databases also impose similarly heavy data requirements <ref> [Arya94] </ref>. In data mining applications, point-of-sale data is collected over many months and years and grows continually. Tele communication companies maintain tens of TB of historical call data.
Reference: [Barclay97] <author> Barclay, T. </author> <title> The TerraServer Spatial Database www.research.microsoft.com/terraserver, November 1997. </title>
Reference-contexts: Assuming a reasonable 10 MB/s for sequential scans, we also see that the aggregate storage bandwidth is more than twice the backplane bandwidth of the machine in almost every case. Data from [TPC98] and <ref> [Barclay97] </ref>. In Figure 1 we show the effects of increasing transistor counts on disk electronics.
Reference: [Berchtold96] <author> Berchtold, S., Keim, D.A. and Kriegel, H. </author> <title> The X-tree: An Index Structure for High-Dimensional Data VLDB, </title> <year> 1996. </year>
Reference-contexts: One way or another, a nearest neighbor query will have to visit a large percentage of the database, effectively reducing the problem to sequential scanning. This is exactly the idea behind recent high-dimensionality indexing methods such as X-trees <ref> [Berchtold96] </ref> which deliberately revert to sequential scanning for high dimensionalities. In data mining, algorithms such as association discovery and classification also require repeated scans of the data [Agrawal96]. In addition to supporting complex, scan-based queries, trends are toward larger and larger database sizes.
Reference: [Berchtold97] <author> Berchtold, S., Boehm, C., Keim, D.A. and Kriegel, H. </author> <title> A Cost Model For Nearest Neighbor Search in High-Dimensional Data Space ACM PODS, </title> <month> May </month> <year> 1997. </year>
Reference-contexts: The dimensionality of these vectors may be high (e.g. moments of inertia for shapes [Faloutsos94], colors in histograms for color matching, or Fourier coefficients). It is well-known [Yao85], but only recently highlighted in the database literature <ref> [Berchtold97] </ref>, that for high dimensionalities, sequential scanning is competitive with indexing methods because of the dimensionality curse. Conventional database wisdom is that indices always improve performance over scanning. This is true for low dimensionalities, or for queries on only a few attributes. <p> In searches such as this across a large number of attributes, it has been shown that a scan of the entire database is as efficient as building extensive indices <ref> [Berchtold97] </ref>. Therefore, an Active Disk scan is appropriate.
Reference: [Bershad95] <author> Bershad, B.N., Savage, S., Pardyak, P., Sirer, E.G., Fiuczynski, M.E., Becker, D., Chambers, C. and Eggers, S. </author> <title> Extensibility, Safety, and Performance in the SPIN Operating System SOSP, </title> <month> December </month> <year> 1995. </year>
Reference-contexts: For the cases where efficiency, space or cost constraints require that application code be co-located with core drive code, recent research offers a range of efficient and safe remote execution facilities that provide innovative ways to ensure proper execution of code and safeguard the integrity of the drive <ref> [Gosling96, Necula96, Romer96, Bershad95, Small95, Wahbe93] </ref>. Some of these mechanisms also promise a degree of control over the resource usage of remote functions to aid in balancing utilization of the drive between demand requests, opportunistic optimizations such as read-ahead, and demand requests.
Reference: [Bitton88] <author> Bitton, D. and Gray, J. </author> <title> Disk Shadowing VLDB, </title> <year> 1988. </year>
Reference-contexts: These two advantages are the focus of this paper because they promise orders of magnitude potential improvements. In storage systems research, however, the most common application-specific optimizations are scheduling, batching and prefetching of disk operations <ref> [Bitton88, Ruemmler91] </ref>. Active Disks can be expected to execute these types of remote functions as well. In particular, we might expect Active Disks to participate as part of a disk-directed I/O model, where scatter/gather accesses are optimized using local information at the disks [Kotz94].
Reference: [Blelloch98] <author> Blelloch, G.E., Leiserson, C.E., Maggs, B.M., Plax-ton, C.G., Smith, S.J. and Zagha, M. </author> <title> An Experimental Analysis of Parallel Sorting Algorithms Theory of Computing Systems 31 (2), </title> <month> March </month> <year> 1998. </year>
Reference-contexts: Consider a parallel sample sort algorithm running across a network of workstations similar to the setup of NowSort [Arpaci-Dusseau97]. The algorithm is composed of a sample phase and a sort phase <ref> [Blelloch98] </ref>. During the sample phase, a subset of the total data is read and a histogram is created allowing the key space to be divided into n buckets of roughly equal size.
Reference: [Boral83] <author> Boral, H. and DeWitt, </author> <title> D.J. Database Machines: An Idea Whose Time Has Passed? International Workshop on Database Machines, </title> <month> September </month> <year> 1983. </year>
Reference-contexts: operations, such as sorts and joins, simple select filters in hardware did not provide significant benefits, 2) special-purpose hardware increased the design time and cost of the machine, and 3) a single general purpose host processor was sufficient to execute select at the full data rate of a single disk <ref> [DeWitt81, Boral83] </ref>. Boral and DeWitt concluded that aggregate storage bandwidth was the principle limitation of database machines. Fortunately, as shown in Table 1, in the intervening years aggregate storage bandwidth has dramatically improved.
Reference: [Cao94] <author> Cao, P., Lim, S.B., Venkataraman, S. and Wilkes, J. </author> <booktitle> The TickerTAIP Parallel RAID Architecture ACM Transactions on Computer Systems 12 (3), </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time <ref> [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] </ref> and for dis tributed file system scalability [Lee96, VanMeter96, Gibson97]. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations.
Reference: [DeWitt81] <author> DeWitt, D.J. and Hawthorn, P. </author> <title> A Performance Evaluation of Database Machine Architectures VLDB, </title> <month> September </month> <year> 1981. </year>
Reference-contexts: operations, such as sorts and joins, simple select filters in hardware did not provide significant benefits, 2) special-purpose hardware increased the design time and cost of the machine, and 3) a single general purpose host processor was sufficient to execute select at the full data rate of a single disk <ref> [DeWitt81, Boral83] </ref>. Boral and DeWitt concluded that aggregate storage bandwidth was the principle limitation of database machines. Fortunately, as shown in Table 1, in the intervening years aggregate storage bandwidth has dramatically improved. <p> the bottleneck resource, this will improve overall performance of the algorithm by up to one-third. 7 Related Work The basic idea of executing functions in processing elements directly attached to individual disks was explored extensively in the context of database machines such as CASSM [Su75], RAP [Ozkarahan75], and numerous others <ref> [DeWitt81] </ref>. These machines fell out of favor due to the limited performance of disks at the time and the complex ity of building and programming special-purpose hardware that could only handle limited functions. Instead, database research has developed large-scale, shared-nothing database servers with commodity processing elements.
Reference: [DeWitt85] <author> DeWitt, D.J. and Gerber, R. </author> <title> Multiprocessor Hash Based Join Algorithms VLDB, </title> <month> August </month> <year> 1985. </year>
Reference-contexts: A promising variant of these common optimizations is interconnect transfer scheduling. While network scheduling alone cannot be expected to yield benefits like we have seen in this paper, it can be an integral part of Active Disk computations for complex operations such as hash-join <ref> [Kitsuregawa83, DeWitt85] </ref> or variants of sort [Salzberg90, DeWitt91].
Reference: [DeWitt91] <author> DeWitt, D.J., Naughton, J.F. and Schneider, D.A. </author> <title> Parallel Sorting on a Shared-Nothing Architecture using Probabilistic Splitting PDIS, </title> <year> 1991. </year>
Reference-contexts: While network scheduling alone cannot be expected to yield benefits like we have seen in this paper, it can be an integral part of Active Disk computations for complex operations such as hash-join [Kitsuregawa83, DeWitt85] or variants of sort <ref> [Salzberg90, DeWitt91] </ref>.
Reference: [DeWitt92] <author> DeWitt, D.J. and Gray, J. </author> <title> Parallel Database Systems: </title> <booktitle> The Future of High Performance Database Processing Communications of the ACM 36 (6), </booktitle> <month> June </month> <year> 1992. </year>
Reference: [Drapeau94] <author> Drapeau, A.L., Shirriff, K.W., Hartman, J.H., Miller, E.L., Seahan, S., Katz, R.H., Lutz, K., Patterson, D.A., Lee, E.K. and Gibson, </author> <title> G.A. RAID-II: A High-Bandwidth Network File Server ISCA, </title> <year> 1994. </year>
Reference-contexts: Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time <ref> [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] </ref> and for dis tributed file system scalability [Lee96, VanMeter96, Gibson97]. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations.
Reference: [Faloutsos94] <author> Faloutsos, C., Barber, R., Flickner, M., Hafner, J., Niblack, W., Petkovic, D. and Equitz, W. </author> <title> Efficient and Effective Querying by Image Content Journal of Intelligent Information Systems 3 (4), </title> <month> July </month> <year> 1994. </year>
Reference-contexts: The general approach to such a search is to extract feature vectors from every image, and then search these feature vectors for nearest neighbors [Faloutsos96]. The dimensionality of these vectors may be high (e.g. moments of inertia for shapes <ref> [Faloutsos94] </ref>, colors in histograms for color matching, or Fourier coefficients). It is well-known [Yao85], but only recently highlighted in the database literature [Berchtold97], that for high dimensionalities, sequential scanning is competitive with indexing methods because of the dimensionality curse. Conventional database wisdom is that indices always improve performance over scanning.
Reference: [Faloutsos96] <author> Faloutsos, C. </author> <title> Searching Multimedia Databases by Content, </title> <publisher> Kluwer Academic Inc., </publisher> <year> 1996. </year>
Reference-contexts: The user provides a desirable image and requests a set of similar images. The general approach to such a search is to extract feature vectors from every image, and then search these feature vectors for nearest neighbors <ref> [Faloutsos96] </ref>. The dimensionality of these vectors may be high (e.g. moments of inertia for shapes [Faloutsos94], colors in histograms for color matching, or Fourier coefficients).
Reference: [Flickner95] <author> Flickner, M., Sawhney, H., Niblack, W., Ashley, J., Huang, Q., Dom, B., Gorkani, M., Hafner, J., Lee, D., Petkovic, D., Steele, D. and Yanker, P. </author> <title> Query by Image and Video Content: </title> <booktitle> the QBIC System IEEE Computer, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: many of the individual specialized chips into a single ASIC, and the next generation of silicon makes it possible to both integrate the control processor and provide a significantly more powerful embedded core while continuing to reduce total chip count and cost. (a) (b) tions such as searching by content <ref> [Flickner95, Virage98] </ref> are particularly good candidates. The user provides a desirable image and requests a set of similar images. The general approach to such a search is to extract feature vectors from every image, and then search these feature vectors for nearest neighbors [Faloutsos96].
Reference: [Gibson97] <author> Gibson, G., Nagle, D., Amiri, K., Chang, F., Fein-berg, E., Gobioff, H., Lee, C., Ozceri, B., Riedel, E., Rochberg, D. and Zelenka, J. </author> <title> File Server Scaling with Network-Attached Secure Disks ACM SIGMETRICS, </title> <month> June </month> <year> 1997. </year>
Reference-contexts: Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] and for dis tributed file system scalability <ref> [Lee96, VanMeter96, Gibson97] </ref>. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations. Instead of etching database functions into silicon as envisioned 15 years ago, Active Disks are programmed in software and use general purpose microprocessors. <p> Our work on Active Disks follows from our prior work on network-attached secure disks (NASD), in which we exploit computational power at storage for parallel and network file system functions, as well as traditional storage optimizations <ref> [Gibson97, Gibson98] </ref>. Our initial work discussed several classes of applications that can benefit from Active Disks including filters, multimedia, batching, and storage management and enumerated the challenges to providing an execution environment on commodity disk drives [Riedel97].
Reference: [Gibson98] <author> Gibson, G., Nagle, D., Amiri, K., Butler, J., Chang, F., Gobioff, H., Hardin, C., Riedel, E., Rochberg, D. and Zelenka, J. </author> <title> A Cost-Effective, High-Bandwidth Storage Architecture Technical Report CMU-CS-98-115, </title> <month> March </month> <year> 1998. </year>
Reference-contexts: Our work on Active Disks follows from our prior work on network-attached secure disks (NASD), in which we exploit computational power at storage for parallel and network file system functions, as well as traditional storage optimizations <ref> [Gibson97, Gibson98] </ref>. Our initial work discussed several classes of applications that can benefit from Active Disks including filters, multimedia, batching, and storage management and enumerated the challenges to providing an execution environment on commodity disk drives [Riedel97].
Reference: [Gosling96] <author> Gosling, J., Joy, B. and Steele, G. </author> <title> The Java Language Specification. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: For the cases where efficiency, space or cost constraints require that application code be co-located with core drive code, recent research offers a range of efficient and safe remote execution facilities that provide innovative ways to ensure proper execution of code and safeguard the integrity of the drive <ref> [Gosling96, Necula96, Romer96, Bershad95, Small95, Wahbe93] </ref>. Some of these mechanisms also promise a degree of control over the resource usage of remote functions to aid in balancing utilization of the drive between demand requests, opportunistic optimizations such as read-ahead, and demand requests.
Reference: [Gray97] <author> Gray, J. </author> <title> What Happens When Processing, Storage, and Bandwidth are Free and Infinite? Keynote Address, </title> <address> IOPADS, </address> <month> November </month> <year> 1997. </year>
Reference-contexts: Instead, database research has developed large-scale, shared-nothing database servers with commodity processing elements. It has recently been suggested that the logical extension is to perform all database processing inside programmable, smart system peripherals <ref> [Gray97] </ref>. Our work on Active Disks follows from our prior work on network-attached secure disks (NASD), in which we exploit computational power at storage for parallel and network file system functions, as well as traditional storage optimizations [Gibson97, Gibson98].
Reference: [Grochowski96] <author> Grochowski, E.G. and Hoyt, </author> <title> R.F., Future Trends in Hard Disk Drives IEEE Transactions on Magnetics 32 (3), </title> <month> May </month> <year> 1996. </year>
Reference-contexts: Moreover, high-end disk rates are now 15 MB/s sustained [Seagate97] and continue to grow at 40% per year <ref> [Grochowski96] </ref>. In place of raw disk bandwidth limitations, modern systems have a limited peripheral interconnect bandwidth, as seen in the system bus column of Table 1.
Reference: [Hsiao79] <author> Hsiao, D.K. </author> <title> DataBase Machines Are Coming, DataBase Machines Are Coming! IEEE Computer, </title> <month> March </month> <year> 1979. </year>
Reference: [Keeton98] <author> Keeton, K., Patterson, D.A. and Hellerstein, J.M. </author> <title> The Intelligent Disk (IDISK): A Revolutionary Approach to Database Computing Infrastructure White Paper, </title> <institution> University of California Berkeley, </institution> <month> May </month> <year> 1998. </year>
Reference-contexts: Similarly, a group at Berkeley has independently estimated the benefit of Active (Intelligent in their terminology) Disks for improving the performance of large SMP systems running scan, hash-join, and sort operations in a database context <ref> [Keeton98] </ref>. 8 Conclusions and Future Work Commodity disks drives with an excess of computational power are visible on the horizon. Active Disks take advantage of this trend to provide an execution environment for application-specific code inside individual disk drives.
Reference: [Kitsuregawa83] <author> Kitsuregawa, M., Tanaka, H. and Moto-Oka, T. </author> <title> Application of Hash To Data Base Machine and Its Architecture New Generation Computing 1, </title> <year> 1983. </year>
Reference-contexts: A promising variant of these common optimizations is interconnect transfer scheduling. While network scheduling alone cannot be expected to yield benefits like we have seen in this paper, it can be an integral part of Active Disk computations for complex operations such as hash-join <ref> [Kitsuregawa83, DeWitt85] </ref> or variants of sort [Salzberg90, DeWitt91].
Reference: [Kotz94] <author> Kotz, D. </author> <title> Disk-directed I/O for MIMD Multiprocessors OSDI, </title> <month> November </month> <year> 1994. </year>
Reference-contexts: Active Disks can be expected to execute these types of remote functions as well. In particular, we might expect Active Disks to participate as part of a disk-directed I/O model, where scatter/gather accesses are optimized using local information at the disks <ref> [Kotz94] </ref>. Or in prefetching systems where disks are provided with hints about future accesses [Patterson95]. A promising variant of these common optimizations is interconnect transfer scheduling.
Reference: [Lee96] <author> Lee, E.K. and Thekkath, </author> <title> C.A., Petal: Distributed Virtual Disks ASPLOS, </title> <month> October </month> <year> 1996. </year>
Reference-contexts: Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] and for dis tributed file system scalability <ref> [Lee96, VanMeter96, Gibson97] </ref>. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations. Instead of etching database functions into silicon as envisioned 15 years ago, Active Disks are programmed in software and use general purpose microprocessors.
Reference: [Livny87] <author> Livny, M., </author> <booktitle> Multi-disk management algorithms ACM SIGMETRICS, </booktitle> <month> May </month> <year> 1987. </year>
Reference-contexts: Boral and DeWitt concluded that aggregate storage bandwidth was the principle limitation of database machines. Fortunately, as shown in Table 1, in the intervening years aggregate storage bandwidth has dramatically improved. The improvement comes from disk array hardware and software that enable individual database operations to exploit disk parallelism <ref> [Livny87, Patterson88] </ref> and because databases are now large enough to justify hundreds of disks. Moreover, high-end disk rates are now 15 MB/s sustained [Seagate97] and continue to grow at 40% per year [Grochowski96].
Reference: [Necula96] <author> Necula, G.C. and Lee, P. </author> <title> Safe Kernel Extensions Without Run-Time Checking OSDI, </title> <month> October </month> <year> 1996. </year>
Reference-contexts: For the cases where efficiency, space or cost constraints require that application code be co-located with core drive code, recent research offers a range of efficient and safe remote execution facilities that provide innovative ways to ensure proper execution of code and safeguard the integrity of the drive <ref> [Gosling96, Necula96, Romer96, Bershad95, Small95, Wahbe93] </ref>. Some of these mechanisms also promise a degree of control over the resource usage of remote functions to aid in balancing utilization of the drive between demand requests, opportunistic optimizations such as read-ahead, and demand requests.
Reference: [Ozharahan75] <author> Ozharahan, E.A., Schuster, S.A. and Smith, K.C. </author> <title> RAP Associative Processor for Database Management AFIPS Conference, </title> <year> 1975. </year>
Reference: [Patterson88] <author> Patterson, D.A., Gibson, G. and Katz, </author> <title> R.H., A Case for Redundant Arrays of Inexpensive Disks ACM SIG-MOD, </title> <month> June </month> <year> 1988. </year>
Reference-contexts: Boral and DeWitt concluded that aggregate storage bandwidth was the principle limitation of database machines. Fortunately, as shown in Table 1, in the intervening years aggregate storage bandwidth has dramatically improved. The improvement comes from disk array hardware and software that enable individual database operations to exploit disk parallelism <ref> [Livny87, Patterson88] </ref> and because databases are now large enough to justify hundreds of disks. Moreover, high-end disk rates are now 15 MB/s sustained [Seagate97] and continue to grow at 40% per year [Grochowski96]. <p> Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time <ref> [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] </ref> and for dis tributed file system scalability [Lee96, VanMeter96, Gibson97]. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations.
Reference: [Patterson95] <author> Patterson, R.H., Gibson, G., Ginting, E., Stodolsky, D. and Zelenka, J. </author> <title> Informed Prefetching and Caching, </title> <booktitle> SOSP, </booktitle> <year> 1995. </year>
Reference-contexts: This ignores the cost of forming, issuing and completing the physical SCSI disk operations, measured in a previous study as 0.58 microsec onds on a 150 MHz Alpha or 10.6 cycles per byte <ref> [Patterson95] </ref>. We add this to our hot cache numbers and report the resulting estimate of the cycles per byte required by each application in Table 2. and superimposes the predictions of the model based on these system and application parameters. <p> In particular, we might expect Active Disks to participate as part of a disk-directed I/O model, where scatter/gather accesses are optimized using local information at the disks [Kotz94]. Or in prefetching systems where disks are provided with hints about future accesses <ref> [Patterson95] </ref>. A promising variant of these common optimizations is interconnect transfer scheduling.
Reference: [Quest97] <institution> Quest Project, IBM Almaden Research Center Quest Data Mining Project www.almaden.ibm.com/cs/quest, December 1997. </institution>
Reference-contexts: We use synthetic data from the Quest data mining group at IBM Almaden <ref> [Quest97] </ref> which contains records of individuals applying for loans and includes information on nine independent attributes: &lt;age&gt;, &lt;education&gt;, &lt;salary&gt;, &lt;commission&gt;, &lt;zip code&gt;, &lt;make of car&gt;, &lt;cost of house&gt;, &lt;loan amount&gt;, and &lt;years owned&gt;.
Reference: [Riedel97] <author> Riedel, E. and Gibson, G. </author> <title> Active Disks Remote Execution for Network-Attached Storage Technical Report CMU-CS-97-198, </title> <month> December </month> <year> 1997. </year>
Reference-contexts: Instead of etching database functions into silicon as envisioned 15 years ago, Active Disks are programmed in software and use general purpose microprocessors. Downloading application code directly into devices has significant implications for language, safety, and resource management <ref> [Riedel97] </ref>. With block-oriented application codes, it is efficient to exploit standard memory management hardware at the drive and provide protected address spaces for applications as in standard multiprogrammed systems today. <p> Our initial work discussed several classes of applications that can benefit from Active Disks including filters, multimedia, batching, and storage management and enumerated the challenges to providing an execution environment on commodity disk drives <ref> [Riedel97] </ref>. Work at Santa Barbara and Maryland has applied Active Disk ideas to a set of similar applications, including database select, external sort, datacubes, and image processing, using an extended-firmware model for next-generation SCSI disks [Acharya98].
Reference: [Romer96] <author> Romer, T.H., Lee, D., Voelker, G.M., Wolman, A., Wong, W.A., Baer, J., Bershad, B.N. and Levy, </author> <title> H.M. </title> <booktitle> The Structure and Performance of Interpreters ASPLOS, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: For the cases where efficiency, space or cost constraints require that application code be co-located with core drive code, recent research offers a range of efficient and safe remote execution facilities that provide innovative ways to ensure proper execution of code and safeguard the integrity of the drive <ref> [Gosling96, Necula96, Romer96, Bershad95, Small95, Wahbe93] </ref>. Some of these mechanisms also promise a degree of control over the resource usage of remote functions to aid in balancing utilization of the drive between demand requests, opportunistic optimizations such as read-ahead, and demand requests.
Reference: [Ruemmler91] <author> Ruemmler, C. and Wilkes, J., </author> <type> Disk Shuffling HP Labs Technical Report HPL-CSP-91-30, </type> <year> 1991 </year>
Reference-contexts: These two advantages are the focus of this paper because they promise orders of magnitude potential improvements. In storage systems research, however, the most common application-specific optimizations are scheduling, batching and prefetching of disk operations <ref> [Bitton88, Ruemmler91] </ref>. Active Disks can be expected to execute these types of remote functions as well. In particular, we might expect Active Disks to participate as part of a disk-directed I/O model, where scatter/gather accesses are optimized using local information at the disks [Kotz94].
Reference: [Seagate97] <author> Seagate Technology Cheetah: </author> <title> Industry-Leading Performance for the Most Demanding Applications, </title> <note> www.seagate.com, 1997. </note>
Reference-contexts: The improvement comes from disk array hardware and software that enable individual database operations to exploit disk parallelism [Livny87, Patterson88] and because databases are now large enough to justify hundreds of disks. Moreover, high-end disk rates are now 15 MB/s sustained <ref> [Seagate97] </ref> and continue to grow at 40% per year [Grochowski96]. In place of raw disk bandwidth limitations, modern systems have a limited peripheral interconnect bandwidth, as seen in the system bus column of Table 1.
Reference: [Small95] <author> Small, C. and Seltzer, M. </author> <title> A Comparison of OS Extension Technologies USENIX Technical Conference, </title> <month> January </month> <year> 1996. </year>
Reference-contexts: For the cases where efficiency, space or cost constraints require that application code be co-located with core drive code, recent research offers a range of efficient and safe remote execution facilities that provide innovative ways to ensure proper execution of code and safeguard the integrity of the drive <ref> [Gosling96, Necula96, Romer96, Bershad95, Small95, Wahbe93] </ref>. Some of these mechanisms also promise a degree of control over the resource usage of remote functions to aid in balancing utilization of the drive between demand requests, opportunistic optimizations such as read-ahead, and demand requests.
Reference: [Smith79] <author> Smith, D.C.P. and Smith, J.M. </author> <title> Relational DataBase Machines IEEE Computer, </title> <month> March </month> <year> 1979. </year>
Reference: [Smith95] <author> Smith, S.M. and Brady, J.M. </author> <title> SUSAN ANew Approach to Low Level Image Processing Technical Report TR95SMS1c, </title> <publisher> Oxford University, </publisher> <year> 1995. </year>
Reference-contexts: The state required at the disk is the storage for the candidate k-itemsets and their counts at each state. 4.3 Multimedia - Edge Detection For image processing, we looked at an application that detects edges and corners in a set of grayscale images <ref> [Smith95] </ref>. We use real images from Almadens CattleCam [Almaden97] and attempt to detect cows in the landscape above San Jose. The application processes a set of 256 KB images and returns only the edges found in the data using a fixed 37 pixel mask.
Reference: [StorageTek94] <author> Storage Technology Corporation, </author> <title> Iceberg 9200 Storage System: Introduction STK Part Number 307406101, </title> <year> 1994. </year>
Reference-contexts: Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time <ref> [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] </ref> and for dis tributed file system scalability [Lee96, VanMeter96, Gibson97]. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations.
Reference: [Su75] <author> Su, S.Y.W. and Lipvski, G.J. CASSM: </author> <title> A Cellular System for Very Large Data Bases VLDB, </title> <year> 1975. </year>
Reference-contexts: In systems where the network is the bottleneck resource, this will improve overall performance of the algorithm by up to one-third. 7 Related Work The basic idea of executing functions in processing elements directly attached to individual disks was explored extensively in the context of database machines such as CASSM <ref> [Su75] </ref>, RAP [Ozkarahan75], and numerous others [DeWitt81]. These machines fell out of favor due to the limited performance of disks at the time and the complex ity of building and programming special-purpose hardware that could only handle limited functions.
Reference: [TPC98] <institution> Transaction Processing Performance Council TPC Executive Summaries www.tpc.org, February 1998. </institution>
Reference-contexts: Assuming a reasonable 10 MB/s for sequential scans, we also see that the aggregate storage bandwidth is more than twice the backplane bandwidth of the machine in almost every case. Data from <ref> [TPC98] </ref> and [Barclay97]. In Figure 1 we show the effects of increasing transistor counts on disk electronics.
Reference: [TriCore97] <institution> TriCore News Release Siemens New 32-bit Embedded Chip Architecture Enables Next Level of Performance in Real-Time Electronics Design www.tri-core.com, September 1997. </institution>
Reference-contexts: Siemens has announced a chip that offers a 100 MHz 32-bit microcontroller, up to 2 MB of on-chip RAM with up to 800 MB/s bandwidth, external DRAM and DMA controllers and customer-specific logic (that is, die area for the functions of Figure 1b) in a .35 micron process <ref> [TriCore97] </ref>. Fundamentally, VLSI technology has evolved to the point that significant additional computational power comes at negligible cost. Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI.
Reference: [Turley96] <author> Turley, J. </author> <title> ARM Grabs Embedded Speed Lead Microprocessor Reports 2 (10), </title> <month> February </month> <year> 1996. </year>
Reference-contexts: Extrapolating to the next generation of technology (from .68 micron to .35 micron CMOS in the ASIC), the specialized drive hardware will occupy about one quarter of the chip, leaving sufficient area to include a 200 MHz Digital StrongARM microprocessor <ref> [Turley96] </ref>, for example. Commodity disk and chip manufacturers are already pursuing processor-in-ASIC technology.
Reference: [VanMeter96] <author> Van Meter, R., Holtz, S. and Finn G., </author> <title> Derived Virtual Devices: A Secure Distributed File System Mechanism Fifth NASA Goddard Conference on Mass Storage Systems and Technologies, </title> <month> September </month> <year> 1996. </year>
Reference-contexts: Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] and for dis tributed file system scalability <ref> [Lee96, VanMeter96, Gibson97] </ref>. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations. Instead of etching database functions into silicon as envisioned 15 years ago, Active Disks are programmed in software and use general purpose microprocessors.
Reference: [Virage98] <institution> Virage Media Management Solutions www.virage.com, February 1998. </institution>
Reference-contexts: many of the individual specialized chips into a single ASIC, and the next generation of silicon makes it possible to both integrate the control processor and provide a significantly more powerful embedded core while continuing to reduce total chip count and cost. (a) (b) tions such as searching by content <ref> [Flickner95, Virage98] </ref> are particularly good candidates. The user provides a desirable image and requests a set of similar images. The general approach to such a search is to extract feature vectors from every image, and then search these feature vectors for nearest neighbors [Faloutsos96].
Reference: [Wactlar96] <author> Wactlar, H.D., Kanade, T., Smith, M.A. and Stevens, </author> <title> S.M. Intelligent Access to Digital Video: </title> <institution> Informedia Project IEEE Computer, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: In addition to supporting complex, scan-based queries, trends are toward larger and larger database sizes. One hour of video requires approximately 1 GB of storage and video databases such as daily news broadcasts can easily contain over 1 TB of data <ref> [Wactlar96] </ref>. Such databases can be searched by content (video, text, or audio) and utilize both feature extraction and a combination of the searching algorithms mentioned above. Medical image databases also impose similarly heavy data requirements [Arya94].
Reference: [Wahbe93] <author> Wahbe, R., Lucco, S., Anderson, T.E. and Graham, </author> <title> S.L. Efficient Software-Based Fault Isolation SOSP, </title> <month> December </month> <year> 1993. </year>
Reference-contexts: For the cases where efficiency, space or cost constraints require that application code be co-located with core drive code, recent research offers a range of efficient and safe remote execution facilities that provide innovative ways to ensure proper execution of code and safeguard the integrity of the drive <ref> [Gosling96, Necula96, Romer96, Bershad95, Small95, Wahbe93] </ref>. Some of these mechanisms also promise a degree of control over the resource usage of remote functions to aid in balancing utilization of the drive between demand requests, opportunistic optimizations such as read-ahead, and demand requests.
Reference: [Welling98] <author> Welling, J. Fiasco: </author> <note> A Package for fMRI Analysis www.stat.cmu.edu/~fiasco, January 1998. </note>
Reference-contexts: The state required on disk is the storage for a single image that is buffered and processed as a whole. 4.4 Multimedia - Image Registration Our second image processing application performs the image registration portion of the processing of an MRI brain scan analysis <ref> [Welling98] </ref>. Image registration determines the set of parameters necessary to register (rotate and translate) an image with respect to a reference image in order to compensate for movement of the subject during the scanning.
Reference: [Wilkes95] <author> Wilkes, J., Golding, R., Staelin, C. and Sullivan, T. </author> <title> The HP AutoRAID hierarchical storage system SOSP, </title> <month> December </month> <year> 1995. </year>
Reference-contexts: Processing power inside drives and storage subsystems has already been successfully used to optimize functions behind standardized interfaces such as SCSI. This includes many innovative optimizations for storage parallelism, bandwidth and access time <ref> [Patterson88, Drapeau94, Wilkes95, Cao94, StorageTek94] </ref> and for dis tributed file system scalability [Lee96, VanMeter96, Gibson97]. With Active Disks, excess computation power in storage devices is available directly for application-specific function in addition to supporting these existing storage-specific optimizations.
Reference: [Yao85] <author> Yao, A.C. and Yao, </author> <title> F.F. A General Approach to D-Dimensional Geometric Queries ACM STOC, </title> <month> May </month> <year> 1985. </year>
Reference-contexts: The dimensionality of these vectors may be high (e.g. moments of inertia for shapes [Faloutsos94], colors in histograms for color matching, or Fourier coefficients). It is well-known <ref> [Yao85] </ref>, but only recently highlighted in the database literature [Berchtold97], that for high dimensionalities, sequential scanning is competitive with indexing methods because of the dimensionality curse. Conventional database wisdom is that indices always improve performance over scanning.
References-found: 57

