URL: http://www.cs.ucsb.edu/~sunilp/pub/iopads97.ps
Refering-URL: http://www.cs.ucsb.edu/~sunilp/wavelets.html
Root-URL: http://www.cs.ucsb.edu
Email: fsunilp,agrawal,amr,ambuj,smithtrg@cs.ucsb.edu  
Title: Browsing and Placement of Multiresolution Images on Parallel Disks  
Author: Sunil Prabhakar Divyakant Agrawal Amr El Abbadi Ambuj Singh Terence Smith 
Address: Santa Barbara, CA 93106.  
Affiliation: Department of Computer Science University of California  
Abstract: With rapid advances in computer and communication technologies, there is an increasing demand to build and maintain large image repositories. In order to reduce the demands on I/O and network resources, multiresolution representations are being proposed for the storage organization of images. Image decomposition techniques such as wavelets can be used to provide these multiresolution images. The original image is represented by several coefficients, one of them with visual similarity to the original image, but at a lower resolution. These visually similar coefficients can be thought of as thumbnails or icons of the original image. This paper addresses the problem of storing these multiresolution coefficients on disks so that thumbnail browsing as well as image reconstruction can be performed efficiently. Several strategies are evaluated to store the image coefficients on parallel disks. These strategies can be classified into two broad classes depending on whether the access pattern of the images is used in the placement. Disk simulation is used to evaluate the performance of these strategies. Simulation results are validated with results from experiments with real disks and are found to be in good agreement. The results indicate that significant performance improvements can be achieved with as few as four disks by placing image coefficients based upon browsing access patterns. 
Abstract-found: 1
Intro-found: 1
Reference: [AMEM95] <author> A. D. Alexandrov, W. Y. Ma, A. El Abbadi, and B. S. Manjunath. </author> <title> Adaptive filtering and indexing for image databases. </title> <booktitle> In Proc. of the SPIE Int. Conf. on Storage and Retrieval for Image and Video Databases - III, </booktitle> <pages> pages 12-23, </pages> <address> San Jose, CA, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: These vectors have the property that images that are similar in content will be placed closer in the multidimensional space defined by the vectors. Hence the Euclidean distance between a pair of images gives a quantitative measure of the degree of similarity of their image contents <ref> [AMEM95] </ref>. 3 Placement Strategies The objective of our study is to propose and evaluate several different schemes for the placement of wavelet decomposed image data. We decided to use multiples of four disks for this study with most of the experiments using only four disks.
Reference: [Ano96] <author> Anonymous. </author> <title> Browsing and placement of mul-tiresolution images on secondary storage. </title> <type> Technical Report TRCS96-22, </type> <institution> Dept. </institution> <note> of Computer Science (A brief abstract of this paper will appear in the proceedings of an IEEE conference. Details omitted to facilitate blind review.), 1996. http://www.cs.ucsb.edu/TRs/TRCS96-22.ps. </note>
Reference-contexts: As expected, the crossover point where Separated performs better than Bundled shifted in the direction of larger number of clients. Further details can be found in <ref> [Ano96] </ref>. phases with 100% expansion To study the impact of the number of disks, the number of disks to was increased to eight. <p> Zonal and Interleaved do not have as many cache hits because the location of items that are accessed by any one client are usually on different disks, hence read ahead is not effective. Further details of these experiments can be found in <ref> [Ano96] </ref>. 5.3 Discussion In all the experiments, we observe that the Distance based strategies perform better than the corresponding Round Robin strategies (not shown for clarity). From this we conclude that it is always beneficial to decluster the images based upon their content.
Reference: [AS95] <author> S. Akyurek and K. Salem. </author> <title> Adaptive block rearrangement. </title> <journal> ACM Trans. on Comp. Systems, </journal> <volume> 13(2) </volume> <pages> 89-121, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: System performance depends upon efficient retrieval of data from secondary storage. A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage <ref> [AS95, BG88, CABK88, PGK88, CP90, GHW90] </ref>. Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]). <p> Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. <ref> [AS95, SWZ94] </ref>). Wavelet decomposed data are not as structured as relational databases, however they are not independent files. With the knowledge of the structure of wavelet decomposed data we can potentially do better than the more general techniques.
Reference: [BG88] <author> D. Bitton and J. Gray. </author> <title> Disk shadowing. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 331-338, </pages> <address> Los Angeles CA., </address> <month> September </month> <year> 1988. </year>
Reference-contexts: System performance depends upon efficient retrieval of data from secondary storage. A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage <ref> [AS95, BG88, CABK88, PGK88, CP90, GHW90] </ref>. Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]).
Reference: [CABK88] <author> G. Copeland, W. Alexander, E. Boughter, and T. Keller. </author> <title> Data placement in Bubba. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 99-108, </pages> <address> Chicago, </address> <year> 1988. </year>
Reference-contexts: System performance depends upon efficient retrieval of data from secondary storage. A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage <ref> [AS95, BG88, CABK88, PGK88, CP90, GHW90] </ref>. Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]).
Reference: [Cas96] <author> K. R. Castleman. </author> <title> Digital Image Processing. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1996. </year>
Reference-contexts: One method of providing images at multiple resolutions is storing multiple copies of images at various resolutions, as in the Chabot project. Due to the multiple copies the storage requirements of this scheme are high. A more storage efficient scheme is to use image decomposition techniques such as wavelets <ref> [Cas96] </ref>. Wavelets transform an image into multiple image coefficients without incurring any additional storage overhead, and one of the coefficients has visual similarity to the original image. Thus, the visually similar coefficient can be thought of as a thumbnail or icon of the original image. <p> Section 4 presents the simulation setup used for the experiments. In Section 5 we present and discuss the results from the simulations. Section 6 presents experiments with real disks and Section 7 concludes the paper. 2 Review of Image Processing Techniques The wavelets transform <ref> [Cas96] </ref> decomposes images into progressively lower resolutions as follows. Beginning with an original image of size N fi M (for simplicity, assume that N and M are powers of 2), the image is decomposed into four parts, each of size N=2fiM=2, as shown in Figure 1.
Reference: [CK93] <author> T. Chiueh and R. H. Katz. </author> <title> Multi-resolution video representation for parallel disk arrays. </title> <booktitle> ACM Transaction on Multimedia, </booktitle> <pages> pages 401-409, </pages> <year> 1993. </year>
Reference-contexts: Wavelet decomposed data are not as structured as relational databases, however they are not independent files. With the knowledge of the structure of wavelet decomposed data we can potentially do better than the more general techniques. In a similar setting, Chiueh and Katz <ref> [CK93] </ref> discuss pyramidal coding schemes for multiresolution video data and a storage layout on parallel disk arrays to provide real time jitter-free video retrieval. They do not however discuss the issue of the relative placement of stripes on disk for better performance.
Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> McGraw-Hill MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: This problem in general has been shown to be NP-complete [GJ79]. However, if we limit the maximum degree of each vertex to d max , then a coloring using d max + 1 colors exists <ref> [CLR90] </ref>. For such a graph a simple greedy algorithm can be used to find such a coloring. This algorithm assigns colors to nodes in a sequential traversal trying to assign the lowest possible color that is different from all colors assigned to its neighbors.
Reference: [CP90] <author> P. M. Chen and D. A. Patterson. </author> <title> Maximizing performance in a striped disk-array. </title> <booktitle> In Proc. of the 17th Int. Sym. on Comp. Architecture, </booktitle> <pages> pages 322-331, </pages> <year> 1990. </year>
Reference-contexts: System performance depends upon efficient retrieval of data from secondary storage. A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage <ref> [AS95, BG88, CABK88, PGK88, CP90, GHW90] </ref>. Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]).
Reference: [DK93] <author> A. L. Drapeau and R. H. Katz. </author> <title> Striping in large tape libraries. </title> <booktitle> In Proc. of Supercomputing, </booktitle> <pages> pages 378-387, </pages> <address> Portland, Oregon, 1993. </address> <publisher> ACM. </publisher>
Reference-contexts: Instead of generating four independent requests to the disks in the second phase, Separated generates a single coarser request to the fourth disk. This reduces the level of contention and the average queueing delays. Similar effects were also observed by Drapeau and Katz <ref> [DK93] </ref> in their experiments with striping in tape libraries. To test this hypothesis, we ran tests where the expansion of the thumbnails was requested one image at a time rather than as a set. <p> Increasing the number of disks reduced the level of contention and limited the gains of the Separated strategy. This implies that the number of disks should be scaled with the degree of con-currency. The experiments of Drapeau and Katz <ref> [DK93] </ref> on tape libraries also bore out similar conclusions. The influence of disk caching was also investigated by increasing the disk cache size to 128 Kilobytes the maximum size for the disks simulated.
Reference: [FBF + 94] <author> C. Faloutsos, R. Barber, M. Flickner, J. Hafner, W. Niblack, D. Petkovic, and W. Equitz. </author> <title> Efficient and effective querying by image content. </title> <journal> In Journal of Intelligent Information Systems, </journal> <volume> volume 3, </volume> <pages> pages 231-262, </pages> <year> 1994. </year>
Reference-contexts: The allocation strategy followed in Chabot is to place all thumbnails and metadata about thumbnails on disk and all higher resolution images on tertiary storage. This results in relatively fast browsing of thumbnails, at the cost of slower retrieval of higher resolution images. Query by Image Content <ref> [NBE + 93, FBF + 94] </ref> does not address the issues of image placement for performance improvement. There appears to be a general lack of placement techniques for image data.
Reference: [GD90] <author> S. Ghandeharizadeh and D. J. DeWitt. </author> <title> A multiuser performance analysis of alternative declustering strategies. </title> <booktitle> In Proc. Int. Conf. Data Engineering, </booktitle> <pages> pages 466-475, </pages> <address> Los Angeles, Cali-fornia., </address> <month> February </month> <year> 1990. </year>
Reference-contexts: A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage [AS95, BG88, CABK88, PGK88, CP90, GHW90]. Some studies such as <ref> [GD90, LSR92] </ref>, have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]).
Reference: [GHW90] <author> J. Gray, B. Horst, and M. Walker. </author> <title> Parity striping of disc arrays: Low-cost reliable storage with acceptable throughput. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 148-161, </pages> <address> Washington DC., </address> <month> August </month> <year> 1990. </year>
Reference-contexts: System performance depends upon efficient retrieval of data from secondary storage. A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage <ref> [AS95, BG88, CABK88, PGK88, CP90, GHW90] </ref>. Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]).
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability, A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Similarly the graph k-colorability problem is to assign colors to nodes in a graph such that no two adjacent nodes have the same color using at most k colors. This problem in general has been shown to be NP-complete <ref> [GJ79] </ref>. However, if we limit the maximum degree of each vertex to d max , then a coloring using d max + 1 colors exists [CLR90]. For such a graph a simple greedy algorithm can be used to find such a coloring.
Reference: [KK95] <author> K. Keeton and R. H. Katz. </author> <title> Evaluating video layout strategies for a high-performance storage server. </title> <journal> Multimedia Systems, </journal> <volume> 3:43 - 52, </volume> <year> 1995. </year>
Reference-contexts: They do not however discuss the issue of the relative placement of stripes on disk for better performance. Placement techniques for multiresolution video data based upon the RAID-II prototype have been studied in <ref> [KK95] </ref>. Multiresolution video data is obtained through sub-band video coding which, like wavelets for images, generates several bands (coefficients) without data replication. Both these studies, however, are not directly applicable to non video data. <p> For low con-currency, the strategies that decluster the image coefficients perform better and for high concurrency the strategies that do not decluster coefficients perform better. It is interesting to note that Keeton and Katz <ref> [KK95] </ref> observed similar results for multiresolution video data. In particular, they found that declustering coefficients or subbands for video resulted in better performance only for low or moderate con-currencies. 6 Results with Real Disks In order to validate the simulation results, some representative experiments using actual disks were conducted.
Reference: [KSR94] <author> D. Kotz, T. B. Song, and S. Radhakrishnan. </author> <title> A detailed simulation of the HP 97560 disk drive. </title> <type> Technical Report TR94-220, </type> <institution> Comp. Sci. Dept., Dartmouth College., </institution> <year> 1994. </year>
Reference-contexts: Use of a simulator provides much greater flexibility. Some of the experiments are repeated with real disks. These results are discussed in Section 6. The simulator that we use has been developed by Kotz et al. <ref> [KSR94] </ref> based on the model developed by Ruemmler and Wilkes of HP laboratories [RW94]. The model is sophisticated and is capable of simulating multiple disks connected to multiple I/O buses. the effects of placement, it is necessary to have a model of the usage patterns. <p> In particular, four separate disks are used in order to investigate inter-disk parallelism for seeking. The simulator models the HP 97560 disk. Some of the parameters of these disks are given in Table 1. Further details of the disk and the model can be found in [RW94] and <ref> [KSR94] </ref>. Although the specified size of the cache for the HP 97560 is 128 Kilobytes, we limited the cache to 4 Kilobytes, in order to study the placement strategies in the absence of caching. Note that 4 Kilobytes is the size of the thumbnail and each coefficient of the images.
Reference: [LSR92] <author> J. Li, J. Srivastava, and D. Rotem. CMD: </author> <title> a multidimensional declustering method for parallel database systems. </title> <booktitle> In Proceedings of the Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 3-14, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage [AS95, BG88, CABK88, PGK88, CP90, GHW90]. Some studies such as <ref> [GD90, LSR92] </ref>, have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]).
Reference: [MM94] <author> W. Y. Ma and B. S. Manjunath. </author> <title> Pictorial queries: Combining feature extraction with database search. </title> <type> Technical Report CIPR 94-18, </type> <institution> Univ. of California, Santa Barbara, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: This method is undesirable because of the slow speed of the annotation process and also the dependence on and limitation of the subjective interpretation of the expert. Fortunately, there exist several image processing techniques for quantifying the image content [NBE + 93, OS95]. We used the Gabor Transform <ref> [MM94] </ref> to generate a set of features for each image. The features for each image are viewed as a vector in a multidimensional space. These vectors have the property that images that are similar in content will be placed closer in the multidimensional space defined by the vectors.
Reference: [NBE + 93] <author> W. Niblack, R. Barber, W. Equitz, M. Flickner, E. Glasman, D. Petkovic, and P. Yanker. </author> <title> The QBIC project: Querying images by content using color, texture and shape. </title> <booktitle> In Proc. of the SPIE Conf. 1908 on Storage and Retrieval for Image and Video Databases, volume 1908, </booktitle> <pages> pages 173-187, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: 1 Introduction With rapid advances in computer and communication technologies, there is an increasing demand to build and maintain large image repositories. Two examples of such repositories are the Chabot project [OS95] and the IBM Almaden Center's QBIC project <ref> [NBE + 93] </ref>. This need is particularly critical for the experts working in the fields of remote-sensing and earth sciences. <p> Multiresolution image retrieval seems to be the key to providing efficient browsing of image data. This retrieval model is employed both in the QBIC <ref> [NBE + 93] </ref> system as well as the Chabot [OS95] project. One method of providing images at multiple resolutions is storing multiple copies of images at various resolutions, as in the Chabot project. Due to the multiple copies the storage requirements of this scheme are high. <p> The allocation strategy followed in Chabot is to place all thumbnails and metadata about thumbnails on disk and all higher resolution images on tertiary storage. This results in relatively fast browsing of thumbnails, at the cost of slower retrieval of higher resolution images. Query by Image Content <ref> [NBE + 93, FBF + 94] </ref> does not address the issues of image placement for performance improvement. There appears to be a general lack of placement techniques for image data. <p> In this paper, the process of reconstructing an image by one level is referred to as expansion of the image. Content based browsing refers to retrieving images based on the similarity of the visual information contained in the images <ref> [NBE + 93, OS95] </ref>. For example, having seen a specific hurricane image, a user may want to see similar images of hurricanes. In order to evaluate the similarity of images, one would first quantify the image content using several possible techniques. <p> This method is undesirable because of the slow speed of the annotation process and also the dependence on and limitation of the subjective interpretation of the expert. Fortunately, there exist several image processing techniques for quantifying the image content <ref> [NBE + 93, OS95] </ref>. We used the Gabor Transform [MM94] to generate a set of features for each image. The features for each image are viewed as a vector in a multidimensional space.
Reference: [OS95] <author> V. E. Ogle and M. Stonebraker. Chabot: </author> <title> Retrieval from a relational database of images. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 41-48, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: 1 Introduction With rapid advances in computer and communication technologies, there is an increasing demand to build and maintain large image repositories. Two examples of such repositories are the Chabot project <ref> [OS95] </ref> and the IBM Almaden Center's QBIC project [NBE + 93]. This need is particularly critical for the experts working in the fields of remote-sensing and earth sciences. <p> Multiresolution image retrieval seems to be the key to providing efficient browsing of image data. This retrieval model is employed both in the QBIC [NBE + 93] system as well as the Chabot <ref> [OS95] </ref> project. One method of providing images at multiple resolutions is storing multiple copies of images at various resolutions, as in the Chabot project. Due to the multiple copies the storage requirements of this scheme are high. <p> In this paper, the process of reconstructing an image by one level is referred to as expansion of the image. Content based browsing refers to retrieving images based on the similarity of the visual information contained in the images <ref> [NBE + 93, OS95] </ref>. For example, having seen a specific hurricane image, a user may want to see similar images of hurricanes. In order to evaluate the similarity of images, one would first quantify the image content using several possible techniques. <p> This method is undesirable because of the slow speed of the annotation process and also the dependence on and limitation of the subjective interpretation of the expert. Fortunately, there exist several image processing techniques for quantifying the image content <ref> [NBE + 93, OS95] </ref>. We used the Gabor Transform [MM94] to generate a set of features for each image. The features for each image are viewed as a vector in a multidimensional space. <p> The Separated placement strategy differs from the others in that the thumbnails are placed on only three disks and all the other three coefficients are placed together on the fourth disk. This storage organization is similar to the placement of data in the Chabot project at UC Berkeley <ref> [OS95] </ref> where the lowest-resolution images or thumbnails are stored on disks and all higher resolution images are stored in tertiary storage (which is in contrast to the fourth disk in the Separated placement strategy).
Reference: [PGK88] <author> D. A. Patterson, G. Gibson, and R. H. Katz. </author> <title> A case for Redundant Arrays of Inexpensive Disks (RAID). </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 109-116, </pages> <address> Chicago, </address> <year> 1988. </year>
Reference-contexts: System performance depends upon efficient retrieval of data from secondary storage. A standard technique for improving disk performance is to control the placement of data on disks. Several data placement techniques have been used to overcome the I/O bottleneck of secondary storage <ref> [AS95, BG88, CABK88, PGK88, CP90, GHW90] </ref>. Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. [AS95, SWZ94]).
Reference: [RW94] <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> IEEE Computer, </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Use of a simulator provides much greater flexibility. Some of the experiments are repeated with real disks. These results are discussed in Section 6. The simulator that we use has been developed by Kotz et al. [KSR94] based on the model developed by Ruemmler and Wilkes of HP laboratories <ref> [RW94] </ref>. The model is sophisticated and is capable of simulating multiple disks connected to multiple I/O buses. the effects of placement, it is necessary to have a model of the usage patterns. Since traces of actual user access patterns for image repositories are not available, we developed approximate models. <p> In particular, four separate disks are used in order to investigate inter-disk parallelism for seeking. The simulator models the HP 97560 disk. Some of the parameters of these disks are given in Table 1. Further details of the disk and the model can be found in <ref> [RW94] </ref> and [KSR94]. Although the specified size of the cache for the HP 97560 is 128 Kilobytes, we limited the cache to 4 Kilobytes, in order to study the placement strategies in the absence of caching.
Reference: [SF95] <author> T. R. Smith and J. Frew. </author> <title> Alexandria digital library. </title> <journal> Communications of the ACM, </journal> <volume> 38(4) </volume> <pages> 61-62, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Two examples of such repositories are the Chabot project [OS95] and the IBM Almaden Center's QBIC project [NBE + 93]. This need is particularly critical for the experts working in the fields of remote-sensing and earth sciences. The Alexandria project <ref> [SF95] </ref> at UC Santa Barbara has been initiated to build a digital library fl Work supported by a research grant from NSF/ARPA/NASA IRI9411330 and NSF instrumentation grant CDA-9421978. for maps and image data, typically stored in raster or vector format.
Reference: [SWZ94] <author> P. Scheuermann, G. Weikum, and P. Zabback. </author> <title> "Disk Cooling" in parallel disk systems. </title> <journal> Bulletin of the Technical Committee on Data Engineering, </journal> <volume> 17(3) </volume> <pages> 29-40, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Some studies such as [GD90, LSR92], have relied on the well understood data structure and access patterns of relational databases to develop placement techniques. Others have worked in more general settings where the data is viewed only as independent files (e.g. <ref> [AS95, SWZ94] </ref>). Wavelet decomposed data are not as structured as relational databases, however they are not independent files. With the knowledge of the structure of wavelet decomposed data we can potentially do better than the more general techniques.
References-found: 24

