URL: http://polaris.cs.uiuc.edu/reports/1396.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Title: Parallelization in the Presence of Generalized Induction and Reduction Variables  
Author: Bill Pottenger and Rudolf Eigenmann 
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: The elimination of induction variables and the parallelization of reductions in FORTRAN programs has been shown to be integral to performance improvement on parallel computers [9, 10]. As part of the Polaris project, compiler passes that recognize these idioms have been implemented and evaluated. Developing these techniques to the point necessary for achieving significant speedups on real applications has prompted solutions to problems that have not been addressed in previous reports. These include analysis capabilities to disprove zero-trip loops, symbolic handling facilities to compute closed forms of recurrences, and interfaces to other compilation passes, such as the data-dependence test. In comparison, the analysis phase of induction variables, which has received most attention so far, has turned out to be relatively straightforward.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Zahira Ammarguellat and Luddy Harrison. </author> <title> Automatic Recognition of Induction & Recurrence Relations by Abstract Interpretation. </title> <booktitle> Proceedings of Sigplan 1990, </booktitle> <address> Yorktown Heights, </address> <month> 25(6) </month> <pages> 283-295, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The strength of this approach lies in the ability of the algorithm to handle a variety of both induction variables and generalized induction expressions under a variety of control flow conditions. Abstract Interpretation Harrison and Ammarguellat's approach <ref> [1] </ref> is based on abstract interpretation, and represents syntactic constructs as maps from variables to expressions which encapsulate the state prior to entry to the construct.
Reference: [2] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference: [3] <author> M. Berry, D. Chen, P. Koss, D. Kuck, L. Pointer, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orszag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The Perfect Club Benchmarks: Effective Performance Evalution of Supercomputers. </title> <booktitle> Int'l. Journal of Supercomputer Applications, Fall 1989, </booktitle> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: of the positions or policies of the Army or the Government. 1 In triangular loop nests, inner loop bounds depend on outer loop indices 1 2 Problem Presentation 2.1 What is Induction Variable Substitution? A class of inductions important to the parallelization of the the Perfect Club Benchmarks R fl <ref> [3] </ref> are termed coupled inductions. For example: K1 = 0 Do I = 1; N K1 = K1 + 1 EndDo K2 = K2 + K1 EndDo Here the induction variable K2 is dependent on the triangular induction variable K1.
Reference: [4] <author> Bill Blume, Rudolf Eigenmann, Keith Faigin, John Grout, Jay Hoeflinger, David Padua, Paul Petersen, Bill Pottenger, Lawrence Rauchwerger, Peng Tu, and Stephen Weatherford. </author> <title> Polaris: The Next Generation in Parallelizing Compilers. </title> <booktitle> Proceedings of the Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Ithaca, New York, pages 10.1 - 10.18, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The system also guarantees the correctness of all control flow information. This is realized through automatic incremental updates of this information as a transformation proceeds <ref> [4] </ref>. 3.1 Induction Variable Substitution The simplest case of an induction variable takes the form: iv = iv + constant and is handled well by existing parallelizing compilers.
Reference: [5] <author> William Blume and Rudolf Eigenmann. </author> <title> The Range Test: A Dependence Test for Symbolic, Nonlinear Expressions. </title> <booktitle> Proceedings of Supercomputing '94, November 1994, </booktitle> <address> Washington D.C., </address> <pages> pages 528-537, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The parallelization of loops requires resolution of many types of data dependences ([2], <ref> [5] </ref>, [17]). In particular, cross-iteration dependences caused by inductions may prohibit parallel execution. Induction variable substitution is an important technique for resolving certain classes of such dependences. In addition, induction solution provides the environment within which privatization of arrays can take place. <p> Following this, a second, data-dependence test pass analyzes these candidate reductions to determine if they are indeed reductions <ref> [5] </ref>. If the data-dependence test can prove independence (i.e., the accumulation operation uses different elements of the array sum () in each loop iteration), the candidate reduction flag is removed from this variable. Finally, a transformation stage dependent on architectural considerations generates either blocked, privatized, or expanded reductions.
Reference: [6] <author> William Blume and Rudolf Eigenmann. </author> <title> Symbolic Range Propagation. </title> <booktitle> Proceedings of the 9th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995, </year> <month> October </month> <year> 1994. </year>
Reference-contexts: For example, the following transformation is only correct for n 0. ind=0 iv=iv+2 ENDDO print *,iv ) a (i*2) = ... ENDDO print *,n*2 Our algorithm handles this zero trip problem with new techniques developed in <ref> [6] </ref> known as Sym bolic Range Propagation. Thanks to these techniques we were able to prove in all crucial cases of our application test suite that loops do not have zero trips. <p> One issue in implementing methods two and three is to determine the size of the partial sum variables for histogram reductions. This is a non-trivial problem in symbolic analysis and is currently handled by the same techniques used in the zero-trip test, Symbolic Range Propagation <ref> [6] </ref>. The range accessed by each reduction statement is determined using interprocedural symbolic analysis, and the resulting ranges are merged to give an overall range. This merged range is then used to allocate the correct amount of memory for the expanded or privatized array.
Reference: [7] <author> William Blume, Rudolf Eigenmann, Jay Hoeflinger, David Padua, Paul Petersen, Lawrence Rauch-werger, and Peng Tu. </author> <title> Automatic Detection of Parallelism: A Grand Challenge for High-Performance Computing. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 2(3) </volume> <pages> 37-47, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: The initialization and final reduction can both be executed in parallel. 3 Implementation The induction substitution and reduction recognition passes are implemented on a basic infrastructure provided by the Polaris compiler development environment <ref> [7] </ref>. Within Polaris, access to the internal program representation is controlled through a data-abstraction mechanism. Operations built onto the internal representation are defined such that the programmer is prevented from violating its structure or leaving it in an incorrect state at any point during a transformation.
Reference: [8] <author> SGI Documentation. </author> <title> Fortran 77 Programmer's Guide and associated man pages. </title> <type> Technical report, </type> <institution> Silicon Graphics, Inc., </institution> <year> 1994. </year>
Reference-contexts: All parallel timing was conducted on an 8 processor processor set. For comparison purposes, the three benchmarks under discussion were compiled and executed using the commercially available SGI product Power Fortran Accelerator, PFA <ref> [8] </ref>. Compilation commands were as follows: for the serial runs, "f77 -O2 -mips2"; for the Polaris parallel runs, "f77 -mp -O2 -mips2"; and for the PFA runs, "f77 -pfa keep -O2 -mips2" 9 .
Reference: [9] <author> Rudolf Eigenmann, Jay Hoeflinger, Zhiyuan Li, and David Padua. </author> <title> Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs. </title> <booktitle> Lecture Notes in Computer Science 589. Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <pages> pages 65-83, </pages> <month> August </month> <year> 1991. </year>
Reference: [10] <author> Rudolf Eigenmann, Jay Hoeflinger, and David Padua. </author> <title> On the Automatic Parallelization of the Perfect Benchmarks . Technical Report 1392, </title> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Current compilers are able to solve simple scalar reductions and in some cases, single dimensional array reductions with invariant indices. Based on work completed in <ref> [10] </ref>, however, two additional classes of reductions were determined important: single address reductions, which occur on a scalar or on an array of one or more dimensions with loop invariant indices; and histogram reductions, which occur on arrays with loop variant indices. fl This work is supported by the National Security <p> = 0 DoAll I = 1; N DoAll J = 1; I K1 private = J + (I 2 I)=2 A (((I 3 + 2 fl I)=3 I)=2) = 0 EndDo K2 private = ((I 3 + 2 fl I)=3 I)=2 EndDo A second class of inductions determined important in <ref> [10] </ref> involve multiplicative inductions 2 . <p> Table 4 that this same reduction was solved by PFA using the more aggressive compilation options "-ag=a -r=3", which allow transformations based on associativity. 5 Related Work Induction variable substitution and parallel reductions were recognized as two of four performance-critical techniques necessary for the parallelization of the Perfect Club Benchmarks <ref> [10] </ref>. Several related approaches to the solution of these two problems have been presented in the literature. At a high level, all these approaches fall under the category of symbolic analysis. <p> To that end we have focussed on two techniques which were identified as important in <ref> [10] </ref> induction variable substitution and parallel reductions. 11 The induction variable types we have termed triangular and multiplicative fall into these two classes 13 Our implementation confirms the findings of these early studies; namely, that idiom recognition techniques are crucial to good performance of real applications.
Reference: [11] <author> Michael P. Gerlek, Eric Stoltz, and Michael Wolfe. </author> <title> Beyond induction variables: Detecting and classifying sequences using a demand-driven ssa form. </title> <note> To appear in TOPLAS. </note>
Reference-contexts: The authors make the point that "This allows the scheme to be tailored to the recognition of a variety of recurrence relations, appropriate to the particular language or applications being compiled." SSA Based Classification Wolfe et al base their approach on the Static Single Assignment representation of the program <ref> [11] </ref>. The algorithm breaks induction variable substitution down into two phases similar to the first two phases of our algorithm. During the recognition (and classification) stage, the SSA form of the graph is searched for patterns representing recurrences.
Reference: [12] <author> Mohammad R. Haghighat and Constantine D. Polychronopoulos. </author> <title> Symbolic Program Analysis and Optimization for Parallelizing Compilers. </title> <booktitle> Presented at the 5th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August 3-5, </month> <year> 1992. </year>
Reference-contexts: At a high level, all these approaches fall under the category of symbolic analysis. Symbolic Execution Haghighat and Polychronopoulos symbolically execute loops and use finite difference methods in conjunction with interpolation to determine the closed form for a given recurrence <ref> [12] </ref>. The scheme executes a loop and captures differences in values assumed by candidate induction variables from one iteration to the next. Differences of differences are taken as well recursively until a constant is obtained at depth d.
Reference: [13] <author> Luddy Harrison. </author> <title> Personal communication with author, </title> <year> 1994. </year>
Reference-contexts: One of the strengths of this approach lie in its capability to recognize inductions which cross conditional control flow structures. However, at the time of writing no capability was present to handle nested loops, and it has been determined that no further work has been conducted in this direction <ref> [13] </ref>. A second feature of this approach is the unification of recurrences with predefined templates containing closed forms.
Reference: [14] <author> Jay Hoeflinger. </author> <title> Automatic Parallelization and Manual Improvements of the Perfect Club Program OCEAN for Cedar. </title> <type> Technical Report 1246, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> July </month> <year> 1992. </year> <month> 15 </month>
Reference-contexts: becomes: K = 1 DoAll I = 1; N K private = 2 fl 2 ((1)+I) A (K private ) = 0 EndDo Collectively, these classes of inductions are a subset of a larger class termed Generalized Induction Variables, or GIVs. 2 Important in the Perfect Club Benchmark code OCEAN <ref> [14] </ref> 2 2.2 What is Reduction Recognition? Consider the following example code where A may be either scalar or multidimensional, ff may be a multivariate function of the loop indice (s), and fi is any symbolic expression: 3 : Do I = 1; N A (ff (i; : : :)) =
Reference: [15] <author> Jay Hoeflinger. </author> <title> Automatic Parallelization and Manual Improvements of the Perfect Club Program TRFD for Cedar. </title> <type> Technical Report 1247, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: As an example, consider the following loop which results from peeling the first iteration of loop 290 of OLDA do300 in the Perfect Club Benchmark TRFD <ref> [15] </ref> 7 : DO 291 K=I+1,N M = M + 1 281 XIJKL (M) = XKL (L) 291 CONTINUE The last value i@n K m of the induction variable m after loop K is: i@n K n X k 0 = (n + n 2 i i 2 )=2 When I
Reference: [16] <author> D. Padua and M. Wolfe. </author> <title> Advanced Compiler Optimization for Supercomputers. </title> <journal> CACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December, </month> <year> 1986. </year>
Reference-contexts: This preserves the semantics of the original untransformed K loop nest. 3.1.2 Wrap Around Variables A wrap around variable is classically defined as a variable which takes on the value of an induction variable after one iteration of a loop <ref> [16] </ref>. There is at least one important case in the Perfect Club Benchmarks where a wrap around variable of this type occurs as the bound of a loop containing an induction site.
Reference: [17] <author> W. Pugh. </author> <title> The omega test: A fast and practical integer programming algorithm for dependence analysis. </title> <booktitle> Supercomputing '91, </booktitle> <year> 1991. </year>
Reference-contexts: 1 Introduction The parallelization of loops requires resolution of many types of data dependences ([2], [5], <ref> [17] </ref>). In particular, cross-iteration dependences caused by inductions may prohibit parallel execution. Induction variable substitution is an important technique for resolving certain classes of such dependences. In addition, induction solution provides the environment within which privatization of arrays can take place.
Reference: [18] <author> Peng Tu and David Padua. </author> <title> Automatic Array Privatization. </title> <editor> In Utpal BanerjeeDavid Gelern-terAlex NicolauDavid Padua, editor, </editor> <booktitle> Proc. Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR. </address> <booktitle> Lecture Notes in Computer Science., </booktitle> <volume> volume 768, </volume> <pages> pages 500-521, </pages> <month> August 12-14, </month> <year> 1993. </year>
Reference-contexts: In the presence of induction variables in array subscripts, induction solution is a prerequisite to the resolution of cross-iteration dependences on array accesses. When combined with array privatization, induction variable substitution becomes a powerful tool for removing cross-iteration dependences <ref> [18] </ref>. Current compilers are able to handle induction statements with loop invariant right hand sides in multiply nested "rectangular" loops.
Reference: [19] <author> Peng Tu and David Padua. </author> <title> Demand-Driven Symbolic Analysis. </title> <type> Technical Report 1336, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> Febraury </month> <year> 1994. </year>
Reference-contexts: lower bound of loop 280 also takes on a constant value after one iteration. 7 The necessity of this peeling is discussed in the following section 6 The recognition of both of these wrap around variables can be accomplished by representing the program in SSA form and using back substitution <ref> [19] </ref> based on techniques discussed in [21]. Simple techniques such as these are sufficient to recognize the wrap around variable patterns that we found in our test suite.
Reference: [20] <author> Stephen Weatherford. </author> <title> High-Level Pattern-Matching Extensions to C++ for Fortran Program Manipulation in Polaris. </title> <type> Master's thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: The algorithm recognizes potential reductions which fall into the two classes of histogram reductions (where ff is loop-variant) and single address reductions (where ff is loop-invariant). The reduction recognition pass of Polaris is based on powerful pattern matching primitives that are part of the Polaris FORBOL environment <ref> [20] </ref>. Transformation In the transformation stage, three different types of parallel reductions can be generated. They are termed blocked, privatized, and expanded. All three schemes take advantage of the fact that the sum operation is mathematically commutative and associative, and thus the accumulation statement sequence can be reordered.
Reference: [21] <author> Michael Wolfe. </author> <title> Beyond induction variables. </title> <booktitle> Proceedings of ACM/SIGPLAN PLDI, </booktitle> <pages> pages 162-174, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: takes on a constant value after one iteration. 7 The necessity of this peeling is discussed in the following section 6 The recognition of both of these wrap around variables can be accomplished by representing the program in SSA form and using back substitution [19] based on techniques discussed in <ref> [21] </ref>. Simple techniques such as these are sufficient to recognize the wrap around variable patterns that we found in our test suite.
Reference: [22] <author> Michael Wolfe and Michael Gerlek. </author> <title> Personal communication with authors, </title> <booktitle> 1994. </booktitle> <pages> 16 </pages>
Reference-contexts: This scheme also is able to recognize the wrap around variables discussed in Section 3.1.2. As of the date of this writing, Wolfe et al are in the process of implementing the techniques necessary to solve and substitute inductions of the form discussed in Section 3.1 <ref> [22] </ref>. Our approach Our approach differs from these schemes in its emphasis on the complementing capabilities an idiom substitution pass needs to have in order to achieve substantial performance gains in real programs.
References-found: 22

