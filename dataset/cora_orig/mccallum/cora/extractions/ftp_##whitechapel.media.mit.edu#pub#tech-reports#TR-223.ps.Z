URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-223.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: sourabh@media.mit.edu and adelson@media.mit.edu  
Title: Analyzing and Recognizing Walking Figures in XYT  
Author: Sourabh A. Niyogi and Edward H. Adelson 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: MIT Media Laboratory  
Pubnum: Perceptual Computing Section  
Abstract: M.I.T. Media Lab Vision and Modeling Group Technical Report No. 223 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chen, Z. and Lee, H. </author> <title> Knowledge-guided visual perception of 3-d human gait from a single image sequence. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 22 </journal> <pages> 336-342. </pages>
Reference-contexts: Since only some of the parts are visible at any given time, any approach that attempts to recover a full three-dimensional model will have considerable difficulty defining the position of occluded body parts. Some make the problem more tractable by interpreting motion with marked feature points <ref> [19, 12, 13, 1, 4] </ref>.
Reference: [2] <author> Cipolla, R. and Yamamoto, M. </author> <title> Stereoscopic tracking of bodies in motion. </title> <booktitle> Image and Vision Computing 8: </booktitle> <pages> 85-90, </pages> <year> 1990 </year> <month> 11 </month>
Reference: [3] <author> Cutting, J.E. and Kozlowski, L. </author> <title> Recog--nizing friend by their walk: Gait perception without familiarity cues. </title> <journal> Bulletin of the Psychonomic Society 9 </journal> <pages> 353-356, </pages> <year> 1977. </year>
Reference-contexts: In gait detection, we find a spatiotemporal pattern that signals the presence of a walking person. In gait recognition, we seek to identify the individual who is walking. It is known that humans can detect and recognize gait with reduce spatiotem-poral sequences (such as moving light displays) <ref> [3, 10] </ref>, and we would like to give similar capabilities to machines. Any reasonable approach to the interpretation of human motion must impose a model of a human and explain how visual observations are to be fitted to the model. Model recovery is difficult for a number of reasons.
Reference: [4] <author> Goddard, N. </author> <title> The perception of articulated motion: Recognizing moving light displays, </title> <institution> University of Rochester Ph.D. </institution> <type> thesis, </type> <month> June </month> <year> 1992. </year>
Reference-contexts: Since only some of the parts are visible at any given time, any approach that attempts to recover a full three-dimensional model will have considerable difficulty defining the position of occluded body parts. Some make the problem more tractable by interpreting motion with marked feature points <ref> [19, 12, 13, 1, 4] </ref>.
Reference: [5] <author> Hogg, D. </author> <title> Model-based vision: a program to see a walking person. </title> <booktitle> Image and Vision Computing 1: </booktitle> <pages> 5-20, </pages> <year> 1983. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time.
Reference: [6] <author> Kurakake, S. and Nevatia, R. </author> <title> Description and tracking of moving articulated objects, </title> <journal> ICPR pp. </journal> <pages> 491-495, </pages> <year> 1992 </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time.
Reference: [7] <author> Leung, M. and Yang, </author> <title> Y.H. Human body motion segmentation in a complex scene. </title> <booktitle> Pattern Recognition 20: </booktitle> <pages> 55-64, </pages> <year> 1987. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time. <p> One reason for this approach is that standard optical flow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking efforts use a change detection operation as well to bypass these problems <ref> [18, 7, 17, 16] </ref>. The constant background assumption employed here need not be so strong. A background appears as vertical stripes in an XT-slice. If the background is in motion, then the background will appear as oriented stripes in the XT-slice.
Reference: [8] <author> Leung, M. and Yang, </author> <title> Y.H. A region based approach for human body motion analysis. </title> <booktitle> Pattern Recognition 20: </booktitle> <pages> 321-339, </pages> <year> 1987. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time.
Reference: [9] <author> Kass, M., Witkin, A. and Terzopoulos, D. SNAKES: </author> <title> Active contour models. Intern. </title> <editor> J. </editor> <booktitle> Computer Vision 1: </booktitle> <pages> 321-332. </pages>
Reference: [10] <author> Kozlowski, L. and Cutting, J. </author> <title> Recognizing the sex of a walker from a dynamic point-light display. </title> <journal> Perception and Psychophysics, </journal> <volume> 21: </volume> <pages> 575-580, </pages> <year> 1977. </year>
Reference-contexts: In gait detection, we find a spatiotemporal pattern that signals the presence of a walking person. In gait recognition, we seek to identify the individual who is walking. It is known that humans can detect and recognize gait with reduce spatiotem-poral sequences (such as moving light displays) <ref> [3, 10] </ref>, and we would like to give similar capabilities to machines. Any reasonable approach to the interpretation of human motion must impose a model of a human and explain how visual observations are to be fitted to the model. Model recovery is difficult for a number of reasons.
Reference: [11] <author> Marr, D. and Nishihara, H.K. </author> <title> Representation and recognition of the spatial organization of three-dimensional shapes. </title> <journal> Proc. R. Soc. London B 200: </journal> <pages> 269-294, </pages> <year> 1978. </year>
Reference: [12] <author> O'Rourke, J. and Badler, N. </author> <title> Model-based image analysis of human motion using constraint propagation. </title> <journal> IEEE PAMI 2: </journal> <pages> 522-536. </pages>
Reference-contexts: Since only some of the parts are visible at any given time, any approach that attempts to recover a full three-dimensional model will have considerable difficulty defining the position of occluded body parts. Some make the problem more tractable by interpreting motion with marked feature points <ref> [19, 12, 13, 1, 4] </ref>.
Reference: [13] <author> Rashid, R. </author> <title> Towards a system for the interpretation of moving light displays. </title> <journal> IEEE PAMI 2: </journal> <pages> 574-581, </pages> <year> 1980. </year>
Reference-contexts: Since only some of the parts are visible at any given time, any approach that attempts to recover a full three-dimensional model will have considerable difficulty defining the position of occluded body parts. Some make the problem more tractable by interpreting motion with marked feature points <ref> [19, 12, 13, 1, 4] </ref>.
Reference: [14] <author> Polana, R. and Nelson, R. </author> <title> Detecting activities. </title> <address> CVPR 2-7, </address> <year> 1993. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time.
Reference: [15] <author> Qian, R.J. and Huang, </author> <title> T.S. Motion analysis of human ambulatory patterns, </title> <address> ICPR 220-223, </address> <year> 1992. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time.
Reference: [16] <author> Rohr, K. </author> <title> Incremental recognition of pedestrians from image sequences. </title> <journal> CVPR pp. </journal> <pages> 8-13, </pages> <year> 1993. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time. <p> One reason for this approach is that standard optical flow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking efforts use a change detection operation as well to bypass these problems <ref> [18, 7, 17, 16] </ref>. The constant background assumption employed here need not be so strong. A background appears as vertical stripes in an XT-slice. If the background is in motion, then the background will appear as oriented stripes in the XT-slice.
Reference: [17] <author> Shio, A. and Sklansky, J. </author> <title> Segmentation of people in motion. </title> <booktitle> IEEE Workshop on Visual Motion, </booktitle> <pages> pp. 325-332, </pages> <year> 1991. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time. <p> One reason for this approach is that standard optical flow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking efforts use a change detection operation as well to bypass these problems <ref> [18, 7, 17, 16] </ref>. The constant background assumption employed here need not be so strong. A background appears as vertical stripes in an XT-slice. If the background is in motion, then the background will appear as oriented stripes in the XT-slice.
Reference: [18] <author> Tsukiyama, T. and Shirai, Y. </author> <title> Detection of the movements of persons from a sparse sequence of TV images. </title> <booktitle> Pattern Recognition 18: </booktitle> <pages> 207-213, </pages> <year> 1985. </year>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time. <p> One reason for this approach is that standard optical flow algorithms fail in regions where there are multiple motions, occlusion, and non-rigidly moving areas; many other human body tracking efforts use a change detection operation as well to bypass these problems <ref> [18, 7, 17, 16] </ref>. The constant background assumption employed here need not be so strong. A background appears as vertical stripes in an XT-slice. If the background is in motion, then the background will appear as oriented stripes in the XT-slice.
Reference: [19] <author> Webb, J.A. and Agarwal, J.K. </author> <title> Structure from motion of rigid and jointed objects. </title> <journal> Artificial Intelligence, </journal> <volume> 19: </volume> <pages> 107-130, </pages> <year> 1982 </year>
Reference-contexts: Since only some of the parts are visible at any given time, any approach that attempts to recover a full three-dimensional model will have considerable difficulty defining the position of occluded body parts. Some make the problem more tractable by interpreting motion with marked feature points <ref> [19, 12, 13, 1, 4] </ref>.
Reference: [20] <author> Yamamoto, M. and Koshikawa, K. </author> <title> Human motion analysis based on a robot arm model, </title> <booktitle> CVPR, </booktitle> <pages> pp. 664-665, </pages> <year> 1991. </year> <month> 12 </month>
Reference-contexts: Some make the problem more tractable by interpreting motion with marked feature points [19, 12, 13, 1, 4]. Recovering these features to these models is not a trivial task, and there have been several attempts to recover models from real imagery, each with a different goal <ref> [7, 8, 16, 18, 17, 14, 5, 6, 15, 20] </ref>. 2 Overview Our approach to human motion analysis takes a novel approach to model recovery, based on the observation that walkers generate special signatures in space-time.
References-found: 20

