URL: http://ftp.eecs.umich.edu/people/neuhoff/horowitz_thesis/MJH_thesis_J.ps
Refering-URL: http://ftp.eecs.umich.edu/people/neuhoff/horowitz_thesis/
Root-URL: http://www.eecs.umich.edu
Title: PERCEPTUAL IMAGE CODING USING A CORTICAL SNAPSHOT MODEL OF HUMAN VISION  
Author: by Michael Joseph Horowitz 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy  Doctoral Committee: Professor David Neuhoff, Chair Professor David Anderson Professor Gregory Wakefield Professor  
Note: Jun Zhang  
Date: 1998  
Affiliation: (Electrical Engineering: Systems) in The University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: <institution> 126 BIBLIOGRAPHY </institution>
Reference: [BaMo82] <author> H. B. Barlow, J. D. Mollon, </author> <title> The Senses, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1982. </year>
Reference-contexts: Moreover, we chose not to have d t,0 be a function of sensor orientation despite the fact that the sensitivity of the HVS is highest for stimuli oriented vertically or horizontally and is 15 to 20 percent lower for stimuli oriented at 45 degrees <ref> [BaMo82] </ref>. To be conservative therefore, we derived the values of d t,0 for vertically oriented RFP types and use those same values for non-vertically oriented RFP's.
Reference: [BaMa92] <author> R. Basari, V. J. Matthews, </author> <title> "Vector quantization of images using visual masking functions," </title> <booktitle> Proc. ICASSP, </booktitle> <volume> Vol. 3, </volume> <pages> pp. 365-368, </pages> <year> 1992. </year>
Reference-contexts: The other coefficients are quantized in the usual manner. All coefficients are then merged and entropy coded to produce a bit stream with standard 6 JPEG syntax. Other coders that explicitly exploit contrast masking include [NePr77], <ref> [BaMa92] </ref>, [Edd93], and [RaFa92]. Most of the coders designed to exploit contrast masking also take advantage of the sensitivity limitations described earlier. Image texture. Another characteristic of HVS sensitivity is related to image texture. <p> For example, in [Wat93], Watson develops a model for 58 perceptual sensitivities to DCT coefficients and uses the resulting sensitivity information to determine quantization thresholds in a DCT based transform coder. Additional examples of this common approach to perceptual image coder design include [SaJo89], [Gra93], [HaMa96], and <ref> [BaMa92] </ref>. In MDPIC, components from an HVS model such as the sensor responses of the cortical snapshot model are coded directly. The performance of an MDPIC coder is tied directly to the capability of the HVS model it employs.
Reference: [BeMa95] <author> F. Bergeaud, S. Mallat, </author> <title> "Processing images and sounds with matching pursuit," </title> <booktitle> SPIE, Wavelet Applications in Signal Processing and Image Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 2-13, </pages> <year> 1995. </year>
Reference-contexts: Further, the decomposition resulting from the use of a 2D Gabor or Gabor-like dictionary is in some respects similar to the decomposition performed at the striate cortex suggesting a useful role for adapted basis in perceptual coding. In <ref> [BeMa95] </ref>, the authors describe how Matching Pursuit can be used to produce a compact representation of an image from a dictionary containing 2D Gabor functions though no explicit coding method is described.
Reference: [Bud88] <author> S. Budge, T. Stockham Jr., D. Chabries, R. Christiansen, </author> <title> "Vector quantization of color digital images within a human visual model," </title> <booktitle> Proc. ICASSP, </booktitle> <pages> pp. 816-819, </pages> <year> 1988. </year>
Reference-contexts: Light adaptation involves the HVS's diminishing sensitivity as background luminance levels increase. This effect is well known in perception and is characterized by Weber's Law. So called homomorpic coding systems such as those developed by Mannos and Sakrison [MaSa74] and Budge et. al. <ref> [Bud88] </ref> as well as those suggested by C. F. Hall and E. L. Hall [Hal77] and Stockham [Sto72], exploit the effects of light adaptation.
Reference: [Che95] <author> S. Chen, </author> <title> Basis Pursuit. </title> <type> Ph.D. Thesis, </type> <institution> Department of Statistics, Stanford University, </institution> <year> 1995. </year>
Reference-contexts: It follows that the atoms are linearly dependent. Several adapted basis techniques have been developed in recent years. We shall briefly describe the most prevalent. Two adapted basis techniques, the Method of Frames [Dbc88] and Basis Pursuit <ref> [Che95] </ref> have similar goals. They find from among all solutions of (5.1) the one whose coefficients, g m , have the smallest l n norm.
Reference: [Dal93] <author> S. Daly, </author> <title> "The visible differences predictor," In Digital Images and Human Vision, </title> <editor> ed. A. B. </editor> <booktitle> Watson, </booktitle> <pages> pp. 179-206, </pages> <address> MA: </address> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In addition, the choice of cutoff ratio, the ratio of the cutoff frequency of the highest frequency band to the Nyquist frequency, also affected the degree of aliasing. After an extensive search, we settled on a set of parameters that represented a good compromise for all conflicting effects. In <ref> [Dal93] </ref>, Daly suggests an alternative approach to mitigate ringing which might have made our task simpler. A third problem with the coder, as suggested by the results in [Wat87] and verified by us, is that the B q parameters are image dependent. <p> We suspect that the rippling is caused by the fact that the lowpass sensor RFPs do not smoothly cover large uniform image features. In <ref> [Dal93] </ref>, Daly mentions modifying the shape of the lowpass sensor to alleviate a similar problem he encountered.
Reference: [Dau80] <author> J. Daugman, </author> <title> "Two-dimensional spectral analysis of cortical receptive field profiles," </title> <journal> Vision Research, </journal> <volume> vol. 20, </volume> <pages> pp. 847-856, </pages> <year> 1980. </year>
Reference-contexts: By the late 1970's, a sensor-based-model for human vision based on the behavior of retinal ganglion cells could accurately predict the results of I/O-model-based contrast sensitivity experiments [WiBe79]. Contributions in the 1980's by Marr [Mar82], Legge and Foley [FoLe81], Daugman <ref> [Dau80] </ref>, and others helped to produce models capable of accurately predicting contrast sensitivity, light adaptation, contrast masking and other visual phenomena. A particularly important example of a sensor-model-based image coder was proposed by Watson in [Wat87]. <p> General Characteristics The common goal of all RFP models is to describe the behavior of the simple cells in the striate cortex. As such, they share general characteristics with one another. We describe some important characteristics below. Matched Pairs The RFP of most simple cells is bandpass in nature <ref> [Dau80] </ref> with passbands consisting of a narrow band of spatial frequencies characterized by their scale, orientation, and phase as shown in 2-10. <p> In our coder implementation in Chapter 5, we chose to use the cortex RFP's discussed shortly. 2-D Gabor RFP's An example proposed independently by Daugman <ref> [Dau80] </ref> and Marcelja [Mrc80] models the simple cell RFP's as 2-D Gabor functions that together constitute a matched pair. Y 1 (x,y) = a (x,y) cosQ (x,y) cos Y 2 (x,y) = a (x,y) sinQ (x,y) sin where a (x,y) = 2 and p .
Reference: [Dau89] <author> J. G. Daugman, </author> <title> "Entropy reduction and decorrelation in visual coding by oriented neural receptive fields," </title> <journal> IEEE Trans. on Biomedical Engineering, </journal> <volume> Vol. 36, No. 1, </volume> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: He then losslessly encoded the quantization indexes. We describe the coding details in more depth in Chapter 4. Most sensor-model-based image coders, including Watson's, <ref> [Dau89] </ref>, and [Fie87], directly code the sensor response values. We shall call this class of coding algorithms model-based direct perceptual image coding (MDPIC) and discuss it further in Chapter 4. <p> MDPIC coders with simple models such as those used in most Fourier transform and DCT based algorithms (e.g., JPEG), are able to identify and remove signal independent image information such as image components associated with high spatial frequencies. More comprehensive models such as [Wat87], <ref> [Dau89] </ref>, and [Fie87] are capable of predicting a wide variety of perceptual phenomena in a unified framework. An especially important consequence of these comprehensive models is their ability to predict signal dependent perceptual phenomena such as contrast masking.
Reference: [Dbc88] <author> I. Daubechies, </author> <title> "Time-frequency localization operators: a geometric phase space approach," </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> vol. 34, </volume> <pages> pp. 605-612, </pages> <year> 1988. </year>
Reference-contexts: In Chapter 4, we discuss MDPIC coders in detail. In addition, we detail the coder due to Watson [Wat87] that we described earlier, to motivate the development of our coder in Chapter 5. In Chapter 5, we introduce adapted basis techniques, e.g. [MaZh93], [ChDo95], and <ref> [Dbc88] </ref>, which are algorithms or sets of rules designed to provide a specific representation of a signal as a linear combination of waveforms from a large collection. <p> It follows that the atoms are linearly dependent. Several adapted basis techniques have been developed in recent years. We shall briefly describe the most prevalent. Two adapted basis techniques, the Method of Frames <ref> [Dbc88] </ref> and Basis Pursuit [Che95] have similar goals. They find from among all solutions of (5.1) the one whose coefficients, g m , have the smallest l n norm.
Reference: [Edd93] <author> S. L. Eddins, </author> <title> "Three-component image compression with frequency-weighted texture coding and edge modeling," </title> <booktitle> Proc. ICASSP, </booktitle> <volume> Vol 5, </volume> <pages> pp. 369-372, </pages> <year> 1993. </year>
Reference-contexts: The other coefficients are quantized in the usual manner. All coefficients are then merged and entropy coded to produce a bit stream with standard 6 JPEG syntax. Other coders that explicitly exploit contrast masking include [NePr77], [BaMa92], <ref> [Edd93] </ref>, and [RaFa92]. Most of the coders designed to exploit contrast masking also take advantage of the sensitivity limitations described earlier. Image texture. Another characteristic of HVS sensitivity is related to image texture.
Reference: [Fie87] <author> D. J. </author> <title> Field, "Relations between the statistics of natural images and the response properties of cortical cells," </title> <journal> Journal of the Optical Society of America A, </journal> <volume> Vol. 4, No. 12, </volume> <pages> pp. 2379-2394, </pages> <year> 1987. </year>
Reference-contexts: He then losslessly encoded the quantization indexes. We describe the coding details in more depth in Chapter 4. Most sensor-model-based image coders, including Watson's, [Dau89], and <ref> [Fie87] </ref>, directly code the sensor response values. We shall call this class of coding algorithms model-based direct perceptual image coding (MDPIC) and discuss it further in Chapter 4. <p> MDPIC coders with simple models such as those used in most Fourier transform and DCT based algorithms (e.g., JPEG), are able to identify and remove signal independent image information such as image components associated with high spatial frequencies. More comprehensive models such as [Wat87], [Dau89], and <ref> [Fie87] </ref> are capable of predicting a wide variety of perceptual phenomena in a unified framework. An especially important consequence of these comprehensive models is their ability to predict signal dependent perceptual phenomena such as contrast masking.
Reference: [FoLe81] <author> J. M. Foley, G. E. Legg, </author> <title> "Contrast detection and near-threshold discrimination in human vision," </title> <journal> Vision Research, </journal> <volume> vol. 21, </volume> <pages> pp. 1041-1053, </pages> <year> 1981. </year>
Reference-contexts: By the late 1970's, a sensor-based-model for human vision based on the behavior of retinal ganglion cells could accurately predict the results of I/O-model-based contrast sensitivity experiments [WiBe79]. Contributions in the 1980's by Marr [Mar82], Legge and Foley <ref> [FoLe81] </ref>, Daugman [Dau80], and others helped to produce models capable of accurately predicting contrast sensitivity, light adaptation, contrast masking and other visual phenomena. A particularly important example of a sensor-model-based image coder was proposed by Watson in [Wat87]. <p> Deterministic Response of Sensor Types 1 and 2. Type 1 Deterministic Responses. Type 2 Deterministic Responses. 28 Second, we assume [c.f. Wat87] & <ref> [FoLe81] </ref> that the function h (h,M v (h)) has the specific form h (h, M v (h)) = t (h) max M d (h) where W = 0.7 and we now discuss parameters M d (h) and t (h).
Reference: [FrSt81] <author> J. H. Friedman, W. Stuetzle, </author> <title> "Projection pursuit regression," </title> <journal> J. Amer. Statist. Asso., </journal> <volume> vol. 76, </volume> <pages> pp. 817-823, </pages> <year> 1981. </year> <month> 127 </month>
Reference-contexts: In 1993, Mallat and Zhang introduced a technique called Matching Pursuit [MaZh93], a greedy algorithm designed to find the solution to (5.1) with a small l 1 norm. Matching Pursuit is similar to projection pursuit strategies developed for statistical parameter estimation <ref> [FrSt81] </ref> as well as an algorithm developed in [QiCh88]. The decomposition of images that result from MP tends to be sparse especially when used in conjunction with a dictionary containing 2D Gabor or Gabor-like vectors with a broad range of scales and orientations.
Reference: [GoSi93] <author> J. Gouronc, J. </author> <title> Si, "A near optimal algorithm for image compression using Gabor expansion, </title> " <booktitle> IEEE Symposium on Circuits and Systems, </booktitle> <pages> pp. 251-254, </pages> <year> 1993. </year>
Reference-contexts: In [BeMa95], the authors describe how Matching Pursuit can be used to produce a compact representation of an image from a dictionary containing 2D Gabor functions though no explicit coding method is described. Gouronc and Si <ref> [GoSi93] </ref> develop techniques to find minimum square error partial expansions of images using atoms from a Gabor dictionary and code the resulting partial expansions. In [NeZa95] and [VeKa94], atoms from a 2D Gabor dictionary are chosen using Matching Pursuit to code video sequences.
Reference: [Gra93] <author> R. M. Gray, P. C. Cosman, K.L. Oehler, </author> <title> "Incorporating visual factors into vector quantizers for image compression," In Digital Images and Human Vision, </title> <editor> ed. A. B. </editor> <booktitle> Watson, </booktitle> <pages> pp. 35-52, </pages> <address> MA: </address> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: For example, in [Wat93], Watson develops a model for 58 perceptual sensitivities to DCT coefficients and uses the resulting sensitivity information to determine quantization thresholds in a DCT based transform coder. Additional examples of this common approach to perceptual image coder design include [SaJo89], <ref> [Gra93] </ref>, [HaMa96], and [BaMa92]. In MDPIC, components from an HVS model such as the sensor responses of the cortical snapshot model are coded directly. The performance of an MDPIC coder is tied directly to the capability of the HVS model it employs.
Reference: [GeSw66] <author> D. Green, J. Swets, </author> <title> Signal Detection Theory and Psychophysics, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1966, </year> <pages> pp. </pages> <month> 59-60. </month> <title> [Hal77] visual system," </title> <journal> IEEE Trans. on Man and Cybernetics, </journal> <volume> vol. smc-7, no. 3, </volume> <month> Mar. </month> <year> 1977. </year>
Reference: [HaMa96] <author> P. J. Hahn, V. J. Mathews, </author> <title> "Distortion-limited vector quantization," </title> <booktitle> Proc. Data Compression Conference, </booktitle> <pages> pp. 340-348, </pages> <year> 1996. </year>
Reference-contexts: For example, in [Wat93], Watson develops a model for 58 perceptual sensitivities to DCT coefficients and uses the resulting sensitivity information to determine quantization thresholds in a DCT based transform coder. Additional examples of this common approach to perceptual image coder design include [SaJo89], [Gra93], <ref> [HaMa96] </ref>, and [BaMa92]. In MDPIC, components from an HVS model such as the sensor responses of the cortical snapshot model are coded directly. The performance of an MDPIC coder is tied directly to the capability of the HVS model it employs.
Reference: [Har40] <author> H. K. Hartline, </author> <title> "The receptive fields of optic nerve fibers," </title> <journal> American Journal of Physiology, </journal> <volume> 130, </volume> <pages> pp. 690-699, </pages> <year> 1940. </year>
Reference-contexts: The collection of responses from all types of sensors at all locations in an image constitute a representation of the striate cortical neural responses to that image. 8 Development of the sensor-based models began with the pioneering work of Hartline <ref> [Har40] </ref> and Hubel and Weisel [HuWe62] which laid the groundwork for a comprehensive understanding of the physiology of early vision 1 . By the late 1970's, a sensor-based-model for human vision based on the behavior of retinal ganglion cells could accurately predict the results of I/O-model-based contrast sensitivity experiments [WiBe79]. <p> Each neuron of the visual pathway is directly or indirectly connected to a set of rods or cones which constitute the receptive field of that neuron. Receptive fields are in general highly organized in a spatial sense <ref> [Har40] </ref>. 18 The HVS is most sensitive to spatial detail in the subset of the retinal image coincident to the fovea 1 , which is a specialized region in the center of the retina containing densely packed cones.
Reference: [HuWe62] <author> D. H. Hubel, T. N. Weisel, </author> <title> "Receptive fields, binocular interaction and functional architecture in the cat's visual cortex," </title> <journal> Journal of Physiology, </journal> <volume> 160, </volume> <pages> pp. 106-154, </pages> <year> 1962. </year>
Reference-contexts: The collection of responses from all types of sensors at all locations in an image constitute a representation of the striate cortical neural responses to that image. 8 Development of the sensor-based models began with the pioneering work of Hartline [Har40] and Hubel and Weisel <ref> [HuWe62] </ref> which laid the groundwork for a comprehensive understanding of the physiology of early vision 1 . By the late 1970's, a sensor-based-model for human vision based on the behavior of retinal ganglion cells could accurately predict the results of I/O-model-based contrast sensitivity experiments [WiBe79]. <p> In addition, each hypercolumn is subdivided into minicolumns so that the overall structure is conceptually similar to a box (the hypercolumn) containing drinking straws (the minicolumns). Hubel and Weisel <ref> [HuWe62] </ref>, the first to detail this cortical structure, found several classes of cells present in the minicolumns. The most abundant by about two-to-one and the ones thought to be responsible for static form were termed "simple" cells. <p> Although simple cells within a minicolumn share the same orientation their receptive fields vary in size, probably to accommodate visual stimuli on several scales [Mar82]. In addition, simple cells demonstrate linear spatial summation <ref> [HuWe62] </ref> and [Mos78]. That is, the response of the cell to illumination is a weighted sum of the illumination in various parts of its receptive field. The weighting varies with spatial location and is called the receptive field profile (RFP) of the cell.
Reference: [HuWe79] <author> D. H. Hubel, T. N. Weisel, </author> <title> "Brain mechanisms of vision." </title> <publisher> Scientific American, </publisher> <month> Sept. </month> <year> 1979. </year>
Reference-contexts: Simple cells within a minicolumn have roughly the same orientation, and minicolumns are distributed throughout a hypercolumn in an orderly fashion with adjacent minicolumns containing simple cells with orientations that differ by about ten degrees <ref> [HuWe79] </ref>. Although simple cells within a minicolumn share the same orientation their receptive fields vary in size, probably to accommodate visual stimuli on several scales [Mar82]. In addition, simple cells demonstrate linear spatial summation [HuWe62] and [Mos78].
Reference: [Jay93] <author> N. Jayant, J. Johnston , R. Safranek, </author> <title> "Signal compression based on models of human perception," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 18, No. 10, </volume> <pages> pp. 1385-1422, </pages> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: If another sinusoidal grating having similar orientation and spatial frequency at a relatively high contrast level were placed on top of the faint grating, the high contrast grating would hide or mask the presence of the first. In <ref> [Jay93] </ref>, Jayant et. al. discuss a system that converts JPEG into an adaptive encoder. The image data is transformed and coefficient amplitudes smaller than a level determined by a distortion profile are set to zero.
Reference: [Joh88] <author> J. D. Johnston, </author> <title> "Transform coding of audio signals using perceptual noise criteria," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 6, no. 2, </volume> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: Recall from Chapter 1 that contrast masking involves the reduction in the ability to detect a visual stimulus in the presence of another similar (usually high amplitude) stimulus. While direct coding approaches using comprehensive perceptual models have been used with great success to code audio signals, as in <ref> [Joh88] </ref> and [Nol93], such attempts in image coding have not been as successful. Examples of MDPIC coders using comprehensive HVS models include [Sen95], [WeZe96], and [Wat87].
Reference: [Jul84] <author> B. Julesz, </author> <title> "A brief outline of the texton theory of human vision," </title> <booktitle> Trends in Neurosciences, </booktitle> <volume> vol. 7, </volume> <pages> pp. 41-45, </pages> <month> Feb. </month> <year> 1984. </year>
Reference-contexts: Image texture. Another characteristic of HVS sensitivity is related to image texture. The HVS seems particularly insensitive to variations in certain details of highly textured regions especially when the second order statistics of the pattern remain undisturbed <ref> [Jul84] </ref>. In [SaJo89], Safranek and Johnston decompose and image into 16 subbands.
Reference: [LeG91] <author> D. LeGall, </author> <title> "MPEG, A video compression standard for multimedia applications," </title> <journal> Communications of the ACM, </journal> <pages> pp. 47-59, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: The contrast sensitivity function of the HVS is shown in Figure 1-1. 4 Source: The Senses, Barlow & Mollen, p. 134. Some of today's most common image coding techniques including JPEG [Wal91] and the intra-picture coding portions of the CCITT H.261 [Lio91] and MPEG <ref> [LeG91] </ref> moving picture standards, are designed to exploit limitations in contrast sensitivity. In these three coding schemes, images are partitioned into small square blocks. The data in the blocks is transformed using a discrete cosine transform. The resulting transform coefficients are uniform scalar quantized.
Reference: [Lio91] <author> M. Liou, </author> <title> "Overview of the p64 kbits/s video coding standard," </title> <journal> Communications of the ACM, </journal> <pages> pp. 60, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: The contrast sensitivity function of the HVS is shown in Figure 1-1. 4 Source: The Senses, Barlow & Mollen, p. 134. Some of today's most common image coding techniques including JPEG [Wal91] and the intra-picture coding portions of the CCITT H.261 <ref> [Lio91] </ref> and MPEG [LeG91] moving picture standards, are designed to exploit limitations in contrast sensitivity. In these three coding schemes, images are partitioned into small square blocks. The data in the blocks is transformed using a discrete cosine transform. The resulting transform coefficients are uniform scalar quantized.
Reference: [Lub93] <author> J. Lubin, </author> <title> "The Use of Psychophysical Data and Models in the Analysis of Display System Performance," In Digital Images and Human Vision, </title> <editor> ed. A. B. Watson, p. </editor> <address> 175, MA: </address> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In our indirect approach, we measured the values of the detection thresholds for the various sensor types at the point of fixation. Then, employing the fact that contrast 86 sensitivity decreases linearly with increasing eccentricity 1 <ref> [Lub93] </ref> we used data from [Wat87c] to interpolate the measured threshold values at desired eccentricities.
Reference: [Mar82] <author> D. Marr, </author> <title> Vision: A Computational Investigation into the Human Representation and Processing of Visual Information, </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1982. </year> <month> 128 </month>
Reference-contexts: By the late 1970's, a sensor-based-model for human vision based on the behavior of retinal ganglion cells could accurately predict the results of I/O-model-based contrast sensitivity experiments [WiBe79]. Contributions in the 1980's by Marr <ref> [Mar82] </ref>, Legge and Foley [FoLe81], Daugman [Dau80], and others helped to produce models capable of accurately predicting contrast sensitivity, light adaptation, contrast masking and other visual phenomena. A particularly important example of a sensor-model-based image coder was proposed by Watson in [Wat87]. <p> Although simple cells within a minicolumn share the same orientation their receptive fields vary in size, probably to accommodate visual stimuli on several scales <ref> [Mar82] </ref>. In addition, simple cells demonstrate linear spatial summation [HuWe62] and [Mos78]. That is, the response of the cell to illumination is a weighted sum of the illumination in various parts of its receptive field.
Reference: [MaSa74] <author> J. Mannos, D. Sakrison, </author> <title> "The effects of a visual fidelity criterion on the encoding of images," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-20, </volume> <pages> pp. 525-536, </pages> <year> 1974. </year>
Reference-contexts: Light adaptation involves the HVS's diminishing sensitivity as background luminance levels increase. This effect is well known in perception and is characterized by Weber's Law. So called homomorpic coding systems such as those developed by Mannos and Sakrison <ref> [MaSa74] </ref> and Budge et. al. [Bud88] as well as those suggested by C. F. Hall and E. L. Hall [Hal77] and Stockham [Sto72], exploit the effects of light adaptation.
Reference: [MaZh93] <author> S. Mallat, Z. Zhang, </author> <title> "Matching pursuits with time-frequency dictionaries," </title> <journal> IEEE Trans. on Signal Processing, </journal> <volume> vol. 41, no. 12, </volume> <pages> pp. 3397-3415, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: In Chapter 4, we discuss MDPIC coders in detail. In addition, we detail the coder due to Watson [Wat87] that we described earlier, to motivate the development of our coder in Chapter 5. In Chapter 5, we introduce adapted basis techniques, e.g. <ref> [MaZh93] </ref>, [ChDo95], and [Dbc88], which are algorithms or sets of rules designed to provide a specific representation of a signal as a linear combination of waveforms from a large collection. We use an adapted basis technique called matching pursuit (MP)[MaZh93] as the first stage in a newly developed two stage image <p> PP is a two stage algorithm. In stage 1, the algorithm selects sensor receptive field profiles (RFP's), modeled after those of the simple cells, and locations using an adapted basis algorithm called matching pursuit (MP) <ref> [MaZh93] </ref>. A large number of RFP's are selected to ensure that the MP reproduction satisfies the indistinguishability criterion developed in Chapter 3. In stage 2, it prunes (i.e., eliminates) a set of RFP's from those selected by MP in such a way that the indistinguishability criterion is satisfied. <p> We call the collection of waveforms a dictionary and the elements of that dictionary atoms after Mallat and Zhang <ref> [MaZh93] </ref>. Specifically, consider D = -x k k=1 a dictionary of size K with elements x k = ( ) x k (1),...,x k ( N ) t where we shall assume that D contains only unit vectors. <p> In 1993, Mallat and Zhang introduced a technique called Matching Pursuit <ref> [MaZh93] </ref>, a greedy algorithm designed to find the solution to (5.1) with a small l 1 norm. Matching Pursuit is similar to projection pursuit strategies developed for statistical parameter estimation [FrSt81] as well as an algorithm developed in [QiCh88]. <p> us to code any image to a predetermined quality without spending time "tuning" the coder parameters. 93 Dictionary Subsampling The MP and consequently, PP algorithm is capable of reproducing any image in F, the set of all discrete images, as long as the elements in its associated dictionary span F <ref> [MaZh93] </ref>. The size and shape of the image being coded affects the choice of dictionary because the dictionary must have sensor types at or near every location in the image. <p> In the paragraphs that follow, we summarize the PP coding algorithm, the indistinguishability criterion, and the cortical snapshot model highlighting novel aspects of each. Recall that the PP algorithm uses an adapted basis method called matching pursuit (MP) <ref> [MaZh93] </ref> to construct a perceptually lossless reproduction as determined by our indistinguishability criterion. At first, we tried to build an MP reproduction using a perceptually motivated sensor selection criterion.
Reference: [Mos78] <author> J. A. Moshvon, I. D. Thompson, D. J. Tolhurst, </author> " <title> Spatial summation in the receptive fields of simple cells in the cat's striate cortex," </title> <journal> Journal of Physiology, </journal> <volume> 283, </volume> <pages> pp. 53-77, </pages> <year> 1978. </year>
Reference-contexts: Although simple cells within a minicolumn share the same orientation their receptive fields vary in size, probably to accommodate visual stimuli on several scales [Mar82]. In addition, simple cells demonstrate linear spatial summation [HuWe62] and <ref> [Mos78] </ref>. That is, the response of the cell to illumination is a weighted sum of the illumination in various parts of its receptive field. The weighting varies with spatial location and is called the receptive field profile (RFP) of the cell.
Reference: [Mrc80] <author> S. Marcelja, </author> <title> "Mathematical description of the responses of simple cortical cells," </title> <journal> Journal of the Optical Society of America, </journal> <volume> vol. 70, </volume> <pages> pp. 1297-1300, </pages> <year> 1980. </year>
Reference-contexts: In our coder implementation in Chapter 5, we chose to use the cortex RFP's discussed shortly. 2-D Gabor RFP's An example proposed independently by Daugman [Dau80] and Marcelja <ref> [Mrc80] </ref> models the simple cell RFP's as 2-D Gabor functions that together constitute a matched pair. Y 1 (x,y) = a (x,y) cosQ (x,y) cos Y 2 (x,y) = a (x,y) sinQ (x,y) sin where a (x,y) = 2 and p .
Reference: [NePr77] <author> A. Netravali, B. Prasada, </author> <title> "Adaptive quantization of picture signals using spatial masking," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 65, No. 4, </volume> <pages> pp. 536-548, </pages> <month> Apr. </month> <year> 1977. </year>
Reference-contexts: The other coefficients are quantized in the usual manner. All coefficients are then merged and entropy coded to produce a bit stream with standard 6 JPEG syntax. Other coders that explicitly exploit contrast masking include <ref> [NePr77] </ref>, [BaMa92], [Edd93], and [RaFa92]. Most of the coders designed to exploit contrast masking also take advantage of the sensitivity limitations described earlier. Image texture. Another characteristic of HVS sensitivity is related to image texture.
Reference: [NeZa95] <author> R. Neff, A. Zakhor, </author> <title> "Matching pursuit video coding at very low bit rates," </title> <booktitle> Proc. Data Compression Conference, </booktitle> <pages> pp. 411-420, </pages> <year> 1995. </year>
Reference-contexts: Gouronc and Si [GoSi93] develop techniques to find minimum square error partial expansions of images using atoms from a Gabor dictionary and code the resulting partial expansions. In <ref> [NeZa95] </ref> and [VeKa94], atoms from a 2D Gabor dictionary are chosen using Matching Pursuit to code video sequences.
Reference: [Nol93] <author> P. Noll, </author> <title> "Wideband speech and audio coding," </title> <journal> IEEE Communications Magazine," </journal> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: While direct coding approaches using comprehensive perceptual models have been used with great success to code audio signals, as in [Joh88] and <ref> [Nol93] </ref>, such attempts in image coding have not been as successful. Examples of MDPIC coders using comprehensive HVS models include [Sen95], [WeZe96], and [Wat87].
Reference: [Pet91] <author> H. Peterson, H. Peng, J. Morgan, W. Pennebaker, </author> <title> "Quantization of color image components in the DCT domain," </title> <booktitle> SPIE, </booktitle> <pages> pp. 210-222, </pages> <year> 1991. </year>
Reference: [PoRo81] <author> D. A. Pollen, S. F. Ronner, </author> <title> "Phase relationship between adjacent simple cells in the visual cortex," </title> <booktitle> Science 212, </booktitle> <pages> pp. 1409-1411, </pages> <year> 1981. </year>
Reference-contexts: The weighting varies with spatial location and is called the receptive field profile (RFP) of the cell. Further, there is evidence that simple cells occur in matched pairs that have spatial RFP's which share the same location, orientation and scale preferences but differ in phase by 90 degrees <ref> [PoRo81] </ref>. This 90 degree phase relation is called quadrature phase. A one-dimensional rendering of the RFP for a typical matched pair of simple cells is shown in Figure 2-2.
Reference: [Pro89] <author> J. G. Proakis, </author> <title> Digital Communications, second edition, </title> <publisher> McGraw-Hill, Inc., </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: y)+Q (x,y) = a (x,y) cosQ (x,y)cos [ ] 2p (u o x+v o y) a (x,y) sinQ (x,y)sin [ ] 2p (u o x+v o y) = F 1 (x,y) F 2 (x,y) where a (x,y) is called the envelope and Q (x,y) the phase 1 of h (x,y) <ref> [Pro89] </ref>. The functions "a (x,y) cosQ (x,y)" and "a (x,y) sinQ (x,y)" are called the quadrature components of h (x,y). All models for the receptive field profiles of bandpass sensors that we have seen in the literature come in matched pairs with equal quadrature components.
Reference: [QiCh88] <author> S. Qian, D. Chen, </author> <title> "Signal representation via adaptive normalized Gaussian functions," </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> vol. 36, </volume> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: In 1993, Mallat and Zhang introduced a technique called Matching Pursuit [MaZh93], a greedy algorithm designed to find the solution to (5.1) with a small l 1 norm. Matching Pursuit is similar to projection pursuit strategies developed for statistical parameter estimation [FrSt81] as well as an algorithm developed in <ref> [QiCh88] </ref>. The decomposition of images that result from MP tends to be sparse especially when used in conjunction with a dictionary containing 2D Gabor or Gabor-like vectors with a broad range of scales and orientations.
Reference: [RaFa92] <author> X. Ran, N Farvardin, </author> <title> "Adaptive DCT image coding based on a three-component image model," </title> <booktitle> Proc. ICASSP, </booktitle> <volume> Vol. 3, </volume> <pages> pp. 201-204, </pages> <year> 1992. </year>
Reference-contexts: The other coefficients are quantized in the usual manner. All coefficients are then merged and entropy coded to produce a bit stream with standard 6 JPEG syntax. Other coders that explicitly exploit contrast masking include [NePr77], [BaMa92], [Edd93], and <ref> [RaFa92] </ref>. Most of the coders designed to exploit contrast masking also take advantage of the sensitivity limitations described earlier. Image texture. Another characteristic of HVS sensitivity is related to image texture.
Reference: [SaJo89] <author> R. Safranek, J. Johnston, </author> <title> "A perceptually tuned sub-band image coder," </title> <booktitle> Proc. ICASSP 1989. </booktitle>
Reference-contexts: Image texture. Another characteristic of HVS sensitivity is related to image texture. The HVS seems particularly insensitive to variations in certain details of highly textured regions especially when the second order statistics of the pattern remain undisturbed [Jul84]. In <ref> [SaJo89] </ref>, Safranek and Johnston decompose and image into 16 subbands. <p> For example, in [Wat93], Watson develops a model for 58 perceptual sensitivities to DCT coefficients and uses the resulting sensitivity information to determine quantization thresholds in a DCT based transform coder. Additional examples of this common approach to perceptual image coder design include <ref> [SaJo89] </ref>, [Gra93], [HaMa96], and [BaMa92]. In MDPIC, components from an HVS model such as the sensor responses of the cortical snapshot model are coded directly. The performance of an MDPIC coder is tied directly to the capability of the HVS model it employs.
Reference: [SaPe93] <author> A. Said, W. Pearlman, </author> <title> "Image compression using the spatial-orientation tree," </title> <booktitle> in Int. Symp. Circ. and Syst., </booktitle> <volume> vol. 1, </volume> <pages> pp. 279-282, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The coder we develop in this work is one. THESIS SUMMARY We develop a perceptual image coder for continuous-tone, grayscale, still images. The coder is capable of producing reproductions with higher subjective quality than that produced by JPEG or by Said and Pearlman's wavelet coder <ref> [SaPe93] </ref> at some fixed encoding rate. At the heart of the coder, lies a novel indistinguishability criterion that determines whether two images are perceptually distinguishable. <p> Also in Chapter 5, we demonstrate that the perceptual pruning algorithm coding performance is superior to that of a matching pursuit based coding method, JPEG [Wal91], Watson's cortex transform coder [Wat87], and Said and Pearlman's wavelet coder <ref> [SaPe93] </ref> over several images. In the sixth and final chapter, we discuss the significance of the contributions of this thesis which fall into two categories. The first is the indistinguishability criterion that we developed from our cortical snapshot model of the HVS. <p> In the fifth section, we describe a psychovisual experiment we performed to compare the RFP selection rule of PP to that of MP and present results of that experiment. We compare PP coding results to those of JPEG, the Said-Pearlman 73 <ref> [SaPe93] </ref> coder, and Watson's cortex transform coder [Wat87] in the sixth and final section. ADAPTED BASIS Adapted basis techniques are algorithms or sets of rules that are designed to provide a specific representation of a signal as a linear combination of waveforms from a very large collection. <p> Further complicating matters, a good coder will exploit the spatial correlation of the selected RFP's that occurs as a result of a small dictionary. In practice, excellent results have been obtained by algorithms such as [Sha93] and <ref> [SaPe93] </ref>, using relatively small dictionaries (e.g., a wavelet basis set) in combination with methods designed to exploit the spatial correlation that occurs between selected dictionary elements. Conversely, we don't expect as much gain using large dictionaries because the spatial correlation between selected RFP's is small. <p> For comparison, the coding results of JPEG and the Said-Pearlman (SP) <ref> [SaPe93] </ref> coder are presented at two different encoding rates. We chose to compare to JPEG because of its ubiquitous presence and SP because it represents today's state-of-the-art for coding performance. We first compare PP to the Watson coder described in Chapter 4. <p> Another possibility is to predict the locations of selected sensors based on locations of RFPs selected earlier. Early results from our investigations suggest that we cannot expect to exploit the correlation between locations of important coefficients as successfully as zero-tree based wavelet coders such as [Sha93] and <ref> [SaPe93] </ref>. In fact, evidence suggests that the larger the dictionary the smaller the correlation between locations of the selected sensors. 120 APPENDIX 121 The purpose of this appendix is to describe the details of the cortex transform, originally proposed by Watson in [Wat87b].
Reference: [Sen95] <author> H. Senane, A. Saadane, D. Barba, </author> <title> "Image coding in the context of a psychovisual image representation with vector quantization," </title> <booktitle> Proc. IEEE International Conference on Image Processing, </booktitle> <pages> pp. 97-100, </pages> <year> 1995. </year>
Reference-contexts: While direct coding approaches using comprehensive perceptual models have been used with great success to code audio signals, as in [Joh88] and [Nol93], such attempts in image coding have not been as successful. Examples of MDPIC coders using comprehensive HVS models include <ref> [Sen95] </ref>, [WeZe96], and [Wat87]. We describe the MDPIC coder proposed in [Wat87] in the following section as it was one of the first MDPIC image coder based on a comprehensive model of the HVS and it provides an excellent introduction for our work.
Reference: [Sha93] <author> J. M. Shapiro, </author> <title> "Embedded image coding using zerotrees of wavelet coefficients," </title> <journal> IEEE Trans. Signal Processing, Special Issue on Wavelets and Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3445-3462, </pages> <month> Dec., </month> <year> 1993. </year> <month> 129 </month>
Reference-contexts: Further complicating matters, a good coder will exploit the spatial correlation of the selected RFP's that occurs as a result of a small dictionary. In practice, excellent results have been obtained by algorithms such as <ref> [Sha93] </ref> and [SaPe93], using relatively small dictionaries (e.g., a wavelet basis set) in combination with methods designed to exploit the spatial correlation that occurs between selected dictionary elements. Conversely, we don't expect as much gain using large dictionaries because the spatial correlation between selected RFP's is small. <p> Another possibility is to predict the locations of selected sensors based on locations of RFPs selected earlier. Early results from our investigations suggest that we cannot expect to exploit the correlation between locations of important coefficients as successfully as zero-tree based wavelet coders such as <ref> [Sha93] </ref> and [SaPe93]. In fact, evidence suggests that the larger the dictionary the smaller the correlation between locations of the selected sensors. 120 APPENDIX 121 The purpose of this appendix is to describe the details of the cortex transform, originally proposed by Watson in [Wat87b].
Reference: [StWo86] <author> H. Stark, J. W. Woods, </author> <title> Probability , Random Processes, and Estimation Theory for Engineers, Theorem 3.6-1, </title> <editor> p. </editor> <volume> 143, </volume> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1986. </year>
Reference-contexts: By the Central Limit Theorem <ref> [StWo86] </ref> , U is approximately Gaussian with mean zero and unit variance, under the assumption that s W (h) s Z is small for h = 1, ..., H.
Reference: [Sto72] <author> T. Stockham Jr., </author> <title> "Image processing in the context of a visual model," </title> <journal> Proc. IEEE, </journal> <volume> vol. 60, </volume> <pages> pp. 828-842, </pages> <year> 1972. </year>
Reference-contexts: This effect is well known in perception and is characterized by Weber's Law. So called homomorpic coding systems such as those developed by Mannos and Sakrison [MaSa74] and Budge et. al. [Bud88] as well as those suggested by C. F. Hall and E. L. Hall [Hal77] and Stockham <ref> [Sto72] </ref>, exploit the effects of light adaptation. In these systems, the dynamic range of an image is compressed to produce a signal which is "perceptually uniform," that is, in the domain of reduced dynamic range, the HVS is equally sensitive to noise at all luminance levels.
Reference: [VeKa94] <author> M. Vetterli, T. Kalker, </author> <title> "Matching pursuit for compression and application to motion compensated video coding," </title> <booktitle> Proc. IEEE International Conference on Image Processing, </booktitle> <pages> pp. 725-729, </pages> <year> 1994. </year>
Reference-contexts: Gouronc and Si [GoSi93] develop techniques to find minimum square error partial expansions of images using atoms from a Gabor dictionary and code the resulting partial expansions. In [NeZa95] and <ref> [VeKa94] </ref>, atoms from a 2D Gabor dictionary are chosen using Matching Pursuit to code video sequences. While MP alone performs well, we suspected that the subjective quality of the reproduction could be improved if we were to employ a perceptually motivated sensor RFP selection criterion and perceptual scalar quantization.
Reference: [Wal91] <author> G. K. Wallace, </author> <title> "The JPEG still picture compression standard," </title> <journal> Communications of the ACM, </journal> <pages> pp. 31-43, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: Sensitivity drops at lower spatial frequencies and is severely attenuated for frequencies above 25 cycles per degree. The contrast sensitivity function of the HVS is shown in Figure 1-1. 4 Source: The Senses, Barlow & Mollen, p. 134. Some of today's most common image coding techniques including JPEG <ref> [Wal91] </ref> and the intra-picture coding portions of the CCITT H.261 [Lio91] and MPEG [LeG91] moving picture standards, are designed to exploit limitations in contrast sensitivity. In these three coding schemes, images are partitioned into small square blocks. The data in the blocks is transformed using a discrete cosine transform. <p> Also in Chapter 5, we demonstrate that the perceptual pruning algorithm coding performance is superior to that of a matching pursuit based coding method, JPEG <ref> [Wal91] </ref>, Watson's cortex transform coder [Wat87], and Said and Pearlman's wavelet coder [SaPe93] over several images. In the sixth and final chapter, we discuss the significance of the contributions of this thesis which fall into two categories.
Reference: [Wat87] <author> A. B. Watson, </author> " <title> Efficiency of an image code based on human vision," </title> <journal> Journal of the Optical Society of America A, </journal> <volume> Vol. 4, No. 12, </volume> <pages> pp. 2401-2417, </pages> <year> 1987. </year>
Reference-contexts: Contributions in the 1980's by Marr [Mar82], Legge and Foley [FoLe81], Daugman [Dau80], and others helped to produce models capable of accurately predicting contrast sensitivity, light adaptation, contrast masking and other visual phenomena. A particularly important example of a sensor-model-based image coder was proposed by Watson in <ref> [Wat87] </ref>. The coder uses a sensor model that computes the responses of many different sensor types at every image location. The sensors are patterned after the simple cells. <p> In Chapter 4, we discuss MDPIC coders in detail. In addition, we detail the coder due to Watson <ref> [Wat87] </ref> that we described earlier, to motivate the development of our coder in Chapter 5. <p> Also in Chapter 5, we demonstrate that the perceptual pruning algorithm coding performance is superior to that of a matching pursuit based coding method, JPEG [Wal91], Watson's cortex transform coder <ref> [Wat87] </ref>, and Said and Pearlman's wavelet coder [SaPe93] over several images. In the sixth and final chapter, we discuss the significance of the contributions of this thesis which fall into two categories. The first is the indistinguishability criterion that we developed from our cortical snapshot model of the HVS. <p> Typically, 4 to 8 orientations are used. Cortex RFP's The "cortex" filters originally proposed by Watson in [Wat87b] and <ref> [Wat87] </ref> are also commonly used to model the RFP's of the simple cells and are described briefly below. To be concrete, we fix the number of scales to be 6 and the number of orientations to 8. <p> Recall from Chapter 1 that in MDPIC, components of a perceptually relevant representation such as those computed by the cortical snapshot model are coded directly. Next, we detail an MDPIC method proposed by Watson in <ref> [Wat87] </ref> because it provides motivation for "adapted basis" image coding, a class of MDPIC algorithms that includes PP. <p> MDPIC coders with simple models such as those used in most Fourier transform and DCT based algorithms (e.g., JPEG), are able to identify and remove signal independent image information such as image components associated with high spatial frequencies. More comprehensive models such as <ref> [Wat87] </ref>, [Dau89], and [Fie87] are capable of predicting a wide variety of perceptual phenomena in a unified framework. An especially important consequence of these comprehensive models is their ability to predict signal dependent perceptual phenomena such as contrast masking. <p> While direct coding approaches using comprehensive perceptual models have been used with great success to code audio signals, as in [Joh88] and [Nol93], such attempts in image coding have not been as successful. Examples of MDPIC coders using comprehensive HVS models include [Sen95], [WeZe96], and <ref> [Wat87] </ref>. We describe the MDPIC coder proposed in [Wat87] in the following section as it was one of the first MDPIC image coder based on a comprehensive model of the HVS and it provides an excellent introduction for our work. <p> Examples of MDPIC coders using comprehensive HVS models include [Sen95], [WeZe96], and <ref> [Wat87] </ref>. We describe the MDPIC coder proposed in [Wat87] in the following section as it was one of the first MDPIC image coder based on a comprehensive model of the HVS and it provides an excellent introduction for our work. <p> After an extensive search, we settled on a set of parameters that represented a good compromise for all conflicting effects. In [Dal93], Daly suggests an alternative approach to mitigate ringing which might have made our task simpler. A third problem with the coder, as suggested by the results in <ref> [Wat87] </ref> and verified by us, is that the B q parameters are image dependent. Consequently, these values must be "tuned" for each individual image. The task of tuning is time consuming and requires human interaction which can lead to tuner-dependent results. <p> In the fifth section, we describe a psychovisual experiment we performed to compare the RFP selection rule of PP to that of MP and present results of that experiment. We compare PP coding results to those of JPEG, the Said-Pearlman 73 [SaPe93] coder, and Watson's cortex transform coder <ref> [Wat87] </ref> in the sixth and final section. ADAPTED BASIS Adapted basis techniques are algorithms or sets of rules that are designed to provide a specific representation of a signal as a linear combination of waveforms from a very large collection. <p> radial passband edges (i.e., those edges perpendicular to ||v|| = w L ) is accomplished by convolving an untapered ideal passband edge with Gaussian R 2 (d, v) = g d p g d where d = ||v||, g d = 2 and sharpness parameter G d = 2 In <ref> [Wat87] </ref>, the square root of the frequency responses described above is computed to create the desired filters. Alternately, the cortex transform as described in [Wat87b] does not include the square root.
Reference: [Wat87b] <author> A. B. Watson, </author> <title> "The cortex transform: rapid computation of simulated neural images," Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> vol. 39, no. 3, </volume> <pages> pp. 311-327, </pages> <year> 1987. </year>
Reference-contexts: Typically, 4 to 8 orientations are used. Cortex RFP's The "cortex" filters originally proposed by Watson in <ref> [Wat87b] </ref> and [Wat87] are also commonly used to model the RFP's of the simple cells and are described briefly below. To be concrete, we fix the number of scales to be 6 and the number of orientations to 8. <p> In fact, evidence suggests that the larger the dictionary the smaller the correlation between locations of the selected sensors. 120 APPENDIX 121 The purpose of this appendix is to describe the details of the cortex transform, originally proposed by Watson in <ref> [Wat87b] </ref>. The transform represents a computationally efficient way to compute the simulated response of cortical simple cells. The transform is composed of a finite set of discrete linear filters which have impulse responses designed to model the receptive field profiles (RFP's) of the cortical simple cells. <p> Alternately, the cortex transform as described in <ref> [Wat87b] </ref> does not include the square root.
Reference: [Wat87c] <author> A. B. Watson, </author> " <title> Estimation of local spatial scale," </title> <journal> Journal of the Optical Society of America A, </journal> <volume> Vol. 4, </volume> <pages> pp. 1579-1582, </pages> <year> 1987. </year>
Reference-contexts: In our indirect approach, we measured the values of the detection thresholds for the various sensor types at the point of fixation. Then, employing the fact that contrast 86 sensitivity decreases linearly with increasing eccentricity 1 [Lub93] we used data from <ref> [Wat87c] </ref> to interpolate the measured threshold values at desired eccentricities. <p> We chose e * = 3 arbitrarily and used the contrast sensitivity data presented in <ref> [Wat87c] </ref> for vertically oriented, even phase, 2-D Gabor signals located at eccentricities of 0 and 3 degrees. The reduction factors at an eccentricity of 3 degrees are shown in Table 5-2. We assume that the contrast sensitivity reduction factor is independent of orientation and phase.
Reference: [Wat93] <author> A. B. Watson, </author> <title> "Visually optimal DCT quantization matrices for individual images," </title> <booktitle> Proc. Data Compression Conference, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 178-197, </pages> <year> 1993. </year>
Reference-contexts: One way to construct a perceptual image coder is to employ a model of the HVS to identify perceptually irrelevant information and then use that information in the context of a conventional coder design. For example, in <ref> [Wat93] </ref>, Watson develops a model for 58 perceptual sensitivities to DCT coefficients and uses the resulting sensitivity information to determine quantization thresholds in a DCT based transform coder. Additional examples of this common approach to perceptual image coder design include [SaJo89], [Gra93], [HaMa96], and [BaMa92].
Reference: [WeZe96] <author> B. Wegmann, C. Zetzsche, </author> <title> "Feature specific vector quantization of images," </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> vol. 5, No. 2, </volume> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: While direct coding approaches using comprehensive perceptual models have been used with great success to code audio signals, as in [Joh88] and [Nol93], such attempts in image coding have not been as successful. Examples of MDPIC coders using comprehensive HVS models include [Sen95], <ref> [WeZe96] </ref>, and [Wat87]. We describe the MDPIC coder proposed in [Wat87] in the following section as it was one of the first MDPIC image coder based on a comprehensive model of the HVS and it provides an excellent introduction for our work.
Reference: [WiBe79] <author> H. R. Wilson, J. R. Bergen, </author> <title> "A four mechanism model for spatial vision," </title> <journal> Vision Research, </journal> <volume> 19, </volume> <pages> pp. 19-32, </pages> <year> 1979. </year>
Reference-contexts: By the late 1970's, a sensor-based-model for human vision based on the behavior of retinal ganglion cells could accurately predict the results of I/O-model-based contrast sensitivity experiments <ref> [WiBe79] </ref>. Contributions in the 1980's by Marr [Mar82], Legge and Foley [FoLe81], Daugman [Dau80], and others helped to produce models capable of accurately predicting contrast sensitivity, light adaptation, contrast masking and other visual phenomena. A particularly important example of a sensor-model-based image coder was proposed by Watson in [Wat87].
Reference: [Zek92] <author> S. Zeki, </author> <title> "The visual image in mind and brain," </title> <publisher> Scientific American, </publisher> <pages> pp. 68-76, </pages> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: THE HVS There is evidence that different aspects of an image such as color, motion and static form are processed along separate neural pathways <ref> [Zek92] </ref>. In this section, we present a brief description of early vision focusing on static form since the processing of static form is fundamental to the perception of grayscale still images.
Reference: [Zet93] <author> C. Zetzsche, E. Barth, B. Wegmann, </author> <title> "The Importance of Intrinsically Two-dimensional Image Features in Biological Vision and Picture Coding." In Digital Images and Human Vision, </title> <editor> ed. A. B. </editor> <booktitle> Watson, </booktitle> <pages> pp. 109-140, </pages> <address> MA: </address> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In contrast, lossless perceptual coding has as its goal the coding of signals with as few bits as possible subject to the constraint that the coded signal is indistinguishable from the original. We adopt the following definition of perceptual losslessness due to Zetzche et. al <ref> [Zet93] </ref>. Definition: A reconstructed signal is perceptually lossless with respect to the original if a critical observer given unlimited time cannot find any difference between the original and the reconstructed signal.
References-found: 56

