URL: http://www.cs.cornell.edu/Info/Projects/Bernoulli/papers/asplos5.ps
Refering-URL: http://www.cs.cornell.edu/Info/Projects/Bernoulli/
Root-URL: http://www.cs.brown.edu/
Title: Access Normalization: Loop Restructuring for NUMA Compilers  
Author: Wei Li Keshav Pingali 
Address: Ithaca, New York 14853  
Affiliation: Department of Computer Science Cornell University  
Abstract: In scalable parallel machines, processors can make local memory accesses much faster than they can make remote memory accesses. In addition, when a number of remote accesses must be made, it is usually more efficient to use block transfers of data rather than to use many small messages. To run well on such machines, software must exploit these features. We believe it is too onerous for a programmer to do this by hand, so we have been exploring the use of restructuring compiler technology for this purpose. In this paper, we start with a language like FORTRAN-D with user-specified data distributionand develop a systematic loop transformation strategy called access normalization that restructures loop nests to exploit locality and block transfers. We demonstrate the power of our techniques using routines from the BLAS (Basic Linear Algebra Subprograms) library. An important feature of our approach is that we model loop transformations using invertible matrices and integer lattice theory, thereby generalizing Banerjee's framework of uni-modular matrices [5]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal. </author> <title> Limits on interconnection network performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 398-412, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Contention in the network has the effect of increasing the expected latency of non-local references; therefore, data management to avoid non-local references has the added benefit of reducing contention, thereby improving performance. Interestingly, analytical studies show that long messages can increase the latency of non-local accesses <ref> [1] </ref>. This is an argument against long messages, but on current machines, this effect seems to be of secondary importance compared to the benefits of amortizing start-up time, as we show in Section 8. <p> This vector can be written as x = cZ (Z T Z) 1 Z T e k for some positive scaling integer c that makes all of the entries integers, where e T i = <ref> [0; 0; ::; 1; ::; 0] </ref>, with the 1 in the ith position, and Z is a column basis from D. j (0 0 1) For our example, the remaining dependence to be satisfied is e 3 . <p> The data access matrix is 1 1 0 0 0 1 1 0 0 . If we apply Algorithm BasisMatrix, we get a base matrix B consisting of the first three rows. However, the dependence matrix is <ref> [0; 0; 1] </ref> T . The legal base mapping is B legal = 1 1 0 0 1 1 , which is B with the second row negated. This matrix is invertible.
Reference: [2] <author> F. Allen, J. Cocke, and K. Kennedy. </author> <title> Reduction of Operator Strength, </title> <address> pages 79-101. </address> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: multiple of the loop index, is shown below. for i = 1, 3 for u = 2,6,2 (a) original code (b) loop scaling This transformation may introduce integer divisions, as is shown in the example, but these operations can be strength reduced and replaced with additions and conditional move operations <ref> [2] </ref>. The required conditional move operations can be implemented without branch instructions on modern processors like the DEC Alpha [9]. Like skewing or reversal, loop scaling is not particularly interesting in isolation, but combined with the other transformations, it lets us do wholesale loop restructuring for NUMA architectures.
Reference: [3] <author> R. Allen and K. Kennedy. </author> <title> Automatic translation of FORTRAN programs to vector form. </title> <journal> ACM Transactions on Progamming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: To reduce synchronization, transformations like loop interchange are carried out to move parallel loops outermost wherever possible <ref> [3, 5, 25, 37] </ref>. This approach does not perform any data management, so it is not suitable for generating good code on NUMA architectures. An alternative approach, implemented by the FORTRAN-D system [12], is to give the programmer control over how data structures are distributed across the processors. <p> This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [4] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> An interactive environment for data partitioning and distribution. </title> <booktitle> In Proc. 5th Distributed Memory Comput. Conf., </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: The techniques in this paper can be used to accomplish this [24]. We require the programmer to specify data distributions. Automatic deduction of this information for special programs has been investigated by Balasundaram and others <ref> [4] </ref>, by Gannon et al [10] on CEDAR-like architectures, by Hudak and Abraham [13] for sequentially iterated parallel loops, by Knobe et al [18] for SIMD machines, by Li and Chen [22] for index domain alignment and by Ramanujam and Sadayappan [29] who find communication-free partitioning of arrays in fully parallel
Reference: [5] <author> U. Banerjee. </author> <title> Unimodular transformations of double loops. </title> <booktitle> In Proceedings of the Workshop on Advances in Languages and Compilers for Parallel Processing, </booktitle> <pages> pages 192-219, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: To reduce synchronization, transformations like loop interchange are carried out to move parallel loops outermost wherever possible <ref> [3, 5, 25, 37] </ref>. This approach does not perform any data management, so it is not suitable for generating good code on NUMA architectures. An alternative approach, implemented by the FORTRAN-D system [12], is to give the programmer control over how data structures are distributed across the processors. <p> It has applications in other areas such as the generation of vector code. * Our loop transformations are expressed in the framework of invertible matrices and integer lattice theory, which is an important generalization of Banerjee's framework of unimodular matrices <ref> [5] </ref>. The rest of the paper is organized as follows. In Section 2, we discuss a simple example that gives an overview of our compiling strategy. We also introduce the data access matrix, which plays a key role in the development. <p> The use of matrix methods for loop transformations was pioneered by Banerjee who showed how common loop transformations such as loop interchange could be modeled using unimodular matrices <ref> [5] </ref>. Unimodular matrices are not sufficient for our purpose. In this section, we present an important generalization of Banerjee's technique that uses invertible matrices; unimodular matrices are a special case of invertible matrices. <p> The use of invertible matrices to model loop transformations is a generalization of the results of Banerjee who showed that unimodular matrices can be used to model loop interchange, skewing and reversal <ref> [5] </ref>. Invertible matrices include unimodular matrices as a special case, and permit us to model loop scaling as well. <p> To understand the problem, consider A = 1 1 0 , a basis matrix, and D A = 0 1 , the dependence matrix. Each column of the depen dence matrix represents the distance vector of a dependence in the loop nest <ref> [5] </ref>. In our example, there is just one dependence, and the distance values tell us that the dependence is between successive iterations of the innermost loop. <p> this paper can be used to partition work and data among the processors; techniques to enhance data reuse can be used to optimize uniprocessor cache performance. 9 Our use of matrix techniques follows the ground-breaking work of Banerjee who showed that unimodular matrices can model loop interchange, skewing and reversal <ref> [5] </ref>. Unimod-ular matrices were used by Kumar, Kulkarni and Basu [20] to eliminate outermost loop-carried dependences in generating code for distributed memory machines. In our work, we use invertible matrices, which include unimodular matrices as a special case.
Reference: [6] <institution> BBN Advanced Computers Inc. Butterfly GP1000 Switch Tutorial, </institution> <year> 1989. </year>
Reference-contexts: For example, in the BBN Butterfly, accesses to local memory take 0.6 microseconds while accesses to remote memory take about 6.6 microseconds <ref> [6] </ref>. Distributed memory machines like the Intel iPSC/i860 have even greater non-uniformity in memory access times because access to remote data must be orchestrated through the exchange of messages. <p> For block transfers, the startup time is about 8 microseconds, and after that, a byte is transferred every 0.31 microseconds <ref> [6] </ref>. Our compiler takes as input FORTRAN-77 programs with data distribution information, and it generates C code for each processor; this node program is compiled into native code using the Green Hills C 0 10 20 Speedup Processors gemm gemmT gemmB compiler (Release 1.8.4).
Reference: [7] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed memory multiprocessors. </title> <journal> The Journal of Supercomputing, </journal> <volume> 2(2), </volume> <month> October </month> <year> 1988. </year>
Reference-contexts: This is accomplished by placing these conditional tests in front of the statement, and having all the processors execute all iterations `looking for work to do' <ref> [7, 39] </ref>. In simple programs, these conditional tests can be optimized away, but in general they must be executed at runtime, which is inefficient. <p> Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [8] <author> T. Coleman and C. Van Loan. </author> <title> Handbook for Matrix Computations. </title> <journal> SIAM Publication, Phil, </journal> <year> 1988. </year>
Reference-contexts: In Section 7, we discuss how code can be generated after loops have been restructured according to our methods. We present experimental results in Section 8 that demonstrate that our methods work well on programs of practical interest such as routines from the BLAS (Basic Linear Algebra Subroutines) library <ref> [8] </ref>. Finally, we discuss related work in Section 9. 2 Overview of NUMA Compilation In this section, we give an overview of our compilation strategy for NUMA architectures. <p> Consider the rank 2k update SYR2K from BLAS (Basic Linear Algebra Subroutines) <ref> [8] </ref>. The subroutine computes C = ffA T B + ffB T A + C. Suppose A and B are banded matrices with band width b, then C is symmetric and banded with band width 2b 1.
Reference: [9] <institution> Digital Equipment Corporation. Aplha Architecture Handbook, </institution> <year> 1992. </year>
Reference-contexts: The required conditional move operations can be implemented without branch instructions on modern processors like the DEC Alpha <ref> [9] </ref>. Like skewing or reversal, loop scaling is not particularly interesting in isolation, but combined with the other transformations, it lets us do wholesale loop restructuring for NUMA architectures.
Reference: [10] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformaions. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 587-616, </pages> <year> 1988. </year>
Reference-contexts: For a machine in which processors have a first-level cache, there is the obvious possibility of selecting the padding to improve cache performance by incorporating results on blocking of nested loops <ref> [10, 32] </ref>. We leave this for future work. 7 NUMA Code Generation Once the program has been transformed by access normalization, we must generate the code that will run on each processor. <p> This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines. <p> The techniques in this paper can be used to accomplish this [24]. We require the programmer to specify data distributions. Automatic deduction of this information for special programs has been investigated by Balasundaram and others [4], by Gannon et al <ref> [10] </ref> on CEDAR-like architectures, by Hudak and Abraham [13] for sequentially iterated parallel loops, by Knobe et al [18] for SIMD machines, by Li and Chen [22] for index domain alignment and by Ramanujam and Sadayappan [29] who find communication-free partitioning of arrays in fully parallel loops.
Reference: [11] <author> H. M. Gerndt. </author> <title> Automatic Parallelization for Distributed-Memory Multiprocessing Systems. </title> <type> PhD thesis, </type> <institution> Bonn University, </institution> <address> FRG, </address> <year> 1989. </year>
Reference-contexts: These steps are routine <ref> [11, 25, 30] </ref>, and are omitted from this paper. 8 Empirical Results and Performance Analysis In this section, we report the performance of our techniques on routines from the BLAS (Basic Linear Algebra Subprograms) library. The target machine is a BBN Butterfly GP-1000.
Reference: [12] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <type> Technical Report TR91-156, </type> <institution> Rice University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: To reduce synchronization, transformations like loop interchange are carried out to move parallel loops outermost wherever possible [3, 5, 25, 37]. This approach does not perform any data management, so it is not suitable for generating good code on NUMA architectures. An alternative approach, implemented by the FORTRAN-D system <ref> [12] </ref>, is to give the programmer control over how data structures are distributed across the processors. The compiler uses this data decomposition information to determine how to assign work to processors. <p> In many of these cases, loop restructuring can improve code quality, but no general approach to loop transformation has been available in this context <ref> [12] </ref>. In this paper, we present a systematic approach to loop restructuring for parallel machines with a memory hierarchy. As in the ownership approach, our starting point is a language like FORTRAN-D with user-specified data decomposition. <p> Most of the examples in this paper use a wrapped column distribution. Blocked column distribution is similar, except that a processor gets a contiguous set of columns. We also support so-called 2-D blocks in which rectangular subblocks of the array are distributed to the processors <ref> [12] </ref>, but for lack of space, we will not consider them any further in this paper. Data distributions can be specified precisely using a distribution function. <p> Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [13] <author> D. Hudak and S. Abraham. </author> <title> Compiler techniques for data partitioning of sequentially iterated parallel loops. </title> <booktitle> In Proc. ACM Int. Conf. Supercomputing, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: The techniques in this paper can be used to accomplish this [24]. We require the programmer to specify data distributions. Automatic deduction of this information for special programs has been investigated by Balasundaram and others [4], by Gannon et al [10] on CEDAR-like architectures, by Hudak and Abraham <ref> [13] </ref> for sequentially iterated parallel loops, by Knobe et al [18] for SIMD machines, by Li and Chen [22] for index domain alignment and by Ramanujam and Sadayappan [29] who find communication-free partitioning of arrays in fully parallel loops.
Reference: [14] <author> K. Ikudome, G. Fox, A. Kolawa, and J. Flower. </author> <title> An automatic and symbolic parallelization system for distributed memory parallel computers. </title> <booktitle> In Proc. of the 5th Distributed Memory Comp. Conf., </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [15] <author> Intel Corporation. </author> <title> iPSC/i860 System Overview, </title> <year> 1991. </year>
Reference-contexts: For example, on the Intel iPSC/i860, it takes 70 microseconds to start up communication, but it takes only 1 microsecond to transfer a double precision floating point number between nearest neighbors once the communication has been setup <ref> [15] </ref>. Therefore, when a number of data items must be sent from one processor to another, it is preferable to use a single long message to amortize startup time.
Reference: [16] <author> F. Irigoin and R. Triolet. </author> <title> Supernode partitioning. </title> <booktitle> In Proc. 15th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1988. </year> <month> 10 </month>
Reference-contexts: This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [17] <institution> Kendall Square Research Corporation, </institution> <address> 170 Tracer Lane, Waltham, Ma 02154. </address> <note> Parallel Programming Manual, </note> <year> 1991. </year>
Reference-contexts: We have attempted to exploit locality by matching code to the data distribution across the machine. This is a static notion of locality, and must be differentiated from the dynamic locality that must be exploited on parallel machines with coherent caches <ref> [17] </ref>. On such machines, the key to high performance is data reuse, and the code must be restructured to allow reuse of cached data wherever possible. Restructuring techniques for doing this have been explored by Wolf and Lam [36]. Their approach is complementary to the one described here.
Reference: [18] <author> K. Knobe, J. Lukas, and G. Steele. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 102-118, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: We require the programmer to specify data distributions. Automatic deduction of this information for special programs has been investigated by Balasundaram and others [4], by Gannon et al [10] on CEDAR-like architectures, by Hudak and Abraham [13] for sequentially iterated parallel loops, by Knobe et al <ref> [18] </ref> for SIMD machines, by Li and Chen [22] for index domain alignment and by Ramanujam and Sadayappan [29] who find communication-free partitioning of arrays in fully parallel loops.
Reference: [19] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiling global names-pace parallel loops for distributed execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2, </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [20] <author> K. G. Kumar, D. Kulkarni, and A. Basu. </author> <title> Generalized unimodular loop transformations for distributed memory multiprocessors. </title> <type> Technical Report FG-TR-014, </type> <institution> Center for Development of Advanced Computing, </institution> <address> Bangalore, INDIA, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Unimod-ular matrices were used by Kumar, Kulkarni and Basu <ref> [20] </ref> to eliminate outermost loop-carried dependences in generating code for distributed memory machines. In our work, we use invertible matrices, which include unimodular matrices as a special case. This lets us model loop scaling as well, which is important in the NUMA context.
Reference: [21] <author> L. Lamport. </author> <title> The parallel execution of do loops. </title> <journal> Communications of the ACM, </journal> <pages> pages 83-93, </pages> <month> February </month> <year> 1974. </year>
Reference-contexts: This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [22] <author> J. Li and M. Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing between distributed arrays. </title> <type> Technical report, </type> <institution> Yale University, </institution> <year> 1989. </year>
Reference-contexts: Automatic deduction of this information for special programs has been investigated by Balasundaram and others [4], by Gannon et al [10] on CEDAR-like architectures, by Hudak and Abraham [13] for sequentially iterated parallel loops, by Knobe et al [18] for SIMD machines, by Li and Chen <ref> [22] </ref> for index domain alignment and by Ramanujam and Sadayappan [29] who find communication-free partitioning of arrays in fully parallel loops. These efforts focus on deducing good data distributions for particular kinds of programs such as fully parallel loops, and no general solution to this problem is known.
Reference: [23] <author> J. Li and M. Chen. </author> <title> Compiling communication efficient program for massively parallel machines. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2 </volume> <pages> 361-376, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [24] <author> W. Li and K. Pingali. </author> <title> Access normalization: loop restructuring for NUMA compilers. </title> <type> Technical Report 92-1278, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1992. </year>
Reference-contexts: The algorithm for generating a restructured program starting from a loop nest and an invertible mapping is given in the associated technical report <ref> [24] </ref>. <p> The algorithm described informally above is simple, but it is expensive to keep checking rows for independence. A more efficient algorithm is obtained by using a variation of computing the Hermite normal form <ref> [24] </ref>. A detailed understanding of this algorithm is not important for reading the rest of the paper, so we give an informal description of what it does. <p> Then, we pad this matrix using Algorithm LegalInvt to yield the final transformation. In this paper, we discuss only the case when dependences are represented by distances; it is straight-forward to extend these results to dependence directions <ref> [24] </ref>. 6.1 Generating a Legal Basis Algorithm LegalBasis , shown in Figure 2, takes a basis matrix and checks each row against the dependences. For example, consider the product of the first row and D A . <p> For lack of space, we will consider only the case when the step size of the outermost loop is 1; the case when the step size is not 1 requires the solution of a simple Diophantine equation <ref> [24] </ref>. <p> Even on machines such as the Fujitsu FACOM that support scatter and gather operations, it is more efficient to use constant stride accesses wherever possible since address generation for vector elements is faster. The techniques in this paper can be used to accomplish this <ref> [24] </ref>. We require the programmer to specify data distributions.
Reference: [25] <author> S. P. Midkiff and D. A. Padua. </author> <title> Compiler algorithms for synchronization. </title> <journal> IEEE Transactions on computers, </journal> <volume> C-36:1485-1495, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: To reduce synchronization, transformations like loop interchange are carried out to move parallel loops outermost wherever possible <ref> [3, 5, 25, 37] </ref>. This approach does not perform any data management, so it is not suitable for generating good code on NUMA architectures. An alternative approach, implemented by the FORTRAN-D system [12], is to give the programmer control over how data structures are distributed across the processors. <p> These steps are routine <ref> [11, 25, 30] </ref>, and are omitted from this paper. 8 Empirical Results and Performance Analysis In this section, we report the performance of our techniques on routines from the BLAS (Basic Linear Algebra Subprograms) library. The target machine is a BBN Butterfly GP-1000.
Reference: [26] <author> R. Mirchandaney, J. Saltz, R. Smith, D. Nicol, and K. Crowley. </author> <title> Principles of runtime support for parallel processors. </title> <booktitle> In Proc. of the 2nd Int. Conf. on Supercomputing, </booktitle> <month> July </month> <year> 1988. </year>
Reference-contexts: Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [27] <author> D. Padua and M. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of ACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: However, rather than use this information directly to generate code, we use the data distribution information to drive access normalization which is a loop restructuring technique that subsumes loop interchange, loop skewing, loop reversal and loop scaling <ref> [27, 38] </ref>. The objective of the restructuring is to transform loop nests so that code can be generated by distributing iterations of the outermost loop among the processors without compromising locality. The structure of inner loops is chosen so that data can be transferred using block transfers wherever possible. <p> This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [28] <author> A. Porterfield. </author> <title> Software Methords for Improvement of Cache Performance on Supercomputer Applications. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [29] <author> J. Ramanujam and P. Sadayappan. </author> <title> Compile-time techniques for data distribution in distributed memory machines. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2, </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: special programs has been investigated by Balasundaram and others [4], by Gannon et al [10] on CEDAR-like architectures, by Hudak and Abraham [13] for sequentially iterated parallel loops, by Knobe et al [18] for SIMD machines, by Li and Chen [22] for index domain alignment and by Ramanujam and Sadayappan <ref> [29] </ref> who find communication-free partitioning of arrays in fully parallel loops. These efforts focus on deducing good data distributions for particular kinds of programs such as fully parallel loops, and no general solution to this problem is known.
Reference: [30] <author> A. Rogers. </author> <title> Compiling for Locality of Reference. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <year> 1990. </year>
Reference-contexts: These steps are routine <ref> [11, 25, 30] </ref>, and are omitted from this paper. 8 Empirical Results and Performance Analysis In this section, we report the performance of our techniques on routines from the BLAS (Basic Linear Algebra Subprograms) library. The target machine is a BBN Butterfly GP-1000.
Reference: [31] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In Proc. of the 1989 SIG-PLAN Conference on Programming Language Design and Implementation, </booktitle> <year> 1989. </year>
Reference-contexts: Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [32] <author> R. Schreiber and J. Dongarra. </author> <title> Automatic blocking of nested loops. </title> <type> Technical Report 90.38, </type> <institution> NASA RIACS, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: For a machine in which processors have a first-level cache, there is the obvious possibility of selecting the padding to improve cache performance by incorporating results on blocking of nested loops <ref> [10, 32] </ref>. We leave this for future work. 7 NUMA Code Generation Once the program has been transformed by access normalization, we must generate the code that will run on each processor. <p> This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [33] <author> A. Schrijver. </author> <title> Theory of Linear and Integer Programming. </title> <publisher> John Wiley & Sons, </publisher> <year> 1986. </year>
Reference-contexts: It is not immediately obvious that this can be done for any invertible matrix T . Fortunately, the iteration space of a loop nest forms what is called an integer lattice; by applying some results from integer lattice theory <ref> [33] </ref>, we can easily construct the required loop nest. 4 Invertible Data Access Matrices In this section, we consider the simple case where the data access matrix is invertible. Consider the program of Figure 1 again. The data access matrix for the program is X. <p> &gt; 0 B r = x T ; End-While H = Padding (B); return (append (B, H)); end It is not immediately clear that such a vector exists; for tunately, Algorithm LegalInvt in Figure 3 gives a positive answer by computing such a vector using a standard result about projections <ref> [33] </ref>.
Reference: [34] <author> P. Tseng. </author> <title> A Parallelizing Compiler For Distributed Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1989. </year>
Reference-contexts: Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
Reference: [35] <author> D. Whitfield and M. L. Soffa. </author> <title> Automatic generation of global optimizers. </title> <booktitle> In Proc. of the SIGPLAN '91 Conf. on Programming Language Design and Implementation, SIGPLAN Notices, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [36] <author> M. Wolf and M. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proc. ACM SIGPLAN 91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: On such machines, the key to high performance is data reuse, and the code must be restructured to allow reuse of cached data wherever possible. Restructuring techniques for doing this have been explored by Wolf and Lam <ref> [36] </ref>. Their approach is complementary to the one described here. It is likely that scalable parallel architectures will be organized as networks of processor-memory pairs with an on-chip cache and perhaps a second level cache between the processor and its local memory.
Reference: [37] <author> M. Wolf and M. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <month> October </month> <year> 1991. </year>
Reference-contexts: To reduce synchronization, transformations like loop interchange are carried out to move parallel loops outermost wherever possible <ref> [3, 5, 25, 37] </ref>. This approach does not perform any data management, so it is not suitable for generating good code on NUMA architectures. An alternative approach, implemented by the FORTRAN-D system [12], is to give the programmer control over how data structures are distributed across the processors. <p> This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [38] <author> Michael Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> Pitman Publishing, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: However, rather than use this information directly to generate code, we use the data distribution information to drive access normalization which is a loop restructuring technique that subsumes loop interchange, loop skewing, loop reversal and loop scaling <ref> [27, 38] </ref>. The objective of the restructuring is to transform loop nests so that code can be generated by distributing iterations of the outermost loop among the processors without compromising locality. The structure of inner loops is chosen so that data can be transferred using block transfers wherever possible. <p> This lets us model loop scaling as well, which is important in the NUMA context. In general, it is easier to work with invertible matrices since there are fewer constraints to be satisfied in generating invertible matrices, as opposed to unimodular matrices. Other work on loop transformations includes <ref> [3, 10, 16, 21, 27, 28, 32, 35, 37, 38] </ref>. The data access matrix is a new concept introduced in this paper, and access normalization is useful in other contexts such as code generation for vector machines.
Reference: [39] <author> H. Zima and B. Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press Frontier Series, </publisher> <address> New York, New York, </address> <year> 1990. </year> <month> 11 </month>
Reference-contexts: Although this strategy takes data mappings into account, it can generate inefficient code, in which all processors execute all iterations `looking for work to do' if the structure of the loop nest does not match the data distribution <ref> [39] </ref>. In many of these cases, loop restructuring can improve code quality, but no general approach to loop transformation has been available in this context [12]. In this paper, we present a systematic approach to loop restructuring for parallel machines with a memory hierarchy. <p> This is accomplished by placing these conditional tests in front of the statement, and having all the processors execute all iterations `looking for work to do' <ref> [7, 39] </ref>. In simple programs, these conditional tests can be optimized away, but in general they must be executed at runtime, which is inefficient. <p> Related Work This paper is a contribution to the state of the art of compiling programs in languages like FORTRAN-D that permit user-defined data decomposition for parallel machines with a memory hierarchy, which is the goal of a number of projects including Parascope, Superb, Id Nouveau, Crystal, and other projects <ref> [7, 12, 14, 19, 23, 26, 31, 34, 39] </ref>. The emphasis in these projects has been on code generation mechanisms (such as the ownership rule discussed in Section 2) and on recognizing and exploiting special patterns of computation and communication such as reductions.
References-found: 39

