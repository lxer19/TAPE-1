URL: ftp://ftp.cs.toronto.edu/pub/jepson/papers/mixImage.ps.Z
Refering-URL: http://www.cs.toronto.edu/vis/publications/abstracts/mixImage.html
Root-URL: 
Title: Mixture Models for Image Representation  
Author: Allan Jepson and Michael Black 
Keyword: Category: Image representation. Keywords: Grey-level image models, probabilistic mixture models, segmentation.  
Affiliation: 1 Department of Computer Science, University of Toronto 2 Xerox PARC  
Abstract: We consider the estimation of local grey-level image structure in terms of a layered representation. This type of representation has recently been successfully used to segment various objects from clutter using either optical flow or stereo disparity information. We argue that the same type of representation is useful for grey-level data in that it allows for the estimation of properties for each of several different components without prior segmentation. Our emphasis in this paper is on the process used to extract such a layered representation from a given image. In particular, we consider a variant of the EM-algorithm for the estimation of the layered model, and consider a novel technique for choosing the number of layers to use. We briefly consider the use of a simple version of this approach for image segmentation, and suggest two potential applications to the ARK project. This paper is the PRECARN ARK Project Technical Report ARK96-PUB-54, March 1996. Correspondence should be sent to A. Jepson, Department of Computer Science, University of Toronto, 6 King's College Road, Toronto, Ontario M5S 3H5, or to jepson@cs.toronto.edu 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Amir and M. Lindenbaum. </author> <title> Quantitative analysis of grouping processes. </title> <editor> In B. Buxton and R. Cipolla, editors, </editor> <booktitle> Proc. Fourth European Conf. on Computer Vision, </booktitle> <address> ECCV-96, Cambridge, UK, </address> <pages> pages 371-384. </pages> <publisher> Springer Verlag, </publisher> <month> April </month> <year> 1996. </year>
Reference-contexts: For each pixel, first select a particular component process by randomly choosing k 2 f0; . . . ; Kg according to the mixture probabilities fm k g K k=0 . Here m k is the probability of selecting process k, with m k 2 <ref> [0; 1] </ref> and P K k=0 m k = 1. Once a k is selected, we then randomly select a grey-level g according to the component distribution p k (g). Together this provides a generative model for the image patch in terms of a mixture of simple processes. <p> However, this use of a connected components algorithm is definitely the weak link in the two ARK specific applications presented. More robust grouping techniques, perhaps along the lines suggested by Amir and Lindenbaum <ref> [1] </ref>, should be considered. Acknowledgements We are grateful to Charles Stewart for supplying both the sports equipment and the wires image pair.
Reference: [2] <author> S. Ayer and H. Sawhney. </author> <title> Layered representation of motion video using robust maximumlikelihood estimation of mixture models and MDL encoding. </title> <booktitle> In Proc. International Conference on Computer Vision, ICCV-95, </booktitle> <pages> pages 777-784, </pages> <year> 1995. </year>
Reference-contexts: That is, we require log (L r ) log (L c ) &gt; ffi; (4:1) where ffi = 2:5 in the computations reported in Figures 4.1 through 4.5. The use of such a threshold is related to a minimum description length criteria <ref> [2] </ref>, in which the ffi is chosen with regards to the extra cost of coding the more elaborate revised model. <p> One shortcoming we have noted is that the number of layers can be unnecessarily large, especially if only a rough approximation of the original image is desired. Perhaps the number of layers chosen can be reduced using an MDL or Bayesian approach (see <ref> [2] </ref> and [9]), or by using spatial correlations in the generative model (see [15]). For the present we recommend that the current algorithm is used with a strict upper limit on the number of layers, and possibly with pruning in a post-processing step.
Reference: [3] <author> M. Black and A. Jepson. </author> <title> Estimating multiple independent motions in segmented images using parametric models with local deformations. </title> <booktitle> In Workshop on Motion of Non-rigid and Articulated Objects, </booktitle> <pages> pages 220-227, </pages> <address> Austin, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: (For similar work 2 Roughly similar results can also be obtained using constant models, instead of linear models, resulting in some speed-up (2.5 to 5 seconds run time) and some degradation in segmentation. 21 connected components for the forklift image (run time 6.7 secs). 22 done with optical flow, see <ref> [3] </ref>.) A second application is in determining the location of landmarks in an image. For example, the majority of the large door in the hall image can be segmented, despite some highlights on it.
Reference: [4] <author> T. Darrell and A. Pentland. </author> <title> Robust estimation of a multi-layer motion representation. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 173-178, </pages> <address> Princeton, NJ, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Layered image models have been proposed for representing a variety of image primitives, including image intensities (see [13]), optical flow (see <ref> [4, 14] </ref>), and range data (see [11]). In earlier ARK related work we have studied the use of a layered representation for the estimation of optical flow [6, 7]. A similar approach was developed for stereo disparity as part of a floor anomaly detector (FAD) application [5].
Reference: [5] <author> M. Jenkin and A. Jepson. </author> <title> Detecting floor anomalies. </title> <editor> In E. Hancock, editor, </editor> <booktitle> Proceedings of the British Machine Vision Conference, </booktitle> <pages> pages 731-740, </pages> <address> UK, </address> <year> 1994. </year>
Reference-contexts: In earlier ARK related work we have studied the use of a layered representation for the estimation of optical flow [6, 7]. A similar approach was developed for stereo disparity as part of a floor anomaly detector (FAD) application <ref> [5] </ref>. The general motivation for this paper is to study the process of fitting layered models to image data. Here we consider the application of layered models to the estimation and representation of grey-level image structure. <p> The motivation from the ARK robot is two-fold. One application is to segment out a large portion of the floor. This would be useful to determine "floor anomalies," especially when used in conjunction with stereo disparity <ref> [5] </ref>, or motion information [10]. A second motivation is to segment fairly large uniform objects which may serve as landmarks, such as the door in the hall image in Figure 4.2. Such a process may provide a fast and reliable means of roughly locating a landmark. <p> In particular, the large segments can provide a rough guess for where to fit planar floor models to the stereo disparity. The requirements here are fairly loose in that a precise segmentation is not needed since the stereo FAD approach described in <ref> [5] </ref> is also tolerant of outliers. Secondly, this stereo FAD system has no spatial integration. As a result, spots on the floor with little or no texture (such as within the piece of paper in Figure 5.1) are considered to have an undetermined depth.
Reference: [6] <author> A. Jepson and M. J. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, CVPR-93, </booktitle> <pages> pages 760-761, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Layered image models have been proposed for representing a variety of image primitives, including image intensities (see [13]), optical flow (see [4, 14]), and range data (see [11]). In earlier ARK related work we have studied the use of a layered representation for the estimation of optical flow <ref> [6, 7] </ref>. A similar approach was developed for stereo disparity as part of a floor anomaly detector (FAD) application [5]. The general motivation for this paper is to study the process of fitting layered models to image data.
Reference: [7] <author> A. Jepson and M. J. Black. </author> <title> Mixture models for optical flow computation. </title> <editor> In Ingemar Cox, Pierre Hansen, and Bela Julesz, editors, </editor> <title> Proceedings of the DIMACS Workshop on Partitioning Data Sets: With Applications to Psychology, </title> <booktitle> Vision and Target Tracking, </booktitle> <pages> pages 271-286, </pages> <address> Providence, RI, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction Layered image models have been proposed for representing a variety of image primitives, including image intensities (see [13]), optical flow (see [4, 14]), and range data (see [11]). In earlier ARK related work we have studied the use of a layered representation for the estimation of optical flow <ref> [6, 7] </ref>. A similar approach was developed for stereo disparity as part of a floor anomaly detector (FAD) application [5]. The general motivation for this paper is to study the process of fitting layered models to image data.
Reference: [8] <author> S. Ju, M. Black, and A. Jepson. </author> <title> Skin and bones: Multi-layer, locally affine, optical flow and regularization with transparency. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, </booktitle> <address> CVPR-96, San Francisco, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: In particular, the spatial correlation of the assignment of pixels to layers is not modelled. Similarly, the correlation of the individual processes themselves across neighbouring image patches is ignored. These properties can be included in an elaborated model (see, for example, [15] and <ref> [8] </ref>). <p> This is appropriate for our present purpose of studying the process of fitting layered models. However, for a practical system it would be of interest to consider spatial interactions between neighbouring patches during the fitting process, perhaps along the lines described in <ref> [8] </ref>. Several other extensions are also of interest. The application to colour data, for example, is a straight forward extension. This involves replacing the scalar grey-level with a colour vector and the variance estimates with a 3 fi 3 covariance matrix.
Reference: [9] <author> D. MacKay. </author> <title> Bayesian interpolation. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 415-447, </pages> <year> 1991. </year>
Reference-contexts: Another approach for limiting the number of layers is to use the Bayesian estimation approach of <ref> [9] </ref>, which essentially penalizes both for model complexity and model parameters which are not well specified. <p> One shortcoming we have noted is that the number of layers can be unnecessarily large, especially if only a rough approximation of the original image is desired. Perhaps the number of layers chosen can be reduced using an MDL or Bayesian approach (see [2] and <ref> [9] </ref>), or by using spatial correlations in the generative model (see [15]). For the present we recommend that the current algorithm is used with a strict upper limit on the number of layers, and possibly with pruning in a post-processing step.
Reference: [10] <author> W.J. MacLean, A. Jepson, and R. Frecker. </author> <title> Recovery of egomotion and segmentation of independent object motion using the EM-algorithm. </title> <editor> In E. Hancock, editor, </editor> <booktitle> Proceedings of the British Machine Vision Conference, BMVC-94, </booktitle> <pages> pages 175-184, </pages> <address> UK, </address> <year> 1994. </year>
Reference-contexts: The motivation from the ARK robot is two-fold. One application is to segment out a large portion of the floor. This would be useful to determine "floor anomalies," especially when used in conjunction with stereo disparity [5], or motion information <ref> [10] </ref>. A second motivation is to segment fairly large uniform objects which may serve as landmarks, such as the door in the hall image in Figure 4.2. Such a process may provide a fast and reliable means of roughly locating a landmark.
Reference: [11] <author> S. Madarasmi, D. Kersten, and T. C. Pong. </author> <title> Multi-layer surface segmentation using energy minimization. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, CVPR-93, </booktitle> <pages> pages 774-775, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Layered image models have been proposed for representing a variety of image primitives, including image intensities (see [13]), optical flow (see [4, 14]), and range data (see <ref> [11] </ref>). In earlier ARK related work we have studied the use of a layered representation for the estimation of optical flow [6, 7]. A similar approach was developed for stereo disparity as part of a floor anomaly detector (FAD) application [5].
Reference: [12] <author> G.J. McLachlan and K.E. Basford. </author> <title> Mixture Models: Inference and Applications to Clustering. </title> <publisher> Marcel Dekker Inc., </publisher> <address> N.Y., </address> <year> 1988. </year> <month> 27 </month>
Reference-contexts: These ownership probabilities are defined by q kn = P K : (3:3) These equations for a maximum likelihood fit have been derived by a number of authors; for further details see <ref> [12] </ref>. The first equation, (3.2a), comes from the condition that the partial derivative of log L with respect to the mixture proportion m k must be equal to the Lagrange multiplier . This Lagrange multiplier arises by imposing the constraint that the mixture proportions must sum to one. <p> While the third equation is obtained from the variation of log L with respect to k . 3.1 The EM Algorithm Equations (3.2) and (3.3) suggest an iterative algorithm, known as the EM-algorithm <ref> [12] </ref>, for obtaining a maximum likelihood fit for the parameters m k , k = 0; . . . ; K, and also for ~a k , k for k = 1; . . . ; K. <p> As we see below, for Gaussian distributions these equations can be easily solved. The overall result of both the E-step and the M-step is an update of the parameters m k , ~a k and k which is guaranteed to increase the log likelihood <ref> [12] </ref>. These two steps are then iterated until convergence. For the details of the M-step, first consider the update for the mixture probabilities fm k g K k=0 . The appropriate choice for m k given the ownerships q kn is obtained from (3.2a).
Reference: [13] <author> M. Nitzberg and D. Mumford. </author> <title> The 2.1-D sketch. </title> <booktitle> In Proc. Int. Conf. on Computer Vision, ICCV-90, </booktitle> <pages> pages 138-144, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Layered image models have been proposed for representing a variety of image primitives, including image intensities (see <ref> [13] </ref>), optical flow (see [4, 14]), and range data (see [11]). In earlier ARK related work we have studied the use of a layered representation for the estimation of optical flow [6, 7].
Reference: [14] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Layered representation for motion analysis. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, CVPR-93, </booktitle> <pages> pages 361-366, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Layered image models have been proposed for representing a variety of image primitives, including image intensities (see [13]), optical flow (see <ref> [4, 14] </ref>), and range data (see [11]). In earlier ARK related work we have studied the use of a layered representation for the estimation of optical flow [6, 7]. A similar approach was developed for stereo disparity as part of a floor anomaly detector (FAD) application [5].
Reference: [15] <author> Y. Weiss and E. H. Adelson. </author> <title> A unified mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, </booktitle> <address> CVPR'96, San Francisco, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: In particular, the spatial correlation of the assignment of pixels to layers is not modelled. Similarly, the correlation of the individual processes themselves across neighbouring image patches is ignored. These properties can be included in an elaborated model (see, for example, <ref> [15] </ref> and [8]). <p> Perhaps the number of layers chosen can be reduced using an MDL or Bayesian approach (see [2] and [9]), or by using spatial correlations in the generative model (see <ref> [15] </ref>). For the present we recommend that the current algorithm is used with a strict upper limit on the number of layers, and possibly with pruning in a post-processing step. As demonstrated here, the results then appear to be sufficient for many practical purposes.
References-found: 15

