URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/austrian/www/pub/icra98-1.ps.Z
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/austrian/www/icra98-1.html
Root-URL: 
Phone: 2  
Title: On Discontinuous Human Control Strategies  
Author: Michael C. Nechyba and Yangsheng Xu , 
Address: Pittsburgh, PA 15213, USA  Hong Kong, Hong Kong  
Affiliation: 1 The Robotics Institute, Carnegie Mellon University,  Department of Mechanical and Automation Engineering, The Chinese University of  
Abstract: Models of human control strategy (HCS), which accurately emulate dynamic human behavior, have far reaching potential in areas ranging from robotics to virtual reality to the intelligent vehicle highway project. A number of learning algorithms, including fuzzy logic, neural networks, and locally weighted regression exist for modeling continuous human control strategies. These algorithms, however, may not be well suited for modeling discontinuous human control strategies. Therefore, we propose a new stochastic, discontinuous modeling framework, for abstracting human control strategies, based on Hidden Markov Models. In this paper, we first describe the real-time driving simulator which we have developed for investigating human control strategies. Next, we demonstrate the shortcomings of a typical continuous modeling approach in modeling a discontinuous human control strategy. We then propose an HMM-based method of modeling discontinuous human control strategies, and show that the proposed controller overcomes these shortcomings and demonstrates greater fidelity to the human training data. We conclude the paper with further comparisons between the two competing modeling approaches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. C. Nechyba and Y. Xu, </author> <title> Human Control Strategy: Abstraction, Verification and Replication, </title> <journal> IEEE Control Systems Magazine, </journal> <volume> vol. 17., no. 5, </volume> <pages> pp. 48-61, </pages> <year> 1997. </year>
Reference-contexts: 1. Introduction In recent years, a number of different researchers have endeavored to abstract models of human skill directly from observed human input-output data (see <ref> [1] </ref> for an overview of the literature). Much of the work to date attempts to model human skill by learning the mapping from sensory inputs to control action outputs.
Reference: [2] <author> M. C. Nechyba and Y. Xu, </author> <title> Learning and Transfer of Real-Time Human Control Strategies, </title> <journal> to appear in Journal of Advanced Computational Intelligence, </journal> <volume> vol. 1, no. 2, </volume> <year> 1997. </year>
Reference-contexts: In the experiments reported in this paper, we enhance the basic cascade learning framework in two ways: (1) we allow new hidden units to have variable activation functions <ref> [2] </ref>, increasing the functional flexibility of the learning architecture; and (2) we train the neural network weights through node-decoupled extended Kalman filtering (NDEKF) [5], as opposed to gradient-descent techniques, such as quickprop or backpropagation.
Reference: [3] <author> H. Hatwal and E. C. Mikulcik, </author> <title> Some Inverse Solutions to an Automobile Path-Tracking Problem with Input Control of Steering and Brakes, Vehicle System Dynamics, </title> <journal> vol. </journal> <volume> 15, </volume> <pages> pp. 61-71, </pages> <year> 1986. </year>
Reference: [4] <author> S. E. Fahlman, L. D. Baker and J. A. Boyan, </author> <title> The Cascade 2 Learning Architecture, </title> <type> Technical Report, </type> <institution> CMU-CS-TR-96-184, Carnegie Mellon University, </institution> <year> 1996. </year>
Reference: [5] <author> M. C. Nechyba and Y. Xu, </author> <title> Cascade Neural Networks with Node-Decoupled Extended Kalman Filtering, </title> <booktitle> Proc. IEEE Int. Symp. on Computational Intelligence in Robotics and Automation, </booktitle> <volume> vol. 1, </volume> <pages> pp. 214-9, </pages> <year> 1997. </year>
Reference-contexts: the experiments reported in this paper, we enhance the basic cascade learning framework in two ways: (1) we allow new hidden units to have variable activation functions [2], increasing the functional flexibility of the learning architecture; and (2) we train the neural network weights through node-decoupled extended Kalman filtering (NDEKF) <ref> [5] </ref>, as opposed to gradient-descent techniques, such as quickprop or backpropagation. Both of these modifications have been shown to significantly improve learning speed and error convergence of the cascade learning architecture.
Reference: [6] <author> L. R. Rabiner, </author> <title> A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, </title> <journal> Proc. IEEE, </journal> <volume> vol. 77, no. 2, </volume> <pages> pp. 257-86, </pages> <year> 1989. </year>
Reference-contexts: This poses an impossible learning challenge not just for cascade neural networks, but any continuous function approximator. 4. Discontinuous control To cope with the problems discussed above, we propose a new HMM-based framework for modeling discontinuous control strategies. Hidden Markov Models <ref> [6] </ref> are trainable statistical models which can be applied to model human control strategy, not as a deterministic functional mapping, but rather as a probabilistic relationship between sensory inputs and control actions outputs. <p> Hidden Markov Models [6] are trainable statistical models which can be applied to model human control strategy, not as a deterministic functional mapping, but rather as a probabilistic relationship between sensory inputs and control actions outputs. They have previously been applied in a number areas, including speech recognition <ref> [6, 7] </ref>, modeling open-loop human actions [8], and analyzing similarity between human control strategies [9]. Although continuous and semi-continuous HMMs have been developed, discrete-output HMMs are often preferred in practice because of their relative computational simplicity and reduced sensitivity to initial parameter settings during training [6]. <p> Although continuous and semi-continuous HMMs have been developed, discrete-output HMMs are often preferred in practice because of their relative computational simplicity and reduced sensitivity to initial parameter settings during training <ref> [6] </ref>. A discrete Hidden Markov Model consists of a set of n states, interconnected through probabilistic transitions, and is completely defined by the triplet, , where is the probabilistic state transition matrix, is the output probability matrix with discrete output symbols, and is the n-length initial state probability distribution vector.
Reference: [7] <author> X. D. Huang, Y. Ariki and M. A. Jack, </author> <title> Hidden Markov Models for Speech Recognition, </title> <publisher> Edinburgh Univ. Press, </publisher> <year> 1990. </year>
Reference-contexts: Hidden Markov Models [6] are trainable statistical models which can be applied to model human control strategy, not as a deterministic functional mapping, but rather as a probabilistic relationship between sensory inputs and control actions outputs. They have previously been applied in a number areas, including speech recognition <ref> [6, 7] </ref>, modeling open-loop human actions [8], and analyzing similarity between human control strategies [9]. Although continuous and semi-continuous HMMs have been developed, discrete-output HMMs are often preferred in practice because of their relative computational simplicity and reduced sensitivity to initial parameter settings during training [6]. <p> In such cases, by monitoring the VQ distortion, it might be possible to temporarily suspend the HMM controller in favor of a neural network controller until the VQ distortion once again returns to an acceptable level. Alternatively, we are investigating whether semicontinuous HMMs <ref> [7] </ref>, which model the VQ codebook as a family of Gaussian pdfs, would (1) improve performance, and (2) be computationally tractable in real- time execution. A second limitation of the HMM approach is the inclusion of the prior probabilities in the stochastic selection criterion.
Reference: [8] <author> J. Yang, Y. Xu and C. S. Chen, </author> <title> Human Action Learning Via Hidden Markov Model, </title> <journal> IEEE Trans. Systems, Man and Cybernetics, Part A, </journal> <volume> vol. 27, no. 1, </volume> <pages> pp. 34-44, </pages> <year> 1997. </year>
Reference-contexts: They have previously been applied in a number areas, including speech recognition [6, 7], modeling open-loop human actions <ref> [8] </ref>, and analyzing similarity between human control strategies [9]. Although continuous and semi-continuous HMMs have been developed, discrete-output HMMs are often preferred in practice because of their relative computational simplicity and reduced sensitivity to initial parameter settings during training [6].
Reference: [9] <author> M. C. Nechyba and Y. Xu, </author> <title> Stochastic Similarity for Validating Human Control Strategy Models, </title> <booktitle> Proc. IEEE Conf. on Robotics and Automation, </booktitle> <volume> vol. 1, </volume> <pages> pp. 278-83, </pages> <year> 1997. </year>
Reference-contexts: They have previously been applied in a number areas, including speech recognition [6, 7], modeling open-loop human actions [8], and analyzing similarity between human control strategies <ref> [9] </ref>. Although continuous and semi-continuous HMMs have been developed, discrete-output HMMs are often preferred in practice because of their relative computational simplicity and reduced sensitivity to initial parameter settings during training [6]. <p> We can quantify the degree of similarity to Larrys control strategy for each controller using a stochastic similarity measure which we have developed previously <ref> [9] </ref> for comparing different human control strategies. The similarity measure is capable of comparing stochastic, multi-dimensional trajectories and yields a value between 0 and 1, with larger values indicating greater similarity.
Reference: [10] <author> Y. Linde, A. Buzo and R. M. Gray, </author> <title> An Algorithm for Vector Quantizer Design, </title> <journal> IEEE Trans. Communication, </journal> <volume> vol. COM-28, no. 1, </volume> <pages> pp. 84-95, </pages> <year> 1980. </year> <title> s s Larry HMM,( ) 0.628= s Larry NN,( ) 0.101= A i P A i ( ) Da g Da b </title>
Reference-contexts: At a minimum, this process involves vector quantizing the input-space vectors to discrete symbols. We choose the well-known LBG VQ algorithm <ref> [10] </ref>, which iteratively generates vector codebooks of size , , and can be stopped at an appropriate level of dis-cretization, as determined by the amount of available data.
References-found: 10

