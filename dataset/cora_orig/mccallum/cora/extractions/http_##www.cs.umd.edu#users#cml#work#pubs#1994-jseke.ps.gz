URL: http://www.cs.umd.edu/users/cml/work/pubs/1994-jseke.ps.gz
Refering-URL: http://www.cs.umd.edu/users/cml/work/pubs/
Root-URL: 
Email: E-mail: lott@informatik.uni-kl.de  
Title: Technology trends survey: Measurement support in software engineering environments  
Author: Christopher M. Lott 
Keyword: commercial software systems. Keywords: software metrics, process modeling, empirical data collection, measurement-based project guidance, MVP Project.  
Note: Appeared in v. 4, n. 3 (September 1994) of the Int. Journal  Funding for the Software Technology Transfer Initiative Kaiserslautern was provided in part by the Ministry  
Address: 67653 Kaiserslautern, Germany  Rheinland-Palatinate, Germany.  
Affiliation: Software Technology Transfer Initiative Kaiserslautern Gebaude 57, Universitat Kaiserslautern  of Software Engineering and Knowledge Engineering  of Commerce and Transport (BMWV) of the State of the  
Abstract: The use of empirical data to understand and improve software products and software engineering processes is gaining ever increasing attention. Empirical data from products and processes is needed to help organization understand and improve its way of doing business in the software domain. Additional motivation for collecting and using data is provided by the need to conform to guidelines and standards which mandate measurement, specifically the SEI's Capability Maturity Model and ISO 9000-3. Some software engineering environments (SEEs) offer automated support for collecting and, in a few cases, using empirical data. Measurement will clearly play a significant role in future SEEs. The paper surveys the trend towards supporting measurement in SEEs and gives details about several existing research and 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Victor R. Basili. </author> <title> Software development: A paradigm for the future. </title> <booktitle> In Proceedings of the Thirteenth Annual International Computer Software and Application Conference (COMPSAC), </booktitle> <pages> pages 471485, </pages> <address> Orlando, Florida, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: The first motivational factor in measurement, the carrot, is improving how a software organization works. Organizations measure their work in order to characterize, understand, and improve it. Measurement is used for these purposes in the Quality Improvement Paradigm <ref> [1] </ref>. The QIP approach involves defining goals, collecting empirical data from the processes and products, and analyzing the data.
Reference: [2] <author> Victor R. Basili. </author> <title> GQM approach has evolved to include models. </title> <journal> IEEE Software, </journal> <volume> 11(1):8, </volume> <month> Jan-uary </month> <year> 1994. </year> <title> Letter to the editor. </title>
Reference-contexts: A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm [4, 3]. Building a data collection plan by using a goal-directed method such as G/Q/M is not a guarantee for success (see also <ref> [6, 2, 41] </ref>) but will encourage goal definition and assist in interpreting the collected data in the context of those goals. In the G/Q/M method, organizational goals are defined first.
Reference: [3] <author> Victor R. Basili and H. Dieter Rombach. </author> <title> The TAME Project: Towards improvement oriented software environments. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-14(6):758773, </volume> <month> June </month> <year> 1988. </year>
Reference-contexts: The importance of starting with goals is vital, because goal-directed data collection skirts the pitfall of gathering large amounts of data that are never used <ref> [3] </ref>. Conformance with guidelines such as the Software Engineering Institute's Capability Maturity Model (CMM, [13, 31]) and the International Organization for Standardization's ISO 9000-3 [16] is the other major motivational factor, the stick driving organizations to measure their work. <p> A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm <ref> [4, 3] </ref>. Building a data collection plan by using a goal-directed method such as G/Q/M is not a guarantee for success (see also [6, 2, 41]) but will encourage goal definition and assist in interpreting the collected data in the context of those goals. <p> Next I present an explanation of this survey's purpose, structured in the form of a goal, a set of questions, and a set of metrics <ref> [4, 3] </ref>. Goal: To survey CASE and CAPE systems, for the purpose of characterizing them, with respect to their support for collection and use of measurement data, from the point of view of the researcher. Questions: The following questions refine the goal. 1.
Reference: [4] <author> Victor R. Basili and David M. Weiss. </author> <title> A methodology for collecting valid software engineering data. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(6):728738, </volume> <month> Novem-ber </month> <year> 1984. </year>
Reference-contexts: A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm <ref> [4, 3] </ref>. Building a data collection plan by using a goal-directed method such as G/Q/M is not a guarantee for success (see also [6, 2, 41]) but will encourage goal definition and assist in interpreting the collected data in the context of those goals. <p> Next I present an explanation of this survey's purpose, structured in the form of a goal, a set of questions, and a set of metrics <ref> [4, 3] </ref>. Goal: To survey CASE and CAPE systems, for the purpose of characterizing them, with respect to their support for collection and use of measurement data, from the point of view of the researcher. Questions: The following questions refine the goal. 1.
Reference: [5] <author> Steve Benford, Edmund Burke, and Eric Fox-ley. </author> <title> Learning to construct quality software with the Ceilidh system. </title> <journal> Software Quality Journal, </journal> <volume> 2(3):177197, </volume> <month> September </month> <year> 1993. </year>
Reference-contexts: Ceilidh. The Ceilidh system 4 is a quality control system for teaching students how to develop programs according to specifications and to quality standards <ref> [5] </ref>. Ceilidh (pronounced cay-lee) offers measurement-based guidance for coding activities. Like all systems for measurement-based guidance, it is critically dependent on the models used as the baselines for comparison with the collected data. In the Ceilidh system, the baseline is based on a sample solution to the problem.
Reference: [6] <author> David N. Card. </author> <title> What makes for effective measurement? IEEE Software, </title> <address> 10(6):9495, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm [4, 3]. Building a data collection plan by using a goal-directed method such as G/Q/M is not a guarantee for success (see also <ref> [6, 2, 41] </ref>) but will encourage goal definition and assist in interpreting the collected data in the context of those goals. In the G/Q/M method, organizational goals are defined first.
Reference: [7] <author> Bill Curtis. </author> <booktitle> Measurement and experimentation in software engineering. Proceedings of the IEEE, </booktitle> <address> 68(9):11441157, </address> <month> September </month> <year> 1980. </year>
Reference-contexts: Further, by integrating the data collection with the process model, measurement-based feedback and guidance can be offered to the people who perform the processes <ref> [7, 33, 23] </ref>. A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm [4, 3].
Reference: [8] <author> Raymond Dion. </author> <title> Process improvement and the corporate balance sheet. </title> <journal> IEEE Software, </journal> <volume> 10(4):2835, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: These activities can be quite expensive but there is strong evidence that organizations have found the effort worthwhile. Dion reports on process improvement at Raytheon, where measurement is an integral part of their effort <ref> [8] </ref>. They claim to have measured a US$7.70 return for every US$1 spent and to have evolved to CMM level three. McGarry reports on empirical data collection and use in NASA's Goddard Space Flight Center and states that measurement is not cost prohibitive [27].
Reference: [9] <author> Interactive Development Environments. </author> <title> Software through Pictures Integrated Structured Environment release 4.2d. 595 Market Street 10th Floor, </title> <address> San Francisco, CA 94105, </address> <year> 1992. </year>
Reference-contexts: A CASE system offers construction tools for evolving software artifacts (documents, designs, code, etc.) in a single life-cycle phase or across multiple phases. An example of a CASE system is the Integrated Structured Environment, which provides editors for structured analysis and structured design diagrams <ref> [9] </ref>. In contrast, a CAPE system uses some formal representation of a process to guide people through enaction of that process. An example of a CAPE system is Process Weaver, which provides a system for defining a process using a network formalism and enacting the process using the network [11].
Reference: [10] <author> Peter H. Feiler. </author> <title> CASE and CAPE: conflict of interest. </title> <editor> In Wilhelm Schafer, editor, </editor> <booktitle> Proceedings of the Eighth International Software Process Workshop, </booktitle> <pages> pages 6971. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> March </month> <year> 1993. </year>
Reference-contexts: This support can be found in at least two types of software engineering environments, namely computer-aided software engineering (CASE) systems and computer-aided process enactment (CAPE) systems. Feiler introduced the term CAPE in <ref> [10] </ref>, and I feel that it captures both the similarities and differences between the two types of systems. A CASE system offers construction tools for evolving software artifacts (documents, designs, code, etc.) in a single life-cycle phase or across multiple phases.
Reference: [11] <author> Christer Fernstr om. </author> <title> Process WEAVER: Adding process support to UNIX. </title> <booktitle> In Proceedings of the Second International Conference on the Software Process, </booktitle> <pages> pages 1226. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> February </month> <year> 1993. </year>
Reference-contexts: In contrast, a CAPE system uses some formal representation of a process to guide people through enaction of that process. An example of a CAPE system is Process Weaver, which provides a system for defining a process using a network formalism and enacting the process using the network <ref> [11] </ref>. Due to the great diversity of existing CASE and CAPE systems, it is often difficult to draw the dividing line between them precisely and unambiguously. Two primary differences are used in this paper. The first is the system's awareness of a process or life cycle.
Reference: [12] <author> Sallie Henry and Calvin Selig. </author> <title> Predicting source-code complexity at the design stage. </title> <journal> IEEE Software, </journal> <volume> 7(2):3644, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Beyond module call-trees and many types of cross references, the system collects data for the following metrics: fan-out, tramp data couples, and tramp control couples. Some of the advantages of design measurement that were discussed in <ref> [12, 37] </ref> are repeated here briefly. Based on the assumption that software structure and complexity affect the maintainability of the software, appropriate choices made in the design phase can have a large influence on later phases.
Reference: [13] <author> Watts S. Humphrey. </author> <title> Managing the Software Process. </title> <publisher> Addison Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1989. </year>
Reference-contexts: The importance of starting with goals is vital, because goal-directed data collection skirts the pitfall of gathering large amounts of data that are never used [3]. Conformance with guidelines such as the Software Engineering Institute's Capability Maturity Model (CMM, <ref> [13, 31] </ref>) and the International Organization for Standardization's ISO 9000-3 [16] is the other major motivational factor, the stick driving organizations to measure their work. This factor can arguably be viewed as a threat because of its use in awarding competitive contracts [38].
Reference: [14] <author> International Organization for Standardization. </author> <title> ISO 9000: 1987 Quality management and quality assurance standards Guidelines for selection and use. </title> <address> Geneva, Switzerland, </address> <year> 1987. </year>
Reference-contexts: A second guideline that has received much attention is the ISO 9000 series <ref> [14, 15, 16] </ref>.
Reference: [15] <author> International Organization for Standardization. </author> <title> ISO 9001: Quality systems Model for quality assurance in design / development, production, installation and servicing. </title> <address> Geneva, Switzer-land, </address> <year> 1987. </year>
Reference-contexts: A second guideline that has received much attention is the ISO 9000 series <ref> [14, 15, 16] </ref>.
Reference: [16] <author> International Organization for Standardization. </author> <title> ISO 9000: Quality management and quality assurance standards; Part 3: </title> <note> Guidelines for the Appeared in Int. </note> <author> J. </author> <title> Software Engineering and Knowledge Engineering, September 1994 20 application of ISO 9001 to the development, </title> <booktitle> supply and maintenance of software. </booktitle> <address> Geneva, Switzerland, </address> <year> 1991. </year>
Reference-contexts: The importance of starting with goals is vital, because goal-directed data collection skirts the pitfall of gathering large amounts of data that are never used [3]. Conformance with guidelines such as the Software Engineering Institute's Capability Maturity Model (CMM, [13, 31]) and the International Organization for Standardization's ISO 9000-3 <ref> [16] </ref> is the other major motivational factor, the stick driving organizations to measure their work. This factor can arguably be viewed as a threat because of its use in awarding competitive contracts [38]. Empirical data collection and use is described in detail in the CMM and also mentioned in 9000-3. <p> A second guideline that has received much attention is the ISO 9000 series <ref> [14, 15, 16] </ref>.
Reference: [17] <author> Gail Kaiser, N. S. Barghouti, and M. H. Sokol-sky. </author> <title> Preliminary experience with process modeling in the MARVEL software development environment kernel. </title> <booktitle> In Proceedings of the 23 rd Annual Hawaii International Conference on System Sciences, </booktitle> <volume> volume II, </volume> <pages> pages 131140. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> January </month> <year> 1990. </year>
Reference-contexts: Provence demonstrates how a number of special-purpose tools can be integrated with a process-sensitive system to form a CAPE system. Their process-sensitive system is Marvel, a rule-driven system for process representation and en-action <ref> [17] </ref>. Processes are monitored and enacted based on their representation as Marvel rules, and any work activity performed on the computer can be supported. Provence focuses on visualizing process data. These data include process status and progress as well as process and product metric values.
Reference: [18] <author> C. D. Klingler, M. Neviaser, A. Marmor-Squires, C. M. Lott, and H. D. Rombach. </author> <title> A case study in process representation using MVPL. </title> <booktitle> In Proceedings of the Seventh Annual Conference on Computer Assurance (COMPASS 92), </booktitle> <pages> pages 137146, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: MVP-S. The MVP-S system is a prototype CAPE system under development in the work group for software engineering at the University of Kaiser-slautern. The system executes explicit project plans written in a declarative, structured process modeling language named MVP-L <ref> [18] </ref>. A project plan consists of models of the products, processes, and roles that people assume in the course of a project. The system currently consists of an execution machine for the project plans and a developers interface that Appeared in Int. J.
Reference: [19] <author> Balachander Krishnamurthy and Naser S. Barghouti. Provence: </author> <title> a process visualization and enactment environment. </title> <editor> In Ian Som-merville and Manfred Paul, editors, </editor> <booktitle> Proceedings of the Fourth European Software Engineering Conference, pages 451465. Lecture Notes in Computer Science Nr. </booktitle> <volume> 717, </volume> <publisher> Springer Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Provence. Provence is a system for monitoring and visualizing software development processes and uses advanced hooks into the file system of its host computer to do so <ref> [19] </ref>. Provence demonstrates how a number of special-purpose tools can be integrated with a process-sensitive system to form a CAPE system. Their process-sensitive system is Marvel, a rule-driven system for process representation and en-action [17].
Reference: [20] <author> Annie Kuntzmann-Combelles. </author> <title> Quantitative approach to software management: the ami method. </title> <editor> In Ian Sommerville and Manfred Paul, editors, </editor> <booktitle> Proceedings of the Fourth European Software Engineering Conference, </booktitle> <pages> pages 238 250. </pages> <note> Lecture Notes in Computer Science Nr. 717, SpringerVerlag, </note> <year> 1993. </year>
Reference-contexts: A closely related method is ami, a European refinement of the G/Q/M paradigm, which offers a twelve-step approach towards implementing a data collection program in an organization <ref> [20] </ref>. Ami is similarly directed by goals but offers additional help for deriving metrics, implementing a measurement plan, and exploiting the collected data. 3 Measurement in SEEs The systems discussed in this section are motivated by the approaches from the previous section.
Reference: [21] <author> Shinji Kusumoto, Ken-ichi Matsumoto, Tohru Kikuno, and Koji Torii. Ginger: </author> <title> Data collection and analysis system. </title> <type> Technical Report SS 905, </type> <institution> Osaka University, </institution> <address> Toyonaka, Osaka 560, Japan, </address> <year> 1990. </year>
Reference-contexts: The systems are presented in rough chronological order of publication. Ginger. The Ginger system consists of a set of monitoring and feedback tools designed to record and improve programmer productivity during coding activities <ref> [25, 21, 24, 26] </ref>. In Ginger, the focus is on measurement of on-line activities, and data is collected from these activities unobtrusively and automatically. The data thus collected is evaluated and stored in a database, and real-time feedback is provided to the system's users.
Reference: [22] <author> Christopher M. </author> <title> Lott. </title> <booktitle> Process and measurement support in SEEs. ACM SIGSOFT Software Engineering Notes, </booktitle> <address> 18(4):8393, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: J. Software Engineering and Knowledge Engineering, September 1994 3 vides no new tools of its own. A theme touched upon in previous surveys <ref> [36, 22] </ref>, namely support for measurement in SEEs, is explored in more detail in this paper. Here, the trend towards collecting and using empirical data in CASE and CAPE systems is surveyed, and details about several software systems are given.
Reference: [23] <author> Christopher M. Lott and H. Dieter Rom-bach. </author> <title> Measurement-based guidance of software projects using explicit project plans. </title> <journal> Information and Software Technology, </journal> <volume> 35(6/7):407419, </volume> <month> June/July </month> <year> 1993. </year>
Reference-contexts: Further, by integrating the data collection with the process model, measurement-based feedback and guidance can be offered to the people who perform the processes <ref> [7, 33, 23] </ref>. A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm [4, 3].
Reference: [24] <author> Ken-ichi Matsumoto. </author> <title> A programmer performance model and its measurement environment. </title> <type> PhD thesis, </type> <institution> Osaka University, </institution> <address> Toyonaka, Osaka 560, Japan, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: The systems are presented in rough chronological order of publication. Ginger. The Ginger system consists of a set of monitoring and feedback tools designed to record and improve programmer productivity during coding activities <ref> [25, 21, 24, 26] </ref>. In Ginger, the focus is on measurement of on-line activities, and data is collected from these activities unobtrusively and automatically. The data thus collected is evaluated and stored in a database, and real-time feedback is provided to the system's users.
Reference: [25] <author> Ken-ichi Matsumoto, Katsuro Inoue, Hideo Kudo, Yuki Sugiyama, and Koji Torii. </author> <title> Error life span and programmer performance. </title> <booktitle> In Proceedings of the Eleventh Annual International Computer Software and Application Conference (COMPSAC), </booktitle> <pages> pages 259265. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1987. </year>
Reference-contexts: The systems are presented in rough chronological order of publication. Ginger. The Ginger system consists of a set of monitoring and feedback tools designed to record and improve programmer productivity during coding activities <ref> [25, 21, 24, 26] </ref>. In Ginger, the focus is on measurement of on-line activities, and data is collected from these activities unobtrusively and automatically. The data thus collected is evaluated and stored in a database, and real-time feedback is provided to the system's users.
Reference: [26] <author> Ken-ichi Matsumoto, Shinji Kusumoto, Tohru Kikuno, and Koji Torii. </author> <title> A new framework of measuring software development processes. </title> <booktitle> In Proceedings of the First International Software Metrics Symposium, </booktitle> <pages> pages 108118. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: The systems are presented in rough chronological order of publication. Ginger. The Ginger system consists of a set of monitoring and feedback tools designed to record and improve programmer productivity during coding activities <ref> [25, 21, 24, 26] </ref>. In Ginger, the focus is on measurement of on-line activities, and data is collected from these activities unobtrusively and automatically. The data thus collected is evaluated and stored in a database, and real-time feedback is provided to the system's users.
Reference: [27] <author> Frank E. McGarry and R. Pajerski. </author> <title> Towards understanding software - 15 years in the SEL. </title> <booktitle> In Proceedings of the Fifteenth Annual Software Engineering Workshop. </booktitle> <institution> NASA Goddard Space Flight Center, Greenbelt MD 20771, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: They claim to have measured a US$7.70 return for every US$1 spent and to have evolved to CMM level three. McGarry reports on empirical data collection and use in NASA's Goddard Space Flight Center and states that measurement is not cost prohibitive <ref> [27] </ref>. He further mentions that although collecting data may cost extremely little, processing and analyzing the collected data can add 10 to 15 per cent to development costs on a single project.
Reference: [28] <author> Markku Oivo. </author> <title> Knowledge-based Support for Embedded Computer Software Analysis and Design. </title> <note> VTT Publication 68, Espoo, Septem-ber 1990. ISBN 951-38-3763-7. Appeared in Int. J. </note> <institution> Software Engineering and Knowledge Engineering, </institution> <month> September </month> <year> 1994 </year> <month> 21 </month>
Reference-contexts: ES-TAME. The ES-TAME system is a prototype of an expert system to support the design process for real-time software <ref> [28, 29] </ref>. ES-TAME supports the design process in that the work processes to be performed can be represented in the system, the quality models for the products can also be represented, and these two sets of models can be integrated such Appeared in Int. J.
Reference: [29] <author> Markku Oivo and Victor R. Basili. </author> <title> Representing software engineering models: The TAME goal oriented approach. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(10):886898, </volume> <month> Octo-ber </month> <year> 1992. </year>
Reference-contexts: ES-TAME. The ES-TAME system is a prototype of an expert system to support the design process for real-time software <ref> [28, 29] </ref>. ES-TAME supports the design process in that the work processes to be performed can be represented in the system, the quality models for the products can also be represented, and these two sets of models can be integrated such Appeared in Int. J.
Reference: [30] <author> Mark C. Paulk. </author> <title> Comparing ISO 9001 and the Capability Maturity Model for software. </title> <journal> Software Quality Journal, </journal> <volume> 2(4):245256, </volume> <month> Decem-ber </month> <year> 1993. </year>
Reference-contexts: ISO conformance is rapidly becoming the prerequisite for conducting business in the European Union. 1 Part 3 of ISO 9000 (ISO 9000-3) applies the policies set forth in ISO 9001 for the software domain and is most directly comparable in terms of its goals to the CMM (see also <ref> [30] </ref> for a detailed comparison). In the 9000-3 guideline, measurement is split into product and process measurement for the purposes of control and improvement. Empirical data collection and use is not as thoroughly integrated into 9000-3 as in the CMM.
Reference: [31] <author> Mark C. Paulk, Bill Curtis, Mary Beth Chris-sis, and Charles V. Weber. </author> <title> Capability maturity model, version 1.1. </title> <journal> IEEE Software, </journal> <volume> 10(4):18 27, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: The importance of starting with goals is vital, because goal-directed data collection skirts the pitfall of gathering large amounts of data that are never used [3]. Conformance with guidelines such as the Software Engineering Institute's Capability Maturity Model (CMM, <ref> [13, 31] </ref>) and the International Organization for Standardization's ISO 9000-3 [16] is the other major motivational factor, the stick driving organizations to measure their work. This factor can arguably be viewed as a threat because of its use in awarding competitive contracts [38]. <p> Section 3 gives examples of CASE and CAPE systems, including both research prototypes and commercial products. Section 4 summarizes aspects of the systems surveyed here and offers some conclusions. 2 Background The appearance of the Software Engineering Institute's Capability Maturity Model (CMM) <ref> [31] </ref> and its subsequent widespread use in awarding contracts [38] is a huge factor motivating software process improvement as well as measurement efforts.
Reference: [32] <author> Adam A. Porter and Richard W. Selby. </author> <title> Empirically guided software development using metric-based classification trees. </title> <journal> IEEE Software, </journal> <volume> 7(2):4654, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: This abstract interface attempts to isolate the primitives needed for using empirical data in a CAPE system. As originally developed, Amadeus made extensive use of classification trees as its basis for data analysis and feedback capabilities <ref> [32] </ref>. The objective of presenting an interface which consists solely of functions for data collection and use means that the Amadeus system has no process modeling component, nor does it serve as a means to evolve any work product.
Reference: [33] <author> C. V. Ramamoorthy, Wei-Tek Tsai, Tsuneo Ya-maura, and Anupam Bhide. </author> <title> Metrics guided methodology. </title> <booktitle> In Proceedings of the Ninth Annual International Computer Software and Application Conference (COMPSAC), </booktitle> <pages> pages 111 120, </pages> <year> 1985. </year>
Reference-contexts: Further, by integrating the data collection with the process model, measurement-based feedback and guidance can be offered to the people who perform the processes <ref> [7, 33, 23] </ref>. A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm [4, 3].
Reference: [34] <author> Raimo Rask. </author> <title> Automating estimation of software size during the requirements specification phase. </title> <type> PhD thesis, </type> <institution> University of Joensuu, </institution> <address> P. O. Box 111, SF-80101 Joensuu, Finland, </address> <month> Novem-ber </month> <year> 1992. </year>
Reference-contexts: JoYCASE. The JoYCASE system consists of editors for structured analysis and entity relationship diagrams, as well as tools that calculate values from those diagrams for Albrecht's function point metric, DeMarco's function bang metric and Symon's Mark II function point metric <ref> [34, 35] </ref>. The assumption in JoYCASE is that these metrics correlate well with finished system size and therefore can be used to predict the resources needed to develop that system.
Reference: [35] <author> Raimo Rask, Petteri Laamanen, and Kalle Lyytinen. </author> <title> Simulation and comparison of Al-brecht's function point and DeMarco's function bang metrics in a CASE environment. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(7):661671, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: JoYCASE. The JoYCASE system consists of editors for structured analysis and entity relationship diagrams, as well as tools that calculate values from those diagrams for Albrecht's function point metric, DeMarco's function bang metric and Symon's Mark II function point metric <ref> [34, 35] </ref>. The assumption in JoYCASE is that these metrics correlate well with finished system size and therefore can be used to predict the resources needed to develop that system.
Reference: [36] <author> H. Dieter Rombach. </author> <title> The role of measurement in ISEEs. </title> <editor> In Carlo Ghezzi and John McDer-mid, editors, </editor> <booktitle> Proceedings of the Second Euro-pean Software Engineering Conference, </booktitle> <pages> pages 6585. </pages> <note> Lecture Notes in Computer Science Nr. 387, SpringerVerlag, </note> <month> September </month> <year> 1989. </year>
Reference-contexts: J. Software Engineering and Knowledge Engineering, September 1994 3 vides no new tools of its own. A theme touched upon in previous surveys <ref> [36, 22] </ref>, namely support for measurement in SEEs, is explored in more detail in this paper. Here, the trend towards collecting and using empirical data in CASE and CAPE systems is surveyed, and details about several software systems are given. <p> The columns correspond to the metrics explained in Section 3. 4 Summary and conclusions Many of the CASE and CAPE systems surveyed here struggle with the problems of integrating software construction, process definition, and measurement capabilities into a single system. A classification scheme first presented in <ref> [36] </ref> is expanded and used to classify the integration of these three elements in the surveyed systems. Figure 4 graphs construction vs. measurement components in SEEs. Figure 5 shows process definition vs. measurement capabilities. Finally, Figure 6 charts construction vs. process definition facilities.
Reference: [37] <author> H. Dieter Rombach. </author> <title> Design measurement: some lessons learned. </title> <journal> IEEE Software, </journal> <volume> 7(2):17 25, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Beyond module call-trees and many types of cross references, the system collects data for the following metrics: fan-out, tramp data couples, and tramp control couples. Some of the advantages of design measurement that were discussed in <ref> [12, 37] </ref> are repeated here briefly. Based on the assumption that software structure and complexity affect the maintainability of the software, appropriate choices made in the design phase can have a large influence on later phases.
Reference: [38] <author> David Rugg. </author> <title> Using a capability evaluation to select a contractor. </title> <journal> IEEE Software, </journal> <volume> 10(4):36 45, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: This factor can arguably be viewed as a threat because of its use in awarding competitive contracts <ref> [38] </ref>. Empirical data collection and use is described in detail in the CMM and also mentioned in 9000-3. However, only the CMM appropriately identifies the vital connection between work processes and data collection. <p> Section 4 summarizes aspects of the systems surveyed here and offers some conclusions. 2 Background The appearance of the Software Engineering Institute's Capability Maturity Model (CMM) [31] and its subsequent widespread use in awarding contracts <ref> [38] </ref> is a huge factor motivating software process improvement as well as measurement efforts. Put briefly, the CMM establishes an ordinal scale with five process maturity levels, assuming that organizations which have attained higher levels will perform more predictably and reliably than organizations at lower levels.
Reference: [39] <author> Richard W. Selby, Greg James, Kent Mad-sen, Joan Mahoney, Adam A. Porter, and Dou-glas C. Schmidt. </author> <title> Classification tree analysis using the Amadeus measurement and empirical analysis system. </title> <booktitle> In Proceedings of the Fourteenth Annual Software Engineering Workshop. </booktitle> <institution> NASA Goddard Space Flight Center, Greenbelt MD 20771, </institution> <year> 1989. </year>
Reference-contexts: Data definitions are fixed in the system (3.1), only the diagrams can be measured (3.2), and the data is only collected; use and interpretation of all data is left to the user (3.3) Amadeus. The Amadeus system 3 is best characterized as a subcomponent of a CAPE system <ref> [39, 40] </ref>. The objectives of the Amadeus system include integrating measurement with process enactment by presenting an abstract interface for data collection, data analysis, and feedback. This abstract interface attempts to isolate the primitives needed for using empirical data in a CAPE system.
Reference: [40] <author> Richard W. Selby, Adam A. Porter, Doug C. Schmidt, and Jim Berney. </author> <title> Metric-driven analysis and feedback systems for enabling empirically guided software development. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Software Engineering, </booktitle> <pages> pages 288 298. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: Data definitions are fixed in the system (3.1), only the diagrams can be measured (3.2), and the data is only collected; use and interpretation of all data is left to the user (3.3) Amadeus. The Amadeus system 3 is best characterized as a subcomponent of a CAPE system <ref> [39, 40] </ref>. The objectives of the Amadeus system include integrating measurement with process enactment by presenting an abstract interface for data collection, data analysis, and feedback. This abstract interface attempts to isolate the primitives needed for using empirical data in a CAPE system.
Reference: [41] <author> Dave Weiss. </author> <title> GQM plus heuristics better than brainstorming. </title> <journal> IEEE Software, </journal> <volume> 11(1):89, </volume> <month> Jan-uary </month> <year> 1994. </year> <title> Letter to the editor. </title>
Reference-contexts: A goal-directed approach towards deciding what to measure and how to interpret the results of mea surement is embodied in the Goal/Question/Metric (G/Q/M) paradigm [4, 3]. Building a data collection plan by using a goal-directed method such as G/Q/M is not a guarantee for success (see also <ref> [6, 2, 41] </ref>) but will encourage goal definition and assist in interpreting the collected data in the context of those goals. In the G/Q/M method, organizational goals are defined first.
References-found: 41

