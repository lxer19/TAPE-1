URL: http://cwis.usc.edu/dept/ATRIUM/Papers/Software_Productivity.ps
Refering-URL: http://cwis.usc.edu/dept/ATRIUM/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Scacchi@gilligan.usc.edu  
Title: UNDERSTANDING SOFTWARE PRODUCTIVITY  
Author: WALT SCACCHI 
Date: July 1994  
Address: Los Angeles, CA 90089-1421, USA  
Affiliation: Information and Operations Management Dept. University of Southern California  
Abstract: What affects software productivity and how do we improve it? This report examines the current state of the art in software productivity measurement. In turn, it describes a framework for understanding software productivity, some fundamentals of measurement, surveys empirical studies of software productivity, and identifies challenges involved in measuring software productivity. A radical alternative to current approaches is suggested: to construct, evaluate, deploy, and evolve a knowledge-based "software productivity modeling and simulation system" using tools and techniques from the domain of software process engineering. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Abdel-Hamid, T. and S. Madnick, </author> <title> Impact of Schedule Estimation on Software Project Behavior. </title> <booktitle> IEEE Software 3(4), </booktitle> <year> (1986), </year> <pages> 70-75. </pages>
Reference: 2. <author> Albrecht, A., </author> <title> "Measuring Application Development Productivity", </title> <booktitle> Proc. Joint SHARE/GUIDE/IBM Application Development Symposium (October, </booktitle> <year> 1979), </year> <pages> 83-92. </pages>
Reference: 3. <author> Albrecht, A. and J. Gaffney, </author> <title> "Software Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation", </title> <journal> IEEE Trans. Soft. Engr. </journal> <volume> SE-9(6), </volume> <year> (1983), </year> <pages> 639-648. </pages>
Reference: 4. <author> Bailey, J. and V. Basili, </author> <title> "A Meta-Model for Software Development Resource Expenditures", </title> <booktitle> Proc. 5th. Intern. Conf. Soft. Engr., IEEE Computer Society, </booktitle> <year> (1981), </year> <pages> 107-116. </pages>
Reference-contexts: However, Lawrence also found that programming experience beyond the first year on the job, structured programming, and walkthroughs contribute little to productivity improvement. 3.6. NASA/SEL Bailey and Basili <ref> [4] </ref> found higher productivity over the entire system life cycle to be associated with the use of a disciplined programming methodology, particularly in the early stages of system development.
Reference: 5. <author> Behrens, </author> <title> C.A., "Measuring the Productivity of Computer Systems Development Activities with Function Points", </title> <journal> IEEE Trans. Soft. Engr. </journal> <volume> SE-9(6), </volume> <year> (1983), </year> <pages> 648-652. </pages>
Reference-contexts: Equitable Life Organizations Behrens <ref> [5] </ref> also utilizes Albrecht's function point measures to compare software productivity in 25 application system projects developed in various life insurance companies from 1980 to 1981. His results are consistent with Albrecht's in supporting the contention that project size, development (computing) environment, and programming language impact software productivity.
Reference: 6. <author> Bendifallah, S. and W. Scacchi, </author> <title> "Understanding Software Maintenance Work", </title> <journal> IEEE Trans. Soft. Engr. </journal> <volume> SE-13(3), </volume> <year> (1987), </year> <pages> 311-323. </pages>
Reference: 7. <author> Bendifallah, S. and W. Scacchi, </author> <title> "Work Structures and Shifts: An Empirical Analysis of Software Specification Teamwork", </title> <booktitle> Proc. 11th. Intern. Conf. Soft. Engr., IEEE Computer Society, </booktitle> <year> (1989), </year> <pages> 345-357. </pages>
Reference-contexts: This conclusion is especially appropriate when comparing such productivity measures across different studies. 10 In a comparative field study of software teams developing formal specifications, Bendifallah and Scacchi <ref> [7] </ref> found that variation in specification teamwork productivity and quality could best be explained in terms of recurring teamwork structures. They found six teamwork structures (ie, patterns of interaction) recurring among all the teams in their study. <p> However, any software process engineering environment or knowledge engineering system capable of modeling, simulating, and enacting software products, production processes, production settings and their interrelationships could be employed. 5.4.1. Knowledge acquisition: We can acquire knowledge about software projects by conducting in-depth, observational field studies <ref> [e.g, 7] </ref>. Ideally, such studies should be organized to facilitate comparative analysis. The data to be collected should account for the concerns described in Section 4. This in turn requires the articulation of a scheme for data collection, coding, and analysis.
Reference: 8. <author> Bhansali, P.V., B.K. Pflug, J.A. Taylor, and J.D. Wooley, </author> <title> "Ada Technology: Current Status and Cost Impact", </title> <journal> Proceedings IEEE, </journal> <volume> 79(1), </volume> <year> (1991), </year> <pages> 22-29. </pages>
Reference-contexts: Last, Bhansali and associates <ref> [8] </ref> report that programmers are two-to-four times more productive when using Ada versus Fortran or Pascal-like languages according to their study data. However, as Ada contains language constructs not present in these other languages, it is not clear what was significant in explaining the difference in apparent productivity.
Reference: 9. <author> Boehm, B., </author> <booktitle> Software Engineering Economics Prentice-Hall, </booktitle> <address> Englewood Cliffs, NJ (1981) </address>
Reference-contexts: The program estimates the cost of a software project as a function of program size expressed in delivered source instructions and a number of other cost drivers. Experience with SCEP in turn gave rise to the development of the COCOMO software cost estimation model presented in <ref> [9] </ref>. Boehm recognized that software cost drivers are effectively the inverse of productivity (or "benefit") drivers. He found, for example, that personnel/team capability and product complexity had the greatest affect in driving software costs and productivity. <p> The consequence is that studies of productivity measurement claiming statistically substantiated relationships based on inappropriate analytical techniques are somewhat dubious, and the strength of the cited relationship may not be as strong as claimed. Boehm <ref> [9] </ref> reported that productivity on a software development project is most keenly affected by who develops the system and how well they are organized and managed as a team. Following this, Scacchi [50] reviewed a number of published reports on the problems of managing large software engineering projects. <p> Jones mentions that he relies upon his data for use in a quantitative software productivity, quality, and reliability estimation model. However, he does not discuss how his model works, or what equations it solves. This is in marked contrast to Boehm's <ref> [9] </ref> software cost and productivity estimation efforts where he both identifies the software project variables of interest, and also presents the analytical details of the COCOMO software cost estimation model that uses them. Thus, we must regard Jones's reported analysis with some suspicion. <p> Since each production process activity can produce valuable products, why is it conventional to measure the outcome of one of the smallest effort activities in this process of developing large software systems, coding. A number of studies such as those reported by Boehm <ref> [9] </ref> indicate that coding usually consumes 10-20% of the total LSS development effort. On the other hand, software testing and integration consume the largest share, usually representing 50% of the development effort. Early development activities consume 10-15% each. Clearly, delivered software source code is a valuable product.
Reference: 10. <author> Boehm, B.W., </author> <title> "Improving Software Productivity", </title> <journal> Computer, </journal> <volume> 20(8), </volume> <year> (1987), </year> <pages> 43-58. </pages>
Reference-contexts: Hurley (ed.), Vol. 4, World Scientific Press, (1995). 1 1. Overview What affects software productivity and how do we improve it? This is a concern near and dear to those who are responsible for researching and developing large software systems. For example, Boehm <ref> [10] </ref> reports that by 1995, a 20% improvement in software productivity will be worth $45 billion in the U.S and $90 billion worldwide. As such, this report examines the current state of the art in understanding software productivity. <p> This questionnaire includes a variety of suggestive questions that people collecting productivity data may find of interest. In setting his sights on identifying software productivity improvements opportunities, Boehm <ref> [10] </ref> also identifies some of the dilemmas encountered in defining what things need to be measured to understand software productivity. <p> Similarly, they do not indicate whether any of the source code involved was measured before or after pre-processing, which can affect source line counts, as already observed <ref> [10] </ref>. 3.13. Information Technology and Productivity Brynjolfsson [14] provides a comprehensive review of empirical studies that examine the relationship of information technology (IT) and productivity. <p> But whatever the choice, the analysis will be constrained by the terms built into the data collection instruments. 4.5. How to improve software productivity? In addressing this question, Boehm <ref> [10] </ref> identifies a number of strategies for improving software productivity: get the best from people, make development steps more efficient, eliminate development steps, eliminate rework, build simpler products, and reuse components.
Reference: 11. <author> Boehm, B., M.. Penedo, E.D. Stuckle, R.D. Williams, </author> <title> and A.B. Pyster, "A Software Development Environment for Improving Productivity", </title> <booktitle> Computer 17(6), </booktitle> <year> (1984), </year> <pages> 30-44. </pages>
Reference-contexts: Scacchi concludes that strategies for managing software development work have been overlooked as a major contributor to software productivity improvement, and thus require further study and experimentation. 9 Boehm and associates at TRW <ref> [11] </ref> described the organization of a software project whose objective was to develop an environment to enhance software productivity by a factor of 2 in 5 years, and 4 in 10 years.
Reference: 12. <author> Boehm, B. and R.W. Wolverton, </author> <title> "Software Cost Modelling: Some Lessons Learned", </title> <editor> J. </editor> <booktitle> Systems and Software 1 (1980), </booktitle> <pages> 195-201. </pages> <note> 13. </note> <author> van den Bosch, F., J. Ellis, P. Freeman, L. Johnson, C. McClure, D. Robinson, W. Scacchi, B. Scheft, A. van Staa, and L. Tripp, </author> <title> "Evaluating the Implementation of Software Development Life Cycle Methodology", </title> <journal> ACM Software Engineering Notes, </journal> <volume> 7(1), </volume> <year> (1982), </year> <pages> 45-61. </pages>
Reference: 14. <author> Brynjolfsson, E., </author> <title> "The Productivity Paradox of Information Technology," </title> <journal> Communications ACM, </journal> <volume> 36(12), </volume> <year> (1993), </year> <pages> 67-77. </pages>
Reference-contexts: Similarly, they do not indicate whether any of the source code involved was measured before or after pre-processing, which can affect source line counts, as already observed [10]. 3.13. Information Technology and Productivity Brynjolfsson <ref> [14] </ref> provides a comprehensive review of empirical studies that examine the relationship of information technology (IT) and productivity. In this study, IT is broadly defined to include particular kinds of software systems, such as transaction processing and strategic information systems, to general-purpose computing resources and services. <p> In a closer comparative examination of these studies, Brynjolfsson concludes "The closer one examines the data behind the studies of IT performance, the more it looks like mismeasurement is at the core of the productivity paradox." <ref> [14, p. 74] </ref> Thus, once again it appears that measuring and understanding the productivity impact of new software systems or IT remains problematic, and that one significant underlying cause for this is found in the methods for measuring productivity data. 3.14.
Reference: 15. <author> Cerveny, R.P., and D.A. Joseph, </author> <title> "A Study of the Effects of Three Commonly Used Software Engineering Strategies on Software Enhancement Productivity", </title> <journal> Information & Management, </journal> <volume> 14, </volume> <year> (1988), </year> <pages> 243-251. </pages>
Reference-contexts: However, due to the small sample size (three firms), small team size vis-a-vis individual programmer variations [19], and other common analytical shortcomings in defining input and output measures, the generality of the assertions is limited. 3.10. Commerical U.S. Banks Cerveny and Joseph <ref> [15] </ref> report on their study software enhancement productivity in 200 U.S. commercial banks. Each bank was required by a change in national tax laws to implement new interest reporting requirements. Thus, all banks had to satisfy the same set of tax law requirements.
Reference: 16. <author> Chrysler, E., </author> <title> "Some Basic Determinants of Computer Programming Productivity", </title> <journal> Communications ACM 21(6), </journal> <year> (1978), </year> <pages> 472-483. </pages>
Reference-contexts: Thus, Jones' results undercut the utility of the findings reported by Walston and Felix [55] which are subject to these paradoxes. As an alternative, Jones recommends separating productivity measures into work units and cost units, while program quality be measured by defect removal efficiency and defect prevention. Chrysler <ref> [16] </ref> sought to identify some basic determinants of programming productivity by examining programming activities in a single organization.
Reference: 17. <author> Conte, S., D. Dunsmore, and V. Shen, </author> <title> Software Engineering: Models and Measures Benjamin-Cummings, </title> <address> Palo Alto, CA (1986). </address>
Reference-contexts: Thadhani reports that programmers were twice as productive when their system's average response time was 0.25 seconds (or less) than when it averaged 2 seconds or more. However, in a review of this and other similar studies, Conte and colleagues <ref> [17] </ref> report that average response time is not as critical as a narrow variance in expected response time. That is, programmers should be more productive when their system's response time is fast, consistent, and relatively predictable from the computing task at hand.
Reference: 18. <author> Curtis, B., </author> <booktitle> "Measurement and Experimentation in Software Engineering", Proc. IEEE 68(9), </booktitle> <year> (1980), </year> <pages> 1103-1119. </pages>
Reference-contexts: In this paper, the phenomenon under study is software production: from system inception through delivery, operation and support. Accordingly, we want to understand how software is produced, how to measure its production, and ultimately, how to positively influence or control the rate of its production. Curtis <ref> [18] </ref> provides an appropriate background on some fundamental principles involved in measuring software production characteristics, including measure validity and reliability, as well as instrumentation and modeling issues. A desire to measure software production implies an encounter with the process of systematic or scientific inquiry. <p> How to measure software productivity? Measuring software productivity presupposes an ability to construct a measurement program comparable to those employed in experimental designs for behavioral studies <ref> [18] </ref>. This is necessary to insure that the measures employed are reliable, valid, accurate, and repeatable. This in turn implies that choices must be made with respect to the following concerns: 4.4.1.
Reference: 19. <author> Curtis, B., </author> <title> "Substantiating Programmer Variability", </title> <journal> Proc. IEEE, </journal> <volume> 69(7), </volume> <year> (1981). </year>
Reference-contexts: However, due to the small sample size (three firms), small team size vis-a-vis individual programmer variations <ref> [19] </ref>, and other common analytical shortcomings in defining input and output measures, the generality of the assertions is limited. 3.10. Commerical U.S. Banks Cerveny and Joseph [15] report on their study software enhancement productivity in 200 U.S. commercial banks. <p> Further, most studies fail to describe how they account for variation in productive ability among individual programmers, which has been systemtically shown to vary by more than an order of magnitude <ref> [19] </ref>. That is, for very large software systems (500K+ code statements), it seems likely that "average programmer" productivity dominates individual variations, while in smaller systems (less than 50K code statements) or those developed by only a few programmers, then individual differences may dominate.
Reference: 20. <author> Cusumano, M., </author> <title> Japan's Software Factories, </title> <publisher> Oxford Univ. Press, </publisher> <address> New York, </address> <year> (1991). </year>
Reference-contexts: U.S. vs. Japan Study In a provocative yet systematic comparison of industrial software productivity in the U.S. and Japan, Cusumano and Kemerer [21] argue that Japanese software development capabilities are comparable to those found in the U.S. <ref> [20] </ref>. Their analyses examined data from 24 U.S. and 16 Japanese development efforts collected from software project managers who completed questionnaires. <p> Clearly, much more needs to be explained in order to begin to adequately answer this question. 3 An awareness of this also impinges on the choice for research design and sampling strategy. 4 Cusumano <ref> [20] </ref> independently reports on how these same strategies are regularly practiced in various Japanese software factories to achieve software productivity improvements. 20 4.6. Summary Large-scale studies of software productivity (i.e., across multiple software projects in many different settings) necessitate collecting of a plethora of data.
Reference: 21. <author> Cusumano, M. </author> <title> and C.F. Kemerer, "A Quantitative Analysis of U.S. and Japanese Practice and Performance in Software Development", </title> <journal> Management Science, </journal> <volume> 36(11), </volume> <year> (1990), </year> <month> 25 </month>
Reference-contexts: U.S. vs. Japan Study In a provocative yet systematic comparison of industrial software productivity in the U.S. and Japan, Cusumano and Kemerer <ref> [21] </ref> argue that Japanese software development capabilities are comparable to those found in the U.S. [20]. Their analyses examined data from 24 U.S. and 16 Japanese development efforts collected from software project managers who completed questionnaires.
Reference: 22. <author> Garg, P.K., P. Mi, T. Pham, W. Scacchi, and G. Thunquest, </author> <title> "The SMART Approach to Software Process Engineering," </title> <booktitle> Proc. 16th. Intern. Conf. Software Engineering, </booktitle> <address> Sorrento, Italy, </address> <publisher> IEEE Computer Society, </publisher> <year> (1994), </year> <pages> 341-350. </pages>
Reference: 23. <author> Garg. P.K. and W. Scacchi, </author> <title> "On Designing Intelligent Software Hypertext Systems", </title> <journal> IEEE Expert, </journal> <volume> 4, </volume> <year> (1989), </year> <pages> 52-63. </pages>
Reference: 24. <author> Hanson, S.J. and R.R. Kosinski, </author> <title> "Programmer Perceptions of Productivity and Programming Tools", </title> <journal> Communications ACM, </journal> <volume> 28(2), </volume> <year> (1985), </year> <pages> 180-189. </pages>
Reference: 25. <author> Irving, R., C. Higgins, and F. Safayeni, </author> <title> Computerized Performance Monitoring Systems: Use and Abuse, </title> <journal> Communications ACM, </journal> <volume> 29(8), </volume> <year> (1986), </year> <pages> 794-801. </pages>
Reference-contexts: Outside observers can often collect such information, but at a higher cost than self report. Similarly, automated production performance monitors may be of use, but this is still an emerging area of technology requiring more insight for what should be measured and how. For example, Irving and associates <ref> [25] </ref> report that use of automated performance monitoring systems is associated with perceived increase in productivity, more accurate assessment of worker performance, and higher levels of organizational control.
Reference: 26. <author> Jeffrey, </author> <title> D.R., "A Software Development Productivity Model for MIS Environments", </title> <journal> J. Systems and Soft., </journal> <volume> 7, </volume> <year> (1987), </year> <pages> 115-125. </pages>
Reference-contexts: In their view, "To be successful, a productivity improvement program must address the entire spectrum of productivity issues. Key features of such a program are management commitment and an integrated approach" (pp. 151-152). 3.9. Australia-80 Study Jeffrey <ref> [26] </ref> describes a comparative study of software productivity among small teams in 38 development projects in three Austrialian firms. Each firm used one programming language in its projects, but different from that used by the other two firms.
Reference: 27. <author> Jones, </author> <title> T.C., "Measuring Programming Quality and Productivity", </title> <journal> IBM System J. </journal> <volume> 17(1), </volume> <year> (1978), </year> <pages> 39-63. </pages>
Reference-contexts: Cusamano and Kemerer employed Fortran-equivalent noncomment source lines of code as the output measure <ref> [27] </ref>, and person-years of effort as the input measure, as well as both parametric and non-parametric statistical test where appropriate. <p> While they report that software productivity appears on the surface to be greater in Japan than in the U.S., the differences that were observed were not found to be statistically significant. 3.12. Other studies of Productivity and Cost Evaluation T.C. Jones <ref> [27] </ref> at IBM was among the first to recognize that measures of programming productivity and quality in terms of lines of code, and cost of detecting and removing code defects are inherently paradoxical. <p> Capers Jones [28] provides the next study in his book on programming productivity. Jones does an effective job at describing some of the problems and paradoxes that plague most software productivity and quality measures based upon his previous studies <ref> [27] </ref>. For example, he observes that a line of source code is not an economic good, but it is frequently used in software productivity measures as if it were--lines of code (or source statements) produced per unit of time are not a sound indicator of economic productivity.
Reference: 28. <author> Jones, C., </author> <title> Programming Productivity, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> (1986). </year>
Reference-contexts: King and Schrems also note that conducting quality cost-benefits has direct costs as well. For example, Capers Jones <ref> [28] </ref> reports that in its software development laboratories, IBM spends the equivalent of 5% of all development costs on software measurement and analysis activities. <p> Nonetheless, they report that this productivity improvement was realized at an additional capital investment of $10,000 per programmer. Current investigations in this project include the development and incorporation of a number of knowledge-based software development and project management aids for additional LSS productivity improvements. Capers Jones <ref> [28] </ref> provides the next study in his book on programming productivity. Jones does an effective job at describing some of the problems and paradoxes that plague most software productivity and quality measures based upon his previous studies [27].
Reference: 29. <author> Keen, P.G.W., </author> <title> "Information Systems and Organizational Change", </title> <journal> Communications ACM, </journal> <volume> 24(1), </volume> <year> (1981), </year> <pages> 24-33. </pages>
Reference: 30. <author> Kemerer, </author> <title> C.F., "An Empirical Validation of Software Cost Estimation Models", </title> <journal> Communications ACM, </journal> <volume> 30(5), </volume> <year> (1987), </year> <pages> 416-429. </pages>
Reference-contexts: Standard, program-oriented productivity or cost estimation measures will provide less accurate information than those measures that account for characteristics of the organization and its computing environment. Mohanty [44] and Kemerer <ref> [30] </ref> also found similar results in their independent examinations of different software cost estimation models. 5 Thadhani [54] and Lambert [37] examined the effects of good computer services on programmer and project productivity during application program development. <p> This means that different cost estimation models, and by logical extension, productivity models, lead to differrent measured values which can show great variation when applied to software development projects. Also, the results of Kemerer's <ref> [30] </ref> study of software cost estimation models corroborates the same kind of findings that Mohanty`s study shows. <p> However, Kemerer does go so far as to show how function points may be refined to improve their reliability as measures of program size and complexity [31,32], as well as tuned to produce the better cost estimates <ref> [30] </ref>. But again, function points depend solely upon program source code characteristics, and do not address production process or production setting variations, nor their contributing effects. Romeu and Gloss-Soler [48] argue that most software productivity measurement studies employ inappropriate statistical analysis techniques.
Reference: 31. <author> Kemerer, </author> <title> C.F., "Improving the Reliability of Function Point Measurement -- An Empirical Study," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> 18(11), </volume> <year> (1992), </year> <pages> 1011-1024. </pages>
Reference: 32. <author> Kemerer, </author> <title> C.F., "Reliability of Function Point Measurement -- A Field Experiment", </title> <journal> Communications ACM, </journal> <volume> 36(2), </volume> <year> (1993), </year> <pages> 85-97. </pages>
Reference: 33. <author> Kidder, T. </author> <title> The Soul of a New Machine, </title> <publisher> Atlantic Monthly Press, </publisher> <year> (1981). </year>
Reference: 34. <author> King, J.L. and E. Schrems, </author> <title> "Cost-Benefit Analysis in Information Systems Development and Operation", </title> <journal> ACM Computing Surveys 10(1), </journal> <year> (1978), </year> <pages> 19-34. </pages>
Reference-contexts: King and Schrems <ref> [34] </ref> provide the classic survey of problems encountered in applying cost-benefit analysis to system development and operation. To no surprise, the "benefits" they identify represent commonly cited productivity improvements.
Reference: 35. <author> Kling, R. and W. Scacchi, </author> <title> "The Web of Computing: Computing Technology as Social Organization", </title> <booktitle> Advances in Computers 21 (1982), </booktitle> <pages> 3-87. </pages>
Reference-contexts: But there is no data available that systematically demonstrates if the expected gains are in fact realized, or to what level. Kraut and colleagues <ref> [35] </ref> report on their study of organizational changes in worker productivity and quality of work-life resulting from the introduction of a large automated system. They surveyed the opinions of hundreds of system users in 10 different user sites. <p> In any event, Kraut and colleagues observe that one needs to understand with web of relationships between the organization of work between and among tasks, developers, and users, as well as the computing resources and software system designs in order to understand what affects productivity and quality of work-life <ref> [35] </ref>. Last, Bhansali and associates [8] report that programmers are two-to-four times more productive when using Ada versus Fortran or Pascal-like languages according to their study data. <p> Most analysis of software productivity are framed in terms expressing economic "costs", "benefits", and "organizational impacts." However, other rationales are commonly employed which broaden the vocabulary and scope of an analysis. For example, Kling and Scacchi <ref> [35] </ref> observe at least five different kinds of rationale are common: respectively, those whose terms emphasize (a) features of the underlying technology, (b) attributes of the organization setting, (c) improving relations between software people and management, (d) determining who can affect control over, or benefit from, a productivity measurement effort (addressing <p> the apparent rush to measure software productivity, we may have lost sight of a fundamental concern: why are software developers as productive as they are in the presence of many technical and organizational constraints? The potential for productivity improvement is not an inherent property of any new software development technology <ref> [35] </ref>. Instead, the people who develop software must effectively mobilize and transform whatever resources they have available to construct software products. Software developers must realize and articulate the potential for productivity improvement. New software development technologies can facilitate this articulation.
Reference: 36. <author> Kraut, R., S. Dumais, and S. Koch, "Computerization, </author> <title> Productivity, and Quality of Work-Life", </title> <journal> Communications ACM, </journal> <volume> 32(2), </volume> <year> (1989), </year> <pages> 220-238. </pages>
Reference: 37. <author> Lambert, G.N., </author> <title> "A Comparative Study of System Response Time on Programmer Development Productivity", </title> <journal> IBM Systems J. </journal> <volume> 23(1), </volume> <year> (1984), </year> <pages> 36-43. </pages>
Reference-contexts: Mohanty [44] and Kemerer [30] also found similar results in their independent examinations of different software cost estimation models. 5 Thadhani [54] and Lambert <ref> [37] </ref> examined the effects of good computer services on programmer and project productivity during application program development. In particular, their studies examine the effects of short response times, programmer's skills, and program complexity on programmer productivity.
Reference: 38. <author> Lakhanpal, B., </author> <title> "Understanding the Factors Influencing the Performance of Software Development Groups: An Exploratory Grou-Level Analysis," </title> <journal> Information and Software Technology, </journal> <volume> 35(8), </volume> <year> (1993), </year> <pages> 468-471. </pages>
Reference-contexts: So an appropriate strategy is to focus in organizing and managing the project to cultivate staff commitment to each other and to the project's objectives [cf. 33]. When developers are strongly committed to the project and to a team effort <ref> [38] </ref>, they are more than willing to undertake the unplanned for system maintenance and articulation work tasks needed to sustain productive work conditions [6,7]. <p> Further, they found that teams shifted from one structure to another for either planned or unplanned reasons. But more productive teams, as well as higher product quality teams, could be clearly identified in the observed patterns of teamwork structures. Lakhanpal's <ref> [38] </ref> study corroborates this finding showing workgroup cohesion and collective capability is a more significant factor in team productivity than individual experience. Thus, the structures, cohesiveness, and shifting patterns of teamwork are also salient software productivity variables.
Reference: 39. <author> Lawrence, M.J., </author> <title> "Programming Methodology, Organizational Environment, and Programming Productivity", </title> <editor> J. </editor> <booktitle> Systems and Software 2 (1981), </booktitle> <pages> 257-269. </pages>
Reference-contexts: Conversely, low staff capability and high product complexity similarly imply low productivity/high cost software production. Through his experience with these cost estimation models, Boehm was able to develop quantitative support for the relative contribution of different software development characteristics that affect software cost and productivity. 3.5. Australia-70 Study Lawrence <ref> [39] </ref> conducted a study of 278 commercial applications developed in 23 medium-to-large organizations in Australia. The organizations and applications studies included those in government agencies, manufacturing and mining concerns, and banking and insurance firms.
Reference: 40. <author> Mi, P. and W. Scacchi, </author> <title> "A Knowledge-Based Environment for Modeling and Simulating Software Engineering Processes", </title> <journal> IEEE Trans. Knowledge and Data Engr., </journal> <volume> 2(3), </volume> <year> (1990), </year> <pages> 283-294. </pages> <note> Reprinted in Nikkei Artificial Intelligence, 20(1) (1991), 176-191 (in Japanese). </note>
Reference-contexts: Simulate and measure the effects of productivity enhancements The design of a knowledge-based system that simulates software production requires an underlying computational model of development states, actions, plans, schedules, expectations (e.g., requirements), and histories in order to answer "what if" questions <ref> [40] </ref>. Ultimately, the operation of the simulator depends upon the availability of a relevant knowledge base of facts, hueristics, and reasoning strategies found in development projects. Consider the following scenario of the simulator use: We have developed or acquired a knowledge-based software production simulation system of the kind outlined above. <p> Codify subsets of available software project data in a knowledge specification language, such as SPSL [40,41,42]. This step corresponds to an initial realization of the "knowledge representation" and "knowledge operationalization" activities described above. Demonstrate results in the computational language and processor suggested earlier <ref> [40] </ref>. Embed the software productivity modeling and simulation system within an advanced CASE environment in order to demostrate its integration, access, and software production guidance on LSS development efforts [22,23,40,41,42,53]. 6.
Reference: 41. <author> Mi. P. and W. Scacchi, </author> <title> "Modeling Articulation Work in Software Engineering Processes," </title> <booktitle> Proc. 1st. Intern. Conf. Software Process, IEEE Computer Society, </booktitle> <address> Redondo Beach, CA, </address> <year> (1991) </year>
Reference: 42. <author> Mi, P. and W. Scacchi, </author> <title> "Process Integration for CASE Environments," </title> <journal> IEEE Software, </journal> <volume> 9(2), </volume> <month> 26 (May </month> <year> 1992), </year> <pages> 45-53. </pages> <note> Reprinted in Computer-Aided Software Engineering, 2nd. Edition. </note> <editor> Chikofsky (ed.), </editor> <publisher> IEEE Computer Society, </publisher> <year> (1993). </year>
Reference: 43. <author> Mittal, R., M. Kim, and R. Berg, </author> <title> "A Case Study of Workstation Usage During Early Phases of the Software Development Life Cycle", </title> <booktitle> Proc. ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <year> (1986), </year> <pages> 70-76. </pages>
Reference-contexts: That is, if programmers currently must share a small number of heavily loaded computer systems, then providing each programmer with a workstation should improve their collective productivity <ref> [43] </ref>. 3.8. ITT Advanced Technology Center Vosburg and associates [55] produced perhaps the most substantial study of large-scale software productivity to date. They examined software production data for 44 programming projects in 17 different ITT subsidiaries in nine different countries.
Reference: 44. <author> Mohanty, </author> <title> S.N., "Software Cost Estimation: Present and Future", </title> <booktitle> Software-Practice and Experience 11 (1981), </booktitle> <pages> 103-121. </pages>
Reference-contexts: Standard, program-oriented productivity or cost estimation measures will provide less accurate information than those measures that account for characteristics of the organization and its computing environment. Mohanty <ref> [44] </ref> and Kemerer [30] also found similar results in their independent examinations of different software cost estimation models. 5 Thadhani [54] and Lambert [37] examined the effects of good computer services on programmer and project productivity during application program development. <p> Therefore, this article by King and Schrems can be recommended as background reading to those interested in conducting software cost vs. productivity analysis. Mohanty <ref> [44] </ref> compared the application of 20 software cost estimation models in use by large system development organizations. He entered data collected from a large software project, then entered this data into each of the 20 cost estimation models.
Reference: 45. <editor> Norman, R.J. and J.F. Nunamaker, </editor> <title> "CASE Productivity Perceptions of Software Engineering Professionals", </title> <journal> Communications ACM, </journal> <volume> 32(9), </volume> <year> (1989), </year> <pages> 1102-1108. </pages>
Reference-contexts: Thus, the structures, cohesiveness, and shifting patterns of teamwork are also salient software productivity variables. In a study that does not actually examining the extent to which CASE tools may improve software productivity, Norman and Nunamaker <ref> [45] </ref> report on what the software engineers they surveyed believed would improve software productivity [cf. 24]. These software engineers answered questions about the desirability and expected effectiveness of a variety of contemporary CASE mechanisms or methods.
Reference: 46. <author> Pengelly, A, M. Norris, R. Higham, </author> <title> "Software Process Modelling and Measurement -- A QMS Case Study," </title> <booktitle> Information and Software Technology, </booktitle> <pages> 35(6-7), 375-380. </pages>
Reference: 47. <author> Reddy, Y.V., M.S. Fox, N. Husain, and M. McRoberts, </author> <title> "The Knowledge-Based Simulation System", </title> <booktitle> IEEE Software 3(2), </booktitle> <year> (1986), </year> <pages> 26-37. </pages>
Reference-contexts: Suffice to say that a knowledge organization scheme is essential, and that such a scheme must again accomodate the kinds software production data 22 outlined in Section 5. A suggestive starting point that others are working from is the Schema Representation Language described by [49], and utilized by <ref> [47] </ref>, or the Software Process Specification Language (SPSL) used in [40,41,42]. For example, in their representation of system development projects, Scacchi and colleagues [22,23,40,41,42,51] developed a scheme for organizing and representing knowledge about organizational settings, resource arrangements, development plans, actions, states, schedules, histories, and expectations.
Reference: 48. <author> Romeu, J.L. and S.A. Gloss-Soler, </author> <title> "Some Measurement Problems Detected in the Analysis of Software Productivity Data and their Statistical Significance", </title> <booktitle> Proc. COMPSAC 83, IEEE Computer Society, </booktitle> <year> (1983), </year> <pages> 17-24. </pages>
Reference-contexts: But again, function points depend solely upon program source code characteristics, and do not address production process or production setting variations, nor their contributing effects. Romeu and Gloss-Soler <ref> [48] </ref> argue that most software productivity measurement studies employ inappropriate statistical analysis techniques. They argue that the type of productivity data usually reported is ordinal data rather than interval or ratio data.
Reference: 49. <author> Sathi, A., M.S. Fox, M. Greenberg, </author> <title> "Representation of Activity Knowledge for Project Management", </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 7(5), </volume> <year> (1985), </year> <pages> 531-552. </pages>
Reference-contexts: Suffice to say that a knowledge organization scheme is essential, and that such a scheme must again accomodate the kinds software production data 22 outlined in Section 5. A suggestive starting point that others are working from is the Schema Representation Language described by <ref> [49] </ref>, and utilized by [47], or the Software Process Specification Language (SPSL) used in [40,41,42]. For example, in their representation of system development projects, Scacchi and colleagues [22,23,40,41,42,51] developed a scheme for organizing and representing knowledge about organizational settings, resource arrangements, development plans, actions, states, schedules, histories, and expectations.
Reference: 50. <author> Scacchi, W., </author> <title> "Managing Software Engineering Projects: A Social Analysis", </title> <journal> IEEE Trans. Soft. Engr., </journal> <volume> SE-10(1), </volume> <year> (1984), </year> <pages> 49-59. </pages>
Reference-contexts: Boehm [9] reported that productivity on a software development project is most keenly affected by who develops the system and how well they are organized and managed as a team. Following this, Scacchi <ref> [50] </ref> reviewed a number of published reports on the problems of managing large software engineering projects. He found, to no surprise, that when projects were poorly managed or poorly organized, productivity was substantially lower than otherwise possible. Poor management can nullify the potential productivity enhancements attributable to improved development technologies. <p> In addition, we must also appreciate that software production can be organized into different modes of manufacture and organization of work, including: Ad hoc problem solving and articulation work [6,7,33,41] Project-oriented job shop, which are typical for software development projects <ref> [50] </ref> Batched job shops, for producing a family or small volume of related software products Pipeline, where software production is organized in concurrent multi-stage development, and staff is specialized in particular development crafts such as "software requirement analysts", "software architects", or "coders".
Reference: 51. <author> Scacchi, W., </author> <title> "On the Power of Domain-Specific Hypertext Environments", </title> <journal> J. Amer. Soc. Info. Sci., </journal> <volume> 40(5), </volume> <year> (1989). </year>
Reference: 52. <author> Scacchi, W., </author> <title> "Designing Software Systems to Facilitate Social Organization", </title> <editor> in M.J. Smith and G. Salvendy (eds.), </editor> <title> Work with Computers, </title> <booktitle> Vol. 12A, Advances in Humans Factors and Ergonomics, </booktitle> <publisher> Elsevier, </publisher> <address> New York, </address> <year> (1989), </year> <pages> 64-72. </pages>
Reference: 53. <author> Scacchi, W., </author> <title> "The Software Infrastructure for a Distributed System Factory", Soft. Engr. </title> <journal> J., </journal> <volume> 6(5), </volume> <month> (September </month> <year> 1991), </year> <pages> 355-369. </pages>
Reference-contexts: Flexible software manufacturing systems, which represent one view of a "software factory of the future" <ref> [53] </ref>. Transfer-line (or assembly line), where raw or unfinished information resources are brought to semi-skilled software craftspeople who perform highly routinized and limited fabrication or assembly tasks.
Reference: 54. <author> Thadhani, A.J., </author> <title> "Factors Affecting Programmer Productivity During Application Development", </title> <journal> IBM Systems J. </journal> <volume> 23(1), </volume> <year> (1984), </year> <pages> 19-35. </pages>
Reference-contexts: Standard, program-oriented productivity or cost estimation measures will provide less accurate information than those measures that account for characteristics of the organization and its computing environment. Mohanty [44] and Kemerer [30] also found similar results in their independent examinations of different software cost estimation models. 5 Thadhani <ref> [54] </ref> and Lambert [37] examined the effects of good computer services on programmer and project productivity during application program development. In particular, their studies examine the effects of short response times, programmer's skills, and program complexity on programmer productivity.
Reference: 55. <author> Vosburg, J., B. Curtis, R. Wolverton, B. Albert, H. Malec, S. Hoben and Y. </author> <title> Liu "Productivity Factors and Programming Environments", </title> <booktitle> Proc. 7th. Intern. Conf. Soft. Engr., IEEE Computer Society, </booktitle> <year> (1984), </year> <pages> 143-152. </pages>
Reference-contexts: That is, if programmers currently must share a small number of heavily loaded computer systems, then providing each programmer with a workstation should improve their collective productivity [43]. 3.8. ITT Advanced Technology Center Vosburg and associates <ref> [55] </ref> produced perhaps the most substantial study of large-scale software productivity to date. They examined software production data for 44 programming projects in 17 different ITT subsidiaries in nine different countries. <p> Cost of code defect detection and removal tends to indicate that it costs less to repair poor quality programs than high quality programs. Thus, Jones' results undercut the utility of the findings reported by Walston and Felix <ref> [55] </ref> which are subject to these paradoxes. As an alternative, Jones recommends separating productivity measures into work units and cost units, while program quality be measured by defect removal efficiency and defect prevention.
Reference: 56. <author> Walton, C.E. </author> <title> and C.P. Felix, "A Method of Programming Measurement and Estimation", </title> <journal> IBM Systems J. </journal> <volume> 16(1), </volume> <year> (1977), </year> <month> 54-65. </month> <title> i Table of Contents </title>
Reference-contexts: Together, these studies provide a loosely-grounded basis for identifying a number of project characteristics that affect software productivity. 3.1. IBM Federal Systems Division Walston and Felix <ref> [56] </ref> conducted the classic study in this area. The authors state that a major difficulty arises in trying to identify and measure which independent variables can be used to estimate software development productivity, cost, and size.
Reference: 1. <institution> Overview 1 </institution>
Reference: 2. <institution> Notes on the Science of Measurement 2 </institution>
Reference: 3. <institution> A Sample of Software Productivity Measurement Studies 2 3.1. IBM Federal Systems Division 3 3.2. IBM DP Services Organization 3 3.3. Equitable Life Organizations 3 3.4. TRW Defense Systems Group 4 3.5. Australia-70 Study 4 3.6. NASA/SEL 4 3.7. IBM 5 3.8. ITT Advanced Technology Center 5 3.9. Australia-80 Study 6 3.10. Commerical U.S. Banks 6 3.11. U.S. vs. Japan Study 6 3.12. Other studies of Productivity and Cost Evaluation 7 3.13. Information Technology and Productivity 10 3.14. Summary of Software Development Productivity Drivers 11 </institution>
Reference: 4. <author> Challenges for Software Productivity Measurement 13 4.1. </author> <title> Why measure software productivity? 13 4.2. Who should measure software productivity data? 13 4.3. What should be measured? 14 4.3.1. Software Products: 15 4.3.2. Software Production Process: 15 4.3.3. Software Production Setting: 17 4.4. How to measure software productivity? 17 4.4.1. Productivity measurement research design and sampling strategy 17 4.4.2. Unit of analysis 18 4.4.3. Level and terms of analysis 19 4.5. How to improve software productivity? 19 4.6. Summary 20 </title>
Reference-contexts: However, Lawrence also found that programming experience beyond the first year on the job, structured programming, and walkthroughs contribute little to productivity improvement. 3.6. NASA/SEL Bailey and Basili <ref> [4] </ref> found higher productivity over the entire system life cycle to be associated with the use of a disciplined programming methodology, particularly in the early stages of system development.
Reference: 5. <editor> Alternative Directions for Software Productivity Measurement and 20 Improvement 5.1. </editor> <title> Develop Setting-Specific Theories of Software Production 20 5.2. Identify and Cultivate Software Productivity Drivers 20 5.3. Develop Symbolic and Qualitative Measures of Software Productivity 21 5.4. Develop Knowledge-Based Systems that Model Software Production 21 5.4.1. Knowledge acquisition: 21 5.4.2. Knowledge representation: 21 5.4.3. Knowledge operationalization: 22 5.5. Simulate and measure the effects of productivity enhancements 22 5.6. An Approach 23 </title>
Reference-contexts: Equitable Life Organizations Behrens <ref> [5] </ref> also utilizes Albrecht's function point measures to compare software productivity in 25 application system projects developed in various life insurance companies from 1980 to 1981. His results are consistent with Albrecht's in supporting the contention that project size, development (computing) environment, and programming language impact software productivity.
Reference: 6. <institution> Conclusions 23 </institution>
Reference: 7. <institution> References 24 </institution>
Reference-contexts: This conclusion is especially appropriate when comparing such productivity measures across different studies. 10 In a comparative field study of software teams developing formal specifications, Bendifallah and Scacchi <ref> [7] </ref> found that variation in specification teamwork productivity and quality could best be explained in terms of recurring teamwork structures. They found six teamwork structures (ie, patterns of interaction) recurring among all the teams in their study. <p> However, any software process engineering environment or knowledge engineering system capable of modeling, simulating, and enacting software products, production processes, production settings and their interrelationships could be employed. 5.4.1. Knowledge acquisition: We can acquire knowledge about software projects by conducting in-depth, observational field studies <ref> [e.g, 7] </ref>. Ideally, such studies should be organized to facilitate comparative analysis. The data to be collected should account for the concerns described in Section 4. This in turn requires the articulation of a scheme for data collection, coding, and analysis.
References-found: 62

