URL: ftp://ftp.cs.clemson.edu/techreports/95-113.ps.Z
Refering-URL: http://www.cs.clemson.edu/html/research/techrpt.shtml
Root-URL: http://www.cs.clemson.edu
Email: malloy@cs.clemson.edu fgupta,soffag@cs.pitt.edu  
Title: A Global Scheduling Technique for Fine-Grained Asynchronous Parallelism  
Author: Brian A. Malloy Rajiv Gupta and Mary Lou Soffa 
Address: Pittsburgh Clemson, SC 29634 Pittsburgh, PA 15260  
Affiliation: Dept. of Computer Science Dept. of Computer Science Clemson University University of  
Abstract: Although a VLIW architecture is capable of exploiting fine-grained parallelism, the lockstep operation of its processing elements limits its effectiveness in the presence of run-time delays introduced by unpredictable events such as memory access conflicts. Existing scheduling techniques for VLIW architectures enable the exploitation of parallelism across basic blocks through global code motion. However, global code motion either exploits speculative execution to generate faster schedules for more likely paths, at the cost of slower schedules for less likely paths, or uses code duplication that can lead to an explosion in code size. We present a technique for fine-grained scheduling on asynchronous MIMD systems that are more tolerant to unpredictable events than VLIW architectures. The algorithm that we present, the shape algorithm, utilizes the flexibility of a MIMD system to exploit parallelism within and across basic blocks with reduced need for speculative execution or code duplication. Our algorithm overlaps the execution of instructions from different basic blocks by matching the shapes of schedules belonging to those basic blocks. In addition, using the shape algorithm, the compilation time can be controlled by increasing the grain size of schedulable units. Experimental results demonstrate that this technique exploits parallelism effectively and, by increasing the grain size, the shape algorithm achieves faster compilation times without any significant reduction in program speedup. keywords: fine-grained parallelism, MIMD systems, instruction scheduling, barrier synchronization.
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Installing and Managing the DG/UX System. Data General Corporation, </institution> <year> 1990. </year>
Reference-contexts: More dramatic cost improvements occurred for most of the other programs. 4.2 Performance of the shape algorithm on a Data General multiprocessor The Shape Algorithm was implemented on a Data General AViiON, shared memory multiprocessor system <ref> [1] </ref>, with a unibus communication network and two homogeneous processors. The send and receive primitives were 18 implemented using spin-lock operations on Unix shared variables [2].
Reference: [2] <author> M. J. Bach. </author> <title> The Design of the Unix Operation System. </title> <year> 1986. </year>
Reference-contexts: The send and receive primitives were 18 implemented using spin-lock operations on Unix shared variables <ref> [2] </ref>. To compare the results of these actual executions with corresponding simulation results, we first conducted a series of experiments to determine the average cost of the send and receive primitives and the cost of using the unibus communication structure.
Reference: [3] <author> K. E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> Proceedings AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: The Trap program implements the trapezoidal rule and Vector [18] manipulates the elements of an array. Loops in the Vector program were unrolled to produce large basic blocks. The MergeSort program is Batcher's merge-exchange sort <ref> [3] </ref> and the final program in the table, Sieve, finds prime numbers using the sieve of Erosthothenes. Our results in Table 1 show that the shape algorithm can appreciably improve execution speed of the program.
Reference: [4] <author> J. R. Ellis. Bulldog: </author> <title> A Compiler for VLIW Architectures. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: 1 Introduction Advances in technology now provide tremendous potential for increased computational speed and power through the exploitation of parallelism during program execution. An important part of this technology has focused on parallelizing a sequential instruction stream to exploit fine-grained parallelism using very long instruction word (VLIW) machines <ref> [4] </ref>. VLIW machines permit the concurrent execution of multiple operations in each long instruction. Techniques, such as trace scheduling [6], exploit fine-grained parallelism across basic blocks through global code motion that results in speculative execution of instructions and/or code duplication.
Reference: [5] <author> J. Ferrante, K. Ottenstein, and J. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <year> 1987. </year>
Reference-contexts: Our shape algorithm utilizes the asynchronous nature of the system to exploit parallelism across basic blocks without necessarily performing code motion between those basic blocks and thus reducing the need for speculative execution or code duplication. The shape algorithm uses the program dependence graph <ref> [5] </ref> and therefore is able to move code across control structures in a manner similar to region scheduling [9]. <p> We show how to partition nodes of the PDG into sets that we use to match shapes formed by already scheduled code. We then present the shape algorithm in the remainder of the section. 3 2.1 Scheduling straight-line code We use the program dependence graph <ref> [5] </ref>, or PDG, in our shape matching technique because both the control dependence and the data dependence information that we require are incorporated into a single structure. Control dependence is captured by a control dependence subgraph (CDS) and data dependence is captured by a data dependence subgraph (DDS).
Reference: [6] <author> J. Fisher. </author> <title> Trace scheduling: A technique for global microcode compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(7), </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: An important part of this technology has focused on parallelizing a sequential instruction stream to exploit fine-grained parallelism using very long instruction word (VLIW) machines [4]. VLIW machines permit the concurrent execution of multiple operations in each long instruction. Techniques, such as trace scheduling <ref> [6] </ref>, exploit fine-grained parallelism across basic blocks through global code motion that results in speculative execution of instructions and/or code duplication. Speculative execution enables a VLIW machine to achieve greater speedups along likely execution paths at the expense of program paths that are less likely to execute.
Reference: [7] <author> R. Gupta. </author> <title> Employing register channels for the exploitation of instruction level parallelism. </title> <booktitle> Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: In an asynchronous MIMD system, the cost of processor synchronization and interprocessor communication must be factored into scheduling considerations. Algorithms that attempt to minimize interprocessor communication during the parallel execution of straight-line code have been developed <ref> [7, 13] </ref>. We base the shape algorithm on one such algorithm, the preferred path selection algorithm (PPS)[13]. Thus, consideration of the cost of processor synchronization and interprocessor communication is included when shapes are matched. <p> For these schedules, we modeled a fast communication structure, assuming hardware support such as register channels <ref> [7] </ref> or message buffers [11]. The first row of Table 1 reports speedups for the program Kernel 1-F, the first of the 24 kernels of the livermore loops [15].
Reference: [8] <author> R. Gupta, M. Epstein, and M. Whelan. </author> <title> The design of a RISC based multiprocessor chip. </title> <booktitle> Proceedings of Supercomputing'90, </booktitle> <pages> pages 920-929, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Thus, while the VLIW architectures perform well on scientific programs, their performance can degrade when faced with factors that decrease run-time predictability. In order to address the above drawbacks of VLIW machines, a number of tightly coupled fine-grained MIMD architectures have been proposed <ref> [8, 10, 20] </ref>. An asynchronous MIMD system is tolerant of delays caused by unpredictable events since the processors are not required to operate in lockstep. Special synchronization and high speed communication hardware is provided to accelerate processor interaction.
Reference: [9] <author> R. Gupta and M. L. Soffa. </author> <title> Region scheduling: An approach for detecting and redistributing parallelism. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(4) </volume> <pages> 421-431, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: The shape algorithm uses the program dependence graph [5] and therefore is able to move code across control structures in a manner similar to region scheduling <ref> [9] </ref>. The goal of the shape algorithm is to match the shape of an unscheduled region with the shape of regions already 2 scheduled, minimizing "gaps" in the schedule that produce processor latency. <p> We refer to this duplication of the test and conditional branch as concurrentization of the control structure. An alternative to duplicating the test on the processors is to compute the test on one processor and broadcast the result to the other processors <ref> [9] </ref>. To concurrentize a control structure, we use information stored in predicate nodes of the PDG.
Reference: [10] <author> H. Kasahara, H. Honda, and S. Narita. </author> <title> Parallel processing of near fine grain tasks using static scheduling on OSCAR. </title> <booktitle> Proceedings of Supercomputing'90, </booktitle> <pages> pages 856-864, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Thus, while the VLIW architectures perform well on scientific programs, their performance can degrade when faced with factors that decrease run-time predictability. In order to address the above drawbacks of VLIW machines, a number of tightly coupled fine-grained MIMD architectures have been proposed <ref> [8, 10, 20] </ref>. An asynchronous MIMD system is tolerant of delays caused by unpredictable events since the processors are not required to operate in lockstep. Special synchronization and high speed communication hardware is provided to accelerate processor interaction.
Reference: [11] <author> J. S. Kowalik. </author> <title> Parallel MIMD computation: HEP supercomputer & its applications. </title> <booktitle> Scientific Computation Series, </booktitle> <year> 1985. </year>
Reference-contexts: For these schedules, we modeled a fast communication structure, assuming hardware support such as register channels [7] or message buffers <ref> [11] </ref>. The first row of Table 1 reports speedups for the program Kernel 1-F, the first of the 24 kernels of the livermore loops [15].
Reference: [12] <author> B. A. Malloy. </author> <title> The validation of a multiprocessor simulator. </title> <booktitle> Proceedings of the 1993 Winter Simulation Conference, </booktitle> <pages> pages 625-631, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: We modeled the asynchronous parallel execution of the schedules using a multiprocessor simulator <ref> [12] </ref>. We measured both the computation cost and the execution time of schedules at the operation, statement and basic block grain. We gauge our results using speedup, the ratio of sequential execution time to parallel execution time.
Reference: [13] <author> B. A. Malloy, E. L. Lloyd, and M. L. Soffa. </author> <title> Scheduling dags for asynchronous multiprocessor execution. </title> <journal> IEEE Transactions on Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 498-508, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: In an asynchronous MIMD system, the cost of processor synchronization and interprocessor communication must be factored into scheduling considerations. Algorithms that attempt to minimize interprocessor communication during the parallel execution of straight-line code have been developed <ref> [7, 13] </ref>. We base the shape algorithm on one such algorithm, the preferred path selection algorithm (PPS)[13]. Thus, consideration of the cost of processor synchronization and interprocessor communication is included when shapes are matched.
Reference: [14] <author> U. Manber. </author> <title> Introduction to Algorithms. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The remaining programs in Table 1 are as follows: Kernel 1-W is similar to Kernel 1-F except that for loops are converted to while loops; we constructed the Kernel 1-W program to compare speedups for unrolled for loops with concurrentized while loops. The Search program <ref> [14] </ref> finds the largest element in an array and the Broadcast program [14] copies elements into an array. The Trap program implements the trapezoidal rule and Vector [18] manipulates the elements of an array. Loops in the Vector program were unrolled to produce large basic blocks. <p> The Search program <ref> [14] </ref> finds the largest element in an array and the Broadcast program [14] copies elements into an array. The Trap program implements the trapezoidal rule and Vector [18] manipulates the elements of an array. Loops in the Vector program were unrolled to produce large basic blocks.
Reference: [15] <author> F. H. McMahon. </author> <title> FORTRAN CPU performance analysis. </title> <institution> Lawrence Livermore Laboratories, </institution> <year> 1972. </year>
Reference-contexts: For these schedules, we modeled a fast communication structure, assuming hardware support such as register channels [7] or message buffers [11]. The first row of Table 1 reports speedups for the program Kernel 1-F, the first of the 24 kernels of the livermore loops <ref> [15] </ref>. The remaining programs in Table 1 are as follows: Kernel 1-W is similar to Kernel 1-F except that for loops are converted to while loops; we constructed the Kernel 1-W program to compare speedups for unrolled for loops with concurrentized while loops.
Reference: [16] <author> T. Nakatani and K. Ebcioglu. </author> <title> Using a lookahead window in a compaction-based parallelizing compiler. </title> <booktitle> Proceedings of the 23rd Annual Workshop on Microprogramming and Microarchitecure, </booktitle> <pages> pages 57-68, </pages> <year> 1990. </year>
Reference-contexts: Previous techniques that have attempted to improve the efficiency of a trace scheduling compiler have done so by limiting the number of operations that are simultaneously considered for scheduling <ref> [16] </ref>. Another technique that exploits both fine-grained and medium-grained parallelism is applied to loop segments but is not extended to complete programs [17]. In the next section, we provide background, discuss the notion of a shape and conclude the section with the shape algorithm.
Reference: [17] <author> C. J. Newburn, S. Huang, and J. P. Shen. </author> <title> Balancing fine- and medium-grained parallelism in scheduling loops for the XIMD architecture. Conference on Architectures and Compilation Techniques for Fine and Medium Grain Parallelism, </title> <journal> IFIP Transactions A-23, </journal> <pages> pages 34-42, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Another technique that exploits both fine-grained and medium-grained parallelism is applied to loop segments but is not extended to complete programs <ref> [17] </ref>. In the next section, we provide background, discuss the notion of a shape and conclude the section with the shape algorithm. In Section 3, we present our technique for scheduling the three grains: operation, statement and basic block.
Reference: [18] <author> J. R. Rice and J. Jing. </author> <title> Problems to test parallel and vector languages. </title> <type> Technical Report CSD-TR-1016, </type> <institution> Purdue University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: The Search program [14] finds the largest element in an array and the Broadcast program [14] copies elements into an array. The Trap program implements the trapezoidal rule and Vector <ref> [18] </ref> manipulates the elements of an array. Loops in the Vector program were unrolled to produce large basic blocks. The MergeSort program is Batcher's merge-exchange sort [3] and the final program in the table, Sieve, finds prime numbers using the sieve of Erosthothenes.
Reference: [19] <author> V. Sarkar. </author> <title> Partitioning and scheduling parallel programs for execution on multiprocessors. </title> <type> Technical Report CSL-TR-87-328, </type> <institution> Stanford University, </institution> <month> April </month> <year> 1987. </year>
Reference-contexts: Our simulation model of a multiprocessor system includes parameters to specify the number of cycles to execute an instruction, the memory bandwidth, which we use in modeling contention among the processors, and the communication 16 cost <ref> [19] </ref>.
Reference: [20] <author> A. Wolfe and J.P. Shen. </author> <title> A variable instruction stream extension to the VLIW architecture. </title> <booktitle> Proc. of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 2-14, </pages> <month> April </month> <year> 1991. </year> <month> 21 </month>
Reference-contexts: Thus, while the VLIW architectures perform well on scientific programs, their performance can degrade when faced with factors that decrease run-time predictability. In order to address the above drawbacks of VLIW machines, a number of tightly coupled fine-grained MIMD architectures have been proposed <ref> [8, 10, 20] </ref>. An asynchronous MIMD system is tolerant of delays caused by unpredictable events since the processors are not required to operate in lockstep. Special synchronization and high speed communication hardware is provided to accelerate processor interaction.
References-found: 20

