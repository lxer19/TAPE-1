URL: file://ftp.cis.ohio-state.edu/pub/communication/papers/icpp98-dsm-trace-irr-adapt.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/paper.html
Root-URL: 
Email: ffsilla,mperez,jduatog@gap.upv.es  fdai,pandag@cis.ohio-state.edu  
Title: Impact of Adaptivity on the Behavior of Networks of Workstations under Bursty Traffic  
Author: F. Silla, M. P. Malumbres and J. Duato D. Dai and D. K. Panda 
Address: Vera, 14, 46071Valencia, Spain  Columbus, OH 43210-1277  
Affiliation: Dpto. Inf. de Sistemas Computadores Universidad Politecnica de Valencia Camino de  Dept. of Computer and Information Science Ohio State University,  
Abstract: Networks of workstations (NOWs) are becoming increasingly popular as an alternative to parallel computers. Typically, these networks present irregular topologies, providing the wiring flexibility, scalability, and incremental expansion capability required in this environment. Similar to the evolution of parallel computers, NOWs are also evolving from distributed memory to shared memory. However, distances between processors are longer in NOWs, leading to higher message latency and lower network bandwidth. Therefore, we can expect the network to be a bottleneck when executing some parallel applications on a NOW supporting a shared-memory programming paradigm. In this paper we analyze whether the interconnection network in a NOW is able to efficiently handle the traffic generated in a DSM with the same number of processors. We evaluate the behavior of a NOW using application traces captured during the execution of several SPLASH2 applications on a DSM simulator. We show through simulation that the adaptive routing algorithm previously proposed by us almost eliminates network saturation due to its ability to support a higher sustained throughput. Therefore, adaptive routing becomes a key design issue to achieve similar performance in NOWs and tightly-coupled DSMs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. J. Boden et al., </author> <title> Myrinet A gigabit per second local area network, </title> <booktitle> IEEE Micro, </booktitle> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Moreover, the nature of NOWs makes them scalable and allows an incremental expansion of the system. Recent network products, like Autonet [17], Myrinet <ref> [1] </ref>, and ServerNet [11], use point-to-point links between switching elements instead of the traditional shared mediums (like Ethernet) used in computer networks. These NOWs usually present an irregular topology as a consequence of the needs in a local area network. <p> As a natural evolution from local area networks, most interconnects for NOWs only provide support for message-passing. These networks consist of a network interface card that is plugged into the I/O bus of each workstation, and one or more switches interconnecting the interface cards through point-to-point links <ref> [1] </ref>. In general, the bandwidth provided by currently available interface cards and switches is high enough for the requirements of message-passing ap plications. However, the performance of some parallel ap-plications is limited by message latency. Most of this latency is due to the software messaging layer. <p> Additionally, the use of irregular topologies makes routing and deadlock handling much more complex. Existing routing algorithms are either deterministic <ref> [1] </ref> or provide some degree of adaptivity [17]. They provide non-minimal paths and an unbalanced use of physical links. As a consequence channel utilization is low, reducing the effective network bandwidth even more. <p> Server-Net II [9] and Myrinet <ref> [1] </ref> use serial and 8-bit links, respectively. neck when executing some parallel applications on a NOW supporting a shared-memory programming paradigm. <p> The introduction of virtual channels and a minimal routing algorithm like the MA-2VC algorithm contribute to meet the requirements of NOWs. 5. Conclusions Networks of workstations are becoming increasingly popular as a cost-effective alternative to parallel computers. Typically, these networks connect processors using irregular topologies <ref> [1, 11] </ref>. Irregularity provides the wiring flexibility, scalability and incremental expansion capabil (a) (b) (a) (b) ity required in this environment. Similar to the evolution of parallel computers, NOWs are also evolving from distributed memory to shared memory. Some commercial interface cards support the shared-memory programming model [5].
Reference: [2] <author> G. T. Byrd et al., </author> <title> Evaluation of communication mechanisms in invalidate-based shared memory multiprocessors, </title> <booktitle> in Proc. of the 1997 PCRCW, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: While the interconnection network is not the bottleneck yet, some researchers began to report that a lower latency [21] and a higher network bandwidth <ref> [2] </ref> may significantly reduce the execution time of several parallel applications. As processor clock frequency is increasing at a faster rate than network bandwidth, the interconnection network may become a bottleneck within the next few years [7]. The situation is more critical for NOWs supporting a single memory address space.
Reference: [3] <author> D. Dai and D. K. Panda. </author> <title> Reducing Cache Invalidation Overheads in Wormhole DSMs Using Multidesti-nation Message Passing, </title> <booktitle> in Int. Conf. on Parallel Processing, </booktitle> <month> Aug </month> <year> 1996. </year>
Reference: [4] <author> D. Dai and D. K. Panda, </author> <title> How we can design better networks for DSM Systems?, </title> <booktitle> in Proceedings of the 1997 Parallel Computer Routing and Communication Workshop, </booktitle> <month> June </month> <year> 1997. </year>
Reference: [5] <author> Dolphin, </author> <note> The Dolphin SCI Interconnect, available at http://www.dolphinics.no. </note>
Reference-contexts: Several attempts have been made to reduce this bottleneck [8]. As parallel computers, NOWs are also evolving from distributed memory to shared memory. Some commercial interface cards support the shared-memory programming model. This is the case for the SCI-PCI adapter from Dolphin <ref> [5] </ref>. However, this card does not support cache coherence in hardware because memory traffic cannot be seen from the I/O bus. Also, interface cards are reaching the limits of I/O buses 1 . <p> Irregularity provides the wiring flexibility, scalability and incremental expansion capabil (a) (b) (a) (b) ity required in this environment. Similar to the evolution of parallel computers, NOWs are also evolving from distributed memory to shared memory. Some commercial interface cards support the shared-memory programming model <ref> [5] </ref>. Some experimental NOWs provide support for shared-memory [16], also implementing a cache-coherence protocol that allows out-of-order delivery of messages.
Reference: [6] <author> J. Duato, </author> <title> On the design of deadlock-free adaptive routing algorithms for multicomputers: </title> <booktitle> Design methodologies, in Proc. of Parallel Architectures and Languages Europe 91, </booktitle> <month> June </month> <year> 1991. </year>
Reference: [7] <author> J. Duato, S. Yalamanchili and L. M. Ni, </author> <title> Interconnection Networks: An Engineering Approach. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1997. </year>
Reference-contexts: As processor clock frequency is increasing at a faster rate than network bandwidth, the interconnection network may become a bottleneck within the next few years <ref> [7] </ref>. The situation is more critical for NOWs supporting a single memory address space. Physical distance between processors is higher in NOWs than in DSMs, leading to higher latency (due to the propagation delay) and lower bandwidth (due to the use of narrower links) 3 .
Reference: [8] <author> T. von Eicken et al., </author> <title> Active messages: A mechanism for integrated communication and computation, </title> <booktitle> in Proc. of the 19th Int. Symp. on Computer Architecture, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: However, the performance of some parallel ap-plications is limited by message latency. Most of this latency is due to the software messaging layer. Several attempts have been made to reduce this bottleneck <ref> [8] </ref>. As parallel computers, NOWs are also evolving from distributed memory to shared memory. Some commercial interface cards support the shared-memory programming model. This is the case for the SCI-PCI adapter from Dolphin [5].
Reference: [9] <author> D. Garcia, </author> <title> Servernet II, </title> <booktitle> in 1997 Parallel Computer Routing and Communication Workshop, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: They provide non-minimal paths and an unbalanced use of physical links. As a consequence channel utilization is low, reducing the effective network bandwidth even more. Therefore, we can expect the network to be a bottle 1 For example, link bandwidth in Myrinet is 160 Mbytes/s. ServerNet II <ref> [9] </ref> provides links with 1 Gigabit/s peak bandwidth. <p> Server-Net II <ref> [9] </ref> and Myrinet [1] use serial and 8-bit links, respectively. neck when executing some parallel applications on a NOW supporting a shared-memory programming paradigm.
Reference: [10] <author> J. L. Hennessy and D. Patterson. </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: The cache was assumed to operate in dual-port mode using write-back and write-allocate policies. The instruction latencies, issue rules, and memory interface were modeled based on the DLX design <ref> [10] </ref>. The memory bus was assumed to be 8 bytes wide. On a memory block access, the first word of the block was assumed to be returned in 30 processor cycles; the successive words follow in a pipelined fashion. The machine used a full-mapped, invalidation-based directory coherence protocol [13].
Reference: [11] <author> R. Horst, </author> <title> ServerNet deadlock avoidance and fracta-hedral topologies, </title> <booktitle> in Proc. of the Int. Parallel Processing Symp., </booktitle> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Moreover, the nature of NOWs makes them scalable and allows an incremental expansion of the system. Recent network products, like Autonet [17], Myrinet [1], and ServerNet <ref> [11] </ref>, use point-to-point links between switching elements instead of the traditional shared mediums (like Ethernet) used in computer networks. These NOWs usually present an irregular topology as a consequence of the needs in a local area network. <p> The introduction of virtual channels and a minimal routing algorithm like the MA-2VC algorithm contribute to meet the requirements of NOWs. 5. Conclusions Networks of workstations are becoming increasingly popular as a cost-effective alternative to parallel computers. Typically, these networks connect processors using irregular topologies <ref> [1, 11] </ref>. Irregularity provides the wiring flexibility, scalability and incremental expansion capabil (a) (b) (a) (b) ity required in this environment. Similar to the evolution of parallel computers, NOWs are also evolving from distributed memory to shared memory. Some commercial interface cards support the shared-memory programming model [5].
Reference: [12] <author> J. Kuskin et al, </author> <title> The Stanford FLASH Multiprocessor, </title> <booktitle> in Proc. of the Int. Symp. on Computer Architecture, </booktitle> <year> 1994. </year>
Reference-contexts: In particular, we evaluated the performance of several routing algorithms for irregular networks by using message traces generated by an execution-driven simulation of several SPLASH2 benchmark applications. The simulated hardware DSM system used an architecture similar to the FLASH machine <ref> [12] </ref>. The system had 64 nodes connected by an 8 fi 8 mesh with a bandwidth of 400 MB/s/link and 15 ns per-hop delay.
Reference: [13] <author> D. Lenoski et al, </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor, </title> <booktitle> in Proc. of the 17th Annual Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: The memory bus was assumed to be 8 bytes wide. On a memory block access, the first word of the block was assumed to be returned in 30 processor cycles; the successive words follow in a pipelined fashion. The machine used a full-mapped, invalidation-based directory coherence protocol <ref> [13] </ref>. The node controller took 14 cycles to process an incoming (or outgoing) request or reply. The network interface took 15 cycles to construct and 8 cycles to dispatch a message. The synchronization protocol assumed was queuing based similar to the one used in DASH [14].
Reference: [14] <author> D. Lenoski, et al., </author> <title> The Stanford DASH multiprocessor, </title> <journal> IEEE Computer, </journal> <volume> vol. 25, no. 3, </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: The node controller took 14 cycles to process an incoming (or outgoing) request or reply. The network interface took 15 cycles to construct and 8 cycles to dispatch a message. The synchronization protocol assumed was queuing based similar to the one used in DASH <ref> [14] </ref>. Our simulated architecture used the sequential memory consistency model. A cache miss stalls the processor until the critical word of data is returned. Four applications Barnes, LU, Radix, and Water, all ported from the SPLASH2 suite [22] were used in this study.
Reference: [15] <author> J. Miguel, et al., </author> <title> Assessing the performance of the new IBM SP2 communication subsystem, </title> <type> Technical Report 960601, </type> <institution> Department of Electrical and Computer Engineering, University of California, Irvine, </institution> <month> June </month> <year> 1996. </year>
Reference: [16] <author> A. G. Nowatzyk, et al., S-Connect: </author> <title> From networks of workstations to supercomputer performance, </title> <booktitle> Proc. of the 22nd Int. Symp. on Comp. Architecture, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Also, interface cards are reaching the limits of I/O buses 1 . In order to provide a higher bandwidth and lower latency, some researchers have started to develop interface cards that are plugged into the memory bus. Some experimental NOWs provide support for shared-memory <ref> [16] </ref>, also implementing a cache-coherence protocol that allows out-of-order delivery of messages. 2. Motivation A decade ago, the invention of wormhole switching led to very fast interconnection networks. As a consequence, the interconnection network was no longer the bottleneck in a multicomputer. <p> Similar to the evolution of parallel computers, NOWs are also evolving from distributed memory to shared memory. Some commercial interface cards support the shared-memory programming model [5]. Some experimental NOWs provide support for shared-memory <ref> [16] </ref>, also implementing a cache-coherence protocol that allows out-of-order delivery of messages. In this paper we analyzed whether a NOW with irregular topology is able to handle the traffic supported by the interconnection network in a DSM with the same number of processors.
Reference: [17] <author> M. D. Schroeder et al., Autonet: </author> <title> A high-speed, self-configuring local area network using point-to-point links, </title> <type> Technical Report SRC research report 59, </type> <month> DEC, April </month> <year> 1990. </year>
Reference-contexts: Moreover, the nature of NOWs makes them scalable and allows an incremental expansion of the system. Recent network products, like Autonet <ref> [17] </ref>, Myrinet [1], and ServerNet [11], use point-to-point links between switching elements instead of the traditional shared mediums (like Ethernet) used in computer networks. These NOWs usually present an irregular topology as a consequence of the needs in a local area network. <p> Additionally, the use of irregular topologies makes routing and deadlock handling much more complex. Existing routing algorithms are either deterministic [1] or provide some degree of adaptivity <ref> [17] </ref>. They provide non-minimal paths and an unbalanced use of physical links. As a consequence channel utilization is low, reducing the effective network bandwidth even more. Therefore, we can expect the network to be a bottle 1 For example, link bandwidth in Myrinet is 160 Mbytes/s. <p> Figure 1 also shows the traffic pattern of the Water, LU, and Radix applications. Bursty traffic can also be observed in these applications as well. 4. Performance Evaluation In this section, we compare the performance of the up/down routing scheme (UD) <ref> [17] </ref> and our minimal adaptive (MA-2VC) routing algorithm [20]. The latter requires two virtual channels per physical channel. In order to make a fair comparison, we have also evaluated the up/down routing algorithm with two virtual channels (UD-2VC). Our simulator models the network at the flit level.
Reference: [18] <author> S. L. Scott and G. Thorson, </author> <title> Optimized routing in the Cray T3D, </title> <booktitle> Proc. of the Workshop on Parallel Computer Routing and Communication, </booktitle> <month> May </month> <year> 1994. </year>
Reference: [19] <author> S. L. Scott and G. Thorson, </author> <title> The Cray T3E networks: adaptive routing in a high performance 3D torus, </title> <booktitle> in Proc. of Hot Interconnects IV, </booktitle> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: However, a 32-bit PCI bus running at 33 MHz only achieves a peak bandwidth of 133 Mbytes/s. 2 Throughout this paper, the terminology `DSM' is used to refer to tightly-coupled distributed shared memory systems like DASH, FLASH, SGI Origin, etc. 3 For example, Cray T3E routers <ref> [19] </ref> use 14 data wires per link. Server-Net II [9] and Myrinet [1] use serial and 8-bit links, respectively. neck when executing some parallel applications on a NOW supporting a shared-memory programming paradigm.
Reference: [20] <author> F. Silla and J. Duato, </author> <title> Improving the Efficiency of Adaptive Routing in Networks with Irregular Topology, </title> <booktitle> in 1997 Int. Conf. on High Perf. Computing, </booktitle> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: We show that the slower interconnection network available in a NOW becomes a bottleneck, saturating during some periods of time. The use of adaptive routing algorithms, derived by using a methodology previously developed by us <ref> [20] </ref> helps to alleviate such bottlenecks. The main contribution of this paper is a study of the network behavior in a NOW under the traffic generated by several shared-memory parallel benchmarks executed on a DSM simulator with the same processors. <p> Figure 1 also shows the traffic pattern of the Water, LU, and Radix applications. Bursty traffic can also be observed in these applications as well. 4. Performance Evaluation In this section, we compare the performance of the up/down routing scheme (UD) [17] and our minimal adaptive (MA-2VC) routing algorithm <ref> [20] </ref>. The latter requires two virtual channels per physical channel. In order to make a fair comparison, we have also evaluated the up/down routing algorithm with two virtual channels (UD-2VC). Our simulator models the network at the flit level. We used traces to drive the simulator. <p> As can be seen in this figure, the three routing schemes behave similarly for low loads, as it was ex pected after the study in <ref> [20] </ref>. The UD routing algorithm achieves the highest latency, as expected, while the lowest latency is achieved by the MA-2VC routing algorithm. However, this difference is not significant because the highest difference is about five clock cycles. <p> Also, with respect to the UD-2VC algorithm, MA-2VC behaves more than four times faster. Figures 3 (c) and 3 (d) show similar results for the second and third bursty points. These results confirm the conclusions in <ref> [20] </ref>, where the MA-2VC algorithm achieved a throughput several times greater than the UD routing algorithm using a uniform distribution of message destinations. However, differences in throughput are more noticeable when application traces are used.
Reference: [21] <author> A. S. Vaidya et al., </author> <title> Performance benefits of Virtual Channels and Adaptive Routing: An Application Driven Study, </title> <booktitle> in Int. Conf. on Supercomputing, </booktitle> <year> 1997 </year>
Reference-contexts: However, DSMs 2 require faster interconnection networks than multicomputers because messages are shorter (a typical message consists of a cache line and some control information) and much more frequent. While the interconnection network is not the bottleneck yet, some researchers began to report that a lower latency <ref> [21] </ref> and a higher network bandwidth [2] may significantly reduce the execution time of several parallel applications. As processor clock frequency is increasing at a faster rate than network bandwidth, the interconnection network may become a bottleneck within the next few years [7]. <p> Finally, in Section 5 some conclusions are drawn. 3. A Simulation Model Based on Application Message Traces In general, the interconnection network is not the bottleneck in current DSM systems. Therefore, techniques that improve network throughput are of little interest in this environment <ref> [21] </ref>. Nowadays, DSMs and NOWs are designed by using the same processors. The main architectural differences between these machines are the interconnection network and communication assisting circuitry such as the node controller. In this paper, we focus on the network. <p> Is the interconnection network the bottleneck in a NOW? Will the network in a NOW be able to handle the traffic supported by the network in a DSM without saturating? Note that only a fraction of the network bandwidth is used in a DSM during the execution of parallel applications <ref> [21] </ref>. Therefore, despite the lower effective bandwidth provided by a NOW, this bandwidth may be enough for the requirements of parallel applications. To answer the above question, we gathered message traces at the node controller during the execution of several parallel applications on an execution-driven DSM simulator.
Reference: [22] <author> S. C. Woo et al., </author> <title> The SPLASH-2 Programs: Chrac-terization and Methodological Considerations, </title> <booktitle> in Int. Symp. on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: Our simulated architecture used the sequential memory consistency model. A cache miss stalls the processor until the critical word of data is returned. Four applications Barnes, LU, Radix, and Water, all ported from the SPLASH2 suite <ref> [22] </ref> were used in this study. The problem sizes (listed in Table 1) for the applications were selected with two considerations. First, they are reasonably large to generate realistic network behavior. Second, the sizes of resulting trace files are manageable.
References-found: 22

