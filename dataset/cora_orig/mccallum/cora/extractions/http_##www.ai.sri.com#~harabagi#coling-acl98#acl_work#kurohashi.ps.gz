URL: http://www.ai.sri.com/~harabagi/coling-acl98/acl_work/kurohashi.ps.gz
Refering-URL: http://www.ai.sri.com/~harabagi/coling-acl98/acl_work/acl_work.html
Root-URL: 
Email: fstetina,kuro,nagaog@kuee.kyoto-u.ac.jp  
Title: General Word Sense Disambiguation Method Based on a Full Sentential Context  
Author: Jiri Stetina Sadao Kurohashi Makoto Nagao 
Address: Yoshida-honmachi, Sakyo, Kyoto, 606-8501, Japan  
Affiliation: Graduate School of Infomatics, Kyoto University  
Abstract: This paper presents a new general supervised word sense disambiguation method based on a relatively small syntactically parsed and semantically tagged training corpus. The method exploits a full sentential context and all the explicit semantic relations in a sentence to identify the senses of all of that sentence's content words. In spite of a very small training corpus, we report an overall accuracy of 80.3% (85.7, 63.9, 83.6 and 86.5%, for nouns, verbs, adjectives and adverbs, respectively), which exceeds the accuracy of a statistical sense-frequency based semantic tagging, the only really applicable general disambiguating technique. 
Abstract-found: 1
Intro-found: 1
Reference: <author> E. Agirre and G. Rigau. </author> <year> 1996. </year> <title> Word sense disambiguation using conceptual density. </title> <booktitle> In Proc. of COLLING, </booktitle> <pages> pages 16-22. </pages>
Reference-contexts: Similarly to our work, (Resnik, 1995)<ref> (Agirre and Rigau, 1996) </ref> challenge the fine-grainedness of Word-Net, but their work is limited to nouns only. (Agirre and Rigau, 1996) report coverage 86.2%, precision 71.2% and recall 61.4% for nouns in four randomly selected semantic concordance files.
Reference: <author> A. Berger, V. Pietra, and S. Pietra. </author> <year> 1996. </year> <title> A maximum entropy approach to natural language processing. </title> <journal> Computational Linguistics, </journal> <volume> 1(22) </volume> <pages> 39-72. </pages>
Reference-contexts: The reason why g j (10) is calculated as a sum of the best scores (11), rather than by using the traditional maximum likelihood estimate <ref> (Berger et al., 1996) </ref>(Gale et al., 1993), is to minimise the effect of the sparse data problem.
Reference: <author> M. Collins. </author> <year> 1996. </year> <title> A new statistical parser based on bigram lexical dependencies. </title> <booktitle> In Proc. of the 34th Annual Meeting of the ACL, </booktitle> <pages> pages 184-191. </pages>
Reference-contexts: To determine the tree head-word we used a set of rules similar to that described by (Magerman, 1995)(Je-linek et al., 1994) and also used by <ref> (Collins, 1996) </ref>, which we modified in the following way: * The head of a prepositional phrase (PP! IN NP) was substituted by a function the name of which corresponds to the preposition, and its sole argument corresponds to the head of the noun phrase NP. * The head of a subordinate
Reference: <author> W. Gale, K. Church, and D. Yarowsky. </author> <year> 1993. </year> <title> A method for disambiguating word senses in a large corpus. </title> <journal> Computers and Humanities, </journal> (26):415-4397. 
Reference: <author> F. Jelinek, J. Lafferty, D. Magerman, R. Mercer, A. Rathnaparkhi, and S. Roukos. </author> <year> 1994. </year> <title> Decision tree parsing using a hidden derivation model. </title> <booktitle> In Proc. of the ARPA Human Language Technology Workshop, </booktitle> <pages> pages 272-277. </pages>
Reference: <author> Y. Karov and S. Edelman. </author> <year> 1996. </year> <title> Learning similarity-based word sense disambiguation from sparse data. </title> <booktitle> In Proc. of the 3rd Workshop on Very Large Corpora, </booktitle> <pages> pages 42-55. </pages>
Reference-contexts: From among the methods based on semantic distance, (Resnik, 1993)(Sussna, 1993) use a similar semantic distance measure for two concepts in WordNet, but they also focus on selected group of nouns only. <ref> (Karov and Edelman, 1996) </ref> use an interesting iterative algorithm and attempt to solve the sparse data bottleneck by using a graded measure of contextual similarity.
Reference: <author> D. Magerman. </author> <year> 1995. </year> <title> Statistical decision-tree models for parsing. </title> <booktitle> In Proc. of the 33rd Annual Meeting of ACL, </booktitle> <pages> pages 276-283. </pages>
Reference-contexts: The key to extraction of the relations is that any phrase can be substituted by the corresponding tree head-word (links marked bold in Figure 1). To determine the tree head-word we used a set of rules similar to that described by <ref> (Magerman, 1995) </ref>(Je-linek et al., 1994) and also used by (Collins, 1996), which we modified in the following way: * The head of a prepositional phrase (PP! IN NP) was substituted by a function the name of which corresponds to the preposition, and its sole argument corresponds to the head of the
Reference: <author> M. Marcus. </author> <year> 1993. </year> <title> Building a large annotated corpus of english: The penn treebank. </title> <journal> Computational Linguistics, </journal> <volume> 2(19) </volume> <pages> 313-330. </pages>
Reference-contexts: Since WordNet only provides definitions for content words (nouns, verbs, adjectives and adverbs), we are only concerned with identifying the correct senses of the content words. Both for the training and for the testing of our algorithm, we used the syntactically analysed sentences of the Brown Corpus <ref> (Marcus, 1993) </ref>, which have been manually semantically tagged (Miller et al., 1993) into semantic concordance files (SemCor).
Reference: <author> G. Miller, C. Leacock, and R. Tengi. </author> <year> 1993. </year> <title> A semantic concordance. </title> <booktitle> In Proc. of the ARPA Human Language Technology Workshop, </booktitle> <pages> pages 303-308. </pages>
Reference-contexts: Both for the training and for the testing of our algorithm, we used the syntactically analysed sentences of the Brown Corpus (Marcus, 1993), which have been manually semantically tagged <ref> (Miller et al., 1993) </ref> into semantic concordance files (SemCor). <p> Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the word-sense disambiguation: Using the semantic concordance files <ref> (Miller et al., 1993) </ref>, we have counted the occurrences of content words which previously appear in the same discourse file. The experiment indicated that the "one sense per discourse" hypothesis works fairly well for nouns, however, the evidence is much weaker for verbs, adverbs and adjectives.
Reference: <author> G Miller. </author> <year> 1990. </year> <title> Wordnet: An on-line lexical database. </title> <journal> International Journal of Lexicography, </journal> <volume> 3(4) </volume> <pages> 235-312. </pages>
Reference: <author> P. Resnik. </author> <year> 1993. </year> <title> Semantic classses and syntactic ambiguity. </title> <booktitle> In Proc. of the APRA Human Language Technology Workshop, </booktitle> <pages> pages 278-283. </pages>
Reference-contexts: From among the methods based on semantic distance, <ref> (Resnik, 1993) </ref>(Sussna, 1993) use a similar semantic distance measure for two concepts in WordNet, but they also focus on selected group of nouns only. (Karov and Edelman, 1996) use an interesting iterative algorithm and attempt to solve the sparse data bottleneck by using a graded measure of contextual similarity.
Reference: <author> P. Resnik. </author> <year> 1995. </year> <title> Disambiguating noun groupings with respect to wordnet senses. </title> <booktitle> In Proc. of the 3rd Workshop on Very Large Corpora. </booktitle>
Reference-contexts: In spite of a very small training corpus, the overall word sense accuracy exceeds 80%. 8 Related Work To our knowledge, there is no current method which attempts to identify the senses of all words in whole sentences, so we cannot make a practical compari-son. Similarly to our work, <ref> (Resnik, 1995) </ref>(Agirre and Rigau, 1996) challenge the fine-grainedness of Word-Net, but their work is limited to nouns only. (Agirre and Rigau, 1996) report coverage 86.2%, precision 71.2% and recall 61.4% for nouns in four randomly selected semantic concordance files.
Reference: <author> M. Sussna. </author> <year> 1993. </year> <title> Word sense disambiguation for free-text indexing using a massive semantic network. </title> <booktitle> In Proc. of Second International Conference on Information and Knowledge Management, </booktitle> <pages> pages 67-74. </pages>
Reference: <author> D. Yarowsky. </author> <year> 1995. </year> <title> Unsupervised word sense disambiguation rivaling supervised methods. </title> <booktitle> In Proc. of the 32nd Annual Meeting of the ACL. </booktitle>
Reference-contexts: 15,373 6,923 5,523 3812 2,057 5,227 933 830 &lt;10 9,474 3,697 2,733 1672 649 2,521 258 214 &lt;4 5,964 2,065 1,566 841 290 1,269 104 82 &lt;2 3,039 986 733 348 103 555 42 27 tion holds in real life sentences, however, has yet to be investigated. 6 Discourse Context <ref> (Yarowsky, 1995) </ref> pointed out that the sense of a target word is highly consistent within any given document (one sense per discourse). <p> They achieve 90.5, 92.5, 94.8 and 92.3 percent accuracy in distinguishing between two senses of the noun drug, sentence, suit and player, respectively. <ref> (Yarowsky, 1995) </ref>, whose training corpus for the noun drug was 9 times bigger than that of Karov and Edelman, reports 91.4% correct performance improved to impressive 93.9% when using the "one sense per discourse" constraint.
References-found: 14

