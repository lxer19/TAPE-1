URL: http://www-ai.cs.uni-dortmund.de/DOKUMENTE/Joachims_97a.ps.gz
Refering-URL: http://www-ai.informatik.uni-dortmund.de/PERSONAL/joachims.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: thorsten@ls8.informatik.uni-dortmund.de  
Title: A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization  
Author: Thorsten Joachims 
Address: Baroper Str. 301 44221 Dortmund, Germany  
Affiliation: Universitat Dortmund, Fachbereich Informatik, Lehrstuhl 8  
Abstract: The Rocchio relevance feedback algorithm is one of the most popular and widely applied learning methods from information retrieval. Here, a probabilistic analysis of this algorithm is presented in a text categorization framework. The analysis gives theoretical insight into the heuristics used in the Roc-chio algorithm, particularly the word weighting scheme and the similarity metric. It also suggests improvements which lead to a probabilistic variant of the Rocchio classifier. The Rocchio classifier, its probabilistic variant, and a naive Bayes classifier are compared on six text categorization tasks. The results show that the probabilistic algorithms are preferable to the heuristic Rocchio classifier not only because they are more well-founded, but also because they achieve better perfor mance.
Abstract-found: 1
Intro-found: 1
Reference: [Bookstein, 1982] <author> A. Bookstein, </author> <title> "Explanation and Generalization of Vector Models in Information Retrieval", </title> <editor> in G. Salton, H. Schneider: </editor> <booktitle> Research and Development in Information Retrieval, </booktitle> <address> Berlin, </address> <year> 1982. </year>
Reference-contexts: Other researchers have already proposed theoretical interpretations of the vector space retrieval model <ref> [Bookstein, 1982] </ref>[Wang et al., 1992] and the TFIDF word weighting scheme [Wong, Yao, 1989] [Wu, Salton, 1981].
Reference: [Buckley et al., 1994] <author> C. Buckley, G. Salton, J. Allan, </author> <title> "The Effect of Adding Relevance Information in a Relevance Feedback Environment", </title> <booktitle> International ACM SIGIR Conference, </booktitle> <pages> pages 292-300, </pages> <year> 1994. </year>
Reference-contexts: The prototype vector is then calculated as a weighted difference of each. ~c j = ff jC j j ~ d2C j jj ~ djj 1 X ~ d (3) ff and fi are parameters that adjust the relative impact of positive and negative training examples. As recommended in <ref> [Buckley et al., 1994] </ref> ff = 16 and fi = 4 will be used in the following. C j is the set of train ing documents assigned to class j and jj ~ djj denotes the Euclidian length of a vector ~ d.
Reference: [Cooper, 1991] <author> W. Cooper, </author> <title> "Some Inconsistencies and Misnomers in Probabilistic Information Retrieval", </title> <booktitle> International ACM SIGIR Conference, </booktitle> <pages> pages 57-61, </pages> <year> 1991. </year>
Reference-contexts: It assumes that the observation of each word is a priori equally likely. I found that this Bayesian estimator works well in practice, since it does not falsely estimate probabilities to be zero. 1 The weaker assumption of "linked-dependence" is actually sufficient <ref> [Cooper, 1991] </ref>, but not considered here for simplicity. The following is the resulting decision rule if equations (8), (10) and (12) are combined.
Reference: [Fuhr, 1989] <author> N. Fuhr, </author> <title> "Models for Retrieval with Probabilistic Indexing", </title> <booktitle> Information Processing and Management, </booktitle> <volume> 25(1), </volume> <pages> pages 55-72, </pages> <year> 1989. </year>
Reference-contexts: The PrTFIDF Algorithm uses a different way approximating Pr (C j jd 0 ) inspired by the "retrieval with probabilistic indexing" (RPI) approach proposed in <ref> [Fuhr, 1989] </ref>. In this approach a set of descriptors X is used to represent the content of documents. A descriptor x is assigned to a document d with a certain probability Pr (xjd).
Reference: [Hayes et al., 1988] <author> P. Hayes, L. Knecht, M. Cellio, </author> <title> "A news story categorization system", </title> <booktitle> Second Conference on Applied Natural Language Processing, </booktitle> <pages> pages 9-17, </pages> <year> 1988. </year>
Reference-contexts: With the amount of online information growing rapidly, the need for reliable automatic text categorization has increased. Text categorization techniques are used, for example, to build personalized netnews filter which learn about the news-reading preferences of a user [Lang, 1995]. They are used to index news stories <ref> [Hayes et al., 1988] </ref> or guide a user's search on the World Wide Web [Joachims et al., 1997]. One of the most widely applied learning algorithms for text categorization is the Rocchio relevance feedback method [Rocchio, 1971] developed in information retrieval.
Reference: [Joachims et al., 1997] <author> T. Joachims, D. Freitag, T. Mitchell, "WebWatcher: </author> <title> A Tour Guide for the World Wide Web", </title> <booktitle> International Joint Conference on Artificial Intelligence (IJCAI), </booktitle> <year> 1997. </year>
Reference-contexts: Text categorization techniques are used, for example, to build personalized netnews filter which learn about the news-reading preferences of a user [Lang, 1995]. They are used to index news stories [Hayes et al., 1988] or guide a user's search on the World Wide Web <ref> [Joachims et al., 1997] </ref>. One of the most widely applied learning algorithms for text categorization is the Rocchio relevance feedback method [Rocchio, 1971] developed in information retrieval. Originally designed for optimizing queries from relevance feedback, the algorithm can be adapted to text categorization and routing problems.
Reference: [Lang, 1995] <author> K. Lang, "NewsWeeder: </author> <title> Learning to Filter Netnews", </title> <booktitle> International Conference on Machine Learning, </booktitle> <year> 1995. </year>
Reference-contexts: With the amount of online information growing rapidly, the need for reliable automatic text categorization has increased. Text categorization techniques are used, for example, to build personalized netnews filter which learn about the news-reading preferences of a user <ref> [Lang, 1995] </ref>. They are used to index news stories [Hayes et al., 1988] or guide a user's search on the World Wide Web [Joachims et al., 1997]. One of the most widely applied learning algorithms for text categorization is the Rocchio relevance feedback method [Rocchio, 1971] developed in information retrieval.
Reference: [Rocchio, 1971] <author> J. Rocchio. </author> <title> "Relevance Feedback in Information Retrieval", in Salton: The SMART Retrieval System: Experiments in Automatic Document Processing, </title> <booktitle> Chapter 14, </booktitle> <pages> pages 313-323, </pages> <publisher> Prentice-Hall, </publisher> <year> 1971. </year>
Reference-contexts: They are used to index news stories [Hayes et al., 1988] or guide a user's search on the World Wide Web [Joachims et al., 1997]. One of the most widely applied learning algorithms for text categorization is the Rocchio relevance feedback method <ref> [Rocchio, 1971] </ref> developed in information retrieval. Originally designed for optimizing queries from relevance feedback, the algorithm can be adapted to text categorization and routing problems. <p> The set of considered features (i.e. words) will be called F . 3.2 Learning Algorithms 3.2.1 TFIDF Classifier This type of classifier is based on the relevance feedback algorithm originally proposed by Rocchio <ref> [Rocchio, 1971] </ref> for the vector space retrieval model [Salton, 1991]. Due to its heuristic components, there are a number of similar algorithms corresponding to the particular choice of those heuristics. The three main design choices are * the word weighting method * the document length normalization * the similarity measure.
Reference: [Salton, 1991] <author> G. Salton, </author> <title> "Developments in Automatic Text Retrieval", </title> <journal> Science, </journal> <volume> Vol. 253, </volume> <pages> pages 974-979, </pages> <year> 1991. </year>
Reference-contexts: The set of considered features (i.e. words) will be called F . 3.2 Learning Algorithms 3.2.1 TFIDF Classifier This type of classifier is based on the relevance feedback algorithm originally proposed by Rocchio [Rocchio, 1971] for the vector space retrieval model <ref> [Salton, 1991] </ref>. Due to its heuristic components, there are a number of similar algorithms corresponding to the particular choice of those heuristics. The three main design choices are * the word weighting method * the document length normalization * the similarity measure. <p> Each element d (i) represents a distinct word w i . d (i) for a document d is calculated as a combination of the statistics T F (w i ; d) and DF (w i ) <ref> [Salton, 1991] </ref>. The term frequency T F (w i ; d) is the number of times word w i occurs in document d and the document frequency DF (w i ) is the number of documents in which word w i occurs at least once.
Reference: [Salton, Buckley, 1988] <author> G. Salton, C. Buckley, </author> <title> "Term Weighting Approaches in Automatic Text Retrieval", </title> <booktitle> Information Processing and Management, </booktitle> <volume> Vol. 24, No. 5, </volume> <pages> pages 513-523, </pages> <year> 1988. </year>
Reference-contexts: The major heuristic component of the Rocchio algorithm is the TFIDF (term frequency / inverse document frequency) <ref> [Salton, Buckley, 1988] </ref> word weighting scheme. Different flavors of this heuristic lead to a multitude of different algorithms. Due to this heuristic this class of algorithms will be called TFIDF classifiers in the following. A more theoretically founded approach to text categorization provide naive Bayes classifiers. <p> Due to its heuristic components, there are a number of similar algorithms corresponding to the particular choice of those heuristics. The three main design choices are * the word weighting method * the document length normalization * the similarity measure. An overview of some heuristics is given in <ref> [Salton, Buckley, 1988] </ref>. In the following the most popular combination will be used (known as "tfc"): "tf" word weights [Salton, Buckley, 1988], document length normalization using Euclidian vector length and cosine similarity. <p> The three main design choices are * the word weighting method * the document length normalization * the similarity measure. An overview of some heuristics is given in <ref> [Salton, Buckley, 1988] </ref>. In the following the most popular combination will be used (known as "tfc"): "tf" word weights [Salton, Buckley, 1988], document length normalization using Euclidian vector length and cosine similarity. Originally developed for information retrieval, the algorithm returns a ranking of documents without providing a threshold to define a decision rule for class membership. Therefore the algorithm has to be adapted to be used for text categorization.
Reference: [Vapnik, 1982] <author> V. Vapnik, </author> <title> "Estimation of Dependencies Based on Empirical Data", </title> <publisher> Springer, </publisher> <year> 1982. </year>
Reference-contexts: This estimator, which is often called the Laplace estimator, is suggested in <ref> [Vapnik, 1982] </ref> (pages 54-55). It assumes that the observation of each word is a priori equally likely.
Reference: [Wang et al., 1992] <author> Z. Wang, S. Wong, Y. Yao, </author> <title> "An Analysis of Vector Space Models Based on Computational Geometry", </title> <booktitle> International ACM SIGIR Conference, </booktitle> <year> 1992. </year>
Reference: [Wong, Yao, 1989] <author> S. Wong, Y. Yao, </author> <title> "A Note on Inverse Document Frequency Weighting Scheme", </title> <type> Technical Report 89-990, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1989. </year>
Reference-contexts: Other researchers have already proposed theoretical interpretations of the vector space retrieval model [Bookstein, 1982][Wang et al., 1992] and the TFIDF word weighting scheme <ref> [Wong, Yao, 1989] </ref> [Wu, Salton, 1981].
Reference: [Wu, Salton, 1981] <author> H. Wu, G. Salton, </author> <title> "A Comparison of Search Term Weighting: Term Relevance vs. Inverse Document Frequency", </title> <type> Technical Report 81-457, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1981. </year>
Reference-contexts: Other researchers have already proposed theoretical interpretations of the vector space retrieval model [Bookstein, 1982][Wang et al., 1992] and the TFIDF word weighting scheme [Wong, Yao, 1989] <ref> [Wu, Salton, 1981] </ref>.
References-found: 14

