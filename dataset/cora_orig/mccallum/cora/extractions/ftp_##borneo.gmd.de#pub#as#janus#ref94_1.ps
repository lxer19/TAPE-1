URL: ftp://borneo.gmd.de/pub/as/janus/ref94_1.ps
Refering-URL: http://borneo.gmd.de/AS/janus/publi/publi.html
Root-URL: 
Title: Data Exploration with Reflective Adaptive Models  
Author: Uwe Beyer Frank Smieja 
Date: 22, 1996, 193-211  
Note: Report number: 1994/1 Computational Statistics and Data Analysis  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> P. Bessiere, J-M Ahuactzin, E-G Albi, and E. Mazer. </author> <title> The Ariadne's clew algorithm: Global planning with local methods. </title> <booktitle> In IEEE-IROS'93 Conference (Intelligent Robots and Systems), </booktitle> <address> Yokohama, Japan, </address> <year> 1993. </year>
Reference-contexts: Exploration has already been demonstrated in adaptive models: in robot control [14] [16], for vehicles coming to terms with a changing environment <ref> [1] </ref>, for automata employing behaviors [6] [8] [12], and in the learning of functions [17]. It has also been handled in [15] in the application of intelligent control. Our aim in this paper is to examine reflective exploration as an adaptive property, and to outline its possible advantages and limitations.
Reference: [2] <author> U. Beyer and F. J. Smieja. </author> <title> Quantitative aspects of data-driven information processing. </title> <type> Technical Report 732, </type> <institution> GMD German National Research Center for Information Technology, </institution> <address> Sankt Augustin, Germany, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: A model constructed using exploration similarly depends on yet more parameters. Furthermore, it is unreasonable to expect a universal method for performing exploration. Everything is highly dependent on the system to be modeled, and the assumptions made in the modeling procedure [7] <ref> [2] </ref>. We therefore focus on a particular example to test exploration, and to illustrate the basic ideas. For visualization purposes the example is taken to be a simple 2-D to 1-D mapping. In the notation of section 1, p = 2; q = 1.
Reference: [3] <author> U. Beyer and F. J. Smieja. </author> <title> Learning from examples, agent teams and the concept of reflection. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 10(3) </volume> <pages> 251-272, </pages> <year> 1996. </year>
Reference-contexts: In order for this to be a valid assumption, the set L needs to be appropriately chosen. The adaptive possibilities open for the model lie in altering its internal structure (i.e. the appearance and method of construction of f L <ref> [3] </ref>) and in choosing 1 How similar depends very much on the system being modeled. If the sample is randomly chosen with replacement using probability distribution p (x), it will be statistically the fairest representation of a system described by this probability function. <p> They are typically used when information availability is low, i.e. when statistical models are invalid. In principle there is no reason why the two forms, which are effectively extremes, cannot be used in a cooperative manner. In practice however, as was discussed in <ref> [3] </ref> and currently forms a central theme in data-driven information processing, the combination of two or more such different models presents major difficulties. <p> For a problem specified by a finite data set this is defined as the error reached when the model is constructed using all observable data. 2 For a problem that can only be specified by an infinite learning set it is defined asymptoti cally (see <ref> [3] </ref>). The purpose of exploration is to turn an open system into a closed system as quickly as possible. Thus, if only 10 data points are theoretically necessary in order to define the system completely, it does in no way mean that 10 randomly chosen data points will be sufficient. <p> infinite number of data points, then for real world problems we postulate that for any exploration procedure lim fl fl fi T (f 1 L (t) ) fl This says that it becomes ever more insignificant which of the data points is learned next, as t ! 1 (see also <ref> [3] </ref>). 2.3 Statistical selective sampling me thods Sampling methods have been discussed in [5] [4] [11]. We follow the method used in [10], which we term "Bayesian statistical sampling". <p> In this respect it does not differ from the statistical methods. However, non-statistical reflective models are distinguished in that they possess particular reflective functions which are used to make decisions at any time in the adaptation. These functions also adapt as the model adapts [13] <ref> [3] </ref>. For exploration we denote the reflective function I. <p> Whatever is chosen will inevitably have its own associated degree of arbitrariness. Preferable would be adaptive methods that control the choice of exploration, or an exploration team <ref> [3] </ref>. Unfortunately this would require at least two stages of learning: one for the individual methods and one for the team. Again, depending on the current application and the ti-mescale of the system, it may not be possible to constrain the incremental nature of the model in this way. <p> Thus large planes (relative to ") cannot be approximated with only 3 points. 3.2 The test problem The accuracy of a model is dependent on a large number of parameters <ref> [3] </ref>. A model constructed using exploration similarly depends on yet more parameters. Furthermore, it is unreasonable to expect a universal method for performing exploration. Everything is highly dependent on the system to be modeled, and the assumptions made in the modeling procedure [7] [2].
Reference: [4] <author> D. Cohn, L. Atlas, and R. Ladner. </author> <title> Training connectionist networks with queries and selective sampling. </title> <booktitle> In Advances in Neural Information Processing Systems 2, </booktitle> <address> San Mateo, CA, </address> <year> 1990. </year> <note> Morgen Kaufmann. 14 Beyer and Smieja </note>
Reference-contexts: any exploration procedure lim fl fl fi T (f 1 L (t) ) fl This says that it becomes ever more insignificant which of the data points is learned next, as t ! 1 (see also [3]). 2.3 Statistical selective sampling me thods Sampling methods have been discussed in [5] <ref> [4] </ref> [11]. We follow the method used in [10], which we term "Bayesian statistical sampling". It is based on the following procedure, where it is assumed there exists a distribution of parameterized statistical models of the system, p (yjx; w), conditional on the appropriateness of the set of parameters w.
Reference: [5] <author> V. V. Feodorov. </author> <title> Theory of optimal experiments. </title> <publisher> Academic, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: for any exploration procedure lim fl fl fi T (f 1 L (t) ) fl This says that it becomes ever more insignificant which of the data points is learned next, as t ! 1 (see also [3]). 2.3 Statistical selective sampling me thods Sampling methods have been discussed in <ref> [5] </ref> [4] [11]. We follow the method used in [10], which we term "Bayesian statistical sampling".
Reference: [6] <author> L. M. Gabora and P. W. </author> <title> Colgan. A model of the mechanisms underlying exploratory behaviour. </title> <editor> In Jean-Arcady Meyer and Ste-wart W. Wilson, editors, </editor> <booktitle> From animals to animats, </booktitle> <pages> pages 475-484. </pages> <booktitle> First International Conference on Simulation of Adaptive Behavior, </booktitle> <year> 1990. </year>
Reference-contexts: Exploration has already been demonstrated in adaptive models: in robot control [14] [16], for vehicles coming to terms with a changing environment [1], for automata employing behaviors <ref> [6] </ref> [8] [12], and in the learning of functions [17]. It has also been handled in [15] in the application of intelligent control. Our aim in this paper is to examine reflective exploration as an adaptive property, and to outline its possible advantages and limitations.
Reference: [7] <author> S. Geman, E. Bienenstock, and R. Doursat. </author> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: A model constructed using exploration similarly depends on yet more parameters. Furthermore, it is unreasonable to expect a universal method for performing exploration. Everything is highly dependent on the system to be modeled, and the assumptions made in the modeling procedure <ref> [7] </ref> [2]. We therefore focus on a particular example to test exploration, and to illustrate the basic ideas. For visualization purposes the example is taken to be a simple 2-D to 1-D mapping. In the notation of section 1, p = 2; q = 1.
Reference: [8] <author> M. C. Mozer and J. Bachrach. </author> <title> Discovering the structure of a reactive environment by exploration. </title> <type> Technical Report CU-CS-451-89, </type> <institution> Dept. of Computer Science, University of Colorado, Boulder, </institution> <month> November </month> <year> 1989. </year>
Reference-contexts: Exploration has already been demonstrated in adaptive models: in robot control [14] [16], for vehicles coming to terms with a changing environment [1], for automata employing behaviors [6] <ref> [8] </ref> [12], and in the learning of functions [17]. It has also been handled in [15] in the application of intelligent control. Our aim in this paper is to examine reflective exploration as an adaptive property, and to outline its possible advantages and limitations.
Reference: [9] <author> Stephen Omohundro. </author> <title> Geometric learning algorithms. </title> <type> Technical Report TR-89-041, </type> <institution> Berkeley, </institution> <year> 1989. </year>
Reference-contexts: These take the form of making assumptions about the problem domain and the behavior of the function to be learned. For our experiments with exploration we made the following assumptions (which are also integral to "Geometrical reasoning" <ref> [9] </ref>). 6 Beyer and Smieja * There exists a metric d (x 1 ; x 2 ) ! &lt; that measures the distance between two points in the input space. * Abbreviate the approximation error of data point (x; y), ffi (y; f (x)), by ffi (x).
Reference: [10] <author> G. Paa and J. Kindermann. </author> <title> Reflective query learning with neural networks. </title> <type> Technical report, </type> <institution> GMD German National Research Center for Information Technology, </institution> <address> Sankt Augustin, Germany, </address> <year> 1994. </year>
Reference-contexts: We follow the method used in <ref> [10] </ref>, which we term "Bayesian statistical sampling". It is based on the following procedure, where it is assumed there exists a distribution of parameterized statistical models of the system, p (yjx; w), conditional on the appropriateness of the set of parameters w.
Reference: [11] <author> M. Plutowski and H. White. </author> <title> Selecting concise training sets from clean data. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4(2) </volume> <pages> 305-318, </pages> <year> 1993. </year>
Reference-contexts: exploration procedure lim fl fl fi T (f 1 L (t) ) fl This says that it becomes ever more insignificant which of the data points is learned next, as t ! 1 (see also [3]). 2.3 Statistical selective sampling me thods Sampling methods have been discussed in [5] [4] <ref> [11] </ref>. We follow the method used in [10], which we term "Bayesian statistical sampling". It is based on the following procedure, where it is assumed there exists a distribution of parameterized statistical models of the system, p (yjx; w), conditional on the appropriateness of the set of parameters w.
Reference: [12] <author> Bernd Schluter. </author> <title> A cybernetic control model from ethology for adaptive coordination of robot behaviors. </title> <booktitle> In Proceedings of the SPIE Adaptive and Learning Systems Conference, </booktitle> <address> 20-24 April 1992, Orlando, Fl, </address> <year> 1992. </year> <pages> SPIE, </pages> ?? 
Reference-contexts: Exploration has already been demonstrated in adaptive models: in robot control [14] [16], for vehicles coming to terms with a changing environment [1], for automata employing behaviors [6] [8] <ref> [12] </ref>, and in the learning of functions [17]. It has also been handled in [15] in the application of intelligent control. Our aim in this paper is to examine reflective exploration as an adaptive property, and to outline its possible advantages and limitations.
Reference: [13] <author> F. J. Smieja. </author> <title> Multiple network systems (MI-NOS) modules: Task division and module discrimination. </title> <booktitle> In Proceedings of the 8th AISB conference on Artificial Intelligence, </booktitle> <address> Leeds, </address> <month> 16-19 April, </month> <year> 1991, 1991. </year> <note> Also available as GMD technical report 638. </note>
Reference-contexts: In this respect it does not differ from the statistical methods. However, non-statistical reflective models are distinguished in that they possess particular reflective functions which are used to make decisions at any time in the adaptation. These functions also adapt as the model adapts <ref> [13] </ref> [3]. For exploration we denote the reflective function I.
Reference: [14] <author> S. Thrun and K. Moller. </author> <title> Active exploration in dynamic environments. </title> <booktitle> In Proceedings of NIPS-4, </booktitle> <address> Denver, Colorado, </address> <year> 1992. </year> <note> to appear. </note>
Reference-contexts: In practice however, as was discussed in [3] and currently forms a central theme in data-driven information processing, the combination of two or more such different models presents major difficulties. Exploration has already been demonstrated in adaptive models: in robot control <ref> [14] </ref> [16], for vehicles coming to terms with a changing environment [1], for automata employing behaviors [6] [8] [12], and in the learning of functions [17]. It has also been handled in [15] in the application of intelligent control.
Reference: [15] <author> S. B. Thrun. </author> <title> The role of exploration in learning control with neural networks. </title> <editor> In D. A. White and D. A. Sofge, editors, </editor> <title> Handbook of Intelligent Control: Neural, Fuzzy and Adaptive Approaches. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> Florence, Kentucky, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: Exploration has already been demonstrated in adaptive models: in robot control [14] [16], for vehicles coming to terms with a changing environment [1], for automata employing behaviors [6] [8] [12], and in the learning of functions [17]. It has also been handled in <ref> [15] </ref> in the application of intelligent control. Our aim in this paper is to examine reflective exploration as an adaptive property, and to outline its possible advantages and limitations.
Reference: [16] <author> F. Weber and A. Linden. </author> <title> Neural networks for reflective exploration. </title> <booktitle> In Proceedings of the 2nd International Conference on Automation, Robotics and Computer Vision, </booktitle> <address> Singapore, pages INV-8.1.1-INV-8.1.4, </address> <year> 1992. </year>
Reference-contexts: In practice however, as was discussed in [3] and currently forms a central theme in data-driven information processing, the combination of two or more such different models presents major difficulties. Exploration has already been demonstrated in adaptive models: in robot control [14] <ref> [16] </ref>, for vehicles coming to terms with a changing environment [1], for automata employing behaviors [6] [8] [12], and in the learning of functions [17]. It has also been handled in [15] in the application of intelligent control.
Reference: [17] <author> Byoung-Tak Zhang and Gerd Veenker. </author> <title> Neural networks that teach themselves through genetic discovery of novel examples. </title> <booktitle> In International Joint Conference on Neural Networks (IJCNN-91), </booktitle> <volume> Vol 1, </volume> <pages> pages 690-695. </pages> <publisher> IEEE and INNS, </publisher> <year> 1991. </year>
Reference-contexts: Exploration has already been demonstrated in adaptive models: in robot control [14] [16], for vehicles coming to terms with a changing environment [1], for automata employing behaviors [6] [8] [12], and in the learning of functions <ref> [17] </ref>. It has also been handled in [15] in the application of intelligent control. Our aim in this paper is to examine reflective exploration as an adaptive property, and to outline its possible advantages and limitations.
References-found: 17

