URL: ftp://ftp.cs.rochester.edu/pub/u/nelson/1996_nayar_chapter.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/nelson/papers.html
Root-URL: 
Title: 1 Memorization Learning for Object Recognition  
Author: Randal C. Nelson 
Address: Rochester  
Affiliation: University of  
Abstract: We consider the fundamental complexity of intelligent systems, and argue that some form of learning is essential in order to acquire the amount of information necessary to specify such a system. In this view, learning is essentially a means of acquiring large amounts of structured information by relatively simple recoding of information flowing down high-bandwidth channels (the senses) from a pre-existing source of structured information (the world). This chapter considers the case of visual learning. We argue that, of the known methods of computational learning, the only technique that can effectively assemble the very large amount of information needed to specify visual intelligence amounts to the construction of an indexed memory. We show how an associative memory organization coupled with the use of robust, semi-invariant features can lead to reliable 3-D object recognition.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Aloimonos, A. Bandyopadhyay, and I. Weiss. </author> <title> Active vision. </title> <booktitle> In First International Conference on Computer Vision, </booktitle> <pages> pages 35-54, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The architecture works quite well for implementing low-level behaviors such as walking using simple sensors; however it now seems clear that higher level behaviors and more sophisticated sensory modalities such as vision, require some form of representation. Recent work on active vision <ref> [1, 3] </ref> has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information.
Reference: [2] <author> Yiannis Aloimonos. </author> <title> Active Perception. </title> <publisher> Lawrence Erlbaum, </publisher> <year> 1993. </year>
Reference-contexts: In other words, intelligence does not exist as a mathematical abstraction, but only embodied in a functioning mechanism. This might seem either an obvious or a purely philosophical point, but it led to the development of what is termed the behavioral vision paradigm <ref> [3, 2, 17] </ref> where the notion of functional behavior is used as a structuring element for creating visual systems. The particular statement in this case, is that vision (being a form of intelligence) cannot be considered independent of its embodiment in a behaving system. 1.1.
Reference: [3] <author> Dana H. Ballard and Christopher M. Brown. </author> <title> Principles of animate vision. </title> <journal> CVGIP, </journal> <volume> 56(1) </volume> <pages> 3-21, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In other words, intelligence does not exist as a mathematical abstraction, but only embodied in a functioning mechanism. This might seem either an obvious or a purely philosophical point, but it led to the development of what is termed the behavioral vision paradigm <ref> [3, 2, 17] </ref> where the notion of functional behavior is used as a structuring element for creating visual systems. The particular statement in this case, is that vision (being a form of intelligence) cannot be considered independent of its embodiment in a behaving system. 1.1. <p> The architecture works quite well for implementing low-level behaviors such as walking using simple sensors; however it now seems clear that higher level behaviors and more sophisticated sensory modalities such as vision, require some form of representation. Recent work on active vision <ref> [1, 3] </ref> has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information.
Reference: [4] <author> Aaron F. Bobick and Robert C. Bolles. </author> <title> Representation space: An approach to the integration of visual information. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 492-499, </pages> <address> San Diego CA, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: There is little work on direct acquisition of 3-D representation from visual exploration, or on implicit representation of 3-D structure, though there is some research on world and object representations that can be refined during navigation by a mobile robot <ref> [4] </ref>. A rigid body representation that is implicitly encoded in linear combinations of three views, and thus is in principle automatically acquirable, is described in [24], but seems not to have been implemented.
Reference: [5] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2 </volume> <pages> 14-23, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: What distinguishes the recent interest in behavioral vision from the historical efforts is the commitment to establish it within a computational framework. The resurgence of interest in the behavioral aspects of intelligence is perhaps most clearly illustrated by the subsumption architecture proposed by Brooks <ref> [5] </ref>. This paradigm is rather rigorously Gibsonian in that it explicitly disavows the notion of internal representation, relying instead on purely reactive strategies.
Reference: [6] <author> R. Brunelli and Thomaso Poggio. </author> <title> Face recognition: Features versus templates. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 15(10) </volume> <pages> 1042-1062, </pages> <year> 1993. </year>
Reference-contexts: Three-dimensional wireframes can be recognized by a neural net that effectively memorizes and interpolates between several training views [20]. Frontal face recognition using a variant of template matching can outperform feature-based methods <ref> [6] </ref>. Murase and Nayar [16] find the major principal components of an image dataset, and use the projections of unknown images onto these as indices into a recognition memory.
Reference: [7] <author> D. J. Coombs and C. M. Brown. </author> <title> Real-time binocular smooth pursuit. </title> <journal> International Journal of Computer Vision, </journal> <pages> pages 147 - 164, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Recent work on active vision [1, 3] has focussed on how directed control of the sensor characteristics (e.g. eyes, or tactile receptors) can simplify the process of obtaining the desired information. Most work to date has focussed on the effect of the ability to move the sensor <ref> [7] </ref> or dynamically change an internal focus of attention [22, 23]. Work on purposive or behavioral vision [17] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature.
Reference: [8] <author> F.Stein and Gerard Medioni. </author> <title> Efficient 2-dimensional object recgnition. </title> <booktitle> In Proc. ICPR, </booktitle> <pages> pages 13-17, </pages> <address> Atlantic City NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Work on automatic acquisition of 2-D representation has been more successful, since all the information is present (e.g. <ref> [8] </ref>) We expect these techniques to be useful here, since we essentially propose utilizing a collection of augmented 2-D representations. 8 NELSON Some recent work has a memory-based flavor. <p> This use of segment chains is somewhat similar to the structural indexing of Stein and Medioni <ref> [8] </ref>. Very recently, we have also run tests using key features based on edge orientation templates normalized by segmented curves. The performance of the system using these keys is considerably superior to that using segment groups, and can be applied to curved objects.
Reference: [9] <author> J. J. Gibson. </author> <title> The Perception of the Visual World. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, </address> <year> 1950. </year>
Reference-contexts: Previous Work Addressing vision from the standpoint of behavior and memory is not a new idea. In fact, prior to the development of electronic computers, behavioral description was the only avenue available for investigating the phenomenon of vision. This precomputational work is epitomized by Gibson (e.g., <ref> [9] </ref>) who advanced 1. MEMORIZATION LEARNING 7 the central postulate that vision was essentially a modality that allowed biological systems to react to invariants in the structure of the world. What Gibson overlooked, however, was the complexity of computing the visual invariants used as primitives.
Reference: [10] <author> W. E. L. Grimson and Daniel P. Huttenlocher. </author> <title> On the sensitivity of geometric hashing. </title> <booktitle> In 3rd International Conference on Computer Vision, </booktitle> <pages> pages 334-338, </pages> <year> 1990. </year> <note> 1. MEMORIZATION LEARNING 21 </note>
Reference-contexts: Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [13, 12, 11]. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various perturbations determined <ref> [10] </ref>. Most model acquisition strategies have focussed on CAD-like techniques. The models are either entered by hand, or via a geometric reconstruction.
Reference: [11] <author> Daniel P. Huttenlocher and Shimon Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: Work on purposive or behavioral vision [17] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are <ref> [13, 12, 11] </ref>. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various perturbations determined [10]. Most model acquisition strategies have focussed on CAD-like techniques. The models are either entered by hand, or via a geometric reconstruction.
Reference: [12] <author> Y. Lamdan and H. J. Wolfson. </author> <title> Geometric hashing: A general and efficient model-based recognition scheme. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 238-249, </pages> <address> Tampa FL, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: Work on purposive or behavioral vision [17] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are <ref> [13, 12, 11] </ref>. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various perturbations determined [10]. Most model acquisition strategies have focussed on CAD-like techniques. The models are either entered by hand, or via a geometric reconstruction.
Reference: [13] <author> David G. Lowe. </author> <title> Three-dimensional object recognition from single two-dimensional images. </title> <journal> Artificial Intelligence, </journal> <volume> 31 </volume> <pages> 355-395, </pages> <year> 1987. </year>
Reference-contexts: Work on purposive or behavioral vision [17] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are <ref> [13, 12, 11] </ref>. The indexing techniques used in several of these systems have been recently analyzed, and the sensitivity of the techniques to various perturbations determined [10]. Most model acquisition strategies have focussed on CAD-like techniques. The models are either entered by hand, or via a geometric reconstruction.
Reference: [14] <author> David C. Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <year> 1982. </year>
Reference-contexts: What Gibson overlooked, however, was the complexity of computing the visual invariants used as primitives. The first influential theory of computational vision, due to Marr <ref> [14] </ref>, essentially defined vision as the problem of determining what is where, and focussed almost entirely on the computational and representational aspects of the problem. Marr's theory of vision essentially described a staged computational architecture leading from image, to primal sketch, to 2-1/2 D sketch to invariant object centered descriptions.
Reference: [15] <author> Bartlett Mel. </author> <title> Object classification with high-dimensional vectors. </title> <booktitle> In Proc. Telluride Workshop on Neuromorphic Engineering, </booktitle> <address> Telluride CO, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Rao and Ballard [21] describe an approach based on the memorization of the responses of a set of steerable filters centered on, or located at key points of an object. Mel <ref> [15] </ref> takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues. Three-dimensional wireframes can be recognized by a neural net that effectively memorizes and interpolates between several training views [20]. Frontal face recognition using a variant of template matching can outperform feature-based methods [6].
Reference: [16] <author> Hiroshi Murase and Shree K. Nayar. </author> <title> Learning and recognition of 3d objects from appearance. </title> <booktitle> In Proc. IEEE Workshop on Qualitative Vision, </booktitle> <pages> pages 39-50, </pages> <year> 1993. </year>
Reference-contexts: Three-dimensional wireframes can be recognized by a neural net that effectively memorizes and interpolates between several training views [20]. Frontal face recognition using a variant of template matching can outperform feature-based methods [6]. Murase and Nayar <ref> [16] </ref> find the major principal components of an image dataset, and use the projections of unknown images onto these as indices into a recognition memory.
Reference: [17] <author> Randal. C. Nelson. </author> <title> Vision as intelligent behavior: Research in machine vision at the university of rochester. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(1) </volume> <pages> 5-9, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: In other words, intelligence does not exist as a mathematical abstraction, but only embodied in a functioning mechanism. This might seem either an obvious or a purely philosophical point, but it led to the development of what is termed the behavioral vision paradigm <ref> [3, 2, 17] </ref> where the notion of functional behavior is used as a structuring element for creating visual systems. The particular statement in this case, is that vision (being a form of intelligence) cannot be considered independent of its embodiment in a behaving system. 1.1. <p> Most work to date has focussed on the effect of the ability to move the sensor [7] or dynamically change an internal focus of attention [22, 23]. Work on purposive or behavioral vision <ref> [17] </ref> attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [13, 12, 11].
Reference: [18] <author> Randal. C. Nelson. </author> <title> Finding line segments by stick growing. </title> <journal> IEEE Trans PAMI, </journal> <volume> 16(5) </volume> <pages> 519-523, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Experiments Using the principles described above, we implemented a memory-based recognition system for polyhedral objects using 3-chains, and recently curve-keyed edge templates, as the basic keys. Component segments were extracted using a stick-growing method developed recently at Rochester <ref> [18] </ref>, and organized into chains. For objects entered into the database, the best 10 chains were selected to represent the object. The threshold on the distance metric between chains was adjusted so 1.
Reference: [19] <author> Roger Penrose. </author> <title> The Emperor's New Mind: Concerning Computation, Minds, and the Laws of Nature. </title> <publisher> Oxford University Press, </publisher> <year> 1989. </year>
Reference-contexts: Thus was born the field of artificial intelligence. Its creed was that the essence of intelligence is some sort of information processing; more precisely, that the primary complexity in an intelligent mechanism can be modeled as and implemented with an information processing system. (This position has been challenged, e.g. <ref> [19] </ref> but no persuasive alternatives have been proposed.) As researchers attempted to emulate intelligent processes, it rapidly became clear that the information processing associated with intelligent abilities was extremely complex compared to the sort of processing that had proved useful for other tasks, such as numerical modeling.
Reference: [20] <author> Thomaso Poggio and Shimon Edelman. </author> <title> A network that learns to recognize three-dimensional objects. </title> <journal> Nature, </journal> <volume> 343 </volume> <pages> 263-266, </pages> <year> 1990. </year>
Reference-contexts: Mel [15] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues. Three-dimensional wireframes can be recognized by a neural net that effectively memorizes and interpolates between several training views <ref> [20] </ref>. Frontal face recognition using a variant of template matching can outperform feature-based methods [6]. Murase and Nayar [16] find the major principal components of an image dataset, and use the projections of unknown images onto these as indices into a recognition memory.
Reference: [21] <author> Rajesh P.N. Rao. </author> <title> Top-down gaze targeting for space-variant active vision. </title> <booktitle> In Proc. ARPA Image Understanding Workshop, </booktitle> <pages> pages 1049-1058, </pages> <address> Monterey CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Rao and Ballard <ref> [21] </ref> describe an approach based on the memorization of the responses of a set of steerable filters centered on, or located at key points of an object. Mel [15] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues.
Reference: [22] <author> R. D. Rimey and C. M. Brown. </author> <title> Controlling eye movements with hidden markov models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(1) </volume> <pages> 47-66, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Most work to date has focussed on the effect of the ability to move the sensor [7] or dynamically change an internal focus of attention <ref> [22, 23] </ref>. Work on purposive or behavioral vision [17] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [13, 12, 11].
Reference: [23] <author> R. D. Rimey and C. M. Brown. </author> <title> Control of selective perception using bayes nets and decision theory. </title> <journal> International Journal of Computer Vision, </journal> <volume> 12(2,3):173-208, </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: Most work to date has focussed on the effect of the ability to move the sensor [7] or dynamically change an internal focus of attention <ref> [22, 23] </ref>. Work on purposive or behavioral vision [17] attempts to take the context of the task explicitly into account. Much previous work in 3-D vision has focussed on model-based systems, on which there is a large literature. Notable recent examples are [13, 12, 11].
Reference: [24] <author> Shimon Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 13(10), </volume> <year> 1991. </year> <title> 22 NELSON Acknowledgements This material is based on work supported by the National Science Foundation under Grants numbered CDA-8822724 and IRI-9202816. The government has certain rights in this material. </title>
Reference-contexts: A rigid body representation that is implicitly encoded in linear combinations of three views, and thus is in principle automatically acquirable, is described in <ref> [24] </ref>, but seems not to have been implemented.
References-found: 24

