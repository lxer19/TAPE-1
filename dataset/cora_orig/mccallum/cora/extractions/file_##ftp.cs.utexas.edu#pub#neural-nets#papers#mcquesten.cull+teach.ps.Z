URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/mcquesten.cull+teach.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: 
Email: paulmcq, risto-@cs.utexas.edu  
Title: Culling Teaching -1 Culling and Teaching in Neuro-evolution  
Author: Paul McQuesten and Risto Miikkulainen 
Address: Austin, TX 78712  
Affiliation: Department of Computer Science The University of Texas at Austin  
Note: To appear in Proc. 7 th Intl. Conf. on Genetic Algorithms (ICGA97), Morgan Kaufmann, San Francisco, CA.  
Abstract: The evolving population of neural nets contains information not only in terms of genes, but also in the collection of behaviors of the population members. Such information can be thought of as a kind of culture of the population. Two ways of exploiting that culture are explored in this paper: (1) Culling overlarge litters: Generate a large number of offspring with different crossovers, quickly evaluate them by comparing their performance to the population, and throw away those that appear poor. (2) Teaching: Use backpropagation to train offspring toward the performance of the population. Both techniques result in faster, more effective neuro-evolution, and they can be effectively combined, as is demonstrated on the inverted pendulum problem. Additional methods of cultural exploitation are possible and will be studied in future work. These results suggest that cultural exploitation is a powerful idea that allows leveraging several aspects of the genetic algorithm.
Abstract-found: 1
Intro-found: 1
Reference: <author> Ackley, David, and Michael Littman (1991). </author> <title> Interactions between Learning and Evolution. In Langton, C.G., </title> <address> C. </address>
Reference: <editor> Taylor, J.D.Farmer and S. Rasmussen, eds., </editor> <booktitle> Artificial Life II. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Redwood City, CA. </address>
Reference: <author> Barto, A.G., Richard S. Sutton, and Charles W. </author> <title> Anderson (1983). Neuronlike adaptive elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> SMC-13. </volume>
Reference-contexts: A teacher could remember significant problems, or remember the range of most frequent input parameters. Perhaps the capability for such significance analysis could be evolvable, along the lines of an Adaptive Critic <ref> (Barto, Sutton and Anderson 1983) </ref>. Several researchers have found it useful to change the syllabus over time, as in the Incremental Learning of Elman (1991) and (Gomez and Miikkulainen 1997), but that requires modifying the evaluation function.
Reference: <author> Braun, Heinrich and Peter Zagorski (1994). </author> <title> ENZO-M - A Hybrid Approach for Optimizing Neural Networks by Evolution and Learning. </title> <editor> In Y. Davidor, H-P.Schwefel, and R.Manner, eds. </editor> <title> Parallel Problem Solving from Nature: </title> <publisher> PPSN-III. Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Davis, L.D. </author> <year> (1991). </year> <title> Bit-climbing, representational bias, and test suite design. </title> <editor> In Belew, R.K. and L.B. Booker, eds, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufman, </publisher> <address> San Francisco. </address>
Reference: <author> Elman, Jeffrey L. </author> <year> (1991). </year> <title> Incremental Learning, or The Importance of Starting Small. </title> <booktitle> In Proceedings of the 13 th Annual Conference of the Cognitive Science Society. </booktitle> <publisher> Erlbaum, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> French, Robert M., </author> <title> and Adam Messinger (1995). Genes, Phenes and the Baldwin Effect: Learning and Evolution in a Simulated Population. </title> <editor> In Brooks, R.A. and P. Maes, eds., </editor> <booktitle> Proceedings of the Fourth International Workshop on the Synthesis and Simulation of Living Systems. </booktitle> <publisher> MIT Press, 1994 (Second Printing 1995). </publisher> <editor> Gomez, Faustino and Risto Miikkulainen (in press). </editor> <title> Incremental Evolution of Complex General Behavior. Adaptive Behavior, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <editor> Culling & Teaching -8--Hightower, Ron R., Stephanie Forrest, and Alan S. </editor> <title> Perelson (1995). The Evolution of Emergent Organization in Immune System Gene Libraries. </title> <editor> In L.J.Eshelman, ed., </editor> <booktitle> Sixth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco. </address>
Reference: <author> Hinton, Geoffrey E., and Steven J. </author> <title> Nowlan (1987). How Learning Can Guide Evolution. </title> <booktitle> Complex Systems 1, </booktitle> <pages> 495-502. </pages>
Reference: <author> Masters, </author> <title> Timothy (1993). Practical Neural Network Recipes in C++. </title> <publisher> Academic Press, </publisher> <address> San Diego. </address>
Reference: <author> Nolfi, Stefano, Jeffrey L. Elman, and Domenico Parisi (1994). </author> <title> Learning and evolution in neural networks. Adaptive Behavior 2 (1994): 5-28 Nolfi, Stefano, and Domenico Parisi (1994). Good teaching inputs do not correspond to desired responses in ecological neural networks. </title> <booktitle> Neural Processing Letters 1 no. </booktitle> <pages> 2 (11/94) pp. 1-4. </pages>
Reference: <author> Nolfi, Stefano, and Domenico Parisi (1995). </author> <title> Learning to adapt to changing environments in evolving neural networks. </title> <type> C.N.R.-Rome Technical Report 95-15. </type>
Reference: <author> Nordin, Peter and Wolfgang Banzhaf (1995). </author> <title> Complexity Compression and Evolution. </title> <editor> In In L.J.Eshelman, ed., </editor> <booktitle> Sixth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco. </address>
Reference: <author> Sebag, Michle, and Marc Schoenauer (1994). </author> <title> Controlling Crossover through Inductive Learning. </title> <editor> In Y.Davidor, H-P.Schwefel, and R.Manner, eds. </editor> <title> Parallel Problem Solving from Nature: </title> <publisher> PPSN-III. Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Whitley, Darrell, Stephen Dominic and Rajarshi Das (1991). </author> <title> Genetic Reinforcement Learning with Multilayer Neural Networks. </title> <note> In Belew, R.K. and L.B. </note>
Reference-contexts: To gain insight into crossovers operation, let us inspect the distribution with a standard GA. The task is the well-known control problem of the inverted pendulum. Fitness evaluations in this problem are very expensive, requiring thousands of simulation cycles. The equations for the simulated system are taken from <ref> (Whitley, Dominic and Das 1991) </ref>, and are reproduced in Appendix A for convenience. The fitness function is the total number of simulator steps until the pole exceeds -12, taken over all eleven initial conditions from (Whitley, Gruau and Pyeatt 1995).
Reference: <editor> Booker, eds., </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufman, </publisher> <address> San Francisco. </address>
Reference: <author> Whitley, Darrell, Frederic Gruau and Larry Pyeatt (1995). </author> <title> Cellular Encoding Applied to Neurocontrol. </title> <editor> In L.J.Eshelman, ed., </editor> <booktitle> Sixth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco. </address>
Reference-contexts: The equations for the simulated system are taken from (Whitley, Dominic and Das 1991), and are reproduced in Appendix A for convenience. The fitness function is the total number of simulator steps until the pole exceeds -12, taken over all eleven initial conditions from <ref> (Whitley, Gruau and Pyeatt 1995) </ref>. A pole-balance attempt is considered successful if the pole remains within limits for 1000 time steps, so a run is successful if a network with a score of 11,000 is found.
References-found: 17

