URL: ftp://thales.cs.umd.edu/pub/reports/iscp.ps
Refering-URL: ftp://thales.cs.umd.edu/pub/reports/Contents.html
Root-URL: 
Title: Invariant Subspaces and Capital Punishment (A Participatory Paper)  
Author: G. W. Stewart 
Address: College Park, MD 20742.  
Affiliation: Department of Computer Science and Institute for Physical Science and Technology, University of Maryland,  
Date: September 1987  
Pubnum: TR-1923  
Abstract: The notion of invariant subspaces is useful in a number of theoretical and practical applications. In this paper we give an elementary treatment of invariant subspaces that stresses their connection with simple eigenvalues and their eigenvectors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. H. Bartels and G. W. Stewart, </author> <title> "Algorithm 432: The Solution of the Matrix Equation AX BX = C," </title> <booktitle> Communications of the ACM 15 (1972) 820-826. </booktitle>
Reference-contexts: The proof in the general case is more difficult. One approach is to use Schur's theorem to reduce L 1 and L 2 to upper triangular matrices <ref> [1] </ref>. This results in a constructive algorithm for solving (3.2).
Reference: [2] <author> C. Davis and W. M. Kahan, </author> <title> "The Rotation of Eigenvectors by a Perturbation, III," </title> <note> SIAM J. Numer. Anal. 7 (1970) 1-46. Invariant Subspaces 13 </note>
Reference-contexts: A treatment of some of the problems is given in [3]. A standard reference for perturbation theory is Kato's comprehensive book [6]. The passage from first order expansions to rigorous bounds has been treated by the author [10,11]. Davis and Kahan <ref> [2] </ref> have developed an elegant perturbation theory for Hermitian matrices (see also [8]). People who calculate a invariant subspaces usually end up with matrices X 1 and L 1 for which R = AX 1 X 1 L 1 is not zero but is merely small.
Reference: [3] <author> I. Gohberg, P. Lancaster, and L. Rodman, </author> <title> Invariant Subspaces of Matrices with Applications, </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: However, there is much more. The algebraic theory of invariant subspaces becomes quite complicated when the subspace is not simple. For example, the subspace may fail to have a complementary invariant subspace. A treatment of some of the problems is given in <ref> [3] </ref>. A standard reference for perturbation theory is Kato's comprehensive book [6]. The passage from first order expansions to rigorous bounds has been treated by the author [10,11]. Davis and Kahan [2] have developed an elegant perturbation theory for Hermitian matrices (see also [8]).
Reference: [4] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1983. </year>
Reference-contexts: For example if T is an operator, then kTk = max kTP k: For more on norms see <ref> [4] </ref> or [12]. fl Department of Computer Science and Institute for Physical Science and Technology, University of Maryland, College Park, 20742. <p> See <ref> [4] </ref> or [12]. 4 The above reduction can be repeated on L 2 and so on. When an eigenvector is used at each stage, the result is that A is reduced to upper triangular form by a unitary similarity transformation|a very useful decomposition due to Schur [9]. <p> Continuing in the same manner, we get a variant of the Schur decomposition in which all the complex eigenvalues are contained in 2 fi 2 blocks on the diagonal, a form computed by the widely used QR algorithm <ref> [4, Ch. 7] </ref>. Invariant Subspaces 5 We are not quite finished, since it is possible that (3.2) has no solution or more than one solution.
Reference: [5] <author> W. Kahan, B. N. Parlett, and E. Jiang, </author> <title> "Residual Bounds on Approximate Eigensystems of Nonnormal Matrices," </title> <journal> SIAM J. Numer. Anal. </journal> <month> 19 </month> <year> (1982) </year> <month> 470-484. </month>
Reference-contexts: In many cases it is sufficient to know that there is a small matrix E such that the space spanned by X 1 is an invariant subspace of A + E. An exhaustive treatment of this question is given in <ref> [5] </ref>. 9 Acknowledgements I would like to thank my friends and colleagues at Fudan University in Shanghai for encouraging me to write this material down and especially Professor Jiang Erxiong, who made made my visit there possible.
Reference: [6] <author> T. Kato, </author> <title> Perturbation Theory for Linear Operators, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: The most common is w = ~x 1 , which amounts to imposing the condition k~x 1 k = 1. The role of normalization in the perturbation theory for eigenvectors is treated in detail in [7]. 9 This result is not trivial to establish. See for example <ref> [6] </ref>. <p> The algebraic theory of invariant subspaces becomes quite complicated when the subspace is not simple. For example, the subspace may fail to have a complementary invariant subspace. A treatment of some of the problems is given in [3]. A standard reference for perturbation theory is Kato's comprehensive book <ref> [6] </ref>. The passage from first order expansions to rigorous bounds has been treated by the author [10,11]. Davis and Kahan [2] have developed an elegant perturbation theory for Hermitian matrices (see also [8]).
Reference: [7] <author> C. Meyer and G. W. Stewart, </author> <title> "Derivatives and Perturbations of Eigenvectors," </title> <note> to appear in Lin. Alg. Appl. </note>
Reference-contexts: The most common is w = ~x 1 , which amounts to imposing the condition k~x 1 k = 1. The role of normalization in the perturbation theory for eigenvectors is treated in detail in <ref> [7] </ref>. 9 This result is not trivial to establish. See for example [6].
Reference: [8] <author> B. N. </author> <title> Parlet The Symmetric Eigenvalue Problem, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1980. </year>
Reference-contexts: A standard reference for perturbation theory is Kato's comprehensive book [6]. The passage from first order expansions to rigorous bounds has been treated by the author [10,11]. Davis and Kahan [2] have developed an elegant perturbation theory for Hermitian matrices (see also <ref> [8] </ref>). People who calculate a invariant subspaces usually end up with matrices X 1 and L 1 for which R = AX 1 X 1 L 1 is not zero but is merely small.
Reference: [9] <author> I. </author> <title> Schur, " Uber die charakteristischen Wurzeln einer linearen Substitution mit einer Anwenduug auf die Theorie der Integralgleichuugen," </title> <note> Mathematische Annallen 66 (1909) 448-510. </note>
Reference-contexts: See [4] or [12]. 4 The above reduction can be repeated on L 2 and so on. When an eigenvector is used at each stage, the result is that A is reduced to upper triangular form by a unitary similarity transformation|a very useful decomposition due to Schur <ref> [9] </ref>. When a sequence of invariant subspaces is used, one arrives at a block triangular form. A particularly important application occurs when A is real but 1 is complex.
Reference: [10] <author> G. W. </author> <title> Stewart "Error Bounds for Approximate Invariant Subspaces of Closed Linear Operators," </title> <journal> SIAM J. Numer. Anal. </journal> <month> 8 </month> <year> (1971) </year> <month> 796-808. </month>
Reference: [11] <author> G. W. </author> <title> Stewart "Error and Perturbation Bounds for Subspaces Associated with Certain Eigenvalue Problems," </title> <note> SIAM Review 15 (1973) 727-764. </note>
Reference: [12] <author> G. W. </author> <title> Stewart Introduction to Matrix Computations, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: For example if T is an operator, then kTk = max kTP k: For more on norms see [4] or <ref> [12] </ref>. fl Department of Computer Science and Institute for Physical Science and Technology, University of Maryland, College Park, 20742. Invariant Subspaces 2 2 Eigenvectors and eigenvalues Simply stated, an eigenvector of an nfin matrix A is a nonzero vector whose direction remains the same when it is multiplied by A. <p> See [4] or <ref> [12] </ref>. 4 The above reduction can be repeated on L 2 and so on. When an eigenvector is used at each stage, the result is that A is reduced to upper triangular form by a unitary similarity transformation|a very useful decomposition due to Schur [9].
Reference: [13] <author> J. H. </author> <title> Wilkinson The Algebraic Eigenvalue Problem, </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1965. </year>
Reference-contexts: As a general rule, one should try to get rid of higher order terms by algebraic means, before simply throwing them away. 11 J. H. Wilkinson <ref> [13] </ref> appears to be the first to explicitly point out the role of this number, or rather its reciprocal. 12 When it is a matter of eigenvalues, ky 1 k can be regarded as the secant of the angle between x 1 and y 1 .
References-found: 13

