URL: http://dimacs.rutgers.edu/techps/1994/94-19.ps
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1994.html
Root-URL: http://www.cs.rutgers.edu
Title: COORDINATION COMPLEXITY OF PARALLEL PRICE-DIRECTIVE DECOMPOSITION  
Author: by Michael D. Grigoriadis and Leonid G. Khachiyan 
Address: New Brunswick, NJ 08903  
Affiliation: Department of Computer Science Rutgers University  
Date: 1994  
Note: April  Research supported by the National Science Foundation under grant CCR-9208539. DIMACS is a cooperative project of Rutgers University, Princeton University, AT&T Bell Laboratories, and Bellcore. DIMACS is an NSF Science and Technology Center funded under ContractSTC-88-09648; and also receives support from the New Jersey Commission on Science and Technology.  
Abstract: DIMACS Technical Report 94-19 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.K. Ahuja, T.L. Magnanti, and J.B. Orlin, </author> <title> Network Flows (Prentice-Hall, </title> <address> NJ, </address> <year> 1993). </year>
Reference-contexts: "statistical" method for polyhedral games [5] analyzed by Robinson [28] (also see Shapiro [31] and Khachiyan [18]), the more general scheme of Everett III [7], and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. <ref> [1] </ref> for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan [19]), the method of volumetric centers by Vaidya [36], <p> Algorithm A E (f; x 0 ; ): Step 0. (Initialization.) Set x = x 0 and select ffi = 6 ln M; t = 7 ln M t ; where is any number in <ref> [(x 0 ); 1] </ref>: Step 1. (Compute prices.) Set f = f (x) 2 IR M + and compute the price vector p = p (f) 2 IR M Step 2. (Block optimization.) For each block k = 1; : : : ; K, perform the following two steps: Step 2.1.
Reference: [2] <author> D.S. Atkinson and P.M. Vaidya, </author> <title> "A cutting plane algorithm that uses analytic centers", in Nondifferentiable and large-scale optimization, </title> <journal> Mathematical Programming - B, </journal> <note> J.L. </note> <author> Goffin and J.P. Vial, Eds., </author> <note> (to appear). </note>
Reference-contexts: maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan [19]), the method of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya <ref> [2] </ref>, Goffin et al. [13], [14]). Coordinators for these methods require all or a substantial part of the history I. For instance, [2], [34], and [36], as well as implementations of [6], maintain the information I for (M ) past iterations. <p> of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya <ref> [2] </ref>, Goffin et al. [13], [14]). Coordinators for these methods require all or a substantial part of the history I. For instance, [2], [34], and [36], as well as implementations of [6], maintain the information I for (M ) past iterations. <p> value of problem (P) can also be computed in O (M ln 1=") iterations by the inscribed ellipsoid (Tarasov et al. [34]) or by Vaidya's method of volumetric centers [36], and in O (M ln 2 1=") iterations by the cutting plane method based on analytic centers (Atkinson and Vaidya <ref> [2] </ref>). The theoretically fastest of these methods, [36], requires O (M (M )) arithmetic operations per coordination round, where M (M ) is the complexity of matrix multiplication for M -order matrices.
Reference: [3] <author> D. Bertsimas and J.B. Orlin, </author> <title> "A technique for speeding up the solution of the Lagrangean dual", </title> <booktitle> Mathematical Programming 63 (1994), </booktitle> <pages> pp. 23-45. </pages>
Reference-contexts: design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan [19]), the method of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin <ref> [3] </ref>, and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. [13], [14]). Coordinators for these methods require all or a substantial part of the history I.
Reference: [4] <author> D. Bertsikas, </author> <title> "Approximation procedures based on the method of multipliers", </title> <booktitle> JOTA 25 (1977), </booktitle> <pages> pp. 443-449. </pages>
Reference-contexts: Polyak studied convergence properties and applications of exponential potential functions to minimax optimization problems [25] (also see Bertsekas <ref> [4] </ref> and Schnabel [30]). Shahrokhi and Matula [29] were the first to obtain a fully polynomial time approximation scheme for the uniform concurrent flow problem (a special linear case of (P)) based on such an exponential potential function and unrestricted PDD.
Reference: [5] <author> G.W. Brown, </author> <title> "Iterative solution of games by fictitious play", in Activity Alnalysis and Production, T.C. </title> <editor> Koopmans, Ed., </editor> <publisher> Cowles Commission Monograph 13 (John Wiley, </publisher> <address> NY, </address> <year> 1951). </year>
Reference-contexts: Background. Price directive decomposition has been studied for almost four decades. We shall mention only a few of the many contributions in this area, mainly those that differ in the way p is computed. Among the earliest such approaches is Brown's "statistical" method for polyhedral games <ref> [5] </ref> analyzed by Robinson [28] (also see Shapiro [31] and Khachiyan [18]), the more general scheme of Everett III [7], and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications
Reference: [6] <author> G.B. Dantzig and P. Wolfe, </author> <title> "The decomposition algorithm for linear programming", </title> <booktitle> Econometrica 29 (1961), </booktitle> <pages> pp. 767-778. </pages>
Reference-contexts: Among the earliest such approaches is Brown's "statistical" method for polyhedral games [5] analyzed by Robinson [28] (also see Shapiro [31] and Khachiyan [18]), the more general scheme of Everett III [7], and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle <ref> [6] </ref>. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov <p> Coordinators for these methods require all or a substantial part of the history I. For instance, [2], [34], and [36], as well as implementations of <ref> [6] </ref>, maintain the information I for (M ) past iterations. Also included in this subclass are much simpler, "oblivious" methods that minimize a potential function : f (x) ! IR, smooth with respect to f , as an approximation to the objective function of the problem.
Reference: [7] <author> H. Everett III, </author> <title> "Generalized Lagrange multiplier method for solving problems of optimum allocation of resources", </title> <journal> Oper. Res. </journal> <volume> 11 (1963), </volume> <pages> pp. 399-417. </pages>
Reference-contexts: Among the earliest such approaches is Brown's "statistical" method for polyhedral games [5] analyzed by Robinson [28] (also see Shapiro [31] and Khachiyan [18]), the more general scheme of Everett III <ref> [7] </ref>, and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g
Reference: [8] <author> K.R. Frisch, </author> <title> "Principles of linear programming with particular reference to the double gradient form of the logarithmic potential method", </title> <note> Memorandum of October 18, 1954, </note> <institution> University Institute of Economics, Oslo, Norway. </institution>
Reference-contexts: The results of this paper imply that they cannot hold for unrestricted PDD. Logarithmic potential (or barrier) functions were introduced to linear and convex 4 optimization by Frisch in the mid 1950's <ref> [8] </ref>, [9]. Leaving aside the well-known application of these functions to polynomial-time interior point methods for linear and convex programming (see e.g., Goldfarb and Todd [15], Nesterov and Nemirovskii [24]), we mention here their recent use within the context of restricted PDD methods by Schultz and Meyer [33].
Reference: [9] <author> K.R. Frisch, </author> <title> "The logarithmic potential method of convex programming", </title> <note> Memorandum of May 13, 1955, </note> <institution> University Institute of Economics, Oslo, Norway. </institution>
Reference-contexts: The results of this paper imply that they cannot hold for unrestricted PDD. Logarithmic potential (or barrier) functions were introduced to linear and convex 4 optimization by Frisch in the mid 1950's [8], <ref> [9] </ref>. Leaving aside the well-known application of these functions to polynomial-time interior point methods for linear and convex programming (see e.g., Goldfarb and Todd [15], Nesterov and Nemirovskii [24]), we mention here their recent use within the context of restricted PDD methods by Schultz and Meyer [33].
Reference: [10] <author> A.V. </author> <title> Fiacco and G.P. McCormick, Nonlinear Programming: Sequential Unconstrained Minimization Techniques (Wiley, </title> <address> NY, </address> <year> 1968). </year>
Reference: [11] <author> M. Frank and P. Wolfe, </author> <title> "An algorithm for quadratic programming", </title> <journal> Naval Res. Logistics Quarterly 3 (1956), </journal> <pages> pp. 149-154. </pages>
Reference-contexts: In this respect, they are reminiscent of successive (under)relaxation and Frank-Wolfe <ref> [11] </ref> type methods.
Reference: [12] <author> L. Fratta, M. Gerla, and L. Kleinrock, </author> <title> "The flow-deviation method: an approach to store-and-forward communication network design", </title> <booktitle> Networks 3 (1973), </booktitle> <pages> pp. 97-133. 22 </pages>
Reference-contexts: In this respect, they are reminiscent of successive (under)relaxation and Frank-Wolfe [11] type methods. An early example is the method of Fratta et al. <ref> [12] </ref> | presented in the context of routing in communication networks | which minimizes a rational potential function for the multicommodity flow problem, Exponential potential functions were introduced in optimization as early as 1951 by Motzkin [23] who suggested the use of gradient descent methods for solving linear systems of inequalities.
Reference: [13] <author> J.L. Goffin, A. Haurie and J.P. Vial, </author> <title> "Decomposition and nondifferentiable optimization with the projective algorithm", </title> <booktitle> Management Science 38 (1992), </booktitle> <pages> pp. 284-302. </pages>
Reference-contexts: as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan [19]), the method of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. <ref> [13] </ref>, [14]). Coordinators for these methods require all or a substantial part of the history I. For instance, [2], [34], and [36], as well as implementations of [6], maintain the information I for (M ) past iterations.
Reference: [14] <author> J.L. Goffin, A. Haurie, J.P. Vial, and D.L. Zhu, </author> <title> "Using central prices in the decomposition of linear programs", </title> <booktitle> European J. of Operational Research 64 (1993), </booktitle> <pages> pp. 393-409. </pages>
Reference-contexts: space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan [19]), the method of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. [13], <ref> [14] </ref>). Coordinators for these methods require all or a substantial part of the history I. For instance, [2], [34], and [36], as well as implementations of [6], maintain the information I for (M ) past iterations.
Reference: [15] <author> D. Goldfarb and M.J. Todd, </author> <title> "Chapter II. Linear Programming", pp. 73-170 in Handbook of OR & MS Vol 1, G.L. </title> <editor> Nemhauser et al., </editor> <publisher> Eds (Elsevier Science (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1989). </year>
Reference-contexts: Logarithmic potential (or barrier) functions were introduced to linear and convex 4 optimization by Frisch in the mid 1950's [8], [9]. Leaving aside the well-known application of these functions to polynomial-time interior point methods for linear and convex programming (see e.g., Goldfarb and Todd <ref> [15] </ref>, Nesterov and Nemirovskii [24]), we mention here their recent use within the context of restricted PDD methods by Schultz and Meyer [33].
Reference: [16] <author> M.D. Grigoriadis and L.G. Khachiyan, </author> <title> "Fast approximation schemes for convex programs with many blocks and coupling constraints", </title> <journal> SIAM J. Optimization 4 (1994), </journal> <pages> pp. 86-107. </pages>
Reference-contexts: Their bounds were substantially improved by Tardos [35], Klein et al. [20], and Leighton et al. [22], and further extended to linear (P) by Plotkin et al. [26]. The best currently known coordination complexity bounds for both linear and nonlinear problems (P) were given by Grigoriadis and Khachiyan <ref> [16] </ref>. It is important to note that these coordination complexity bounds for exponential-potential PDD were shown for explicitly or implicitly -restricted block optimizations. The results of this paper imply that they cannot hold for unrestricted PDD. <p> In Section 3 we discuss restricted PDD ((x) +1). We use an exponential-potential restricted PDD method to solve problem (P) with M coupling constraints and K blocks to a relative accuracy of " in (1:3) N E = O (K ln M (" 2 + ln M )) iterations <ref> [16] </ref>; in particular, its coordination complexity is O (K ln 2 M ) for a fixed ". We use this method for K M= ln M , where each coordination round requires O (M ) operations, or O (ln M ) operations in parallel on M= ln M processors. <p> The next theorem generalizes the above iteration bound for any starting point x 0 2 B and for a given relative accuracy " &gt; 0. Its proof invokes a ternary search procedure T S, similar to that in <ref> [16] </ref>, which calls Algorithm A L as a subroutine to gradually decrease the value of t 3=7. T S maintains the interval [ ; ], its length ffi = , and the parameters 1 = + ffi=3, 2 = + 2ffi=3, - = 1=(2 + ), and = -ffi=3. <p> We plan to address some of these aspects in a future paper. 3. Restricted PDD and the exponential-potential method. In this section we briefly state the exponential-potential restricted PDD method for (P) along with its complexity bounds developed in <ref> [16] </ref>. Then, we obtain a lower bound on the coordination complexity of any restricted PDD method for solving (P) to a fixed relative accuracy of " = 1. <p> Replace x by y (k; t k ). Go to Step 1 to start a new iteration. tu The coordination complexity of this algorithm is given by the theorem below. THEOREM 4. <ref> [16] </ref> For any initial point x 0 2 B such that (x 0 ) 1, and for any 2 (0; 1=3], Algorithm A (f; x 0 ; ) halts in (3:3) N = O K (x 0 ) fl iterations with an x 2 B such that (x) fl + . <p> Solving (P) to a given relative accuracy and the complexity of exponential-potential PDD. Applying the ternary search procedure T S of Section 2.3 along with Algorithm A E of Section Section 3.2, we readily obtain the following theorem. THEOREM 5. <ref> [16] </ref> Given any initial point x 0 2 B and a number " 2 (0; 1], problem (P) can be solved to a relative accuracy of " in (3:4) N = O K ln M " 2 + ln fl : iterations of the exponential-potential PDD method.
Reference: [17] <author> M.D. Grigoriadis and L.G. Khachiyan, </author> <title> "An exponential function reduction method for block-angular convex programs", </title> <institution> LCSR-TR-211, Laboratory for Computer Science Research, Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: On the other hand, an exponential-potential restricted PDD method was found to be even more efficient in solving the same class of problems <ref> [17] </ref>. 1.4. Results.
Reference: [18] <author> L.G. Khachiyan, </author> <title> "Convergence rate of the game processes for solving matrix games", </title> <journal> Zh. </journal> <note> Vychisl. Mat. & Mat. Fiz. 17-6 (1977) pp. 1421-1431. English translation in U.S.S.R. </note> <institution> Comput. Math. & Math. Phys., </institution> <month> 17 </month> <year> (1978), </year> <pages> pp. 78-88. </pages>
Reference-contexts: We shall mention only a few of the many contributions in this area, mainly those that differ in the way p is computed. Among the earliest such approaches is Brown's "statistical" method for polyhedral games [5] analyzed by Robinson [28] (also see Shapiro [31] and Khachiyan <ref> [18] </ref>), the more general scheme of Everett III [7], and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model also includes various
Reference: [19] <author> L.G. Khachiyan, </author> <title> "Optimal algorithms in convex programming, decomposition, and sorting", pp. 161-205 in Computers and Decision Problems, Ju. </title> <editor> Zhuravlev, Ed., </editor> <publisher> (Science Publishers - Nauka, </publisher> <address> Moscow, </address> <year> 1989, </year> <note> in Russian). </note>
Reference-contexts: and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan <ref> [19] </ref>), the method of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. [13], [14]).
Reference: [20] <author> P. Klein, C. Stein, and E. Tardos, </author> <title> "Leighton-Rao might be practical: faster approximation algorithms for concurrent flow with uniform capacities", </title> <booktitle> in Proc. 22nd Annual ACM Symp. on Theory of Computing, </booktitle> <pages> pp. 310-321, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Shahrokhi and Matula [29] were the first to obtain a fully polynomial time approximation scheme for the uniform concurrent flow problem (a special linear case of (P)) based on such an exponential potential function and unrestricted PDD. Their bounds were substantially improved by Tardos [35], Klein et al. <ref> [20] </ref>, and Leighton et al. [22], and further extended to linear (P) by Plotkin et al. [26]. The best currently known coordination complexity bounds for both linear and nonlinear problems (P) were given by Grigoriadis and Khachiyan [16].
Reference: [21] <author> L.S. Lasdon, </author> <title> Optimization Theory for Large Systems (The MacMillan Company, </title> <address> NY, </address> <year> 1970). </year>
Reference-contexts: This observation forms the basis of the well-known class of Lagrangian or price directive decomposition (PDD) methods (see e.g. <ref> [21] </ref>). Such methods maintain x 2 B, p 2 P , and the scalar (x) +1, and repeat the following three steps at each iteration 0; 1; : : :, until an appropriate stopping criterion is satisfied: Step 1 (Compute prices). <p> Among the earliest such approaches is Brown's "statistical" method for polyhedral games [5] analyzed by Robinson [28] (also see Shapiro [31] and Khachiyan [18]), the more general scheme of Everett III [7], and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon <ref> [21] </ref> and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan
Reference: [22] <author> T. Leighton, F. Makedon, S. Plotkin, C. Stein, E. Tardos, and S. Tragoudas, </author> <title> "Fast approximation algorithms for multicommodity flow problems", pp. </title> <booktitle> 101-111 in Proc. 23rd Annual ACM Symp. on Theory of Computing, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: Their bounds were substantially improved by Tardos [35], Klein et al. [20], and Leighton et al. <ref> [22] </ref>, and further extended to linear (P) by Plotkin et al. [26]. The best currently known coordination complexity bounds for both linear and nonlinear problems (P) were given by Grigoriadis and Khachiyan [16].
Reference: [23] <author> T.S. Motzkin, </author> <title> "New technique for linear inequalities andoptimization", in Project SCOOP Symp. on Linear Inequalities and Programming, Planning Research Division, </title> <type> U.S. </type> <institution> Air Force, </institution> <address> Washing-ton, DC, </address> <year> 1952. </year>
Reference-contexts: An early example is the method of Fratta et al. [12] | presented in the context of routing in communication networks | which minimizes a rational potential function for the multicommodity flow problem, Exponential potential functions were introduced in optimization as early as 1951 by Motzkin <ref> [23] </ref> who suggested the use of gradient descent methods for solving linear systems of inequalities. Polyak studied convergence properties and applications of exponential potential functions to minimax optimization problems [25] (also see Bertsekas [4] and Schnabel [30]).
Reference: [24] <author> Y. Nesterov and A. Nemirovskii, </author> <title> Interior Point Polynomial Algorithms in Convex Programming (SIAM, </title> <address> Philadelphia 1993). </address>
Reference-contexts: Logarithmic potential (or barrier) functions were introduced to linear and convex 4 optimization by Frisch in the mid 1950's [8], [9]. Leaving aside the well-known application of these functions to polynomial-time interior point methods for linear and convex programming (see e.g., Goldfarb and Todd [15], Nesterov and Nemirovskii <ref> [24] </ref>), we mention here their recent use within the context of restricted PDD methods by Schultz and Meyer [33]. Their strategy involves a one-sided box constraint as a block restriction and a K-dimensional search in the coordination step that minimizes the potential over all convex combinations of K block directions. <p> Although the above approach may be adequate in practice, the bound can be improved using Newton's method to compute min (; f ). For a fixed f , the function (; f ) is t=M -self-concordant <ref> [24] </ref> in and hence each Newton iteration decreases by a factor of t=M unless is in the region of quadratic convergence (2:21) fi P M fi fi P M 2 (see Section 2.2.3 in Nesterov and Nemirovskii [24]). <p> For a fixed f , the function (; f ) is t=M -self-concordant <ref> [24] </ref> in and hence each Newton iteration decreases by a factor of t=M unless is in the region of quadratic convergence (2:21) fi P M fi fi P M 2 (see Section 2.2.3 in Nesterov and Nemirovskii [24]).
Reference: [25] <author> R.A. Polyak, </author> <title> "Smooth optimization methods for minimax problems", </title> <journal> SIAM J. Control and Optimization 26 (1988), </journal> <pages> pp. 1274-1286. </pages>
Reference-contexts: Polyak studied convergence properties and applications of exponential potential functions to minimax optimization problems <ref> [25] </ref> (also see Bertsekas [4] and Schnabel [30]). Shahrokhi and Matula [29] were the first to obtain a fully polynomial time approximation scheme for the uniform concurrent flow problem (a special linear case of (P)) based on such an exponential potential function and unrestricted PDD.
Reference: [26] <author> S.A. Plotkin, D.B. Shmoys, and E. Tardos, </author> <title> "Fast approximation algorithms for fractional packing and covering problems", </title> <booktitle> in Proc. 32nd Annual Symp. on Foundations of Computer Science, </booktitle> <pages> pp. 495-504, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Their bounds were substantially improved by Tardos [35], Klein et al. [20], and Leighton et al. [22], and further extended to linear (P) by Plotkin et al. <ref> [26] </ref>. The best currently known coordination complexity bounds for both linear and nonlinear problems (P) were given by Grigoriadis and Khachiyan [16]. It is important to note that these coordination complexity bounds for exponential-potential PDD were shown for explicitly or implicitly -restricted block optimizations.
Reference: [27] <author> T.R. Rockafellar, </author> <title> Convex Analysis (Princeton Univ. </title> <publisher> Press, </publisher> <address> Princeton, NJ, </address> <year> 1970). </year>
Reference-contexts: to B = B 1 fi : : : fi B K , where (1:1) B k = f x k 2 B k j f k (x k ) e g ; k = 1; : : : ; K: 2 From von Neumann's saddlepoint theorem (see, e.g., Rockafellar <ref> [27] </ref>, p. 393), fl = min max L (x; p) = max min L (x; p); where P = f p 2 IR M j e T x = 1; p 0 g is the unit simplex, and L (x; p) = P K P K k=1 p T f k
Reference: [28] <author> J. Robinson, </author> <title> "An iterative method of solving a game", </title> <journal> Ann. of Math. </journal> <volume> 54 (1951), </volume> <pages> pp. 196-301. </pages>
Reference-contexts: Price directive decomposition has been studied for almost four decades. We shall mention only a few of the many contributions in this area, mainly those that differ in the way p is computed. Among the earliest such approaches is Brown's "statistical" method for polyhedral games [5] analyzed by Robinson <ref> [28] </ref> (also see Shapiro [31] and Khachiyan [18]), the more general scheme of Everett III [7], and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications in network optimization and
Reference: [29] <author> F. Shahrokhi and D.W. Matula, </author> <title> "The maximum concurrent flow problem", </title> <editor> J. </editor> <booktitle> ACM 37 (1990), </booktitle> <pages> pp. 318-334. </pages>
Reference-contexts: Polyak studied convergence properties and applications of exponential potential functions to minimax optimization problems [25] (also see Bertsekas [4] and Schnabel [30]). Shahrokhi and Matula <ref> [29] </ref> were the first to obtain a fully polynomial time approximation scheme for the uniform concurrent flow problem (a special linear case of (P)) based on such an exponential potential function and unrestricted PDD.
Reference: [30] <author> R.B. Schnabel, </author> <title> "Determining feasibility of a set of nonlinear inequality constraints", Math. </title> <booktitle> Progr. Study 16 (1982), </booktitle> <pages> pp. 137-148. </pages>
Reference-contexts: Polyak studied convergence properties and applications of exponential potential functions to minimax optimization problems [25] (also see Bertsekas [4] and Schnabel <ref> [30] </ref>). Shahrokhi and Matula [29] were the first to obtain a fully polynomial time approximation scheme for the uniform concurrent flow problem (a special linear case of (P)) based on such an exponential potential function and unrestricted PDD.
Reference: [31] <author> H.N. Shapiro, </author> <title> "Note on a computation method in the thoery of games", </title> <journal> Comm. Pure and Applied Math. </journal> <volume> 11 (1982), </volume> <pages> pp. 587-593. </pages>
Reference-contexts: We shall mention only a few of the many contributions in this area, mainly those that differ in the way p is computed. Among the earliest such approaches is Brown's "statistical" method for polyhedral games [5] analyzed by Robinson [28] (also see Shapiro <ref> [31] </ref> and Khachiyan [18]), the more general scheme of Everett III [7], and several other "two-level" price decomposition methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model
Reference: [32] <author> N.Z. Shor, </author> <title> Minimization Methods for Nondifferentiable Functions (Springer Series in Computational Mathematics 3, </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1985). </year>
Reference-contexts: methods, including the Dantzig-Wolfe decomposition principle [6]. (See, e.g., Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor <ref> [32] </ref>), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan [19]), the method of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. [13], [14]).
Reference: [33] <author> G.L. Schultz and R.R. Meyer, </author> <title> "An interior point method for block-angular optimization", </title> <journal> SIAM J. Optimization 1 (1991), </journal> <pages> pp. 583-602. </pages>
Reference-contexts: Leaving aside the well-known application of these functions to polynomial-time interior point methods for linear and convex programming (see e.g., Goldfarb and Todd [15], Nesterov and Nemirovskii [24]), we mention here their recent use within the context of restricted PDD methods by Schultz and Meyer <ref> [33] </ref>. Their strategy involves a one-sided box constraint as a block restriction and a K-dimensional search in the coordination step that minimizes the potential over all convex combinations of K block directions. A convergence analysis and attractive parallel computational results are reported in [33] for a set of large, practical minimum-cost <p> restricted PDD methods by Schultz and Meyer <ref> [33] </ref>. Their strategy involves a one-sided box constraint as a block restriction and a K-dimensional search in the coordination step that minimizes the potential over all convex combinations of K block directions. A convergence analysis and attractive parallel computational results are reported in [33] for a set of large, practical minimum-cost multicommodity flow problems with K &lt;< M . On the other hand, an exponential-potential restricted PDD method was found to be even more efficient in solving the same class of problems [17]. 1.4. Results.
Reference: [34] <author> S.P. Tarasov, L.G. Khachiyan, and I.I. Erlich, </author> <title> "The method of inscribed ellipsoids", </title> <journal> Soviet Math. Dokl. </journal> <volume> 37 (1988), </volume> <pages> pp. 226-230. </pages>
Reference-contexts: Lasdon [21] and the recent book by Ahuja et al. [1] for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. <ref> [34] </ref>, Khachiyan [19]), the method of volumetric centers by Vaidya [36], with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. [13], [14]). <p> Coordinators for these methods require all or a substantial part of the history I. For instance, [2], <ref> [34] </ref>, and [36], as well as implementations of [6], maintain the information I for (M ) past iterations. <p> And a useful property of the method is that it provides an "-approximate optimal dual vector p when it halts. The optimal value of problem (P) can also be computed in O (M ln 1=") iterations by the inscribed ellipsoid (Tarasov et al. <ref> [34] </ref>) or by Vaidya's method of volumetric centers [36], and in O (M ln 2 1=") iterations by the cutting plane method based on analytic centers (Atkinson and Vaidya [2]).
Reference: [35] <author> E. Tardos, </author> <title> "Improved approximation algorithm for concurrent multicommodity flows", </title> <type> Tech. Rep. 872, </type> <institution> School of OR/IE, Cornell Univ., </institution> <address> Ithaca, NY, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: Shahrokhi and Matula [29] were the first to obtain a fully polynomial time approximation scheme for the uniform concurrent flow problem (a special linear case of (P)) based on such an exponential potential function and unrestricted PDD. Their bounds were substantially improved by Tardos <ref> [35] </ref>, Klein et al. [20], and Leighton et al. [22], and further extended to linear (P) by Plotkin et al. [26]. The best currently known coordination complexity bounds for both linear and nonlinear problems (P) were given by Grigoriadis and Khachiyan [16].
Reference: [36] <author> P.M. Vaidya, </author> <title> "A new algorithm for minimizing convex functions over convex sets", </title> <booktitle> in Proc. 30th Annual IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pp. </pages> <month> 338-343 </month> <year> (1989). </year>
Reference-contexts: [1] for a number of applications in network optimization and design.) The PDD model also includes various approaches based on nondifferentiable optimization for maximizing g (p), such as space-dilation methods (Shor [32]), the method of inscribed ellipsoids (Tarasov et al. [34], Khachiyan [19]), the method of volumetric centers by Vaidya <ref> [36] </ref>, with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. [13], [14]). Coordinators for these methods require all or a substantial part of the history I. For instance, [2], [34], and [36], as well <p> by Vaidya <ref> [36] </ref>, with improvements for structured problems by Bertsimas and Orlin [3], and cutting plane methods based on analytic centers (see Atkinson and Vaidya [2], Goffin et al. [13], [14]). Coordinators for these methods require all or a substantial part of the history I. For instance, [2], [34], and [36], as well as implementations of [6], maintain the information I for (M ) past iterations. <p> The optimal value of problem (P) can also be computed in O (M ln 1=") iterations by the inscribed ellipsoid (Tarasov et al. [34]) or by Vaidya's method of volumetric centers <ref> [36] </ref>, and in O (M ln 2 1=") iterations by the cutting plane method based on analytic centers (Atkinson and Vaidya [2]). The theoretically fastest of these methods, [36], requires O (M (M )) arithmetic operations per coordination round, where M (M ) is the complexity of matrix multiplication for M <p> computed in O (M ln 1=") iterations by the inscribed ellipsoid (Tarasov et al. [34]) or by Vaidya's method of volumetric centers <ref> [36] </ref>, and in O (M ln 2 1=") iterations by the cutting plane method based on analytic centers (Atkinson and Vaidya [2]). The theoretically fastest of these methods, [36], requires O (M (M )) arithmetic operations per coordination round, where M (M ) is the complexity of matrix multiplication for M -order matrices.
References-found: 36

