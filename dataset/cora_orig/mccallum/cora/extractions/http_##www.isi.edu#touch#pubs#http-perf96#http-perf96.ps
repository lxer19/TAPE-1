URL: http://www.isi.edu/touch/pubs/http-perf96/http-perf96.ps
Refering-URL: http://www.isi.edu/touch/pubs/http-perf96/
Root-URL: http://www.isi.edu
Web: HTTP  
Date: August 1996,  
Note: Note: This document first appeared on the web in June 1996, and was revised to its current form in  as http://www.isi.edu/lsam/publications/http-perf/. This is an archive of that version, with updated references only. 1: Introduction 2:  
Abstract: 1 We discuss the performance effects of using per-transaction TCP connections for HTTP access, and the proposed optimizations of avoiding per-transaction reconnection and TCP slow-start restart overheads. We analyze the performance penalties of the interaction of HTTP and TCP. Our observations indicate that the proposed optimizations do not substantially affect Web access for the vast majority of users, who typically see end-to-end latencies of 100-250 ms and use low bandwidth lines. Under these conditions, there are only 1-2 packets in transit between the client and server, and the optimizations reduce the overall transaction time by only 11%. Rates over 200 Kbps are required in order to achieve at least a 50% reduction in transaction time, resulting in a user-noticeable performance enhancement. There have been several recent discussions about the performance problems of HTTP over TCP. This Web page continues that discussion with a description of the performance benefits of the proposed approaches. We discuss the evolution of the HTTP protocol, and the potential for inefficiencies. We then present analysis of these inefficiencies in current Web systems. We have found that, except for users with Ethernet-speed end-to-end links between the client and server, the performance enhancements proposed in [16] and [9] have limited benefit. The proposed application-layer persistent connection mechanisms achieve only a 11-27% reduction in response time for low bandwidth access, whereas we consider a 50% reduction in response time the minimum for substantial user benefit (i.e., the transaction is twice as fast). We conclude that such mechanisms are of limited benefit, and observe that they may interfere with emerging Internet services. The HTTP protocol was originally developed to reduce the inefficiencies of the FTP protocol [14], [1]. The goal was fast request-response interaction without requiring state at the server. To see the performance advantage of HTTP over FTP, we can compare the process of file retrieval transactions in each protocol. Both protocols use TCP, a reliable, connection-oriented transport protocol [13]. In FTP, a client opens a TCP connection with the server for control (Figure 1). Once that connection is established, a request for a file is sent on that channel. The server then opens a separate TCP connection for the file transfer, and returns the file in that other connection. Each connection requires one round-trip time (RTT) to open. The request takes 1/2 a RTT to get to the server, and the response takes another 1/2 RTT to return, in addition to the transmission time of the file. The overall time required for an FTP transaction is: 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Berners-Lee, T.J, R. Cailliau and J.-F. Groff, </author> <title> The WorldWide Web, </title> <booktitle> Computer Networks and ISDN Systems 25 (1992) 454-459. </booktitle> <address> Noth-Holland. </address>
Reference-contexts: We conclude that such mechanisms are of limited benefit, and observe that they may interfere with emerging Internet services. 2: HTTP The HTTP protocol was originally developed to reduce the inefficiencies of the FTP protocol [14], <ref> [1] </ref>. The goal was fast request-response interaction without requiring state at the server. To see the performance advantage of HTTP over FTP, we can compare the process of file retrieval transactions in each protocol. Both protocols use TCP, a reliable, connection-oriented transport protocol [13].
Reference: [2] <author> Braden, R., </author> <title> Extending TCP for Transactions -- Concepts, </title> <address> RFC-1379, USC/ISI, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: As a result, the inefficiency of application-layer segmentation and reassembly occurs for every transaction. Finally, application-level multiplexing interferes with emerging Integrated Services multiplexing in the kernel, for Type-of-Service and Quality-of-Service mechanisms [4]. 4.2: Transaction TCP Transaction TCP (T/TCP) provides transaction-oriented service over TCP via extensions to the TCP protocol <ref> [2] </ref>, [3]. T/TCP uses cached per-host state to avoid the delayed delivery of data carried with an OPEN, as discussed earlier. TCP delays that data to avoid delivery to the wrong connection, especially in cases of aborted connections.
Reference: [3] <author> Braden, R., </author> <title> T/TCP -- TCP Extensions for Transactions: Functional Specification, </title> <address> RFC-1644, USC/ISI, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Finally, application-level multiplexing interferes with emerging Integrated Services multiplexing in the kernel, for Type-of-Service and Quality-of-Service mechanisms [4]. 4.2: Transaction TCP Transaction TCP (T/TCP) provides transaction-oriented service over TCP via extensions to the TCP protocol [2], <ref> [3] </ref>. T/TCP uses cached per-host state to avoid the delayed delivery of data carried with an OPEN, as discussed earlier. TCP delays that data to avoid delivery to the wrong connection, especially in cases of aborted connections.
Reference: [4] <author> Clark, D., Shenker, S., and Zhang, L., </author> <title> Supporting Real-Time Applications in an Integrated Services Packet Network: Architecture and Mechanism, </title> <booktitle> Sigcomm 92, </booktitle> <pages> pp. 14-26. </pages>
Reference-contexts: As a result, the inefficiency of application-layer segmentation and reassembly occurs for every transaction. Finally, application-level multiplexing interferes with emerging Integrated Services multiplexing in the kernel, for Type-of-Service and Quality-of-Service mechanisms <ref> [4] </ref>. 4.2: Transaction TCP Transaction TCP (T/TCP) provides transaction-oriented service over TCP via extensions to the TCP protocol [2], [3]. T/TCP uses cached per-host state to avoid the delayed delivery of data carried with an OPEN, as discussed earlier.
Reference: [5] <author> Fielding, et al., </author> <note> Hypertext Transfer Protocol - HTTP/1.1, (working draft), June 7, 1996. NOTE: This became RFC 2068 in Jan. </note> <year> 1997. </year>
Reference-contexts: These include persistent-connection HTTP, Transaction TCP, and (recently) sharing TCP control blocks. These proposals address either connection or slow-start overheads, and in some cases, both issues. 4.1: Persistent HTTP Persistent HTTP addresses both connection and slow-start overheads. There are several distinct proposals for P-HTTP, including <ref> [5] </ref>, [15], and [9]. For the purposes of this discussion, we treat them as equivalent. P-HTTP attempts to achieve optimal transaction time for sequences of transactions to the same server. The initial transaction occurs as in HTTP, but the connection is not closed.
Reference: [6] <author> Heidemann, J., Obraczka, K., and Touch, J., </author> <title> Analysis of HTTP Transport Protocols, (in progress). NOTE: This was published with the revised title Modeling the Performance of HTTP Over Several Transport Protocols, </title> <journal> ACM/IEEE Transactions on Networking 5(5), </journal> <pages> 616-630, </pages> <month> October, </month> <year> 1997. </year>
Reference-contexts: We are currently looking at HTTP performance over several transport protocols, including TCP, p-HTTP, T/TCP, and UDP-based RPC protocols, over a wider variety of network conditions <ref> [6] </ref>. This paper will contain both a more detailed model of HTTP performance than presented here and validation of this model against real-world traffic. 6: Environment Characteristics The degree of inefficiency of HTTP over TCP depends on the environment in which the Web operates. <p> Other analysis at ISI shows that the Web page case has a greater potential for optimization than the HTML case, because it is composed of multiple files <ref> [6] </ref>. In particular, the aggregate of files denoted by a Web page can be retrieved in a single connection with a single aggregate GET-ALL request, rather than even using persistent connections [12]. <p> The effect of the optimizations (avoiding connection establishment and slow-start) depends on the network properties; for modem links it is 11%, for ISDN it is also low, around 27%. Optimization increases significantly for faster connections or for higher latency paths <ref> [6] </ref>, which is similar to the results in [16] and [9]. 7: Evaluation We want to determine the potential for inefficiency in HTTP over TCP. <p> When other factors, such as server processing, packet loss, etc., are included, the optimizations are even less noticeable. The following section presents analysis for HTTP over TCP. A more complete analysis of HTTP over several transport protocols and P-HTTP is currently underway <ref> [6] </ref>. The formulae below are simplified versions originally developed there. The formulae in this paper provide an upper bound on performance, the formulae in [6] are more precise and include implementation-specific interactions. 7.1: Analysis The following notation is used in the analysis: R = RTT bw = bandwidth MSS = max. <p> The following section presents analysis for HTTP over TCP. A more complete analysis of HTTP over several transport protocols and P-HTTP is currently underway <ref> [6] </ref>. The formulae below are simplified versions originally developed there. The formulae in this paper provide an upper bound on performance, the formulae in [6] are more precise and include implementation-specific interactions. 7.1: Analysis The following notation is used in the analysis: R = RTT bw = bandwidth MSS = max. segment size (packet size) K = number of packets in the file = filesize / MSS L = round trip time in packets, i.e., <p> in packets, i.e., length of the pipe = number of packets to fill the pipe = bw * R / MSS M = max useful window size (lower bound) = min (L, K) S = round trips stalled in slow-start, assuming no loss (upper bound) (window starts at 2, see <ref> [6] </ref>) = oor (log2 (ceil (M/2))) Net (bps) (bytes) Latency (ms) LAN/MAN WAN satellite 9K 512 250 500 modem 29K 512 150 250 ISDN 112K 1460/512 30 130 direct 1M 1460/512 2 100 fast 155M 8192/512 2 100 TABLE 1. <p> File sizes may increase as well. Given all three of these advances, it is not easy to predict the overall effect. This is discussed in further detail in ongoing work <ref> [6] </ref>. 9: Acknowledgments We would like to thank the members of ISIs HPCC Division, especially Ted Faber, for their assistance with this document. This document was the result of discussions on the http-ng and web-talk mailing lists, and we also thank the members of those lists for their feedback.
Reference: [7] <author> Jacobson, V., </author> <title> Congestion Avoidance and Control, </title> <booktitle> ACM Sigcomm 88, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: TCP establishes a connection prior to transferring any data, namely the request. TCP also includes a congestion avoidance mechanism <ref> [7] </ref>. In both cases, these mechanisms are restarted for each file request, possibly resulting in exces sive overheads. <p> FIGURE 5. Delayed request deliver 3.2: Congestion Management TCP also employs two congestion management mechanisms, one called slow-start, and the other called congestion avoidance <ref> [7] </ref>. Slow-start prevents overwhelming the network when a connection begins by limiting the initial send window size, and allowing that window to grow in moderation to positive feedback. Congestion avoidance incorporates the negative feedback of packet loss, and modulates the send window as a result.
Reference: [8] <author> Jacobson, V. and Karels, M., </author> <title> Congestion Avoidance and Control, </title> <note> NOTE: This is a revised version of [7], which adds Karels as co-author and includes an additional appendix. The revised version has not been published, but is available at ftp://ftp.ee.lbl.gov/papers/congavoid.ps.Z </note>
Reference-contexts: Where implemented, MTU discovery will allow Ethernet-sized MTUs on wide-area connections [10]. Slow-start occurs when a connection is initialized, when a packet is lost, or may occur when there is a significant idle period in the connection. The latter is described in <ref> [8] </ref>, and implemented in 4.4BSD and derivatives, although it has not been adopted by earlier BSD-TCP users (for example, SunOS 4). 4: Alternative Protocol Mechanisms There have been several proposals to address the potential inefficiencies of using HTTP over TCP.
Reference: [9] <author> Mogul, J., </author> <title> The Case for Persistent-Connection HTTP, ACM Sigcomm 95, </title> <month> August </month> <year> 1995, </year> <pages> pp. 299-313. </pages> <note> A longer, more comprehensive version of this paper is available on line at Digital Equipment Corporation Western Research Laboratory Research Report 95/4, </note> <month> May, </month> <year> 1995. </year>
Reference-contexts: We discuss the evolution of the HTTP protocol, and the potential for inefficiencies. We then present analysis of these inefficiencies in current Web systems. We have found that, except for users with Ethernet-speed end-to-end links between the client and server, the performance enhancements proposed in [16] and <ref> [9] </ref> have limited benefit. The proposed application-layer persistent connection mechanisms achieve only a 11-27% reduction in response time for low bandwidth access, whereas we consider a 50% reduction in response time the minimum for substantial user benefit (i.e., the transaction is twice as fast). <p> These include persistent-connection HTTP, Transaction TCP, and (recently) sharing TCP control blocks. These proposals address either connection or slow-start overheads, and in some cases, both issues. 4.1: Persistent HTTP Persistent HTTP addresses both connection and slow-start overheads. There are several distinct proposals for P-HTTP, including [5], [15], and <ref> [9] </ref>. For the purposes of this discussion, we treat them as equivalent. P-HTTP attempts to achieve optimal transaction time for sequences of transactions to the same server. The initial transaction occurs as in HTTP, but the connection is not closed. Subsequent requests occur without needing to re-open the connection. <p> Optimization increases significantly for faster connections or for higher latency paths [6], which is similar to the results in [16] and <ref> [9] </ref>. 7: Evaluation We want to determine the potential for inefficiency in HTTP over TCP. For this purpose, we analyze the time required for an HTTP interaction, computing an upper-bound for both the per-transaction connection establishment and potential slow-start overheads, and compare that to the optimal time for transfer.
Reference: [10] <author> Mogul, J., and S. Deering, S., </author> <note> Path MTU Discovery, </note> <institution> RFC-1191, DECWRL, Stanford University, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: The packet size is negotiated. The default is 536 bytes in TCP, although many implementations round this down to 512. Hosts on Ethernets typically use 1460 for local connections. Where implemented, MTU discovery will allow Ethernet-sized MTUs on wide-area connections <ref> [10] </ref>. Slow-start occurs when a connection is initialized, when a packet is lost, or may occur when there is a significant idle period in the connection.
Reference: [11] <author> Moskowitz, R., </author> <title> Why in the World is the Web So Slow? Network Computing, </title> <address> March 15, </address> <year> 1996, </year> <pages> pp. 22-24. 9 </pages>
Reference-contexts: When S-TCB and T/TCP are coupled, they provide similar efficiency to P-HTTP, but at the kernel-level rather than requiring application-layer multiplexing. 5: Prior Analyses Earlier analyses have claimed significant performance problems with HTTP over TCP [16], <ref> [11] </ref>, [12]. Both Speros and Moguls analyses focused on client/server interactions in well-connected (1 Mbps) hosts [16], [12]. Their conclusions do not apply to the vast majority of web accesses, which are for small files over modem and ISDN links.
Reference: [12] <author> Padmanabhan, V., and Mogul, J., </author> <title> Improving HTTP Latency, </title> <booktitle> Proc. of the Second International WWW Conference, </booktitle> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: When S-TCB and T/TCP are coupled, they provide similar efficiency to P-HTTP, but at the kernel-level rather than requiring application-layer multiplexing. 5: Prior Analyses Earlier analyses have claimed significant performance problems with HTTP over TCP [16], [11], <ref> [12] </ref>. Both Speros and Moguls analyses focused on client/server interactions in well-connected (1 Mbps) hosts [16], [12]. Their conclusions do not apply to the vast majority of web accesses, which are for small files over modem and ISDN links. <p> T/TCP are coupled, they provide similar efficiency to P-HTTP, but at the kernel-level rather than requiring application-layer multiplexing. 5: Prior Analyses Earlier analyses have claimed significant performance problems with HTTP over TCP [16], [11], <ref> [12] </ref>. Both Speros and Moguls analyses focused on client/server interactions in well-connected (1 Mbps) hosts [16], [12]. Their conclusions do not apply to the vast majority of web accesses, which are for small files over modem and ISDN links. Moskowitz described performance problems at the server, where buffering limitations in the operating systems affected transaction performance. <p> In particular, the aggregate of files denoted by a Web page can be retrieved in a single connection with a single aggregate GET-ALL request, rather than even using persistent connections <ref> [12] </ref>. The effect of the optimizations (avoiding connection establishment and slow-start) depends on the network properties; for modem links it is 11%, for ISDN it is also low, around 27%.
Reference: [13] <author> Postel, J., </author> <title> Transmission Control Protocol, </title> <address> RFC-793 / STD-007, USC/ISI, </address> <month> September </month> <year> 1981. </year>
Reference-contexts: The goal was fast request-response interaction without requiring state at the server. To see the performance advantage of HTTP over FTP, we can compare the process of file retrieval transactions in each protocol. Both protocols use TCP, a reliable, connection-oriented transport protocol <ref> [13] </ref>. In FTP, a client opens a TCP connection with the server for control (Figure 1). Once that connection is established, a request for a file is sent on that channel. <p> time to transmit the file -------- 1 RTT + Ftrans = time to get a file optimally TCP does not support the minimal transaction because the initial request cannot be delivered to the server until the connection has been established, which takes 1.5 RTTs, from the servers perspective (Figure 5) <ref> [13] </ref>. This is true even if the request is enclosed with the initial SYN OPEN packet; delivery of the request at the server is stalled until the third packet of the exchange arrives. FIGURE 5.
Reference: [14] <author> Postel, J., and Reynolds, J., </author> <title> File Transfer Protocol (FTP), </title> <address> RFC-959 / STD-009, USC/ISI, </address> <month> October </month> <year> 1985. </year>
Reference-contexts: We conclude that such mechanisms are of limited benefit, and observe that they may interfere with emerging Internet services. 2: HTTP The HTTP protocol was originally developed to reduce the inefficiencies of the FTP protocol <ref> [14] </ref>, [1]. The goal was fast request-response interaction without requiring state at the server. To see the performance advantage of HTTP over FTP, we can compare the process of file retrieval transactions in each protocol. Both protocols use TCP, a reliable, connection-oriented transport protocol [13].
Reference: [15] <author> Spero, S., </author> <note> Progress on HTTP-NG, (URL) NOTE: This document was never archivally published. The original URL was http://www.w3.org/pub/WWW/Protocols/HTTP-NG/ http-ng-status.html </note>
Reference-contexts: These include persistent-connection HTTP, Transaction TCP, and (recently) sharing TCP control blocks. These proposals address either connection or slow-start overheads, and in some cases, both issues. 4.1: Persistent HTTP Persistent HTTP addresses both connection and slow-start overheads. There are several distinct proposals for P-HTTP, including [5], <ref> [15] </ref>, and [9]. For the purposes of this discussion, we treat them as equivalent. P-HTTP attempts to achieve optimal transaction time for sequences of transactions to the same server. The initial transaction occurs as in HTTP, but the connection is not closed.
Reference: [16] <author> Spero, S., </author> <title> Analysis of HTTP Performance Problems, </title> <note> (URL) NOTE: This document was never archivally published. The original URL was http://sunsite.unc.edu/mdma-release/http-prob.html </note>
Reference-contexts: We discuss the evolution of the HTTP protocol, and the potential for inefficiencies. We then present analysis of these inefficiencies in current Web systems. We have found that, except for users with Ethernet-speed end-to-end links between the client and server, the performance enhancements proposed in <ref> [16] </ref> and [9] have limited benefit. The proposed application-layer persistent connection mechanisms achieve only a 11-27% reduction in response time for low bandwidth access, whereas we consider a 50% reduction in response time the minimum for substantial user benefit (i.e., the transaction is twice as fast). <p> When S-TCB and T/TCP are coupled, they provide similar efficiency to P-HTTP, but at the kernel-level rather than requiring application-layer multiplexing. 5: Prior Analyses Earlier analyses have claimed significant performance problems with HTTP over TCP <ref> [16] </ref>, [11], [12]. Both Speros and Moguls analyses focused on client/server interactions in well-connected (1 Mbps) hosts [16], [12]. Their conclusions do not apply to the vast majority of web accesses, which are for small files over modem and ISDN links. <p> and T/TCP are coupled, they provide similar efficiency to P-HTTP, but at the kernel-level rather than requiring application-layer multiplexing. 5: Prior Analyses Earlier analyses have claimed significant performance problems with HTTP over TCP <ref> [16] </ref>, [11], [12]. Both Speros and Moguls analyses focused on client/server interactions in well-connected (1 Mbps) hosts [16], [12]. Their conclusions do not apply to the vast majority of web accesses, which are for small files over modem and ISDN links. Moskowitz described performance problems at the server, where buffering limitations in the operating systems affected transaction performance. <p> The effect of the optimizations (avoiding connection establishment and slow-start) depends on the network properties; for modem links it is 11%, for ISDN it is also low, around 27%. Optimization increases significantly for faster connections or for higher latency paths [6], which is similar to the results in <ref> [16] </ref> and [9]. 7: Evaluation We want to determine the potential for inefficiency in HTTP over TCP.
Reference: [17] <author> Touch, J., </author> <title> TCP Control Block Interdependence, </title> <booktitle> (work in progress), </booktitle> <address> USC/ISI, </address> <month> June </month> <year> 1996. </year> <note> NOTE: This became RFC-2140 in April 1997. </note>
Reference-contexts: Reusing slow-start information, which would avoid slow-start restart, is discussed briefly in the T/TCP specification. 4.3: Shared TCP Control Blocks Shared TCBs (S-TCB) augment the TCB state-sharing mechanism of T/TCP and show how to aggregate parameters such as window size across sets of concurrent connections <ref> [17] </ref>. T/TCP state caching is aimed predominantly at serial connection state reuse, whereas S-TCBs address both serial and concurrent shared state reuse. S-TCBs optimize only the inefficiency of the slow-start restart component of HTTP over TCP.
References-found: 17

