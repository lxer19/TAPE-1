URL: ftp://ftp.cs.jhu.edu/pub/subodh/papers/connected.ps.Z
Refering-URL: http://www.cs.jhu.edu/~subodh/research/pub.html
Root-URL: http://www.cs.jhu.edu
Title: CONNECTED-COMPONENTS ALGORITHMS FOR MESH-CONNECTED PARALLEL COMPUTERS  
Author: SUBODH KUMAR, STEPHEN M. GODDARD, AND JAN F. PRINS 
Abstract: We present efficient parallel algorithms for finding the connected components of sparse and dense graphs using a mesh-connected parallel computer. We start with a PRAM algorithm with work complexity O(n 2 log n). The algorithm performs O(log n) reduction and broadcast operations on within the rows and columns of a mesh connected computer. Next, a representation of the adjacency matrix for a sparse graph with m edges is chosen that preserves the communication structure of the algorithm but improves the work bound to O((n + m)logn). This work bound can be improved to the optimal O(n + m) bound through the use of graph contraction. In architectures like the MasPar MP-1 and MP-2, parallel row and column operations of the form described achieve high performance relative to unrestricted concurrent accesses typically found in parallel connected component algorithms for sparse graphs and exhibit no locality dependence. We present MasPar MP-1 performance figures for implementations of the algorithms described. The implementations are exercised on a variety of parametrically-generated graphs, differing in structure and connectivity. These graphs are generated externally and read in as input for the algorithms, permitting comparison of different implementations on identical graphs. Opportunities for additional performance improvement of the implementations are described. 
Abstract-found: 1
Intro-found: 1
Reference: [AS87] <author> B. Awerbuch and Y. Shiloach. </author> <title> New connectivity and msf algorithms for ultracomputer and pram. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(10) </volume> <pages> 1258-1263, </pages> <year> 1987. </year>
Reference-contexts: Hirschberg et. al [Hir76, HCS79, CLC82] showed an O (n 2 ) work algorithm for CREW PRAMs. This algorithm starts with the adjacency matrix of the graph and shrinks the graph based on local connectiviety information at each step, recomputing the new matrix each time. Shiloach et. al <ref> [SV82, AS87] </ref> use a similar idea for sparse graphs. This CRCW-PRAM algorithm starts with a list of edges, forming trees of connected vertices and grafting smaller trees to form larger trees till all vertices of a component are in the same tree.
Reference: [CLC82] <author> F. Chin, J. Lam, and I. Chen. </author> <title> Efficient parallel algorithms for some graph problems. </title> <journal> Communications of the ACM, </journal> <volume> 25(9) </volume> <pages> 659-665, </pages> <year> 1982. </year>
Reference-contexts: There exist a variety of PRAM algorithms for the connected components problem. Hirschberg et. al <ref> [Hir76, HCS79, CLC82] </ref> showed an O (n 2 ) work algorithm for CREW PRAMs. This algorithm starts with the adjacency matrix of the graph and shrinks the graph based on local connectiviety information at each step, recomputing the new matrix each time.
Reference: [CV91] <author> R. Cole and U. Vishkin. </author> <title> Approximate parallel scheduling. part ii: Application to optimal parallel graph algorithms in logarithmic time. </title> <journal> Information and Computation, </journal> <volume> 92(1) </volume> <pages> 1-47, </pages> <year> 1991. </year>
Reference: [Gre93] <author> J. Greiner. </author> <title> A comparison of data-parallel algorithms for connected components. </title> <type> Technical Report CMU-CS-93-191, CMU, </type> <year> 1993. </year>
Reference-contexts: A 2D graph is a subset of two-dimensional toroidal grid. The neighbors of a vertex of 2D graph is a subset of the four neighbors on such a grid <ref> [Gre93] </ref>. Similarly, a 3D graph is a subset of three-dimensional toroidal grid [Gre93]. The edges are picked randomly in a random graph, and unless otherwise noted, the number of components is not constrained and is a function of the random vertex connections. <p> A 2D graph is a subset of two-dimensional toroidal grid. The neighbors of a vertex of 2D graph is a subset of the four neighbors on such a grid <ref> [Gre93] </ref>. Similarly, a 3D graph is a subset of three-dimensional toroidal grid [Gre93]. The edges are picked randomly in a random graph, and unless otherwise noted, the number of components is not constrained and is a function of the random vertex connections. Each vertex of a tertiary graph has a degree of 3.
Reference: [HCS79] <author> D. Hirschberg, A. Chandra, and D. Saraswate. </author> <title> Computing connected components on parallel computers. </title> <journal> Communications of the ACM, </journal> <volume> 22(8) </volume> <pages> 461-464, </pages> <year> 1979. </year>
Reference-contexts: There exist a variety of PRAM algorithms for the connected components problem. Hirschberg et. al <ref> [Hir76, HCS79, CLC82] </ref> showed an O (n 2 ) work algorithm for CREW PRAMs. This algorithm starts with the adjacency matrix of the graph and shrinks the graph based on local connectiviety information at each step, recomputing the new matrix each time.
Reference: [Hir76] <author> D. Hirschberg. </author> <title> Parallel algorithms for the transitive closure and the connected component problems. </title> <booktitle> In Eighth Annual ACM Symposium on theory of Computing, </booktitle> <pages> pages 55-57, </pages> <address> Hershey, Pennsylvania, </address> <year> 1976. </year>
Reference-contexts: There exist a variety of PRAM algorithms for the connected components problem. Hirschberg et. al <ref> [Hir76, HCS79, CLC82] </ref> showed an O (n 2 ) work algorithm for CREW PRAMs. This algorithm starts with the adjacency matrix of the graph and shrinks the graph based on local connectiviety information at each step, recomputing the new matrix each time.
Reference: [HRD94] <author> T. Hsu, V. Ramachandran, and N. Dean. </author> <title> Parallel implementation of algorithms for finding connected components. In DIMACS implementation challenge, </title> <year> 1994. </year>
Reference-contexts: However, the sequential machine did not have sufficient memory to store graphs larger than 8K nodes. While developing and testing these algorithms we created graphs `on the fly' as by some other research projects <ref> [KLCY94, HRD94] </ref>. However, we found that this method presented two problems. First, duplicate edges were created which inflated the `actual' number of edges; our algorithms seemed to work faster.
Reference: [HW90] <author> Y. Han and A. Wagner. </author> <title> An efficient and fast parallel-connected component algorithm. </title> <journal> JACM, </journal> <volume> 37(3) </volume> <pages> 626-642, </pages> <year> 1990. </year>
Reference: [J 92] <author> J. Jaja. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison Wesley, </publisher> <address> NewYork, </address> <year> 1992. </year>
Reference-contexts: We have chosen instead to report results measured on the canonical graph benchmarks of random and tertiary graphs and variations thereof. Apart from the algorithms described in this paper, we also implemented some well known algorithms from Jaja's text <ref> [J 92, Vis84, SV82] </ref> on the MasPar using both MPL and NESL. Though those implementations were very naive and unoptimized, an improvement by a factor of more than a hundred suggests our algorithms performed well on meshes.
Reference: [KLCY94] <author> A. Krishnamurthy, S. Lumetta, D. Culler, and K. Yelick. </author> <title> Connected components on distributed memory machines. In DIMACS implementation challenge, </title> <year> 1994. </year>
Reference-contexts: However, the sequential machine did not have sufficient memory to store graphs larger than 8K nodes. While developing and testing these algorithms we created graphs `on the fly' as by some other research projects <ref> [KLCY94, HRD94] </ref>. However, we found that this method presented two problems. First, duplicate edges were created which inflated the `actual' number of edges; our algorithms seemed to work faster. <p> Thus, each tertiary graph has 1.5n edges. As with all graphs generated by mkgraph, no self-loops or duplicate edges are allowed. We varied the definition of tertiary graphs, but the performance of our algorithms was not really affected. In particular, we created AD3 <ref> [KLCY94] </ref> graphs. Each vertex in an AD3 graph selects between 0 and 3 neighbors so that one vertex may end up being directly connected to many different nodes. Such graphs tend to have more components [KLCY94]. <p> In particular, we created AD3 <ref> [KLCY94] </ref> graphs. Each vertex in an AD3 graph selects between 0 and 3 neighbors so that one vertex may end up being directly connected to many different nodes. Such graphs tend to have more components [KLCY94]. We also generated graphs in which the degree of each vertex lies between 0 and 6 (uniformly distributed). These graphs also followed the behavior of tertiary graphs.
Reference: [KRS86] <author> C. Kruskal, L. Rudolph, and M. Snir. </author> <title> Efficient paralle algoritms for graph problems. </title> <booktitle> In 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 278-284, </pages> <address> St. Charles, Illinois, </address> <year> 1986. </year>
Reference: [SV82] <author> Y. Shiloach and U. Vishkin. </author> <title> An o(log n) parallel connectivity algorithm. </title> <journal> Journal of Algorithms, </journal> <volume> 3(1) </volume> <pages> 57-67, </pages> <year> 1982. </year> <note> 14 KUMAR, GODDARD, AND PRINS </note>
Reference-contexts: Hirschberg et. al [Hir76, HCS79, CLC82] showed an O (n 2 ) work algorithm for CREW PRAMs. This algorithm starts with the adjacency matrix of the graph and shrinks the graph based on local connectiviety information at each step, recomputing the new matrix each time. Shiloach et. al <ref> [SV82, AS87] </ref> use a similar idea for sparse graphs. This CRCW-PRAM algorithm starts with a list of edges, forming trees of connected vertices and grafting smaller trees to form larger trees till all vertices of a component are in the same tree. <p> There must exist two consecutive nodes i 0 and j 0 on this path such that the edge (i 0 ; j 0 ) 2 G, and P (i 0 ) 6= P (j 0 ). But then 2 Contrast this with the grafting operation of <ref> [SV82] </ref> 4 KUMAR, GODDARD, AND PRINS the algorithm could not have terminated since either P (i 0 ) &lt; P (j 0 ) and P (i 0 ) must change or vice-versa. 2.2. Complexity: Let us define a chain as follows: * i and P (i) lie on a chain. <p> We have chosen instead to report results measured on the canonical graph benchmarks of random and tertiary graphs and variations thereof. Apart from the algorithms described in this paper, we also implemented some well known algorithms from Jaja's text <ref> [J 92, Vis84, SV82] </ref> on the MasPar using both MPL and NESL. Though those implementations were very naive and unoptimized, an improvement by a factor of more than a hundred suggests our algorithms performed well on meshes.
Reference: [Vis84] <author> U. Vishkin. </author> <title> An optimal parallel connecttivity algorithm. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 9(2) </volume> <pages> 197-207, </pages> <year> 1984. </year>
Reference-contexts: We have chosen instead to report results measured on the canonical graph benchmarks of random and tertiary graphs and variations thereof. Apart from the algorithms described in this paper, we also implemented some well known algorithms from Jaja's text <ref> [J 92, Vis84, SV82] </ref> on the MasPar using both MPL and NESL. Though those implementations were very naive and unoptimized, an improvement by a factor of more than a hundred suggests our algorithms performed well on meshes.
Reference: [Wyl79] <author> J. Wyllie. </author> <title> The Complexity of Parallel Computation. </title> <type> PhD thesis, </type> <institution> Cornell University, Department of Computer Science, Ithaca, NewYork, 1979. Department of Computer Science, University of North Carolina, </institution> <address> Chapel Hill NC 27599-3175, USA, </address> <publisher> E-mail address: kumar@cs.unc.edu </publisher>
References-found: 14

