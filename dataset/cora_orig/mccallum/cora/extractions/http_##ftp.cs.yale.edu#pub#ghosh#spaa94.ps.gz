URL: http://ftp.cs.yale.edu/pub/ghosh/spaa94.ps.gz
Refering-URL: http://ftp.cs.yale.edu/pub/ghosh/
Root-URL: http://www.cs.yale.edu
Email: ghosh@cs.yale.edu.  muthu@cs.nyu.edu,  
Title: Dynamic Load Balancing in Parallel and Distributed Networks by Random Matchings (Extended Abstract)  
Author: Bhaskar Ghosh S. Muthukrishnan 
Note: Research supported by ONR under grant number 4-91-J-1576 and a Yale/IBM joint study.  (212) 998-3061. The research of this author was supported in part by NSF/DARPA under grant number CCR-89-06949 and by NSF under grant number CCR-91-03953.  
Address: P.O.Box 208285, New Haven, CT 06520. Internet  New York University, 251 Mercer Street, New York, NY 10012-1185, USA;  
Affiliation: Departmentof Computer Science, Yale University,  Courant Institute of Mathematical Sciences,  
Abstract: The fundamental problems in dynamic load balancing and job scheduling in parallel and distributed computers involve moving load between processors. In this paper, we consider a new model for load movement in synchronous parallel and distributed machines. In each step of our model, each processor can transfer load to at most one neighbor; also, any amount of load can be moved along a communication link between two processors in one step. This is a reasonable model for load movement in significant classes of dynamic load balancing problems. We derive efficient algorithms for a number of task reallocation problems under our model of load movement. These include dynamic load balancing on processor networks, adaptive mesh re-partitioning such as those in finite element methods, and progressive job migration under dynamic generation and consumption of load. To obtain the above-mentioned results, we introduce and solve the abstract problem of Incremental Weight Migration (IWM) on arbitrary graphs. Our main result is a simple, randomized, algorithm for this problem which provably results in asymptotically optimal convergence towards the state where weights on the nodes of the graph are all equal. This algorithm utilizes an appropriate random set of edges forming a matching. Our algorithm for the IWM problem is used in deriving efficient algorithms for all the problems mentioned above. Our results are very general. The algorithms we derive are local, and hence, scalable. They work for arbitrary load distributions and for networks of arbitrary topology which can possibly undergo link failures. Of independent interest is our proof technique which we use to lower bound the convergence of our algorithms in terms of the eigenstructure of the underlying graph. Finally, we present preliminary experimental results analyzing issues in load balancing related to our algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [AA+93] <author> W. Aiello, B. Awerbuch, B. Maggs, and S. Rao. </author> <title> Approximate Load Balancing on Dynamic and Asynchronous Networks. </title> <booktitle> In Proc. of 25th ACM Symp on Theory of Computing, </booktitle> <pages> 632-641, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In each of these guises, equitable load redistribution is critical for efficient implementation of algorithms on both distributed and parallel computers. Standard models for dynamic load balancing make 1 the following assumptions. (See for example <ref> [AA+93, LM93, R91] </ref>.) In one time step, each processor can migrate load to any (possibly all) of the other processors (possibly including non-neighbors). Also, at most one unit of load can be transferred across any link in a step. Under this model, dynamic load balancing has been extensively studied. <p> For arbitrary topologies, under the assumption that one load unit can be migrated across each edge in parallel and that each processor can communicate with all its neighbors in one step, <ref> [AA+93] </ref> presents an algorithm for dynamic load balancing which takes O ( log (n)=) steps to approximately balance the loads. The approximation is within an additive term of d fi diameter (G). <p> Note that our algorithm is the first known algorithm to make such a guarantee. In a related work <ref> [AA+93] </ref>, (under the weaker assumption that tasks are not dynamically generated or consumed), a distance function (different from ours) is used to measure the progress towards the load-balanced state in several steps. <p> For choosing such a random matching, we draw upon the intuition from the very sparse phase in the evolution of random graphs [B87]. There appears to be some connection between our techniques for analyzing our algorithm and those used in analyzing rapidly mixing properties of Markov Chains <ref> [M89, AA+93] </ref>. However no formal connection is known to us. 1.5 Organization of the Paper The IWM problem for real weights is solved in Section 3. We extend this solution in Section 4 to the case when the weights are discrete. <p> As a result we derive an algorithm which converges to the load balanced state provably faster (when the initial potential is sufficiently large) than the fastest algorithm previously known <ref> [AA+93] </ref> for this problem. In fact our algorithm works on a weaker model than the one in [AA+93]. However, our algorithm is randomized while the algorithm in [AA+93] is deter ministic. <p> As a result we derive an algorithm which converges to the load balanced state provably faster (when the initial potential is sufficiently large) than the fastest algorithm previously known <ref> [AA+93] </ref> for this problem. In fact our algorithm works on a weaker model than the one in [AA+93]. However, our algorithm is randomized while the algorithm in [AA+93] is deter ministic. We defer further details to the full paper. 8 Acknowledgements Thanks to Ravi Boppana, Stan Eisenstat, Laszlo Lo-vasz, Eric Mjolsness and Martin Schultz for their critical feedback and encouragement during this work. <p> algorithm which converges to the load balanced state provably faster (when the initial potential is sufficiently large) than the fastest algorithm previously known <ref> [AA+93] </ref> for this problem. In fact our algorithm works on a weaker model than the one in [AA+93]. However, our algorithm is randomized while the algorithm in [AA+93] is deter ministic. We defer further details to the full paper. 8 Acknowledgements Thanks to Ravi Boppana, Stan Eisenstat, Laszlo Lo-vasz, Eric Mjolsness and Martin Schultz for their critical feedback and encouragement during this work.
Reference: [AB92] <author> Y. Aumann and M. Ben-Or. </author> <title> Computing with Faulty Arrays. </title> <booktitle> In Proc of 24th ACM Symp on Theory of Computing, </booktitle> <pages> 162-169, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: These algorithms do not ex tend to arbitrary or dynamically changing topologies. For dynamically changing topologies, load balancing has been studied under assumptions on the pattern of failures for specific architectures <ref> [R89, AB92] </ref>.
Reference: [AHS91] <author> J. Aspnes, M. Herlihy and N. Shavit. </author> <title> Counting Networks and Multiprocessor coordination. </title> <booktitle> In Proc of 23rd ACM Symp on Theory of Computing, </booktitle> <pages> 348-358, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Among analytical results, load balancing for specific topologies under statistical assumptions on input load distributions has been studied [HCT89]. For arbitrary initial load distribution, load balancing has been studied in special topologies such as Counting Networks <ref> [AHS91, HLS92] </ref> Hypercubes [P89], Meshes [HT93] and Expanders [PU89]. These algorithms do not ex tend to arbitrary or dynamically changing topologies. For dynamically changing topologies, load balancing has been studied under assumptions on the pattern of failures for specific architectures [R89, AB92].
Reference: [B87] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <address> New York. </address> <year> 1987. </year>
Reference-contexts: This property ensures global conver gence bounds. For choosing such a random matching, we draw upon the intuition from the very sparse phase in the evolution of random graphs <ref> [B87] </ref>. There appears to be some connection between our techniques for analyzing our algorithm and those used in analyzing rapidly mixing properties of Markov Chains [M89, AA+93].
Reference: [BB87] <author> M. J. Berger and S. H. Bokhari. </author> <title> A Partitioning Strategy for Nonuniform Problems on Multiprocessors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. C-36, No. 5, </volume> <pages> 570-580, </pages> <year> 1987. </year>
Reference-contexts: Achieving balanced sub-domains usually involves shifting the boundaries of adjoining sub-domains (i.e., across edges in the quotient graph) so as to equalize the data points in each sub-domain. Further references on these areas can be found in <ref> [BB87, HT93, W91] </ref>. Clearly, our algorithm for the IWM problem can be used repeatedly on the quotient graph to solve the problem of mesh partitioning.
Reference: [CA87] <author> G. Cybenko and T. G. Allen. </author> <title> Parallel Algorithms for Classification and Clustering. </title> <booktitle> In Proc. SPIE Conference on Advanced Architectures and Algorithms for Signal Processing, </booktitle> <address> San Diego, CA 1987. </address>
Reference-contexts: This is an appropriate model when each task has small associated data space; therefore several tasks can be communicated in one time step. This is true for a large class of problems like fine grain programs which spawn processes dynamically [GH89, K88], real time data fusion problems <ref> [CA87, FG91] </ref> and game tree searches [F93]. Clearly, the dynamic load balancing problem for discrete weights can be solved by applying our algorithm for the IWM problem repeatedly. This algorithm balances load approximately in O ((d= 2 )(log 0 + dn)) invocations of our algorithm for the IWM problem.
Reference: [C89] <author> G. Cybenko. </author> <title> Dynamic Load Balancing for Distributed Memory Multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 2, No. 7, </volume> <pages> 279-301, </pages> <year> 1989. </year>
Reference-contexts: The load balancing is approximate in the sense that our algorithm stops when for each edge (i; j); j w i w j j 1. Our algorithm works for arbitrary topologies under possible failure of links connecting the processors. We remark that Cybenko <ref> [C89] </ref> considered a stronger version of our model by additionally allowing each processor to transfer load to all its neighbors in one time step. This work is of mathematical interest since it considers only the case when the weights are real. Problem Re-Partitioning.
Reference: [F93] <author> R. Feldmann. </author> <title> Game Tree Search on Massively Parallel Systems. </title> <type> PhD Thesis, </type> <institution> Dept. of Mathematics and Computer Science, University of Paderborn. </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: This is true for a large class of problems like fine grain programs which spawn processes dynamically [GH89, K88], real time data fusion problems [CA87, FG91] and game tree searches <ref> [F93] </ref>. Clearly, the dynamic load balancing problem for discrete weights can be solved by applying our algorithm for the IWM problem repeatedly. This algorithm balances load approximately in O ((d= 2 )(log 0 + dn)) invocations of our algorithm for the IWM problem.
Reference: [FG91] <author> M. Factor and D. Gelernter. </author> <title> Software Back-planes, Realtime Data Fusion and the Process Trellis. </title> <institution> Research Report YALEU/DCS/TR-852, Yale Computer Science Department, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: This is an appropriate model when each task has small associated data space; therefore several tasks can be communicated in one time step. This is true for a large class of problems like fine grain programs which spawn processes dynamically [GH89, K88], real time data fusion problems <ref> [CA87, FG91] </ref> and game tree searches [F93]. Clearly, the dynamic load balancing problem for discrete weights can be solved by applying our algorithm for the IWM problem repeatedly. This algorithm balances load approximately in O ((d= 2 )(log 0 + dn)) invocations of our algorithm for the IWM problem.
Reference: [GH89] <author> B. Goldberg and P. Hudak. </author> <title> Implementing Functional Programs on a Hypercube Multiprocessor. </title> <booktitle> In Proc. of the 4th Conference on Hypercubes, Concurrent Computers and Applications, </booktitle> <volume> Vol. 1, </volume> <pages> 489-503, </pages> <year> 1989. </year>
Reference-contexts: This is an appropriate model when each task has small associated data space; therefore several tasks can be communicated in one time step. This is true for a large class of problems like fine grain programs which spawn processes dynamically <ref> [GH89, K88] </ref>, real time data fusion problems [CA87, FG91] and game tree searches [F93]. Clearly, the dynamic load balancing problem for discrete weights can be solved by applying our algorithm for the IWM problem repeatedly.
Reference: [HCT89] <author> J. Hong, M. Chen and X. Tan. </author> <title> Dynamic Cyclic Load Balancing on Hypercubes. </title> <booktitle> In Proc. of the 4th Conference on Hypercubes, Concurrent Computers and Applications, </booktitle> <volume> Vol. 1, </volume> <pages> 595-598, </pages> <year> 1989. </year>
Reference-contexts: A class of such research has involved performance analysis of load balancing algorithms by simulations [LMR91]. Among analytical results, load balancing for specific topologies under statistical assumptions on input load distributions has been studied <ref> [HCT89] </ref>. For arbitrary initial load distribution, load balancing has been studied in special topologies such as Counting Networks [AHS91, HLS92] Hypercubes [P89], Meshes [HT93] and Expanders [PU89]. These algorithms do not ex tend to arbitrary or dynamically changing topologies.
Reference: [HLS92] <author> M. Herlihy, B. Lim, and N. Shavit. </author> <title> Low contention load balancing on large-scale multiprocessors. </title> <booktitle> In Proc. of 4th ACM Symp on Parallel Algorithms and Architectures, </booktitle> <pages> 219-227, </pages> <year> 1992. </year>
Reference-contexts: Among analytical results, load balancing for specific topologies under statistical assumptions on input load distributions has been studied [HCT89]. For arbitrary initial load distribution, load balancing has been studied in special topologies such as Counting Networks <ref> [AHS91, HLS92] </ref> Hypercubes [P89], Meshes [HT93] and Expanders [PU89]. These algorithms do not ex tend to arbitrary or dynamically changing topologies. For dynamically changing topologies, load balancing has been studied under assumptions on the pattern of failures for specific architectures [R89, AB92].
Reference: [HT93] <author> A. Heirich and S. Taylor. </author> <title> A Parabolic Theory of Load Balance. </title> <institution> Research Report Caltech-CS-TR-93-25, Caltech Scalable Concurrent Computation Lab, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Among analytical results, load balancing for specific topologies under statistical assumptions on input load distributions has been studied [HCT89]. For arbitrary initial load distribution, load balancing has been studied in special topologies such as Counting Networks [AHS91, HLS92] Hypercubes [P89], Meshes <ref> [HT93] </ref> and Expanders [PU89]. These algorithms do not ex tend to arbitrary or dynamically changing topologies. For dynamically changing topologies, load balancing has been studied under assumptions on the pattern of failures for specific architectures [R89, AB92]. <p> Achieving balanced sub-domains usually involves shifting the boundaries of adjoining sub-domains (i.e., across edges in the quotient graph) so as to equalize the data points in each sub-domain. Further references on these areas can be found in <ref> [BB87, HT93, W91] </ref>. Clearly, our algorithm for the IWM problem can be used repeatedly on the quotient graph to solve the problem of mesh partitioning.
Reference: [K88] <author> L. V. Kale. </author> <title> Comparing the Performance of Two Dynamic Load Distribution Methods. </title> <booktitle> In Proc. of International Conference on Parallel Processing, </booktitle> <volume> Vol. 1, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: This is an appropriate model when each task has small associated data space; therefore several tasks can be communicated in one time step. This is true for a large class of problems like fine grain programs which spawn processes dynamically <ref> [GH89, K88] </ref>, real time data fusion problems [CA87, FG91] and game tree searches [F93]. Clearly, the dynamic load balancing problem for discrete weights can be solved by applying our algorithm for the IWM problem repeatedly.
Reference: [KZ88] <author> R. Karp and Y. Zhang. </author> <title> A randomized parallel branch-and-bound procedure. </title> <booktitle> In Proc. of 20th ACM Symp on Theory of Computing, </booktitle> <pages> 290-300, </pages> <year> 1988. </year>
Reference-contexts: We are required to schedule the tasks in each step by moving them to underloaded or idle processors so as to increase the throughput. This scenario arises in general purpose distributed computing [LK87, NX+85] as well as in specific applications such as the parallel branch-and-bound search on game trees <ref> [KZ88] </ref> and dynamic tree embeddings on distributed or parallel architectures [LN+89, R91]. We initiate a new paradigm for these problems. For motivation, note that there are broadly two paradigms for task scheduling in this scenario.
Reference: [LK87] <author> F. C. H. Lin and R. M. Keller. </author> <title> The Gradient Model Load Balancing Method. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 13, No. 1, </volume> <pages> 32-38, </pages> <year> 1987. </year>
Reference-contexts: We are required to schedule the tasks in each step by moving them to underloaded or idle processors so as to increase the throughput. This scenario arises in general purpose distributed computing <ref> [LK87, NX+85] </ref> as well as in specific applications such as the parallel branch-and-bound search on game trees [KZ88] and dynamic tree embeddings on distributed or parallel architectures [LN+89, R91]. We initiate a new paradigm for these problems.
Reference: [LM93] <author> R. Lueling and B. Monien. </author> <title> A Dynamic Distributed Load Balancing Algorithm with Provable Good Performance. </title> <booktitle> In Proc. of 5th ACM Symp on Parallel Algorithms and Architectures, </booktitle> <pages> 164-172, </pages> <year> 1993. </year>
Reference-contexts: In each of these guises, equitable load redistribution is critical for efficient implementation of algorithms on both distributed and parallel computers. Standard models for dynamic load balancing make 1 the following assumptions. (See for example <ref> [AA+93, LM93, R91] </ref>.) In one time step, each processor can migrate load to any (possibly all) of the other processors (possibly including non-neighbors). Also, at most one unit of load can be transferred across any link in a step. Under this model, dynamic load balancing has been extensively studied.
Reference: [LMR91] <author> R. Lueling, B. Monien and F. Ramme. </author> <title> Load Balancing in Large Networks: A Comparative Study. </title> <booktitle> In Proc. of IEEE Symp on Parallel and Distributed Computing, </booktitle> <address> Dallas, </address> <year> 1991. </year>
Reference-contexts: Dynamic load balancing has been studied in a number of settings. Almost all research has focused on algorithms for specific topologies and/or rely on global routing phases. A class of such research has involved performance analysis of load balancing algorithms by simulations <ref> [LMR91] </ref>. Among analytical results, load balancing for specific topologies under statistical assumptions on input load distributions has been studied [HCT89]. For arbitrary initial load distribution, load balancing has been studied in special topologies such as Counting Networks [AHS91, HLS92] Hypercubes [P89], Meshes [HT93] and Expanders [PU89].
Reference: [LN+89] <author> T. Leighton, M. Newman, A. Ranade and E. Schwabe. </author> <title> Dynamic tree embeddings on butterflies and hypercubes. </title> <booktitle> In Proc. of 1st ACM Symp on Parallel Algorithms and Architectures, </booktitle> <pages> 224-234, </pages> <year> 1989. </year>
Reference-contexts: This scenario arises in general purpose distributed computing [LK87, NX+85] as well as in specific applications such as the parallel branch-and-bound search on game trees [KZ88] and dynamic tree embeddings on distributed or parallel architectures <ref> [LN+89, R91] </ref>. We initiate a new paradigm for these problems. For motivation, note that there are broadly two paradigms for task scheduling in this scenario. In one paradigm, the scheduling guarantees that each processor has at least one task to execute at the end of the step.
Reference: [M89] <author> M. Mihail. </author> <title> Conductance and Convergence of Markov Chains A Combinatorial Treatment of Expanders. </title> <booktitle> In Proc. of 30th IEEE Symp on Foundations of Computer Science, </booktitle> <pages> 526-531, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: For choosing such a random matching, we draw upon the intuition from the very sparse phase in the evolution of random graphs [B87]. There appears to be some connection between our techniques for analyzing our algorithm and those used in analyzing rapidly mixing properties of Markov Chains <ref> [M89, AA+93] </ref>. However no formal connection is known to us. 1.5 Organization of the Paper The IWM problem for real weights is solved in Section 3. We extend this solution in Section 4 to the case when the weights are discrete.
Reference: [MP92] <author> B. Mohar and S. Poljak. </author> <title> Eigenvalues in Combinatorial Optimization. </title> <type> Research Report 92752, IMA, </type> <institution> Minneapolis, </institution> <year> 1992. </year>
Reference-contexts: Fact 1. G is a connected graph if and only if 2 &gt; 0. It can be shown that for any connected graph with n vertices, 2 = (1=n 2 ). Fact 2. From the Courant-Fischer Minimax Theo rem, it follows that <ref> [MP92] </ref>, 2 = min x T x where v 1 = (1; 1; :::; 1) T is the eigenvector correspond ing to 1 = 0 and x ? v 1 implies that the vector x is orthogonal to v 1 . 3 Algorithm for IWM (Real Weights) In this section we
Reference: [N92] <author> D. Nicol. </author> <title> Communication Efficient Global Load Balancing. </title> <booktitle> In Proc. of Scalable High Performance Computing Conference, </booktitle> <pages> 292-299. </pages> <address> Williamsburg, VA. </address> <month> April </month> <year> 1992. </year>
Reference: [NX+85] <author> L. M. Ni, C. W. Xu and T. B. Gendreau. </author> <title> Drafting Algorithm ADynamic Process Migration Protocol for Distributed Systems. </title> <booktitle> In Proc. of Int. Conf. on Distributed Computing Systems, </booktitle> <pages> 539-546, </pages> <year> 1985. </year>
Reference-contexts: We are required to schedule the tasks in each step by moving them to underloaded or idle processors so as to increase the throughput. This scenario arises in general purpose distributed computing <ref> [LK87, NX+85] </ref> as well as in specific applications such as the parallel branch-and-bound search on game trees [KZ88] and dynamic tree embeddings on distributed or parallel architectures [LN+89, R91]. We initiate a new paradigm for these problems.
Reference: [P89] <author> C. G. Plaxton. </author> <title> Load Balancing, Selection and Sorting on the Hypercube. </title> <booktitle> Proc. of 1st ACM Symp on Parallel Algorithms and Architectures, </booktitle> <pages> 64-73, </pages> <year> 1989. </year>
Reference-contexts: Among analytical results, load balancing for specific topologies under statistical assumptions on input load distributions has been studied [HCT89]. For arbitrary initial load distribution, load balancing has been studied in special topologies such as Counting Networks [AHS91, HLS92] Hypercubes <ref> [P89] </ref>, Meshes [HT93] and Expanders [PU89]. These algorithms do not ex tend to arbitrary or dynamically changing topologies. For dynamically changing topologies, load balancing has been studied under assumptions on the pattern of failures for specific architectures [R89, AB92].
Reference: [PU89] <author> D. Peleg and E. Upfal. </author> <title> The token distribution problem. </title> <journal> SIAM J. on Computing, </journal> <volume> Volume 18, </volume> <pages> 229-243, </pages> <year> 1989. </year>
Reference-contexts: Among analytical results, load balancing for specific topologies under statistical assumptions on input load distributions has been studied [HCT89]. For arbitrary initial load distribution, load balancing has been studied in special topologies such as Counting Networks [AHS91, HLS92] Hypercubes [P89], Meshes [HT93] and Expanders <ref> [PU89] </ref>. These algorithms do not ex tend to arbitrary or dynamically changing topologies. For dynamically changing topologies, load balancing has been studied under assumptions on the pattern of failures for specific architectures [R89, AB92].
Reference: [R89] <author> M. O. Rabin. </author> <title> Efficient dispersal of information for security, load balancing and fault tolerance. </title> <journal> Journal of the ACM, </journal> <volume> Vol. 36, No. 3, </volume> <pages> 335-348, </pages> <year> 1989. </year>
Reference-contexts: These algorithms do not ex tend to arbitrary or dynamically changing topologies. For dynamically changing topologies, load balancing has been studied under assumptions on the pattern of failures for specific architectures <ref> [R89, AB92] </ref>.
Reference: [R91] <author> A. Ranade. </author> <title> Optimal speedup for backtrack search on a butterfly network. </title> <booktitle> In Proc. 3rd ACM Symp on Parallel Algorithms and Architectures, </booktitle> <pages> 40-49, </pages> <year> 1991. </year>
Reference-contexts: In each of these guises, equitable load redistribution is critical for efficient implementation of algorithms on both distributed and parallel computers. Standard models for dynamic load balancing make 1 the following assumptions. (See for example <ref> [AA+93, LM93, R91] </ref>.) In one time step, each processor can migrate load to any (possibly all) of the other processors (possibly including non-neighbors). Also, at most one unit of load can be transferred across any link in a step. Under this model, dynamic load balancing has been extensively studied. <p> This scenario arises in general purpose distributed computing [LK87, NX+85] as well as in specific applications such as the parallel branch-and-bound search on game trees [KZ88] and dynamic tree embeddings on distributed or parallel architectures <ref> [LN+89, R91] </ref>. We initiate a new paradigm for these problems. For motivation, note that there are broadly two paradigms for task scheduling in this scenario. In one paradigm, the scheduling guarantees that each processor has at least one task to execute at the end of the step.
Reference: [RSU91] <author> L. Rudolph, M. Slivkin-Allalouf, and E. Upfal. </author> <title> A simple load balancing scheme for task allocation in parallel machines. </title> <booktitle> In Proc. 3rd ACM Symp on Parallel Algorithms and Architectures, </booktitle> <pages> 237-243, </pages> <year> 1991. </year>

References-found: 28

