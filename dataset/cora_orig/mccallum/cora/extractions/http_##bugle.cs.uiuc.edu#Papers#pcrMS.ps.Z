URL: http://bugle.cs.uiuc.edu/Papers/pcrMS.ps.Z
Refering-URL: http://bugle.cs.uiuc.edu/Papers/pcrMS.html
Root-URL: http://www.cs.uiuc.edu
Title: ETRUSCA: EVENT TRACE REDUCTION USING STATISTICAL DATA CLUSTERING ANALYSIS  
Author: BY PHILIP CHARLES ROTH 
Degree: THESIS Submitted in partial fulfillment of the requirements for the degree of Master of Science in Computer Science in the Graduate College of the  
Date: 1992  
Address: Iowa,  1996 Urbana, Illinois  
Affiliation: B.S., University of  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Anderson, T., and Lazowska, E. Quartz: </author> <title> A Tool for Tuning Parallel Program Performance. </title> <booktitle> In Proceedings of the 1990 SIGMETRICS Conference on Measurement and Modeling of Computer Systems (Boston, </booktitle> <month> May </month> <year> 1990), </year> <journal> Association for Computing Machinery, </journal> <pages> pp. 115-125. </pages>
Reference-contexts: An external sampling task periodically examines the system state, and updates a counter associated with the observed state. When the profiling interval is complete, the counter values are proportional to the amount of time spent in each observed state. Quartz <ref> [1] </ref> and gprof [5] are two common profiling tools for use on parallel and uniprocessor systems, respectively. Both associate a sampling state with each of a profiled program's source code functions. When the program completes, the counters indicate the approximate proportion of execution time spent in each function.
Reference: [2] <author> Argawal, A., and Huffman, M. </author> <title> Blocking: Exploiting Spatial Locality for Trace Compaction. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on the Measurement and Modeling of Computer Systems (May 1990), Association for Computing Machinery, </booktitle> <pages> pp. 48-57. </pages>
Reference-contexts: Several studies investigate the volume reduction of performance data taken from a restricted problem domain. For example, Wang and Baer [11] detail a reduction technique for memory reference traces that retains sufficient information to exactly reproduce the cache simulation obtained with the full trace. Argawal and Huffman <ref> [2] </ref> describe a similar method for compacting memory reference traces. Ball and Larus [4] present two algorithms which determine program profiling and tracing instrumentation points which significantly reduce the volume of performance data generated.
Reference: [3] <author> Aydt, R. A. SDDF: </author> <title> The Pablo Self-Describing Data Format. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: ETRUSCA uses as input a set of event trace data files in Pablo Self-Defining Data Format (SDDF) <ref> [3] </ref>, taken from an instrumented parallel application. These files are merged using the SDDFmerger tool, resulting in a file whose event traces are sorted in non-decreasing order.
Reference: [4] <author> Ball, T., and Larus, J. R. </author> <title> Optimally Profiling and Tracing Programs. </title> <journal> ACM Transactions on Programming Languages and Systems 16, </journal> <month> 4 (July </month> <year> 1994), </year> <pages> 1319-1360. </pages>
Reference-contexts: For example, Wang and Baer [11] detail a reduction technique for memory reference traces that retains sufficient information to exactly reproduce the cache simulation obtained with the full trace. Argawal and Huffman [2] describe a similar method for compacting memory reference traces. Ball and Larus <ref> [4] </ref> present two algorithms which determine program profiling and tracing instrumentation points which significantly reduce the volume of performance data generated. Their approach, however, requires a computationally intensive post-processing phase to derive the complete profile or event trace, limiting its usefulness for real-time performance data analysis.
Reference: [5] <author> Graham, S., Kessler, P., and McKusick, M. </author> <title> gprof: A Call Graph Execution Profiler. </title> <booktitle> In Proceedings of the '82 Symposium on Compiler Construction (Boston, </booktitle> <month> June </month> <year> 1982), </year> <journal> Association for Computing Machinery, </journal> <pages> pp. 120-126. </pages>
Reference-contexts: An external sampling task periodically examines the system state, and updates a counter associated with the observed state. When the profiling interval is complete, the counter values are proportional to the amount of time spent in each observed state. Quartz [1] and gprof <ref> [5] </ref> are two common profiling tools for use on parallel and uniprocessor systems, respectively. Both associate a sampling state with each of a profiled program's source code functions. When the program completes, the counters indicate the approximate proportion of execution time spent in each function.
Reference: [6] <author> Hollingsworth, J. K., and Miller, B. P. </author> <title> Dynamic Control of Performance Monitoring on Large Scale Parallel Systems. </title> <booktitle> In 7th ACM International Conference on Supercomputing (Tokyo, </booktitle> <month> July </month> <year> 1993), </year> <journal> Association for Computing Machinery, </journal> <pages> pp. 185-194. 89 </pages>
Reference-contexts: Instead of capturing data for the duration of execution, their system provides the capability to capture data for the "interesting" intervals (those requiring optimization), while ignoring those portions that are not problematic or are well understood. Hollingsworth and Miller <ref> [6] </ref> also describe an expert system called Performance Consultant which guides parallel application developers toward those areas of interest. During intervals when performance data capture is enabled, data is gathered from all nodes in the system.
Reference: [7] <author> Hollingsworth, J. K., Miller, B. P., and Cargille, J. </author> <title> Dynamic Program Instrumentation for Scalable Performance Tools. </title> <booktitle> In Scalable High Performance Computing Conference (Knoxville, </booktitle> <address> TN, </address> <month> May </month> <year> 1994). </year>
Reference-contexts: While these techniques are effective and efficient for their particular problem domain, they rely on characteristics of the performance data or its analysis which may not be present in more general event traces. 6 Hollingsworth, Miller, and Cargille <ref> [7] </ref> describe a data capture system that reduces performance data by dynamically enabling and disabling data capture during the execution of an instrumented application.
Reference: [8] <author> Jain, A. K., and Dubes, R. C. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: These two approaches to performance data reduction could be combined to leverage the advantages of both systems. Data clustering is a well-known statistical analysis method for finding structure in multidimensional data sets. In an introductory text, Jain and Dubes <ref> [8] </ref> present the data similarity concepts at the heart of cluster analysis. <p> We present only a minimal overview of the concept to facilitate the reader's understanding through the remainder of this thesis. The interested reader is directed to Jain and Dubes <ref> [8] </ref> for further information. 6 A square error clustering algorithm is well-suited for an ETRUSCA implementation|if we apply the square error algorithm to metric space points, the Euclidean distance between the data points may be viewed as a measure of the behavioral similarity of the nodes from which the points were
Reference: [9] <author> Reed, D. A. </author> <title> Performance Instrumentation Techniques for Parallel Systems. In Models and Techniques for Performance Evaluation of Computer and Communications Systems, </title> <editor> L. Donatiello and R. Nelson, Eds. </editor> <booktitle> Springer-Verlag Lecture Notes in Computer Science, </booktitle> <year> 1993, </year> <pages> pp. 463-490. </pages>
Reference-contexts: Access to accurate, detailed performance data is essential to the success of any such optimization effort. In particular, access to dynamic performance data is crucial to identify not only whether an application exhibits poor performance, but also where, when, and why its performance suffers. 1.1 Instrumentation Techniques Reed <ref> [9] </ref> describes four basic approaches to performance data capture: timing, counting, profiling, and tracing. Each approach exhibits a different balance among data volume, instrumentation perturbation, and implementation complexity.
Reference: [10] <author> Reed, D. A., Aydt, R. A., Noe, R. J., Roth, P. C., Shields, K. A., Schwartz, B. W., and Tavera, L. F. </author> <title> Scalable Performance Analysis: The Pablo Performance Analysis Environment. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <editor> A. Skjellum, Ed. </editor> <publisher> IEEE Computer Society, </publisher> <year> 1993. </year>
Reference-contexts: program's dynamic behavior, and the processing overhead required to track and cluster metric space points during program execution. 3.1 Prototype Components For the sake of simplicity and ease of experimentation, the prototype implementation of ETRUSCA is a post-mortem analysis tool that uses several components of the Pablo performance analysis environment <ref> [10] </ref> in its operation. 1 The process is illustrated in Figure 3.1. ETRUSCA uses as input a set of event trace data files in Pablo Self-Defining Data Format (SDDF) [3], taken from an instrumented parallel application.
Reference: [11] <author> Wang, W.-H., and Baer, J.-L. </author> <title> Efficient Trace-Driven Simulation Methods for Cache Performance Analysis. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on the Measurement and Modeling of Computer Systems (May 1990), Association for Computing Machinery, </booktitle> <pages> pp. 115-125. 90 </pages>
Reference-contexts: We present a system that reduces the performance data volume using statistical cluster analysis, while retaining an approximation of the program's dynamic behavior in its reduced event traces. Several studies investigate the volume reduction of performance data taken from a restricted problem domain. For example, Wang and Baer <ref> [11] </ref> detail a reduction technique for memory reference traces that retains sufficient information to exactly reproduce the cache simulation obtained with the full trace. Argawal and Huffman [2] describe a similar method for compacting memory reference traces.
References-found: 11

