URL: http://hobart.cs.umass.edu/~mmedia/postscript/dl97.ps.gz
Refering-URL: http://wagga.cs.umass.edu/~ajenkins/
Root-URL: 
Email: fvwu, manmathag@cs.umass.edu  
Title: Finding Text In Images  
Author: Victor Wu, R. Manmatha, Edward M. Riseman 
Keyword: text reading system, character recognition, multimedia indexing, digital libraries, text detection, text extraction, texture segmentation, filters, focus of attention, hierarchical processing, binarization, histogram-based thresholding, background removal, morphological processing, connected-components analysis.  
Address: Amherst, MA 01003-4610  
Affiliation: Center For Intelligent Information Retrieval Computer Science Department University of Massachusetts  
Abstract: There are many applications in which the automatic detection and recognition of text embedded in images is useful. These applications include multimedia systems, digital libraries, and Geographical Information Systems. When machine generated text is printed against clean backgrounds, it can be converted to a computer readble form (ASCII) using current Optical Character Recognition (OCR) technology. However, text is often printed against shaded or textured backgrounds or is embedded in images. Examples include maps, advertisements, photographs, videos and stock certificates. Current OCR and other document segmentation and recognition technologies cannot handle these situations well. In this paper, a system that automatically detects and extracts text in images is proposed. This system consists of four phases. First, by treating text as a distinctive texture, a texture segmentation scheme is used to focus attention on regions where it may occur. Second, strokes are extracted from the segmented text regions. Using reasonable heuristics on text strings, such as height similarity, spacing and alignment, the extracted strokes are then processed to form tight rectangular bounding boxes around the corresponding text strings. To detect text over a wide range of font sizes, the above steps are first applied to a pyramid of images generated from the input image, and then the boxes formed at each resolution of the pyramid are fused at the original resolution. Third, an algorithm which cleans up the background and binarizes the detected text is applied to extract the text from the regions enclosed by the bounding boxes in the input image . Finally, text bounding boxes are refined (re-generated) by using the extracted items as strokes. These new boxes usually bound text strings better. The clean-up and binarization process is then carried out on the regions in the input image bounded by the boxes to extract cleaner text. The extracted text can then be passed through a commercial OCR engine for recognition if the text is of an OCR-recognizable font. Experimental results show that the algorithms work well on images from a wide variety of sources, including newspapers, magazines, printed advertisements, photographs, digitized video frames, and checks. The system is also stable and robust|the system parameters work for all the experiments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. S. Baird and K. Thompson. </author> <title> Reading Chess. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 12(6) </volume> <pages> 552-559, </pages> <year> 1990. </year>
Reference-contexts: However, most such schemes require clean binary input [3, 15, 16, 17]; some assume specific document layouts such as newspapers [6] and technical journals [9]; others utilize domain-specific knowledge such as mail address blocks [12] or configurations of chess games <ref> [1] </ref>. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. The system takes both greyscale and binary images as input 3 . It detects text strings in the image and puts rectangular bounding boxes around them.
Reference: [2] <editor> Mindy Bokser. Omnidocument Technoligies. </editor> <booktitle> Proceedings of The IEEE, </booktitle> <volume> 80(7) </volume> <pages> 1066-1078, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: To build digital libraries, this large volume of information needs to be digitized into images and the text converted to ASCII for storage, retrieval, and easy manipulation. Current OCR technology <ref> [2, 8] </ref> is largely restricted to finding text printed against clean backgrounds, and cannot handle text printed against shaded or textured backgrounds, and/or embedded in images. There is thus a need for systems which extract and recognize text from general backgrounds.
Reference: [3] <author> Lloyd Alan Fletcher and Rangachar Kasturi. </author> <title> A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images. </title> <journal> IEEE Transactions on Pattern Analysis And Machine Intelligence, </journal> <volume> 10(6) </volume> <pages> 910-918, </pages> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: The pyramid of the input image is shown as I, I 1 , I 2 : : :; (b) An example input image; (c) Output of the system result before the Character Recognition module. non-text items. However, most such schemes require clean binary input <ref> [3, 15, 16, 17] </ref>; some assume specific document layouts such as newspapers [6] and technical journals [9]; others utilize domain-specific knowledge such as mail address blocks [12] or configurations of chess games [1]. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. <p> Bottom-up methods work by grouping small components (starting with pixels as connected components) into successively larger components until all blocks are found on the page <ref> [3, 10] </ref>. The third category of document segmentation methods treat text as a type of texture and hence use texture segmentation algorithms to detect text [5]. Many of these algorithms have limitations on their use. The top-down and bottom-up approaches require the input image to be binary.
Reference: [4] <author> C. A. Glasbey. </author> <title> An Analysis of Histogram-Based Thresholding Algorithms. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 55(6) </booktitle> <pages> 532-537, </pages> <month> Nov. </month> <year> 1993. </year>
Reference: [5] <author> Anil K. Jain and Sushil Bhattacharjee. </author> <title> Text Segmentation Using Gabor Filters for Automatic Document Processing. </title> <journal> Machine Vision and Applications, </journal> <volume> 5, </volume> <year> 1992. </year>
Reference-contexts: The third category of document segmentation methods treat text as a type of texture and hence use texture segmentation algorithms to detect text <ref> [5] </ref>. Many of these algorithms have limitations on their use. The top-down and bottom-up approaches require the input image to be binary. <p> The projection profile based schemes work if the page has a Manhattan layout: that is, there is only one skew angle and the page can be segmented by horizontal and vertical cuts. Although the texture segmentation scheme in <ref> [5] </ref> can in principle be applied to greyscale images, it was only used on binary document images, and in addition, the binarization problem was not addressed. <p> The first phase of the system, therefore, uses (Texture Segmentation (Figure 1 (a))) to segment the text (Section 2). This algorithm is based on the standard multi-channel filtering techniques in texture segmentation <ref> [5, 7] </ref>. It should be pointed out that texture segmentation schemes are not sufficient for text detection and extraction if images more complicated than clean newspaper scans have to be dealt with. <p> Thus, one natural way to detect text is by using texture segmentation. A standard approach to texture segmentation is to first filter the image using a bank of linear filters, such as Gaussian derivatives ([7] or Gabor functions <ref> [5] </ref> followed by some non-linear transformation such as half-wave rectification, full-wave rectification, or a hyperbolic function tanh (fft). Then features are computed to form a feature vector for each pixel from the filtered images. These feature vectors are then classified to segment the textures into different classes.
Reference: [6] <author> Mohamed Kamel and Aiguo Zhao. </author> <title> Extraction of Binary Character/Graphics Images from Grayscale Document Images. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 55(3) </volume> <pages> 203-217, </pages> <month> May. </month> <year> 1993. </year>
Reference-contexts: However, most such schemes require clean binary input [3, 15, 16, 17]; some assume specific document layouts such as newspapers <ref> [6] </ref> and technical journals [9]; others utilize domain-specific knowledge such as mail address blocks [12] or configurations of chess games [1]. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. The system takes both greyscale and binary images as input 3 . <p> Consequently, current OCR systems work poorly in these cases. 3 A binary image can be processed by first scaling it so that its intensity ranges from 0 to 255 2 One solution to the global thresholding problem is to use different thresholds for different local regions (adaptive thresholding) <ref> [6] </ref>. Trier and Taxt [14] report an evaluation of eleven local adaptive thresholding schemes. Many document segmentation methods have been proposed in the literature. Some of these methods are top-down approaches, some are bottom-up schemes, and others are based on texture segmentation schemes in computer vision.
Reference: [7] <author> Jitendra Malik and Pietro Perona. </author> <title> Preattentive texture discrimination with early vision mechanisms. </title> <journal> J. Opt. Soc. Am., </journal> <volume> 7(5) </volume> <pages> 923-932, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The first phase of the system, therefore, uses (Texture Segmentation (Figure 1 (a))) to segment the text (Section 2). This algorithm is based on the standard multi-channel filtering techniques in texture segmentation <ref> [5, 7] </ref>. It should be pointed out that texture segmentation schemes are not sufficient for text detection and extraction if images more complicated than clean newspaper scans have to be dealt with.
Reference: [8] <author> S. Mori, C. Y. Suen, and K. Yamamoto. </author> <title> Historical Review of OCR Research and Development. </title> <booktitle> Proceedings of The IEEE, </booktitle> <volume> 80(7) </volume> <pages> 1029-1058, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: To build digital libraries, this large volume of information needs to be digitized into images and the text converted to ASCII for storage, retrieval, and easy manipulation. Current OCR technology <ref> [2, 8] </ref> is largely restricted to finding text printed against clean backgrounds, and cannot handle text printed against shaded or textured backgrounds, and/or embedded in images. There is thus a need for systems which extract and recognize text from general backgrounds.
Reference: [9] <author> G. Nagy, S. Seth, and M. Viswanathan. </author> <title> A Prototype Document Image Analysis System for Technical Journals. </title> <booktitle> Computer, </booktitle> <pages> pages 10-22, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: However, most such schemes require clean binary input [3, 15, 16, 17]; some assume specific document layouts such as newspapers [6] and technical journals <ref> [9] </ref>; others utilize domain-specific knowledge such as mail address blocks [12] or configurations of chess games [1]. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. The system takes both greyscale and binary images as input 3 . <p> Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image first, then, horizontal and vertical projection profiles [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs <ref> [9, 13, 16] </ref>. Bottom-up methods work by grouping small components (starting with pixels as connected components) into successively larger components until all blocks are found on the page [3, 10].
Reference: [10] <author> Lawrence O'Gorman. </author> <title> The Document Spectrum for Page Layout Analysis. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15(11) </volume> <pages> 1162-1173, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Bottom-up methods work by grouping small components (starting with pixels as connected components) into successively larger components until all blocks are found on the page <ref> [3, 10] </ref>. The third category of document segmentation methods treat text as a type of texture and hence use texture segmentation algorithms to detect text [5]. Many of these algorithms have limitations on their use. The top-down and bottom-up approaches require the input image to be binary.
Reference: [11] <author> Lawrence O'Gorman. </author> <title> Binarization and Multithresholding of Document Images Using Connectivity. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 56(6) </volume> <pages> 494-506, </pages> <month> Nov. </month> <year> 1994. </year>
Reference: [12] <author> Paul W. Palumbo, Sargur N. Srihari, Jung Soh, Ramalingam Sridhar, and Victor Demjanenko. </author> <title> Postal Address Block Location in Real Time. </title> <booktitle> Computer, </booktitle> <pages> pages 34-42, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: However, most such schemes require clean binary input [3, 15, 16, 17]; some assume specific document layouts such as newspapers [6] and technical journals [9]; others utilize domain-specific knowledge such as mail address blocks <ref> [12] </ref> or configurations of chess games [1]. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. The system takes both greyscale and binary images as input 3 . It detects text strings in the image and puts rectangular bounding boxes around them.
Reference: [13] <author> Theo Pavlidis and Jiangying Zhou. </author> <title> Page Segmentation and Classification. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 54(6) </booktitle> <pages> 484-496, </pages> <month> Nov. </month> <year> 1992. </year> <title> [14] ivind Due Trier and Torfinn Taxt. Evaluation of Binarization Methods for Document Images. </title> <journal> IEEE Transactions on Pattern Analysis And Machine Intelligence, </journal> 17(3):312-315, March 1995. <volume> 13 </volume>
Reference-contexts: Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image first, then, horizontal and vertical projection profiles [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs <ref> [9, 13, 16] </ref>. Bottom-up methods work by grouping small components (starting with pixels as connected components) into successively larger components until all blocks are found on the page [3, 10].
Reference: [15] <author> F. M. Wahl, K. Y. Wong, and R. G. Casey. </author> <title> Block Segmentation and Text Extraction in Mixed Text/Image Documents. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 20 </volume> <pages> 375-390, </pages> <year> 1982. </year>
Reference-contexts: The pyramid of the input image is shown as I, I 1 , I 2 : : :; (b) An example input image; (c) Output of the system result before the Character Recognition module. non-text items. However, most such schemes require clean binary input <ref> [3, 15, 16, 17] </ref>; some assume specific document layouts such as newspapers [6] and technical journals [9]; others utilize domain-specific knowledge such as mail address blocks [12] or configurations of chess games [1]. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. <p> Many document segmentation methods have been proposed in the literature. Some of these methods are top-down approaches, some are bottom-up schemes, and others are based on texture segmentation schemes in computer vision. Classic top-down techniques are based on the run length smoothing (RLS) algorithm <ref> [15, 17] </ref> to smooth the image first, then, horizontal and vertical projection profiles [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs [9, 13, 16].
Reference: [16] <author> D. Wang and S. N. Srihari. </author> <title> Classification of Newspaper Image Blocks Using Texture Analysis. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 47 </volume> <pages> 327-352, </pages> <year> 1989. </year>
Reference-contexts: The pyramid of the input image is shown as I, I 1 , I 2 : : :; (b) An example input image; (c) Output of the system result before the Character Recognition module. non-text items. However, most such schemes require clean binary input <ref> [3, 15, 16, 17] </ref>; some assume specific document layouts such as newspapers [6] and technical journals [9]; others utilize domain-specific knowledge such as mail address blocks [12] or configurations of chess games [1]. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. <p> Some of these methods are top-down approaches, some are bottom-up schemes, and others are based on texture segmentation schemes in computer vision. Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image first, then, horizontal and vertical projection profiles <ref> [16] </ref> are commonly used to cut the page into smaller blocks such as columns and paragraphs [9, 13, 16]. Bottom-up methods work by grouping small components (starting with pixels as connected components) into successively larger components until all blocks are found on the page [3, 10]. <p> Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image first, then, horizontal and vertical projection profiles [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs <ref> [9, 13, 16] </ref>. Bottom-up methods work by grouping small components (starting with pixels as connected components) into successively larger components until all blocks are found on the page [3, 10].
Reference: [17] <author> K. Y. Wong, R. G. Casey, and F. M. Wahl. </author> <title> Document Analysis System. </title> <journal> IBM Journal Res. Dev., </journal> <volume> 26(6) </volume> <pages> 647-656, </pages> <year> 1982. </year>
Reference-contexts: The pyramid of the input image is shown as I, I 1 , I 2 : : :; (b) An example input image; (c) Output of the system result before the Character Recognition module. non-text items. However, most such schemes require clean binary input <ref> [3, 15, 16, 17] </ref>; some assume specific document layouts such as newspapers [6] and technical journals [9]; others utilize domain-specific knowledge such as mail address blocks [12] or configurations of chess games [1]. In this paper, a new end-to-end system is proposed which automatically extracts and recognizes text in images. <p> Many document segmentation methods have been proposed in the literature. Some of these methods are top-down approaches, some are bottom-up schemes, and others are based on texture segmentation schemes in computer vision. Classic top-down techniques are based on the run length smoothing (RLS) algorithm <ref> [15, 17] </ref> to smooth the image first, then, horizontal and vertical projection profiles [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs [9, 13, 16].
References-found: 16

