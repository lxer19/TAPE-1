URL: http://www.medg.lcs.mit.edu/mpf/papers/Ginsberg/Ginsberg-et-al-90.ps
Refering-URL: http://www.medg.lcs.mit.edu/mpf/papers/Ginsberg/Ginsberg-et-al-90.html
Root-URL: 
Title: Search Lessons Learned from Crossword Puzzles  
Author: Matthew L. Ginsberg Michael Frank Michael P. Halpin Mark C. Torrance 
Address: 444 High Street Stanford, California 94305 Palo Alto, California 94301  Stanford, California 94305  20525 Mariani Avenue Cupertino, California 95014  Stanford, California 94305  
Affiliation: Rockwell International Computer Science Department Palo Alto Laboratory Stanford University  Center for the Study of Language and Information Stanford University  Development Systems Group Apple Computer, Inc.  Computer Science Department Stanford University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> L. Davis. </author> <title> Genetic Algorithms and Simulated Annealing. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: In any event, if this sort of a technique is to be used, it seems natural to combine it with some of the ideas underlying simulated annealing <ref> [1] </ref>. One might envision the puzzle generator as having a "temperature" that controlled how prepared it was to backtrack significantly without exhaustively searching a portion of the search space, and how far back it went when it did so.
Reference: [2] <author> L. J. Mazlack. </author> <title> Computer construction of crossword puzzles using precedence relationships. </title> <journal> Artificial Intelligence, </journal> <volume> 7 </volume> <pages> 1-19, </pages> <year> 1976. </year> <type> 5 Personal communication. 15 </type>
Reference-contexts: conventional 26-letter dictionary, and it is not clear to what extent our experimental results will change if a dictionary such as that suggested by (2) is used. 3 Existing work 3.1 On crosswords There is very little published work on automatic generation of crossword puzzles; the old paper by Mazlack <ref> [2] </ref> is the only work of which we are aware. Mazlack discusses and dismisses the approach of completing the puzzle a word at a time (i.e., successively solving the subgoals in an expression such as (1)). <p> These are as follows: 13 6.1 Simulated annealing Mazlack suggests in <ref> [2] </ref> that if a variety of choices have been tried at a point in the search space and none has proven successful, the search backtrack further on the assumption that the problem lies elsewhere (Mazlack backtracks after seven failed attempts, for example).
Reference: [3] <author> D. E. Smith and M. R. Genesereth. </author> <title> Ordering conjunctive queries. </title> <journal> Artificial Intelligence, </journal> <volume> 26(2) </volume> <pages> 171-215, </pages> <year> 1985. </year>
Reference-contexts: Given these modifications, it is clear that any declarative query that involves lookup only (as opposed to inference) can be translated into a suitable crossword puzzle problem, and that the classes of crossword problems considered here is in fact equivalent to the class of database queries considered by Smith in <ref> [3] </ref>. 2 Of course, the experimental data that we will present concerns only a conventional 26-letter dictionary, and it is not clear to what extent our experimental results will change if a dictionary such as that suggested by (2) is used. 3 Existing work 3.1 On crosswords There is very little <p> There are essentially three commonly-accepted domain-independent heuristics for addressing problems of this sort: 1. The cheapest-first heuristic, 2. Connectivity, and 3. Smith's adjacency restriction <ref> [3] </ref>. <p> heuristic suggests that when deciding which conjunct to expand next, one should expand the conjunct that is the most difficult to solve, in that it has no more solutions than any of the other remaining conjuncts. 3 Although it does not always lead to optimal conjunct orderings (as shown in <ref> [3] </ref>), this heuristic has the advantage of being cheap to compute and easy to apply. <p> The justification for this heuristic is that solving difficult conjuncts early makes it more likely that the remaining conjuncts will have solutions at all, thereby reducing the need for backtracking. When discussing the cheapest-first heuristic in <ref> [3] </ref>, Smith makes two assumptions that we wish to avoid. <p> We will have more to say about this in Sections 4.5, 5.2 and 5.3. Adjacency In <ref> [3] </ref>, Smith presents a provably correct restriction on the ordering of the conjuncts in a query of the form we are considering.
Reference: [4] <author> R. M. Stallman and G. J. Sussman. </author> <title> Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9(2) </volume> <pages> 135-196, </pages> <year> 1977. </year>
Reference-contexts: If we are unable to fill a particular word, backtracking to an intersecting word is likely to introduce new possibilities for the word causing trouble. What is happening here is that connectivity is being used to produce a cheap version of dependency-directed backtracking <ref> [4] </ref> that does not require us to maintain dependency information during the search process.
Reference: [5] <author> G. L. Steele, Jr. </author> <title> Common Lisp: The Language. </title> <publisher> Digital Press, </publisher> <address> Billerica, MA, </address> <year> 1984. </year> <month> 16 </month>
Reference-contexts: The bitwise conjunction of the (1; 1) and (5; 4) entries in this array now corresponds to words that have an A in the first position and an E in the fourth. Common Lisp is well suited to support manipulations of this sort <ref> [5] </ref>. Integers of arbitrary length are supported, and the Common Lisp functions integer-length and logcount can be used to find the first word matching a given pattern and to count the number of such words respectively. Note also that this hashing scheme is fairly compact.
References-found: 5

