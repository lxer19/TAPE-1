URL: http://www.cs.jhu.edu/salzberg/ml94.ps
Refering-URL: http://www.cs.jhu.edu/salzberg/home.html
Root-URL: 
Email: lastname@cs.jhu.edu  aha@aic.nrl.navy.mil  
Title: Towards a Better Understanding of Memory-Based Reasoning Systems  
Author: John Rachlin Simon Kasif Steven Salzberg David W. Aha 
Keyword: Bayes does.  
Address: Baltimore, MD 21218  Washington DC 20375  
Affiliation: Dept. of Computer Science Johns Hopkins University  Navy Center for Applied Research in AI Naval Research Laboratory  
Abstract: We quantify both experimentally and analytically the performance of memory-based reasoning (MBR) algorithms. To start gaining insight into the capabilities of MBR algorithms, we compare an MBR algorithm using a value difference metric to a popular Bayesian classifier. These two approaches are similar in that they both make certain independence assumptions about the data. However, whereas MBR uses specific cases to perform classification, Bayesian methods summarize the data probabilistically. We demonstrate that a particular MBR system called Pebls works comparatively well on a wide range of domains using both real and artificial data. With respect to the artificial data, we consider distributions where the concept classes are separated by functional discriminants, as well as time-series data generated by Markov models of varying complexity. Finally, we show formally that Pebls can learn (in the limit) natural concept classes that the Bayesian classifier cannot learn, and that it will attain perfect accuracy whenever 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., Kibler, D., & Albert, M. </author> <year> (1991). </year> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 (1). </volume>
Reference: <author> Albert, M. & Aha, D. W. </author> <year> (1991). </year> <title> Analyses of instance-based learning algorithms. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 553-558. </pages>
Reference: <author> Albrecht, R. & Werner, W. </author> <year> (1968). </year> <title> Error analysis of a statistical decision method. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 10, </volume> <pages> 34-38. </pages>
Reference: <author> Aoki, M. </author> <year> (1965). </year> <title> On some convergence questions in bayesian optimization problems. </title> <journal> IEEE Trans. on Automatic Control, </journal> <volume> 10, </volume> <pages> 180-182. </pages>
Reference: <author> Chandrasekan, B. </author> <year> (1971). </year> <title> Independence of measurements and the mean recognition accuracy. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 17, </volume> <pages> 452-456. </pages>
Reference: <author> Chandrasekan, B. & Harley, T. </author> <year> (1969). </year> <title> Comments on the mean accuracy of statistical pattern recogniz-ers. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 15, </volume> <pages> 421-423. </pages>
Reference: <author> Clark, P. & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-284. </pages>
Reference-contexts: A new point is classified into C i if P (C i ) Q is maximal. This classifier has been evaluated in some recent machine learning papers (e.g., <ref> (Clark & Niblett, 1989) </ref> and its average case behavior has also been analyzed (e.g., (Langley & Iba, 1992)).
Reference: <author> Cost, S. & Salzberg, S. </author> <year> (1993). </year> <title> A weighted nearest neighbor algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10 (1), </volume> <pages> 57-78. </pages>
Reference-contexts: They argued that the VDM is more appropriate than the simple overlap distance measure, which defines distance as the number of mismatching features between two instances. More recently, Cost and Salzberg <ref> (Cost & Salzberg, 1993) </ref> demonstrated that Pebls, which uses a modification of the VDM distance measure called MVDM, can outperform the overlap measure and several other learning algorithms on a number of practical problems.
Reference: <author> Cover, T. & Hart, P. </author> <year> (1967). </year> <title> Nearest neighbor pattern classification. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 13, </volume> <pages> 21-27. </pages>
Reference-contexts: Briefly, NN classifies an instance X according to the class of the stored instance whose Euclidean distance to X is minimal. NN has been analyzed for its learning behavior in the limit <ref> (Cover & Hart, 1967) </ref>, in PAC analyses (Aha, Kibler, & Albert, 1991; Al-bert & Aha, 1991), and for its average case behavior (e.g., (Langley & Iba, 1993)). These analyses concerned numeric-valued features.
Reference: <author> Delcher, A. L., Kasif, S., Goldberg, H. R., & Hsu, B. </author> <year> (1993). </year> <title> Probabilistic prediction of protein secondary structure using causal networks. </title> <booktitle> In Proceedings of the 11th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 316-321. </pages>
Reference: <author> Duda, R. & Hart, P. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> John-Wiley. </publisher>
Reference: <author> Haussler, D., Krogh, A., Mian, S., & Sjolander, K. </author> <year> (1992). </year> <title> Protein modeling using hidden markov models. </title> <type> Tech. rep. </type> <institution> UCSC-CRL-92-23, Computer and Information Sciences, University of California, Santa Cruz. </institution>
Reference-contexts: In Section 4 we study how our classifiers perform on data characterized by some underlying functional description. We then compare their performance on data generated by Markov models, which corresponds to the approach taken for scientific data analysis problems in molecular biology <ref> (Haussler, Krogh, Mian, & Sjolan-der, 1992) </ref> and speech recognition (Rabiner, 1989). Our comparison indicates that Pebls has faster initial learning rates than Bayes for this class of problems.
Reference: <author> Hughes, G. </author> <year> (1968). </year> <title> On the mean accuracy of statistical pattern recognizers. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 14, </volume> <pages> 55-63. </pages>
Reference: <author> Kononenko, I. </author> <year> (1991). </year> <title> Semi-naive bayesian classifier. </title> <booktitle> In Proceedings of the Sixth European Working Session on Learning, </booktitle> <pages> pp. 206-219 Porto, </pages> <address> Portugal. </address> <publisher> Pittman. </publisher>
Reference: <author> Langley, P. & Iba, W. </author> <year> (1992). </year> <title> An analysis of bayesian classifiers. </title> <booktitle> In Proceedings of the Tenth National Converence on Artificial Intelligence, </booktitle> <pages> pp. 223-228. </pages>
Reference-contexts: A new point is classified into C i if P (C i ) Q is maximal. This classifier has been evaluated in some recent machine learning papers (e.g., (Clark & Niblett, 1989) and its average case behavior has also been analyzed (e.g., <ref> (Langley & Iba, 1992) </ref>).
Reference: <author> Langley, P. & Iba, W. </author> <year> (1993). </year> <title> Average-case analysis of a nearest neighbor algorithm. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pp. </pages> <address> 889-894 Chambery, France. </address>
Reference-contexts: NN has been analyzed for its learning behavior in the limit (Cover & Hart, 1967), in PAC analyses (Aha, Kibler, & Albert, 1991; Al-bert & Aha, 1991), and for its average case behavior (e.g., <ref> (Langley & Iba, 1993) </ref>). These analyses concerned numeric-valued features. Stanfill and Waltz (Stanfill & Waltz, 1986; Stanfill, 1987) introduced the Value Difference Metric (VDM) to define similarity when using symbolic-valued features and empirically demonstrated its benefits.
Reference: <author> Michie, D. & Attar, A. </author> <year> (1991). </year> <title> Use of sequential bayes with class probability trees. </title> <journal> Machine Intelligence, </journal> <volume> 12. </volume>
Reference: <author> Rabiner, L. R. </author> <year> (1989). </year> <title> A tutorial on hidden markov models and selected applications in speech recognition. </title> <booktitle> In Proceedings of the IEEE, </booktitle> <pages> pp. 257-286. </pages>
Reference-contexts: We then compare their performance on data generated by Markov models, which corresponds to the approach taken for scientific data analysis problems in molecular biology (Haussler, Krogh, Mian, & Sjolan-der, 1992) and speech recognition <ref> (Rabiner, 1989) </ref>. Our comparison indicates that Pebls has faster initial learning rates than Bayes for this class of problems. We then prove in Section 5 that Pebls can learn (in the limit) a larger class of functions than can the Bayesian classifier. <p> The literature on Markov models is quite extensive. (For a thorough introduction see <ref> (Rabiner, 1989) </ref>.) A Markov model is simply a graph in which the nodes represent states and the arcs define transitions between states. Attached to each arc is a transition probability which defines the probability that a given arc is actually taken when in a particular state.
Reference: <author> Stanfill, C. </author> <year> (1987). </year> <title> Memory-based reasoning applied to English pronunciation. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 577-581. </pages>
Reference: <author> Stanfill, C. & Waltz, D. </author> <year> (1986). </year> <title> Toward memory-based reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29 (12), </volume> <pages> 1213-1228. </pages>
Reference: <author> Yi, T.-M. & Lander, E. </author> <year> (1993). </year> <title> Protein secondary structure prediction using nearest-neighbor methods. </title> <journal> Journal of Molecular Biology, </journal> <volume> 232, </volume> <pages> 1117-1129. </pages>
Reference: <author> Zhang, X., Mesirov, J., & Waltz, D. </author> <year> (1992). </year> <title> A hybrid system for protein secondary structure prediction. </title> <journal> Journal of Molecular Biology, </journal> <volume> 225, </volume> <pages> 1049-1063. </pages>
References-found: 22

