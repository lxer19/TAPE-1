URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/94-08.ps.Z
Refering-URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/README.html
Root-URL: 
Email: email: iahmad@cs.ust.hk  
Title: -1- A Performance Assessment of Express on the iPSC/2 and iPSC/860 Hypercube Computers  
Author: Ishfaq Ahmad Min-You Wu Jaehyung Yang and Arif Ghafoor 
Address: Hong Kong  New York, Buffalo, NY  West Lafayette, IN 47907  
Affiliation: Department of Computer Science Hong Kong University of Science and Technology, Clear Water Bay,  Department of Computer Science State University of  School of Electrical Engineering Purdue University,  
Abstract: This paper describes the performance evaluation of Express programming environment on the iPSC/2 and iPSC/860 hypercube computers. Express allows parallel programs to be developed in a completely portable fashion and is available on most commercially available parallel computers as well as networks of workstations. We have developed a set of benchmarks to make a comprehensive performance assessment of the frequently used communication primitives of Express on hypercube computers. A comparison with the equivalent iPSC/2 and iPSC/860 primitives is also carried out. In addition, we have developed and benchmarked a suite of real applications including three different versions of Gaussian elimination, fast Fourier transform, and the N-body problem. These results help us evaluate the performance of Express and judge its merits against the extra overhead incurred due to portability. The results also enable us to make a comparison of two generations of hypercube systems. Furthermore, algorithm developers can benefit from these results by using the times required by the basic communication primitives on both hypercubes with and without Express, and can automate performance estimation by using these timings. 
Abstract-found: 1
Intro-found: 1
Reference: [10] <author> S. Ahuja, N. Carriero and D. Gelernter, </author> <title> Linda and Friends, </title> <journal> IEEE Computer, </journal> <volume> no. 8, </volume> <month> August </month> <year> 1986, </year>
Reference-contexts: There also exists the problem of portability - it is distressing to repeat the implementation work on a new machine. A few noteworthy efforts have been made to deal with such issues. These include PVM [32], Linda <ref> [10] </ref> PICL [21] and Express [29]. These systems allow parallel programs to be developed using C or Fortran by including their message-passing library routines. Express from Parasoft Corporation is a software programming environment for writing parallel programs for MIMD multiprocessors.
Reference: [11] <author> I. Angus, G. Fox, J. Kim, D. Walker, </author> <title> Solving Problems on Concurrent Processors, Volume II, </title> <publisher> Pren-tice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1990. </year>
Reference-contexts: The need for efficient solutions of a number of scientific problems led to the incorporation of a number of message passing primitives, such as broadcast and concatenation, into CrOS. The advanced version of this operating system, called CrOS III, was implemented on the Mark III hypercube <ref> [11] </ref>, [23]. The main features of CrOS III were synchronous communication among nodes with direct communication links.
Reference: [12] <author> G. Bell, </author> <title> Ultracomputers - A Teraflop Before its Time, </title> <journal> Communications of the ACM, pp. </journal> <volume> 27-47, Vol. 35, No. 8, </volume> <month> August </month> <year> 1992. </year>
Reference-contexts: With the advent of the High Performance Computing and Communication initiative and the quest for achieving a teraflop computing speed, this trend is likely to continue <ref> [12] </ref>. However, the advances in software technology for parallel computers have been outpaced by the spectacular progress in hardware. Consequently, programming of parallel -2--computers still remains a tedious task.
Reference: [13] <author> R. Berrendorf and J. Helin, </author> <title> Evaluating the Basic Performance of the Intel iPSC/860 Parallel Computer, </title> <journal> Concurrency: Practice and Experuience, </journal> <volume> vol. 4(3), </volume> <month> May </month> <year> 1992, </year> <pages> pp. 223-240. </pages>
Reference-contexts: Thus, we are not interested in benchmarking the basic computational operations. Some performance results showing the computational operations on the iPSC/2 and iPSC/860 can be found in <ref> [13] </ref> and [16]. All of our programs have been written in Fortran. For communications tests, every point in each test is the result of taking the average of a large number of repetitions.
Reference: [14] <author> S. Bokhari, </author> <title> Communication Overhead on the Intel iPSC/860 Hypercube, </title> <type> ICASE Interim Report 10 182055, </type> <institution> NASA Langley Research Center, Hampton, VA, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: If the message is to be forwarded, new channel has to be obtained. It is well known that in both iPSC/2 and iPSC/860 hypercubes, there are two types of protocols used for sending messages <ref> [14] </ref>, [18]. For messages of length smaller than or equal to 100 bytes, the sending node does not check to see if there is buffer space available at the receiving node.
Reference: [15] <author> S. Bokhari, </author> <title> Multiphase Complete Exchange on a Circuit Switched Hypercube, </title> <type> Tech. Report 91-5, </type> <institution> ICASE, NASA Langly Research Center, Hampton, Virginia, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: This communication pattern is equivalent to a complete directed graph. It is used in a number of algorithms including matrix transpose, matrix-vector multiply, 2-dimensional FFTs, distributed table look-ups <ref> [15] </ref>, etc. The time required to carry out the complete exchange is an im portant measure of the power of a distributed-memory parallel computer system since it is the densest communication requirement that can be implemented on a network. <p> A simple implemen tation is given in the following although more sophisticated versions can be found in <ref> [15] </ref>, [24], and [25]. do j = 0, NumNodes - 1 if (thisNode .EQ. j) then do k = 0, NumNodes - 1 if (thisNode .NE. k) then call crecv (MsgType, RecBuffer, Size) end if else Dest = j call csend (MsgType, SendBuffer, Size, Dest, PId) end do The Express version
Reference: [16] <author> L. Bomans and D. Roose, </author> <title> Benchmarking the iPSC/2 Hypercube Multiprocessor, </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. 1(1), </volume> <month> Sept. </month> <year> 1989, </year> <pages> pp. 3-18. </pages>
Reference-contexts: Thus, we are not interested in benchmarking the basic computational operations. Some performance results showing the computational operations on the iPSC/2 and iPSC/860 can be found in [13] and <ref> [16] </ref>. All of our programs have been written in Fortran. For communications tests, every point in each test is the result of taking the average of a large number of repetitions.
Reference: [17] <author> P. </author> <title> Close, The iPSC/2 Node Architecture, </title> <booktitle> The Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <volume> Vol. I, </volume> <year> 1988, </year> <pages> pp. 43-50. </pages>
Reference-contexts: The operating system on nodes is NX (Node eXecutive) developed by Intel. The iPSC/2 system is based on 32-bit 80386 microprocessor while the iPSC/860 is based on 64-bit i860 RISC microprocessor. Details of the iPSC/ 2 and iPSC/860 node architectures can be found in <ref> [17] </ref> and [26], respectively. The summary of some of the architectural features of the computers we used is given in Table 1. In both systems, each node has a hardware communication module, called DCM (direct connect module) which connects a node to the interconnection network [27].
Reference: [18] <author> T. H. Dunigan, </author> <title> Performance of the Intel iPSC/860 and Ncube 6400 Hypercubes, </title> <journal> Parallel Computing, </journal> <volume> No. </volume> <pages> 17, </pages> <address> 1991, </address> <publisher> North Holland, </publisher> <pages> pp. 1285-1302. </pages>
Reference-contexts: If the message is to be forwarded, new channel has to be obtained. It is well known that in both iPSC/2 and iPSC/860 hypercubes, there are two types of protocols used for sending messages [14], <ref> [18] </ref>. For messages of length smaller than or equal to 100 bytes, the sending node does not check to see if there is buffer space available at the receiving node.
Reference: [19] <author> J. Flower and A. Kolawa, </author> <title> A Packet History of Message Passing Systems, </title> <institution> Parasoft Corporation, </institution> <year> 1992. </year>
Reference-contexts: Initially, a so called operating system known as CrOS (Crystalline Operating system) consisting of a few message passing primitives was the only support that was available to derive those machines <ref> [19] </ref>. The need for efficient solutions of a number of scientific problems led to the incorporation of a number of message passing primitives, such as broadcast and concatenation, into CrOS. The advanced version of this operating system, called CrOS III, was implemented on the Mark III hypercube [11], [23].
Reference: [20] <author> G.C. Fox, M.A. Johnson, G.A. Lyzenga, S.W. Otto, J.A. Salmon, and D.A. Walker, </author> <title> Solving Problems on Concurrent Processors, Volum I, </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: algorithm with Express over NX are given in Figure 11 (c), indicating that the degradation in performance using Express with this algorithm is better than the column-block partitioning algorithm but is comparable with row-block partitioning. 8.4 Fast Fourier Transform For the fast Fourier transform, we used the algorithm given in <ref> [20] </ref> with modification. For N points, the algorithmss complexity is . The two dimensional matrix is partitioned across nodes in a row orientation style. The algorithm works by transforming the rows first, then transposing the rows with columns, transforming the columns and so on. <p> 256 256 512 512 768 768 11024 1024 N Nlog ( ) -29--number of communication operations, the problem granularity is large and the effect of extra overhead of Express is substantially low. 8.5 The N-body Problem The program for the N-body problem has been written using the algorithm reported in <ref> [20] </ref>. The algorithm used in this program is the simple O ( ) algorithm and not the more optimized O ( ) approach.
Reference: [21] <author> G.A. Geist, M.T. Heath, B.W. Peyton and P.H. Worley, </author> <title> A Users Guide to Picl, a Portable Instrumented Communication Library, </title> <type> Technical Report ORNL/TM-11616, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, TN, </institution> <month> Oct </month> <year> 1991. </year>
Reference-contexts: There also exists the problem of portability - it is distressing to repeat the implementation work on a new machine. A few noteworthy efforts have been made to deal with such issues. These include PVM [32], Linda [10] PICL <ref> [21] </ref> and Express [29]. These systems allow parallel programs to be developed using C or Fortran by including their message-passing library routines. Express from Parasoft Corporation is a software programming environment for writing parallel programs for MIMD multiprocessors.
Reference: [22] <author> Intel Corporation, </author> <title> iPSC/2 and iPSC/860 Programmers Reference Manual, </title> <month> June </month> <year> 1990. </year>
Reference-contexts: If the argument DestNode in the call for csend routine (see above in section 5.1) can be give as -1, the message is sent to all the nodes in the attached subcube.Message can also be sent to a subcube composed of a set of nodes surrounding the source node <ref> [22] </ref>. Compared to this, Express has the extra advantage of specifying arbitrarily any node in the NodeList argument which should receive the message. number of nodes in this case has been chosen as 4.
Reference: [23] <author> A. Kolawa and S. Otto, </author> <title> Performance of the MARK II and Intel Hypercube, Hypercube Multiproc -33--essors 1986, M.T. </title> <editor> Heath, ed., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1986, </year> <pages> pp. 161-180. </pages>
Reference-contexts: The need for efficient solutions of a number of scientific problems led to the incorporation of a number of message passing primitives, such as broadcast and concatenation, into CrOS. The advanced version of this operating system, called CrOS III, was implemented on the Mark III hypercube [11], <ref> [23] </ref>. The main features of CrOS III were synchronous communication among nodes with direct communication links.
Reference: [24] <author> S. L. Johnson and C.T. Ho, </author> <title> Optimal Broadcasting and Personalized Communication in hypercubes, </title> <journal> IEEE Tran. on Computers, C-38, </journal> <volume> No. 9, </volume> <month> Sept. </month> <year> 1989, </year> <pages> pp. 1249-1268. </pages>
Reference-contexts: on the iPSC/2 and iPSC/860 (0 to 200 bytes). the iPSC/2 and iPSC/860 (200 to 1000 bytes). processors on the iPSC/2 and iPSC/860 (1000 to 16000 bytes). and 32 processors on the iPSC/860 (200 to 1000 bytes). 32 processors on the iPSC/2 (200 to 1000 bytes). -15- trix multiplication, LU-factorization, <ref> [24] </ref> etc. The Express primitive for the broadcast operation is as follows: status = kxbrod (Buffer, Origin, Size, NumNodes, NodeList, Type) This function starts from node Origin which broadcasts Size bytes of data in Buffer. The number of nodes to which the date is broadcasted is indicated by NumNodes. <p> A simple implemen tation is given in the following although more sophisticated versions can be found in [15], <ref> [24] </ref>, and [25]. do j = 0, NumNodes - 1 if (thisNode .EQ. j) then do k = 0, NumNodes - 1 if (thisNode .NE. k) then call crecv (MsgType, RecBuffer, Size) end if else Dest = j call csend (MsgType, SendBuffer, Size, Dest, PId) end do The Express version is
Reference: [25] <author> M.H. Lee and S.R. Seidel, </author> <title> Concurrent Communication on the Intel iPSC/2, </title> <type> Tech. Report CS-TR 90-03, </type> <institution> Dept. of Computer Science, Michigan Technical University, </institution> <month> July </month> <year> 1990. </year>
Reference-contexts: A simple implemen tation is given in the following although more sophisticated versions can be found in [15], [24], and <ref> [25] </ref>. do j = 0, NumNodes - 1 if (thisNode .EQ. j) then do k = 0, NumNodes - 1 if (thisNode .NE. k) then call crecv (MsgType, RecBuffer, Size) end if else Dest = j call csend (MsgType, SendBuffer, Size, Dest, PId) end do The Express version is similar to
Reference: [26] <author> S.A. Moyer, </author> <title> Performance of the iPSC/860 Node Architecture, </title> <type> Tech. Report IPC-TR-91-007, </type> <institution> Institute of Parallel Computations, University of Virginia, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: The operating system on nodes is NX (Node eXecutive) developed by Intel. The iPSC/2 system is based on 32-bit 80386 microprocessor while the iPSC/860 is based on 64-bit i860 RISC microprocessor. Details of the iPSC/ 2 and iPSC/860 node architectures can be found in [17] and <ref> [26] </ref>, respectively. The summary of some of the architectural features of the computers we used is given in Table 1. In both systems, each node has a hardware communication module, called DCM (direct connect module) which connects a node to the interconnection network [27].
Reference: [27] <editor> S.F. Nugent, </editor> <booktitle> The iPSC/2 Direct-Connect Communications Technology, The Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <volume> Vol. I, </volume> <year> 1988, </year> <pages> pp. 51-60. </pages>
Reference-contexts: The summary of some of the architectural features of the computers we used is given in Table 1. In both systems, each node has a hardware communication module, called DCM (direct connect module) which connects a node to the interconnection network <ref> [27] </ref>. Each DCM router can support up to eight channels. Channels are bit-serial and full duplex. Physically, each channel consists of four wires that connects each of the nearest neighbor nodes. <p> The intermediate nodes in the path are determined by the e-cube algorithm <ref> [27] </ref>. Each node maintains one outgoing and one incoming 4 Kbyte FIFO buffer. The flushing and filling of the buffer is done by a DMA controller on the iPSC/2 and by the i860 processor itself on the iPSC/860.
Reference: [28] <author> Parasoft Corporation, </author> <title> Express, Fortran Users Guide, </title> <year> 1990. </year>
Reference: [29] <institution> Parasoft Corporation, </institution> <note> Express Introductory Guide version 3.2, </note> <year> 1992. </year>
Reference-contexts: There also exists the problem of portability - it is distressing to repeat the implementation work on a new machine. A few noteworthy efforts have been made to deal with such issues. These include PVM [32], Linda [10] PICL [21] and Express <ref> [29] </ref>. These systems allow parallel programs to be developed using C or Fortran by including their message-passing library routines. Express from Parasoft Corporation is a software programming environment for writing parallel programs for MIMD multiprocessors.
Reference: [30] <author> C.L. Seitz, </author> <title> The Cosmic Cube. </title> <journal> Communications of the ACM, </journal> <volume> No. 28, </volume> <year> 1985, </year> <pages> pp. 22-33. </pages>
Reference-contexts: execution times of application benchmark suite are presented in Section 8 and Section 9 concludes this paper. 2 Background and Overview of Express The history of Express can be traced back to the Caltech/JPL machines, including the first hy-percubes (the Cosmic Cube and Mark II), developed in the early eighties <ref> [30] </ref>. Initially, a so called operating system known as CrOS (Crystalline Operating system) consisting of a few message passing primitives was the only support that was available to derive those machines [19].
Reference: [31] <author> T. Schmiermund and S.R. Seidel, </author> <title> A Communication Model for the Intel iPSC/2, </title> <type> Tech. Report CS-TR 90-02, </type> <institution> Dept. of Computer Science, Michigan Technical University, </institution> <month> April </month> <year> 1990. </year>
Reference: [32] <author> V. Sunderam, </author> <title> PVM: A Framework for Parallel Distributed Computing, </title> <journal> Concurrency: Practice & Experience, </journal> <volume> Vol. 3, No. 4, </volume> <month> Dec </month> <year> 1990, </year> <pages> pp. 315-339. </pages>
Reference-contexts: There also exists the problem of portability - it is distressing to repeat the implementation work on a new machine. A few noteworthy efforts have been made to deal with such issues. These include PVM <ref> [32] </ref>, Linda [10] PICL [21] and Express [29]. These systems allow parallel programs to be developed using C or Fortran by including their message-passing library routines. Express from Parasoft Corporation is a software programming environment for writing parallel programs for MIMD multiprocessors.
Reference: [33] <author> J. Yang, I. Ahmad and A. Ghafoor, </author> <title> Estimation of Execution Times on Heterogeneous Supercomputer Architectures, </title> <booktitle> Intl Conference on Parallel Procesing, </booktitle> <year> 1993, </year> <pages> pp. </pages> <address> I-219 - I-226 </address>
References-found: 24

