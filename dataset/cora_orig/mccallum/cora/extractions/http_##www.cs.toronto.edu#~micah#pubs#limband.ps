URL: http://www.cs.toronto.edu/~micah/pubs/limband.ps
Refering-URL: http://www.cs.toronto.edu/~micah/pubs/pubs.html
Root-URL: 
Title: Parallel Sorting With Limited Bandwidth  
Author: Micah Adler John W. Byers Richard M. Karp 
Date: December 19, 1996  
Address: Berkeley, CA 94720  Berkeley, CA 94720  Berkeley, CA 94720  
Affiliation: Computer Science Division UC Berkeley  Computer Science Division UC Berkeley  International Computer Science Institute and Computer Science Division UC Berkeley  
Abstract: We study the problem of sorting on a parallel computer with limited communication bandwidth. By using the recently proposed PRAM(m) model, where p processors communicate through a globally shared memory which can service m requests per unit time, we focus on the trade-off between the amount of local computation and the amount of inter-processor communication required for parallel sorting algorithms. We prove a lower bound of ( n log m m ) on the time to sort n numbers on the exclusive-read and queued-read variants of the PRAM(m). We show that Leighton's Columnsort can be used to give an asymptotically matching upper bound in the case where m grows as a fractional power of n. The bounds are of a surprising form, in that they have little dependence on the parameter p. This implies that attempting to distribute the workload across more processors while holding the problem size and the size of the shared memory fixed will not improve the optimal running time of sorting in this model. We also show that both the upper and the lower bound can be adapted to bridging models that address the issue of limited communication bandwidth: the LogP model and the BSP model. The lower bounds provide further convincing evidence that efficient parallel algorithms for sorting rely strongly on high communication bandwidth.
Abstract-found: 1
Intro-found: 1
Reference: [ABK95] <author> M. Adler, J. Byers, R. Karp. </author> <title> Parallel Sorting with Limited Bandwidth Proc. </title> <booktitle> 7th ACM Symp. on Parallel Algorithms and Architectures: </booktitle> <pages> pp. 129 - 136, </pages> <year> 1995. </year>
Reference-contexts: Thus, the ratio between upper and lower bounds for sorting on the ER PRAM (m) was fi ( q m log 2 n) prior to this work. Subsequent to a preliminary version of this paper in <ref> [ABK95] </ref>, Adler [Adl96] provides an algorithm for sorting in the CR PRAM (m) that is considerably faster than the lower bound for the ER PRAM (m) presented in this paper. <p> After the preliminary version of this paper appeared in <ref> [ABK95] </ref>, work on this problem by Goodrich [Goo96] has tightened the bounds for sorting on the BSP, giving deterministic algorithms which run in time O ( n log n P + (L + gn P )(log n= log (n=P ))) for all values of P , coupled with a matching lower
Reference: [ACS90] <author> A. Aggarwal, A. Chandra, and M. Snir. </author> <title> Communication Complexity of PRAMs. </title> <booktitle> Theoretical Computer Science 71: </booktitle> <pages> pp 3-28, </pages> <year> 1990. </year>
Reference-contexts: Other related work on parallel sorting includes [BC82], where Borodin and Cook prove that sorting requires TIME SPACE = ( n 2 log n ). Aggarwal, Chandra and Snir show in <ref> [ACS90] </ref> that any parallel comparison-based algorithm that sorts n words requires ( n log n p log ( n p ) ) communication steps.
Reference: [ACS87] <author> A. Aggarwal, A. Chandra and M. Snir. </author> <title> Hierarchical Memory with Block Transfer. </title> <booktitle> In Proc. 28 th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pp. 204-216, </pages> <year> 1987. </year>
Reference: [ACS89] <author> A. Aggarwal, A. Chandra and M. Snir. </author> <title> On Communication Latency in PRAM Computations. </title> <booktitle> In Proc. 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <year> 1989. </year> <month> 19 </month>
Reference-contexts: Aggarwal, Chandra and Snir show in [ACS90] that any parallel comparison-based algorithm that sorts n words requires ( n log n p log ( n p ) ) communication steps. Also, the 3 same authors show in <ref> [ACS89] </ref> that sorting requires ( n log n p + l log p) in a model where reading or writing a block of size b from memory takes time l + b.
Reference: [Adl96] <author> M. Adler. </author> <title> New Coding Techniques for Improved Bandwidth Utilization In Proc. </title> <booktitle> 37 th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pp. </pages> , <year> 1996. </year>
Reference-contexts: Thus, the ratio between upper and lower bounds for sorting on the ER PRAM (m) was fi ( q m log 2 n) prior to this work. Subsequent to a preliminary version of this paper in [ABK95], Adler <ref> [Adl96] </ref> provides an algorithm for sorting in the CR PRAM (m) that is considerably faster than the lower bound for the ER PRAM (m) presented in this paper. <p> Thus, that result together with the lower bound presented here imply that the CR PRAM (m) is strictly more powerful than the ER PRAM (m). <ref> [Adl96] </ref> also slightly improves the ER PRAM (m) upper bound to O ( n log p m ).
Reference: [AHU74] <author> A. Aho, J. Hopcroft, and J. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley: </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference: [AKS83] <author> M. Ajtai, J. Komlos and E. Szemeredi. </author> <title> An O(n log n) sorting network. </title> <journal> Combinatorica 3: pp. </journal> <volume> 1 - 19, </volume> <year> 1983. </year>
Reference: [BGMZ95] <author> G. Blelloch, P. Gibbons, Y. Matias and M. Zagha. </author> <title> Accounting for Memory Bank Contention and Delay in High-Bandwidth Multiprocessors. </title> <booktitle> In Proc. 7 th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 84-94, </pages> <year> 1995. </year>
Reference: [BC82] <author> A. Borodin and S. Cook. </author> <title> A Time-Space Tradeoff for Sorting on a General Sequential Model of Computation. </title> <journal> SIAM J. of Computing, </journal> <volume> 11(2): </volume> <pages> pp. 287 - 297, </pages> <year> 1982. </year>
Reference-contexts: Indeed, an interesting question would be to determine whether we could apply our lower bound technique to a non-standard VLSI model in which the chip could receive each input in more than one location and at more than one time. Other related work on parallel sorting includes <ref> [BC82] </ref>, where Borodin and Cook prove that sorting requires TIME SPACE = ( n 2 log n ). Aggarwal, Chandra and Snir show in [ACS90] that any parallel comparison-based algorithm that sorts n words requires ( n log n p log ( n p ) ) communication steps.
Reference: [Col88] <author> R. Cole. </author> <title> Parallel Merge Sort. </title> <journal> SIAM J. of Computing, </journal> <volume> 17(4): </volume> <pages> pp. 770 - 785, </pages> <year> 1988. </year>
Reference-contexts: An easy upper bound can be obtained by using a variant of Cole's parallel merge sort <ref> [Col88] </ref> for the PRAM, which uses O (n log n) bits of memory and runs in O (log n) time.
Reference: [CD82] <author> S. Cook, C. Dwork, and R. Reischuk. </author> <title> Upper and Lower Bounds for Parallel Random Access Machines Without Simultaneous Writes. </title> <journal> SIAM J. of Computing 15: </journal> <pages> pp. 87-97, </pages> <year> 1985. </year>
Reference: [CKP+93] <author> D. Culler, R. M. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subra-monian and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Proc. 4th ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, </booktitle> <pages> pp. 1-12, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: This leaves unresolved the question of how to design algorithms for machines which have limited inter-processor communication bandwidth. Addressing this limitation has motivated the development of other models of parallel computation, representative of which are the BSP model [Val90a], the LogP model <ref> [CKP+93] </ref>, and the PRAM (m) model [MNV94]. Provably efficient algorithms in the PRAM model are not necessarily the most efficient algorithms for these new models, so a host of problems need to be re-evaluated in this new framework. <p> In a classical PRAM, p processors communicate by writing to and reading from a large globally shared memory in unit time. Access to the shared memories is slowed by such factors as long message send overheads <ref> [CKP+93] </ref>, contention at memory banks, the fact that memory banks are much slower than processors [?], and bandwidth limitations of the network connecting processors to memory banks. In practice, the available per-processor bandwidth to shared memory is quite small. Similar difficulties exist in distributed memory parallel machines. <p> We give a brief discussion of the complexity of sorting in the LogP model <ref> [CKP+93] </ref> and the BSP model [Val90a]. 5.1 The LogP model In the LogP model, limited communication communication throughput in a parallel machine is enforced by requiring that each processor must wait for a gap of at least g cycles between the transmission of consecutive point-to-point messages.
Reference: [CS92] <author> R. Cypher and J. Sanz. Cubesort: </author> <title> A Parallel Algorithm for Sorting N Data Items with S-Sorters. </title> <journal> Journal of Algorithms 13: </journal> <pages> pp. 211-234, </pages> <year> 1992. </year>
Reference-contexts: Thus, that result together with the lower bound presented here imply that the CR PRAM (m) is strictly more powerful than the ER PRAM (m). [Adl96] also slightly improves the ER PRAM (m) upper bound to O ( n log p m ). Related work on upper bounds includes <ref> [CS92] </ref>, in which Cypher and Sanz allude to a recursive version of Columnsort, and introduce Cubesort, which can be used to obtain a running time of O ( n log n m (1 fi) 2 )25 log fl nlog fl (n=m) for sorting on the PRAM (m).
Reference: [Dus94] <author> A. Dusseau. </author> <title> Modeling Parallel Sorts with LogP on the CM-5. </title> <type> Technical Report: </type> <institution> UCB/CSD-94-829, </institution> <month> May </month> <year> 1994. </year>
Reference: [GMR94a] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The QRQW PRAM: Accounting for Contention in Parallel Algorithms. </title> <booktitle> In Proc. 5th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 638-648, </pages> <month> January </month> <year> 1994. </year>
Reference: [GMR94b] <author> P. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Efficient Low-Contention Parallel Algorithms. </title> <booktitle> In Proc. 6th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 236-247, </pages> <month> June </month> <year> 1994. </year>
Reference: [Goo96] <author> M. Goodrich. </author> <booktitle> Communication-Efficient Parallel Sorting Proceedings of the 28 th Annual ACM Symposium on Theory of Computing: </booktitle> <pages> pp. 247 - 256, </pages> <year> 1996. </year>
Reference-contexts: Finally, with respect to BSP algorithms for sorting, Gerbessiotis and Valiant [GV94] introduce a randomized algorithm for parallel sorting in the BSP model. Also, subsequent to an earlier version of this paper, the upper bound for sorting in the BSP model has been improved by both Goodrich <ref> [Goo96] </ref>, as well as by Gerbessiotis and Siniolakis [GS96]. <p> After the preliminary version of this paper appeared in [ABK95], work on this problem by Goodrich <ref> [Goo96] </ref> has tightened the bounds for sorting on the BSP, giving deterministic algorithms which run in time O ( n log n P + (L + gn P )(log n= log (n=P ))) for all values of P , coupled with a matching lower bound.
Reference: [GS96] <author> A. Gerbessiotis, C. Siniolakis. </author> <title> Deterministic Sorting and Randomized Median Finding on the BSP Model. </title> <booktitle> In Proc. 8th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. </pages> <year> 1996. </year>
Reference-contexts: Also, subsequent to an earlier version of this paper, the upper bound for sorting in the BSP model has been improved by both Goodrich [Goo96], as well as by Gerbessiotis and Siniolakis <ref> [GS96] </ref>. <p> Other recent work by Gerbessiotis and Siniolakis <ref> [GS96] </ref> gives a deterministic algorithm for sorting on the BSP which runs in time (1 + o (1))( n log n P + L) + P ) for P = n 1* , 0 &lt; * &lt; 1, and uses 1-optimal local computation. 6 Conclusion We have examined the problem of
Reference: [GV94] <author> A. Gerbessiotis, L. Valiant. </author> <title> Direct Bulk-Synchronous Algorithms. </title> <journal> In Journal of Parallel and Distributed Computing, 22:251 -267, </journal> <year> 1994. </year>
Reference-contexts: However, this algorithm has substantial overhead and is considerably more involved then the one presented in this paper. Finally, with respect to BSP algorithms for sorting, Gerbessiotis and Valiant <ref> [GV94] </ref> introduce a randomized algorithm for parallel sorting in the BSP model. Also, subsequent to an earlier version of this paper, the upper bound for sorting in the BSP model has been improved by both Goodrich [Goo96], as well as by Gerbessiotis and Siniolakis [GS96]. <p> The running time holds provided that P = O (n fi ) for some constant fi &lt; 1, since in this case there is only a constant number of phases. This result for sorting in the BSP model compares with the previous best randomized methods of Gerbessiotis and Valiant <ref> [GV94] </ref> for the BSP model with the assumption that each packet that is transmitted consists of exactly one key.
Reference: [KR90] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel Algorithms for Shared-Memory Machines. </title> <booktitle> In Handbook of Theoretical Computer Science, </booktitle> <editor> J. van Leeuwen, </editor> <publisher> Ed., </publisher> <pages> pp. 869-941. </pages> <publisher> Elsevier Science Publishers: </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year> <month> 20 </month>
Reference: [Lei85] <author> T. Leighton. </author> <title> Tight Bounds on the Complexity of Parallel Sorting. </title> <journal> IEEE Trans. on Com--puters, </journal> <volume> c-34(4): </volume> <pages> pp. 344-354, </pages> <year> 1985. </year>
Reference-contexts: When m = O (n fi ), for some fi &lt; 1, we show that a version of Columnsort <ref> [Lei85] </ref> has a running time that is bounded by O n log n (1 fi) 3:42 : For n m, the case of greatest interest, the final factor becomes a small constant and so in this setting the ratio between the upper and lower bounds is fi ( log n log <p> Using Thompson's VLSI model [Tho80], Leighton, in <ref> [Lei85] </ref>, proves a lower bound of AT 2 = (n 2 log 2 n) for sorting n keys of size fi (log n), where A is the area of a VLSI chip and T is the running time of the chip. <p> By the little birdie principle, the probability that processor d responds correctly on an input chosen uniformly at random, when not given the matrix H, is also at most 3 4 . 4 The Upper Bound We show that a version of Leighton's Columnsort <ref> [Lei85] </ref> performs well in the ER PRAM (m).
Reference: [Lei92] <author> T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures, </title> <publisher> Morgan Kaugmann, </publisher> <year> 1992. </year>
Reference-contexts: The following simple description of Columnsort is provided in <ref> [Lei92] </ref>. In phases 1, 3, and 7, the columns are sorted into increasing order. In phase 5, odd columns are sorted into increasing order and even columns are sorted into decreasing order.
Reference: [Mac95] <author> P. Mackenzie. </author> <title> Lower Bounds for Randomized Exclusive Write PRAMs. </title> <booktitle> In Proc. 7th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 254-263, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Also, for the uniform distribution over all possible inputs, the running time of any Monte Carlo algorithm is at least n log m 8m . We prove this theorem using an alternate formulation of Yao's lemma, provided in <ref> [Mac95] </ref>: Lemma 10 Let P 1 be the success probability of a T step randomized algorithm solving problem B, where the success probability is taken over the random choices made by the algorithm, and minimized over all possible inputs.
Reference: [MNV94] <author> Y. Mansour, N. Nisan and U. Vishkin. </author> <title> Trade-offs Between Communication Throughput and Parallel Time. </title> <booktitle> In Proceedings of the 26 th Annual ACM Symposium on Theory of Computing: </booktitle> <pages> pp. 372-381, </pages> <year> 1994. </year> <title> [MV 84] . Mehlhorn and U. Vishkin. Randomized and Deterministic Simulations of PRAMs by Parallel Machines with Restricted Granularity of Parallel Memories. </title> <journal> In Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: This leaves unresolved the question of how to design algorithms for machines which have limited inter-processor communication bandwidth. Addressing this limitation has motivated the development of other models of parallel computation, representative of which are the BSP model [Val90a], the LogP model [CKP+93], and the PRAM (m) model <ref> [MNV94] </ref>. Provably efficient algorithms in the PRAM model are not necessarily the most efficient algorithms for these new models, so a host of problems need to be re-evaluated in this new framework. <p> Also, the 3 same authors show in [ACS89] that sorting requires ( n log n p + l log p) in a model where reading or writing a block of size b from memory takes time l + b. When introducing the PRAM (m) model in <ref> [MNV94] </ref>, Mansour, Nisan and Vishkin prove a lower bound of ( n p mp ) for several problems, including sorting, in a concurrent read version of the PRAM (m), which implies the same bound in the ER PRAM (m). <p> During each synchronized round of computation, every processor can perform one of four actions: it can read the contents of a ROM location, read the contents of a globally shared memory location, write to a globally shared memory location, or perform local computation. As defined in <ref> [MNV94] </ref>, the PRAM (m) model allows processors concurrent read, concurrent write access to the globally shared memory. In this paper, we consider exclusive read and queued read variants of the PRAM (m) model. <p> The lower bound, however, does not apply to the concurrent read version of the PRAM (m) originally introduced by Mansour, Nisan and Vishkin in <ref> [MNV94] </ref>, and thus the asymptotic complexity of sorting in this model remains an open question. 7 Acknowledgements We would like to thank Ralph Werchner for his useful comments and suggestions on an earlier version of this paper.
Reference: [Tho80] <author> C. Thompson. </author> <title> A Complexity Theory for VLSI. </title> <type> PhD Thesis. </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1980. </year>
Reference-contexts: Using Thompson's VLSI model <ref> [Tho80] </ref>, Leighton, in [Lei85], proves a lower bound of AT 2 = (n 2 log 2 n) for sorting n keys of size fi (log n), where A is the area of a VLSI chip and T is the running time of the chip.
Reference: [Val90a] <author> L. Valiant. </author> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8): </volume> <pages> pp 103-111, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: This leaves unresolved the question of how to design algorithms for machines which have limited inter-processor communication bandwidth. Addressing this limitation has motivated the development of other models of parallel computation, representative of which are the BSP model <ref> [Val90a] </ref>, the LogP model [CKP+93], and the PRAM (m) model [MNV94]. Provably efficient algorithms in the PRAM model are not necessarily the most efficient algorithms for these new models, so a host of problems need to be re-evaluated in this new framework. <p> We give a brief discussion of the complexity of sorting in the LogP model [CKP+93] and the BSP model <ref> [Val90a] </ref>. 5.1 The LogP model In the LogP model, limited communication communication throughput in a parallel machine is enforced by requiring that each processor must wait for a gap of at least g cycles between the transmission of consecutive point-to-point messages.
Reference: [Val90b] <author> L. Valiant. </author> <title> General Purpose Parallel Architectures. </title> <booktitle> In Handbook of Theoretical Computer Science, </booktitle> <editor> J. van Leeuwen, </editor> <publisher> Ed., </publisher> <pages> pp. 943-971. </pages> <publisher> Elsevier Science Publishers: </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference: [VW85] <author> U. Vishkin and A. Wigderson. </author> <title> Trade-Offs between Depth and Width in Parallel Computation. </title> <journal> SIAM Journal of Computing, </journal> <volume> 14(2): </volume> <pages> pp. 303 - 314, </pages> <year> 1985. </year>
Reference: [Yao77] <author> A. Yao. </author> <title> Probabilistic Computations: Toward a Unified Measure of Complexity. </title> <booktitle> In Proc. 18 th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pp. 222-227, </pages> <year> 1977. </year> <month> 21 </month>
Reference-contexts: For Las Vegas algorithms, or randomized strategies which are guaranteed to provide a correct solution with a bound only on the expected running time, we have a lower bound which follows from a direct application of Yao's lemma <ref> [Yao77] </ref>. Theorem 8 For any Las Vegas algorithm A v for the ER PRAM (m) where n p 2 , there is some input I for the sorting problem, such that A v requires expected time at least n log m 8m to solve I. <p> Also, the expected running time of any Las Vegas algorithm on an input chosen uniformly at random from the set of all inputs is at least n log m 8m . Proof: Yao's lemma <ref> [Yao77] </ref> states that a lower bound of L for the expected running time of any deterministic algorithm acting on some distribution over the inputs implies that for any randomized algorithm there exists an input for which the expected running time is at least L.
References-found: 29

