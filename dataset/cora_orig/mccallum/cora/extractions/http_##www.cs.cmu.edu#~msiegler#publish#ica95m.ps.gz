URL: http://www.cs.cmu.edu/~msiegler/publish/ica95m.ps.gz
Refering-URL: http://www.cs.cmu.edu/~msiegler/
Root-URL: 
Title: ABSTRACT  
Abstract: It is well known that a higher-than-normal speech rate will cause the rate of recognition errors in large vocabulary automatic speech recognition (ASR) systems to increase [1]. In this paper we attempt to identify and correct for errors due to f ast speech. We first suggest that phone rate is a more meaningful measure of speech rate than the more common w ord rate. We find that when data sets are clustered according to the phone rate metric, recognition errors increase when the phone rate is more than 1 standard deviation greater than the mean. We propose three methods to improve the recognition accuracy of fast speech, each addressing different aspects of performance de gradation. The first method is an implementation of Baum-Welch codebook adaptation. The second method is based on the adaptation of HMM state-transition probabilities. In the third method, the pronunciation dictionaries are modified using rule-based techniques and compound w ords are added. We compare improvements in recognition accuracy for each method using data sets clustered according to the phone rate metric. Adaptation of the HMM state-transition probabilities to fast speech improves recognition of f ast speech by a relati ve amount of 4 to 6 percent. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. S. Pallett, et. al., </author> <title> Be Sure to Read the Fine Print: II, </title> <booktitle> Proc. ARPA Spoken Language Systems and Technology Workshop, </booktitle> <month> March </month> <year> 1994. </year>
Reference-contexts: 1. INTRODUCTION Speech rate has been shown to have a significant effect on recognition <ref> [1] </ref>. When speech rate e xceeds a threshold, recognition accuracy drops. It is difficult to pinpoint this threshold as there is no standard metric for quantifying speech rate. The f irst part of this paper is concerned with computing speech rate and this threshold. <p> Siegler and Richard M. Stern Department of Electrical and Computer Engineering School of Computer Science Carnegie Mellon University Pittsburgh, Pennsylvania 15213 sex-dependent senone models, and a trigram language model was used. 2. MEASURES OF SPEECH RATE Pallett et al. <ref> [1] </ref> used the word rate measure to compute the speech rate of utterances from the WSJ1 corpus. In their e xperiments, word rate was calculated by dividing the number w ords in the transcript by the total length of the utterance in minutes.
Reference: 2. <author> D. Paul, and J. Baker, </author> <title> The Design of the Wall Street Journal-based CSR Corpus, </title> <booktitle> Proc. DARPA Speech and Natural Language Workshop, </booktitle> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Since these procedures provide only limited benefit, we also suggest a number of fruitful avenues for future research. We used the Wall Street Journal (WSJ1) training corpus <ref> [2] </ref> which contains a total of 29,000 testing utterances. In all e xperiments a fast and somewhat less accurate version of the CMU SPHINX-II recognition system [3] with a 20,000-w ord vocabulary, 10,000 ON THE EFFECTS OF SPEECH RATE IN LARGE VOCABULARY SPEECH RECOGNITION SYSTEMS Matthew A.
Reference: 3. <author> X. Huang, F. Alleva, H.-W. Hon, M.-Y. Hwang, K.-F. Lee, R. Rosenfeld, </author> <title> The SPHINX-II Speech Recognition System: An Overview, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 7: </volume> <pages> 137-48, </pages> <year> 1993. </year>
Reference-contexts: We used the Wall Street Journal (WSJ1) training corpus [2] which contains a total of 29,000 testing utterances. In all e xperiments a fast and somewhat less accurate version of the CMU SPHINX-II recognition system <ref> [3] </ref> with a 20,000-w ord vocabulary, 10,000 ON THE EFFECTS OF SPEECH RATE IN LARGE VOCABULARY SPEECH RECOGNITION SYSTEMS Matthew A. Siegler and Richard M.
Reference: 4. <author> W. N. Campbell, </author> <title> Extracting Speech-Rate Values from a Real-Speech Database, </title> <booktitle> Proc. </booktitle> <address> ICASSP-88, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: It has been pointed out that w ord rate is unsatisfactory because of unpredictability in the structure and length of a w ord, which may be monosyllabic or polysyllabic, and because of the indeterminacy of any pause durations between w ords <ref> [4] </ref>. A more precise measure of speech rate must characterize the rate of information using a much smaller unit than the word. In this work we have chosen the phone as the unit of measurement.
Reference: 5. <author> F.-H. Liu, </author> <title> Environmental Adaptation for Robust Speech Recognition, </title> <type> Ph.D. Thesis, </type> <institution> Department of Electrical and Computer Engineering, Carnegie Mellon University, </institution> <month> June </month> <year> 1994. </year>
Reference: 6. <author> F. Liu, P. Moreno, R. Stern, and A. Acero, </author> <title> Signal Processing for Robust Speech Recognition, </title> <booktitle> Proc. ARPA Human Language Technology Workshop, </booktitle> <month> March </month> <year> 1994. </year>
Reference: 7. <author> G. Peterson, I. Lehiste, </author> <title> Duration of syllable nuclei in English, </title> <journal> J. Acoust. Soc. Am. </journal> <volume> 32: </volume> <pages> 693-703, </pages> <year> 1960. </year>
Reference-contexts: It has been sho wn that when speech rate increases the change in duration of v owels is greatest <ref> [7] </ref>. We used forced-alignment techniques to confirm this observation for the WSJ1 corpus. <p> As some studies ha ve found that vowel durations are most sensitive to speech rate <ref> [7] </ref>, it is also possible the a verage vowel rate would be a superior metric. We explored several methods in three different domains of speech modelling to reduce recognition errors for f ast speech.
Reference: 8. <author> M.-H. Hwang, </author> <title> Subphonetic Acoustic Modeling for Speaker-Independent Continuous Speech Recognition, </title> <type> Ph.D. Thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: In the SPHINX-II system, only monophone transition probabilities are trained because they are assumed to be relati vely unimportant in recognition <ref> [8] </ref>. utterances computed from Baum Welch adaptation. 500 utterances, the fastest 1000, and as modeled by the HMMs. We evaluated the importance of state-transition probabilities by creating two new sets of state-transition models. <p> Neither rule resulted in a signif icant change in the overall word error rate. 3.3.2 Inter-Word Transformations The pronunciation of a sequence of w ords is often different than the words spoken in isolation <ref> [8] </ref>, and if they are of short duration and have few phones, deletions can occur. In our observations of recognition performance of fast speech, the fraction of errors that are deletions is approximately 33 percent.
Reference: 9. <author> L. R. Shockey, </author> <title> Phonetic and Phonological Properties of Connected Speech, </title> <type> Ph.D. Thesis, </type> <institution> Phonetics and Phonology, Ohio State University, </institution> <year> 1973. </year>
Reference-contexts: Modification of Pronunciation Dictionaries Fast speech frequently produces changes in word pronunciation as well as in phone articulation, and it has been sho wn that these changes occur both within and between w ords <ref> [9] </ref>. <p> A linguist helped us to identify possible pronunciation dif ferences for fast speech. The rules governing intra-word transformations are numerous and complex <ref> [9] </ref>. Because we found deletions of unstressed v owels to be very common in fast speech, we selected tw o simple rules involving transformations of the schwa. In each case, we modified the dictionary and repeated recognition of the fast speech. The rules were: 1.
Reference: 10. <institution> Personal communication with Ellen Eide, BBN, </institution> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: These compound words are of the form IN_THE, AND_IN and have slightly different pronunciations than each w ord separately. From 20,000 words in the dictionary, 164 new compounds representing the most frequent merges were added. Other sites <ref> [10] </ref> have obtained a slight decrease in error rate using dictionaries with compound w ords for the Switchboard corpus [11]. Nevertheless, we found that adding compound w ords to our dictionary did not improve recognition accuracy. 4.
Reference: 11. <author> J.J. Godfrey, E. C. Holliman, J. McDaniel, </author> <title> SWITCHBOARD: Telephone Speech Corpus for Research and Development, </title> <booktitle> Proc. </booktitle> <address> ICASSP-92, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: From 20,000 words in the dictionary, 164 new compounds representing the most frequent merges were added. Other sites [10] have obtained a slight decrease in error rate using dictionaries with compound w ords for the Switchboard corpus <ref> [11] </ref>. Nevertheless, we found that adding compound w ords to our dictionary did not improve recognition accuracy. 4.
References-found: 11

