URL: ftp://speech.cse.ogi.edu/pub/docs/icslp980856.ps
Refering-URL: http://www.cse.ogi.edu/cslu/publications/abstracts/icslp98/abstracts.html
Root-URL: http://www.cse.ogi.edu
Title: THE CSLU SPEAKER RECOGNITION CORPUS  for Spoken Language Understanding  
Author: Ronald Cole, Mike Noel, Victoria Noel 
Address: USA  
Affiliation: Center  Oregon Graduate Institute,  
Abstract: This paper describes the CSLU Speaker Recognition Corpus data collection. The corpus was motivated by a need for speech data from many speakers, under different environmental conditions, with each speaker providing data over a significant period of time. The corpus was designed to provide sufficient data to study phonetic variability within and across sessions, and to design and evaluate systems for both vocabulary independent and vocabulary specific recognition and verification tasks. The protocol includes fixed vocabulary phrases, digit strings, personal utterances (e.g., eye color), and fluent speech. The resulting Speaker Recognition Corpus is a collection of telephone speech recordings from over 500 participants collected over a two-year period. We describe the data collection procedure, the protocol, the transcription methods and the current status of the Speaker Recognition Corpus. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. P. Campbell, Jr. </author> <title> Testing with the YOHO CDROM voice verification corpus. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 341-344, </pages> <address> Detroit, MI, </address> <year> 1995. </year>
Reference-contexts: In the field of speaker recognition and verification, progress has been hampered by the lack of accessible language resources that reflect real-world conditions. A recent corpus developed by Campbell <ref> [1] </ref> provides a good starting point for speaker verification research, but it is limited in that the recordings were made in a quiet environment, and individual speakers were not recorded at different times over a period of several months.
Reference: 2. <author> S. Furui, </author> <title> An Overview of speaker recognition technology. </title> <booktitle> In Proceedings of the ESCA Workshop on Automatic Speaker Recognition, Identification and Verification, </booktitle> <pages> pages 1-9, </pages> <address> Martigny, Switzerland, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Furui has found that speaker verification performance degrades for a standard set of templates after only a few months <ref> [2] </ref>. In order to examine speaker changes over time in realistic environments, new corpora are needed. Since 1996, CSLU has been developing a corpus for use in Speaker Recognition and Verification research.
Reference: 3. <author> T. Lander, </author> <title> The CSLU Labeling Guide, </title> <address> CSLU, Oregon, </address> <month> June </month> <year> 1996 </year>
Reference-contexts: Files that were transcribed automatically were assigned a confidence score, and files that were flagged as low confidence were inspected by human transcribers. 5.1 Human Transcriptions All manual transcriptions were produced according to the CSLU transcription conventions <ref> [3] </ref>. After transcription, the following quality control checks were performed. Files were checked for proper convention usage. Each file was checked automatically for improper use of transcription conventions. For example, cutoff speech markers not connected to a word. Any malformed transcriptions were flagged and investigated by a transcriber.
Reference: 9. <editor> ACKNOWLEDGEMENTS This data collection was supported by a grant from NSF (NSF IRI-9529006 Human Language Resources/Multilanguage Systems) and CSLU center member support. </editor> <title> The views expressed in this paper do not necessarily represent the views of NSF. CSLU would also like to thank the callers who have participated in this data collection. It goes without saying that without their contribution, this corpus wouldnt be nearly so interesting. </title>
References-found: 4

