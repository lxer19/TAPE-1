URL: http://www.cs.utexas.edu/users/vlr/papers/tcs_vp.ps
Refering-URL: http://www.cs.utexas.edu/users/vlr/pub.html
Root-URL: 
Title: Efficient Massively Parallel Implementation of Some Combinatorial Algorithms  
Author: Tsan-sheng Hsu Vijaya Ramachandran 
Address: Nankang 11529, Taipei, Taiwan, ROC  Texas 78712, USA  
Affiliation: Institute of Information Science, Academia Sinica,  Department of Computer Sciences, University of Texas at Austin, Austin,  
Note: In THEORETICAL COMPUTER SCIENCE, 1996. Copyright Elsevier  Preprint, accepted for publication in Theoretical Computer Science 1996  
Abstract: We describe our implementation of several efficient parallel algorithms on the massively parallel SIMD machine MasPar MP-1 with virtual processing. The MPL language that we used on the MasPar MP-1 does not support virtual processing. In this paper, we describe the implementation of virtual processing for several combinatorial algorithms using the MPL language. We present our data allocation scheme for virtual processing and code rewriting rules for converting a code that uses no virtual processors into a code with virtual processing. We then describe the implementation of virtual processing and the fine-tuning of a set of commonly used routines. In coding these routines, we tried different underlying (deterministic and randomized) algorithms. We present the performance data for our different implementations. We also compared the performance of several of the parallel routines with their sequential implementations. The performance of our code tracks theoretical predictions quite well for the range of values for virtual processing that we tested. We used techniques presented in this paper to convert non-virtual processing code for undirected graph algorithms into virtual processing code. Our experimental data suggests that by using our techniques, one can implement parallel algorithms with virtual processing quite effectively on the MasPar MP-1 using the MPL language. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, J. H. Spencer, and P. Erdos. </author> <title> The Probabilistic Method. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1992. </year>
Reference: [2] <author> R. J. Anderson and G. L. Miller. </author> <title> Deterministic parallel list ranking. </title> <booktitle> In Proc. 3rd Aegean Workshop on Computing, </booktitle> <volume> volume LNCS #319, </volume> <pages> pages 81-90. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference: [3] <author> R. J. Anderson and G. L. Miller. </author> <title> A simple randomized parallel algorithm for list-ranking. </title> <journal> Information Processing Letters, </journal> <volume> 33(5) </volume> <pages> 269-273, </pages> <month> January </month> <year> 1990. </year>
Reference: [4] <author> J. D. Becher and R. V. Thanakij. </author> <title> Massively parallel processing for fingerprint classification. </title> <type> Technical Report TR-MP/IP/SP-36.93, </type> <institution> MasPar Computer Corporation, </institution> <year> 1993. </year>
Reference: [5] <author> M. Berry, J. Comiskey, and K. Minser. </author> <title> Parallel map analysis on 2-D grids. </title> <booktitle> In Proc. 6th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 312-319, </pages> <year> 1993. </year>
Reference: [6] <author> T. Blank. </author> <title> The MasPar MP-1 architecture. </title> <booktitle> In Proc. of COMPCON Spring 90 - 35th IEEE Computer Society International Conference, </booktitle> <pages> pages 20-40, </pages> <year> 1990. </year>
Reference: [7] <author> G. E. Blelloch. </author> <title> Scan Primitives and Parallel Vector Models. </title> <type> PhD thesis, </type> <institution> M.I.T., </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: The implementation of the sendwith operator with virtual processing is as follows. We first sorted all requests from active VPE's according to their destination addresses. We then grouped requests to the same destination in a segment and performed a segmented scan operation <ref> [7] </ref> using the associative operator specified by the sendwith operator. In each segment, we picked the last VPE to write the result to the destination. Note that to send 32-bit integers using the sendwith operator, we had to sort 64-bit data.
Reference: [8] <author> G. E. Blelloch, C. E. Leiserson, B. M. Maggs, C. G. Plaxton, S. J. Smith, and M. Zagha. </author> <title> A comparison of sorting algorithms for the Connection Machine CM 28 2. </title> <booktitle> In Proc. 3th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 3-16, </pages> <year> 1991. </year>
Reference: [9] <author> H. Chernoff. </author> <title> A measure of the asymptotic efficiency for tests of a hypothesis based on the sum of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-509, </pages> <year> 1952. </year>
Reference: [10] <author> R. Cole and U. Vishkin. </author> <title> Approximate parallel scheduling. Part I: The basic technique with applications to optimal parallel list ranking in logarithmic time. </title> <journal> SIAM J. Comput., </journal> <volume> 17 </volume> <pages> 128-142, </pages> <year> 1988. </year>
Reference: [11] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Our current implementation includes a set of coding techniques for writing code with virtual processing and fine-tuned routines for several primitives such as (i) exchanging data between neighboring virtual processors, (ii) the scan routine [26] with several combining operators, (iii) routing routines, (iv) list ranking routines <ref> [11] </ref>, (v) routines for ordering data, (vi) concurrent write routines with several combining operators, and (vii) range minima routines (see e.g., Section 3.4.3 in [23]). For many of our primitives, we implemented several different algorithms and we present a comparison of their performances. <p> A Simple Optimal Randomized Algorithm In addition to the fairly complicated deterministic optimal algorithms in [2,10], there are several simple randomized optimal algorithms for list ranking (see e.g., [3,11,24,46]). A simple randomized optimal list ranking algorithm <ref> [11] </ref> is shown in Algorithm 1. The implementation of step 1.1 on the MasPar using MPL needed to use one global routing of 8-bit flags. Step 1.2 used one global routing of 8-bit flags and two pipelined global routings of 32-bit integers. <p> The reason might be that the size of the input is not large enough for the probabilistic analysis in <ref> [11] </ref> to hold with high probability. By tracing our code, we observed the following.
Reference: [12] <author> D. M. Eckstein. </author> <title> Simultaneous memory access. </title> <type> Technical report, </type> <institution> Computer Science Dept., Iowa State Univ., Ames, IA, </institution> <year> 1979. </year>
Reference: [13] <author> T. Feder, A. G. Greenberg, V. Ramachandran, M. Rauch, and L.-C. Wang. </author> <title> Circuit switched link simulation: Algorithms, complexity and implementation. </title> <type> Draft manuscript, </type> <year> 1992. </year>
Reference: [14] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The QRQW PRAM: Accounting for contention in parallel algorithms. </title> <booktitle> In Proc. 5th ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 638-648, </pages> <year> 1994. </year>
Reference-contexts: The first two factors are determined by the nature of the routing request and are hard to be changed. Though the effect of the third factor is not considered in the PRAM model, it is addressed in the QRQW PRAM model <ref> [14] </ref> and can be improved by algorithmic approaches. To improve the performance of a routing statement, we could reduce the maximum degree of concurrency (i.e., the third factor). There is a well-known PRAM algorithm to simulate a concurrent read (write) statement by using sorting and exclusive read (write) statements [12,24,45].
Reference: [15] <author> A. G. Greenberg, B. D. Lubachevsky, and L.-C. Wang. </author> <title> Experience in massively parallel discrete event simulation. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 193-202, </pages> <year> 1993. </year>
Reference: [16] <author> W. Hightower, J. Prins, and J. Reif. </author> <title> Implementations of randomized sorting on large parallel machines. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-167, </pages> <year> 1992. </year>
Reference: [17] <author> W. D. Hillis and G. L. Steele Jr. </author> <title> Data parallel algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 29 </volume> <pages> 1170-1183, </pages> <year> 1986. </year>
Reference: [18] <author> T.-s. Hsu. </author> <title> Graph Augmentation and Related Problems: Theory and Practice. </title> <type> PhD thesis, </type> <institution> University of Texas at Austin, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: A preliminary version of this paper appears in Proceedings of the Seventh IEEE Symposium on Parallel and Distributed Processing, 1995, pp. 154-159. This work is also reported in T.-s. Hsu's Ph.D. thesis <ref> [18] </ref>. 2 Also supported by an IBM graduate fellowship.
Reference: [19] <author> T.-s. Hsu, V. Ramachandran, and N. Dean. </author> <title> Implementation of parallel graph algorithms on the MasPar. </title> <booktitle> In DIMACS Series in Discrete Mathematics and Theoretical Computer Science, </booktitle> <volume> volume 15, </volume> <pages> pages 165-198. </pages> <publisher> American Mathematical Society, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction This paper describes an on-going project for implementing parallel algorithms on the massively parallel SIMD machine MasPar MP-1. There are important problems that can be solved on massively parallel SIMD machines with virtual processing [4,5,15,13,22,27,28,39,40]. In <ref> [19] </ref>, we reported the implementation of several parallel graph algorithms on the MasPar MP-1 using the parallel language MPL [30,31] which is an extension of the C language [25]. The MPL language provides an efficient way of using the MasPar MP-1. <p> The MPL language provides an efficient way of using the MasPar MP-1. However, it requires the user to specify the physical organization of the processors used in the program, and provides no support for virtual processing. As a result, our implementation in <ref> [19] </ref> could only handle the case when the size of the input is no more than the number of physical processors. In the current paper, we describe our implementation of virtual processing using MPL. <p> Second, MPL also provides subroutines for some fundamental parallel primitives such as computing the prefix sums of an array, sorting and interprocessor communication (again without virtual processing). In Section 5, we will discuss how to incorporate virtual processing into these system-provided subroutines and the commonly used routines given in <ref> [19] </ref>. 4 4.1 Mapping of Virtual Processors and Data Allocation Let nproc be the number of physical processors. For the MasPar MP-1 we used, nproc = 16,384, and these processors are organized as an nxproc fi nyproc mesh, where nxproc = nyproc = 128. <p> The following parallel primitives are in this category. The neighbor operator which retrieves data from the processor whose ID is adjacent to the ID of the current processor. This operator is described in the kernel routines given in <ref> [19] </ref>. For example, the kernel routine Lneighbor32 retrieves a 32-bit integer from processor i 1 for each processor i, i &gt; 0. We implemented this operator without virtual processing in the work described in [19] by using two MPL system mesh-communication operations (i.e., xnet). <p> This operator is described in the kernel routines given in <ref> [19] </ref>. For example, the kernel routine Lneighbor32 retrieves a 32-bit integer from processor i 1 for each processor i, i &gt; 0. We implemented this operator without virtual processing in the work described in [19] by using two MPL system mesh-communication operations (i.e., xnet). Thereduce operator which applies an associative operator on a plural variable and outputs its result. For example, the MPL library routine reduceAdd32 returns the summation of 32-bit integers in each active processor. <p> This operator is described in the kernel routines given in <ref> [19] </ref>. For example, the kernel routine segRshift32 rotates a 32-bit integer in each active processor to the processor on the right in the same segment. We implemented this operator without virtual processing in the work described in [19] by using several MPL mesh-communication operations and global routings (i.e., router). <p> This operator is described in the kernel routines given in <ref> [19] </ref>. For example, the kernel routine segRshift32 rotates a 32-bit integer in each active processor to the processor on the right in the same segment. We implemented this operator without virtual processing in the work described in [19] by using several MPL mesh-communication operations and global routings (i.e., router). The scan operator which applies prefix summing using a given associative operator on a plural variable. <p> In Table 1, we also show the ratio between the performance of our current implementation with virtual processing and the performance of a previous implementation in <ref> [19] </ref> without virtual processing using p = 16,384 physical processors. <p> Given a linear linked list, each element in the list is stored in a processor. For each element, compute the summation of all the data that are ahead of it in the linked list. This operator is described in the kernel routines given in <ref> [19] </ref>. For example, the kernel routine listrank32 (ptr, data) performs list ranking on the plural variable data for each active processor, where ptr specifies the location of the next element. <p> We ran the randomized algorithm until the first time the number of elements remaining was no more than the number of physical processors. Then we ran the deterministic algorithm without virtual processing given in <ref> [19] </ref> after evenly distributing the remaining elements among available physical 19 =fl A revised optimal randomized list ranking algorithm. fl= 1. =fl Shrink the size of the list fl= perform the while loop in step 1 of Algorithm 1 until the the total number of remaining elements is less than or <p> This operator is described in the kernel routines given in <ref> [19] </ref>. For example, the kernel routine buildTMin32 (v) builds such data structures for 32-bit integers and the kernel routine queryMin32 (s, t) returns the minimum (maximum) values queried. We implemented these two routines in the work reported in [19] without virtual processing. <p> This operator is described in the kernel routines given in <ref> [19] </ref>. For example, the kernel routine buildTMin32 (v) builds such data structures for 32-bit integers and the kernel routine queryMin32 (s, t) returns the minimum (maximum) values queried. We implemented these two routines in the work reported in [19] without virtual processing. We describe these primitives in the following subsections. 5.3.1 Sort, Rank, and Sendwith The first three routines in this category could be implemented with virtual processing by calling a sorting routine that could handle virtual processing. For this, we used the package developed in [38]. <p> Note that to send 32-bit integers using the sendwith operator, we had to sort 64-bit data. Performance data for these three routines are shown in Table 6. 5.3.2 Range Minima (Maxima) In our code without virtual processing <ref> [19] </ref>, the table we built in each physical processor for the range minima (maxima) queries was a one-dimensional array W such that W [i] is the minimum (maximum) value of all elements starting from the current physical processor to a physical processor whose ID is 2 i 1 larger than the <p> We have used this approach to convert the non-vp code for six parallel graph algorithms given in <ref> [19] </ref> into code that solves the same set of graph algorithms with virtual processing. Our coding approach is summarized as follows. Using our original code when no virtual processors are used [19] as a blueprint and the extended mapping as a guideline, we transformed our code to handle the allocation of <p> We have used this approach to convert the non-vp code for six parallel graph algorithms given in <ref> [19] </ref> into code that solves the same set of graph algorithms with virtual processing. Our coding approach is summarized as follows. Using our original code when no virtual processors are used [19] as a blueprint and the extended mapping as a guideline, we transformed our code to handle the allocation of virtual processors. Since the MPL language does not support virtual processing, we had to implement our own scheme for virtual processing. <p> Since the MPL language does not support virtual processing, we had to implement our own scheme for virtual processing. To do this, we re-coded and fine-tuned the set of parallel primitives identified in <ref> [19] </ref> and several system library routines to handle the allocation of virtual processors efficiently. This was done using the techniques described in the present paper. Then we implemented a set of parallel graph algorithms by calling these parallel primitives and system routines. The performance data is shown in Table 8. <p> The input size of non-vp programs is m = 8; 192. The input size for programs with virtual processing is 32 times larger than the input size for non-vp programs. The data for parallel programs without virtual processing is from <ref> [19] </ref>.
Reference: [20] <author> T.-s. Hsu, V. Ramachandran, and N. Dean. </author> <title> Parallel implementation of algorithms for finding connected components. </title> <booktitle> Presented at the 3rd DIMACS Implementation Challenge Workshop, </booktitle> <year> 1994. </year>
Reference: [21] <author> T.-s. Hsu, V. Ramachandran, and N. Dean. </author> <title> Implementation of parallel graph algorithms on a massively parallel SIMD computer with virtual processing. </title> <booktitle> In Proc. 9th International Parallel Processing Symp., </booktitle> <pages> pages 106-112, </pages> <year> 1995. </year> <month> 29 </month>
Reference-contexts: We used the quick sort routine provided by the system library for sorting. The performance data for the sequential algorithms was obtained by running our programs on a SPARC 10/41 machine with 32 megabytes of main memory and about 80 megabytes of swapping space. As indicated in <ref> [21] </ref>, the SPARC 10/41 is at least 230 times faster than a single MP-1 PE. Since the MP-1 that we used has 16,384 PE's, the raw computational power of the MP-1 was at least 63 times larger than a SPARC 10/41. 24 Fig. 1.
Reference: [22] <author> W. M. Hsu. </author> <title> Segmented ray casting for data parallel volume rendering. </title> <type> Technical Report TR-MP/IP/SP-39.93, </type> <institution> MasPar Computer Corporation, </institution> <year> 1993. </year>
Reference: [23] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: primitives such as (i) exchanging data between neighboring virtual processors, (ii) the scan routine [26] with several combining operators, (iii) routing routines, (iv) list ranking routines [11], (v) routines for ordering data, (vi) concurrent write routines with several combining operators, and (vii) range minima routines (see e.g., Section 3.4.3 in <ref> [23] </ref>). For many of our primitives, we implemented several different algorithms and we present a comparison of their performances. Previous work on implementing commonly used parallel primitives includes work reported in [7,8,16,17,35,38,41,43,44]. The rest of the paper is organized as follows. Section 2 gives a high-level description of our implementation.
Reference: [24] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel algorithms for shared-memory machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <pages> pages 869-941. </pages> <publisher> North Holland, </publisher> <year> 1990. </year>
Reference: [25] <author> B. W. Kernighan and D. M. Ritchie. </author> <title> The C Programming language. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year> <note> Second Edition. </note>
Reference-contexts: There are important problems that can be solved on massively parallel SIMD machines with virtual processing [4,5,15,13,22,27,28,39,40]. In [19], we reported the implementation of several parallel graph algorithms on the MasPar MP-1 using the parallel language MPL [30,31] which is an extension of the C language <ref> [25] </ref>. The MPL language provides an efficient way of using the MasPar MP-1. However, it requires the user to specify the physical organization of the processors used in the program, and provides no support for virtual processing. <p> The ACU is at least 10 times faster than an MP-1 PE. We used the MPL high-level programming language for coding our programs. The current version of the MPL language [30,31,36] is an extension of the ANSI C language <ref> [25] </ref> with data parallel constructs and a library of parallel primitives. In addition to all of the standard C language features, it allows the user to program a set of PE's to execute the same instruction on their own local data. <p> The three basic parallel primitives are prefix summing, list ranking, and sorting. We implemented sequential linear time algorithms for prefix summing and list ranking using the C programming language <ref> [25] </ref> on a UNIX system [42] (SunOS 4.1.3). We used the quick sort routine provided by the system library for sorting.
Reference: [26] <author> R. E. Ladner and M. J. Fischer. </author> <title> Parallel prefix computation. </title> <journal> J. ACM, </journal> <volume> 27 </volume> <pages> 831-838, </pages> <year> 1980. </year>
Reference-contexts: In the current paper, we describe our implementation of virtual processing using MPL. Our current implementation includes a set of coding techniques for writing code with virtual processing and fine-tuned routines for several primitives such as (i) exchanging data between neighboring virtual processors, (ii) the scan routine <ref> [26] </ref> with several combining operators, (iii) routing routines, (iv) list ranking routines [11], (v) routines for ordering data, (vi) concurrent write routines with several combining operators, and (vii) range minima routines (see e.g., Section 3.4.3 in [23]).
Reference: [27] <author> S. Lanteri and C. Farhat. </author> <title> Viscous flow computations on MPP systems: Implementational issues and performance results for unstructured grids. </title> <booktitle> In Proc. 6th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 65-70, </pages> <year> 1993. </year>
Reference: [28] <author> A. K. Lenstra. </author> <title> Factoring integers using simd sieves. </title> <type> Technical Report TR-MP/PA-28.94, </type> <institution> MasPar Computer Corporation, </institution> <year> 1993. </year>
Reference: [29] <institution> MasPar Computer Co. </institution> <note> MasPar Data Display Library (MPDDL) Reference manual, version 3.0, rev. a6 edition, </note> <month> July </month> <year> 1992. </year>
Reference-contexts: Under the above mapping scheme, each physical processor simulates a roughly equal number of the vnproc virtual processors needed, except that the last V P vnproc virtual processors have their local active flag set to 0 throughout the computation. For our implementation, we used the so-called hierarchical partitioning scheme <ref> [29] </ref>. Each physical processor simulated a vpr fi 1 sub-mesh of virtual processors.
Reference: [30] <institution> MasPar Computer Co. </institution> <note> MasPar Parallel Application Language (MPL) Reference manual, version 3.0, rev. a3 edition, </note> <month> July </month> <year> 1992. </year>
Reference: [31] <author> MasPar Computer Co. </author> <title> MasPar Parallel Application Language (MPL) User Guide, </title> <note> version 3.1, rev. a3 edition, </note> <month> November </month> <year> 1992. </year>
Reference: [32] <institution> MasPar Computer Co. MasPar System Overview, </institution> <note> rev. a5 edition, </note> <month> July </month> <year> 1992. </year>
Reference: [33] <institution> MasPar Computer Co. </institution> <note> Release Notes for MasPar System Software, version 3.1, rev. b4 edition, </note> <month> November </month> <year> 1992. </year>
Reference-contexts: The system routine p random generates a pseudo-random number for each active PE. On page 5 of <ref> [33] </ref>, it says "Although the values of p random are random sequences from each PE's point of view, you might see some discernible pattern in the PE array as a whole." A Revised Optimal Randomized Algorithm In order to remedy the above problem we modified Algorithm 1 as follows.
Reference: [34] <author> J. R. Nickolls and J. Reusch. </author> <title> Autonomous SIMD flexibility in the MP-1 and MP-2. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 98-99, </pages> <year> 1993. </year>
Reference: [35] <author> P. M. Pardalos, M. G.C. Resende, and K.G. Ramakrishnan, </author> <title> editors. Parallel processing of discrete optimization problems, </title> <booktitle> volume 22 of DIMACS series in discrete mathematics and theoretical computer science. </booktitle> <publisher> American Mathematical Society, </publisher> <year> 1995. </year>
Reference: [36] <author> R. Pickering and J. Cook. </author> <title> A first course in programming the DECmpp/Sx. </title> <type> Technical report, </type> <institution> para//lab, Dept. of Informatics, Univ. of Bergen, N-5020 Bergen, Norway, </institution> <year> 1993. </year> <title> Series of Parallel Processing: A Self-Study Introduction. </title>
Reference: [37] <author> L. Prechelt. </author> <title> Measurements of MasPar MP-1216A communication operations. </title> <type> Technical Report 01/93, </type> <institution> Institute fur Programmstrukturen und Datenorganisation, Fakultat fur Informatik, Universitat Karlsruhe, Germany, </institution> <month> January </month> <year> 1993. </year> <month> 30 </month>
Reference-contexts: However, we found that s p (Q) remained roughly the same no matter how many active physical processors were used in the MP-1 for all the routines in this category. (This fact was also confirmed by experiments conducted in <ref> [37] </ref>.) Thus we were unable to further fine-tune our code using this approach. 5.2 Category 2: Locality Insensitive Routines In this category are those parallel primitives that could be implemented with virtual processing by exactly vpr executions of the original non-vp parallel primitive and some local computations performed in each physical
Reference: [38] <author> J. F. Prins and J. A. Smith. </author> <title> Parallel sorting of large arrays on the MasPar MP-1. </title> <booktitle> In Proc. 3rd Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 59-64, </pages> <year> 1990. </year>
Reference-contexts: Thus given an nxproc fi nyproc 2-dimensional mesh, the virtual machine being simulated is an (nxproc vpr) fi nyproc 2-dimensional mesh. (This is the same mapping scheme as the one used in the implementation of bitonic sort with virtual processing <ref> [38] </ref>.) The reason for our choice is that, in our implementation, we frequently need to use operations that utilize locality of data, and this locality is preserved by our data partitioning scheme. <p> We describe these primitives in the following subsections. 5.3.1 Sort, Rank, and Sendwith The first three routines in this category could be implemented with virtual processing by calling a sorting routine that could handle virtual processing. For this, we used the package developed in <ref> [38] </ref>. Since the sorting package in [38] can only handle the case when the number of virtual processors simulated by each physical processor is a power of two, our code inherited the same restriction. <p> For this, we used the package developed in <ref> [38] </ref>. Since the sorting package in [38] can only handle the case when the number of virtual processors simulated by each physical processor is a power of two, our code inherited the same restriction. <p> psort32 prank32 sendwithMax64 time (ms) ratio time (ms) ratio time (ms) ratio system (no VPE) 7.69 9.44 9.6 vpr = 2 17.87 2.3 24.76 2.6 34.4 3.6 8 59.64 7.8 98.57 10.4 134.4 14.0 32 241.90 31.5 415.41 44.0 559.8 58.3 Table 6 Performance data for performing the sort operator <ref> [38] </ref> and the rank operator on 32-bit integers, and for performing the sendwith operator on 64-bit integers by using maximum as the combining operator. <p> We find that for performing prefix summing, our parallel implementation ran 25 Fig. 2. Performance data for performing list ranking sequentially and in parallel. Fig. 3. Performance data for performing sorting sequentially and in parallel. The sequential implementation used a quick sort algorithm. The parallel implementation which is given <ref> [38] </ref> uses a bitonic sort algorithm. The function f (X) in the right figure is 0:004 + 0:004X + 0:001X log X + 0:0000064X log 2 X. about 70 times faster than our sequential implementation when all data could fit in the main memory of our SPARC 10/41. <p> On the other hand, our parallel implementation performed predictably well for the size of the the input that was more than 5 times larger than the largest input that we have tested on the sequential implementation. For performing sorting, the parallel implementation of the bitonic sort algorithm we used <ref> [38] </ref> was about 45 times faster than the sequential implementation of the quick 26 sort algorithm on the largest input that we have tested. 7 Performance for Implemented Parallel Graph Algorithms The techniques presented in this paper can be used to rewrite a general MPL code without virtual processing to a
Reference: [39] <author> A. Purkayastha and J. Seguel. </author> <title> Efficient algorithms for some specific FFTs on a massively parallel computer. </title> <booktitle> In Proc. 7th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 21-26, </pages> <year> 1995. </year>
Reference: [40] <author> V. Ramachandran and L.-C. Wang. </author> <title> Parallel algorithms and complexity results for telephone link simulation. </title> <booktitle> In Proc. 3rd IEEE Symp. on Parallel and Distributed Processing, </booktitle> <pages> pages 378-385, </pages> <year> 1991. </year>
Reference: [41] <author> M. Reid-Miller. </author> <title> List ranking and list scan on the CRAY C-90. </title> <booktitle> In Proc. 6th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 104-113, </pages> <year> 1994. </year>
Reference-contexts: All of our test cases for our revised algorithm succeeded in 5 2 vpr iterations. We also note that on the largest input, our revised randomized algorithm was more than twice faster than the sub-optimal deterministic version (Program 6). For a comparison with other work, Reid-Miller <ref> [41] </ref> implemented a list ranking algorithm on a vector super computer CRAY C-90. Using 8 processors on a 16-processor machine, their implementation is currently the fastest parallel implementation known.
Reference: [42] <author> D. M. Ritchie and K. Thompson. </author> <title> The Unix timesharing system. </title> <journal> Communications of the ACM, </journal> <volume> 17 </volume> <pages> 365-375, </pages> <month> July </month> <year> 1974. </year>
Reference-contexts: The three basic parallel primitives are prefix summing, list ranking, and sorting. We implemented sequential linear time algorithms for prefix summing and list ranking using the C programming language [25] on a UNIX system <ref> [42] </ref> (SunOS 4.1.3). We used the quick sort routine provided by the system library for sorting. The performance data for the sequential algorithms was obtained by running our programs on a SPARC 10/41 machine with 32 megabytes of main memory and about 80 megabytes of swapping space.
Reference: [43] <author> J. T. Schwartz. </author> <title> Ultracomputers. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 2 </volume> <pages> 484-521, </pages> <month> October </month> <year> 1980. </year>
Reference: [44] <author> T. J. She*er. </author> <title> Implementing the multiprefix operation on parallel and vector computers. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 377-386, </pages> <year> 1993. </year>
Reference: [45] <author> U. Vishkin. </author> <title> Implementation of simultaneous memory address access in models that forbid it. </title> <journal> J. Algorithms, </journal> <volume> 4 </volume> <pages> 45-50, </pages> <year> 1983. </year>
Reference: [46] <author> U. Vishkin. </author> <title> Randomized speed-ups in parallel computation. </title> <booktitle> In Proc. 16th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 230-239, </pages> <year> 1984. </year>
Reference: [47] <author> J. C. Wyllie. </author> <title> The complexity of parallel computations. </title> <type> Technical report, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, NY, </address> <month> August </month> <year> 1979. </year> <type> Tech. Rep. </type> <institution> TR-79-387. </institution> <month> 31 </month>
Reference-contexts: section, we can conclude that if the degree of concurrency is not too large, it is better to use the naive implementation of routing given in Program 5. 5.2.2 List Ranking Our code without virtual processing for list ranking was for the simple EREW list ranking algorithm using pointer jumping <ref> [47] </ref>. The algorithm runs in log n iterations by repeatedly changing the current pointer of each active processor Q to the pointer stored in the processor that is currently pointed to by Q. A processor becomes inactive when it reaches the end of the list. <p> The MPL code for a simple sub-optimal deterministic list ranking algorithm <ref> [47] </ref> with virtual processing. 15 Routing 32-bit Integers expected time (ms) concurrency no virtual vpr = 16 (con) processing naive convert to implementation exclusive read 1 0.45 18.00 236.97 4 1.13 45.03 244.78 16 2.86 115.71 237.72 64 5.44 216.33 232.18 256 10.59 415.99 233.74 1,024 41.28 1,624.66 229.56 4,096 144.84
References-found: 47

