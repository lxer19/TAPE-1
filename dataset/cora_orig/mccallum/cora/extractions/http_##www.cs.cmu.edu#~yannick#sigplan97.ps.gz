URL: http://www.cs.cmu.edu/~yannick/sigplan97.ps.gz
Refering-URL: http://www.cs.cmu.edu/~yannick/publis.html
Root-URL: 
Email: vialle@ese-metz.fr  cornu@di.epfl.ch  yannick@cmu.edu  
Title: ParCeL-1: a parallel programming language based on autonomous and synchronous actors  
Author: Stephane Vialle Thierry Cornu Yannick Lallement 
Address: 2 rue Edouard Belin F-57078 Metz cedex 3  CH-1015 Lausanne  BP 239 F-54506 Vandoeuvre-les-Nancy  
Affiliation: Supelec  Swiss Federal Institute of Technology EPFL DI, LITH  Crin-CNRS-Inria Lorraine  
Abstract: In this paper we present a new language, called ParCeL-1, intended to make easier the implementation of computation-intensive applications on highly parallel MIMD architectures. The computational model of ParCeL-1 is object-oriented and synchronous. The current prototype is implemented on several multi-processor systems (Cray T3D, Intel Paragon, Telmat T-Node and workstation networks using PVM). Benchmarks are presented for several parallel programs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agha. </author> <title> ACTORS, a model of concurrent computation in distributed systems. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Among the most prolific class of alternate models are those based on concurrent objects or actors. Concurrent object computation traces back to the actor model proposed by Hewitt [9] and later improved by Clinger and Agha <ref> [1] </ref>. The most recent system in this lineage is the HAL [10] language. The concept of actors has also been developed independently by the team of Yonezawa since the mid-eighties, yielding the successive variants of the ABCL language [17, 13]. <p> citer = 0; for (cconn = 0; cconn &lt; N; cconn += 1) /* Connection between these cells */ for (ccell = 0; ccell &lt; N; ccell += 1) - connect PosIn [cconn][0] of TabBody [ccell] to PosOut [0] of TabBody [cconn]; connect PosIn [cconn]<ref> [1] </ref> of TabBody [ccell] to PosOut [1] of TabBody [cconn]; - TRUE ==&gt; - /* Wait until all the iterations are */ citer += 1; /* completed */ if (citer &gt; NB_ITER) halt; - typecell Body (int NbIter, int me) - in double PosIn [N][2]; /* Current positions */ out double PosOut [2]; /* Future positions */ <p> /* Square of the distance */ int i,iter; symbol Fs; /* Trajectory file */ void InitSys (int i) /* Initialization function */ - - initially ==&gt; - /* Rule executed on creation of the cell */ InitSys (me); Fs = mfopen ('traject',me,'w'); fprintd (Fs,PosOut [0]); fprints (Fs,' '); fprintd (Fs,PosOut <ref> [1] </ref>); fprintnl (Fs); citer = 0; - citer &lt; NbIter ==&gt; - /* Compute new speed/position of the body */ a [0] = 0.0; a [1] = 0.0; /* Initialize temporary buffers */ for (i = 0; i &lt; N; i += 1) /* Compute total strength */ if (i != <p> ==&gt; - /* Rule executed on creation of the cell */ InitSys (me); Fs = mfopen ('traject',me,'w'); fprintd (Fs,PosOut [0]); fprints (Fs,' '); fprintd (Fs,PosOut <ref> [1] </ref>); fprintnl (Fs); citer = 0; - citer &lt; NbIter ==&gt; - /* Compute new speed/position of the body */ a [0] = 0.0; a [1] = 0.0; /* Initialize temporary buffers */ for (i = 0; i &lt; N; i += 1) /* Compute total strength */ if (i != me) - dp [0] = PosIn [i][0] - PosIn [me][0]; dp [1] = PosIn [i][1] - PosIn [me][1]; d2 = dp [0]*dp [0] + dp <p> /* Compute new speed/position of the body */ a [0] = 0.0; a <ref> [1] </ref> = 0.0; /* Initialize temporary buffers */ for (i = 0; i &lt; N; i += 1) /* Compute total strength */ if (i != me) - dp [0] = PosIn [i][0] - PosIn [me][0]; dp [1] = PosIn [i][1] - PosIn [me][1]; d2 = dp [0]*dp [0] + dp [1]*dp [1]; a [0] += G*WEI [i]*(dp [0])/d2/sqrt (d2); a [1] += G*WEI [i]*(dp [1])/d2/sqrt (d2); - SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE [1] += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] <p> 0.0; /* Initialize temporary buffers */ for (i = 0; i &lt; N; i += 1) /* Compute total strength */ if (i != me) - dp [0] = PosIn [i][0] - PosIn [me][0]; dp <ref> [1] </ref> = PosIn [i][1] - PosIn [me][1]; d2 = dp [0]*dp [0] + dp [1]*dp [1]; a [0] += G*WEI [i]*(dp [0])/d2/sqrt (d2); a [1] += G*WEI [i]*(dp [1])/d2/sqrt (d2); - SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE [1] += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] + DELTA_T*SPE [0]; /* Compute new position */ PosOut [1] = PosIn [me][1] + DELTA_T*SPE <p> 0; i &lt; N; i += 1) /* Compute total strength */ if (i != me) - dp [0] = PosIn [i][0] - PosIn [me][0]; dp <ref> [1] </ref> = PosIn [i][1] - PosIn [me][1]; d2 = dp [0]*dp [0] + dp [1]*dp [1]; a [0] += G*WEI [i]*(dp [0])/d2/sqrt (d2); a [1] += G*WEI [i]*(dp [1])/d2/sqrt (d2); - SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE [1] += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] + DELTA_T*SPE [0]; /* Compute new position */ PosOut [1] = PosIn [me][1] + DELTA_T*SPE [1]; fprintd (Fs,PosOut [0]); fprints (Fs,' '); /* Save <p> [0] = PosIn [i][0] - PosIn [me][0]; dp <ref> [1] </ref> = PosIn [i][1] - PosIn [me][1]; d2 = dp [0]*dp [0] + dp [1]*dp [1]; a [0] += G*WEI [i]*(dp [0])/d2/sqrt (d2); a [1] += G*WEI [i]*(dp [1])/d2/sqrt (d2); - SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE [1] += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] + DELTA_T*SPE [0]; /* Compute new position */ PosOut [1] = PosIn [me][1] + DELTA_T*SPE [1]; fprintd (Fs,PosOut [0]); fprints (Fs,' '); /* Save position in file */ fprintd (Fs,PosOut [1]); fprintnl (Fs); citer += 1; /* This was one more iteration <p> [i][0] - PosIn [me][0]; dp <ref> [1] </ref> = PosIn [i][1] - PosIn [me][1]; d2 = dp [0]*dp [0] + dp [1]*dp [1]; a [0] += G*WEI [i]*(dp [0])/d2/sqrt (d2); a [1] += G*WEI [i]*(dp [1])/d2/sqrt (d2); - SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE [1] += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] + DELTA_T*SPE [0]; /* Compute new position */ PosOut [1] = PosIn [me][1] + DELTA_T*SPE [1]; fprintd (Fs,PosOut [0]); fprints (Fs,' '); /* Save position in file */ fprintd (Fs,PosOut [1]); fprintnl (Fs); citer += 1; /* This was one more iteration */ - citer <p> [0]*dp [0] + dp <ref> [1] </ref>*dp [1]; a [0] += G*WEI [i]*(dp [0])/d2/sqrt (d2); a [1] += G*WEI [i]*(dp [1])/d2/sqrt (d2); - SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE [1] += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] + DELTA_T*SPE [0]; /* Compute new position */ PosOut [1] = PosIn [me][1] + DELTA_T*SPE [1]; fprintd (Fs,PosOut [0]); fprints (Fs,' '); /* Save position in file */ fprintd (Fs,PosOut [1]); fprintnl (Fs); citer += 1; /* This was one more iteration */ - citer == NbIter ==&gt; - /* Final rule of the cell */ fclose (Fs); citer += <p> a [0] += G*WEI [i]*(dp [0])/d2/sqrt (d2); a <ref> [1] </ref> += G*WEI [i]*(dp [1])/d2/sqrt (d2); - SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE [1] += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] + DELTA_T*SPE [0]; /* Compute new position */ PosOut [1] = PosIn [me][1] + DELTA_T*SPE [1]; fprintd (Fs,PosOut [0]); fprints (Fs,' '); /* Save position in file */ fprintd (Fs,PosOut [1]); fprintnl (Fs); citer += 1; /* This was one more iteration */ - citer == NbIter ==&gt; - /* Final rule of the cell */ fclose (Fs); citer += 1; - 4 Benchmarks criteria In <p> SPE [0] += DELTA_T*a [0]; /* Compute new speed */ SPE <ref> [1] </ref> += DELTA_T*a [1]; PosOut [0] = PosIn [me][0] + DELTA_T*SPE [0]; /* Compute new position */ PosOut [1] = PosIn [me][1] + DELTA_T*SPE [1]; fprintd (Fs,PosOut [0]); fprints (Fs,' '); /* Save position in file */ fprintd (Fs,PosOut [1]); fprintnl (Fs); citer += 1; /* This was one more iteration */ - citer == NbIter ==&gt; - /* Final rule of the cell */ fclose (Fs); citer += 1; - 4 Benchmarks criteria In order to evaluate ParCeL-1 performance, a sequence of criteria is defined.
Reference: [2] <author> G. M. </author> <title> Amdahl. Validity of the single processor approach to achieving large scale computing capabilities. </title> <booktitle> In AFIPS conference proceedings, </booktitle> <address> Atlantic City, N.J., </address> <year> 1967. </year>
Reference-contexts: TabBody [ccell] to PosOut [1] of TabBody [cconn]; - TRUE ==&gt; - /* Wait until all the iterations are */ citer += 1; /* completed */ if (citer &gt; NB_ITER) halt; - typecell Body (int NbIter, int me) - in double PosIn [N]<ref> [2] </ref>; /* Current positions */ out double PosOut [2]; /* Future positions */ double SPE [2],WEI [2]; /* Speed, weight */ double dp [2]; /* Position differences buffer */ double a [2]; /* Acceleration buffer */ double d2; /* Square of the distance */ int i,iter; symbol Fs; /* Trajectory file */ void InitSys (int i) /* Initialization function <p> - TRUE ==&gt; - /* Wait until all the iterations are */ citer += 1; /* completed */ if (citer &gt; NB_ITER) halt; - typecell Body (int NbIter, int me) - in double PosIn [N]<ref> [2] </ref>; /* Current positions */ out double PosOut [2]; /* Future positions */ double SPE [2],WEI [2]; /* Speed, weight */ double dp [2]; /* Position differences buffer */ double a [2]; /* Acceleration buffer */ double d2; /* Square of the distance */ int i,iter; symbol Fs; /* Trajectory file */ void InitSys (int i) /* Initialization function */ - - initially ==&gt; - /* Rule <p> all the iterations are */ citer += 1; /* completed */ if (citer &gt; NB_ITER) halt; - typecell Body (int NbIter, int me) - in double PosIn [N]<ref> [2] </ref>; /* Current positions */ out double PosOut [2]; /* Future positions */ double SPE [2],WEI [2]; /* Speed, weight */ double dp [2]; /* Position differences buffer */ double a [2]; /* Acceleration buffer */ double d2; /* Square of the distance */ int i,iter; symbol Fs; /* Trajectory file */ void InitSys (int i) /* Initialization function */ - - initially ==&gt; - /* Rule executed on creation of the cell */ <p> /* completed */ if (citer &gt; NB_ITER) halt; - typecell Body (int NbIter, int me) - in double PosIn [N]<ref> [2] </ref>; /* Current positions */ out double PosOut [2]; /* Future positions */ double SPE [2],WEI [2]; /* Speed, weight */ double dp [2]; /* Position differences buffer */ double a [2]; /* Acceleration buffer */ double d2; /* Square of the distance */ int i,iter; symbol Fs; /* Trajectory file */ void InitSys (int i) /* Initialization function */ - - initially ==&gt; - /* Rule executed on creation of the cell */ InitSys (me); Fs = mfopen ('traject',me,'w'); fprintd (Fs,PosOut <p> The sequential slow-down SD0 amounts to 1.4, and limits the efficiency to approximately 70%, as shown on figure 7, even for a small number of processors. The efficiency decay for a large number of processors is due to load imbalance, communication overheads and sequential fraction problems (Am-dahl's law <ref> [2] </ref>) that become critical beyond 100 processors.
Reference: [3] <author> T. Cheatham, A. Fahmy, D. Stefanescu, and L. Valiant. </author> <title> Bulk synchronous parallel computing | a paradigm for transportable software. </title> <booktitle> In Proceedings of the 28th Annual Hawaii Conference on System Sciences, volume II. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> January </month> <year> 1995. </year>
Reference-contexts: BSP provides a framework for automatic data allocation, for latency hiding and for performance prediction. Theoretical results [15] strongly suggest that it may be implemented efficiently on many parallel computer architectures. In the recent years, actual programming tools using BSP were developed <ref> [7, 3] </ref>. At the time of writing, a standardization effort is going on to set up a worldwide standard for a BSP library [6]. Meanwhile, new MIMD architectures appeared such as the Cray T3D and T3E, in which virtual shared memory as well as synchronization barriers are hardware-implemented.
Reference: [4] <author> A. Chien, U. Reddy, J. Plevyak, and J. Dolby. </author> <title> IC++: A C++ dialect for high performance parallel computing. </title> <booktitle> In 2nd international symposium on object technologies for advanced software (ISOTAS), </booktitle> <address> Kanazawa, Japan, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: The concept of actors has also been developed independently by the team of Yonezawa since the mid-eighties, yielding the successive variants of the ABCL language [17, 13]. In parallel to actor languages, extensions of compiled object languages like C++ or Eiffel also introduced concurrent objects <ref> [4, 8] </ref>. In actor- or object-based models, parallelism of execution is expressed explicitly. The main specificity of these models is that they make programmers write already distributed code. This opens interesting opportunities for automated data distribution and process mapping.
Reference: [5] <author> R. Chin and S. Chanson. </author> <title> Distributed object-based programming systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 23(1), </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: As a result, communication is not easy to implement efficiently and concurrent object systems are often restricted to coarse grain parallelism for performance reasons. As a result, concurrent object programming, while finding a wider and wider acceptance for implementing distributed systems over wide area networks <ref> [5] </ref>, is still seldom used in massively parallel high performance computers. Bulk-synchronous computation Bulk-synchronous computation was first introduced by Valiant [14, 15] with the Bulk Synchronous Programming (BSP) model.
Reference: [6] <author> M. W. Goudreau, H. M. D. Hill, B. McColl, S. B. Rao, D. C. Stefanescu, T. Suel, and T. Tsantilas. </author> <title> A proposal for the BSP world-wide standard library (preliminary version). BSP Worldwide document, </title> <month> April </month> <year> 1996. </year> <note> Available at http://www.bsp-worldwide.org/. </note>
Reference-contexts: In the recent years, actual programming tools using BSP were developed [7, 3]. At the time of writing, a standardization effort is going on to set up a worldwide standard for a BSP library <ref> [6] </ref>. Meanwhile, new MIMD architectures appeared such as the Cray T3D and T3E, in which virtual shared memory as well as synchronization barriers are hardware-implemented. The most efficient way to program these machines is to use asynchronous remote memory access, also called one-sided message passing, and synchronization barriers.
Reference: [7] <author> M. W. Goudreau, S. B. Rao, and T. Tsantilas. </author> <title> A study of the BSP model: Algorithms and implementation. </title> <type> Technical Report UCFCS:CS-TR-94-04, </type> <institution> Department of Computer Science, University of Central Florida, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: BSP provides a framework for automatic data allocation, for latency hiding and for performance prediction. Theoretical results [15] strongly suggest that it may be implemented efficiently on many parallel computer architectures. In the recent years, actual programming tools using BSP were developed <ref> [7, 3] </ref>. At the time of writing, a standardization effort is going on to set up a worldwide standard for a BSP library [6]. Meanwhile, new MIMD architectures appeared such as the Cray T3D and T3E, in which virtual shared memory as well as synchronization barriers are hardware-implemented.
Reference: [8] <author> A. S. Grimshaw, J. B. Weissman, and W. T. Strayer. </author> <title> Portable run-time support for dynamic object-oriented parallel processing. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 14(2), </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: The concept of actors has also been developed independently by the team of Yonezawa since the mid-eighties, yielding the successive variants of the ABCL language [17, 13]. In parallel to actor languages, extensions of compiled object languages like C++ or Eiffel also introduced concurrent objects <ref> [4, 8] </ref>. In actor- or object-based models, parallelism of execution is expressed explicitly. The main specificity of these models is that they make programmers write already distributed code. This opens interesting opportunities for automated data distribution and process mapping.
Reference: [9] <author> C. Hewitt, P. Bishop, and R. Steiger. </author> <title> A univer-sal modular actor formalism for artificial intelligence. </title> <booktitle> In IJCAI, </booktitle> <year> 1973. </year>
Reference-contexts: Among the most prolific class of alternate models are those based on concurrent objects or actors. Concurrent object computation traces back to the actor model proposed by Hewitt <ref> [9] </ref> and later improved by Clinger and Agha [1]. The most recent system in this lineage is the HAL [10] language. The concept of actors has also been developed independently by the team of Yonezawa since the mid-eighties, yielding the successive variants of the ABCL language [17, 13].
Reference: [10] <author> C. Houck and G. Agha. Hal: </author> <title> A high-level actor language and its distributed implementation. </title> <booktitle> In 21st International conference on parallel processing (ICCPP'92), volume 2, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Among the most prolific class of alternate models are those based on concurrent objects or actors. Concurrent object computation traces back to the actor model proposed by Hewitt [9] and later improved by Clinger and Agha [1]. The most recent system in this lineage is the HAL <ref> [10] </ref> language. The concept of actors has also been developed independently by the team of Yonezawa since the mid-eighties, yielding the successive variants of the ABCL language [17, 13]. In parallel to actor languages, extensions of compiled object languages like C++ or Eiffel also introduced concurrent objects [4, 8].
Reference: [11] <author> Y. Lallement, Th. Cornu, and S. Vialle. </author> <title> Application development under parcel-1. </title> <editor> In H. Ki-tano, C. Suttner, and J. Geller, editors, </editor> <booktitle> Parallel Processing for Artificial Intelligence, </booktitle> <volume> 3. </volume> <publisher> Elsevier, </publisher> <year> 1996. </year> <note> In Press. </note>
Reference-contexts: We are currently working on further optimizations of the compiler, especially regarding code generation, I/O semantics and cell communications. We are also currently implementing real size applications (connectionism and artificial intelligence <ref> [11] </ref>), with large parallel I/O and data sets. ParCeL-1 Home Page: http://www.ese-metz.fr/ info/project/parcel/parcel.html
Reference: [12] <author> R. Miller. </author> <title> A library for bulk-synchronous parallel programming. </title> <booktitle> In British Computer Society Parallel Processing Specialist Group workshop on General Purpose Parallel Computing, </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: The most efficient way to program these machines is to use asynchronous remote memory access, also called one-sided message passing, and synchronization barriers. This programming style closely matches the BSP model and implementing a BSP library on top of these machines is extremely simple <ref> [12] </ref>. Introduction of one-sided message passing in standard parallel programming models like High Performance Fortran is also under discussion.
Reference: [13] <author> K. Taura, S. Matsuoka, and A. Yonezawa. ABCL/f: </author> <title> A future-based polymorphic typed concurrent object-oriented language its design and implementation. </title> <editor> In G. Blelloch, M. Chandy, and S. Jagannathan, editors, </editor> <booktitle> Proceedings of the DIMACS workshop on specification of parallel algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: The most recent system in this lineage is the HAL [10] language. The concept of actors has also been developed independently by the team of Yonezawa since the mid-eighties, yielding the successive variants of the ABCL language <ref> [17, 13] </ref>. In parallel to actor languages, extensions of compiled object languages like C++ or Eiffel also introduced concurrent objects [4, 8]. In actor- or object-based models, parallelism of execution is expressed explicitly. The main specificity of these models is that they make programmers write already distributed code.
Reference: [14] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8), </volume> <month> August </month> <year> 1990. </year>
Reference-contexts: As a result, concurrent object programming, while finding a wider and wider acceptance for implementing distributed systems over wide area networks [5], is still seldom used in massively parallel high performance computers. Bulk-synchronous computation Bulk-synchronous computation was first introduced by Valiant <ref> [14, 15] </ref> with the Bulk Synchronous Programming (BSP) model. Computation in a BSP program consists of a sequence of super-steps; each super-step is a sequence of steps followed by a synchronization barrier at which non-local communications take effect.
Reference: [15] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, chapter 18. </booktitle> <publisher> Else-vier Science Publishers, </publisher> <year> 1990. </year>
Reference-contexts: As a result, concurrent object programming, while finding a wider and wider acceptance for implementing distributed systems over wide area networks [5], is still seldom used in massively parallel high performance computers. Bulk-synchronous computation Bulk-synchronous computation was first introduced by Valiant <ref> [14, 15] </ref> with the Bulk Synchronous Programming (BSP) model. Computation in a BSP program consists of a sequence of super-steps; each super-step is a sequence of steps followed by a synchronization barrier at which non-local communications take effect. <p> Computation in a BSP program consists of a sequence of super-steps; each super-step is a sequence of steps followed by a synchronization barrier at which non-local communications take effect. BSP provides a framework for automatic data allocation, for latency hiding and for performance prediction. Theoretical results <ref> [15] </ref> strongly suggest that it may be implemented efficiently on many parallel computer architectures. In the recent years, actual programming tools using BSP were developed [7, 3]. At the time of writing, a standardization effort is going on to set up a worldwide standard for a BSP library [6].
Reference: [16] <author> S. Vialle, T. Cornu, and Y. Lallement. ParCeL-1, </author> <title> User's Guide and Reference Manual. </title> <institution> Technical Report R-10 (Crin number 94-R-235), Supelec, etablissement de Metz, France, </institution> <year> 1994. </year>
Reference-contexts: ParCeL-1 is aimed to provide an alternate programming model that would: * make it possible to program a wider class of ap plications than data parallel languages; * still partly hide to the programmer the architec ture of the parallel machine; * yield acceptable performance. ParCeL-1 <ref> [16] </ref> hides to the user the actual parallel architecture and is efficient on a wide variety of applications (e.g. scientific computing, artificial in-telligence, connectionism...). ParCeL-1 is based on an intrinsically parallel computing model which attempts to be a compromise between high-levelness and efficiency.
Reference: [17] <author> A. Yonezawa, J. P. Briot, and E. </author> <title> Shibayama. </title> <booktitle> Object-oriented concurrent programming in ABCL/1. In OOPSLA, </booktitle> <year> 1986. </year>
Reference-contexts: The most recent system in this lineage is the HAL [10] language. The concept of actors has also been developed independently by the team of Yonezawa since the mid-eighties, yielding the successive variants of the ABCL language <ref> [17, 13] </ref>. In parallel to actor languages, extensions of compiled object languages like C++ or Eiffel also introduced concurrent objects [4, 8]. In actor- or object-based models, parallelism of execution is expressed explicitly. The main specificity of these models is that they make programmers write already distributed code.
References-found: 17

