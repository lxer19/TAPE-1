URL: ftp://ftp.cs.monash.edu.au/pub/annn/UMUAI98.ps
Refering-URL: http://www.cs.monash.edu.au/~annn/cv/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fdwa,ingrid,annng@cs.monash.edu.au  
Title: Bayesian Models for Keyhole Plan Recognition in an Adventure Game  
Author: DAVID W. ALBRECHT, INGRID ZUKERMAN and ANN E. NICHOLSON 
Keyword: Key words: Plan recognition, Bayesian Belief Networks, language learning, abstraction, performance evaluation.  
Address: Clayton, VICTORIA 3168, AUSTRALIA  
Affiliation: Department of Computer Science, Monash University  
Abstract: We present an approach to keyhole plan recognition which uses a dynamic belief (Bayesian) network to represent features of the domain that are needed to identify users' plans and goals. The application domain is a Multi-User Dungeon adventure game with thousands of possible actions and locations. We propose several network structures which represent the relations in the domain to varying extents, and compare their predictive power for predicting a user's current goal, next action and next location. The conditional probability distributions for each network are learned during a training phase, which dynamically builds these probabilities from observations of user behaviour. This approach allows the use of incomplete, sparse and noisy data during both training and testing. We then apply simple abstraction and learning techniques in order to speed up the performance of the most promising dynamic belief networks without a significant change in the accuracy of goal predictions. Our experimental results in the application domain show a high degree of predictive accuracy. This indicates that dynamic belief networks in general show promise for predicting a variety of behaviours in domains which have similar features to those of our domain, while reduced models, obtained by means of learning and abstraction, show promise for efficient goal prediction in such domains. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. and Perrault, C. </author> <year> (1980). </year> <title> Analyzing intention in utterances. </title> <journal> Artificial Intelligence, </journal> <volume> 15:143 178. </volume>
Reference: <author> Bauer, M. </author> <year> (1996). </year> <title> Acquisition of user preferences for plan recognition. </title> <booktitle> In UM96 Proceedings of the Fifth International Conference on User Modeling, </booktitle> <pages> pages 105112, </pages> <address> Kona, Hawaii. </address>
Reference-contexts: They perform simple probabilistic calculations to match a user's actions in a particular time window to those in the domain plans. The system described in <ref> (Bauer, 1996) </ref> uses a plan hierarchy to represent the actions in the domain, and it applies decision trees (Quinlan, 1983) in combination with the Dempster-Shafer theory of evidential reasoning to assess hypotheses regarding a user's plans in the context of a user's actions.
Reference: <author> Box, G. E. and Tiao, G. C. </author> <year> (1973). </year> <title> Bayesian Inference in Statistical Analysis. </title> <publisher> Addison-Wesley Publishing Company, Philippines. </publisher>
Reference-contexts: USING DIFFERENT FLATTENING CONSTANTS The flattening constant is a small number which is added to frequencies to account for possible events which do not occur in training. This constant is the result of assuming a Dirichlet prior distribution or Jeffrey's non-informative prior distribution <ref> (Box and Tiao, 1973) </ref> when calculating the posterior distribution for the probabilities of events. As indicated in Section 4.3, due to computational efficiency considerations, in our implementation this constant is not added to zero frequencies corresponding to events which involve domain variables seen in training.
Reference: <author> Buntine, W. </author> <year> (1996). </year> <title> A guide to the literature on learning probabilistic networks from data. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, 8(2):195210. </journal>
Reference: <author> Ca namero, D., Delannoy, J., and Kodratoff, Y. </author> <year> (1992). </year> <title> Building explanations in a plan recognition system for decision support. In ECAI92 Workshop on Improving the Use of Knowledge-Based Systems with Explanations, </title> <type> pages 3545, </type> <institution> Vienna, Austria. </institution>
Reference-contexts: This has allowed a shift in domain size, where later systems deal with hundreds of actions in realistic domains. The systems described in <ref> (Ca namero et al., 1992) </ref> and (Wrn and Stenborg, 1995) rely on domain knowledge for keyhole plan recognition. Ca namero et al. use an abstraction/specialization plan hierarchy to perform plan recognition from noisy input representing sequences of observations of an evolving situation in traffic monitoring.
Reference: <author> Carberry, S. </author> <year> (1990). </year> <title> Incorporating default inferences into plan recognition. </title> <booktitle> In AAAI90 Proceedings of the Eight National Conference on Artificial Intelligence, </booktitle> <pages> pages 471478, </pages> <address> Boston, Massachusetts. </address>
Reference-contexts: In particular, the Dempster-Shafer theory takes into account the reliability of the data obtained so far in order to moderate the probability mass assigned to the hypotheses postulated by means of the decision trees. The Dempster-Shafer theory is also applied in <ref> (Carberry, 1990) </ref>, where a threshold plausibility and different levels of belief are used to distinguish among competing hypotheses. The plan recognition mechanism described in (Lesh and Etzioni, 1995) works on a graph which represents the relations between the actions and possible goals of the domain.
Reference: <author> Charniak, E. </author> <year> (1993). </year> <title> Statistical Language Learning. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference: <author> Charniak, E. </author> <year> (1997). </year> <type> Personal communication. </type>
Reference: <author> Charniak, E. and Goldman, R. P. </author> <year> (1993). </year> <title> A Bayesian model of plan recognition. </title> <journal> Artificial Intelligence, 64(1):5056. </journal>
Reference: <author> Cheeseman, P., Self, M., Kelly, J., Taylor, W., Freeman, D., and Stutz, J. </author> <year> (1988). </year> <title> Bayesian classification. </title> <booktitle> In AAAI-88 Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 607611, </pages> <address> St. Paul, Minnesota. </address>
Reference: <author> Conati, C., Gertner, A. S., VanLehn, K., and Druzdzel, M. </author> <year> (1997). </year> <title> On-line student modeling for coached problem solving using Bayesian Networks. </title> <booktitle> In UM97 Proceedings of the Sixth International Conference on User Modeling, </booktitle> <pages> pages 231242, </pages> <address> Sardinia, Italy. </address>
Reference: <author> Dagum, P., Galper, A., and Horvitz, E. </author> <year> (1992). </year> <title> Dynamic network models for forecasting. </title> <booktitle> In UAI92 Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 4148, </pages> <address> Stanford, California. </address>
Reference: <author> Dean, T. and Wellman, M. P. </author> <year> (1991). </year> <title> Planning and control. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California. </address>
Reference: <author> Forbes, J., Huang, T., Kanazawa, K., and Russell, S. </author> <year> (1995). </year> <title> The BATmobile: Towards a Bayesian automated taxi. </title> <booktitle> In IJCAI95 Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 18781885, </pages> <address> Montreal, Canada. </address>
Reference-contexts: The mechanism described in this paper resembles most closely the system described in <ref> (Forbes et al., 1995) </ref>, but there are several important differences: (1) we infer a user's longer term goals, i.e., quests, in addition to the locations and actions inferred by Forbes et al.; (2) our data was collected prior to the undertaking of this project, hence we have had no choice in
Reference: <author> Good, I. J. </author> <year> (1965). </year> <title> The Estimation of Probabilities: An Essay on Modern Bayesian Methods. </title> <journal> Research Monograph No. </journal> <volume> 30. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: This adjustment consists of adding a small number that corresponds to Good's flattening report.tex; 16/12/1997; 19:04; no v.; p.9 10 ALBRECHT ET AL. constant <ref> (Good, 1965) </ref> or Heckerman's fractional updating (Heckerman, 1995) to the non-zero frequencies. <p> As indicated in Section 4.3, due to computational efficiency considerations, in our implementation this constant is not added to zero frequencies corresponding to events which involve domain variables seen in training. The three main flattening constants used in the literature <ref> (Good, 1965) </ref> are 1, 0:5, and 1=k, where k is the number of possible values.
Reference: <author> Heckerman, D. </author> <year> (1995). </year> <title> A tutorial on learning Bayesian networks. </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research. </institution>
Reference-contexts: This adjustment consists of adding a small number that corresponds to Good's flattening report.tex; 16/12/1997; 19:04; no v.; p.9 10 ALBRECHT ET AL. constant (Good, 1965) or Heckerman's fractional updating <ref> (Heckerman, 1995) </ref> to the non-zero frequencies.
Reference: <author> Huber, M. J., Durfee, E. H., and Wellman, M. P. </author> <year> (1994). </year> <title> The automated mapping of plans for plan recognition. </title> <booktitle> In UAI94 Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 344350, </pages> <address> Seattle, Washington. </address> <note> report.tex; 16/12/1997; 19:04; no v.; p.35 36 ALBRECHT ET AL. </note>
Reference-contexts: They automatically generate a BN from a sequence of observations by applying rules which use plan knowledge to instantiate the network. The incorporation of prior probabilities into this network supports the selection of plausible explanations of observed actions. Similarly, Conati et al. (1997) apply the mechanism described in <ref> (Huber et al., 1994) </ref> to automatically construct a BN from the output of a rule-based physics problem solver that generates all the possible solutions to a given physics problem. This BN is then used to identify a student's problem-solving strategy and predict his or her next step. <p> Like Conati, they also apply the mechanism described in <ref> (Huber et al., 1994) </ref> to map planning actions to a DBN. Forbes et al. (1995) emphasize issues that pertain to sensor noise or failure, and to uncertainty about the behaviour of other vehicles and about the effects of drivers' actions.
Reference: <author> Jameson, A. </author> <year> (1996). </year> <title> Numerical uncertainty management in user and student modeling: An overview of systems and issues. User Modeling and User-Adapted Interaction, </title> <publisher> 5:193251. </publisher>
Reference-contexts: In particular, BNs have been applied in several areas of User Modeling, such as knowledge assessment, plan recognition and prediction of user responses (for an overview of these applications see <ref> (Jameson, 1996) </ref>). Belief networks a brief overview. BNs are directed acyclic graphs where nodes correspond to random variables. The relationship between any set of state variables can be specified by a joint probability distribution.
Reference: <author> Lesh, N. </author> <year> (1997). </year> <title> Adaptive goal recognition. </title> <booktitle> In IJCAI97 Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 12081214, </pages> <address> Nagoya, Japan. </address>
Reference-contexts: We believe that these measures are more informative regarding the performance of a plan recognizer than a measure such as that used in <ref> (Lesh, 1997) </ref>, which gives the average percentage of quest completion when the following conditions are satisfied: (1) the top-predicted quest is the current quest, and (2) the probability of this prediction reaches some probability threshold. Lesh's measure requires the pre-selection of thresholds, which may vary between different domains.
Reference: <author> Lesh, N. and Etzioni, O. </author> <year> (1995). </year> <title> A sound and fast goal recognizer. </title> <booktitle> In IJCAI95 Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 17041710, </pages> <address> Montreal, Canada. </address>
Reference-contexts: The Dempster-Shafer theory is also applied in (Carberry, 1990), where a threshold plausibility and different levels of belief are used to distinguish among competing hypotheses. The plan recognition mechanism described in <ref> (Lesh and Etzioni, 1995) </ref> works on a graph which represents the relations between the actions and possible goals of the domain. The system iteratively applies pruning rules which remove from the graph goals that are not in any consistent plan.
Reference: <author> Lesh, N. and Etzioni, O. </author> <year> (1996). </year> <title> Scaling up goal recognition. </title> <booktitle> In Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 178189. </pages>
Reference-contexts: In later work, Lesh and Etzioni use plan and goal biases assumptions about what types of plans and goals people have to automatically construct a plan library from primitive actions and goal predicates <ref> (Lesh and Etzioni, 1996) </ref>. <p> However, the Unix domain highlights the importance of extending our approach to conjunctive goals, since a typical Unix goal may be to print on a double sided printer that is also a color printer and that is also on the fourth floor (from <ref> (Lesh and Etzioni, 1996) </ref>). It is difficult to determine similar goals in the MUD, which limits the applicable models to those containing a single quest node.
Reference: <author> Litman, D. and Allen, J. F. </author> <year> (1987). </year> <title> A plan recognition model for subdialogues in conversation. </title> <journal> Cognitive Science, 11:163200. </journal>
Reference: <author> Nicholson, A. E. and Brady, J. M. </author> <year> (1994). </year> <title> Dynamic belief networks for discrete monitoring. </title> <journal> IEEE Systems, Man and Cybernetics, 24(11):15931610. </journal>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California. </address>
Reference-contexts: In addition, at present, a user's goals in our system (MUD quests) correspond to single predicates, while Lesh and Etzioni's system admits conjunctive goals. The extension of our mechanism to such goals is the subject of future research (Section 8). Belief (or Bayesian) networks (BNs) <ref> (Pearl, 1988) </ref> have become a popular representation for reasoning under uncertainty as they integrate a graphical representation of causal relationships with a sound Bayesian foundation. <p> The observation of specific values for nodes is called evidence. Beliefs are updated by re-computing the posterior probability distributions given the evidence. Belief propagation for singly-connected networks can be done efficiently using a message passing algorithm <ref> (Pearl, 1988) </ref>. When networks are multiply-connected (i.e., when there is a loop in the underlying undirected graph), simple belief propagation is not possible; informally, this is because we can no longer be sure that evidence has not already been counted at a node having arrived via another route. <p> In such cases, inference algorithms based on clustering, conditioning or stochastic simulation may be used <ref> (Pearl, 1988) </ref>. Belief networks have been used both in static and dynamic applications. In static applications the nodes and links in a BN do not change over time. Hence, in principle, hand-crafting BNs for these applications is possible. <p> nodes for the domain at ? Since we are dealing with nodes with very large state spaces, we use hash tables of hash tables to store the CPD entries, and do not explicitly store zero probabilities. ?? One of the reviewers suggested the investigation of canonical models of multi-causal interactions <ref> (Pearl, 1988) </ref> to address this problem. This investigation is left for future research. report.tex; 16/12/1997; 19:04; no v.; p.10 BAYESIAN MODELS FOR KEYHOLE PLAN RECOGNITION 11 1. Receive initial data: PreviousQuest, PreviousAction, PreviousLocation. 2. Add data as evidence for nodes Q, A 0 and L 0 . 3. <p> This would seem to indicate that we must use an inference algorithm based on clustering, conditioning or stochastic simulation <ref> (Pearl, 1988) </ref>. However, further analysis of these structures, together with the location of the evidence nodes, identifies d-separations (Pearl, 1988), indicating that certain nodes are conditionally independent (see Appendix A for details of this analysis). <p> This would seem to indicate that we must use an inference algorithm based on clustering, conditioning or stochastic simulation <ref> (Pearl, 1988) </ref>. However, further analysis of these structures, together with the location of the evidence nodes, identifies d-separations (Pearl, 1988), indicating that certain nodes are conditionally independent (see Appendix A for details of this analysis).
Reference: <author> Pynadath, D. and Wellman, M. </author> <year> (1995). </year> <title> Accounting for context in plan recognition with application to traffic monitoring. </title> <booktitle> In UAI95 Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 472481, </pages> <address> Montreal, Canada. </address>
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Michalski, R. S. and Carbonell, J., editors, </editor> <booktitle> Machine Learning: an Artificial Intelligence Approach. </booktitle> <publisher> Tioga Publishing Company, </publisher> <address> Palo Alto, California. </address>
Reference-contexts: They perform simple probabilistic calculations to match a user's actions in a particular time window to those in the domain plans. The system described in (Bauer, 1996) uses a plan hierarchy to represent the actions in the domain, and it applies decision trees <ref> (Quinlan, 1983) </ref> in combination with the Dempster-Shafer theory of evidential reasoning to assess hypotheses regarding a user's plans in the context of a user's actions.
Reference: <author> Raskutti, B. </author> <year> (1993). </year> <title> Handling Uncertainty during Plan Recognition for Response Generation. </title> <type> PhD thesis, </type> <institution> Monash University, Victoria, Australia. </institution>
Reference-contexts: 1. Introduction To date, research in plan recognition has focused on three main areas: (1) inferring plans during cooperative interactions, (2) understanding stories, and (3) recognizing the plans of an agent who is unaware that his or her plans are being inferred <ref> (Raskutti, 1993) </ref>. In the first two areas, the plan recognition process is intended, since a user/writer is attempting to convey his or her plan to the system.
Reference: <author> Raskutti, B. and Zukerman, I. </author> <year> (1991). </year> <title> Generation and selection of likely interpretations during plan recognition. User Modeling and User Adapted Interaction, </title> <publisher> 1(4):323353. </publisher>
Reference: <author> Russell, S., Binder, J., Koller, D., and Kanazawa, K. </author> <year> (1995). </year> <title> Local learning in probabilistic networks with hidden variables. </title> <booktitle> In IJCAI95 Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 11461152, </pages> <address> Montreal, Canada. </address>
Reference-contexts: Typically, for these Dynamic Belief Networks (DBNs), the connections over time are Markovian, and a temporal `window' is imposed to reduce the state space. Such DBNs provide a more compact representation than the equivalent Hidden Markov Model <ref> (Russell et al., 1995) </ref>. Two applications of DBNs are described in (Forbes et al., 1995; report.tex; 16/12/1997; 19:04; no v.; p.4 BAYESIAN MODELS FOR KEYHOLE PLAN RECOGNITION 5 Pynadath and Wellman, 1995). Pynadath and Wellman (1995) use a DBN for plan recognition in traffic monitoring.
Reference: <author> Wrn, A. and Stenborg, O. </author> <year> (1995). </year> <title> Recognizing the plans of a replanning user. </title> <booktitle> In Proceedings of the IJCAI-95 Workshop on The Next Generation of Plan Recognition Systems: Challenges for and Insight from Related Areas of AI, </booktitle> <pages> pages 113118, </pages> <address> Montreal, Canada. </address>
Reference-contexts: This has allowed a shift in domain size, where later systems deal with hundreds of actions in realistic domains. The systems described in (Ca namero et al., 1992) and <ref> (Wrn and Stenborg, 1995) </ref> rely on domain knowledge for keyhole plan recognition. Ca namero et al. use an abstraction/specialization plan hierarchy to perform plan recognition from noisy input representing sequences of observations of an evolving situation in traffic monitoring.
Reference: <author> Wallace, C. </author> <year> (1990). </year> <title> Classification by minimum-message-length inference. </title> <editor> In Goos, G. and Hartmanis, J., editors, </editor> <booktitle> ICCI '90 Advances in Computing and Information, </booktitle> <pages> pages 7281. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Wallace, C. and Boulton, D. </author> <year> (1968). </year> <title> An information measure for classification. </title> <journal> The Computer Journal, 11:185194. </journal>
Reference: <author> Wallace, C. S. and Dowe, D. L. </author> <year> (1994). </year> <title> Intrinsic classification by MML the Snob program. </title> <booktitle> In AI94 Proceedings of the Seventh Australian Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 3744, </pages> <address> Armidale, Australia. </address>
References-found: 33

