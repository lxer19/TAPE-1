URL: ftp://wilma.cs.brown.edu/u/mfc/vldb98.ps.Z
Refering-URL: http://www.cs.brown.edu/software/cokokola/
Root-URL: http://www.cs.brown.edu
Email: mfc@cs.brown.edu  sbz@cs.brown.edu  
Title: Inferring Function Semantics to Optimize Queries  
Author: Mitch Cherniack Stan Zdonik 
Address: Providence, RI 02912  Providence, RI 02912  
Affiliation: Brown University  Brown University  
Abstract: The goal of the COKO-KOLA project [10, 9] is to express rules of rule-based optimizers in a manner permitting verification with a theorem prover. In [10], we considered query transformations that were too general to be expressed with rewrite rules. In this paper, we consider the complementary issue of expressing query transformations that are too specifc for rewrite rules. Such transformations require rewrite rules to be supplemented with semantic conditions to guard rule firing. This work considers the expression of such transformations using conditional rewrite rules, and the expression of inference rules to guide the optimizer in deciding if semantic conditions hold. This work differs from existing work in semantic query optimization in that semantic transformations in our framework are verifiable with a theorem prover. Further, our use of inference rules to guide semantic reasoning makes our optimizer extensible in a manner that is complementary to the ex tensibility benefits of existing rule-based technology.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Aberer and G. Fischer. </author> <title> Semantic query optimization for methods in object-oriented database systems. </title> <editor> In P. S. Yu and A. L. P. Chen, editors, </editor> <booktitle> Proceedings of the 11th International Conference on Data Engineering, </booktitle> <pages> pages 7079, </pages> <address> Taipei, Taiwan, </address> <year> 1995. </year>
Reference-contexts: These rules are always valid given that they are specific to particular operators. Therefore they perform no inference nor conditional rewriting (Category (1)). More recent work in the context of object models has looked at semantic optimization in the presence of methods. <ref> [1] </ref> considers semantic optimization over methods based on equivalences derived from method semantics. This semantics comes from the schema and is then translated by hand into rules that can be applied to expressions written in their algebra.
Reference: [2] <author> C. Beeri and Y. Kornatzky. </author> <title> Algebraic optimization of object-oriented query languages. </title> <editor> In S. Abiteboul and P. C. Kanel-lakis, editors, </editor> <booktitle> Proceedings of the Third International Conference on Database Theory, number 470 in Lecture Notes in Computer Science, </booktitle> <pages> pages 7288, </pages> <address> Paris, France, </address> <month> December </month> <year> 1990. </year> <title> EATCS, </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Therefore, this work comes close to falling in Category (3) because it includes both conditional rules and inference, but falls short because inference is not over function conditions. Beeri and Kornatsky <ref> [2] </ref> describe a combinator-based algebra for representing queries and they even present several rewrite rules that are conditioned on function conditions. For example, they have several rules that only apply to expressions that contain an idempotent function.
Reference: [3] <author> M. J. Carey, D. J. DeWitt, G. Graefe, D. M. Haight, J. E. Richard-son, D. T. Schuh, E. J. Shekita, and S. L. Vandenberg. </author> <title> The EXODUS extensible DBMS project: An overview. </title> <editor> In S. B. Zdonik and D. Maier, editors, </editor> <booktitle> Readings in Object-Oriented Database Systems, </booktitle> <pages> pages 474499. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, Cal-ifornia, </address> <year> 1990. </year>
Reference-contexts: The added complexity of objects and hence object queries makes the task of building object (i.e., object-oriented and object-relational) database optimizers that much more difficult. It is now accepted practice to use software engineering techniques when building optimizers. For example, many optimizers are now rule-based <ref> [3, 11] </ref>, and therefore express the query-to-query or query-to-plan transformations that take place during optimization incrementally with rules. This approach makes optimizers extensible as the behavior of an optimizer can be altered by modifying its rule set. <p> This work contrasts with existing rule-based systems (e.g., [20], <ref> [3, 13, 12] </ref>) that use code to express semantic conditions (thereby compromising verifiability) and that embed this code within rewrite rules (thereby compromising extensibility). Our approach could be used to express, verify and extend semantic transformations from many sources.
Reference: [4] <author> R. Cattell, </author> <title> editor. The Object Database Standard: ODMG-93. </title> <address> Morgan-Kaufman, </address> <year> 1993. </year>
Reference-contexts: However, each type has its own secondary keys that include senator, capital and cities (for states), mayor (for cities), reps (for senators and mayors), and leader and mayors (for parties). Figures 1a and 1b show object (specifically, OQL <ref> [4] </ref>) queries over this political database. The Capitals Query (Figure 1a) queries a set of senators (S) applying the path expression, x.reps.capital, to each. The result of this query is the collection of capital cities of states represented by the senators in S (with duplicate cities removed).
Reference: [5] <author> U. Chakravathy, J. Grant, and J. Minker. </author> <title> Semantic query optimization: Additional constraints and control strategies. </title> <booktitle> In Proceedings of Expert Database Systems Conference, </booktitle> <pages> pages 259269, </pages> <address> Charleston, SC, </address> <month> April </month> <year> 1986. </year>
Reference-contexts: Our approach could be used to express, verify and extend semantic transformations from many sources. This includes semantic transformations used in relational systems (aside from those mentioned here, these primarily involve the use of integrity constraints as discussed in [16], [18] and <ref> [5] </ref>). But our approach also permits expression of semantic transformations that depend on the semantics of queries (i.e., functions) and not just data.
Reference: [6] <author> S. Chaudhuri and K. Shim. </author> <title> Query optimization in the presence of foreign functions. </title> <booktitle> In Proceedings of the 19th VLDB Conference, </booktitle> <pages> pages 529542, </pages> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: As we move from the first to the third category, we get more general making the approach more scalable. Chaudhuri and Shim's work <ref> [6] </ref> involves optimizations of SQL queries that contain foreign functions. They incorporate rewrite rules over foreign functions to express equivalent expressions. Each equivalence must be captured in a separate rule. These rules are always valid given that they are specific to particular operators. <p> This semantics comes from the schema and is then translated by hand into rules that can be applied to expressions written in their algebra. As with <ref> [6] </ref>, these rewrites are unconditional and there is no inference (Category (1)). Grant et al [14] employ a Datalog-based scheme for object-oriented databases that infers new integrity constraints from old explicitly declared constraints plus schema-related information about functions (methods).
Reference: [7] <author> M. Cherniack. </author> <title> Translating queries into combinators. </title> <type> Technical Report CS-96-40, </type> <institution> Brown University Department of Computer Science, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: KOLA is designed to be easy to manipulate by the optimizer as opposed to being easy to read. Users write queries in a language such as OQL, and those queries are translated into KOLA. We have a working OQL to KOLA translator described in <ref> [7] </ref>. 2 In KOLA, functions and predicates are separated and invoked differently (! for functions; ? for predicates).
Reference: [8] <author> M. Cherniack. </author> <title> Building query optimizers with combinators. </title> <type> Technical report, </type> <month> December </month> <year> 1997. </year> <title> Dissertation proposal. </title>
Reference-contexts: There is no conceptual difference between the formers of Table 1 and those of Table 2; all create complex functions and predicates from simpler ones. That queries are first-class functions and predicates facilitates reasoning about their meaning, as was demonstrated in <ref> [8] </ref> by formally specifying KOLA with the Larch algebraic specification language LSL [15] and by verifying well over 300 KOLA rewrite rules with the Larch theorem prover (LP). 2.2 COKO COKO [9] is our language for expressing general transformations.
Reference: [9] <author> M. Cherniack and S. Zdonik. </author> <title> Changing the rules: Transformations for rule-based optimizers. </title> <booktitle> In Proc. ACM SIGMOD Int'l Conference on Management of Data, </booktitle> <address> Seattle, WA, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: As we argued in [10], code-based rules are difficult to verify. We seek an alternative means of expressing both general and semantic transformations that enables their verification with a theorem prover. In <ref> [9] </ref>, we proposed a new language (COKO) for expressing general transformations in terms of sets of declarative rewrite rules and an algorithm to control their firing (a firing algorithm). This paper proposes a complementary technique for expressing semantic transformations. <p> In the interest of space, we review just what is required for this paper. More in-depth treatments can be found in [10] (for KOLA) and <ref> [9] </ref> (for COKO). 2.1 KOLA KOLA is a combinator-based query representation. As such, queries are built out of other functions using special combinators or formers. The expression of a query (or any other function or predicate) 2 contains no variables. <p> That queries are first-class functions and predicates facilitates reasoning about their meaning, as was demonstrated in [8] by formally specifying KOLA with the Larch algebraic specification language LSL [15] and by verifying well over 300 KOLA rewrite rules with the Larch theorem prover (LP). 2.2 COKO COKO <ref> [9] </ref> is our language for expressing general transformations. A COKO transformation consists of a set of KOLA rewrite rules and a firing algorithm to control their firing. <p> The techniques proposed here target the expression of query transformations that are too specific to be captured with rewrite rules. (Expression of transformations that are too general to be expressed with rewrite rules is addressed in <ref> [9] </ref>.) This work builds upon the foundation laid with the combinator-based algebra, KOLA. We extend KOLA's rewrite rules by introducing conditional rewrite rules: rewrite rules whose firing depends on the satisfaction of semantic conditions of matched expressions.
Reference: [10] <author> M. Cherniack and S. B. Zdonik. </author> <title> Rule languages and internal algebras for rule-based optimizers. </title> <booktitle> In Proc. ACM SIGMOD Int'l Conference on Management of Data, </booktitle> <address> Montreal, Quebec, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: A rewrite rule consists of a pair of patterns: a lhs (left-hand side) pattern that matches expressions that should be transformed, and a rhs (right-hand side) pattern that specifies the transformation of the expression. Rewrite rules are straightforward to verify with theorem provers as we showed in <ref> [10] </ref>. But rewrite rules lack the expressive power required to express many real query transformations. 1.1 General Transformations Some query transformations are too general to be expressed with rewrite rules. Consider transformations that rewrite query expressions into syntactically characterizable forms (normalizations). Typically, normalizations affect large classes of syntactically varied expressions. <p> For example, the SQL transformation above that eliminates duplicate removal would be expressed in Starburst [20] with C code that examined annotations of the underlying query representation (QGM) to decide if a matched attribute was a key and if a matched collection was a set. As we argued in <ref> [10] </ref>, code-based rules are difficult to verify. We seek an alternative means of expressing both general and semantic transformations that enables their verification with a theorem prover. <p> In [9], we proposed a new language (COKO) for expressing general transformations in terms of sets of declarative rewrite rules and an algorithm to control their firing (a firing algorithm). This paper proposes a complementary technique for expressing semantic transformations. As with COKO, this work builds upon our KOLA <ref> [10] </ref> foundation which used a combinator-based (i.e., variable-free) query algebra to express rewrite rules without code. To express semantic transformations, we propose the addition of two alternative kinds of rules for rule-based optimizers: * Conditional rewrite rules, and * Inference rules. <p> We compare our work with related work in Section 5 and conclude in Section 6. 2 Background This section reviews the COKO-KOLA approach to expressing query transformations. In the interest of space, we review just what is required for this paper. More in-depth treatments can be found in <ref> [10] </ref> (for KOLA) and [9] (for COKO). 2.1 KOLA KOLA is a combinator-based query representation. As such, queries are built out of other functions using special combinators or formers. The expression of a query (or any other function or predicate) 2 contains no variables. <p> Again, rules such as this one can be added to simply extend a relational optimizer to work robustly in an object setting. 3.4.2 The Advantage of KOLA In <ref> [10] </ref>, we showed that the KOLA's combinator style makes it easier to formulate declarative (unconditional) rewrite rules to express query transformations. Query representations that include variables make it difficult to express rewrite rules without code supplements because representations can include subexpressions with free variables.
Reference: [11] <author> J. C. Freytag. </author> <title> A rule-based view of query optimization. </title> <editor> In U. Dayal and I. Traiger, editors, </editor> <booktitle> Proceedings of the SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 173180, </pages> <address> San Francisco, California, </address> <month> May </month> <year> 1987. </year> <booktitle> ACM Special Interest Group on Management of Data, </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: The added complexity of objects and hence object queries makes the task of building object (i.e., object-oriented and object-relational) database optimizers that much more difficult. It is now accepted practice to use software engineering techniques when building optimizers. For example, many optimizers are now rule-based <ref> [3, 11] </ref>, and therefore express the query-to-query or query-to-plan transformations that take place during optimization incrementally with rules. This approach makes optimizers extensible as the behavior of an optimizer can be altered by modifying its rule set.
Reference: [12] <author> G. Graefe. </author> <title> The Cascades framework for query optimization. </title> <journal> Data Engineering Bulletin, </journal> <volume> 18(3):1929, </volume> <month> September </month> <year> 1995. </year>
Reference-contexts: Existing rule-based systems address the expressivity issues above by replacing or supplementing rewrite rules with code. General transformations are expressed as rules supplemented with code in the rule's rhs to manipulate matched expressions in ways that cannot be expressed with patterns. For example, CNF would be expressed in Cascades <ref> [12] </ref> as a function rule whose firing invokes user-defined code. Semantic transformations are expressed with rules supplemented with code in the rule's lhs to test semantic conditions of expressions that successfully matched the head pattern. <p> This work contrasts with existing rule-based systems (e.g., [20], <ref> [3, 13, 12] </ref>) that use code to express semantic conditions (thereby compromising verifiability) and that embed this code within rewrite rules (thereby compromising extensibility). Our approach could be used to express, verify and extend semantic transformations from many sources. <p> With respect to verification, the declarative flavor of both forms of rules makes them amenable to verification with a theorem prover. This is in stark contrast to the code-based rules of existing rule-based systems such as Starburst [20] and Cascades <ref> [12] </ref> which express conditions and condition-checking with code. With respect to extensibility, the separation of a condition's inference rules from the rewrite rules that depend on them achieves a different form of extensibility than was provided by rewrite rules alone.
Reference: [13] <author> G. Graefe and W. J. McKenna. </author> <title> The Volcano optimizer generator: Extensibility and efficient search. </title> <booktitle> In Proceedings of the Ninth International Conference on Data Engineering, pages 209218, </booktitle> <address> Vienna, Austria, </address> <month> April </month> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: This work contrasts with existing rule-based systems (e.g., [20], <ref> [3, 13, 12] </ref>) that use code to express semantic conditions (thereby compromising verifiability) and that embed this code within rewrite rules (thereby compromising extensibility). Our approach could be used to express, verify and extend semantic transformations from many sources.
Reference: [14] <author> J. Grant, J. Gryz, J. Minker, and L. Raschid. </author> <title> Semantic query optimization for object databases. </title> <booktitle> In Proceedings of the 13th ICDE Conference, </booktitle> <pages> pages 444454, </pages> <address> Birmingham, UK, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: This semantics comes from the schema and is then translated by hand into rules that can be applied to expressions written in their algebra. As with [6], these rewrites are unconditional and there is no inference (Category (1)). Grant et al <ref> [14] </ref> employ a Datalog-based scheme for object-oriented databases that infers new integrity constraints from old explicitly declared constraints plus schema-related information about functions (methods). This work employs inference, but only of new integrity constraints (i.e., conditions that hold of data) and not conditions that hold of functions.
Reference: [15] <author> J. Guttag, J. Hornung, S. Garland, K. Jones, A. Modet, and J. Wing. </author> <title> Larch: Languages and Tools for Formal Specifications. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: That queries are first-class functions and predicates facilitates reasoning about their meaning, as was demonstrated in [8] by formally specifying KOLA with the Larch algebraic specification language LSL <ref> [15] </ref> and by verifying well over 300 KOLA rewrite rules with the Larch theorem prover (LP). 2.2 COKO COKO [9] is our language for expressing general transformations. A COKO transformation consists of a set of KOLA rewrite rules and a firing algorithm to control their firing.
Reference: [16] <author> M. Hammer and S. B. Zdonik. </author> <title> Knowledge-based query processing. </title> <booktitle> In Proceedings of the 6th International Conference on Very Large Databases, </booktitle> <address> Montreal, Canada, </address> <month> October </month> <year> 1980. </year> <month> Morgan-Kaufman. </month>
Reference-contexts: Our approach could be used to express, verify and extend semantic transformations from many sources. This includes semantic transformations used in relational systems (aside from those mentioned here, these primarily involve the use of integrity constraints as discussed in <ref> [16] </ref>, [18] and [5]). But our approach also permits expression of semantic transformations that depend on the semantics of queries (i.e., functions) and not just data.
Reference: [17] <author> W. Kim. </author> <title> On optimizing an SQL-like nested query. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 7(3):443469, </volume> <month> September </month> <year> 1982. </year>
Reference-contexts: 1 Introduction Query optimizers are hard to build. In the past, relational optimizers have proved to be brittle and error-prone <ref> [17] </ref>. The added complexity of objects and hence object queries makes the task of building object (i.e., object-oriented and object-relational) database optimizers that much more difficult. It is now accepted practice to use software engineering techniques when building optimizers.
Reference: [18] <author> J. King. </author> <title> A system for semantic query optimization in relational databases. </title> <booktitle> In Proceedings of the 7th International Conference on Very Large Databases, </booktitle> <pages> pages 510517, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: Our approach could be used to express, verify and extend semantic transformations from many sources. This includes semantic transformations used in relational systems (aside from those mentioned here, these primarily involve the use of integrity constraints as discussed in [16], <ref> [18] </ref> and [5]). But our approach also permits expression of semantic transformations that depend on the semantics of queries (i.e., functions) and not just data.
Reference: [19] <author> A. Y. Levy, I. S. Mumick, and Y. Sagiv. </author> <title> Query optimization by predicate move-around. </title> <booktitle> In Proceedings of the 20th VLDB Conference, </booktitle> <pages> pages 96107, </pages> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: As with the previous example, the transformations discussed here are not new many are implemented in commercial database systems and some were proposed in the context of relations by Levy et. al. in <ref> [19] </ref>. What is new is their expression with declarative rules that simplifies their verification and extension. A predicate p is stronger than a predicate q (is stronger (p, q)) if p always implies q. <p> Example 2: Whereas the previous example used predicate strength to avoid invoking predicates unnecessarily, the following examples add predicates to queries to make them more efficient to evaluate. These examples evoke the spirit of the predicate move-around transformations of <ref> [19] </ref>. The OQL query below joins senators from collections S and S 0 who have served the same number of terms such that the senator from S has served more than 5 terms. <p> Those that remove quantification from complex predicates (Example 1 of Section 3.3.2) are standard techniques that one can find in many textbooks. Those that introduce new predicates (Examples 2 and 3 of Section 3.3.2) are similar to the predicate move-around techniques for transforming relational queries proposed in <ref> [19] </ref>. What is unique in our work is the use of declarative conditional rewrite rules and inference rules to express these complex transformations. <p> Verification of inference rules establishes that semantic conditions are inferred only when appropriate (soundness). The other contribution of this approach concerns extensibility. [20] and <ref> [19] </ref> present the transformations discussed in Sections 3.1 and 3.3 in the context of relational databases. <p> By similar reasoning, not all of the predicate strength inference rules of Figure 5 are required to express the transformations of <ref> [19] </ref> when confined to relations (e.g., rule (4) of Figure 5 is unnecessary because of its use of function composition).
Reference: [20] <author> H. Pirahesh, J. M. Hellerstein, and W. Hasan. </author> <title> Extensible/rule based query rewrite optimization in Starburst. </title> <booktitle> In Proc. ACM SIGMOD Int'l Conference on Management of Data, </booktitle> <pages> pages 3948, </pages> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Consider a relational transformation to eliminate unnecessary duplicate removal from the processing a query that projects on a key attribute. This transformation (used in many relational systems such as Starburst <ref> [20] </ref>) is captured by the rewrite rule below, such that the patterns shown are SQL patterns, and pattern variables x, f , A and p match arbitrary SQL variables, attribute names, relation names and boolean expressions re 1 A query optimizer is correct if it preserves the semantics of queries that <p> Semantic transformations are expressed with rules supplemented with code in the rule's lhs to test semantic conditions of expressions that successfully matched the head pattern. For example, the SQL transformation above that eliminates duplicate removal would be expressed in Starburst <ref> [20] </ref> with C code that examined annotations of the underlying query representation (QGM) to decide if a matched attribute was a key and if a matched collection was a set. As we argued in [10], code-based rules are difficult to verify. <p> The transformation of Section 3.1 that recognizes when duplicate elimination is unnecessary is used in many commercial relational database systems. It is also presented as one of the Starburst transformations in <ref> [20] </ref> performed during the query rewriting phase of query processing. In Starburst, this transformation is used as a normalization step before view merging. Subqueries that perform duplicate elimination make view merging impossible because duplicate semantics are lost as a result of the merge. <p> Verification of inference rules establishes that semantic conditions are inferred only when appropriate (soundness). The other contribution of this approach concerns extensibility. <ref> [20] </ref> and [19] present the transformations discussed in Sections 3.1 and 3.3 in the context of relational databases. <p> To simulate their results, we do not need all of the inference rules of Figure 4a that infer injectivity, nor do we need all of the inference rules of Figure 5 that infer predicate strength. For example, to capture the duplicate elimination transformation presented in <ref> [20] </ref> for relational queries, we only need inference rules that establish an attribute to be injective if it is a key (Figure 4a, rule (2)) and if it is a pair (equivalently, a relational tuple 3 ) containing a key (Figure 4a, rule (4)). <p> This work contrasts with existing rule-based systems (e.g., <ref> [20] </ref>, [3, 13, 12]) that use code to express semantic conditions (thereby compromising verifiability) and that embed this code within rewrite rules (thereby compromising extensibility). Our approach could be used to express, verify and extend semantic transformations from many sources. <p> This work contributes to the extensibility and verifiability of rule-based optimizers. With respect to verification, the declarative flavor of both forms of rules makes them amenable to verification with a theorem prover. This is in stark contrast to the code-based rules of existing rule-based systems such as Starburst <ref> [20] </ref> and Cascades [12] which express conditions and condition-checking with code. With respect to extensibility, the separation of a condition's inference rules from the rewrite rules that depend on them achieves a different form of extensibility than was provided by rewrite rules alone.
Reference: [21] <institution> Swedish Institute Of Computer Science. </institution> <note> SICStus prolog user's manual. Release 3, # 5, 1996. Page 12 </note>
Reference-contexts: Section 4.2 presents the inference engine component of our optimizer. Section 4.3 describes the operation of our rule firer in the presence of conditional functions. 4.2 The Inference Engine Our inference engine is the Sicstus Prolog interpreter <ref> [21] </ref>. Using Prolog as an inference engine makes our implementation a prototype rather than one of commercial quality. We envision replacing the Prolog interpreter with specialized unification routines that operate directly on KOLA queries as future work.
References-found: 21

