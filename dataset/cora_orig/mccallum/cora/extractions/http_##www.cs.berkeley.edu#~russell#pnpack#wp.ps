URL: http://www.cs.berkeley.edu/~russell/pnpack/wp.ps
Refering-URL: http://www.cs.berkeley.edu/~russell/pnpack/pnpack.html
Root-URL: http://www.cs.berkeley.edu
Title: PNPACK: Algorithm and Software Development for Computing with Probabilities Draft White Summary algorithms for computing
Date: December 31, 1996  
Pubnum: Paper  
Abstract: We propose a multi-year, multi-investigator project that will significantly advance the state of the art in computing with probabilistic information, building on dramatic technical advances in the last decade. The project has three basic components: 
Abstract-found: 1
Intro-found: 1
Reference: [ Andersen et al., 1989 ] <author> S. K. Andersen, K. G. Olesen, F. V. Jensen, and F. Jensen. </author> <title> HUGIN|a shell for building Bayesian belief universes for expert systems. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <volume> volume 2, </volume> <pages> pages 1080-1085, </pages> <address> Detroit, Michigan, </address> <month> August </month> <year> 1989. </year> <note> Morgan Kaufmann. 6 </note>
Reference-contexts: Because the mathematics and algorithmic details are quite complex, it is often not feasible for AI researchers to develop their own code. On the other hand, commercial software such as HUGIN from Aalborg University in Denmark <ref> [ Andersen et al., 1989 ] </ref> is both expensive ($6500 academic license) and inflexible because source code is not available. The most comprehensive available public domain software is the IDEAL system, which is in use at about 150 sites [ ? ] .
Reference: [ Dean and Kanazawa, 1988 ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Probabilistic temporal reasoning. </title> <booktitle> In Pro--ceedings of the Seventh National Conference on Artificial Intelligence (AAAI-88), </booktitle> <pages> pages 524-528, </pages> <address> St. Paul, Minnesota, </address> <year> 1988. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: These are currently the only feasible techniques for very large networks or for general networks with continuous variables. * Dynamic probabilistic networks (DPNs) for handling domains that change over time <ref> [ Dean and Kanazawa, 1988; Kjaerulff, 1992 ] </ref> . * Learning methods for constructing networks from data and prior knowledge [ Heckerman et al., 1994; Lauritzen, 1995; Russell et al., 1995 ] . 3 2.1.2 Development of new methods (Yrs.1-3) Each of the following research projects will result in the creation
Reference: [ Forbes et al., 1995 ] <author> Jeff Forbes, Tim Huang, Keiji Kanazawa, and Stuart Russell. </author> <title> The BATmobile: Towards a Bayesian automated taxi. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <address> Montreal, Canada, August 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Dynamic probabilistic networks (DPNs) represent and update probability distributions on the state of a partially observable system over time. They can be used for monitoring and controlling arbitrary stochastic processes. We will refine and implement methods for real-time monitoring based on the ER/SOF and temporal invariance algorithms reported in <ref> [ Forbes et al., 1995; Kanazawa et al., 1995 ] </ref> . * Compilation techniques for efficient, stand-alone inference (Yr.1). Knowledge base interpreters, including most expert system shells as well as probabilistic network packages, solve queries as if the evidence pattern and knowledge base were completely new.
Reference: [ Geman and Geman, 1984 ] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), </journal> <volume> 6(6) </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference-contexts: We expect DPNs and related models to become a powerful new weapon in the armory of empirical scientific investigation. * Computer vision (Yrs.3-4). Computer vision and image processing have used probabilistic methods, usually based on Markov random fields, for many years, but only for low-level processing <ref> [ Geman and Geman, 1984 ] </ref> . We propose that low-level and high-level vision can be integrated successfully by adopting probabilistic models for object, scene, and behaviour recognition, as demonstrated for traffic scenes in [ ? ] .
Reference: [ Heckerman et al., 1994 ] <author> D. Heckerman, D. Geiger, and M. Chickering. </author> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <type> Technical Report MSR-TR-94-09, </type> <institution> Microsoft Research, </institution> <address> Redmond, Washington, </address> <year> 1994. </year>
Reference: [ Kanazawa et al., 1995 ] <author> Keiji Kanazawa, Daphne Koller, and Stuart Russell. </author> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <booktitle> In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI-95), </booktitle> <address> Montreal, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Dynamic probabilistic networks (DPNs) represent and update probability distributions on the state of a partially observable system over time. They can be used for monitoring and controlling arbitrary stochastic processes. We will refine and implement methods for real-time monitoring based on the ER/SOF and temporal invariance algorithms reported in <ref> [ Forbes et al., 1995; Kanazawa et al., 1995 ] </ref> . * Compilation techniques for efficient, stand-alone inference (Yr.1). Knowledge base interpreters, including most expert system shells as well as probabilistic network packages, solve queries as if the evidence pattern and knowledge base were completely new. <p> We anticipate providing a "network supercomputer" Probabilistic Computation Facility using Berke ley's NOW system, which will be available as an Internet resource. * New methods for stochastic simulation (Yr.2). We will develop and analyze new algorithms such as "Survival of the Fittest" (SOF) <ref> [ Kanazawa et al., 1995 ] </ref> , which offer faster convergence than existing methods. * Hierarchical probabilistic models (Yr.3). Complex systems such as computers, vehicles, cities, transportation systems, and corporations can often be modelled successfully using hierarchical representations, in which complexity is reduced exponentially through multiple levels of abstraction.
Reference: [ Kjaerulff, 1992 ] <author> U. Kjaerulff. </author> <title> A computational scheme for reasoning in dynamic probabilistic networks. </title> <booktitle> In Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 121-129, </pages> <year> 1992. </year>
Reference-contexts: These are currently the only feasible techniques for very large networks or for general networks with continuous variables. * Dynamic probabilistic networks (DPNs) for handling domains that change over time <ref> [ Dean and Kanazawa, 1988; Kjaerulff, 1992 ] </ref> . * Learning methods for constructing networks from data and prior knowledge [ Heckerman et al., 1994; Lauritzen, 1995; Russell et al., 1995 ] . 3 2.1.2 Development of new methods (Yrs.1-3) Each of the following research projects will result in the creation
Reference: [ Lauritzen and Spiegelhalter, 1988 ] <author> Steffen L. Lauritzen and David J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 50(2) </volume> <pages> 157-224, </pages> <year> 1988. </year>
Reference: [ Lauritzen and Wermuth, 1989 ] <author> S. L. Lauritzen and N. Wermuth. </author> <title> Graphical models for associations between variables, some of which are qualitative and some quantitative. </title> <journal> Annals of Statistics, </journal> <volume> 17 </volume> <pages> 31-57, </pages> <year> 1989. </year>
Reference-contexts: Four principal developments are missing from both commercial and public domain packages: * Hybrid networks containing both discrete and continuous variables <ref> [ Lauritzen and Wermuth, 1989 ] </ref> . Continuous variables are essential for modelling many real-world domains. * Stochastic simulation methods such as likelihood weighting [ Shachter and Peot, 1989 ] .
Reference: [ Lauritzen, 1995 ] <author> S. L. Lauritzen. </author> <title> The EM algorithm for graphical association models with missing data. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 19 </volume> <pages> 191-201, </pages> <year> 1995. </year>
Reference: [ Pearl, 1988 ] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: Although textbooks are available that stress probabilistic methods <ref> [ Pearl, 1988; Russell and Norvig, 1995 ] </ref> , the lack of software suitable for educational purposes has proved to be a big problem for instructors, and is slowing down the process of training new generations of researchers and practitioners in this vital technology. 1 Also known as causal networks, Bayesian <p> Norvig, 1995 ] , the lack of software suitable for educational purposes has proved to be a big problem for instructors, and is slowing down the process of training new generations of researchers and practitioners in this vital technology. 1 Also known as causal networks, Bayesian networks, and belief networks <ref> [ Pearl, 1988 ] </ref> . 2 Also called influence diagrams. 3 The recent announcement by Microsoft of a standard file format for belief networks is a positive development on which we will build. 2 The objectives to be achieved by the proposed research are as follows: 1.
Reference: [ Pradhan et al., 1994 ] <author> M. Pradhan, G. M. Provan, B. Middleton, and M. Henrion. </author> <title> Knowledge engineering for large belief networks. </title> <booktitle> In Proceedings of Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, Washington, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Russell and Norvig, 1995 ] <author> Stuart J. Russell and Peter Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1995. </year>
Reference-contexts: Although textbooks are available that stress probabilistic methods <ref> [ Pearl, 1988; Russell and Norvig, 1995 ] </ref> , the lack of software suitable for educational purposes has proved to be a big problem for instructors, and is slowing down the process of training new generations of researchers and practitioners in this vital technology. 1 Also known as causal networks, Bayesian
Reference: [ Russell et al., 1995 ] <author> Stuart Russell, John Binder, Daphne Koller, and Keiji Kanazawa. </author> <title> Local learning in probabilistic networks with hidden variables. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <pages> pages 1146-52, </pages> <address> Montreal, Canada, August 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We will extend the repre sentation and inference schemes for probability models to include qualitative constraints. * New learning algorithms (Yr.2). Existing methods for learning probabilistic networks from data <ref> [ Russell et al., 1995 ] </ref> will be extended to handle continuous and hybrid models, functional representations of conditional probability distributions, DPNs and the automatic creation and modification of network structure including hidden variables. * Local structure (Yr.2).
Reference: [ Shachter and Peot, 1989 ] <author> R. D. Shachter and M. A. Peot. </author> <title> Simulation approaches to general probabilistic inference on belief networks. </title> <booktitle> In Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence (UAI-89), </booktitle> <address> Windsor, Ontario, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Four principal developments are missing from both commercial and public domain packages: * Hybrid networks containing both discrete and continuous variables [ Lauritzen and Wermuth, 1989 ] . Continuous variables are essential for modelling many real-world domains. * Stochastic simulation methods such as likelihood weighting <ref> [ Shachter and Peot, 1989 ] </ref> .
Reference: [ Wellman, 1990 ] <author> Michael P. Wellman. </author> <title> Fundamental concepts of qualitative probabilistic networks. </title> <journal> Artificial Intelligence, </journal> <volume> 44(3) </volume> <pages> 257-303, </pages> <month> August </month> <year> 1990. </year> <month> 7 </month>
Reference-contexts: We will investigate languages and methods for knowledge-based model construction, in particular for monitoring and controlling processes over time where the structure of the model may need to change dynamically (for example, as new objects enter the system). * Qualitative probability (Yr.2). Qualitative probabilistic networks <ref> [ Wellman, 1990 ] </ref> allow specification of non-numeric constraints on probabilities (e.g., "higher impact velocity increases likelihood of damage"). We will extend the repre sentation and inference schemes for probability models to include qualitative constraints. * New learning algorithms (Yr.2).
References-found: 16

